I find it very difficult to believe anyone actually delivered this message to the OP. Probably the most ridiculous thing I've read all day.
Nope, that's just an implicit join. An Oracle join is a whole different mess. 
I'm not entirely sure you (or possibly your professor) knows what a join actually is. Whatever the case is, if your professor actually said that (which I doubt), he or she is completely wrong. I strongly suggest you either study independently on the subject or seek education elsewhere (probably both). Your SQL provided *is* using a join (as everyone has already stated), can you give an example of the SQL statement you'd envision using instead that is "difficult to read"? Also, what about it do you feel is difficult? I imagine you're writing something like this, which is actually easier to read by most people's estimation (but that's possibly a matter of opinion, it is at least the most common way you'd see it these days): SELECT s.studentid, s.fName, s.lName, n.ContactTelNo FROM student s INNER JOIN nextofkin n ON n.studentid = s.studentid WHERE s.sex = 'm' ORDER BY s.lName, s.fName ; Is that particularly difficult to read?
hahahahaha your professor should get fucked
This happens to me all the time, drives me nuts.
http://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins visualizes all the different joins really well
The trick to 3NF is avoiding transitive values, if check_bounced bool is set to either true or false, you have a transitive value since you can now infer whether the payment method was a check. So as you suspect, you'll have to create a bounced checks table. It's actually not that odd to have a two int value table, a look up table mapping a many to one relationship will only have two int values. Also, you don't need customer ID in the invoice item rental table or the payment table, it's already in the invoice table. Your current setup would mean updating the customer ID would require three updates instead of one. As for order of insert; create customer record if it doesn't exist -&gt; create invoice place holder using Customer ID -&gt; create line items with invoice id -&gt; use line items to update invoice with total -&gt; create payment record using invoice ID. Other functions would have to be created to create bounced check records as applicable, update invoice item records when returned, add additional payments, etc.
University profs often do not have a great deal of experience in the industry, or the last experience they actually had was decades ago. This doesn't surprise me at all. 
Really old-school coders use the SQL-86 standard where joins are all done in the where clause and I occasionally encounter them or their code in the wild. The thing is, the *main* reason why they moved joins from the where clause like the OP's example is that you make one little tiny mistake in that where clause and you end up with a cartesian join, which for larger data sets and smaller hardware can often blow up your server. 
No. It depends on the database kernel and the optimizer. Some are smart enough to figure this sort of thing out. Some aren't. The main reason why they adopted the join syntax in SQL-92 is that you only need a single keystroke mistake to change a where clause join into a cartesian join and blow up your server. 
Damn you, smart quotes!
Joins makes things hard to read? I guess it's more what you are used to. Joins are essential to my job and since everyone uses them, everyone can read them. You can also achieve quite a lot in terms of finding orphan records or certain scenarios based on what kind of join is used If I asked you to show examples of how to show students where there is no in your Next of Kin, how would you go about writing that based on how your professor has taught you? [This should help a little bit to start you in what you are going to get into with joins](http://www.codeproject.com/KB/database/Visual_SQL_Joins/Visual_SQL_JOINS_orig.jpg)
You're 100% right. I'm graduating in May. Last semester I had a professor tell me to never alias my tables. 
That's amazing, thank you! I've tried to make it into a view but theres an error on the [view name] saying no column specified for column 8 of 'viewname' Do you know what this means, I don't understand as it works as a query just not a view :S
That's a real WTF moment right there.
Came here to post that same graphic. It has saved my bacon on more than one occasion. 
You can write joins like that but it always makes it difficult to follow how the tables are joining doing that. I like having the connection inside the from statement: from student s inner join nextofkin n on s.studentid = n.studentid then i can easily change it to left outer, right outer, etc without changing a bunch of code. Plus it is easier for the rest of my development team to understand and read.
Ill try this. Thank you.
I don't find it surprising in the slightest. Anecdote time: A friend of mine in college was in a really severe car accident to where he took over a year to walk again, and had a few years of recovering... Fast forward 10 years (!!!) and he was going back to college, I let him stay with me. By this time I had been a software developer professionally for about 9 years. Most of the work I did was web related, maybe 20-30% in Flash/ActionScript. So my friend is taking this Flash/Actionscript class and he asks me for help with his assignment. I help him complete his assignment the way me and a few of my colleagues would have, and even have a few colleagues vet the work before he turns it in. My friend receives an F for the work because the prof said "I don't understand how this works, if people like ME can't understand it, no one will be able to work on it. .. F" To be clear, we didn't *do* the work for my friend, we just told him how to do it and explained it to him. He told me he learned more that week than he had the whole quarter in the class.
I have been using SQL Server SSRS as a reporting front end to an Oracle database, using MSVS as the development environment. There is a known quirk with the Oracle - Microsoft Query Designer interface that cause all the queries with joins to automatically be rewritten using the WHERE... standard. So it can show up in current code, depending on what you are working on.
You're being downvoted but your statement is true. His professor most certainly should get fucked.
The bane of my existence has been trying to rewrite all the old "Where clause joins" in our SQL Server procedures after I upgraded the machine to 2008 compatibility. Is that a join or a condition? Should I put four ANDs in the ON clause or leave some in the WHERE?
Err... No. Standard Changes are not based on keystroke mistakes. http://stackoverflow.com/questions/334201/why-isnt-sql-ansi-92-standard-better-adopted-over-ansi-89 ...there are well-documented scenarios where the old ANSI-89 Join syntax produces incorrect results... specifically outer Joins when there are conditional filtering predicates on non-Join related columns from the "outer" side of the join.
Never alias your tables A,B,C,etc. I hate trying to update those queries.
The older standard is not even supported by some databases, like SQLServer 2008.
That makes sense. Aliases should be representative of the table. dbo.employeeSalary should probably be aliased as es, etc. 
Are you sure on that? I know for a fact implicit joins work in SQL Server 2012 SP1 (I just tested it to make sure I'm not crazy!). Unless you just mean they're deprecated, in which case you're probably right. 
Try an implicit outer join. I had a stored proc failing and that was the cause. Date 3/8/2013 6:00:00 AM Log Job History (CustomerSat Upload - SFDC-Daily) Step ID 1 Server *********** Job Name CustomerSat Upload - SFDC-Daily Step Name Generate CUSTOMERSAT_SUPPORT table Duration 00:00:00 Sql Severity 15 Sql Message ID 4147 Operator Emailed Operator Net sent Operator Paged Retries Attempted 0 Message Executed as user: NT AUTHORITY\SYSTEM. The query uses non-ANSI outer join operators ("*=" or "=*"). To run this query without modification, please set the compatibility level for current database to 80, using the SET COMPATIBILITY_LEVEL option of ALTER DATABASE. It is strongly recommended to rewrite the query using ANSI outer join operators (LEFT OUTER JOIN, RIGHT OUTER JOIN). In the future versions of SQL Server, non-ANSI join operators will not be supported even in backward-compatibility modes. [SQLSTATE 42000] (Error 4147). The step failed.
http://www.dpriver.com/pp/sqlformat.htm 
Interesting! I think I remember seeing they were being deprecated, wasn't aware they had been removed outside of compatibility level changes. I think I actually remember saying "I didn't even know you could do that" when I read they were being deprecated. Thanks for the info. 
You just said opening_balance is always 0, your first statement will always evaluate as false.
To be clear, you're asking for two very different things. In the first, you're requiring that none of the three be 0, in the second you're requiring that they not all be 0, but one or two columns having 0 is okay.
Experience in the industry is not required to realize that a particular SQL statement is using an implicit join (or that joins are a fundamental component of utilizing a relational database). My point is merely that I doubt the professor said verbatim: "Do not use joins." What he or she might possibly have said was more along the lines of "Do not use ANSI join syntax, it's confusing" (which would be stupid, but would not be nearly as stupid as saying that you should never join tables together). Joining tables is a primary function of a relational database and unless your model is represented by a single flat table is going to be necessary in virtually every use case. TL;DR - I think what we have here is a case where the OP misunderstood the professor and a professor who may or may not also be a completely incompetent boob.
thanks - that's it. Jesus, I thought I was taking crazy pills.
It's probably that the COUNT column is not being assigned a name. Change the COUNT line as such: COUNT(*) AS ' StudentCount', This assigns the column name [StudentCount] to the counting column, which does not have a name by default. 
SQL*Plus: Release 10.1.0.5.0 - Production Any idea how can I solve this problem?
I ended up with this: SELECT opening_balance, movement, closing_balance FROM your_table LEFT JOIN (SELECT 0 o, 0 m, 0 c from dual) r ON o = opening_balance WHERE o IS NULL AND m IS NULL AND c IS NULL but no rows returned and none the wiser.
How did you create a user with brackets in the name. The CREATE USER statement should have failed on that. From the schema naming doc (which user naming is supposed to follow): &gt;Nonquoted identifiers can contain only alphanumeric characters from your database character set and the underscore (_), dollar sign ($), and pound sign (#)
SELECT opening_balance, movement, closing_balance, o, m, c FROM your_table LEFT JOIN (SELECT 0 o, 0 m, 0 c from dual) r ON o = opening_balance and m = movement and c = closing_balance where o is null and m is null and c is null; ; I finally got it with this. Since we were only joining on opening_balance = 0 and it always is, we always got non null values from r. By adding m = movement and c = closing_balance , we are able to get the left join to work appropriately and then the where clause works as expected as well. This was an interesting and fun little exercise/
I'm not sure I follow, do what exactly with a subquery? At some point, if you're joining data from multiple tables together you're either doing so directly (table join), or you're joining together resulting data from multiple subqueries. Regardless: Either you cartesian join everything from all tables/subqueries (arguably still a join) or you inner/outer join the tables/results. I'm still failing to see how you relate data among several tables without using some form of a join. The only way to actually "join" data from multiple tables that I can envision without using some form of join in SQL (implicit or explicit) would be to pull all data from both tables separately and then utilize the resultset to do that joining in whatever script/language you're pulling that data from. But maybe I'm missing something...?
It was intended as a joke. :) Correct version: -- Create a sample table to do joins with CREATE TABLE #temp_tbl ( opening_balance INTEGER, movement INTEGER, closing_balance INTEGER ); INSERT INTO #temp_tbl VALUES (0, 0, 0); INSERT INTO #temp_tbl VALUES (0, 0, 1); INSERT INTO #temp_tbl VALUES (0, 1, 2); INSERT INTO #temp_tbl VALUES (0, 3, 4); -- #temp_tbl could be replaced with your table SELECT * FROM #temp_tbl as h LEFT JOIN (SELECT a=0, b=0, c=0) AS zero ON h.opening_balance = zero.a AND h.movement = zero.b AND h.closing_balance = zero.c WHERE zero.a IS NULL AND zero.b IS NULL AND zero.c IS NULL DROP TABLE #temp_tbl
I would like to see how that professor handles joining a table to itself.
I see, thank you a lot for this answer. At least I know why and that I wasn't making a mistake. I will see what can I do to get SQL*Plus upgraded. Thanks again.
Sorry guys, I understand that the query used an implicit join (after speaking to the interviewer), what I mean is that my prof. told us not to use INNER JOIN, OUTER JOIN, or any other JOIN. One of the guys at the interview graduated a few years back and he said that he thinks he was taught it during the third year.
So what the professor is saying is to not use a specific syntax. FWIW - The professor is wrong, this syntax is extremely common and you should at least understand it. It's also highly readable and downright simple to pickup if you already understand the concepts. The usage of this syntax shouldn't throw you off, assuming you actually understand the concepts behind these joins (which you'd need to understand regardless of syntax). If you understand the different types of joins and what they actually mean you should have no problem understanding one syntax versus the other (the only difference is where these particular pieces of join criteria appear in your SQL statement). My general suggestion? Regardless of which join syntax you use, write your SQL in a clear and consistent manner and it will be much easier for others to read.
Well, the SQL statement functions the same regardless of how cleanly it's provided. If it helps in these situations I would always rewrite the query clearly and consistently in a way that is maximally easy to read and understand. The format I use above is the way I tend to write all my SQL these days and, imo, it makes reading and understanding queries (even highly complex ones) substantially easier to do at a glance. Good luck! :)
Thank you very much, I will attempt to construct my queries in a similar manner. :)
Thank you very much, I'll read up more on what each of the joins do - thank you for your help :)
SQL Server? Oracle?
Thanks very much for this response. Basically, I wasn't going mad; I was just ignorant. ;-) Thanks again. bit of reading ahead of me and some testing, cheers. EDIT: words
The portion of the example you provided: WHERE s.studentid = n.studentid actually ends up creating an INNER JOIN. These are just two different syntax. Your professor seems to be favoring Oracle syntax. Personally, I prefer ANSI syntax, as it separates your join conditions from your filter conditions (Oracle syntax lumps join conditions into the where clause).
I would definitely recommend TortoiseSVN. We use it and it scales beautifully for 1 to 100 people. Integrates with Windows security. Free. Easy to use too.
Thank you! 
well, my company uses TFS (Team Foundation Server). Vault was okay as well. It is basically up to the users and configuration to figure out which system to use. Both have permission systems. TFS is built within Visual Studios and 2012 SQL Server so that is a bonus. 
That's like telling an architect never to use vaulted ceilings, double doors or breakfast nooks. They aren't something you'll use every time or without thinking about it, but you will use them a lot and there's not another way to achieve the result very often. And breakfast nooks are awesome. 
after doing some googling.. check out subversion (even with Tortoise SVN) http://stackoverflow.com/questions/182298/subversion-versus-vault 
I've used Visual SVN Server before. It's super easy and free. You can then use TortoiseSVN as a client, which is also super easy http://www.visualsvn.com/ 
by chance are you in the orange county area :) you have the makings of a great IT guy if you think this way. systems are in place to support the business. you have no purpose if you are not improving and helping the business make and/or save MONEY. otherwise your just a maytag repair guy, sitting around waiting for something to fix.
Nice tip. You know, to this day I still see folks clicking the "go" arrow because they didn't know about Alt-X or F5 (I prefer Alt-X as I still associate F5 with "Execute Package" in DTS). Knowing how to use your tools more efficiently is huge, so it's always good to share time savers! With regards to scrolling, I shudder to recall how we got by before the mouse wheel came around...
Ha thanks. Metro Detroit actually. I am an incessant tinkerer anyway, but yeah, I aim to please.
My favorites: * **ctrl + r** - gets rid of the results window * **ctrl + k, c** - comments highlighted code * **ctrl + k, u** - un-comments highlighted code
Get rid of the results window :-) awesome dude
Ctrl + shift + r is one I've been trying to train myself to use as well. Refreshes the intellisense cache so if I add a new column to a table i can use auto complete as soon as I press the shortcut. I find it takes too long for SQL ms to do it on its own. The option is already up in the menu (edit I think) but this is much handier
The dark days .. The less I remember about those days the better hehe
Why do message boards make ' and ' into ` and ´ in the first place? They are not the same characters damnit. Is it their way of protecting themselves against sql injection or a crule joke on us db guys?
My favorite: sp_help is Alt or Ctrl + F1. Highlight the object - table, index, whatevs and alt + f1 it to get sp help info. It's hugely productive. 
As an addition, you could have done the following. SELECT * FROM your_table as h WHERE (opening_balance + movement + closing_balance) != 0 Note: This only works if all the values are positive, otherwise you could end up with a negative and a positive adding together to be zero, but not all columns being zero.
Found it! For anyone who discovers this and has the same problem here is the solution: "To change this option, on the Tools menu, click Options, expand Designers, and then click Table and Database Designers. Select or clear the Prevent saving changes that require the table to be re-created check box." This was taken from the following link if you would like further reading: http://stackoverflow.com/questions/9870968/cant-change-table-design-in-sql-server-2008 
Not entirely sure why you would want to do this; the normal/better practice is to convert/cast a datetime on the select/data pull **or** convert in code at a later period, for a few reasons: * Datetime can be easily converted to different formats * Datetime querying is better optimized than string comparisons * Datetime takes up less space then a corresponding string representation * Binding a datetime to a variable in almost all IDEs is easier/better supported because they have pre-built functionality, where the string representation often has to be added manually. Additionally, doing what you described has the detractor of breaking any entity model(or similar) connected to the database. 
I was just asked to investigate whether it was possible to change the data type of the column between the specified above types, with data on the table. Thanks for the information though, i'll relay it just incase.
For the time component, I know other applications add the number of seconds past the time of epoch. So I think the SQL Value is just the number of seconds from epoch. Figure out what the date and time is and you can just add the sql value in terms of seconds to figure out the current datetime, and then parse out the time. This is a guess on my part, but doesn't hurt to try. Not sure abou tthe longitude value.
When editing a table directly ("Edit top 200 Rows"), you can click on the sql button in the toolbar ("Show SQL Pane"). This will allow you to edit the conditions of what's showing up. Obv. you can't do joins since you need to select from the one table you're editing, but you can do all kinds of narrowing down in the WHERE statement. Also: "Edit"&gt;&gt;"Advanced"&gt;&gt;"Word Wrap"
oh lordy... sooo... Management studio has a very bad way of doing things when it comes to changing the columns on something. As in it will create a temp column, put all the data in there, then drop the original column, then create the old column in the new type and put all the data in the new/old column and drop the temp column. This is fine for small tables, NEVER do this for large tables. Plus... I'm siding with Coldchaos here... why do you need to change the column from an awesome datatype to that generic type? I almost can 100% guarantee that this will slow down everything that touches that column now.
Long and lat is a float, too.
I think you're a bit smarter and this question is going over my head, but i've had a bit to drink so I will just confirm what I meant. I don't think SQL does any calcs for long/lat, he's not talking about the geography data point :s
For the (HH:MM:SS) format the following should work: -- Replace '08:06:41' with your datetime field in the database SELECT convert(integer, convert(binary(4), convert(datetime, '08:06:41', 8))) Not sure on/where your formatting for lat/long come from, if I knew more about it I could try to help. &gt;------------ Edit - As I suspected, it does appear that your manual conversions are wrong. Datetime has a length of 8 bytes, of those... * The first four bytes is number of days since '1900-01-01' (in your case zero because you don't care about how many days) * The second four bytes is the number of clock-ticks since midnight equaling 3.33 milliseconds each. Example: * **'08:08:06'** in hex is **0x00860F88** which is **8785800** as an integer * **3.33**ms per tick, and **3600000** ms in an hour. * (**8785800** X **3.33**) / **3600000** = **8.17~ hours**
The only possible excuse for telling you not to use explicit JOIN statements is because that material is for a later course. Badly written JOINs or JOINs that do not have proper indexing can cause problems. Unless you're dealing with vastly large data sets or you're using a crappy RDBMS that doesn't optimize JOINs well or is misconfigured, the performance impact on the server is going to be significantly less than the performance impact you'd have to make in your application to merge the data together there. The people who program databases are extremely good. Chances are, the code they wrote to join the data is going to be far better than the code you're writing to combine two result sets in your application. Joins confuse a lot of people with SQL, but IMO it confuses them because *they wait too long to learn them*. People treat them as arcane or obscure when they're... really not. I learned SQL by being required to be the sole support for an in-house PHP/MySQL application, so I really learned via trial by fire. The biggest problem with learning SQL is the fact that you either understand working with declarative sets, or you don't. Unfortunately, not everybody who can write a procedural program understands working with a set mentality. This means that people who are perfectly capable of working with Java or C# or PHP are completely incapable of understanding SQL. The biggest problem I had in school with database classes is that I understood the relational model better than most of my teachers (whose experience ended with Access, as often as not). For some reason I'm able to visualize most database queries intuitively. SQL is one of the few areas that I had much better luck teaching myself instead of attending a class. It paid off; one of my major roles is as a DBA, and I couldn't be happier. 
The "go" arrow in SSMS is actually for Debug, not Execute, which makes it more annoying since in Query Analyzer it was for execute.
That was my idea when I read the title also. Just make a dummy column, copy the data over, then delete and recreate the original, then copy it back. I went to the comments to see if there was a better option. Apparently not. With dates and strings the others would work. But if you had a bit column and needed to add a third state, you could only do the temp column option to convert it to an integer.
How to convert your unix timestamps to a SQL datetime: &gt;select dateadd(second, 1359014801, '1970-01-01') -- 2013-01-24 08:06:41.000 &gt;select dateadd(second, 1359014886, '1970-01-01') -- 2013-01-24 08:08:06.000 Not sure about the latitude longitude though.
Which table has the "Blah door 1" / "Blah door 2" entries in it? edit: What purpose does the plantrouting table serve in this query?
Grouping seems a good idea, you can even do max(1) can't you? 
Well why even return a column at that point? I think the OP wants some data from that column.
for the future, if you need to take data out of a table and into another one, you can use bcp if you are familiar with the command prompt commands.
Right, one of the columns if it's numeric, with the max as you said
The following or very similar should work, it will create a list of the doors for each destination, to a maximum of four, then use that instead of creating a row for each entry. SELECT DISTINCT e.Arrival, c.SupplierName, r.DestName, a.ControlNumber AS [SID], a.GrossWeight FROM ManualAsnMaster a INNER JOIN plants b ON a.plantid = b.plantid LEFT JOIN suppliers c ON a.supplierid = c.supplierid INNER JOIN (SELECT plantid, DestName(SELECT t.plantid, destinationid, MAX( CASE rownum WHEN 1 THEN t.destinationName + '; ' ELSE '' END ) + MAX( CASE rownum WHEN 2 THEN t.destinationName + '; ' ELSE '' END ) + MAX( CASE rownum WHEN 3 THEN t.destinationName + '; ' ELSE '' END ) + MAX( CASE rownum WHEN 4 THEN t.destinationName + '; ' ELSE '' END ) AS DestName FROM (SELECT rownum = ROW_NUMBER() OVER (PARTITION BY plantid ORDER BY destinationName), plantid, destinationid FROM destinations) AS t GROUP BY t.plantid, destinationid) AS r ON a.plantid = r.plantid INNER JOIN plantrouting d ON f.destinationid = d.plantid AND a.receivedwid = d.warehouseid INNER JOIN trailers e ON a.trailerid = e.trailerid WHERE arrival &lt; @EndDate AND arrival &gt;= @StartDate AND e.WarehouseID = @WarehouseID I use something similar to build a list of all contributors to a booking, so there is only one row per booking. Edit - Just realized that you used something other than plantid later on, I changed it a bit; should be close, hard to do without the tables to test against.
Nope. I wear khakis and a button down shirt. I work in the public sector, though. A medium size school district, to be precise.
Could you point me to any step by step instructions on how to user SSIS to do this? I haven't played with it much
wha? why would you insert something and then select it back out again? are you perhaps thinking of the INSERT... ON DUPLICATE KEY UPDATE option?
Just a suggestion... I would recommend splitting your schema into an artists table, and instead of querying all the tracks where artist LIKE '%CHEESE%', instead you pass a lit of artist id's. select * from library where artistid IN (1234,4367,2748) This way, if you want to playlist a band called CHEESE, you aren't also playlisting an artist called MOULDY BLUE CHEESES 
ix2 is redundant, since there are already root index nodes held in ix3. ix3 however, provides no indexing which would replace the need for ix2. 
Two things: 1) Please don't use * in your SELECT statements unless you are just testing things out. 2) It's a DB, not a spreadsheet. You should be normalising your data and at least separating out the artists and genres into separate tables. A well designed and normalised databaseis required for data such as that which you propose, after all MySQL is an RDMBS. It will be much easier to index, write queries for, have a smaller footprint and be more responsive. If you have other people writing queries for this DB but they might struggle with the schema, then they need to get some practice in writing and understanding joins. The other thing would be to write an API of some sort to allow other people to pull data without having to know T-SQL.
Thanks for the feedback. 1) Agreed. 2) As I noted in my other reply, I am aware and certainly use proper relational object practices when I write applications. However, the goal of this fun project is to see if sufficiently long queries can replace radio djs, regardless of the dataset. So, the overall app isn't intended to allow people to run queries on my personal dataset, but to share queries amongst datasets hosted wherever. I'm expecting best practices to go out the window on this, with regards to the library datasets being queried. The application itself follows best practices, but the individual library db's are currently using a single table. I'm trying to create the pandora/last.fm/autoplay experience using personal media collections. Creating an API would end up in just another smart playlist experience http://i.imgur.com/ZICtCiL.jpg The service aspect from the app involves converting various media library db files (itunes, beet, rhythmbox, etc) to a standard table and generating the m3u's and/or loading up a media player queue somewhere. Do you have any thoughts on targeting such a skill level (good enough to swap/enhance/personalize basic or even advanced queries), still believe I should create additional tables and document the standard assuming user base can perform joins, etc., or keep it a personal project as there is no value in social/shared music playlist generating queries?
Ok, I didn't realise people were sharing queries Is there a reason why you're not just using a direct match then? where artist = 'cheese' 
I probably should be doing direct match, hopefully with enough edits they eventually will be. It was done at first as a quick fix to inconsistent artist labeling ( "the string cheese incident", "string cheese incident", "string cheese ft. some guy", etc ) to be overly inclusive for moments of laziness. Hard to find time to curate the source library.
I think this would do it CREATE VIEW CourseReport AS SELECT Department.DepartmentCode, Department.DepartmentName, Course.CourseNum, Course.CourseTitle, Course.NumCredits, Prereq.PrereqCourseNum, Prereq.PrereqDepartmentCode FROM Department JOIN Course on Department.DepartmentCode=Course.DepartmentCode LEFT JOIN Prereq on Prereq.CourseNum=Course.CourseNum AND Prereq.DepartmentCode=Course.DepartmentCode; 
i think the important point of learning the various joins is to start using the explicit JOIN syntax (INNER JOIN, LEFT OUTER JOIN, RIGHT OUTER JOIN, FULL OUTER JOIN) instead of the old style "comma joins" where you list the tables in the FROM clause and then specify the join conditions in the WHERE clause explicit JOIN syntax is actually really simple, once you get started...
I dont think it should be allowed on the list if the backups work and the data was recovered. Outtage is one thing, lost data is another thing entirely.
Left join 
Outer joins is the right answer. Not sure why this was at 0.
Agreed, even the best systems can have outages from unplanned for/unforeseen situations. For services like Amazon this is obviously a net loss due to reduced business, but for general services as long as the data is recovered it shouldn't really be considered a disaster; maybe an incident. 
&gt; I'm lost trying to figure this out. not gonna do your assignment for you surely you took notes during the course? reviewed examples of joins? give it your best shot, and we'll help you make corrections
#1 SELECT * FROM dbo.students AS s --know * is bad form, don't care INNER JOIN dbo.courseEnrollments AS e ON s.student_id = e.university_id INNER JOIN dbo.courses AS c ON e.course_id = c.course_id WHERE s.student_id IN (SELECT s.student_id FROM dbo.students AS s INNER JOIN dbo.courseEnrollments AS e ON s.student_id = e.university_id INNER JOIN dbo.courses AS c ON e.course_id = c.course_id WHERE c.course_code = 'CSC330') If you really care about only choosing one student, just use the following in the subquery instead, or use an additional WHERE clause to find a specific student. SELECT TOP 1 s.student_id 
#2 SELECT * FROM (SELECT s.student_id, e.grade, c.* FROM dbo.students AS s INNER JOIN dbo.courseEnrollments AS e ON s.student_id = e.university_id INNER JOIN dbo.courses AS c ON e.course_id = c.course_id WHERE c.course_code LIKE 'MATH%') allmath INNER JOIN (SELECT s.student_id, e.grade, c.* FROM dbo.students AS s INNER JOIN dbo.courseEnrollments AS e ON s.student_id = e.university_id INNER JOIN dbo.courses AS c ON e.course_id = c.course_id WHERE c.course_code LIKE 'CSC3%' or c.course_code LIKE 'CSC4%') AS allcs ON allcs.student_id = allmath.student_id WHERE allcs.grade &gt; allmath.grade 
That's all the help you get from me, neither of my other ones are fully complete, but if you are in a third year CS course and can't even figure it where to go from here, you should feel bad and probably deserve to fail.
 WITH TMP_AVGSAL AS (SELECT AVG(SALARY) AS SALARY FROM EMPLOYEES ) SELECT E.EMPLOYEE_ID, E.SALARY FROM EMPLOYEES E JOIN TMP_AVGSAL AS ON E.SALARY &lt; AS.SALARY WHERE LAST_NAME NOT LIKE ('%Z%')
You're question isn't quite clear as to whether or not your average is of employees without a Z, or if you're only looking for employees with a below average who don't have a Z, or both.
The most efficient way is to use analytic functions (but not all RDBMSs support them) : SELECT employee_id, last_name, salary FROM ( SELECT employee_id, last_name, salary, avg(salary) over (partition by department_id) dept_avg FROM employees WHERE last_name NOT LIKE '%z%') WHERE salary &lt; dept_avg ORDER BY salary, last_name otherwise... SELECT e.employee_id, e.last_name, e.salary FROM employees e JOIN ( SELECT AVG(salary) dept_avg, department_id FROM employees GROUP BY department_id) a ON a.department_id = e.department_id WHERE (e.last_name NOT LIKE '%z%') and (e.salary &lt; a.dept_avg) ORDER BY e.salary, e.last_name 
It's average of ALL employees, then display the salaries of employees in a group with an employee NOT with a 'z' in their last name. I actually JUST figured this out, and am about to post my result. 
You can't use lastname in the having clause because you haven't grouped by it. Use where instead (goes before the group by).
I just came up with the result.... i was over thinking this way too much. SELECT employee_id, last_name, TO_CHAR(salary, '$999,999.00') as Salary FROM employees WHERE salary &lt; ( SELECT AVG(salary) FROM employees) AND department_id NOT IN ( SELECT department_id FROM employees WHERE last_name LIKE '%z%') ORDER BY salary;
Thanks, yeah I figured that as much... but I solved the problem on my own already. Just took some time to work through the logic. 
wow, that's on another level of SQL I'm not on yet.
Not perfectly sure, but it may be that user accounts are explicitly granted the permissions, while the system account is implicitly granted it?
I am constantly impressed by window functions in use. In this case, though, I think the simple GROUP BY is more readable.
It sounds like a regular inner join is what you are looking for here. SELECT u.UserName, p.PhoneNumber from User u INNER JOIN PhoneNumbers p on u.a_id = p.a_id WHERE p.PhoneNumber in (1,2,3,4,5) This will give you all the records where a user has a phone number in the list of numbers you are looking for. Does this help?
There are a few ways to do this: Pseudo code because I am on my phone: Select distinct user_id from users inner join phonenumbers. On users.user_id = phonenumbers.user_id Where phonenumbers.num in your list. And not exists (select 1 from phonenumbers pn2 where pn2.user_id = users.user_id and pn2.number not in your list) Or: Select user_id from users Where exists (select 1 from phonenumbers pn where pn.user_id = users.user_id and number in your list) Except Select user_id from users Where exists (select 1 from phonenumbers pn where pn.user_id = users.user_id and number not in your list) The "except" keyword varies from database to database. In SQL server it is "except" in others I think it is minus. Respond if you have questions about how either of these works. 
I think he's looking to exclude entirely those Users who have even a single number NOT in the list. I would think an IS NOT NULL sub query on table B might work, but a) I'm on an iPad and b) I don't know what SQL flavor OP is using.
So tblA has columns a_id and User, tblB has columns b_id (I'm assuming, but not needed exactly), a_id, and Number SELECT tblA.User FROM tblA WHERE User NOT IN ( SELECT tblA.User FROM tblA INNER JOIN tblB ON tblA.a_id = tblB.a_id WHERE tblA.Number IN (1,2,3,4,5) /*Your number list*/ ) It sounds like that should do it. You could store your numbers list in a variable or you could put them in another table, and change that to a subquery, to make it more dynamic. I hope that works, I've been unable to find a SQL-related job for a couple years, so I'm feeling a bit rusty.
Could just add an 'AND NOT IN (6, 7, ...)' or 'AND NOT BETWEEN x and y'
Yes, in my job I'm surprised how often I find a use for them, and how much easier they make in solving complex query scenarios. In my opinion one of (if not the) most useful addition to SQL syntax in its history.
I disagree. Many businesses use *operational* databases. I work for a school district, for example. Do you think a downtime in the student information system -- which handles attendance entry, grades (both marking period and teacher gradebooks), and student contact information among other things -- could handle a three day downtime without any problems? If the system were down for an extended period in the fall we'd actually risk our state funding of $80 million USD due to being unable to complete mandatory reports. Similarly, we have a database that centralizes the cafeteria system. Do you think a couple days of not being able to use a cash register or identify which students get free or reduced lunch is acceptable? Now consider more serious cases. How much money do you think would be lost if a stock trading company's operations database were down or trade management system were offline? How about a bank where account holders expect to be able to write checks and use automated bill paying? What if the patient database at a hospital suddenly went offline? Patients aren't going to stop dying just because your doctors can't access the necessary medical images to diagnose the problem. When data can't be retrieved, a database is largely indistinguishable from a landfill. Lack of availability can, in many cases, be just as damaging as outright data loss. 
Thats probably not the best solution as you'd have to specify all the numbers you didn't want or multiple ranges. You could do SELECT u.UserName, p.PhoneNumber from User u INNER JOIN PhoneNumbers p on u.a_id = p.a_id WHERE p.PhoneNumber in (1,2,3,4,5) AND u.UserName NOT IN ( SELECT u2.username FROM User u2 INNER JOIN PhoneNumbers p2 on u2.a_id = p2.a_id WHERE p2.PhoneNumber NOT IN (1,2,3,4,5) ) 
http://www.merriam-webster.com/
Databases in the Cloud, yech.
I think this is what you are looking for. It ensure's the user has atleast 1 known phone number while eliminating them if they have any non-known phone number. select distinct u.* from user u join PhoneNumbers p on (p.username = u.username and p.phonenumber in (1,2,3,4,5) ) where u.username not in (select username from PhoneNumbers p2 where p2.PhoneNumber not in (1,2,3,4,5) )
It's not clear to me exactly what your question is -- you want to know how to do this in a PL/SQL stored procedure or what? Are you trying to figure out how to construct a SQL query statement at runtime? 
"When SYSTEM, SYS, or a user authenticating with SYSDBA or SYSOPER privileges connects or logs in, SQL*Plus does not read the PUP table. Therefore, no restrictions apply to these users." From here: http://docs.oracle.com/cd/B10501_01/server.920/a90842/ch10.htm Yeah, it's from an older release but I'm pretty sure it's still true. 
Sorry. I added a bit to ask what I'm looking for... "How would I put the column name I need into a variable? Or can all of this be done in the context of one query inside the SP?"
Thanks! I guess I'm trying to use Dynamic Substitution. Still trying to figure out how to get the result of a SELECT into the value of the variable.
INNER JOIN will only return rows that have values from both the 'left' and 'right' tables. 
If you can write your select so it's guaranteed to be single-valued, then "select into". Otherwise, your best bet is a cursor loop. 
YES! This worked. Thank you! Could you possibly explain this? I gather that when you type LEFT JOIN product pr "pr" becomes a variable that you can use later for shorter code? Could you explain the LEFT JOIN versus a "JOIN"? I have been reading about it, but can't quite wrap my head around it. 
Sure. The pr part is an alias. When you call a field that is in multiple tables, SQL doesn't know which one you are referring to. So you have to add the table name to the field. The alias makes this simpler. Joins are like a venn diagram. [This link has a good visual explanation](http://www.codinghorror.com/blog/2007/10/a-visual-explanation-of-sql-joins.html).
We're technology providers, so we should utilise the technologies which best provide solutions. Familiarity comes from exposure or need, so if people in your team don't understand analytic (window) functions, they never will unless they are made familiar with them. I was working on some code the other day trying to evolve a query of about 200 lines with some new requirements, I realised it could be written in about 10 lines using LEAD and LAG analytics. It is now more readable, more maintainable and about 300% faster. Win win. I could've bolted onto old syntax but I embraced the new, because the benefits far outweigh the cons.
Try LEFT OUTER JOIN ... WHERE BID.ItemID IS NULL On my iPod at the moment so it's hard to remember your scheme while I'm commenting.
 WHERE AUCTION_ITEM.itemID NOT IN (select unique itemID from BID) 
Take BID.amount out of the select list in tge query since you want auctions with no bids 
This executed successfully, except it didn't return any results just the column names. (It should bring back 2 results with the data I've already put in.)
Two ways to exclude rows that exist in a second table First and most straightforward is the not in: SELECT AUCTION_ITEM.itemName, AUCTION_ITEM.itemDescription FROM AUCTION_ITEM WHERE AUCTION_ITEM.itemID NOT IN ( select itemID from BID) GROUP BY itemName, itemDescription The "Not in" method is useful because it lets you add a where clause, group by, top 10, having, or just about any other query logic. The problem with "not in" is it doesn't perform very well, you're basically running a query, and then running a separate query after that one completes. Since it appears you don't need a where clause the better solution would be to left join and filter rows where a matching record in the right table is found. The left join exclusion is quite often faster because it's using a section of the sql engine that's always heavily optimized, joins, because most sql engines are tuned for relational databases. This solution relies on implicit vs explicit join conditions, while there is some nuance to that subject, basically the difference is where you establish the relation between the two tables. There are two places where it's common to tell sql how to relate the tables, first and most common nowadays is in the on clause (explicit join), the other and more old school is in the where clause (implicit join). Ok with that out of the way only one more piece of ground work to get down, how a left outer join works. A left outer join selects all rows from the left table (eg: the table being joined against) and conditionally selects rows from the right table that match the on condition. If no match can be found it sets the columns for the right table to null. Ok, what you want is to find all rows in the auction_Item table, that do not have a match in the bids table. In this case it's desirable to establish what column(s) we are using to tell when items are related, which is Item_ID. Then once we have the relation established, we use an implicit join condition to eliminate rows from the left table (which if you recall are all selected in a left join). Here is the code for that: SELECT AUCTION_ITEM.itemName , AUCTION_ITEM.itemDescription FROM AUCTION_ITEM LEFT OUTER JOIN BID ON AUCTION_ITEM.itemID=BID.itemID WHERE BID.ItemID IS NULL GROUP BY AUCTION_ITEM.itemName , AUCTION_ITEM.itemDescription So bascially we use the outer joins on clause to establish the relation, then we use the where clause to eliminate rows where a matching row exists in the right table. I also corrected a few other errors in your query, the largest being that you were selecting bid amount but not including it in the group, or performing some aggregation on it such as a sum. I'm guessing since bids is likely to be a many to one relationship to auction_items, that when you joined them you got back a bunch of duplicate records on the left table. Which is why you included the group by to try and get a single result set. I suspect the group by isn't necessary, but I left it in just in case you can have duplicate names and descriptions, and it isn't likely to hurt anything if that's not the case. Anyway, hope this helps, sql OTJ training is like drinking from the firehose, so I wish you luck.
The two most efficient approaches to achieve what you want use NOT IN and NOT EXISTS. Joins with IS NOT NULL cannot use an index, so are generally not a good idea. select i.ITEMNAME, i.ITEMDESCRIPTION from AUCTION_ITEM i where not exists (select null from BID b where b.ITEMID = i.ITEMID) select i.ITEMNAME, i.ITEMDESCRIPTION from AUCTION_ITEM i where i.ITEMID not in (select distinct b.ITEMID from BID b) As a rule NOT EXISTS performs better as it can perform short circuit evaluation (once one found, bail) and unlike NOT IN doesn't have to consider nulls. 
You shouldn't really need the "GROUP BY" clause. You're only going to see each item once, since it's not joining to any records in the bid table. Also, "ISNULL" is a function that replaces the value for a column with a specified value (i.e. "ISNULL(bid.amount, 0 )" would output a zero instead of NULL if the bid amount is null). "IS NULL" is a comparison (what you were trying to do) where the word "IS" acts like an equal sign, except that using equal signs with NULLs always comes out false (unless you have ANSI NULLS turned on apparently, but I've always avoided that). So NULL *IS* NULL, but NULL != NULL (except NULL != NULL is also false. NULLS are weird that way. NULL never equals anything, and never doesn't equal anything. It is both everything and nothing. It's a lot like God in that respect. Do not question whether or not NULL exists, as it both does, and does not, and so the question itself is pointless.)
Just wanted to add that I typically use "select 1" instead of "select null" in the not exists clause, probably does not make a difference, but it is fewer keystrokes ;) Also I believe the "not exists" method will work for more cases than the "left join" method, I remember having problems with edge cases using left join years ago with regards to duplicate data.
http://sqlzoo.net/ has great tutorials, if you have any specific questions I'm sure reddit or another board will be able to help.
My bad with the crappily titled post, I haven't eaten lunch yet and I think I've been staring at code for too long..
&gt; it's pulling all 4 columns which isn't what I'm looking for so maybe you could explain in more detail what you want, because that query sure looks like it's doing what you asked -- "pull the max integer and use data from the other three columns"
Sorry for being unclear, I now I have a belly full of chinese food to bring me back to the world of the somewhat sane. The gist of it is, there are multiple SKU_CODEs per each comp_code qty_bkd_prof_code combinations, each sku_code has its own qty_bkd_prof_lev_num. I only want to see the records with the largest qty_bkd_prof_lev_num. My group by is specifying sku_code, so it's just returning each value, he's an example of a result with or without the max function and my group by: 01,PC,PLT,1 01,PC,CASE,2 01,PC,EACH,3 here's what I want the code to return: 01,PC,EACH,3 Now, I know I could build a subquery that returns MAX(QTY_BKD_PROF_LEN_NUM) for each comp_code, qty_bkd_prof_lev_num and then work from there, but I would just like to use cleaner looking code if possible.
i'm afraid that this is the cleanest it's gonna get... SELECT t.comp_code , t.qty_bkd_prof_code , t.sku_code , t.qty_bkd_prof_lev_num FROM ( SELECT comp_code , qty_bkd_prof_code , MAX(qty_bkd_prof_lev_num) AS max_int FROM m_qty_bkd_prof_d GROUP BY comp_code , qty_bkd_prof_code ) subq INNER JOIN m_qty_bkd_prof_d t ON t.comp_code = subq.comp_code t.qty_bkd_prof_code = subq.qty_bkd_prof_code t.qty_bkd_prof_lev_num = subq.max_int 
that's very similar to what I would up doing, it's ugly, but it works SELECT D.COMP_CODE, D.QTY_BKD_PROF_CODE, D.SKU_CODE, M.LOWEST_SKU FROM M_QTY_BKD_PROF_D D JOIN (SELECT D.COMP_CODE, D.QTY_BKD_PROF_CODE, MAX(D.QTY_BKD_PROF_LEV_NUM) AS LOWEST_SKU FROM M_QTY_BKD_PROF_D D GROUP BY COMP_CODE, QTY_BKD_PROF_CODE) M ON D.COMP_CODE = M.COMP_CODE AND D.QTY_BKD_PROF_CODE = M.QTY_BKD_PROF_CODE AND D.QTY_BKD_PROF_LEV_NUM = M.LOWEST_SKU 
Thanks for taking a look at it. I actually cross-posted it to stack overflow and someone was able to help figure it out. Here it is in case you're interested: http://stackoverflow.com/questions/15819530/trouble-with-a-mysql-query I'm going to put an edit in my post to let people know it's been answered.
http://sqlfiddle.com/
http://sqlzoo.net/
http://www.dpriver.com/pp/sqlformat.htm
http://data.stackexchange.com/stackoverflow/query/new Some real data to play with.
I second sqlzoo.net. It helped me get a job because I practiced on this so much without knowing a single thing about sql.
I'm trying to do the same, any other advice?
Do they have an answer key somewhere at sqlzoo? I started doing their tutorials this week and there are a few that I just can't seem to get. I'd be nice to just see the answer and move on.
... well, well, well, lookee here, we got a sql guy who places commas at the end of each line instead of the beginning... :)
I hoping to find the same thing. 
It is possible for a large table but you have to be pretty sofisticated. Set up a transaction that from the commited values on the table creates a new table with the correct schema and then loads the records in batches so not to fill tempdb with the new values. Then at the end just drop table1 and rename table2 to table1s name and commit.
What type of job did you get and what type of responsibilities do have at your job, if you don't mind me asking?
I think a few questions are in order before someone can answer yours. What RDBMS are you using? What version? What does your expected output look like? For example is items in the final output? Could you provide the CREATE TABLE/INSERT statements of the original tables so we could build a query? Thanks!
Just this? select /*orderid,*/ sum(deliveryfees) from (select distinct orderid, deliveryfees from orderfee) --group by orderid Commented out the orderid since you want 40, not 1|20, 2|20
Thanks for that..but now the DeliveryFees is an alias column.\ It's actually calculated by using Max(....)as DeliveryFees. How can I add that to the query? Also, this is supposed to be a subquery.
&gt; Also, this is supposed to be a subquery. homework assignment? nothing ~has~ to be a subquery if there's an easier way to do it
no it's not an assignment at all. It's just that there's already a query and I need to extract the Sum of Fees from it without messing up the whole main query.
absolutely right, there's too much unknown here OP, please provide the table layout
Ok, Here you go SELECT a.idOrder, g.nmPerformance, b.idAccount, Max(Case When fees3.idFee=39 And fees3.idFee is not null then fees3.amFee else 0 end) as DeliveryFee FROM Orders a LEFT JOIN LEFT JOIN Account b ON a.idAccountCreatedBy = b.idAccount INNER JOIN OrderItem e ON a.idOrder = e.idOrder left outer join Delivery delv on delv.cdDelivery=e.cdDelivery left outer join Fee Fees3 on Fees3.idFee=delv.idFee INNER JOIN Performance g ON f.idPerformance = g.idPerformance GROUP BY a.idOrder, b.idAccount, g.nmPerformance order by b.idAccount, g.nmPerformance I'll try to explain: This query displays what the idAccount sells from performances in certain Orders and it calculates the DeliveryFee so the output is * Performance1 idAccount_1 idOrder_1 20 * Performance2 idAccount_1 idOrder_1 20 Edit: I'd like to calculate the sum of Delivery Fees but they get doubled (=40) but it's supposed to be (20) because it's per Order not per item. 
that query has a bunch of syntax errors (for instance, there is no "e" or "f" or "j" table) also, there seems to be no reason to LEFT JOIN to "b" and "b1" since you aren't using any columns from them but let's assume the query is fine... which column is Items and which is OrderID?
Well, I had to minimize it a little bit, so I removed some tables that are not important. Items is Table Performance g. OrderID is Table Orders. a.idOrder, b.idAccount, g.nmPerformance
 SELECT a.idOrder, g.nmPerformance, b.idAccount, Max(Case When fees3.idFee=39 And fees3.idFee is not null then fees3.amFee else 0 end) as DeliveryFee FROM Orders a LEFT JOIN LEFT JOIN Account b ON a.idAccountCreatedBy = b.idAccount INNER JOIN OrderItem e ON a.idOrder = e.idOrder left outer join Delivery delv on delv.cdDelivery=e.cdDelivery left outer join Fee Fees3 on Fees3.idFee=delv.idFee INNER JOIN Performance g ON f.idPerformance = g.idPerformance GROUP BY a.idOrder, b.idAccount, g.nmPerformance order by b.idAccount, g.nmPerformance I'll try to explain: This query displays what the idAccount sells from performances in certain Orders and it calculates the DeliveryFee so the output is Performance1 idAccount_1 idOrder_1 20 Performance2 idAccount_1 idOrder_1 20 Edit: I'd like to calculate the sum of Delivery Fees but they get doubled (=40) but it's supposed to be (20) because it's per Order not per item. 
There is nothing that prevents my query from being used as a subquery. If you want to sum the MAX, then max the inner query. select sum(fees.maxfees) from ( select ofee.orderid, MAX(ofee.deliveryfees) maxfees from orderfee ofee group by ofee.orderid ) fees
That didn't work with me. It displays the same Value of the DeliveryFee and it doesn't perform any summation. Can you please check the code in the comments?
I forgot to change the column name I was summing. Try it now. Might also be a good idea to alias the tables to avoid parser confusion.
okay, so where i was heading was basically what THLycanthrope said, put your query into a subquery... SELECT idOrder , SUM(max_delivery_fee) AS sum_delivery_fees FROM ( SELECT a.idOrder , g.nmPerformance , b.idAccount , MAX(CASE WHEN fees3.idFee = 39 AND fees3.idFee IS NOT NULL THEN fees3.amFee ELSE 0 END) AS max_delivery_fee FROM ... ) AS yourquery GROUP BY idOrder 
The cleanest is using analytic functions.... (Here I use ROW_NUMBER rather than RANK to avoid duplicates). select COMP_CODE, QTY_BKD_PROF_CODE, SKU_CODE, QTY_BKD_PROF_LEV_NUM from ( select COMP_CODE, QTY_BKD_PROF_CODE, SKU_CODE, QTY_BKD_PROF_LEV_NUM ROW_NUMBER() over (partition by COMP_CODE, QTY_BKD_PROF_CODE order by QTY_BKD_PROF_LEV_NUM desc) as RNUM from M_QTY_BKD_PROF_D) where RNUM = 1 
very nice! I'll have to give this a shot
totally agree on a dates table, but you may not need to have columns for values which simple display functions can provide month of year might be one to include, if you were interested in searching on records in, say, august across multiple years (since you'd index that column, whereas you couldn't index a function call), but not for month name, which you would never search on 
[This](http://www.reddit.com/r/SQL/comments/14pplc/mssql_grouping_by_fortnight/c7fazjt) is a comment I made in an earlier thread with code for SQL Server to create a "Date" table - with population.
Hi SELECT YEAR(GETDATE()), month_index.month_name, sales_data.sales FROM ( SELECT 'January' as month_name, 1 as month_number UNION SELECT 'February', 2 UNION SELECT 'March', 3 UNION SELECT 'April', 4 UNION SELECT 'May', 5 UNION SELECT 'June', 6 UNION SELECT 'July', 7 UNION SELECT 'August', 8 UNION SELECT 'September', 9 UNION SELECT 'October', 10 UNION SELECT 'November', 11 UNION SELECT 'December', 12 ) as month_index LEFT JOIN ( SELECT YEAR([timestamp]) AS year_name, MONTH([timestamp]) AS month_name, COUNT(*) AS sales FROM table1 WHERE YEAR([timestamp]) = GETDATE() GROUP BY YEAR([timestamp]), MONTH([timestamp]) ) AS sales_data ON month_index.month_name = sales_data.month_name ORDER BY month_index.month_number DESC;
Sorry for the late reply and thanks for your reply. I've just tried your query but there's an error that says he can't bind the idOrder. I tried "yourquery.idOrder" but still doesn't get it. Any idea?
Thanks a lot.
Its like... don't do this... nooo... Then again, this forces the issue... assuming i got the logic right. But ya... you prolly won't want to do this for a massive query. I would almost just batch it by month and insert into a results table. You can even make it so it inserts into a real table so you can keep track of it through the process and pick up where it left if it errors out. Here's the bad code: declare @Tab table (provider varchar(50), Year smallint, Month smallint, dat as Convert(date,convert(varchar(4),year) + '-' + convert(varchar(2),month)+ '-1')) Insert @tab (provider,year,month) values ('Dr Smith',2012,1),('Dr Smith',2012,2),('Dr Smith',2012,3),('Dr Smith',2012,7),('Dr Smith',2012,8),('Dr Smith',2012,10),('Dr Smith2',2012,1),('Dr Smith2',2012,3) declare @mindate date = (select min(dat) from @tab) declare @maxDate date = (select max(dat) from @tab) ;with cte as ( Select Dateadd(month,number,@minDate) as Mnth from master.dbo.spt_values where Type = 'P' and Number between 0 and DateDiff(month,@mindate,@maxdate) ), cte2 as( Select Mnth as [Month], DateName(month,mnth) as [MonthName], sum(case when t.Provider = t2.provider then 1 else 0 end) as [Count], t2.provider from cte c left join @Tab t on c.Mnth = t.dat cross join (select distinct provider from @Tab) t2 group by mnth,t.provider,t2.provider,DateName(month,mnth) ) select [Month] ,[MonthName] ,max([count]) as [Count] ,Provider from cte2 group by [Month], [monthname], provider order by provider So... to make use of why this query is what it is. I devise the temp table, push in data. Sorry if you are using before 2008. I get the min and max dates. This is more for the dates table, as been suggested. You can plug in the start and end date if you have static dates. If you don't have a nums table, create it through recursion, or use the table i did. This post goes through many methods of making a nums table: http://stackoverflow.com/questions/1393951/what-is-the-best-way-to-create-and-populate-a-numbers-table So, you have your pseudo date table, I then get the month and name of the month as required. This is where it gets naughty. Since you need the provider name on all the dates to check if they are all there, you have to cross apply just the names on the result set. Then you can count the times it matches with the values from the table vs the date table. Then cuz, the above still actually shows all the values from the 'sum', you max the results to get the single record of needed. Its crude, and i would imagine this WILL NOT scale well at all, so use it sparingly... but at least you have a method of doom to get your query results :D Still, as i said, break out this query and batch it if you have many rows/dates to deal with. The cross join gets annoying fast if you are not careful. 
it seems there must be more than one idOrder in the subquery... either that, or you're not selecting it in the subquery's SELECT clause
Thanks a lot for your help.
I prefer to have as much as possible in the dates table - it may come in handy for a query, without trying to figure out if DayOfWeek (1..7 or 0..6) starts on Sunday or Monday. The extra bytes the columns take up isn't that great - if we waste 30 bytes per row, we waste 10 KB per year, or 1 MB per hundred years, and a column store index will compress that right down for us as well. I'd rather waste those extra bytes than put a load on the CPU every time I need to calculate those values. That said, at the reporting layer, localisation may require recalculation, but that's purely for presentation, not generating the dataset for the results.
I deal with some oracle and sql databases, mainly doing queries and creating tables. Also a little bit of C# programming, which I also started learn before I got the job. I guess unofficially I'm a junior developer right now in IT. They just needed someone who was familiar with all that but it wasn't necessary, but I'm sure it helped that I knew some stuff. We have others who are experts at all this, but it helps to not have to bug them for stuff.
This. There isn't a good reason to ever split a database backup. The best option would be to do... mysqldump --all-databases | gzip -c &gt; dumpfile.sql.gz ...then unzip it at the other end. &gt;You can also use: *--databases YOUR_DBNAME* instead.
I did do that, it just disconnects me from the server after a few minutes. To its credit it does actually start the import and get a bit of the data in but not nearly enough for me to proceed with what I need it to do.
Thanks everyone, I got it up finally by asking the host to do it. I'm not sure what they did but it actually took 3 representatives before they managed to do it...but its done :D
Instead of using single quotes which is likely the problem with PHP or a cmd prompt, switch any case where you use single-quotes as reference to use square brackets. ie - [Branch ID] instead of 'Branch ID' This should take care of that issue for you and is standard through MSSQL/Express for names with spaces. Though, if you have the control, it would be better form to change the column to BranchID instead, without a space. HTH.
Hey, just glad I could help. I've been in a similar situation and spent a long time dealing with it. It infuriated me so much so that most of my normal naming conventions no longer contain spaces. Also, thanks for the reddit gold!! :-)
True that I'd never use spaces but this particular debase was out of my hands; thanks again!
Here is a [blog post](http://blogs.msdn.com/b/sqlserverfaq/archive/2010/04/23/how-to-un-cluster-sql-server-2005-cluster.aspx) explaining clustering of SQL Server. Before doing the actual unclustering, please complete below steps * Find which node currently runs SQL Server. You can connect to SQL server via management studio, open a new query and run SELECT SERVERPROPERTY('ComputerNamePhysicalNetBIOS') * Take a backup of all user and system databases(except tempdb). [Here](http://www.mssqltips.com/sqlservertip/1070/simple-script-to-backup-all-sql-server-databases/) is a simple script * Script out [logins](http://support.microsoft.com/kb/246133) and [user permissions](http://www.sqlservercentral.com/blogs/brian_kelley/2009/08/28/quick-2005-2008-script-to-export-permissions/) * Script out all [jobs](http://learnmysql.blogspot.in/2012/05/script-all-jobs-in-sql-server.html) * Take a look at the other server objects like linked servers and script them out. * Connect to integration services from management studio and see if there are any SSIS packages stored in msdb database (or query SELECT * FROM msdb..sysssispackages), if you see user created packages stored, you may have to export them to the file system and save them. [Link here](http://www.mssqltips.com/sqlservertip/1428/import-export-copy-and-delete-ssis-packages/) * So far, you took all the precautionary measures and you can rollback if something goes terribly wrong during unclustering. * Communicate downtime with business and start unclustering. Refer link at the beginning of this comment. Good luck! Let us know if you run into any issues. 
It's that bad *dead*. We don't have a TA for the course, and while my teacher is very knowledgeable his lectures and assistance after class are difficult to follow. There is no assigned text so I have been using a combination of lecture notes and w3c. I planned on asking next week in class, but figured I would try posting on here anyway.
here ya go big dawg SELECT * FROM ( select e.store_id ,count(*) as count from employee group by e.store_id ) storecount ,( select avg(i.count) as average from ( SELECT e.store_id ,count(*) as count from employee group by e.store_id ) i ) storeavg where storecount.count &gt; storeavg.average; 
Holy crap thank you so much. I didn't realize you could have more than one query within the FROM section. Going to look over my others now to see if that simplifies them at all.
Can you explain the logic behind this? I ask because I am new to SQL too and I like to actually know why things happen rather than be told "here ya go"
when you put a select between (), it's like selecting from a table select sum(a.price) as total from (select itemprice+margin as price from sales) as a 
OKay i get that. I guess where I am confused is where all the counts come in play. When i was trying to do this i thought of it as something like SELECT * FROM (SELECT e.store_id FROM Employee GROUP BY e.store_id) stores , select avg(i.store_id) as AVERAGE FROM (SELECT e.store_id FROM EMPLOYEE GROUP BY e.store_id) i ) storavg WHERE stores &gt; storavg.average;
Yeah it is really simple, and lurking this subreddit has made me realize I need to find a few SQL books to read (from the Learning SQL thread) because the notes just aren't cutting it. I appreciate the comments/feedback.
[SQL Fiddle](http://www.sqlfiddle.com/#!3/edf97/15) with schema and query. Not sure I read your question right, but I think that should do it. Dunno if you've learned about standard joins or window functions (like OVER() ), but they're things you could easily stumble upon on your own with a few hours learning on stack overflow anyway... so hopefully your teacher won't accuse you of cheating. Unless he Googles the query and this Reddit post pops up. Oops. SELECT Count, Store FROM (SELECT Count, Store, AVG(x.Count) OVER() AS Average FROM (SELECT COUNT(e.e_sID) AS Count, Store FROM Stores s JOIN Employees e ON s.StoreID = e.e_sID GROUP BY Store) X ) Y WHERE Count &gt; Average
StudentStatus.GPAGrouping, &lt;---- Is that an extra comma?
Holy crap, it is the small things that get you. I have had like four other people look at this code. You are the first to notice that.
Ha... If I'm debugging I'll usually have them at the beginning (and I'll also have my WHERE clause led off with a 1 = 1 so every other line, including the first actual one, can be commented out individually without having to add/remove "AND" or whatnot).
Why are you doing "Student as student1"? For reference, that's the way you create an alias for a column. if you wanted to create an alias for a table, you would just do "select blah as blah_alias from table1 table_alias where ...." Also you need to have an your join conditions with each table e.g. select something from some_table b join some_other_table a on (a.some_column = b.some_column) join yet_another_table c on (c.some_column = b.some_column) where ... Also, why are you using group by when you have no aggregate functions in your select statement?
 ON Student1.StudentUID=Demographics.StudentUID Student1.StudentUID=StudentStatus.StudentUID no and/or
**First query: storecount.** This creates a table with a unique list of store_id's and the total count of employees at that store. ( select e.store_id ,count(*) as count from employee group by e.store_id ) storecount **second part: storeavg** the inner query "i" is the exact same as the first query. a count of employees by store id. the outer query here "storeavg" returns the average number of employees per store across all stores. ,( select avg(i.count) as average from ( SELECT e.store_id ,count(*) as count from employee group by e.store_id ) i ) storeavg Since there is no join criteria in the outermost query it results in a full join; resulting in a table like this: store_id count average -------- ----- ------- 1 666 734 2 420 734 3 1337 734 4 515 734 finally, by adding the where clause "where storecount.count &gt; storeavg.average" on the outermost query, it filters the above to the final result set: store_id count average -------- ----- ------- 3 1337 734 
First off, your order by is a literal so that's not going to do anything. What you're asking to do is group by multiple different things but show totals for different levels of the group. So what you need to do is use something like "GROUP BY GROUPING SETS". Here's an example: CREATE TABLE #temp ( ModuleID int, TaskID int, Priority int ) insert into #temp values (1, 1, 1), (1, 1, 2), (1, 2, 1), (2, 1, 1) SELECT ModuleID, Priority, COUNT(*) AS Total FROM #temp GROUP BY GROUPING SETS ((ModuleID, Priority),(ModuleID))
You're joining #All_Visits to #Employee_Working_Hours only by name and not date or anything else. So that means every individual row in All_Visits for an employee is going to join to ALL the rows in Employee_Working_Hours for that given employee. You should probably create a Common Table Expression of the employee working hours grouped by employee / year / month and possibly another one of all visits by employee / year / month, and then join them together on all 3 columns so you get a 1-to-1 scenario. 
PKs are supposed to be immutable, for that reason Oracle doesn't have an "on update cascade" FK constraint clause. With update cascade, when updating a PK or alternate key, FK columns are also updated, which is what you are looking for. Some RDBMS support it, Oracle chooses not to. "Videos" are FK'd to your movienum PK, but you are trying to change the PK, but the FK is dependent on it, so the constraint raises an error. The best way to do it is to have a FK with a "deferred constraint" (You'll want to issue it as deferrable and initially deferred - Google for help). This type will only validate your FK at the point of commit, so will allow you to do as you are trying to do. Alternatively, disable the FK constraint, do your updates commit, then re-enable.
As was previously mentioned PKs are supposed to be immutable. Personally in this case I'd INSERT a new record into the parent table. Then I'd UPDATE the child record and finally DELETE the original parent. INSERT INTO movie SELECT 2008, other_columns FROM movie WHERE movie_num = 1234; UPDATE video SET movie_num = 2008 WHERE movie_num = 1234; DELETE FROM movie WHERE movie_num = 1234; I hope this helps!
Still getting errors Line 2 - Integrity constraint - Parent key not found Line 3 - integrity constraint - child record not found Also confused about "other_columns", am I supposed to just list all the other columns in the table there?
Are you doing this SQL server? If so, you can use a windowing function to get all that back in 1 step. If not well I'll let someone else answer. Edit: Select ModuleID, Count(TaskID) Over (Partition by ModuleID, TaskID) as TaskCount, Count(Priority) Over (Partition by ModuleID, Priority) as PriorityCount From AmsTaskMain I wouldn't say this is a beginner level concept though. LeviW is right about you doing two group sets.
Can you provide the exact output you are getting g when you execute the statements please? Preferably through a tool like SQL*Plus. Yes, other_columns are all the non-PK columns. 
SQL&gt; create table movie (movie_num number, name varchar2(40)); Table created. SQL&gt; create table video (movie_num number, type varchar2(20)); Table created. SQL&gt; alter table movie add constraint pk_movie_num primary key (movie_num); Table altered. SQL&gt; insert into movie values (148, 'Hook'); 1 row created. SQL&gt; insert into video values (148, 'DVD'); 1 row created. SQL&gt; alter table video add constraint fk_movie_num FOREIGN KEY (movie_num) references movie (movie_num); Table altered. SQL&gt; update movie set movie_num = 500 where movie_num = 148; update movie set movie_num = 500 where movie_num = 148 * ERROR at line 1: ORA-02292: integrity constraint (CRABTBX.FK_MOVIE_NUM) violated - child record found SQL&gt; update video set movie_num = 500 where movie_num = 148; update video set movie_num = 500 where movie_num = 148 * ERROR at line 1: ORA-02291: integrity constraint (CRABTBX.FK_MOVIE_NUM) violated - parent key not found SQL&gt; alter table video drop constraint fk_movie_num; Table altered. SQL&gt; alter table video add constraint fk_movie_num FOREIGN KEY (movie_num) references movie (movie_num) initially deferred; Table altered. SQL&gt; update video set movie_num = 500 where movie_num = 148; 1 row updated. SQL&gt; update movie set movie_num = 500 where movie_num = 148; 1 row updated. SQL&gt; commit; Commit complete. SQL&gt; update video set movie_num = 501 where movie_num = 500; 1 row updated. SQL&gt; commit; commit * ERROR at line 1: ORA-02091: transaction rolled back ORA-02291: integrity constraint (CRABTBX.FK_MOVIE_NUM) violated - parent key not found Deferred basically gives you until the commit is done to update records. 
&gt;Why are you doing "Student as student1"? For reference, that's the way you create an alias for a column. &gt;if you wanted to create an alias for a table, you would just do "select blah as blah_alias from table1 table_alias where ...." I always use AS to distinguish an alias, be it column, table, subquery, everything... It makes for much easier to understand code. Remember, you need to think about the guy who has to maintain your code if you quit or get hit by a bus (or get hit by a bus because you quit) 
Just Try: SELECT ModuleID, Priority, COUNT(*) as 'Total Tasks' FROM AmsTaskMain GROUP BY ModuleID, Priority ORDER BY count(*) desc 
no join criteria is a cross-join, a full outer join is when there is a criteria but you return all rows from both sets even if there is no corresponding match in the other set. Your where clause becomes the join criteria.
If this is the schema to use I got some revisions to your code. First and foremost, count returns integers, avg(int) returns integers aswell. Second, you can use a cte to tidy up the logic. We can't put avg() over() in a having clause since it is a window function, thus we need the cte. --which stores have an above average count of employees with empCount as ( SELECT COUNT(*)*1.0 as c,s.Store,AVG(COUNT(*)*1.0) over () as avgc FROM Stores as s INNER JOIN Employees as e ON s.StoreId = e.e_sID GROUP BY s.Store ) SELECT Store,c,avgc FROM empCount WHERE c &gt; avgc 
 SELECT ModuleID, Priority, COUNT(*) as [Total Tasks] FROM AmsTaskMain GROUP BY ModuleID, Priority ORDER BY count(*) desc 
My advice would be to design your ASP application so it executes a SQL stored procedure when a new entry is entered. That was you can write your SQL with lots of lines and variables that look at if the publisher already exists, then reference it, otherwise create a new one with that name etc. Using Store Procedures gives you a lot better control than executing INSERTs directly from ASP, and it keeps the business logic in one place.
Thanks. That's actually what I said above. Sorry if the language was murky. But, the stored procedure itself is my issue. How am I grabbing the identity from the newly created row to insert into another table? Should I use scope_identity, or is there a better method? 
Sorry about that. Yes, scope identity would work. You may want to wrap it in a transaction so that separate calls don't get crossed. I've seen people use identity tables too. I usually use uniqueidentifiers, so I would call newid() and place it in a variable for use in multiple insertions. It's so much tidier.
you also have sequences available to you, new in 2012. They allow for a incremental number to be used over multiple tables and other fun uses.
Seconded on this comment, looks like it may be a copy/paste error but the re's some weirdness happening in the JOIN syntax
To be honest, it's near impossible to make suggestions about your schema, since it sounds like a small-table one-user database. Based on that use case, I would just put in Excel, honestly. If you want to make up some fake larger user base for the sake of discussion, we could talk about how best to build it for the new, imaginary need. These messy problems of dealing with the keys of new records are something we all deal with in our applications.
I appreciate the help anyways. Yeah, it is tiny, and I was actually taking it out of Excel and putting it into this database. Mostly as a learning exercise, but also to try and get a shoe in the door with either a sysadmin or dba position here. The place I work is one of those places where you can get more responsibility by just coming up with projects that will benefit the users in some way. I was thinking this database might be expanded in the future to also record how many licenses we have, which computers have what software installed, which users are authorized to use the software, departments associated, etc. But, that part is less likely than what I'm doing now. On the other hand, I think it's more practical to learn by creating a project that MIGHT be used some day. 
[SQL Fiddle](http://www.sqlfiddle.com/#!3/7e5b0/10), hopefully standard SQL syntax applies... Query: SELECT f.VIDEO_ID, TITLE, COUNT(FORMAT_ID) FROM Video v JOIN VideoFormat f ON v.VIDEO_ID = f.VIDEO_ID GROUP BY f.VIDEO_ID, TITLE HAVING COUNT(FORMAT_ID) &gt; 1
Here is the original SQL http://www.sqlfiddle.com/#!4/d6297 Error starting at line 2 in command: UPDATE video SET movie_num = 2008 WHERE movie_num = 1245 Error report: SQL Error: ORA-02291: integrity constraint ([Name Ommited].VIDEO_MOVIE_NUM_FK) violated - parent key not found 02291. 00000 - "integrity constraint (%s.%s) violated - parent key not found" *Cause: A foreign key value has no matching primary key value. *Action: Delete the foreign key or add a matching primary key. _ Error starting at line 3 in command: DELETE FROM movie WHERE movie_num = 1245 Error report: SQL Error: ORA-02292: integrity constraint (Name Ommited.VIDEO_MOVIE_NUM_FK) violated - child record found 02292. 00000 - "integrity constraint (%s.%s) violated - child record found" *Cause: attempted to delete a parent key value that had a foreign dependency. *Action: delete dependencies first then parent or disable constraint.
So the only way to do this is drop the foreign key? [This is my original](http://www.sqlfiddle.com/#!4/d6297) 
Is the INSERT completing successfully? If so, is the UPDATE executing in the same session? 
I honestly have no idea, this is my SQL: http://www.sqlfiddle.com/#!4/d6297 I am basically brand new to SQL so if you wanted to try it yourself you could. Sorry I can't be more help.
You would need to change this line: CONSTRAINT VIDEO_MOVIE_NUM_FK FOREIGN KEY (MOVIE_NUM) REFERENCES MOVIE INITIALLY DEFERRED I dropped the constraint just to show the differences. You might be able to alter table the constraint as well. 
I had written a solution - but this seems a lot like homework so it seems wrong for me to answer it for you. So how about you reply with some things you have tried but which failed and I can help you work through it. 
Turns out I was reading the instructions wrong the entire time, it was actually a really simple solution, sorry for wasting your time.
does oracle actually support those square brackets? in any case, for datatype conversions, use oracle's CAST function
Convert(nvarchar(255),[number])+[fruit]+[pants]
I dont want to add them, just display all three things together.
Yeah this SQL I posted is from Access, I'm not sure. I don't want to "convert" data, just display all three in a single column
if one of them is a text column, then yes, you have to convert it as cataclysm said, how do you expect it to add a string and an integer together? by the way, what are you actually going to run the query in? access or oracle?
That's what i figured, and i asked because on most platforms you will have to make sure the columns or variables are of the same datatype or have to cast them to a compatible one. The convenience of having "+" as a concatenation operator tends to make us a little sloppy in our thinking.
Well I'd start by saying when you are joining on say 8 tables its a lot easier to read. Also to your question about outer joins, I created a quick example to display the importance of outer joins. Yesterday I was creating a summary report that pulled from 10 tables to get different stats for employees. So lets say you just joined all of the tables, if one of those employees is in say 9 tables out of 10 but not the 10th you are not going to get a row in your output for that employee. If you left outer join it will ignore the fact that the employee is not in the table and output their results from the other tables along with null or 0 if you want for the columns of the table they are not in. Here is an example: http://sqlfiddle.com/#!6/800d2/1 You'll see the first join doesn't return the 4th employee, while the second returns him and nulls for the missing values.
I'm assuming your not adding them, you just want to display them together. If so its easy. Number||Fruit||Pants as New Column Also if you want to add something else in between the values on your output you could do Number||'-'||Fruit||':'||Pants as ColumnB This will only work for Oracle which in your title it says 'Oracle' but I see another post where you mention access. 
I would say this is the correct solution. He isn't trying to add anything so conversion isn't necessary.
It's correct but plus sign is not necessary unless you want that in your results
I answered my own question, proper notation is: 27^(1/3) = 3 however using: SELECT POWER(27, (1/3)) yields 1 what you need to do is: SELECT POWER(27.0,(1/3.0)) yields 3.0
And if you wanna do it hardcore style, try with a recursive query and no math function :)
It's been a very long time since I've installed MySQL on a Windows host, but check your Services list (Control Panel -&gt; Administrative Tools -&gt; Services). See if you can find the MySQL Server in that list and if it is in a running state or not. If you don't see it in the list, odds are the MySQL Server wasn't installed. If you do see it running, pull up command prompt and do a netstat to see if you can find it listening on port 3306 (or whatever custom port should that be the case). Let us know the results, it'll help troubleshoot further as to the current state of install.
MySQL is in the services list. I see nothing listening on port 3306 unfortunately. I started MySQL while I had netstat running. I didn't change any port configuration for MySQL so it should be defaulted to 3306 right? Thanks so much for your help.
Yup, the default TCP port for MySQL is 3306. If memory serves me correctly, you can also start MySQL in socket file only which would mean it's running but you won't see anything listening on TCP port 3306 (I don't remember if that's *nix specific or not). Now that you started the MySQL service, has any of the connection errors changed or anything different from the mysql command line service?
Sorry for long response, been out of town, all I want is to display them all together. No addition.
Check your my.cnf to see if 'skip-networking' is enabled, and what the bind-address is. Normally on Linux you connect over a socket file (normally in /var/run/mysqld/mysqld.sock) over TCP. If you use TCP, it only binds to a single address, as opposed to all possible listening addresses on your system. I believe the 'mysql' command line assumes sockets by default, and will use TCP if you supply a -H flag.
okay, concatenation and which dbms are you going to want to run this in? they all have different syntax
I gave up. Ended up just using Servoy/postgres
Postgres is the better database anyway :)
Install Sql Server 2012. Assuming you've already done this and you have used default settings you should have a `localhost\SQLExpress` instance of SQL installed. Now you want to use SQL Server Management Studio. If you haven't installed it, you need to install SSMS. Use SSMS to connect to `localhost\sqlexpress` (or whatever you named your install)
This was exactly my issue, can't believe I missed that haha, thanks!
Awesome! Glad to be taking this route then =D Thnaks for your help anyways
For Oracle only, we of course offer the free Oracle SQL Developer. If you have any questions about moving over, transitioning, feature mapping from Rapid SQL and DB Artisan, just let me know. All of the features (again, Oracle only) you mentioned are available.
I feel like you started in the middle of a conversation. What IDE are you talking about?
I could be wrong, but I've always had to pass in a string variable to exec declare @SQL nvarchar(max); SET @SQL = ' SELECT * FROM TABLE WHERE SOMETHING = 20130401 '; EXEC (@SQL) at as400; You might need to use a `nvarchar` and use `EXEC` instead of `EXECUTE`. I know you have to use a prebuilt string if you want to dynamically make the query to pass... but you may not need to if you are using a static query. For the remote procedure... you should be able to enable RPC &amp; RPC out in the linked server properties and then use the same `exec` statement: SET @SQL = ' call p_iestd_trend_manage_trend_process(''EFT_D'',''TRND_EFT'',''D'',''N'',''Y'',null) '; EXEC (@SQL) at as400;
I don't have an answer but I do have some advice from being where you are now. Give more information about what you are trying to accomplish and the Application that is using MySQL you are trying to query. There may be a fundamental issue with that code depending on what you are trying to accomplish, for e.g. certain types of SQL may not allow specific commands (meaning you'll need their help restructuring the query) or the syntax for similar (or identical) commands may be slightly different. 
you fix it by eliminating the temp table SELECT book.title , sum(inventory.onHand) as BigSum FROM book INNER JOIN inventory ON inventory.bookcode = book.bookcode WHERE book.publishercode = @publishcode GROUP BY book.title ORDER BY BigSum DESC LIMIT 1 
I'm in the same position right now, check out my user profile and see the tutorials people have suggested to me. Maybe it will be of help.
I'm in the same position as you. I got a job as an entry level analyst at a local college so I've been learning on the job experience. The basics of SQL are pretty simple, there's a very limited number of statements, the hard part is learning to use those statements to solve whatever problem you are faced with, therefore in my opinion, it's somewhat hard to efficiently 'practice'. I would definitely look start looking into PL/SQL though. It's much more powerful and robust (if that's the right word). Create some procedures and learn about functions and cursors and loops and if statements and all that fun stuff. Feel free to ask me any questions about anything SQL or Oracle related. Hope I was of some help to you. 
I will say the one thing I wish I knew when I was starting out....Avoid Cursors. 95% (Probably 100%) of the time you can get the results without using the seductive cursor. Cursors are easy and they bring you into their dens of brute force and hour long queries. It took me a long time to break my bad habit of using Cursors and my queries are so much better for it. SQL is set based and works best when you work as a set. I can try to answer specific questions the best I can. Good Luck!
Thank you, I will be sure to find some tutorials :). It might already be in your history, but do you know anything about the credibility of Lynda tutorials?
Thanks for the response. I'll start familiarizing myself with PL/SQL and see where I can go from there.
Hmm I'll look into those certifications, thanks for the tip!
Noted. Thanks!
read data modeling books (hay, silverston, fowler), so you know how to design a db read joe celko's sql books, so you know how to query a db read sql anti-patterns book, so you know how to not design a db read kimball data warehouse book, so you know how to design a data warehouse consider reading the JBoss Hibernate source code or stepping thru it to see the sql it writes. It tends to write better sql than most developers. use postgres, as it has more features than say mysql and is more standards compliant
I'll see if I can find these books online. Thanks!
This looks like homework. What does that output to and why would you write 3 queries as 6 and put it in a function where it cannot be optimized by the database? 
so does b.ID = b.Region? I'm asking because you are linking the Region up to b.Region AND you are trying to update it with b.ID, I'm trying to figure out why. Maybe you need to add another column to store the ID in RafSil_QuarterlyBonus2013.
This will work but the datatype of Region in RafSil_QuarterlyBonus2013 will still be a literal and not an INT.
the way you have the Region will change the Region to the ID [int] and not the Region Name like what is currently in there. But there is another problem with the statement. Even if you get it to work the values will never change because you are updating the field that links the Region To RafSil_QuarterlyBonus2013. How does Region get changed?
Quadman said the same thing above, I still get the same error message.
Just so I can see if I understand it, I can't update the region field at the same time I'm pulling information from the same table? 
Just recently there was a Stanford class online, called [Introduction to Databases](https://class2go.stanford.edu/db/Winter2013/preview/) which helped me a lot with getting into SQL, databases etc. I'm not sure if they still have their materials online or if they're available to non-students, though.
Wish I knew about this class earlier... Lol. However, it looks like they left some videos/slides online so I'll be sure to check those out after work. Thanks!
That course does look pretty interesting (and relevant). I'm very tempted. Do you know the credibility of these courses though... Especially if they are free?
I think they are a little simplified versions of "real-world" courses provided on campus, but I'm not sure about the credibility. You do get a statement of accomplishment, but for me it was just great to learn from a good teacher (prof. Widom from Stanford) and have a populous forum where you can ask for help if you get stuck. Can you tell I love the MOOC format? I'm not sure if you'd get any college credit or even employer recognition of these courses though, but since they're free you can always drop out of the course, if you feel like it's a waste of time.
All I want it is to come out of it learning something new which will help me grow in my field. Also, as you said, I can easily drop out if its not relevant to my interests. I think I'm going to ask my supervisors if the course seems relevant before committing to anything. Thanks for the help!
the GROUP BY is wrong, it should have all the non-aggregates in the SELECT clause
&gt; Is there a particular reason why one is more correct than the other? yes... standard sql try yours in mysql and no problem, try it in any other database and you get a syntax error the reason it works in mysql may be beyond the scope of this thread, but if you're interested, check this out -- [Debunking GROUP BY myths](http://rpbouman.blogspot.ca/2007/05/debunking-group-by-myths.html) (it's a long read but very worthwhile)
/u/r3pr0b8 has the correct answer to the query, but for future reference: First, thought this looks like MS SQL Server, you failed to state your RDBMS platform. Hard to answer the question without knowing exactly what RDBMS you're using. Second, don't post pseudocode. If this isn't pseudocode, please refer to your RDBMS's documentation. None of these statements are valid SQL. You have undeclared variables, invalid table creation syntax, and what looks like a set statement that's likely to try to set a table value to a scalar variable. If it's "too time consuming" to post your actual code, then it's going to be too time consuming for us to help. Why should we care if you obviously don't? Third, if you're getting error messages, *post the error messages verbatim*. Error messages really do tell you exactly what is wrong 9 times out of 10.
They are mostly interchangable because they both support ANSI Standards. However, many of the convenience functions and variables have different names. If you know what you're looking for in one, there's a million websites with the appropriate conversion to the other. I mostly use SQL Server, but occasionally have to query our PeopleSoft Oracle DB.
The remark about ANSI SQL is right: there are a lot of similarities, but there are many differences that will impact your productivity for a while transitioning, from dialect features like "select into" to handling backups. Microsoft SQL started out as pure Sybase ported to the microcomputer, and retains a lot of that character under the covers to this day, so learning Sybase is a good way to understand what Microsoft is doing and how to navigate system stored procedures, Transact SQL, the cost-based query-optimizer, and various other important aspects that differ somewhat from the PL/SQL and MySQL equivalents. That said, any shop that runs MS SQL is going to be at least somewhat Microsoft-centric. The problem with that is that Microsoft controls customer-loyalty to some degree through the use of non-standard language and packaging - i.e. groups of functions are bundled together in different sets than in the rest of the computer community, and then renamed. One example is Microsoft's ETL tools, which have a somewhat counter-intuitive way of cascading transformation logic, and go by different package names through the years. Look up Microsoft DTS, the and SSIS, and SQL Server Agent for an idea of what I mean.
You're just missing a close-paren after the table definition. References CUST(CustID) ON Update No Action ON Delete No Action); ^ ^ 
I think you're missing a close bracket before the semicolon.
Thank you! Glad it's something small that I can understand. 
I'd suggest heading over to [SQLServerCentral](http://www.sqlservercentral.com) and asking the same thing within their forums as it's a more active place with smarter people than I. I know there are limitations when using SQL Express, for example it can only be a subscriber, see the following: http://msdn.microsoft.com/en-US/library/ms165686(v=sql.105).aspx http://msdn.microsoft.com/en-US/library/ms165686(v=sql.90).aspx http://msdn.microsoft.com/en-us/library/ms151819(v=sql.105).aspx 
I had something like this in my sql yesterday when working with php, drove me nuts.
Yes, there are differences. Yes, the vast majority of your Oracle will come over to SQL Server.
Most of it is the same and as long as you know how to Google, you'll do fine. For MSSQL, I tend to Google "SQL Server &lt;name of object or concept&gt;". The top results will usually be from an MSDN page. For Oracle, I keep [this bookmarked for Oracle searches](http://www.oracle.com/pls/db112/search?remark=quick_search) One thing that is different between T-SQL and Oracle are the way they did the old-style or non-ANSI outer joins. I may have this backwards, but I think its MSSQL that used *= and =* for left and right outer joins, while Oracle used =+ and +=. (again I probably got them backwards, but they are definately different) Also, alot of the functions are different. MSSQL uses an ISNULL functions while Oracle uses NVL and NVL2. DateTime functions are especially a pain between the two. Not to mention that the datetime data types don't line up between to two flavors.
It's like comparing English English to American English. They are still both speaking the same language and you will likely understand what is going on but the new dialect will take some getting used to.
i would upload the excel sheets as is to tables that reflect the design of each sheet then use sql to extract from those tables into your normalized tables for instance... INSERT INTO categories (category) SELECT DISTINCT column4 FROM sheet2table
&gt; When is it a good idea to mix left and right joins? never
For job security
Well... you are either dealing with legacy code from a programmer who did not know what they were doing, or... a single query that solves several problems in one execution--the work of a genius. Personally, I've never found a need to mix.
Or: &gt; when is it a good idea to use RIGHT joins at all? Also never.
I had to process fifty or so spreadsheets once, all of which were very wide but thankfully all had the same structure. I used a Perl script to chunk thorugh all the spreadsheets and put them into a sort of pivoted table which had the form: File Name | Sheet Name | Row | Column | EntityID | Attribute | Value PROJ-0100 | Sheet1 | 6 | 3 | 14321 | Second_Contractor | ACME INC. And then loaded that into SQL. The data in my exercise all related to a specific entity type, which had a unique identifier used more generally. The "attribute" I got from the column heading. Obviously there was a lot of rows in my work table (millions) but a lot of it could be deleted quite quickly. The advantage I found was I could standardise some of the answers (woefully inconsistent conventions had been adopted in different spreadsheets, so a particular term had 8 or 9 different spellings). Once I was a bit happier with the quality of the data I started to copy my answers to more normalised tables. So a lot of things are obvious candidates as lookup tables for example. Most of this work was essentially manual but I found doing it through scripts meant I could repeat the process again and again as I made further decisions about where to put certain bits of data (and realised earlier mistakes). I don't think you can get away from making conscious decisions about how data should be normalised. I suspect any full automation would end up producing an unholy mess that would be very complex to work with (there are programs which can convert complex XML schemas to SQL table structures and the end result can be horrible).
I would guess the dev who wrote that query kept hacking at it until he got the results he expected and then left it...
I don't agree with normalization being a bad thing. And your example seems to be a perfect case where normalization should be used. There are also multiple ways of doing that. My preferred method, is to have your customer table, a customer_address table, and an address table. The customer_address table would hold a customer_id, an address_id, and an address_type_id. The address_type_id would be a foreign key to a type table, and that would hold info on what type of address that is for that customer (billing, shipping, etc). There would be no need to do a lot of the checks you are talking about, because it may be perfectly legitimate that two customers have the same address. If they move, that is also not an issue with this model. It seems to be those advocating denormalization just don't have a great enough understanding how to query normalized data to return what your application needs. It does take more more forethought when designing, but it leads to a great amount of flexibility for future enhancements you may want to make. 
I'm leaning heavily toward heavy incompetence, even if they needed all the information that looks to be gotten above it could have been quicker with increased readability to do consistent outer joins or sub-queries with comments. SELECT top 1 * FROM Table3 as t3 LEFT OUTER JOIN Table2 AS t2 ON t3.bID = t2.bID LEFT OUTER JOIN Table4 AS t4 ON t3.cID = t4.cID LEFT OUTER JOIN Table5 AS t5 ON t3.dID = t5.dID INNER JOIN Table1 AS t1 ON t1.aID = t2.aID To answer your question, LEFT and RIGHT joins shouldn't be used at the same time and can usually be easily re-written given some thought.
Basically where I would have went with it. I would take it a step further: SELECT top 1 * FROM Table3 as t3 INNER JOIN Table2 AS t2 ON t3.bID = t2.bID INNER JOIN Table1 AS t1 ON t1.aID = t2.aID LEFT JOIN Table4 AS t4 ON t3.cID = t4.cID LEFT JOIN Table5 AS t5 ON t3.dID = t5.dID T2 inner join T1 means the T3 should be an inner join too, unless I'm confusing myself.
I don't think that is quite the same, you won't get all items from Table3 like that.
Don't eliminate the off chance this was just copy-paste. If you design a query in SQL Server or MS Access then go to SQL View and steal the code you will get those mix joins.
Well to be honest, looking closer neither will yours. `T3 left join T2 ... ... inner join T1` - I'm fairly certain that will exclude T3 rows that don't' have a matching T2 -&gt; T1. Without mixing Left and Right, I think you'd have to: SELECT top 1 * FROM Table3 as t3 LEFT JOIN ( table2 AS t2 INNER JOIN Table1 AS t1 ON t1.aID = t2.aID ) as T ON t3.bID = t.bID LEFT JOIN Table4 AS t4 ON t3.cID = t4.cID LEFT JOIN Table5 AS t5 ON t3.dID = t5.dID Not pretty, but I think the inner/right/left mix might actually be the easiest to follow.
That's what I thought.
So an app like a e-commerce site wouldn't benefit from storing addresses in a normalized form? I beg to differ. Here is a problem we can try and solve... We have an e-commerce website, and we want our users to be able to save multiple addresses on their account, which they can then choose which they want to use for billing and shipping on that order at the time of checkout. How would you save that information? If your data is denormalized, you better have a whole bunch of "address" columns (address_1,2,3,4; city_1,2,3,4; etc) if you wish to store all the possible addresses your customer may choose from. If we use that method, we better be prepared to save the full "address" in the "orders" table for both shipping and billing once the customer chooses to place his order. That is bad design in my eyes. I've dealt with this exact same problem in the past, and I see the initial "this is the easier way to do it!" thought that the developer had, but it causes problems. Now you have the same data being stored all over. If you ever need to update that data, your code better remember to update it every single place it could live. It's messy. Spending a bit more time to learn about normalization, and putting more thought in how to store data is well worth it in the long run. I can assure you, if you create a large, data centric application and follow the mantra of denormalization there will be issues that you will come across when shit isn't doing what you expect it to.
I'm not sure... I think this might actually be the easiest way to get the results. If you want the same results, with all left or right joins, it would make the query even more convoluted. `Never` is a bit too strong. Just like `never use goto`. The challenge is if this returns the correct results, then how would you create this query without mixing the joins? 
I don't understand what you mean by "data stored all over" - if you have billing and mailing address all in the same customer record it's all in one place... I'll agree with you though, if your business rules say that a customer can have 1 to N addresses on their account, you would want to normalize out the address. That's why the first thing I said was it should be driven by business rules. I would be willing to bet that not very many designs need this unnecessary complexity though. If you know anything about database design you'll know that there's never a "one size fits all" design holy grail or anything like that. The answer is always "it depends" and you pick the best option that suits your needs. My mantra has always been to stick with the simplest solution and add complexity where necessary instead of adding unnecessary complexity when you can't justify it!
Came to this sub just for this advice. Thanks for the info!
&gt; if this returns to correct results that's a mighty big if
To be more accurate, I should have done a full joined again and just added a where. This one isn't to hard to follow because it's linear. Doing this with a query that is 150 lines long is impossible. I think the following is correct: SELECT top 1 * FROM Table3 as t3 LEFT OUTER JOIN Table2 AS t2 ON t3.bID = t2.bID LEFT OUTER JOIN Table4 AS t4 ON t3.cID = t4.cID LEFT OUTER JOIN Table5 AS t5 ON t3.dID = t5.dID FULL OUTER JOIN Table1 AS t1 ON t1.aID = t2.aID WHERE t1.aID IS NOT NULL AND t2.aID IS NOT NULL Edit alternatively and easier you could do the following(I know * is bad): SELECT top 1 * FROM Table3 as t3 LEFT OUTER JOIN (SELECT * FROM Table1 AS t1 INNER JOIN Table2 AS t2 on t1.aID = t2.aID) as t12 ON t3.bID = t12.bID LEFT OUTER JOIN Table4 AS t4 ON t3.cID = t4.cID LEFT OUTER JOIN Table5 AS t5 ON t3.dID = t5.dID 
Corrected the typo :) ... and yeah, it's a mighty big assumption but assuming it's got the correct results (lots of programming goes into reproducing bugs/results in new versions), I'm not sure how I'd do only left or right, get the same results and not have the query look worse. It definitely doesn't feel like it flows right... but because of the way that the grouping happens, the "T1 INNER JOIN T2" has to happen by itself and include all T3 rows. Then add T4/5 rows. I think this will work on Sql Server... SELECT ... FROM Table3 as t3 LEFT JOIN ( table2 AS t2 INNER JOIN Table1 AS t1 ON t1.aID = t2.aID ) as T ON t3.bID = t.bID LEFT JOIN Table4 AS t4 ON t3.cID = t4.cID LEFT JOIN Table5 AS t5 ON t3.dID = t5.dID The goal being, of course, to have the same results (Right or wrong)
That would basically be inner joins (T1 cant' be null... T2 can't be null). In the original query, T3 can have null T1 AND T2 id fields (but not T1 OR T2... both are null, or neither). You would have to say (T1 is null AND t2 is null) OR (t1 is not null and T2 is not null): SELECT top 1 * FROM Table3 as t3 LEFT OUTER JOIN Table2 AS t2 ON t3.bID = t2.bID LEFT OUTER JOIN Table1 AS t1 ON t1.aID = t2.aID LEFT OUTER JOIN Table4 AS t4 ON t3.cID = t4.cID LEFT OUTER JOIN Table5 AS t5 ON t3.dID = t5.dID WHERE (t1.aID IS NOT NULL AND t2.aID IS NOT NULL) OR (t1.aID IS NULL AND t2.aID IS NULL) That, or my amended answer above... Would have all T3 rows, with left joined T1+T2, T4, T5... 
&gt; I don't understand what you mean by "data stored all over" - if you have billing and mailing address all in the same customer record it's all in one place... You mean: Customer_billing_address_1, Customer_billing_address_2, Customer_billing_address_3, Customer_billing_address_4, Customer_billing_address_5?! 
You seem to be confuse the idea of One to Many relationships with Normalization in your address1,2,3,4 quote. 
Always hard to come up with something when you don't have MSSMS open to make some temp tables to test. :) I just hate trying to follow legacy queries that have right &amp; left joins when there isn't that good of a reason to do it. The one I redid last month for some (terrible) room booking software took me the better part of two days to unravel.
fixing your sql so that it's valid sql would not be an improvement and could make it worse it's lovely just the way it is
Making it more technically correct would make it more boring. That's a great present as-is! Make sure to leave a cursor at the end, nice and calligraphy-florid-like.
 Select count(*) from world where men = dave.williams and perfect_match is not null union select count(*) from world where women = beth.smith and perfect_match is not null 2 rows returned
Can you clarify what the different columns in your screenshot are named/what the data represents?
 Starter, Ender, pointsStarter, pointsEnder, debatedate 
 That is a bad, bad table structure. (Besides not being normalised, poorly chosen attributes and datatypes, and has every attribute as part of the key, but also because it requires convoluted queries to return basic data) 
FYI... your query is producing a set of loser-starters unioned onto loser-enders. A person can be a loser who subsequently wins or vice-versa, this person will still be present in your product. (Hence your Michael) Edit: If it's an assignment question, I'm not going to give you the answer, just explain how you might be wrong, and encourage you to try again. Knowing how to be right or how to produceas correct result is usually more important than simply having/holding a right answer.
I didn't write it, I just have to pull the information from it. 
rollback transaction......rollback!
 (assumes there is no significance to your differing usage of "the contest"/"a contest") Assemble a candidate Person population. Remove from this candidate Person population all Persons in the set (Persons who did not debate in this contest) Alternatively, start by assembling a list of distinct debaters by querying your linked table, either method technically works if the initial assumption holds that this contest contains many debates, and scope of the assessment question is this contest only... Further, remove from this Person sub-population any Person in the set (Persons who won one or more debates in this contest) You are now left with a sub-population of Persons who debated but never won any debate.
Assuming your table is called @ttable, this should work: SELECT AllOrders.OrderID FROM @ttable AllOrders LEFT JOIN @ttable Within15 ON AllOrders.OrderID = Within15.OrderID AND Within15.OrderIndicator = 'Order created within 15 days of enrollment' WHERE Within15.OrderID IS NULL 
Not enough INNER JOIN in this thread. ^snicker
Wouldn't this just mean they married on the same day? Doesn't mean they get married to each other. I'll show my nitpicking self out.
Awesome, that's looks great! Since they both are pretty programming saavy, I wanted it to make sense code-wise. Cheers.
I was going to suggest an update statement with a commit transaction. 
Yes; the results would also display twice; once from each select statement. Needs to be be a group by to have it return only once.
if you are using MS SQL server you can follow the examples to write a scheduler to execute the stored procedures [SQL server POP3 stored procedures](http://www.example-code.com/sql/pop3.asp) schedule job for SQL server http://msdn.microsoft.com/en-us/library/aa259582(SQL.80).aspx
If you have a SQL Server, set up SQL Mail. It uses the MAPI account set up on the actual server and can send and read mail via stored procedures. 
I have never parsed attachments in SQL Mail. However, I have used the new Database Mail that comes with 2012 (maybe also 2008r2?). That has a sproc that will pull an attachment into a binary var that you can immediately write out to a table or a row set. http://msdn.microsoft.com/en-us/library/ms187646.aspx
Thanks, ill look into that - might be extremely useful!
 SELECT AllOrders.OrderID FROM Orders WHERE 1=1 /* date diff within 15 days */ and DateDiff(day, EnrollDate, OrderDate) &lt;= 15 /* OrderIndicator = 'Order created within 15 days of enrollment' */ and OrderID not in (select OrderID from Orders where OrderIndicator = 'Order created within 15 days of enrollment') Might need sprucing up depending on what SQL you're using (MySql, MSSql, Oracle, ...) But you might also want to consider a different table layout. Normalize the tables. Something like would remove alot of duplication: Order Table: OrderID, EnrollDate, OrderDate Order Indicators: OrderID, Indicator SELECT O.OrdersID FROM Orders O LEFT JOIN OrderIndicators OI on O.OrdersID = OI.OrdersID and OI.Indicator like '%15%' where DateDiff(...) &lt;= 15 and OI.OrdersID is null Or use [Boolean/Bit/TINYINT(1)](http://stackoverflow.com/a/289767/409025) To trade "Text" fields for "Switches": Order Table: OrderID, EnrollDate, OrderDate, In15, InUS, Over100,... SELECT OrderID from X where DateDiff(...) &lt;= 15 and In15 = 0 Also... after thinking about it, why do you need a "note" that says "Within 15 days?"? You can tell just by comparing enroll and order date.
4 spaces before code... please: SELECT AllOrders.OrderID FROM @ttable AllOrders LEFT JOIN @ttable Within15 ON AllOrders.OrderID = Within15.OrderID AND Within15.OrderIndicator = 'Order created within 15 days of enrollment' WHERE Within15.OrderID IS NULL Your query is missing the "order within 15 days of account creation". Throw a DateDiff in the where: WHERE DateDiff(day, EnrollDate, OrderDate) &lt;= 15 and Within15.OrderID IS NULL
 SELECT Person FROM /* Generate a list of Contestants */ ( SELECT Starter as Person FROM Contest` UNION SELECT Ender as Person FROM `Contest`) as People Left join /* Left Join "winners" */ ( SELECT Starter as Person ,case when pointsStarter &gt; pointsEnder then 'Win' when pointsStarter &lt; pointsEnder then 'Lose' else 'Tie' end as Result FROM `contest` UNION SELECT Ender as Person ,case when pointsStarter &gt; pointsEnder then 'Lose' when pointsStarter &lt; pointsEnder then 'Win' else 'Tie' end as Result FROM `contest` ) as Results on People.Person = Results.Person and Results.Result = 'Win' /* Show only people who have no "Win" */ WHERE Results.Result is null edit: Ballpark of what should work. Probably better looking ways to do this... but should work with cleanup depending on version of SQL using.
Yeah looking at the views in msdb: use msdb go select * from dbo.sysmail_allitems it only shows sent email messages (not received). Let me know if you have had any success reading email messages sent to the account that could be parsed by SQL Server (in order to take action remotely).
thanks, I'll take a look.
For an entry into a field that is designated as a foreign key to be valid, there had to be a corresponding record in the table that field is a foreign key to. So it looks like in your error there is a table called zip_code_states. I assume this is meant to link up each zip code with the state it resides in? If that field is defined as a foreign key, say to a tale called "all_zip_codes" then you would see that error if you tried to insert a zip into zip_code_states that was not already in all_zip_codes. Let me know if you need more help. If so, some more information on your table schema and the data you are trying to insert would be useful. 
Thanks for the quick reply. Unfortunately, I really don't know anything about PHP. My skills are fairly limited to JAVA and .net (I know, pretty useless, but that's what they teach). For the purposes of this project, I think I'm just going to create a local database and hit that instead of the remote. It isn't elegant or really very useful at all, but I understand the principle and really this only has to work well enough to show my professor. Again, many thanks for your reply!
It's a foreign key violation. The value you are inserting must already be present in the PK. If that's already the case, you'll need to provide information on the PK values and what you're inserting. 
Is this a one time upload or does the project need to be able to do this on demand? If it is one time, them just bcp the file into your own server and then dump out SQL insert statements for all the data to execute on the university server. If it is ongoing then I don't know what to tell you. 
I think I'm just going to make a local DB. It isn't necessary for this application to really function, I just need it to send a demo video to my professor so I can get a grade and graduate! 
I did this once in .NET. I had a file upload control place the file on the DB server and then told SQL server to look for it under D:\xyz...although if you don't have access to it then I guess this isn't helpful. 
i'm betting that your zip codes table is missing those 10-character codes like 60803-2949
ZIP codes can cross state boundaries. In other words, in a table of all ZIP/State combinations, you'll repeat a few ZIPs. They won't be unique. 
I think you're confusing Union and Join. Unions return results from two separate select statements. Joins will join tables together ON columns. Look up your notes on Joins and see if that gets your farther.
That was one of the issues, but it still won't work. I think it might be that in the table with Zip codes and Phone numbers there are duplicate zip codes because there are phone numbers with the same zip code. Could that be the issue? If so what do I do about it? 
What you'll want is something similar to this: SELECT s.stu_fname ,s.stu_lname ,ot.vact_name ,concat('$', format(ot.act_fee,2)) as 'activity fee' ,s.stu_notes FROM student AS s LEFT JOIN OtherTable AS ot ON s.StudentID = ot.StudentID ORDER BY stu_lname DESC; Odds are this won't work (you don't list the "other" table you need to pull from), but the idea is that you need to "Join" the two tables on a common identifier (most likely "ID" or "StudentID"). I've aliased Students as S and Othertable as OT. Then explicitly named each column (Since OT *COULD* have a stu_fname field). What are the two tables (along with descriptions)? Which column matches in each table (ID of some sort)? Which rows from each table do you need to pull?
You definitely want to join, not union the tables; as this obviously looks to be homework I've added some comments. Please read them and let me know if you have any questions. &gt;-- -- These column names are horrendous, always alias column names to be understandable where possible -- Converts the floating value of a.act_fee to a string and string concats a $ sign SELECT s.stu_fname as Firstname, s.stu_lname AS Lastname, s.act_name as Username, '$' + CONVERT(varchar(10), a.act_fee, 1) AS 'ActivityFee', s.stu_notes AS Notes &gt;-- -- Join of where the information is coming from, basically a row for every activity a student has done. -- If the student has not done any activities, they will not show up in this list. -- If they do 5 activities they will have 5 rows, with the student info followed by each individual activity FROM students AS s INNER JOIN activity AS a on s.stu_id = a.stu_id ORDER BY stu_lname desc I aliased all the columns, because frankly that style of naming for columns died out with Socrates. Table names are also a good way to practice renaming; such as using 's' to alias the 'students' / etc. If you start needing more than a few table aliases use more proper / full descriptions to make finding them easier. P.S. - [Look at this image to understand different joins and how they work.](http://i.imgur.com/7Ssc4.jpg)
I'd recommend doing a local copy if you can manage it, but if you are interested here is come [PHP Code](http://stackoverflow.com/questions/11893501/import-an-excel-csv-into-mysql-using-php-code-and-an-html-form) that creates a CSV insert webpage for a database. &lt;?php if ( isset( $_FILES['userfile'] ) ) { $csv_file = $_FILES['userfile']['tmp_name']; if ( ! is_file( $csv_file ) ) exit('File not found.'); $sql = ''; if (($handle = fopen( $csv_file, "r")) !== FALSE) { while (($data = fgetcsv($handle, 1000, ",")) !== FALSE) { $sql .= "INSERT INTO `table` SET `column0` = '$data[0]', `column1` = '$data[1]', `column2` = '$data[2]'; "; } fclose($handle); } // Insert into database //exit( $sql ); exit( "Complete!" ); } ?&gt; &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;CSV to MySQL Via PHP&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form enctype="multipart/form-data" method="POST"&gt; &lt;input name="userfile" type="file"&gt; &lt;input type="submit" value="Upload"&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 
I think the Sum() portion needs a join. SELECT Quantity FROM OrderItem oi JOIN CustomerOrder co WHERE oi.orderID = co.orderID
This appears to be homework, if I interpreted the question correctly the following should work. SELECT OrderId, count(ItemId) as ItemCount FROM CustomerOrder AS c INNER JOIN OrderItem AS o on c.orderid = i.orderid GROUP BY OrderId ORDER BY count(ItemId) desc Result will look like: &gt; OrderID, ItemCount &gt;1, 71 &gt;4, 45 &gt;3, 34 &gt;2, 12 
 SELECT 'Congratulations Beth and Dave' FROM life.dbo.weddings AS w ON LEFT JOIN life.dbo.brides AS b ON w.wedding_id = b.wedding_id FULL JOIN life.dbo.grooms AS g ON b.wedding_id = g.wedding_id WHERE b.name = 'Beth Smith' and g.name = 'Dave Williams' AND w.wedding_id IS NOT NULL AND b.wedding_id IS NOT NULL and g.wedding_id IS NOT NULL AND w.date = '2013-04-27'
I have never really thought about nesting joins like that.
&gt;OrderItem AS o on c.orderid = i.orderid OrderItem AS o on c.orderid = **o.**orderid
What system?
Is this Sybase? You might need a semicolon after your "end". Is the select statement supposed to be outside of the procedure?
Think he's asking what flavor of SQL - Microsoft, MySQL, Oracle, Sybase, etc. Different versions of SQL, different syntax needed.
delimiter // -- this is mysql needs a semi-colon after the drop, before the create
oh, wait... you're not inside the procedure yet... so it requires a // after the drop, not a semi-colon
&gt; Are you sure? yes, but you should confirm it for yourself... just run this -- SELECT MAX( SUM(Quantity)) FROM OrderItem GROUP BY orderId
if you use **BEGIN** keyword, you have to close it with **END**. { [ BEGIN ] sql_statement [;] [ ...n ] [ END ] } ref : http://msdn.microsoft.com/en-us/library/ms187926.aspx
Thanks this really helped me a lot. 
Thanks for the help. 
Thanks to the guys that gave me a hand, enjoy the gold!
The most important thing is do you understand HOW and WHY it works? It should be a simple matter of breaking the problem down into three parts: 1. List the people/population. 2. Determine who won/tie/lost. 3. Exclude those without a win. The table layout made it... clunky... and tough to roll about the brain - but like all programming tasks you need to break down the problem into steps and solve each step in kind. Thank you for the Gold :)
I'm assuming this is MySQL and I would say semicolon after END should probably fix it.
I've only really dealt with Oracle stored procedures, never MySQL. I don't know why I didn't think about the Select statement needing to be inside the begin...end block. I'll blame it on the fact that it's early and I haven't had coffee yet. Either way, glad to hear you got it working.
(add 4 spaces to lines for code... for the love of god): delimiter // drop procedure if exists sp_exercise; CREATE PROCEDURE sp_exercise () begin INSERT INTO patient_treatment values (null, '5', '5', '5', '2013-04-23', '11:00:00', '12:30:00', 'released', 'ok'); select * from v_physician; end; // delimiter ; Something along these lines.
you want the SELECT executed by the procedure? also, don't forget to set the delimiter back
Do you just need to qualify that T2 should also be greater (so you ensure T2 BETWEEN T1 and T1+10 min)? AND t2.Timestamp &gt; t1.Timestamp AND DATEDIFF(minute, t1.Timestamp, t2.Timestamp) &lt; 10
Well in that case... &gt;| SELECT OrderId, cntm AS ItemCount FROM (SELECT o.OrderId, cntm = count(ItemId) FROM #CustomerOrder AS c INNER JOIN #OrderItem AS o ON c.orderid = o.orderid GROUP BY o.OrderId) AS a LEFT JOIN (SELECT TOP 1 cnt = count(ItemId) FROM #CustomerOrder AS c INNER JOIN #OrderItem AS o ON c.orderid = o.orderid GROUP BY o.OrderId ORDER BY count(ItemId) desc) AS b ON a.cntm = b.cnt WHERE b.cnt IS NOT NULL &gt;| I'm sure there is other ways to do it that might be a bit fancier, but there one is really easy to tell what is going on. This one is also dynamic and will handle as many items that are at the max count. Note if you are using MySQL use **LIMIT 1** / Oracle use **ROWNUM == 1** instead of **TOP 1**
Don't forget the ambiguous OrderID column!
Few options: Storage and Backups: * If you are using transaction logging make sure they are running on a different SAN drive, preferably one optimized for write. (Also backup your transaction logs accordingly). * Have the backups on a separate drive from all other SQL files. (Even better, on a different array/controller). * Separate SQL data and ldf files if possible, transaction logs can go onto the ldfs drive if you can't swing a separate storage for it. Server/network Speed: * Setup a few test databases. * Run a memory heavy query, using large subqueries and temp tables usually works; after that test to see how much memory you can allocate to the server without it digging into swap. Set your maximum memory usage to a couple hundred megabytes under that. Alternatively you can take your max memory and subtract a few GB for the OS and services. * Run heavy testing, something that causes large signal wait percentages; remove one processor affinity if possible if you find that these causes high(&gt;80%) CPU utilization. This can prevent the OS and services crashing during a period of high database usage. If you don't notice this trend leave all them all available. Stability over speed is the name of the game for database. * Work with your developers/etc who will be using the database to figure out a rough maximum for allowed connections, ideally have them intercept connection denied messages as server busy. Once again stability over speed, it also drastically reduces the vulnerability to DDoS from hijacked application servers. SQL Optimizations: * Promote the use of T-SQL and stored procedures, they are far better optimized then the hand coded alternative. * Setup proper indices for tables, you'd be surprised how often one index can fix a performance issue. * Limit large queries pulls to the parameters of the reports(e.i. getting the top salespersons statistics shouldn't require all the sale peoples data) Edit - * If your organization / company require antivirus software on your machines, makes sure to add exceptions for real time scanning for the database files and services.
Like I mentioned, the syntax will be slightly different for different platforms, this ran fine / tested on a MSSQL 2008 but *WITH TIES* is a T-SQL exclusive as far as I'm aware. *TOP 1* has direct translations into others. 
You sure? I pasted it into SQL Fiddle with the OP's schema (set to MSSQL 2008) and it was just throwing syntax errors. Tried changing a few things but no dice.
I don't need to worry about that - ten minutes is just a measure of time that I figure will work for this purpose. It's not something that needs to be super accurate, but more of a "if one thing hasn't happened within a reasonable amount of time before the second thing happened" kinda thing. Edit: Oh, and yes! That works like a champ, though its a bit slow with the added date-check vs the original code. (LOTS of data to pore over here.) But that's fine as this is going to go into a one-off utility anyhow, query performance isn't a massive concern. Reddit gold for you, sir/ma'am/small furry creature from Alpha Centauri!
Copied the wrong query back when I pasted, just had a small error with flattening. Updated the other post and formatted it to be more readable.
2008. And if you're talking about what I think you're talking about (as I saw "CTE" referenced in a couple of examples I found whilst googling), that didn't do the trick as it was referencing row numbers, which with my query, weren't consecutive.
That syntax appears to return pretty much the opposite of what I'm after :D
I don't believe so - the order of the timestamps in the DATEDIFF should handle that fine. I did try adding that first line of your post into the mix, and it ended up returning all occurances of Type=1 instead of just the ones I was after. Not sure why.
Thanks, dude! Now I almost feel bad for not making it more efficient. But hey, if it works it works ;)
Bet you the &gt; should be reversed
You're calling your procedure from within your procedure. That isn't really the point here I think
the recursive call never ends it is a infinity loop DBMS will prevent infinity recursive call and shows error to you You must add a break condition before you invoke the function itself 
Thanks, I a networking trainee so database is a little out of my area 
my sincere recommendation: never use NATURAL JOIN unless it is needed to answer a homework question -- in the real world you will fsck yourself badly
So I was never able to get the email/gmail angle to work but came up with something that is better (for my purposes). Using a [3rd party tool](http://www.sqlsharp.com/), I'm able to read twitter direct messages. So I setup a lookup/reference table to join against based on the content of the direct message to retrieve the sql needed to execute. I could take this a step further and accept parameters but for now, just executing stored procedures and performing actions within those stored procedures including emailing report results seems to work fine. The beauty of this solution is unlike email, the only people that can DM you on Twitter are people you follow so it has an added level of security.
Taking the concept of "Never Assume" to an extreme, and hopefully not insulting you: You are just showing us the WHERE clause of the INSERT statement, right? Also, what is the exact error message?
How exactly are you writing the full query? It should look very similar to a stored procedure. CREATE PROCEDURE spDateProc @sDate datetime = '', @eDate datetime = '' AS BEGIN DECLARE @qStr varchar(5000),@s datetime, @e datetime --checks to see if the values exist, replaces with values that will not cause an update of any data IF @sDate &lt;&gt; '' SET @s = @sDate ELSE SET @s = '2100' IF @eDate &lt;&gt; '' SET @e = @eDate ELSE SET @e = '1969' SET @qStr = 'INSERT INTO your_table (col1, col2, etc) SELECT dol1, dol2, etc FROM your_source_table AS src WHERE src.DDATE &gt; ' + convert(varchar(20), @s, 120) + ' AND src.DDATE &lt; ' + convert(varchar(20), @e, 120) --Optionally shows the query that ran, good for testing / debugging --print(@sql) EXEC(@sql) END 
I appreciate your response and you have many good points and ideas, but what I was more hoping was on the server OS setup side for MPIO/iSCI 1gig lan setup for my "local" harddrives on SAN. I've seen some iSCI drops and SQL wait times of &gt;15 seconds, I'm trying to figure out that part of the setup.
SQL Task in Control Flow. When Trying to parse Query I get: The query failed to pars. Syntax error, permission violation, or other nonspecific error. 
Here is a good link https://www.simple-talk.com/sql/ssis/passing-variables-to-and-from-an-ssis-task/ Dates can be tricky. I always try and break things down as far as I can so I can pinpoint the exact issue. Try using the same syntax but having one parameter as a varchar. Insert into tblFoo Select field1, field2 where parmFoo = ? If that works you know your syntax is good and it's something to do with your date (it may not actually be a date etc)
Two different methods; first one is preferred, if possible, because it can be done in bulk vs. per insert: &gt; Make the second table the same as the first except set the primary key to be nullable(and no auto incrementation) then just left join the missing data into place. INSERT INTO dbo.DATAB (pk, col1, col2, etc) SELECT a.col1, a.col2, etc FROM DATAB AS b LEFT JOIN DATAA AS a ON b.pk = a.pk WHERE a.pk IS NULL &gt; Use a trigger for on INSERT for DATAA do so for DATAB CREATE TRIGGER databInsert ON dbo.DATAA FOR INSERT AS INSERT INTO dbo.DATAB (pk, col1, col2 , etc) SELECT pk, col1, col2, etc FROM inserted GO
Option one is definitely the one to do. One question though, and excuse my ignorance. If the primary key is nullable will I still be able to utilize it in queries? Currently I use the primary key to link tables when performing complex queries.
Yes, you can still use it... He's suggesting to allow nulls and no auto incremental so that you can retain the key integrity of the DATAA tables into the DATAB tables... otherwise DATAB will create a unique key when you do the insert, which would be different than the DATAA key and thus break any linking you do. 
Hi there! I've found that a good way to implement and test the usage of parameters in SSIS for Execute SQL components is to use expressions on the component. Expressions let us use the parameters to create a complete string value for our query before it is used. This way we can evaluate this query-string beforehand to see if it is going to work or not when we run the package. This is what it might look like in 2012, 2008R2 is very similar (variable usage is underlined with red) http://imgur.com/AlWdrZF If you are just running one statement on SQL Server, use the Execute T-SQL Statement component over the Execute SQL Task component. It uses less resources from what I've gathered.
What MyOpus said; DATAB will basically become a storage table and the key constraints should be removed.
aaaaaaah. Perfect thanks to both of you!
I can give you the Oracle version: constraint column_name check (column_name between 0 and 10)
your professor is wrong COUNT() will produce an error message
uh, wait... the asterisks were interpreted as reddit italics, sorry
Use four spaces to after a blank link to format text like code, each four spaces is a tab. It just looks nicer. :) SELECT .* FROM Store WHERE s_id IN (SELECT e_sid FROM Employee GROUP BY e_sid HAVING COUNT(.) &gt; (SELECT AVG(e_count) FROM (SELECT COUNT(.) AS e_count FROM Employee GROUP BY e_sid)));
&gt; since there is no way to turn that off. Put four spaces before each line that you want to format as code. Then Reddit won't apply its normal formatting stuff. You can click "formatting help" for other tips.
Sorry for not coming back soon, but this really helped! Thanks!
ur awesome dude
Np 
If what you're looking for is a SUM of sales for each item, [this should do it](http://sqlfiddle.com/#!3/6287d/9): SELECT * FROM ( SELECT ITEM, SALES FROM Sales ) AS a PIVOT (SUM(SALES) FOR ITEM IN (W01, W02, W03, W05, W06, W08, W12)) AS pvt
And this will break it down by product/month: SELECT * FROM ( SELECT year, month, item, sales FROM yourtable ) x PIVOT ( SUM(sales) FOR item IN (W01, W02, W03, W05, W06, W08, W12) ) z WHERE Year=2012
OP forgot to mention which dbms he or she is using PIVOT doesn't work in all of them
If you have both in tables, a cross join will give you what I think you might want. http://msdn.microsoft.com/en-us/library/ms190690(v=sql.105).aspx
Sorry I forgot! I'm using SSMS. 
Sorry I forgot! I'm using SSMS. 
1. flow control - use it. 2. Keep everything 10gb or 1gb - mixing will do this! especially with shit switches or misconfigured nic's
insert the filename into the table. basically what filestream does for ya!
Yeah, but it also handles storage and retrieval on disk for you. Your application doesn't need to know where to look or have correct security on the file system's storage location. It's all in the DB. There are advantages and disadvantages to both systems, though. I'd just rather not have to store binary files!
DATEADD is not a valid Oracle SQL function. If you want to add 14 days and assuming BILL_DATE is a column with the DATE data type just do: BILL_DATE + 14 Also, it's always helpful to post the error messages as well as the Oracle version you are using. It may also be worth viewing the SQL Reference for your version at http://tahiti.oracle.com 
Thanks. It actually didn't get any errors this time. Only now I have to figure out why it didn't actually update any rows (0 rows(s) update). 
I had completely forgotten about testing the subquery on its own. I ended up with : UPDATE CUSTOMER SET CUS_STATUS = 'INACTIVE' WHERE CUS_ID IN( SELECT CUS_ID FROM BILLING WHERE trunc(sysdate) &gt;= trunc(bill_date+14) AND BILL_STATUS = 'OPEN') And it worked! I hope this doesn't look like a stupid way around something that might have been staring me in the face but I'm happy. Thanks a lot.
I can also provide the database if you'd like.
Here's what I have so far.... ------------------------------------------- CREATE TABLE LARGE_SLIP (MARINA_NUM char (4) not null, SLIP_NUM char (4) not null, RENTAL_FEE int, BOAT_NAME char (50), OWNER_NUM char (4),); 
If you want the nulls to be allowed you just dont mention "NOT NULL" 
Also , is there some context to this question ? Or you just have to create some random table with a column having these specifications ?
I figured it all out, thanks for the replies!
Sigh, I found out what it was. Normal users don't have permission to run the sp_send_dbmail procedure. Thanks for looking anyway.
Do you get any output from the following query? sp_helparticle 'pubName', 'tableName' If you've dropped and recreated the table, it won't be included as a published article by default, you'll have to add it... But we need to see if it's in there, first.
The column field should continue to say 'COLUMN'. it's specifying the object you are changing the name of. exec sp_RENAME 'SALE.SaleBuyerId', 'SaleCustId', 'COLUMN';
Inserted and deleted can have more then one row. Triggers fire per transaction not per row so you can't just set a variable like that as your query could get multiple rows as a result. This may seem dumb but is the column NULLable? Also try commenting out the send mail as it may be the issue. When you say this isn't working and not giving an error, what does it do? Does it roll back or just hang or what? Oh and include the full trigger create text. What type of trigger is this?
so unless i'm mistaken about your requirements wouldn't you just want an order by clause that looks something like this: order by first_order desc, second_order asc that should give you the data sorted something like this: ..., 4, 1, 91 ..., 4, 1, 8 ..., 4, 1, 21 ..., 4, 2, 12 ... ..., 4, 3, 9 ..., 4, 4, 13 ..., 3, ... If that's not what you're wanting and you really do want to go through second order like 12341234123121222, then you might try setting up something that I'll call a "second order incrementer." Basically you would find the min and max of second order and start the incrementer at min, then process the first row where 2nd order = incrementer, then incrementer++, after it gets to max set it back to min, if it doesn't find any data incrementer++ again until you're done processing all of the "4" 1st order data. lather, rinse, repeat with remaining groups of data in the 1st order column. Of course that's really inefficient, if you have a whole lot of rows then you'll be better off trying to change up the data so you can do something like I mentioned first.
Nothing was returned other than a "Commands completed successfully." This is what executed. sp_helparticle 'CompanyIndividualContactandCampaign', 'dbo.importindividual' 
OK. What's the output of the following? (Run at the Publisher) EXEC sp_addarticle @publication = 'CompanyIndividualContactandCampaign', @article = 'dbo.importindividual', @source_object = 'dbo.importindividual', @source_owner = 'dbo', @type = 'logbased';
Msg 14013, Level 16, State 1, Procedure sp_MSrepl_addarticle, Line 168 This database is not enabled for publication. Is the result, not sure that makes much sense though as it is defiantly replicating. Is it possible that we need to define the database as well? I've confirmed that the Transactional check box is checked for the publication databases properties for that database.
I'm not an expert, so I could be wrong on this, but I don't think you can sort on a derived field that you're building in your select. You might need to do something like this: ORDER BY CustLastName,CustFirstName,StockName
&gt; DELETE FROM Artists WHERE ID = 2399 or &gt; DELETE FROM Artists WHERE LEN(Artist) &gt; 255 You change 255 with how long the artist name can be, any artists with names over 255 characters will be deleted.
Hi and thank you for the response! My old MM.DB file is currently sitting on my desktop waiting to be fixed, but I did allow the application to launch without a MM.DB to load, thus causing it to write a new one. Although it now functions, all of the data I had wanted to keep (various playlists, play counts, date added, ratings, and in some instances, album art) is not present, as it was stored in the old file. The amount of time to fix all this data would be staggering, as the library itself is currently sitting at 120gb (about 17k files). Also, but database schema, I assume [THIS](http://i.imgur.com/1Sy3SQD.png) is what you are referring to? 
Hi! I just tried both of these commands but these were the results: &gt;no such collation sequence: IUNICODE and &gt;no such function: LEN for each, respectively. Not sure if it is just a language thing or what.
try length( instead of len( and then we'll deal with that first try this: &gt; SELECT * FROM Artists WHERE LENGTH(Artist COLLATE BINARY) &gt; 255 If that turns out to work, try: &gt; DELETE FROM Artists WHERE LENGTH(Artist COLLATE BINARY) &gt; 255 
Just tried them both. The first command you gave resulted in "No Error" but nothing else happened. The second command once again had the "no such collation sequence: IUNICODE" Also, not sure if it helps, but I was able to isolate the individual tracks in a different table as seen [HERE](http://i.imgur.com/jHIAjLE.png)
You can run delete scripts on that database to remove the unwanted records but you'll need to know which tables have references to your unwanted records. You can definitely work at it with just the database schema alone but it will be tedious without proper documentation. The database tables are named nicely enough though that you can just experiment after backing up that copy and then testing the db after every change you make. DELETE &lt;SomeTable&gt; WHERE &lt;SomeUniqueIdentifyingColumn&gt; = &lt;'FileName'&gt; 
DELETE FROM Artists WHERE ID = 18538 DELETE FROM Artists WHERE ID = 18539 DELETE FROM Artists WHERE ID = 18540 DELETE FROM Artists WHERE ID = 18541 DELETE FROM Artists WHERE ID = 18542 DELETE FROM Artists WHERE ID = 18543 DELETE FROM Artists WHERE ID = 18544 DELETE FROM Artists WHERE ID = 18545 DELETE FROM Artists WHERE ID = 18546 
I took 70-461 and 70-463. Only because my company requires one cert per year. I am considered a "SQL Ninja" at my company, been to SQL Pass twice, and multiple local SQL chapter meetings (so I know that I stack up well with most SQL gurus) - yet these exams were crazy stupid hard. Be sure to sign up for a free second shot, you will need it. To study, I recommend buying the transcender tests - without them i would never have been able to pass. 463 is mostly a SSIS exam. I took the SQL 2008 version of 462 and it was a joke, so easy. I thought this was odd since I spend 2% of my time on DBA tasks and 98% on writing an optimizing complex queries. I would say start with that one. Why are you wanting to take these exams? I feel like the whole MCSA thing is watered down from people who cheat that it is meaningless. My company only requires it so we keep our Microsoft Partner status, giving us free developer versions of all the Microsoft products, not because you really learn anything useful from them. If I think of anything else I will add it. 
Before you do anything, take a backup of the database. Deleting records to get your app working is fine for the short term, but you know, it would be much better to just fix the app so it can cope with unprintable characters (or at least doesnt just explode) Having a broken database to test with will make bug fixing so much easier
OK. Try going into SSMS, find the publication, right click, Properties. Go to Articles an uncheck "show only published..." Then check the table you want to add. Will it let you save, or do you get an error?
I am unable to check the box to add it. The error is : This table cannot be published because it does not have a primary key column. Primary key columns are required for all tables in a transactional publications. I checked the table and there is nothing listed under Keys. I am assume that there was a key here previously but I have no idea what it was or needs to be.
1) can't help with such a vague description of your tables 2) trivially easy -- set up an animal_types table, and use a foreign key (do some research on **referential integrity** ) 3) that's right, mysql does not (at present) implement CHECK constraints 
"Kiss the Anus of a...." WAT?
 DELETE from Songs where Artist LIKE '%Big Black Delta%'; or DELETE from Songs where Artist='Big Black Delta'; 
I'm making a career change from IT work to entry SQL development/support. I think I would like to move into Business Intelligence in a couple years, so I thought this would help get me the gig down the road. 
Its certainly not going to hurt. Some companies will put weight in it, some will not. Personally, when I see certifications on resumes I don't even take it into consideration since the exams are so easy to cheat on (the full exams are available online). If you take them seriously and legitimately then you will learn a lot - but you will also learn a lot of useless information that is not practical for any job as well. BI can be great, but having a strong foundation of SQL skills will differentiate you from others who ONLY know BI. I do a lot of work with SSIS, SSRS, PowerView, PowerPivot, and some SSAS - but I can't imagine being able to do any of it without my SQL knowledge.
Something else... like the actual questions from the exams and the answers. I think they are called Brain Dumps. I am at work right now so I don't really feel like Googling it :D Like I said - unfortunately, these Brain Dumps water down the meaning of having these certifications. You could get a full MCSA in a month if you cheat - but you won't learn anything, then you will likely get fired after a month at your new job when they find out you know nothing. We have had to let contractors go multiple times, even though they had glowing resumes. I suspect it is something along these lines.
I'm probably misunderstanding what you're doing, but could you not do something like the below? Basically have a subquery which has the terms in it (there are better / more dynamic ways of doing that btw - but my static example is just for illustration purposes) and then just join the tables against it? Obivously I haven't tested this works. This will be quite performing I suspect, but that doesn't necessarily matter in all scenarios. with [athletes] as ( select distinct FactStudentActivity.StudentKey, FactStudentActivity.ActivityKey,convert(int, FactStudentActivity.StudentTermCode) AS StudentTermCode from [iBNSA_41].final.FactStudentActivity join final.DimActivity on DimActivity.ActivityKey = FactStudentActivity.ActivityKey where ActivityTypeCode = 'SPRTS' and DimActivity.SourceKey &lt;&gt; 'CHEER' and DimActivity.SourceKey &lt;&gt; 'NON_COMP' ), [department] as ( select distinct FactRegistration.StudentKey, FactRegistration.StudentDepartmentKey, FactRegistration.TermCode from [iBNSA_41].Final.FactRegistration ) select @term as [TermCode], DimStudent.UniversityID, DimDepartment.Description as [Department], DimActivity.Description as [Sport] from [department] join final.DimDepartment on DimDepartment.DepartmentKey = [department].StudentDepartmentKey join final.DimStudent on DimStudent.StudentKey = [department].StudentKey left outer join [athletes] on [athletes].StudentKey = [department].StudentKey left outer join final.DimActivity on DimActivity.ActivityKey = [athletes].ActivityKey cross join ( SELECT 201110 AS TermCode UNION ALL SELECT 201210 UNION ALL SELECT 201310 UNION ALL SELECT 201410 ) as [Terms] where left(DimDepartment.Description, 2) &lt;&gt; '[H' AND athletes.StudentTermCode &lt;= Terms.TermCode AND atheletes.StudentTermCode &gt; Terms.TermCode AND department.TermCode = Terms.TermCode
I understand where you're coming from but I can search on text fields. The LIKE works perfectly ok if I manually insert the term I'm looking for ie. jobrun_params LIKE '%234523%' it doesn't let me search using my declared variable even though it's the same amount. ninja edit - we're on MSSQL 2008 R2
In order to use a variable with the LIKE operator you will need to create your request in a string and then prepare and execute your SQL statement. DECLARE @parentID varchar(7) DECLARE @sqlstmt varchar(5000) SET @parentID = (SELECT jobrun_id FROM jobrun WHERE jobrun_params LIKE '%equity_warrant_euro.dif%' AND jobrun_proddt = '2013-04-29' AND CAST(jobrun_stachgtm As DATE) = '2013-04-29' AND jobrun_prntid IS NULL) SET @sqlstmt = 'SELECT jobmst_name, CAST (jobrun_proddt AS DATE) ProdDate, jobrun_duration DuraTime, DATEDIFF (ss,jobrun_launchtm, jobrun_lstchgtm) TidDuraTime, CAST (jobrun_lstchgtm As TIME) CompTime FROM jobrun JOIN jobmst ON (jobrun.jobmst_id = jobmst.jobmst_id) WHERE jobrun_prntid = (SELECT jobrun_id from jobrun WHERE jobrun_prntid = ( SELECT jobrun_id from jobrun WHERE CONVERT(varchar,jobrun_params) LIKE ''% ' CONCAT @parentID CONCAT '%''))' PREPARE @sqlstmt as statement1 EXECUTE statement1 I'm not all that familiar with prepare and execute syntax, so you'll have to look that up for your system, but that is the basics.
I could guess what this query would look like but it would be better with a real table structure. Do you just have 1 table named department then we would start off with SELECT * FROM [employee] Now we build a WHERE clause. **employees in department 10** Our first piece. SELECT * FROM [employee] WHERE (departmentID = 10) **any employee who earn a commission** Now we need to append to what we already have and make sure either condition can be met. We would use an "OR" instead of an "AND" between the two criteria. SELECT * FROM [employee] WHERE (departmentID = 10) OR (commission = 1) If the commissions are held in another table, which I would suspect then maybe something like this would do. SELECT * FROM [employee] WHERE (departmentID = 10) OR (employeeID IN (SELECT fkEmpID from commissions)) **employees in department 20 whose salary is greater than $ 2,000** The parentheses are very important for the next piece as this will require an "AND" to make sure the employee meets 2 criteria apart from the other two things that we have already added. SELECT * FROM [employee] WHERE (departmentID = 10) OR (employeeID IN (SELECT fkEmpID from commissions)) OR ((departmentID = 20) AND (salary &gt; 2000)) That's my guess. Hopefully my explanation helped as it's more important that you learn how to do and not just get the right answer.
you are the winner, however it's not working with the existing UNIONs I'm playing on it with. I'm assuming it's because we're now declaring the results as a varchar instead of what each column originally was? ie. Date is now varchar as part of the string?
I don't see any UNION's in the original query. Looking at your query, are you trying to do something recursive?
Like '%' + @parentID + '%' You forgot the trailing wildcard. 
Thanks for the reply, I had an error when i input your statement in the command line in SQL. Here is everything I have to work with right now.. http://imgur.com/a/FAxCR Edit: nevermind figured it out Select * from emp where deptno = 1 or comm != 0 or deptno = 2 and sal &gt; 2000; 
I initially had everything in phpadmin in the 10s 20s and 30s but it reverted to single digits for some reason.. Right now i'm having trouble writing a statement to pull up managers under my job column. I used the statement: select * from emp where job = manager; Had an error coming up saying ERROR Unknown column 'manager' in 'where clause' I'm thinking its not working for some reason since its not an integer like how the comm, deptno, and sal were
Yep exactly you should put single quotes around text. where job = 'manager' 
You have to query against a second instance of the vendor name table, Vendor_Code2, and that has to be joined to destination vender code. 
The technique gerson described would look like this SELECT t1.original_vendor_code ,orgt2.vendor_name as orginal_vendor_name ,t1.destination_vendor_code ,dest2.vendor_name as destination_vendor_name FROM table_1 t1 --first instance of vendor code table for orignal vendor LEFT JOIN table_2 orgt2 ON orgt2.vendor_code = t1.original_vendor_code --second instance of the vendor codes table for destination vendor code LEFT JOIN table_2 dest2 ON dest2.vendor_code = t1.destination_vendor_code
I have 2 selects ahead of this one correct :) edit - updated the parent with the selects.
it doesn't work even with the trailing wildcard. OK I lied I must have been brainfarting earlier it does work but I'm updating my parent thread it's not working with the UNION now.
Haha, it is "Kiss the Anus of a Black Cat" Actually some really good freak folk music. I would be lying though if I told you that I didn't originally get it because of the title though, haha. Sample: http://www.youtube.com/watch?v=eLSxlCY_l8c
&gt; A SELECT list cannot include both a group function, such as AVG, COUNT, MAX, MIN, SUM, STDDEV, or VARIANCE, and an individual column expression, unless the individual column expression is included in a GROUP BY clause. so move the single-value subquery into the FROM clause as a derived table, cross joined to the employees... SELECT TO_CHAR(AVG(salary),'$999,999.00') as AVG_SALARY , derived.EMP_below , COUNT(employee_id) TOTAL_EMPLOYEES FROM employees , ( SELECT COUNT(employee_id) EMP_below FROM employees WHERE salary &lt; ( SELECT AVG(SALARY) FROM EMPLOYEES) ) derived
I was doing something like this last night as well, I'm still getting the same error
I don't know what servoy is, but you can setup a free MSSQL server by downloading SQL Express... Give it a google, let me know if you need any more specific help.
I'm confused, do you want a list of all prior amounts for a given user, or the previous amount given a user and sequence? If it is the latter then you need a self-join: select current.amount as current_amount, coalesce(prior.amount,0) as prior_amount from amounts current left join amounts prior on prior.user_id = current.user_id and prior.sequence = current.sequence-1 where current.user_id = ? and current.sequence = ?
 select name, year, sequence, amount, lag(amount,1,0) over (partition by name order by sequence) as priorAmount from &lt;table clause&gt; where &lt;clause&gt; http://msdn.microsoft.com/en-us/library/hh231256.aspx If you don't have sql server 2012, self join is where its going to be. row_number will help if the sequence goes out of wack for whatever reason.
Thanks everyone - this solved the problem. You guys rock!
Oh man. I cannot freaking wait to move our team to 2012.
And it gets more complicated if your [prior] isn't sequence-1 (like with a date column). Then you need to find the max sequence less than current. select current.name ,current.amount as current_amount ,prior.amount as prior_amount from amounts current left join amounts prior on prior.name= current.name and prior.sequence = (select max(highest.sequence) from amounts highest where highest.sequence &lt; current.sequence and highest.name = current.name) (Also I ditched the coalesce because 0 is a valid amount and null means there is nothing prior. Just personal preference.) tweaqslug was right though, you shouldn't assume unique names and you should add a user_id to your data.
What type of database system is this? MS SQL Server? MySQL? Oracle? Excel '97? Also, can you give a little better idea of what you are "sampling"? What is the intended use of this process?
&gt; Select ('CustLastName','CustFirstName')as CUSTName I'm sure that this will cause an error to be thrown. I see what you are trying to do. But, simply trying to create one result field using parens will not work. You are going to have to concatenate the values. Also, you don't need the single quotes around the field names. Select CustLastName+', '+CustFirstName as CUSTName This is for SQL Server. Oracle uses || for the concat operator. I'm not sure what MySQL uses for concatenation. Also, you are selecting from the Stock table, but you aren't specifying a join for it in the WHERE clause like you do for the CUST table. You are going to end up with a "Cartesian Product" in your results. This would cause you to end up with many times more result rows that you want and 99% of them won't be valid.
Oh okay, that's good to know! I'll probably be making use of that then, thanks! 
You will want to alias the table and join to a second copy of it. Below your table is assumed to be called Employee. SELECT emp.employee_id as emp_id , emp.first_name as emp_first_nm , emp.last_name as emp_last_nm , man.employee_id as man_emp_id , man.first_name as man_first_nm , man.last_name as man_last_name FROM employee emp LEFT JOIN employee man ON emp.manager_id = man.employee_id 
You shouldn't implement that much logic in to your database at all. Send the data to an application layer and let it do the calculations.
Wow, Thank you a lot. I was way off. I was a little confused using the left join and on commands. Thank you for clearing it up for me. 
I've heard conflicting advice about this. Some say to let the application do the work, and others say it would be more efficient to let it be done in SQL server itself, especially since the app would only need to select the last n rows of the view instead of the entire set just to calculate the EMA value on each event. Another part of me just wants it done in SQL so I can feel the satisfaction of making it work. Man vs machine and all that. :)
You do understand that EMA is defined by a [recurrence relation](http://en.wikipedia.org/wiki/Recurrence_relation) and you won't be able to calculate it by simply selecting a subset of the dataset. You need the whole thing. The first datapoint affects the result of any later datapoint, however, minuscule the effect is after a while. That is, if you want to calculate the n'th EMA you will have to use all existing datapoints prior to it.
What technology are you using for your website? Microsoft's ASP / ASP.NET will be easiest for working with Microsoft Access. This link will help you -&gt; http://www.w3schools.com/aspnet/aspnet_dbconnection.asp
Probably the best method is to create a web service which handles the data retrieval and the have your website interact with the web service to display the data. I have being using ASP.NET in that sense with SQL for nearly 2 years now.
Could you possibly upload a database diagram somewhere for us to view?
I am now stupider for having read this. 
I kept waiting for the good part...it never came
UPDATE &lt;table name&gt; SET &lt;column name&gt; = &lt;value&gt; WHERE state = 'kansas' 
Could also be state = 'ks' depending on how the state column is stored
Here's an idea with CTE's: with MaxGrouping as ( SELECT B.LastTradeID , B.TradeDayClose , A.price , ROW_NUMBER() OVER(ORDER BY B.TradeDayClose) as rowno FROM dbo.Trades as A JOIN ( SELECT max(tradeID) as LastTradeID , max([date]) as TradeDayClose FROM dbo.trades GROUP BY CAST([date] as date) ) as B ON A.tradeID = B.LastTradeID), SMA as ( SELECT Maxgrouping.LastTradeID , MaxGrouping.TradeDayClose , Maxgrouping.price , Maxgrouping.rowno , AVG(Maxgrouping.price)OVER(ORDER BY MaxGrouping.TradeDayClose ROWS 89 PRECEDING) as SMA90DayPeriod , AVG(Maxgrouping.price)OVER(ORDER BY MaxGrouping.TradeDayClose ROWS 29 PRECEDING) as SMA30DayPeriod FROM MaxGrouping), EMA as ( SELECT currentDay.TradeDayClose , currentDay.price , currentDay.rowno , currentDay.SMA90DayPeriod , currentDay.SMA30DayPeriod , previousDay.SMA90DayPeriod +(2/(90+1))*(currentDay.price - previousDay.SMA90DayPeriod) as EMA90DayPeriod , previousDay.SMA30DayPeriod +(2/(30+1))*(currentDay.price - previousDay.SMA30DayPeriod) as EMA30DayPeriod FROM SMA as currentDay JOIN SMA as previousDay ON currentDay.rowno = previousDay.rowno-1) SELECT currentDay.TradeDayClose , currentDay.price , currentDay.SMA90DayPeriod , currentDay.SMA30DayPeriod , coalesce(previousEMA.EMA90DayPeriod,previousSMA.SMA90DayPeriod) +(2/(30+1))*(currentDay.price - coalesce(previousEMA.EMA90DayPeriod,previousSMA.SMA90DayPeriod)) as EMA90Day , coalesce(previousEMA.EMA30DayPeriod,previousSMA.SMA30DayPeriod) +(2/(30+1))*(currentDay.price - coalesce(previousEMA.EMA30DayPeriod,previousSMA.SMA30DayPeriod)) as EMA30Day FROM EMA as currentDay JOIN SMA as previousSMA ON currentDay.rowno = previousSMA.rowno - 1 JOIN EMA as previousEMA ON currentDay.rowno = previousEMA.rowno - 1 It might not be working as I didn't test it out on any data, but the logic should be correct. Although, my join on (rowno = rowno -1) might be backwards, I can never seem to get it right on my first try. 
http://imgur.com/FRnajOW There's a link to the database diagram. State is only present in two of the tables, I believe, so wouldnt it return an error if I tried using state for the tables that do not have a state column? Thanks, and sorry for not posting the pic earlier
No problem. Let me know if this works. My syntax might not be correct for MS SQL, I am using DB2.
try the following: SELECT vendorCode, address1 FROM table GROUP BY vendorCode, address1 HAVING count(1) &gt; 1 
Thanks for your reply. I've tried this but it doesn't give the results I'm wanting. If I used your SQL in the following table: **vendorID -- address** V001 ---- 123 Main St V001 ---- 22 West Broad V002 ---- 22 West Broad X051 ---- 12 Uptown St X051 ---- 75 East Way V001 ---- 123 Main St V001 ---- 123 Main St V001 ---- 123 Main St V001 ---- 123 Main St V001 ---- 123 Main Street X051 ---- 75 East Way X051 ---- 12 Uptown St V002 ---- 22 West Broad It gives me: **vendorID -- address** X051 ---- 12 Uptown St X051 ---- 75 East Way V002 ---- 22 West Broad V001 ---- 123 Main St Where I actually want it to say: **vendorID -- address** V001 ---- 22 West Broad V002 ---- 22 West Broad In my desired report (above), you'll note that these 2 results came up because they are the only vendors that shared the same address.
Sorry, I misread your original request. try the following: SELECT DISTINCT vendorID, address FROM table WHERE address in (SELECT address FROM table GROUP BY vendorID, address HAVING count(DISTINCT vendorID) &gt; 1)
Thanks for your reply. I tried this and it gave me a similar report as what smileythom originally suggested I try.
This worked like a charm, and no subqueries needed (as I was currently using). Thanks!
You can't mix and match data types so you'll need to cast your numeric data to varchar. Something like: cast(li.ALLOCATED_QTY as nvarchar(10)), For each of those numeric types Then union that with your other query. This plan of yours is highly unorthodox though and I don't see why you can't just retrieve two data sets, one with the column names and the other with the actual data. Hope this helped. Edit: You'll also need to transpose the column name data using SQL Server's pivot operator.
Thanks for the reply - unfortunately, what you're suggesting is over my head. I do know that we don't actually need all the resultants. We only need 2 columns that contain numeric values (AVAILABLE_QTY &amp; ITEM.) The only reason they were included is because there were formulas run to get the resultants. In addition, I don't actually need to retrieve 2 data sets - the headers are static. The catch is, this is a report that will be run daily. We're trying to automate the process, but in order for the correct data to be pulled, we'll need the column headers. Instead of casting numeric data to varchar, can we leave some headers blank? ("",item,"","","",avail_qty,"", etc) We just figured it would be easier to include the headers when we're querying the data rather than trying to automate them them in another program (excel) later. Thoughts? 
How are you guys exporting the data? 
Hah no problem.
It looks like you are making this way more difficult then it needs to be. It should really look something like... SELECT 'Company', 'Item', 'ON_HAND_QTY', 'ALLOCATED_QTY', 'SUSPENSE_QTY', 'AVAILABLE_QTY', 'TOTAL_COST', 'TOTAL_VALUE', 'USER_DEF3', 'IN_STOCK' UNION ALL SELECT i.COMPANY, i.ITEM, cast(li.ON_HAND_QTY AS nvarchar(10), cast(li.ALLOCATED_QTY AS nvarchar(10), cast(li.SUSPENSE_QTY AS nvarchar(10), cast(CASE WHEN li.ON_HAND_QTY - li.ALLOCATED_QTY - isnull(sd.total_qty , 0) &lt; 0 THEN 0 ELSE li.ON_HAND_QTY - li.ALLOCATED_QTY - isnull(sd.total_qty , 0) END) AS nvarchar(10) AS AVAILABLE_QTY, cast(li.TOTAL_COST AS nvarchar(10), cast(li.TOTAL_VALUE AS nvarchar(10), cast(i.USER_DEF3 AS nvarchar(10), case when li.ON_HAND_QTY - li.ALLOCATED_QTY - isnull(sd.total_qty , 0) &gt; 0 then 'In Stock' else 'Out Of Stock' end AS IN_STOCK FROM /*etc etc etc */ &gt; UNION ALL basically takes two queries and merges the results into one, the requirement being that they are the same data type; hence why the use of cast to change the integers/floats to be strings. 
Excellent - I will work with this to try to streamline the code. I did eventually find the solution though - There's an option on the tools menu to include column headers when saving the results. However, it's possible that it won't work if the query is completely automated. I've got to talk to my boss (the one that wrote the original query) and provide your code just in case. Thanks! 
I'd do it the way chaos said you don't want to modify other things to make a query work. His way is portable
10-4, that sounds mighty reasonable. Unfortunately, my boss was away the rest of the day, so test tomorrow. 
Well it appears to have worked! Looks like it's calculating the EMAs as accurately as possible given my current shortage of data. Your syntax was correct. Only change I had to make was (as you suspected) the rowno -1. I just switched the sign(s) and all is well. Again, big thanks! I doubt I'd have figured that out on my own anytime soon.
Glad to hear! I hope that performance isn't a problem.
If you can get your hands on one, the Oracle University books are great. After that I would look into O'Reilly books. 
Sams was a great book and highly recommend as a starter. They really do a great job on building knowledge in a clear and concise manner. 
Don't use books to learn programming. O'Reilly is the best bet, but seriously, don't use books. Also, 'learn XYZ in UVW {time measurement}' books are almost always horribly sparse. "Learn to program before you die" would be the only book I'd ever buy, if they made it. There are plenty of online materials for free that do a better job of keeping themselves up to date. An error is a trivial fix on a website. You can't just unprint 10,000 books though. http://www.w3schools.com/sql/ is an OK starting point. http://shop.oreilly.com/product/9780596007270.do if you INSIST on buying a book. http://web.cecs.pdx.edu/~maier/TheoryBook/TRD.html is a really good primer on relational databases in general. http://sql.learncodethehardway.org/ - "Learn SQL the Hard Way" - the 'hard way' online books are awesome. There's lots of languages there to jump on.
Why isn't it doing it the first time round? Because it has nothing previous to reference? Could you post any kind of samples or anything we can look at. 
I've always liked *SQL For Dummies*, now in its 5th or 6th edition.
&gt; Don't use books to learn programming. Why not? Why make such a blanket statement? &gt; You can't just unprint 10,000 books though. That argument assumes that there will be errors in the book. For something like SQL that hasn't changed in forever, I can't see that a book from OP's local public library won't do the job. Remember that not everyone learns the same way. For many of us, learning on paper is entirely different than learning on a screen.
For the basics? Learn SQL the Hard Way. It's still in alpha, but if you put the work in it will pay off.
Dude, there has been errors in every single programming book I've read. Often times, in compiled languages, the 'tutorial programs' don't compile, because the compiler or language has gone through revision or there is error. Further more, do you really want to type out every single line of code you're copying from the book? That doesn't teach you crap; might as well copy/paste. Also, as the language changes, the books don't; that book you got on PHP from 2008? It's moot now. Books are horrible places to learn programming because the landscape of programming changes that fast. If there was a way to update books after the fact, I'd suggest them. As there is not, and programming as a skill and knowledge domain is all of 70 years old (compared to other knowledge domains like engineering or architecture or carpentry or even electricians which are 100+ years old, even thousands of years old), we really don't know shit about programming. The whole industry is guessing and changing and morphing as the years go by; our hardware today is much better than two years ago, and will be unusable in ten years. The software it runs will change with it. Books are an antique of the past; they are not a proper media form. Goto page 53 for this. Now go back to the glossary to find the term you don't understand that sends you to page 22. The stuff there requires some predicate knowledge, so flip back an arbitrary amount of pages. Or you could do a google search or click on a hyperlink. Some documentation formats on the computer even let you hover over a word to see the definition. http://www.codinghorror.com/blog/2008/04/programmers-dont-read-books----but-you-should.html That highlights, more eloquently, some of the issues with books. But it does point out there are books you should read; however, none of those books are 'how to do this' or 'learn this' books. They are books on theory. Yes, if you haven't read SICP, then go get the book or the PDF. So on so forth for the other seminal pieces. But to learn SQL by a book? Ah, fuck no. Furthermore, if you can't learn a language by any other method than a book, your thinking is far too linear and you're going to have trouble with programming. Programming doesn't fit the book model anyways; it's not like learn this then learn this then learn this, chapter by chapter. Everything interacts with everything. Nothing stands alone; a-z ordering is irrelevant; it's more like each piece of knowledge opens up and branches into more possibilities and folds back into things prior learned. You can't make a chapter by chapter representation of that.
I am in no way an authority (still busy to get my MCSA in SQL Server), but I've created a course on [memrise](http://www.memrise.com/course/88361/sql-4/). It will teach you the most used functions, the different datatypes and some basic queries. It will take 2 hours to complete the course and memrise will remind you to retake the course to refresh your memory. I recommend toying with this [free database](http://msftdbprodsamples.codeplex.com/downloads/get/478214) on [MSSQL Express 2012](http://www.microsoft.com/en-us/download/details.aspx?id=29062 ) if you follow/finish the course.
The records it references are being inserted earlier in the process. I'm wondering if the entire procedure has to finish before it's "committed" in a sense, and the records are made available for reference. Here's an example of the data I'm trying to import: JobID JobName RunAfterJobName RunAfterJobID 1 Apply NULL NULL 2 Continue Apply 1 When "Continue" is inserted, it can't find a RunAfterJobID for "Apply" because it was only just inserted moments earlier as part of the same merge. Here's an example of my merge statement: &gt;MERGE JobsTable AS PROD &gt; &gt;USING ( SELECT STG.[JobName] , FK_JobsTable.[ScheduledJobID] &gt;FROM JobsStaging AS STG &gt; &gt;LEFT JOIN JobsTable AS FK_JobsTable &gt; ON FK_JobsTable.[JobName] = STG.[ScheduledJobName] &gt; &gt; ) AS STAG ( JobName, RunAfterJobID ) &gt;ON STAG.JobName = PROD.JobName &gt; &gt;WHEN MATCHED AND ( &gt; ( STAG.RunAfterJobID &lt;&gt; PROD.RunAfterJobID ) OR ( STAG.RunAfterJobID IS NULL AND PROD.RunAfterJobID IS NOT NULL ) OR ( STAG.RunAfterJobID IS NOT NULL AND PROD.RunAfterJobID IS NULL ) &gt;) THEN &gt;UPDATE &gt;SET PROD.JobName = STAG.JobName , &gt;PROD.RunAfterJobID = STAG.RunAfterJobID &gt; &gt;WHEN NOT MATCHED THEN &gt;INSERT ( JobName , RunAfterJobID ) 
I have to partially agree with you. I absolutely hate it when book examples do not work. Keep in mind online tutorials often face the same problems.
SELECT INTO and UNION are your friends. Make end table (CREATE TABLE end_table ...) Then: SELECT * INTO end_table FROM table1 UNION table2 UNION table3 ...
It depends on what database you are using but with most of them you can query a system table to get a recordset of all of your tables. You can turn this into a query. You can do something like this combining badjuice's post. This is for SQL Server: select 'SELECT * FROM ' + [name] + ' Union' from sys.TABLES Then put "insert into [new table]" and get rid of the last union. That should be pretty quick for you.
Bad Advice, websites are just shallow information. A website only gives a simplistic view of programming. Real programmers need books.
This http://www.amazon.com/Microsoft-Server-2012-T-SQL-Fundamentals/dp/0735658145 excellent with great examples
Yup, that's the one. I went through the book for 9i and it was very good. 
Trial and error seems to be the best guide. Set it up any play...You don't really need a life after all...
This looks pretty cool. Shame there isn't a PDF or Kindle-friendly format yet :(
but duplicate record will not be insered twice in a table no ?
It depends how your table is setup and whether you want them or not. 
What Database are you using? In SQL Server (and Oracle) you can write a recursive CTE to generate your data. In other databases you'd have to write a Stored Procedure or even an external application. If the data already exists and you simply want to append a date to it, it gets easier. You can use the Row_Number() functionality as your count as you update records.
You could declare a cursor: http://msdn.microsoft.com/en-us/library/ms180169.aspx
Can you provide sample data of both source and desired output? SQL is more designed around set based operations not just item so there may be a way to do it
there's a technique that can do it easily (without looping) using a **numbers table** holler if you want me to elaborate (also, pls mention which dbms you're using)
Select Company, COUNT(Product) as NumberofProducts from Master_Table GROUP BY Company 
not sure who downvoted you, but that's how I'd do it.
What is being stored in the product field, a count of the number of products or a product identifier?
with company and product in the SELECT clause, but only company in the GROUP BY clause, this will give an error in all standard sql compliant database systems
ID Interval Iteration Start Date 12345 monthly 4 1/15/2013 12346 bi-weekly 3 3/8/2013 12347 semi monthly 2 5/1/2013 ID Occurrence Date 12345 1/15/2013 12345 2/15/2013 12345 3/15/2013 12345 4/15/2013 12346 3/8/2013 12346 3/22/2013 12346 4/5/2013 12347 5/1/2013 12347 5/15/2013 **EDIT** Sorry I can't figure out this reddit formatting. 
No need for the quotes around the number, it's not a string. Not a crit just a tip.
We don't actually know what data type Product has so the quotes may be valid.
If it's varchar or even bit in the db, in the query it's int. You don't need quotes.
Here is the issue im having. There are 100's of products in table B. Which makes the Fee in table Aduplicate 100's of times. And there are 2 fees in table A. Causing each Fee in table B to show up twice. I just want a grand total of Table A Fee and Grand Total of Table B fees to show up side by side and they should equal the same thing.
Data migration/manipulation I'm assuming, address parsing blows.
 Try this: SELECT A.BillingItem, SUM(A.Fee),SUM(B.Fee) FROM tableA A INNER JOIN tableB B on B.billingcode = A.BillingITem GROUP BY A.BillingItem I assumed a couple of things. 1) i assumed this is T-SQL 2) I assumed billing code in tableB is the same as billing Item in tableA 3) I assumed you wanted the tax and the price to be totalled.
2 and 3 are correct. Im just using SQL in Access. I am pretty sure that is just ANSI SQL but im new to this. I will try in a second but just wanted to see if that changes anything thanks for your time
You're correct. Disregard my post!
I did it and it still has the issue of table A fee summing up 100 of times for each individual unit. 
Can't help with syntax but what about something like this: SELECT A.BillingItem, SUM(A.Fee), (SELECT SUM(B.Fee) FROM tableB B WHERE B.billingcode = A.billingITEM) FROM tableA GROUP BY A.BillingItem
Seriously, address parsing *blows*. Find out if you can use some service (USPS, Google, Bing) to do it. Doing it on your own is just...terrible.
select company from master_table where product &lt;&gt; 0 group by company order by 1 That gives you all the companies that sell products through you in alphabetical order.
This would be a great way to get the number of products sold and the company name.
OP already mentioned he wanted both rows, price and tax.
Since we aren't told the definition of "Master_table" and it's not "tblProducts", you might get a more usable count by using "COUNT(DISTINCT Product)", in case any Product value is repeated in that table. Otherwise, this looks perfect and is probably exactly what is needed.
From the way your description sounds... SELECT a.billingitem ,a.status ,a.fee ,Sum(b.fee) FROM tableA a INNER JOIN tableB b ON a.billingItem = b.billingcode GROUP BY a.billingitem ,a.fee ,a.status If this doesn't work, could you post some sample data? This sounds easy, just not sure I follow your table descriptions
Well the product column is not needed as the requirements state the OP wants a list of companies. In general you don't want to include columns if they are not requested as this reduces performance. That would mean this is a correct answer but not the most correct answer and for teaching purposes we should be giving the best answer.
What database? In SQL Server, I'd do it like this: WITH dates as ( Select &lt;ID&gt; ID,&lt;Interval&gt; Interval ,&lt;Iteration&gt; Iteration ,&lt;StartDate&gt; StartDate UNION ALL Select d.ID, d.Interval ,d.Iteration-1 Iteration ,(CASE WHEN d.Interval = 'monthly' THEN dateadd(mm,1,d.StartDate) WHEN d.Interval = 'bi-weekly' THEN &lt;whatever SQL date math&gt; WHEN d.Interval = 'semi monthly' THEN &lt;whatever SQL date math&gt; END )StartDate From Dates d Where d.Iteration &gt; 0 ) Select * from dates
My best advice when trying to seek help on this stuff is to provide a sample of the tables you have, and what you think the table should look like. Most of us SQL guys don't need an explanation. We just need a before and a estimated "after" and we can write the in between. 
Try a SELECT DISTINCT.
OP here, forgot my pass i guess I read SAMS learn SQL in 10 minute book and it was good, but i was already doing alot of the stuff in there. What is a "intermediate book" i can read from here? and an advanced book i can read after that? I really want to concentrate on mastering sql. 
it was a good starter, what is your recommendation for an intermediate book I can read next? thanks
Came here to post this, but since you already have, I'll just jump on.
select Company from Master_table group by Company having COUNT(Product)&gt;0 
 O'Reilly is usually a goto publisher in this area, but I would recommend reading Sam's and figuring out where you go from there. Pick what aspect you love (T-SQL, programming, etc) and just go deeper down the rabbit hole.
How about this: SELECT RIGHT('00000000000' + CONVERT( VARCHAR(11) , customer_account_num), 11) We create a string with 11 leading zeroes before the id number and then grab the 11 rightmost characters from the string. Quick and dirty!
BASH and PHP. Doesn't it store it in a .db file?
I can also bet the the CSV import is the problem. Open the CSV and ensure you have ...,"0000001235",... If yes, the import is probably assuming number and needs to be adjusted to import as varchar. If the CSV doesn't have the string then you know the SAS export is the problem.
It was my dufus boss. He opened the CSV in Excel, deleted two extraneous columns, and then saved it as a CSV without masking the column. Excel dropped the leading zeros. 
SQLite has a [command line interface](http://www.sqlite.org/sqlite.html) which I assume you can invoke with BASH as well. The PHP wrappers make PHP access to SQLite easy. Yes, the SQLite data is in a single .db file.
I guess I just need to figure out how SQLite organizes its data, so I can visualize and understand how to put it in.
Development, I use "development" and "sandbox" interchangeably
"DEV" is short for development, i.e. an environment where things are being developed (generally a pretty unstable environment) before being pushed to production (preferably via a staging environment). See [http://en.wikipedia.org/wiki/Development\_environment\_(software\_development_process)](http://en.wikipedia.org/wiki/Development_environment_\(software_development_process\))
Never read it, but it was recommended to me by an app dev a few years ago. [Access 2007: The Missing Manual](http://www.amazon.com/Access-2007-Missing-Matthew-MacDonald/dp/0596527608/ref=sr_1_5?s=books&amp;ie=UTF8&amp;qid=1368205999&amp;sr=1-5). The Stanford DB course is pretty good, might want to check out microsoft training materials. Check out [SQLcourse](http://www.sqlcourse.com/index.html) as well.
I realize this doesn't answer your question, and I also realize that this may be a lot of work depending on how many courses you have and how much data there is, but if you combined all those course tables into one table you'd save yourself a TON of trouble in the long run. (For example, there are at least two tables that aren't linked to EMSCourses).
i would like to do that, but i update each report maybe once or twice a day, would i just filter the big table, delete and paste there? I was not sure if that was allowed, or if even that would require a query to find all records with courseID and replace with whatever i update. I think i overcomplicate myself sorry those 2 tables were errors haha
Oh those are reports and not tables! I'm having a hard time wrapping my head around your data so I'm not sure how to answer your question. However, if your reports are set up correctly, you shouldn't have to add or remove data to change what the report displays, if that makes sense. You might be helped by looking at database normalization. [Wikipedia](http://en.wikipedia.org/wiki/Database_normalization) has some pretty good explanations (particularly look at [third normal](http://en.wikipedia.org/wiki/Third_normal_form)). It changed how I look at the world :)
http://i.imgur.com/QcHSPcY.png It became easier once i realized access did not treat cells like excel, making it a DATABASE dream come true, i feel stupid now
And now your life is complete :)
I am using this -[Free SSMS plugin](http://www.apexsql.com/sql_tools_refactor.aspx)
It's the non production instance.
Thank you for the reply! I'll be able to show sample data in the morning if that is OK. My issue is that there are just duplicate books and authors in the tables. For instance the book "the hobbit" is entered 7 times. But my code : Select distinct * From book Cross join author Yields all 7 hobbits. This is greatly bloating my results. I know I have to get these results down someway. Maybe I'm not thinking on the right path. Is there a different type of method of listing all columns without duplicates? Edit. Doh! Is cross join messing me up ?? Doesn't that combine all possible combinations?? 
Ugh, Still cant figure it out. http://imgur.com/a/wGHs4 there is the data I am working with. It is still duplicating the data when I join...
DEV QA UAT PreProd PROD that's what we have for some applications. For most it's minus the PreProd. We're insanely cautious at work.
put the word ALL after the word UNION
Is lm.condition an indexed column? 
Are your primary keys ints or GUIDs? are they clustered on the primarys? Are any of your column that you have criteria on large object types? (nvarchar(max), image, XML) 
It's MSSQL, did OP use SQL Server Management Studio and review the execution plan?
Does it return 0 rows? Your statement shows PBBARegion as having 0 rows, if you try to JOIN against it your resultset will have 0 rows. Your Stops table is LEFT OUTER JOIN'd, yet you are referencing columns directly in the next INNER JOIN, so in a sense you no longer are LEFT OUTER JOIN-ing the Stops table. So much is wrong with this query, did you write it or inherit it? 
[Checklist for Analyzing Slow-Running Queries](http://msdn.microsoft.com/en-AU/library/ms177500%28v=sql.90%29.aspx). The execution plan should make it clearer as to what operation is taking the longest, and then you can focus on optimising that. General suggestions: - consider upgrading as newer versions usually have performance improvements. - PBBARegion doesn't seem to be used for anything, remove that join from the query. - reconsider the JOIN ON ... OR, I don't understand why that is used instead of a WHERE, or a UNION ALL subquery, or maybe even some CASE statements. - depending on the query execution the LEFT JOIN Stops might be returning rows that are eliminated by later INNER JOINs, so try doing it last. - if there are tables with a filter applied (like LM.LoadStatus = 90) and the data isn't updated regularly, it might be worth considering putting that in a periodically updated table instead, so that the filter is already done. - try selecting only the columns you need from each table - it might be faster, depending on indexes. I'd at least use a DISTINCT subquery for the table that is giving you duplicate rows, so you don't need to DISTINCT the whole result. - taking some of the above suggestions together i'd rewrite it as copied below, but obviously this is a first guess and probably many other guesses are required before you get to your optimisation goal. --- SELECT DISTINCT lbts.loadnum , lbts.stopseqnum , lbts.customercode , lbt.customercode , c.name FROM loadbilltostops lbts INNER JOIN ( SELECT lbta.customercode , lbta.loadnum , lbta.sequencenum ) lbt ON LBTS.LoadNum = LBT.LoadNum AND LBTS.BillToSeqNum = LBT.SequenceNum INNER JOIN ( SELECT ca.companycode , ca.name , ca.updateddate FROM customers ca ) c ON C.CompanyCode= LBT.CustomerCode INNER JOIN ( SELECT lma.loadstatus , lma.condition , lma.loadnum FROM loadstatus lma ) lm ON LBTS.LoadNum = LM.LoadNum INNER JOIN ( SELECT lda.loadnum , lda.updateddate , lda.entereddate FROM loads lda ) ld ON LM.LoadNum = LD.LoadNum LEFT JOIN ( SELECT wa.companycode , wa.updateddate , st.loadnum , st.seqnum FROM warehouses wa INNER JOIN stops st ON st.warehousecode = wa.warehousecode ) stwa ON stwa.loadnum = lbts.loadnum AND stwa.seqnum = lbts.stopseqnum WHERE (ld.entereddate BETWEEN (SELECT pbadr.startdate FROM PBBADateRange pbadr) AND (SELECT pbadr.enddate FROM PBBADateRange pbadr) OR ld.updateddate BETWEEN (SELECT pbadr.startdate FROM PBBADateRange pbadr) AND (SELECT pbadr.enddate FROM PBBADateRange pbadr) OR c.updateddate BETWEEN (SELECT pbadr.startdate FROM PBBADateRange pbadr) AND (SELECT pbadr.enddate FROM PBBADateRange pbadr) OR wa.updateddate BETWEEN (SELECT pbadr.startdate FROM PBBADateRange pbadr) AND (SELECT pbadr.enddate FROM PBBADateRange pbadr)) AND lm.loadstatus = 90 AND lm.condition &lt;&gt; 'X' AND lm.condition = 'F' --- 
Books tend to start from a base level of knowledge and work forward from a structure. Websites don't. Google works great when you know the question, but terrible for any kind of overview. 
I would venture a guess that if you look at the execution plan, that's what the optimizer did: drop the &lt;&gt; and only care about = 'f'
remove
Firstly, you run everything inside of a transaction. If things are good you commit, if there are problems you rollback. Pretty simple really. If you find later that you screwed up, well that's why you have backups. You test your backups so you can restore lost data in as short a time as possible. It's cute how you sit there pointing fingers at the software and state how there should be Ctrl-Z functionality. You probably shouldn't have access to be able to make updates in production if that's where your comfort level resides.
Phooey, *everything* should have a Ctrl-Z functionality, its just that some things are way too complex for that. Anyways, please cut back on your attitude there, he was asking a question, no reason at all to be so condescending.
Everything? Seriously?
Well, the poor soul doesn't know the difference between an application and a service or 'engine.' SQL server is NOT an application, SSMS is an application and it does have a CTRL-Z. SSMS and other applications are used to interact with the SQL Server engine. Basically they send commands to the engine, which are executed and results sent back to SSMS or what ever other application you are using to interact with the engine. SQL Server does have a CTRL-Z and it is implemented in a variety of forms: *Transactions with Commits and Rollbacks, but you have to know how to prepare for it by sending the right sequence of commands to the SQL Server engine. *Make a backup of the data you are going to change before changing it. *Not really a CTRL-Z but common sense dictates a test instance. OP screwed up because he did not a) take proper precautions by testing his query on a test environment and was a bit arrogant by assuming that the system would cover his mistake, and b) not knowing what the heck he was doing and how costly and inconvenient his 'data assassination' would be to others. OP is not at fault. OP's supervisor is responsible for trusting valuable assets to an inexperienced person. Perhaps OP should go back to using Excel or Access for his data needs - they have a CTRL-Z. Of course, we could talk about change tracking, restores in point, etc. but the experience, support structure, and knowledge is apparently not there at the moment. Enjoy the gold, SonOfZork.
Not just once in my case. I leaned a lot about the RESTORE command, though. 
Cannot +1 this enough. 
Check out the "Learn XYZ the hard way" series. There are others like it that are conceptually beginning to usable-end; yes there are a lot of crappy tutorials, and it takes an eye to know.
I've wanted to CTRL+Z life a couple of times. 
1. It's been stated several times already, but, always run potentially destructive commands inside of a transaction, and only commit it when you're confident with the results. 2. Generally speaking, updates may be reversed, provided they are caught in time ("time" will vary based off database configuration). 3. It doesn't change the fact that you screwed up, but know that you are neither the first, nor the last to make it. In fact, in the 5 hours since you made this post, I'm sure someone else goofed an update or delete. Learn from this. Write better SQL, double check your work in a safe environment, run in prod only after fully vetting, and even then, in a reversible fashion.
Thank you very much for your reply. With your help I was able to find that I was missing a table name. The teacher didn't include it in the document. 
This isn't really feasible in a high-traffic environment though. After you run your UPDATE statement, other transactions are likely to happen. You can't simply put things back the way they were before.
Exactly this. Without encapsulating your changes in a transaction, the database doesn't exactly keep track of every change made by your UPDATE statement. Also, without the transaction to lock things down before commiting, other users/processes can also change the data between the time you UPDATE and the time you try to ROLLBACK.
You should also have a test instance where you design your queries before running in Prod. If you break test, you can simply query Prod to restore your data.
Yes, I don't believe SQL Server maintains a rollback segment per session without initiating a transaction. Oracle may be considered implicitly transactional as it does give that. 
&gt;There are backups and &gt;permanently destroyed Are mutually exclusive statements. Besides the "use transactions" advice that's going around, here's a couple more tips: 1) Always use a prototype environment or staging area to test your queries first. 2) When running in production, *ALWAYS* run a SELECT statement first, so you can see what data will be affected before you change the query to an UPDATE. Clever usage of line breaks and SQL comments can make it very easy to switch the same statement between SELECT &amp; UPDATE.
It doesn't slow queries down to have this. Oracle has it and it isn't any slower. The logging is already in place for all of this.
Yes, it can be done, that is what log files are for. Check out Oracle's Flashback feature.
One other tip that I would recommend (Not in all cases) but I've been known to use the same where clause to copy those records to another table with a trailing datetimestamp type thing that I can come back later and remove. You have to be diligent about the removal bit though. As an example if I have: Update table set columnA = value * .10 where columnA &lt; 20; I'll first execute: Create table table_201305130800 ( table definition ) GO Insert into table_201305130800 Select * from table where columnA &lt; 20 This of course assumes I have space, etc. It also works for deletes. 
Yes but the post I was referring to implied that such a feature wouldn't be feasible I. A large/high paced environment. It is feasible though in other vendors it is just chosen by MS to not be important to provide
Don't have a back up plan, have a restore plan!
Just because it can be done doesn't mean it should. Once the accidental update has been committed, the newly changed data is available to other users, who may have subsequently made their own updates. It all depends on the way the business uses the data, but there is a good chance that just rolling it back to what it was before would not be the logically sound course of action. 
There is an undo button, it's called a transaction. Either way running an untested sql command against a production database is a surefire way to screw something up. Always run it in a test environment first and make sure the results are what you expect. Or at the very least select * into tblNameofTableAndDate from tblNameofTable so you have a backup of the table. 
That's why in flashback you select the data as it was before "the change" happened that caused you to do the flashback. You can then compare the current (possibly since modified) rows vs. what it was before. It is a great feature.
Oracle's SQL\*Plus is configured by default to be non-committal. Thus, you must issue **commit;** statements. SQL Server's SSMS is by default does an implicit commit. You can configure it to not behave like this by changing the [SET IMPLICIT_TRANSACTIONS](http://msdn.microsoft.com/en-us/library/aa259220.aspx) mode for the connection here: * Tools... * Options... * Query Execution... * SQL Server... * ANSI... * Check SET IMPLICIT_TRANSACTIONS
Yes, there's a nonclustered index on this column, and LoadNum / LoadStatus as well. Thanks &lt;3 
Good point. I have no idea. I'm changing this to just LM.Condition = 'F' just for cleanliness' sake if nothing else. Thanks &lt;3
There is a function called DATE_ADD() that you can look up how to use. I would also use between in the where clause. DATE_ADD(date,INTERVAL expr type) Not sure if you are worried about minutes or seconds but that is something that causes problems when dealing with dates. This is how I would probably write what you have above. If you don't want to include the current date you may have to run the date_add -1 on that too. SELECT * FROM table WHERE [Date] BETWEEN DATE_ADD(CURDATE(), INTERVAL -5 DAY) AND CURDATE() 
Awesome, thanks I look more into this. The data we're using is automatically a day old so the day's date should be all I need.
&gt; Also, can someone point out some reasons to why any these tables are not in 3NF or BCNF? only if you explain why it would matter to you
So, what WAS on the test?
Well, I feel it helps me to prevent inconsistency within the data. So basically it has to do with data quality. I am a nerd, so I also get pleasure from just having code that meets a certain criteria.
These may also come in handy: Left(expression, count), Right(expression, count), LEN(expression), LTRIM(expression) and RTRIM(expression)
for a personal project, your database looks okay from a strict perspective, some of the columns are redundant (e.g. the goals table has both the player who scored and the team, and it's technically possible to record an inconsistent pair of values), but i wouldn't bother trying to fix that 
Yea, the query designer will do that, it will also flip the order (where to start the query) of the tables. I hate it when it does that... because I get to 'solve the slow query', you know rewrite it.
Thank you for your input. I see what you mean regarding inconsistent pair of values. However, I don't think it is redundancy since both the player.id and player.team_id together form the primary key of the players. This was a strange decision I made and I might change it, but it allowed the player.id to be the same as the jersey number of the player. 
&gt; However, I don't think it is redundancy since both the player.id and player.team_id together form the primary key of the players Yeah I'm not clear why you've done that. I'm actually a fan of compounded keys in some contexts but I don't think it makes sense here. &gt; it allowed the player.id to be the same as the jersey number of the player. I can see the attraction of something like this but I'd be cautious about this approach since: 1. You're still calling the Player column "id" which strongly suggests a meaningless key. If it's the shirt number, name it accordingly. 2. Your Player.id column is an auto_incrementing column which is even more indicative of being a meaningless key. 3. Is it a "hard" rule that people can't do weird things with their shirt number? If it is then fine, but I'd worry that a team might field a player with a shirt of "11X" or something stupid like that or worse still reuse shirt numbers for some reason. I suspect FIFA rules prohibit both these things, but I'd double check that. Although I am fond of natural / meaningful keys I tend to worry when my primary key is under someone elses control as they might do all sorts of crazy things in the future. In this context I'd give the table a meaningless key (i.e. the id) and then add in a shirt number column separately. Other comments/questions: - You might also want more granularity when it comes to player position(s) - e.g. central midfielder, left-back, etc. - Your matches table has a column called "date" (I don't like that) with a datatype of integer. Why? Are these unix time stamps? - Similarly, birthdate (better name) has a datatype of integer. - You are slightly inconsistent with your column references. When referring to your player.id column elsewhere you name it player_id (fair enough) but your venue.id column is just referred to as venue. - How do you store a second yellow card? A separate entry for the yellow and the red?
Thank you very much for your feedback. I will definitely add a column for jersey number and make the player.id unique within the player table. What you mentioned concerning some external factor being in control of my keys is what really got to me. On a side note, in Fifa World Cup the player jersey are limited to being a number between 1 and 23 included, this is different from national leagues where I've seen jersey numbers from 0 to 99. When players are signed up to the world cup by the qualified country they have to be signed up as either GK, DF, MF, FW (With a limitation of 3 GKs per team). To me it just appeared as a easy solution to just use those positions. I might consider adding more granularity to the positions. Yes, I've always treated dates as timestamps and I find it quite easy to work with. I agree that "date" is not a good name, i might change it to match_date or something. Thx for locating the inconsistency in the naming of columns, I'll make sure it gets fixed. If a player receives two yellow and then a red card there will be 3 rows in the card table. Two with "yellow" and one with "red". Again, thank you very much for good feedback =)
You will probably want to create a third dable instead of overwriting table 2. In this example, everything is put into a table 3 (which you have to define). After you are satisified with the results, you can can delete table 2. INSERT INTO table3 SELECT Table2.customer AS customer, Table1.year AS year, Table1.month AS month, Table1.day AS day, Table2.amount AS amount Table1.price AS price, Table2.amount AS "amount*price" FROM table1 AS t1 INNER JOIN table2 as t2 ON t1.year = t2.year AND t1.month = t2.month AND at1.day = t2.day 
It is like it asks itself "How nested can I possibly make this?". Regardless of query performance I end up re-writing them anyways so I can understand them. :)
The Inline select subquery can only return a SINGLE value. The UNION ALL has no purpose. Also why is there a comma before the FROM?
You don't get much lighter than SQL*Plus. It's included as part of the database installation or you can download the client from Oracle's site. 
SQL Tools (sqltools.net) is a great alternative if you cant get your hands on a copy of TOAD.
thanks i'll check this out
DBVisualizer is a good tool that offers a lite version. You can try that one out for simple query writing and debugging. I use the premium version at work almost daily. 
You can disable all the plugins you want on Oracle SQL Developer to "lighten" it up. I think by default it has a few enabled that most people probably will never use. Disabling those will free up memory.
SQL STATEMENT TO FIX THIS?
I also really like DBVis (uses JDBC). I have to query several Oracle, MySQL, and SQL Server databases. The free version only lets you have a single query window open. Once you get a Pro license, you can have as many as you want and it saves them until you specifically close the tab. It's great for projects that take a couple days to finalize your SQL.
He's asking for one that works with Oracle. 
I was in Oracle and tried to do something like this, but it didn't work. Baseline that works: select dummy from dual where dummy='X' results: DUMMY ----- X Derived column: select dummy as testcol from dual where testcol='X' Error starting at line 93 in command: select dummy as testcol from dual where testcol='X' Error at Command Line:95 Column:7 Error report: SQL Error: ORA-00904: "TESTCOL": invalid identifier 00904. 00000 - "%s: invalid identifier" *Cause: *Action: 
SELECT FedTracker.CEC, FedTracker.CourseID, ISNULL(AllReports.EnrollmentStatus, 'Not Started') as EnrollmentStatus, AllReports.CompletionDate FROM FedTracker LEFT JOIN AllReports ON FedTracker.CEC = AllReports.CEC;
You can use a case statement or the IsNull that other people have posted CASE WHEN AllReports.EnrollmentStatus is null then "Not Started" WHEN AllReports.EnrollmentStatus = '' then "Not Started" ELSE AllReports.EnrollmentStatus END as CaseOutputBrah
Okay basically * Table One has the UserID * Table Two has the userID and many courses and completions for people inside of the course * Query takes the people i want from Table One (UserID) and matches them to people in Table Two, it pulls completion and makes a new Query with the UserID and Completion. There is people who will be in Table One but not Table Two, im unable to set the set a default anywhere :( If i set a default on Table Twos Completion, it wont transfer. Im a bit stuck!
As suggested elsewhere you can use ISNULL(value, replaceIfNull) or you can use **CASE** similar to below that can be done more generically and allows for additional manipulation were required. SELECT FedTracker.CEC, FedTracker.CourseID, CASE WHEN AllReports.EnrollmentStatus IS NULL THEN 'Not Started' WHEN AllReports.EnrollmentStatus = '' THEN 'Unknown Status' WHEN AllReports.EnrollmentStatus = 'W' THEN 'Withdrawn' /* Additional cases go here */ ELSE AllReports.EnrollmentStatus END, AllReports.CompletionDate FROM FedTracker LEFT JOIN AllReports ON FedTracker.CEC = AllReports.CEC; 
its inside of MSACCESS, i will see what i can edit
 SELECT FedTracker.CEC , FedTracker.CourseID , CASE WHEN AllReports.EnrollmentStatus is null then "Not Started" WHEN AllReports.EnrollmentStatus = '' then "Not Started" ELSE AllReports.EnrollmentStatus END as CaseOutputBrah , AllReports.CompletionDate FROM FedTracker LEFT JOIN AllReports ON FedTracker.CEC = AllReports.CEC;
These should be two separate queries with the current table design I don't know if what you want is possible, at least not easily in Access. &gt;If possible you should redesign the structure to be similar to this. TABLE Person(pk1 [unique], firstname, lastname, email) TABLE Friends(p_pk1, f_pk1) &gt; The result would be something like this for the above Person : (1, 'Alester', 'A', Alester@lam.com), (2, 'Jude', 'B', Alester@lam.com), (3, 'Carl', 'C', Alester@lam.com), (4, 'Jones', 'J', Alester@lam.com) Friend : (1,2), (1,3), (1,4) &gt; Now to get the information above you can do the following if you can guarantee the friend to be unique pairs SELECT a.fname, a.lname, a.em FROM (SELECT f.firstname as fname, f.lastname as lname, f.email as em FROM Person as p inner join Friend as i on p.pk1 = i.p_pk1 inner join Person as f on i.f_pk1 = f.p_pk1 UNION ALL SELECT p.firstname as fname, p.lastname as lname, p.email as em FROM Person as p inner join Friend as i on p.pk1 = i.f_pk1 inner join Person as f on i.p_pk1 = f.p_pk1) as a WHERE a.em = 'bob@bob.bob' &gt; This design also has the added benefit of drastically reducing overlap in information; Alester's information is only stored once instead of three times. This is a good practice to get into when doing this. Strings are acceptable on the small scale but if you scaled this up to ten million friend pairs(lol access) it wouldn't be able handle it.
-*Redacted because I'm a derp*- And apologies.
&gt;One common approach is to simply store the id of each person's boss. Although this works for simple cases, it requires multiple queries to get all the parents or children of any node. False. http://www.postgresql.org/docs/8.4/static/queries-with.html
All the up votes in the world for my friend thank you
Coldchaos 1 point 54 minutes ago* (1|0) NakedLoki 1 point 59 minutes ago (1|0) He was first though and you're both right.
[No hard feelings bro.](http://i.minus.com/iTBTKBqQXbkqk.gif)
Could also create a view using basically the same as above: CREATE VIEW Bro_View AS --Select statement from above. 
You can do something similar to the above, instead of using the Person(pk) can you use e-mails to do it, query should be pretty much the same. Basically would use the email in place of the key. Edit - Table format: Person : ('Alester', 'A', Alester@lam.com), ('Jude', 'B', 'Alester@lam.com'), ('Carl', 'C', 'Alester@lam.com'), ('Jones', 'J', 'Alester@lam.com') Friend : ('Alester@lam.com','carl@lam.com'), ('Alester@lam.com','jones@lam.com'), ('Alester@lam.com','jude@lam.com')
access eh? Does this work? IIF(IsNull(AllReports.EnrollmentStatus),"Nothing replace text",AllReports.EnrollmentStatus) as EnrollmentStatus
In Access you can also use a IIF statement. iif(expression, do this if true, do this if false) iif(AllReports.EnrollmentStatus is null, 'Not Started', AllReports.EnrollmentStatus) as EnrollmentStatus
Like this? SELECT (M.First_Name + " " + M.Last_Name) AS Member ,(M.First_Name) AS Name ,F.e_mail FROM Members M JOIN ( SELECT Friend_E_Mail e_mail FROM Friends WHERE My_E_Mail = ? and Friend_E_Mail &lt;&gt; ? UNION ALL SELECT My_E_Mail e_mail FROM Friends WHERE Friend_E_Mail = ?and My_E_Mail &lt;&gt; ?) F ON M.First_Name = Left(F.e_mail, CHARINDEX(F.e_mail, '@')) You really should have a better join field between member and their friends list. Member = [ID, First_Name, Last_Name, E_Mail] Friend = [MemberID, FriendID] Then you can simply do this and not worry about cross joins or string parsing: From Member M Join Friend F ON M.ID = F.MemberID Join Member FM ON F.FriendID = FM.ID
#
So I take it you got it? The iif statement is the ideal choice considering that it is coming from access.
Its not hw
I was able to make a new column to perform what i needed automatically Completion: IIf(IsNull([EnrollmentStatus]),"Not Started",[AllReports].[EnrollmentStatus]) I was unable to succesfully make the EnrollmentStatus have the default, so i made a new column which checks EnrollmentStatus and feeds me "Notstarted" if blank :D
#
:-( its a personal work project. currently i use 15+ excels . i think access can help me lol. is,it that ancient! :-( 
im sorry i don't like reposing but im desperate for an answer everything i try keep s failing like so in the current structure i have in the post dose not work. CODE///// SELECT Members.First_Name + ' ' + Members.Last_Name AS Member, iif(isNull(Friends.My_E_Mail) , Friends.My_E_Mail, Friends.Friend_E_Mail) AS E_Mail, Members.First_Name AS Name FROM ((Members LEFT OUTER JOIN Friends ON Members.E_Mail = Friends.My_E_Mail AND Friends.Friend_E_Mail = 'jude@pam.com') LEFT OUTER JOIN Friends Friends_1 ON Members.E_Mail = Friends.Friend_E_Mail AND Friends.My_E_Mail = 'jude@pam.com') //////CODE i keep getting "JOIN OPERATION NOT SUPPORTED"
Go to your other thread and let me know if my suggestion works. Coldchaos only suggested how to make it work if your data was redesigned to make sense.
Yeah, it's true, you can do recursive CTEs. I glossed over them because I was trying to describe the naive approach so that people had a basis for getting started. I'll add a link to the 9.2 docs on recursive CTEs in the article.
now i have this code from THLcanthrope ///code SELECT fname, lname, em FROM (SELECT f.firstname AS fname, f.lastname AS lname, f.email AS em FROM ((Members p INNER JOIN Friends i ON p.pk1 = i.p_pk1) INNER JOIN Members f ON i.f_pk1 = f.p_pk1) UNION ALL SELECT p.firstname AS fname, p.lastname AS lname, p.email AS em FROM ((Members p INNER JOIN Friends i ON p.pk1 = i.f_pk1) INNER JOIN Members f ON i.p_pk1 = f.p_pk1)) a WHERE (em = 'jude@pam.com') //code dose not work 
Reddit uses 4 spaces to begin a line for code/tabbing, after a return character: SELECT both.fname, both.lname, both.em FROM (SELECT f.firstname AS fname, f.lastname AS lname, f.email AS em FROM ((Members p INNER JOIN Friends i ON p.pk1 = i.p_pk1) INNER JOIN Members f ON i.f_pk1 = f.p_pk1) UNION ALL SELECT p.firstname AS fname, p.lastname AS lname, p.email AS em FROM ((Members p INNER JOIN Friends i ON p.pk1 = i.f_pk1) INNER JOIN Members f ON i.p_pk1 = f.p_pk1)) AS both WHERE em = 'jude@pam.com' &gt;Also not sure why that would, might need to change the ' to " for the string, pretty sure Access uses those; haven't really used it in a while.
thanks now any thoughts on this ?
I don't see how this is too complex even by 2000 standards. I'm just using your email UNION subquery and joining it to Member. I put some "As"es in there, but you're going to have to debug it yourself. SELECT (M.First_Name + " " + M.Last_Name) AS Member ,(M.First_Name) AS Name ,F.e_mail FROM Members As M JOIN ( SELECT Friend_E_Mail As e_mail FROM Friends WHERE My_E_Mail = ? and Friend_E_Mail &lt;&gt; ? UNION ALL SELECT My_E_Mail as e_mail FROM Friends WHERE Friend_E_Mail = ?and My_E_Mail &lt;&gt; ?) as F ON M.First_Name = Left(F.e_mail, CHARINDEX(F.e_mail, '@')) 
This does basically the same thing with less code. Case when isnull(AllReports.EnrollmentStatus, '') = '' then 'Not Started' else AllReports.EnrollmentStatus end as EnrollmentStatus
What if the address is "123 32nd St". Edit: Because I sounded like an asshole in my original reply. 
this does the same thing with even less code -- COALESCE(NULLIF(AllReports.EnrollmentStatus,''),'Not Started') AS EnrollmentStatus 
#
I dont understand why your example doesnt return Jim Jones as the sole cust_contact result either 
I don't know what the data looks like so I can only speculate. It is only stipulating that c2.cust_contact must equal 'Jim Jones'. That means that there are some cases where the cust_name between c1 and c2 are the same but the cust_contact is not necessarily 'Jim Jones'. If we had this: Cust_ud||Cust_Name||Cust_contact 1, 'joe', 'Jim Jones' 2, 'joe', 'Bob Smith' 3, 'steve', 'nobody' This would return records 1 and 2. The c2 table would return record 1 but when it is "joined" to c1 the cust_name 'joe' would match on records 1 and 2. Since we do not require that c1.cust_contact = 'Jim Jones' it doesn't care that 'Bob Smith is the cust_contact for record 2. Make sense?
Show manager for each employee is a perfect example of a self join. Your book really should be using this instead of the one you posted. The logic is: You need to get the name and address of a manager from the customers table... resulting from a join you did from a select statement you did for employees on the customers table. Without a self join, how would the SQL engine know whether you wanted the name and address of the manager or the employees?
Self joins are easier to understand when you think of the examples such as a person who is maried to another person. This will required a unary 1-1 relationship (for simplicity) So we would need data from both tables to get records on a person spouce SELECT Husband.firstname, Wife.firstname, Husband.lastname FROM Person Hustband INNER JOIN Person Wife ON Husband.spouceID = Wife.personID WHERE Hustband.fullName = 'Jim Jones' Maybe I am misunderstanding your example, but this is where I typically see self-relationships. 
Does 'Jim Jones ' really contain a space after jones? I copied and pasted from your query.
Okay, first off, if your book isn't using ANSI joins, you should probably be worried about the quality of the text. Thriven had a good example - formatted below for sanity: SELECT c1.Cust_ud, c1.cust_name, c1.cust_contact FROM customers AS c1 INNER JOIN customers AS c2 ON c1.cust_name = c2.cust_name WHERE c2.cust_contact = 'Jim Jones' That INNER JOIN part is useful because it has the criteria for the join right there next to the join, rather than jumbled into the WHERE clause with the other criteria (here it's only the "Jim Jones" thing, but if you've got 7 JOINs and 8 other criteria in your WHERE clause, you want the join criteria with the JOINs, otherwise you're going to have a bad time when you have to revisit the query). Now, with your query, you're getting (people)(c1) who have the same name as the (people who have "Jim Jones" as a contact)(c2), even if they themselves do NOT, which is why you're getting records that don't have Jim Jones as a contact. 
Was the update inside a transaction? Did the transaction get committed or rolled back?
BTW I HAVE THE SOLUTION! i cant believe this im a novice in college and their making me do queries like this!!!? Thank you for all your help SELECT Friends_2.Friend_E_Mail AS email, LEFT (email, INSTR(email, '@') - 1) AS Member, LEFT (email, INSTR(email, '@') - 1) AS Name FROM (Members INNER JOIN Friends Friends_2 ON Members.E_Mail = Friends_2.My_E_Mail) WHERE (Friends_2.My_E_Mail = ?) AND (Friends_2.Friend_E_Mail &lt;&gt; ?) UNION ALL SELECT Friends_2.My_E_Mail AS email, LEFT (email, INSTR(email, '@') - 1) AS Member, LEFT (email, INSTR(email, '@') - 1) AS Name FROM (Members Members_1 INNER JOIN Friends Friends_2 ON Members_1.E_Mail = Friends_2.My_E_Mail) WHERE (Friends_2.Friend_E_Mail = ?) AND (Friends_2.My_E_Mail &lt;&gt; ?)
For example, I use a self join when I have an order number, and I want to see all orders on that account (customer ID is also stored in the same table as a foreign key to the customer table). select o2.* from orders o1, orders o2 where o1.ordernumber = 123456 and o1.cust_id = o2.cust_id; This often gets combined into larger queries where I have an order number on an account and I want to look at a bunch of other stuff without jumping thru the customer table, often because the customer table has nothing relevant to my interests at that time. (edit for formatting my query)
What happens if you run DBCC OPENTRAN
imo any time you need a self join, just apply a conditional instead( either WHERE or HAVING depending on the case)...self joins are silly and they make logic seem unnecessarily complex.
Sounds like the transaction is still open / running. A commit doesn't commit all transactions, just the current one. So : BEGIN TRANSACTION BEGIN TRANSACTION UPDATE foobar SET val = 1 COMMIT SELECT @@TRANCOUNT -- Returns "1" If I try and query the foobar table from another session then the query will sit and wait (and wait). 
Glad you got something working, sometimes being thrown into the fire is the best way to learn if you have a little direction. :)
Not entirely sure, but it sounds like the row might be locked or the update was/is blocked. &gt;Try the following and see if you can see your update in there. SELECT cmd AS RunningProcess, cpu, s.* FROM sys.sysprocesses AS s WHERE --Process status blocked &lt;&gt; 0 AND --CPU time is long running s.cpu &gt; 1000 &gt;Also it might be worth trying to query the table with a condition to exclude that row and see if it works. SELECT pk1, etc, etc1, etc2 FROM dbo.your_table WHERE pk1 &lt;&gt; key_of_record_updated 
Few points: * If you ever aren't sure about trying something, setup some [temp tables](http://decipherinfosys.wordpress.com/2007/05/04/temporary-tables-ms-sql-server/) or use a service like [SQL Fiddle](http://sqlfiddle.com/) * This should really be performed in an application not on the database side; running this on a huge table would *very likely* bring the database servers to its knees. String operations are better left to the far better optimized coding languages for all parties involved. * A large chunk of the T-SQL could be converted to C# or JAVA in a matter of hours if you wanted to be lazy about it. * This T-SQL assumes that the information is always in the same format; which brings to mind the adage: 'Applications programming is a race between software engineers, who strive to produce idiot-proof programs, and the universe which strives to produce bigger idiots. So far the Universe is winning.' - Rick Cook
Those can't return the same. [Demorgan's Laws](http://en.wikipedia.org/wiki/De_Morgan's_laws) NOT (A OR B) = NOT A AND NOT B NOT (A AND B) = NOT A OR NOT B . Also an empty string "" and 0 are not NULL. This should be the correct set of conditions to return if any of the three are non NULL (it will only skip when all 3 are NULL). WHERE cl1 IS NOT NULL OR cl2 IS NOT NULL OR cl3 IS NOT NULL
Thank you THL, I appreciate the input and I will use what you say at work. I actually got my SQL code in one of my Excel macros to give me the data i want but i don't know why. The one i have at work I used 0.00 instead of IS NOT NULL. I will have to try out the IS NOT NULL and see what happens. The below part had me thinking for a bit. I dunno if the NOT part of the code changes how AND and OR work but I'm guessing it does? Sorry i'm fairly new at SQL so these things kind of confuse me. NOT (A OR B) = NOT A AND NOT B NOT (A AND B) = NOT A OR NOT B I will have to test in access again. from the above then there is something wrong with the results of my access code and the results i got at work with AS400 are correct. Cheers 
Access is looked down upon. It's the furthest from an enterprise RDBMS you can get and it tends to perform badly and fail in unexpected ways. MySQL works well. I really like SQL Server. Oracle and Postgresql are other strong ones. For the most part SQL is standardized. [The sections documented here](http://www.w3schools.com/SQl/default.asp) should work in every database tool. Then each of the databases have their own helper functions. Once you learn one set you can easily Google to find the equivalent in another database.
SQLite is very flexible on its storage and will let you store numbers in text fields and vice versa. The main types to store are text, Int, real (for any floating point numbers). There's no date fields but a real (floating point) will do. If you know C you could build an exe that includes the SQLite code (I've done it for Windows [here](http://cplus.about.com/od/howtodothingsin1/a/tutorial-three-sqlite-insert-and-c.htm). It would only need a couple of lines changed for Linux.
I'm still learning PHP and Javascript, and I know Bash but people who are good at Bash would laugh at me. lol
Well, the first suggestion is that your tables are poorly built. If you have the ability to change how this data is stored, spend some time googling for normalization techniques. That said, I'm going to assume the table structure is fixed, and you just have to deal with it as is. I've been there. Let's try a self-join: Select t1.DocumentID, t2.DcoumentField, t2.Data, t2.ImageType From DocumentTable t1 inner join DocumentTable t2 on (t1.DocumentID = t2.DocumentID and t2.DocumentField = 'Date of Service') Where t1.Patient = 'Smith' Order By t1.DocumentID; That should give you what you asked for. If there were other requirements, I might go with a Group By clause instead of the self join.
Thanks! Perhaps more details would help make this clearer. I'm joining multiple tables together to get my table I drew above. Here is my current code that gives me my table: SELECT index_value.person_id as person, index_value.value as index_date_of_service, doc_field_mstr.index_type_id as index_id, document.document_id, doc_type_mstr.description as doc_type, Substring (CONVERT(CHAR(8), document.create_timestamp, 112), 5, 2) + '/' + Substring (CONVERT(CHAR(8), document.create_timestamp, 112), 7, 2) + '/' + Substring (CONVERT(CHAR(8), document.create_timestamp, 112), 3, 2) as scan_date, page.location+page.sub_location+page.file_name as filelocation FROM doc_type_mstr INNER JOIN document ON doc_type_mstr.doc_type_id = document.doc_type_id INNER JOIN index_value ON index_value.document_id = document.document_id INNER JOIN page ON page.document_id = document.document_id INNER JOIN doc_field_mstr ON doc_field_mstr.doc_field_id = index_value.doc_field_id This table gives me all the information I need, but the limiting problem arises from the index_value table. That table has null data for some of the person_id data. The doc_field_id field lists what type of field it is, ie date of service, and links to the result in index_value.value. This links to the document ID for every field, but the index_value.person_id only lists values for some of the cases and lists NULL for the others. I'd like my final table to list ONLY the values that have date of service (which is technically listed as index_value.doc_field_id = '68033687-49DC-4DA2-BC8A-C2D3B8B58ED1') but then I have a blank person_id field. Is there a way to tune that up to make it list it with a self join? I tried adding this line but it didn't work as I was hoping: INNER JOIN index_value iv2 ON (iv2.document_id = index_value.document_id and iv2.doc_field_id = '68033687-49DC-4DA2-BC8A-C2D3B8B58ED1') Thanks!!
This is rather useful. Thanks! 
One thing I have learned and taught people I've mentored in DB design and T-SQL is this: *If you're having a hard time writing a query to return the data you want, it's usually down to poor schema design.*
haha. Sadly, this is a popular medical records system that I cannot change. The system is well built on the user end, but I guess the tables aren't too clean. Nothing I can do, gotta work with what I got!
did you post the schema of the tables you are joining?
YouTube is your best friend. 
Play The Schemaverse :D If you have experience coding in other languages, you will be able to use that experience to compete against others in a SQL battlefield. You will likely need some additional external resources but the game does have a tutorial that will help explain how to get started. Players, myself included, are always happy to help too. http://schemaverse.com 
holy shit. that sounds awesome!
[SQLZoo](http://sqlzoo.net/) is interactive and pretty good.
what is person_temp.person_id? There is no person_temp table so this is won't work. If I change that to index_value then I get an error saying "The correlation name 'index_value' has the same exposed name as table 'index_value'." Also, select unique is not recognized as a command. I changed it to select distinct, is that the same? Thanks for your help! No worries on the time delay :)
To get houseNum, you seem to be looping over the string char by char until you hit a character which isn't a numeric char. Just a few thoughts... 1) Probably best to LTRIM your string before you start looping, especially if the data comes from a third party data feed (and isnt trimmed on insert). 2) What RDBMS are you using? If this is really how you want your code to work, then you may aswell restrict it to the subset of records which begin with a number ie, in MySQL this would involve something like ... WHERE ADDRESS1 REGEXP '^[0-9]+' 3) How are you planning on handling alphanumeric house numbers (like some apartments) ? I suspect some of the addresses might be like '4a', 'some apartment block', 'some city' 4) Personally, as much as I adore SQL, I think I would probably pre-process the file in a scripting language (PHP, maybe bash) before importing it. 
Yes, unique, not distinct... sorry about that. Person_temp is an alias for the subselect. Just like "iv2" in the join you tried.
Dont know why you got downvoted for that, it's a perfectly valid question, all SQL shares a lot of syntax, structures and ways of doing things, but there are also a lot of differences between the flavours.
If it's SQL Server your using, then one of the best ways you could pick things up is here - http://www.sqlservercentral.com/stairway/ it takes you from complete basics all the way up. 
WHAT IS THIS WIZARDRY??? So much for me getting any code written today.
Thanks! I hope it helps :) To say the game has a bit of a learning curve is an understatement but that's most of the fun. There is an IRC channel (#schemaverse) on freenode if you want some realtime help.
You mean, writing double the amount of code but on something completely not work related... At least it LOOKS like work
Not exactly sure what result you're wanting, but the way the query is currently structured, the wins, loss, and draws fields will return the same data for all records. If that's what you want, you can just declare some variables and set them to the calculated values and then select those variables. DECLARE @wins INT, @loss INT, @draws INT SELECT @wins = SUM(CASE WHEN result ='win' THEN 1 ELSE 0 END) ,@loss = SUM(CASE WHEN result ='loss' THEN 1 ELSE 0 END) ,@draws = SUM(CASE WHEN result ='draws' THEN 1 ELSE 0 END) FROM wars SELECT *,@wins,@loss,@draws FROM wars If you're trying to get the number of wins, loss, draws grouped by a specific field, the query below should work. SELECT "named Fields", SUM(CASE WHEN result ='win' THEN 1 ELSE 0 END) as wins, SUM(CASE WHEN result ='loss' THEN 1 ELSE 0 END) as loss,SUM(CASE WHEN result ='draws' THEN 1 ELSE 0 END) as draws FROM wars GROUP BY "named fields" ORDER BY dateAdded DESC
How and where you run your SQL query/script will depends on what SQL you are using. I use Microsoft SQL Server, so I use the SQL Server Management Studios (SSMS) to connect to the server and run my queries. Are you trying to SQL from a custom program? Connect from Excel?
Yeah, I guess it's actually technically YQL (Yahoo's version of SQL), not SQL. I want to pull fantasy sports data from their database, however it sounds like I need some platform to run it off of.
Found a blog post on it. [Pulling YQL data into excel](http://www.jpsoftwaretech.com/pulling-yql-data-into-excel/)
It makes no sense to select *, alongside aggregate functions, without using a GROUP BY. MySQL will not stop you trying, but its not valid and the results are unpredictable. I'm going to assume you want one row per user.. select userid, count(CASE WHEN result='win' THEN 1 ELSE NULL END) as wins, count(CASE WHEN result='loss' THEN 1 ELSE NULL END) as loss, count(CASE WHEN result='draw' THEN 1 ELSE NULL END) as draws from wars GROUP BY userid LIMIT :start, :limit
I've never used LogiAnalytics so I can't be certain why you're getting that error. If this is supposed to return a single record, try putting SUM(a.Paid)/SUM(b.owing). Also might try to replace the inner join with a comma and put a where clause "WHERE a.de_cell_extension = b.de_cell_extension".
No. Your "pretty" query is ugly and makes no sense. When you are doing multiple inline selects against the same table it's time to consider using the JOIN. As far as wars querying itself for counts, you just need a CountIf. If your DB doesn't have it, you can fake it with SUM. SELECT COUNTRYID, SUM(CASE WHEN result='win' THEN 1 ELSE 0 END) as wins, SUM(CASE WHEN result='lost' THEN 1 ELSE 0 END) as loss, SUM(CASE WHEN result='draw' THEN 1 ELSE 0 END) as draws FROM wars GROUP BY COUNTRYID
Try this. SELECT a.de_cell_extension ,(a.paid / b.owing) AS Quotient FROM (SELECT d00_collect.debtor.de_cell_extension, Sum(d00_collect.de_transaction.tr_to_agency) AS Paid FROM d00_collect.debtor INNER JOIN d00_collect.de_transaction ON d00_collect.debtor.debtor_rowid = d00_collect.de_transaction.debtor_rowid WHERE d00_collect.debtor.de_cell_extension &lt;&gt; 'TEST' AND d00_collect.de_transaction.tr_type &lt;&gt; '196' AND d00_collect.de_transaction.tr_type &lt;&gt; '301' AND d00_collect.de_transaction.tr_type &lt;&gt; '499' GROUP BY d00_collect.debtor.de_cell_extension) a, (SELECT d00_collect.debtor.de_cell_extension, Sum(d00_collect.debtor.de_principal + d00_collect.debtor.de_interest + d00_collect.debtor.de_misc) AS Owing FROM d00_collect.debtor WHERE d00_collect.debtor.de_principal &lt;&gt; 0 GROUP BY d00_collect.debtor.de_cell_extension) b WHERE a.de_cell_extension = b.de_cell_extension
 SELECT a.de_cell_extension , a.Paid / b.Owing AS quotient FROM ( SELECT d.de_cell_extension , SUM(t.tr_to_agency) As Paid FROM d00_collect.debtor AS d INNER JOIN d00_collect.de_transaction AS t ON t.debtor_rowid = d.debtor_rowid AND t.tr_type &lt;&gt; '196' AND t.tr_type &lt;&gt; '301' AND t.tr_type &lt;&gt; '499' WHERE d.de_cell_extension &lt;&gt; 'TEST' GROUP BY d.de_cell_extension) AS a INNER JOIN ( SELECT d.de_cell_extension , SUM(d.de_principal + d.de_interest + d.de_misc) As Owing FROM d00_collect.debtor WHERE d.de_principal &lt;&gt; 0 GROUP BY d.de_cell_extension) AS b ON b.de_cell_extension = a.de_cell_extension any chance you could have owing but not paid?
A great big bushy beard ;-{&gt;
Yes, I could and will have owing but not paid.
Firstly, I don't think that query does what you think it does; secondly it's definitely not efficient/portable. Something like this should work for you to get the counts for all participants, assuming there is a column for that also. &gt;Edit - Apparently some people answered this while I was on lunch and had the tab open. &gt;Agree with THLycanthrope 100%, that query is a frankenstein. SELECT participant, SUM(CASE WHEN result='win' THEN 1 ELSE 0 END) as wins, SUM(CASE WHEN result='lost' THEN 1 ELSE 0 END) as losses, SUM(CASE WHEN result='draws' THEN 1 ELSE 0 END) as draws, FROM wars GROUP BY participant ORDER BY dateAdded DESC 
in that case you need to use owing as the left table, paid as the right table, with a LEFT OUTER JOIN and a COALESCE SELECT a.de_cell_extension , COALESCE(a.Paid,0) / b.Owing AS quotient FROM ( SELECT d.de_cell_extension , SUM(d.de_principal + d.de_interest + d.de_misc) As Owing FROM d00_collect.debtor WHERE d.de_principal &lt;&gt; 0 GROUP BY d.de_cell_extension) AS b LEFT OUTER JOIN ( SELECT d.de_cell_extension , SUM(t.tr_to_agency) As Paid FROM d00_collect.debtor AS d INNER JOIN d00_collect.de_transaction AS t ON t.debtor_rowid = d.debtor_rowid AND t.tr_type &lt;&gt; '196' AND t.tr_type &lt;&gt; '301' AND t.tr_type &lt;&gt; '499' WHERE d.de_cell_extension &lt;&gt; 'TEST' GROUP BY d.de_cell_extension) AS a ON a.de_cell_extension = b.de_cell_extension
[Upboat for you.](http://i.qkme.me/355zwt.jpg)
So is GET just something you can do from an HTML document?
GET is just a general term for GETting some data from the web (as opposed to POST.) Can you do it with just with HTML? no, I don't believe so. You would need some type of application layer to pull that data in. Even if it was from within your page using something like php or javascript. Which could be coded into the .html file, but of course is not html. Here's an example in javascript: http://developer.yahoo.com/yql/guide/yql-code-examples.html#yql_javascript Also keep in mind the data you'll be getting is not a standard MSSQL data output type like .csv, it will be XML, so you'll need to parse that as well. If you copy and paste the original query I sent you into a web brower address bar it will return the data so you can have a look: http://query.yahooapis.com/v1/public/yql?q=select * from geo.places where text="sunnyvale, ca" 
Oh, here's a great tutorial for using this type of data aggregation method in Python if you want to process it locally: http://www.codecademy.com/courses/python-intermediate-en-6zbLp?curriculum_id=50ecbb9b71204640240001bf Plus, it has cats!
I am also really interested in getting started. If I download something like Toad (for PL/SQL learning purposes) is their a public database I can attach to?
Look up "select into". That particular query solution will get you where you need to be.
Yeah, trying to duplicate the values of 5407 for all the other IDs, but I don't know how to select them all. EDIT: The ProductID is a UID in another table, so they are linked which is why I need to select all ProductID's.
As a fellow "DB2 for i"/System i/iSeries/AS400 user, you question indicates that the fields are probably not null capable. Many of these legacy programs and files will be defaulting to blanks/empty string for alpha fields and 0 for numeric fields. This is probably why you will see different behavior between SQL directly on your AS400 and the test database in Access. In case you don't have the SQL reference to DB2 here is the latest [version (7.1).] (http://pic.dhe.ibm.com/infocenter/iseries/v7r1m0/index.jsp?topic=%2Fdb2%2Frbafzintro.htm) Poke around there to find whatever version you are running.
I'm just duplicating what's on one product already to all the other products so they have those three values as well. It won't need to be run again but there's over 5,000 products to updare
Well if you need only do it once then you should be able to do the following. Just take the information from 5407's row and put it into the select where appropriate. INSERT INTO ProductsPreferredLocations (ProductID, BranchID, WarehouseID, BinID) SELECT ProductID, '5407's BranchID', '5407's WarehouseID', '5407's BinID' FROM ProductsPreferredLocations WHERE ProductID != 5407 &gt;Obviously replacing the strings with the correct information. Edit- Another additional note, there won't be a way to distinguish the rows after you have done this. 
The visual tools are always so basic it's not worth the trouble. What problems are you having? All you can really do is drop in tables and define the Join columns then set WHERE filters.
I just ran that in our test database and it worked! Thank you so much!
I think mostly I have to get better at writing SQL code, doing it visually is as of now the best way I can make my tables without loosing track. Have settled on using eer modeling in workbench until I can gain some more knowledge and experience. It's all just a hobby so it's not like I have all the time I would like. 
so like sqlfiddle? 
I typically just connect create an ODBC connection in MSAccess and then copy/paste my Excel data into the linked table. Edit: Wrote "OLAP" instead of "ODBC"
You can easily import data from Excel with SQL Management Studio. Right click on the db and go to import. Select Excel as the source, point to your file, and edit your mappings.
This will work but is a bit more complex than what typical use would require. 
Where do I get this SQL Management Studio? Does this come with MS SQL Server 2005/2008? Or do I need to purchase this and install? Thanks. This looks like what we are looking for as our users are a bit under the non technical side. 
Or for universal import into (most) any database, you can save the Excel file as a .csv then import it.
Directly using SQL scripting.. Import/export has too much trouble with data formats.... And it never tells you why
Thanks - I tinkered with it and I got it working as desired! I really appreciate your help. That last self join did it. 
How big and complex is your dataset? As a quick &amp; dirty, you could always fashion a concatenated INSERT INTO statement off the end of each row in excel &amp; just paste into SQL server... But wouldn't recommend for more than a few hundred rows, or with data of any complexity - in this case, an import using SQL Server Mgnt Studio is the way to go...
I wiki'd SSIS. Is it similar to SQL Management Studio? Which is simpler and safer to use for non technical users to import their excel files to an SQL server at the end of their shift?
concatenate() is a function in excell, not sure if it would be good for this, but I've used it to get data into a program in the past.
Sounds like this field should be set up correctly :) Correct the problem at source as well and save yourself some headache :)
Can even do a Wamp install or mysql and play around there if you want.
Here's an article that might get you started: http://office.microsoft.com/en-us/access-help/import-or-link-access-to-sql-server-data-HA010341762.aspx 
perfect, just perfect. Thanks!
I just learnes sql practicing with Oracle SQL developer ober the last couple weeks. I would use oracle or microsoft sql server since there seems to be a lot of material online to help you learn
yes, Download and install SQL Server 2012... in there is Books Online, use it to search out syntax questions. Also if you right click a table and click Edit Top 200 rows, you see the contents of a table. Hit Ctrl 1, Ctrl 2, Ctrl 3, you'll have access to the use the visualization portion of sql queries. You can click and drag a table into the top screen.. develop where clauses in the 2nd screen, see the sql query syntax in the 3rd screen, and see the results in the bottom screen.. I found this part of SQL server to be very helpful learning the language and learning the databases connections between tables, etc. 
be careful.. it doesn't always work. SQL Server tries to make assumptions on data formats and will import sometimes half the data or throws in nulls into fields without letting you know.
[SQL Fiddle](http://sqlfiddle.com/) is a good place to start if you just want to monkey around a bit. It supports varying versions of the following: * MySQL * Oracle * PostGreSQL * SQLite * MSSQL
&gt; I'm still getting a syntax error mind telling us what it said?
don't you need product in your a,b,c and for the joins to work?
select p.event as Event, a.fee as AFEE, b.fee as BFEE, c.fee as CFEE from ( select event from mcm2 union select event from 051913) as P left join (select fee, event from mcm2 where status='passed') as A on p.event=a.event left join (select fee, event from mcm2 where status='bypassed') as B on p.event=b.event left join( select fee, event from 051913) as C on p.event=c.event order by p.event
It looks like it should work, try it like this: SELECT p.event AS PEvent, a.fee AS AFEE, b.fee AS BFEE, c.fee AS CFEE from (SELECT [event] from [mcm2] UNION SELECT [event] from [051913]) as P LEFT JOIN (SELECT fee, [event] FROM [mcm2] WHERE [status]='passed') AS A ON p.[event]=a.[event] LEFT JOIN (SELECT fee, [event] FROM [mcm2] WHERE [status]='bypassed') AS B ON p.[event]=b.[event] LEFT JOIN (SELECT fee, [event] FROM [051913]) AS c ON p.[event]=c.[event] ORDER BY p.[event] Also, what SQL version are you using and what error is it throwing? Edit - If you add a newline and four spaces in front of each line it will appear as code, much easier to read :)
This is what I had in mind when I asked the question. Thanks
Play with SQL Server, get the Adventureworks or Northwind database from Microsoft, then follow along with the numerous tutorials that use these databases. Also try to learn how to model a database in Visio so you can conceptualize the tables and relationships before writing your create table statements when you make your own database. Designing a normalized database is a skill that people need to know in order to understand how a relational database works. In the database design class I TA for there are people who intuitively get it and those that don't. If you get it, it is a lot of fun. 
SQL Developer is a full featured edition of SQL Server (same license features as Data Center edition if I'm not mistaken, although it can only be used on your PC to learn/code against. You couldn't use it in Production). It would be perfect for what you'd like to use it for. SQL Joes to Pros are great books to learn basic SQL skills in. I don't think the books have been updated to teach new features built into SQL 2012, it will still be a great resource for a beginner just learning about SQL. You can purchase the first book in the series on Amazon [here](http://www.amazon.com/Beginning-SQL-Joes-Pros-Beginners/dp/143925317X/ref=sr_1_cc_1?s=aps&amp;ie=UTF8&amp;qid=1369340644&amp;sr=1-1-catcorr&amp;keywords=sql+joes+to+pros)
I really was looking for something like Adventureworks database! Could you maybe direct me to the tutorials you mentioned that use these databases? Thanks for the help :D
Look a little like [Database.Net](http://fishcodelib.com/database.htm) though some of the buttons don't use the same icons.
It's called Database Master 5 by Nucleon Software. You can google a link for it, but a link is also posted in the FAQ for the class. I know because I took that same class.
The screen shot appears to be from a Coursera course, [Introduction to Databases](https://www.coursera.org/course/db), taught online by Stanford University's Jennifer Widom.
This is possibly the worst designed website I have ever used.
No argument there; tool is sound though
I think I shall give it a shot. Always looking for alternates to SSMS and the built in server explorer in VS never really did anything for me.... EDIT: Alright it's pretty nice and lightweight. 
You never visited geocities did you?
I wish database.net had snippets! I filed a feature request for it a couple days ago. 
It will not. Adding Gatorade or hot coffee (even applied gently) will break your SQL cluster though.
Geocities shut down 4 years ago. Also it wasn't meant for companies to sell their products.
In that case I will forgive crappy website design. That's pretty cool that he's diligent like that.
I was going to say Oracle SQL Developer.
well, i use access at work. So it seems silly not to learn it where I can immediately apply it to my daily responsibilities.
Sometimes I need something really quick and lightweight. The only other reason is to try out something else. 
only time i've seen him is when googling questions on sql server, so perhaps he primarily does sql server so perhaps postgres people may not be aware of him?
Depends what you are trying to learn. If you want to learn how to use ANSI compliant databases, then sure this book can be good. If you are trying to get better at using MS Access then no, this book is not something I'd recommend. If you want to get better at SQL I'd get a copy of SQL Server Express Edition (free) or Oracle Express (free) or MySQL (free) and install it on your own computer and learn from any of the books you'll find on ANSI-SQL. If your learning style is better from just reading information and tinkering then this book you mentioned may not be good for you. If you learn by someone giving a specific example of a quasi-real world idea and how to solve it, this book would be good for that it seems. The reason I wouldn't recommend this to get better at MS Access is much of this book is geared toward standard ANSI-SQL. MS Access was loosely based on a loose interpretation of ANSI-89 and ANSI-92 (depending on your version of Access and my (bad) memory) and doesn't support quite a bit of what you'd read in this book. Are you trying to learn more about querying and database design or about using Access with its forms/reports and what not?
That is a bunch of bull. SQL Server is nothing like Access first off. They've added some features into SQL Server over the years to support non-ansi SQL statements from Access to make the jump easier but SQL Server is a much more ANSI style database then Access. As long as you learn ANSI style SQL you can jump between Oracle and SQL Server just fine. If you spend all your time in one or the other learning their proprietary extensions you'll have a bad time moving to another system later. 
Surprisingly these do make things much easier to read and understand. I know the Cartoon Guide to Statistics is rated very well by people and has been in print for years. Don't laugh at the fact it is a cartoon/manga, it is just a way to present the data to make it more interesting...the core concepts are still there and are a great tool for learning.
Not laughing, I own it. It's far from the definitive guide but it's actually not a bad place to start if you are brand new to SQL.
I agree. I wish there were more Cartoon Guides as not everyone is into Manga. Still, it is a great way to introduce people without having walls of text to read through. 
Also, might be a silly question, but have you looked into using defaults on your table? I'm not sure if product 5407 has any significance or if it just happens to be a good representative of the data you want.
I've done this now, but I was just copying all of the data in 5407, and changing the UID (5407) to all the other UIDs!
Yes. Very cool. Keep in mind it's free for non commercial use. Since I use it at the office I forked over the $19 bucks. So cheap I didn't even ask the boss. ;)
What does SSMS Tools pack give you that prompt doesn't? If it's only for the remembering closed tabs, Red Gate Tab Magic (which will be integrated into SQL Prompt eventually) will work just dandy. If it's something else (that I am maybe missing?) speak up. Sometimes I overlook features that could benefit me without thinking about it too hard. I know SSMS Tools pack has snippets (as does sql prompt), etc etc.. so it mostly seems redundant. 
i can already do forms and reports quite well in access. im mostly interested in learning about querying. i can do basic stuff. but get a bit lost when it comes to joins and subqueries in sql. 
I've recommended this book to people many times and have always gotten good feedback. http://shop.oreilly.com/product/9780596520847.do. They have versions for SQL Server and Oracle but I think this one is best as it is non vendor specific.
why would you say this is better than the SQL cookbook out of curioisity? aprreciate the help
The Learning SQL book talks about the background of SQL and why you do things behind the scenes. It doesn't get too deep in theory but good enough to give a basis on it all. Also it covers more topics that will be useful to you like indexing and constraints which the SQL Cookbook doesn't cover. Learning SQL also covers topics like "working with sets" which is the basis for database theory and explains things about why relational SQL works the way it does (like there is no order in sets and what that means for SQL statements). I happen to own both the books (the one you asked about and the one I am recommending) and have been flipping through them while answering. I think for beginners the Learning SQL is just a better all around starter book (or a great refresher for someone who wants to brush up on their skills). Also, the one you asked about is more of a one or two line question followed by a one or two page answer that is mostly the same query in multiple vendors syntax. It poses a question and then a one paragraph answer. “You have a table and want to see values for specific columns rather than for all the columns.” Excerpt From: Molinaro, Anthony. “SQL Cookbook.” O'Reilly Media, 2009-02-09. iBooks. This material may be protected by copyright.
Wait, that's a woman?
I looked around and didn't find one from Microsoft on SQL, but maybe someone else here knows of one. Maybe there's one on someone's blog that you might stumble upon or some YouTube videos. At worst, you can combine what you learn from other sources and have a large dataset to play with after you learn something. 
If you use access at work you can turn your DB into an exportable, whilst not touching the production db. Install the eval version of sql server on something (server, win7, even xp sp3) import it and play, see what works from the access db and what doesn't... MS "Books online" has multiple tutorials. Getting your hand dirty is the best way to learn because the real thing doesn't always go by the book. There are a few syntax differences between T-SQL and PL/SQL but nothing that is insurmountable. Also...Train signal has some very good material for fiddy bucks a month. TLDR: Install evaluation version on something and get your hands dirty.
Yes, and she's a great teacher. She has a couple of minor fault s early on in the course, but she really irons it out towards the end.
I have quite a bit of ssis experience. Basically, you're going to develop a package 'for each format of excel file your users deal with, then map that data to your DB tables. You will need some way for your users to trigger this execution of the package. CMD/PS scripts calling dtexec.exe will work, as well as some interface for running the scripts since they are nontechnical. Honestly, for one dev supporting several non technical business folks, ssis is the ideal way to have most data they generate thrown into a database, as long as they can be relied upon to keep the DTA structured properly. You can also dump out to these excel files if need be.
Got any links for a tutorial or guide about the method you mentioned above? I would like to compare your method against the above mentioned management studio. The simpler it is the better is what I would prefer as the aim is to make things easier for the non techie staff.
Well, its simpler for them, much tougher for you. Regardless, check out http://msdn.microsoft.com/en-us/library/ms169917.aspx
Well, its simpler for them, much tougher for you. Regardless, check out http://msdn.microsoft.com/en-us/library/ms169917.aspx
Perfect! In the long run, what do you think I should focus on? What's commonly used in the industry? Because that's my second criteria. If both are easy for the non techie users then I'll choose the path that will benefit me the most.
Ssis is extremely common in MS enterprise shops that entail using lots of data generated by non-technical users outside of specific custom built applications. Since excel/access is very widespread amongst the business folk, ssis allows them to keep their tools of choice (and possibly scripts and other such ad-hoc business logics) while you build bulletproof business logic in SSIS to keep them as productive as possible in their already existing workflows. It is also used a lot in systems integration and data warehousing for obvious reasons and allows you to build fully fledged file processing frameworks fairly easily and intuitively. A couple of tips however for maintainability and readability of packages: use variables, liberally but not excessively. And create a base workflow template that you can adapt to each data process you need to implement. And keep data tasks to 1 per package, as it reduces complexity when deciphering packages months down the road. A series of single data flow package s that all look the same is far easier to maintain than a bunch of unique little creatures.
Thank you. :-) i really love this subreddit! So much good people! 
I highly recommend the intro to relational databases course that Stanford offers. Check it out at https://class2go.stanford.edu/db/Winter2013/preview/ You should still be able to access all course material including videos and exercises/quizzes.
it depends entirely on the columns and their purpose your example joins both B and C to A it's also possible to join B to A, and then C to B
So if the tables held the following information: Table A: Student ID, Name, Term, Degree Table B: Student ID, Term, Graduation Date Table C: Student ID, Term, GPA, Advisor and I needed to join all the information without dupes, what would that look like? (Thanks in advance!!) edit: for formatting 
is this a homework assignment? what are the primary keys of those tables?
Not familiar with Oracle, but my 3 seconds of research leads me to believe joins are the same as in MS SQL so: i. I assume all students are in Table A, since they might not have an advisor or a grad date yet, but if they exist in the system, they'll prob have a name :) ii. Since Tables B and C might have different subsets than each other (student might have a grad date, but not an advisor and vice versa), it prob makes sense to use A for both: Select distinct a.studentid, a.name, a.term, b.grad_date, c.gpa, c.advisor from table_a as a left join table_b as b on a.stud_id = b.stud_id left join table_c as c on a.stud_id = c.stud_id 
It seems like you may want FROM tableA as a JOIN tableB as b on a.studentID = b.studentID AND a.term = b.term JOIN tableC as c on a.studentID = c.studentID AND a.term = c.term which would be the same as: FROM tableA as a JOIN tableB as b on a.studentID = b.studentID AND a.term = b.term JOIN tableC as c on b.studentID = c.studentID AND b.term = c.term Either one would work since a.studentID is equal to b.studentID (which will then be equal to c.studentID) Same goes for term. I'm not sure what the data looks like, but I'm assuming each table has a row for each term a particular student was enrolled during.
I have the algorithm in PHP, but what I use is the euclidean distance (although I can use other one). What I do, is, for example, get all the common scores from two critics, and return 1 / ( 1 + sqrt ( sum ( (c1-c2)^2 ) ) I mean, I loop for every critic, I sum the difference, apply pow2 and then return 1 / (1 + sqrt ). The sqrt is the distance, and then I apply 1 / 1 + sqrt to inverse, and return 1 if they are idetnical and 0 if they are very different. What I don't know how to do is "the loop and then the distance" with the records, only in one query :) Thank you so much for your answer rjbwork :)
you have an index on the timestamp column, right?
Thanks so much! This is exactly what I hoped to see! A co-worker has a tendency to over complicate his syntax, and I wanted to make sure what I was doing was correct. 
Index the timestamp column, preferably with the clustered index. Since a timestamp is a naturally incrementing field it lends itself well to clustered indexing. Also - why are you doing a select from a select subquery? There doesn't seem to be any reason for it.
1st Put the clustered index on the date field. 2nd Try using a data warehouse style DimDate (and DimTime) table so that any date arithmetic is pre-calculated. When you populate the DimDate table per-calculate any ranges you would likely need. DimDate (date (pk), daystart, dayend, weekstart, weekend, monthstart, monthend, qtrstart, qtrend, etc...) I also like to add a next date and previous date column. Your queries will join using "mydate between DimDate.____start and DimDate._____end" 
Ahh, okay, that is what you mean by euclidean function. I wasn't quite sure. Okay here's a sample peice of code. Obviously you can add your own inner joins to the critics get back to the names of critics instead of their IDs. Use http://www.generatedata.com/ to generate some sample data for your scores table and try this code: SELECT s1.critic_id, s2.critic_id, 1/(1+SQRT(SUM(POWER(s1.score-s2.score,2)))) as EucDist FROM [redditAnswers].[dbo].[Score] s1 inner join [redditAnswers].[dbo].[Score] s2 on s1.critic_id &lt;&gt; s2.critic_id and s1.movie_id = s2.movie_id group by s1.critic_id, s2.critic_id order by EucDist desc
In addition to the indexing on timestamp strategies mentioned here, you can also partition your table using the timestamp column. You can do things like make each month in it's own little partition. EDIT: Check out this article on MSDN http://msdn.microsoft.com/en-us/library/ms190787.aspx
Hi! I've tried Management Studio and it worked like a charm! I just need to learn a bit more about it so I could use it based on my needs. I just have a quick question though and it's one that I could not figure out how to search via google. What if I made a mistake in importing the data, how could I undo what I've imported to my database? The only thing I could think of is to add a date of upload column to my data and just delete them if necessary via SQL. Is there a simpler way via Management Studio Express? Thanks again!
Table Partitioning only with Enterprise. I'd love to use that at our office.. sigh 
you can still manually partition, ie: year2010, 2011, 2012, 2013, and union.
AH I getcha. 
Then you can actually create a view that merges them together with unions for your normal queries, and use the seperate tables when you have a specific timeline.
That's pretty cool.. though if your primary large table(s) aren't already split in some fashion like this.. I guess you'd just make these tables for the sake of querying them(faster?) and then delete them later or are you using some sort of SP or some automation to split your data later? 
Seems like there would be a better way... that's a lot of duplicated data in the DB. Which is generally a RDBMS nono is it not? I think you can create clustered indexes on views. Why not create a view for each year and then a view for the year union? 
That's why, as I mentioned, you should import to a staging table first - so you can make sure everything's kosher before you move it to the real table. If you somehow screw that up, then having a timestamp column like you mentioned might help. When all else fails, restore from a backup. And with transaction log backups you can restore to any point in time. 
Not true. Sql server puts a clustered index on the primary key by default, but this absolutely is not mandatory and in many cases can be a bad idea. 
It's not duplicated. You delete the data from the main table upon creating archive tables and populating from the main table. This allows you to have multiple smaller indexes that are rarely updated on the archival tables. The main table doesn't have to deal with, in my case a 200 million row index, it just grows to maybe 20 million a year then gets move to archive. Then when we need a specific piece of it we can go to those tables. The view for each year does nothing for your partitioning on the main table. Like the guy said earlier, you're manually partitioning by separating data out into multiple tables and then treating the view like a partitioned table through union. Your way may work, but I can't really say. 
Appreciate you trying!
Yeah I haven't dealt with tables of that magnitude. I think our largest it 25M rows right now.I'll have to check. 
Wow, that's great. I will check it. Is it paid or something?
Yeah my bad, I thought he was using MySQL for some reason
FYI. He's added code snippets to the latest version. I just got an email from him about it. Ps I did not downvote you. 
Well he implemented them just because I asked. Maybe it helps I'm paying customer? I think they offer great support given the price.
Mostly true, in the case of duplicates on a clustered, SQL server makes the key unique by adding more bits to it, which can slow down inserts and look ups. Even a lag time of a few seconds can kill write performance, and it only gets worse if different timezones are involved. I worked time and attendance for years, and we always resisted the temptation to do a clustered index on date times, because the hazards outweigh the benefits.
If you have no particular preference, use 2012 Developer edition. Developer edition has all of the features available and 2012 has all of the most recent functionality. 2008 and 2012 are largely the same, so most of your book will be relevant still. And just an FYI, this sub is for the language SQL. This would be better suited to the SQLServer sub. 
You are using joins, implicitly. Inner joins if I'm not mistaken. However, converting to ANSI notation is best, as it makes your query easier to understand. For example: SELECT p.name, b.name brand, t.name type FROM products p JOIN brands b on (b.id = p.id) JOIN types t on (t.id = b.id) Also your original query is wrong, presumably you wanted to join on products.id. 
Use the latest version available to you but don't feel too bad if you can't use 2012. Many of the new features aren't going to be of much interest to you at this point and migrating to a later version in the future won't be too much of a pain.
You're only getting 3 results because your types data only contains 3 types and your joining the type.id column to the brand.id column. Inner Join(or join for shorthand) will only show you data in all tables that matches the ON criteria. 
so what would be a similar query to mine using joins?
I would imagine you'd want some sort of outer join. Perhaps SELECT p.name, b.name AS brand, t.name as type FROM product AS p JOIN brands AS b on b.id = p.id LEFT JOIN types AS t on t.id = b.id; 
Right, because you have 3 types, but you are only referencing type 1 and type 2 from your inserted data (table data).. so the type would be blank for the non typed product. Turns out I had the join criteria wrong anyway. I was using/matching the id for each table rather than the added columns in products. Edit: here's your sqlfiddle mockup with the proper join query. Helps to see the data sometimes.. hah http://sqlfiddle.com/#!2/b09f2/13 
Howdy, first up, as suggested here already, come visit us over on /r/sqlserver - plenty of die-hard SQL Server users available to answer your questions. As for versions, go for 2012 if possible, as it's the bees knees, but if for some reason you want to go lower, try to stick to 2008 R2 at a minimum. At this point in your education, editions likely don't really matter - use Developer; it'll provide all you need, without the constraints of Express. Do be aware that your student licensing almost assuredly does not allow for any sort of commercial implementation; if you're only practicing/learning, there's nothing for you to worry about. However, if you're working on a product that you intend to eventually monetize, evaluate the actual licensing costs before you tie yourself to some feature only available in a particular edition - they are *brutal* for individuals. 
well that's an interesting site, thanks for the tip :D, according to the execution time the join query took 5ms and the AND query took 1ms, i guess i'll stick with AND queries thanks for the help
your timing results could be skewed due to query caching on your DBMS. Also, you may want to try with a non-trivial dataset before you draw conclusions about timing. 
ALTER, like this: ALTER TABLE table_name ALTER COLUMN column_name datatype If it already has incompatible data, you may have to make a new column, UPDATE to copy from one column to the other, then delete the old column.
trane_0 is right, and FWIW I just re-clicked the link at work and your query took 4ms and mine took 1ms. But it's all about caching here.
where column like '%Y%' and column not like '%YY%' and column not like '%Y%Y%' Just a guess
It is going to depend on what kind of Database you have. A quick search found [this](http://stackoverflow.com/questions/287373/how-can-you-find-the-number-of-occurrences-of-a-particular-character-in-a-string) post that should work for SQL Server. Also, [this](http://stackoverflow.com/questions/1860457/how-to-count-instances-of-character-in-sql-column) might help.
It's weird how that second link (from 4 years ago) is exactly the same as OP. Are we doing someone's homework?
thanks for this, it makes it much clearer now, im still not sure if i should change to joins from the style i use
lol ya that's funny. Not me though I'm actually fairly new to SQL. I'm tasked with figuring out an archaic and horribly designed (by my standards) db.
LIKE is not a particularly fast operator. REPLACE is not particularly fast either. A [CHARINDEX](http://msdn.microsoft.com/en-us/library/ms186323.aspx) combo can do the trick. WHERE CHARINDEX('Y', str) &lt;&gt; 0 AND CHARINDEX('Y', str, CHARINDEX('Y', str) + 1) = 0 EDIT: My own bullshit.
If your database supports it, I'd use a regular expression [^Y]*Y[^Y]*
I just Google the real world scenarios as they come up. There's no point knowing how to make a recursive CTE until you need a report that sorts by the company hierarchy and indents and colors each management/employment level.
By using joins you can do left, right, or full joins in a more efficient manner. For example if you wanted to see all brands joined to products, your way would only show any brands that actually have a match. By doing a simple left join you would see all brands even if they have a product or not. You should also note that placement is key as well. Check out this post on stack overflow. http://stackoverflow.com/questions/354070/sql-join-where-clause-vs-on-clause I'm not trying to be a bully but there is a reason that everybody does join on instead of where. If you ever decide to do a job that has any SQL your code will simply be rejected cause its not inline with standards set by senior developers, DBAs, and any IT management. My last reason why you should use joins is if you move over to MS SQL server you gain access to cross joins, cross apply, or outer apply. 
Oh yeah, duh. Good catch.
i just implemented a long query with left joins at work today and im pretty happy with the results, the join gave me more freedom for when a field was empty, with an and clause i couldnt do that, so thanks :) i think i'll change to joins from now on
Everyone I know of that knows sharepoint hates sharepoint. Matter of fact, I've met maybe 2 people that love sharepoint. The overall consensus is hate.
does ? work?
And you got a bunch of messages with the same timestamp. Better hope skype orders by primary key as well, otherwise you might get them back in random order. Also, you've just shown a bunch of jealous teenagers how to spy on their partnets.
Wow, I haven't even thought about reading other's messages. But it's basically always the same: if you are getting hacked / someone have access to your computer, he can do whatever he want, including but not limited to reading your messages. On the other hand, jealous teenagers most probably won't find my article on /r/SQL :) &gt;And you got a bunch of messages with the same timestamp. Indeed. I didn't care about those messages. Might as well deleted them. I just wanted to keep using Skype, with "future messages first" it was unusable. If you can assemble some neat SQL query, that will set real timestamp, please post it!
I don't know if you already have a job as a DBA, but you can always look at reports from your ERP, CRM ect system and try to reverse engineer it. What I also like to do is ask people in finance or marketing if they would like a query they currently don't have. You can of course make any kind of query out of your databases, so try to give them a query in the general direction of your scenarios. You can also just ask here on /r/sql :)
? is for parameters
you just want to remove "ESQ" or do you want to replace it with other characters? Are there other characters in that same field? Also, what system are you in? MS Access? SQL Server? 
1. Yes, just want to remove ESQ. Some of the records will not have it, some will. 2. Yes. It's a name table, filled with lawyers. So I want to change JOE BLOW ESQ to just JOE BLOW 3. SQL Server 2008 R2
 update &lt;tablename&gt; set &lt;FieldName&gt; = replace(&lt;FieldName&gt;,'ESQ',''); That should do it... if i were you.. i would create a temp table. create table temp1 as( select * from &lt;tablename&gt; where rownum &lt; 100 ); and run the update on the temp table... i always do that when im updating records just to make sure nothing crazy happens... once im satisfied it works.. i run it on the main table.
Awesome, thank you so much for your help!
You're right, in SQL Server the wildcard for a single character is an underscore _ Which won't work here anyways. 
UPDATE `table_name` SET `column_name` = REPLACE(`column_name`,'ESQ','');
Oh no you found me on reddit. Time to delete my gonewild posts!
The only thing I would do before running this is make sure that no one has this series of characters as a part of their name. I think in this case you are probably pretty safe. I would maybe do a select first and find where the ESQ is not on the end of the string something like this: SELECT * FROM &lt;tablename&gt; where &lt;fieldname&gt; like '%ESQ%' AND RTRIM(&lt;fieldname&gt;) Not Like '%ESQ' That should return records where the ESQ is somewhere other than the end. If you have none then you are probably safe with shemp5150's query. You could also modify his query above to only replace the ones on the end this way. update &lt;tablename&gt; set &lt;FieldName&gt; = replace(&lt;FieldName&gt;,'ESQ',''); where RTRIM(&lt;fieldname&gt;) Like '%ESQ'
Thanks. I didn't even think about that. 
 SELECT table1.patient_id , table1.patient_name , table1.date_of_birth FROM table1 LEFT OUTER JOIN table2 ON table2.patient_id = table1.patient_id AND table2.document_title = 'Oooh la la' WHERE table2.patient_id IS NULL 
Thank You. I'm running the query now and will see if this accomplishes what I need! :)
So it worked, it grabbed all unique ID's perfectly... Now I need to narrow this down even more and select it where table1.date_of_birth &lt; "number" If I add it after this line: AND table2.document_title = 'Oooh la la' It doesn't appear to work... 
You're wanting items from the result set where date_of_birth &lt; number. Don't add it to the join, add it to the WHERE.
please show the entire query with your addition
Also do a begin transaction and rollback or commit. This way if something isn't right you can just undo the changes before commiting them
Not a problem. Glad I could help. When starting out I like do do left joins and get a fell for how the data looks then convert to inner joins. 
Also since you seem a little new with SQL(no offense) but if you do any updates statements check out begin transaction and commit. Those commands would have saved me hours if I knew about them before my first major update.
I'm working on an internal quoting system atm, i used begin transaction for registering a quote, it starts then it registers in the quote table with the general info and then it registers multiple details rows for each product in the concept table, if any of the concept data is invalid or an sql error happens it throws a rollback if all finishes it throws a commit, this is all in PHP with the PDO class which connects directly with the driver of the database, but im not really sure if i need to rollback if i haven't commited, any thoughts? so far it works smoothly
you messed up the LEFT OUTER JOIN the join is supposed to specify what to **look for** in the right table so therefore, you need to say this -- AND table2.TITLE = 'Colonoscopy Report' you want to look for that specific title then -- and here's where the magic happens -- you test for an **unmatched row** with this -- WHERE table2.ID is NULL the join attempts to find that title, and the IS NULL returns only those rows from table 1 where that title was **not** found, as indicated by the NULL also, you don't need table2.title in the SELECT clause, because you know already it's going to be NULL 
great idea, thanks!
Thanks!!
True enough, thanks!
Thanks!!
Ok, now the records returned look correct! Thank you so much man. :)
Why not use a join?
Thank you! I will give this a shot tomorrow, and will be a legitimate reason for me to Reddit while at work. ;)
&gt; these dates are in columns along with many others what are the datatypes of the date columns?
What database (though it shouldn't matter)? I just tried it in my SQL Server and I get the expected -31 select datediff(d,'14-apr-2013', '14-mar-2013')
Try wrapping your date fields in a conversion just to make sure they're the right dates. select datediff(d,convert(datetime,table1.userdate), convert(datetime,table2.userdate2)) If that fails I'll typically run a select to see what's coming back. So something like this: select convert(datetime,table1.userdate), convert(datetime,table2.userdate2), datediff(d,convert(datetime,table1.userdate), convert(datetime,table2.userdate2))
That doesn't change anything. My date literals are just converted to dates. I'm betting this is user error. Double check your values. Select datediff(d,table1.userdate,table2.userdate2) ,table1.userdate ,table2.userdate2
It works with join. =) Thank you much.
use a right join instead of an inner join and you should get those universities and classes that have no votes. You might want to put a COALESCE or IFNULL function around the v.preference to change the nulls to 0.
Here is my suggestion: select c.id, c.name, u.name, coalesce(SUM(v.preference),0) from votes v right join universities u on (u.id = v.uniID) right join classes c on (c.id = v.classID) group by c.id, c.name, u.name order by SUM(v.preference) DESC Your sample screen shot shows that there are negative in the preference fields, so I'm not sure what kind of sum you will be getting and how you want to treat the null values (or you could leave them as nulls.
My first gold! Thanks so much.
Same results. These numbers are from the UK. I'm wondering if there's some way to set the date format that I don't know about
I believe this is what I was after, searching still returns results that haven't had votes (although there's no university campus listed next to it, but that's how it should be!) and orders correctly by preferences. Thank you!
Appreciate it but unfortunately I can't provide screen shots. 
This should be in /r/SQLServer I'm not sure about the problem. UPDLOCK and READUNCOMMITED should not block. 
The blocking process is in the "sleeping" state, which means it's awaiting a command. Check that with sp_who2 for SPID 76, and use sp_lock 76 to see what other locks it's taken. Note how the lastbatchcompleted of the blocking process finished prior to the blocked process starting. Essentially, it's created a transaction, done a bunch of stuff, including something that used resource 15:72057594355646464, and is waiting for a commit transaction. If you can get that transaction to commit (by getting the user to hit the save button, or whatever you need to do in Dynamics), the blocking should be resolved. Worst case, you can kill the spid, but that will rollback the transaction, which is rarely desirable.
Don't group by the date.
basics of database sql commands practice, practice and practice maintain running notes while practicing
A wee follow up - this morning I was mucking about trying to set my query up as a stored proc (though seeing as I pass in a table name, I have to do it where you build up the SQL query into a string and then execute it, meh), and I happened upon a way to improve the query as a whole. Basically what we discussed above was applicable to just part of my query - I had a UNION ALL with another nearly identical bit of syntax. The top part (with your help) queries where "Referrer" (which you put in as "URL") had a slash present and was not a particular dummy value (which also has a slash), vs. the bottom part where the column had no slash or WAS the dummy value-with-a-slash. I ended up nesting two CASES to get rid of the necessity of the UNION ALL - CASE WHEN (CHARINDEX('/',Referrer) = 0 OR Referrer = 'dummy-string-with-slash-here') THEN Referrer ELSE CASE WHEN Referrer LIKE 'www.%' THEN SUBSTRING(Referrer, 5, CHARINDEX('/',Referrer) - 5) ELSE SUBSTRING(Referrer, 1, CHARINDEX('/',Referrer) - 1) END END Just thought I'd share. :)
Create delete/drop statements using sys.objects with a creation date of day you made the boo :)
* customers-orders * orders-orderitems * subreddits-threads 
try any type of business school pet shop lemonade stand Load up Adventureworks for SQL Server and look at the table relationships. 
You can practice syntax at [sqlzoo](sqlzoo.net) for any type of SQL. Also, download Adventure Works databases.
Try this: CREATE OR REPLACE **PROCEDURE** create_new_emp Declaration errors are usually because of missing keywords, commas, etc.
OMG. This is what I get when I'm coding when I haven't had a coffee yet. Seriously was driving me insane
The other day one guy posted his [interview questions](http://www.reddit.com/r/SQL/comments/1f70t7/our_sql_interview_questions/) which were pretty good examples. As /u/evilalive posted, you can also hit up [sqlzoo.net](http://sqlzoo.net)
If you think about the businesses I listed and design a database for each business, you would understand why the relationships exist between the tables and you would understand how to write the queries. But what do I know, I've only been doing this for 30 years.
You didn't know you were supposed to read his mind? 
[sqlzoo.net](http://sqlzoo.net) Great series of tutorials.
This should be a straight forward join, but I don't know anything about DBgird. SELECT * FROM Flight_Schedules AS t1 INNER JOIN Flight_Costs AS t2 ON t1.flight_number = t2.flight_number_id
http://schemaverse.com is a game you play by writing pl/pgsql functions. Not quite pl/sql but should still be a great resource for getting familiar with writing sql heavy code. 
That seems sort of complicated for &gt;MSSQL SELECT CONVERT(varchar(10),(@height/12)) + '''' + CONVERT(varchar(10),(@height%12)) + '"' &gt;MYSQL should be something like the following: SELECT CONCAT(CONVERT((@height/12),char(10)), '''', CONVERT((@height%12),char(10), '"')
Says no value given for one or more parameters. http://i43.tinypic.com/358ytms.jpg
Nepobot is indeed correct, what is the error it is throwing. I tested the MSSQL one, and redid/checked the following with SQLFiddle for MYSQL. SELECT CONCAT(CONVERT(FLOOR(67/12), CHAR(8)), "'", CONVERT(67%12, CHAR(8)), """") &gt;Note : 67 is just a random number to test, update it a variable or column name you require to convert.
Oracle 11g
Error: "FROM keyword not found where expected" Thanks for all your help btw 
That is a good catch!
&gt;-- always want to see what null input looks like Pretty sure you have to be a citizen of /DEV/NULL to go there, I heard it was pretty boring, nothing to see.
This should work. My alternative approach is to construct the parameter query to use the (value, label) like such: SELECT '&lt;ALL&gt;' as label, NULL AS value UNION ALL SELECT Name as label, Name as value FROM dbo.foobar And then in the main query use a condition like AND user2 = COALESCE(@techID, user2) Meaning that the query will return all values if @techid is null - which it will be if you've past that value from the parameter. I sometimes add a third column (ordinality) which I can then use to force the &lt;ALL&gt; label to the top of any list.
Best practice in this case would probably be a stored procedure. Views usually offer slower performance. Also keeps your codeo n the server and in once place.
&gt;Would a view or stored procedure be more appropriate? Well, views don't accept parameters so you'll end up using a stored procedure either way. You might choose to create views to encapsulate some of the join logic between your base tables (and some of the conditions) and then have your SP reference the views. Or, you might just reference the base tables directly in the SP. It depends on how complex your query is, your internal approach to views, etc. But you'll want to use a Stored Procedure if you want to supply parameters. &gt;Would I be better off creating two views/SPs, one for each select query It depends on the queries. If the resultset is the same (in terms of columns/data types) then you can combine the two queries together in a view or stored procedure using UNION ALL. Or have one view for each query and then UNION ALL the two in the stored procedure. If however they're two different resultsets (different columns), then keep them separate and have two procedures. Combining the two wouldn't work well.
The easy thing to do would be to turn the parameter into a multi value parameter and change the where clause to be where table.user2 in (@techID) 
yeah, I wound up doing this for now. The problem is that the list of techs updates pretty frequently so we'd have to manually add new values to the parameter as we go. I'd like it to pull dynamically if I can ever figure it out :-) but thank you for your suggestion, it definitely provides a working method!
The only issue I have experienced with SQL clustering was when I tried using Broadcom network teaming with the two cluster servers. Somehow that messed up the network traffic and the cluster kept trying to migrate back and forth between nodes nonstop. After removing the broadcom teaming everything worked fine. That was two years ago, haven't had any problems since.