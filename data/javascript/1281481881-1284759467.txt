I had the same problem when I started. I was all about JQuery. The trouble is it's a different way of thinking with ExtJS. You're not working with divs and stuff anymore. You are forced into their components and that's what you gotta use. You can start hack around with the DOM like you do when you use JQuery, but you'll most likely end up breaking their layout code. Personally, I'm all about JQuery and/or rolling my own, but I can't say that ExtJS isn't a nice, well thought out library. Just feels like it restricts creativity. 
I feel like you can be an excellent JavaScript programmer and have trouble with ExtJS. You can also be quite proficient with ExtJS and not know a lot about JavaScript. I work with some people who probably don't have a clue about Prototypal inheritance, but they sure can bang out some ExtJS code. 
I didn't even catch why you were using the arguments.callee bit. I think you just blew my mind.
that recommendation kind of presumes that I don't know about inheritence, pubsub, or dependency management. also don't see how those things are incompatible with jquery. I looked at dojo again. require is useful. http://css.dzone.com/articles/jquery-14-improves-code-and widget support in dojo looks good. http://jqueryui.com/docs/Developer_Guide http://weblog.bocoup.com/publishsubscribe-with-jquery-custom-events 
*shudder* Wow that is so verbose. Kudos to you for being able to interpret that so easily.
Alerts bother me, espcially if i print out say 20 properties from an object: alert: Prop 1 click close alert: Prop 2 click close alert: Prop 3 click close FFFFFFFUUUUUUUUUUUU
Animal is still there? Shit I remember him back in the day (2005 i think) when it was YUI-EXT. What a trooper.
The examples are the best source. Admittedly its complicated, but as a Qt programmer also I love the "API".. Its cool once you wrap your head aroun dit. Javascript is difficult anyway as its manipulates the DOM, and that's another API to read..
Yea. I generally only use an alert for single properties. Otherwise I'll find it in Firebug.
Alas I can't take credit for the idea, I learned it watching this: http://paulirish.com/2010/10-things-i-learned-from-the-jquery-source/ And it likewise blew my mind :D
I am currently at my 3rd position (1 was a contract with Experian) where I have used ExtJS/Sencha. My current employer chose me because of my activity on the ExtJS forums and demonstrable knowledge. ExtJs2 was horrid. I couldn't stand it. Renaming Sencha is like renaming to Syfy. It has no technical basis but I'm sure there's a business reason. "I feel like you can be an excellent JavaScript programmer and have trouble with ExtJS." - Bzzt. You can be an average web developer who has used javascript regularly and have trouble with ExtJS. If you know javascript professionally, you shouldn't have trouble with ExtJs at all. Even the source is readable (from the API app). The biggest problem with ExtJs is that its design stems from being cross platform compatible and it is designed for work/data entry. The visual style is very bland and not forgiving. In many cases you will choose to use plain HTML or another javascript library to make the face pretty and have to relegate extjs to the model and service communication...basically causing a huge overhead in sending this giant library to the client that you only use a little of in specific cases. I've seen many companies simply choose a custom-rolled or alternative to extjs for the holy UI reason of "it wont do what we want, visually" on a few or most of their web pages. This is a legitimate reason to not use it, imo.
A production ready site has a build process to minify all javascript. It ends up NOT being verbose.
That wasn't my point, unless you are making a joke... I'm talking about the readability of the code.
Extra hard upvote for citing and providing link to source. 
Thank fsm for Chrome showing an 'ignore' check box after a few rapid alerts.
The recommendation is based on numerous experiences I've had with people who don't, and try to build large applications with jQuery anyway. I am in the midst of one right now -- the code is so disorganized, so tightly coupled, so completely unmaintainable, so completely untestable, that any given commit seemed to have about a 30% chance of breaking something else. The DZone article you link to suggests that jQuery has its own require. It does not -- it was removed at the last minute, and last I heard there were no plans to reinstate it. Pubsub can be accomplished with custom events, but as that article states it can be accomplished more efficiently without them. The widget factory is a fine piece of engineering, but does not provide what, say, Dojo's Widget does (especially when used in conjunction with Dojo's Templated), most notably multiple inheritance. I do not doubt that smart people can assemble their own toolkits. I have assembled my own toolkit in the past. However, I have come to believe strongly that doing so simply doesn't make sense, not when toolkits already exist, and not when jQuery offers me very little those toolkits don't offer as well. 
I think part of your frustration comes from the fact that you are comparing apples to oranges. jQuery is a low-level framework. If you want to compare it to Ext, you compare it to Ext.Core, Observables and those pieces. I think what you probably want to compare is ExtJS to jQuery UI. As for a lack of examples, I don't quite follow you there. They have a lot of examples for a lot of functionality. The documentation and functionality in ExtJS is light-years ahead compared to jQuery **UI**. For that matter, you can use the jQuery adapter with ExtJS such that the low-level calls are transparently handled by jQuery. ExtJS is a more complete solution. jQuery is a framework with a lot of plugins and a GUI layer sort of blended together. Both are awesome and we should all be happy they exist.
http://www.reddit.com/r/javascript/comments/czh2l/do_any_of_you_have_extjs_experience/c0wg1l8
Here's the deal. ExtJS components (especially in the examples) are self-documenting. I know what you want to call "bullshit" on that, because you don't understand them by looking at them. Part of that is because the examples often sprinkle-in superfluous functionality to the task at hand, but just pay attention to the end goal you are going for. You want to learn how to draw a grid? Look at the basic grid example. It shows how to make a new grid component. It has a configuration object that takes a lot of properties. What do the properties do? Look at the documentation. It actually work out *really* nicely to get people into the documentation from the beginning as to avoid some horrible hack-job of copy &amp; paste coding. There's also a decent FAQ for early stumbling blocks, in addition to some screen casts and user contributed tutorials in the [learning center](http://www.sencha.com/learn/Main_Page)
I've been wanting to find an excuse to use this toolkit for something for ages, it always looks really interesting. The [Mozilla site map](http://www.mozilla.org/community/universe.html) that he links is pretty inspiring, and looks great.
If you're going to write strange closure wrappers around setTimeout calls, you might as well go all out and run with [narrative javascript](http://www.neilmix.com/narrativejs/doc/).. 
Urgh, why did you have to remind me of narrative..
I see the point; as they say "splitting long processes into smaller ones." But I don't know what real-world situations you'd need it in. The example given is a 1 million iteration for loop. Is that realistic for JavaScript these days? If you're coding and you know that you're likely to cause the browser to freeze, you can code around it. Introducing a library (which seems to want you to change the way you write the most fundamental parts of JS) seems like it's not the right approach. But I'm not hugely experienced with JS, I could be wrong. jQuery makes the same demands (changing the way you write JS) and is widely accepted. But I feel that jQuery is solving a real and wide problem in a way NoFreeze isn't.
I'd like to see some benchmarks. With the default options, it'll introduce a 1ms delay every 10 iterations. That'll add up quite quickly. A 1000 iteration loop will take 100ms on top of the normal execution time. Unless I'm misreading the [source](http://github.com/dsimard/jskata/blob/master/src/jskata.nofreeze.js)?
Gmail uses tons of iframes. Just view the source. They also load data (json) inline into html. So instead of making one or several json requests. They'll load a single page with multiple script blocks that contain the JSON they would have fetched from the server.
&gt;But I don't know what real-world situations you'd need it in. I added something like this to the reddit uppers and downers user script a few weeks ago. It processes for 50msec, then waits 25msec, and so on. I also added some tweaks which made the processing itself about twice as fast. So, basically it now takes only 75% of the time and that without making your browser unresponsive. Another place where I used this kind of pattern was `text-overflow:ellipsis` emulation in Firefox (it's supported everywhere else). The thing is, this is an amazingly wasteful thing to do. You have to iterate over different text lengths until you find one which fits and you get a reflow for each iteration. So, if there are 100 or even 1000 places where you do this it gets *very* slow very quickly. The pattern itself (and the rationale behind it) is nicely explained in High Performance JavaScript (Zakas). It's in chapter 6: Responsive Interfaces.
javascript is very tricky, you have to be vary careful you have not gotten into a situation where you are not freeing memory after you use it, then "lose" it by basically having it inside of a closure where you can no longer access it, or rebinding events over and over even if they are not used. iframes can help i suppose in that situation but it is a horrible solution.
Agreed, 'tis a nasty solution indeed. This is a bit trickier than I'd hoped.
First of all, you have to kill IE6. There are solutions for IE6 memory leaks but they are strange (look for finally { return; }). Secondly, you do have to watch your closures, etc. If your app is really app-like and you aren't really concerned with google-ability, you ought to look into GWT (index.html =&gt; app.js =&gt; direct dom injection) which basically uses Java as a base to handle all that crap for you and exports out to a bare-bones HTML + JS page that does everything dynamically. Not the best of advice but it's all I've got. --Robert
Worth looking in to. I'm currently using jQuery and it's leaking like a sieve. And yes, it's absolutely app-like, so GWT is now on my list to investigate.
Build your application in the way that makes the most sense to you, without too much regard to memory leaks. As you are building it, you might avoid techniques that you believe will cause leaks, but not at too much cost in time or effort -- in that case simply take note and move on. Once your app is functional, profile it and decide where you need to implement workarounds. Or not -- once you have a releasable iteration, you could just turn it over to your target audience and see if they complain about memory leaks. I've built several complex javascript applications using the approach above and have never had problems with memory leaks. Of course, you are not me. Browser+js memory leaks are real, but overhyped, and sometimes I get the feeling that front end developers only like talking about them because they are envious of system programmers, or can't grow beards, or something like that. http://c2.com/cgi/wiki?PrematureOptimization
Using Closure (like Gmail does) can help manage memory leaks by: (1) Using goog.bind() (or equivalent in your favorite JS framework) to limit the scope of closures that you create. (2) Proper use of goog.Disposable to ensure references are released when appropriate (see Chapter 5 of Closure: The Definitive Guide). This is by no means a 100% guarantee in preventing memory leaks, but it certainly helps.
You know what? I think I'm going to take your advice. I'm most definitely guilty of premature optimisation. You live an' learn!
closure compiler does most if not all of these strategies, if you don't mind un-minifying your code to see the changes.
This too... (although GWT is still worth looking into). Pay attention to the emerging ~standard~ of: http://example.com/app#!/foo/bar/baz mapping directly (ajaxily?) to http://example.com/app/foo/bar/baz and then you can get away with a location.href =... ; every once in a while to fix things. --Robert
Am I looking at a paginated browser? That's it?
I'll point to a [comment thread yesterday](http://www.reddit.com/r/javascript/comments/czih2/askjs_dom_insertion_questions_whats_the_fastest/c0wg311) in which I had my mind blown via the use of closures (okay...) and arguments.callee (wai--whuh?) No need for entirely new syntax and a library. Just learn the language and abuse it accordingly.
Yes, the backend is MVC'd so this is very easy to implement also. I'm not sure why you're being downvoted. That was a useful contribute to the discussion.
How is writing a fast memory-leak free app better by writing it in java first then compiling it to javascript code?
This may sound odd, but I use a pseudo-memory manager for tracking variables that need to be available to other elements on the page. e.g. one global variable with a variety of setters and getters mm = { interval: 60000, pid: false, bound: {}, data: {}, get: function(i){ var i = i || false; if(i &amp;&amp; this.data[i]){ return this.data[i]; } return false; }, set: function(i, v){ var i = i || false; if(i){ this.data[i] = v; } return this; }, drop: function(i){ var i = i || false; this.unbind(i); if(i &amp;&amp; this.data[i]){ delete(this.data[i]); } }, empty: function(){ this.bound = {}; this.data = {}; }, bind: function(i, s){ var i = i || false; var s = s || i; if(i){ this.bound[i] = s; } }, unbind: function(i){ var i = i || false; if(i &amp;&amp; this.bound[i]){ delete(this.bound[i]); } }, clean: function(){ for(var i in mm.bound){ if(!$('#' + mm.bound[i]).length){ mm.drop(i); } } }, start: function(i){ var i = i || this.interval; if(!this.pid){ this.pid = setInterval(mm.clean, i); } }, kill:function(){ if(this.pid){ clearInterval(this.pid); this.pid = false; } }, debug: function(i){ var i = i || false; var d = this.get(i); if(i &amp;&amp; d){ alert(json_encode(d)); } else { alert(json_encode(this)); } } } mm.start(); Whenever I create an element that has data I need to track throughout the page, I give it a unique hash, then use mm.set(hash, data *[can be anything, even functions]*) with mm.bind(hash); Once every minute, the function runs a quick check to see if any bound elements no longer exist, and if so, it drops the data it is holding for the element. mm.debug gives me an easy run down through the firebug console of what's being held in memory. (It uses the json_encode function from php.js)
That object structure blows my mind with how many features are implemented. How did you figure out how to design it? What education background do you have? What other information do you think would be relevant for an aspiring JavaScript programmer?
this stuff is awesome, I need to find a reason to use it now...
I'm going to assume you're not being sarcastic (*this is reddit, after all. edit: ok, I'm just insecure ;)*): It's really just a giant global attached to the window object, with the functions abstracting the otherwise typical var[] = data scheme (and yes, I'm abusing javascript's object type by treating it as an associative array). Then an interval call that checks for missing elements, *ala* pseudo-garbage collection (since 99% of the time, if the element you needed the data for is gone, the data should be as well). The typical use case is this: Say I have a datatable element like this: Name | Quantity | + | |:------|:-----|:--| Reddit Gold | 1 | - porn | 144 | - Bacon | 3 | - Clicking on the name of an item brings up an autocomplete menu that calls a remote source. You can also click the "+" button to add a new row: element: &lt;a onclick="javascript:addRow(this);"&gt;+&lt;/a&gt; function: function addRow(i){ $(i).closest('table').find('tbody').append('&lt;tr&gt;&lt;td&gt;' + '&lt;input type="text" name="name" value="New Row" /&gt;&lt;/td&gt;' + '&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;a onclick="javascript:removeRow(this);"&gt;-&lt;/a&gt;&lt;/tr&gt;'); } However, the element has no idea what the autocomplete options were so it can bind a new autocomplete to the newly added row. So, the addRow function can call the following: function addRow(i){ var t = $(i).closest('table'); var d = t.attr('id'); t.find('tbody').append('&lt;tr&gt;&lt;td&gt;&lt;input type="text" name="name" value="New Row" /&gt;&lt;/td&gt;' + '&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;a onclick="javascript:removeRow(this);"&gt;-&lt;/a&gt;&lt;/tr&gt;'); if(var v = mm.get(d + '-init')){ t.find('input[name="name"]').autocomplete(v); } } When the datatable was first created by the server (in PHP in this example), it echoed the following: $h = md5(mt_rand()); //autocomplete options array $o = array('source'=&gt;'source.php', etc. . .); echo '&lt;table id="' . $h . '", etc. . .'; echo '$(function(){$(\'#' . $h . ' input[name="name"]\').autocomplete(' . json_encode($o) . ');'; echo 'mm.bind("' . $h . '-init", ' . json_encode($o) . ')})'; As for the design: frankly, I'd think of it as a hack. As for education: self-taught, roughly 12 years. As for learning Javascript: quirksmode.org, w3schools.com, and jquery.com are godsends. **Edit:** formatting sucks.
I'm not being sarcastic. My response would have lost any possibility of humor if it were an attempt at sarcasm. Thank you for the detailed response. I spent the last three months doing JavaScript programming from scratch (I used my college experience with C++ as a backbone for proper commenting, encapsulation, et al). I'm trying to pick up as much good JavaScript techniques I can while it's all fresh in my mind. (Reading through JavaScript: The Good Parts right now, by the way)
Ah, well thanks for the kind words. If you read a lot of proggit comments you've probably ran into the shred-fests that can emerge when any amount of code gets posted ;) JS: TGP is definitely a good primer. I also recommend reading through the source of any javascript toolkits you admire, as they are typically filled with tons of javascript-kungfu that are easily applied to your own programming. jQuery in particular helped me figure out a lot regarding scope and execution contexts. Good luck.
FWIW, plovr also facilitates splitting JavaScript into modules (similar in concept to the code-splitting feature in GWT), compiling Closure Templates automatically, and much more. From code.google.com, it may appear that there is a lot to learn before you can get up and running with Closure, but plovr aims to break down those high barriers to entry.
If you're only interested in the part where it routes the location hash changes (like in `/mail/#inbox`), and not the entire 20kb Sammy shebang (of templates, apps, etc), you may want to checkout jQuery.hashListen (just 1kb or so). $.hashListen('/post/:id', function (id) { $("#content").html("Loading post number "+id+"..."); // ... }); http://github.com/sinefunc/jquery.hashlisten 
Awesome!
I like it, polluting the marketing pool is always my preference.
Sammy seems to have trouble with the get/post listening. [In the demo](http://nettuts.s3.amazonaws.com/763_sammyJSIntro/demo/index.html#/inbox) you cannot load compose after submitting something without first clicking another path.
I like this.
I've always suspected gmail's codebase was a bit of a hairball, and that these sorts of things were happening. I wonder if some compromises were made to support IE6. However this is mainly baseless speculation on my part.
&gt;[...] if there are 5 independent animations each wanting repainting 50 times a second, then we'll try to repaint 5*50=250 times a second. We should only repaint 20 times a second. It's not like everything is redrawn. Redrawing 5 small regions is certainly faster than redrawing everything. Also, if you redraw everything you have to update these 5 regions individually anyway. &gt;"setIntervalIfVisible" etc. That stuff, however, is pretty interesting. I'd probably go with events though since they are more flexible.
I suspect this is because Firefox no longer allows the Webdings font (or any symbol fonts, for that matter).
That's ridiculous and awesome!
Thanks for making plovr! I think it is just the thing to make Closure more approachable.
banner rotation and an navbar
I think this guy missed this one: http://api.jquery.com/delegate/
Why do you think you are being hacked? I don't see any attempt to hijack or seal anything here. The only odd thing I saw was setting document.title, but that's not all _that_ odd.
A better solution would be to replace it with the Unicode character for a smiley
Hmm, why are they no longer allowed?
I was just talking to my girlfriend about this the other night...reddit trips me out sometimes.
[This article](http://www.dwcourse.com/dreamweaver/firefox-webdings.php) sums it up nicely: &gt; The bottom line is this. Webdings is a dozen years old and encoded in a way that doesn’t play well with emerging web standards. Mozilla has [a page explaining their stance on it](https://developer.mozilla.org/en/Mozilla_Web_Developer_FAQ#Why_aren.e2.80.99t_symbol.2fdingbat_fonts_working.3f), which basically amounts to "Because we say you should use Unicode instead." Of course, IE7 doesn't support Unicode, so either way you're fucked.
One thing i've always wondered, is it necessary to use the outer parentheses to encapsulate the function? I've noticed no difference from my day to day use. Also, another benefit of self executing functions is to create singletons. Essentially you cannot create new instances of this object.
Love your work man! I had a client prefer [this live method](http://valums.com/scroll-menu-jquery/) of a horizonal image array. Any chance of getting this as an option? :D Thanks again!
It's a parser thing: function(){}() Will generate a parsing error, because the parser sees the function as a statement, while (function(){})() Will run just fine, because the starting "(" forces the parser to process whatever follows as an expression.
Except i cannot replicate any parsing errors when using the first example. Can you give me an example of what the error says and which conditions will show it? EDIT: Ah i see the issue, i was doing: var foo = function(){}(); Your example is without assigning it to a variable. Thanks for pointing this out.
&gt;One thing i've always wondered, is it necessary to use the outer parentheses to encapsulate the function? No, it's purely cosmetic. However, it makes it clear that the function is self-invoking in the very fist line. This means you (and everyone else) will read the code under the correct assumptions. (function () { [...] }()); I agree with Crockford. The wrapper parens should wrap the whole thing. Coincidentally this is the only way to make it work in AS3.
Oh... and there I though that Janet always signs her mails with a 'J' at the end. Haha.
@ChiperSoft Thanks for the link!
that would be a good Idea too! But, I feel that yahoo smileys are more natural ☺
I use a small library of my own, that parses a json structure into DOM objects. Big plus: within the json-structure I can use live function elements, object references and such. Building the json structure is extremely fast, parsing the json-structure into the live DOM as well, because it already has the correct order and inheritance and is straight-forward. Since than, writing plain HTML is no fun anymore. Same with CSS structures. Creating those programmatically saves a lot of time when having user-dependend styles/colors that should match a complex design requirement.
Other unary operators like `-`, `+`, `~` work too and might have less tendency than `!` to give pause or mislead. That aside, though, the use of parentheses has become convention and should probably be stuck with.
http://paulirish.com/2010/10-things-i-learned-from-the-jquery-source/
Interesting. I recently saw a post from Rey Bango about just this sort of thing. I may have to explore it. Thanks!
I have "the good parts" but it's too theoretical for me at this point. Looking for a good foundation, with theory too but lower level.
Do you already have programming experience? If so, how much, and with what?
What is your goal with JS? If you're looking to write Node.js applications, then you'll want to focus on ECMAScript, and the sorts of things you learn from "The Good Parts." If you're interested in front-end web dev, then you'll really want to learn about the DOM first. My suggestion is to read and re-read "The Good Parts," until the syntax it presents is clear and then to supplement that knowledge with whatever speciality stuff you're actually interested (ie, my first question). In the case of web development, read up at sites like quirksmode.org and developer.mozilla.org. For stuff around Node, or other JS based coding read the specific documentation for said tool. All-in-all, you won't find a better syntax and style guide than "The Good Parts," which has a carefully defined scope, and teaches you just JavaScript instead of the quirks of individual browsers, etc.
Have you not programmed in a language with closures before? The best advice you're going to get is to suck it up and work through the good parts again. Actually write code when you learn something, don't just try to skim through it.
Give Head First a shot - And don't just read it - program all the examples, and then program some more. You can't learn without real hands on experience.
some, I play with django, so python mostly but no expert at all.
mostly front end stuff now, but I want to go beyond that to node as soon as i can
good point, It's the best
javascript head first?
It's written under the assumption that you know any of the languages with C-like syntax. Therefore all those mundane things like if/else, for, while, do-while, break, switch/case, and so on are omitted. Since they are (pretty much) the same everywhere. However, the whole syntax is explained in the form of railroad diagrams in appendix D. Personally, I'm a big fan of JS:TGP. The concise writing style was a huge plus from my point of view.
Very clever, actually. I consider this property of closures to be a feature rather than a limitation, but it's true that debugging it is annoying. This is a neat technique.
ok, so you're not just struggling with the javascript, but with programming in general. The thing that's confusing about javascript is that it's a "functional" language, that looks like an old fashioned procedural language. I've programmed for a long time and that's what took getting used to. I would say learn about the DOM and how to manipulate it with javascript. But it does take getting used to not only the language and its warts and beauty, but also how to successfully use it in the context of the browser, and what its role should be. Take a look at jQuery too, because one of the first things that gets frustrating is the differences between browsers. jQuery has a learning curve too, but it makes things easier once you get the hang of it. So, what's the best "book"? Havent bought a computer book in a long time so hard to tell. I get bored a lot and have a ton of JS experience, so feel free to shoot me a private message if you need anything clarified. godspeed. edit: just reflecting on what book I used originally 10+ years ago... it was O-Reilly, and then some other books from the library. I just keep them in the bathroom, and just keep flipping through them to reinforce the concepts and terminology and whatnot. It helps just to continually look at it, even if the books never leave the bathroom. Get the most up to date tutorials and hints online. There is no real secret and there is definetley a lot of questionable code out there that works.
That exact syntax is used in the jQuery source. There's information about how it's used and why in [this video](http://paulirish.com/2010/10-things-i-learned-from-the-jquery-source/) by Paul Irish
Yes. I never read JS:HF, but I did read Ajax:HF and it gave me a good understanding of how all that stuff works a couple years ago
I don't have "The Good Parts", but I do have "Javascript: The Definitive Guide by Flanagan. I hope someone with both can comment on whether it's a higher level or lower.
Obligatory: http://jmesnil.net/weblog/wp-content/uploads/2009/09/RzRcw.jpg
Head first, Javascript later..
Thanks for the advice. I have a hard time focusing on a programming book for more than the first third or so. 
[This](http://www.reddit.com/r/javascript) really obscure site; you probably haven't heard of it
[HFJS](http://www.headfirstlabs.com/books/hfjs/)
Not a book but, check out [Doug Crockford's series on JavaScript](http://video.yahoo.com/watch/111593/1710507). It's a comprehensive overview of the language from top to bottom. It helped me out a lot when I was first learning. It's a 4 part series. The link is part 1. You can go [here](http://developer.yahoo.com/yui/theater/) and do a find for *The JavaScript Programming Language* for the other 3 parts.
http://socaljs.com/
I'm a fan of the [Missing Manual](http://www.amazon.com/JavaScript-Missing-David-Sawyer-McFarland/dp/0596515898) series myself.
[Ajaxian](http://ajaxian.com/)
[Object-Oriented JavaScript](http://www.amazon.com/Object-Oriented-JavaScript-high-quality-applications-libraries/dp/1847194141) - the first book I read about JavaScript, and loved it. Despite its name, its not filled with just OOP; very practical, has everything from core syntax &amp; data types, working with DOM elements, events, objects, some AJAX, etc. 
I would go with * w3schools javascript section then * pro javascript techniques and lastly * the good parts if you have never don programming though, i am not sure exactly what you would need to start, I don't know any "intro to programming" JS books. Edit: I would like to know why I was down voted, I am not trying to start a fight, I am just wondering what someones disagreement with what I said was. It is a very unique language, that I personally like, and I think the information I provided was relevant and good. If you disagree, I would really like to know why.
Excellent. Wonder how libraries like jQtouch will fair. And Sencha.
While not exactly news, sometimes there's a good discussion in ##javascript on Freenode.
"Give Head First" sounds like an awesome instructional manual
What about [Eloquent Javascript](http://eloquentjavascript.net/)?
Here's a couple of good ones: http://weblog.bocoup.com http://brendaneich.com http://dailyjs.com http://www.davidflanagan.com/ http://howtonode.org http://learnjs.org/ http://inimino.org/~inimino/blog/ http://javascriptweblog.wordpress.com http://jsconf.us/ http://mathiasbynens.be http://www.nczonline.net/blog/ http://paulirish.com http://perfectionkills.com/ http://www.quirksmode.org/blog http://tjholowaychuk.com http://www.wait-till-i.com/ 
http://html5ian.com
John Resig, my personal hero. He is like the superman of the internet.
this should probably be cross-posted to /r/jquery I am really excited about this though, I use jquery extensively, and the higher-ups are starting to look into mobile...they thought I was retarded for suggesting it a year ago though.
very nice
I'm using chrome http://i.imgur.com/jCEhB.png
ive worked on a roll-your-own version of this for the iphone, and its pretty cool. with these kinds of apps you dont need to screw around with the app store. theres even a growing html5 site out there for html5 specific web apps. (www.openappmkt.com i believe)
http://ejohn.org/ http://www.wtfjs.com/
Maybe these tricks will be useful when they're actually supported by the browsers. http://i.imgur.com/bZe8z.png
This would be cool if it worked by adding looking glass after the object is created. However, since it has to exist on instantiation inside the scope of the constructor to see the "private" values, it isn't much use for already existing code.
Yes, that would be cool, but impossible -- we need something to share the same context with the private members in order to get our 'foot in the 'door.' As of now, to test private members you would have to either expose those members manually, or put your testing code inside the same context. I think this is a slightly more convenient solution since you only need to put a small function inside.
Thank a lot for the answers!
In fairness though, the last 50% or so of The Definitive Guide is an API listing in a javaDOC sort of format, not actual content. It also hits the high points: - variables are declared before the code that declares them - undeclared variables are global - stuff that doesn't work in IE - document.getElementById("theID").style.whatever = "newthing" - timers That's all there is to JavaScript right?
A bit of a Chrome slant.
Wow, the css3 animations are not exactly the smoothest thing. We've still got a ways to go before it's usable for anything big.
Web: [help I don't know JavaScript from mootools blog](http://mootools.net/blog/2007/06/05/help-i-dont-know-javascript/)
Well, if you *insist* on using javascript for this, you could look into the Windows Script Host. I think Microsoft Office applications can also run JScript (aside from VBScript).
You could make an ajax call to some external file, then return some json data... But I don't think that's the answer you were looking for.
[titanium](http://appcelerator.com) has a API for working with the filesystem using JS Firefox (Gecko) has a file read/write capabilities, but they are limited to the addons only. IE has similar stuff as far as I remember.
There are various hacks depending on the environment you find yourself in. There's a discussion of a few of them here: http://stackoverflow.com/questions/1087246/can-javascript-access-a-filesystem 
node.js but not available for windows
what
What is the actual problem you're trying to solve?
I think this method would force you to run the node sever on the machine you wanted to scrape, which would be kinda silly.
In the browser? No. From the command-line? [CommonJS.](http://www.commonjs.org/)
Lots of people are kind of hinting at this, but no one has come right out and said it. JavaScript is designed as a "safe" language that people can download off the web and run without trusting the author. If you need to scan the hard drive, either you're a bad person trying to betray someone's trust, or you're trying to use the wrong tool for the job. It might be possible to make javascript do this, but it's specifically designed not to.
'come on ... that's web 2.0
this
Damn right. When the web was first designed, it had safety and privacy built in. Then I started hearing of people getting viruses (whatever) from websites, and I couldn't believe it, because the design policy at the time included NO ACCESS to the filesystem -- EXCEPT -- Cookies store small amounts of data on the client machine. AND -- There's the file upload object, which *might* serve the OP's purpose, if only the OP would be more specific; although the use of the word "scrape" makes me wonder what's up. 
Nice try, officer Friendly. 
Yeah, how about not.
The Windows Scripting Host supports JScript if you need something that runs on the command line. I don't know how whether Vista or Win7 have retained the WSH, though.
Use mozilla's Rhino and the whole java shebang is under your fingertips with the feckin' javascript syntax.
If you're using IE (or Firefox with some extension to allow ActiveX objects), using the FilesystemObject is fairly straight forward. Depending on the application, you can use cscript to run your script and forget the browser entirely.
Not entirely true. While Javascript was originally designed as a "Web scripting language", the spec authors say this included server side computation where Javascript has access to files (ES5 Section 4). Practically speaking, today Javascript is designed as a more general purpose scripting language that can run in any environment. Its capabilities depend on what objects the host makes available to the programmer. Javascript in a browser, though, is supposed to be "Safe", so if he's using Javascript in the browser, he's probably out of luck unless he's ok depending on ActiveX components.
This is just awesome..
I hesitate to further this discussion, for the reasons I gave above, but parent could be very misleading, in that the memory from the leaks that you need to worry about is **not** reclaimed when the user leaves or refreshes the page.
The example given in this summary is pathetic since it uses an image! This gives the complete wrong impression of how MathJax works. I recommend look at the top example on the [MathJax HomePage](http://www.mathjax.org/) 
I first thought this would be another image replacement + server-side LaTeX hack. It's actually quite amazing. The generated code seems to take accessibility into consideration (via ARIA) and allows sensible text selection.
If you are doing this on Windows, you can make an HTML file and change its extension to HTA to run it as an HTML Application. It will run as a local application and give you access to a filesystem object that you can use javascript or VBscript.
Your best options are taking your head and banging it against the wall, that'll be less painful than trying to achieve whatever you have in mind.
I hate people who downvote valid contributions without giving a reason. Personally I dislike w3schools (see eg their for loop documentation; they don't really properly explain what the for loop is, only how to use it for the typical "incrementing over an array" use case) But yeah your advice was given in good faith, there's no reason I can see why anyone would downvote it. Perhaps because you suggested TGP when OP already said he didn't get on with it - although I agree, you can't find a better JS book, and if you can't follow it then maybe you should start by learning the basics of C-syntax and programming.
Seems solid. Opera/9.80 (Windows NT 6.1; U; en) Presto/2.6.31 Version/10.70 full concat: 81 partial concat: 316 no concat: 189 full concat: 71 full concat: 47 full concat: 48 partial concat: 204 partial concat: 256 partial concat: 268 no concat: 282 no concat: 299 no concat: 184
The no concat is faster in Chrome but I'd be interested to see how things work out over EDGE in my iPhone. Or over 3G. Or on an Android. Can you tell I deal with mobile development?
no
very true that mobile is a different world. but then again, most sites would/should send very different javascript code (much smaller) to a mobile client versus a desktop client. if you're sending 100k of JS to a mobile, it's gonna take a LONG time. :) FYI: I just ran the test using my Palm Pre over Verizon 3G... 54 sec for full concat, 12 and 14 sec for partial and none, respectively. So clearly it's a lot higher than desktop browsers/connections. But interesting that approx same pattern even with much higher numbers. Basically, partial and none are tied given those numbers, which is generally about the same results as on desktop.
It is, indeed, much slower. I tried to build a non-blocking iterator library a while back. I stopped as soon as I realized it added way too much overhead (I was using setTimeout with 0ms). It keeps things from freezing by sheer hackery: setTimeout waits until the stack is clear AND the timeout is reached. That means that setting timeout to 0, will execute as soon as the stack is clear. If your timeout function is small enough, any browser action will shim between timeouts. The smart situation, of course, is to use webworkers instead. (this was my stab: http://github.com/warfangle/Kalmarus/blob/master/src/mapreduce.js )
Interesting. I'll probably abuse this code for my own test suite. I'm in the process of porting a full-on web application to a portable version. Thing is, the business wants the "full functionality" as seen in the desktop-based app. Sounds like a fun problem to solve!
I'm glad jQuery doesn't include an inheritance/class setup. JavaScript has very little need for it. If you need to extend the functionality of an object, just extend it already. It's a dynamic language, not Java. Going through many of the design patterns in the Head First book, I quickly discovered that many of them are simply not applicable to JavaScript: they were engineered to work around basic incapabilities of static languages like C++ and Java. Take a look at the decorator pattern, for instance (has both Java and JavaScript examples): http://en.wikipedia.org/wiki/Decorator_pattern You can still use the pattern. You just don't need fifteen classes and interfaces to do it.
You can try and use Webworkers as they're implemented in latest versions of modern browsers. Next version - use some thing like Narcissus (you'll have to heavy patch it to cross-browser-usable state, though). It's simplier than writing your own JS parser-lexer-engine. There also was this thing called `evalcx` in Firefox, that run script in defined context.
Webworkers sounds like a good idea with the exception that I believe they have access to XMLHttpRequest. Might be easier just to scrub for XMLHttpRequest then covering any exploits in the entire language.
You should check out [Caja](http://code.google.com/p/google-caja/).
I second this. Caja is exactly what you want. Writing your own script sandbox would be a pretty major undertaking.
There's really no scrubbing one can do short of full parsing.
Another strong vote for Caja. Reap the fruits of a bunch of smart people's effort.
 window['XMLHt'+'tpRequest']
prepend XMLHttpRequest = {}; or XMLHttpRequest = function(){}; 
If we're lucky, we have 6 concurrent connections allowed by the browser (much fewer on mobile platforms and on *ahem* certain other browsers). After the initial html is loaded one of those goes to css, one to single-sprite, one to repeat-x-sprite, one to repeat-y-sprite, several go to one-off images. Often you will have a few that go to external tracking and so on, you get the idea. My gut-feeling is that using up more than one initial http-connection at page load for js is most likely* not going to be faster, it's just gonna block the loading of other resources. I'd like to see a real-world load test, that includes normal resources as well. *unless you're running a large project, in which case it of course is a good idea to download an initial bootscript to give the user some bare bones UI while loading the real app..
You would also have to prevent the script from instantiating another WebWorker that would be able to access XMLHttpRequest (and WebSocket, and any other security-sensitive object that might be added in the future).
So just go Stalin and kill all the worker constructors. 
The next "test" in this series will be a more real-world test... this is the baseline test to establish if there's any validity to the theory of parallel loading overcoming connection overhead at some point in file size. "Full" vs. "Partial" is about being curious to see if self-hosting jquery, and bundling it with your code, is better than using the remote CDN (even with extra DNS lookup penalty). Turns out the parallel loading benefit to jquery's 70k (25k with gzip) is more than enough to justify using the CDN. The "full concat" is by far slower on average in this test's results than the other two. "Partial" vs. "None" is about seeing if a single extra connection has so much more connection server overhead (which is *not* the same thing as a browser connection limit issue) that it negates the benefit of parallel download. Thus far, it shows that at worst, the two are equal, with "None" still trending faster. Even if the two are equal, or even if "None" was slower by a little bit, the other benefits of separate files (like better cacheability) are something to consider. ---------- As for connection limit, this is a different (but valid) concern, which the next test will take into account. True, a lot of browsers have 6 connection limit, but several have even more (Chrome has 8, I believe... IE8 has more too). Keep in mind this is usually per-host. So theoretically you could connect to two different sub-domains and grab both your JS files separately in parallel. Also, only in a truly ideal situation do all those per-host connections purely run in parallel at all times during load. For instance, scripts loaded with &lt;script&gt; tag will block in some browsers, as they also will in the presence of &lt;link&gt; tags, etc. There's *lots* of complications to the real world scenario. Not to mention the fact that not all content is local, so there's additional DNS latency, blah blah blah. The connection limits of modern browsers are often under-utilized, even on resource-heavy pages. Also, the question is not "should i split my one concat'd js file to 10 separate files", it's just "should i split up my one big file into *2* separate files" -- only one extra connection. I think odds are there will be an extra connection to use in most non-perfect-connection-utilization page loadings. So the more important question in my mind was: will that extra connection's overhead on the server be greater than the parallel benefit. --------- Parallel loading vs. connection overhead is a more universal (and less subject to change) topic than "is my page fully utilizing the connections available in the browser", because the latter is constantly changing and differs from browser to browser. Just blindly reducing connections to try to address those inconsistencies is, I think, throwing the baby out with the bathwater.
Why is it a bad idea for the user to be able to run client side code, on their own client side? Unless you're running the code on a different client's machine, I don't see the problem. If you need to 'share' the effects of the code can't you just send the resulting object movement events?
problem?
I think it would be important to decide if you are going for the "Parallel loading vs connection overhead", or "optimal in a browser environment". In the latter case, which I was referring to, I am, again, pretty certain of what I said in my original post. We are talking about static content loading, something that in any major setup is heavily cached at several levels. One JS file will need one HTTP connection to verify the file is unchanged, two JS files will need two connections, and so on. If you're lucky, they will execute in parallel, but like I said before, they probably won't. The number of parallell connections in a browser are also lower than you mention. HTTP 1.1 spec says 2, most browsers up until last year as well as all mobile browsers AFAIK follow that (don't quote me on it though). IE 8 does 6, IE 9 does 8. FF does 6. Dunno about chrome.. It is true you can expand that limit via subdomains and CDNs, but DNS-lookups are slow, and there is no reason to do it like that when you almost always can keep the initial need of connections around 6. I figure playing devils advocate will shine some light on parts of this subject that would be interesting to include in tests to come. I have no data to back any of this up, it would be interesting to see how all of this relates to real-world usage :)
Is your user-submitted code going to be shared with others on the site, or is it only visible to the user who submitted it in the first place? If it's not shared with anyone else (i.e., never executed in other people's browsers) then there's no security risk in just eval()-ing the code. (There's nothing that the user would be able to do that they couldn't with a greasemonkey script or some other client-side plugin). The only benefit to sanitizing the input is to prevent the user from inadvertently messing up the page by doing something silly. But if the contributed code will be visible to (and executed by) others, you're right to want to sanitize it. Carry on.
Regexp filtering definitely won't work. It's possible to execute any arbitrary bit of JavaScript using only the characters ()[]+!: http://discogscounter.getfreehosting.co.uk/js-noalnum.php I can't envision any useful script that doesn't use these characters. You probably want Caja, which deals with the problem by not letting you access any of the unsafe APIs, not caring about the code. If you let them execute anything, but don't let that code touch the outside world, you should be pretty safe.
Actually, I think code security would work the opposite way, forcing them to use alnums in places where it would be ridiculous not to. A function like function x(){()[]+} would be right out.
Well, you're not the first one to bang your head on those kind of things. The Right Way (tm) would be for every browser to provide a fully sandboxed way to run untrusted scripts. We're not there yet, although Web Workers are an encouraging step. Until then, on the client side, you can use: - [caja](http://code.google.com/p/google-caja/): feels like javascript, require a fair amount of plumbing, runs slower than javascript. - [adsafe](http://www.adsafe.org/): runs client side, removes a lot of javascript features (no [] for example), runs at full speed (except for the weird work-arounds you have to use to make up for the absence of [], for example) on the server side, you can go with: - [rhino](http://www.mozilla.org/rhino/). That's what [YQL](http://developer.yahoo.com/yql/) is using to run arbitrary user-submitted javascript code for example. It won't feel like a browser environment, and it can make your server overheat. - [node.js](http://nodejs.org/) + [nifty libraries to emulate the DOM](http://www.yuiblog.com/blog/2010/04/09/node-js-yui-3-dom-manipulation-oh-my/). pretty bleeding edge. should scale better than Rhino, but still liable to melt your server's face under load. The server options might not be appropriate if you need your untrusted code to pilot client-side animations, but it can be applicable to a number of other uses where it may not seem like an option initially. *edit: I can't believe I forgot to pitch my own harebrained project, [ScreamingDonkey](http://screamingdonkey.hurlant.com/). It will take your JS code, compile it to as3 bytecodes and run it within the Flash Player. Why? Because it can. If you enjoy the less travelled road, you could take that code, fix all the bugs and tweak the DOM proxy objects to sandbox it nicely to only what you want it to see. You may have to tweak the parser too to prevent access to internal Flash APIs. so yeah, terribly idea, but hey, fabulously weird project.
What does r/javascript think?
[Adsafe](http://www.adsafe.org/) is a take on that filtering approach. The trade-off? use of [] is forbidden, and replaced by calls to helper methods that make sure you're not doing something silly.
Oops, that's a huge piece of information that I forgot to mention in my original post. The goal is to eventually have a Javascript application that's made up of code created by several different 3rd party users, who are trusted as in they have access to my site, but untrusted as in they could potentially input whatever code they wanted.
Nope, just a fairly straight forward (but annoying) security problem. I'm not really trying to determine any information from the code, just prevent it from doing damage.
Well, maybe a little, when I first posted this thread. Right now, it looks like the best path to take is to not care about determining whether or not the code will do something, but to simply prevent it from doing all of those things by using some kind of sandbox.
So, it's PowerPoint with source code highlighting
It's not the halting problem. He just needs to restrict access to a couple functions. It wouldn't be easy but there's definitely a finite number of ways to call the dangerous functions.
Pretty much. Those are just some test apps as a proof of concept I guess. Working on the environment at the moment.
Online desktops have always fascinated me, but I think it's mostly from a standpoint of being impressed with the current state of web technologies. As much as it hurts me to say it, I think huge web "platforms" like Facebook are closer to the dream of a useful online desktop than anything.
That's just [280slides](http://280slides.com/), a separate affair altogether.
The desktop metaphor of windows does not translate well at all to what people need to do on the web. New paradigms must be invented. New paradigms not about scrollbars, title bars, square things you can drag around, a file system or even a "desktop." New paradigms about actions, data ubiquity, and so forth. Usability concerns not in dealing with where to place buttons (though, of course, that's a valid concern). Usability concerns in what your online, distributed, in-the-cloud operating system can do for you without you even asking. You need to rethink how desktops work just like Apple rethought the cellular phone, if you want this to actually gain traction.
I feel bad for recommending this, as I've been neglecting it for so long: [JSandbox](http://github.com/eligrey/jsandbox). It's a library I made that I've been planning on completely rewriting into a `Runnable`s interface. It's more locked-down and secure than Caja, and also offers (in the future) multi-threading, though it's only useful at the moment for sandboxed object IO.
How complicated do the scripts need to be? If you want the users to have access to a full JavaScripting environment, something like Caja is (probably) the way to go. If what you need is something like a small DSL, like for drawing on a canvas...you could create your own scripting language that "compiles" to "safe" JS. That way, you could give the user access only to the functionality you want them to have. This will probably end up being more performant than a full sand-box, but will obviously still add some weight. Coffeescript would be a good reference if you want to go that route. It's goal is different, it's a language with a mix of Pythonic and JavaScript-esque syntax that compiles to JavaScript. You include the CoffeeScript in the page, and another "interpeter" script...or you can "compile" the CoffeScript ahead of time. Their goal is different, but you could take a similar approach to create your DSL. You'll prob have some kind of library anway so you can combine that with the syntax of your DSL. From your description, it actually sounds like this is all you need.If you want to go that route, there was a great talk at JSConf 2010 about creating DSL in JavaScript. It's certainly a bit of work, but there are a few parser generators for JS that will do a lot of it for you, and you can learn a lot from studying CoffeeScript. If the DSL you need isn't overly-complex I don't think this is really a bad way to go. The compilation could be done in-browser for testing, and then you could also do it server-side after it's submitted and before it's served to other users.
I think Webworkers are def something OP should look into as part of what they are doing overall, but I don't think it really solves their main problem e.g. security. They'd still have to basically write a sort of DSL to use in conjunction with the Webworker as throwing the user submitted code into the WW doesn't magically create a sand-box. WW's don't have access to the DOM for one. Also, fwiw there are a few parser-generators for JS available, so they wouldn't have to write one if they didn't want to.
That was my initial proof of concept... :)
I very much like your thinking, sir. The window paradigm works best for point and click however window paradigm inside a window paradigm probably isn't ideal. I would like to hear what ideas you have if you have some.
means?
I commend your tenacity.
Everybody is saying that node.js does not work on windows. On official page it is written that is **works** and I have compiled it on windows without a single problem/error/anything.
tl;dr: get a job where you write a lot of javascript. When you don't know how to do something, look up javascript tutorials online. 
That's not a very accurate TL;DR. He mentioned paying attention to design, studying the details of *multiple* Javascript libraries very closely, and working on your own projects. He links to the Douglas Crockford videos, and recommends various things to spend time on. This was a pretty good post on not just Javascript, but programming in general, and I encourage people to actually read it.
tl;dr: Read the post.
You actually gave me an idea on how to pull the whole mess off last night. prepend something like: var allowedList = ["onMessage", "terminate", "postMessage", ... ]; for( id in window){ if( id in allowList) continue; //For brevities sake, hijacking Python operator if( typeof window[id] == "function") window[id] = function(){}; } That should nuke pretty much everything in scope thats undesirable before the potentially malicious user script gets a chance. 
This looks very promising. I might have to contribute some tests.
If people want a really fast JavaScript minifier, they should look at Cycript.
They seem to emphasizing speed. So what if it's fast? It's not like anyone (sane) would invoke it per request (or even per development cycle); you minimize your JavaScript once per deployment to a live server so who cares if it's X seconds faster than Closure - it's all about the bytes.
Javascript and badass do not go together.
That's not its only advantage, though: &gt; ...the code produced by UglifyJS is safer than the code that Closure generates. For example, Closure doesn’t know how to deal with eval or with{} - it just logs an error and continues to rename variables anyway. This, obviously, leads to broken code. UglifyJS does not have this problem
It's also written in JavaScript. You need to have a Java runtime (or use Google's web service) to use Closure Compiler.
The [W3Schools website](http://www.w3schools.com/js/default.asp) has some good reference material on most of the functions. Specifically I think you'll get the most use out of the JS Objects stuff on the left-hand menu.
I'm using these constantly, they are clear and comprehensive: https://developer.mozilla.org/en/JavaScript/Reference https://developer.mozilla.org/en/Gecko_DOM_Reference
Thanks. This is the sort of reference I am looking for.
Bump for the Mozilla Developer Connection. It's clearer and more comprehensive than the JavaScript books that I have. In my experience, W3Schools is only good for documentation on the DOM API.
How about HTML, JavaSript, DOM and CSS (and potentially more) [all in one?](http://www.gotapi.com/html) ___ `For the Ctrl-F narrow-downers: gotapi` ___ *Also, there's: - [QuirksMode](http://quirksmode.org/resources.html) - JavaScript Kit \[ [JS](http://www.javascriptkit.com/jsref/) | [DOM](http://javascriptkit.com/domref/) \] - [DevGuru](http://devguru.com/technologies/javascript/home.asp) And if that wasn't enough, check out a [comprehensive list of resources compiled by StackOverflow users.](http://stackoverflow.com/questions/823718/best-reference-sites-for-html-and-javascript-programming)
Hey, surprised no one has replied to this yet. I watched a great video by Nicholas Zakas, he did a great job of explaining when reflow happens (and how to minimize it happening by using document.createDocumentFragment). The rest of the video is worth watching too.
MDC FTW.
Ugh I cringe whenever someone appends Ninja/Rockstar/Badass/Howler monkey/etc to IT positions/programming languages, it makes me feel like I'm a 15 year old. Anyone remember the initial release of the jQuery site design which had the whole "Become a Javascript ROCKSTAR" accompanied by a cartoon rockstar throwing out the viking while hacking the gibson? I was in a meeting with potential clients trying to explain the libraries I was going to use to solve their problem and they had released it the night before my presentation, when I navigated to the site I got a bunch of scoffs and and snorts, I was not taken very seriously. /tangent Good article though. 
woo, thanks for the ref http://googlecode.blogspot.com/2009/06/nicholas-c-zakas-speed-up-your.html
[This](http://www.clientcide.com/deep-thoughts/how-to-become-a-javascript-badass/) was posted earlier today. Some good info in the link. He mentions the [Crockford videos](http://developer.yahoo.com/yui/theater/), which are absolutely invaluable.
Upvoted for DevGuru--it's my go-to reference for native JS.
W3Schools is outdated and sometimes blatantly wrong. Stick to MDC.
I actually on the constant hunt for a bit of goodass instead.
I think a link to it would probably net more responses...
Thank you reflectiveSingleton for pointing that out... i forgot the text submits are a little different... arf
Navigation is difficult and - even worse - unintuitive. Background is distracting and over busy.
I still don't understand how to run this. Do i need node.js installed? How does it work?
yea i dont make it clear... no where near where i want it but cool thank you...
the post was tl;dr.
just realized... ipad is kinda SOL... you can navigate by clicking on the other divs and by rolling over the broken thing on the bottom right... ipad... rollover no workie... so I will have to think about that instance
Dude, section 11.8.7. TLDR: Javascript has an in operator, and it works just like you want it to :)
You mean you don't read ECMA-262 every night before going to bed?
It's not my fault my E-reader broke!
How about the runtime speed of the compressed code compared to code generated by Closure? I imagine there's little to no difference though. How come these minifiers rarely store commonly used static strings? For example, if you look at jQuery compressed code you'll see code like: typeof o === "object" or typeof o === "string" I'm sure you could save a few bytes by keeping "string" or "object" in variables with short names. Ditto with property accessing with `.`. If code accesses the "getElementById" property a lot, why don't they store that in a variable and access the property using square brackets? * Also, why does jQuery use `===` for `typeof` checks? Doesn't it always return a string, making `===` overkill? Is there a performance benefit? 
&gt;Do i need node.js installed? Yes. It uses the node.js module system so it probably wouldn't work in all other javascript environments. But other than that it looked like it was done in standard javascript/ecmascript so it could probably be modified to run in a browser for example. &gt;How does it work? The source code is available for viewing
&gt; Why? Because it can. You sir, are a True Hacker of the Old School. There is no better reason to write a program. 
Nice try, but certain properties of window can't be overwritten, "document" for example (at least in some browsers). var XHR = document.body.appendChild(document.createElement("iframe")).contentWindow.XMLHttpRequest; Rewriting the user submitted JavaScript using Caja (or AdSafe or whatever) is really the only way to go.
&gt; Also, why does jQuery use === for typeof checks? Doesn't it always return a string, making === overkill? Is there a performance benefit? Yes, it [always returns a string](http://bclary.com/2004/11/07/#a-11.4.3). Performance is [degraded by using ===](http://jsperf.com/typeofequality). (By a couple of percent in Chrome and Firefox for me) Not that surprising given that === tests value and type, but == tests only value.
Also, storing typeof comparison in variables to save a few bytes seems to [impact performance](http://jsperf.com/variables-vs-strings) in this unscientific test.
didn't know that. can you make the binary available how did you compile it? you are not using cygwin?
I think that small percentage would probably be barely noticeable, but then again you probably wouldn't save more than 50 bytes even in a script like jquery. Perhaps it would be useful in something like that JS 1k contest where every byte matters. Also that benchmarking site is pretty cool. Bookmarked.
Yes, MDC is great. "MDC" also works great as google keyword. E.g. *mdc date* gives you https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Date as first result. For my own documentation I'm using YUI Doc, by the way. But there are a zillion other choices.
Oh god no, stay away from W3Schools. I've encountered lots of bad info there.
Yes, I am using cygwin as recommended on their [web site](http://nodejs.org/). After running ./configure, some packages were missing so I needed to install them using "setup.exe" from cygwin web site. Other than that it was ./configure &amp;&amp; make &amp;&amp; make install I managed to reproduce effect from [this blog](http://jeffkreeftmeijer.com/2010/experimenting-with-node-js/). EDIT: And I had to have a python from the cygwin distribution, I think regular windows python did not work (can't remember why).
by far *most* of the arguments made against loading separate files are more aimed at the server overhead than the possible connection starvation in a browser. It's also much harder to address connection limits in browsers since they all vary so much and under various conditions. but server overhead is a cleaner target to address. So I *am* trying to shoot that argument down with some proof that maybe the overhead is not quite so outrageously drastically bad as many claim it is. connection starvation is a valid issue, but a separate issue. and i also think it's less likely to be something that any developer, no matter what they do, can do much about. In IE6, you only get 2. So do you boil down your whole site to the lowest denominator? No, then all the other browsers can't take as much advantage. Saying "I will reduce all http requests absolutely to a bare minimum blindly because that's the only way to effectively deal with connection starvation" is, as I said before, throwing the baby out with the bathwater.
Double checked and it looks like in operator isn't syntactically equiv to pythons
Alright I am admitting defeat :)
For instance, what if in 70% of your visitors cases, they had an extra unused connection (which you don't know about), and if you split your JS into two files, for them things get quicker... and for the other 30%, maybe it slows it down for them. In that case, would you say it's a valid technique? Or would you discard it to the detriment of the majority?
whytf is any of this javascript in the &lt;head/&gt;?
That's addressed in the comments. There are a lot of pages where JavaScript usage goes beyond simple progressive enhancement and script references toward the top of the page make sense (think JS-heavy Intranet apps and/or apps like GMail (or actually, view source here on reddit)).
ok, running inside of cygwin is different than native windows.
A newer, smarter version was linked on that page. http://www.learningjquery.com/2009/04/better-stronger-safer-jquerify-bookmarklet
I could have written this post, seriously, i even worked for CNET.
I think you missed my point, "reduce all http requests absolutely to a bare minimum blindly" is exactly how you speed the initial loading of a site up. The reason for this is browser caching. Users will, except for the first time their browser visit the site, not actually download any JS, CSS or images. It will all be cached in the users browser. Even if the client has an extra connection, it won't matter if you have split the JS file in two, since all that will lead to is an extra request with a "304 Not modified" HTTP response. At best, two connections will be about as fast as just one at finding out that a file hasn't been modified. In many cases though, most of the time they will block each other and other resources waiting to load.
Why? It makes coding easier to stuff it in a header and that's it. Additionally, jquery people recommend $(window).load over $(document).ready.
The [event object](http://api.jquery.com/category/events/event-object/) you receive for the event should contain a pageX and a pageY property giving the coordinate where the event happened. So if the mouseleave coords are still in the bubble, the pointer has not left it.
It depends on what you are doing.
It's rare that you should use $(window).load() over $(document).ready(). It fires potentially much later than $(document).ready(), after assets have finished loading.
The only problem with this, is if you want to interact with *other* elements on the page when they're also ready (suppose you want to map the contents of `#foo` to `#bar`). Before long, you're opening up your filter for the `live` event to so many elements that you might as well hook on the `document.ready` event instead.
I think people should be careful with the $.ajax example, although it will probably work, because it fires before the $(document).ready, it is possible for it to return before the $(document).ready. Then if you are for instance inserting the result into the DOM, it is possible the node you are trying to insert it into does not exist yet, which would cause problems. The .live one is valid though, and again goes back to people not really understanding how .live works.
reddit is one of the least js heavy sites I could think to use of as an example to delay the page rendering in an article about speeding up page rendering, but okay also just because gmail does something doesn't make that correct, I have some google labs bullshit that preloads my inbox and then re-renders the page when all the JS garbage that isnt' cached downloads it would make a ton more sense to just grab the html, render the page, and then have the javascript trigger since it's at the end of body. the only excuse for doing this is to have a layout dependent on javascript, which for the most part is complete bullshit
I'm glad I'm not the only one that noticed that.
Actually, I've found quite the opposite in my optimization efforts for my sites and for others I've helped. First of all, we have to remember that caching is not super reliable, Yahoo taught us that a few years back. So, if only 40% of repeat visitors are coming with a primed cache, we have to narrow our scope. But if you suggest that making it more painful (even by 500ms) for first-time guests is better, then you're assuming that most users are repeat visitors. I don't know about you and your sites, but I care *extremely* about the first impressions, even more so than the repeat business. So I'd never take an approach that made it worse for them and just hope they ignored that and came back anyway. I'd try to balance and amortize that cost as much as possible. First impressions are key, still, IMHO. Secondly, even if we do assume the cache is useful (which I do in fact!), for at least the 40%, there are other benefits to the split JS that are not necessarily obvious at first glance. Primarily, I think it yields better long-term cache performance on a site to not have everything grouped together into larger chunks. Why? Because you can't partially invalidate a cached item. It's all or nothing. Again, I don't know about you, but on all the sites I work on, there's two kinds of script code (at least): the kind that is very stable and doesn't change (libraries, 3rd party scripts, etc), and the kind that changes all the freaking time (UX tweaks, new 'features', etc). I constantly tweak code related to how my blog post's external links are styled, etc. That's just me and my process, but I've seen a lot of sites and apps that do change often. Facebook changes their code nearly every hour it seems. :) So, if given a choice to take 70k of stable code and 30k of unstable code (or even 80/20), and either stick them together, or keep them separate, I think separate will yield better long-term cacheability, because in general, the 70k stable code will not have to be re-downloaded over and over again in the big bundle that was invalidated because of a change to the more volatile 30k. ------------ As you said, if you are opening up lots of connections just for 304 checks, that's bad. But the beauty of having two chunks instead of one is that I can set a different cache-lifetime on the more stable code versus the more volatile code. For instance, I can set the stable code to be 2 weeks lifetime (highly likely to be at or greater than the real retention life of most cache items), but I can set the volatile code snippet to be a lifetime of 1 day, meaning that the 304 checks will only happen frequently for the code which is more subject to change. We won't necessarily be wasting those valuable connections to revalidate the stable code, because if the browser behaves well and respects cache-lifetime, it won't need to check for a longer period of time.
Due to JavaScript's single-threaded execution model in the browser, that actually hasn't been an issue in my experience. Even if the $.ajax() call returns instantly (which will happen sometimes due to caching), it won't have a chance execute its callback until the page is ready. It's the same as how setTimeout(foo, 0) defers execution until the page is finished rendering, not 0ms. If it makes you uncomfortable, you can always wrap the success handler in $(document).ready() and still benefit from initiating the $.ajax() request early. There's a code example of that in the comments on the post.
reddit is actually not a bad example. View source on this page. Notice the scripts are referenced at the top of the page? Then, see the obtrusive, inline onclick handlers on each voting button? That could all be replaced with a relatively simple .live() handler in one of those scripts referenced in the head, and they'd save quite a bit of bandwidth. The reason some sites choose to set these things up early, rather than late, is so that the page is functional immediately. When reddit is loading slow (like that would ever happen!), the last thing you want is for the page to be hung in a half-functional state until the very last lines of markup are emitted. Sure, you should try to get the scripts to the bottom if you can, but that isn't a one-size-fits-all solution for every site. It's just a best practice for purely progressive enhancement, if you can manage it.
Hmm, I would be very interested to read some more concrete evidence on that, seeings as the whole point (well, not the whole point) of ajax is that it is asynchronous. My solution (had been doing that), would have been to put the success in a $(doc).ready. If anybody can point to some reading about this, I am always happy to learn.
Ah, had not thought of this... Thank you fforw, it works now!
The XHR request *does* happen asynchronously, but the callback event has to line up in the same FIFO queue as the rest of the page's rendering and JavaScript parsing/execution.
I agree on that point, but I still see no reason why that would prevent it from running before the .ready. I believe jquery is using the DOMContentLoaded (when possible) for .ready. So, in my mind, when the ajax request returns, its callback will indeed be added to the normal queue to be executed after everything else already in it. But I have no reason to believe that the DOM will be ready before that, so a can't reasonably assume that the DOM is "ready" when that callback fires. Again, not trying to argue, just trying to learn.
In practice it would be very rare for your callback to get executed before the DOM is ready. Though you are right, it's possible the page could be taking forever at page rendering or downloading the original html and has an empty script processing queue. But I think the most important point here is that (at least as far I as I know) browsers' behavior in processing scripts is not defined anywhere. That is to say, tomorrow, chrome could decide to process all scripts on their own thread as soon as they become available. I would say it's critical for future proofing your apps to ensure your callbacks that modify DOM check for DOM ready, otherwise some future browser may break your site.
&gt; Again, not trying to argue, just trying to learn. No worries. I didn't take it as argumentative at all. I looked briefly, but couldn't find a good reference link. The crux of it is that JavaScript, page rendering, and the browser UI are all executed via the same, single-threaded queue. So, if you queue a JavaScript callback at any time after the document begins loading, it won't be executed until (at least) the document is ready. That's why setTimeout(fn, 0) works how it does. It's also why alert() blocks the browser UI and an unresponsive script appears to crash the browser. Everything's competing for the same thread.
It's fairly safe to depend on the browsers to continue behaving as they do. Any browser that implemented opt-out threading would be unusable. Instead, the problem of threading for computational tasks is being solved with a new API in HTML5. WebWorkers are basically the answer to the question "How do we give browser-based JavaScript threading without breaking the web?"
You misunderstood the post. You only use live before .ready when you would be using it after .ready. There's no reason to use live after ready when it will run much faster before ready, and allow the user to start interacting.
The best way to understand .live() is to think of it as a declaration, like CSS. When you say: strong { color: red; } All strong elements are just red. You don't have to worry about the [flash of unstyled content](http://en.wikipedia.org/wiki/Flash_of_unstyled_content) or about what happens if you delete or add new strong elements later on. You've just declared strong to be red and the browser handles the rest. It's the same with .live(). If we did CSS the same way as typical JavaScript using .ready(), we'd ditch CSS and use this: $(document).ready(function(){ $('strong').css({color:'red'}); }); Think of how absurd it would be if we did *all* our CSS that way. That's why .ready() is ultimately braindead.
Unfortunately that is all most people know about them. It is most important to understand how live events work. They are very useful, but they can also slow down your pages, and not work as expected if you do not understand what exactly it is they are doing.
Ok I was mistaken there; fine. But why put the script on the top? Do you have any concrete examples?
It must have taken a good hour or two to write this code. Thanks for the effort! And thanks to github for hosting all of these wonderful snippets!
Agreed, although that can be generalized to any jQuery feature. And in my experience the performance risks associated with .ready() tend to be cumulatively worse than the ones with .live(). (of course YMMV) That said, .live() will probably remain a little-used and slightly mystical feature, just because it really does work in a radically different way than people are used to thinking about.
That is just good software right there.
I much prefer the jQuery getter/setter style. This is a square peg trying to fit in a round hole.
I don't think just because .live() works before the DOM is ready means that one should refrain from $(document).ready(). Like .bind() for example. I use the shortcut method nowadays: $(function() { //leet onReady code goes here });
Proxy is my friend's first foray into open source development... even if it's just a dip into the water, I'm pleased to see another programmer get wet.
Good luck to all programmers everywhere!
Yes, you definitely still need to use $(document).ready() for many things. Applying plugins comes to mind. The post isn't recommending that you avoid $(document).ready() altogether. It's just pointing out some places where you can gain performance by not using it when it's unnecessary.
To be clear, I *don't* recommend putting script at the top if it can be avoided, and definitely do not recommend moving script from bottom to top just to take advantage of the benefits described in the article. It's common for a page that depends on JavaScript to load it early though. Sometimes it's so that the page is responsive earlier (as in the reddit example; reddit would degrade it's overall usability during slow times if they moved scripts to the bottom). Other times, it's because partial views emit bits of JavaScript throughout the page. If you have a partial view that renders out a bit of JavaScript that depends on, say, jQuery, then you need to have included jQuery by then or you throw a JavaScript error. Script-heavy sites like GMail (or other GWT sites) really aren't a bad example either. The way those sites work, moving script to the bottom only makes the site effectively usable *slower*, and presents the user with a flash of unstyled content for no other than following the dogma of scripts at the bottom. Ultimately, there's no panacea. Both approaches are appropriate in different situations.
what
'#'+((r&lt;&lt;16)+(g&lt;&lt;8)+b).toString(16)
Why are people downvoting this?
Good question, though to be honest I do feel dickish posting it since the blog looks to be part of a string of tutorials.
why bother? both the code(posted by tunk) as well as that blogpost looks just fine to me..ppl with different level of experience will benefit from both
Awesome. I don't think I've ever actually seen bit shifting in use.
That's because bit shifting in Javascript is generally frowned upon, unlike most languages it's not advantageous over regular math, the double (which all numbers in javascript are) is converted to an integer, then the bitwise operation is performed, then converted back into a double.
I believe that they are comparing themselves to Closure Compiler's "Simple" mode rather than its "Advanced" mode. There is a tremendous difference in what Advanced mode can do (http://bolinfest.com/javascript/closure-compiler-vs-yui.html), so long as your code adheres to the restrictions of Advanced mode: http://code.google.com/closure/compiler/docs/limitations.html
Unfortunately looks like you are right, internally stored as double and converted to ints for bitwise operations. Though in some cases it is a lot faster than using string manipulation and math functions.
I find a lot of people drop these kinds of examples to show their programming badassness but don't realize that it sucks in javascript. Same goes for recursion in js as well. 
From what people with greater understanding than I have said it's a double and according to the ecmascript spec it seems to confirm that, now if browsers have implemented it otherwise I'm not sure. I agree that the speed difference would be negligible in any regard but personally I would side on the err of readability and just be verbose in my implementation using a similar solution to the article rather than saving a few bytes. Ps. This the same Tunk that used to play infantry?
Same one that aided the death hoax.
Cool, I R Unit92 :)
WTFS? Post on your blog and Ill believe it. Preferably about Yankee's latest feats in bed. Also I need a recent pic for the people at izone to jizz over.
I haven't posted on my blag in years. I should really just take it down. Here's a [sexy pic](http://imgur.com/bNEKs.jpg)
Definitely the man himself much improved. Or alternatively half the man you used to be.
On most modern JS JITs (except TraceMonkey), recursion is faster than iteration when performing say a b-tree traversal.
this
Ok, that's interesting, but why is this better than using the user agent string?
The user-agent string is unreliable, it can change for all sorts of reasons. Plus, varying responses based on that header can reduce your cache hit ratio.
Check for features, not for browsers.
As an aside, this won't actually work on IE8 in certain circumstances. IE8 claims to be IE7 in conditional comments whenever it is in "compatibility mode", which doesn't mean it behaves like IE7 with regard to things like security, etc.
Good point as well, although ideally if IE8 is in IE7 compatibility mode it should be identical to IE7 in all respects.
Unless working around a browser bug...
That's like telling somebody not to use tables. Yes, lots of people use browser detection when they should be using feature detection, but that doesn't mean that every single case of browser detection is wrong. For example, if you need to work around a bug in a particular version of Internet Explorer and it's not feasible to detect the bug itself, browser detection is the best option. Using feature detection in those cases is exactly the same mistake as using browser detection to decide which features to use; you're conflating implementation details and capabilities. 
 var jscript = 0/*@cc_on||@_jscript_version@*/ 
Because it doesn't produce real rgb values. Black should be #000000 but the code above produces #0.
But it isn't. For example, localStorage is undefined in IE7 compat mode, yet fully functioning in IE8.
More accurately, IE7 did not have localStorage, but it is in IE7 compatibility mode. That's why I said ideally :) There are some differences, but it's pretty rare overall. If you have an app built for IE7, it should run flawlessly in IE7 compat mode. Or, if the browser is in IE7 compat mode, it's pretty safe to treat it as IE7. The presence of localStorage shouldn't break apps. It's worth pointing out that the web developer can control the compatibility mode IE is in by doctypes and meta-tags, so if IE7 compatibility mode would break your app for whatever reason (like this version detection), just make sure you're running in the latest standards mode with a standards compliant doctype or meta tag.
I don't think a one-to-one mapping between JScript versions and Internet Explorer versions is guaranteed by Microsoft. I'm pretty sure installing some service packs or other software in the past has had the effect of bumping the JScript version without otherwise changing Internet Explorer.
&gt; I don't think a one-to-one mapping between JScript versions and Internet Explorer versions is guaranteed by Microsoft. You're right. The code above will only tell you the jscript version number. But conversely, just knowing the MSIE version number will not tell you about which jscript engine you are using. Sometimes you want to know the jscript engine (for code) and sometimes you want to know the MSIE version (for rendering). You also need to consider the document "mode": http://msdn.microsoft.com/en-us/library/cc196988\(VS.85\).aspx
I don't think it is either. Another problem is that IE8 in IE7 compat mode will still report 8 for the jscript version...
Ah, right, I thought you were suggesting it as a replacement for the linked technique. Yep, you're right, if you need to differentiate JScript versions, you shouldn't be using browser detection.
#0 will work in browsers as far back as ie6 Problem comes when you have a 0 red value but non zero green/blue or 0 red &amp; green, in that case you want to pad it to length.
looks cool but 1. doesnt work in IE8 (havent tried others) 2. no mouseover tooltips are showing up in FF3.6.8 although the code seems to show there should be some 3. how about some documentation or examples about how the json data looks
A voice of reason in a web standards debate? Who'da thunk it.
Meh.. script only.. [multi body hack](http://paulirish.com/2008/conditional-stylesheets-vs-css-hacks-answer-neither/) is better..
The point isn't that it's the perfect solution, the point is that the problem is so trivial it doesn't warrant a dedicated article. Even the non-bitshifting solution in the article is stupefyingly trivial. Anyone incapable of solving this problem should take a step back and learn about bases and base conversion before writing another line of code.
OK. Black is not the greatest example. I was just explaining why Tunk's code should be voted down.
You should have tested it more.
Finally! I've been wanting something like this forever. I've been having to use openlayers for awhile now and it kind of difficult to find easy to use basic layers for counties in the US or other countries. I like the easy API feel this has, very nice while allowing lots of control that you don't find in things like Google Vis, etc. Can't wait to play with this.
Here's a good example from the Closure Library where feature detection is not a practical option: goog.style.setPreWrap = function(el) { var style = el.style; if (goog.userAgent.IE &amp;&amp; !goog.userAgent.isVersion('8')) { style.whiteSpace = 'pre'; style.wordWrap = 'break-word'; } else if (goog.userAgent.GECKO) { style.whiteSpace = '-moz-pre-wrap'; } else if (goog.userAgent.OPERA) { style.whiteSpace = '-o-pre-wrap'; } else { style.whiteSpace = 'pre-wrap'; } }; 
The linked technique is effectively browser sniffing. Some people will bend over backwards rather than inspect the user agent string.
Thanks for the link settimeout! :-) @9jack9 Yes, I should have written this as a Gist... I was a lil' enthusiastic about using GitHub this first time. Plus, I was pushing myself to write some decent documentation. Anyway, Proxy *is* a "test" repository, and I'm using this experience to prepare for my next project. @yourparadigm I did go heavy with the "it's a getter/setter" thing, but that's not what Proxy is about. The g/s aspect is about controlling what external routines *can* do with your object - not how they do it. Still, did you mean jquery emulates native getters/setters, or that objects uses the same-name method approach for getting and setting (i.e. ".val()" and ".val(blah)")?
that's fairly clean.
About the UA unreliable argument. I realize that this can be changed to something arbitrary but when I tried doing so, calling my browser something like "Presto Gecko Opera WebKit Safari msie 6.0" or whatever, most of the web juts started breaking. My question is why should I bend over backwards for such people? (this was a few years ago) Other then for getting around stupidity where people block you based on UA string, is there any legitimate purpose for this? 
$25 an hour, shouldn't take more than an hour or two. PM me if you're interested, details would help too, like if you're using a framework like jQuery, etc.
Could you please explain the use of this and give an example usage?
I'm using jQuery but none of these plugins are loaded with jQuery. Right now I have the widget JS inline into the theme, and I'm using custom user profile fields via functions.php so I can plug in the usernames via user-profile-meta in the inline JS.
Just wanted to say, given what is known, sounds like a fair price/estimate.
[context-free grammar](http://en.wikipedia.org/wiki/Context-free_grammar)
How does this compare to OpenLayers?
When's your deadline? I might be up for it, but I can't guarantee I would be able to start, much less finish, before Monday (being the weekend and all). My bid is $25/hr, to match the other person's bid. I would have actually considered it doing it for free (for experience and the networking since I'm trying to get into freelancing) but I don't want to undercut fellow /r/js readers.
I think I have someone, although I'm not going to touch this thread until I get the results in... I could end up needing more help. Thanks everyone for the quick replies!
I think i can help you. Its not only that id like to do this in order to keep you in time with the project, i knoe pretty much jquery and would love to give a try on the solution. $20/h for me would be fair. Cheers. Email me to mciparelli@gmail.com
Yeah, it doesn't sound like much when it's presented in a technical way. Let me quickly show you why Jison is totally amazing. In a few words: Jison will generate a javascript parser for your programming language. That means you can parse the source code of an arbitrary* language (Java, C, javascript, brainfuck) in any browser - with that you can build an on-the-fly syntax checker or syntax highlighter - **without** having to make a quick ajax request every time the user stops typing. To see exactly what I'm talking about, hit "Try CoffeeScript" at the top of this page: http://jashkenas.github.com/coffee-script/ If you delete some characters from the end of the CoffeeScript code you will immediately see a syntax error. That message is coming from a Jison-generated parser for CoffeeScript running in your browser. And lucky for you, that parser is built from the most [beautifully literate code I have ever seen in my life](http://jashkenas.github.com/coffee-script/documentation/docs/grammar.html). * (an arbitrary language generated by a context-free grammar)
&gt;you can parse the source code of an arbitrary* language (Java, C, javascript, brainfuck) in any browser Why would I want to do that?
Did you check out the "Try CoffeeScript" interface? http://jashkenas.github.com/coffee-script/ An in-browser parser is necessary for online IDE-like tools to have real-time syntax checking. Tools like [Bespin](https://bespin.mozillalabs.com/), [IDEone](http://ideone.com/) or [codepad](http://codepad.org/) can't yet tell you whether your Java code is correctly formed.
Aren't there any off line tools for real-time syntax checking for most programming languages?
Not any web based tools that I'm aware of. Plus, most of those tools rely on some sort of compiler to compile the code and present the user with appropriate warnings/errors (think the compile time errors thrown by Eclipse/Visual Studio).
I did it!
Does anyone else giggle when they try to pronounce the project's name?
You're the only one[.](http://www.youtube.com/watch?v=bTzVagNHs4M)
seconded
That's what it's doing.
What's with the "Rock Star" term in recruitment posts these days? I've seen it quite a bit over the months. &gt; E. Viddal &amp; Associates is searching for a hard-core developer hard-core developer? Give me a break.
Yeah, it makes any job recruitment sound like porn.
Really. I mean, if there's a web development position that will get me groupies... show me the way.
Pure awesome.
Rock star postings always turn me off. According to the Dunning-Kruger effect, smart people may not have enough self-confidence to see themselves as rock-stars. Incompetent people may see themselves as rock star. My idea of a rock-star is John Resig. I don't know what good developers think. 
wow, I glanced at it and totally mis-understood what it was doing. My bad. 
Wrote the code and the RGBA demos several weeks ago. Wasn't really sure if there was actually some demand for this. Well, recently I learned there actually is. So, yea. Here it is. Hope it's of some use to someone here, too.
We appreciate your extensive marketing experience, personal likes/dislikes and criticisms, but they are not helping us find the right person. Go troll elsewhere.
I use a similar trick for caching tile sets, sprite sheets and terrain. I return a canvas object with its context attached though. In short the reason you want to use buffer canvases is: Its much faster for canvas -&gt; canvas copying over image -&gt; canvas or redrawing large amounts of stuff every time. A practical example of this is a 20x20 tile field (640x400) is currently rendering at 75fps in FF 3.6 on a three year old laptop in front of me.
OOoo, fankoo! I'm glad there's the rare kind of person like yourself that takes time to make articles like this. I had to trawl through FAR too many sites source code to find out how to do the following: http://www.untamed.co.uk/CanvasColouredCircles/canvasColouredCircles.htm Your article makes it much easier and quicker to understand, Thanks!
Between drinking, doing drugs, and screwing groupies, I play with Javascript. Contact my manager if you'd like more info.
Interesting idea, but where's the source code? Bug tracker? Unit tests? I see at least a couple of oversights there. Would be nice to see those fixed (if they aren't intentional, of course). (function(){ return arguments[1]; })(1, 'x'); // shows fun type as &lt;number | string&gt; (function(){ return 1 || 'x'; })(); // also shows fun type as &lt;number | string&gt; var f = function(){ return f; }; // shows fun type as "any", not "function"
In case you're interested... The RGBA demo: http://kaioa.com/k/ct/image_combine/index.html The game I mentioned: http://mbtic.com/ddd (stealthy work in progress, mind you)
It actually took less than a minute because there's nothing there.
Are you using IE6 or something? The site uses HTML5 `&lt;audio&gt;`.
I'm using Chrome. The content on that page was [created](http://imgur.com/JUQgH.png) some time [after](http://imgur.com/p34Bf.png) I posted my first comment. Did you listen to it before you submitted?
I am the author of the podcast, I inadvertently mucked with the created_at field which made it disappear for a second. It is fixed, would have been only noticeable for a short period. Should be fixed! Thanks!
Right here: http://github.com/pcwalton/jsctags
Yup, I listened to it. Was about 2 minutes long. :)
Also, to respond to the issues you reported: (function(){ return arguments[1]; })(1, 'x'); // shows fun type as &lt;number | string&gt; Arrays don't track the types of every one of their values separately, because that could be too computationally expensive. All the types get joined together. For example, the type of [ "foo", 1 ] is Array(&lt;number | string&gt;). At the moment, arguments is treated as any other array. (function(){ return 1 || 'x'; })(); // also shows fun type as &lt;number | string&gt; The analysis is not flow-sensitive. Flow-sensitive analyses tend to blow up in complexity. var f = function(){ return f; }; // shows fun type as "any", not "function" This one is actually a bug. Feel free to file :) 
That was more than a minute! I demand my money back. *edit: Also, [this submission](http://www.reddit.com/r/javascript/comments/d4a7r/javascript_the_doctor_is_in/) is related.
Even though it could be more precise, it's not actually a bug. When computing the type of f, the analysis works as follows: it sees that it's a function and tries to recursively find the return type, which is a function that returns a function and so on... So, when it finds a cycle while trying to compute the type, it'll give up and say "any".
More interesting would be a concise way to convert RGB to HSV.
CakeJS? http://glimr.rubyforge.org/cake/canvas.html 
We're setting up a Doctor JS category in Bugzilla. It should be up very soon. As soon as we've got it up I'll post back here and your feedback will be most welcome! Thanks, Dave
Bugzilla's configured for submitting Doctor JS bugs now. The Product is Mozilla Labs and the Component is Doctor JS. You can add a bug here: http://bit.ly/as4WZF or view all Doctor JS-related bugs here: http://bit.ly/aykfpQ Dave
so what *is* Doctor JS?
The main other option would be dojox.gfx, part of the dojo toolkit. It can run with SVG, canvas, or silverlight backends. There are other dojox libaries too for graphical drag and drop stuff. http://archive.dojotoolkit.org/nightly/dojotoolkit/dojox/ See this article for more on raphael vs. dojox.gfx: http://www.lrbabe.com/?p=217 Remember there is ExCanvas if you want IE support (pre-9) for a canvas-based solution instead. SVG won't work in android. I don't know of a 2D UI framework that runs inside canvas. Eventually someone will probably port some 3D opengl gui framework probably to webgl (3d canvas), like crazy eddie's gui. 
Nice :)
Feature request: have the envelope turn orangered actively upon new message.
Ooh, you were my first desktop-notified orangered. I'm guessing it's a limitation of the desktop notification API, but is there any way to have the notification--on click--take you to your reddit inbox?
Do you also pronounce Bison as Biz-on? If so you're doing it wrong.
You can use createHTMLNotification('url.html') to put HTML into a notification.
These are probably the best canvas games I've seen, but still pretty jumpy. Having tried to make a simple ball bouncing game with Canvas.... it's really just not up to the task. It's jumpy and anything not moving at a crawl blurs in a "ow my eyes!" kind of way because you can't move things you have to re-draw the entire canvas with the object in new location so there's no automatic interpolation between frames. flash and unity3d are still waaaaay better suited for animation/games at this point. 
let me guess- you were just passing the html in as a string? I was playing with webkit notifications a while back and tried to do that, getting increasingly frustrated with it, until I re-re-read the docs, heh. I didn't try it but I bet you could generate the HTML and then pass it into the function as a data: url. Or you could just host a "click here" html file on some webspace somewhere.
Patrick says this one is a bug: var f = function() { return f; }; // shows fun type as "any", not "function" But the comment is misleading; it's not actually a bug. The inferred type is: function() -&gt; any A more precise type would be an infinite type: function() -&gt; function() -&gt; function() -&gt; ... but infinite types like this aren't particularly helpful, and would be much more complex to infer. Similarly, if you did: var a = []; a[0] = a; The result from the analysis is Array, i.e., Array[any], rather than Array[Array[Array[Array[...]]]]. It's much cheaper computationally to break cycles by backing off to "any" and not really less useful. Dave
Are notifications still unable to be killed unless the user clicks them off? That is the only reason I don't use them in my apps.
Looks like Lisp to me...I'll keep looking for the kittehs though.
js2.. that reminded me of es4, and gave me a sad. :'( 
A+++++++++++++ WOULD FREELANCE AGAIN
Jumpy? Na, just bad programming. =) http://www.untamed.co.uk/canvasWorms/index.htm http://www.untamed.co.uk/CanvasColouredCircles/canvasColouredCircles.htm
Interesting. Can someone explain what this might be useful for beyond documentation or usage look-ups?
 var scrollbarWidth = window.innerWidth - document.width That will tell you if a scrollbar is present, but I'm not sure if that's the same on all browsers. You can also test if window.innerHeight is less than document.height, since that will always trigger a scrollbar unless you've disabled it through CSS.
window.innerWidth is the width of the viewport including scrollbars. document.documentElement.clientWidth is the width of the viewport not including scrollbars. Unfortunately Internet Explorer only supports the second. Would offsetLeft/offsetTop help with calculating the computed margin values? AFAIK getComputedStyle() doesn't help as IE just gives back 'auto'.
[Avoiding WWIII is just a matter of deciding to face reality and embrace sanity.](http://globalresearch.ca/index.php?context=va&amp;aid=20403) I'm sorry but I'm not surprised because I think that WikiLeaks is more or less controlled by the CIA or some group like it. The guy says 9/11 is a false conspiracy for starters. Also, look at the stuff he 'leaked'. I don't have the link but there are a lot of people saying this person may actually have been brainwashed or something. Take a look at this site http://www.globalresearch.ca and compare the stuff on there what is coming out of WikiLeaks. Please read redditquette and don't bury this if you disagree because then people won't even know there are people like me who don't think WikiLeaks is 'legit'. At least leave it with 1 point please.
What's the worst thing that could happen? Whenever you visit a website with JS, you are executing JS that somebody else wrote. I can almost hear the alarmist on talk radio saying that. It sounds dangerous, but consider that anybody already can put any kind of javascript on a page, as long as they own the page. How much damage can they do? They can't access a file system, they can't do much, really. The browser running javascript absolutely must provide an isolated environment for the security of the system it runs in. Clever hacking of actual defects, i.e. security holes aside, there's not much permanent damage that someone can do with straight JS source. But, and I mean big but, it would be trivially easy to mess up a page. There used to be guestbooks that allowed people to enter completely unfiltered text, that would accept javascript -- just because there was no filtration. I doubt many of those guestbooks have not been "bombed" by now. You're idea of using a safe subset is the right approach. However, I think it's going to be a bigger job than just having a 'whitelist' of allowable functions. If you allow your users to submit a function with parameters, that's one thing. But if you let them write things like loops, conditionals, and "real programming" stuff, your job has just gone ^2 or more in complexity. OTOH, creating a tiny interpreter can be a very worthwhile project if you have never done one before. Get an old Apple II and a FORTH interpreter and see how they work. When you know how to write an interpreter, the unicorns will let you ride them. 
It can prove a code path never executes, which is generally a bug.
When d.dE.offsetWidth/Height &lt; d.dE.scrollWidth/Height, a scrollbar is present, otherwise it is not. Works on all browsers. I use it to auto switch style sheets to the largest one that doesn't require scrolling.
It's a rewrite of Rhino in elisp by Steve Yeggie - [more details](http://steve-yegge.blogspot.com/2008/03/js2-mode-new-javascript-mode-for-emacs.html)
Neato.
Nice pattern. No need to apply it to Math.max though: Math.max.apply(Math, [1,2,3,4,5]) // =&gt; 5
 Math.max(5, 6, 7, 8, 99); ...already works. Math.max() isn't a "binary" function in JavaScript.
http://isgeolocationpartofhtml5.com/
Thanks. Updated.
 Math.max(1,2,3,4,5) // =&gt; 5 
Or, since you have just installed malware, that malware could just do exactly what your web browser does: send your IP address to a free public geo-location service such as Google. The web browser has nothing to do with this ability. Its always been there. Anyone with your IP address (e.g. every site you visit) can, without your consent or knowledge, figure out approximately where you are located, with varying degrees of accuracy.
Great. Now before I file a bug, quick question: I noticed that variable declaration w. function expression shows 2 "mappings", even though only 1 binding is created. Is this intentional? Given `var f = function(){}` as an input, I see 1: f : function() → void 1: f : function() → void
Exactly, if you read the first 3 steps in their supposed hole and are still afraid of holes in geolocation and not your own computer incompetence to install this malware then I give up.
do you have firebug open? are you seeing any errors in it? have all of the files loaded correctly? 
I'm not using it. A quick google search tells me firebug is something to do with Firefox, and I hadn't heard of firebug up till now. I use Safari and am on a Mac. For the website building I'm using TextMate.
If your page is on a server accessible to the world, could you post the link? You might want to check the following: * Is lightbox.css in the location referenced by the href attribute in the link tag? * Are the javascript files in the locations referenced by the src attribute in the script tags?
I would very strongly recommend gettinG fire fox and firebug if you plan on doing any amount of javascript. If there is an error in your javascript is will show you exactly where it is, it will also let you set breakpoint and step through your javascript. it will also show you if any of the files you are trying to use are having problems being loaded. http://getfirebug.com/
Thanks, I'll have a look into it and get back to you if there's any progress :)
It's all local at the moment I'm afraid. I still haven't shelled out for a host. &gt;Is lightbox.css in the location referenced by the href attribute in the link tag? Yep, I checked that several times. Looks like this at the moment: &lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt; &lt;html&gt; &lt;head&gt; &lt;link rel="stylesheet" href="style3.css" type="text/css"&gt; &lt;script type="text/javascript" src="js/prototype.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="js/scriptaculous.js?load=effects,builder"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="js/lightbox.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; I checked the folder names, they're all ok. They're also in the same folder as my .html and .css files. I pulled all the lightbox stuff out of the folder I downloaded them in though because otherwise it was just something else to reference to. It wasn't working before that either. The CSS looks like this: #left { width: 600px; background-color: transparent; float: left; } &lt;link rel="stylesheet" href="css/lightbox.css" type="text/css" media="screen" /&gt; #left h2 { letter-spacing:-12px; font-family: arial, verdana, serif; font-size: 100pt; font-weight: 600; text-align: left; padding: 5px 0 5px 0; color: #333333; background-color: transparent; } and I created a table for the images so that looks like this: &lt;div id="main"&gt; &lt;div id="left"&gt; &lt;h2&gt;GALLERY&lt;/h2&gt; &lt;br&gt; &lt;table border="0" align="center" width="70%"&gt; &lt;caption&gt;Picture Gallery&lt;/caption&gt; &lt;tr&gt; &lt;td&gt; &lt;a href="images/red-dress-2.jpg" rel="lightbox" target="_blank"&gt; &lt;img src="images/red-dress-2thumb.jpg" alt="Resized JPEG graphic" title="Click to view" border="0" width="100" height="100" hspace="10" /&gt;&lt;/a&gt; &lt;/td&gt; &lt;td&gt;&lt;a href="images/red-dress-2.jpg" rel="lightbox" target="_blank"&gt; &lt;img src="images/red-dress-2thumb.jpg" alt="Resized JPEG graphic" title="Click to view" border="0" width="100" height="100" hspace="10" /&gt;&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;a href="images/red-dress-2.jpg" rel="lightbox" target="_blank"&gt; &lt;img src="images/red-dress-2thumb.jpg" alt="Resized JPEG graphic" title="Click to view" border="0" width="100" height="100" hspace="10" /&gt;&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href="images/red-dress-2.jpg" rel="lightbox" target="_blank"&gt; &lt;img src="images/red-dress-2thumb.jpg" alt="Resized JPEG graphic" title="Click to view" border="0" width="100" height="100" hspace="10" /&gt;&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;a href="images/red-dress-2.jpg" rel="lightbox" target="_blank"&gt; &lt;img src="images/red-dress-2thumb.jpg" alt="Resized JPEG graphic" title="Click to view" border="0" width="100" height="100" hspace="10" /&gt;&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;a href="images/red-dress-2.jpg" rel="lightbox" target="_blank"&gt; &lt;img src="images/red-dress-2thumb.jpg" alt="Resized JPEG graphic" title="Click to view" border="0" width="100" height="100" hspace="10" /&gt;&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &gt;Are the javascript files in the locations referenced by the src attribute in the script tags? I think so, should be in the code above. 
I believe Safari includes WebKit's inspector. I'm not a Mac user, but I would guess you can open the inspector by going to Tools &gt; Inspector, or pulling up the context menu on the webpage and selecting Inspector. WebKit's inspector is just as versatile as FireBug (and better, IMHO).
Can you tell me the structure of your directory?
This is the type of problem that Raymond Chen talks about in his [It rather involved being on the other side of this airtight hatchway](http://blogs.msdn.com/search/SearchResults.aspx?q=airtight%20hatchway&amp;sections=2905) series.
I just noticed something: it looks like you have a link element in your css: &gt; The CSS looks like this: &gt; left { &gt; &gt; width: 600px; background-color: transparent; float: left; } &gt; &gt; &lt;link rel="stylesheet" href="css/lightbox.css" type="text/css" media="screen" /&gt; &gt; left h2 { &gt; &gt; letter-spacing:-12px; font-family: arial, verdana, serif; font-size: 100pt; font-weight: 600; text-align: left; padding: 5px 0 5px 0; color: #333333; background-color: transparent; } The link element should not be inside of a css file, or a style element. That should be directory in your html page (probably above the style3.css link element). Maybe this will help.
Right now the folder is located on my desktop, and is called "Photography Website". Everything is in there. 5 html files (one for each page), 3 css stylesheets and the lightbox stuff I downloaded. Folders for lightbox are called css, images2, js and something called index.htm (basically a read me for the lightbox which I find confusing). There's also another folder called "images" which I'm using to hold other images for the site including the ones for the gallery. It was there before the lightbox got downloaded. Should I move the images for use with lightbox from "images" to "images2"? I hope that's structured enough, if it's not then it kinda looks like this: home page.html -&gt; style.css bio.html -&gt; style2.css portfolio.html -&gt; style3.css blog.html -&gt; style2.css contact.html -&gt; style.css Arrows indicate what the html file is looking at. Lightbox just kinda hangs around in the "Photography Website" folder.
You need to enable it with production safari. Safari menu option -&gt; preferences -&gt; advanced -&gt; Show Develop menu in menu bar Then it will be accessible
It sounds like your directory structure is fine. See my other comment regarding the link element and let me know if what I am seeing is accurate.
!! YAY! It worked! Thank you so much! I've been toying with this for **hours** and I've not gotten it to work. It works perfectly now! Awesome! Thanks again! The only thing that appears to be wrong though is that the next, preview and close buttons aren't showing up. It does everything else though.
Cool. Good to know. I will hopefully be getting a Mac soon, and my understanding is that native Cocoa apps have cool builtin tools, like dictionary entries based on highlighted text.
Excellent! &gt; The only thing that appears to be wrong though is that the next, preview and close buttons aren't showing up Double check that the urls are correct in lightbox.css (just do a search in TextMate for the word **url**). They are probably hardcoded in there.
lightbox.css looks like this: #lightbox{ position: absolute; left: 0; width: 100%; z-index: 100; text-align: center; line-height: 0;} #lightbox img{ width: auto; height: auto;} #lightbox a img{ border: none; } #outerImageContainer{ position: relative; background-color: #fff; width: 250px; height: 250px; margin: 0 auto; } #imageContainer{ padding: 10px; } #loading{ position: absolute; top: 40%; left: 0%; height: 25%; width: 100%; text-align: center; line-height: 0; } #hoverNav{ position: absolute; top: 0; left: 0; height: 100%; width: 100%; z-index: 10; } #imageContainer&gt;#hoverNav{ left: 0;} #hoverNav a{ outline: none;} #prevLink, #nextLink{ width: 49%; height: 100%; background-image: url(data:image/gif;base64,AAAA); /* Trick IE into showing hover */ display: block; } #prevLink { left: 0; float: left;} #nextLink { right: 0; float: right;} #prevLink:hover, #prevLink:visited:hover { background: url(../images/prevlabel.gif) left 15% no-repeat; } #nextLink:hover, #nextLink:visited:hover { background: url(../images/nextlabel.gif) right 15% no-repeat; } #imageDataContainer{ font: 10px Verdana, Helvetica, sans-serif; background-color: #fff; margin: 0 auto; line-height: 1.4em; overflow: auto; width: 100% ; } #imageData{ padding:0 10px; color: #666; } #imageData #imageDetails{ width: 70%; float: left; text-align: left; } #imageData #caption{ font-weight: bold; } #imageData #numberDisplay{ display: block; clear: left; padding-bottom: 1.0em; } #imageData #bottomNavClose{ width: 66px; float: right; padding-bottom: 0.7em; outline: none;} #overlay{ position: absolute; top: 0; left: 0; z-index: 90; width: 100%; height: 500px; background-color: #000; } I'm figuring I need to alter this? #prevLink:hover, #prevLink:visited:hover { background: url(../images/prevlabel.gif) left 15% no-repeat; } #nextLink:hover, #nextLink:visited:hover { background: url(../images/nextlabel.gif) right 15% no-repeat; }
I think you will want to change the last two lines to: prevLink:hover, #prevLink:visited:hover { background: url(images/prevlabel.gif) left 15% no-repeat; } nextLink:hover, #nextLink:visited:hover { background: url(images/nextlabel.gif) right 15% no-repeat; } 
I'm not sure what you mean. I pulled the last two lines out of the code thinking I might have to change them. The ones you've quoted there are the same :S
Aah I was wondering how. I couldn't find it. Ta :)
I should restate what I was trying to say. It looks like lightbox.css is looking for the images one directory higher than where they really are. So, where you see "../images", try changing it to just "images" (i.e., remove the "../").
Oh right, sorry. I missed that...now I see they weren't the same at all. Sorry. Just changed that, and changed it to say images2 rather than images, since that's the folder those pictures are in. They still don't show up though for some odd reason. I'm not sure if the next and previous buttons are meant to show up with this layout, but the close button should. It's also located in images2.
To be on the safe side, try putting just a "/" before images2.
Ok, done that, saved it, still nothing. Just got that little blue box with a question mark in it. Functions as a close button but doesn't look like one.
Thank you!
thanks!
I love how the browsers can't seem to agree on anything...
I'm not sure what to tell you at this point. Make sure that the images are readable by all users, and make sure that the urls in the css file are correct. Other than that, I can't say much else.
Ok. Thanks for all your help though, you've really catapulted my progress further. I'm guessing it's a fairly common problem. Something I've noticed though is that those two lines of code we've been looking at relate to the next and previous buttons/icons though and not the close icon. I can't find anything that points to using the close icon anywhere in lightbox.css The white box that appears also does that little "expand before showing the image" thing the first time it's clicked, but not the subsequent times. I have to refresh the browser at that point if I want it to do it again. Any advice there or should I go hunting again? :)
&gt; Ok. Thanks for all your help though, you've really catapulted my progress further. No problem! &gt; I'm guessing it's a fairly common problem. Something I've noticed though is that those two lines of code we've been looking at relate to the next and previous buttons/icons though and not the close icon. I can't find anything that points to using the close icon anywhere in lightbox.css You need to change lines 49 and 50 of lightbox.js to point to the correct directory &gt; The white box that appears also does that little "expand before showing the image" thing the first time it's clicked, but not the subsequent times. I have to refresh the browser at that point if I want it to do it again. Any advice there or should I go hunting again? :) I'm not really sure what you mean here. Good luck!
&gt;You need to change lines 49 and 50 of lightbox.js to point to the correct directory Awesome, just did it, can now see the close icon :) Thanks, you've been awesome at helping me with this. &gt;I'm not really sure what you mean here. [Here's an example.](http://www.huddletogether.com/projects/lightbox2/) Click one of the single images and watch the white box it appears in. I *think* it'll show the same animation even if you're not using Safari. Thing is, instead of expanding/stretching every time like that, it just appears straight away on the second and subsequent clicks on the same and different images. I'm currently searching through the script to see if there's something causing it.
I found this in the script, it looks like what I need to fiddle with. Basically, after clicking one image and closing the box that appears over the page, clicking another image or the same image makes lightbox act as though animations are turned off when they're not meant to be. The only way to rectify this is to refresh the page. initialize: function() { this.updateImageList(); this.keyboardAction = this.keyboardAction.bindAsEventListener(this); if (LightboxOptions.resizeSpeed &gt; 10) LightboxOptions.resizeSpeed = 10; if (LightboxOptions.resizeSpeed &lt; 1) LightboxOptions.resizeSpeed = 1; this.resizeDuration = LightboxOptions.animate ? ((11 - LightboxOptions.resizeSpeed) * 0.15) : 0; this.overlayDuration = LightboxOptions.animate ? 0.2 : 0; // shadow fade in/out duration // When Lightbox starts it will resize itself from 250 by 250 to the current image dimension. // If animations are turned off, it will be hidden as to prevent a flicker of a // white 250 by 250 box. var size = (LightboxOptions.animate ? 250 : 1) + 'px';
Just make it look weird in IE? Not always an option but maybe.
Safari is capable of all of this as well, without any addons. You just have to turn on the Developer menu in the preferences to access it.
Protip: If you've got a block of code you want to paste into reddit, press command-] in TextMate to indent it one tab before you copy it. Reddit will interpret that as being code and apply the correct formatting.
Did I say kittens? I meant Rhinos.
I left it for a while and then came back to it and played around with things a bit more with fresh eyes. There's nothing wrong with the code/script, I was overlooking something silly. I was using the same image over and over again, and since the image had already loaded once I can only assume it didn't think it was necessary to animate from 250 x 250 all over again for some reason. So, after using another image that was a different size, I found the animation works just fine and it was me being a n00b again. Thanks! I'm so happy it's working, you've been such a great help to me :)
firebug is a far better tool, i'd switch to chrome or safari for speed alone if it wasn't for firebug.
&gt; Right, but 9jack9 was showing how to get the max out of an Array of arbitrary length. That's different than passing a fixed number of arguments to Math.max(). A lot of novice/intermediate JS programmers don't know about Function.apply. What's Function.apply? I know about Function.prototype.apply... :p
The analysis will find types for variables and functions. In your example, one mapping refers to the variable f and the other to the function. Even though the function is anonymous, we have a heuristic to give it the name f (the same would happen e.g. when you have an obj literal {f : function() {...} }. So, DrJS will produce one tag for the variable and a separate tag for the function. The variable and the function just happen to have the same name.
Using === is to ensure the values you're checking are exactly what you expect them to be. Using === all the time over a mish mash of == and === makes code more maintainable, the performance hit for using === over == is negligible and better optimizations can be made in other places. 
CodeFaces is a web-based source control client that targets at easing the pain of navigating codes on a browser. We are veteran programmers who read thousands of lines of codes everyday and we know how sucky most source control system’s web interfaces are! We are dreaming of a web-based tool that makes our experiences of reading codes on the web smooth and enjoyable. Here we came up with CodeFaces. Follow us (@CodeFaces) and help us spread the words! 
Im well versed in firebug and honestly webkit's inspector in chrome or safari does 99% of the things I need in firebug. Right now I keep firefox installed for those rare instances I do need firebug, but I'm really happy with the web inspector.
Sepia Tone produces nasty HSV overflow or underflow errors - splotches of primary and secondary color. 
It doesn't sound like it was too difficult for them. It seems like they went with; if not implementing it will break existing web pages, we will do it, if not, we don't give a fuck about it. 
http://bu4.taipudex.com/pinyin.htm
"How do we decide whether to implement a feature that isn’t included in a standards specification?" This is another bullshit blog from m$; simple answers .. * because it does not advance our monopoly or * its does not f** up the competitors * we cant implemet it Happily all my applications are webbased and the "backend" has a huge &lt;blink&gt;SECURITY RISK, THIS SITE IS INCOMPATIBLE AS m$ DOES NOT DO STANDARDS, YOUR ADDRESS HAS BEEN REGISTERED AND REPORTED&lt;/blink&gt; warning.. in huge letters.. 
Sounds a little bit like the behavior of dmenu
Might want to make the backspace key do the same thing as the left arrow key. It's more natural.
It should work this way, and Pos1 jumps to the intial menu.
That regex thing... they are probably to blame for that. `javascript:alert(/]/.test(']'))` Alerts "true" in IE6.
Great, another fucking problem from Redmond 
With 50%+ in market share, I think IE should NOT append to specs and should NOT forgive bad code (e.g. that regex). IE should break websites that deserve it and redirect the users to meatspin.com. That would force the site developers to quit being stupid. And then everyone wins.
I don't think you understand how it works...
It returns true in all current browsers, you probably need to find a browser from about 10 or 15 years ago to determine who was first to ship it
Why do these IE devs completely ignore the standard's recommendation &gt;It is recommended that ECMAScript implementations [..] issue a warning when such a usage is encountered and then see how quick those non-compliant issues get resolved.
I'm not terribly knowledgeable with JavaScript but this sounds really fucking cool.
[JavaScript: The Good Parts](http://www.amazon.com/JavaScript-Good-Parts-Douglas-Crockford/dp/0596517742/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1282992625&amp;sr=8-1) is also highly recommended,
Im sure that being some what abusive on reddit will help your nobel cause. :/
associated [blog post](http://www.puremango.co.uk/2010/08/writing-a-javascript-app-in-10k-aea10k-part-one/).
This is going to really kick ass with Firefox's Direct2D acceleration. 
Wow, what an interesting idea. I may mess around with this when I get some spare time.
On one hand, I hate twitter. On the other hand, this idea seems so cool that I *really* want to play with it.
Wrong subreddit.
Yeah, I've forked a few running websites in my time. Completely forked. Had to restore from back up. I've also borked a few as well.
His output is pretty similar to [Dean Edward's packer](http://dean.edwards.name/packer/)
I don't do Twitter. Can you explain the concept? 
Very interesting! Sadly this compression scheme will tend to decrease in effectiveness as the original code grows.
I usually like sitepoint articles, but IMHO you should have held off on publishing this one and instead included this information on tomorrow's article. Too much fluff in this one.
What exactly do you mean by "forked a website"? 
appears to be down
Using the Advanced mode of the Closure Compiler would accomplish Step 2 while also providing static checking. In practice, Step 3 is generally accomplished by gzip.
Since Step 3 states that it's utterly useless except for demo competitions like js1k and the like, and since whoever reads your comment won't know that, unless he has read the article, but since you've clearly read the article, since you know about Step 3, your comment is utterly void of any purpose. Here, have an upvote.
Github has public repositories, which allow you to fork them (make your own copy) make changes and do as you wish. So the author means, he downloaded the source to this site, and hosted his own version (maybe local for dev purposes who knows.) http://github.com/cramforce/streamie
http://s1.b3ta.com/host/creative/29424/1280172144/knifeforkspoon.gif
Users can fork the site on Github, push them to their Github-Pages site and then access them via GITHUB_USERNAME.streamie.org (via a reverse proxy) with full access to the backend API of that site (which basically means you can access twitter without worrying about OAuth)
A fair point, but it would have become a very long article. The first post reported that the Closure Compiler REST API was available - it can be called from any language. The second post tells you how you can specifically use it with PHP (http://is.gd/eMX5p). That wouldn't be applicable to many developers - it would have been a shame if they missed news about the CC API thinking it was for PHP only.
This sounds like a huge PITA. Use fewer variables by breaking monster functions into several smaller more manageable functions.
Really? No prototype/scriptaculous? 
Agreed. All credit to the [S] for taking the time to figure this out and post the solution but this kind thing is a sign not of an interesting problem to solve but an architecture failure to rework.
They say you can request that a library be [added](http://cachedcommons.org/readme) I'm sure that others would be happy to see prototype and scriptaculous hosted through the CDN *edit: fixed broken link
I can understand being bummed they didn't have those already, but as f0ad points out, you can request anything you want. jQuery has pretty much become the standard, to the joy of some and the chagrin of others... so I imagine they hosted that one based on its popularity, not as an intentional slight to other libraries...
Why should we trust them to keep maintain a reasonable uptime and keep their servers secure? I realize it's more convenient, but I'm not sure I would put so much trust in something like this. If for whatever reason I needed my scripts hosted on a CDN, I would go directly to a CDN provider to host them or just use google-hosted scripts.
GitHub themselves use jQuery. I suspect that is why it's the major library set on the CDN.
They host a lot more than google does, and it's github, which I'd say is pretty trustworthy so far... I do understand your point, don't get me wrong... I just think it's probably not a big worry to most people... github may not be google, but it's solid.
I didn't realize webOS used Java. I thought the whole hubbub about that platform was that native apps were written in JS.
Wow this is brilliant! Is there any place to host our own JS code to be CDN hosted?
Could you explain "it's github"? I couldn't find any explanation on the site besides "Github Pages can be used as a CDN" which I don't understand.
Everybody is not using your CDN, that's the difference. They will already have a cached copy.
Free hosting is not the point. The point of a CDN hosted file is that a user will come to my site, download the file from the CND link, then go to your site and they will not have to download it as they have already got a cached copy from that url. It's not just a fast host, it's the same host. Hosting your own scripts will not really benefit in this way unless everybody is using your script.
True. But I thought CDN hosted also meant that scripts are hosted at various places around the world and the closest one is chosen for less latency.
True, but from the best I gather this new update will make it possible to run websites.. in the browser.. as apps?
that's also an advantage of CDN. There's Amazon CloudFront if you want a reliable CDN that's cheaper than Akamai: http://aws.amazon.com/cloudfront/
A few background daemons were using Java. The front-end applications were all still written in JavaScript. (E.g. the default Mail application is written in JavaScript, the source even comes with the free SDK, however I'm pretty sure the services it utilizes are provided by Java daemons).
No? Node.js just makes it so one can write daemons/system services in JavaScript (instead of the old Java ones which were never officially exposed and the newer official C/C++). Web applications will still run in the browser as they always have on the Pre, only there will likely be improvements to touch even support (given Palm is a sponsor of jQuery *Mobile*) and other HTML5 goody updates. *edit:* I'm dumb, jQuery *MOBILE* not jQuery *touch*.
&gt; Palm is a sponsor of jQuery touch Not quite, Palm is sponsoring http://jquerymobile.com/ , not jqtouch -- which is apparently now subsumed by Sencha touch? It's hard to keep track of it all.
I am consumed by js1k as well (even though the site atm seems to be down) I don't have the patience to make something in 140 bytes though lol but somehow I do to make something under 1k :P. Nice job on your latest entry.
thanks :) I just found a new way to get the canvas, saving 1 byte in the process: `document.body.children.c` instead of `document.body.children[0]` :0) I just added a new tweet-sized demo with that trick and some other cool stuff.
Good point, that's what I meant but naturally not what I said :P
I just did d.getElementById("c"), i might try your way. I use the document a few times so i just did d=document, but d.body.children.c is still a tad smaller than what I have now.
the code is open source so feel free to chip in or give some feedback. [screenshot here](http://imgur.com/zte28.jpg) for the just curious
This is absolutely awesome. Thanks a lot! :)
Would be great to detect reddit links/submissions and add up/down arrows to the view; maybe even "just" the whole of reddit toolbar (which includes those of course, and more)..
yeah, if you need document elsewhere it's probably not worth it. either .body.children[0] or .body.children.c is smaller than .getElementById("c") though.
Fantastic. Good work!
This might be pretty interesting for a physic game.
Indeed :)
 document.all['c'] or, document.all.c document.all is deprecated, but works in all browsers I tested. (firefox, opera, chrome). I checked a lot of the other entries, and I seem to be the only one using it so far....but I'll share my secret :-) 
There's quite a lot someone can do, actually. For example, post javascript that attempts to hit a popular bank site. If a lot of users get your javascript, odds aren't bad that one of them will be logged into an account there, and you can cause them all sorts of trouble. This is a pretty [common attack](http://en.wikipedia.org/wiki/Cross-site_scripting).
node.js is supposed to be pretty fast and load-friendly. It's a very fast webserver written in C, running Google's javascript engine which is way faster than, say, Ruby. And of course it has no trouble at all with gobs of long connections, which sounds like it could be a consideration for this app. Not sure how much DOM emulation he really needs, since he's mainly dealing with Canvas....or what risk there might be in running user-submitted code in node. Your project looks pretty cool!
I've done physics like this many times over the years and never thought of tinting the constraints to show stress. Added to the playbook, thanks.
Neat, but canvas animation is still blurry and jumpy. Still needs some improvement before I'll use it over flash. 
They've also got a lot of good stuff here: [http://vision-media.ca/resources](http://vision-media.ca/resources)
It's perfectly smooth over here, even in FF. What OS/Browser/GFX/CPU do you use?
ooh, clever!
I'll look into that but I'm pretty sure it can't be done when viewing a page outside of reddit..
thank you!
internet explorer user?
now now, go easy on the insults :)
nice! upvoted
Latest FF. Chrome does the same thing for me though... running a P4 with 4 GB. I get a shutter every few seconds (perhaps video card related I guess... does it even use acceleration though?), and there's no interpolation between movement (this is a defect of the canvas design imho) so things moving still appear blurry unless they move pretty damn slow or there's a lot going on so you don't notice it. That's not to say that it doesn't have it's uses... it's very useful in certain areas. But I just don't see the canvas object taking anything away from flash or unity3d as far as games go... it's just way too limited for that. 
Well, I've clocked it at 30 fps. On my box rendering one frame takes about 6ms while the physics take up 0.05ms. If your box isn't capable of delivering at that speed, it would look bad of course. Though again, I don't have the issues you speak of. Sure if something would move very fast, you'd see it hopping around. But it's not like Flash would render at 80fps either, not for games anyway. That canvas insists on immediat mode drawing *is* a disadvantage. But that's only intermediary. WebGL does have retained mode drawing and graphics shaders. So just wait for ctx = canvas.getContext('3d'); :)
Tried on Windows XP: * Firefox 3.6.4 - Was a little choppy * Chrome 5.0.375.99 beta - ran wonderfully * Internet Explorer 7 - throws MANY script errors (I have full debugging enabled at work), and eventually starts to play in this "JW Flash Video Player", which clearly isn't the idea, but I don't know if you defaulted to this if HTML5 didn't work or IE did.
That it pretty sweet, well done. It causes a shit-ton of errors in IE, but that's IE for you.
I'll have to try it at home I guess, I had been playing with canvas at work but these work computes suck :( Is adding webGL into the mix on the roadmap? I didn't know that, cool :)
Thank you, what version of IE do you use please ? 
Well, the ultimate goal is to have the media content available one way or another to the end user. So yes, the fallback to JW Flash Video player was expected! I'll be gratefull if you could forward to me the complete javascript error trace from your IE7. If it's possible and if you are whiling to send it to me of course. Thank you for your feedback :)
Ah, sorry I tried to edit my message to add that, but it kept failing, it is IE 8/windows 7
Thanks! I guess I'll have to find a Terminal server somewhere to debug that. 
I can tell you the problem is here: function __flash__addCallback(instance, name) { instance[name] = function () { return eval(instance.CallFunction("&lt;invoke name=\""+name+"\" returntype=\"javascript\"&gt;" + __flash__argumentsToXML(arguments,0) + "&lt;/invoke&gt;")); } } And it says: Object does not support method or property. 
This is what happens when I enter fullscreen in FF 3.6.8 XP http://imgur.com/FnELY.jpg 
Are you sure? I do not recognize this piece of code as a part of my library.
Well this is my bad. The fullscreen mode behaves like this on any platform. /blush
internet explorer 8.0.7600.16385 running wonderfully :) in flash chrome :) html 5 :) running nice, opena nice firefox... choppy 
Thank you! Would you kindly precise your OS version please?
Probably wont help, but here is the full output from the IE developer console: http://paste2.org/p/973057
That helped, I blindly used Array methods *map* and *filter*. Sadly, these are not supported by IE's JScript implementation. Many thanks for the logs, I'm creating a new issue in the [bug tracker](http://code.google.com/p/html5-media/issues/list).
Ran smoothly on my Ubuntu Lucid Lynx (10.04 LTS) Google Chrome: 5.0.375.125 Nice demo-video selection by the way. Good of you to spread the word about the Durian project through this. The only possible critique I can think of is maybe the styling. I don't like the big blue play button too much. Include a themes option in the future, perhaps? But that's just nitpicking... Looks good... Great work ncrovatti!
Cheering is gladly welcomed also! Thank you c0balt279! The play button is not part of the player itself. I could write some different themes, that's a good idea!
Says NaN on the time at the beginning. When video is loaded up the time is displayed correctly. Set it to 00:00 on load. Safari5/Mac
I will never understand why authors put their terrible mug shots next to articles. 
In Chrome 5 I could only play the video once. If I wanted to play it again I had to refresh the page, otherwise nothing happened. Have you considered switching the positions of the volume control and the timer display? It seems more logical that the timer be next to the pause/play button. Also, draggable control for the volume would be nice, it is a lot easier to find your desired volume without clicking around and guessing.
Really awesome, do I smell possibly a different js1k submission?
This is all sorts of badass, though it conflicts just a bit with some of the stuff that Reddit Enhancement Suite does... I wonder if you'd consider allowing me to add this to Reddit Enhancement Suite, and adjusting to make it play nicely with it? RES is free. [link to RES](http://reddit.honestbleeps.com/)
Thanks. You have my permission to do anything you like with it as long as you respect its open-source license. Is RES open-sourced? I did see RES at some point before but since I don't use greasemonkey I did not know how it works or what it does. Viewably is not just for Reddit - actually the only thing specifically relating to reddit is the (r) link which just searches reddit for the item you are viewing.
Thank you thank you, for not using the big buck bunny trailer. That randy Newman-esque music is literally going to drive me insane one of these days. (I've been researching html5 media players lately, and that video is everywhere)
I tried in on Chrome 5.0.375.127 on Windows XP. I like the overall look, the button design. The functionality seems a bit spotty. I could click on the volume bar to change the volume, but I couldn't drag to slide the volume (which was my first instinct, developed with other flash based and standalone players). With the video paused, clicking on the video position bar would jump the video to that point and start it playing. It seemed to me wrong that it should automatically start playing in that case. The video bar is also not draggable, counter to my expectations. Using the keyboard space bar to start/stop video playback doesn't work (this is common in other media players). Letting the video play to the end, did not quite bring the video position bar to the end. There was still a few pixel's width of white visible to the right of the blue bar. After the video had finished playing, the pause button reverted correctly to the play button, but clicking the play button did not restart the video. Clicking the video position bar to jump backwards while the video was playing didn't work reliably. The bar would jump back to the clicked position, the video frame would flash, then flip back to the previous playing position as the video continued to play from the original time (i.e. it wouldn't complete the jump back). Not sure if this is a browser or player bug. After doing this several times, the video came out of sync with the audio. Then, after clicking several more times the pause/play &amp; other controls became unresponsive. 
pentium 4?? they introduced core 2 in 2006. http://en.wikipedia.org/wiki/Intel_Core_2
The first of 154,343 'media players' to be 'written' and adopt exceedingly cute names, which are really just window decorations and extraneous features tacked on to the built-in &lt;audio&gt; or &lt;video&gt; tags that allow you to absorb partial credit for all the work that was done to actually code audio and video. Its MP3 players all over again. You made your own jQuery? Brilliant. Just use the controls="controls" attribute. &lt;video width="480" height="267" controls="controls" durationHint="33" poster="http://cdn.kaltura.org/apis/html5lib/kplayer-examples/media/bbb480.jpg" &gt; &lt;source src="http://cdn.kaltura.org/apis/html5lib/kplayer-examples/media/bbb_trailer_iphone.m4v"/&gt; &lt;source src="http://cdn.kaltura.org/apis/html5lib/kplayer-examples/media/bbb400p.ogv" /&gt; &lt;/video&gt; Someone should tell the Firefox and WebKit developers we need to be able to style the controls with CSS. Anyway, fuck you and everyone who comes after you. I have a special subreddit for you. http://www.reddit.com/r/fuckyouall
lmao... I know. I have a core 2 quad at home but work won't give me a new one (I actually have 5 of these things). I would just take one of the rack-servers and make that my desktop if I didn't have this one configured exactly how I want with everything already installed. 
Dude not to rip on your or anything. But it's a wee bit "funny" to come in and say "oh canvas won't do any good, too slow" while at the same time using a computer that was modern 10 years ago. Sure canvas isn't as fast as flash is, but computers got faster, like, in the last 10 years. It's a bit like if it was the 1990ties and Doom1 just came out, and you're like trying it out on your 286 and complain "nah, that doom thing, no use, much too slow, I'll stick to Alone in the Dark".
I never said it wouldn't do any good. I simply said I would currently stick with flash etc for the time being as canvas still has a few issues in my experience. I still use it for graphing, I still use it for playing, but for a real game or animation I found it too limited. Just my $0.02, take it for what it's worth. Besides, a P4 is still pretty fucking fast compared to my 100Mhz PI I had windows 95 on. The thing does billions of calcs a second. I mean, why would you want to use a technology that is so horribly slow and bloated that it can't work on a P4? I mean besides Windows ;) Regardless, I doubt it was the CPU... it was more likely the shitty dell video card assuming canvas offloads processing to the GPU (it does right??)
I can't even begin to unravel that tangle of misconceptions, where should I start? First of all, most modern flash games won't run good on your 10 year old pc, or so I strongly suspect. Second, there's plenty of software that won't run well on a pentium4. And it's not just because it's crap. It's because people enjoy the extra functionality those programs manage even though they use more computer resources. And speaking of crap, sure canvas isn't as fast as flash. But that's not much to do with there being any amount of bloat. It's a new technology, implementations of it vary, but speed does improve all the time. Speaking of bloat. What do you think has more bloat? A 15 year old proprietary vector graphics tweener, maintained and distributed by a proprietary company, or any of the 2 or 3 opensource implementations of canvas that where written from scratch in the last 3 or so years? Much the same criticism as is levied against canvas has been levied against Javascript. Too slow, actionscript is faster, no debugging tool, design by comitee, fractured standard, won't go anywhere, yadda yadda yadda. Look what happened, in just a few years we got excellent debuggers, clean and fast implementations of javascript, and if you're doing webapps, you're probably using tons of it. Pretty much any advancment of web standards has been loudly greeted by a fanfare of naysayers. I know, I was one of them. But the whole circus keeps moving forward, sometimes slowly, but forward, and I stopped laughing and took notice of a platform that doesn't back down.
Thanks! Yes, RES is open source... I don't have it somewhere like github or anything like that, but people are free to do what they like with it. It's javascript, I couldn't close-source it even if I wanted to (which I don't :-))...
&gt; First of all, most modern flash games won't run good on your 10 year old pc, or so I strongly suspect. I play both those, and unity3d games (a co-working makes them for fun). &gt; Second, there's plenty of software that won't run well on a pentium4 Sure, but that's serious graphics intensive stuff, not little games inside the browser. The rest of your post is a rant... you need to relax. I'm not insulting Canvas, and a few constructive criticisms should not be met with a rant about how a P4 is too slow and my computer is shit and I'm just a naysayer. 
meh I've made things that seem to perform well and look as good as any flash game. (well I'm talking about one game currently in production) anyway, your points are moot because IE the last holdout is even moving forward and has some impressive JS speeds, so really i see nothing standing in the way of canvas. BTW its not Canvas that is slow, its whatever's browsers underlying JS engine your using. Most are starting to support HW rendering rather than software which shows even more speed increases. Try his example in Chrome , Opera, or FF4 beta and I bet itll perform better
Firefox nightly (Gecko 20100901) on Gentoo Linux x64. I get no controls and the error messages: &gt; Error: Applying the 'delete' operator to an unqualified name is deprecated &gt; &gt; Source File: http://jamli-player.appspot.com/dist/jamli-latest.js &gt; &gt; Line: 435, Column: 4 &gt; &gt; Source Code: &gt; &gt; delete settings; --- &gt; Error: window.Jamli is not a function &gt; &gt; Source File: http://jamli-player.appspot.com/ &gt; &gt; Line: 16 Otherwise it works fine, no stuttering on play; though there are some "misplaced" frames in fullscreen. This might be due to me not having restarted X after updating the nvidia-drivers. (The update queue isn't finished yet.) 
You can find implementations of [map](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/map#Compatibility) and [filter](https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Array/filter#Compatibility) on MDN for backwards compatibility. They should be compatible with JScript.
Ah, this one is probably related to the use strict declaration. Issue created, Thank you!
Thank you! Just created the issue.
Great thanks for this comprehensive and extensive tests! I carefully created issues, proposals and tasks for all the things you described. 
If you look closely at the SVN you might spot the trailer of Big Buck Bunny. Please, forgive me.
Thank you for your feedback lulzitsareddit.
Thanks for pointing that out. However, If HTML5 is not supported by a browser, the complete Javascript library should not be used at all. The errors reported on map &amp; filter usage are made in a self executing function without a proper prior feature check.
Thank you for this! The message is probably related to the use strict declaration. 
Thank you for you comprehensive and extensive tests ocrow. I carefully created issues, proposals and tasks according to your reports in the bug tracker. 
You're not giving constructive criticism. We're having a discussion about the pointlessness of pointing out how slow something is on your computer from the medieval ages. And I'm not disputing that flash renders a bit quicker right now. But I'm also pointing out that if you hadn't had a computer from the neolithic, it would not matter. What I'm further pointing out is that the argument "oh it uses so much resources, therefore it must be crap" is a fallacy. Everything we do today is a stupendous waste of computing resources compared to say 20 years ago. Therefore, everything we do today must be crap, after your logic. No Sir, that's unfortunately not how it works. If you'd be familiar with the history of smalltalk, you'd know that at some point we got so many computing resources fitting on your desktop, that we simply didn't know what to do with them all, hence there was a very important realization: You can trade off speed for development convenience! This was the moment modern programming languages where born. They waste stupendous amounts of resources compared to their assembly bretheren, but you get things done (tm) in them, that's why we use them. So, I get things done (tm) in canvas and not in flash. And I don't pretty much care if on some computer from Mesopotamia isn't going to run it well. You're free to ignore all this modern computing hubbub until implementations of canvas superseed the speed of flash. Meanwhile don't go around bugging people that your computer is so frackin slow.
Yea, I'll leave this thread now as this isn't going anywhere. 
I have *no idea* what I'm looking at, but I think I really like it. Any practical reason to use canvas over SVG? When I see lines and circles, I think vector.
Nice work. I just wrote a video player for a large company and had to use jquery. I thought that it would be an extremely difficult task, but it wasnt that bad. There are a lot of browser quirks -- opera not having progress events, or webkit autobuffering no mater what, or firefox passing in the old agrument for the progress event -- but it was good times. I hated jquey's syntax/api so much that I did what you did and just rolled my own helpers in an object literal and the video player is a function constructor. 
That's the sexiest embedded media player I have ever seen.
Although not really a tutorial, I always suggest checking out [Doug Crockford's "The JavaScript Programming Language"](http://video.yahoo.com/watch/111593/1710507) series on [yui theater](http://developer.yahoo.com/yui/theater/). Its a 4 part series that takes you through pretty much every aspect of the language. Most importantly he covers inheritance and the prototype object, and functions as first class objects. Like I said, this is more of a lecture than a tutorial so don't expect to write code along the way. But, if starting at the beginning is what you want then this is it.
Your 5|&lt;1||z are amazing, d00d. Keep up the good work!
Hey old chap, tried it on OpenSUSE 11.0 with Firefox 3.0 beta 5 and it works great!
http://code.google.com/edu/ Start here. 
That's awesome! A JavaScript to LLVM compiler could really make websites fast and give more options for other languages on the web if browsers integrated LLVM directly. For a minute I thought I read LLVM to JavaScript compiler, but that would just be nuts.
This bothers me sometimes about JS also. However, it seems to be a feature that people have taken advantage of in unusual ways, just look at how extremely overloaded jQuery() is for example. A culture of programming has grown up around this looseness that's not all bad. Ultimately this seems to be a variation of the strong versus loose typing argument.
I hear you my good Sir.
Are you planning on (or does it already have) audio features? I'm thinking something like turning a list of files into a fairly standard scrolling playlist with basic features like shuffle/repeat/album art(if provided). Also, I don't mind jQuery-dependency if it makes it easier/simpler to write. Most of my sites already need jQuery, so it's no extra burden. Thanks for the great work!
The playlist support sounds good
That's a good question. I think canvas is simpler to script. It possibly is also faster, though I'm not sure. Comparing canvas and SVG: canvas can do everything that SVG can. But SVG can't do everything that canvas can. So in the spirit of not painting yourself in a corner, canvas seems like a better choice as well.
Doesn't jQuery help hide browser incompatibilities? What specifically are you doing with jQuery that doesn't work properly in IE?
Wrong sub reddit mate. Move this to /r/web_design
The other fix would be to use: "vertical-align: middle".
Somethin like this: &lt;head&gt; &lt;script type="text/javascript" src="jquery.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="thickbox.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; $(window).ready(function(){ $("#link_in_thickbox").click(function(){ $("#append_to_me").append( // append new input value to form $('&lt;input type="text" name="foo" value="' + $("#tb_input").val() + '" /&gt;'); ); tb_remove(); //remove thickbox }); }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt;&lt;form ...&gt; &lt;div id="my_thickbox_div" style="display: none;"&gt; &lt;select id="tb_input"&gt; &lt;option value="1"&gt;one&lt;/option&gt; &lt;option value="2"&gt;two&lt;/option&gt; &lt;/select&gt; &lt;a href="#" id="link_in_thickbox"&gt;add&lt;/a&gt; &lt;/div&gt; &lt;div id="append_to_me"&gt;&lt;/div&gt; &lt;a href="#TB_inline?inline_div=my_thickbox_div" class="thickbox"&gt;open tb&lt;/a&gt; &lt;/form&gt;&lt;/body&gt; In Firefox and Chrome, everything works as planned: 1. user clicks "open tb" link 2. Thickbox opens up with inline div content 3. User chooses option in &lt;select&gt; 4. User clicks "add" button in thickbox div 5. A new &lt;input&gt; is appended to the form with the value and the thickbox is closed. **However**, in Internet Explorer, the steps go as follows: 1. same 2. same 3. same 4. same 5. nothing happens, no &lt;input&gt; is created and the thickbox does not close. I'm guessing it has to do with something with the `$("link_in_thickbox").click(function(){/* */})` code... but I don't know what... It's just a bunch of appends and creations that seem to work in anything but IE. I could post the whole code, but it's quite long...
It does work, but it fixes only the most horrid problems in IE. It fixes many visual bugs, allows for transparency in PNGs, makes opacity (as CSS property) work, etc. It does not fix all visual problems, far from it. And in your case I'm not certain it would make any difference, you should try it's very easy to add (as you can see on the project's main page.) As for your problem, have you tried using live instead of click? I know that #link\_in\_thickbox is already there, but still, it's IE.
What do you mean by "using live instead of click"? *(my strength is server-side)*
This method: http://api.jquery.com/live/ It adds events to elements as they're created, which may or may not be the problem here.
http://jquery-howto.blogspot.com/2009/03/dynamically-creating-input.html
:O! This may be the problem/solution! Will test in the morning. 4am FFUUUU
Adding another IE shim library is no substitute for understanding what is going on in your own code. IE8 has a very respectable debugger; just press F12, go to the script debugging tab, and set a breakpoint on the .append() in your click handler to see if it gets there and what values you have. Seems like the click handler should return false, at minimum, to cancel the default action. This line: $('&lt;input type="text" name="foo" value="' + $("#tb_input").val() + '" /&gt;'); is very fragile as written. For one thing, .append() can take an html string directly, there's no reason to wrap it in $(). More importantly, if #tb_input has a value that contains a double quote (or worse, html) then the input would be invalid. If you set the value using .val() or .attr() those problems go away. You'll probably want to head over to either forum.jquery.com or stackoverflow.com, those are better places for programming and debugging help. 
You should be able to debug this without using ie7-js. I don't think it would help in your case (what you're trying to do should work in IE). Also it looks like the thickbox data is hardcoded? $.live() won't really help in that case. I'm thinking it's some small syntax issue that IE doesn't like. Maybe change your $(window).ready(function() { to $(function() {...
I would advice to stay away. When I first found ie7.js I thought it was really awesome, did couple of small scale tests and went on to integrate it in our cms which was going through a major rewrite. The thought of basing the new cms version on IE7's CSS capabilities instead of IE6 made very happy. It was a bit slow but hey, IE6 is a dying browser and I do not want to spend a ton of my time supporting it. My big mistake was only doing small scale tests, much smaller than what the cms would eventually grow to. As I added libraries that came with their own CSS (highslide, jquery UI), the performace kept getting worse and worse. Couple of months ago I was creating another site using the cms and found that it consistently crashed on IE6. I pretty much immediately knew that ie7.js was the cause. That was the last straw and I decided to remove ie7.js from the system entirely. Luckily by then we had only migrated 5 other sites to the new cms version so it wasnt too painful of a task to remove it and deal with IE6 in other ways. I could still consider ie7.js for very small scale stuff (couple of static campaing pages etc). Of course, for that kind of work it's usually trivial to desing around IE6 bugs or add one or two simple hacks. So when you most desperately need ie7.js it doesn't work, and when it does work you tend not to need it.
I'm the author of ie7-js and I mostly agree with you. :) I wrote the script more than six years ago. At the time there was no such thing as jQuery and jQuery UI etc. The script was intended to allow people to create simple sites using CSS and HTML. It was never intended to be used in complex DHTML sites. People's expectations of what it can do are a little too high. It fixes a lot of major bugs but that still leaves lots of little MSIE bugs that it does not fix. I would recommend it for pure CSS/HTML sites. You can try it with a dynamic site and if it works for you then that is great. I certainly would not recommend including it in a CMS as a panacea for all MSIE's problems.
Redditors, I would advise that you heed this person's advice.
I have used jquery off and on for other projects but I'm not sure if you mean the entire API or specifically jQuery itself. Although jQuery itself does provide a good example though so I'll just go with it: shttp://api.jquery.com/jQuery/. I think from a software engineering perspective and from a practical perspective this is very vulnerable to bugs. Also not to sound too much like THAT guy but I don't think weak function prototypes are going to be an issue until you start breaking 100 lines or more. As JS continues to grow in usage and complexity this kind of logical cohesion in functions combined with weak function prototypes is going to become more difficult to manage. Variable numbers of arguments, ie. all arguments are dom elements, are OK provided that there is a way for function authors to turn that off. Otherwise you are just opening parts of your code up to bugs just so that a few functions can accept a variable number of arguments. Right I would argue for stronger types but that will never happen and I think just strengthening Javascript's function model would be good enough.
Thank you for the input. :)
#tb_input is a &lt;select&gt; that always contains pk's, so integers. It is generated by my server-side code, so there's no user input, but I understand your concern. Was not aware of .append()'s ability to take html. Thank You!
This is my guess... Probably a retarded syntax error that IE is complaining about. I haven't had a chance to do in depth debugging yet.
There are at least two syntax errors in that code. The semicolon in this line (note the context of the line): $('&lt;input type="text" name="foo" value="' + $("#tb_input").val() + '" /&gt;'); and these dots: &lt;form ...&gt; With those errors - at least with the semicolon - I would expect the code would not work in any browser, much less in IE. Also there are no &lt;html&gt;&lt;/html&gt; tags and no DOCTYPE. This is why it's important to post a link to a test page, not just a snippet of code. I suspect that the code you posted may not be exactly the same as the actual code you're testing. And as others have mentioned, there are other places where it would be better to ask for help.
The dragging speed on the iPad seemed a bit sluggish, which is worrisome because the iPad is rather fast. But in every other way this was extremely awesome. 
Semicolon I don't think matters, and I don't even know if I have it in my actual code, that wasn't where I think the issue is/was. [Here](http://alkfhsdkjhfgksfjghfds.pastebin.com/Ga5Asrc4) is actual code.
I think that ie7-js was quite influential, even if it was never all that popular. Stuff like [CSS3 PIE](http://css3pie.com/) might not have existed at all without it.
But if you take everything you just said and replace "weak function prototypes" with "weak typing" these sound like very well-worn and familiar arguments. &gt; I don't think *weak typing* is going to be an issue until you start breaking 100 lines or more. It's been argued before and will continue to be until the end of time. Not saying they're invalid arguments, just inconclusive for how programming languages should be as a whole. If you demand strong function prototypes, why not also strong types? Why not a compile step? It quickly becomes unrecognizable as JavaScript. The looseness paradigm goes deep into the design and implementation of the language. Plus you can always validate your function's arguments and throw informative errors or assign defaults (obj = obj || {}). Personally I just try to follow the law of demeter, keep my parameter lists short, and validate my args when I need to.
That semicolon absolutely matters. As I said, note the context: $("#append_to_me").append( // append new input value to form $('&lt;input type="text" name="foo" value="' + $("#tb_input").val() + '" /&gt;'); ); I don't think any JavaScript parser will accept that as valid syntax. Stripped to its essentials, this code is: a( b(); ); which is invalid syntax. But the code you posted here doesn't appear to resemble your actual code at all. Were you trying to make a simplified example to help make it easier for people to look at the problem? That can be a very good idea, but the missing step is to put the example up as a live web page and give people the URL to it. And I *don't* mean a link to source code in pastebin - that is not helpful - what are people supposed to do, copy and paste it into an HTML page of their own? You have to make it easy for people to help you. If you'd posted the code snippet as a live page and tried to load it yourself, you would have found that semicolon error immediately. :-)
The iPad is fast, but the javascript engine mobile safari uses is dirt slow. If they want developers to seriously use webapps, they need to speed it up.
&gt; trying to make a simplified example to help make it easier for people to look at the problem This ^ I was more worried about errors in my plan of attack versus syntax, I guess. I could make a live page, and I probably will soon, after I get a chance to try a few things to fix it. (Haven't had a chance yet) Thanks for your input, sorry if I seem to come across as defensive. I don't mean to :)
Get a book.
Thank you! I agree that scrolling is a bit slow right now on the iPad, though we already have a few optimizations in mind. The engine performs really well on the iPhone 4, and once iOS 4 hits the iPad, performance should be about the same as on the iPhone - which is to say good. :) - Jiri, Rocket Pack
Hi and thanks for the comments. Please bear in mind that the content, nor the actual game you saw have been optimized yet. The raw rendering speed of the engine itself is actually fairly high. - Tommi, Rocket Pack
Thank you for your valiant effort at fixing IE6. Turns out it can't be done but good try none the less.
The canvas does not have a display list. Until it does, JS games and animations on it will be limited to about 15-20 FPS. While this project does sound promising, the capabilities will be severely limited and sluggish by that fact. JavaScript and the canvas are not designed to be a game environment.
&gt;The raw rendering speed of the engine itself is actually fairly high. fairly high = 15 - 20 fps. A framerate that low is noticeably sluggish. Until the Canvas supports a display list, no engine is going to pull a FPS much higher than that.
Hi. Please have a look at http://rocketpack.fi/engine - we explicitly make a point of not using a canvas (yet!). This both of performance reasons, but also because a very major browser does not currently support the tag at all. Also, skip the video to 2:37 to see some more material running on the iPad.
I don't think the slippery slope really applies here. Especially since I use Python which doesn't cause these problems and it does not have compiling. It does have stronger typing than JS though. What I'm saying is there is some good compromise between too strong and too weak that emerges out of everyday usage. If the bugs you run into over and over again are caused by a certain behavior that you could eliminate with very little pain via small modifications in their coding style and additional debug warnings then why wouldn't people want to work towards that? Again, I don't want to get into weak and strong typing because that's just too much change. The language is weakly typed and I don't think that would ever change.
So you draw right to a DOM element? Doesn't this cause issues with position inconsistencies? I love the canvas for the pure fact that is resolves position problems that you have with positioning elements in the DOM, but at the same time I dislike it because of framerate issues. I will check out your framework to be fair in my opinion.
Nice, thanks, I just finished The Good Parts, so I probably won't learn too much from his talk, but still, it looks interesting.
Thank you very much for the suggestions. http://developer.yahoo.com/yui/theater/ and http://code.google.com/edu/ are looking good!
Hi again. I am not sure what you mean with "position inconsistencies" - inconsistencies between what exactly? We have of course a transformation system for converting between world -&gt; screen coordinates (where the main container for the game's world can be placed inside any element - as can be seen in the editor, world living inside the small viewport on the right, or cover the entire screen like on the iPad). One of the main points is that we take care of all of these problems in the engine, so that the end-user won't need to wrestle with them! Glad that you decided to give our engine a test try. - Tommi, Rocket Pack
&gt; Especially since I use Python which doesn't cause these problems Interesting .. I seem to run into such problems more often in Python, probably mostly because I'm dealing with a richer taxonomy of types. ''arguments'' is the only exception, but a lot of js libraries have adopted the convention of taking an object as their only argument. Why do you think your experience is different?
Yep totally, I've found that too. However Mobile Safari does have an ace up it's sleeve in that it has hardware acceleration extensions for CSS3. It's a bit unweildy (and vendor-specific) but you can get some decent graphical performance out of it, even on the 3G.
&gt;inconsistencies between what exactly? For example, if you place an asset inside of a div, and you want to move that asset across the stage, you would shift the top and left position of the div through absolute positioning. Now lets say that div was inside a container div that was centered on the page using auto margins and you wanted to set limits on the asset so it can't move outside of the window of your application. You will have no idea of what numbers to use for the limits because the container is going to shift based on the size of the browser window. Of course there are ways to keep this in check, but in general it is a pain in the butt. With the canvas, the asset is attached to a position relative to the canvas itself so you don't have this issue. Your response seems to indicate that your framework accounts for the positioning issue, so it seems like it is worth looking into. Thank you for the information!
Hi. Since you're here, what will be the licence options? Obviously you'll be charging for commercial projects, but will there be a cheap/free for non commercial use option?
Hi, the only thing we can say about licensing options at this point is what is stated in the article at http://www.develop-online.net/news/35780/New-game-engine-runs-on-iPad-and-iPhone - ie "[...] a free version is likely the tech’s creators tell Develop".
I wasn't very specific but I guess by problems I mean things such as incorrectly ordered arguments, too many arguments, too few arguments and typos leading to variables/arguments roaming around as undefined via undefined properties. I have those problems in python all the time but they are very easy to detect(except for incorrectly ordered arguments all of the same type). Maybe you are talking about other problems or maybe I'm just doing something horribly wrong in Javascript(very possible). Could you elaborate on the problems you have in python and why they do not exist as much in Javascript? This whole thing was so I could try to understand the language more and extrapolate why I have problems with it in a constructive way. Yes I think taking an object as an argument is a great idea, its actually exactly what I'm proposing for optional arguments. Although it doesn't quite make sense for required arguments to be in there. Also just a regular object won't detect minor mistakes in the interface such as extra arguments or the wrong arguments. Of course function authors can check for such a mistake but no one really wants to write checks manually all over their code and such checks would not perform well and would be just more code that could go wrong.
Working example here: http://neuralmesh.com/webtop/ A code example of how one would write an app to utilize the technology: App.route.out("Message to send to all connected apps"); //Invoke callback function when message recieved App.route.into(function(msg) { //Set the body text to the message recieved document.body.innerText = msg; });
JSON is a data interchange format based on JavaScript's object literal notation. The two are not exactly equivalent. Crockford is responsible for JSON and its official specification, but is perfectly clear about the fact that it came from object literal notation in JavaScript.
Christ he specifically claims not to have 'invented' it. Did you do any research and unless he was granted a patent on it who cares?
Interesting idea. Visual [pipes](http://en.wikipedia.org/wiki/Pipeline_%28Unix%29). If you've ever played with Yahoo's (aptly namned) Pipes, it has a similar interface for manipulating feeds. It would be neat to see something like this actually implemented on an OS GUI.
Like a framework?
Sort of, in a visual sense and a way that the user determines the connections rather than the software.
He's also the creator of JSON.js and JSON2.js, which are wrappers around the eval() function (with added functionality) that process the JSON text and sanitize it for evaluation.
Thanks for that. Yahoo pipes has given me a few ideas. I'm hoping that many developers will write apps for it as they are not restricted to one framework.
He wrote the specification and the de facto JSON-parsing lib (json2.js)
http://developer.yahoo.com/yui/theater/video.php?v=crockford-json
Looks like visual programming to me, which for some reason never took off, as far as I can tell. Doing your example from the commandline seems a lot easier to me. Or if you want to use a GUI, menus and toolbars are a simpeler solution than forcing the user to play with spaghetti.
I've skimmed thru *The Good Parts* and, from what I can tell, this series makes up the basis for the book. It's probably the way I learn but, it made a difference hearing someone explain it, especially someone like Crockford who is one of the fathers of modern JavaScript programming.
Yeah you're right, it is sort of like visual programming. To fix that I had the idea of saving a set of connected apps as a new application altogether. So there would be a shortcut to the app spaghetti.
Grouping together groups of commands and hiding them behind a single (expandable/collapsable) node icon is an obvious way of getting a visual handle on the spaghetti's complexity. What do you think is the advantage of programming in this spaghetti style? I'm pretty sure most programmers would find it cumbersome to use. What kind of code does the spaghetti app generate?
Have you seen OS X's Automator?
DDE?
Modularity. It shouldn't be cumbersome. How hard is it to just receive data, manipulate it and then maybe output it. See my first comment for a code example. The point is not to rely on this new style but as an advantage or extension. Edit: It's not actually visual programming. The coding is all in javascript but it's visual for the client/user.
[Butters' voice](http://en.wikipedia.org/wiki/Simpsons_Already_Did_It): "[Unix did it](http://en.wikipedia.org/wiki/Pipeline_(Unix\))".
OP, I suggest you watch the [JSON Saga](http://video.yahoo.com/watch/5647980/14811995)
Look into [BeOS](http://www.birdhouse.org/beos/bible/bos/aboutbeos-scot.html) and the [BMessage](http://www.acm.uiuc.edu/bug/Be%20Book/The%20Application%20Kit/Message.html "A BMessage bundles information so that it can be conveyed from one application to another, one thread of execution to another, or even one object to another."). This was part of its amazing potential and it was even open to [user scripting](http://www.birdhouse.org/beos/bible/bos/ch_scripting1.html#appscripting "Every single application running on BeOS can accept and respond to "suites" of scripting commands, whether or not the programmer added special code to handle this. It's all automatic."). That was the first OS for which I ever felt zelotry.
Thanks.
This is awesome.
Cross posted from [/r/bubbling](http://www.reddit.com/r/bubbling/comments/d9p1y/drunken_project_html5_automatic_bubblator/), where apparently it's been blocked as spam. * put image URL in input, press load * roughly paint the parts of the pictures you want to keep * press the *hide* checkbox, pain the part you want to hide, press clear if you mess up * click *go* then *finish* when you have enough bubbles I know it's ugly and buggy, I made that the other night and honestly I don't feel like cleaning up the code right now. If there's some interest I might do it tomorrow. 
I keep seeing this bubble thing everywhere and I have no idea what the point is. Someone enlighten me?
nothing happens when i click finish. 
http://www.reddit.com/r/funny/comments/d8bul/
There's actually a difference between JSON the interchange format, and JSON in javascript. If you look at the spec here: http://json.org/ You'll notice that all keys in a hash are strings, and all strings *must* be double quoted. This is not true in JS, where you only need to double quote if its a reserved word (e.g. "class"). Its a minor detail, but it shows how it is made for data interchange and compatibility.
Hi
kewl beanz, dood
http://vimeo.com/groups/16014/videos/12529436 The 10 things I learned from the JQuery source. Great video.
Ah... Finally someone's embracing the Java in Javascript
I recommend http://jsfiddle.net/
Impressive, surely. But the thing about this JS1K demo is that a lot of the submissions appear to be just graphics demos that utilize some well-trodden demo-scene algorithms. I really want to see a 1k demo that utilizes the expressive power of the higher level language, the facilities afforded by the browser, and the net in general - not just the ASM demo from 1998, rewritten in minified JS on top of an HTML canvas. I just feel that most of these entries are not very 'web' for lack of a better word and to be quite chaffing, it's far easier to pack a lot of math in 1k then a lot of anything else.
What version of js is this for? It's not compatible with FF 3.6 is it?
All I care about is that my shit works on the first try after I load up from developing in Safari/Firefox without having to spend an hour debugging script errors. As long as IE does that, the rest is pomp and circumstance.
Precisely. IE sucks bitime, fortunately for me as a web application developer and "God", I command all the users to use chrome or IE, and never heard a winge from then. 
$.ajax({ async:false });
Are you people actually interested in javascript news or not? Whether you like it or not, MSIE is a *major* JavaScript platform. Downvoting news about it does not make you a programming hero, it makes you a knobhead. I've given up on this subreddit. It's full of juvenile script-kiddies and not much else.
You are obviously a brilliant programmer. Can you expand on your ideas a little bit for the rest of us mortals?
xmlhttprequest has a optional asynchronous flag. By default it is true, but when false you get a synchronous request. $.ajax allows you to change jqueries ajax settings.
Thanks for the explanation. But it would have been better if you didn't type anything in the first place and left the original post to stand on its own.
&gt;Whether you like it or not, MSIE is a major JavaScript platform That may be, but there's something to be said for the effect of willful ignorance. If everyone stops talking about ie, other than as an afterthought where you need to make a standards compliant website work in ie, there's a better chance of it crawling into a corner and dying. People downvote because what the ie devs are doing is irrelevant and has been for a long time.
Things don't go away just because you ignore them.
The snark is acknowledged, but not quite understood. I get that disabling the asynchronous nature of AJAX requests is generally not a good idea for front-facing UIs, but it seems fine for this (granted, contrived) example of a developer's test suite. Not rhetorical: what exactly makes this comment not just wrong, but also worthy of ridicule?
They're actually doing good stuff these days, though. IE9 has a good chance of becoming an actually reasonable browser, especially given posts like this that indicate that this particular IE staff knows what they're doing and are willing to acknowledge IE's previous faults. IE8 was designed to make things more user-friendly; the big IE9 emphasis really does seem to be to make web developers not hate their guts. Let's condemn IE9 after we see it.
It's just the nature of the competition. 1K of JS is absolutely tiny, so people have to resort to math to do anything. Plus, this contest actually forbids loading external data. There was another contest going on with a 10K budget, and a JavaScript library for free, which is much more webby: http://10k.aneventapart.com/ 
What a pro. EDIT: Actually, that's pretty reasonable.
Read the original post again and stop talking like a twat. Sorry, I couldn't find a nicer way to phrase it.
...well, this comment asked you to please hold my hand and walk me through it, but now it clicked in my brain :) Since we're testing real code with asynchronous calls deeper within it, we can't just go ahead and edit it to set the async switch. I wish the post had said that more explicitly, since the example made that somewhat unclear for a while, but maybe I just need more sleep. Even so. Much more a fan of your code than your tone here :x
Don't take the example too literally. He's showing a programming pattern for queueing up synchronous calls and waiting until they are loaded. I haven't verified the code or tested it. I thought that it would be interesting to share with other JavaScript programmers. Instead, it got downvotes and arcane jQuery one-liners. This makes me mad at /r/javascript. And you're still talking like a twat. Please stop it. 
Sorry. Your defending it so much made me think it was yours. All done :)
I wasn't particularly defending the original post. I was attacking the original comment for being off-topic (and arcane). I am an admirer of the JCoglan's work though. His blog is interesting if you are a serious JS programmer. I'm done too. :) EDIT: And you massively edited your comment above. Oh well..
I'm sorry, but when I look at articles like this all I can picture is a Microsoft dev waving his arms and saying "Hey, look at us! We can be compliant too!" 1. I was developing during the browser wars, I worked on the forefront of that field, and I remember how much of a total pain in the ass it was that one browser would have a feature that the other didn't. 2. For the past five years we've been working in an environment that is the opposite, where one dominant browser has been dragging everone behind because of their lack of modern support. Microsoft sat on their asses for 8 years and did NOTHING for web development. I don't care what grand awesomeness they add, it's not gonna make me drop to my knees and cry "all is forgiven". I'm not 20 years old any more, I don't have time for this shit. All I want from Microsoft is total compliance with current standards, and regular continued compliance that matches what the other browsers *currently have out* so that I don't have to worry about if my web apps are going to completely malfunction. New ECMA standards support is awesome, I'm glad they're adding it, but I'm not going to sing praises for them because they finally decided it was a good PR move to spend some money their shitty software.
So... you don't want to read news about IE9 because MS is evil? I can see how that makes sense. Except if you need your code to work on IE browsers, of course.
&gt; I'm not going to sing praises for them because they finally decided it was a good PR move to spend some money their shitty software. Fine. Don't sing. But don't downvote a JavaScript *news* story. It's not an election.
I never said I didn't want to read it, I upvoted the article, but Dean's acting like we should be jumping for joy over this announcement.
I'm pretty sure he wasn't asking for any jumps of joy, merely being puzzled by people trying to make his submission go away. 
Come on man, you've been on Reddit long enough to know how fickle people can be with their votes. Twice as many people upvoted it then downvoted it (that includes me, btw). You have any idea how many great posts get voted to oblivion? Statistically you're doing awesome just by being above zero.
Bah. Fair enough. My grumpiness has passed now anyway. :)
Yeeaah. I thought I had done the edit before you had seen it, but apparently wasn't fast enough. Meh. It all works out.
Stop whining, every submission in every subreddit gets plenty of downvotes from bots.
Van Persie's down again! Oh wait, wrong thread ;) Arsenal for some silver this year!
It doesn't matter so much what the IE team is doing for the next iteration of the browser but what they are doing to make the one two iterations back die. We had to cut out a lot of features on our new website (that gets an overhaul less often than IE does) because 10% of our traffic is still coming from paying IE6 customers (i.e., corporations locked into IE6 legacy apps.) Imagine our elation when MS announced they are extending WinXP support to 2014
embrace and extend...
I don't think that is a very arcane piece of jQuery...maybe that means I use jQuery too much.
&gt;Things don't go away just because you ignore them Sure they do. If I may use an example: &gt;I've given up on this subreddit.
&gt;They're actually doing good stuff these days, though As far as I know, they don't _do stuff_, only copy/keep up with what other browsers are doing. No developer is going to use ie at all except to make sure things that should work do.
cr9900.hasLayout = false;
I agree, IE9 is a contender and I'm glad they're bringing things around to standards. Most of the negativity here is probably pent-up frustration looking for an outlet. Posting about IE here is like walking around waving a lightening rod in a thunderstorm. Even so, good post, and thanks.
Catching up is a satisfactory starting point for the biggest browser there is.
I can see a few problems. Firstly, it's unlikely anyone apart from me will want to sit down and learn your code in order to debug it for you - put together a minimal test case in future (and, 9/10 times, you'll see what you've done while you're doing that). Secondly, you're trying to access replyTypes[currentReplyType], but currentReplyType is a string. JavaScript Arrays are supposed to be numerically indexed, so I'm not sure what will happen there. I think you want to use {} instead and be assigning properties to objects. To repeat: There's no such thing as associative arrays in JavaScript - use Objects instead. Thirdly, `foo=[2]` creates a one-element array who's zeroth element holds the integer 2. I wonder if what you expected was it to create a 2 element array? (if so, use `foo = new Array(2);`, or just say `foo=[]` and don't worry about how many elements you need. We're not coding C here.) There's probably other things in there, but #2 is the big one. Rewrite it using numerically indexed arrays or objects and you'll probably sort the problem out. I'm also a big worried about "custom html tags"... does that work in all browsers? How about conforming to semantic, standardised html? Why not use jQuery? Seems like something like this would do the trick, assuming you dumped your custom tags and used `&lt;span class='init'&gt;` instead of `&lt;init&gt;`: replyTypes = []; function getAllReplies(parentElement) { $('.'+parentElement).each(function() { obj = {}; obj.replyType = $(this).attr("replyType"); obj.subject = $(this).attr("subject"); replyTypes.push(obj); getAllReplies(obj.replyType); }); } More or less, anyway. Final tip: install firebug and use console.log not alert for debugging, you'll thank me. edit: so, with that jQuery function on this html: &lt;span class="init" replyType="foo" subject="bar"&gt;bar &lt;span class="foo" replyType="none" subject="baz"&gt;baz&lt;/span&gt; &lt;span class="foo" replyType="none" subject="baz2"&gt;baz2&lt;/span&gt; &lt;span class="foo" replyType="bing" subject="baz2"&gt;baz2&lt;/span&gt; &lt;span class="bing" replyType="none" subject="bing"&gt;bing&lt;/span&gt; here's what replyTypes looks like after it's run: `[{"replyType":"foo","subject":"bar"},{"replyType":"none","subject":"baz"},{"replyType":"none","subject":"baz2"},{"replyType":"bing","subject":"baz2"},{"replyType":"none","subject":"bing"}]`
 replyTypes[currentReplyType] = [thisReplyTypes.length]; This doesn't do what you think it does. You're trying to initialize an array of length (thisReplyTypes.length)? Javascript doesn't work like that, what you're actually doing is initializing an array with the first element as (thisReplyTypes.length). Same on the next line where you're doing [2]. Just do: replyTypes[currentReplyType] = []; Another problem you're having is that you're re-initializing replyTypes[currentReplyType] each time through that for loop. You should do it once, before the loop. As it stands, each time through the loop, you're wiping out the previous iteration.
thanks for your points, all of which I understand. Yeah, I caught the array declarations ( e.g. m = [2] ) and you're right about that - those slipped in last night being bleary-eyed. Yeah, I was trying to simplify a test case, but I have been around this so many different ways I thought I just post it to illustrate the obvious: inside the function array (er object) element myObj["init"][0]["myType"] has a value, is shown to have a value, and outside the function, when the function is done myObj["init"][0]["myType"] is show to be undefined. Javascsript allows one to mimic associative arrays, because arrays are objects too - correct? this what I am doing, and it works. I would like to use this method to quickly index the structure I need to build. I have firebug, and firebug is buggy - so it's easier to do some quick debugging with alert, rather than to have to restart firefox every couple of refreshes to reset firebug. OK, so how would you dynamically create an object that can be referenced it thusly obj[someString][i][j] ? -- that is it needs to be 3 dimensional, and I won't know how many "someString" values there are, or how many elements of each obj[someString] (obj[someString][i] ) I do know that the third dimension has a fixed number of elements (2 for now) I know this can be done with "pure arrays", but having the first dimension indexed by a string ("associatively") is going to save me a lot of trouble down the line. 
hey, really thanks for your input. about the tags, I don't want values to be shown - so the span tags you illustrate could be empty, right? eg: &lt;span class="foo" replyType="none" subject="baz2"&gt;&lt;/span&gt;
unfortunately I am customizing a system that does not play with JQuery.
yeah the elements don't have to have any contents. Not sure how cross-browser the custom attributes are mind you. Should be fine. Worth testing. Firebug shouldn't be giving you trouble, maybe it's conflicting with another extension. *shrugs*. I still use alert for debugging now and then ;) &gt; Javascsript allows one to mimic associative arrays, because arrays are objects too - correct? this what I am doing, and it works. Yeah.... but you shouldn't do that. It would make as much sense to say foo = new String(); foo["bar"] = 'baz'; (yes, that 'works' too) Use arrays if you've got numerically indexed elements. Else use objects. Better for clarity, if nothing else. &gt; OK, so how would you dynamically create an object that can be referenced it thusly obj[someString][i][j] ? obj = {}; obj[someString] = []; obj[someString][i] = []; obj[someString][i][0] = val; obj[someString][i][1] = val2; obj[someString][i2] = []; obj[someString][i2][0] = val; obj[someString][i2][1] = val; obj[otherString] = []; obj[otherString][i] = []; obj[otherString][i][0] = val; obj[otherString][i][1] = val2; I think that covers it, assuming `i` and `i2` are numeric. If you're planning to iterate over obj though, I'd stick with a numerically indexed array. You can iterate over objects (`for(property in object) {...}`), but that's what arrays are for. edit: or even: obj[otherString] = []; obj[otherString][i] = [val,val2]; 
This sentiment. Residual bitterness from MS careless disregard of my time and sanity + MS's self-congratulations on doing what every fucking other browser has done for the last decade = RAGE.
I tried this route in several permutations more than once, but each time an error is thrown on the statement: obj[someString][i] = [] that "obj[someString][i]" is undefined, indicating there is a problem with the previous statement: obj[someString] = [] I also tried: obj = {}; obj[someString] = new Array(); obj[someString][i] = new Array(); but generates the same error "obj[someString][i] is undefined" Here is another strategy I tried, declaring class objects: obj = {}; function replyObject(){ this.replies = new Array(); } function replyData(){ this.replyType = ""; this.subject = ""; } Then inside my function: obj[someString] = new replyObject(); obj[someString].replies[i] = new replyData(); obj[someString].replies[i].replyType = "OK this works"; and it works - I can verify that each for each "someString" and i obj[someString].replies[i].replyType has data. But, outside of the function - when the function is done building my structure - if I try to iterate through the structure: for( var mTypes in replyTypes ){ // test for( j = 0; j &lt; replyTypes[mTypes].replies.length; j++ ){ alert( replyTypes[mTypes].replies[j].replyType ] an error is reported that replyTypes[mTypes].replies[j] is undefined. Just seems really bizarre. 
hah! I'm an idiot. Actually the problem was in my recursive function - I was reassigning my second dimension array overtime through my loop. should have been before the loop. Anyway, thank you for all of your help. It really clarified my strategy. (I don't know who or why anyone would down vote you for that post, but I would up vote you a thousand times if I could)
thanks, that just sunk in, and that was the whole problem.
Yay! [huggles] I like that flexibility with js arrays - and push and stuff like that.
That's pretty good but, wouldn't it be easier to install VirtualBox, load up a linux OS and just operate in that environment? That's how I work with node anyway.
huggles is undefined.
i thought that too. 
nothing new here, move along.
Yep, just another rehash of what has been said a zillion times.
Yup. If anyone is interested, there were &gt;160 comments when [the article was posted to /r/programming](http://www.reddit.com/r/programming/comments/d9dfb/why_javascript_is_awesome/) a few days ago.
Everyone who reads 'The Good Parts' should also be required to read [this book](http://books.google.com/books?id=ED6ph4WEIoQC&amp;printsec=frontcover&amp;source=gbs_ge_summary_r&amp;cad=0#v=onepage&amp;q&amp;f=false) I've done a fair bit of research in functional programming, adore Scheme, Lisp and Haskell, and really enjoy the functional features of JavaScript, however you do have to be careful when programming in a functional style in languages that are not designed for it. I've written a purely functional set of tools for JavaScript for mostly pedagogical reasons, and the lesson is that while JavaScript has the expressive power of many fp languages it takes a dramatic performance hit, because in the end it really is not a fp language. Crockford's book is awesome and offers a lot of insight into the language, but it's important to not get overly enthusiastic about treating JavaScript like a functional language (I don't think Crockford implies this either, but a lot of people seem to take this away). also this blog post is essentially a very brief summary of half that book, and since you can read 'the Good Parts' on a plane ride, there's no reason to not just read that if you haven't already.
Heh, it's getting to the point where the only thing that really needs to be cross-platform is virtualization software.
While I am pleasantly surprised by MSIE's newfound fondness of compliance, they still have a history of roughly 14 years (from Win95 to MSIE 8) speaking against them. They're definitely looking like they're trying to get their act together this time, but I'm still not convinced that Microsoft suddenly cares about cross-UA compatibility. MSIE9 may look decent, but Microsoft doesn't exactly have a reputation of _supporting_ open standards.
That, too. While it's neat that Windows users who update regularly will get a non-crap browser without having to manually install a good one, the marketshare of die-hard MSIE users is probably far lower than the marketshare of MSIE users who are stuck with legacy software because they don't know any better (e.g. Average Joe) or because they have no choice (e.g. corporate users). A new browser isn't going to magically make the pain go away, no matter what it's called and what OS it ships with. Chrome Frame is probably a bigger help than MSIE 9 when it comes to pesky legacy browsers.
Essentially, the article confirms that Node.js will compile and run on a fairly normal cygwin install. The only thing you'll save by installing VirtualBox and running a linux image is installing cygwin. every other step is identical. 
Really, when you have size restrictions, you're going to have a lot of people trying to cram a lot of code in using all types of weird tricks that you would never use in production. Maybe I like imagination, but anything that shows off the expressive power of the higher level languages isn't necessarily that exciting for *small* demo/competition purposes. Personally, I had some fun working on it. Never really had much experience with graphics outside of school. I took it more as motivation to do something new. http://js1k.com/demo/603 was my submission. Wasn't the most impressive but I had a lot of fun doing it.
Ohhh! Kool!
Yay! =)
var huggles=sarahStuff.getGoodStuff(factoryRelax);
I've written a similar set of tools, I ported much of the Haskell prelude into JavaScript and learned a lot about both. It was fun. Anyway, I'm starting to feel like the minority, but I didn't think *The Good Parts* was really all that good. It's easily the best JS book I've read, but I didn't think it was that great as a programming book.
Don't feel alone re:The Good Parts. I think the thing to remember is the wide range of the audience for JavaScript books. I remember implementing the 'Curry' example on my own long before reading that book, but I also don't think that book is targeted at me. I picked up a few good tips reading it, but most of the really interesting stuff I was already pretty familiar with. IMHO Zakas is actually the most under-appreciated author on JavaScript, at least for people that are seriously interested in the details of the language. Although it's getting a little old, 'Professional JavaScript for Web Developers' is an amazingly thorough look into the language (it still has the most detailed discussion of different ways to view OOP in js that I've seen). And 'High Performance JavaScript' (mentioned in my previous post), at least in the 'stuff learned per page', is performing much better than 'The Good Parts'. He really understands both the core language an very nuanced details of the language's implementation in various browsers. 
I like it! I have a project where I convert images to unicode art, but I can't stuff it in 1K :-(.
Have ya tried using Stack Overflow instead of reddit for your programming aneurysms? :) -- www.stackoverflow.com
That looks great, thanks for the tip. It's now on my wish list :) And a good warning about the functional nature of JavaScript. I do think the functional parts are great, and make it a lot of fun, but I understand about performance as well.
I'm really looking forward to the 4.0 release. I am one of those people locked to Firefox due to the awesomeness of all the addons, but longing for the speed of Chrome. This is a great step in the right direction!
I agree completely -- *High Performance JavaScript* has a much higher information density than *The Good Parts*. (I also [strongly disagree with some of Crockford's points](http://bolinfest.com/javascript/inheritance.php).) Zakas's book is well-written and brings together a lot of tips and tricks that have been strewn about the Net for some time. (I also approve of his move to bring in several contributing authors to collect more knowledge from JS gurus.) If *JavaScript: The Definitive Guide* (O'Reilly) were half as thick (which it easily could be if it ditched all that reference material), then perhaps more people would have found it accessible and not looked to O'Reilly for another, shorter explanation of JavaScript, which is where I believe Crockford's book fits in. At this point, I wish I had bought Zakas's *Professional JavaScript for Web Developers* rather than *JavaScript: TDG*.
I think its a destructive book actually. The author mixes up sound solid advice with personal coding conventions and styles. There is a history of people blindly repeating some non-applicable out of context catch phrase ad-naseum like it's good advice in the world of programming. An example would be stating that the goto construct is of no use (which is a flat out lie). These things then become battles in group efforts. People will kindly inform me of the ubiquitous disinformation as if I haven't heard it and then I have to very carefully waste a crapload of time defending sane programming that violates some insane dogmatic bullshit canon. Programming then becomes some kind of ceremony where you follow arbitrary rules for absolutely no reason, and don't apply any critical thinking in the situations where it's needed the most.
YES! THIS. This is the problem I had with the book and is additionally the problem I've had with much of the JavaScript literature out there. The books explain how to do something, as you said, ceremonially, but never seem to advocate a deep understanding. I even think I saw this in *JavaScript: The Definitive Guide* (which @bolinfest was talking about) it's a big, thick, dry reference volume. A deep understanding of the JavaScript language **as a language** is what people need to be effective, and few of the existing books seem to provide this. I'd say this is roughly the problem we've had with JavaScript all along. In the 90's JS started out as an extra layer of interface hacks and minor interactivity functions and it was such a flimsy add-on layer that no developer would consider it as a layer to be architected or deeply considered. It was just another part of the application to get out of the way and it was unpleasant because people didn't understand it. (Also implementations were annoyingly subtly different, but that's no longer a big problem.) Fast forward to the present: JS is a significant part of the web stack. Runtimes are reasonably consistent. Client-side code have grown to be complex, architected systems. The problem is that too many think of it as that extra layer to get out of the way. I don't think JS gets messy because the language stinks. It gets messy because people don't think about it like it's a real language. Language features are things to be *grokked*, not *regurgitated*. So, I totally agree with out. *The Good Parts* didn't treat JS like a language. It treated it like a set of incantations. I've actually been considering writing my own JS book the way I see things and putting it online for free. I'm also looking forward to John Resig's forthcoming book.
The thing about FP in JavaScript is that thinking in FP makes doing trickier Ajax a lot more natural. Taking a class on Haskell was probably the best thing for my JS. With a language that can get as soupy as JS, I think a performance hit is sometimes a worthwhile sacrifice for clarity. Keep in mind, it's not a huge performance hit anyway.
Interesting article, and good to know for the future. Wish he had covered Sizzle specifically in the analysis, or is it fair to assume that all the complaints concerning jQuery also apply to Sizzle? This was the first I had heard of Native-first Dual Approach and it explains why in Webkit I can do queries and matches with multiple selectors separated by commas, but in IE it doesn't always work. Minor quibble: &gt;Not throwing errors on invalid, unhandled input. either returning a result that is either empty or contains elements (All: YUI2, YUI3, Ext, Sencha, jQuery). The last thing I want to have to do is wrap my query statement in a try. I consider an empty enumerable response to be the the correct response in this case, since any methods called on that enumerable will still work, they just wont do anything.
Really, a big part of being a professional programmer is balancing readability with performance. The biggest problem with JavaScript is the non-programmers who write it, and the programmers who write it but don't learn it. I think it's coming into its own as a language, and it looks like more and more people are looking into it as a real language. There'll be more and more books, and the good ones will rise to the top. I'm looking forward to reading some Zakas!
I like jQuery quite a lot, but all of these just solve the same problem for me: making all browsers produce the same output without having to manually handle every little thing. If the browsers would just conform to the same methods and standards, I would have no use for any of these libs.
It seems like the main purpose of this is to get `$.extend()` to return a deep/recursive merge: $.extend({foo: 'fu', etc: { one: 1 }}, {bar: 'bar', etc: { two: 2 }}) // Returns: { foo: 'fu', bar: 'bar', etc: { two: 2 } } // But we'd like: { foo: 'fu', bar: 'bar', etc: { one: 1, two: 2 } } Which is possible if you enable deep copy by passing `true` as the first argument to `$.extend()`, like so: $.extend(true, {foo: 'fu', etc: { one: 1 }}, {bar: 'bar', etc: { two: 2 }}) // =&gt; { foo: 'fu', bar: 'bar', etc: { one: 1, two: 2 } } As for not modifying the first object, just pass an empty object for the first one: var newObj = $.extend(true, {}, {foo: 'fu', etc: { one: 1 }}, {bar: 'bar', etc: { two: 2 }}); Edit: clarified the first example
Didn't know that about `$.extend`. The jQuery API is inscrutable sometimes.
i hate hate hate HATE HATE the fact that an empty jQuery query returns an object and not something that can be compared to false. I like to run selectors once, or a little as possible, and test for their existence before usage. 
Isn't there a way to determine how many nodes were returned?
Yes, just check the `length` property of the jQuery object.
&gt; Any javascript developer who uses jQuery, YUI, Ext-JS, or Sencha either has not read the source code enough, is not capable of understanding the problems, or has read and understood the problems but has not appreciated the consequences deeply. The use one any of these libraries is substantially irresponsible and uninformed decision that puts quality and long-term success of his project at risk. Right. We'll all stop using jQuery because it's not perfect. 
Looks pretty good to me: http://api.jquery.com/jQuery.extend/ It contains examples of both the deep copy argument and the practice of passing an empty object to create a new collection. I admit though, the challenge can sometimes be to find the method that you're looking for, especially if you can remember what it does, but not what it's called.
If we were heeding advice we wouldn't need your advice. ... If you'll notice this notice you'll notice this notice is not worth noticing.
The author is one those comp.lang.javascript nuts who thinks that all JavaScript library authors are idiots. Still, it was a good article and he's right to call them out on some pretty basic mistakes.
Yep, I can't argue with the fact that he seems to know what he's talking about. Unfortunately his abrasive tone and unrealistic expectations don't really help to promote his cause. 
I hear you, but I think the current behaviour is the better way in the long run. Sometimes you want to progressively enhance all of a particular kind of element on a page (say, `a.whatever`), and you know there are none or more on the page. `$('a.whatever').click(handler)` will always work in that case. Otherwise you would have to write something like this: var links = $('a.whatever'); if (links) links.click(handler); That's no fun. 
Confusing, isn't there already a handlebar.js? This doesn't appear to be the same thing.
I do enjoy watching the progress at: http://arewefastyet.com/
Deckard: Embarrassing. Bryant: No sir. Not embarrassing, because no one's ever going to find out they're down here. 'Cause you're gonna spot 'em and you're gonna air 'em out! Deckard: I don't work here anymore. Give it to Holden. He's good. Bryant: I did. He can breathe okay, as long as nobody unplugs him. 
It's not *that* hard to get right. [NWMatcher](http://javascript.nwbox.com/NWMatcher/) does not suffer any of these problems and it is not bloated. It is also faster than the selector engines mentioned in the article. http://javascript.nwbox.com/NWMatcher/release/test/css3-compat/
Yes, but can I ride my bike without it? 
I only meant that it's not very intuitive that passing a boolean positional argument _at the beginning_ triggers "deep extend" mode. Whether it's documented or not.
I wouldn't use GPL'd or LGPL'd libraries or plugins. These licenses are way too complicated and yet completely fuzzy when it comes to JavaScript (or well, anything which isn't C or C++). If it's BSD, MIT, or zLib everything is fine.
…can you be more specific? Talk about it in code terms. What are you expecting to happen? What is actually happening?
No.
I'm most excited by the improvements they haven't even *thought of* yet.
Do you want to make like &lt;a href="http://gardentr.com"&gt;this site&lt;/a&gt; Scrolling or what do you want?
Click on "Prices", it animate-scrolls down to the prices section. Menu stays in place, all I want is the scroll effect.
Yep, exactly like that, but the menu doesn't need to scroll.
Ok. Menü position is CSS. if you don't write position:absolute for menu, menu position won't be mine. Others are only your imagine. Scrolling is jquery scrolling. http://www.learningjquery.com/2007/09/animated-scrolling-with-jquery-12 in this page explain page scrolling effectively. We use this plugin.
I'm not sure if it's legal, but I think if you do due diligence in showing your sources, it's not going to be an issue. Personally, I wrote a script to compress all the jquery plugins into a single file and then generate a header which links back to the original files. [Example here.]](http://content.ytmnd.com/assets/jquery/ytmnd_jquery.js) Coincidentally, the server hosting the originals had a disk crash this week so the links are dead. Let's hope no one tries to sue me before I restore the backups.
Can't help with the issue at hand, but that design is *nice*. Great work!
Thanks very much! I'm a filmmaker, but I've always had a small passion towards design and programming, maybe I should do this on the side for money! :)
It should be fine. You could include the compressed versions you've generated and link to those in the code and also still redistribute the original, uncompressed source files with the script. That will also make it easier for anyone who wants to make changes to the code. Then just put a note in the readme, and maybe at the top of the compressed code, telling them to reference the uncompressed versions. If you're not blatantly stealing and make a reasonable effort to maintain copyright notices, most people aren't going to care. The original authors are programmers too, and will understand you wanting to maximize performance, so long as you still give proper attribution somewhere.
haven't they already had a couple betas of ff4? seems a little late in the cycle to be changing the javascript engine.
I would just add a precision : position:fixed is what should be used to achieve this effect.
The GPL and LGPL do NOT require copyright information in all source files, only that any modifications to the source are available publicly and that the end-user is informed of where to obtain those changes. The code you minify or manipulate, if it has no underlying changes to the source, shouldn't require anything more than a note somewhere on the site to where the user can download the originals for themselves.
I like the subtle use of marquees here: http://svn.ytmnd.net/
It's interesting to see that sunspider seems to be horrible for a tracing JIT, JaegerMonkey by itself does better than combined with TraceMonkey.
jQuery.scrollTo is a decent and easy to use plugin for this
there is no prices section to scroll to. but yeah, like urbandev said, jquery.scrollto
How dare Google Chrome copy Firefox so much!
True. Definitely counter-intuitive, that.
IE wins??? What is happening to this world? Time used to be when everyone could stand together in unison and hate IE more than anything. Where will we direct this hate now? Where my hate once was, now only a hole remains, it feels like losing an old friend. I miss you IE6, may you rot in hell forever.
I have the section labelled id="prices", is that not the correct way to create a "section"?
I'm using scrollTo for the prices section, which animates horizontally (and works). But vertical scrolling does not for some reason.
Well, this is a very small subset of ECMAScript 5, and IE does this particular subset better than the rest. Not really a fair test.
didn't know prices was that part that was showing. maybe make a heading. and then fill in the other sections and then use jquery scrollto
Dunno. According to this site, "This Browser" that I'm running (Chrome 7 dev) is equal to the IE9 abilities exactly.
Would you care to be a bit more specific? I've never seen it that way.
I'm not entirely sure, but I think ECMAScript 5 evolved out of the ECMAScript 3.1 standard, which was spearheaded, coincidentally, by Microsoft... Which is not to say that ECMAScript 5 does not contain good ideas, but it misses a number of things from later versions of JavaScript, e.g., "local" (lexically scoped declarations), and I'm not sure whether IE has full support for JavaScript 1.8.5, or even 1.7. (And there isn't much reason to consider ECMAScript more of a "standard" than JavaScript: every browser should thrive to implement both, and be judged by that.)
The test suite is not a subset. It covers all of the ES5 enhancements.
The reason ECMAScript is considered a standard and JavaScript isn't is that the former was created by a committee of all the major browser vendors and several other companies, whereas the latter was created by Mozilla, and the features from 1.6 onward had no input from anyone else.
These two licenses were written with C and C++ in mind. As such they use C and C++ related terminology like "linking". It was awfully fuzzy with Java (most people avoided LGPL - there are lengthy discussions all over the net about this topic) and it's even worse with JavaScript. One key point of LGPL is for example that the user can replace a LGPL'd library with a different version of that library. With JavaScript you can't do that in first place. And of course it's downright impossible if you used something like the Closure Compiler. I also generally dislike both licenses, because they are simply too complicated. I'm not a lawyer who spent a few weeks with those monstrosities of legalize. I don't know every fine detail which their lengthy FAQs try to explain. Just try to explain - in your own words - what those two licenses mean. And don't omit anything. You'll need at least 10k words each. It's just too f-ing complicated. BSD, MIT, and zLib on the other hand are short, fairly easy to understand, and they are also unambiguous - no matter which language is used. LGPL is great for C or C++ libraries. And GPL is great for big open source projects. They make a lot of sense there.
Right, and then there is the whole rest of the standard. All that stuff from earlier versions is still part of the standard, and are (arguably) more important than the enhancements.
I prefer Mozilla's vision for JavaScript but committees always win.
&gt; You can, of course, also use the low-level $.ajax() method. Calling any jQuery function "Low-level" tickles me.
That's odd... I've used jQuery.scrollTo for vertical and jQuery.scrollable for horizontal with no issue several times... http://flesler.blogspot.com/2007/10/jqueryscrollto.html http://flowplayer.org/tools/demos/scrollable/ Double check your doctype and code structure, and keep in mind that scrollTo scrolls to an element, not a set top() position.
Firefox 4 *does* support the majority (if not all) of strict mode features. This table only tests for `this` primitive values.
1024 bytes? Oh nevermind, I actually read the article.
yep.
What are lexically scoped declarations? Both variable and function declarations are scoped lexically in Javascript (eg. they are not globals).
Mozilla's "vision" is carried out quite well through TC-39 as far as I can tell. Read the mailing list, they're very active.
So you mean the stuff present from ES3 and covered by Google's Sputnik test suite? IE9 has a higher pass rate than chrome 7, ff 4 beta, and Safari 5.
Yes. For a more comprehensive test of strict mode, follow the link in the table — http://kangax.github.com/es5-compat-table/strict-mode/ FF4 does in fact support almost all of strict mode (except `this` non-coercion; `parseInt` with leading 0 treating values as octal ones; and `eval` creating a separate binding environment for evaluation, rather than using caller's one).
On the octal thing; Firefox does throw on all other banned uses at least (I think you should add them, ie. `\123` and `0123` (literally, not in `parseInt`)). I was able to persuade ECMA and Mozilla to keep `\0` (NUL literal), as it can be very useful. I am sorta disappointed though that they left octal escape sequences in regular expression grammars.
I meant "[let](https://developer.mozilla.org/en/JavaScript/Reference/Statements/let)" (where I wrote "local"), as opposed to "var".
The most interesting part of that article is that IE9 seems to be cheating on benchmarks.
http://npm.mape.me/ They *appear* to be different implementations of the same thing...
TL;DR It's a rather generic slider.
Fuck me... This would've been nice yesterday morning. I spent about 4-5hrs combing the wilderness to find all this. A word of warning: be prepared to read source code. mongodb-node-native and Mongoose have *zero* API documentation (I never looked at express.js, seems to be documented). Luckily, the code is simple enough to follow (why I love javascript).
A solid job, but why aren't the slides in an `&lt;ul&gt;`?
The dynamic nature of the language is precisely why it's recommended to use === over ==. Because you can't necessarily predict what type of value your variables will hold, it's better to be as clear as possible about what you're expecting to happen.
&gt; it's recommended to use === over == No. If you're not sure then use ==, especially if using user input or input from another script.
 var option1 = 0 == ''; //true var option2 = '' == '0'; //false Yea, because that's the kind of stuff you want to have to deal with. 
Understand what both == and === do. Use the one that does what you intend. They both do things that are useful in different situations.
If you're not sure you *definitely* want to use ===.
I completely disagree. :) Really, most JavaScript is written using == and it works just fine. === has crept into library code because it is sometimes faster (not always). There are times when === is *right* but most of the time you should use == (just like you always did).
It's funny that you used that particular phrasing to explain why you think it's okay (I don't mean that condescendingly). Here's an excerpt of one of Douglas Crockford's talks where he discusses this exact topic: &gt; They always use the words "perfectly fine." "I did this thing and it was perfectly fine." Well, I think "perfectly fine" is double equal to "faulty." There is a difference between dynamism and ambiguity. While == may work "perfectly fine" in many or most situations, the bottom line is that it is ambiguous - something you should strive not to be in your programs. I agree that 9 times out of 10 it's not necessary. It's just a good habit to use === for the 1 time out of 10 it will trip you up unexpectedly.
I posted this article so that people understood the differences. Maybe we are muddying the water by having this debate. :)
Why are you swapping the order there? It makes it look like some kind of associativity problem. I think this is clearer: var option1 = 0 == ''; //true var option2 = '0' == ''; //false
It's definitely important to understand the differences, but I don't understand why you would want to be more lax when it comes to user input. If anything, you would want to be more strict. JavaScript, like other languages that use type coercion (implicit type conversion), has a lot of trouble distinguishing zeros (Numbers and Strings) from Boolean false. In the case of typeof it's no big deal because we're not comparing to zeroes or boolean values (undefined | object | boolean | number | string | function | xml). Instead, we know that these values are predefined, so we're not going to end up comparing to zeroes or booleans, so sure, it's probably no problem to use double equals. When you're dealing with user input you're likely to be checking for empty values on non-predefined values, so this is completely different than typeof. Now you introduce the possibility of something like this happening: var userInput = ''; // user didn't type anything if (userInput == 0) { // '' implicitly converts to the number 0 // this code executes } I know this is an edge case, but it produces something unexpected that might be hard to track down. This isn't really unique to JavaScript... PHP is probably not a good example (it has plenty of issues), but I use it a lot and I'm familiar with a similar problem with strpos(haystack, needle), which returns the position of the needle String within a haystack String, or Boolean false if it's not found: if (strpos ('foo', 'f') != false) { // this code does NOT run because the result of strpos is 0, // which gets implicitly converted to false because it's being compared // to a Boolean value } if (strpos ('foo', 'f') !== false) { // this code works! } In any case, what I'm trying to say is I agree with the others - 1) use triple equals (===) when you don't know any better, or double equals (==) when you know exactly what you're doing (as in the case of typeof) and 2) use triple equals on user input. // Appendix - back to JavaScript! // Examples of unexpected stuff (from Crockford) 0 == ''; // true 0 === ''; // false 0 == '0'; // true 0 === '0'; // false false == '0'; // true false === '0'; // false null == undefined; // true null === undefined; // false EDIT: removed invalid unexpected stuff
Nope, we're clearing it up. ;)
It was a copy/paste, sorry.
I worked with Erik (and Emil) back in 2000 at WebOS. Fucking geniuses, those guys, I learned so much from their code.
My God what hell hath LLVM wrought
The Reddit that I participate in is [r/reportthespammers](http://www.reddit.com/r/reportthespammers). Most of the time all we do is comb through the [r/all/new](http://www.reddit.com/r/all/new) queue and single out user accounts to be reported and banned. We have a high level of success doing it that way but it is labor-intensive. In almost all cases we are whacking random *new* users spamming random domains. But sometimes the spammers are particularly devious, creating new users for each post that all point to the *same* domain. These are the most difficult to whack. Fortunately Reddit allows you to view posts by domain - see the most infamous spammer [Toydots.com](http://www.reddit.com/domain/toydots.com). And that's why I'm asking for the script. If we can identify career spammers like this and mass report from their /domain/ page, it will make our lives much easier, and will significantly improve the average Redditor's experience on this site. Hope I've made sense... it's late and I'm on my 6th beer... (edit: minor correction)
This is insanely awesome. It definitely seems related to Adobe's own [Alchemy project](http://labs.adobe.com/technologies/alchemy/) (glorious hack that allows one to compile C/C++ code into actionscript bytecode, built on top of, you guessed it, LLVM), except this one is open-source, and, you know, doesn't require a proprietary interpreter to run the output. Oh oh, and the compiler itself is *written in JavaScript*. http://code.google.com/p/emscripten/source/browse/#hg/src
Well, Reddit has jQuery, so it'd be like a single line of code. I'm not sure it's a good idea though. Reddit already attempts to do automated anti-spam. A second layer of automated anti-spam adds yet more potential for false positives.
Does my [post in this thread](http://www.reddit.com/r/javascript/comments/ddj26/i_participate_in_a_reddit_that_plays_whackamole/c0zeqsl) change your mind in any way?
Alchemy has been awesome but I can see how this would be better.
For one thing, it's not dependent on Adobe giving enough free time to the Alchemy hacking dude to update it. Given that it produces valid JS code, it wouldn't be very hard to generate valid AS3 code from it as well, although it wouldn't use the neat raw memory access opcodes Alchemy uses. That'd be a reason to generate Haxe code, actually.. 
I had read it before posting.
&gt; I had read it before posting. Thanks - Not too common around here :P &gt; A second layer of automated anti-spam adds yet more potential for false positives. Considering that I am asking for help for a community that is exclusively devoted to obliterating the spam that makes it past the Reddit filters, do you still feel that way?
 '' === '0'; // true false
I made a start, might revisit it at lunch time (3 hours), might forget entirely: `javascript:void($('.author').each(function(){console.log($(this).text());}));` Now you just need to figure out the get/post request required. The post request for submitting is: `uh=xsk5f9pb5vc8bd4c2d4d2f68cb66a8357b0aa3a7e897faf6df&amp;kind=link&amp;url=http%3A%2F%2Freddit.com%2Fuser%2Fjeryyhelpshe&amp;sr=reportthespammers&amp;title=toydots+spam&amp;id=%23newlink&amp;r=reportthespammers&amp;renderstyle=html` `uh` is a hidden field from the submit form - will probably have to $.get that page and extract $('input[name=uh]').value() from it in order to make the requests. The rest of the post should be easy enough to add to a $.post request though. If anyone wants to finish off the code, be my guest :) edit: oh yeah, that jquery I pasted also gets the username of the sponsored link - just write in a test to ignore the first one, or play around with `$("*:not(.promoted) .author")`, but I couldn't get that to work in the 15 minutes I spent on it.
Yes. I understand that there are false negatives, but there are also false positives. Without making the algorithm smarter, you can't increase the strength of the filter without increasing the number of false positives. From what I've heard, the number of false positives is already fairly high. If you and your community want to help solve the spam problem, learn some math and improve the spam heuristics (allowing for increased performance both for false positives and false negatives). Otherwise, careful manual spam reporting is fine, but I don't think an army of spam vigilantes armed with tactical nukes constitutes a viable alternative.
I'd expect reddit to have similar protections against mass reporting as there are against mass up-/downvoting. Are you sure this won't just trigger some filters and ignore your reports?
Just something to consider: spammers are *people, not domains*. A javascript bookmarklet that reported all submissions *by a person* would be useful for punishing spammers, although it would also catch any "non-spammy" headliens they also posted (if spammers ever really post non-spam links). However, a script to report all submissions *to a domain* risks banning even valid content posted by another, non-spamming user... and worse, may even unfairly implicate them in spamming even when they've never done it. I'm not saying don't do it - just pointing out that you'll have to make sure that everyone involved in the process knows a "report" from you is now a vague suggestion for someone else to decide upon, rather than a considered, definite accusation from someone who knows what he's talking about in each case.
&gt; Considering that I am asking for help for a community that is exclusively devoted to obliterating the spam that makes it past the Reddit filters, do you still feel that way? In what way does "a community dedicated to catching spam" negate the problem of false positives? They're the *source* of false positives. Also, making a spam-catching system faster and more efficient does not reduce false positives - it *increases* them. I'm not unsympathetic to your cause, but you seem to just automatically assume "quicker reporting = good", and seem worryingly blind to the wider issues and potential negatives eg, a higher rate of false positives). If I was going to arm someone with a powerful system which could easily have destructive effects, I'd like to make sure they were capable of taking a nuanced view on the issues involved and weren't just some wild-eyed zealot with no appreciation for the attendant dangers. &gt; Thanks - Not too common around here :P Protip: When requesting help from a community, you'll generally get more cooperation if you *don't* insult them right up-front.
Great interview, but its a big pet peeve of mine that we call the best in our industry a 'ninja'. It seems to lessen someone of his accomplishments
I think you accidentally a word.
Nodules, I have used CPAN. I know CPAN. CPAN is a friend of mine. Nodules, you're no CPAN. 
Ah, good catch, that part was invalid. I removed it from the post.
I for one don't use `==` and `!=` at all. If I want to check if something is truthy or falsy I use `if(foo)` and `if(!foo)`. This way I won't end up with stuff that looks like a potential typo. Everything that looks like a potential typo will waste time whenever the code is reviewed, read, or modified. Everything which increases the workload should be avoided at all costs.
The benefits afforded by C/C++ in my mind, are in the realm of performance and lower level minute system integration. When performance doesn't matter and I don't need to do anything with the hardware, I try to avoid those languages because they love to make things tedious. Given that, what would be the practical use of such a system?
Maybe I'm a jerk... but tend to I ignore these "make your code worse so IE can be faster" things unless I have a real performance problem, proven by profiling, that needs to be dealt with.
Thanks.
Premature optimization is the root of all evil, as they say.
I had it described to me from a guy at msft like so... var foo = "a" + "b" + "c" + "d"; is the equivalent of each one being a COM string and concatenated like this var foo = "ab" + "c" + "d"; var foo = "abc" + "d"; var foo = "abcd"; At least... in old IE.
&gt; Just something to consider: spammers are people, not domains. We know that. But sometimes one domain uses thousands of shill users. Do a search for toydots.com to see how bad it can get.
I'm not sure if there's a more specific /r/ I should be posting this too, but hopefully this isn't a bad choice. Any comments, modifications or anything of the sort would be gratefully received!
The book, [High Performance Javascript](http://oreilly.com/catalog/9780596802806) has a nice [analysis of this issue](http://qaa.ath.cx/classic_string.png). The array approach isn't bad. You can do this pattern for instance output = []; for(...) { output.push(element); } dom.innerHTML = '&lt;ul&gt;&lt;li&gt;' + output.join('&lt;/li&gt;&lt;li&gt;') + '&lt;/li&gt;&lt;/ul&gt;'; or perhaps: rowList.push('&lt;td&gt;' + output.join('&lt;/td&gt;&lt;td&gt;') + '&lt;/td&gt;'); ... dom.innerHTML = '&lt;table&gt;&lt;tr&gt;' + rowList.join('&lt;/tr&gt;&lt;tr&gt;') + '&lt;/tr&gt;&lt;/table&gt;'; etc... IMHO, It's a rather efficient MVC-style approach. 
THANK YOU!
Firefox Web Developer extension -&gt; Forms -&gt; Populate Form Fields
Ahhh, guess that's what I get for not using Firefox... Perhaps I should make it a Chrome Extension...
No problem! Although it would seem I'm late to the party on this one...
Firebug, as glitchy as it is, is imo still the most powerful development tool. YSlow, FireCookie, FireDiff, and Page Speed make it even better. Things like Live HTTP headers are also very handy.
The main benefit of C/C++ here is the ability to reuse existing code and libraries. Performance is not going to be particularly awesome, although if this somehow takes off, browsers could end up adding support for fast access memory arrays, which would make things a little less bad. It could be used to port a game to the browser sandbox without rewriting almost any of it (drivers not included). It could probably be used to port an ancient legacy corporate app. Maybe you want a MNG encoder on the client side that's correct and doesn't take shortcuts, maybe you need encryption algorithms based on time-test implementations. There can be a number of use-cases. 
&gt; Protip: When requesting help from a community, you'll generally get more cooperation if you don't insult them right up-front. Don't read everything as a personal attack, sometimes people are making a lighthearted joke. I was talking about Reddit in general. No hard feelings, I hope.
I'm really impressed by the editor and the framework. The game looks great too. Chrome 6 BETA crashed after a few minutes of play though.
this is why god invented selenium ide. 
The current Chrome version (dev channel) is 7.0.517.5 though.
You think that you are clearing things up but really you are just confusing people for the sake of your own ego. My original advice was the best advice.
Firefox 3.6.9 on Ubuntu crashed as well. Sadly this happens to me a lot with canvas.
The same extension is available on Chrome, and has that same feature.
**TL;DR:** * Chrome 6.0: ~10ms * Opera 10.6: ~16ms * Firefox 3.6: ~30ms * Safari 5.0.1: 5ms / 55ms. * IE 8.0: 30ms / 70ms. * IE7: 200ms / **2.5 minutes**
I started writing it myself thinking of course you had googled it before asking for help. Then I googled it. First result: function addCommas(nStr) { nStr += ''; x = nStr.split('.'); x1 = x[0]; x2 = x.length &gt; 1 ? '.' + x[1] : ''; var rgx = /(\d+)(\d{3})/; while (rgx.test(x1)) { x1 = x1.replace(rgx, '$1' + ',' + '$2'); } return x1 + x2; } 
Well, of course I saw that one, as well as many other variants. I am a js newbie, and I have no idea how to take that and make it work with what I have. Every time I tried adding that code in some way the numbers just disappeared.
Just because I'm a perverse bastard: numPeopleDead.toString().split('').reverse().join('').replace(/((\d+\.)?\d{3})/g,'$1,').replace(/,$/,'').split('').reverse().join(''); E: or: String.prototype.rev = function() { return this.split('').reverse().join(''); } function addCommas(n) { return n.toString().rev().replace(/((\d+\.)?\d{3})/g,'$1,').replace(/,$/,'').rev(); } 
Holy crap. I had no idea it was that difficult/complicated to do! So do I take this line: document.getElementById("deathCount").innerHTML = numPeopleDead; And replace it with: document.getElementById("deathCount").innerHTML = numPeopleDead.toString().split('').reverse().join('').replace(/((\d+\.)?\d{3})/g,'$1,').replace(/,$/,'').split('').reverse().join(''); ? EDIT: Went ahead and did it. You sir are a god among men!
Heres a rough one that doesnt rely on regex and should be easier for you to read. It changes it to a string, splits it into a array and works its way back from the end. Send your number to the function and it will return a formatted string. eg numPeopleDead = num_format(numPeopleDead); function num_format(num) { formatted = ''; num=num.toString().split(''); length = num.length; for(i=1;i&lt;=length;++i) { formatted=num.pop()+formatted; if(i%3==0 &amp;&amp; i!==length) formatted = ','+formatted; } return formatted; }
No, *never* write code that way. You've taken the code to format a number and smooshed it together with the code that fetches the number and the code that stores the formatted number where you want it. Now, what do you do when you want to use the same kind of number formatting for some *other* number? Like your `aliveCount`? Copy and paste that whole complicated thing again? And if you have ten different places in your code where you need a formatted number? Ten copies of that code? Ouch. No, assuming that zobier's code is correct, what you *should* do is: document.getElementById("deathCount").innerHTML = addCommas( numPeopleDead ); See how simple that is? It's barely any different from your original: document.getElementById("deathCount").innerHTML = numPeopleDead; The only difference is that it calls the `addCommas()` function. This is how you should write code. Take any complicated bit and hide it inside a function, so all of the places where you use that function can be much simpler. And if you want to change the way the function works - for example you may decide to use the version that flippzz posted - you won't have to change all the places where you use that function.
Yes, this makes a lot of sense. Very similar in concept to the way that one would use CSS.
I like it, nice and clean looking! I think with all of your guys's help I am beginning to understand how Javascript works much better. Thanks!
So under Kraken Firefox is 2x faster than the latest chrome build, but any other javascript test chrome knocks Firefox out of the park. I don't quite trust this benchmark yet.
FYI, you may not want a comma for numbers &lt;= 9999: http://en.wikipedia.org/wiki/Decimal_separator#Exceptions_to_digit_grouping
In a listing within web application that may seem a bit inconsistent, though. By the same logic you could say that numbers &lt;= 100 should be written out.
zobier solution with reverse regex is much better and faster.
Sorry to place a bit of a rant here, but this is a pretty fickle reddit. I can post a one liner and get told off for being cryptic/arcane/showy. Or I can post a simple easy to read, unoptimised solution suited to beginners (as the op has stated he is) and get people jumping the shark for it being too basic and/or slow (speed is also hardly a issue here). Someone please write a guideline as to wtf everyone would prefer?
Some people code, some complain about other people's code. Don't sweat it.
 Chrome 6.0.472.59 13610.2ms +/- 0.3% Internet Explorer Platform Preview 4 48787.6ms +/- 0.4% Opera 10.62 11620.1ms +/- 1.7% Firefox 4 Beta 5 10428.3ms +/- 0.2% Safari 5.0.1 16140.9ms +/- 0.2% Tested on Windows 7 x64, Intel i7 930, 12GB RAM. With these results we need to know what the other vendors has to say.
 use NumberFormat; var formatted = NumberFormat.format(numPeopleDead); This is simple, efficient, gets locale stuff right, and doesn't work because Javascript doesn't have a freaking module system. /RAGE FACE
Well, that settles that.
This function from your blog entry fails 7 of my numeric tests: var isnan = /^(NaN|-?Infinity)$/; function isNumeric(num) { return !isnan.test(+num); } * false : Empty string, expected: false result: true * false : Whitespace characters string, expected: false result: true * false : Tab characters string, expected: false result: true * false : Boolean true literal, expected: false result: true * false : Boolean false literal, expected: false result: true * false : Null value, expected: false result: true * false : Date object, expected: false result: true To properly check if a value is numeric, I currently use: function isNumeric(n) { return !isNaN(parseInt(n, 10)) &amp;&amp; isFinite(n); } These variations also work: !isNaN(parseInt(n, 10)) &amp;&amp; !isNaN(+n) !isNaN(parseFloat(n)) &amp;&amp; isFinite(n) Additionally, I'm not quite sure what the point of the is() function is with your examples. I can't think of a logical use for it. As already stated in many other comments, Douglas Crockford has several excellent references covering typeof, == and === usage. 
In any case it seems to work and the numbers never go higher than about 4,000. So it works for me!
How easy is it to install VirtualBox and *load up a linux OS* vs. installing Cygwin? Honest question — I just followed the instructions and got it working; the Cygwin install wasn't *that* difficult, and I would imagine installing a Linux OS would be more difficult...
Maybe. I guess it depends on how you like to work. For me it was easier because I didn't want to have to download all those dev tools and wget, etc. I read that and I said to myself "I'd rather spend my time getting the *true* environment setup, than hack together some Cygwin environment." And using VirtualBox is going to get you as close to the true environment as possible without doing a real install on your box (I can't because the wireless drivers don't work under a real install, only VirtualBox). As for Linux, a Linux install is dirt simple, especially with a distro like Ubuntu. It takes 2 minutes to run through the install wizard then maybe 10 more to copy the files etc. Plus, I've found VirtualBox to be an invaluable dev tool. It's perfect for setting up nice little sandboxes for testing.
http://www.arewefastyet.com/
Great article. There are a few errors here and there, but the general theme is dead on.
I believe The jQuery template syntax referenced in the post is already outdated. See [here](http://github.com/jquery/jquery-tmpl/blob/master/demo.html) and [here](http://forum.jquery.com/topic/jquery-templates-proposal) for more info.
The main point is not the syntax "##" or "&lt;%" or "{{" are almopst the same, the difference is in the IDE compatibility, pre-compilation (or not), readability. I'm just finished to integrate in the same templating system a solution "Resig's style". I'll be out sooner with a new post. Stay tuned on http://reoberto.open-lab.com
&gt; you cannot nowadays write code without a decent IDE, or better: you cannot write decent code without a great IDE! This is why I use IntelliJ! Excuse me? So what are all the Vim and Emacs users? (I'm not saying IDE's are bad.) My personal favorite template is jQote2, it stays out of the way and I can use the full power of Javascript. (And the syntax is identical to ASP.NET) 
I have a feeling this is a bad way to create multiple instances of an object since they will not share the same prototype. Which means that if you create 1000s of these object, they will have 1000 different prototypes and not share just one. A better way would be var point = function (x, y) { this.x = x; this.y = y; } point.prototype = { setPoint: function (x, y) { this.x = x; this.y = y; } }; Then create the objects like myPoint1 = new point(x, y); myPoint2 = new point(x, y); Now all the point objects will share the same prototype. (Edit: formatting) 
&gt;My 2c: If your devs have a hard time figuring out when, or even remembering to use the 'new' operator where proper; you have much more fundamental issues than "classical classes" vs. adaptive objects. I know its in *The Good Parts*, but I agree with you about the new operator. I feel like once you understand the fundamentals, its not dangerous to use it.
Not one that wouldn't be super easy to break. You'd have to have a variable that I could easily read as the captcha text. There are a couple ones others have made (http://www.archreality.com/jcap/) though, note the top text on the site - &gt;***NOTICE (2008-01-22): Due to overwhelming controversy, the developer would like to place emphasis on the fact that this script's main purpose (in it's basic form) is primarily for experimentation. No developer (including this one) would ever recommend implementing client-side scripting for the protection of highly sensitive data. I'd recommend finding a back end one. We typically use [Recaptcha](http://www.google.com/recaptcha)
A captcha made from Javascript is entirely pointless. Captchas are designed to prevent bots from having their form submissions processed, and bots don't run Javascript. The form would submit completely unprotected.
You could, by using javascript to output some base64 encoded images or something.
**There is one rule of javascript:** leave all security functions to the SERVER SIDE. Client-side security an oxymoron! Every javascript developer should be beaten with this phrase from day one!
If bots didn't *ever* run Javascript, then it would be trivial to build a form that required Javascript to enable submission (e.g. insert the submit button using JS after page load, or even the full form HTML), thereby avoiding all bots. But some bots do run JS, so a JS Captcha could still have an effect. Still not the best solution, though.
ah this reminds me of a "developer" who was implementing a login page using only JS. It was for a photography site, so the person could manage their photos etc... I tried to explain to him why he cant do this, but he said he didnt know how to do it any other way. I just assumed users would be turned off by the 8mb swf to even attempt the login.
The general captcha process is: Generate =&gt; Input =&gt; Validate When you have the server involved (on the generate side) you know that it is difficult for a computer / bot to reproduce those calculations b/c they don't know them. You can make the validation be all client-side by simply sending back &lt;img&gt; + &lt;md5 of answer&gt; ... pretending that l33t-sp33k is captcha: "|-|377O" =&gt; "hello" =&gt; md5( 'hello' ) =&gt; b1946ac... So, if the server sends: [ "|-|377O", "b1946ac..." ], you can validate that only a human can give input to md5 that gives the output b194ac... The problem is that if you give your generating code *and* validation code to the client they can generate and validate arbitrary captcha events. So, while it might *look* like a captcha it won't do what a captcha is supposed to do (prevent bot-like abuse of resources). --Robert
**Whoa whoa whoa everyone!** We're all assuming that this is client side Javascript (in which case, stupid, don't do it etc.), but surely we can't go a week without being reminded about server side JS? In which case you could use node.js, look at some existing libraries in PHP, and start hacking from there. You'll probably end up using ImageMagick, which I can't find any wrapper for at the moment, so you'll have to use the process module. As a theoretical browser based exercise you should use canvas, render some text to it, get the pixel data and apply manipulations.
I did forget this was reddit and "alot of people" (myself included) are on the nodejs/serverside js kick
yes windows 7 64bit
All this talk about security meanwhile the OP hasn't said a thing about this JavaScript running on the client (I guess it's unlikely he wants to do server side javaScript but that would be valid).
if the implementation to create the captcha is done by javascript on the client side, then it can be reverse engineered on the client making the whole effort pointless.
No working example?
I used to love VB6 programs that required a login password, almost every time there was a plain text admin/debug password that could be found by opening the program in notepad and searching for password/pwd/psswd 
To every javascript developer this is common knowledge. The problem is the non-developers doing javascript.
Shaving bytes is all well and good but don't sacrifice code maintainability to save a couple here and there, if such optimizations are absolutely necessary it might make sense to use/create some sort of tool to change your development code to production. Hopefully there are better low hanging fruit you can attack before resorting to this (ie. images)
1 question != everyone
or just use mod_gzip
We all know that isn't what they meant.
True, but I would say in this case it's more interesting to explore the question a bit further
&gt;There is one rule of javascript: leave **all** security functions to the SERVER SIDE. (emphasis mine) Actually, this is wrong IMHO, or rather: incomplete. What it should be is: Leave all **crucial** security functions to the SERVER SIDE. The only security functions that should be done client side are "extra" enhancements. There's lots of stuff you can do client side to enhance security, but you should not **rely** on it in any way. For example here; a common technique for fighting bots with some sites (like Stack Overflow) is an "invisible captcha" which relies on JavaScript. It works as a lot of spam-bots don't have the ability to evaluate JavaScript. This is obviously very easy to bypass, and needs to be combined with other techniques like traditional captchas, but it's an example of some of the types of extra security you can implement client-side, depending of course on what exactly your needs are.
&gt;A captcha made from Javascript is entirely pointless. Actually, it's not. There are quite a lot of websites that use what is basically a JavaScript Captcha: they are called "invisible captchas". They work because the majority of bots don't evaluate JavaScript. So it's not so much "entirely pointless" as it is "easy to bypass"...it obviously needs to be combined with other techniques to be really effective, but that doesn't mean it's not useful in **some** cases. 
I know it's not totally related... You could potentially send an image (or data representing an image) along with a secondary data packet that is encrypted with the code that the human must enter. This code will be able to live very short lives, so it won't be able to be brute forced (i.e. if you generate the captcha now, make sure that in ten minutes or less it's no longer active). that way you'll still use server-side (JS or not) to generate the secret code, but you'll be able to validate the code before doing the round trip back and forth. [You've actually inspired me to write something about it.](http://elis.ws/client-side-captcha-verification/)
A quick point of reference on this topic. http://www.reddit.com/r/javascript/comments/depjf/is_it_possible_to_make_a_captcha_with_javascript/c0znjfp
Most of the commentors are assuming this is some sort of image-based CAPTCHA. As defined on Wikipedia, a CAPTCHA is "a type of challenge-response test used in computing to ensure that the response is not generated by a computer." Why couldn't you generate a series of colors , images, or math problems the user must click on/solve on using JavaScript? Of course, the only downside to all of this is that you're assuming the client is running JavaScript. In the event they are not, they wouldn't be able to submit whatever it is you're attempting to protect.
If you'll read through the comments of that thread, you'll notice that I was inspired by that exact thread ;) And note that this has nothing to do with security, only user experience.
Yes. Don't.
I kept clicking on it, expecting some fancy interface. And no, I didn't read the words. I just looked for the demo. I mistakenly clicked on the screen captures first.
Why dont these kinds of sites make the demo link more obvious, or better yet, embed the demo on the page?
awful ux for the demo. fyi you hover over the names on the bottom to get them to slide out. Really the skewing on the photo is ugly and jquery pretty much just animates the marginleft of the photo, thats it. Something that's existed for years.
Don't JSONP calls work over HTTPS?
wow thats great! Thanks
touche.
Same comment I posted on the site, in relation to the reddit post from yesterday I guess you can save a bit by waiting for a valid value before sending to the server, really all that would change is the captcha graphic itself is generated by the client, if theres any sort of server validation though it no longer is a client side captcha imo.
I got both locked at 60FPS on FF4b6 and IE9b1. Enable hardware acceleration in FF4 and make it a fair fight.
Whenever I try that in Firefox Nightlies, the UI ends up looking all glitchy. I'm guessing there's a reason it isn't enabled by default. 
Also it's vendor locked to Windows, closed source and proprietary so that's pretty awesome too according to most Redditors who recently delighted in having ads of "honest discussion about IE9" pushed in their news all over Reddit. Due to this feature though I receive a *0 FPS* for IE9 on my tests though so actually Internet Explorer 9 appears buggy as Satan's underpants.
Sorry that not everyone on reddit lives to serve the FSF.
21 fps on chromium 5.0.382.0 for me 1920x1200 (and 6.0.472.53, just upgraded)
Nightlies != Beta release. Usually at least, assuming that's the case with FF here too.
What operating system?
2-6 fps on my notebook (`Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.2.10) Gecko/20100915 Ubuntu/10.04 (lucid) Firefox/3.6.10`). Yay.
I would try IE9, but... \*\* *does backflip onto motocyble and peels out* I run linux! 
2 fps on the iphone 4. Does safari on mac os x have hardware acceleration? I'll check when I get home.
i tried ie9 preview some time ago, but i decided today to install ie9 beta on my windblows virtual machine (my other virtual machines are xp, so no soup for me there). a long time ago i wrote a small javascript [canvas game](http://www.binarni.net/projects/franjo/). i am not really css meister (meaning, i should look and fix it somehow), but i got same fu*ked up front page (same css features like previous ie versions) plus game refused to open (i have one visible and one hidden canvas). i understand that people are excited, but in general i am pretty sure ie9 has all the legacy with css bugs like previous versions and microsoft has put, like always before, set of specific "features" for javascript/css/dom/.... this new features is something they were suppose to do a loooong time ago, and just because they did it now does not mean we should all switch to ie9 (and windows 7) and forget about 15 years of their torture with ie. it is still good old microsoft, and there will be plenty of ie8,ie7 on business machines for a long long time.... but other then that, good to see microsoft doing some good work with their browser, and i sure hope it will make chrome/firefox people move their ass faster.
"Live to serve" is obviously too excessive, but I will assert that the FSF is a tremendously useful organization, especially if you're concerned with rights, freedoms, open standards and so forth.
One of the better jQuery articles out there, especially when it comes to performance. Lots of clever techniques in there!
My favorite part of this book, which I love, is that she takes on the topic of code organization, and how **not** to put everything inside a giant `$(document).ready()`.
5-6 on my Motorola Droid with the stock browser. Granted, I am overclocked.
12fps Fedora 13, Chrome 6 and Nvidia drivers installed
Please remove the trailing . from your link.
Why do you test two different Firefox versions, and only one variation of hardware acceleration each?
You know I'd be a lot more forgiving of all those rabid Linux fanboys if they accompanied all their ravings with gymnastics and motorsports.
shamelessly stolen from xkcd of course... http://xkcd.com/272/
It does, as do most of the Firefox 4 betas. You have to enable `gfx.font_rendering.directwrite.enabled` and change `mozilla.widget.render-mode` to `6`.
14fps chromium 6.0.472.53 (57914) Linux 2.6.35-4.slh.9-aptosid-amd64 Intel(R) Core(TM)2 6300 @ 1.86GHz Intel Corporation 82Q963/Q965 Integrated Graphics Controller (rev 02)