What do you mean exactly? Why can't you write it in Vue?
Practice.
Mostly because of things like animating scroll: $list.animate({ scrollLeft: $list.scrollLeft() + distance }, speed); I have no idea how I would animate a scroll position in pure javascript with basic easing.
Seriously, does any dev prefer this over React/Vue/etc.?
Yes, but which are the old ones?
Learning functional programming really helped me view different ways to achieve the same things.
It's just the rotation code. The rotation libraries provided by three probably have better compatibility than the stuff she put together. 
&gt; animate a scroll position in pure javascript with basic easing sounds to me like a perfect stackoverflow question hint hint 
Thats your criteria for ‚Äúknows how to code‚Äù? Yikes
It's nice to see a Three.js demo that uses modern JS practices and readable code. Their style guide drives me crazy, it pads everything with white space and makes it so sprawling and hard to read.
That‚Äôs your definition of ‚Äúknowing how to code‚Äù? :thinking
Google has been pushing for development of these custom elements for quite a while now. But has not been able to get that many devs attracted to it and also browser vendors have only recently implemented these. Polymer, a Google project, was where all the HTML web components development started and they are being used in many Google projects.
Well there's more overhead with things like React/Vue/Angular/etc. so if your project doesn't have a good reason to use one of these frameworks, this is probably a cleaner way to develop using a leaner stack... I know that I really dislike developing without components because I got used to it, and I dislike that this preference sort of forced me to use frameworks when I didn't necessarily need them... I'm interested in trying this out for sure. Not totally sold on it until I try it, though. 
Seriously, does any professional web dev visit and read reddit?
Use css transitions. It pretty much replaces mot uses for animating in jQuery. Vue even has a great built in support for creating simple animations. https://vuejs.org/v2/guide/transitioning-state.html
I don't think I phrased my post very well, but I was interested in a bit more a discussion from the reddit JavaScript community rather than a definitive answer. Like whether people would favour pulling in a library to handle things like this or just write some vanilla JS. I'll update my post slightly.
Do you want to remove "45" as well? Or just non-numeric strings?
Excellent. Now you can try to use their code to create a bookmarklet üòé
Have fun : D
You can use css transitions or velocity.js
I find it funny that they care about reducing their landing page load by a few ms, when you need superfast internet to stream any video content XD
Very nice. Going to try this out today. Thanks for sharing!
PDF link - http://hs-1667658.t.hubspotemail.net/e1t/c/*Vhjf2x4z4YcqW1QDnJl271lxM0/*W1Mc5BC4hk3ttW8PLdNl4sxbwt0/5/f18dQhb0S5fs9c-mG2W69MSrn8LCvkbW2Qy9CD7tBMhQW6Blznz1Vq7GqVLDpF18B-Wz0VZ6Q4W1p7ybxW5yLrhL5wMw-5W3TJNm83M2y_nW63Kg1m1n3hZGW8SrtQG3Kz704W5cvzXZ4CQWqxW1BrVZ_1xXxr8W2_VNPZ2K_L3SV6rKqx5sFnHRW4zyh6l30THS_W4dPpCT7K94m2Vvf9fl1DWSSbW57Qqn41FsphSW4bJ02h4b_rKwW7MbC372dwyBxW7dDxTN7mWsnXW7dz8FN1nY85cW1nbj7V6jvS29W69NG1w6Pr5qtW2mPgvX3Kq2SWW8sYz-P3tpkRvVRFkK45G18KhW3y9KYQ3dgtNkW3XkfGy8gLl78W8FNyFK8KdZdDVFGW3v5mfDkzW8m3dJM3TZsZNW43dlkT15mCgZW3pfVCJ8jGJgYW5QvlMK8KnT0NW5jS6TZ5DKnNwW3J5GDp41dkFpW8GTm3j5mVL7FW8lBGHq5rNhP3W42b3Zs5x6M7bW3ncHMX5tM2k8W3RmvR15lMfGJVsz5Qs64V3p2MBz2GFwKJnCV3qXTq3n8MkZW2z3q-23TdwkrW51fy4163dvmVW1bHJb_8tzmRxW2GD9D749NC28W4jPkrj67ttbWVcw_qd6XSB5lW5lbqB06_d5-WW9gwgjC5V9XlMW3f5_rb1nX-Frf6Q026404
anyone got a tip or can point me in the right direction?
Wordpress and Medium are two good options. It depends on your needs. A lot of companies use Medium and it's definitely easy to use. People love to hate on Wordpress, but gives you so much out of the box that younger platforms don't give you, and even if you think you don't need certain features at the beginning, you'll soon find it would be great if the blog could do x, y, z and there will always be a WP plugin that does it for you. I don't like to waste time on blogs so Medium is what I use for personal posts and WP what we use for our startup's content.
Practice and repetition. Same as becoming an expert in anything else. It takes years of doing it over and over again. 
Well, until you need to support browsers that need polyfills, that is... That said, I think Web Components and frameworks solve completely different problems, and I don't foresee everybody dropping frameworks as soon as Web Components are natively supported for a sufficient number of visitors.
Even if it were possible by scouring the dom and pulling the right links. I would say don‚Äôt go down this path. It‚Äôs fraught with issues and COR errors and it‚Äôll break every time the site is updated. Though if you want a general idea of what to do: Iframes are sandboxed away and will not get events that you make on runtime. I‚Äôm assuming a web app here as well. The best you could possibly do is to see if you can register events after the iframe is loaded, add the link clicks, capture the click and reload the iframe with the new link. 
Amen
 return Number.bedBefore10pm();
I‚Äôve written a few books that explain JS to programmers ‚Äì they are free to read online: http://exploringjs.com
Indeed pretty nice! I'm going to get it too!
Totally agreed. Frameworks definitely aren't going away. I just think it's nice to have components available for use when you don't have a reason to use a framework. Different tools for different problems :)
&gt;Seriously, does any dev prefer this over React/Vue/etc.? You can use Vue to build out standalone custom elements like this.
Any npm modules that you can recommend to host a personal / small website?
I'd say it's nice to have them available when you _are_ using frameworks as well :)
Modern vdom implementations can fit under 3kb. Every React app can shrink down to 2 and a half kb with preact-compat for instance. The fun part comes when you realize that each web component that you load internally relies on a framework. If you load a couple you'll inline some Polymer, some Skate, some Lit, some Vue, some Preact, etc. And even if they're all based on the same, the polyfil alone is larger than anything you're doing now. 
This is my first attempt at anything programming language related (Implementing my own) but here is how I implemented a basic tokenizer - it is in C# rather than JS but should allow you to follow easily enough: https://github.com/danielcirket/language/blob/develop/src/Compiler/Lexing/Tokenizer.cs I didn't particularly do any research beforehand but does seem like a reasonable approach, its definitely the most simple part of any compiler/interpreter though
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [danielcirket/language/.../**Tokenizer.cs** (develop ‚Üí aa51735)](https://github.com/danielcirket/language/blob/aa51735e9c7d34d1861a8728ed57b6e0d18ac383/src/Compiler/Lexing/Tokenizer.cs) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dowwt8g.)^.
The answer is: [no](http://www.npmtrends.com/angular-vs-react-vs-vue-vs-@angular/core-vs-skatejs-vs-litjs-vs-@polymer/polymer-vs-@stencil/core).
Ha brilliant
You mean the same people that are working for over 20 years on "standards," which in their language is code for perpetual backward compatibility, shims, polyfills and browser-checks, and still haven't managed to get to a state that can compete against native on its own? Well sign me up. 
[Flickity](https://flickity.metafizzy.co/) might be what you're looking for. You'll still need to write the CSS yourself of course.
https://www.reddit.com/r/ProgrammerHumor/comments/78ua91/we_can_tell_you_its_wrong_even_when_it_works/
The basic code would be like below. var theVariable = 9; var mainTimerId, variableDecrementerTimerId; function mainTimerHandler() { console.log("theVariable", theVariable); if (theVariable &lt;= 0) { clearInterval(timerId); clearInterval(variableDecrementerTimerId); } } function decrementVariable() { theVariable--; } mainTimerId = setInterval(mainTimerHandler, 1000); variableDecrementerTimerId = setInterval(decrementVariable, 1500); The above uses timer interval to decrement the variable, but you can implement it based on e.g. mouse click to a button.
React/Vue/Angular(2+) are wrappers for these web components then? 
postmessage?
I mean the same people who created the web, your browser, and everyone else's browser, and who religiously read and follow those standards in the making of such things as opposed to an anonymous poster on reddit.
I was wondering the same thing. I'm surprised Angular wasn't mentioned at all in the article since as soon as I started reading it my mind screams "Directives!"
Umm actually no. That's like saying when you use a polymer component in a react app you'll also be serving polymer. You'd using a web component made just using native APIs(many available on webcomponentsjs.org) just like you do for react apps. 
The browser is the buggiest app on your computer, it is the most fragmented target you ever written an app for. Yes the web is good, but their work hasn't exactly been glorious and they've committed countless of errors along the way. Meanwhile we're running apps today that supercede the browser, than can run natively on mobile, desktops, watches, robots, consoles and whatnot. In a unified language, with shared code. Scheduling that lifts performance into native territory even inside the browser. I'm not sure why i should ignore their work, is it because you think they're not involved in the WHATWG? Many of them are actually. 
Agreed. I can see the point of Express being lightweight and "plugin-based", but omitting this always felt like trying to follow convention over producing a framework that was complete.
Polymer is a framework. If you use a web component that internally uses Polymer, then yes, you'll be loading Polymer. If that component uses Skate, then you'll be loading Skate. Polymer isn't a standard, 99% of it isn't cast in specs. The Webcomponents spec consists of a few harmless calls to create a shadow-root and that is all. But you're left with a generic dom inside that needs driving. Polymer introduces templates, parsers, emulators, code-syntax, data-binding, etc. to create dynamic apps. That code won't magically drift away when you're shipping your component. 
Saved, this is gold. Thank you, sir!
And all that is based on standards you seem to tell other people to ignore. If it weren't for standards, nothing would work together.
It is only because of their "standards" that absolutely nothing is working together. The WC spec changed drastically over the years. Apple and other vendors had petty fights over in in part motivated by their fear of specs competing against their revenue models. Polymer had you rewrite your app from scratch from 0.5 to 1.0. Then again from 1.0 to 2.0. Then again from 2.0 to 3.0. And the API is still flopping around, like, suddenly we learned HTML imports aren't good any longer. Most developers aren't gullible enough to fall for it, because we have fallen for it for more than 20 years.
These components exist in the same way a `video` element does. If you wish to use one in [insert framework here], go ahead, its just a HTML element. I don't stay up to date with frameworks anymore, but i assume most don't produce web components (yet). 
They don't wrap the web component API, so no, they aren't.
Wow! I haven't heard anyone talk like that in maybe 10 years! Back when people used to think Microsoft and Internet Explorer should ignore the W3C and standards altogether just like you propose. I would say your statements are shocking but then I remind myself this is reddit, where such outrageous statements are the norm!
Polymer is not a web standard.
The fact that I can't just read it online without entering my email turned me off. Sorry, I am not subscribing to it.
Frameworks don't break or ignore standards.
awesome looking forward to taking a closer look at this when I'm not on my phone later. thank you.
Just use simple, plain old JavaScript and some jQuery. This would take the least amount of time to learn and is peobably what you want, and it could be implemented in a couple of lines probably. No need for any big frameworks or planning, if the project grows, rewrite it. Investing four hours now to avoid potentially throwing away two isn't worth it.
Never said it is. But it shows how fragile and basic the spec is.
Didn't specify what my definition was, you should brush up on your reading comprehension.
It's not fragile at all. Web Components &amp; Shadow DOM V0 was a Google-only proposed specification (like SPDY vs HTTP2). V1 is a WHATWG Web Standard adopted by all major browser vendors, and there have been no breaking changes since then.
Sometimes they even push the standard to evolve. I wouldn't be surprised if native DOM diffing and render functions were introduced.
Hey daedius - thank you for the response. This is all really great info - especially when you mention digging deeper and seeing how Google writes their code. You really seem to know your stuff. Do you have any particular projects that you remember doing yourself, or things you worked on at work, or source code you dug deeper into and what it taught you? I'd love to hear your anecdotes.
Self induced JavaScript fatigue. You mentioned Vue, React, and Angular. Pick a framework and build something.
&gt; Why is the index equal to 4? Because that is the value of `i` when the callback function runs. The function captures a reference to `i`, so it has whatever live value `i` has when the callback executes, and the callback executes after the loop has completed. It does not capture a snapshot or copy of the value at the time the callback was defined.
For the highlighting stuff I would add a class to indicate it‚Äôs been selected. Each time the element is clicked check to see if it has the selected class, if it does then remove it and if it doesn‚Äôt add it. The class should have its own background colour. As you add or remove the class, you should push/pop the element to/from an array containing the user‚Äôs selections (just the pieces of information you need really, not the entire element object). Then when the user submits, send up the array with the rest of the request and there you go. Hope that works! Sorry if I missed stuff, on my phone right now
HTML imports going down is a pretty big breaking change. We can tiptoe around the fact that once you've called `attachShadow({mode: 'open'})` and extended `HTMLElement` you're confronted with a barebones dom. Unless you use it raw it needs a driver and the prevalent approach has been Polymer, in some peoples heads almost synonymous with web-components as you can see below. And it has been the a fragmented experience so far.
Did you see OP post the PDF in their comment?
Okay.
But the argument in for loop `i &lt; arr.length` changes value of `i` from 0 to 3. It never hits 4?
Quick aside: this changes with `let`. If you replace the `var` in the header of the `for` loop with it, you get different indices.
For examples, see any NASA ‚Äúphoto‚Äù
It increments it to 4, which stops the for-loop from continuing forever.
Actually it does. The `i++` part is the final expression of the for loop. for ([initialization]; [condition]; [final-expression]) statement The final-expression runs at the end of each loop. So at the end of the 4th loop, i=3, **i** gets incremented one last time to 4. Thats why the 5th loop fails, since 4 &lt; 4 is false. --- Reference: https://devdocs.io/javascript/statements/for
I'm using these on (one of) my current side projects, and for the most part, I really like them. Google supports them directly without the polyfills, and while firefox kinda supports them with a flag change, the pollyfill library doesn't detect this, so I'd keep the flag off for firefox. There is some weirdness to them, so be warned. You can have issues where the browser shows no errors, but your whole page just doesn't show up because of issues with one components inheritance. The component conforms to the spec, though the inheritance works in some but not all cases; this can be frustrating to troubleshoot. I'd stay away from component inheritance until you have a very solid understanding of how these interact. At most, I would inherit from native elements, but not your own. Another thing I would recommend is to take the time to define your methodology around styling early, and try to avoid edge cases. While the article doesn't mention it, you really want to read up on CSS3 variables, and use them. Define a 'variables.css' and keep out any hard coded values outside of your component. Look to Bootstrap's variables for guidance on how to do this. CSS variables cross the shadow DOM boarder, while CSS styles don't. If you're just creating a one off component, this isn't neccesary, but if you're using this as a replacement for React/Angular/Vue, it'll save you a lot of boilerplate. I'd skip Sass/Less, unless it's just to generate the variables file. You may miss the nesting and a few other features offered by these libraries, but because of scoped style (your styles inside of the component don't leak out to other components). Using HTML Imports, your page can selectively use which components are needed by the page. It can reduce your footprint, and there are potential benefits to this if you're using HTTP/2. HTML Imports aren't going to be the standard, at least not in their current form, so this will change. So you'll also want to avoid using libraries in the components, as loading of these libraries happens for each component that references the library (which will slow your page load, and lead to a lot of unnecessary files being repeatedly downloaded by the component). A way around this is to include the required javascript libraries on the page, and reference them in the components, but this is brittle, and makes your components less portable. With ES6 features, I find I don't use man (any really) libraries anymore. Modern javascript features like fetch, map, filter, querySelector, etc... have significantly reduced my dependence on lodash, jQuery, etc... So you may find you're not needing them. HTML templates can be used as a substitute for a templating framework, though you'll need to be clever in how you use these, as the base templating doesn't directly support conditional/loops/etc. Though javascript template literals sorta do, since you can nest javascript and additional literals in parent literals. So how you go about this as a templateing engine replacement is you write your template in a template element (adding inline javascript for your loops and conditionals) and then read out the template as a string. You then construct a "new Function", passing in a model object with your values, and the template. Essentially, you're doing a slightly safer eval, though this isn't completely safe, so make sure you're using https (you should be anyway) and don't allow/accept users to upload/mutate these. You'll also want to be smart, use the templating for the initial load or server side prerender, but you'll want to be reactive with updates, so don't just reuse the template for any change to the data unless the change significantly changes the content. You can control the API, and how rendering happens, so you can use a DOM diff library to mimic React, or you can just be smart about how you update. I wouldn't recommend using these yet if you're not seasoned, but if you're a lead dev, you can set this up for juniors to use rather quickly. The tooling isn't there yet, and you'll be re-inventing the wheel a fair bit. But if you're looking to cut your page size by a couple orders of magnitude, this is a very reasonable option. While not complete, my current page is very functional, and is smaller than the smallest frameworks or templating engines that I would commonly use for this. The polyfills aren't huge, and if you sniff your header, you can dynamically determine which polyfills are required by the user agent. It's also great for computer generated pages. Given an AST, you can essentially walk the tree, and generate very clean markup. Rapid prototyping is also a huge plus, as you can easily isolate a component by just creating a new html, add the HTML import, and you're good to go. Once you have a stable prototype, then you can setup webpack/rollup/etc... to target a wider range of browsers. If you have any questions, let me know. 
Why do you code blocks have like for scroll bars?
Maybe you could find more learning resources at r/LearnJavaScript :)
`i` being incremented to 4 is what causes the loop to terminate, because it is what causes `i &lt; arr.length` to become false. 
lmao I thought you were trolling but then I was four way scrolling
As a previous gulp user, it was quite tricky and difficult to be honest :p
I think the other commentators had some good recommendations with Gatsby and Jekyll.
This! After playing so much with directive, I just can't get back to using something vanilla. Still, from time to time, I really like to do a side project using vanilla js, so I might try this in the future, but at the time, I'm married with AngularJS
In all honesty, your best bet would be to make a mobile site. Now, it sounds like you've been contacted, if that is the case you'll need to know what features from the main site they would want in the mobile app. Apart from pretty static features it's not really fair to yourself if they are paying you for a one time release app that is supposed to dynamically adjust to their websites' changes.. What kind of framework does their website have?
Cool thanks, and question. Why aren't you using only one language? I only now Javascript and learning other stuff to get a job as Frontend so no time to learn :/ 
Make a native one you mean? they want the whole site, so that is why i am using an iframe. I just witheListed &lt;allow-navigation href="*://*.sjomannskirken.no/*" /&gt; as it said that it might do the case. Now it loads in the webviewer, but my menu is lost. it is built with HTML5, CSS3 and JS
This makes me wish I was using MobX over Redux.. it almost looks too good to be true!
&gt; Using HTML Imports, your page can selectively use which components are needed by the page. Why use HTML imports to import javascript? I see webpack as the best solution for bundling your custom components. Then it's pretty much the same workflow for bundling another javascript/"thick client" application.
plebs
Oh true. Thank you.
How is this simplier? It uses third party libraries, doesn't use MIT, it doesn't handle truthy values the same, it always presumes an object input instead of also allowing arguments. It's probably slower too.
Hey! Sadly I'm not the author.. you can find his Twitter page right here though!: https://twitter.com/raymondcamden
 &gt; [45, 66, 90, "remove",100].filter(Number.isInteger) [45, 66, 90, 100]
I will remove the external library and switch to MIT. As for presuming object - it must limit the choice, otherwise one can simple use NPM's `classnames` library. As for speed - I will include benchmarks and we'll see which one is faster.
My friend, the post is a joke.
You can use a [Proxy](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy). You can define a`construct` trap to intercept calls to the `new` operator. You can use that to return fake values or augment the real values or whatever you want to dream up.
I'm using a Jekyll theme and didn't notice that. Thanks for letting me know! I'll fix that ASAP.
Wow. I didn't know about/thought about most of the things you talked about here. I also encountered the "web components just don't work" when building a project with it. I do have some questions regarding web components, especially the styling and slots part. I would love to ask them sometime!
From a practical standpoint, it sounds like both parties would be better off if they redesigned their website with more of a mobile first approach.. Having JS interact with iframe elements isn't a solution I'd pursue.
We know. but... thanks for that.
Have you tried using just what's provided on official website?
Just because I‚Äôve learned different ways to use different languages (personal preference). Also, sometimes library capability is an issue. You‚Äôll learn more as time goes by and you‚Äôll develop so don‚Äôt worry when you see people using 5languages. Sometimes less it more. 
it uses system.js and also wants you to code along in plunker instead of just giving you a repo... ive learned a bunch of different frameworks over the years. i have never seen such a uncoordinated cluster fuck that i see with the angular community right now.
But why do this at all? Your code is not significantly smaller or simpler than the existing classnames.
If all you care about is passing it from one page to the next you can use the same strategy. window.location.href='nextpage.html?name=' + line; //or whatever then on the next page you can parse the querystring. Here's a couple of ways to do that: https://davidwalsh.name/query-string-javascript
Is it really that simple? I couldn‚Äôt find anywhere online that did anything with an html file Thanks 
Try changing overflow from scroll to auto. .highlight{ background-color: #efefef; padding: 7px 7px 7px 10px; margin: 20px 0 20px 0; overflow: auto; } Great article though, can't wait to try it!
You could consider also using cookies. Set a cookie, then have the second page look for the cookie. https://www.quirksmode.org/js/cookies.html
Allow me to clarify. Hiring developers at lower wages who have the specific or generalized skills the company needs does not make them cheap or abusive, which is a generalization anyway. It means they realize how basic the skills are that they need, and that they can hire people new to development. The article, if I recall, was not based on the needs of companies hiring experienced and capable developers.
&gt; I didn‚Äôt care too much about Webpack either, until I found out it could do the same things as Gulp does. This is why I started to think about switching from Gulp to Webpack for all of my projects. Makes totally sense. Tool B does what tool A does so I'm switching from A to B. &gt; One could argue that Gulp is a task runner while Webpack is not. Anyway, with Webpack I‚Äôm able to do the same things I was doing with Gulp. But with less code and a declarative configuration. He then proceeds to implement these points: * taking one or more HTML file, generating the final HTML, and producing the minified version of each * optimizing images * compiling SASS to CSS and producing the minified version * adding vendor prefixes to CSS * transpiling Javascript with Babel * watching files and re-compiling on save in webpack, but with about three times the code you'd need in gulp.
Very similar to React's API. Seems straight forward. Instead of accessing `this.state` and `this.props`, Web Components have `this.getAttribute('key')`. Both have callbacks for when they are placed in the DOM: Web Component's ` connectedCallback()` and React‚Äôs ` componentWillMount()`. And they both call `render()` to update. This API for rendering via Shadow DOM looks awkward to use. Instead of using templates or functions to created elements like `h1('Hello World')`, it uses jQuery like selectors to update an external file. To update a text value: this.shadowRoot.querySelector('.title__label').innerHTML = 'Hello World' // With some aliasing I now have jReact const $ = this.shadowRoot.querySelector $('.title__label').innerHTML = 'Hello World' Templates are easier to use than selectors for updating text. Their API is closer to the DOM. React provides JSX, and `createElement/Component()`. Vue has a mustache template. This allows developers to populate a template and organize the DOM/style at the same time. If static HTML and dynamic data are split between files, then a developer will have to look at two files simultaneously to populate the DOM with information. Connecting the Component is too complicated. To fully initialize the Component you have to manually acquire the current document global, the shadow dom, and the template in `connectedCallback()`. That could all be injected with `customElements.define('element-name', ComponetClass)`, if it accepted the a template selector. This could easily be improved in future versions. A few final questions. Can these be nested? Separation of concerns by nested is a great way to separate UI code. If so, when a parent calls `render()`, do the children also call `render()`? 
Well your #1 problem is that you're not calling cToF or fToC, you are actually over-writing the functions that you wrote above. You need to store the value of the prompt in it's own variable, then call cToF(userInput) - where userInput is your variable name.
Think thats done it pastbin.com/EEvctAhH
I don't know man. I've always felt that using gulp gives me a lot of freedom and readability. Webpack seemed like a chore at first, something that never happened with gulp. Moreover, it's easier for a beginner to understand gulp that diving into the blasphemy that webpack is. Anyway, it's a technology and everyone has their views. P.S. - I have to use webpack at my work due to react
Yes, anything after the ? is not used by the browser, but you can use it in your code - if you open the console and type window.location you can see all of the things you can use.
Good article. Quick read and he demolished a good half-dozen dangerous misconceptions about testing all in one page!
You will also need to add an else if (Q1===2){ in replace of the else}
haha no, when they mature, these web components are going to make those frameworks obsolete. i hope they find a sensible type system, because typescript is obnoxious and provides less type safety than something like flow
The ultimate reason your code did not work was the way you tried to *call* your `cToF` and `fToC` functions; you were *assigning* the result of the `prompt` to variables, which then overwrote the functions which had the same names. This could've been fixed by writing: ``` cToF( prompt("How many degrees?") ); ``` Check this out; https://jsfiddle.net/4Lozj79k/1/ - I removed the `var cTemp = celcius` and `var fTemp = fahrenheit` parts. They're redundant here, because the functions' argument can be used as-is. - Instead of assigning the converted temperature into yet another variable, I changed it so that the functions simply *return* the calculation's result. This way the functions become composable, instead of just serving one predetermined purpose. - I removed the prompt which chooses between modes. There's technically nothing wrong with it, but I figured it's simpler (for both the user and the programmer) to just convert the user's input both ways at the same time. If you want to keep it, at least remind the user which choice they made, when prompting them for `degrees`. - Finally, I added two `console.log` statements to print out the result of both conversions, as well as wrap them in explanatory text. Notice how I'm calling the `cToF` function with `degrees` as it's parameter, and how the result is *returned* where the function was called. 
Mostly because I find myself in situations where I'd prefer to refer a function instead of the current logic of 'classnames'
The [quickstart](https://angular.io/guide/quickstart) shows how to use the cli. Use it. You can do the tutorial using the cli.
Don't *have* to, but it's good practice
Ah
By the way big props to monterail for making Vuelidate! Best validation plugin i used
So, is or will there be a method to bind object or array to element attribute? Like what react or vue have. From one side it‚Äôs highly usefull and removes a lot of boilerplate, from the other it goes against html spec, and widens area of responsibility in how reactivity will be handled etc. Something wrong with it right from the start. Looks like web-components will never be full replacement solution to modern view libs.
Very good post, my only concern is at the very end advocating for users to freeze their web component implementations. This defeats the ability of debugging and monkey patching. Please do not do this. You have the shadow dom, you have closures, you have plenty of other ways of making your consumers life hell.
I managed to get part of the way. Ive loaded the code under /tmp/ I only wanted to test the crawl against careerbuilder so I moved all the page files besides that one to a new folder, page_tmp (could be my issue?) [user@ip tmp]$ ls LICENSE npm-debug.log package.json querys README.md source @TODO.md www [user@ip tmp]$ cd source [user@ip source]$ ls apis bots crawler.js gigs.js index.js node_modules pages pages_tmp [user@ip source]$ cd pages [user@ip pages]$ ls careerbuilder@com@@jobs-javascript-remote.js [user@ip pages]$ [user@ip ~]$ ls node-v4.6.0 [user@ip ~]$ npm start npm ERR! Linux 4.9.51-10.52.amzn1.x86_64 npm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "start" npm ERR! node v4.6.0 npm ERR! npm v2.15.9 npm ERR! path /home/ec2-user/package.json npm ERR! code ENOENT npm ERR! errno -2 npm ERR! syscall open npm ERR! enoent ENOENT: no such file or directory, open '/home/ec2-user/package.json' npm ERR! enoent This is most likely not a problem with npm itself npm ERR! enoent and is related to npm not being able to find a file. npm ERR! enoent npm ERR! Please include the following file with any support request: npm ERR! /home/ec2-user/npm-debug.log **After moving all the files under home directory i got the same issue:** [user@ip ~]$ ls LICENSE npm-debug.log querys source node-v4.6.0 package.json README.md @TODO.md [user@ip ~]$ npm start &gt; crawler@1.0.0 start /home/ec2-user &gt; benny-hill-x node source/index.js sh: benny-hill-x: command not found npm ERR! Linux 4.9.51-10.52.amzn1.x86_64 npm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "start" npm ERR! node v4.6.0 npm ERR! npm v2.15.9 npm ERR! file sh npm ERR! code ELIFECYCLE npm ERR! errno ENOENT npm ERR! syscall spawn npm ERR! crawler@1.0.0 start: `benny-hill-x node source/index.js` npm ERR! spawn ENOENT npm ERR! npm ERR! Failed at the crawler@1.0.0 start script 'benny-hill-x node source/index.js'. npm ERR! This is most likely a problem with the crawler package, npm ERR! not with npm itself. npm ERR! Tell the author that this fails on your system: npm ERR! benny-hill-x node source/index.js npm ERR! You can get information on how to open an issue for this project with: npm ERR! npm bugs crawler npm ERR! Or if that isn't available, you can get their info via: npm ERR! npm ERR! npm owner ls crawler npm ERR! There is likely additional logging output above. npm ERR! Please include the following file with any support request: npm ERR! /home/ec2-user/npm-debug.log Any help would be greatly appreciated.
I managed to get part of the way. Ive loaded the code under /tmp/ I only wanted to test the crawl against careerbuilder so I moved all the page files besides that one to a new folder, page_tmp (could be my issue?) [user@ip tmp]$ ls LICENSE npm-debug.log package.json querys README.md source @TODO.md www [user@ip tmp]$ cd source [user@ip source]$ ls apis bots crawler.js gigs.js index.js node_modules pages pages_tmp [user@ip source]$ cd pages [user@ip pages]$ ls careerbuilder@com@@jobs-javascript-remote.js [user@ip pages]$ [user@ip ~]$ ls node-v4.6.0 [user@ip ~]$ npm start npm ERR! Linux 4.9.51-10.52.amzn1.x86_64 npm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "start" npm ERR! node v4.6.0 npm ERR! npm v2.15.9 npm ERR! path /home/ec2-user/package.json npm ERR! code ENOENT npm ERR! errno -2 npm ERR! syscall open npm ERR! enoent ENOENT: no such file or directory, open '/home/ec2-user/package.json' npm ERR! enoent This is most likely not a problem with npm itself npm ERR! enoent and is related to npm not being able to find a file. npm ERR! enoent npm ERR! Please include the following file with any support request: npm ERR! /home/ec2-user/npm-debug.log **After moving all the files under home directory i got the same issue:** [user@ip ~]$ ls LICENSE npm-debug.log querys source node-v4.6.0 package.json README.md @TODO.md [user@ip ~]$ npm start &gt; crawler@1.0.0 start /home/ec2-user &gt; benny-hill-x node source/index.js sh: benny-hill-x: command not found npm ERR! Linux 4.9.51-10.52.amzn1.x86_64 npm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "start" npm ERR! node v4.6.0 npm ERR! npm v2.15.9 npm ERR! file sh npm ERR! code ELIFECYCLE npm ERR! errno ENOENT npm ERR! syscall spawn npm ERR! crawler@1.0.0 start: `benny-hill-x node source/index.js` npm ERR! spawn ENOENT npm ERR! npm ERR! Failed at the crawler@1.0.0 start script 'benny-hill-x node source/index.js'. npm ERR! This is most likely a problem with the crawler package, npm ERR! not with npm itself. npm ERR! Tell the author that this fails on your system: npm ERR! benny-hill-x node source/index.js npm ERR! You can get information on how to open an issue for this project with: npm ERR! npm bugs crawler npm ERR! Or if that isn't available, you can get their info via: npm ERR! npm ERR! npm owner ls crawler npm ERR! There is likely additional logging output above. npm ERR! Please include the following file with any support request: npm ERR! /home/ec2-user/npm-debug.log Any help would be greatly appreciated.
I don't get your point - he wanted to make sure he could do on webpack all the stuff he was doing on gulp. Makes sense to me.
Good write up, but with no links to a snippet ( e.g. Codepen or Fiddle ) it's probably not going to make a compelling case for web components and convince anyone they're ready for broad consumption. I'd like to know if I spend the time setting it all up as per the article, that I'll get encapsulation in IE11 / Edge on Windows 7, 8.1 and 10 because that's still a fair chunk of our audience. Pretty much every example / test I've tried with numerous Polyfills ( Promises + ShadyDOM / Shady CSS for IE11 ) still fails to prevent style bleed in IE11 on Windows 7. Polymerjs uses the same polyfills and so [also fails](https://fiddle.jshell.net/svqjed34/), although it's fine in Firefox and Edge on Win 10. I so want Web Components to work ( even with horrid Polyfills ) across 99% of our audience, but they're not there yet. 
I've built and maintained large projects using both. I will always prefer Gulp (and Browserify).
Nitpick: npm init -y or --yes not --y i think
What about puppeteer?
Cool article. I love web components! Unfortunately, HTML Import is dead. The browser makers that don't yet support it have said they are not going to support it, and the ones that do support it are going to deprecate it. Polymer version 3, Googles web component library, is moving to ES6 modules instead.
I've been working on improving testing on project, and I can't say I quite understand. I like having a test fail when something I've done as an unintended consequence causes an issue elsewhere. When I make an implementation change somewhere, it is useful to be able to follow the failing test to refactor the needed changes elsewhere in the project. The author mentions shallow renders not being so great, but its part of the big draw of testing just plain knowing when and where something changes a part of your system? I'm talking mostly about javascript here, as I like my test of verify that I am input and outputting the right object shapes/types. I don't know how one has any confidence in their code without testing such things without strong typing. I'm not saying that I'm right, mind you. I just don't understand what one would test if not the most basic functionality.
You got by any chance the code for that page, I'm trying to make a carousel like the one that's being use there!?
But why would you switch to another tool and spend time learning for literally no gain. The point of changing is because it offers you something what your changing from, doesn‚Äôt 
The difference is between testing behavior of systems and testing the implementation of logic. He's suggesting, and I agree, that it's better to 1) test systems you write working together 2) test the behavior of those systems and 3) don't test that each line of code works _as you wrote it_; rather tests that each unit of code _behaves how it should_. The last item is a subtle difference, but what it means is that you aren't testing to make sure you wrote code correctly. While this does test behavior, it tightly couples your tests to every line of code you wrote. Suddenly if you change a line you have to change a test. Instead your tests shouldn't care _how_ you did something, only that the thing you did works like it should. In this way your tests are decoupled from implementation. Think of modules or functions like black boxes for your tests. You should be able to completely change implementation and still have your tests pass. Then you know that what you changed still works exactly like it needs to. When your tests are tightly coupled how do you know that your tests are failing because behavior changed or simply because implementation changed? Sure, getting all your tests to pass means it's probably working, but that is a lot more extra effort for little to no payoff. This also, I find, causes you to think more about how the systems of your project are architected and work together, giving you a more hollistic understanding of your code. Speaking of which, I'm a big fan of the idea of "mock nothing until you are forced to". From a certain perspective, mocking everything is testing implementation. It means your tests are now tightly coupled to your mocks. When this occurs you could completely change the behavior of some code, forget to update the mocks, have your tests still pass and yet your code fails in actual usage. Long story short, the idea presented here is about thinking about why you are writing tests in the first place and what you hope to accomplish from them. Unit tests are great, but without integration tests you aren't necessarily assured that everything works _together_. So why not save some work, kill two birds with one stone, and just write integration tests. 
I hate to be that guy who says, "use this other framework", but use [this other framework](https://vuejs.org/). It's pretty straightforward, it won't get in your way, but it has enough legs that it won't limit you. Read the guide page and tell me if that doesn't cover your use cases.
It would be great if there was some data behind this. Though I more or less agree somewhat. I have problems that 'code coverage' isn't defined at all and I find that term meaningless when it's used by just about everyone. 
Some of this feels misguided and confused to me. For example &gt; Instead your tests shouldn't care how you did something, only that the thing you did works like it should. In this way your tests are decoupled from implementation. This is completely consistent with unit testing as I understand it, and yet I also believe in achieving high code coverage. I don't see these as competing goals. If you're struggling to maintain unit tests as you change implementation details, it means your implementation details are leaking. Integration tests in my experience tend to be very complex and difficult for new members of a project to understand. They're much more likely than unit tests to depend on equally dubious implementation details details about how units are combined, and due to the corresponding lack of true unit tests developers are unaware of how problems with each unit are corrupting the overall architecture. &gt; It means your tests are now tightly coupled to your mocks. But the question arises as to why your mock isn't just a legitimate use case. If you can't write loosely-coupled unit tests then how is the rest of your code loosely coupled? This is an architecture smell that you're writing a monolithic nightmare that's slowly drowning you in technical debt. I feel like the author walks right past this and doesn't see it when they admit that their open source projects have 100% code coverage because they're small libraries that a lot of people depend on. I should say something else: the purpose of unit testing is NOT to find bugs. Finding bugs is a happy consequence of any interaction you have with the software, including unit testing. But the real purpose of unit testing is to document the expected behavior of the software in a human-and-machine-readable form.
I just use both, √† la [Webpack Stream](https://github.com/shama/webpack-stream). I have tasks unrelated to my Webpack bundle (starting a dev server, building docs, bump version numbers). Also I despise npm scripts. Fitting some obnoxious bash script for a CLI that was tacked onto some package after the fact, into a single line of JSON just bothers the crap out of me. Obviously, you could write a real bash script and just call it, but this is 2017, we have gulp and most packages have better JS APIs than their CLI counterpart...
I was going to correct you and say its **deprecated**, not depreciated, but as it turns out one is just another word for the other. So you win. Have some gold.
Thanks! Will apply the styles today.
Fancy! I remember looking up the same thing.
There is a difference. connectedCallback doesn't call render. I've created a function and named it render and explicitly called it unlike componentWillMount. Also yes these components can be nested. I'm writing a post where I'm showing how to nest components and create higher order components, parent child communication, maintaining state, etc. As far as render is concerned, you'd have to call render methods from either the parent component yourself or call it in connectedCallback of child and add the child to DOM using the parent's connectedComponent function.
I guess I should add a codepen. It'd make it easier for people to play around with components. webcomponentsjs pretty much works on every browser if you're careful enough. But some weird issues are still there. And what I experienced was using these polyfills actually worked great with IE 8 and didn't work all that well with Firefox. 
Hmm it is interesting that we talk about 'code coverage' as appose to say 'feature coverage'. Anecdotally, I'm definitely in favor of the later. Especially for front-end tests.
If you like the programming in React style, you might like my project https://github.com/richardanaya/webcompose/
This text block must be the Reddit equivalent of the great Wall of China.
This is great, I feel that unit tests are a complete waste of time and actually make me less confident about my code, but since our team is all about 100% code coverage I write it anyways. Personally I feel that the usefulness of TTD is a Relic of RoR and enforcing structure and more discipline when dealing with thousands of highly coupled objects each containing their own state where edge cases arise in unpredictable ways and it can be scary. But with React everything is mostly stateless and all the state is contained in one place, so to me unit tests feel completely pointless since none of them contain or modify state so I never worry about code changes in one place breaking code somewhere else. For me TTD makes sense for Rails but for React it's just a huge waste of time. Only time something breaks is if someone renames a prop, which is a solved via TypeScript. For React and UI logic integration tests are the only thing that matters to me. 
What's funny is this is essentially the opposite philosophy of https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell
Maybe I'm misunderstanding some terminology here. So I'll use an example: Say I have an model object called Foo. I want to ensure that Foo always has the right shape. That it always has a property bar, that take a Baz object. I want to ensure that there is no possibility that Foo can ever be created with anything other than a default Baz or precisely a Baz object passed into the constructor. I do checks in the constructor for this very purpose, and throw a descriptive error immediately when it is not because I want to fail early and descriptively on construction rather than later in somewhere else in my app when that object has been touched by thousands of line of code. I don't know of any way to check those requirements without testing that I'm throwing an error and testing that Foo.bar is actually a Baz. I will have to assert on those implementation details in my tests explicitly. If I change my model, it is very possible that those implementation details will cause tests to fail. I don't see a way around that, why I wouldn't want such a thing to happen, or why I wouldn't want to be so careful about my model's integrity.
I'm also someone who prefers to have a (very) healthy suite of tests. I don't believe the author is saying you shouldn't have those tests. Those are integration tests, and wonderful to have. The author is mostly saying that you don't necessarily need 100% coverage. Sometimes, getting that last &lt; 15% coverage or so is just testing the code that someone else wrote and tested in their own library already. I would absolutely agree with him there. There's no real point to that - you already know it works. Plus, after a certain point, having a huge suite of tests can slow down deployments or development due to the long run times. So, it's good to know what needs tested and where. No need to write tests just to have them. Tests should all have a well-defined purpose.
&gt; from the other it goes against html spec The W3C is set to officially recommend custom elements, most of the rest is already in recommendation status, so what do you mean goes against html spec?
I have been trying a few more of these, results are on my GitHub. But I found this post today. http://www.datchley.name/recursion-tail-calls-and-trampolines/ really good explanation of recursion in JavaScript and how it works. 
Did you check the Layout section in this tutorial https://mithril.js.org/simple-application.html? &gt; I also feel working around that changing the url doesn't 'reload' the page on screen is a bit 'hacky' and is perhaps open to a maintenance nightmare. I don't understand this. Did you mean changing screens/pages without full-page reload is hacky? Another way to get helps is heading to https://gitter.im/mithriljs/mithril.js. The community there is very friendly and helpful. 
Well, you can write components so they're all in javascript, but this loses you a lot of functionality of tooling. Linting, syntax highlighting in many tools, etc. The way I'm implementing them, they're a single html files, with a template element, a style element, and a script element. Like a vue component. Bundling on HTTP/2 isn't a good idea, unless you're setting up your bundling carefully, otherwise it'll slow you down. You can use it, like I reference at the end, but my test show considerable speed benefits to multiple small files over HTTP/2. Regardless, that will slow you down fiddling with with webpack setups and whatnot when you're trying to flesh out an idea. When I'm coming up with a POC, it's all creative. I want to prove out a list of points in order for it to be viable. Adding things like webpack don't add any value to my process, at least not until I need to look at targeting older browsers.
Fire away anytime. I'm on holiday, but I'll try to answer as I'm able. Slotted styling can be a little trickier depending on your goal. And the current shim isn't as comprehensive as I'd like, but it can be worked around.
Yea, sorry about that. I wanted to share what I'd found out, because they have great potential, but are still a little raw. Didn't think it would challenge the post for length when I started.
In the whole discussion of testing 'code coverage' is probably the **most** well defined and measurable term. It is simply the percentage of code lines executed by the tests. 
I am using Grunt at work so far, was looking a bit into Webpack and I still don't really see why I'd switch. It seems way harder to understand the typical Webpack script than a Grunt Script, even when they are doing the same thing. 
We have started using headless chrome and firefox and replace all our Phantomjs based tests with it. You can find a quick step by step guide from https://engineering.upgrad.com/turn-your-website-testing-painless-with-chrome-and-firefox-headless-92b6f023d375
Yep, and also J.B. Rainsberger's talk "Integrated tests are a scam". The problem with this approach is that it doesn't scale. It works very well at first, but very soon your test suite will be taking minutes to run and at that point you've totally broken your dev cycle. Plus, you've missed tons of edge cases due to the 2^N conditional paths problem, and you've lost most of the design benefits of TDD by "working around" the pain points which are _supposed_ to be there.
Test behavior not implementation details. That you decide to inject that object through the constructor is absolutely an implementation detail. You will need to call the constructor in your tests anyway out if necessity, but rather than testing the constructor you should be testing public methods that perform a function, i.e. what your class is supposed to do. How it decides to use that dependency (or not) is not your concern while writing the test. Regarding your example: if you want to add some defensive coding to quicker prevent future mistakes you could check the type in the constructor and throw an exception if it's the wrong type.
An important point which isn't mentioned in the article regarding the pyramid is that the higher layers validate the requirements of the tests in the layer below. For example, your integration tests can tell you if the unit tests should demand that there be a `computePrice()` method or a `computePriceWithTax()` method. Unit tests only tell you if what you wrote is correctly implemented, not whether you should have written that in the first place. Same with End-to-End testing or manual testing. It can tell you what scenarios your integration tests should be targeting. This might seem obvious to some, but in the last 12 months I've seen a team who were heavily into TDD build a system from the ground up and at each layer baking in their faulty assumptions about what the code should be doing. When an experienced QA person joined the team it became very clear just how little value the 'testing' up to that point had. In summary, you need the whole pyramid and as early as possible. 
&gt; Personally I feel that the usefulness of TTD is a Relic of RoR From what I've been able figure out, some kind of TDD cult formed around RoR. That is the impression I get from the RoR devs I've worked with. 
That mostly depends on what concepts you are already familiar with in addition to JS and ES6. Angular is still popular despite its version chaos, each version requiring you to learn new paradigms. React has been pretty rock solid and straightforward the whole time. So I guess React is easier. Make sure you also adopt redux for more complex projects.
Personally I would go with React. It‚Äôs adoption rate is really high and it opens you to using React Native and React VR. As far as difficulty, I have not used Angular since the 1.X days but React was fairly easy to get much easier than Angualr. Hardest part was understanding the data flow. Make sure to pickup Redux while you‚Äôre at it.
Do you need to pick one of those? Because if you're looking for a popular frontend framework that is easy to learn your best bet is [Vue.js](https://vuejs.org/). If you can't learn Vue.js though, React would be a better fit than Angular. The latter is much better used with Typescript, which is another thing to learn.
I‚Äôm also a developer myself ‚Äì I get it that it is frustrating to leave your email and receive a 7 pages "report" where 2 of those pages are trying to sell you a product, and you got yourself subscribed for tons of daily spam. I hate it. However, this is not the case. As one of the creators of the report, I believe that asking for an email is quite justified here. After all, it has been around two months of work, resulting in around 80 pages of content. I tried to make sure that after the report you won‚Äôt receive any "sales" emails besides 2-3 emails asking for your feedback regarding the report. I believe that‚Äôs a fair price for the value you get. You can always click unsubscribe the moment you receive the report. :) 
It was a long since I did not serious development but I really doubt that one should do more integration test than unittest. It totally dismiss the fact that the unittest are cheaper to create as the unit part pretty much never change while integration part are more likely to change as integration part will change too.
What I think the problem with this article is that it treats every kind of tests as **having the same goal**: provide confidence that your application is working. And yes, the higher-level tests give you more of that. They're great at catching regressions. Where unit tests excel, however, is **locating the bug** once you've found it. When a higher-level tests fails, you know that there's some part of your application that's not working, and some general idea of what's going wrong. Ideally, though, at that point you also have a unit test failing that tells you what the bug is. Another thing that I think unit tests are great for (all though less necessary in e.g. Elm) is to help you find edge cases you forgot to implement. If you spend some effort on them, unit tests help you systematically analyse your code paths, and find e.g. error conditions you did not handle. 100% coverage helps with this, as it forces you to consider each line. However, I agree that you needn't test everything. What I'd argue, however, is that you explicitly mark untested code as ignored for coverage, with a comment about why it's fine not to test that bit. That way, you can still rely on the coverage report to make sure you've tested everything relevant.
Well, if your code doesn't contribute to a feature... What's it doing in your project? :P
It's not a good idea to learn react and redux at the same time, it only increases mental load without any gains. He should start with react, you shouldn't use redux until you absolutely have to.
Or of code branches executed, or of statements executed, ...
&gt; I don't know how one has any confidence in their code without testing such things without strong typing. He does say: &gt; Static typing and linting tools like Flow and ESLint can get your a remarkable amount of confidence
NightwatchJS + browserstack or soucelabs
I think part of it is terminology is different. OP talks about making "integration tests" by "mocking less", which means he is essentially (partly at least) just using unit tests for "integration testing", allowing the unit tests to spread out more and test more than just a single method/class. I think that makes a lot of sense and the only thing that makes sense to allow tests to stay unmodified when refactoring code is that a *unit* is a more abstract concept that does not map one-to-one with any construct in the code. I think a better terminology that I saw on the google test blog some years ago is to talk about *small tests* instead of *unit tests*, and anything that stays within the same process without accessing a file system or network or anything like that is *small* even if it spans almost your entire code base. There was a great google talk by one of their test engineers also a few years ago mentioning unit tests and "friendlies", ie classes that you have already tested and that have no bad side-effects, so that you know that when you unit test some method you can allow it to call the friendlies without having to mock them, essentially allowing your "unit tests" to grow and cover more of your code (and find more bugs!), taking on some of the work of classical "integration tests" without all of the heavy cost of those.
I think a problem is that a *unit* has been increasingly narrowly defined over the years. In the last 5 or so years I even heard many argue that a unit is a single small method and that everything it does must be mocked. If you consider a unit more an abstract unit of stuff to test, that might be a method, but later you refactor it so that the method (unit) is now a big set of classes with complex interactions, you can have unit tests that depend less on implementation details and that will support you when refactoring instead of just making it painful by forcing you to rewrite mocks. And also it will test the integration between methods and classes (even if that is not the high-level integrations I would cover only with integration-tests, like different servers/clients communicating).
Here is the post from 2010 about Google's test sizes: https://testing.googleblog.com/2010/12/test-sizes.html I have no idea if they still use them, but I think it was at least a good attempt to solve the endless confusion about where the limit between unit tests and interaction tests is. But no matter if you call them small or unit tests I think they have a good list of things a unit/small test can do (ie anything as long as it does not communicate with anything in the outside world like the file system or network or other processes) as opposed to limit their usefulness immensely by trying to force a unit to be a function or method or class like I unfortunately have experienced.
It's extremely valuable information though, so thanks for that! :)
Rainsberger distinguishes "integrated tests" which is possibly what OP is referring to here from "integration tests". An "integrated test" is a test that hits multiple units (i.e. when it fails you don't know where to look). Whereas "integration test" is mainly used for non-isolated tests, ones that do I/O. Ironically despite the drawbacks of non-isolated integration tests, they are nonetheless essential at the program boundaries (but should be kept small). Within the core of the program itself it shouldn't be necessary to use integrated tests to get full coverage -- under the JBR approach you check that all parts talk to each other correctly using "collaboration tests" for the client (dependency user) and "contract tests" for the server (dependency implementation). This is a fundamentally different approach from the one talked about by OP -- while it can be labour-intensive, it tends to lead to a more flexible design. OP's approach is actually extremely old school -- it's a hacker vs manager approach where you are trying to justify time spent writing tests. Which is kind of strange because it's written with the assumption that he's already mocking &amp; stubbing out dependencies, so his shop's already sold on the virtues of TDD, so why not spend the extra time to get a more decoupled design? On the other hand the heavy decoupling architectural style is traditionally associated with statically typed languages and I can see why it may turn off some JS people. Especially with the low barrier of entry to JS development. Many times I've seen a problem with Java codebases where a new hire comes in, finds the decoupled style confusing because they're used to splattering I/O everywhere, and refactors the whole lot back to a big ball of mud.
It is definitely a problem in both Java and JavaScript that there is very little done by the languages or by conventions to isolate I/O. Functional languages often have naming conventions at least to make it obvious when you call something that might result in I/O, so you know what to avoid in your unit tests. I did not read anything about "integrated tests" but not sure I like having to separate them from unit tests at all. If I write a test that a very simple function returns the correct output for some input I do not want to ever have to modify that test as long as the API of the function stays the same (which it ideally will), even if the implementation grows over time and you end up with a huge mess of different classes to implement that function behind the scenes. As long as no I/O is needed from the pov of my test it is still just a unit I test, and since I never had to modify my test code it helped verify that breaking out all the parts from the original small function did not break it. I really dislike the idea I have encountered that as soon as the function has grown beyond being just a small function everything it does must be mocked out, so suddenly I only test that my mocks are correctly configured and everything else happening in the function is lost and only (at best) tested by other unit tests (that also mostly test that mocks were correctly configured).
IMO you'd should look for some lightweight solution that handles it nicely as you really shouldnt be wasting your time on something thats already been done before. Mainly because stuff like easing wont exactly be straightforward to implement. 
I really wish that ATDD would be more popular practice. Large codebases with no tests, or only unit tests can be a pain to work with. I still remember some colleagues of mine just running curl commands all time to test that an API was working. With acceptance/integration test, you know that if your test pass and if your test is good, then your feature works. It lives you with the peace of mind of knowing that your job is done.
Go for react, the community is very big and the documentation is very good.
Not the answer you‚Äôre looking for, but the reason you see so many libraries not strictly sticking to a functional style is because in a lot of cases that‚Äôs the best route to go down. I‚Äôve got a great example from work for this. We have a guy that loves functional programming, he‚Äôs good at it and he knows all about it, but he sticks to it a bit too rigidly. Consider the way he was working out percentage: const percentValue = _.chain(value).divide(100).multiply(percentage).value(); That‚Äôs great in that it‚Äôs highly declarative, the functions are describing what‚Äôs going on and you don‚Äôt need to know lodash to understand the code. However, we‚Äôve imported the entirety of lodash (which is unavoidable when using _.chain), we‚Äôve written way more code than we need to, and it‚Äôs just unnecessary. Looking at how we would normally work this out using an expression it‚Äôs pretty obvious which is the best route to go down: const percent = value / 100 * percentage; The same thinking applies to things like function composition - often it just isn‚Äôt worth it. Another pitfall of sticking too rigidly to FP is your code becomes too onion-like. You have to peel back layers upon layers (functions upon functions) to get to the code that you‚Äôre after. Sorry I don‚Äôt have any examples of functional code in the real world, but this should at least explain why you have a hard time finding it. If strict FP is what you want you‚Äôll find most of it around academia. Check out Haskell if you haven‚Äôt already.
React, hands down. It's much closer to plain JS and has a relatively small API surface. 
described insanity around fp pretty well!
I'm gonna have to be the person to say don't learn a framework yet if you only have a grasp on the basics. Work on the fundamentals first. React is probably easier, but it requires a pretty decent understanding of JS along with introducing the extended JSX syntax.
I agree with this.
I have a Google interview coming up for Front End Engineer, and just wanted to say this is awesome. I can build anything imaginable with React, so it has spoiled me a bit, and I've found myself having a bit of trouble visualizing how to build without it. In the interview, I'm pretty sure they're going to ask me to build widgets/components using raw DOM manipulation without frameworks and whatnot, so it's nice to know how to do it the vanilla way. This helps bridge the gap so I can still think in components like I'm used to, but just write them differently. Thanks!
I'll let the fanclubs argue which is better, as I'm a fan of both. In terms for ease of learning from knowledge of ES6. I'd say React, as React uses regular Javascript mixed with HTML, where as Angular and Vue use voodoo magic mixed with HTML. This means React at a basic level is easier to learn. Although when you get to doing more complex things and a full website I could see the argument as Angular is a full framework that it would be less intimidating to learn. Not that React will be complicated it's just there are a lot more ways of doing things
React is easier to learn than most frameworks because the cognitive overhead is minimal. It is a small lib with a tiny api surface. I've never had to study documentations and such, you pick up the concept and start making apps. Also needless to say, it has the highest adoption rate and the biggest components eco system, bigger than all the others combined: http://www.npmtrends.com/angular-vs-react-vs-vue-vs-@angular/core
I've been working on a functional wrapper around Web Components with [Switzerland](https://github.com/Wildhoney/Switzerland).
Those functions are mandatory when you use webpack. There is no way to turn that off. It's how webpack achieves the ES6 module transpilation. I can see three options: - Ditch webpack and use the Babel and SASS compilers directly from the command line or from another build tool (such as gulp) - Ditch Babel entirely. Many modern browsers support a lot of ES6 out of the box now and you don't need a transpiler at all. It could be fine for a school project where you don't need to support older browsers. - Keep using webpack and add a minifier like UglifyJS to obfuscate variable names, but this could be a problem if the final source code should still be readable
Erm, no, you can get full or high unit coverage without testing line by line, an example would be testing a public function which may call 4-5 "internal" functions, but without actually explicitly testing the 4-5 functions themselves
Why are the `const` here not functions? The function composition is only to used to compute `percentValue`. It should at the very least be something like `const calculatePercentValue = (value, percent) =&gt; ...`. And furthermore this is an extremely trivial example, which of course makes FP seem like overkill. Image you had XML that you needed to run through several transformations line by line. This could be const ourCoolBusinessTransform = compose( filter(mentionsWidowmaker), map(colorizeInJungebug), groupBy(levelOfCoolness) ) This would need type signatures though otherwise it's hard to know what the function takes as arguments. Contrast this with what I often see which is more akin to: const ourCoolBusinessTransform = (...) =&gt; const widowmakers = foo.filter(value =&gt; { ....do stuff }) ... and on and on Of course you could argue that this is just sloppy and more functions should be extracted, but the usual imperative JS style often doesn't encourage that. Or in other words: it's easy to just type away happily because without adequate tools to do composition and partial application, you might not even consider it. Anyway... we could get into a huge discussion about pros and cons which would probably lead nowhere and has been done countless times before. Your example does bring up a fair point although, as mentioned, I'd say it's also a bit contrived.
An integration test is a slow feedback loop. They take a long time, traditionally, to spin up (because they usually init an environment), to run, and to generate feedback. They can also be tough to troubleshoot. Consider an example where you use promises, errors and stacktraces can be swallowed, leading to obscurity when things go wrong. Sure, integration tests are necessary for anything that will inevitably hit production, but strongly agree that they "kill two birds" with one stone. What if you simply forget a few integration tests altogether? It's feasible because when you're when you're not shooting for a specific target coverage percentage, there isn't necessarily an reliable indicator that you've left some tests out. Unit tests are awesome for fast feedback, help you spot regressions, and ultimately make your code easier to understand. Sometimes they're harder to write (e.g. Middleware-based apps) but in my opinion they should never be left out altogether 
I'm willing to debate whether that guy is actually good at FP or, at least, that the example is actually a good example of FP :) I mean, the value of FP is in a completely different place than the difference from... const percentValue = value / 100 * percentage; ...to... const percentValue = _.chain(value).divide(100).multiply(percentage).value(); ...which I wouldn't defend as a particularly _functional_ approach. In fact, I would argue that, no, that line is not declarative. At all. It is exactly as imperative as the _simpler_ alternative. Get the value, divide it by 100, multiply it by `percentage`. Both lines express the same imperative process. Now, a _completely different thinking_ applies to function composition... if done correctly. The nature of FP is not _exactly_ onion-like. Instead, what you do is _build a language_ for your application. Even better, _build a few languages_. To be more precise, the nature of FP is _building different levels of abstraction to better express the business needs of each part of the application_. You build "application language(s)". It is _very hard_ to present the nature and advantages of a functional approach in just one line of code, but clearly, your line should be _something like_... const getTax = percentage =&gt; value =&gt; value / 100 * percentage; ..., a function, which you would then mix and compose with other functions. Maybe... const addTax = percentage =&gt; value =&gt; value + getTax(percentage)(value); const getPrice = pluck('price'); const calculateTotal = compose(getPrice, sum, addTax(COUNTRY_TAX)); // and then somewhere else you would actually apply this... (or you could do more composition, more language building) calculateTotal(items); A line such as `const calculateTotal = compose(getPrice, sum, addTax(COUNTRY_TAX))` better explains the nature of FP. It is indeed declarative, because where only declaring an certain action, not _applying_ it. It is descriptive, because it clearly expresses that the total is calculated by getting prices, summing them, and adding tax. It also (only a little in such a small example) builds a bit of language. At a certain level of abstraction, `pluck` exists. It doesn't care about prices or whatever. Then at this level you declare a specific application of `pluck`, getting the `price` property. At that point, you forget about `pluck`; you have defined a different level of language, one where you're not mapping properties from objects, but _getting the prices of items_. And in a similar manner, you now declare what calculating the total means. Once you have that defined, other places won't worry about what it means internally, about how that is done, it externally expresses its meaning. The line you showed simply _uses some functional tools in an imperative manner_. That line, in itself, is not really functional but imperative. You could make a similar case if you brought object orientation to the table. Could you _in one line_ express the advantages of OO? I would find it very hard. In fact if I tried to present an "OO equivalent" of that line of yours... what would that be? Maybe... const percentValue = (new PercentageCalculator(value)).calculatePercentage(percent); ...? Isn't that pretty? No, probably not. But more than that, does _that_ fairly express the advantages or strengths of object orientation? No, clearly not. Back to the FP approach... You may have noticed I wrote my function as... const getTax = percentage =&gt; value =&gt; value / 100 * percentage; ...instead of... const getTax = percentage =&gt; value =&gt; _.chain(value).divide(100).multiply(percentage).value(); I did so intentionally. I do see the cumbersomeness of writing that. I don't argue that at all. Yes, it _is_ cumbersome and tiring and bloated. (I'm leaving aside the argument about "including all of lodash" just for this, because it's mostly irrelevant to the subject at hand). But then again, few functional programmers will defend the second as _more functional_ than the first.
Whenever I read that unit testing is better than integration testing, I always reflect back at these tests: https://github.com/cartalyst/sentry/tree/2.1/tests It's an old package, sure, but a while back when I was attempting to change the way something works, with the same same result, but I had to change the test in every single case. Having your tests so tightly integrated to their implementation is fragile and creates an additional work.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [cartalyst/sentry/.../**tests** (2.1 ‚Üí c679730)](https://github.com/cartalyst/sentry/tree/c679730b8848686f59125cd821bf94946fb16a94/tests) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply doylvag.)^.
This is so old hat. There are ten million articles exactly like this one. What's the point?
Here is a fiddle, did not have your html in mind when I wrote it though. http://jsfiddle.net/11w1df2s/
It's all good! It was a good read
The variables are not functions because variables and assigning the result of an expression to a variable is perfectly valid FP. People stick too rigidly to the idea that in functional programming everything should be a function, which leads to far more redundancy than is acceptable and leads to the onion-like code I talked about earlier. FP in the real world doesn‚Äôt mean using functions religiously, it‚Äôs functional*al* programming, not function programming :). Use functions where necessary, but not simply because you can. Just bear in mind the core principles: immutability, no side effects, pure functions, declarative code, etc. I‚Äôm not debating the benefits of FP - all I did was explain why you won‚Äôt see many strictly functional libraries out there. Yes it‚Äôs a simple example, but that‚Äôs the point.
If you are using a different language on the backend, then Vue seems much easier to deal with. For example, getting Vue to work with SignalR on the client side was much easier than angular. Its much easier to fit into a project as well, you can start with a simple script reference and ease your way into whatever you need, as opposed to adding a new project on-top like with Angular.
People ask these questions because its important to know the basics of a framework to get a job. No matter what is learned first, your learning rate on-the-job (assuming you are surrounded by competent developers) is probably going to be dramatically higher than reading from a book or some articles alone...while also advancing your career and making money. I learned on the job then went back for fundamentals. If I had done it the other way around, I'd be making 20k less a year than I am now and would know less as well.
Glad that this post helped you! Google has been the one pushing for web components and the Google developers website has some good resources for web components. You can check this out: https://developers.google.com/web/fundamentals/web-components/customelements
That is definitely not something I would be attaching my real name to.
React will teach you the language as well as the library, Angular will teach you the framework but not as much about the language. Angular also uses TypeScript now, which might actually benefit you in the long run since it gives you a solid understanding of type systems that JS otherwise wouldn‚Äôt, although it might not be what you‚Äôre looking for right now.
Record the video stream for the duration of the delay. https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API Then play that recording and start the next chunk of recording.
Last time I checked, they weren't able to agree on how existing modules would be imported through ES imports. Their module exports don't work like the ES exports.
Last time I checked, they weren't able to agree on how existing modules would be imported through ES imports. Their module exports don't work like the ES exports.
I meant that any way to bind non-string value to element attribute will be against html spec. Just like el.dataset.* attributes.
I think it was the team from Atlassian - hopefully that will point you in the right direction. (Google "atlassian drag and drop react")
[FFMPeg](https://trac.ffmpeg.org/wiki/StreamingGuide) will be able to do things like that.
Oh that sucks, thank you for your answer. I guess the best solution in my case would be the second one, but what would. I need to change in my config to ditch Babel and still have hot reloading ? Do I have to change all my import to require ? And how much do I miss from ES6 without it ? 
Actually you already can use it, but with caution. The latest versions of Nodejs (8.5.0 and over) already support using ES Modules, but it requires you to save the modules as .mjs instead of .js and running with the flag "--experimental-modules".
[removed]
There are mainly two reasons: 1. Babel does not really deal with module loading. Babel transforms `import`s into `require` calls, and rely on an implementation of `require`. Node, otoh, does have a module loading system. 2. It has been debated for some time that `import` and `require` work in different ways, with some fundamental incompatibilities that make it difficult for both to work _together_. As /u/fredamsouza indicates, the selected solution implies making changes in the code (file extensions). Reaching this decision has taken time. The second reason, not being able to work with both "node modules" and "ES6 modules" together is what has delayed the introduction of `import` in Node.
i've read most of vue's docs and it seems bloody easy to dive into and start using. are there any main gotchas i should be concerned about?
&gt; This testing pyramid is a combination of one I got from Martin Fowler‚Äôs blog and one I got from the Google Testing blog. This article totally misses the point of Fowler's work. He's not saying that the pyramid represents an 'axis' of different tradeoffs for different kinds of test. He's saying **most of your tests should be unit tests**. **This article is misguided, nonsensical and harmful. Do not provide it more exposure.**
Vue supports server side rendering
Or localStorage 
&gt; However, this is not the case. but we won't know that unless we have read the material first. &gt; I believe that‚Äôs a fair price for the value you get. again we won't know unless we have read the thing first.
Ffmpeg in browser?
To put this into a sort of real world example I dealt with is testing a server route. The functions used by the server route were ideally made to have no IO. All of those functions are made into unit tests. The route itself is also technically functional as it returns an object and takes inputs never modifying internal state, but has IO dependent on a third party API so a few tests are written around ensuring the route behaves correctly and that the API continues to work as expected.
You can read the information about the content and length of the report on the landing page. You can see how your email will be used if you hover over the "What will happen to my email?" phrase. Do you also refrain from paying for a book or game without first reading/playing through the whole thing? Hence, you can always "get your money back" the moment you receive the report. As already mentioned, the OP posted the direct link to the PDF ‚Äì feel free to use it. But will you care enough to subscribe if you happen to actually enjoy the report?
The problem is that I want to use it in React-Native/NativeScript later and also want to develop PWAs with it. There are tutorials on doing PWAs with Angular and React. I don't know if VueJs is used for creating native apps or not, and if there are tutorials on how to use VueJs for creating PWAs.
I am the Submitter of this question. A reply said VueJs is easier than both of these, but I don't know if VueJs have some native library like NativeScript or ReactNative, also I don't know if there are some tutorials or courses on creating PWAs with VueJs (for Angular there is a lynda course, and for React there is a Packt book for creating PWAs with these technologies).
it's just your typical weekly articles on this sub. either es6 introduction or async / await introduction tutorial.
Those are all very valid points. It is still a bit unfortunate that no one else has replied so far but so be it.
Ah, I'm being silly, for I thought the "webcam" was on a server.
What would we do if we're not reminded weekly about scoping and this?
[Ref](http://michaelpollan.com/reviews/how-to-eat/) ‚ÄúEat food. Not too much. Mostly plants.‚Äù
Look up web service testing using protocols such as SOAP and REST. That's the easiest way to do what you are asking. A lot easier than making a program that moves the mouse around to click on buttons/links. RESTful APIs take out the whole middle man (mouse) and just goes to wherever you tell it to. (Etc. Clicking button x, moving mouse to y, etc)
it's such a cult it's off putting, I unfortunately work with Rails and it's essentially all they ever speak about. Except I will say that Unit testing is actually useful in Rails since everything is coupled together so one small change to a class can have a Butterfly effect across the application and a unit test can tell you where it failed(since in Rails where state is dispersed across thousands of classes with their own data and, flags and methods). But the way I write JS in Node, React or Vanilla I never have to worry about changing code since state is not split up and almost all the functions are pure `input =&gt; output`. 
Hmm... If you want to take advantage of the many components and libraries available, and single file components, you should set up npm and webpack, if you haven't already. Vue-cli makes that pretty easy, though. I can't think of anything else in the way of gotchas at the moment.
&gt; Martin Fowler Why do people care about what he says to me he comes across as the Dr. Phil of programming 
Thank you I will look into this ASAP! I appreciate the feedback! 
I don't actually have control over the server on this project, so I need to use pre-render
This is my promisify library. There are many like it, but this one is mine. https://github.com/Jahans3/ez-promise
&gt; Erm, no, you can get full or high unit coverage without testing line by line, an example would be testing a public function which may call 4-5 "internal" functions, but without actually explicitly testing those 4-5 functions as long as the public method tests are comprehensive Sure you can, the inputs of the higher level function will determine which of the other functions are called and why. If you need to test every function line by line then maybe it's because your code is overly complex. You should be able to test at a given level of abstraction with all different permutations of input types and also test all code that sits below that level of abstraction. that being said, since the goal is to write composable functions is it really so wrong to test every function that's exposed? 
Angular was developed as a consulting tool so expect many frequent breaking API changes as time goes by. To me Angular's approach is a lot like an Auto shop on a country road that dig potholes for cars driving by and charging huge fees to "fix" it. For Angular having a straight forward, easy to reason about API is not in their best interest since it's not actually used by any core Google product and was developed solely for the purpose of consulting. A bunch of Google guys came to our companies HQ and convinced some higher up aging "Architects" to use the new Angular. But luckily every team essentially refused since it's an obvious scam. They sounded like snake oil salesmen, all buzzwords and presentations but not real concrete evidence to back it up. 
I'm not really sure what motivated this comment. The internal functions are presumably part of the unit and generally not dead code, so they should get code coverage that corresponds with externally observable behavior. Right?
Yes, you need to manually trigger the event after updating the value using javascript.
Puppeteer is love, puppeteer is life.
Not sure whether you are allowed to or are using jQuery but it has a trigger function that you can use to programatically trigger events on DOM element.
How would I do that for something like react or angular? So lets say the listener is of the format: ng-keyup='formatInput(event)' ?
It's not triggering the event that I have the problem with. It's that the listener on the node doesn't get triggered. I'm also not using jquery.
Did they never hear of 'defer'? We need more details!
Oh I just noticed its an either or scenario, which do you recommend? Thanks. 
Seems like this would be a pretty bad idea to enable this in production: I have to imagine there'd a pretty decent performance hit from doing a ton of type-checking all the time, but I could see some benefits to having this enabled in development. I'm more of a Typescript person, myself, and the compile-time checking is the most important bit, but it would be nice to opt into some runtime checks from time-to-time.
I have found in my experience that when I change values programatically event listeners generally do not trigger. For instance if I have a select element with an event listener that listens for a change in the selected value. When I change the selected value programatically the event does not trigger. This is why I use jQuery to manually trigger the event listener. Unfortunately my vanilla javascript is not good enough to sugest a solution without the use of jQuery.
The actual presentation: https://www.youtube.com/watch?v=V8oTJ8OZ5S0&amp;t=11m30s
If the function attached to the element was just vanilla JS then I'd be fine. The issue is, I don't have control over the listener as it's in a different scope and then the event function is also attached via angular in this case. By ng-keyup='formatInput(event)'. How do I trigger this event?
People do automation and scraping with headless chrome all the time. You just need a webdriver library. There are drivers for all the major browsers.
Why do you want pre rendered components? I'm not sure I understand your real goal here
I dont get why they used React for their landing page? It‚Äôs some text and a images plus some links, seem overkill to use a framework for that anyway. Am I missing the point?
What does it do when it actually encounters an error? Does it just throw? If so, how is that any better than just throwing the null reference exception in the same place?
I see your point. But once you know what you're doing setting up a basic webpack build is like 10 mins of work at most.
This is really slick!
That's project business for you. 1. Implement new Framework 2. Bog down even the most minuscule tasks with it's overhead (if your error page can be displayed when the rest of the application crashed you did something wrong) 3. Demand immediate fix for performance issues from vendor (or the guys that you forced to implement it against their protests) 4. Get told (often rather blunt) that 99.9% of your use case doesn't even needed that new framework, never has and never will (but MUH CORNFLOWER BLUE BUTTONS!) 5. Complain that you shouldn't ever have used a framework in the first place 6. GOTO 1; // temporary fix 7. Sensibly decide where the framework is required
Oh well actually PWA can easily be done with Vue just look at the Vanilla JS version https://developers.google.com/web/fundamentals/codelabs/your-first-pwapp/ and develop your app like normal. All PWA does is it stores all of your stylesheets and JS files on the phone so launching is just a matter of fetching the latest data from your API. 
They explain why here - https://news.ycombinator.com/item?id=15568305 Looks like their landing page is way more complicated than meets the eye.
Thanks :) I tried to make the UI more polished than the average technology demo.
I'll take a look! I found NickJS in my searching
You are missing jQuery. Also, you should only have the contents of `body` in the HTML pane, the the entire HTML document. Like so https://codepen.io/anon/pen/KyPOdv
I still don't get how a button and a background screen warrants 300kb of javascript. We compress React for our landing pages to 2.5kb of loading effort, plus a couple of bytes for the initial views, while bigger parts are split up and async load in the background. Maybe Netflix has very intense things going on underneath, but i'm scratching my head ...
This is Netflix we're talking about. Let's be real. Give them the benefit of the doubt. You have no idea why they're using React there.
deferring can be just as bad. It means you have components popping in with the correct data... even if you had loading states, that still isn't a great experience.
I assume it would just throw. It's better, because it means that the error will be thrown from the place where the contract was violated: rather than a contract violation causing an error somewhere else in the codebase, and having to track that back to the source of the error. Or some type errors wouldn't result in exceptions at all. Like if my API call returns a string when I was expecting a number. I might later go to use that "number" and end up with a bunch of unexpected NaN values and it might be somewhat tricky to track that back to the original place where the bad type slipped it. If my code had thrown an exception immediately when it got a string rather than a number, finding the error would have been trivial.
If they are rendered on the server, the components won't "pop" in. Deferring the javascript will make it so the user can't interact with the components as fast, but they will be rendered like any old static page from days if yore.
React as web components is very valuable even if there's limited interaction. I've seen codebases reach a critical mass where you have enough react components that it just makes sense to keep going. If you've built 8 react buttons out of necessity, next time you need a button on a landing page, you have them ready to go and are not going to fragment your code.
Agreed, `setState` is just fine for starting out and learning the patterns, after that Redux is somewhat easy to learn. 
All I know is that their page gets worse over time.
I have added a section to the article clarifying this. You can also try out the Flow runtime in this web IDE https://codemix.github.io/flow-runtime/#/try.
try: angular.element(targetNode).triggerHandler("keyup"); 
I want to use Vue.js as a tool to build out the site I'm working on. I like the logic Vue.js uses and it will make maintaining the site easy and clean, but most of the site doesn't need to be interactive or dynamic. And for this project the client wants static HTML, CSS and JS unless the component needs to be interactive. So instead of building most of the site components using vanilla JS and then using Vue.js for the interactive components, I would rather use Vue.js to build everything and then output most of the components as static code, but keep a few of them as dynamic Vue.js components. It seems that both Nuxt.js and the prerender-spa-plugin for Webpack can kick out a Vue.js site as a static site, but I can't find anything about making only *part* of the site static.
Hey, I wrote this! Happy to answer any questions here too.
You can use NativeScript with Vue.js.
If that's enough for you. Godspeed. I can get 100% code coverage by doing a lot of bullshit things. It's meaningless. 
I was more suprised on them "discovering" caching resources with XHR, a "trick" that the community has been using since late 2000 to preload images that you would show in `onMouseOver` menu :/
yup. A And yup i know. But that not always work. And yes uBlock Origin is brilliant, more better than any other blocker.
No kidding. Cover features. Cover your ass. 
Could calling pause on your stream immediately after appending the first chunk of video help? Then you call play after the desired delay and take it from there.
No. Frameworks are a designed set of helper functions and file structure methodologies to add standardization to a project. A framework does nothing by itself - you still write code, they just make it easier.
Thank you for the reply!! Much appreciated! As I've understood there are many JS frameworks. Is it possible to combine different frameworks in one JS application?
Some frameworks can be combined, but most of them are designed to be pretty self-contained and have their own ecosystems including different plugins/modules/components that you can add-on as needed. You will find that many accomplish the same things but go about applying their methods in different ways, so preferences are largely subjective.
Rest might be easier. 
Thought so already. Thank you for the replies! Trying to break out of Oracle's golden cage :-) and JavaScript seems like an excellent way to do that. Syntax and so on won't be a problem for me I suppose, but I'm trying to understand the way the JS ecosystem works.
jQuery... how does that relate to something like Angular.JS (the name I often hear when people talk to about JS frameworks)??
Angular, ember, and Vue are probably most comparable to something like C# + WPF but for browser applications. React and it's offshoots only directly deal with the view layer as component frameworks but have an ecosystem around them for routing, state management, etc. Those are only rough analogies, not exact matches. But they should give you a general idea. There are other ones too that fill various niches but those seem to be the most popular at the moment.
This can talk to a .exe window properly from a webpage? Looks like the examples I found are webpage to webpage. Thanks! 
If you don't know the difference between java and JavaScript please leave :)
It may be worth distinguishing library and framework. jQuery is a library, React is a framework. The first can be used for many things (helper fns, tack-on some interactive UI, build a framework, the latter is for building an application. Frameworks are usually not combined, but a framework is often combined with a library (eg. pairing React with Redux for state management).
jQuery would probably be more accurately labelled as a library where Angular is a framework but it still got my point across. Angular can accomplish anything you'd use jQuery for with the addition of many other things: RESTful API, integration testing, MVC pattern support, templating, two-way data binding, dependency management, routing, form validation, localization and more. jQuery can get a quick job done if you want to write a short amount of code and add some quick functionality to a website. Angular would be a better choice if you're writing an entire application that needs to scale.
The reason for sharing that post is just to help some people .. if its in the wrong place or not helpful i can remove it, am not the author of the article , and thanks for your comment 
It's just a completely different language. 
The application would have to expose some sort of API that you can communicate with programatically, this is usually done over HTTP.
Jquery is just a library that contains higher level functions for manipulating the dom and related activities. Some are just convenient functions. Others are specifically to cover the differences in browsers. In theory browsers all support the same stuff but in practice sometimes there are differences on how you accomplish certain tasks depending on the browser. Jquery abstracts these so that you just call a function in it and Jquery figures out how to do the action without worrying about browser differences. It has also become less and less needed as time goes on because the browsers are getting closer aligned to the standard meaning there aren't as many differences as there used to be. But if you are targeting ie8 users or something like that it can still be useful. It has nothing to do other Javascript frameworks directly. It's a separate library. Except confusingly enough angularjs does contain a modified version of Jquery inside itself that they provide for some features. Most of the newer Javascript frameworks explicitly don't want you to use Jquery because they handle the dom already in their own manner and changes with Jquery break that model.
- While A/B testing, what changes made the biggest impact on the conversion rate? (good and bad) - How complicated is the machine learning used for A/B testing. How much of an increase did you see from it?
to be honest, i am a very very new java learner .. I just started to learn it at codecadmy.com and am trying to join all java scripting community around to learn more .. so excuse me for my shortage in knowledge 
Sorry for all the questions, but this software was made specifically for our company so I doubt it has an API, but windows forms has an API doesn't it? 
That I don't know, but worth looking into. In that case you'd need to have your own webserver (where people could log in), then that server would communicate to the app.
I can only speak to the engineering side of things, but app performance and load time is very important to us. You can see some more of our [public talks on performance on our engineering blog](https://medium.com/netflix-techblog/performance-without-compromise-40d6003c6037). For machine learning, we use a learning technique called explore / exploit. You can learn more about that in our [engineering blog post where we talk about using it for boxart selection](https://medium.com/@teamrework/personalized-content-and-image-selection-at-netflix-a1b3d4bc8851). 
[r/java](https://www.reddit.com/r/java/)
They sure can.
Thank you am removing post from here and posting to r/java 
Here's a sneak peek of /r/java using the [top posts](https://np.reddit.com/r/java/top/?sort=top&amp;t=year) of the year! \#1: [Finally: Effective Java, 3rd Edition](https://np.reddit.com/r/java/comments/74x9gv/finally_effective_java_3rd_edition/) \#2: [Why reverse loops are not faster](https://arnaudroger.github.io/blog/2017/06/15/forward-vs-backward-loop.html) | [67 comments](https://np.reddit.com/r/java/comments/6hg530/why_reverse_loops_are_not_faster/) \#3: [Java 9 Released](http://mail.openjdk.java.net/pipermail/announce/2017-September/000230.html) | [77 comments](https://np.reddit.com/r/java/comments/71lse7/java_9_released/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
you'll need to add jquery. In your html, above the websiteJS.js script tag insert this line: &lt;script src="https://code.jquery.com/jquery-3.2.1.js"&lt;/script&gt; I made the change on your codepen and it works!
No problem. Confusing Java and Javascript is an easy mistake to make especially if you're new. 
You likely need to have synchronous physical interaction from the user to play a video/audio when autoplay is disabled. This means that you clicking a show to play must call `video.play()` synchronously. My guess is that Netflix sees your click on a show, then does something asynchronously (waits for an animation to finish, makes an XHR request to get a one-time URL for the video content, etc.) before attempting to call `video.play()` which violates the synchronous rule.
That is why chunk splitting. You can split all your code to 2 files, one is yours, one is webpack's, plus people usually split another chunk for vendor code(axios...). here is what you need: entry: { app: './src/index.js' }, plugins:[ new Webpack.optimize.UglifyJsPlugin({ test:/\.js$/, exclude: [/\.min\.js$/gi] , beautify: false, comments: false, compress: { warnings: false, drop_console: false, collapse_vars: true, reduce_vars: true, } }), new ExtractText('css/app.css'), new OptimizeCssAssetsPlugin({ safe: true }), new Webpack.optimize.CommonsChunkPlugin({ name: 'vendor', minChunks: function({ resource }) { return resource &amp;&amp; resource.indexOf('node_modules') &gt;= 0 &amp;&amp; resource.match(/\.js$/); } }), new Webpack.optimize.CommonsChunkPlugin({ name: 'manifest', minChunks: Infinity, }), new Webpack.HashedModuleIdsPlugin() ] 
is there one site for vue libraries / components or are they all across github?
Ah, yeah that makes sense.
React is not a framework, it's a view library.
Not /r/java either. We don't want that spam.
Check out http://GitHub.com/vuejs/awesome-vue for everything vuejs related
Seems pretty obvious that using vanilla js would be faster than a framework. Am I missing something?
Yeah, you pretty much got it. It's not rocket science.
Well under the covers its just a class; getters and setters can expose properties that can set/pull from attributes, you can use callback on attribute changes to observe changes on the attribute to update your state. That provides a quite straight forward two way binding for anything you'd like and however you'd like to bind, but you're correct that would have to be set inside javascript not html.
Because number modulo 2 is 0 for even numbers. If a number is not even it's odd
With the major assumption that you can write optimized JS code (which is unfortunately not true for most inexperienced JS developers). Technically, all frameworks are written (or transpiled to run in) JavaScript, so you could just rewrite the parts of that framework in JS for your own site that you intend to use and it will always be faster.
excellent thanks
Since %2 is always 0 or 1 and 0 is considered falsy and represents an even number, the if will fail and go into the else. The 1 is considered truthy and represents an odd number so it will go into the if.
Place I was working at recently, we had one. At first we took some time in _deciding_ to set it up. Was it worth it? Would it need much maintenance? etc. Our main drive was that sometimes back-end people had to bundle up the front code and they weren't happy having to wait for an `npm install` to download all dependencies (they weren't that many, actually, but still connection wasn't always good and it took some minutes downloading). We also had the intention of sharing modules across the department, with the idea of unifying development for different teams. But in any case none of these two goals was pushing us hard enough to actually try it. Finally, we got our arses on it not because of any of that, but because some day connection to the NPM registry was lost during a deployment and we couldn't deploy correctly and it was a mess. In the end, waiting times for developers were mostly fixed in some other way and though the private repo did help a bit, what helped were the other things we did. Module sharing... well, internal conflicts of interest made that hard to happen. But for the deployment process it was clearly a very good move. This was about 1.5 to 2 years ago. We never had any problems with the private repo. Even considering that machines tended to be some what fragile there, the VM that ran the Sinopia must have been one of the few that I don't ever remember crashing or needing a reboot. So I guess it worked out nicely.
deferring on the js side is different from server side rendering of react. If you're rendering on the server side, it's not only going to be faster, but the page will be served once it's ready, not served but then the page itself is loading the pieces inside of it.
So I just tried the config you suggested and I still get some Webpack-related code in my app.js... :/ It seems like it's not enough to solve my problem, but thanks anyway. 
Yep. They‚Äôre extremely simple. I think the only people that have trouble with them are people who haven‚Äôt yet nailed asynchronicity in JavaScript.
Use the global Event object to define them and then listen to them as you would any other event. That‚Äôs what‚Äôs going on under the hood with most events already. https://developer.mozilla.org/en-US/docs/Web/Guide/Events/Creating_and_triggering_events
/u/kaikomai posted their explanation: https://www.reddit.com/r/javascript/comments/793a9i/_/doyw5oo
Got it working, thanks!
thanks, writing component html is the main problem i have atm, though i'll certainly keep mithril in mind
I have no idea what your are taking about, but just so we are on the same page this is what I mean. OP was referring to the "defer" attribute of a script tag: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/script If you render your content on the server side and defer the javascript tag so that it doesn't block rendering you can achieve an extremely fast initial render. If done properly there will be absolutely no "popping in" of content later. Are you taking about lazy loading?
The difference between a library (such as jQuery) and a framework (such as Angular) is that *you* call into a library and a framework calls into *you*.
Ok... what he's saying, is you defer the javascript so it speeds up the initial page view. The thing you're not grasping, is if you're doing A/B tests in a React architecture and you're conditionally showing components, you have to wait until the javascript is finished loading... deferring isn't going to help you there. The only thing that helps you, is moving the React and A/B tests to the server. Deferring javascript that you rely on to display your view, means you have to wait until the Javascript is ready. If you're mostly controlling views with React then deferring most likely is going to yield no benefits.
You haven't addressed the issue. If you're a company and you have a blazing fast homepage and your company takes in 10,000 every month... and you have the opportunity to quadruple that amount by increasing the size of the page load (doing a/b tests, whatever they're doing)... you'd do it right? Guess what? Reddit is subjectively worse for having that dumb sidebar on the right there, not allowing the page to be responsive, doing all their Reddit.com url redirects. What you have to address, is what exactly they're trying to accomplish, and if it has merit. Netflix is very active in the React community and is one of the big adopters. Not that arguments don't have validity in of themselves, but unless you do React conferences or you're a foremost leader in the community, you can't just be like "Oh it's Netflix, what do they know". Not only are they using React but they're an extremely successful company. Again, I'm not saying they're immune from criticism but come on. You can't just be like "oh yeah Netflix is as bad as Comcast and EA". They deserve a little bit more credit.
A framework is something like a skeleton, something like a car body chassis. You have to fill the rest of the parts to make it work for you. A library is something like an external part, something like a car spoiler, which you can use for your car. You have to notice the inversion of control here. For framework, the calls are made from framework to your code and for a library, you make the call from your code to the library. Real example, in Django framework , there is a structure defined for how you store the controllers, models and views. All the connections are taken by the framework once it is started. For a library, take the famous requests library in python, you clearly import and do whatever. PS: I am no expert, just giving you my way of remembering things. I hope the car analogy is not too bad. :)
I was under the impression that React is technically just a view library, not a framework. You don't get a MVC framework until combined with Redux. Angular and Vue are full MVC frameworks. But I guess I'm defining a framework as the full MVC pattern. I just wouldn't know how to define it otherwise. 
If you server side render, like they do at Netflix, that conditional will resolve on the server and the initial content will reflect the results. When client-side side react hydrates there will be no change because the conditional will resolve exactly the same. There is absolutely no "popping in" of any type of you utilize renderToString properly. Therefore, if you defer the script, the user sees the content without any future "popping in" just as fast as if a traditionally templated page were being served . deferring the script stops the download from blocking that initial render so the user sees all of your content faster, but don't cause noticeable jank to the user, so if course it helps. They don't have to move any logic, they use the exact same logic in the server and client.
You're not getting what I'm saying. IF you server side render. IF.
&gt; we use a learning technique called explore / exploit. As a native American, I find this offensive! ;)
We use them at my current place. They work really well. Our use case is that we have a lot of internal utilities and SDKs that for business reasons we can‚Äôt open source, so we add them all to our private npm repositories and it makes reusing that code a breeze. Would recommend for a small team.
A possibility would be to record the stream as /u/AngryClosetMonkey suggests; but you'd need 2 separate video elements (and recorders) to account for the loading time, and only show one while the other is loading the next chunk of data. Here's a rough sketch: &lt;script src="https://gist.github.com/m3g4p0p/dd05494db42e87bb3d033d9f375ae7ab.js"&gt;&lt;/script&gt;
They were specifically talking about TTI not TTR (Time To Interactive and Time To Render)
Is it react-beautiful-dnd you‚Äôre thinking of? https://medium.com/@alexandereardon/rethinking-drag-and-drop-d9f5770b4e6b?source=linkShare-c049de851810-1509134336
Just a note - the idiomatic way to do this with chained `then` calls is: function processN (n) { console.log('promise n') return inc(n) .then(n =&gt; mul(n)) .then(n =&gt; dbl(n)) } You shouldn't have a pyramid shape when using promises. Think about it like this: Promises let you avoid callback hell in asynchronous code. Async/await takes advantage of promises to let you write asynchronous code that *looks* synchronous.
or function processN (n) { console.log('promise n') return inc(n) .then(mul) .then(dbl) }
Yep, as long as they are unary functions.
It's a library tho...
That's a poor inference. We use React both on the client and the server. Server-side rendering has been part of React since the beginning. As far as I know, Reddit is really the only large company that doesn't make use of it. :-\
if you use React on the server, why would your experience load slow? Again... I want you to take some time and actually listen to what I'm saying. There's 2 big benefits to rendering on the server. One is SEO, the other is speed. When you come out with an article and go "ok by moving our stuff to the server, we've cut down the speed at which our stuff loads by 50%", what exactly is being conveyed there? That they were using server rendering for speed but weren't doing it correctly? "oh we've just moved more stuff to the server side of things"?
&gt; why would your experience load slow? Because even though your page loads *fast*, it's not interactive until the javascript finishes downloading, parsing, and executing. If you have an isomorphic app, it's the same amount of javascript on the server and the client, so you'd *still* have a high Time To Interaction, despite having low Time To Render. &gt; That they were using server rendering for speed but weren't doing it correctly I'd assume they were doing it primarily for SEO purposes, but sure you could characterise it as "not doing it correctly". It's not very charitable to say it that way though ;) Likely they did their best and the time, then did *even* better when they got the chance to.
Good point. What's the alternative? Queueing up user actions so that once the deferred app logic loads it then knows what to do?
&gt; It's not very charitable to say it that way though ;) I mean sure but that's your point. "We did server rendering correct finally and it resulted in a 50% performance improvement". Also, is that what they're actually referring to with that 50% number? Time to Interaction? I mean if it is, then you guys indeed did have a point.
Amazing work! PS Implement ML here and this will be **combo wombo**! :D
The last time I used this, you needed to have a sufficiently sized pane for this to work (unless they've fixed this in the 1.0 iteration). In terms of webpack, it's something you don't need to constantly be looking at, so it takes a very small amount of screen real estate on my screen.
Netflix is an industry leader when it comes to online streaming. HBO and cable companies are still trying to catch up to Netflix‚Äôs UI. Netflix knows what the fuck is up. Front end development is in a very experimental phases. Lots of new technologies and practices coming about. React being one of those. In software development ‚Äúdon‚Äôt knock it til you try it‚Äù is a very valid argument. 
So what if they're Netflix? I remember people years ago assuming when Facebook first became popular that it was a shining example of development excellence when in fact it was a cobbled together piece of shit. These things are popular because they are a great idea or have great content. The first versions are rushed efforts trying to get something out there to make money. The development quality comes iteratively later over time. This is no different for Facebook and Netflix. 
This just in - removing unnecessary frameworks results in performance upgrade! 
https://i.imgur.com/fv0zGe0.png
I actually downvoted you specifically because of your obnoxious edit
It's a little bit more difficult to do that now as Facebook is creating most of the software we're using these days. And Netflix is an active member in the React community. I'm not saying their immune from criticism but... if you're going to call out Netflix when you don't know what type of problems they're trying to accomplish, you have to make an actual argument. And if you follow the trail and look at Netflix's explanation for why they're using React, it makes 100% sense. So it all goes back to my original argument.
Yep that's what they are talking about.
Yes thank you!
Theres a minimal mode now
Ok, enlighten me. What do you think is the circlejerk here?
Landing and error pages can be used to pre load your actual app bundle so when the user logs in they don‚Äôt need any additional wait time.
Literally all of it
It's quite a bit more than that - https://news.ycombinator.com/item?id=15568305 throw react, redux, react-redux, i18n, logging/thunk/reselect plus anything else they have, maybe react-router and friends in a vendor bundle and 300kb sounds about right, even minified. 
Simply any number other than 0 is True. The modulo operation % finds the remainder after devision. Even numbers should not have a remainder after dividing it by 2. So Even numbers gives 0 which is not True.
Great presentation, thank you
Hey! You should check out [NoMansConnect](https://github.com/jaszhix/NoMansConnect). It's a react+electron app that builds a map of other users and lets you teleport and share screenshots.
Thanks so much for the enthusiasm everyone! If you enjoyed, I would encourage you to follow our publication https://medium.com/gitconnected
If you enjoyed, I would encourage you to follow our publication https://medium.com/gitconnected
Make that early 2000. `new Image(url)` in header is a pretty old trick.
Thanks for pointing this out! I've added the following function: const spreadArgs = (...args) =&gt; { if (args.length &lt; 1) return if (args.length === 1) return args[0] return args } And added the following to the docs: ### Resolving Multiple Values Since a promise can only resolve a single value, if a function's callback has an arity of 3 or greater an array containing the values is returned. ``` ezpromise(someAsyncFn, './some/path') .then(([arg1, arg2, ...rest]) =&gt; { // ... }) ``` Cheers
&gt;async function return a promise. That's not what makes it an async function. As a matter of fact if you're returning a promise you might want to make it a regular function. async wraps the function in a promise for you. And also makes it a generator that can be paused with await. If you don't need either of these things you don't need to declare it async. You don't need await if all your operations inside the function is synchronous, and you don't need async's promise wrapping if you already have a promise. If you're returning a promise from an async function it's a warning sign. Most likely you either forgot to say await to a function call, or you're double wrapping promises, which is a waste. Example: function returnsPromise(a, b, c) {...} function asyncWouldBeAWaste(a, b, c) { // doing some sync operations return returnsPromise(a, b, c); } You can use async/await with anything, that's one of the great things about it, but this also lets people overuse them. (If the thing returned to await is a promise it will be waited on and when it resolves it will unpause the function it paused. If it's not a promise value it will be treated like an instant Promise.resolve(value) so it's the same thing.)
I wouldn't go as far as calling them extremely simple. They're deceptively simple to learn, but consider the fact they're basically syntactic sugar over generators and promises. Both of which are rather tricky topics. If you're very, very familiar with both then being introduced to async/await will feel very natural. But if someone's jumping directly to it I'm very doubtful they're going to know all the gotchas. One example is what I explained in my other post. Another is how to deal with uncaught promises properly. (If the Node devs ever do as they threaten, and make them fatal, we'll be swimming in dev tears on that day.) These are both rather subtle topics which should be instantly obvious to people who mastered promises, but will leave others baffled.
Yeah, we can call a resolved multitimes, it will be always resolved, but that is just a demonstation, thank you. 
Is there a list of tricks that are still worth knowing, rather than being obsolete workarounds for problems that no longer exist?
Rendering on server makes the load faster and time to render much shorter, AND by removing React client side and writing tiny custom javascript the time to parse and boot the client side javascript went down, reducing the time from rendered state to interactive state. Which led to much faster Time-to-Interactive With that said, it sounds like further development and changes would cost a lot more, which might be fine!
 Is that as mature as using NativeScript with Angular? i heard it's still in alpha.
Makes sense. Though - most of these we use ourselves, and to reach 300kb with them, not sure how that's possible. Looking into the bundle report, react (-&gt;preact-compat) is at 3kb, redux 4kb, router 5kb, ... they're all tiny modules.
Nope, all in browser but thanks anyway ;-) maybe someone else searching the internet might come across this post one day and find it helpful.
Oh man. If you‚Äôre learning Elixir and Phoenix, I would absolutely dive into Elm. It is a great community with tons of resources. Not as big or mature as react, but I find it just as valuable. Elm in Action is a great read by Richard Feldman. [elm seeds ](https://elmseeds.thaterikperson.com/) Has some awesome walk through. 
So they didn't use modern feature like http2 push or defer. Why is that info valuable ? Browser compatibility maybe ?
Thanks!
Because it‚Äôs a lot more complicated than it seems - NodeJS uses CommonJS modules (require) which are quite different from ES6 imports. When Babel allows you to use import, all that‚Äôs happening is it‚Äôs being transpired to require underneath. If NodeJS were to implement ES6 imports it would require a lot of work underneath and making it play nice with CommonJS will be a headache, but it‚Äôs getting there.
Hi dude! Once again, thank you for your help. Actually, I already utilize the first script you gave. const fs = require('graceful-fs'); const archiver = require('archiver')('zip'); const through = require('through2'); const filter = require('gulp-filter'); const zip = require('gulp-zip'); const gulp = require('gulp'); var sourceFiles = ['file2/**/*', 'app/**/*', './**/*.json','./**/*.js' , '!./package-lock.json'] gulp.task('default', () =&gt; { return gulp.src(sourceFiles) .pipe(filter(file =&gt; !file.stat.isDirectory())) .pipe(zip('Test1435.zip')) .pipe(gulp.dest('dist')); }); Using the variable *sourceFiles*, I can now add and exclude files that I don't want to be inserted in my zipped file, hence I was able to complete my use case. Though the code is not flexible enough. Because in order for me to include and exclude a file, I need to open the gulp script and edit it. I've checked the code you created, but I'm not really sure where to add the source files and destination files. All in all, I really wanted to thank you for your great help. Thank you so much! :)
I don't know about the overhead of managing a private npm repo. But another option may be private npm packages. https://docs.npmjs.com/private-modules/intro Although this has a monthly cost associated with it. https://www.npmjs.com/pricing
Even if it returns a promise (and you don't need to use await for the returned value), you should make it an async function; it documents your function returns a promise and it prevent your function from throwing.
Yes, they said that it gives them ~95% support across all current browsers.
missed the no react, pure vanilla
join to the JAVASCRIPT TELEGRAM group and ask all questions https://t.me/truesoft
HBO go is so slow compared to Netflix, their UI is okay but man it‚Äôs slow AF. 
This is my first show at releasing something I've made, but I am currently working on a JavaScript template literal to DOM tool that can be used with Web Components. It's really light weight and handles basic content, event and property bindings. You can find it on npm as [templiteral](https://www.npmjs.com/package/templiteral). 
Check out all of our articles at https://medium.com/gitconnected 
need to go full perl cgi scripts....
It is a really silly idea to use Puppeteer to "scrape the web". It is super inefficient to launch a whole browser to scrape content. To start with, the website used in the example is a SPA. This means that there is an API that you can query directly, bypassing all scraping in the first place. For websites that aren't SPAs, it is 100x times faster to just request the HTML, parse it, and extract the content from the DOM. If you are serious about scraping content in JavaScript, check out https://github.com/gajus/surgeon. It is tested across thousands of websites and works in Node.js and browser, such as Puppeteer environment. Unlike Cheerio, it provides a declarative, strict interface to scraping data. Therefore, if a remote site structure changes, you will know instantly, and you don't need a programmer to maintain your scraper scripts.
You know I had exactly the same thinking as you but I decided to jump in into a JSFiddle and try it out (because I had my doubts). Using _async_ as a wrapper doubles the time of a function most of the time (versus just using a Promise inside of the function without the _async_ keyword), now that I know this I don't think is good to use them just as "documentation" for knowing the function returns a promise, I think this could be better accomplished through TypeScript. Also your comment &gt; prevent your function from throwing. I don't think is a valid argument if you check [this](https://jsfiddle.net/jucxLh6t/2/) you will see that I'm using a function that is not using the _async_ keyword but still is creating a Promise and throwing an error inside of it, at the end in the function where we use this _throw an error_ function we use _async_ and _await_ with a try catch and we are able to catch the error. I will now be more aware of using _async_ just for the sake of documentation, if I'm returning a promise and I'm not using _await_ I'll not mark that function as _async_.
If some websites block requests that dont have client headers set, wouldnt it make sense to start an instance of chrome and have the headers set to look like a normal client? Can you accomplish that with the github link?
Small correction: %2 is not always 0 or 1; if the user enters a number with a decimal portion the program will always say it's odd.
&gt; client headers set, You can set whatever headers you want when making a HTTP request.
Only reason for launching a browser is to run dynamic content, I needed to do that on a project. Two of the three sites I was scraping I could use cheerio, but one of them loaded content dynamically so had to run the js. Was slower and inefficient but worked, mostly. 
I use: https://github.com/matthewmueller/x-ray It's really as simple as: (example is scraping Xe.com currency rate data - just for fun/test. Yes I'm aware there are APIs that can be used) const url = createXeUrl(fromCurrency, toCurrency); const getCurrencyRate = promisify(x(url, '.uccResultAmount')); const currencyRate = await getCurrencyRate();
If it was loading the content dynamically, then it used an API. It makes no sense whatsoever to use browser to automate those requests, render DOM and then scrape DOM, when you can simply make the requests yourself. Just load the page in a browser, inspect the networks tab, see the requests that you are interested, press copy as a cURL request, and analyse what are the required parameters/ cookies/ payload to replicate the request.
Xray is just a less powerful and less strict version of Surgeon.
Yes, I also like ELM, but I am afraid it doesn't have some native apps library like React and Angular do.
I took your test and ran it across multiple browsers and Node, and see consistnently similar execution times, particularly as the length of the loop grows. I think it's always a mistake to prematurely optimize JavaScript, as the compiler is much better at finding the hotspots than we are.
If the ultimate goal is to also develop a native iOS and Android app, and not just a native wrapper like phonegap. I feel your best bet would be react native. And use react native web to render that existing code base to DOM. https://github.com/necolas/react-native-web
Ah. I did not know that. Will checkout Surgeon then. Thanks!
A JS framework is like ATG for Java
I dont see how to avoid using a browser in certain scenarios. Eg it loads content, then runs javascript to generate the derived content you want to scrape. You can't extract the javascript, because it is hard to navigate through or just minified, and also assumes the dom exists or will crash otherwise. Also the api might be quite hard to reverse engineer. Eg there is auth or binary interface. However when running a browser, it's only ever a matter of poking around in an element inspector and finding the correct selectors for the html.
&gt; I dont see how to avoid using a browser in certain scenarios. Eg it loads content, then runs javascript to generate the derived content you want to scrape. You can't extract the javascript, because it is hard to navigate through or just minified, and also assumes the dom exists or will crash otherwise. Also the api might be quite hard to reverse engineer. Eg there is auth or binary interface. You are making up things. Show me a web app with a "binary interface" to an API. If there is an authentication, just make API request to authenticate and send the cookie in the next request. `tough-cookie` and similar abstractions make it piss easy. It is not a rocket science. The initial content is retrieved either via API or inlined in the response document. Derived requests are using the data from the earlier documents. Simple. I have written scrapers for banks, travel sites, insurance sites, search engines, social networks, etc. Of all these sites, the only website I have encountered that is truly tricky is Google search. Google uses client behaviour fingerprinting to distinguish real users from bots. All the other sites... simple.
I understand your point and the time might be negligible, I'll reconsider using it or not, I've been using ``async`` always as a documentation also, I think the fact that a developer can know if a function is asynchronous or not outweigh the micro optimization in this case. 
Huh. I didn't realise at the time that was an option, but makes sense... Cheers! 
you're being disingenuous. sure, a json api usually sits behind a website. but i've seen websites that have their own protocol over websockets, for example. in those cases, it can be easier to execute the website in a browser. to say otherwise just suggests you only have experience with json apis. at which point you're speaking with a bit too much authority on the matter.
What about cross origin policies? Just because it‚Äôs a single page app doesn‚Äôt mean that cors will allow your request. Not all endpoints for sites are public. 
&gt; own protocol over websockets What are you talking about?
If SPA can access it, then by definition, the client can access it to.
Not derived requests. Derived *content* that is generated by client side javascript, then rendered to the dom. If you don't have to deal with derived content, and you have no problem figuring out the APIs for yourself, then I guess you don't need to run their javascript for your use cases.
‚ÄúUse webpack‚Äù sorry. I make an assumption that you do not really need gulp (or grunt whatever) 
Well I meant finding the right selectors in the element inspector, then doing the actual scraping in a headless browser. But for quick small tasks you probably can copy-paste your scraper directly into the web console. I know I've done it before.
I've also seen websites making http requests where the params were all smashed together in a huge mess, and even base64 encoded. Sure, their server understands, but I don't, and won't spend the effort trying to. So headless browser it is...
Yes using headless browsers are very inefficient at scraping multiple end points and not recommended in all cases. Surgeon does not emulate a browser but does parse really well. If you *have* to emulate a browser due to ajax/dhtml then there is no other technology to do that.
https://jew.ski/ost/ Never had any musical talent, but listening to the [Undertale soundtrack](https://www.youtube.com/watch?v=SxNcKXjfaQo) inspired me to start learning a bit about generating music to make similar songs using the Web Audio API. The sounds are pretty bad right now, but this is only the first component of, what could be if I have enough time, a pretty cool web UI for building songs. The app is written in [Raj](https://github.com/andrejewski/raj) if anyone wonders what the debugger button is all about.
Cors can be enforced on the server. Even if we disregard eventual authentication. You are stubborn but that doesn't mean you are right.
CORS stands for Cross-Origin Resource Sharing. It is a mechanism to prevent unauthorised requests client-side. It has nothing to do with HTTP request validation or authentication.
&gt; If you have to emulate a browser due to ajax/dhtml then there is no other technology to do that. Well, thats the point, for scraping purposes, you never have to. There are tons of valid use cases for Puppeteer*/ browser emulation, but scraping of specific content is not one of them. (*Validation of the content. Scraping for the intent of content indexing [very different from specific content scraping]. Testing. Automation using browser instructions.)
Well of course. But if you‚Äôre just trying to hit an endpoint with postman, some rest client, or Node scraping app on your machine, then you‚Äôll get a cros origin access denied (if they have a policy set up, and most sites do.) The only reason the client has access to it is because it‚Äôs coming from a browser that is on that same domain. You can‚Äôt spoof requests origin headers. So you have to spin up an actual browser, wait for it to load then go through the DOM for the stuff you want. Even in a SPA. 
............................................________ ....................................,.-'"...................``~., .............................,.-"..................................."-., .........................,/...............................................":, .....................,?......................................................, .................../...........................................................,} ................./......................................................,:`^`..} .............../...................................................,:"........./ ..............?.....__.........................................:`.........../ ............./__.(....."~-,_..............................,:`........../ .........../(_...."~,_........"~,_....................,:`........_/ ..........{.._$;_......"=,_......."-,_.......,.-~-,},.~";/....} ...........((.....*~_......."=-._......";,,./`..../"............../ ...,,,___.`~,......"~.,....................`.....}............../ ............(....`=-,,.......`........................(......;_,,-" ............/.`~,......`-...................................../ .............`~.*-,.....................................|,./.....,__ ,,_..........}.&gt;-._...................................|..............`=~-, .....`=~-,__......`,................................. ...................`=~-,,.,............................... ................................`:,,...........................`..............__ .....................................`=-,...................,%`&gt;--==`` ........................................_..........._,-%.......` 
If you cannot predict the parameters, i.e. predictably replicate the request, then you cannot implement a strict scraper. If you need a mishmash quick way to scrape content, then sure, thats a way. If you need to scrape stock price tick data or anything else that has high value/ impact, then you don't mess around with approximations.
Service can still enforce limitations on API access by making sure code that is only served from the web server hosting the trusted front-end was executed on client before access is allowed. It might not be "CORS by definition" but serves the reciprocal purpose of protecting the trust between a specific front-end and a specific service. 
Dude you don‚Äôt know what you‚Äôre talking about if you think you can scrap data from endpoints that don‚Äôt have an open cors policy. And the fact that everyone is agreeing with you just means that there‚Äôs not a lot of smart developers out there. More job security for me then!
Oh i must be confused between headless chrome and headless requests then?
When you need to use large amounts of promises, if you combine them carelessly with async the overhead can become very real. I don't have the links right now but there's definitely been real world scenarios and articles written about it.
Excellent report! Thanks!
You can‚Äôt set request origin headers. Those are set by the browser automatically and can not be controlled by the user. 
&gt; sure code that is only served from the web server hosting the trusted front-end was executed on client before access is allowed Please, share a link to the description of this protocol/ service/ concept that you are talking about.
The fuck does browser have to do with anything? We are talking about constructing HTTP requests, be it cURL, Node.js, C, telnet or whichever interface you choose. It is up to the client to identify itself. The only thing you cannot change is the client address, because it is the ISP that identifies the origin of the client. Literally every other bit of the request is constructed by the client.
237k is not small I thinl. 2.46s seems very reasonable. That being said ... If you want to write es6 style code how are you going to bundle your modules ? You can't just feed gulp one giant file ... that's not really how it works. Normally you would have a bunch of files and one entry point , say index.js or main.js. The output of the compile + bundle step would be one output bundle , say bundle.js. In that case when you change one file only that file needs to be recompiled, thus improving your rebuild speed. If you want to write true es6 (es2015+) you're going to need a module bundler like webpack or rollup. If you absolutely want to stick with gulp I'd go with rollup but webpack is very nice too. 
I don't see the need for Puppeteer. When I needed to write a web scraper for my job, I used JSDom (`fromURL` method), and it was incredibly simple and easy. 
&gt; cross origin policies Cross origin access control is a concern of the *client*. My browser blocks cross origin requests to protect *me* not the web site. The web site has no idea who is making the request and has no concept of cross origin.
I've created a data visualization dashboard of the U.S. Congress. Built with React, Mobx, the data at github.com/unitedstates, and the ProPublica API. http://whogovernsus.org
That is a good point. Browsers are trying to protect you from sending information to the wrong server and giving credentials away. But there's still plenty of reason for the website to know who the client is in the case of protected API endpoints. 
There is obviously no protocol here and I can't conjure up a publicly accessible service so you win the pissing contest if that is the point. This is not common or considered a good practice (because in essence it is security by obscurity) but that is not worth much if it is implemented (and I have ran across it) and the context is scraping. Typically this works so that an application serves a token in javascript inside HTML and then custom minified JS performs hashing which is verified on the service (and usually sent in headers). The result is short lived and ensures that an anonymous unauthenticated client is able to access service from the website it is served from and everyone else is discouraged. Finally, that is often good enough for the content owner since the data is public but just not bulk scraping friendly. I've seen it before and I'm sure many people that read this far in a thread about web scraping have at least once ran across something like this. Finally this IS all about economy of data acquisition, just not the one you subscribe to. It is often cheaper (in billable time, which is the real, actually significant cost that really breaks the bank in most projects) to just spoof the browser and scrape from DOM rather than to reverse engineer someone's API. 
While /u/gajus0 has not been polite in some of his comments, his arguments have demonstrated an accurate understanding of network requests and parsing. Anytime we are wrong it is an opportunity to learn something new, something we will no doubt find novel. It is in that spirit that I want to chime in here. Unfortunately, your comments have not belied an inaccurate understanding of these matters. The age old mantra of never trusting the client applies here. In case you don't know CORS is completely reliant on the 'origin' header sent from the client. The client can set it to be anything, it can even set the origin header to match the domain that it is requesting data from. Thus the server will be told that the request is not cross-origin at all! CORS is not intended to protect the server, it couldn't if it tried. CORS is intended to protect the client from the server. To get around things like CORS scrapers are designed to make it easy to spoof headers. Changing the origin header in a scraper isn't just possible, it's typical. Even regular web browsers will sometimes lie in their origin headers, especially those with extensions or add-ons. Further a "client" does not even have to be a browser of any kind, it can be a human using hand crafted CURL requests lying about everything single thing it says. A server can never trust the headers sent to it.
SPAs often do, but are not restricted to just regurgitating API data into the DOM. It's a complete waste of your time to reimplement whatever business logic the app is using to generate the data you're *actually* interested in scraping, just to maintain pointless dogmatic purity versus just spinning up a headless browser.
CORS is a browser/user protection not api. If a browser can make the request then so can any program. The api can add things to make it slightly more painful (e.g. csrf tokens) but they are trivially overcome.
Thank you for your reply. gajus0 and I have been private messaging for the past hour or so. I'm learning a lot. The moment he sent me a massive "facepalm" image, I immediately went hostel and my mind went cloudy. Today has been a good opportunity to learn more about all this.
Of course this protocol isn't public! It is part of many sites' 'anti-scraping' technology. Its very purpose is to prevent straightforward (not involving a phantom browser simulating human interaction or employing human workers at a 'click farm'') scraping applications from harvesting data. Possible implementations can encompass anything from checking cookies to calculating verification data related to mouse activity, scroll events and the like. Basically anything a Web site could use to determine if a client 'isn't a 'robot' apart from image classification questions.
I found the 300kb to be reasonable because I've got a personal project that uses all the bells/whistles; SSR routing / chunking / localization / etc... and the vendor directory - anything imported from `node_modules` - is 330kb. I've taken a look at the bundle analyzer and I'm not sure where you're getting 3kb for react -- react-dom.min.js in their dist directory is 128kb.... parsed size in my vendor.bundle.js is 111.16kb - that's the lion's share. next biggest is babel-runtime at 25.83, followed by react-router-server 21kb, react-router 18.38, react-intl 17.52. gzipped, the whole thing can get down to 94kb. Also, that's react 15.5. I heard 16 is a bit smaller but I haven't gotten around to upgrading the project yet.
gajus0 and OP are referring to public websites with public facing endpoints. I'm referring to private sites with logins, tokens, sessions, etc. We're both speaking the truth, just different scenarios.
&gt; This is not common ... In my experience, all the 'big name' sites (Google, Amazon, etc.) use it in some form or another. Usually these sites have a paid API in place which they wish to protect.
&gt; It is part of many sites' 'anti-scraping' technology. You are blabbing about client behaviour fingerpriting, which I mentioned here https://www.reddit.com/r/javascript/comments/799kol/scraping_the_web_with_javascript/dp0hfia/. Google and Facebook are about the only two websites I know who are doing this. And it is not designed to prevent. It is designed to deter. The closest there is to public accessible resource of a similar kind is the "invisible reCAPTHA" (https://developers.google.com/recaptcha/docs/invisible), but even that, in the words of the author is designed to deter, not to prevent bot attacks. I suggest reading about this guy and his current company, https://en.wikipedia.org/wiki/Shuman_Ghosemajumder if you are interested about the latest advancements.
Good luck with 'strictly' scraping any reasonably sophisticated shopping site (no cheating, only publically accessible URLs, no auth, no paid APIs!). Being prime targets for price comparison scrapers, many of those go out of their way to make a scraper's life miserable (dynamically generating content, regularly / randomly moving DOM content around, rate limiting requests per IP, etc.).
The 3kb you get when you alias to preact-compat, or a little larger for react-lite. It's an api compatible layer where some internals have been taken out, like pooled events. I run most of my apps through it in production to safe space.
Thats literally what I specialise in. :-)
what private repos are you generally using? Have used Sinopia but that is deprecated so currently moving to jfrog artifactory..
It looks fine as it is. You have to cache the value, so any one-liners are going to be ugly.
Ah, okay :-)
I use the play framework, which has this config option: play.filters.cors.allowedOrigins - allow only requests with origins from a whitelist (by default all origins are allowed)
Correction, Facebook is buying all the software and apps we regularly use hehe don‚Äôt take me wrong .
Oh, damn.
&gt; It makes no sense whatsoever to use browser to automate those requests, render DOM and then scrape DOM, when you can simply make the requests yourself. Unless it's a public API, it makes plenty of sense to do this. It can be a lot easier to select DOM elements than to reverse engineer a site's "internal" API. Especially authentication is involved. 
This really underscores why I don't like Node.js for certain things: this program is inherently synchronous, but the author is forced into a async paradigm. Yuck. 
This shouldn't be a getter. Getters are supposed to be cheap. An async one is just bizarre. There is no way to do the same thing without defineProperty, is there? This is really fucking weird.
https://www.youtube.com/watch?v=4zwHCx54mIM
&gt; It can be a lot easier to select DOM elements than to reverse engineer a site's "internal" API. Especially when authentication is involved. You are making no sense. If anything, asserting authentication is harder using a tool such as Puppeteer than using whatever low level HTTP client. Compare: a) making a request to http://internal-api and getting 5** status code (or error in JSON or whatever); vs b) loading http://some-shop web page and figuring out from the DOM if the user is authenticated DOM simply does not contain this information, e.g. Amazon will show you your full name, all your account navigation URLs, etc. when your session is expired. Only once you try to navigate to a part of the website that enforces authentication, you are going to get some, non-standard response indicating that you are not authenticated. &gt; It can be a lot easier to select DOM elements than to reverse engineer a site's "internal" API. It is just not. It will take you 1 minute to look up and network tab and see what requests are being made as you navigate the page, then construct this request in one line of code and parse standard JSON (or whatever else the API responds with). Compare this with all the boilerplate to manage the state of a headless browser, writing logic for knowing when the page fully loaded (because simply getting HTTP response is no longer enough, you need to wait for all the bells and whistles that might be required to load the page; see Puppeteer documentation), figuring out what is being displayed (you have *no guarantees* that the loaded page will display consist output; banner, welcome back messages, promotions, etc) and then extracting the content from DOM.
FYI - this is called [memoization](https://en.wikipedia.org/wiki/Memoization). 
RTFM: https://developers.google.com/web/tools/chrome-devtools/
&gt; If anything, asserting authentication is harder using a tool such as Puppeteer than using whatever low level HTTP client. Find elements, fill out elements, submit form. &gt;&gt; It can be a lot easier to select DOM elements than to reverse engineer a site's "internal" API. &gt; It is just not. It will take you 1 minute to look up and network tab and see what requests are being made as you navigate the page If only reversing engineering were always this easy. Just because one can see a request, doesn't mean they know what the fields are and what their values represent. 
Started learning react, and this is the first application i built with it, still in progress and its made as one of the project for my class. [react-personality-test](https://github.com/irfanabliz/react-personality-test), so its basically we learning about different types of personality and the user answer question which will then in the end tell that user what type of personality he/she is. 
I definitely agree with this, an async getter is very weird and unintuitive.
Ah thanks a lot, I knew caching wasn‚Äôt the right term.
I also eventually decided this and made it a function instead. Thanks.
Nice
i think you should shush
At my previous place of employment we used NPM's enterprise offering and ran a full mirror which meant we were shielded from any internet issues or NPM issues during builds. I never want to not be able to deploy because of issues during a prod outage at 3am. The NPM enterprise software at the time was pretty ropey. It would randomly die, but during the course of a year it stabilised as NPM pushed changes. We ran a linux box with 4TB of disk space which accomodated the full mirror.
Useful, but I hate inflammatory titles. Can‚Äôt you just say ‚Äú14 JS debugging tips‚Äù???
"debugging tips you probably didn't know": debugger fuck off.
pretty good, some I didnt know
I shared [https://github.com/fwilkerson/muve](muve) here a few weeks ago. This week I decided to put together a PWA demo with muve. https://github.com/fwilkerson/muve-forward It was a lot of fun to dig into webpack and learn more about how you put together a PWA. When I decided to implement code splitting, I sorta discovered a nice way to write single page apps with muve. A happy accident as they say.
Here is a list of threads in other subreddits about the same content: * [Building a Budget Manager with Vue.js and Node.js (Part III)](https://www.reddit.com/r/node/comments/79e8ze/building_a_budget_manager_with_vuejs_and_nodejs/) on /r/node with 1 karma (created at 2017-10-29 10:43:51 by /u/Shiintapix) * [Building a Budget Manager with Vue.js and Node.js (Part III)](https://www.reddit.com/r/vuejs/comments/79e8xg/building_a_budget_manager_with_vuejs_and_nodejs/) on /r/vuejs with 1 karma (created at 2017-10-29 10:43:30 by /u/Shiintapix) * [Building a Budget Manager with Vue.js and Node.js (Part III)](https://www.reddit.com/r/webdev/comments/79e8u8/building_a_budget_manager_with_vuejs_and_nodejs/) on /r/webdev with 1 karma (created at 2017-10-29 10:42:52 by /u/Shiintapix) ---- ^^I ^^am ^^a ^^bot ^^[FAQ](https://www.reddit.com/r/DuplicatesBot/wiki/index)-[Code](https://github.com/PokestarFan/DuplicateBot)-[Bugs](https://www.reddit.com/r/DuplicatesBot/comments/6ypgmx/bugs_and_problems/)-[Suggestions](https://www.reddit.com/r/DuplicatesBot/comments/6ypg85/suggestion_for_duplicatesbot/)-[Block](https://www.reddit.com/r/DuplicatesBot/wiki/index#wiki_block_bot_from_tagging_on_your_posts) ^^Now ^^you ^^can ^^remove ^^the ^^comment ^^by ^^replying ^^delete!
delete
Welcome to clickbait.
&gt; Plenty of sites have been made and function perfectly fine without a framework. Is that really true for anything remotely complex nowadays? Do you have any examples to quench my curiosity?
This is really good stuff 
I feel like conditional breakpoints are more useful than all of these...
Thank you for introducing me to Electron.
React absolutely is a framework. It's not a library. React absolutely imposes a way to deal with the UI, that's the very definition of a framework, you hook your code to React "engine" when you create a react component. But it's react that completely drives your view, nothing else. You don't call or query the DOM on react components for instance.
[Rectangles](http://ronilan.com/rectangles/) "Rectangles" is a Computer Art Project. To create this art, a computer generates a "board" with randomly placed "obstacles". The computer then covers the board entirely, with colorful rectangles. The computer tries to do so using as few rectangles as possible. (Disclaimer: I did do this in a week, but it wasn't last week, it was a random one, almost four years ago. This week I waxed the kids snowboards.)
Can't find it. I liked the blue one without the rectangle a lot.
TIL: `debug` and `monitor`. 
Ban the site.
That's reverse engineering you... Hacker!
Get online book, Eloquent JavaScript or something.
Yes, I knew all of these... would be a way better title.
Try code.org
I'm new and thank you :') 
Absolutely. Performance warning on debugger. The mere presence of the keyword (even `if(false){debugger;}`) renders the code unoptimizable by the JS engine resulting in slow code. It should never be present in production code. I strongly doubt this has been fixed.
Regardless of whether you plan to use Node.js as your backend, you should still use it for your build tools. You say you expect everything to work when you double-click your HTML file, but that‚Äôs unfortunately not a realistic expectation if you want to use modern tooling such as Babel and/or JSX. You probably want to read up on a tool such as Webpack that will be able to set things up properly. The reason including the Babel dependency from the node_modules directory doesn‚Äôt work is because the file you‚Äôre including expects to run in a *Node* environment, which is not present when you try to load it directly into the browser. Using a tool such as Webpack will make sure those details are handled correctly.
Eloquent JS and the You Don't Know JS series are great
That being said ... If you want to write es6 style code how are you going to bundle your modules ? You can't just feed gulp one giant file , that's not really how it works. Normally you would have a bunch of files and one entry point , say index.js or main.js. The output of the compile + bundle step would be one output bundle , say bundle.js. In that case when you change one file only that file needs to be recompiled, thus improving your rebuild speed. If you want to write true es6 (es2015+) you're going to need a module bundler like webpack or rollup. If you absolutely want to stick with gulp I'd go with rollup but webpack is very nice too. The giant file was just for the test case, but I think that it's 6000 lines of code can be representative for a project codebase we might have. By bundling you mean 
The file I used here merely served as a test case. I thought ~6000 lines of code is something we might encounter IRL. &gt; That being said ... If you want to write es6 style code how are you going to bundle your modules ? You can't just feed gulp one giant file , that's not really how it works. What do you mean by bundling? We normally write a bunch of files that are concatenated and minified and then served to our user as one file. &gt;Normally you would have a bunch of files and one entry point , say index.js or main.js. The output of the compile + bundle step would be one output bundle , say bundle.js. How does that differ from what we do? Example: index.html src/` _utils.js main.js vendor/ some.library.min.js some.jquery.plugin.js My gulpfile would be configured to source from `['src/vendor/**/*.js', 'src/*.js']` or similar and then compile to public/js/scripts.min.js doing concat, minify and sometimes browserify. Thanks for your time! :)
Not every SPA has an accessible API. Sometimes you need to scrap data from a page that uses JavaScript.
Bower is probably outdated because it's obsolete. The way you use both is wrong, you're inlining from node_modules/bower_components, which means you have to upload the entire thing onto the server. You're also putting loading effort on your users shoulders. JSX is a compile time effort, so is most of babel. Clicking a HTML and expecting it to work is naive at best. The browser won't allow you to fetch resources and the scripts you pull are bloated with code you will never run. Webpack packs only the bits and pieces that your application needs and it reduces your manual labour down to nothing. I'm scratching my head over why you'd want to go through all the pain just to be able to click and run, then debug by refreshing the entire application. 
Well what? Why would you need a server to develop front-end? The tutorial I mentioned here also show that I don't need server to just render simple JSX. Everyone else can just refer to CDN and there is no server necessary. Perhaps, for later I will do what it is the best practice. For now I just want to develop my front-end with all dependencies managed. Would be better if you just tell me how can I use Webpack to compile my front-end node_modules honestly.
Node is not a server. It is an independent platform. You can use it on your server, but also on the frontend as a foundation for your build tools. Webpack is not hard to use, follow a couple of examples on their page and you'll be up and running fast: https://webpack.js.org/ Most frameworks also give you tools to make it easier. Since you mentioned JSX you probably use React, in that case you can use [create-react-app](https://github.com/facebookincubator/create-react-app). But all frameworks have them. Internally these cli's rely on node and webpack again.
My question was actually set because I don't want to use CDN. Internet is not good in where I live. I want everything downloaded once for all and managed like it was with Bower. I want to know how to use Yarn and Webpack like it is mentioned as a Bower replacement.
Unminify to help debug. Why minify it in first place?
Alright, okay... I will try using CLI to generate React. I have tried Webpack several times last night. Still don't get it why it is convenient, perhaps I just don't get it yet. All in all I am still confused though. 1. I agree that I missunderstood NodeJS as a web server. In fact, thing like Express and Hapi are web server. 1. A year ago Bower was still a thing. And now having both Bower and NPM is considered bad thing. I remember people advocating Bower to separate back and front-end deps. Now, imagine all legacy web apps that is still using Bower. 1. How can I import JS files? Initially every import started with that `&lt;script&gt;` in HTML files. Then again, considered bad practice. Then everyone is using RequireJS (there is CommonJS as well, wtf is that? Also SystemJS ). Now, everything need to be packed first with Webpack, if I am not missunderstand it. Seems like web dev is something I never finished, what is best "LTS" way to import JavaScript files nowadays? 1. There is Yarn and NPM, which one to use? They both are seems the same though.
Debugging bug in production...
You cannot close the window, sorry. Maybe think of some other alternative.
Yea, I know, Im sorry if its shit for you guys. Im just trying to build up my blog and create new content and this was really easy to write. (Also I was preparing for a JS interview and writing the article and looking up everything was really useful for me.)
And I were using local dev servers for stuff like that.. Thanks!
thanks for updating the thread! posting here so I can try it later
A view days ago there was an **excellent** post explaining the whole javascript universe for people that don't really get the *why* [Modern JavaScript explained for Dinosaurs](https://medium.com/@peterxjang/modern-javascript-explained-for-dinosaurs-f695e9747b70)
2. Forget Bower. Just npm. 3. Forget manual script tags, systemjs, commonjs, all this complexity. Learn the basics of webpack and get familar with es6 module semantics, that's all you need. npm install thePackageYouNeed import { something } from thePackageYouNeed something.foo() Webpack is convenient because it AST-analyzes your project. Just give your entry index.js and all the packages you use will be in the bundle. It discards even code inside the dependencies you load that you don't use. Webpack also optimizes, loads images/resources, gives you a proper server with live reload or hot-module-reload, etc. 4. npm and yarn both use the npm registry. yarn is simply an alternative for the client. It doesn't matter which you use.
So I'm currently using the following code to close certain pages with certain text within the page's HTML (and it works well): var blacklist = ["There are no HITs in this group available to you at the moment.", "You are not qualified to accept this HIT"], re = new RegExp(blacklist.join('|'), "i"); if (re.test(document.body.textContent)) { var win = window.open("","_self"); win.close(); } Is there a way I can utilize the above code's style but with an aforementioned url.match?
11 is pretty vague. He doesn't explain in the body of the item that you're supposed to type monitor(func1); in the console, so it took me a couple of minutes to see what he was on about.
`debugger` shouldn't be committed to repo. It should only be used in production when attempting to debug production issue. Usually setup a linter in the CI to caught this. 
Bower is a plugin manager. Plugins are out of fashion now. Bower was created at the time when JS had no module system, only plugins. It just dump the plugins into a directory without much consideration of "entry point" and portability. For modern projects, you should use a module system - preferably ES6 or CommonJS, but AMD/RequireJS and SystemJS works too. You make those work on the client by using a bundler like Webpack/Browserify/Rollup/RequireJS/etc. You manage project's modules using NPM/Yarn. 
Kill em all
Create a simpler exploratory example; it‚Äôs not clear what you‚Äôre trying to do. This will also help you with figuring out what you‚Äôre doing wrong. Note that you have to return functions from the `get` trap: Alas, there is no trap for method calls.
JavaScript: The Good Parts. Still relevant today and a great book for anybody looking to get into the language.
NOOb starting out I didn't know about the trace call that's super handy üëçüëç
Hi /u/gajus0, fair reminder that facepalm may not help your point, and others might see this as a dick move. Your comment appeared in the modqueue as multiple people found this to be condescending. We're not particularly harsh when it comes to comments, but do pay attention to the whole "Remember the human"
Just tried Webpack. Does this means that the process is actually longer since I need to bundle when I change something? Usually, I will just go to browser and hard-refresh. Now I need to re-bundle my JavaScript files before I go to to browser.
If you are trying to find slow code, use console.profile instead of a timer. Makes no sense to litter your code with timers when the profile will tell you exactly where the slowness is.
RTFM IS THE ONLY WAY!
There are cases (like compiled code from TypeScript) where breakpoints sadly doesn't work :(. I was really glad I found out about "debugger".
I actually prefer /u/DeUsuahiaALaQuiaca‚Äôs version: * I can see more clearly what‚Äôs going on (that may be just me, though). * You can add a second parameter (with a default value) later on and the code won‚Äôt break.
Not at all. You use webpack-dev-server while developing. Change some code in any text editor you want, save, and your app refreshes by itself. Later on you add hot-module-reload (i believe create-react-app sets that up automatically), then only the component you change will refresh while the application retains its state. https://raw.githubusercontent.com/r7kamura/katatema/master/images/demo.gif
Here's my userscript to close spotify website and open album/track/playlist in the native app instead, then close the tab. It should work for you with little tweaking. Source: http://fiaxhs.com/dev/misc/SHUT_UP_SPOTIFY.user.js // 1. open about:config // 2. search "dom.allow_scripts_to_close_windows" // 3. set it to true. if (matches = /(album|track|user\/[^\/]*\/playlist)\/([^\?]*)/.exec(window.location)) { window.location = 'spotify:' + matches[1] + ':' + matches[2]; window.close(); }
Okay..... sounds cool. I hope it is easy to learn. Is there any other tools to ease my development? Like for the best-best practice?
I personally found books like Eloquent JS a bit difficult to understand after the first two/three chapters. I would personally recommend (in no specific order): * [Beginning JavaScript](https://www.amazon.co.uk/Beginning-Javascript-5th-Jeremy-McPeak/dp/1118903331/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1509285509&amp;sr=1-1&amp;keywords=beginning+javascript) * [JavaScript and JQuery: Interactive Front-End Web Development](https://www.amazon.co.uk/JavaScript-JQuery-Interactive-Front-End-Development/dp/1118531647) * [You Don't Know JS: Up &amp; Going](https://github.com/getify/You-Dont-Know-JS/blob/master/up%20&amp;%20going/README.md#you-dont-know-js-up--going) Hope that helps! :)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [getify/You-Dont-Know-JS/.../**README.md#you-dont-know-js-up--going** (master ‚Üí c4ab888)](https://github.com/getify/You-Dont-Know-JS/blob/c4ab888b4b7d778f58591e4dee440734c0333847/up%20&amp;%20going/README.md#you-dont-know-js-up--going) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
It sounds like you wish to invoke your `ErrorContainer` instance's (i.e. the `Object` you're _virtualising_) `add` method when the `get` trap is invoked. You could additionally proxy the function itself, but it seems easier to return a function from `get` that the consumer will then call. i.e.: ``` get(target, prop) { // use duck typing if running in different execution environments if (typeof target[prop] === 'function') { console.log('Requesting function property!'); /* this returned function will pass the arguments * specified by the consumer to the original function. */ return (...args) =&gt; target[prop](...); } return target[prop]; } ```
I used TextMate, and recently switched to Atom. 
Webstorm
Atom üëå
Forgot about it. IntelliJ has some great tools indeed.
They're Jetbrains :)
create-react-app
The thing is that exploit (opening the `_self_` window and _then_ closing it) is just a kludge and it doesn't always work (works in _some_ versions of Chrome). You _could_ try /u/Fiaxhs suggestion of setting the config of `dom.allow_scripts_to_close_windows` to `true` but it's only for Firefox and I wouldn't recommend it as then, other scripts could close your windows, which you wouldn't like.
It depends on the edit, for small edits I just use a simple terminal based editor, large edits I use vs code. Neither I would consider ides.
Still using eclipse after trying everything else.
Vscode. Especially cause I use typescript a lot. 
For TS I've had good luck using source maps with newer versions of Chrome. Breakpoints and the locals window all seem to work correctly. 
Ah, I think OP misunderstood how yarn (or npm) works. Firstly, it's true that they are both package manager, which means you specify a manifest file (say, package.json) and both will download code from a repository to a local folder. Now the different between them is how you import them into your HTML. In the case of Bower, your HTML will look like this &lt;script src="bower_components/library1/main.js" /&gt; &lt;script src="bower_components/library2/main.js /&gt; ... &lt;script src="bower_components/libraryN/main.js /&gt; This is because Bower is a very simple package manager. You make a reference to the files directly and the browser will execute them from top to bottom. That's why you would usually have jQuery imported first, and your application code last. In case of Yarn + Webpack, we will use CommonJS - NodeJS's way to use modules. But I won't think flooding you with NodeJS stuff could help. So let's go back to the HTML file. Your file would now look like this: &lt;script src="/my-app/main.js" /&gt; Well, now there is only one file, and this file is called an entry file. To understand where this main.js file comes from, you must understand how webpack works. It looks kinda like this: an input file ---&gt; [WEBPACK] ---&gt; main.js Let's assume the input file is input.js. In your input.js file you would declare something like this: var React = require('react'); React.doSomething... Do you see this magical "require" method, which is not available in most browsers just yet? Under the help of webpack, it will fetch React's source code in node_modules folder and put it in main.js (The actual process is much more complicated). In the end, main.js contains both vendor's code and your code, in a specific order that you won't need to care about.
I say this every time I see these God awful titles. I usually get downvoted though, but then again, I‚Äôm a little more aggressive in my approach. Even ‚Äúmight‚Äù would be better than ‚Äúprobably.‚Äù
To add to point 3, you can also click the options pane when in device mode and hit "Show media queries", which will highlight all of your breakpoint as found in your CSS, and allow you to quickly jump to your sizes.
I checked the `apply` trap but it doesn't feel like will help or I couldn't wrap my head around it. :)
&gt; Bower: downloads the files locally and we include them based on path name &gt; NPM (Yarn): downloads the files locally, (currently) we use webpack to inject blocks of source code into a single output file, ready to be included inside HTML. Nice explanations. Since last night I still have the same question: from your definition of Yarn and Bower, doesn't it clear that using Bower is more practical than using Yarn/NPM? With Yarn/NPM we need to download the packages, `require(something)`, Webpack configurations that is not as obvious as it is with Bower, run Webpack, run browser, found an error, run Webpack again berfore refreshing browser. Whereas with Bower I just need to download package, embed in HTML, and refresh browser. I know this "2017 Front-end JavaScript Edition". People definitely knows better than me. People advocated Bower in previous years as "the best practice" while now Bower is considered not good to be used at all. I couldn't find why using Yarn + Webpack is more flexible than using Bower. Would the "2018 Front-end JavaScript Edition" change the best practice again XD?
Vim. IDE is for idiots.
I paid for phpstorm, but I still end up always using VSC . 
The power of alt enter 
Lodash has `_.memoize` which does this for you, without the boilerplate. By default, it memoizes based on the first argument to the function, so future calls with the same first argument will just return the memoized value. 
It's true that Bower's model is way simpler, but firstly we face an economic problem: people create packages in npm first because they want to use both Node JS and in the browser, and Bower, sadly, only supports browser. Secondly, in case you haven't noticed yet, how do you use jQuery with Bower? In your app code you would have access to a magic, global-scope, attached-to-window variable named $, is that right? Global is evil, and with npm pattern, we can avoid that: Lastly, Webpack has a lot of plugins and it's more complicated than just copying blocks of code. For example, you can read YAML file or import SCSS or optimize the output files. The ecosystem is just huge.
I‚Äôd include `this`: return function (...args) { return target[prop].call(this, ...args) };
How is server-side performance of React? I suppose server-side renders are cached?
Vim + bash/cmder depending on what OS I am using. 
Having to press more keys is so manly! Oh wait. It's not. Using a dumb editor is... well, not the best use of your hardware. It also doesn't improve the resulting product in any shape or form. It doesn't add some handmade charm or other voodoo. It only adds some inconvenience to your workflow. You are of course free to take some misguided pride in this, but you should try to view this more objectively.
Actually I used it only to change some strings literals to template ones so far.
Consider caching the promise, not the result. Callers can still use `await`. It's perfectly alright to give the same promise to multiple callers. It's as simple as: class Whatever { fetch() { if (!this.cache) { this.cache = myAsyncFunction(); } return this.cache; } } 
Just a suggestion, add some examples of usage / output / options to the readme. It looks a bit bare, and as someone looking at your development I didn't really get an idea of why this is different than any other minifyer out there.
Good shout Axel! I've updated my example.
And alt insert
Based on the title, I fully expected all of these to be thing I already knew. But black boxing and `monitor` was new! Good stuff.
Ah good point on that last part. However, the await part doesn't resolve to a Promise. I've checked, and it gives me the returned value of the async function.
Notepad++ because I'm a rebel.
There shouldn't be an `await` in your function, and it should be a normal function, not async. The *callers* will use await on it. Your function simply obtains, caches and passes along a promise.
VS Code. I‚Äôm interested in giving webstorm a try though
I think he's talking about conditional breakpoints; which (at least as of two weeks ago) don't work with compiled code and source maps. 
You're missing out. https://code.visualstudio.com/docs/languages/javascript
The same one that uses the text editor I prefer.
From my understanding, the react app is supposed to be served from a server and not opened using the file protocol (just opening index.html in a browser) If you are running express you can use a GET routing path to send back the index file that the build process produces.
Firefox has a responsive design mode (Ctrl-Alt-M) that lets you resize the viewport, test touch events, take screenshots, and more.
You're missing the point. Your post seems to suggest that promises result in a pyramid structure, like: function processN (n) { console.log('promise n') return inc(n).then(n =&gt; { return mul(n).then(n =&gt; { return dbl(n) }) }) } That is not how you are supposed to use promises. You are supposed to flatten out the chain: function processN (n) { console.log('promise n') return inc(n) .then(n =&gt; mul(n)) .then(n =&gt; dbl(n)) }
Probably, but I have trouble tolerating big IDEs. I like being able to just quickly open files rather than load up a monster. If I really need a proper environment, I use Brackets.
I have figured out your point now. That's a great suggestion, given that I was already awaiting the getter. If you're able, please do review [the module I'm working on](https://gitlab.com/3VtDHnbvGd/speedlane). Thanks.
I usually vim all the things. Otherwise, webstorm.
Yes, just go through Eloquent JS first.
Atom. It's finally come into its own. I was a super early adopter and struggled for months, but stuck with it and glad I did.
Code is fast
vs code is hardly a "big IDE"
I wouldn't know to be honest. I've only used Visual Studio before and that physically hurts to load up.
You can run a bundle by double clicking index.html, if you can't something else is going on. From your error output it looks like it simply can't find your files. Also, you can copy the source of those cdn libs into local files which you then load as script tags. What you can't do is local requests and fetches, the browser doesn't allow it because of security concerns.
&gt;Unminify code What are source maps
size wise it's similar to sublime text
Why is it that everyone that uses VIM or Emacs thinks they have the biggest dick in the programming world?
Atom. A lot of Atom users seem to be switching to VSCode. I tried it but it wasn't for me. So I am sticking with Atom. I have previously used Gedit, jEdit, Eclipse, and Sublime Text.
&gt; load up a monster VS Code takes about 2 seconds to load on my 2013 laptop. This is with 6 extensions (3x Java, Python, Dart, and TSLint).
What benefit does this give over webpack/uglifyjs? Is there support for dead code removal?
I‚Äôm still on Atom. I will switch over to VS Code the day I can get it to match the feature set I have with Atom. They are so close. I think once the Tree View git color coding is released (which I know is actively in dev) I will give it another try.
Thanks, my fault
Is it faster than it used to be? I wanted to like it, but it was super slow, and often crashed. 
vim is about using fewer keys and ergonomics. Dogma is bad, no matter what side you're on. I personally find control keys clunky, and don't understand why you'd want to move your hands to switch between navigation and typing. 
Thanks, I got it. I did not dig in too much. I thought each then just recall the previous resolved promise.
Same here.
If it's java then I use eclipse. For .net projects then I use visual studio. Everything else I use vim.
Atom. VSCode interests me, but I don't love using a project under Microsoft's domain. I'm considering switching away from Atom because it can be pretty slow, but no non-web GUI (As in, not `vim`/`emacs`.) IDEs for Linux come to mind.
Used to use WebStorm, but now use VS Code. WebStorm is still a great product, but I dislike the subscription model they switched to and VS Code with a couple plugins is 98% as good, and is faster with more frequent updates. Also its TypeScript support is top notch.
I'm with you. I fully uninstalled Atom and tried to switch to VSCode for a couple of weeks, but working on files via SFTP and working on different projects at once wasn't nearly as good. Atom may be slower to start, but it's getting better with each release.
VS code, yes. Not VS. 
You might have a better time at /r/learnjavascript.
Surprised no one said Sublime Text, especially after it finally came out of beta.
&gt; ####4. Get the answer to ‚Äúdoes this actually make me happy‚Äù. ü§î
Intellij Idea + IdeaVim + Eslint + Prettier. Your productivity will SKYROCKET.
Sublime Text 3 - fast and built in plugin library
It is. That being said, I use VSCode :)
Coda
&gt; but working on files via SFTP this kills the version control
Visual Studio Code
It should work with sourcemaps, I use IntelliJ ‚Äòs JavaScript debugger with typescript, and it works, but so does chrome‚Äôs debugger
I speak at conferences for a couple reasons. 1) I have a lot of friends that speak at conferences, and that allows me to hang out with them. 2) I want to help shape the profession 3) The group in #1 often provide a great opportunity to learn. I have friends that are experts in various areas, and I can tap into their knowledge. I personally enjoy speaking and have had some good tangible and intangible benefits come out of speaking at conferences. For example, I can literally tie a chunk of money over the past 3 years to my speaking since 2012. That said, it's not for everyone, and that's OK. Also, for the "How" a large part is knowing people. It's not exclusive, like every other part of life, knowing people helps.
Yes you can, this is an example https://www.kirupa.com/react/creating_single_page_app_react_using_react_router.htm. The tutorial uses CDN. I want to have something like that as well, but managed with package manager like Bower. Actually, I can do that with Bower. But most people says using Bower is not the best practice anymore. So, I have been asking around wondering how can I done such like that with NPM or Yarn.
Yes using CDN or Bower works. But I want my front-end packages managed. Most people says using Bower is not the best practice anymore. Hence, I want to know the way to manage front-end dependencies using NPM or Yarn.
[removed]
VSC
Are you sure you are not confused between Visual Studio and Visual Studio code?
 if (app.keyboard.isPressed(pc.KEY_X)) { y += [some int value]; // and int value will be an immediate jump to the y coordinate. // you would want to use an interval to accelerate the player to the y coord, // then make the player fall back to the ground. Bonus height if they press jump twice within some time span. } // probably need an interval to handle falling back to the ground. if (x !== 0 &amp;&amp; z !== 0) { force.set(x, y, z).normalize().scale(this.power); this.entity.rigidbody.applyForce(force); }
Yes, it now handles large files fine. IIRC, the major issue was an architectural issue with the way large files were processed, requiring line by line highlight and indenting, which was recursive and very slow. It's now been improved by a large factor
That‚Äôs good to hear! I‚Äôll give it another go then.
IntelliJ Idea. Sublime Text 3. Vim. In the order of increasing urgency / proximity to production.
I appreciate your questions as they are valid. I will try to address those in the documentation. 
Yes, I definitely needed to add more clarification in the repo. Also, examples are also a nice idea. 
You are a masochist!
VIagra
PHPStorm (i.e. WebStorm) mostly. VSCode is awesome and tempting me to switch, but I keep discovering great things in PHPStorm.
How is it still better than SublimeText?
Forces add to acceleration, you want to add to your velocity to instantly start moving up. What you want is called an impulse, which is the integral of force over time, or the change in momentum. If your using someone's code for the rigid body, there may be a applyImpulse function or something. If not, you just need something like ridigbody.velocity.y += jumpImpulse / rigidbody.mass. 
&gt;You are of course free to take some misguided pride in this, but you should try to view this more objectively. Just want to point out that the entirety of your post up until the point of pleading for "objectivity" is some weird jab at how you think people who want to use the keyboard instead of the mouse must think they're more manly (but are not!), and that vim a "dumb editor", and that people who use it must think it adds "handmade charm" and that vim must add some kind of inconvenience to the workflow without siting anything. But yeah people definitely need to learn to look at things objectively. lol
Visual Studio and Visual Studio Code have nothing to do with each other. VS Code is just a text editor with some extra bits, like Notepad++. I wish Microsoft had just named it Visual Code or Visual Text...something like that. 
Emacs 25: jslint, snippets, Git support, deployment support, project management support, TDD support, SSH connections. Unbeatable productivity. 
+ IdeaVim
What plugins do you use?
I used to be the same way. Not-Ballmer MS is impressing me though. 
Atom took my IDE virginity and has been a gentle lover ever since
VS Code, switched from Atom and loving it. VS Code runs well on older computers, which is very important to me... my shitty old laptop just died, so when I'm not at home I'm on an even shittier, even older laptop (we're talking like a low end budget HP laptop from 2008). Last time I tried to run Atom on it, the computer froze. Meanwhile, VS Code runs just as smoothly as on my desktop.
&gt; you think people who want to use the keyboard instead of the mouse You got that part wrong. It's about making the machine do more for you. Context-sensitive auto-complete, call-tips, type-checking, linting, go to definition, find references, rename identifiers, auto formatting, and things like that. Also, having things like build automation, debugging, SCM, and so forth integrated is also very convenient. For what it's worth, the first IDE I used didn't have mouse support. What it did have was a compiler and a (super basic) debugger. Mouse support isn't a defining characteristic of IDEs.
Isn't this questioned asked like every month of every year? Why don't you just look up last months responses instead of asking the same question over and over and over and over?
VS Code is more like Notepad++ and Sublime than full Visual Studio. It's an extendable text editor, not a full-fledged IDE.
Not a fan of Typescript, but I prefer VS Code. Atom was a little bloaty feeling, and I just felt bad pirating SublimeText 2.
Do you guys know what sourcemaps are you using? I tried most of [these](https://webpack.js.org/configuration/devtool/) and couldn't find the right combo for fast recompile and breakpoints
Believe me. Not my choice. 
Awesome. Thanks for the response. Going fiddle with it and then let you know how it goes.
Same reason the IRS doesn‚Äôt just send you a bill for what you paid last year. Same reason I‚Äôm not typing this in aol on my blazin 28.8k connection. 
Spacemacs for life
Sublime and Atom.
&gt; It's about making the machine do more for you. Context-sensitive auto-complete, call-tips, type-checking, linting, go to definition, find references, rename identifiers, auto formatting, and things like that. ...which of these do you think vim can't do?
Why not set a break point?
Whose brain dead choice is it? It's 2017. This should never be allowed, or even be allowed as an option. I'm guessing there are no sysadmins at your company, and everyone is from 1998? 
Yeah, it is. I did some benchmarking on my system on Ubuntu 16.04 with the latest Sublime, latest VSCode, and latest Atom and the results were interesting. Sublime launches in less than 1 second, VSCode launches in 2 seconds, and Atom launches in 3 seconds. To me, the extra telemetry found in the core and especially addons of VSCode (some that cannot be turned off, without even any comparable alternative non-telemetry addons) is not worth the extra 1 second faster performance compared to Atom. I like Sublime for large files and Atom for everything else, even though Atom is a lot better with large files than it used to be.
So you are saying a month in the world of IDEs is equivalent to an IRS period (whatever an IRS is), or 20 years of modem development. That's an interesting insight. Do you honestly believe that or are you just trying to be funny?
Sublime Text
That indexing tho...
It probably can't do quite a lot after you spend a few weeks configuring it. I don't think you'd be able to get the JS/TS capabilities up to VS Code's level, though. And VS Code does all of that out-of-the-box. Oh, and if you add features like debugging, you got an IDE.
Yes Emacs! IDEs are overrated.
&gt;It probably can't do quite a lot after you spend a few weeks configuring it. Try years. Customizing vim is an ongoing thing, I personally find it extremely fun (this is actually what I consider the most important thing when picking an editor - finding the one you actually enjoy using the most. It's your job, after all). An advantage here is that vim will be around forever, so this will never be "time wasted". And yeah, I think most people use vim as a sort of bootstrapped IDE - it's really not a dumb editor. You can also edit any filetype with all of the capabilities of the editor, and use it in your terminal obviously. There are a lot of upsides to vim's ubiquity, beyond the insane editing efficiency it provides, which is often glossed over when talking about it.
Is 1 extra second to start up really that critical though?
Yeah that drove/drives me crazy. Make sure to set node_modules and any dist/build folders as "ignore". Should save you from slow indexing.
You look like an experienced developer, so I'm not sure why I have to explain this to you. For example, look at socket.io's websocket frames. The library does message_id reconciliation so that you can write this on the client: socket.emit('login', [uname, password], (err, user) =&gt; { if (err === 'INVALID_CREDS') { // reflect error on the login form return } else { // unexpected error throw err } // authn succeeded, so we can initialize our client // with the user payload. }) It does this by wrapping its websocket messages with message_id envelopes which is why you can't just connect to a socket.io server with `new WebSocket()` and start blasting away. In other words, it has its own message protocol over the wire. A given websocket server might implement this sort of message_id system (I've used some that roll their own) and/or custom message encodings (for example, binary with Protobufs), not everything is just pretty json messages. The point here is that there's a moment where it can be easier to execute a web app in a headless browser than implement its wire protocol. It just depends. 
1 second hardly makes a difference to be honest, if I need speed I'll use Sublime otherwise I'll use Atom.
Emacs can be an IDE, actually the best IDE... if you want.
Saying that like your deadline in an hour and you're writing code like a stenographer. Environment in IDE implies you'll spend some time in it.
Sometimes you need to debug code that **YOU** didn't compile, or was 3p code.
Sometimes you need to debug code that **YOU** didn't compile, or was 3p code.
I made the switch from phpstorm to vsc last month... emmet is a little clunkier than the shortcuts in phpstorm still, but I've adapted to gathering else for the most part. Much less laggy I find as well
GP is being a jerk, but responding in kind just feeds the flames. Don't get drawn into editor wars, there are few things more inane than a pissing match over tools. (FD: Long-time vim user, but I'm impressed by vscode's features, and shocked by how well it runs.)
Browser console anyone?
VSCode
tmux + vim + plugins + command line.
Can't escape neovim on the cli. Been using vim or neovim for the past 5 years. If I didn't spend the majority of my time in a term with tmux, I'd likely use vscode. 
WebStorm, hands down.
I used to, but VSCode's "intellisense" is just better. 
I still use PhpStorm for php though. 
If I confused them why would I have said the above?
true
I'm still using Gedit. Atom seems to struggle a bit with larger files.
I've never run in to that, but it's good to know
I still find myself in IDEA most of the time, but it really depends on what I'm doing. Sometimes, especially when starting up a new project, I don't feel like fiddling with environment setup and all that really any IDE forces you to deal with, so then I fall back on UltraEdit and a command prompt and that's it. That way, I can get the basic skeleton banged out quickly, without worrying about any tooling getting in my way, and THEN, later, I can create a project in IDEA and bring the code into it, knowing that it works to at least a basic level, and get the environment set up to take it further. I'll usually do it that way if it's a little throwaway project just to test something out... it's more efficient then setting up a project in whatever IDE, even IDEA, where it's not exactly difficult to get something set up. It's still easier with just a text editor and a command prompt (and often a batch file to streamline the setup/compile/run cycle, be it Node, Java, C++, whatever I'm working with that day).
Settle down. Things move slowly in higher education. You think that's bad? Don't look into health care or the financial industry.
What are the ‚Äûmust have‚Äù plugins to work with js/ts in vscode?
It‚Äôs a text editor, not an IDE. 
I use Atom. I've tried VS Code but support for Flow there is bad as the language server just yells at you for using types in non .ts files. 
react static.
Reatic. *** ^(Bleep-bloop, I'm a bot. This )^[portmanteau](https://en.wikipedia.org/wiki/Portmanteau) ^( was created from the phrase 'react static.'.)
VS Code is the Microsoft equivalent of Sublime or Atom. It shares very little with Visual Studio itself, apart from the brand. 
Wait, VS Code isn't an IDE... is it? I guess it does have a debugger.
I've done security contracts for both of those industries, and I've yet to see either do anything as dumb as have an FTP server running on production systems exposed to the internet with user accounts. Mind you, if they didn't pay for yearly security audits then they may still be doing that garbage. Nonetheless, it's no excuse. Make it your choice and end that practice. Put the education back into higher education, rather than working like you're high.
I dunno, I use Sublime Text ;) A lot of people in this thread seems to think VSC is an IDE though. 
Sublime. I've tried both Atom and VSCode recently but Sublime has just always clicked with me. I love the package control thingy.
The new atom-ide-ui is really awesome!
Interesting concept. You could add quite a bit of variation by applying some random css classes to various tiles, like opaciity, blur, border-radius, negative margins, etc.
i don't have any plugins
I would definitely think of vscode as an IDE. Seems I might be wrong there, but I‚Äôm interested to know why if anyone wouldn‚Äôt mind educating me. 
I was literally waiting for someone to name socket.io or either of the alternatives. The point is ‚Äì there are handful of these protocols and all of them are open-source. This argument is void as such.
Here is a list of threads in other subreddits about the same content: * [Next Level Webpack Dashboard](https://www.reddit.com/r/node/comments/79j0am/next_level_webpack_dashboard/) on /r/node with 7 karma (created at 2017-10-30 04:43:41 by /u/thickoat) * [Next Level Webpack Dashboard](https://www.reddit.com/r/webdev/comments/79iyb7/next_level_webpack_dashboard/) on /r/webdev with 8 karma (created at 2017-10-30 04:34:41 by /u/thickoat) * [Next Level Webpack Dashboard](https://www.reddit.com/r/vuejs/comments/79jdmb/next_level_webpack_dashboard/) on /r/vuejs with 2 karma (created at 2017-10-30 05:43:38 by /u/thickoat) * [Next Level Webpack Dashboard](https://www.reddit.com/r/reactjs/comments/79jdio/next_level_webpack_dashboard/) on /r/reactjs with 2 karma (created at 2017-10-30 05:43:11 by /u/thickoat) * [Next Level Webpack Dashboard](https://www.reddit.com/r/Frontend/comments/79iygd/next_level_webpack_dashboard/) on /r/Frontend with 3 karma (created at 2017-10-30 04:35:22 by /u/thickoat) ---- ^^I ^^am ^^a ^^bot ^^[FAQ](https://www.reddit.com/r/DuplicatesBot/wiki/index)-[Code](https://github.com/PokestarFan/DuplicateBot)-[Bugs](https://www.reddit.com/r/DuplicatesBot/comments/6ypgmx/bugs_and_problems/)-[Suggestions](https://www.reddit.com/r/DuplicatesBot/comments/6ypg85/suggestion_for_duplicatesbot/)-[Block](https://www.reddit.com/r/DuplicatesBot/wiki/index#wiki_block_bot_from_tagging_on_your_posts) ^^Now ^^you ^^can ^^remove ^^the ^^comment ^^by ^^replying ^^delete!
delete!
I found that VS Code failed to automatically find my imports (and offer to import for me) from other project files in the same directory as my current text file; am I missing something in its setup or something? Have stuck with WebStorm as a result.
dude! this is awesome! I was planning to build something similar. Did you use D3? 
Webstorm is great at guessing what functions or variables might be available when you're in the Wild Wild West of Javascript. The downside is it's still just guessing, and it's still wrong, a lot. Also the cost of the good guessing is painfully slow indexing. VS Code is great at actually knowing exactly what things are available when using Typescript, or even using JS modules that include typings. Typescript and VS Code are also both getting better every release at trying to do their best at handling plain old Javascript. 
Webstorm is great at guessing what functions or variables might be available when you're in the Wild Wild West of Javascript. The downside is it's still just guessing, and it's still wrong, a lot. Also the cost of the good guessing is painfully slow indexing. VS Code is great at actually knowing exactly what things are available (or not) when using Typescript, or even using JS modules that include typings. The Typescript compiler and VS Code are also both getting better every release at trying to do their best at handling plain old Javascript. 
I used to use WebStorm heavily but recently switched to VS Code. Much lighter to run, and my laptop fan doesn't scream like crazy while indexing.
This is the correct usage. If you want genuine immutability, [it can be done](https://facebook.github.io/immutable-js/), but using `const` to define an object you will later add properties to, or change the properties of, is absolutely fine.
I had been using VS code since emacs and vim seemed too complicated. Spacemacs changed my mind. It's so good.
Webstorm
Prettier, auto import, vim (if that's your thing).
Same, but I swapped neovim for tmux to keep all my split management consistent 
I use a plug-in for auto imports. 
Pasting my comment from HN for visibility: I find the tagline to be rather confusing. Why "for babies"? Also, while this appears to be _inspired_ by Redux, it's definitely not the same as Redux. In particular, it has separate event emitters for each top-level key in the state instead of a single change event, no middleware, no store enhancers, etc.
If you use eslint you can enable the no-debugger and no-console rules: * https://eslint.org/docs/rules/no-debugger * https://eslint.org/docs/rules/no-console In fact they already come enabled in most popular presets. That way you can use them in development but the moment you try to build for production it will yell at you.
Vscode with vscodevim. I used to use vim a lot more but now it's mostly for small-scale use.
What plugin?
Atom is such a pig, I'm not sure how anyone is remotely productive with it unless they running a super high end system. I tried it for a bit but it's just so awful at loading large files or anything I gave up on it. 
A bit??? Hahahaha 
Hi /u/TomNotTomYT, For javascript help, please visit /r/LearnJavascript. Thank you!
Hi /u/madelfant, For javascript help, please visit /r/LearnJavascript. Thank you!
I don't care about startup times. I care about file access and dealing with large files. Atom last time I used it was so bad at this I gave up on it. 
How do I achieve this? Also I'd love to know how to change which file types are in the add list.
That could be difficult to do in certain setups. Though normally you would want to do that as it is better practice. In my last job, we had async module loading and significant non-persistent UI state. So setting a breakpoint in some of the rarely used async code was a pain. Not only did you have to induce the UI state, the code would run once and never run again. So we would need to reload the page and run though the whole process all over again just to trigger the breakpoint. 
* Code Spell Checker - cause TypeScript doesn't prevent you from misspelling words * EditorConfig - to enforce text format in all files, not just TypeScript * TSLint - duh, maybe ESLint/JSHint if you are still in pure-JS-land 
sure. people cant be ‚Äúremotely‚Äù productive in a text editor that might be slightly slower than another text editor. do you realize what a fucking moron you are?
no, youre an aspie moron and your team hates you.
just like girlfriends and ... well, friends in general... am i right?
How long ago is last time? Atom somewhat recently has somewhat drastically improved large file access time.
If you use TypeScript, TypeScript hero is really good. 
Thank you
It's my favorite editor by far, though I imagine VS Code is being mentioned more because it's pretty good, and infinitely cheaper than a Sublime license.
visual code till the moon such wow
Who is viewing massive files in a code editor? I feel bad for that person
Try /r/learnjavascript 
I‚Äôm on a 2009 MacBook Pro (8gb ram) and have been using SublimeText since 2011. Have tried Atom and VS Code, and they are both a bit laggy for me, and are pretty slow to load up. I still prefer a lot of how Sublime does things, and the speed of it, so I continue to use it. I think a big reason of why atom and VS seem bloaty and slow is because I think they‚Äôre built on/with electron... and compiled python (Sublime) just runs faster than JS (electron).
jedit, atom, vscode every now and then i switch from one to another..
`const` only applies to primitives. If you want immutability on objects, you have a few options: * use a library - Immutable.js and Seamless Immutable are two popular ones * TypeScript - [code example](https://www.typescriptlang.org/play/index.html#src=const%20arrayBuilder%20%3D%20%5B1%2C%202%2C%203%5D%0D%0AarrayBuilder.push(4)%3B%0D%0Aconst%20array%20%3D%20arrayBuilder%20as%20ReadonlyArray%3Cnumber%3E%3B%0D%0A%0D%0Aconsole.log(array.join(''))%3B%20%2F%2F%20OK%0D%0Aarray.push(5)%3B%20%2F%2F%20error%0D%0Aarray%5B5%5D%20%3D%201%3B%20%2F%2F%20error%0D%0A) * `Object.seal()` and `Object.freeze()` - not generally considered good practice in application code 
Netbeans. 
+1 on Prettier. Can't live without it. (I use it in Sublime).
I use both Sublime and VS Code. I would call VS Code an IDE, mostly for the debugger, which is great for NodeJS.
`const` only applies to primitives. If you want immutability on objects, you have a few options: * use a library - [Immutable.js](https://facebook.github.io/immutable-js/) and [Seamless Immutable](https://github.com/rtfeldman/seamless-immutable) are two popular ones * TypeScript * `Object.seal()` and `Object.freeze()` - not generally considered good practice in application code For TypeScript const arrayBuilder = [1, 2, 3] arrayBuilder.push(4); const array = arrayBuilder as ReadonlyArray&lt;number&gt;; console.log(array.join('')); // OK array.push(5); // error array[5] = 1; // error 
Atom
Contribute to open source. That's a guaranteed way to get your code reviewed for free.
Never realized till you just told me, you saved me dude. I owe you big time. 
4 months ago maybe 
&gt; whatever an IRS is It's called google. And showing off you don't know about things just makes you kind of stupid, sorry
Notepad++
How do you even do this when most functions in your code aren‚Äôt public?
Atom. Can‚Äôt touch anything by Microsoft 
No, though I have used D3 before. It's highcharts, since i have lots of experience with it, wanted to get something released sooner than later. Been debating migrating it to VictoryCharts or D3, but need to get various other features release first. Can i ask what features or similarities you'd intended to build, or what might make it more useful? I'd like to open source this, but am worried about it being forked for partisan purposes, which i definitely don't want.
I'm in the financial industry and we run everything in Azure with git for development, and use modern stuff (cqrs with eventstore, dotnet core, vue/angular/react, graphql etc), don't paint us all with the same brush :p
Well, there are subreddits where people will review your code. Even this one; people have sometimes posted here some small repository link for code to be reviewed. You would generally need to show a project that is clean enough and not too big and maybe people will look at it and give you feedback.
VS Code
Webstorm. Though VsCode seems pretty decent too
VSC is an IDE. Has its own terminal. Its own debugger. Its own dev server. Sublime requires plugins for all that. Sublime is a code editor with extensible IDE functionality.
Webstorm. Use it on Linux.
https://marketplace.visualstudio.com/items?itemName=steoates.autoimport
VS Code is about the most lightweight IDE out there.
You can right click on a folder and under "Mark Directory As" select ignore or content root. Ignore will stop indexing things in that folder. This helps in build/dist folders where you have large minified files that slow the indexer.
Been using Brackets by Adobe since I primarily work with HTML/CSS/JS and it has an interactive live view to see your web pages. Pretty nifty.
I started making nodejs backends with socket.io messaging. It is really easy, and I had personally a lot of fun making apps where you can message between devices. My tip: make a tic-tac-toe app where you set up a nodejs server so that people can play against each other online. You can look here for inspiration: https://github.com/andreas0607/tictactoe
Vscode for sure!! Coming from atom and sublime text
ladies
Should a person learning javascript be using these plugins to help?
I switched from Webstorm to Atom a few months ago. So far, it's been working reasonably well, but it's not perfect. Given the love for VSCode in here, I might have to give that a go.
That's definitively strange, you shouldn't need any plugin for this. Not sure if it has something to do with the tsconfig.json file or not, but in my Angular 4 and Ionic projects, VSCode was able to understand and suggest all my imports...
Only vim. I wont use anything else
I just can't get onboard with using anything Microsoft created. I use Atom for JavaScript and Eclipse (I do a lot of enterprise work) for Java.
no
Same. It just causes me immediate repulsion.
&gt;const only applies to primitives. No, const applies to objects as well. But it makes the reference constant to the object. So that you are always dealing with the same object. The data inside the object is not constant so you can change it. In other words this is fine: const a = []; a.push(1); But this is not: const a = []; a = [1];
That's a great question!
OSX at work and Windows/Linux at home. Don't mind OSX at all actually, its nice to use a UNIX based OS. Haven't tried bash on Windows yet so it's my least favorite dev os at the moment.
These are plugins to help you work faster which is not something you want to worry about while learning how to program. 
How about the autocomplete features in like atom/sublime. Where typing html then hitting tab auto-writes the whole backbone for you?
Thank you for correction
The startup is slower and there's a bit of a delay while typing, but once you have your files open I don't see how it hinders productivity. Depends on the kind of project you're working on I guess, e.g. if you're constantly opening different large files? I had problems with it and I switched away, but *obvious lessened productivity* wasn't really one of them. And I didn't run it on super high end systems.
OSX at work and Windows at home. I haven‚Äôt found a need to use the bash on Windows and, for the most part, everything just works.
I‚Äôd be willing to switch, but I‚Äôm sure it would take time to figure out how to do the same things. The time I save is worth the cost. The stuff they‚Äôve been doing lately is awesome. The new REST client is great, codeception (and now test generation) helps me learn that stuff, code fragments and a bunch more. If only I could get Xdebug stuff to work consistently...
Debian at work, Debian at home.
The fact that there are keystrokes that comprehend structures in code for each language and let you whizz around at light speed without taking your hands off the keyboard is killer. And don‚Äôt forget keyboard macros. 
you have a couple of problems here : 1. switch (numLocal). but you don't have a variable called numLocal. I think you meant "location" 2. you need to declare the result variable first. 3. in your switch block, the variable of text refer to what? here's the fixed version : https://jsfiddle.net/angganegara/xrj5jkqs/
There seem to be a few different issues: Your switch statement is using the variable `numLocal`, which is not defined. Based on the variables you've declared at the beginning of the function, it should be `location`. The value of output2 isn't being updated with the text from the switch statement. You can remove this section: if (location == 1) { document.getElementById("output2").value = "Redfern"; } And add in something after the switch statement, eg.: document.getElementById("output2").value = text You also reference two variables `text` and `result` which haven't been declared using `var result`/`var text`. This probably isn't stopping it from working but they should be declared somewhere. 
Atom fanboy here
If you could do it manually but a plugin helps you do it faster then go for it!
When you're serving a react application from a server locally that is usually a dev server (although more and more people are during server rendered react these days). That is just a convenience for development. Generally these applications are built with a bundler like webpack. Webpack dev-server is what you will run locally. But for deployment you would run a 'webpack build' that would output static JS files. All you would then need to do is include those js files in your index.html and you can open that index.html and your application will run. There are some webpack plugins available to generate the html file for you during a build. The issue you might be running into is that the paths are not set up for a file open type of running. People don't usually look at js applications this way because that's not how they are viewed on a server. You can run a simple server in your terminal to serve the current directory with an npm package like `http-server` or use `python -m SimpleHTTPServer &lt;port&gt;` If that doesn't work for you, you should be able to setup the paths in the html file to work. by using relative paths `./bundle.js` instead of `/bundle.js` 
I've just started working on this kind of thing - can't believe how easy/fun it is. Got a feeling I'm going to learn a lot while building these kind of projects too.
This is above and beyond what i was expecting! Thank you so much, its perfect.
Thank you!! I had location set as the variable earlier, I started fiddling with it to see what I could change to make it work.
Good luck!
IDEA(Kotlin).
osx and osx
I'm a monster and still use vs with resharper. Usually involved with the back end enough that I need it for builds and I'm so used to the hotkeys at this point. 2017 is slightly faster at least...
Microsoft contributes a lot back to Electron which is what is used to power both Atom and VS Code.
Booting up is slow, but I never notice any slowness while actually doing work. You will need a healthy dose of RAM, though, since it's an Electron app.
Just a side note, always post a jsfiddle link or codepen or something of the nature containing your code rather than copy pasting it all here. Especially when trying to solve a bug.
Atom requires a package for html autocomplete, I'm almost certain vscode has several. It also supports sublime, Atom and possibly some vim key shortcuts. Once vscode's support for wsl is more mature, I'm switching for sure.
&gt; we run everything in Azure my sympathies.
It's Arch all the way down, with a bit of macOS thrown in for screen sharing/portability when needed
Prettier TSLint/ESLint Debugger for chrome
(on mac). These days I kind of use PHPstorm and SublimeText3 equally. I sub in Atom for quick stuff. I very quickly tried VScode because of the hype and since it took over the default to open all files i had that ‚Äúoh shit this is microsoft crap‚Äù and nuked it immediately. I know it‚Äôs popular but that bugged me. 
VSCode. For general purpose editing, i use sublime text.
Can you expand on what you mean? I'm using Tmux + Vim now.
Jetbrains. But I'm SOOO ready for something else to replace it. It jumped the shark years ago. Its actually becoming unusable on Mac's with 4 and 5k monitors. Its a two year old bug they know about but still can't seem to fix https://youtrack.jetbrains.com/issue/IDEA-144261
macOS for work. At home I use a combination of all three: macOS, Windows, and Ubuntu. It depends where I start the project is where I'll continue development.
Can you explain how or why `Object.seal()` and `Object.freeze()` might not be considered good practice?
Notepad++. Light weight, handles almost all common languages with syntax highlighting and autocompletion
OSX at home, Windows at work. I don't have to do a lot of true open source development and access linux servers for work, so Windows doesn't bother me so much. But if I had to do the kind of AWS sys admin stuff I did before, Windows would drive me up a wall. As far as the non-development parts of the operating systems are concerned, there are some pros and cons to each. Spotlight Search on OSX is its best feature by far. It's not just search, it's everything - calculator, unit converter, you name it. Very, very handy. Sorely missing on Windows. OSX also focuses scrollable panes under the cursor. It's surprising how useful this feature is until you have to go back to Windows where it forces you to click inside of a scrollable pain to actually scroll with the trackpad or mouse. But window management in Windows is better than the kludgy minimize/maximize behavior in OSX.
Windows/windows. When it's time for new hardware I can never justify the extra cost of a mac. Also, I like video games.
I develop on OSX mostly. I have a gaming PC running windows at home in my rack. Also in that rack is a machine running ubuntu 16.04 + ESXi that I use to boot up VMs. It the moment, I've got one VM with ubuntu, and another with arch running. I use the ubuntu VM to run docker with some containers for my web server, home media server, and some usenet stuff. I prefer OSX for dev, personally. Windows for gaming, and you can't beat linux for services.
Vim has tabs and buffers much like tmux. Neovim adds a terminal emulator built in which means you can use its splits in a very similar way to tmux splits. So, I switched from vim to neovim and ditched tmux. When I SSH in somewhere I can install neovim and them I have everything I need. When I can't it's more of a pain but so far I've been able to everywhere except my University.
I'm not employed but I use a MacBook for laptop and a Windows desktop. I used to dual boot on my desktop but after I got my MacBook in 2015 I never went back to Ubuntu. Can't stand all the mysterious errors I get. 
IÔ∏è just made the same switch! 
Use whatever you like! Honestly, your JavaScript development will be the least of your worries. You can do that equally well on any of the popular OSes. There may be other things in unrelated areas that will steer you toward other OSes: is there something you need to do that works best in Windows, macOS, or Linux? Then use that OS. JS development will be fine in any of them.
Learn another language paradigm if you haven't. Maybe Elm or Purescript. It will seriously challenge your thinking which is why most people don't do it, but it will make you a stronger programmer in a way packing away JS trivia wont.
OSX at work, OSX at home for almost everything, Windows for gaming.
Previous job I used Linux and Linux at home, current job I use a Mac and I bought myself a Mac for home. I still keep the formerly Linux computer as a Windows computer for gaming. 
To be fair, it is somewhat trickier to get various technologies up and running on a Windows system as it doesn't have a posix terminal *by default*, and the package manager, choco, is an optional add-on. 
Linux everywhere only. I forgot how to use anything else.
I use Gentoo, but I usually dev on a Ubuntu headless vps, because that's what my prod servers ran. Work gave me a MacBook pro but I only ever used it for video chat for meetings. I work from home so my work machine and home machine are the same thing. I'll dev on any Unix system, but I prefer Linux, specifically Gentoo and Ubuntu/Debian. I hate windows and would never take a job requiring me to dev on windows. Linux is seriously amazing, it's come such a long way.
They make me use Windows at work, and I like to play Windows games at home, so I just run Linux VMs on both for coding.
vsCode for sure
I paid for Sublime Text long ago, but I tried VS Code about a month ago because I wanted to see what coding ligatures looked like (and ligatures aren't supported by Sublime). But VS Code was impressive enough that I'm giving it a bit of a trial run. The jury's still out, but if I switch to VS Code for good, that'll be pretty much the worst reason ever to switch.
Define statusTimeout outside of the click event handler. Check if statusTimeout is defined before clearing it and then setting it.
Build stuff, build more stuff, keep building stuff. Try new approaches to things as you keep building stuff, revisit older stuff and refector in new approaches that you like. [Codewars](http://codewars.com/) is a very cool site that gives you little challenges to solve; they're ranked in a way that there's exercises for any and every skill level once you've gotten the basics down.
I wrote a function call thresholder recently. This seems like a good use-case for it. Check out this Gist https://gist.github.com/gaganjakhotiya/d171eb35c9ff2985f335f5adc7a6303b
Linux/Linux. I own a Windows machine too which I use for Java stuffs only.
It is better to just use one of the immutable libraries. As its behavior is more thought out from an application standpoint. Both `seal` and `freeze` are: * Shallow immutable * Traditionally caused performance hit ([post few years ago](https://news.ycombinator.com/item?id=4415981) [still a concern to Node developers few month ago](https://github.com/nodejs/node/issues/14789)). Tho I think it is as performant as an object dictionary now, at least in V8 * Does not remove the mutating API * It causes runtime errors when those APIs are called Most of the above problem is solved by Immutable.js or Seamless-Immutable in their own way. 
Atom, VSCode, Sublime
I have setup sourcemaps, but Chrome's breakpoints are not working well with them. Like I put a breakpoint on a line and if I am lucky it will stop execution somewhere around that line +-5 lines. If I am unlucky it won't ever get stopped, it's very unreliable. Putting a "debugger;" somewhere works 100% of time.
What are you goals? Those should dictate your learning. Do you want to write open source? Are you trying to climb a company career ladder? Are you just doing it for fun? **Why are you learning JS?** &gt; I've completed several tutorials and completed several of my own personal projects but I feel like my JS has reached its limit and is now stagnating. It seems like you are doing it for fun? If so, find some contract work (I'm a full time freelancer). Do small gigs. Writing production code made me aware of my weaknesses. That was my first few projects: *Start project --&gt; design one way --&gt; halfway through, realize why that was a terrible idea --&gt; research, learn --&gt; rewrite codebase*
Could you elaborate on the Java part? 
I guess it's just vim vs emacs all over again. 
As long as you follow best practices, cross-platform compatibility should never be an issue. Write more code and less bash. Using `npm scripts` alongside platform agnostic packages like `copy`or rimraf and using `path` as much as possible, you can get the job done these days, ez pz. Hell, your `npm run build` could just run `node build.js` which handles all of it. No matter what OS you're on, your package is started with `npm start`
Visual Studio Code - the one &amp; only open source project that Microsoft should be proud of, as far as I know. üòú
Unfortunately, Vim is greatly inferior than Visual Studio when it comes to C#. With VsVim you can keep most of your bindings though. 
Windows for gaming, Ubuntu for my server and macos for anythig else. 
Funny. Ask what IDE you prefer, downvote if you don't like the answer!
I used to want osx but apple realeses trash recently like latest phone os update. Not gonna trust this company anymore. Staying with linux for both work and home
Windows 7 at work and windows 10 at home. Never tried Linux and MacOs 
It shouldn't take too long to add all these sorts of things, but then you might not want all of these things in him. I mean, it would be nice to get a simple installer that pulls in things like autocomplete: https://valloric.github.io/YouCompleteMe/
**You are just starting up &amp; trying to learn JavaScript as a beginner. Here are some Beginner JavaScript books:** *1 JavaScript Programmer‚Äôs Reference (by Alexei White) *2 Beginning JavaScript and CSS Development with jQuery (by Richard York) *3 JavaScript &amp; DHTML Cookbook, 2nd edition (by Danny Goodman) *4 JavaScript: The Definitive Guide, 4th Edition (by David Flanagan) *5 JavaScript Goodies (by Joe Burns &amp; Andree Growney)
The article says choose vscode because people love vscode. That's a weird argument. 99% of the feature list is covered by both atom and sublime. 
Thanks!!
 var div = document.querySelector('div'); div.onclick = function(event) { var target = event.target; if (target.timeout) { clearTimeout(target.timeout); } target.timeout = window.setTimeout(function() { console.log('tadaaaa'); }, 0); };
macOS at work with Windows in a VM. macOS for my own code at home. Windows for play.
Linux/Windows. When I can play my games, use Adobe suite and record music with Ableton on Linux, I'll switch for good.
You were talking about cors, not token and auth, stop bullshitting.
I use eslint typescript parser and it's really good to!
The way he talk's about a "new development machine" is so cringeworthy ^^ Anyhow, i use Atom and i love. It crashes sometimes but that's very rare for me.
It's an editor not an IDE.
Neither is Atom, VSC, vim or Emacs and people don't seem to say "it's not an IDE".
windows but all my code runs in linux vagrant vms.
Windows at work, Arch Linux + a little macOS at home. When it comes to web development, Windows can fuck itself with a rake -- the amount of problems I have that are specific to that shitty piece of shit dumpster fire of an environment completely baffles me. There are few things more enraging, for example, than when my computer tells me that I need permission from me to delete a folder. Fuck. Windows.
I'm currently using Komodo but I think it's time to switch. It's just too slow. 
Are you talking front end or back end? Because with anything server side, you actually do need to account for the boneheaded and fucktarded decisions that were made in Windows, like using the escape character as the path separator, or how if you run child_process.spawn on a Node binary, you need to have the .CMD extension on it or it will fail, even if it's in your path. I really, *really* wish that developers would stop using Windows so we didn't even have to support that bullshit, and make Microsoft actually fix their shit if they want the devs back.
ubuntu at work, windows/osx at home. Don't care, doesn't matter.
Not a JavaScript developer at my full time job, but I use Windows 10 at work and Debian/OSX at home. If I'm choosing, I'll use Debian or Ubuntu every time. 
Vscode and Atom are just text editors with plugin, no? It may seems I'm trolling, but I always used Intellij until here and Vscode replaced notepad++ (I over underuse Vscode I know) So can someone sell me those? :)
I always find the anti-Windows cult pretty funny. I use Windows most of the time and it‚Äôs fine, I can be just as productive as anybody on a Mac/Linux and use all of the same tools.
osx and Archlinux.
While you can use `const`, and many argue you should, I would personally stick to `let` there. I feel array object itself is less important than the contents, therefore `let` signifies that the contents are subject to change.
&gt; I just can't get onboard with using anything Microsoft created when there's a free alternative Do you mean *Opensource* alternative, because VSCode is free.
osx osx
Here's a quick example: https://jsfiddle.net/px6epdjf Hope it helps.
Ubuntu
On the contrary, I thought jetbrains's subscription model is really nice, you get 1 year of updates, but have a lifetime license for the version you bought. That's way more interesting than Adobe's subscription model for public schools, starting freelancers, students, etc. My friend even got a 25% discount when upgrading from his student (totally free) license to a paid one.
If you dont mind OSX so much, why run Windows at home? Is work just all Macs?
Thanks. Maybe its just because I'm on my phone but typing x into the input doesnt do anything 
Open up your console and see what it returns when you press down on x. 
Fired up my laptop and it was because I was on my phone. Is it possible to do it without an input box? That's kinda what I was hoping for, but i've never dabbed in js before and didn't know what was possible.
you went into a lot of details
Replace "input" with "html", then click on the sandbox form and hit x.
GEDIT
Mint KDE + macOS / Win10 on a VM.
Thanks! 
You're right, I'll talk to our ops team and we'll go to an SFTP solution instead :)
Make a weapon to surpass Metal Gear coded with JavaScript.
You just need 2 apps to access the same firebase. All data mutations on Firebase are pushed to every client that subscribe to it
Thanks for your answer, right now the Cashier app for example has it's own internal state which is tracking some things, I'm guessing I have to move All state to firebase for this to work correctly, right?
At first, you're not binding function, you're calling function in the moment of bind. // wrong $('#tabs).on('{one-of-the-events}',resizeText()) // resizeText is called when this line executed. // right $('#tabs).on('{one-of-the-events}', resizeText); // no parenthness, so you're using the function as an argument At second, I have never used "foundation tabs", but if it's a plugin to jQuery or something similar, the event should be fired on the same element, whcih is used to initialize the tabs. Also, you can look for examples, usually it's available in the docs or on the plugin's website, or just try to google it.
OSX because of native photoshop, but would prefer linux (actually virtual box with PS works pretty well if you have the ram for it) windows is for gaming.
Yes, you‚Äôd need to move the shared state there. 
Windows everywhere and Ubuntu subsystem on Windows for linuxy things
Webstorm, VSCode
Because today's JavaScript is "new". With all those changes and additions, fighting with DOM optimization etc. everything gets "created" from the ground like it's 1990. Now Flux and Redux are cool and "the web developers using it are the best because they invented unidirectional data flow and everybody else is struggling with design patterns". But still they do not notice that other part of the world moved on because that's not the way you do it. It's probably one of the best ways of doing it right now in web development and I do not take anything from anybody but WinApi patterns are very old. People start noticing DOM is not good for writing *applications*, WebAssembly is also coming and that's even not related to WebAssembly but I guess more people will see you do not have use DOM at all in some apps.
The turbulent nature of Javascript is caused by a sheer gigantic community it has. Since you can't really use any other language in the browser, it forces huge crowds of developers from different backgrounds into writing JS and as they come they create tools that fit their needs. JS has a huge landscape because it does a lot these days. IMHO these most turbulent times are over. I've been doing web apps with React + Babel/Typescript for 2 and half years now. Maybe apart from migrating from eslint to prettier for formatting I have had the same tools/workflows for this whole time. I don't think we'll see much innovation in how to write javascript web apps in the next 5 years. The most people who need better workflow/tooling are writing other languages such as Reason. 
Javascript was invented to add some basic stuff for web pages. Currently, it's used to write huge applications, both browser and server side, even desktop and mobile applications. Obviously, it requires lot of new features and APIs, and since code become more complex, it requires new ways to handle and manage it. That's why the language itself is evolving. And since it's very popular and have large community, lot of new tools/modules/plugins/etc appears, some of them may become more popular than older things.
Visual Studio 2017. I enjoy waiting 10 seconds for it to figure out what I'm doing, and being unproductive in general. /s VSCode is my preference, though. It's faster than VS with TyoeScript, and everything generally just works... 
IntelliJ - Love the features but mainly because I use other languages too but WebStorm was what I started with. It was game changing.
debian/debian, and sometimes i run windows on vm(vmware) (if i need windows software)
Mac OSX at home, Ubuntu at work.
/u/from-nibly linked a plugin for typescript. If you want a similar plugin for JS, it's here: https://marketplace.visualstudio.com/items?itemName=capaj.vscode-exports-autocomplete /shamelessplug
Well I guess if people want to re-create anything as an alternative to DOM it will take years more to get it into the new "best practice".
This website crashes on mobile. I can't read the article at all.
Ubuntu @ work Double boot Windows (Gaming) and Linux Mint (Working @ home) 
Ubuntu / Ubuntu. Was given a windows 10 at work. Asked if it's ok for me to use Linux, got the ok. I think I did not boot on windows for a year or so... (Node, react native, browser stuff and php mainly)
What's the benefit of coding under Linux in comparison to Windows?
It is an area of very rapid development and change, and as technology evolves best practice evolves with it. If look away fromt he bleeding edge a little though, things are steadier. You don't have to start using NewTechThing Phase 2 Reimagine 5 Version 0.32 just because it has been released. Last year's tools and best practise are probably still at least good practise so no need to retool all your active projects unless you expect to gain something from the change. Also the Javascript world is *wide* as well as deep. For client-side and hybrid code (server-side too to a lesser extent) it is filling several niches where best practise will differ. Some of the old C vs C++ vs Delphi vs Java vs .Net vs... type of discussions/arguements (themselves still going) are being seen *within* the Javascript world between the various frameworks and methodologies. Javascript is not one thing anymore, so some of the change and complexity you are seeing is due to changes i several areas that are not tightly coupled. You don't need to learn (or evenpay attention to) it all, at least not in great depth.
Osx at work, mostly windows at home ( out of convenience since that's also my gaming rig). Honestly I'd kinda prefer to use a linux env in both spaces, though, but haven't primarily out of laziness.
Cool!
Works fine on mine. Article is literally copy-paste of many other same articles. Nothing new
Lets be honest, Windows still beats Mac at gaming. And who doesn't need some flaming in DotA2 to calm down?
Why all the hate, this is a useful article, never mind the clickbaity title. I am sure a lot of devs weren't aware of one or two. For example I knew them al but had never heard of debug and monitor
sublime
Flip if-else is another useful one
I didn't mean to start a platform war here, but I'm happy with Starcraft II haha. But seriously, if we're talking gaming, then sure... WIN will beat OSC any day. Personally, if they just ported all of Age of Empires of to OSX, I'd be a happy camper. Once I finish my workstation build on my Mac Pro, I'll be dual booting with the intentions just to run Solidworks, but I may sneak some AoE in there for nostalgia (AoE II and Duke Nuken were the first PC games I played on a non-green green)... especially with the announcement of AoE IV. I was just legit curious why the switch in OS based on location. 
I've only ever used sublime text. I love it, but I want to try of the IDEs listed in this thread, but I am not sure of which one to try first. Any suggestions?
Personally, apart from gaming, only reason why I still use windows, is because Linux customization takes forever. Last time I was spending hour a day for that. Way too many options and stuff.
Configuring your work for the eventual target system makes a lot of sense. You want any platform differences to come up early and not late in a project.
Hm how do you mean?
``` window.addEventListener('beforeinstallprompt', =&gt; {}) ``` Ref: https://developers.google.com/web/fundamentals/app-install-banners/
Adding to this, in Foundation, _usually_ you can identify your tabs because they are marked with a _class_ `.tabs` So, you could probably do... $('.tabs').on('deeplink.zf.tabs', resizeText); (Probably. Can't be sure without seeing the code)
Thank you very much :)
It's kind of crazy how quickly VSC took over the market.
When I right click a folder and hover `New`I get a list of file types to choose from. I'd like to modify that list, adding some and removing others.
I didn‚Äôt say anything about using that amateur hour sftp ‚Äúsolution‚Äù. Just that you have my condolences for using a system that I find painful in its drawbacks to have to use. I also use Azure on my current project and I hate it.
You might be able to use the target property to understand which tab the event was fired on. const resizeText = event =&gt; { console.log(event.target) }
Maybe writing javascript, ya... I do work with Kubernetes... The Windows docker environment is just woefully immature compared to Linux.
Yeah Docker on Windows is a bit rubbish, I run it in a Ubuntu VM on VirtualBox.
(Dota runs on Linux native, just like all Valve games)
Containers, bro.
I'm a console gamer personally, but a designer/developer by trade so I've been in the Apple Ecosystem since like 1999 or something like that (I currently own like 11 Apple products). I do have one WIN tower that's an eMachines with abysmal stats I use to solely run a vinyl cutter to make decals. There is Mac software, but even I'll admit that it's astronomically priced, so I have just kept the eMachine. I have considered making a post on /r/BuildPC to post a challange to see how best to upgrade the poor tower and make a little game out of it. The Mac software I'd need isn't even remotely affordable and theoretically I could always just reinstally the Windows version once my Mac Pro is done and dual-bootable. The specs would be *plenty* high then haha ____ You talk about customization and tweaks and I can say that I have a lot going on with all my Apple computers. I know there is a culture of "set it and forget it," but I still tweak all mine as much as possible to get the best experience *for me.*
I've previously used a UTM tag on the link in the web app manifest. It doesn't give an exact number of course, but you can filter for it in your analytics and get some idea of whether people are using it.
I can't stop loving Dracula, personally. :)
Have you seen for example Google Chrome, Windows Explorer, Outlook, Office, Adobe Reader, Photoshop and tons of other native apps (those are just examples)? Guess what... they already have decades of experience and practices... that's what I was pointing at. We are happy from flux and redux etc. and it's indeed amazing in current state of JavaScript (I went from backend dev to frontend because of that) but flux is just "immutable" JavaScript's version of for example WndProc http://www.winprog.org/tutorial/window_click.html See those switches? It just looks ugly because it's C, performance oriented (mutable) and at least 20 years old already. Today nobody writes native apps like that.
Generate random number: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/random Use the function that convert a character code number, into a character: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/fromCharCode Combine each: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Expressions_and_Operators#String_operators Get a specific character: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Character_access Treat it as a number: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseInt Calculate it: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Arithmetic_Operators Then show it: https://developer.mozilla.org/en-US/docs/Web/API/Window/alert
&gt; Today nobody writes native apps like that. Agree, no one uses C and C++ anymore nowadays for just to make "daily app" or SaaS. I prefer Python myself, but JavaScript is okay as well. For me programming in JS is easier and flexible. It is not as conservative as older programming language. However, things that pissed me off is how convoluted to just get properly started programming with JavaScript nowadays. You need NPM/Yarn (I don't get it why we need two package managers), then pick your front-end framework, CSS to SCSS, and same with JavaScript transpiler. Now everything needs to be "compiled" for JavaScript and CSS and HTML rendered from server, virtual DOM, etc. And front-end needs to be ran from server because "best practices and you should not do that" clause. I just want to program something in just a HTML file and think about the best practice later.
&gt; Today nobody writes native apps like that. Agree, no one uses C and C++ anymore nowadays for just to make "daily app" or SaaS. I prefer Python myself, but JavaScript is okay as well. For me programming in JS is easier and flexible. It is not as conservative as older programming language. However, things that pissed me off is how convoluted to just get properly started programming with JavaScript nowadays. You need NPM/Yarn (I don't get it why we need two package managers), then pick your front-end framework, CSS to SCSS, and same with JavaScript transpiler. Now everything needs to be "compiled" for JavaScript and CSS and HTML rendered from server, virtual DOM, etc. And front-end needs to be ran from server because "best practices and you should not do that" clause. I just want to program something in just a HTML file and think about the best practice later.
Why is docker a dependency?
Thank you for this! I might not have been clear enough - by random number I mean the user will be prompted and enter a random string of numbers and it is this string of numbers I need to add up and then show the user this string? For example the user is prompted "Enter a random number:" where they might then enter '1234' and I need the alert to return the sum of 1+2+3+4
Don't do OOP
I find react much simpler if you use some github starter kit. Most projects ~~need~~ use react, redux, react-redux, react-router, redux-thunk and it is difficult to setup sometimes.
Sounds great *in theory*, but the main problem is that there are *so many* things you have to do to make Windows compatible node-packages when 99% of the time, your operating system *in production* will be a *nix machine. Yes, if you write completely cross-platform code following [all these best practices](https://shapeshed.com/writing-cross-platform-node/) then it works, but the problem is that if you slip up and add just *one* windows-only convention, then you end up with a "works in development, fails in production" problem. At that point, you might as well run Vagrant or Docker on your windows machine with port forwarding, or just go full-blown with VirtualBox or something like that. 
So you can kick it off without setting any environment up?
Eslint (or TSLint but I just use typescript parser for ESlint if/when using TS), GitLens, EditorConfig, Document This, EcmaScript Quotes, Path Intellisense, either Indenticator or indent-rainbow (or if you're like me, both :) ), and REST Client if you can't be bothered to leave the editor to do some requests. All of these regardless of whether you're using TS, ES6, vanilla JS and most are useful if you aren't using JavaScript at all.
Happy to help with your homework, but not to do it for you :-) If you harvest a number from user input (I'm guessing you're using a prompt) it will be received as a string.(For bonus points on your assignment verify that only numerical data was entered.) The split() method will convert the string to an array. Iterate over the array adding the value of each digit to a variable to be returned. Return that variable to the user. 
It looks like its running node.js in the docker container. Doesn‚Äôt seem like it should require it as we all probably have npm and node installed anyway. Even if we haven‚Äôt, it seems like node doesn‚Äôt have too many weird dependencies, and it is easy to install AFAIK.
I switched to VS.Code. For what I do nowadays (which is mostly JavaScript in browser or Node) it just works better and even if there are less extensions they are more applicable to what I do. I used to use Sublime as a text editor for local config files etc. in the interim (as it's lightning fast and handles sudo/gksu very gracefully) but even that has slowly been moving to either vim or VSCode depending on the context.
So there is no setting up at all.
I don't want people to handle the whole NodeJS side. I want the project to separate it's own tech from user concerns.
Fair enough. I figured there was a reason for using Docker - and it does makes sense to abstract the nodejs part away from the user.
For almost all files I give the choice to the user between YAML/JSON (except override files maybe, cause I haven't implemented that properly yet) just so it abstracts furthermore the JS part of MorphlingJS 
Whatever was causing the issue seems to have been fixed, it is working fine for me now
...except for setting up docker :)
Programming is only the first step. Learn how the client and server interact with each other and their gotchas. For example, learn about CORS and what it means for an application. Learn how to implement security for the front end, something that's quite challenging, in my opinion. Get a high level understanding of how JavaScript frameworks actually work, that will help you in the future for debugging problems that might come up.
Have you tried to install docker recently? It's the easiest thing.
Make sure you've sat through the 13-14hrs of Douglas Crowford videos to gain an appreciation for the language most people learning the language seem to lack and then run into issues as they fight the language. It isnt about good parts, bad parts, its about "dont code like this period in any language". Plugin to the Medium.com JS community, https://medium.com/@_ericelliott drops tons of great info. Find something in another language you know, rewrite it in JS using nodejs.
Links?
Huge +1 here. I think learning concepts from languages that embody or enforce them that you can bring into your JS practice, you'll benefit in a major way. The fact that functional programming is suddenly a big deal in JS didn't come from the abyss. If you want to *really* get ahead of the curve there, go learn a language where those functional concepts were fostered. For me, that's Haskell :) Just started through the Haskell Book (haskellbook.com), and so far it's great. Learning a ton!
Ya, it's wierd... Java actually runs better on Linux, especially with libaio. There's a lot of overlap between Java and Linux communities, certainly more than between Windows and Java...
If I install it with npm/yarn why do I need Docker to install node? 
You need Node to even install it. Docker isn't needed and is a waste of resources. 
For those of us on windows 7 it's still a pita.
Is the name a DotA reference?
Except that I am still required, atop of setting up Docker, to do `npm install something something` not to mention that your intructions are far from clear whether I need to do it in the container or on my own system so... If you want frictionless distribution, and assuming there are no binary Node modules you depend on, my warmest suggestion would be using GitHub releases and [zeit/pkg](https://github.com/zeit/pkg)
Most folks stopped using Bower two to three years ago. Many never used it at all. npm has existed all this time, and bower still works the same as it did day one. What's the issue again?
"chunk of money"...? Typically devs are not paid for speaking engagements, let alone any number that would yield a chunk. Could you elaborate further on that?
I love Spacemacs. Unfortunately I can't for the life of me figure out how to get indentation working as smoothly as it does in vscode for react components. I've tried the React layer, rjsx... none of it works as well as VScode. Once there's a layer or bulletproof config, I'd love to switch back.
windows w/ linux vms At work and at home.
Prompt user for input: https://developer.mozilla.org/en-US/docs/Web/API/Window/prompt Parse the input for valid number: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseInt Add the number into a variable which is initially zero. Then repeat that process: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/while Use the prompt's return value for the loop condition. 
Couldn't you use babel? Using it ever since it was stage-0, and still serving it to old browsers via babel. 
Yep!
Sorry about that.
Probably, but I don't -know- ES2016+ yet, so I was kinda hoping for something I could get up and running now that I can refactor once I'm up to speed.
nice.
Everything ever deprecated between years. And what is the problem with JavaScript has been existed for nearly 20 years yet the best practices change every months or so?
You need npm to install it but I plan on releasing it on a public docker repo so it's without Node for the install.
I want it to be a container rather than a process.
You just need to do an `npm install morphlingjs -g`. Everything beyond that is taken care of.
As far as I know Bower was still popular in 2016, many people was still using it. Suddenly it is not the best practice anymore. Bower is deprecated if you don't know it :(.
&gt; Also, in Jest I would like to write: import puppeteer from "puppeteer"; &gt; To do so we need Babel for Jest. Man, just use `require`. It's not worth transpiling your code just so you can use an `import` statement.
Think OP is implying that opportunities arose because of talking at conferences and getting more visibility.
When you return a value or promise from a promise, the next then will resolve with the returned value. doThing1().then(doThing2).then(doThing3) Will call doThing3 with doThing2's return value
You don't have to know it. If async/await is all you ever use then it will transform it. Later on you could decide to tap into other features and it will as well. Promise salad and iife's make javascript verbose and complex, doesn't have to be that way.
You can use the feature that jQuery.ajax() returns a Promise-like object and chain them with `.then()`; jQuery.ajax({ url: '/path/to/url/1' }).then((data, status) =&gt; { console.log('first request:', status); return jQuery.ajax({ url: '/path/to/url/2' }); }).then((data, status) =&gt; { console.log('second request:', status); return jQuery.ajax({ url: '/path/to/url/3' }); }).then((data, status) =&gt; { console.log('third request:', status); }); 
Yup that book is great. I hope you stick with it!
When you refer to $ working in console do you mean that you have window.$ defined? Usually that's not the case with webpack because the imported modules are not added to the global scope. They should be visible only within your scripts. Maybe something else is adding jQuery to the global scope.
morphling is literally my favorite hero! I remember just smashing people with full `agi` then morphing to `strength` and `tping` home. Man I should play video games again.
What's... It's just a demo of the browser speech synth?
Honestly, it doesn't really matter as long as I control the environment. I used to be 100% Linux for Dev work but now I'm usually just on windows. Powershell is cool and the bash support is really nice. Plus I can use winsshfs to mount my servers into windows explorer, which used to be the main reason I was on Linux.
Honestly man it just sounds like you're making a big deal out of it. I have no problem maintaining cross-platform code on all 8 of my company's products as the only front-end dev on staff.
My mobile experience on the element website is not good. Why doesn't the menu disappear?
The amount of times I have to write `if (os.platform() === 'win32') { // Some bullshit to account for the idiot, special snowflake behaviour of Windows }` Is too damn high
Thank you for your effort. It's very nice library. What I am missing there is example templates for these layouts: http://element-cn.eleme.io/#/en-US/guide/nav 
GitBash actually isn't that bad...that said, I would be using linux for my dev environment if: a) I didnt need the adobe suite b) I didnt occasionally game on my home PC
I'm talking both? I work on isomorphic React applications and typescript APIs all day. You don't have to worry about path separators when using the path library, and using child_process.spawn is generally an anti-pattern in the first place. I'm not defending Microsoft here, tbh I hate developing on Windows and I only do it because it's easier than dual booting on my gaming PC at home. Just trying to help people write better code.
How does it compare to using background-size contain?
You really don't understand basic JavaScript until you understand closures. I'd recommend reading [Javascript Allonge](https://leanpub.com/javascriptallongesix/read) in order to learn closures and other aspects of functional programming.
Cross-posting response from HN as well: Thanks for the feedback. The "for babies" part came out of a conversation with coworkers a while back, where people were complaining that Redux is too complicated. Ie. To add a property to the store, you also have to define an Action and a type for that Action, then add the type to your Actions sum or enum type, then define a reducer, and finally use the property in your React component. I thought this could be simplified quite a bit for the 90% use case where an action maps directly to a property on the store. Babydux is certainly a Redux. From the Readme: &gt; Babydux is like Redux, but reducers are already baked-in. Babydux automatically creates an action and a reducer for each key on your state, so you don't have to write tedious boilerplate. Babydux still emits Actions under the hood (which you can listen on to produce effects), but gives you an incredibly simple get/set API that covers most use cases. There is an undocumented top-level emitter (`onAll`), but I'm not sure there is a use case for it where targeted emitters wouldn't be a better fit. There is certainly middleware support (see https://github.com/bcherny/babydux#effects). Unlike Redux, middleware fires *after* the state has been updated, not before. The effect is to fold the concepts of middleware and subscriptions into one. I want to keep the API as simple as possible, but I could see a future where before-write middleware could be a good fit for simulating transactions and preventing writing bad state to the global store.
I disagree. I would only use `let` if the array itself will be replaced by a different array at some point in time. If I will always use the same array (so that its reference is constant), I would use `const`.