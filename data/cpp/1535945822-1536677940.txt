Yea it avoids filling the cache with data you don’t intend to read back any time soon
A few have asked me if my company name, [Ebenezer Enterprises](http://webEbenezer.net), is related to Ebenezer Scrooge. It's not. It's from 1 Samuel 7:12. &gt;Then Samuel took a stone and set it up between Mizpah and Shen. He named it Ebenezer, saying, "Thus far the L-RD has helped us."
You always need it. You can cast any `shared_ptr&lt;T&gt;` to `shared_ptr&lt;void&gt;` and the compiler needs to know how to delete the memory. It's also used for the aliasing constructor. `shared_ptr` has a lot of magic in it.
He's falling off the radar. I'm not happy about it, but understand. 
https://twitter.com/NoBugsHare/status/1022129373292445696
It doesn’t have to be a micro service. For all I care, invoke out-of-process COM objects if you want. Heck, in most situations the user would just start their server ahead of the main application, or the application would do it trivially. If it doesn’t start, then something went seriously wrong, and you’d get the identical error at plugin intialization time. It’s ultimately the same code, just running in-process vs. out-of-process, as the RPC/IPC mechanism should be transparent in anything but most trivial examples. I really wish Maya plugins were not in-process — in fact, a studio that does some work for us at work uses their own Maya plugins and they are all just a stub shuffling events and rendered widget bitmaps between the application process and a local node server process that actually hosts the plugin written in nothing the Maya people had in mind for it. Works awesome, too. I got to try it out, and their in-house tooling people told me all about it. I know how to be productive in Qt and even I wouldn’t want to mess with that with Maya — I’d do something out-of-process, where a plugin failure doesn’t bring down the application, and doesn’t tie me to the exact C++ abi and runtime Maya was compiled with. That’s just an example of an application that was designed for user extensibility with plugins, where the plugins as-is are a hindrance and a real pain in the ass. None of this is needed at all if your application doesn’t let anyone else develop plugins: just link everything in and be done, who cares for plugins then? They are overhead, nothing more. You seem to have tied a lot of concepts with very particular and perhaps niche embodiments: I talked about some out-of-process server, and you immediately turned it into a micro service. That is just about as limiting as the straitjacket of an in-process plugin. There is no reason it has to be any particular type of a server at all — and even then, we’re talking of end-user or third-party extensibility. If your application isn’t sufficiently heterogenous itself, you’ll never need plugins. Even applications that ship partitioned into plugins never need them. Let’s say Qt Creator, because I’m familiar with it. The plugin partitioning there doesn’t do anything useful. You can tear it all out and everything works exactly the same. It’s a mental scaffolding that serves no purpose once the application leaves the developer’s desk.
With the right kind of coaching and determination you can accomplish anything. - Reese Witherspoon
Windows works with either / or \ Hell, you can even mix them 
There are some pitfalls though, here's a good read about what can happen if you bypass the cache on a multicore system (XBox 360): https://randomascii.wordpress.com/2018/01/07/finding-a-cpu-design-bug-in-the-xbox-360/
C++'s biggest problem is that it's difficult to justify using it for anything.
no :( well... not really, but if you are willing to use boost, you can use boost::shared_ptr and define BOOST_SP_DISABLE_THREADS - even if it was in std, it wouldn't matter a lot since you wouldn't be able to convert between a lock-free and a non-lock-free shared ptr
Isn't it more like "the lack of a C++ abstract machine"? all the things he mentions are 'undefined behavior/not specified' in C++; i.e. there is no guarantee of alignment, read/write sequencing, synchronization.
D&amp;E's quote has always been one of my favourites: _Within C++, there is a much smaller and cleaner language struggling to get out_. I think most features that were added to C++ in the last 10 years have made the language itself larger and more complicated, but the programs smaller and simpler. As for weakly typed languages, my personal and professional experience tells my that they are unsuitable for large-scale projects. When I change a function's signature, I want compilation to fail until I fixed all the callers. I don't want to have to rely on tests for this. Tests are always incomplete and out of date. YMMV.
You can't compare JavaScript to C++. Als i prefer pretty much any language over JavaScript.
Aligning data structures to cache line sizes is critical for any of these operations to have reasonable behavior in my opinion. That’s a great read though. In hindsight, I suppose it’d be an obvious consequence of branch prediction but still cool to consider
Agreed on the weak typing thing. Yes it makes simple scripts easier to write but it does not scale (in my opinion, I'm sure there are people who can pull it off). Not a fan of Javascript myself, though with Typescript and some ES6 it's doable and sometimes you just have no alternative. At the same time, I don't think WASM will be that much of an improvement, yeah, eventually you'll be able to write DOM manipulating apps with C++ and whatnot but seriously, would it make your life better? As it's not native code it's doubtful there would be even a marginal performance benefit.
&gt; Not a fan of Javascript myself, though with Typescript and some ES6 it's doable and sometimes you just have no alternative. About two years ago, I wrote a smallish web application in JavaScript and got fed up with it. I then started looking into more strongly typed alternatives and ended up rewriting the whole thing in TypeScript, but I found its type system was full of holes. It helped, but not enough. The further down I went into the transpiling rabbit hole, the more I started questioning _why_ a scripting language was necessary at all. That's when I found Emscripten and cheerp, and that's when I realized that JavaScript is just like assembly. Find a better language that compiles into it instead of using it directly. The only time I would use JavaScript would be for something like modding a game. I've worked a lot with V8 in the past few years and have developed a pretty good modding engine. Mods are usually small and self-contained and JavaScript has low barrier of entry for casual modders.
&gt;'m sure there are people who can pull it off. Doesn't really help for large projects involving dozens of engineers.
We're already at a point of no return when it comes to feature bloat.
Well I wouldn't intend to have any kind of implicit conversion between a lock-free and non-lock-free pointer.
Hmm, now I get it.. I really don't know much of COM process, maybe I'm limited and talking shit over there. I'll study that and keep this talk in mind. All I know that linking anything could be a problem, indeed, I was thinking to make something that start the plugin in another thread, try it initialization somewhat that if anything goes wrong just kill that thread. But again, I haven't study it for real, so I couldn't tell if this would work, maybe it get too overhead, idk. Anw, thanks for the advice. If something comes up, I'll be back here to discuss. Meanwhile, I think I need to study these alternatives first. 
Why linked list?
LLVM intermediate already has the pointer bitwidth baked onto it, for example. You can't (easily) change it back.
No, it doesn't, and isn't that just the whole problem in a nutshell? You *can* write good JS but the whole environment doesn't enforce any good practices. And if you're not adamant about coding standards with your team then the whole thing becomes Swiss cheese.
Care to elaborate?
indeed :p
even preprocessed C++ source isn't portable
I think all these languages trying to allow for more functional approaches to programming are bound to become overly complicated. All I want is functions as first class citizens and a strong type system. Scala fits that perfectly.
But static already has sooooo many meanings. :(
public and private at the namespace, global scope, would be great
Usually with small blocks, you store a pointer to the next free small block in each small block. So that forms a linked list. Haswell and later CPUs can speculatively fetch two levels of indirection, so don't pull more than two blocks at a time with a single linked list, and no more than one at a time on any other CPU.
Sure. It's difficult to make a business case for starting a new project with it. Other languages will let you get up and running far more quickly, will likely have more feature-rich/stable runtimes/eco-system and won't be as expensive to maintain. Gaming may be an exception here, but how much of &lt;algorithm&gt; do gamer devs actually use?
Thanks for the reply. I guess it was badly worded question, what I meant to say that if you want to use, say, C++ or python using emscripten, do you get access to the web APIs or in case of node the ecosystem?
I generally like that C++ is not managed/owned by 1 company and instead requires cooperation to publish new ISO standards.
Could be `private using namespace` instead
Generally in this design approach all blocks have known size and known use purpose. So no need for different sizes. And generally all blocks are at least a pointer in size, so a simple linked list works.
And has it succeeded?
Yes, that's the first thing that come to my mind: do modules change the situation with namespace pollution?
I don’t know about gaming but for high-performance and/or memory critical applications C++ still reigns supreme. All these benchmarks showing that Java/… can perform on par with C++? Yeah, those die on the first day out in the real world. 
Since you would only be writing cpp files, you can `using` and `using namespace` all you want without affecting the users. This is one of the best things about modules IMO.
References don't have sizes.
Even better then (although in many contexts they are just implemented as pointers).
You keep saying 'You' like they did it personally (they said 'we'). Let he who has perfectly and continuously audited code throw the first stone.
In C you also don't pay for what you don't use and it is definitely much less bloated.
Then why is all the software you run made with C++?
It is still incompatible with other compilers and there are no grantee that Microsoft will keep the ABI compatibility and also the MSVC ABI is incompatible with other compilers like Mingw and even with older versions of MSVC, aka VC++. if you compile a code with MSVC, let's say a class Foo as the shared library Foo.dll and try to link or dynamic load this class from client code called Bar compiled with GCC/Mingw it will not link or crash the program at runtime, if the Bar.dll is dynamically loaded. It is more likely to happen if you use STL containers or non C types at the class method signatures, although STL can be used inside the class methods. That is why there are not many pre-compiled C++ shared libraries ready to download as there many C pre-compiled shared libraries ready to use. &amp;#x200B;
Have you ever seen a large scale project written in Perl? It was my awaken nightmare for years
Not true. See, for example, C++'s sort vs C's qsort. 
Do you consider that with the new value-based `throw` (when it will be added), you will remove `throw` from your banned list of features?
Do you think it could land in C++20, or is it more reasonable to expect to wait until c++23?
It derives from the container of an incomplete type. That is UB.
*If* it were added, if in the Sg14 hard deterministic form only, and not the mainstream token form, then yes but only for the value semantics throw only. I appreciate that will be confusing committee speak. Watch out for a paper by me in the San Diego mailing on the different ways of implementing P0709.
C++ 23, maybe 26. C++ 20 is basically done already, apart from minor features or ones almost complete.
You could, in one header, create a namespace alias: namespace sd = SuperDuperLibrary; That way you don't clutter your code but don't bring all symbols into your own namespace.
I've been hacking at this for a few days now, and at this point, I'd really like to get some feedback on the general direction of things. It's far from feature complete, but there's enough in there to start playing with it and determine if there is value in there.
To say "the mighty fell" is to imply a tragic end to one considered heroic. There's no condescension in lamenting the loss of a hero, but that's not what this is. It's like posting an article about former President George W Bush making paintings and commenting with "how the mighty have fallen."
I would like it more if the committee disregarded backwards compatibility issues and strived for the best language possible. Obviously I completely understand why they don't do this, but personally I would prefer it.
&gt; GLSL basically cannot be reimplemented without relying on undefined behavior. I'm curious there: why can't you implement something like GLSL vectors without undefined behavior? As far as I know swizzling is implementable without breaking rules.
Imho it moves far too slowly, with far too little direction and gets far too little usability improvements (random anyone? Terse lambda syntax? But I think those are all inherent consequences of c++ being an ISO standard and not being developed by a payer language design team.
You don't even need to get into swizzling to run into UB issues. Just supporting `vec.x` and `vec[i]` at the same time can't be done :(. glm does it like this: float&amp; operator[](length[i]) { return (&amp;x)[i]; } which... yeah...
Not only is it trivially possible, it is even efficient: https://godbolt.org/z/eeEVXS 
Well I feel foolish, that's 100% correct.
The engine that I am working on does this in the math library. Just curious, for what reason is this considered incorrect? Is it an issue with the index possibly being out of range? How else would it result in undefined behaviour?
I have not looked at the compiler output, but assuming the switch statement is optimized to a jump table, wouldn’t direct array access be more efficient?
just to make it clear: the \`boost\` library helps at the loading level, and maybe helping with the plugin's lifetime (registering callback when it's deleted, etc). The main thing here is to make easier to retrieve any object created by a plugin without knowing that is coming from a plugin. It means that you'll need to know about plugins only at the registration of , what I called, "Adapters", which problably will fit at the startup of your application. After that, all the plugins will be registered into this "Adapter" and can be retrieved as your custom interface. Again, \`boost\` does not do it. \`Qt\` does not do it. \`Dlopen\` does not do it. And it's okay these frameworks not have this feature, I'm not judging, just clarifying. &amp;#x200B; &amp;#x200B;
Hey, we both learned something new here. At least I wasn't quite sure how efficient this was going to be...
I don't quite understand how the potential optimizations unlocked by templates are in any way a rebuttal to the fact that in C you don't pay for what you don't use.
Just need a compiler with C++17 support.
I would argue that Rust honors this principle better than C++, actually. And I am looking forward to C++ catching up ;) --- Herb Sutter raised two issues in his "Value Exception" proposal: 1. Compiling with exceptions (default), bloats binaries with side-tables for unwinding... even if the binary itself does not use throw/catch any exception. 2. Although the former is unlikely, since `new` throws `std::bad_alloc`, which (1) is unnecessary on many platforms due to overcommit and (2) impedes optimizations. On the other hand, Rust features: - value exceptions, under the form of `Result`, or in the words of Alexandrescu `Expected`. - abortion on OOM. Which results in lighter binaries, and deterministic error-propagation. --- C++ inherits C's layout rules, where each data-member *must* be laid out after the previous one. By default, this often results in needless padding in-between data-members due to alignment. Contrast to Rust's more flexible behavior, where the compiler is free to reorder fields by default, and has an opt-out when order really matters. --- `dynamic_cast` requires that for any type with a `virtual` method, a description of the type layout be embedded into the library. Cue `-fno-rtti`. --- `virtual` methods lead to a virtual pointer in the class. Even if you have a `std::vector&lt;T&gt;`, the virtual pointer is embedded inside each and every instance of `T`, and there's naught you can do to pull it out. --- `final` is opt-in, meaning that unless stated, and unless the compiler figures out that the class is actually final, you get dynamic dispatch when calling a virtual method from within a sibling method.
Why did you stay in that project for years if it was a nightmare to you?
Can you post the specific text of the errors? VS2017 supports range-based for loops, which have been in the language single C++11. Are you sure it's not simply a warning about copying objects? If so, you can declare `bot` in the for-statement like this to avoid unnecessary copying: `for (Bot &amp; bot : bots)` — note the use of a reference. If the body of the loop won't mutate `bot`, then make it const too: `for (const Bot &amp; bot : bots)`.
Also I'll be speaking to the Dublin C++ users group on this topic on the 17th. Obviously only useful to those in Ireland!
What, now they want me to buy colored ribbons for my teletypewriter?! /s
So your argument boils down to Rust having better defaults than C++ (exceptions, data member layout, RTTI, vtable which can be replaced...). I don't see how this makes Rust honor the principle any better. The user can still choose exactly what to use.
I've seen that with DLLs. You register some object as an OS resource and then exit the program in some way that the de-registration code doesn't get run (like, crash,) and the DLL will stay open until you reboot. I don't know if you can do the same thing with a .exe file. I've only ever had it happen with DLLs. Maybe if you register it as a system service and then don't re-register it. That's the sort of thing I'd be looking for.
this is low level plumbing, nothing more, nothing less what's needed is something like COM+ with interface loading, interface discovery, safe shutdown with resources deallocation etc
Grab [*Process Explorer*](https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer) from Sysinternals (now owned by MS). No install necessary. Run it elevated to administrator. Press Ctrl-F to open the search dialog. Enter the name of your .EXE and click *Search*. It will show you every process that has a handle to that .EXE. Might be some Visual Studio debugger helper process. Select the offending process and press *Delete* to kill it.
tbh honest i only skimmed your project. but it seems to me you're passing an object with virtual inheritance through a dll boundary. vtables are not standardized afaik, so this can break whenever you use different compilers for exe and dll. stick with C when passing anything around, and watch your alignments! 
Lovely
&gt;With for (const Bot &amp; bot : bots) this is the error &gt; &gt;C2662 'std::vector&lt;bool,std::allocator&lt;\_Ty&gt;&gt; Bot::getStatus(void)': cannot convert 'this' pointer from 'const Bot' to 'Bot &amp;' BasicGraphics c:\\users\\butte\\source\\repos\\basicgraphics\\basicgraphics\\rts.cpp 22 I did say "If the body of the loop won't mutate `bot`, ...". If function `getStatus` is not `const`, the compiler will assume it mutates the object on which it is called, so it cannot be called on a \`const. The linker error is saying that you have no definition of a matching `getStatus` function. Make sure the signature of the definition matches the declaration in the class.
This has nothing to do with lambdas - it's about `std::function`: https://godbolt.org/z/LTSOVQ
Your post has been automatically filtered because it appears to be spam (it was a link to imgur.com). If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9co57r/lldb_now_also_supports_tabcompletion_for_cc/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Ah. Intersting, hadn't thought of that. Still curious as to why GCC produces that much more assembly.
Correct me if I'm wrong but the standard doesn't define how optimizations are made. That's why compilers take different paths to optimize the code. 
I wont' claim to have dug keeping into what's going on, but I'd hazard this has much more to do with the how the respective compilers treat `std::function` rather than lambdas. Use a template parameter to capture the lambda type so you can avoid `std::function` entirely, and they optimize the same. https://godbolt.org/z/iniwpZ
Nothing, empty
An interface with both a full blown IDE and the lldb prompt is the ultimate option. I don't use Xcode as an IDE but I often open it up just to use it as a debugger GUI. Some things are only doable or easier via `(lldb) some command` while others are easier via clicking. You're most productive with an interface that provides both. The fact that Visual Studio doesn't offer a CLI completely stops me from ever trying to use it. 
It now also supports tab completing expressions: https://i.imgur.com/5WIeEdx.png And there are some even cooler features in the pipeline :)
If by "within the list" you mean the list of running processes shown by Process Explorer, that's not necessary for it to be undeletable. If some *other* process has a handle open to the EXE, you need to use Ctrl-F to search for the name of the EXE — this does not search the names of the running processes — it searches the names of the objects held open by the running processes, which is different.
The best thing about gdb (and presumably lldb although I don't follow it closely) is it's builtin python interpreter which allows you ta hack up just about anything you want. I've seen people do crazy things like loading code and patching VMTs on the fly or scripting runs to allow reverse debugging of overflown&amp;corrupted stacks which are otherwise notoriously hard to debug.
It may be related to heap elision or just constant propagations. You use type erasure with `std::function` but the compiler can clearly see that the polymorphism is not needed in this case. GCC has yet to learn how to do that particular optimization.
That's exactly my question, nothing is showing using my EXE, I've downloaded multiple programs without success.
That sounds fascinating. Do you happen to have any links to demonstrations of these kinds of things?
GDB has a built-in Python interpreter, you can do pretty much anything you can think of to inspect or patch the program in memory. I'd really recommend watching some videos from LiveOverflow on Youtube!
(gdb) py == (lldb) script 
Yes, we are fully aware of this. We assume that the `sharedlibpp` library, any software that uses it and any plugin are compiled with compatible ABI (including Release/Debug configuration) and link the same CRT, to be able to safely exchange C++ objects. Indeed the proper documentation of this was probably lost in making the project standalone from its previous location, thanks for the observation! 
Sure, the thing that first showed me that gdb is more than just a console debugger you can use over ssh was this video few years ago: [CppCon 2015: Greg Law " Give me 15 minutes &amp; I'll change your view of GDB"](https://www.youtube.com/watch?v=PorfLSr3DDI) It doesn't go into too much detail, but covers most of python thingy and shows simple demo of corrupted stack debugging.
gdb and lldb have builtin python interpreters and fully functional python APIs. e.g. all the internal lldb classes are usable from Python. Not to mention that sometimes it's just easier to write the thing you want to do rather than find and click it. `rbreak SBDebugger` runs a regex over all symbols loaded from the binary and shared libraries for the term `SBDebugger` and sets a breakpoint on it. While this is doable from a GUI you have to click a dozen buttons to get to it. In general, it's faster to do an action when you act on it directly where you are aware of it. And by that I mean if you want to break at some point in the code right in front of your face it is easier to click on the gutter to set a breakpoint rather than looking at the name of the file and then looking at the line and typing `breakpoint set --file thisfile.cpp --line 284`. But if you are aware that you want to break on every occurrence of a symbol that might be a part of a thousand different lines of code then `breakpoint set --func-regex '^SB.*Create'` is obviously a million times more efficient. 
How does this compare with hpx?
k, good that you knew already :) been digging deep into the topic for a while now and there's a lot of subtleties i didn't expect at first. 
A sign that the age of C++ is coming to an end maybe? &amp;#x200B; Frankly his explanation makes perfect sense. The last thing you want to do as a teacher is give an answer you don't really know if it is accurate. In this context an author is a bit like a teacher.
Viewing arbitrary memory cast into an arbitrary type. In LLDB you can type e *(Type*)(address_expression) Super useful when following linked-lists or any other type-erased item. 
The right place for that question is /r/cpp_questions
Yes
These are some great examples for when the CLI is indeed superior, thank you very much!
I think you might even be able to do that in the VS Watch window as well, you can indeed write expressions there. But anyway, in my comment, VS was just an example, you can substitute it in my post with CLion, and there you can then probably open a gdb or lldb prompt, in the GUI, while debugging.
The C++17 standard library: https://en.cppreference.com/w/cpp/filesystem
This looks awesome, how come I never used that before :-O But I just tried it on a solution of mine and it doesn't work as described in that SO post. I'm always getting `identifier "something" is undefined` where "something" is `(std::)string` or a variable that I'm trying to define. Only thing that seems to work is math... (`5+6` and the like). Maybe it's because I'm using a cmake-generated `.sln` file...
It’s rather domain specific to iOS/macOS development, but there is a lot of general purpose lldb knowledge to be learned from Derek Selander’s lldb book. I highly suggest it even if you aren’t interested in iOS development. 
Not a very static keyword, is it.
File Locks? What is that? The most I use with files is "fopen" and "fclose" when closing
[FYI](http://open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0589r0.pdf)
well, I'm not really surprised, /u/andrewsutton seems to be one of the few select people who wants to make the language saner.^^^metaclassesplease
And if you can't use C++17, Boost has a very similar filesystem library too.
I agree. I use an IDE that embeds an LLDB REPR.
&gt; C++ inherits C's layout rules, where each data-member must be laid out after the previous one. By default, this often results in needless padding in-between data-members due to alignment. Only in default layout types, but I don't know if any compiler makes actually use of the freedom to optimize the layout in the other cases.
Can you provide the link that says you need c++17? I don't see why or should but VS 2017 supports c++17 anyway (you have to select it though)
Because not everyone follows or cares about biblical quotes, and in common parlance it is condescending. Calling somebody Nimrod is going to be taken as condescending regardless of who Nimrod was.
Does it support moving files?
&gt; In C++, you can emplace types into the various data structures quite easily. In Rust, even if all you want to do is put a struct in the back of a vector, you still have to construct it, and copy it in. Nitpicking, but I don't think thats true. For one, in Rust, primarily you *move* things. Moving is fast and cheap, and destructive. There shouldnt be any copying going on there. Copying in general should be and is avoided in Rust, compared to C++s copy everything by default and complicated, non destructive, move.(Move assignment/constructors complicate things.) We can even check the [source](https://doc.rust-lang.org/src/alloc/vec.rs.html#1056-1067) to see `Vec::push(T)` boils down to `ptr::write(end, T)`, which just writes `T` to location `end` in memory.(Also by moving the value)(Where `end` is the end of `Vec`s internal buffer. As noted by the lack of any calls to `clone`, there should never be any copies happening.
Thank you for the recommendation, I suppose you mean [this one](https://dl.acm.org/citation.cfm?id=3203567)?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; how can Rust guarantee ABI compatibility? Easy. It doesnt. Just like C++ doesnt. And, just like C++, you can opt in to a specific layout/ABI guarantee. For types, you would use the `#[repr(C)]` attribute. For functions you would use `extern "C"` Other than that, the Rust ABI is currently undefined.
Thx, will check that out if i cant use c++17
Wow scarry
Never actually used QT but I thought it was an API? Can API can include functions for handling files?
C++ standard may not say a word on ABI compatability [citation needed] but well spread compilers provide some guarantees on ABI such as GCC using Itanium ABI. They even made new libstdc++ ABI compatible with C++0x implementation. If Rust behaves as you represented then compilation of seperate units is made completely impossible. It will require all of the clients of shared libraries need to be recompiled every time. 
The attendance at C++ standards committee meetings is up somewhere between 50% and 100% compared to 5 years ago. Cppcon attendance is growing like mad too (and this year is only the 5th meeting). If the age of C++ is coming to an end, it's going to be a crowded end. Individuals come and go. But from where I sit, it looks like the C++ foot is heavy on the accelerator.
Another important domain for C/C++ is embedded systems, especially of the bare metal variety where you have no operating system. These systems often can't afford a runtime and it frequently doesn't make sense to do so from a usability standpoint. Performance on these systems is important not only for usability, but also energy consumption. There is no ecosystem that supports embedded like C's, with C++ being a growing runner-up. In short, a business case for a product in this domain that doesn't include C++ nowadays isn't likely to be entertained.
You are I guess using move vs copy in the semantic language sense. Under the hood, a move is still a copy, obviously. You can't get away from copying less than the size of the object itself. For common generic types like vector and string, the actual size of the object is much less than the semantic size so moving is cheap and much faster than copying. But this isn't always true, e.g. stack arrays and simple pod structs with many fields. The latter show up rarely in generic or library code, but a ton in business logic. For a struct with twenty integer or double fields, copies and moves are both the same operation and they're both slow (at least, for people who really need to be fast).
lldb supports the "gui" command, which provides a minimal text-based tui client (think ncurses interface). Aside from Xcode which provides both gui and command line debuger interfacing, there is also Qt Creator, which uses lldb under the hood, and thus provides the GUI part. The lldb command line support is also there, but is less polished than the one in Xcode.
I use a GUI debugger whenever I can.. but honestly learning gdb has been a lifesaver over my whole career. Gdb has features I haven’t seen anywhere else: break when a thread reads from a variable, break when a thread writes to a variable (both work with addresses too)... etc
&gt; For a struct with twenty integer or double fields, copies and moves are both the same operation and they're both slow What would emplace do differently here to avoid having to actually put all that data in the buffer though? Presumably it has to come from somewhere, and it has to get into the buffer somehow.
In your examples there's no reason not to move the using statements inside the body of the functions themselves. You're not referencing std in the signature. But also, I'd suggest bringing in specific names instead of the whole namespace. `using std::begin;` is a bit more clear on the impact.
Off the top of my head, command line supports: * smart step into (I think Visual Stuido also started to provide it recently). If you have `auto a = foo(bar(), baz())`, and you want to step into `foo()`, instead of doing step in, step out, step in, step out, step in, you can just execute `"sif foo"` (sif is a short alias for the smart step into functionality) * complex expression evaluation which can call methods `e myObj.call1().call2()[2].call3()` or `e myObj().myCustomString().toStdString()` and see the output of the string as std::string (assuming your custom string type provides toStdString()). * Stepping into your own custom expression! Set a breakpoint anywhere you are interested in the code, let's say `b myMethod`, and then call another method on a local object, and debug that method! `e --debug -- myObj.foo()` will create JIT code for a temporary function that calls foo(), and step into foo(). So your stack trace will be MyClass::myMethod() -&gt; JIT code -&gt; MyClass2::foo(). * `image list` and `image lookup` are really useful for finding loaded libraries / symbols using regular expressions. * `gui` (minimal ncurses-like gui) to debug an application over ssh for example.
I don't understand what you mean? No matter where your struct comes from, it will always first be populated, and then copied in Rust. In C++ you can create it in place. struct Foo { Foo(const MyDataSource&amp; d); double m_d1; ... // lots more fields }; MyDataSource d; std::vector&lt;Foo&gt; v; while (d.update()) v.emplace_back(d); The rust equivalent of this code would first create a Foo instance from d and then memcpy it into the correct place in the vector. The C++ equivalent creates the Foo at the correct place immediately. Note that of course emplace is also critical for supporting immovable types. You say "moving is fast and cheap", that's often true, but the cost of \*enabling\* move for a type may not be cheap, which goes back to my mutex example. For example, the following C++ code is really zero overhead in some sense: std::deque&lt;std::mutex&gt; d; d.emplace_back(); I don't think you can write the equivalent in Rust. This example I think is cool for highlighting the progress made in modern C++.
You can write expressions in the VS watch window, casting integer to pointer also works just fine and won't segfault if it points to an invalid address.
I think he's trying to say that `std::vector&lt;T&gt;::emplace_back` will call the `T` constructor directly in the appropriate location, forwarding it's parameters. However, in Rust you have to construct the object outside of the vector then move the generated value into the vector, which requires a shallow copy. He's got a point in theory, but practically speaking couldn't Rust optimize that out?
&gt; will call the T constructor directly in the appropriate location, forwarding it's parameters. For the given example of "a large struct of integer variables", whats the difference between moving the struct in and copying/moving all those integers inplace? 
&gt; and beware forward declarations. I think avoiding forward declarations where possible is good practice in c++. There are a number of subtle traps just waiting to cause you problems. Hopefully modules will help with the compilation speed issues that cause people to use forward declarations. 
Gotchya, I'm not familiar enough with Rust's compilation strategy to know how deep it's strict semantics allow optimizations like those to occur. 
&gt; Do you guys like what C++ is becoming today Yes, very much. It's been much more interesting ever since C++11 came out. &gt; Do you prefer a more free or open language like Javascript "Free and open"? You mean all this time I've been using an expensive and closed language, like a chump? Seriously, what does "free and open" even *mean* in this context?? &gt; with less rules ? C++ has a lot of rules. Most of them revolve around things you don't need to use. You don't *need* to use templates, or move semantics, or smart pointers (or raw pointers!), or lambdas, or constexpr, or the STL, or operator overloading, or whatever. You can restrict yourself to less - at the expense of performance, or code bloat/duplication, or readability, or writing your own containers/algorithms, etc. It's a big toolbox, and you can choose not to use (or learn) all the available tools. It's a big toolbox because it's been so successful for so long, and virtually nothing gets removed from it because people want old code to still be usable. The only problem with having so many tools, is that it's daunting for beginners. They want to learn it all in a few days, but then see this big language with a big standard library, and they get intimidated. And even beyond that, C++ isn't the right language for *every* task. Sometimes another language just makes more sense. Even Java might make sense for some thing. (I have no idea what that thing would be, but I'm sure there is one)
Well, as you can see, that optimization is not performed even in C++: [https://gcc.godbolt.org/z/eWgyPu](https://gcc.godbolt.org/z/eWgyPu). Note the call to Foo's move constructor when calling push\_back but not emplace\_back. It's possible that Rust might be better than C++ but I'm not sure; my guess will be that it will be similar (i.e. it will not optimize out the memcpy) but i could be wrong.
I mean, you aren't going to see much overhead, if any, from wrapping a member function call in a lambda, and passing around the lambda as a template object. If you aren't capturing the object itself, it's even easier as said lambda can be decomposed directly into a regular function pointer.
You can `static` them as well, as it will force their symbols to be local to the translation unit that is including it. I don't like that, though.
We should have `movable_const`.
As /u/GNULinuxProgrammer said, those aren't different semantics. `int *ptr` is a pointer to an integer. `int i` is an integer. Making either `const` makes *what it is* const - the former makes an immutable *pointer*, the latter makes an immutable *integer*. `const int * const ptr` makes an immutable pointer to an immutable object.
I'd just like to interject for a moment. What you're referring to as Linux, is in fact, GNU/Linux, or as I've recently taken to calling it, GNU plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning GNU system made useful by the GNU corelibs, shell utilities and vital system components comprising a full OS as defined by POSIX. Many computer users run a modified version of the GNU system every day, without realizing it. Through a peculiar turn of events, the version of GNU which is widely used today is often called "Linux", and many of its users are not aware that it is basically the GNU system, developed by the GNU Project. There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine's resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system: the whole system is basically GNU with Linux added, or GNU/Linux. All the so-called "Linux" distributions are really distributions of GNU/Linux. 
`inconstfix`.
&gt; Nowadays, compilers decides which function should be inline'ed. Compilers will still take `inline` into account in their heuristics. There are also some optimization modes which will *only* inline functions that are marked `inline`.
Thank you, Ameisen, for voting on __interjectionBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://botrank.pastimes.eu/). *** ^(Even if I don't reply to your comment, I'm still listening for votes. Check the webpage to see if your vote registered!)
From what I heard, only clang does it yet. But it doesn't change the fact it is not the main `inline` purpose.
Of course not. That's what `__attribute__((alwaysinline))`/`__forceinline`is for ;)
I had a colleague back at NetApp who would extract network buffers from core dumps using python scripts in gdb and generate pkt files for debugging NFS traffic using wire shark.
Add to this the ability to snapshot the memory and cpu state in a core file at any time, and do a rollback. Like VM snapshots, except on the real thing, so if you crash but didn’t mean to, you can resume. 
Thank you very much for the explainer and the links, much appreciated! Obviously this is something I need a closer look at, as it's something I've had wrong thoughts about previously, so thanks again for this reply.
Thinking better, it doesn't look related to file locks anyway. But something preventing to delete a file without holding any handle probably could be caused by holding a pointer to the kernel file object. And since the file is executable one, that changes every time (that is compiled)... Do you have any kind of AV installed in that computer? 
I suggest we just post those questions here or on stackoverflow, or Scott could always ask committee members (ie just ask Richard Smith) for definitive answers. Alternatively, I think Scott should pass on all his "Effective C++", ah, "empire", to me, and I will gladly answer these questions, and also update the books for future C++ versions. :-)
Visual Studio also just got that recently, based on OS support so the snapshots are done via copy-on-write so you don't have to write out a whole core file.
You're missing what I'm talking about. I *know* that the pointer itself is a thing. I'm talking about its referent. And `const int &amp; x` does *not* say that the thing to which `x` refers doesn't change, even absent `const_cast`s or `mutable`. Suppose I have the following code, in a single translation unit with no LTO (those aren't fundamental limitations and such): double pure(double x) __attribute__((const)); extern void do_something(); extern void observe(int x); void foo (int const &amp; x) { observe(my_sqrt(x)); do_something(); observe(my_sqrt(x)); } and compare to the non-reference case: double my_sqrt(double x) __attribute__((const)); extern void do_something(); extern void observe(int x); void foo (int const x) { observe(my_sqrt(x)); do_something(); observe(my_sqrt(x)); } The question is: is the compiler allowed to assume that the two reads of `x` will return the same value? In the second case, the compiler is allowed to assume that. I'm using the `__attribute__((const))` here to make it simpler to show the allowed optimization, but this too isn't required. (`std::sqrt` seems to not be marked with that for some reason...) The compiler can know that `x` is const, so `do_something()` can't change `x`, and because of the attribute it knows that `my_sqrt` is pure, so `my_sqrt(x)` will return the same thing for both calls. So the resulting code only calls `my_sqrt` once. (That's true for both GCC and Clang with any optimization on, including `-Og` which seems questionable to me but whatever.) _Z3fooi: cvtsi2sd xmm0, edi push rbx call _Z7my_sqrtd // *************** cvttsd2si ebx, xmm0 mov edi, ebx call _Z7observei call _Z12do_somethingv mov edi, ebx pop rbx jmp _Z7observei https://godbolt.org/z/q8e0op What about the first case, with the reference? In that case, the compiler is *not* allowed to make that assumption. Toss in that `&amp;` and [neither GCC nor Clang can make that optimization any more](https://godbolt.org/z/6wCBws), and must include both calls to `my_sqrt`: _Z3fooRKi: push rbx cvtsi2sd xmm0, DWORD PTR [rdi] mov rbx, rdi call _Z7my_sqrtd // **************** cvttsd2si edi, xmm0 call _Z7observei call _Z12do_somethingv cvtsi2sd xmm0, DWORD PTR [rbx] call _Z7my_sqrtd // ***************** pop rbx cvttsd2si edi, xmm0 jmp _Z7observei As an example of code that would be broken if the compiler made that optimization with `const int &amp; x`, here is supporting code: int a_global; double my_sqrt(double x) { return std::sqrt(x); } void do_something() { a_global = 100; } void observe(int x) { std::cout &lt;&lt; x &lt;&lt; '\n'; int main() { foo(a_global); } In that case, the program should: * Call `foo`; the function enters with `x` equal to 0 * `foo` calls `observe(my_sqrt(0))` which prints 0 * `foo` calls `do_something`, which sets `a_global` to 100 * `foo` calls `my_sqrt(x)`. Because `x`'s referent is `a_global`, that means `my_sqrt(100)`, which is then `observe`d -- the program prints 10 Again, `int const &amp; x` *does not say* that `x` can't change. It says it can't change *via that access path*.
I didn't say that it can't change. Immutability depends upon context. If a variable is `const`, then it is by definition immutable within that scope - that scope cannot alter it. That doesn't mean that it cannot be altered from outside the scope. Nobody has claimed that `const` means that the variable cannot ever change, so I don't understand what you're arguing against. It just means that within that scope, the variable is immutable - that scope cannot change it. Whether it's a pointer or a value doesn't really matter - a `const int *`'s pointed-to value cannot be changed by the scope, but the pointer itself can. If it's a pure value type, it only changes in the sense that according to the spec, the variable cannot have been aliased outside of the scope without it being explicit in some fashion. That doesn't have anything to do with `const`, though. (I didn't do GNU/Linux, only GNULinux. Clearly that's unacceptable.)
I've just reinstalled cheerp and had a quick look at it, seems like it's still generating pretty nice code. Here's `a.cpp`: #include &lt;cheerp/clientlib.h&gt; void webMain() { client::console.log("Hello, world!"); client::document.get_body()-&gt;set_textContent("test"); } Build with this: c:\cheerp\bin\clang++ -target cheerp -O1 -cheerp-pretty-code -cheerp-no-lto a.cpp -o a.js And here's the relevant part of `a.js`: function __Z7webMainv(){ var LretConstructor=null,LretConstructor3=null; LretConstructor="Hello, world!"; console.log(LretConstructor); LretConstructor=document.body; LretConstructor3="test"; LretConstructor.textContent=LretConstructor3; } __Z7webMainv(); This is really useful while you're developing because your browser's developer tools become your debugger, so you want to keep the code clean if you can. I think cheerp supports sourcemaps, but I couldn't make them work last year. Things may have changed. Since the optimizer is part of LLVM (between clang and cheerp, it works on the bytecode, it's mostly language-agnostic), you can try `-O2` to see the good stuff.
Oh man, thank you very much for the reply! This is absolutely what I'm looking for, as I want it easy as possible to "ignore" the transpiler and focus on the generated code instead. I'll definitely focus on this. Thanks again!
&gt;I know that Clang sometimes performs optimizations that are not standard compliant Huh? No it doesn't, that would be madness. Also, the standard's take on optimization is quite literally common sense, i.e. only optimizations are allowed that don't change the observable behavior of the program. 
&gt; I have no idea what that thing would be, but I'm sure there is one Getting paid in KLOC's maybe.
Did they at least `use strict;`? I haven't worked with a large-scale Perl project. I did however get tasked with maintaining a small-ish (maybe a few thousands LOC) tool written in Perl. And I don't mind Perl, I used it extensively back in the 90's. But the thing is, they didn't `use strict;`, and took advantage of the liberties granted by it. It was a mess...
Don't quote me on this, but I think it might only support .NET languages. Maybe other high-level languages (java-script, etc) too? I know the watch window in VS allows you to execute functions in it with C#, but not with C++.
I'm sure Bazel is great and you had great experience using it, but.... &gt; JDK 8. You must install version 8 of the JDK. Versions other than 8 are not supported. No thanks.
Even just on the "human encyclopedia" front, there are more people nowadays qualified to go in depth about the standard. Only ten or so years ago, you mostly just hear about Bjarne (of course), Scott, Herb and Andrei. Now there are too many to name off the top of my head.
Oh my wow... and it's really good, too. Thanks!
For the new code yes, not for the whole codebase, but even with strict it is not that better 
Great article, I'm always interested in handling legacy libraries better. Similar effect can be achieved by something like: &amp;#x200B; \#define function\_to\_poison function\_to\_poison\_hidden \#include &lt;legacy\_lib.h&gt; \#undef function\_to\_poison
Yea, so long as your index is constant. I wouldn't call it too efficient with dynamic indices: https://godbolt.org/z/Rg4T8U.
AFAIK Python was added into GDB later on, so not everything is possible (tried some logging on syscall executions, possible to setup, just difficult). On the other hand, LLDB in in its core a library and has full API exported to python. Most of its testsuite is actually using the Python API. So for scripting, I would say LLDB is even easier and much more powerful then GDB.
MSVC supports somewhat similar #pragma deprecated. It's a warning by default, but can be promoted to an error with another pragma or /we.
Ask on /r/cpp_questions
Could be. I personally never heard it used in a condescending context, that's the problem with _common parlance_ it's culturally dependant.
Something similar implemented using attribute may be candidate for standardization.
&gt; That’s unfortunate because with the windows API such a technique would be so much valuable. Maybe there are other compiler-specific techniques to get a similar behavior that I do not know #define poison_func REALLY_ANYTHING_THAT_BREAKS_THE_BUILD Since C++14 we have a very good alternative: `[[deprecated]]`. Will build (unless you force stop on warnings), but outputs a warning every time it is used.
You need to check your inputs before doing conversion or look for a throw from your conversion function. If you check for a throw, you can't just wrap the variable declaration in a try and have rest of your function outside it -- that would create a scope and your variables would cease to exist as soon as they leave the try block. So either wrap the whole thing in a try and pop your message box up in the catch or declare your variables to some fixed value and assign them with the conversion in a try/catch block. Usually the flow on the former is a bit more natural, but personally I try to keep my try/catch blocks as short as possible. Check your API reference to see if the function you're using to convert the string to an int will throw if it receives non-numeric input. Your teacher might still want you to manually check the strings (by iterating over them and verifying each character is an allowed numeric character,) so you might want to check with them about it before you turn your program in.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9cswrf/how_to_create_an_error_message_box_if_there_is_no/e5dcl3c/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
MSVC has also supported Microsoft specific extensions such as #pragma deprecated, __pragma deprecate and __declspec deprecated in addition to [[deprecated]]. Option /WX allows you to treat warnings as errors, achieving the same end result.
Unfortunately, if people copy-paste and dont try to understand, that's when bad things happen and bad practices propagate everywhere :( Some comments: * The line: `target_include_directories(${PROJ}_LIB PUBLIC src/)` For the library to work with install targets you would have to use generator expressions to differentiate between the build interface and the install interface. Also the comment Include in PUBLIC... doesnt properly explain why it should be public, or justify it. Of course, for both this issues, you need to consider whether the purpose of your project is to just build the executables in it, or to generate libraries that can be integrated in other projects. * Would you do the following in C++? `#define MySuperGenericBaseClass MyClass` `class MySuperGenericBaseClass {};` I dont understand why it is so popular to do that in CMake. Be explicit with the project name, be explicit with the project and target in all the calls to the \`target\_xxx\` functions. It makes the code more readable and easier to follow. `target_link_libraries( simple-cpp-setup PRIVATE simple-cpp-setup_LIB)` is more explicit and readable than `target_link_libraries(${PROJ} PRIVATE ${PROJ}_LIB)` &amp;#x200B;
The problem is that it doesn't work with names that are too generic. Another alternative to the dance above would be to provide your own header, poison symbols and then use include_next to use the real one. That makes it easy to be opt-in. 
For `std::tuple a = b;`, if `b` is a `std::pair&lt;int, int&gt;`, then `a` will be a `std::tuple&lt;int, int&gt;`, i.e. different from both `tuple&lt;decay_t&lt;B&gt;&gt;` and `decay_t&lt;B&gt;`.
In `"foo.h"`: namespace foo { void evil_function(); } in `"foo_wrapper.h"` that I write: #include "foo.h" namespace foo { [[depricated("poisoned")]] void evil_function(); } you can depricate things in a single declaration. 
If you use namespaces (as you should) you could also delete a same-named function in your namespace instead of poisoning the identifier: namespace my { unique_foo create_unique_foo(); void create_foo() = delete; } - Can be used with all modern compilers. - Works in headers with just declarations. - Prevents accidental mistakes. - If you include the namespace somewhere else and try to use the banned function you will get an ambiguity error. - The original function can still be called by explicitly referring to the global namespace.
Use #poison all the time to figure out which header defines what and where, especially when porting code or digging through new large codebases. Good point about improving type safety with it.
Politics.
Ok, my point was C vs C++. I don't know enough of Rust to reply.
In the example of C's qsort vs C++'s std::sort, templates allow sorting to be faster than that in C, due to the fact that no call indirection is required when calling the comparison function. So C doesn't give you as many chances as C++ does to don't pay for what you don't use.
You can do that in kernel too with pykdump. I've done it with storage hbas to generate reports on crash dumps and sanity check the usual suspects. Dramatically improved my triage process and overall quality.
I'm staying with Catch 2.2
That's not a property of the language, actually. It's only a limitation of the implementation of `qsort` and the toolchain you are using to compile it. The biggest advantage of `std::sort` in terms of performance is not that it's template, it's that it's inline. Of course, template implies inline, however the reverse is not true, and a conforming implementation of `qsort` could perfectly be defined inline. Furthermore, even without `qsort` being defined inline, LTO could still kick-in. On the other hand, I have routinely implemented template interfaces on top of non-template code. The templated layer for type-safety, the non-templated core to avoid code bloat. That is to say, it would be perfectly feasible to implement `std::sort` on top of an improved version of `qsort` (you'd need to pass a function to swap elements, too). There's no inherent performance in templates; in fact, `std::sort` will generally perform *worse* than `qsort` in Debug mode because of all the template layers. It just so happens that compilers have much more aggressive inline threshold for templated code, and this may (or not) result in faster code... the "not" case happening when the amount of templated code is such that it trashes your i-cache without delivering much speed gain in exchange.
I've tried to capture the pertinent details of Rust in my answer, since Rust here is just used as an illustration of alternative semantics without veering into vaporware. If there are parts that are confusing without knowing Rust, please let me know and I'll try to improve them.
&gt; Only in default layout types I seem to remember that even within a `class`, there is an ordering guarantee between data-members at the same access level, and no guarantee across access levels. Since in many classes all members have the same access level (all `private` or `protected`), there's not much leeway for compilers.
&gt; If Rust behaves as you represented then compilation of separate units is made completely impossible. It will require all of the clients of shared libraries need to be recompiled every time. Rust only has ABI compatibility for a given version of the compiler. In fact, it *explicitly* incorporates a hash of the version and flags into all mangled symbols so as to avoid accidents. There is a strong emphasis, indeed, on compiling from source. `cargo` (the package manager/build tool) automatically fetches the sources of the dependencies and builds them up for the specific target/flags combination that you wish to build your code. I personally think it is an advantage: 1. It ensures that all dependencies are compiled with the same set of flags. I still remember accidentally pulling a dependency not specifying `-fno-strict-aliasing`, and the resulting issues were quite a puzzler. 2. In a programming language with generics, many changes will anyway require recompiling from source.
&gt; So your argument boils down to Rust having better defaults than C++ (exceptions, data member layout, RTTI, vtable which can be replaced...). In C++ it's not a default, it's the only Standard. `-fno-rtti`, `-fno-exception`, `-fno-strict-aliasing` are non-portable implementation specific extensions; they are not Standard. I am glad that Sutter finally acknowledged that we have an extensive *shadow world* in the C++ community who has, for at least the last 20 years, lived in a parallel world without RTTI or exceptions. I am hopeful that the Standard may be amended to *officially* support such usecases. On the other hand, this will not fix a number of issues that I presented here: - `std::bad_alloc` preventing 90% of the `std` functions/methods from being marked `noexcept`, with all the optimization possible that this entails, - virtual pointers being embedded in classes, even when unnecessary in context.
Isn't that a limitation of the implementation, not the language? A more aggressive inliner with a better LTO or an inline implementation of `qsort` would be able to inline the comparisons. There's nothing in the C standard itself preventing this, it's just a compiler weighing code size vs execution speed.
As someone who uses gtest and gmock for testing, why would I switch to Catch?
Have you read https://github.com/catchorg/Catch2/blob/master/docs/why-catch.md#top?
More time to think while waiting for it to compile?
&gt; Anyway, if your goal was to prove the grandparent post false, I feel like that's pretty easy to do simply on the basis of historical bloat, which is anyhow most of the difference in feature set size between C++ And Rust. I disagree with the idea that historical bloat inevitably leads to violating the YDPFWYDU principle; in fact your own point (2) about `emplace` illustrates how a new feature can help avoiding unnecessary overheads. C++ has made a number of *choices* during its design, which go against its stated principle. They were pragmatic choices to make, but they do violate the principle nonetheless. --- &gt; (3) Rust doesn't really support immovable types very well. Indeed! This is a perfect illustration of how a design choice may impact run-time performance. There have been proposals to fix this, for years, but until now the decision has been that the increase in complexity was not worth it. --- Now, this gets more complicated. I hesitated using Rust as an illustration of what could be done differently precisely because I feared it would turn into a feature-war; yet unsubstantiated claims that a different implementation was possible without actually backing them up felt like an empty argument. I'd like to note that whether Rust sometimes violates this principle, or not, does not in anyway change the fact that C++ does, which is the heart of the debate here. --- Now, veering slightly off-topic for this sub-reddit as we are going to dive deeper into Rust. Both your points (1) and (2) are technically true, but seem to miss two important points: - Backward compatibility: the issues I raised with C++ are baked into the language, and cannot be easily salvaged at this point as far as I can see. - Optimizability: while at the source code level, there is indeed (1) an unknown array size or (2) a redundant move, the fact of the matter is that simple inlining solves the issue, so that in practice it rarely matters. I won't talk much about optimizability, here, C++ developers are probably very familiar about expecting the compiler to peel away abstraction layers for them, and relying on inlining to get good performance out of template code. The topic of backward compatibility, however, is a tad more interesting to me. I am afraid that a number of the issues I raised about C++ are somewhat enshrined into the standard, and that it would take a small revolution to address them. I may be wrong, I was very surprised when the committee actually seemed in favor of transforming OOM situations into aborts after all. Examining your points under the lens of backward compatibility yields two different thing: - (3) is a direct result of wishing to keep backward compatibility; it could be made opt-out (`?Move`), but so much code would have to be altered to work with `?Move` types that it felt too big a change for too little benefit already at the time. - (1) and (2), however, are in no way constrained by backward compatibility. Work is actually ongoing on non-type parameters as we speak, so (1) should be solved within a couple months, and there have been a number of attempts at tackling (2) already and though they were unfruitful, they never raised any issue about backward compatibility. So, for me, the question is more one of *choice* than *state*. State evolves over time, whereas choices, deliberate or accidental, tend to constrain future endeavors. And I am very grateful to Sutter for kicking the anthill open on the topic of exceptions :)
Nope . If you read them you know it's build once and you're done
It's a header library...
That just looks like a list of features (of which none seem to be unachievable in gtest). Does anyone have experience with both and know why I would choose Catch over gtest? And is there a similar twin library for setting up mocks?
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9cxgwy/what_libraries_would_be_neededin_demand_what/e5dwbvz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
but it's a header only library written in the spirit of the \[stb\]([https://github.com/nothings/stb](https://github.com/nothings/stb)) libraries - meaning that a major part of the framework is conditionally compiled in only one translation unit - think of it as a header + a source file into one. Header-only doesn't imply "slow as %\^$# to compile"
Good old Microsoft providing ten APIs to do something and nine of them are probably depreciate. They even followed their own pattern while implementing a way to stop using old APIs. Ironic.
Are people lucky enough to be using cpp17 using optionals? I used to do some iOS stuff with Swift and fucking LOVED Swift optionals. But they are a much more integrated part of the language and using them in CPP feels much more clumsy. 
 set(PROJ simple-cpp-setup) # Set language project(${PROJ} CXX) This is considered at anti-pattern at this point. CMake is notoriously bad for trying to figure out the evolution of variables. If you don't absolutely require a variable then you can skip using one. add_library(${PROJ}_LIB CMake has the variables `CMAKE_SHARED_LIBRARY_{PREFIX,SUFFIX}` that automatically name your library targets properly. So the word `lib` would be redundant in the products here. I also think a nice thing to add to your example would be a `target_compile_features`. A lot of people still use `set(CMAKE_CXX_FLAGS "-std=c++17"` instead of `target_compile_features(targetname PUBLIC cxx_constexpr)`.
Indeed, sorry for being unclear - the point about it being a header only library is that it isn't "build once and you're done". It says absolutely nothing about how slow it is to compile. But, well, now that you mention it... g++ -std=c++11 -Wall -I../single_include -c 000-CatchMain.cpp 5.44s user 0.33s system 88% cpu 6.517 total :( Frankly I'm not even super-impressed at the speed of building one tiny little file even if you're planning on keeping its `main` in its own file. % cat 020-TestCase-2.cpp | wc -l 33 % time time g++ -std=c++11 -Wall -I../single_include -c 020-TestCase-2.cpp 0.53 real 0.44 user 0.07 sys time g++ -std=c++11 -Wall -I../single_include -c 020-TestCase-2.cpp 0.45s user 0.07s system 97% cpu 0.538 total This stuff really adds up. C++ build times are bad enough already - why make it worse?
Is that production ready?
No, not really
Have any more in depth explanations for the anti-pattern? I typically take an approach where one project maps to one shared lib and take advantage of [`PROJECT_NAME`](http://devdocs.io/cmake~3.12/variable/project_name) to name the library so I can use the same scaffold across my other library projects. I'm curious what the big disadvantages are.
You are right for the anti pattern with `set(PROJ simple-cpp-setup`. I've updated it :). For the generator expression while including directories, i want to keep this simple. And a generator expression can probably freak out a lot of people. Plus the goal of this is just to compile and executable and easily test it, so I don't think it's that necessary. Thanks for the feedback!
&gt; Rust only has ABI compatibility for a given version of the compiler. Assuming ABI is stable "only" for a specific version: This isn't nice. Modern Linux distributions trust GCC's ABI compatibility. So a new upgraded version of GCC can be used compiling new things that are linked to older standard C++ library versions. I don't assert that C++ has(or must have) a standard well defined ABI across all versions, all architectures or all compilers which is a terrible idea. But ABIs should have a maintainable window that makes software easier to maintain. On the proprietary side not having a stable ABI throws us into same DLL hell that Microsoft created with VC++. A proprietary software developer may still want to keep compilation times low while providing forward compatibility. On the Linux side we have pretty good ABI stability over years. Clang guys do quite a good job making their standard library binary compatible [1,2]. GCC changes ABIs now and then but most of the time you can run and compile new stuff with older stuff unless you change C++ standard [3,4]. There're corner cases like ABI affecting compiler options like you mentioned with `-fno-strict-aliasing` but you have to document those in any case. There will be people who want to use proprietary software and maintainers may not want to recompile things every so often. Those are the challenges C++ has faced, the views and solutions from C++ side will benefit for Rust too. [1] https://abi-laboratory.pro/index.php?view=timeline&amp;l=libcxx [2] https://abi-laboratory.pro/index.php?view=timeline&amp;l=libcxxabi [3] https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html [4] http://allanmcrae.com/2015/06/the-case-of-gcc-5-1-and-the-two-c-abis/
Thanks for the feedback! I knew that cmake prepend the `lib` suffix. It's just that CMake can't stand a target with the same name (the executable, and the library in this case). I added a workaround to that both of them don't have the same name in cmake, but they have the same name when building. I didn't knew about `target_compile_features` at all. I always used `target_compile_options` and add my flags. I'll look into it.
Any particular reason for not switching to 2.3/2.4?
If options supported by every single C++ compiler in existence are the "shadow world" for you just because they're not ISO standard, maybe you could point be to those Rust ISO defaults so we can do a fair comparison.
I would also do that in the context of big project. But for a tiny such as this one, they are the same to be honest. I do not know of any advantage/disadvantage on a big project though.
I think they were making a pun with the phrase [Catch 22](https://en.wikipedia.org/wiki/Catch-22_\(logic\)). Tho I could be totally wrong and it's just a great coincidence xD
Ah right. How did I miss that.
I'm still on the fence as well, depending on the project. One discriminator is that Catch supports BDD-style tests (Given, When, Then), as well a test sub-sections, neither of which requires test fixtures. For example, for each Then section, the code in the Given section is run but it isn't a named fixture. Sadly there is no twin library for mocking. I'd recommend Google Mock although I wish it supported automatic mock generation like [FakeIt](https://github.com/eranpeer/FakeIt) (which can't easily mock functions that take a non-copyable argument by reference).
The 3 best things about catch are: 1) Scope-based hierarchical SECTIONS. This alone is a killer feature and makes writing edge/error cases for a given flow extremely natural. You notice that some part of the flow hasn't been covered? Simply drop in another "sibling" SECTION somewhere in the hierarchy and now it's covered. No repition of complex setup logic. Once you get used to this you'll never want to go back to anything else. 2) It's so easy to set up. Most other frameworks in C++ take quite a lot of time and effort mconfiguring a new project before you're actually writing your first test. As a header only library, catch literally takes about 2-3 mins before you're thinking about your test, not how you're going to compile your dependency, and link it into your new test project. Do you have the right settings for 32bit/64bit? Release/debug? Other platforms? Etc... Reducing the friction and barrier to entry of writing tests means that people write more tests, and don't just dump them all into one big test project monolith "because it's already set up". 3) Once it's set up it's insanely simple and powerful. There are some more advanced features being added, but at the end of the day you need exactly 2 things to write catch unit tests - SECTIONs and REQUIRE. Behind those is quite a bit of magic, for example, if you get a failure the output tells you the assertion that failed but also tells you the values involved at runtime. You'll see REQUIRE(s.x == p.getDimensions().getWidth()) FAILED with 6 == 4. By providing you with these simple and powerful tools it just seems to get out of your way, lets you write your tests without bumping into the test framework the whole time. 
That's cool, but I think the generators are a way more interesting addition :)
This library looks like a very good starting point when you want to write your webserver without bothering about what's under the hood just yet. Are there any plans to add some flexibility to change nlohmann's json with rapidjson when speed is of the essence?
Automatic template type deduction is your friend
CATCH has the smallest overhead, both conceptually and syntactically, of all C++ testing libraries I know of (not counting its clones such as doctest etc). IOW it just doesn't get into your way at all and allows you to write your tests without thinking of anything else, while still providing all the convenience of running them (i.e. running just the tests with the given name or tag) and debugging test failures (i.e. excellent failure messages). Once you try it there is really no going back to the traditional testing frameworks. The only drawback of CATCH is the compile-time penalty you pay for using it. It becomes less and less important as your test suite grows, but it's still there.
A nlohmann/json is added as an example for RPC server. You can use any other library to parse the json that you want!
I've been using boost ones since 1789 and c++17 one since 1824. Impls (stable &amp; reliable) have been around for a long time, a lot of code use optional types in ways that make them basically interchangeable.
&gt; I've been using boost ones since 1789 and c++17 one since 1824. I know who to contact when I see a job opening that requires over 200 years of C++ experience.
Is that really worthy of a Reddit post?
Well, any implementation can optimize under as-if, and by definition the "same" program written in two different languages, are, well, the same, so a "sufficiently smart" optimizer can always transform one program into the other. For this reason, kicking it back to the implementation is only reasonable if the implementation is actually going to consistently do the optimization, which in this case, it isn't (key word is consistently). Eventually it all comes back to making life easier for the optimizer, and types are easier for the optimizer than constant propagation, which is basically what inlining the function pointer in qsort is a form. Constant propagation is very dependent on inlining, as you noted. Types are not.
When your project is small enough to have one lib with the same name as the project then it doesn’t matter. When you have a big project with many libs and executables then using variables unnecessarily makes the experience miserable. 
I'm not a Rust expert, but a quick Google search suggests that Rust is not immune to [leaking memory via circular ownership semantics](https://doc.rust-lang.org/book/second-edition/ch15-06-reference-cycles.html#reference-cycles-can-leak-memory). &amp;#x200B; Generally speaking, even in 'safe' languages, you can always create a circular ownership relation and that has nothing to do with aliasing. 
&gt; I disagree with the idea that historical bloat inevitably leads to violating the YDPFWYDU principle; in fact your own point (2) about &gt; emplace &gt; illustrates how a new feature can help avoiding unnecessary overheads. My point was not that historical bloat leads to violating YDPFWYDU, the point is just that historical bloat itself is inevitable. So the original post is clearly wrong; part of C++'s feature set is just historical bloat and does not aid with YDPFWYDU, so it's clearly possible to have a less bloated language that supports the principle (just imagine C++ with various now-agreed-to-be historical mistakes deleted). I think though the "spirit" of the original post was just that you need a big feature set to support YDPFWYDU, which I agree with (Rust's feature set is not so markedly different in size/complexity than C++'s). &gt; I'd like to note that whether Rust sometimes violates this principle, or not, does not in anyway change the fact that C++ does, which is the heart of the debate here. But we're all familiar with those examples. I took exception with you saying that "Rust does it better". Despite what you're writing here I feel like that's an invitation to a language war. I don't disagree with your points re backwards compatibility. It certainly makes me very sad that C++ will never have destructive move for example (and I think it's one of the nastiest fundamental warts in the language). I am genuinely curious though how Rust is going to do emplace, are they really planning to add variadics?
How does this support HTTP 2.0? 
I see. I guess it's been working for me then because I keep the scope of responsibility for my `CMakeLists.txt` confined to the library at hand. If a project depends on a first party library then it's handled as if it was a third party library.
I've looked at switching; I'm a heavy gtest user. However, I rely extensively on data-parameterised tests, as well as type-parameterised tests. Does catch support these, because I didn't see them in the documentation. What I really want is to be able to use data- and type-parameterisation at the same time, which gtest doesn't support. If I could do that with catch, it would be a big selling point.
Hey do you have any pointers/links to read more about data-parameterized tests? I have no idea what they are, tried googling a bit, but wasn't really successful.
Yea me too, I could never warm up to QtCreator or other Linux IDEs. And don't even mention Xcode, LOL! The Visual Studio experience is just too good - the debugger, debug-visualizers, profiler, blazingly-fast auto-complete with VAX (ok fair enough, that's a (paid) plugin), and everything just works out of the box, also for cmake projects (previously with the CMake VS generator, nowadays natively in VS). CLion comes sort-of close though, it provides quite a good out-of-the-box experience too. VSCode is quite neat too but you need to do a significant amount of customization and download a few plugins, which is a bit too much work, if you're used to VS's out-of-the-box experience. Anyway this wasn't supposed to be an IDE discussion ;-)
It doesn't scale well. I work on the llvm family of projects. The proliferation of `set(${LIB_NAME_${ARCH}_${PLATFORM}} ${LIB_NAME_${ARCH}_${PLATFORM}}_${WHATEVER{ARCH})` type code is miserable. CMake is HORRIBLE designed to deal with this type of situation. 
Right, but a conceptually very similar example, just involving two or more circularly owning objects, would seem to be allowed in Rust. &amp;#x200B; Your post seemed correct but besides the point. This example illustrates (to me, anyway) a general class of problem which is circular ownership, the mutable aliasing is just an incidental detail of the illustrative example and not a core property of it. &amp;#x200B; &amp;#x200B;
I still might be young, but it's not a reason to make fun of me.
The advice is solid -- use std::optional (or boost::optional until you adopt 17) and it makes code so much better. Same for the (yet-experimental) `std::expected` &amp;#x200B; I'm a bit confused on their motivating bit though -- has anyone really decided that `pair&lt;T,bool&gt;` is a better return value that means "maybe a T" than `smart_ptr&lt;T&gt;` where you get 'for free', the nullptr value? That just seems like an utterly bizarre design choice. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9d05kc/beginner_c_course_for_independent_study/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yup, for like a year now. It is true that in C++ you have to be more explicit about which types are optional (although, as I noted in a different post, all smart pointer types are implicitly optional unless marked with gsl::not\_null&lt;&gt;).
Cool! It’s the first lib I see which is based on beast! It would be cool if a future version supports HTTP2 and Websockets 👌🏼I’ll definitely keep an eye on this project. 
Libraries that have global state that it's difficult to reset - common with frameworky-type systems that have singletons, logging, type registry initialised by registrar-type globals, and so on. Much easier just to have separate programs so that things are in a known state when you start. There's also runtime global state (locale, `ios::sync_with_stdio`, various bits of the C runtime, etc.) but that's typically less of an issue.
i think 0.0.1 is an understatement and has more to do with it being added to boost. i remember learning about the library when binging cpp talks: https://www.youtube.com/watch?v=uJZgRcvPFwI
I think that's one of the things that this new version of Catch is aiming to support with its [Generators](https://github.com/catchorg/Catch2/blob/v2.4.0/docs/generators.md) (although they are still considered experimental). But in general I think the idea is "this test should hold true for any inputs in this set", so the framework will run the test multiple times, testing against some/all of the values in that input set. Though I'm not sure how that differs from just writing a loop in your test that iterates over the values that you care about.
Catch is adding experimental support for generators which gives you native support for data parameterisable tests. What we do a lot of is just rolling our own. You declare a simple struct or tuple that contains a collection of params for your test case. Then you declare a vector of these, and initialise it with nested initialiser lists. Then you simply run a for loop over a REQUIRE with the different inputs and expected outputs per item in the vector. It's not exactly rocket science but it works pretty well. I haven't used type-paramterised tests before, can you give examples? 
Yea, I agree. I prefer writing in dart and compiling it into JS now, but unfortunately not many people are doing this these days.
Advertise that you can compile code? You just wouldn't.
&gt; Has anyone really decided that `pair&lt;T,bool&gt;` is a better return value that means "maybe a `T`" than `smart_ptr&lt;T&gt;` where you get 'for free', the `nullptr` value? I admit that example is a bit of a stretch, but if `T` were say `int`, I can imagine preferring `pair&lt;int, bool&gt;` to `unique_ptr&lt;int&gt;` in a tight loop that otherwise does not allocate memory.
well, with a shared_ptr retrun you get one more indirection, one more memory allocation, and potential atomic operations if for some reason RVO didn't work... so performance wise, it's `pair&lt;T, bool&gt;` all the time
Maybe he wants advice, opinion or just help on his codebase.
Maybe.
Maybe not.
Unit test files still compile much slower than with alternative frameworks
That is a generall problem with c++: optional, variant, string, the list goes on and on. 
If you are willing to pay dynamic allocation costs everyone, then a smart pointer might be an alternative. Generally you should prefer to return values, not pointers though - this isn't jave we are talking about.
Not that I'm in favor of returning a pointer in generall, but why would you use a shared_ptr for that at all?
!removehelp
When I first saw std::optional I was really excited. It's far less usefull than I thought, though. What we need is std::result so that we can do go-esque constructs: &gt; std::result&lt;foo*, int error&gt; function();
This has been in development since at least 2016. it's 0.0.1 for boost but it's used in production for the ripple cryptocurrency. [https://github.com/vinniefalco](https://github.com/vinniefalco) is the main guy behind it
i had to adopt some unit tests to this. Compilation is atrocious and I'm not seeing a huge gain over my 15 lines of code vector of named function pointers struct that return a std::string (pass if string is empty), with one executable per class or utility functions run by a bash script.
Hell, Java is a really complex language. I use Python daily, and I'm still dazzled by the actual complexity of the language (instead of the surface complexity). C++ might actually be easier to fully understand than python, which is terrifying if you want to understand what your code is actually doing all the way down.
Why do you find it cubersome? Have you checked Blaze(https://bitbucket.org/blaze-lib/blaze), Eigen(https://github.com/eigenteam/eigen-git-mirror) and other tensor libraries? They are really great to use and it's really hard to write code that actually beat their usability, performance.
You could always derive your own result type off of a variant. Arbitrary example: template&lt;typename T&gt; using result_or_error = std::variant&lt;T, std::exception&gt;; // Or your own Error type result_or_error&lt;SQL::Response&gt; run_query(std::string_view query); auto queryResult = run_query("SELECT * FROM dbo.accounts"); if (std::holds_alternative&lt;SQL::Response&gt;(queryResult)) { auto&amp; response = std::get&lt;SQL::Response&gt;(queryResult); // ... Handle successful result (may be SQL error tho) } else { auto&amp; error = std::get&lt;std::exception&gt;(queryResult); // ... Handle system error (SQL service is down? Out of memory?) }
If you're used to using numpy, it'd probably be irritating having to get used to something else. Its already done anyway. 
What are you using for the underlying implementation of the BLAS/LAPACK routines? There is an enormous difference in performance between the reference implementation and an optimized implementation.
Very cool, thanks much! 
The amount of effort you have put into this is remarkable. Having said that, if you feel the need to use NumPy in any serious C++ project, go with Eigen. It will be really hard for an individual effort or even NumPy for that matter to measure up to Eigen 
 XmlDoc ParseXml(std::string_view sv); XmlDoc ParseXml(std::filesystem::path p); Bet you can tell which overload loads the xml from a path and which parses the xml already in a string. Adding the string overload was the source of a bug in our codebase until I made the mandate that all paths must be passed around as path objects and never as strings. Now we never confuse the two. 
Linear algebra libraries share a lot of common syntax regardless of language. I do a lot of numerical work and I assure you making your own library is the hardest possible way to do it.
I'm just pulling this from memory... but I'm pretty sure NumPy has its own version of this library in C. I think they just called it NumPy bindings for C.
My intentions were a library that was as close to a one to one clone of NumPy for fast easy conversion to C++. Also, Blaze and Eigen are more for straight up linear algebra, while NumPy contains much more. Some of the extra things included in NumCpp are: 1) A Rotations namespace with Quaternion and Direction Cosine classes. 2) A Coordinates namespace for converting to/from cartesian/spherical and other corresponding operations. 3) 1D and 2D signal/image processing filters 4) A random number module (basically wraps the boost random module) 5) Easy to use timer with simple tic()/toc() interface 6) All of the NumPy array methods for operating on arrays 7) Some very basic linear algebra support (determinant, matrix hat operator, inverse, least squares, SVD, matrix power, and multi-dot product). If you need more complex routines then Blaze and Eigen will definitely be better options for you. 8) Some more image processing routines for threshold generation and application, pixel clustering, cluster centroiding, etc. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9d2zkg/help_needed_recommend_subs_are_not_active_right/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I believe you are right, but it is for C not C++. Also the documentation is severely lacking, and the API is pretty difficult to use...
Oh, OK, as long as you assure me.
at least in theory C++ is backwards compatible so that shouldn't be a big problem.
It's nice, i had the same struggle and my decision was to just not use python anymore for work because i had to redo it in C++ anyway. That's also why i usually don't recommend people on my field (signal processing and communications) to use python. Because even though it seems we live in an age with too much computing power that doesn't hold up for anything that needs to happen in what is basically real time. C++ still beats any scripting language or wrappers by a lot. And even though i think it is a great idea and it might help some people, i think your approach is not ideal. The project is gigantic and it's going to be impossible for you to beat any of the existing C++ libraries. People use those because they are fast and optimized and yours will be slow and clunky. You need to use libraries or your project will be mostly useless, there's just too many libraries that are amazing in C++ (fftw, it++, openCV, eigen, ...). And usually people learn them instead of complaining that it's too much work to use/learn them. 
I'm not sure why you think this library is slow and clunky, especially since you've never used it or done any profiling... also, are super heroes writing these other libraries, or why do you think matching their performance is impossible? Lastly, most applications don't actually require every last ounce of optimization and won't be able to tell a performance difference anyway.
i checked some of the code and the fft isn't even implemented that means at least everything that does filtering or correlations is far from where it could be. Random seems to be using boost so it should be fine, but yeah i haven't checked everything. So there might be parts that run just fine. 
I think you've missed the point of this library. My intention was a more or less feature for feature and interface clone for NumPy. Eigen will definitely be a better choice for Linear Algebra, but Numpy and NumCpp have many other features than Eigen. And hopefully with a much easier to use interface as well.
Correct, the FFT and Polynomial modules are still on my to do list. I was going to try and wrap FFTW, but it uses the GNU GPL and I wanted to keep this library under MIT license so I can still use it at work.
oh alright, that will make things a lot more complicated for you.
For other readers' information: &gt; A Rotations namespace with Quaternion and Direction Cosine classes. Eigen has this http://eigen.tuxfamily.org/dox/group__TutorialGeometry.html &gt; 1D and 2D signal/image processing filters Eigen has only FFT and convolution. &gt; A random number module (basically wraps the boost random module) Eigen can generate matrices/arrays with random uniformly distributed on [0,1] elements, in naive way based on `rand()`. It can, however, also use `std::random` in C++11 mode: https://bitbucket.org/eigen/eigen/src/default/doc/special_examples/random_cpp11.cpp?at=default
&gt; NumCpp have many other features than Eigen such as ? Just curious
There are alternative implementations. Including reference implementation here: https://github.com/akrzemi1/optional
This looks great! Definitely will check it, might just use it in one of my projects related to ANNs ... some of the modules do use Eigen, and some features indeed are missing for me, I've signed to "watch" this one! Thanks!
Why is HTTP/2 important to you?
Awesome work! It's really a shame that the various python math/ML extensions don't just publish a clean C++ API as well. Anyway, I could definitely see this being useful. I look forward to checking it out.
True (I might have to do something with one of those others (*cough* [doctest](https://github.com/onqtam/doctest))), but that is not because it is header-only
The numpy FFT implementation is actually contained in a single C header + BSD licensed, that could be easily used from (or ported to) C++. If you want, we could collaborate on that (we would reuse it for xtensor).
I know these are references to old brands, but I can't recall which ones they are.
True. However, as far as the cost of header only is concerned: If you do use separate compilation of the main file, it is effectively no longer s header only lib. It is a regular lib containing one source file and one header file that are merged together and the pre processor turns them effectively into two separate files again. So, if you use catch as a true header only library, it is really slow, if you use the other trick it is faster, but it is no longer header only, but s library with only two files.
And thank you for that.
&gt; hat's not a property of the language, actually. It's only a limitation of the implementation of qsort and the toolchain you are using to compile it. The biggest advantage of std::sort in terms of performance is not that it's template, it's that it's inline. Of course, template implies inline, however the reverse is not true, and a conforming implementation of qsort could perfectly be defined inline. Furthermore, even without qsort being defined inline, LTO could still kick-in. Not true by a long shot - and leaving performance to a possible optimization is not good. &gt; That is to say, it would be perfectly feasible to implement std::sort on top of an improved version of qsort (you'd need to pass a function to swap elements, too). Not possible. The indirection will not go away. &gt; There's no inherent performance in templates Yes it is. Templates allow superfluous indirection to be avoided. &gt; in fact, std::sort will generally perform worse than qsort in Debug mode because of all the template layers. No one cares about this. &gt; the "not" case happening when the amount of templated code is such that it trashes your i-cache without delivering much speed gain in exchange Ridiculous claims...
There's a reason. First, I don't want qualify types of parameters. Second, I don't want to put using namespace into each function. It is much easier to put it into one place.
Considering how complex it is already, my idea adds just a very little more. But the benefit is huge (for me, at least). I hate qualifying identifiers, *when* they are just 1. visual clutter 2. unnecessary typing. Unfortunately, this is true 99% of the cases of my work. I use `using namespace` in cpp files, and don't use it in header files (I would, if I could). And I like to be consistent. So, when I copy a function signature to/from .cpp/header, I need to adjust it. Annoying.
What does "custom" mean? Can I use it to create a client to access to a JSON-RPC server?
No, it is my fault. HTTP/2 was planned, but not yet implemented in Beast. This will be fixed!
I have a little personal anecdote to offer here: a lot of the libraries you refer to are optimized to extract full hardware performance, and often there’s nothing one can do to make them any faster on a given CPU family. It’s not always the case of course, but quite often it is. I have found that a lot of times just rather straightforward autovectorized C++ can get anywhere between 25-75% of performance of those beasts of libraries, if you have some background in the specifics of the platform and know what code patterns to use in C++, as there are ways to write simple C++ that can preform abysmally, and similarly simple C++ to do the same thing, just as intuitively, and it performs great. So, if your needs are to extract close to full platform performance, you’ll need to use the specialized libraries. If you can afford to blow off some computational steam and run at 1/4-1/2 speed compared to fftw or blas, then a plain-C++ implementation might do just fine, and in a real-time setting. Heck, if you can live with 20% performance of so, Python with numpy might just cut it for you. It all depends how much work you have to do each “frame”/“packet”/“time quantum”. 
The problem is not backwards compatibility. The problem is documentation and the API.
Would you prefer hunter or vcpkg ?
Some questions... 1. Is this intended as a complete replacement of the existing exception system? Will we have to rewrite all our software that currently uses exceptions? If so, how will we deal with exceptions that currently carry just a little bit more than a number? 2. Has any performance testing been done? Currently a C++ application can assume that on the non-exceptional path, there is no need for testing error codes on every operation. If I understand correctly, this paper proposes to automatically test the return exception value on every single function call, leading to what I imagine to be rather massive overhead compared to the current situation. In fact early exception handling used this method, and was replaced by the current approach precisely because of the performance overhead. 3. Have other, less invasive approaches to improve the situation been considered? I mean restrictions of some kind on the type of thing that can be thrown as an exception, thus removing the need for the RTTI lookup, and simplifying memory handling for the exception object itself. 
Thanks for that, Roger. Yeah I guess you could roll your own version of that on top of Catch2 relatively easily. I guess you could define a templated input struct that captures the parameterised types as well as the data.
Does anyone know the difference betweel llvm::Epected and std::optional?
So firstly, I come into work, go to check /r/cpp and bam!, there is a paper I didn't expect to see until the WG21 San Diego mailing. It was a bit of a surprise. Anyway ... &gt; Is this intended as a complete replacement of the existing exception system? Everything I am about to answer refers to my specific proposed implementation of P0709, which is this paper P1095. Herb or others do not necessarily agree with the mechanism proposed in P1095. I would envisage that future compilers will default to implementing type-based exception throws as they currently do, and value-based exception throws use the proposed mechanism. This is to retain backwards binary compatibility. However there would be a compiler option which converts all exception throws to use the proposed mechanism. Throwing type-based exception throws would involve a malloc, as they often implicitly do right now, but all existing source code compiles and works as it currently does, just minus any EH tables being emitted into the binary, and thus not being binary compatible with older compilers. Throwing value-based exception throws would be as lightweight as control flow, as it uses the proposed C `fails(E)` mechanism. &gt; Will we have to rewrite all our software that currently uses exceptions? If so, how will we deal with exceptions that currently carry just a little bit more than a number? All existing code still works without modification. You opt in to the new mechanism on a function by function basis. &gt; Has any performance testing been done? We have a very good idea of likely performance from Boost.Outcome, which already can optionally use the proposed `std::error` implementation. Performance, if I do say so myself, is beautifully deterministic. We discovered a Windows scheduler bug due to how deterministic this code is. Beautifully deterministic code is not necessarily the highest performing code, just that it is highly predictable. I do want to be clear that there may be a performance loss in the average case, but large improvements in performance predictability i.e. performance worst case bound. &gt; Currently a C++ application can assume that on the non-exceptional path, there is no need for testing error codes on every operation. If I understand correctly, this paper proposes to automatically test the return exception value on every single function call, leading to what I imagine to be rather massive overhead compared to the current situation. If memory serves early exception handling used this method, and was replaced by the current approach precisely because of the performance overhead. As the paper mentions, under SJLJ exception implementations much of the performance loss on successful paths came from the increased stack usage of pushing unwind handlers per stack frame. The proposed mechanism doesn't increase stack usage, and uses the CPU carry flag or equivalent as the discriminant to branch upon after function return. This is usually speculatively executed out of the pipeline by modern CPUs because the CPU already knows whether the function succeeded or not. So, we believe currently that performance impact will be statistically unmeasurable for real world code on Haswell or later CPUs. For other CPUs, we don't know with any firmness given the wide variety of CPU architectures out there (I'm confident with ARM Cortex A57, due to testing done by me on my phone), but a major compiler vendor intends to implement an experimental compiler early in 2019. This current debate at standards committee level is on what form that experimental compiler ought to take. &gt; Have other, less invasive approaches to improve the situation been considered? I mean restrictions of some kind on the type of thing that can be thrown as an exception, thus removing the need for the RTTI lookup, and simplifying memory handling for the exception object itself. Yes, but almost entirely by private email, with a touch of that debate leaking onto std-proposals at times. It is my opinion that there would be little gain to tinkering with the edges, and only an experimental compiler compiling real world code will prove this proposed approach and mechanism. Other questions and feedback are welcome, though I wasn't prepared for this to happen today, I'll do my best to find time to reply to feedback as best I can. Thanks in advance. 
&gt;When still in generic form passes can query the target via hooks, mostly for performance heuristics to guide generically valid transformations. Conversely generic passes after CodeGen generally use callbacks to find out what the MIR is actually doing and manipulate it. There aren't many of those because it's such a hassle. Interesting. I was thinking of something like having mul %1, %2 add %1, %3 in the IR where the register allocator puts them in the same registers because that's the generic optimization to reduce ALU contention. But then a target-specific optimization would be to put them in different registers because it knows that addition and multiplication are on different ports. mul %1, %2 add %4, %3 Or, as in my above example, could be fused into a single instruction. Would this happen through hooks in LLVM, then?
You can try out xtensor in a C++ Jupyter notebook [here](https://mybinder.org/v2/gh/QuantStack/xtensor/stable?filepath=notebooks/xtensor.ipynb). This provides an experience similar to that of NumPy in a Python notebook. &amp;#x200B; &amp;#x200B;
You could try kissfft https://sourceforge.net/projects/kissfft/ It's BSD licenced
I made my own Result type, which basically combines std::error\_code and std::optional. If anyone is interested it's in [this folder](https://github.com/kareldonk/QuantumGate/tree/master/QuantumGateLib/Common) in the files Result.\*
&gt; So firstly, I come into work, go to check /r/cpp and bam!, there is a paper I didn't expect to see until the WG21 San Diego mailing. It was a bit of a surprise. Is it when we have /u/vormestrand on the case? ;)
His sense of superiority makes for a hard read. 
What do you mean? 
Premature optimization is evil. Stop spreading evil. 
If it was a tight loop that you knew was a performance hot-spot, that might be justified. This assumes that you've profiled &amp;#x200B; In the vast majority of cases, it's an evil premature optimization. 
this is why I use my cpp compiler as a way of adding operator overload do C style programming, and nothing more.
Yes, value semantics are preferred -- hence optional is better. &amp;#x200B; But premature optimization is the root of evil. Don't do it. Unless you know for a fact from real profiling data that dynamic allocation costs for functions that need to return a maybe&lt;T&gt; are any kind of significant slowdown at runtime, don't do it.
They certainly are prodigious in finding and posting interesting material! For which I am grateful.
UUC! But I would love to have it ;)
[This exists](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0323r4.html), it's called `std::expected` using ThingOrError = std::expected&lt;Thing,Error&gt;; ThingOrError SomeFunction(...); { auto ret = SomeFunction(...); if ( ! ret ) { // Checks if the ThingOrError is an error HandleError(ret.error()); // ret.error() returns a value of type Error // If ret doesn't contain an error, this would throw return /..../; } auto retval = ret.value() // retval is of type Thing // If ret didn't contain a Thing, this would throw // But good thing we checked, eh? /... do stuff with retval .../ } There are already some [mostly-compliant implementations](https://github.com/TartanLlama/expected) floating around the web. Once you get used to it, it's really magical. A few other points: &amp;#x200B; 1. You can construct a ThingOrError from a Thing (or Thing&amp;&amp;). That means you don't have to modify any of the non-error return paths. 2. You do have to notate where functions return an unexpected value (duh). This is a Good Thing™ that you have to write something like: `return makeUnexpected(...);` because it clearly delineate an error path (like `throw`) &amp;#x200B;
To support this, I will have to write individual headers using the already existing code. I have an idea of further Boost.Beast extension to support HTTP / 2. For WebSockets, there will be an other repository. 
&gt; Premature optimization is evil. Stop spreading evil. but there's no premature optimization here. using `std::optional&lt;T&gt;` or `std::whatever_ptr&lt;T&gt;` will have the exact same syntax upon usage - `if(t) { t-&gt;do_stuff(); }` but the `optional` is safer since it cannot point to deleted memory like a pointer could. Initialization of optionals is also simpler since you don't have to use speciale `make_unique/make_shared` functions. The performance benefits are a free bonus, but `optional` should be your first choice if you have a "possibly null" value. 
Sure. A heap allocation is 100x more expensive than an average line of code immediately, and every bit of non-locality causes cache pressure going forward. A habit of using heap allocated data can easily cost a "background" 2x - 3x performance loss as you get common memory stalls. An easy place to see this is in the various gc languages, which make avoiding heap allocations difficult. Someone using a `std::shared_ptr&lt;int&gt;` just to return an optional `int` is going to get the side-eye and a code review rejection. Someone returning a `pair&lt;bool, int&gt;` prior to `optional`, I'd honestly prefer. Heck, I'd even consider an `int` with `MAX_INT` being "not present", and that is **horrible**. Today I'd demand `optional&lt;int&gt;`. 
&gt; I like how Hunter at least supports regular make and autobuild, so non-cmake projects at least have a chance at getting packagified. At the moment, I'm trending toward hunter. With Hunter I put all the magic to build in my CMakeLists.txt, and don't have to worry about external tooling. Android and Qt support is tripping me up, but that appears to be because of a wholesale change in the NDK from gcc to clang vcpkg has the momentum at the moment. I started a scratch project using it recently, and stopped, but I can't remember why ATM. I'm just a hobbyist, not a full-time dev, so what do I know, really? 
That sounds reasonable. I think gtest gets data-parameterisation right, mostly. Define test parameter struct, and provide a static or dynamically-generated list of parameters. However, dynamic generation is a bit inflexible--because it's a side-effect of global constructors, it runs before `main()` and you can run into odd problems. For example, I ran into issues with `boost::filesystem::path` due to its requirement for locale functionality before that was correctly set up. Being able to defer until later would have been handy, e.g. with a lambda to generate the list. This happened with the dynamic discovery of tiff files I linked to in another reply, which builds a list of `path` objects. For typed-parameterisation, I think they could probably have done better. Passing a list of types is "clever", but doesn't really help much. I'd rather have defined the template, and then specialised it by type, plus a list of test data. i.e. one at a time. A clever macro could let you create a list of `((type, data), (type2, data), ...)`, I suppose. Depending on the situation, you might want separate data per type, or share it between some or all types. A good interface would permit that flexibility. IIRC gtest's use of macros prevents the use of a templated test parameter/fixture type to do this by hand (I spent a while trying). I did look at converting to catch2, but with half a decade's worth of gtest test code to convert, it was a large effort. However, if this type of functionality does become available, I would be very interested in revisiting our use of gtest, since its idiosyncrasies can be a PITA (like the lack of proper installability, and the above problems mentioned).
&gt; `errno` is just an ordinary external defined global variable Not necessarily. On this Linux box I'm currently SSH'd into `errno` is a macro: /* Function to get address of global `errno' variable. */ extern int *__errno_location (void) __THROW __attribute__ ((__const__)); # if !defined _LIBC || defined _LIBC_REENTRANT /* When using threads, errno is a per-thread value. */ # define errno (*__errno_location ()) # endif
https://godbolt.org/z/epsbII It does.
I've been working with the Linux fdt library and it forces big endian and doesn't abstract it for you. It drives me up a wall, admittedly it is a niche corner case.
First of all, this isn't just about performance, but using values usually also is easier to handle correctly. Second: I not sure if you understand what premature optimization is about. It doesn't mean "don't write efficient code by default". It means don't invest a **lot of time** into optimizing your code before you know a) it is necessary and b) have concrete data about the usecase for which you want to optimize . So: If your object is supposed to be on the heap anyway (for whatever reason) sure, return a pointer, but if you'd normally return a value, then std::optional is the more natural choice - this had nothing to do with performance.
1. You can also do `*` on a pointer when the pointer is false. And FYI, you can also do `*` in optional when the optional is false. So there's no real enforcement anywhere here (though optional is the only one that gives a safe option at all). 2. Okay, I will grant this point because using a `unique_ptr` at least looks like `optional` superficially. Boost program options is making a decision to care very little about performance. Given what the library is doing, this isn't unreasonable for two reasons. First, people usually parse very few (in relative terms) command line options. Second, the library is doing something very specific, and in that specific context the performance isn't that crucial. Most code isn't that specific, so it can be used in a wider variety of contexts, which means it is more likely to be used in the critical path. The critical path is also never a truly black and white thing; there are parts that are ultra critical because they are either in the latency critical path, or throughput bottlenecks. But there are lots of bits of code around them that while currently less critical, would become an issue if significantly slowed down (this again is what Carruth is talking about). I have a smart enum library that parses a string into an optional&lt;enum&gt; type. Do you think that if I couldn't use optional, I'd return a unique_ptr&lt;enum&gt;? Would any sane person do that? &gt; Especially if you're writing, I dunno, ffmpeg. This is just Amdahl's Law But boost PO and ffmpeg are not written by the same person. Most software is big enough today that even in the rare case where nearly all the source code (barring STL) comes from one company, it's still not all written by a single team, with detailed awareness of all the critical paths where their code will/won't be used. boost PO just happens to occupy a niche where it can very safely assume that it's performance matters extremely little. This is not common for library software. Amdahl's law is fine as it goes but it's a law for beginners mostly to stop them from doing crazy things. People who are serious about performance do not cite Amdahl's law as a reason not to consider performance in code that they write; it just may be a reason not to write code in an uglier way to achieve performance they don't need.
Make me feel sad and tell me how many big endian CPUs they'll probably still be running on in 2024?
By taking a look at the code, he is not using the BLAS/LAPACK Fortran libraries. A huge problem of Fortran is that most open source Fortran such as GNU Fortran, aka GFortran, implementations aren't good as the proprietary ones such as Intel Fortran, PGI Fortran and etc.
If we have pure math functions, they will not only be faster, but will be possible to mark them constexpr. Good job! I cannot wait for this to be in the standard!
So, on this implementation of `errno`, under P1095 the macro definition might instead become: #define errno (__builtin_using_fails_errno() ? __builtin_read_fails_errno() : *__errno_location()) ... or something similar, depending on compiler of course.
`fails_errno` would be a macro probably expanding into `_FailsErrno`, or whatever WG14 decides, if they accept this proposal.
Hey Sylvain, How's the python compatibility with xtensor? Do you need to pass through something like pybind11 to make a python package using xtensor as a math backend?
Out of curiosity, how do you intend to use the library? Do you write throwaway programs to calculate or compute something? Or will you write long-term programs for your field? Or will you integrate this in Python or any other scripting language using Swig or turn it into a shared library for binary reuse?
Oh, my bad memory
&gt;You can also do \* on a pointer when the pointer is false. And FYI, you can also do \* in optional when the optional is false. So there's no real enforcement anywhere here (though optional is the only one that gives a safe option at all). Indeed. If someone sent me a code review that did \*optional instead of .value(), I would surely ask them to use the interface that better preserves correctness. &gt;Most code isn't that specific, so it can be used in a wider variety of contexts, which means it is more likely to be used in the critical path. I dunno, I just looked at profiling data for some code, and virtually none of the code is used in the critical path, which is like, 2-3 functions (out of thousands). This seems like a dispute we ought to resolve empirically rather than just arguing about it :-) &gt;I have a smart enum library that parses a string into an optional&lt;enum&gt; type. Do you think that if I couldn't use optional, I'd return a unique\_ptr&lt;enum&gt;? Would any sane person do that? I tend to think of it like this: you can sacrifice correctness guarantees for performance, both you and the client should be aware. &amp;#x200B; Also, what's the alternative? You can't return a pair&lt;enum, bool&gt; because you wouldn't know what to initialize in the enum half. An invalid enumeration would violate the invariant that all variables held in the enum type are valid (in-range). You could pick a 'default' which is arbitrary, or you could explicitly add an INVALID enumeration to each one, which is intrusive and then has to be handled in switch/case statements. 
Your post has been automatically filtered because it appears to be spam (it was a link to imgur.com). If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9d6r4v/i_was_told_my_code_for_c_class_should_go_here/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
N00b question here: if I'm understanding right, this proposes to be able to return from functions a union of the returned type T and the error type E, where the error type is 2 cpu registers in size. Instead of this union also containing another bit to determine if the active member of the union is T or E we'll use the cpu's carry flag. Is this ever a problem if the function were to set this flag itself? Ie. how come it's fine to just hijack this flag for this use? Is this done in other things ie. is it common practice?
&gt; It means don't invest a **lot of time** into optimizing your code before you know a) it is necessary and b) have concrete data about the usecase for which you want to optimize . It also means "don't sacrifice correctness or readability for optimizations unless you know they are worth it". &amp;#x200B; Anyway, I've written a dozen times, optional is the best. I was just dumbfounded at the suggestion that **if optional wasn't available**, people would use some awful construction like pair&lt;T,bool&gt; 
The grass always grows quicker on the other side.
Now I see where this went astray. I read your comment as "I don't see the motivation for optional" not as "the motivation part of the blog is badly written". Sorry for that
Some would say a mandatory runtime garbage collector is overly complicated. Sure, the programmer my not feel the difference, but a datacentre's power bills do. &amp;#x200B; In C++, lambdas are first class citizens, and the C++ type system is strong.
Nice dogmatic platitudes you've got there, dear. :-)
It does matter if you want to encode data. Iirc the 's and wire endian format matches, you can just interpret your (pod) data structure as a stream of bytes and send it. If they don't match, you have to use rose siding and masking operations to copy the data I to a new buffer and then send that.
My fault for not reading your post carefully before commenting on it. Either way - good this was cleared. 
In the same way, you first read it as an integer and then reinterpret_cast it to float. 
Wow, xtensor looks very nice. Now that I think about it I do remember stumbling on this a while back and completely forgot about it. I'd definitely be down for any collaboration, though it looks like you guys are quite a bit further along than my implementation.
That's UB, I believe. 
&gt; a text file is either "ANSI" or "Unicode". ISO 8859, UTF-8 and other encodings don't exist. Encodings don't exist (see byte order fallacy again). That's just Windows/Microsoft terminology. Windows calls 8-bit character encodings (including UTF-8; known as "Code Page 65001" in Windows-land) "ANSI" and 16-bit UTF-16 "Unicode". All Microsoft documentation uses this terminology and therefore, so do many Windows programmers. Of course any programmer worth their salt will be able to "translate" these terms into more "standard" language if necissary. Nobody is denying the existence of other encodings.
It is common to read/write data just by dumping entire structs. I've seen this a lot in computer games, e.g. BSP map format used in e.g. Half-Life and Counter-Strike is essentially a bunch of structs. When reading and writing such files it becomes necessary to [swap byte orders](https://github.com/ValveSoftware/halflife/blob/5d761709a31ce1e71488f2668321de05f791b405/utils/common/bspfile.c#L173) to make file format cross-platform. Writing/reading these files the way author proposes it seems to be more code.
\`xtensor-python\` is a set of bindings for Python built upon pybind11, which allows using numpy arrays inplace using the xtensor API. &amp;#x200B; [https://github.com/QuantStack/xtensor-python](https://github.com/QuantStack/xtensor-python) &amp;#x200B; We also have similar bindings for Julia and R.
The more the merrier! You should hop on our gitter chat and say hi. We are a growing group of like-minded open-source developers building for the C++ scientific stack.
The ABI is only part of the problem on Windows. The other more serious problem is the limited nature of the DLL PE-COFF object format. Unlike ELF, it doesn't have weak linkage, and can't support export of templates properly. This makes it almost impossible to use the standard library types, or your own templated types, in library interfaces. Whereas on Linux, BSD, MacOS X etc., it works without any special effort.
Well this was published back in 2012, when `htonl` and friends were at least 30 years old.
Correct, but you can byte copy it.
Correct!
This is utterly baffling. If I want to convert from an external byte stream to an unsigned integer type, I absolutely care about the internal representation of the unsigned integer type on the machine on which I'm currently running. &amp;#x200B; Actually, forget my opinion. Let's look at some large codebases to see what they use: &amp;#x200B; [Linux byte swap code](https://elixir.bootlin.com/linux/v4.0/source/include/linux/byteorder) [Linux networking code](http://www.jbox.dk/sanos/source/include/net/inet.h.html) [BSD byte swap code](http://web.mit.edu/freebsd/head/sys/sys/endian.h) [Chromium byte swap](https://cs.chromium.org/chromium/src/base/sys_byteorder.h?q=byte+swap&amp;sq=package:chromium&amp;g=0&amp;l=26) [Mozilla byte swap](https://dxr.mozilla.org/mozilla-central/source/mfbt/EndianUtils.h?q=endian&amp;redirect_type=direct#347)
Just reuse the Go grammar then and add in support for C++ templates so it wont be compatible with Go 2.0 . 
`std::optional` is very good and almost versatile, but since it has to add a `bool` value to the type and must respect alignment, it may easily extend the size of a simple type by a factor of two. In places where this might lead to performance penalty, and for special cases, where at least one value from the type's input range may be assigned as sentinel (like `MAX_INT` in your case), there exists a very nice alternative: `optional` class from the [`type_safe` library](https://github.com/foonathan/type_safe). Having nearly same semantics (and even providing a couple of convenience methods) this class lacks the mentioned downsides of `std::optional`. Example use cases: 1. Return an optional `int`, where `MAX_INT` may be considered as "missing" value. 2. Return an optional `std::string`, where an empty string may be considered as "missing" value.
I would think Hunter would be better for UNIX, much more user friendly too though source code wise it's pretty messy
It would be much better if the compiler had an intrinsic or such to convert from a piecewise representation of a float to a native one, so the compiler knows it should optimize it. Something like `float __builtin_create_float(bool sign, int exponent, int mantissa);`, with some special functions to create an infinity or NaN.
And what do you do with the old state? What you are talking about is Copy&amp;Move which is applicable to ctors only (mostly). You need the swap so the old resources are cleaned up. And the only point where there are extra ops are for self-assignment. Most of it will probably be optimized away too.
Premature pessimization is just as evil as premature optimization. The heap is great when you have complex lifetime objects whose identity (and not value) is most important. I'm not doing some insane optimization. I'm just saying "don't use the heap unless it is something you should use the heap for". Heap usage leads to general program slowdown, not just local code slowdown; and even the local code slowdown is pointless, because a smart pointer to an int is a really complex and crappy model for a nullable int anyhow. Avoid the heap by default. When you must use the heap, use something like std::vector to keep things contiguous, and use values within the vector. And all of this is just the performance hit -- the raw complexity of non-value types is good enough reason to avoid it when not required. All pointer types, barring smart pointers to immutable data, are insanely difficult to reason about. And smart pointers to immutable data just model optional anyway. --- Now the above rules do imply "don't use std::map". And that is true; if you have a decent replacement, don't use it. So when you notice a performance problem with your std::map usage, you'll find or roll your own flat-map; at that point, you should start changing your default map from the std::map to a flat-map. You don't go back and replace existing std::maps with flat-maps, because the semantics are not identical and barring evidence that is premature optimization. But you do avoid premature pessimization by using flat-maps in *new* code. Now your maps cover most use cases better than the old maps do. Avoiding premature pessimization means having coding habits that *don't* lead to pointless slowdowns and costs. Avoiding premature optimization means not making your code suck because you want it to go faster, and not spending effort making code faster when you don't know it is slow. 
Even better would be if there was a complete set of network serialisation (to a standardized network format) primitives built in. As for the format, I believe having two's complement integers and IEEE-754 floating point would already help a lot of people. 
Mostly the first two uses. I don't think there is too much of a point to integrating with python since NumPy already exists. I do provide a class in NumCpp for passing arrays back and forth between python and C++. As for a shared library, this is all templatized header only so that isn't really an option. I also don't want to mess around with trying to support a bunch of different platforms and complilers.
Deprecate absolute paths... why!? How is this scenario going to play out: the program asks the user to select a file using a file dialog box. The file dialog box returns an absolute path. The program cannot open it because someone thought that was going to be 'dangerous', so now it has to somehow transform it to a relative path. This is assuming we are even on a system where such a thing is possible to begin with; on Windows you cannot take a relative route from one drive letter to another. We all know that equivalence testing cannot be done with absolute 100% certainty. We'll have to either accept that `equivalent` will make the occasional mistake, or just not offer it at all. Given that it exists in in the standard, I believe we have chosen to put up with the occasional mistake. Considering that it is apparently "good enough" for code written by mere mortals, I feel it should also be considered good enough for compilers writers and their `#pragma once`. 
I think there are two fundamental problems with your views here. The first is that pointers give you any correctness guarantees. They don't, in any way. Either way, nothing forces you to check validity, and either way, doing * or .first without checking validity gives you nonsense results. Second, you're assuming it's typical to have an ultra narrow, extremely black and white critical path. In some kinds of relatively simple (in the software engineering sense) software, like e.g. certain numerical work where almost all the cost is in a few matrix operations, sure, that does happen. This is not "80-20" rule because you are saying that basically only 0.3% (not 20%) of your code accounts for the vast majority of performance. If you are writing that kind of software, great, that probably affects your outlook. Most people aren't, and error handling shows up everywhere, and it makes sense to be reasonably consistent about it. So why pick something that's so slow you can't use it in many, many places, when there's something not dramatically different that is fast?
Just to clarify - this proposed exception mechanism necessitates a new calling convention, right? Windows calling convention uses only 1 register for returning function values, but the proposed mechanism allows 2 registers. And you are taking over the carry flag too.
I assume this is also what was happening in the Photoshop files the author is so baffled by. They seem to think Adobe was manually serializing every field, but I'm pretty sure they were taking a pointer to a struct holding all their data and passing it straight to `fwrite`
I can't comment on your links. Those are certainly authoritative sources. Perhaps they're written as they are for performance reasons? The blog author's opinion is that most code^\* shouldn't care about the computer's representation. Build an unsigned integer based on the external byte stream's representation, then let the compiler handle your computer's representation. Specifically his example i = (data[0]&lt;&lt;0) | (data[1]&lt;&lt;8) | (data[2]&lt;&lt;16) | (data[3]&lt;&lt;24); interprets the external data as little-endian and builds an appropriate integer. ^\* "except to compiler writers and the like, who fuss over allocation of bytes of memory mapped to register pieces", which I would contend include kernel developers. 
Fast. Track. This. Shit.
How do I open the documentation? Going to https://github.com/dpilger26/NumCpp/blob/master/docs/doxygen/html/index.html just prints out the html code. Not very straightforward.
One would be extending or replacing a current calling convention, correct. This is why the proposal is targeting both WG14 and WG21. I don't think it a problem for x86/x64/ARM, RISC-V's current calling convention would need a complete replacement though.
Cool, thank you for the explanation &amp; links!
&gt; The file dialog box returns an absolute path. The program cannot open it because someone thought that was going to be 'dangerous', so now it has to somehow transform it to a relative path. That's what `path_handle` in P1031 is for. So: llfio::path_handle dirh = llfio::path(llfio::path_view(absolutepathstring).parent_path()); llfio::file_handle fileh = llfio::file(dirh, llfio::path_view(absolutepathstring).filename()); That's what I mean by "deprecate". &gt; This is assuming we are even on a system where such a thing is possible to begin with; on Windows you cannot take a relative route from one drive letter to another. P1031's reference implementation library works perfectly well on Windows. &gt; We all know that equivalence testing cannot be done with absolute 100% certainty. We'll have to either accept that equivalent will make the occasional mistake, or just not offer it at all. Given that it exists in in the standard, I believe we have chosen to put up with the occasional mistake. I phrased myself poorly on Friday due to tiredness. What I meant to say is that `std::filesystem::equivalent()` works via the `.unique_id()` mechanism I spoke about before. That's literal equivalence rather than semantic equivalence. And that's the only type of filesystem entity equivalence I'd be happy with in the standard. So basically, on this one point the current standard is good. 
Hunter is just CMake, so it should work anywhere cmake works. It has a few dependencies in older cmake versions on bzip, etc. so works well on mingw too. Yes, it's a bit of a kludge. As a user it's still fairly straightforward. The docs definitely need a good refreshing for some of the lesser used packages, 
I can comment on a few problems of doing things like this `set(LIBRARY_NAME myLibrary)` `add_library(${LIBRARY_NAME} ${LIBRARY}_SOURCE_FILES)` People tend to do it because they have projects in which the same (or a very similar) pattern is repeated frequently, so they think: oh! it's the same but the only thing that changes is the name of the library. However, some problems, in no particular order 1) Every cmake file is called \`CMakeLists.txt\`. If you have a project with several of these, and you have to open multiple of them, chances are most of the modern text editors with tabs will have several tabs with the same name \`CMakeLists.txt\`. The only differentiating factor becomes that one \`set(LIBRARY\_NAME xxx)\` statement, so if for whatever reason you need to change only one of them, it's very confusing unless you look at the file path. 2) Notice how I said same or *very similar* pattern. In most cases in practice, they're not the same, there will be small differences that no longer make it generic / copyable code. So what's the point in using the awful anti-pattern if each case is different? 3) And if each case \_is\_ the same, why copy paste code?? Follow the 'DRY' principle: if it really is the same pattern, cmake has macros and functions. If the only differentiating factor is the library name, make a function/macro that takes that as the argument. That way if you need to modify what happens for multiple targets, you change it once. Otherwise it's a maintainability nightmare. 4) Think of cmake targets conceptually as base classes. And then think of \`add\_executable\`, \`add\_library\`, \`add\_custom\_target\` as constructors, and \`target\_link\_libraries\`, \`target\_include\_directories\`, etc as methods of the base class. In this case, the target name becomes the name of a specific instance. When you have \`target\_link\_libraries(MyLibrary PRIVATE Boost::filesystem)\` you are expressing intent. When you have \``target_link_libraries(${IM_TOO_LAZY_TO_TYPE_THE_LIBRARY_NAME} PRIVATE Boost::filesystem)`\`, I don't know whether you actually intended this, or you copy pasted from somewhere else and contaminated the dependency graph. 5) As @lanzaio points out, stuff like the following is unreadable: `set(${LIB_NAME_${ARCH}_${PLATFORM}} ${LIB_NAME_${ARCH}_${PLATFORM}}_${WHATEVER{ARCH}})` 6) Imagine one glorious day you need to create a list of all libraries (\_not\_ executables) built by a large project. Now, there are many ways of doing this, but one of them is simply searching all files for \`add\_library\`. Now imagine the frustration when every like looks like this: `add_library(${LIBRARY_NAME} ${LIBRARY}_SOURCE_FILES)` &amp;#x200B; &amp;#x200B;
Coming soon: https://en.cppreference.com/w/cpp/numeric/bit_cast With it, you can make this constexpr create_float function without any compiler-specific builtins.
This part &gt; Let's say your data stream has a little-endian-encoded 32-bit integer. Here's how to extract it (assuming unsigned bytes): Is 100% correct. What do you mean "make format cross-platform"?
&gt; But we're all familiar with those examples. I took exception with you saying that "Rust does it better". Despite what you're writing here I feel like that's an invitation to a language war. I do think that "Rust does it matter" *on the specific topics I mentioned*. I never claimed that Rust was better *overall*; I was just trying to illustrate that some of the choices made in C++ were sub-optimal. &gt; I am genuinely curious though how Rust is going to do emplace, are they really planning to add variadics? As far as I know, variadics are not on the table yet; it's not even clear if Rust will ever have full variadics. The proposals for `emplace`, in essence, were all syntactic sugar for an in-place construction as Boost used to have for `optional` in C++03. Essentially, you'd type something like `vec.emplace_back() &lt;- T{ a, b, c };` and it would get translated to: vec.emplace_back([&amp;](T* t) { new (t) T{ a, b, c}; }); With the following definition of `emplace_back`: template &lt;Function&lt;void(T*)&gt; Fun&gt; void Vec&lt;T&gt;::emplace_back(Fun&amp;&amp; fun) { grow(1); fun(&amp;mData[mEnd]); ++mEnd; } The nice thing about this is that you avoid all the privacy issues that plague C++. Just today I had to resort to `std::shared_ptr&lt;T&gt;(new T{ ... });` instead of `std::make_shared&lt;T&gt;(...)` because the constructor of `T` was private. On the other hand, unlike variadics, it's special purpose, so there's the big question of whether it's worth having a special purpose feature just for this usecase, or if there's a more generic pattern struggling to emerge. For example, keen Rubyists made the remark that this very much resembled "block expressions" (?) in Ruby, where you'd write `items.foreach |i| { ... }` and the block is passed to `foreach` as a callable.
&gt; Constant propagation is very dependent on inlining, as you noted. **Types are not.** Funny that you mention that, it's very much *an implementation detail* of current C++ compilers. For example, in Java generics are type-erased. Specialization muddies the waters somewhat, but there's no real reason that `template &lt;typename C&gt; void sort(C&amp; container);` could not be compiled to: struct SortHooks { bool (*compare)(const void*, const void*); void (*swap)(void*, void*); ... }; sort_impl(SortHooks { ... }, &amp;container); Actually, there are clear benefits to doing so; it would make compilation to Debug mode much faster (less generated code &amp; debug information), and thus make the edit-compile-test cycle shorter (for fast tests). Now, it's much easier to do in Java: *boxing* means that all objects have the same size on the stack and all generic types are constrained by a specific *interface*. Yet it does mean that it's a *choice* made by C++ compilers to produce different instantiations for each set of parameters, making them very inline-friendly. Nobody forced them to.
\&gt; But what is he using? Just C++ templates and vectors STL container. Another problem of BLAS/LAPACK is the lack of Fortran standard ABI. In Gfortran the symbols matches the names with prefix underscore, for instance, the function dpxy, has the symbol \_dpxy, so it can be called with extern "C" dpxy ..., but this name decoration works only for GFortran and it may not work for other Fortran implementations.
&gt; Assuming ABI is stable "only" for a specific version: This isn't nice. I find "this isn't nice" pretty one-sided. It has implications, I agree, however as any technical choice there are *advantages* too. For example, it allows innovation. The layout of `enum` and `struct` has changed over time as new optimizations were added to the compiler, making programs more efficient (less memory/cache, better latency/throughput). &gt; On the proprietary side not having a stable ABI throws us into same DLL hell that Microsoft created with VC++. If using DLL. The default in Rust, like in Go, is to statically compile executables. If you only deliver statically compiled executables to your clients, they care not which version of the compiler they were compiled with, and which ABI they use internally. There's no DLL hell without DLLs :) *Note: DLLs are supported, at least on Linux, just not encouraged.* &gt; There will be people who want to use proprietary software and maintainers may not want to recompile things every so often. I wish I could say that it should not be an issue; but I do realize that given the current performance of the Rust compiler it very much is one. Performance has been steadily getting better, so hopefully it will be less and less of an issue, though I doubt it'll ever reach Go levels of compilation speed (unfortunately). &gt; Those are the challenges C++ has faced, the views and solutions from C++ side will benefit for Rust too. Indeed, and Rust has already taken advantage of the hindsight provided by C++ with regard to dependency hell. In Rust, a single executable can link against both v1.0 and v2.0 of a given 3rd-party dependency. It just works. The magic underneath the cover is that both versions are considered *completely separate libraries*, and as such the library hash which is part of the mangled name of each function differs, so that there's no link-time/load-time issue. There's a slight implication for the type-system: since the libraries are considered to be different, the types (despite having the same fully qualified path) are considered different and passing one to the other will result in a compiler error, preventing accidents. This explicit attention to making cohabitation of multiple versions of a dependency feasible was born from the frustration of dealing with dependency hell in other languages. 
Solution seems reasonable. Personally, I'm not a fan of that special purpose &lt;- syntax. I think you either simply have a normal function called emplace_back that takes a callable (i.e. write out the code block you decribed below by hand), or you solve it properly with variadics. To me I don't think &lt;- carries its weight in terms of language complexity. Ruby's block expressions are also just passing lambdas around ultimately, so if you have a decent syntax for lambdas I don't think there's any point including it. I think one of the biggest language design mistakes that people make, is that instead of adding complexity for genuine expressiveness (solving more problems in a type safe way, adding new capabilities, reducing duplication), they add complexity simply to make things slightly more concise. It seems more persuasive than it should be in reddit arguments but in real codebases I don't think Ruby's block syntax has any value over just passing a lambda as you do in C++ or Rust.
You can always throw away information you have, and fail to make optimizations. Everything is implementation dependent in the end. I don't think though that this invalidates the key point here. In a statically typed language, types have to be known throughout the program, on every line, with no exceptions. If your callable is passed by type (in the sense that a stateless lambda is, for example), then rules of the language simply guarantee 100% that the compiler has the information necessary, *locally*, in principle, to do the inlining. When you depend on constant propagation, the information isn't available locally, and whether or not it reaches that point is dependent completely on other optimizations. So yes, ultimately the optimization is implementation dependent, but that is a bit of a vacuous statement since all optimizations are. There is still a key distinction that optimizations based on types are guaranteed to be available everywhere, optimizations based on values are not.
(so, by the way, could a further proposal for a standard ABI be based on this? because if it has to change... well let's just change everything at once right ?)
Yeah, Guthub will just display it raw. If you clone the repo and open in a browser it will be much more useful.
&gt; To me I don't think `&lt;-` carries its weight in terms of language complexity. I tried to be as language neutral as I could be when presenting the information :) I think `&lt;-` is *necessary* in the sense that placement `new` is necessary: at some point you want a syntax to tell the compiler *build this value at this address*, rather than leaving it to it to build a temporary and then moving it at the desired address (which may not optimize well). On the other hand, I don't like `vec.emplace_back() &lt;- T{ ... }` because then `&lt;-` is promoted to *both* express building at a specific address *and* wrapping stuff in a lambda. Personally, I'd favor something like: fn emplace_back(f: impl FnOnce(Place&lt;T&gt;)); Which would be used as: vec.emplace_back(|p| p &lt;- T { ... }); where the user is in charge of the bundling, and there's this newfangled `Place&lt;T&gt;` type which indicates there's a spot for building a `T` right there, and you can use `&lt;-` to build something into it (which consumes the spot, so no building twice at the same address without intervening destruction). It's slightly more verbose, but it does allow the user to distinguish between captures by value or reference, for example, which matters in Rust since `T { ... }` could be "moving" from a local variable. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9d9led/please_help_me_with_the_code_not_the_correct/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Calling convention != ABI. And note that the calling convention only changes for functions marked `throws` or `fails`.
Interesting. I just did a quick look. Its functionality looks useful for C++ applications that need a light and fast numerical analysis. I have also implemented the Python Pandas like package in C++ at https://github.com/hosseinmoein/DataFrame. 
Make files saved on le machine work on be machine. 
My understanding from listening to cppchat is that code that works will continue working, if this is the "herbceptions" or static exceptions mechanism. What is does is if you opt in is provide a mechanism where the return value is more like an expected type and a register bit will indicate if there was a value or an error(think std::system_error but called std::error and constexpr too) being returned. So there will be one error type for static exceptions and if you buy in, the cost of the exception is like that of an error code. If not, it will act like a dynamic exception(like we have now). 
You missed the fallacy. It's not that you don't care which standard the data uses. You do and the article says so explicitly. The fallacy is about needing two different routines depending on what machine you are running one. You can do it that way, but you don't need to and the single implementation that works everywhere without an if() or a #if is pretty simple.
Unfortunately I don't have a web host for the documentation yet. Fortunately, cloning the repo or simply downloading a .zip file of it is as simple as a single button click from Github.
We are building a REST API as part of a embedded device to control smart home tech. It would be helpful to have multiple parallel requests over one connection as well as the ability to push responses to the client. If you turn on a light for example via HTTP you would typically get an ACK from the lamp that it got the command and later on a report that the state was changed. With HTTP1 you would need to make 2 requests from the client an having some kind of dynamic endpoint management to achieve this. 
A specific constrained use-case thereof, but yes, yes it is. It relies on a trick that only works for binary sum types so it's not entirely relevant to generalized sum types, and of course the language specifics are highly targeted at the binary pass/fail uses and not generalized sum types, nor the pattern matching or other language facilities that make sum types so desirable. :)
\&gt; Should it be Microsoft to modify it's product/OS to link with them ? I guess that no. As it is not specified by the C++ standard, in addition, to the mingw compiler, there are also some other proprietary compilers for high performance computing on Windows such as PGI C++ compiler, Intel C++ and etc. Unless all compiler vendors agree to use the same ABI, they shouldn't modify their compilers. &amp;#x200B; The binary reuse is not a hassle for projects where the developers control the whole source code and use the same compiler, but it can be become a problem for open source projects, plugin systems, library vendors and also for the development of a component market like the old COM component market where people bought and sold COM libraries that were linked to visual basic. Many people don't have this problem because they use the same compiler and compile all dependencies source code before linking. &amp;#x200B; But C++ if had an stable and standardized ABI like C would bring a lot of benefits for the whole community as it would allow to download pre-compiled static and shared libraries and reuse them with any compiler. In addition, it would make easier to create scripting language bindings, for instance, Python bindings, Ruby bindings and so on. &amp;#x200B;
Hehe thx
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
How do you think 1789 and 1824 are supposed to be interpreted?
Is it just me or the implementation of coroutine type seem much easier in the core coroutine proposal?
https your shit.
&gt;But the seed of doubt had al­ready been plant­ed and so I was still un­sure if this is the right way to do it — the short­est-path choice ba­si­cal­ly takes one de­gree of free­dom away from the us­er. This would seem to indicate some sort of misunderstanding of the problem. No user is going to negate one of their quaternions because they want their slerp to "go the other way." Everyone considers q and -q to be the same thing everywhere. Deviating from that is stupid. &gt;I named the func­tions Math::slerp() and Math::slerp­Short­est­Path() (and not slerp() and slerpNotShortestPath()) to sug­gest the one with the longer name is do­ing some­thing ex­tra and might not be al­ways the best choice. That is a very poor choice of naming. Your `slerp­Short­est­Path()` is what everyone means what they say "slerp" and your `slerp()` should be named something like `slightlyFasterSlerpIfYouCanGuaranteeDotProductOfBothQuaternionsIsPositive()`.
&gt; Computes a 32-bit integer value regardless of the local size of integers. Nope. The expression is i = (data[0]&lt;&lt;0) | (data[1]&lt;&lt;8) | (data[2]&lt;&lt;16) | (data[3]&lt;&lt;24); Each shift promotes its LHS operand to `int` and produces an `int` result. If the result of the shift can't fit into an `unsigned int` that shift is UB. Therefore if you have a &lt;32 bit `int`, this can be UB (eg. if `data[3]` is `0xff`). You can instead do i = (uint32_t(data[0]) &lt;&lt; 0) | (uint32_t(data[1]) &lt;&lt; 8) | (uint32_t(data[2]) &lt;&lt; 16) | (uint32_t(data[3]) &lt;&lt; 24);
Cgold.readthedocs.io It appears to mostly be by the guy behind hunter. How much of what you want to do can you fit in there?
I may be wrong, but I interpret them as "very early". The sentence is decorated with a technique known as [hyperbole](https://en.wikipedia.org/wiki/Hyperbole), i.e. the use of exaggeration as a rhetorical device, to make the sentence less boring, and to evade clumsiness of recalling and explaining the exact details. The choice of the years adds enough absurdity to make clear the sentence is not mean to be interpreted literally and to signal the reader to invoke their rhetorical sense. It also provokes humour through cultural references. I know explaining pun ruins a pun. But sometimes, some people just don't get it without an explanation. 🤦
I did a 3D animation package back in the day (early 90s), probably one of the early uses of quaternions commercially. Going the long way around is sometimes worthwhile - it can make a more interesting animation. Definitely not the default, but it was worthwhile having a button that allowed it to be flipped.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9den1a/help_me_im_new_to_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Interesting. Welp, I guess I should've said "almost no user" rather than "no user". Why not just make that button insert a keyframe with an orientation in the midpoint of the longest path?
That's exactly what he explains. "If format is a, do b, if firmat is c, do d".
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9df22b/code_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Does anyone actually prefer the equations everywhere? I like to look at code so there is little difference between what you've written and what I'm looking at. Sure the math is computer language agnostic, but you're writing in a C++ sub so most of what you've written would be most widely understood written in C++. Unless the goal isn't to be understood, but IDK who does that
More keyframes is more complication for the user. My design was based on a napkin drawing - I want the object here, then here like this, then end there like that. Quaternions make the path look natural without the user even thinking about it. But when you have say 3 orientations A, B, C, the change through B can be jarring, or a bounce, ie if the turn at B is sharp like a right angle. Sometimes you want the animation to appear that there was momentum from A to B, and the object flows "through" B, causing it to take the long way to C. (You could also then tweak the spline with tension/continuity/bias params, which worked fine for normal (ie position, etc) interpolation, but I had to completely invent something for quaternions.)
Your post has been automatically filtered because it appears to be spam (it was a link to imgur.com). If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9dfcmx/new_to_this_stuff_i_cant_debug_or_start_a_c_file/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Can you drop a link to the signed version you have? I'd love to see it.
He has a point in that the use of the carry flag should really be part of an ABI, rather than a language standard. For one thing, there is actually a CPU around that doesn't have a carry flag (https://en.wikipedia.org/wiki/RISC-V, "RISC-V has no condition code register or carry bit") 
Calling convention is not ABI. For example, the ARM Linux uses the ARM calling convention, but the same SysV ABI as on Linux on x64. MSVC also uses the same ARM calling convention on ARM, but the MSVC ABI instead. So RISC-V, as the paper points out, would probably use an additional register for the discriminant, and perhaps in a future edition might implement a carry flag (doing bigint math on RISC-V is currently very inefficient due to lack of carry flag).
codebehind shown in video: void makeFileFolder(Folder * folder) { if (folder-&gt;name.length() == 0 || folder-&gt;name[0] == '.') return; for (auto &amp; p : filesystem::directory_iterator(folder-&gt;fullName)) { auto name = p.path().filename().string(); if (p.is_directory()) { auto it = folder-&gt;subfolders.find(name); if (it == folder-&gt;subfolders.end()) { folder-&gt;add(Folder(name)); it = folder-&gt;subfolders.find(name); } makeFileFolder(&amp;it-&gt;second); } else { if (!contains(folder-&gt;files, name)) folder-&gt;add(name); } } } The iterator includes all the files unless you run it through the debugger, then it misses the same set every time.
Interesting point, thank you :) I don't have a problem understanding math equations, so I didn't even question putting them there — and I mostly just copied them from the [docs](http://doc.magnum.graphics/magnum/classMagnum_1_1Math_1_1Quaternion.html#a702539c58371af1c8635c2bc60e3e0a5). On the other hand, the equivalent C++ code looks like this: return ((T(1) - t)*a + t*b).normalized(); which I am sure is far from understandable if you don't have a good knowledge of given math library. To fix that I would need to "unroll" the code using just standard functionality. That would make it span several lines, I would probably make a few errors there, and it would be far from concise. Hope that's understandable. Visualizations: sorry about that, next time I'll improve ;) Spent a lot of time researching things and visualizations would take another few hours on top, which I didn't have.
Oh, sorry about that, but did you notice it has: - no cookie / GDPR popup - no user tracking - no Google Analytics - no intrusive ads - no megabytes of javascript bloatware ... and loads actually fast? There's no attempt to do any data mining on you, so the absence of HTTPS is less of a problem on such a site. HTTPs is high on my priority list, but so far I focused rather on having the site snappy and responsive than messing with certificates. That's not a completely wrong thing to focus on, no? ;)
Nah, math is just fine.
We are constrained by C when it comes to the math and POSIX functions i.e. we can only express what is possible in C. The `fails_errno` approach was warmly received by WG14 as finally solving a long standing problem neatly, and the Austin Working Group (POSIX) also did not object to it. Non-C++ folk dislike the side effects of `errno` as much as everybody else.
Absolutely right. Some minor migration is required e.g. you can't read `errno` in a `fails_errno` function, because there is no way of `errno` entering a function. But there was a strong wish from WG14 that existing code using the C standard library, when recompiled, should simply perform much better than now. You may have noticed that WG21 tries, whenever possible, to do exactly the same.
A previous draft (one of six!) did propose a generalised C sum type called `either(A, B)`. There was not opposition to it, but there was a lot of committee bikeshedding. Somebody pointed out that we could avoid the bikeshedding by indirecting via designated initialisers, and that's how the final paper does it. We, in C++, do have a problem that we don't currently have an extensible and generic method for constructing arbitrary types from designated initialisers, but I'm sure someone on WG21 will think of something for C++ 23.
Firstly, a youtube video is a terrible way to ask a question on /r/cpp. It's very anti social. Please use text and formally specify how to repeat the problem in a self contained short example. That said, I assume you're not trying to iterate a directory tree which is being modified at the same time? As that won't work. Use something like `llfio::directory_handle::read()` instead if you need whole-directory snapshotting. 
&gt; "If format is a, do b, if firmat is c, do d". but that's the thing: when you have for instance struct x { int a; float b; // 200 others }; you want your save code to look like (well, I don't but some people apparently do) : fwrite(&amp;x, sizeof(x), 1, my_file); now, when loading, if your endinanness is the same than the save file, you can just do a fread in your struct. But you have to test for your local endianness to be able to apply this optimization. 
Ah, optimisation! Yeah, my bad.
I find it confusing. 
Sounds like a perfect use-case for WebSocket.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
As far as I remember, there was something about memory allocation being a part of observable behavior. Then if `std::function` allocates for type-erasure, you wouldn't be able to optimize this out. I think that changed in.. C++17? But Clang performed thess optimizations even before.
https://godbolt.org/z/0liQ34 Blows right the fuck up.
&gt; probably one of the early uses of quaternions commercially Maybe in 3D graphics, but in aerospace industry quaternions were widely used way before that. Like 30 years earlier. 
&gt; In general, you should prefer to use actual profile feedback for this (-fprofile-arcs), as programmers are notoriously bad at predicting how their programs actually perform. I love this part of the GCC documentation. Yes, we have all kinds of intrinsics for "helping" the compiler. Still in most cases profile-guided optimization (i.e. optimizations based on actual profile data) are producing better results. There's a great talk by STL "Don't help the compiler"; Sometimes it's best to write sane code and let the compiler do the rest. Of course, things like cache prefetching intrinsics make sense if you have a memory access pattern that is not detected by the hardware (for instance)
I don't like putting a barrier between normal users and library writers. That will make the language even more expert friendly. I'm pretty sure coroutine can be simpler than that and if our system is simple, normal user will be able to build their abstraction more easily, and share their code, making more library writers, more libraries and a healthier ecosystem. Coroutine are quite an important feature. It would be nice if we can make it more accessible.
This is why we can't have nice things.
You know that some performant modern BLAS/LAPACK implementation are not written in Fortran, right? ATLAS is C, OpenBLAS is C/Asm, BLIS is C, Eigen is C++, (MKL I don't know).
&gt; For fails(E) returns, it is proposed for at least AArch64, ARM, x86 and x64, that the discriminant be returned via the CPU's carry flag. [...] On other architectures [....] It doesn't matter what an architecture chooses, so long as it is consistent across all compilers. N00b question: How will “an architecture” choose a single consistent compiler implementation for reporting this bit of state? Is there some per-architecture C compiler harmonization group?
Lets Encrypt is super easy to set up. Many hosts offer free SSL. And it is great that you have all those things, but it is so easy to get SSL going now that non-https sites are a super turnoff for me. Should have been less agressive on that statement.
I'm not trying to discount the video series, I think it's a great idea. Some people just learn better that way. I personally don't, so I'd rather see this information condensed to text somewhere. Ideally by Kitware, but if needs to be somewhere else? Fine. 
Depends on the architecture. The ARM calling convention is defined by ARM, so they would set it for all compilers targeting ARM. On x64, probably clang will do whatever GCC does, and Microsoft will do whatever Microsoft chooses. So basically, it depends, but we're long past the days of individual compilers choosing calling conventions incompatible with other compilers, except in the MSVC vs everybody else situation. I don't think it'll be a problem in practice, people will do whatever the experimental compiler(s) do if the experimental compilers prove this approach is worth doing.
Another favourite fallacy of mine is the * Always use epsilons for float comparisons/Never tests floats for equliaty In almost every case the issue is that someone has learned the 'rule' without understanding the motivation for the rule. It is, as you say, incredibly frustrating.
'this' is a pointer. Your vector contains objects! Not pointers to objects. Also, your vector is useless. You don't return it and isn't a reference either. Are you coming from Java or other language?
You're passing s by value, so the lifetime of s ends when the function returns. Read up about passing pointers to things. 
could you give me an example? I understand passing my reference and value. It just won't work.
Sure, and that's where Ken Shoemake and slerp() comes from. But slerp() was published in 1985. https://dl.acm.org/citation.cfm?id=325242 
fixed that, thanks. but i still cannot seem to load the class into the vector array. an example would be good.
`sizeof(Temp)` will return the size of the array in bytes if it is declared as `type foo[n]`. If it is declared as `type* foo;` then `sizeof` will return the size of the pointer.
[This might help](https://pastebin.com/wpYDVyHv)
Use `std::array`.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I'd also wish for a better readme (then I wouldn't need to really look at the documentation for a first judgement of the project). I'm just suggesting what people are looking for when they find an open source project online. Your library itself might be great, but you don't show it, on the contrary, I'd go there, don't find a readme with any infos, then can't even view the documentation online, so I'm going to close the browser tab and move on. I am sure that goes for quite a significant percentage of potentially interested people. You can use GitHub pages to host the documentation.
&gt; Though I'm not sure how that differs from just writing a loop in your test that iterates over the values that you care about. I forget whether gtest manages this, but several potentially-important differences can come out of the fact that the test runner knows about the separate tests. For example, their results will be reported and tracked (if you store old test results) separately. Maybe most usefully, you would be able to request one specific test be run as opposed to have it just be all values or no values.
You can make a language with coroutines that can be weakly customized. Like, well, every coroutine in every language out there. Or you can expose the underlying nuts and bolts of a coroutine and allow extreme customization, and then write libraries on top of it to duplicate the simple coroutines that other languages expose. #1 reduces the difference between experts and normal users. #2 allows non-standard committee experts to develop new and interesting techniques beyond what the writers of the language intended. Both provide a user-friendly interface to using coroutines the way that every other language does. Now, in magic fun land, we'd have a way to both have extremely customized coroutines that are also really easy to write. But that option isn't on the table, because nobody knows how to do that. 
It matters that coroutines are easy to use, not necessarily easy to write. Core coroutines are harder to use and arguably easier to write, which I think is defeating the purpose of coroutines
I think you're right, using them should as easy as the TS, but the core implementation is much more elegant. It would be awesome to have a merged proposal.
Nope, memory allocation was never part of observable behavior. In C++14 there was the addition that exceptions and stuff that operator new does is not important (just like in copy elision: The possible side effects are ignored). 
The 'pure' attribute has been a surprise to me. AFAICT, the one thing C++ compilers should be *really* good at is determining that if a function is pure or not. Are there really non-adversarial cases where the attribute helps?
And, in theme with your first paragraph, `__builtin_prefetch()` *can* help. But, oh boy is it notoriously difficult to get positive results using it. Hardware prefetchers are really good these days. Even in seemingly obvious use cases, adding in a manual prefetch most often has no measurable effect at all and can be detrimental.
&gt; old man's humor, I'm 35 already Relax, you're just a child.
Bloomberg is despairing of even getting C++11 on the BE machines, and looking at dumping them. Chances of C++23 on BE appears to be on the close order of 0. 
When the function body is not available it is of extreme importance. Some for throw/nothrow.
Didn't both IBM and Oracle roll out C++11 awhile ago? (okay, looks like IBM on AIX is still [partial](https://www.ibm.com/support/knowledgecenter/en/SSGH3R_13.1.3/com.ibm.xlcpp1313.aix.doc/language_ref/cpp0x_exts.html), unless there's a newer version, but Oracle should be ok, no?
That was humor too.
personally, i prefer callbacks. they should add a concurrent queue to the STL
write your own function and use it every day. I don't use something like this often. Could be you are just extrapolating from your situation too much.
Right! The main API is realized over websockets but some platforms don’t allow for websockets. e.g. iOS Widgets, watchOS Apps, Android home screen widgets,...
Right! The main API is realized over websockets but some platforms don’t allow for websockets. e.g. iOS Widgets, watchOS Apps, Android home screen widgets,...
They should fix the platforms instead of requiring you to resort to over-engineered technology.
IBM is partial, Oracle's has regressions that matter at the moment. And not having both compiling the same code isn't really worth it. Particularly if the one vendor is Oracle. Now, couple that with performance per watt issues, and it is all even less attractive. BE big iron is mostly dying to the point where throwing money at the issue wasn't even feasible. 
You're sure you're not looking at QString?
Just use Boost's string algorithm library's [replace_all()](https://www.boost.org/doc/libs/1_68_0/doc/html/boost/algorithm/replace_all.html) and [erase_all()](https://www.boost.org/doc/libs/1_68_0/doc/html/boost/algorithm/erase_all.html).
I've adopted pystring for C++14 and it offers a bunch of nice goodies to work with strings (basically it reimplements the Python string functions). There is a `replace` function available, which, when given an empty string as second argument will remove occurences. You can find it here: https://github.com/wolfv/pystring14
Not everybody wants or can include boost in their project. 
A few thoughts from a quaternionista. 1. It is best to embrace the 'double cover' nature of quaternions, for unconstrained rotations in particular, or use it as a feature where there are constraints. 2. SLERP is just one way to interpolate orientations; it is the one special 'perfectly symmetrical' scheme that makes no assumptions about the object being interpolated. Or, it assumes that the object is effectively a featureless homogeneous ball on its own in space. If you have more knowledge of the object's geometry, mass distribution or environmental constraints then you can incorporate that knowledge to create a more tailored interpolation scheme, effectively using some (non-isotropic) metric in place of 3-sphere distance. At one extreme, you end up simulating physics. Staying in the realm of kinematics, sometimes you do want to interpolate using a set of spherical coordinates if they happen to represent the object's possible motions. Usually there is some distinguished direction or frame, a pencil or an aeroplane say, or known constraints on the motion. In many cases, a 'twist and swing' decomposition is more natural than spherical interpolation. Then, taking velocity into account, the instantaneous direction of motion is a decider - no need for the user to intervene with 'longest' or 'shortest' hints. 3. Using arccos to extract the angle is a classic error that causes a catastrophic loss of precision for small angles or, more seriously, for angles close to 180. You should use atan2 on the 'projection' and 'rejection' magnitudes (the projection magnitude is just the 'dot product' cosine term as used, the rejection is the remaining sine term which, in 3D, is the magnitude of the cross product). 4. Then again, there are many ways to optimize, short-cut or reuse operations to gain performance, especially for SLERP. Trig calculations can often be eliminated, or hoisted out of the loop if the step is uniform. Back in the 80's it was common to avoid square roots for performance reasons, a practice that still persists in some code as a lurking bomb (a potential problem when converting quaternion to and from matrix). 5. Read some Geometric Algebra; a quaternion is just a rotor.
Those people are doing it wrong.
&gt; Did you mean No I didn't. The definition of a shift `E1 &lt;&lt; E2` when `E1` is signed (and non-negative as it is here) says that the result is UB if E1 2^E2 can't fit into the corresponding _unsigned_ integer type. If E1 2^E2 can fit into the unsigned type, the result of the shift is as if this unsigned integer were then cast to the signed result type. See [expr.shift].
Finding a match in general is a complicated problem. Looking for an exact (bit-identical) match in a string is just a single special case. How about a case-blind match? Whitespace normalisation? Locales (uppercase "i" is different in Turkey than in the rest of the world)? Are we talking UTF-8, or Latin-1, or what? Thus, use the search algorithm of your choice to obtain the match position, and then `std::string::replace` to replace it. And if you're happy with exact matches, your search algorithm probably will be `std::string::find`.
Wow, thanks a lot for such a lengthy insightful response. I appreciate that. Some further comments: 2: for SLERP, the assumption I made is that the animation itself will be most often authored in some 3D editor and slerp/lerp then only used for interpolating between usually dense keyframes. There the artist will either try to simulate a behavior that "feels right" or it might be baked from some physics simulation. For this case the shortest path calculation in the interpolation algorithm can be completely eliminated by trivially preprocessing the data. That was the conclusion of the article. A different case is when users are authoring simple animations by hand with code, there the ability to pick the longer path can be *sometimes* useful — I'm not saying the users should need to intervene every time. 3: From a purely mathematical PoV (infinitely large precision, no rounding errors or anything), arccos would be correct, right? That's why I chose to use math equations and not C++ code in the article — show the math behind without obscuring it with discussion about floating point precision limits. (OTOH, yes, the code itself happens to be using arccos for historical reasons. I feel bad for that. Thank you for reminding me to use atan2.) 4: One optimization I have on my roadmap is calculating the interpolation factor once for all animations that share the same time track. Another is [this blog post that approximates slerp using a tightly fitting polynomial](https://zeuxcg.org/2015/07/23/approximating-slerp/).
Well, it's 153 according to this blog https://foonathan.net/blog/2017/06/14/member-vs-free.html
&gt; There are six groups (find, rfind, find_first_of, find_last_of, find_first_not_of, find_last_not_of) with five overloads each in std::string and four overloads each in std::string_view, the missing one overload from std::string_view is finding a std::string overloads aren't exactly the same as 200 unique ones, IMO. 
So the reason it's not in the standard is because "it's too hard" ? Why do people make excuses like this? It's one of the big reasons why people are reluctant to call C++ a modern language.
Does - O3 generate any of these attributes automatically? 
&gt; "it's too hard" Most other languages are intended to run on everything from supercomputers to microcontrollers with 256 bytes of RAM. Not saying you are wrong, but the needs of Python and Java are much different Comparing systems languages, Rust seems to take a similar approach: https://doc.rust-lang.org/std/string/struct.String.html#method.replace_range Or not, :( https://doc.rust-lang.org/std/string/struct.String.html#method.replace
I would say that other languages generally solve a subset of these problems well. By either restricting the search space (e.g. Python 3 with Utf-8 encoding) or not covering corner cases (e.g. Java and only handling Latin type alphabets with the default String object and char)
There are actually some people working on a text class proposal: 1. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0244r2.html 2. https://github.com/tahonermann/text_view
Well, you as long as the replacement is equal to or shorter than the search string, you can use `std::regex_replace` from the standard library (as I mentioned, you’ll still need a DFA when the search string is a simple string, so regular expressions aren’t overkill). When the replacement string is longer, the problem is much more complicated and you’ll need to make some trade offs that depend on the problem. Do you expect a lot of replacements or just a few? If you expect many, then maybe you should walk the string once and determine how big the new string will be and allocate the space up front. If you expect few or no replacements, then doing it lazily might be more efficient. Despite its apparent simplicity, this is a non-trivial problem without a best solution. The standard writers would rather give you no solution than a compromise solution (usually). No solution forces you to consider and confront the trade offs yourself
The authors of the standard. If you implement /`replaceAll` and it has a bug, that's your problem. If the standard has a bug, that's a much bigger problem.
Not handling all edge cases is not a bug if you make the situations in which it works clear.
Fair enough. But you said well enough without qualifying what you actually are looking for. And most of the solutions are deficient in lots of ways if you need really through text editing. Except Java’s String, they did a good job with creating a through solution. It’s just fairly complex. And the std::string certainly isn’t nearly as complex as Java’s String and Character classes. My point being that C++ strings are pretty good at what they are built to do, manage a group of chars and allow stl operations while still allowing printing to a console or terminal.
If you really just stick to the standard, you're not even guaranteed that your floating point numbers use IEEE-754.
The algorithms are designed to work on ranges, not on containers. A string is also not a container. Strings are also not the only sequences for which you might not (usually) care about those operations you mentioned. I don't see what your problem is, `std::transform`, `std::search` and `std::partition` cover the use cases you mentioned. 
I never understood why you needed to set `errno` when pretty much all these functions use floating-point and NaN was literally made for it. Checking for NaN is really easy as well, and you only to do it when you don't trust the input data.
Since now clang is getting a large adoption rate, I believe people from both compilers will talk about it instead of implementing it unilaterally.
’#define p cout’ is one of the worse things I've seen in long time.
Adding a feature does not make the language less suitable for one application or another. Nobody is forcing you to use it. Such constrained applications probably wouldn't even use std::string to begin with. I mean to take it to an extreme, we still have new and delete even though some of the largest C++ code bases ever conceived do not allow dynamic memory allocation.
#define cout ((rand() % 2) ? cin : cout)
And this is why the world is full of shitty software. "it should've been clear that doing that causes your house to explode" should never be considered a valid response. But it is, I've seen it so many times in my life. And I have to wonder if it's unique to software developers, or if other industries are this brazenly arrogant. "is safe to use in every case without doing the wrong thing" is apparently not a requirement for the standard library of a programming language that's used by millions the world over? At what fucking point do we consider the need for correctness to be more important than convenience if not in the fucking standard library of goddamned C++? Attitudes like yours rub me the wrong way because you put your shit out, pat yourself on the back, and then act like **I'M** the problem when it starts causing unexpected issues. 
Mind giving a quick tutorial on how to use GitHub pages to host the doxygen html?
Then [absl::StrReplaceAll()](https://github.com/abseil/abseil-cpp/blob/master/absl/strings/str_replace.h#L50) maybe?
You're confusing completeness with correctness.
I don’t think this is on-topic for the C++ subreddit. It’s a bit of assembly code.
Well you cam have cblas.
By your title, I had expected to see a code generator that generated a header that transformed seamlessly calls to a C API to dynamic calls. Now *that* would have been quite interesting.
No I'm not, the poster specifically said edge cases. These edge cases exist and not covering them is not about completeness, it's about not letting someone's ass hang out in the wind because they assumed it would do the right thing in all cases.
Yes, I'm sure all the code that you've ever written is perfectly correct and complete, handles all edge cases perfectly, and doesn't define constraints, because it handles *everything*. Software and functions have *constraints*. It is idiotic to mandate that software handle *all possible situations*. I suppose that the fact that dereferencing a null pointer is undefined upsets you? As /u/ReversedGif said, you confuse completeness and correctness. Establish constraints, be correct within those constraints. What you are doing here is rejecting constraints, and establishing that *all* input must be considered to be valid input. I don't even know how to respond to that.
Thx for your reply. I read up about this and you are right about the shift and the implicit conversion to unsigned if it fits. Additionally i found this on cppreference for the later conversion from unsigned to signed: "If the destination type is signed, the value does not change if the source integer can be represented in the destination type. Otherwise the result is implementation-defined. (Note that this is different from signed integer arithmetic overflow, which is undefined)." So as you said, you will come into trouble when your platform has an integer(signed or unsigned) smaller than 32 bit (because we cant read all bytes correctly without wrap around from the bytes), but also on exactly 32 bit integers we can get into trouble if the value read uses the MSB from the 32bits.
The idea that pointing out I'm not god and make mistakes is a defense for seriously arguing that the C++ standard shouldn't try and protect people from misusing their API's is just another example of your poor thinking. And the worst part is that you completely misunderstood /u/jherico's point. Because C++ cannot reasonably cover all edge cases, it doesn't try. It allows users to write the code with the assumptions necessary to cover their specific use case. This is why he said, emphasis mine: _If you implement /replaceAll and it has a bug, that's your problem. **If the standard has a bug, that's a much bigger problem**._ Anyone who is writing API's that need special knowledge to avoid being misused is fucking it up, period. It's not ok. I don't want to be a goddamned expert in your shitty API because you couldn't be fucked to design it in such a way that I'm not able to misuse it, or at the very least, detect the anomalous input and give a clear warning. I strive to write API's that are **easy to use in a bug-free manner**. And I don't try to rationalize my mistakes by claiming it's the users problem for using it incorrectly since you made "the situations in which it works clear.". And with that I'm disengaging. The lack of clarity in your response tells me it's not worth my time to continue in this conversation. 
There's two different main philosophies, as I understand it, when it comes to the standard library. One group of people wants to have all the commonly used operations in there to make programmers' lives easier. The other group of people wants to provide a sort of minimal subset of tools that people can combine together to make their own solutions to problems. There's pros and cons to both approaches. 
How does UTF8 affect the string operations in python3? And I also doubt that Java is limited to *Latin type alphabets* too - whatever that means. Both languages rely on an *internal* Unicode abstraction as base for its string type. So all string operations are based upon *code points* (which isn't what you want most of the time, but clearly does not impose any restrictions to some *external* encoding) - in Java historically more on *code units*; but there are methods to deal also with code points. 
Yes, I'm the one who lacks clarity in my response. Calling me 'brazenly arrogant', 'fuckface', amongst other things. You are clearly worth discussing with.
&gt; There is also a legitimate argument for software doing one thing well, instead of everything poorly. false dichotomy, the 3rd option is to expect the user to write the code themselves, which is what the standard library does and what kicked off this discussion.
Your third option basically turns it into a Hobson's Choice, which isn't a great turn of events either.
This is what it looks like when someone refuses to give someone a point that they realize is unassailable. This argument would never pass the reasonable person defense. No reasonable person is going to agree that asking developers to write code specific to their needs is the equivalent of hobson's choice.
Sounds to me like we need to fork the standard library?
Or... was it Go?... where they used Canadian Aboriginal characters that looked like angle brackets to pretend they had generics?
There is also the regex library. Which exists, for better or worse. But you should note that these are all data operations not language operations like I thought you wanted. 
One big thing is that those calls would have to manage memory some how. Assuming you want a container that fits and is separate. Otherwise the stdlib does have that functionality and it works with normal strings in the const parameters because they have iterator like behaviour. And usually the standard library doesn’t to much dynamic memory allocation implicitly unlike the other examples which do object copies in these cases.
I understand where this is coming from, but sometimes I just wish they'd add the 95% use case in a way that does not require passing begin and end to everything. I've needed startsWith, endsWith, replace, replaceAll, find etc. so often that the stackoverflow page for them is always the first and already visited link when searching for it. I understand that some of it is coming in C++20 and am very much looking forward to it.
where would you pass the path to the library to load ? Incidentally, I think that this is pretty much how windows .dlls are implemented ;p
Sounds like a cool project. And yeah they have a different philosophy. I think there is pretty strong incentive to try and keep the current stdlib philosophies though. It’s hard to understand all the API when philosophy constantly changes, like that’s noticeable in Java where lots of objects expose 2-3 different views or data types for specific use cases and knowing the right one is an art into itself.
Here's a basic replace all function: std::string replace_all(std::string str, std::string const key, std::string const val) { size_t pos {0}; for (;;) { pos = str.find(key, pos); if (pos == std::string::npos) break; str.replace(pos, key.size(), val); pos += val.size(); } return str; } // usage example std::string str {"the cat in the hat"}; str = replace_all(str, "the", "REDACTED"); // str == "REDACTED cat in REDACTED hat" str: the string to act on key: the string to find val: the string to replace
Except that pulling in a header only boost library will pull in at least boost's smart pointers and all the things C++11 has and that boost keeps around for backwards compatibility.
Java manages to have all the problems of one-company direction, and none of the benefits. C# is the opposite. But yeah, with standard C++, you'd generally pass around containers as a templated argument, or as a range. In mine, you would pass it with the appropriate view - not terribly dissimilar from interfaces in Java. You see `string_view`, `array_view`, `map_view`, and `allocator_view` a lot. Allocators work very differently and also understand `realloc` and `try_realloc`.
Really cool implementation and very well said about Java and C#.
 const std::string &amp; str ::isspace( str[i] ) Only used with ASCII strings, I'm guessing? 
The compiler might figure out some optimizations by itself. However they do not specifically add these attributes, since the purpose of them is to aid compiler optimization and are not a result of optimization by itself. 
https://github.com/OSSIA/libossia/blob/master/OSSIA/ossia/detail/algorithms.hpp suit yourself ! 
Right. Specifically I mean doing things like prefetching. 
You can't distinguish between UTF-8, UTF-16 LE, and UTF-16 BE reliably unless a BOM is present, and those aren't required. Also, I think you mean 'ASCII', 'ANSI' isn't an encoding. Other than that, I agree.
I wouldn't mind having a `std::string::find_replace` function or similar that just does the `find` - `replace` combo. The question is: would this be sensibly used in anything else than throwaway, toy programs? Anything that implements a user-facing search/replace operation will sooner or later switch to a much more complex `find` algorithm, to deal with case-blindness etc. If I recall how long it took to get rid of the toy-programs-only function `gets`... Sure, it's not directly comparable (`gets` is a security problem, `find_replace` hopefully not), but at least it's a maintenance burden.
&gt; Locales (uppercase "i" is different in Turkey than in the rest of the world)? Are we talking UTF-8, or Latin-1, or what? That's hasn't stopped regex from being added to the standard, with a blind disregard for any kind of encoding-awareness.
Try Visual Studio Code. It has many extension which provide C++ debugging support, for example this LLDB extension: https://github.com/vadimcn/vscode-lldb
Really useful for those of us stuck in old codebases, where the abstractions and immutability tends to be clobbered by liberal use of pass-by-pointer. Speaking of (and possibly a tangent), does anyone have a best-practices list of when you have to pass complex object hierarchies across the DLL border (i.e. C++ &lt;--&gt; |C api| &lt;--&gt; C++?)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9dmqh3/why_stdstring_doesnt_have_functions_to_replace_or/e5jot1i/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
struct A { struct A \*next; int field; }; int f(struct A \*item) { while (!item) { // Not NULL check since invalid addr OK \_\_builtin\_prefetch(item-&gt;next, 1, 1) ; item-&gt;field++; // more processing... item++; } return 0; } GCC: 01 - prefetcht2 02 and higher - ud2 trap.
So what happens if I call replace_all(str,"the","thethe")?
Why not simply do this? I actually like this appraoch better then the one using move semantics. Value x; x = addThis(x); //self assignment is ok, but not necessary addThat(x); x = topItOffWithACherry(x); Value&amp; addThis(Value&amp; x); Value&amp; addThat(Value&amp; x); Value&amp; topIfOffWithACherry(Value&amp; x); &amp;#x200B;
&gt; You can't distinguish between UTF-8, UTF-16 LE, and UTF-16 BE reliably unless a BOM is present, and those aren't required. So what? Which of my points are you referring to? ANSI is an encoding, and a common (but wrong) term for any superset of ASCII. ANSI is whatever "works on my machine". Screw other people with their weirdly configured operating systems. Unicode is somehow a separate concept you don't need to think about because "we don't have users in Asia anyway". Most developers have no idea how Unicode or UTF-8 work even though they use both every day.
Could someone explain to me why the move semantics option is able to use call by value rather than explicit rvalue reference? Does the somehow get replaced by an rvalue reference when possible? Is this part of the standard or a compiler optimisation? 
It's a pessimization: there's an extra move.
&gt; Replacing with the same length or shorter is easy Not true. If you think so, give some pseudo-code that satisfies the 3 conditions I mentioned above. &gt; it’s replacing with a longer string that’s the challenge to do efficiently! I’d say that’s actually probably easier. Since you know you’ll need to perform an allocation, you should start out by counting how many matches there are. You can then allocate the new string and perform the update. The challenge of the shorter replacement has a lot to do with the fact it can be done in-place and with a single pass. Since the longer replacement case doesn’t allow that, you can use a simpler algorithm 
Your proposal is, at least, more fun. I remeber to see in production code of a company I was working time ago: #include &lt;windows.h&gt; #define FALSE 1 #define TRUE 0 ...
A better word than "beneficial" was probably "useful." What I meant is that functions with in-out parameters should not be seen or treated as lesser in C++, because they're naturally very useful in many contexts. We should definitely aim for writing pure functions, and move semantics allowed us to write a lot more of them, but not all of them.
Maybe one call at the start? Then you'll check if the loading succeeded it not? Then add a function to check if the library need to be loaded? Well I don't know either, it was just an idea like that ;)
Please don't do that. Two months after you submit this, some smart guy is going to do auto&amp; y = addThis(x); // Now y and x are aliases addThat(y); // Now, debug how did x get That? Unfortunately, the same problem shows up much more subtlely, at least in my code base. Return by value, or modify in-place with a member function.
Yeah, but that’s going to have terrible performance if there are a lot of matches. You’ll need to move the string each time you have a match, so if there are M matches, you’ll need to do M moves of up to N characters (where N is the length of the string). If you keep track of the total matches so far, you can just move as you go: auto it = str.begin(); for ( size_t k = 0; k &lt; str.length(); ) { if ( str.compare( k, search.size(), search ) == 0 ) { it = std::copy( replace.begin(), replace.end(), it ); k += replace.size(); } else *it++ = str[k++]; } This is still not optimal though, because if there’s not a match, we should be able to skip more than one character. This is what regex libraries do. That would transform the algorithm into O(N+L) instead of O(N\*L) that those one is, where L is the length of the search string.
3: Yes but no. In theory arc-cosine is ok but here it is better to writte explicitly what you mean - a function extracting the angle between two vectors a and b - angle(a,b) rather than acos(a.b) In practice, always no. If it has been written mathematically as acos(a.b) then it is all too easy to translate that directly into code. It turns out that MATLAB made this mistake in its 'angle' function and the bug persisted for over three decades - see the ref. Bugs like this lurk - it may not matter much for many applications, until it matters. The classic reference is William Kahan's 'Mindless' paper, section 12: Mangled Angles [https://people.eecs.berkeley.edu/\~wkahan/Mindless.pdf](https://people.eecs.berkeley.edu/~wkahan/Mindless.pdf) Depressing reading, I'm afraid: &gt;What do mangled angles teach us? The goal of error-analysis is not to find errors but to fix them. They have to be found first. The embarrassing longevity, over three decades, of inaccurate and/ or ugly programs to compute a function so widely used as ∠(X, Y) says something bleak about the difficulty of floating-point error-analysis for experts and nonexperts: Without adequate aids like redirected roundings, diagnosis and cure are becoming practically impossible. Our failure to find errors long suspected or known to exist is too demoralizing. We may just give up. &amp;#x200B;
I am moving as I go! write_pos = std::move(read_pos, next, write_pos); It only moves the range in between the current read pos and the next match, _not_ the entire rest of the string.
Thank you! I'm unsure how that would let me push dynamic object across the divide, there, but I'll definitely look over it.
By that logic, why is there a standard library at all? 
Some platforms C and C++ support don't implement NaN, so the standard can't assume that. If you think that anodyne, neither standard requires arithmetic types to be in two's complement, either. Much of today's C and C++ code would probably not port cleanly to a one's complement arithmetic for example, but the standard still allows it.
Fair enough. I’ll admit I just read your description and didn’t read the code (on mobile so lots of soft line breaks). My bad. Still, looking at either code snippet, I don’t think the algorithm is as trivial as some might assume at first blush
Except every image, audio and miscellaneous binary asset files are byte order dependent. Classic example is PNG, which is big endian. Network protocls also transmit in big endian. Some libraries can take care of endianness for you, while others don’t, so you’ll have to roll up your sleeves and do it yourself. Endianness is not something you can ignore if your aim is to share data between machines. 
It's not trivial, but it's also not really that _hard_ when you think about it for a minute - especially when you have algorithms like std::search to help you. It probably helps that I have previously implemented a `remove_all` function, which looked for runs of "things to remove" and "things to keep" and compacted runs of "things to keep" together in much the same fashion. Implemented to optimise a function that was removing single elements one-by-one, moving the entire rest of the container for each thing removed, of course. 
&gt; It’s not trivial, but it’s also not really that hard when you think about it for a minute You’d be surprised how often people fail to do that. And yes, I think `std::search` is a big help here (though its new, so some might not have access to it or be aware of its existence)
&gt;because our C/C++ functions are obviously based on mathematical functions. They're based on assembly procedures in every form but syntax, which just happens to be how any language on a computer \_emulates\_ mathematical functions on real hardware. :) &gt;consider that purely functional languages can trivially achieve safe concurrency/parallelism due to lacking state outside of the function, having no side effects, only immutable variables, and so on. And it's fair to consider that where concurrency is the need. A good deal of code is still (rightfully) serial in nature (potentially a bunch of separate serial bits spread out concurrently at a higher layer), and when serial performance matters, languages like C++ still smoke every other competitor in single-threaded tests for well-written code (e.g., code avoiding temporary heap-allocated objects or expensive constructors/copies that inout parameters may help one avoid). It's all a trade-off. Which is one of the reasons many of us appreciate C++'s adherence to "multi-paradigm programming." Sometimes the best tool is functional, sometimes its objects, sometimes is procedural, sometimes its declarative... C++ can do it all with a single toolchain and easy interoperability between all those different paradigmatic realms. :)
#define while if // optimization
You should understand pointer and new/delete. In new code there should be only non owning raw pointer and no new delete. See [Cpp Coew Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#S-resource) for details. 
Definetely: http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-resource. You probably need to learn C-style pointers well, because of legacy code bases, and because you'll need to interface with C code. But avoid using it in new code unless explicitly necessary. 
I don't think I've written a single `delete` in production code since at least 2005. There were definitely placement-`new`s though, and plenty C-style pointers.
&gt; though its new, so some might not have access to it or be aware of its existence I think I found out about it because of an article talking about the new "searcher" classes. They're neat :)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; anyone with a speck of common sense If you don’t agree with me then you’re stupid. Great way to convince people. 
He measures the performance by the number of characters to write. It's just a joke.
Piggybacking off other people's comments: * Pointers are still useful/useable if you are not transferring ownership. * A place where I do this frequently is if I am trying to perform a calculation and split the calculation into two parts: one to handle buffers and the other to handle the raw computation. Typically, I give the part handling the raw computation a pointer to avoid having it dependent on whether the input data is in a vector, array, something else. * new, delete, malloc, and free should not be used unless you are writing a library that actually needs to allocate memory and the standard smart pointers are not useable for some reason. Then which one to use/which variant to use is dependent on your application. * Placement new is an exception to the above. The only time I have used it is when I am working with objects that are not copyable. That said, anything allocated through placement new should be de-allocated through a destructor in a wrapping class. The other danger here is using placement new twice on the same memory location. If what was constructed through placement new itself had dynamic memory, the destructor might not have been called and so there is a memory leak. 
Thanks for this post! It let a newbie programmer learn about the Actor Model and the SObjectizer framework looks amazing.
Isn’t that technically true in all the “take and store by value” functions where taking the input by value is recommended? I would guess that generates no instructions in most cases. 
The library is still very young and I'd like to improve on it. I've written it because I've realized that my parsers contain a lot of boilerplate code and once I've factored out common code, I got myself a library. I'd be happy to receive feedback on it!
Passing by value is being recommended in these cases only because it's simpler than perfect forwarding, and the cost isn't too big. Still, there is a performance penalty, and optimizers can't **always** figure it out.
Read of one compiler, the writer got error as follows. Start with x = 0.3; Now read in a file with "0.3" in it. Convert to double in variable **y**. And now x == y is false. That's right. The compiler's conversion of "0.3" was different from the runtime libraries. Another time, and this happened to me, a very smart and precise coworker didn't understand why comparing floats for equality might be a mistake. After 15 minutes he finally got it. In this case it was along the lines 0.999999 vs. 1.0, from adding 0.45 + 0.3 + 0.25. He wasn't an idiot, he'd just never thought about it before.
&gt; "we don't have users in Asia anyway" I'll ask Mister Muñoz what he thinks of that idea.
Thank you! I likely missed that because my hearing isn't great. 
Once had to write conversion when moving to new system. Not only was it bigendian vs. littleendian, but the compiler alignment for structures was different. 
Sorry for the misunderstanding, but it just looked as an obvious thing to me. `x = sort(move(x))` shows three operations to the reader: move, sort and assign back the result. `sort(x)` reads as just "sort x" with zero boilerplate.
Thanks, it looks clean and complete, nice work!
&gt; Speaking of (and possibly a tangent), does anyone have a best-practices list of when you have to pass complex object hierarchies across the DLL border (i.e. C++ &lt;--&gt; |C api| &lt;--&gt; C++?) The following resources may be useful: https://github.com/MattPD/cpplinks/blob/master/interoperability.ffi.md#c, https://github.com/MattPD/cpplinks/blob/master/interoperability.portability.md
I use Visual Studio Code for Rust, and the experience is definitely not as complete as CLion; of course it may be due to the still flailing Rust Language Server ;)
My small knowledge of numerical analysis tells me that picking the epsilon is important. If epsilon is 10^-6 and the values are around, let's say 10^15 you will never compare equal, for example. If the values are around 10^-15 then you will always compare equal. Oops. In my example, it was money, so really it should have been kept as whole number of pennies or something similar, to avoid floats entirely.
&gt; In my example, it was money, so really it should have been kept as whole number of pennies or something similar, to avoid floats entirely. In some sense this is the real answer - try to avoid being in a situation where you even need to do the comparison in the first place. 
I prefer `x.sort()` in this case too. It reads as `sort` being an action performed on `x`. The problem with `sort(x)` is there's no way of seeing at the call site that `x` is modified by the function call. This is something I dislike immensely about the C++ syntax.
&gt;The problem with `sort(x)` is there's no way of seeing at the call site that `x` is modified by the function call. Same is true for `x.sort()`. 
Did you read the article? Endianness _is_ something you can ignore if you work byte by byte. And if you pack bytes into your int in a platform-independent way (like the code in the article) then you're fine. You only run into issues if you `memcpy` the int directly and then have to figure out whether you have to byteswap or not. (And if you turn on optimizations the "slow" shift-and-or code will [compile down to the same thing](https://godbolt.org/z/epsbII), except that now it's the _compiler's_ job to make sure all the byteswapping is correct instead of yours.)
The behaviour is undefined, since you define identifiers that are reserved for the implementation: #define __CPPCMB_HPP__
Ahh I keep forgetting this rule! Would `CPPCMB_HPP__` be fine then?
Almost, it still contains two consecutive underscore, so it is reserved.
Fixed, thanks!
I think two consecutive underscores are only reserved when they're at the beginning. In the middle or at the end is fine, is it not?
This wouldn't work, since the header is included blindly by the preprocessor. The compiler sees one giant file.
Looks nice and clean. What kind of languages can it parse?
The former is like sugar around `variant&lt;T, Error&gt;`; the latter is like sugar around `variant&lt;monostate, T&gt;`.
&gt; Each identifier that contains a double underscore __ or begins with an underscore followed by an uppercase letter is reserved to the implementation for any use. http://eel.is/c++draft/lex.name#3.1
&gt; a resource compiler is a tool that will compile arbitrary data into a program. The program can then read this data from without needing to store that data on disk external to the program. So this will become deprecated if/when we get std::embed? http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1040r1.html &gt; Accessing external resources at compile-time and making them available to the language and user. 
It should work on any compiler with minimal C++11 support, and CMake 3.3 or newer. If it doesn't work, send me an issue or PR. The size overhead will be just larger than the size of the data you are embedding. The data will be stored in the static data section of a binary. There's also a static `std::map`-based index that is constructed when you first access the embedded filesystem object.
Yes-ish. `std::embed` will only load data from a compile-time string (AFAIK), so you will need to know up-front the paths to all the files you wish to load. CMakeRC also supports directory iteration.
llvm/clang would be a good target to test as well!
 char c = 'X'; cout &lt;&lt; int(c) &lt;&lt; endl; output is 88 
I know you asked for characters, but for std::string you can use std::stoi ([https://en.cppreference.com/w/cpp/string/basic\_string/stol](https://en.cppreference.com/w/cpp/string/basic_string/stol))
If you have C++17 available use std::from_chars https://en.cppreference.com/w/cpp/utility/from_chars
404 for anyone but me?
A single character can't be '10', but two characters could be. A character string like that would be equivalent to an array `{0x31, 0x30, 0x00}` (Character for '1', character for '0', null terminator). Since the characters are encoded in ASCII/Unicode as 0x30 through 0x39, and '0' is 0x30, you can subtract 0x30 (48, in decimal) from the number to find out the value of that digit. To convert a larger number, it's just a matter of some arithmetic (multiply by 10, add the next digit, continue until you hit the null). std::stoi is the real practical answer, if you need the standard way of doing it in "real" code. You should only be doing it the way I described above as a coding exercise, like for a class requirement.
So in addition of accidentally created a functional language, we accidentally added language level synchronized blocks? Oh well...
&gt; It should work on any compiler Doesn't putting arbitrary data into an executable require custom stuff to make the object file? Or is that support coming through cmake?
There are no explanations on the repo, but there's a link to [this short article](http://stryku.pl/poetry/mutexes_are_passe.php). It relies on two things: 1. Function-level static objects are initialized once and are thread-safe. 2. Throwing during construction will apparently make it try again the next time the function is called. That's news to me, but I guess it makes sense. This is a simplified version: template &lt;typename F&gt; void sync_call(F&amp;&amp; f) { try { static auto dummy = [f] { f(); throw 0; }(); } catch (...) { } } There's one `dummy` per specialization of `sync_call()`. It calls `f()`, then throws, which makes `dummy` uninitialized. Calling `sync_call()` again will try to initialize `dummy` again, call `f()`, then throw, etc. Just by itself, that's a very convoluted way of calling `f()`. What makes this "interesting" is that the initialization of static objects is thread-safe. So if 10 threads are calling `sync_call()` for the same `F`, they're all serialized. Problems: 1. This doesn't avoid a mutex. It hides the mutex. 2. There's no easy way of returning something from `f()`. 3. It serializes calls based on the type of `F`, not on the individual callables, so two different functions with type `void ()` will be protected by the same mutex. This can be somewhat mitigated by exclusively using lambdas, since each lambda is guaranteed to have a different type. 4. It's cute and relies and obscure language features. The alternative (a `std::mutex` and a `std::scoped_lock`) is clearer, easier to work with and more flexible. The article and the github repo also have typos and problems, such as an exception privately inheriting from `std::exception` and using non-ASCII chracters in identifiers, which I think is legal, but certainly not recommended. 
You can just embed a string literal (or array literal)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9dyk3k/what_is_the_easiest_way_to_convert_a_character_to/e5kyq8n/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
oh.. so this is likely just doing a base64 encode behind the scenes and then compiling it? 
You can read about how it works [here](https://vector-of-bool.github.io/2017/01/21/cmrc.html). TL;DR: Encode every hex byte in a generated `.cpp` file in a huge character array. Then use pointers to that array as a way to access the file contents.
I vaguely remember having seen some Microsoft reference page that erroneously claims this, so maybe that has been true in their pre-standard variant of C++ over 20 years ago. But the C++ standard reserves identifiers that contain a double underscore anywhere. See A_Seat_for_One's quote.
Welcome C++. If you thought that C++98/03 was cool, you will love C++17. You mentioned that you were not yet familiar with some of the new C++ stuff. Here is a nice, fairly short overview of some of the new features of idioms of Modern C++ https://docs.microsoft.com/en-us/cpp/cpp/welcome-back-to-cpp-modern-cpp?view=vs-2017
Works for me
HTTPS in 2018, please. The contact address at the bottom of the website has a .com domain, instead of the .org domain that the website is on. (There's no website at the .com.) I suspect this email address doesn't go anywhere. &gt; a charity which can accept tax deductible contributes from the general public. "contributes" typo. &gt; Conservancy, whose mission is to support the development of FLOSS libraries supports the Boost Libraries project, Missing comma between "libraries supports". I'm not sure what I think about the video reel that plays on the website, showing a bunch of C++ speakers (including me, briefly, holding my life-giving DMD). It creates an impression of association or endorsement, which doesn't seem to be proper if the speakers weren't asked for their approval. I'm not saying that I have anything against the Alliance (it seems to be reasonable and I know several of the people involved), and I'm not concerned specifically about myself, but the general principle of featuring people who weren't asked about it (and I know I wasn't asked).
Your github page is not clever. It is an annoying waste of the time of others.
Cool to see this announced! &gt; The Alliance is focused exclusively on the C++ environment and is free to support non-FLOSS projects such as language proposals, books, education materials, tools, or other projects &gt; Offering incentives or bounties to individuals or groups for achieving goals in alignment with the mission. Can you elaborate on both of these aspects of the organization? I'm interested to learn more.
The .com address is correct - try it!
&gt;HTTPS in 2018, please. It's in progress.. Unfortunately in 2018 it's still not as easy as flipping a switch. &gt;The contact address at the bottom of the website has a .com domain, instead of the .org domain that the website is on. (There's no website at the .com.) I suspect this email address doesn't go anywhere. That email works just fine :-) We will move emails to the org domain eventually though.
Pretty sure let’s encrypt is dang near turn key if you’re just looking to provide https
https://pybind11.readthedocs.io/en/stable/ 
The site is hosted on GitHub Pages and served with Jekyll ([https://github.com/CPPAlliance/cppalliance.github.io](https://github.com/CPPAlliance/cppalliance.github.io)). It is possible to set up HTTPS and we will certainly do so but there are a couple of things that need attention first, and I didn't want to risk the site being down during the announcement period.
You can use cloudflare for SSL. That’s what I use for my blog
Good lord, they never asked you? When I first looked at that site I thought all you guys where the 'godfathers' and supporters of this project. Thanks for letting us know. Pffff... life these days. 
Github pages automatically supports https, you may need to update your A records to point to the new IP's and remove then add the custom domain in the Github repo settings to force a refresh. 
I don’t know if this falls into making it better but have you thought about using enigma to represent the input type?
It can parse any unambiguous context-free language, but I think with the lexer hack, C should be possible as well. I'm working on a language project that will need to parse C and I'm hopeful I'll be able to use this there!
It can parse any unambiguous context-free language, but I think with the lexer hack, C should be possible as well. I'm working on a language project that will need to parse C and I'm hopeful I'll be able to use this there!
It can parse any unambiguous context-free language, but I think with the lexer hack, C should be possible as well. I'm working on a language project that will need to parse C and I'm hopeful I'll be able to use this there!
It can parse any unambiguous context-free language, but I think with the lexer hack, C should be possible as well. I'm working on a language project that will need to parse C and I'm hopeful I'll be able to use this there.
I like the guideline by Google: only pass by const-ref, never nonconst-ref. If you need an output parameter, pass it as a raw pointer. It seems super weird at the beginning but if you can rely on your entire code base to follow this pattern, it is actually very nice. Just a quick look at the function declaration will tell you all you need and you even get compiler errors if you make a mistake.
I like the guideline by Google: only pass by const-ref, never nonconst-ref. If you need an output parameter, pass it as a raw pointer. It seems super weird at the beginning but if you can rely on your entire code base to follow this pattern, it is actually very nice. Just a quick look at the function declaration will tell you all you need and you even get compiler errors if you make a mistake.
I like the guideline by Google: only pass by const-ref, never nonconst-ref. If you need an output parameter, pass it as a raw pointer. It seems super weird at the beginning but if you can rely on your entire code base to follow this pattern, it is actually very nice. Just a quick look at the function declaration will tell you all you need and you even get compiler errors if you make a mistake.
I like the guideline by Google: only pass by const-ref, never nonconst-ref. If you need an output parameter, pass it as a raw pointer. It seems super weird at the beginning but if you can rely on your entire code base to follow this pattern, it is actually very nice. Just a quick look at the function declaration will tell you all you need and you even get compiler errors if you make a mistake.
I like the guideline by Google: only pass by const-ref, never nonconst-ref. If you need an output parameter, pass it as a raw pointer. It seems super weird at the beginning but if you can rely on your entire code base to follow this pattern, it is actually very nice. Just a quick look at the function declaration will tell you all you need and you even get compiler errors if you make a mistake.
Now if you were to use Discord instead of slack, there would not be server costs at all! 
Now if you were to use Discord instead of slack, there would not be server costs at all! 
Now if you were to use Discord instead of slack, there would not be server costs at all! 
Now if you were to use Discord instead of slack, there would not be server costs at all! 
It can parse any unambiguous context-free language, but I think with the lexer hack, C should be possible as well. I'm working on a language project that will need to parse C and I'm hopeful I'll be able to use this there.
!removehelp
Thank you, I appreciate that.
I like the guideline by Google: only pass by const-ref, never nonconst-ref. If you need an output parameter, pass it as a raw pointer. It seems super weird at the beginning but if you can rely on your entire code base to follow this pattern, it is actually very nice. Just a quick look at the function declaration will tell you all you need and you even get compiler errors if you make a mistake.
The problem of not knowing what might be getting modified largely goes away if you make everything that can be const, const. 
Why not this: 'if you need an output parameter, return it'? And if you have multiple things to return, return a struct containing all the things you need returned. I find this results in incredibly readable code. I hate the raw pointer thing. You need to test whether the pointer is not nullptr, and all those extra asterisks and ampersands just look ugly. 
Have you read the article? This is about having a member function that doesn't need to be a member function (needs no access to private members).
Plus you'll get IPv6 support with CloudFlare. Though you can get IPv6 on GitHub Pages, as long as you're not using HTTPS. [They disabled it for no reason for HTTPS though](https://github.com/isaacs/github/issues/354#issuecomment-385746014) (it works using HTTPS over the old IPv6 space just fine for *.github.io).
I am familiar with C++ and Python. Will I be a good fit?
I was responding very specifically to the general statement that read "cramming member functions into a class has been discouraged for quite some time now because it reflects negatively on code reusability and robustness.", rather than the article. 
You make more calls to move constructors and need assignment operators. For example, I would prefer this: A foo = Initialize(); Process(&amp;foo); over this: A tmp = Initialize(); A foo = Proccess(std::move(tmp)); You don't need to test whether the pointer is null. It's not an optional, it's a reference. I think the ampersand is very nice as it makes it clear to the caller that they are using an output parameter. I understand that working with a pointer all the time can be a bit annoying but overall I think the benefits outweigh this small disadvantage. Moreover, if you really want to you could always do something like this: void func(A* foo_out) { A foo = std::move(*foo_out); // do something with foo_ foo_out = std::move(foo); }
Correct. But in C++ it's at least more idiomatic for a method to mutate the object it operates on (and you could argue that non-const methods are the default semantics). Meanwhile, the default semantics for a function call is to not mutate the passed parameter. Personally I think Rust got it right by requiring passed references to be annotated as such at the call site as well as in the function signature.
Yes, but that makes non-const-ref parameters even more of an unexpected case when they are actually used.
Try Netlify if it is a static site. Setting up HTTPS (and HSTS on top) is really one click.
Why not use [raw string literals](https://en.cppreference.com/w/cpp/language/string_literal) instead? For example: std::string glew_licence = u8R"res(テスト. These are a file's contents.)res";
Does it also support Atom feeds?
&gt; It can parse any unambiguous context-free language While technically true, this is misleading. Combinator based parsers like this can't directly use left-recursive grammars, and you have to manually convert them to non-left-recursive form, which is annoying.
Well, English is not my first language but I'd say ', or' separates the sentence, that is &gt; (double underscore __ followed by an uppercase letter), or (begins with an underscore followed by an uppercase letter), I am not sure what you meant by "followed by" only applies to the part after the "or"? 
&gt; And this is fundamentally wrong in a procedural language like C++ where modifying things in-place is very common, beneficial, and above all -- natural. This is an imperative language so parameters are not fundamentally inputs of a function? Come on! Notwithstanding that some imperative languages do not have output parameters, it's a shame we removed the distinction between functions and procedures, because there is actually a gigantic case for privileging the former. &gt; &gt; In some cases, you can remove the input-output parameters altogether from a function, by transforming the function into a class method. &gt; What is x in x.foo() if not an input-output parameter? Yes, but the syntax is, helpfully, different. And limited to one param. Which can help the programmer to avoid circle-ellipse problems, both by the surface limitation, and seeing that x is special. &gt; Again, C++ is not a pure functional language. And that shall not prevent you from using safer constructs instead of mutating everything without structure, like there is no tomorrow. 
In C++, functions are essentially procedures, it's just how we call them now. I agree that pure functions are great and should be preferred, but the article does not contain a single good example of such a function.
I heard that Thunderbird++17 removed trigraphs tho. 
&gt; but I found that MSVC choked on strings even for resources in the kB range so i submitted a pull request to revert back to an array of bytes instead. Sounds like a bug. Did you happen to make a bug report?
Well, an interesting idea.. So what is the value compared to using a mutex? Also, what do you consider typical use cases for synchronizing function calls (on a per function type basis) instead of synchronizing the actual data access?
What, no SOAP support? 
That goes contrary to the convention that a pointer represents an *optional* parameter. It means the function has the overhead of checking whether the caller passed nullptr, or risk a crash. 
Thank you for sharing. Is the docker and user link deliberately 404? Edit: [Found it](https://hub.docker.com/r/cjdb/amcpp-stdlib/)
Style guides *are* conventions. You only risk a crash if someone breaks your style guide. 
&gt;Do you want to make a lot of money? &amp;#x200B; "**Easy come, easy go, but steady diligence pays off."** I've been working for 20 years on on-line code generation and have not gotten rich -- unless you count [rich in terms of software](https://github.com/Ebenezer-group/onwards). &amp;#x200B;
Hi, I’ve been mainly using vim in the console with a combination of cscope (mainly do C programming). Think it’s worthwhile switching to QT for cpp work?
Not so much a "bug" as an implementation-defined limit. I don't believe the standard guarantees that string literals may be arbitrarily large, although it would be great if MSVC permitted larger strings.
Nope, Photoshop converts each value as needed to match the host data to the file byte order. It is not writing structs blindly. Apparently the author of that piece has very, very little experience with binary file formats. TIFF files can be big endian or little endian. Both byte orders are readable and writable by any host, but the data in the file has to be consistent. Photoshop has the byte order option in TIFF because some poorly written TIFF readers (like certain video titler brands) do not handle both byte orders.
What a great title
I love it and use it everyday. Less clutter, no accidental implicit conversions, consistency (think \`using\`), easy to refactor. In C++14 was not really a thing but with C++17 and copy elision guarantee it is the way to go.
In my company, we tend to use this by default, only not using it if the compiler fails to automatically generate a copy or move constructor (which we then add to the pile of technical debt). We tend to find that it makes the code more readable, but there's quite possibly a level of Stockholm Syndrome in there so all I can say is that I currently like the style, and that in the company I work for we use it ubiquitously. On the assumption that our compiler (recent MSVC) provides full copy elision we _shouldn't_ see any issues from doing this. If there's any problem with copy elision in MSVC it may contribute to some unexplained slowdowns I've been trying to diagnose recently....
I think we all went "full auto" for a while, I know I did. The problem is that you then rely on whatever code completion tool you have to figure out the real type of objects. For something like `auto x = f();`, you better be using a real good name for `f()` or you'll have no idea what `x` is. Nowadays, I try to use `auto` only when I can visually infer the type from the right side, like `foo::create()`, `make_unique()`, `get_widget()`, etc. I also tend to use `auto*` if it's a raw pointer, just to make sure I don't lose that information. I've also stopped "reversing" definitions to use `auto`, like `auto f = std::string();`. They're longer to type, more difficult to parse, and generally useless. I think we're all still learning how to use `auto`.
Completely agreed. Where it's even worse are lambda input parameter auto types (for fixed argument types), where even the IDE can't help you.
The person I was responding to called string a container, not me. If you're trying to make the point that C++ is missing a bunch of functionality to handle sequences, then I agree. I'm not sure what else to take away (not being mean). Obviously I can implement `replace_substring` myself using existing functions. But it will take more than one line, and I see no reason why *I* should do that, instead of the library doing it for me, so I can earn money writing code to handle the unique business logic I need. I'm not sure how `partition` would help. Maybe I don't understand it. Can you give an example? My point is that if people regularly require search and replace with entire substrings, then having the `std::string` class not have "search" and "replace(substring)" or "equals ignore case" APIs leads to wasted time, and poor re-implementations. Heck, I have even often met unsafe re-implementations of wstring&lt;-&gt; string re-encoding, despite it being available (sort of) in non trivial APIs. (Also recently read that it has awkward corner cases and won't always work when you actually need true unicode). 
It is a little bit more than just a style choice. He makes good arguments about maintainability, performance, etc. The code ends up looking dramatically different than legacy C++ applications. So I guess I'm curious about whether that barrier is just too high.
&gt; copy elision guarantee That is the guarantee that the below won't create a temp and then copy it to x? auto x = type { };
I've been writing in this style since roughly 2015, inspired by that video. I also use auto in my function definitions. ie `auto foo(int bar) -&gt; int { ... }` I like it. Yes, it is more characters and a bit more wordy when you end up writing things like `auto foo = int{};`, but it's not been a problem. Yes, it looks weird / unusual, but it really is quite nice. It would be nice to see header file support for this style, and in future versions of C++ I hope the auto keyword can become optional, so this style becomes `foo = int{}`. I highly recommend trying this style, when it does not clash with a preexisting style.
&gt; It would be nice to see header file support for this style, and in future versions of C++ it would be nice if the auto keyword become optional You'd still need to distinguish declaration from assignment. 
I don't use the style when default constructing objects. string str is less typing than auto str = string{}
I just started writing C++ coming from other languages and I've decided to use `auto` for everything except new initializations such as `int x = 2;` or `std::vector&lt;int&gt; a;`.
Thanks for notifying me. Link fixed.
I haven't done a conversion of existing code, but I have started using it for new code where it improves readability. This is primarily: - factory functions which return an instance of known type, e.g. `std::make_shared`; no need to duplicate the type information twice - return values where the type is irrelevant, e.g. iterators returned by `begin()` and `end()` - range-based for loops - templated code where the type isn't known or is hard/verbose to deduce I don't use it for construction of types where it is more verbose and slightly less readable. And I try to avoid excessive use which could lead to confusion over what the real type might be. I think there's a happy medium between verbose typing and "full auto" which maximises readability and maintainability, but I think many of us are still working on finding exactly where that point truly is.
I think this overlooks the importance of private property(closed source) for a healthy society. 
In some cases, `auto` can result in hard-to-debug problems. For example, see [this](https://eigen.tuxfamily.org/dox/TopicPitfalls.html) recommendation regarding Eigen library. Other similar libraries also suffer from this issue.
Agreed. I don't want to lose the syntactic separation of declaration and assignment
If you want to pretend you're in a functional-inspired language, you can always do `#define let auto`.
 #define while(x) if( 0 &amp;&amp; x ) //optimization &amp;#x200B;
We don't use auto unless the type is obvious from the RHS of the assignment.
Yeah, I find that it a bit unfortunate as well.
Exactly. I mean, compillers has been elliding the copy since forever, but since C++17 they are know required to do it.
We don't follow it. He makes. a good argument for not repeating types (`auto x = std::make_unique&lt;Foo&gt;()`) and omitting the (exact) type where it is of no interest (`auto it = x.begin()`), so this is where we also use auto in our code. However, I don't think he makes a good argument for enforcing this style at places, where it just adds noise ( `auto foo = std::string{}` vs `std::string foo{}` or obscures important type information (if something is an **unsigned** int I want to know). Consistency is a nice property but not always the most important one. 
I also went full auto for a while. Problem was, my IDE (CLion) does not understand `auto`, especially in a loop: auto vec = std::vector&lt;some_struct&gt;{}; for(const auto&amp; item : vec) { // do things } CLion wouldn't tell me about any of the members of the struct inside the loop. Bleh. Now I mostly use it for iterators, e.g. `auto itr = vec.rbegin();`. Life has been much better since I switched
I like that it emphasizes the function of objects (what you can do with it) rather than the shape (storage type) of the objects. I've found it makes it much easier to evolve and refactor the code over time. I use Visual Studio and haven't had problems with type info. In business logic functions I think this is most useful, if you find yourself default-initializing a string then that tells me you have to do some work to get a meaningful value inside it, and that work should be encapsulated into its own function... where "string retval;" vs. "auto retval = string{};" is not a very interesting discussion. But since I always forget how the most vexing parse works, I just choose the latter to keep it simple.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9ea7qv/struggling_with_pointers_please_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Is that still the case? I swear I get correct type hints now. 
&gt; Then there's GLM, where slerp() is shortest-path and lerp() isn't. I'm sorry, but I truly feel like you are out of your depth in some manner due to this statement (among others). lerp stands for "linear interpolation"; it should be used for interpolating vectors and never be used for interpolating rotations, which can never be sanely linearly interpolated no matter what representation you're using, because at the heart of it, *rotations do not form a vector space*. GLM's lerp might work on quaternions, but that is merely a low-level function not intended for interpolating rotations. It doesn't even return a unit quaternion - proof of it not being for interpolation. These words (lerp/slerp) have precise, commonly accepted definitions, and you're throwing them to the wind.
I'd say that's an example of where the type is obvious from the right-have expression.
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9eapwp/setting_string_string/e5nid9c/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You can create your own serializer and possibly implement transport. Perhaps the your solution will be based on the example of https://github.com/tdv/nanorpc#pure-core
Some of the examples in the early discussion are completely wrong AFAICT: &amp;#x200B; \&gt; for example, the following is a valid syntax for creating and initializing an array of int: \&gt; \`int b { 1, 2, 3, 4, 5 };\` &amp;#x200B; No.. &amp;#x200B; \&gt; For example, the following two loops are similar: \&gt; \`for (int i : v)\` \[snip\] &amp;#x200B; Also no..? &amp;#x200B; The rest of the article is pretty interesting, I wasn't aware of mutation testing at all before this. Thanks for sharing!
&gt; That’s because the type (const char *) satisfies the syntactic requirements of this function (it has an operator&lt;&lt;), but some of its values violate the semantic requirements of this function (they cannot be printed) well, that's why we have contracts, right ? 
Well, it's a proposal that hasn't been accepted and/or implemented in the compilers yet. There is no performance difference now, but the code is harder to support.
It's interesting: at our work we're moving towards Herb's Almost Always Auto. We find that when there is an objection to auto, the objection tends to highlight another underlying problem. Bad variable or function names hiding intent; God objects and general violations of the Single Responsibility Principle making it hard to reason about the "contact" you expect from the inferred type; etc. We've started thinking of auto as a code smell amplifier. Also, though this is off topic, we've started wondering if agile methodologies are the same: objections to it tend to imply an issue elsewhere, a code smell amplifier for process...? That's a half formed thought though :)
[My little baby is all grown up and... *Sniff*... getting coroutines and modules](https://imgur.com/gallery/fOkFs3I)
With QtCreator it works fine in this case
This has already been posted 2 months ago.
The point here is that something is being lost. If we use pointers for both optional and non-optional out-parameters, then we have no way to express which out-parameters are optional. The style guide can't help much. It can say they are all optional, or none of them are, or leave it as case-by-case. All of which choices are problematic. The first choice adds overheads for the checks. The second choice adds overheads for calculating out-parameters which are not needed. The third choice leads to confusion and crashes.
One reason I really like Herb's suggestion, is that it makes finding the name much easier. Especially when the type name and constructor arg list is really long, it's sometimes a pain to find the variable name. Using mostly auto makes it much easier, and it naturally aligns all the declarations. auto x = dynamic_matrix&lt;double, 2, 2&gt;(begin, end); auto y = std::vector&lt;int&gt;(10); vs dynamic_matrix&lt;double, 2, 2&gt; x(begin, end); std::vector&lt;int&gt; y(10);
My employer has a fairly strict rule forbidding `auto` in shared code. The only exception is for unutterable types. This is partly because we have had bugs caused by `auto x = y();` due to the type returned by `y()` not being what was expected. It's simply too dangerous to start using in our codebase. We also feel the code is more readable with the types manifest. It saves second-guessing the type deduction, or having to ask the IDE what is going on. We're not too bothered about verbosity. Frankly, a lot of uses of `auto` look like laziness. It won't kill you to write out the name of the iterator.
I would say yes, definitely. My productivity increased by a lot by switching from bare vim + plugins to QtCreator + fakevim. Expecially useful for example is the Ctrl+K search bar and all of its modes.
@u/dpilger26 I've not used NumPy much, but it came up in a Neural Network course I was taking, before long they talked about how its ability to vectorize the code was critical to the performance. (which is why they chose NumPy) &amp;#x200B; From the little I've read and from what I can tell, you are using standard STL calls to implement the underlying operations and your not using any OPenMP or SIMD intrinsics to speed up the operations &amp;#x200B; This library looks like it could really be an excellent test bed for parallel STL as it could be used to demonstrate how parallel STL could bring a performance improvement to an existing STL implementation, I think that would be an excellent future experiment. &amp;#x200B; Despite all the other suggestions of why didn't you use XXX (all of which are reasonable arguments), I think there is always something elegant of seeing API compatible cross technology libraries, Nice job. &amp;#x200B;
In your case, why not use an interface? 
That brings me to a question I had for some time now. Do concepts allow me top specify a requires consider in terms of function parameters? something like (I'm not very familiar with the syntax yet): template&lt;class T, class U&gt; bool foo(const T&amp; l, const U&amp; r) requires requires { l.bar(r); } { ... } 
Luckily there is std::optional or something similar in most modern code bases, so that ambiguity falls away. Usage of raw pointers as optional parameters has been discouraged with our without this "pointers as out parameters" pattern. 
Not only that but twice already!
Btw, there is trick I liked from the same guy [1] similar to what `boost::hof::first_of()` does: ``` template&lt;typename T&gt; auto stringify_impl(const T&amp; x, priority_tag&lt;2&gt;) -&gt; decltype(x.stringify()) { return x.stringify(); } template&lt;typename T&gt; auto stringify_impl(const T&amp; x, priority_tag&lt;1&gt;) -&gt; decltype(std::to_string(x)) { return std::to_string(x); } template&lt;typename T&gt; auto stringify_impl(const T&amp; x, priority_tag&lt;0&gt;) -&gt; decltype(static_cast&lt;std::ostringstream&amp;&gt;(std::ostringstream() &lt;&lt; x).str()) { std::ostringstream s; s &lt;&lt; x; return std::move(s).str(); } template&lt;typename T&gt; auto stringify(const T&amp; x) { return stringify_impl(x, priority_tag&lt;2&gt;()); } ``` While `boost::hof::first_of()` is more general solution, `priority_tag&lt;&gt;` can be used for quick prototyping or if you don't have boost::* dependency [1] CppCon 2017: Arthur O'Dwyer "A Soupçon of SFINAE": https://youtu.be/ybaE9qlhHvw?t=56m36s 
iterators are the prime object to use auto on, for me. You lose no valuable information by not exactly knowing the excruciatingly uninteresting string of type information of an iterator to an object that with all probably you can get the type of by checking the container the iterator has been initialized from. It let's you focus on the fact that, e.g., you're going through all elements of container in this loop instead of the boilerplate cpp demands.
Would still prefer Concept auto x = f(); Nice to get that extra visual cue that this isn't a type and two things declared `Concept auto aren't necessarily, but could be, the same type. YAACD makes this extra `auto` optional, which at least means it's possible to use.
&gt; I think we're all still learning how to use `auto`. It's interesting, my background is C++ but I moved over to C# some years ago (I still like to dabble, of course). In C# land, it has the `var` keyword which is synonymous with C++'s `auto`. From a lot of the discussions here, the main arguments against `auto` seem to mostly revolve around how the IDE can cope with it (i.e. determine the resulting type), how that makes debugging difficult and so on. In .net land this is a non-issue, there's almost never any ambiguity and every IDE I've used has been able to tell me type information on hover 99% of the time. There are exceptions, of course, but that's when you explicitly define the type. The general consensus is that `var` everywhere is a good thing as it enhances readability and makes refactoring much easier. I find this interesting as the language construct is almost identical across both, yet usage is different based entirely on how good the tooling around it is. I think it's less that we're still learning how to use `auto` and more we're waiting for the tooling to catch up and actually make it as useful as it can be. Until then, I think it very much boils down to _it depends_.
C++ is significantly more difficult to parse than C# and as a result tooling for it tends to be a lot worse.
I meant abstract classes. And what do you mean by duck typing? 
If the type is that verbose, the container should have a typedef. MyContainer::iterator really isn't that bad.
what the fuck
&gt; Do concepts allow me top specify a requires consider in terms of function parameters? Yes. https://godbolt.org/z/PqugPF
I don't disagree with that at all, in fact I very much agree with it. It'll take time but eventually the tooling will improve and I suspect people's usage will change as a result.
`std::unordered_map&lt;KeyType, ValueType&gt;::const_iterator` is pretty bad, though.
Following Herb's methodology. He highlights two primary use cases. One where you want to track whatever type is returned, even when it changes. and one where you want to stick or commit to the type that you expect to use. auto x = y(); // Use when you want to track the type from y() auto x = type { y() }; // When you want to commit to a type The former a situation where you're developing against an "interface" while the latter is when you're developing against an implementation. It seems like the bugs you are running into are related to tracking the type but developing against an implementation. I actually think that is a good argument for using this syntax. If you use the 'commit' auto syntax then your intention is clear in what you mean versus the other syntax which suggests a more generic approach. 
How could it not be, unless you're a top 1% C++ wizard already? I'd have no idea why that move needed to be there or what that's doing, and even if I knew now, I'd not remember if I look at this code in 3 weeks, unless there was a comment in the code there, documenting it. I'd bet many, if not most coworkers are in the same situation. And the best code is code that is clear without needing documentation.
Good to know. I had sort of been operating under the assumption that this was already true but it is good to know we have a guarantee and not a just a probable compiler optimization.
"If it looks, walk etc like a duck, it is a duck" That is, if the type have the interface we require, then whatever the type, we can use it. That's how templates work, but at compile-time. Python, Javascript and Ruby do that too implicitly but at runtime. Here using concepts means restricting compilation to only types that match the interface and behavior we expect. We don't compile otherwise. Also we don't constrain that type to know about or inherit from (aka have strong dependency on) a type we have declared. That's what would allow you for example to use an optional type whatever the library providing them as long as the basic manipulations you're doing can compile. Concepts here just help with checking what you allow or not (instead of discovering what you want to do with the object by failing to compile).
TypeScript is my favourite language (and I only got in contact with it in 2016) but if you've used it you can literally see through this video how much the guys at microsoft are inspired by modern C++ for their typing system, and how much these languages typing systems collide (even though one compiles to machine code and the other to javascript). Obviously the whole part about pointers is unique to C++ compared to TypeScript but the rest is very similar. I work mostly with java and most of the time it feels stupid both to write and read because of having the type show up both on the left and the right.
Not op but I didn't think C++ had interfaces in the same way Java (for example) does Duck typing is an approach to polymorphism where you assume that if a function or method exists with the name you expect, it does the thing you expect - i.e. if it quacks like a duck, it must be a duck
"Write code for humans first, compilers second". If not using auto improves readability, don't use auto.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9eefod/looking_for_c_book_recommend_me_a_one_with_a_lot/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
IMO, more problematic than this being posted three (or whatever number of) times is the lack of progress it represents, at least in some areas. Just for example, consider Henry Miller's comment that start with: "I’ve been thinking about fragmentation. The only reason you cannot defragment C++ memory today is someone might send a pointer to someplace not trackable as a pointer." Unfortunately, he's wrong. This is *far* from being the only problem you need to deal with, and probably not even the most difficult one. The specific difficulties involved bother me less than the fact that the real difficulties have been known for quite a while, and every time subjects like this arise, we seem to need to re-discover them from basic principles, so to speak. In this case, part of the blame lies with Google--if they hadn't completely broken searching for Google Groups, it would have been a whole lot easier for him to find a thread from comp.std.c++ that started out as: "C++/CLI - Microsoft Persists With Suggestive Marketing", but morphed into "Can GC be Beneficial", that happened through roughly the first quarter of 2006: https://groups.google.com/forum/#!topic/comp.lang.c++.moderated/hCU9N_lw3Ss%5B1-25%5D I'll grant there's a lot of noise there as well--it included some argumentation, so the signal to noise ratio sometimes dropped pretty badly, and sorting through ~900 posts to find the few that attempt to really deal with the problems isn't trivial. Nonetheless, I think we need to work harder at making such knowledge more generally available, so it doesn't have to get re-invented every time.
Wait... Really? Ugghhhh
That only holds if the variable names are the same length.
No. Because where the name starts is what matters.
This is one of the reasons I really hate Eigen. Modern libraries that were developed with modern C++ on mind shouldn't have such issue. For example Blaze works perfectly fine. It just shows Eigen is outdated.
&gt; no accidental implicit conversions Hmm... This is a bit orthogonal: we shouldn't have to commit to `auto` just to solve a problem with implicit conversions, to be honest. C++ should have had a way to disable implicit conversions easily way before `auto` came to be a thing. Regardless of that, I feel implicit conversions are not really an issue in big code bases which use mostly user-defined classes.
Ah, I see what you mean. Yes, it is an improvement for names, but a disadvantage for the types' alignment. Anyway, you can either use an IDE that highlights someone the type or name; or you can use a tool like `clang-format` to align things automatically. Don't get me wrong, I actually like the `let x = T` or `x : T` style of many other languages, but I think the big discussion about `auto` is about the type deduction, not the swapping of name/type in declarations.
Actually one of Herb's talking point was that using auto everywhere simplifies the way we read the code. So I think swapping the name and type is relevant. And I also want to add, I think it's a good ide a.
Well said! I find that excessive use of auto makes my own code easier to read, but makes other people's code more difficult to read
Interfaces can have a runtime cost. And vector::iterator and list::iterator don't derive from the same interface. But they have many of the same functions and operations (like ++) and thus _look_ like the same interface - that's duck typing (as other answers mention). for (...) { auto it = container.begin(); auto itmid = it + container.size()/2; // ** ... } That `itmid` calculation is making an assumption about the iterator interface. And is probably hoping that `operator+(int)` is O(1) not O(n). (ie for a list it would need to be O(n)) So for (...) { RandomAccessIterator it = container.begin(); auto itmid = it + container.size()/2; // ** ... } would probably help guarantee that your algorithm doesn't go from O(n) to O(n^2) accidentally, because someone changed the container. For example.
Sure you can do extra work to solve the problem but the point he (and Herb) make are that auto takes care of this for you without that extra work.
I guess I should have put some reasoning in my post. My intention was to get the community to list off the more common errors (for beginners or not) you encounter with the language and I was going to be drawing up some charts purely out of my own interest. I understand it's not meaningfully useful in terms of understanding the errors. I was genuinely just curious what the community thought of.
Intel compiler says: "Error 3" on a trivial example. Literally 3 lines of code that should work but don't. Literally that, nothing else. Send repro to Intel, "we'll fix it in next release". Several \*months\* pass. It's fixed. You compile, and now get some other "Error 3"-type message. Rinse, repeat.
Removed as duplicate. (Also, links should be posted as links instead of text posts, /u/karburator9 .)
And it was answered already many times. Basically the same situation as with `noexcept(noexcept(...))`.
I'm certain that `requires (` or `requires {` would disambiguate `requires` in a function's prototype. E.g.: template&lt;typename T, typename U&gt; bool foo(const T&amp; l, const U&amp; r) requires { l.bar(r); } { return true; } That `requires {` can't be ambiguous. The consistence argument doesn't make up with this `requires requires` weirdness.
Are there people who suggest using auto for lambda parameters when you don't intend to use the lambda generically?
I don't know about other tools, but I think that Visual Studio is already there. I don't use auto everywhere, but I regularly hover expressions to figure out the type.
I agree, especially since outside Boost and the standard library, it's common to use Pascal case for all UDTs. I wonder if concepts will make snake case for types more popular...
Please try to make your points without being unnecessarily hostile.
Easy ones, like those resulting from mismatched/missing braces and parentheses. Definition errors, when adding a new file, and maybe getting some includes wrong. Similarly, linking errors when adding a new library and getting some of the links wrong. Cousins of those would be incompatible library versions meaning that I used functions/constants that weren't defined in the old library, or that were changed in the new one. For linking, library bitness. Index out-of-range accesses. Hopefully the program seg faults. If it doesn't, you can have a subtle error for a long time. I'm fond of deriving a `rangecheckvector` class that implements `operator[]` with `::at()`. Being pretty common, those are all pretty easy to fix. Definition errors and out-of-range tend to be the ones that take a bit of thought.
Why not save some pain and money and use an open source compiler?
Certain loop optimization, instruction selection/scheduling, and parallelization features may be superior on Intel's compiler.
variable X not declared in this scope.
you can ban me or not, but warnings have no effect on my behavior.
develop on clang, release on icc
Your library encourages to `#include &lt;json.hpp&gt;` while it should be `#include &lt;nlohmann/json.hpp&gt;` to avoid pasting library directly into main library path like `/usr/include`. Move few parent comments up.
Without having looked at the proposal I have a very good idea what it would probably tell me and I find the code to be extremely obvious. Specifying on which kinds of references a method works really isn't something new and for understanding this particular example a basic understanding of lvalues and rvalues should really be sufficient.
Mainly because of the optimizations which, if you don't mess with C++ too much and just do numerics, work really well (when they do work). Intel's done a lot of work in this regard, and provided you use a 'very stable subset' of all those compiler optimization flags, you can get code that's impossible to get with MSVC. Also for historic reasons related to the era when the Xeon Phi was actually a separate PCI card rather than a processor. And yes I bought lots of the bottom-end Phi cards when they were selling them off at $200 a pop. Did you know you can watercool them? So anyways, you can only compile for a Phi if you have the Intel compiler so there's that. Feature-wise, the Intel compiler is pretty bad as you can imagine, but you get support from Intel, woo-hoo. Sorry, too much sarcasm, it's like eating a cactus, really, it stings you but you keep on eating it regardless. If Intel makes some Altera-related compiler solution, that would get us in deep even more, I fear.
I don't think anyone suggests it, but let me tell you if the coding guidelines don't prohibit this, the AAA people will use auto parameters for almost all the lambdas... At least that's my experience so far. Another case against against using auto is that it makes larger refactorings harder. E.g. if you want to use for the usage of a certain type all over your codebase.
Why aren't people just using IRC anyhow? i don't get why a bunch of programmers want to use some commercial, proprietary chat system.
&gt; For example Blaze works perfectly fine Could you provide any links? Because documentation says you have to use `evaluate()` for auto to deduce type correctly. 
I am on 2017 (15.9.0 Preview 1.0).
Sorry, one more question. I've noticed that in fakevim, ctrl + ] works as far as going to a definition, but ctrl + t doesn't seem to always go back. Did you end up sticking with the vim + ctags way of navigation or did you switch to F2 to go to a definition and alt + left to go back? Or is there an entirely different way that I'm missing? Thanks again
Agreed. The committee needs to leave this pedantry behind in order to evolve the language in a way that users don’t find repulsive!
I think Reddit's 'warning list' needs to be reviewed. I think everyone learns in a different way. I think these discouraged youtube channels might very well be helpful to some people going into programming. But hey what do I know? I'm just a single person that has some opinions...
Despite that style, his videos are incredibly helpful for understanding C++. They were very helpful for me.
Well, learnprogramming mods also "banned" thenewboston over petty things such as variable naming in his Java tutorials, i.e. naming variables "bucky", "tuna" and "beef" instead of proper naming such as "databaseInstanceConnectorValidatorFactory". Because of course that's what matters in a hello world example that shows assignment and multiplication to absolute beginners - proper variable naming. TNB was the channel that introduced me to C++ and made his lessons entertaining enough so that I didn't fall asleep halfway through, that's why I'm kind of mad at this decision - one moderator doesn't like a channel and imposes his view on everyone by making a bot that discourages people from recommending TNB (or in your case, TheChernoProject), thereby scaring people off from good content. And because it was so entertaining, I stuck with it and learned on my own, if he had come off at me with "okay this is how you properly name your variables" I don't think I'd be a programmer today. So my advice is: Take advice from /r/learnprogramming with a grain of salt. A lot of advice on there is the blind leading the blind, advice based on hearsay and rumor. Start thinking for yourself instead of just following recommendations - in your case, I wouldn't give a f*** about what learnprogramming says or not, the important question is if *you* understood the video; nothing else matters. These tutorials also aren't supposed to teach you everything, don't expect to watch a 20 minute YouTube video and be an expert on the topic. I think that's where /r/learnprogramming gets it wrong - these videos give more or less give you the keywords to google for, not the 100% accurate explanation.
What he said is still true. Member functions that take this by r-value are not in most examples and I suspect most C++ programmers would be confused by them ("how can it be safe to move out of something while calling a method on it?").
Evaluate is used in case for evaluating expression templates. Eigen simply doesn't work with auto for trivially constructing types. That's what I meant.
Emoji, device notifications, apps for smartphones and tablets, consistent cross-platform experience, integrations, voice calling, to name a few reasons.
Emoji - a reason not to use it Device notificatiosn - I get those on irc. Apps for smartphone.. those notifications.. I get them on my smartphone. consistently bad xplatform expreience. voice calling - ... on my mobile? I kinda get that already. Doesn't sound like very good reasons.
And having some idea of what stuff does will help because the documentation can be hard to read as it is often too precise for a beginner.
Wouldn't an arbitrary increase of an `InputIterator` simply refuse to compile in your first case? [CppReference](https://en.cppreference.com/w/cpp/named_req/InputIterator) doesn't list arbitrary increment as an allowed function.
For a course that was published in 2017 he is surprisingly unaware of modern C++ features. The pointer lecture starts with "void\*" and using ampersand to take addresses, and towards the end he is throwing "char\*\*" around. I'm sorry, but this guy is a memory leak waiting to happen. The clean way to learn to program C++ is with smart pointers. Ok, they are in lesson 44. I give it a thumbs down.
I’m not pro either option, but there are many reasons to not want to give out my personal phone number. Are you honestly suggesting that is a good option?
Honestly I think all the C++ smart pointer stuff not worth teaching someone is just learning. It's important to understand what real pointers are and their dangers before teaching the safer abstractions. 
This was exactly what i needed. You're absolutely right i always try to find the best source or the best recommendation when all i really need is to understand the concepts and do research myself.
I really like Cherno's videos. Shure they may not be the be all end all of learning C++, but his videos are informative and worth watching if you are a beginner. 
Yup. std::list doesn't have operator+(int): std::vector&lt;int&gt; vec = {0,1,2,3,4,5,6}; std::list&lt;int&gt; list = {0,1,2,3,4,5,6}; auto vec_it = std::begin(vec) + (vec.size()/2); // compiles fine std::cout &lt;&lt; *vec_it &lt;&lt;'\n'; auto list_it = std::begin(list) + (list.size()/2); // compile time error std::cout &lt;&lt; *list_it &lt;&lt;'\n';
IMHO some of his videos are great. they explain things exactly the way you probably need them for your course &amp;#x200B; There are some caveats to some of his courses - but nothing that will affect you negatively. You should be approaching material from many different directions - there is nothing inheririntly bad about Cherno's lessons
I’ve been watching some of his videos and they’ve helped me understand some concepts I wasn’t too sure about. I also watch some courses from Udemy, the material I’m giving in class (I’m taking my 3rd C++ class) and I started to read the primer from Lippman/Lajoie (and I LOVE it!).
I meant in the case where it only met the requirements of `InputIterator` (and nothing else). My comment was more about the fact that you won't get O(n^2), because it wouldn't compile in the first place.
No. No. No. Safety should not be taught after the unsafe things. Teach the common use cases first, because they give context for understanding when to choose one approach over another.
Absolutely. Give a motivation for pointers (not the crap that's in his lecture) and show how to do it with shared or unique pointers. Bare pointers only for non-owning passing.
&gt;you won't get O(n2), because it wouldn't compile in the first place. What would make a such guarantee with `InputIterator`? I don't really get your point.
I recommend joining his discord if you have any questions. There are channels for lots of different languages and if you are stuck on something its pretty easy to get people to help you out.
I think this says something about the quality of the videos: https://youtu.be/oEx5vGNFrLk?t=165
Right, an InputIterator (like list's) would just not compile. But, like templates pre-concepts, you get don't get the best error message. With concepts you at least get the _potential_ for better error messages. Additionally, some other custom container might decide to implement `+`, and still not be a RandomAccessInterator. Then you get N^2. (Of course they could implement + and also claim to be RandomAccess, but that'd just be wrong.)
Like Bjarne says, people thought they'd want to type `struct Foo x = f();` as well, but no one does.
I don't really think that "People thought they wanted X syntax, but they didn't" is a good argument against any other syntax that anybody will every consider introducing again. In particular, I think the argument in favor of `Concept auto x = f()` is substantially stronger than the argument in favor of `struct Foo x = f()`;
Would there be a way with Concepts to check that you are not lying and the execution time is O(1) for a fake RandomAccess? 
What does is say?
As a beginner smart pointers are way more confusing and scary if you dont even know what a pointer even is. I think its fine as long as you say that in a real program you wouldnt do it this way before teaching pointers.
I have been following his game engine series to learn opengl and I think it is extremely valuable, he explains things very well. I cant speak to his C++ series but I think he’s a great teacher.
My biggest turnoff as far as Cherno is concerned is his insistence on telling viewers that C++ does not have types... what!
#define rreeqquuiirreess requires required
I enjoyed watching some of the videos. But i also found some problems. For example in the type punning and/or the casting lessons he just plain run into undefined behaviour doing casts which are not allowed by the standard rules. The problem is: i was aware of some of these things beforehand and could tell: ok now this is wrong. Others may not and think: oh well thats the way i will do it in the future. And thats bad. On the other side, coming around the corner with undefined behavior in a beginners tutorial may disturb some people. So mh. I would say watch it if you enjoy. But dont "belive" that things you see/learned are the only (valid) way to do something. If you are interested, do further research. I think its best to use different resources to learn something. This way you get different explanations and different views to problems and solutions.
The issue is that a requires expression can have an optional parameter list. template&lt;int I&gt; void f() requires (bool(I)) { I + 1; }; Is `(bool(I))` the constraint and `{I + 1; }` the function body? Or is `(bool(I))` the requires-expression parameter and `{I + 1; }` the constraint?
I ended up using F2 and Ctrl+K + :, find usages, and alt+left to navigate between symbols.
**Company:** Klebert Engineering **Type:** full time **Description:** Klebert Engineering - is a small and experienced team that helps customers to build digital maps for infotainment and self-driving cars - provides technical expertise and develops visualization and analysis tools - works together with the [NDS Association](https://nds-association.org/) - a consortium of leading car manufactures, application developers and map suppliers - utilizes agile methodologies, a digital Scrumboard, Git and continuous integration for day to day work - offers very good working conditions and a flexible workspace Feel free to apply when you - want to think about topics like digital maps for self-driving cars or efficient 3d visualization of roads and cities - are interested in engineering requirements, thinking about good designs and providing high-quality implementations - enjoy working in a team, which prefers direct communication instead of complex processes - are neither afraid of embedded devices (like Raspberry Pi) nor of cloud computing ... and last but not least you should have a good sense of humor and be open to also discuss non work-related topics at the lunch table ;) **Technologies:** C, C++11, QML/JavaScript, Qt5, SQLite, Docker, AWS **Location:** Munich, Germany **Remote:** Unlikely **Visa Sponsorship:** We prefer candidates who are already permitted to work in the European Union but we are open for discussion. **Contact:** [jobs@klebert-engineering.com](mailto:jobs@klebert-engineering.com), [http://www.klebert-engineering.com/](http://www.klebert-engineering.com/) or [https://www.linkedin.com/company/klebert-engineering](https://www.linkedin.com/company/klebert-engineering)
&gt;https://youtu.be/oEx5vGNFrLk?t=165 The timing part is okay, he seemingly makes some mistakes later on (the timer class for example stores too much data, or "std::endl is slow for some reason" -- he should explain quickly why it's slow), but in general it's not bad.
I don't see what the fuss is. For example, operator &lt;&lt; (const char *)nullptr should simply print "". 
TIL using a mutex provided implicitly by the language is better than using a mutex of my own. Big yawn, really. And not something that any sane code base would have.
Last time I checked on godbolt, the Intel compiler would happily do the signed-overflow-is-UB optimisation for both signed _and_ unsigned values. You may want to check if that additional performance doesn't come at the cost of standard compliance.
Doesn't help if it's not compiling...
Source?
Might be a poor way of trying to convey all program data is just bits/bytes being interpreted as a type? Alluding to how char is often used for misc 8 bit data or how you can do things like `reinterpret_cast`. Maybe in context it's clearer what is meant by that. For a beginner, types, casting, and relating things might just seem like magic under the hood.
Chernos videos are really good for explaining stuff that other tutorials seem to take for granted, like the stuff you mentioned with the linker and compiler. The problem is that they're short and fast and skip over the nitty gritty bits, so you really can't use them for much more than a taster. 
I am using Vim and YouCompleteMe for completions and browsing a codebase. As long as it is set up correctly (it needs to know the flags your compiler uses to compile your file) it can tell what type it is.
No they really are not. They're only confusing if you teach them badly - ie, teaching them as a contrast to pointers, instead of teaching them as their own thing. I've witnessed too many people "teach" smart pointers by telling beginners about the horror stories with pointers. &amp;#x200B; Just stop dragging in all the mental baggage of raw points when teaching smart pointers in the first place. They're only "smart" to those of us who have used C++ before smart pointers. Someone with no concept of the horrors of pointers would not find smart pointers smart at all. And if you start teaching C++ from the ampersand reference end of the spectrum, it's even easier to ease them into smart pointers.
So, I guess the problem is that a reference (which T gets deduced to in the second case) isn't an integral type? 
Interesting fact. It works not because there is an optimization required, but because copy/move isn't even needed due to new semantics of how objects get materialized from prvalue expressions.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9elwo1/good_recent_20172018_book_about_c_ideally_gamedev/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
https://stackoverflow.com/a/42612438
Why? In fact I'd argue they are simpler, they behave like every other object such as float i.e. create and forget. Every thing you have to do with smart pointers you also need to do with raw pointers, and then some. Yes the create method is more involved than float, but is equally as complex as creating a ptr.
Could this be indicative of how they work at EA where he is employed?
Looking forward to a good explanation of this one.
Extra work?
Yeah exactly, it would need to be `is_integral_v&lt;remove_reference_t&lt;T&gt;&gt;`
All compilers did the optimization, but since C++17 it happens at the language level. This means that in C++17 you can `auto x = type();` even if the type is non-copyable non-moveable - this was not possible previously.
- undefined reference to... - multiple referenes to... - skipping library because it's not compatible - library/linkable object not found in provided paths
/r/learnprogramming also banned learncpp.com. It has it's flaws but I havent found any better text-based tutorial.
It shouldn't require top 1% C++ wizard to know std move doesn't mutate. There is even a simple rule to follow: the last time you use any local variable move it (unless returning it directly). You don't need to know if there is already an optimization. 
Possibly true, and it could be indicative of any C++ coder in the games industry now, who are slowly learning the C++ isn't solving the problems that it set out to solve, mainly "Code reusability &amp; Encapsulation". Which once you work on a large C++ project, you soon find that none of the code is reusable, and the encapsulation was just a lie as every programmer just ends up exposing all the innards of their data structures just to the program to work correctly. Object oriented programming is also causing problem in the high-performance computing domain (such as games), as it is a terrible way to structure data for the most efficient CPU use, so C++ actually ends up causing problems in that area.
Smart pointers are just one of many ways of managing memory. You can't understand what smart pointers are until you understand pointers. Any programmer will need to understand char\*\*, because it will be used in program code they have to work on. How are you going to create a DX12 device if you don't know what \*\* does? [https://docs.microsoft.com/en-us/windows/desktop/api/D3D12/nf-d3d12-d3d12createdevice](https://docs.microsoft.com/en-us/windows/desktop/api/D3D12/nf-d3d12-d3d12createdevice) &amp;#x200B;
How is the inner state machine supposed to know that "Fault" is supposed to be a state in an enclosing state machine and not a state of its own? All the states you specify in the transition table will be instantiated as states of the state machine. So yes, the inner Fault is a completely different one than the top-level Fault. They're not even copies of each other. They're distinct states. If you want to transition to Fault in the outer state machine, then you have to specify a stateB -&gt; Fault transition outside. If you only want to have a B2 -&gt; Fault transition, you'll probably need a exit pseudo-state in between.
Shouldn't it segfault or print something like (null) to match behavior with printf? 
The `requires` grammar should dictate that an opening parentheses is the requires-clause parameter. Sounds rather trivial. It's like how an opening parentheses after `[]` indicates the lambda's parameter list.
Yes, there are legacy APIs with multiple stars. But for all other purposes you have a choice and then you should learn the safe mechanism first.
You're simply not going to be a DX12/Vulkan programmer at the level where you are learning what pointers are.
Is interface still considered modern? To me it feels more, um, classic, than modern.
In most cases, lambdas are not the way to go (at least, not in my projects). Let's say you want to want to define a set of methods an object must implement in order to be a string. You could do that with lambdas / \`std::function\`, buuut... :\\
Can we just get sum types and pattern matching sometime before we all retire?
I was pleasantly surprised by the capability of boost::hof, assuming that using external headers isn't a deal breaker for you (and that you're using a relatively new compiler).
Maybe the string example was confusing. Concepts are compile-time. Interfaces are validated on runtime. In other words, you can't use concepts for non-template functions. 
&gt; the C/C++ community of the common errors that you come across when using the language There is no language called ["C/C++"](http://www.stroustrup.com/bs_faq.html#C-slash)
In this case I'm using the term to group the two communities together, because I care about the opinions of both communities. Please keep the comments on topic.
DX12 is Microsoft's cutting edge graphics API, i doubt they would call it "legacy". But either way, legacy API's are part of the job of being a programmer, so you have to understand ALL the ways to program, the good and the bad, especially the bad.
Using auto is a bad idea. I (almost) never use auto. The C++ type system is the essential feature of C++. Properly used, it's the single most useful feature contributing to program correctness. It guarantees that the type of the result you want/expect is in fact the type you get. Implicit conversion is also a great idea - again only of properly used. To some extent implicit conversions can be used to work around/override the guarantees provide by the C++ type system. So it merits a lot of thought. Never use auto - unless there is no other way. &amp;#x200B;
Yeah, conventional OOP paradigms as we've been taught them do *not* work well for high performance use cases. I'm dealing with this now; I'm restructuring a 25 year old C++ simulation engine to be more performant and modern, and one of the first things to deal with was the old structure. Moving to a limited ECS-like structure now (limited mostly cus our entity count will remain small, and because I can't implement a full ECS structure alone lol), which is definitely going to help better capture the premise of encapsulation and code reuse. Combine with some heavy C++17 use and TMP techniques and things are looking pretty spiffy, honestly
&gt;In Objekt Orientation &gt; &gt;Bevor I write in the next post Thanks. I already fixed both typos. To be honest, in German I often use the English expression before. That is too much for my brain. 
it would still have functions, but only the ones using K&amp;R syntax
&gt; int x Here is where he makes his argument for exactly this case: https://youtu.be/xnqTKD8uD64?t=41m11s Which is first it is more consistent and if you are truly going to the modern syntax leaning on C++14 literals then it is actually more explicit and avoids subtle narrowing conversions.
No. For many constraints, the value category is super important. Implicitly removing it would prevent you from being able to differentiate on that. The simplest example would be... consider the difference between `Constructible&lt;T, T const&amp;&gt;` (i.e. copy constructible) and `Constructible&lt;T, T&gt;` (i.e. move constructible)
&gt; C++ should have had a way to disable implicit conversions easily way before If you want to avoid implicit conversions without using auto you have to do some other work, no? It is a bit absurd to think implicit conversions don't really cause problems in large code bases because they use classes. It happens all of the time where a function used to return a float and someone fixes it to return a double. The code calling that function doesn't likely doesn't care which one is returned they just want to be operating on the correct type. If you weren't using auto you would have to go update every single place this function was called to use the correct type otherwise you'll end up altering the value during a narrowing conversion. And if the caller actually did want to be operating on specifically a float not a double then the auto f = float { foo() }; format would be very explicit that this is what they wanted and would prevent users from changing the type when they do end up alrtering the return value of foo();
If he's suggesting that people not use endl everywhere that's a point in his favor.
Yes. They will be included in c++45. 
It's not wrong by definition in C++, though. It's wrong in Java/C# because interfaces are \_actually different\_ than classes, particularly in areas around multiple inheritance and the related issues with that. (e.g., they allow implementing multiple interfaces but only only a single base class, for runtime reasons and not just "purity" reasons.) In C++, it's entirely feasible and sometimes quite correct to have a non-pure-abstract base class on what is otherwise a pure abstract class.
People always bring up IDEs but forget all the \*other\* tooling we view code in. As fancy as an IDE may ever be, that doesn't help reviewing the code in a GitHub PR. :)
Is it necessary to apply that as a rule to all concepts? It seems there would be a lot of concepts that would benefit from looking through references where it is intuitive to do so.
Any idea why they feel that way? I've really only once seen someone with credentials I believe (some technical lead in Microsoft) argue that they needed C, because with C++ they couldn't guarantee placement of data in managed memory. Something very obscure like that.
Probably the beginning of a long serie of mis-use of concepts!
That's good to hear it's reliable when configured well. I'm just not super incentivized to mess around with configuring that unless I can just point something at a .sln file and generate the config from that.
More typos: `functio`n. And your sub operation is `*`. ;) While it might scare some people, a quick template based type erasure could be added, like this: void quack( std::ostream&amp; os, int x ) { for (int i = 0; i &lt; x; ++i) os &lt;&lt; "quack!"; os &lt;&lt; "\n"; } struct DuckView { void quack( std::ostream&amp; os ) const { do_quack(os, ptr); } friend void quack( std::ostream&amp; os, DuckView v ) { v.quack(os); } template&lt;class T, std::enable_if_t&lt;!std::is_same&lt;DuckView, std::decay_t&lt;T&gt;&gt;{}, bool&gt; = true &gt; DuckView( T&amp;&amp; t ): ptr(std::addressof(t)), do_quack([](std::ostream&amp; os, void const* ptr){ auto* p_t = static_cast&lt;std::decay_t&lt;T&gt; const*&gt;(ptr); using ::quack; quack( os, *p_t ); }) {} private: void const* ptr = nullptr; void(*do_quack)( std::ostream&amp;, void const* ) = nullptr; }; A `Duck` is something you can `quack( std::ostream&amp;, Duck const&amp; )`. A `DuckView` is a non-owning view of a `Duck`. An `int` is a `Duck` because you can `quack` it. struct Mallard { friend void quack( std::ostream&amp; os, Mallard const&amp; ) { os &lt;&lt; "I'm a mallard!\n"; } }; so a `Mallard` is a `Duck`. [Live example](http://coliru.stacked-crooked.com/a/f0ea1ff3c1c4fe45) -- the code isn't *that* complex. 
That isn't the complete argument. There are more parallels. The argument for `struct Foo` was "so we know what Foo is" (ie not a typedef for `int`, etc). That's very similar to the argument for `Concept auto` IIUC. There might be more repercussions to the Concept vs type though (like forwarding references, etc) so maybe the argument is stronger. (Of course, I'd rather just fix forward referencing syntax)
YCM can use the compile_commands.json if a user provides that instead, so there is a zero-configuration option.
Pretty sure C/C++ is undefined behavior.
You fail to describe what `extends` and `implements` does. Does `implements` guarantee that all pure virtual members of the base are implmented in the implementing class? I'd guess that `extends` does ... nothing besides inheritance? 
My take on the topic is that back in the early 90s-2000s, when C++ became popular, everyone drank the crazy OOP Kool-Aid, and that lead to some crazy unmaintainable code. Game programmers got burned by that, and they shy away from C++ ever since. There's also something to say about game programmers using programming languages as a form of expression. They want a more stable platform (I haven't seen many game programmers care about C11).
In my opinion, the [reply from Z01dbrg](https://www.reddit.com/r/cpp/comments/7jxq8r/does_anybody_know_why_requires_requires_was_not/drd6m5p) to that post is very valid and the majority of his points is backed by research and studies (e.g. the UX parts). You may or may not agree with his wording (and I find his follow-up reply also unneedlessly inflammatory) but that does not make what he says wrong.
&gt;Another thing, interfaces are one of the building blocks of a well-separated modular software. Not true. I think interfaces create unnecessary coupling, can create accidental polymorphism and hinders refactoring. I have many well separated codebases without any interfaces required in the API of my modules. I think OOP in general is overrated. When I need polymorphism, I prefer to use the runtime concept idiom, and never put virtual method elsewhere. In other words, in my code, interfaces with virtual methods are hidden as private member classes and only are a implementation detail. The runtime concept idiom could as well be implemented with function pointers.
Could be. I definitely do not like looking at code that is too much templated. It's slow to compile, slow to run, and likely to bomb with totally mysterious errors. I think people went overboard with templates.
&gt; A lot of advice on there is the blind leading the blind Ironically, "the blind leading the blind" describes the situation with all C++ tutorials I've seen so far (I didn't see Cherno though)
It's interesting. It's a mixture of C and C++.
Thanks. I fixed the sub operation. I took me longer to find the wrong formatting of function.
&gt; slow to run I agree with most of that, except for slow to run. If anything, dynamic dispatch with virtual functions (or any eventual emulation of that in C) is going to be slower than template 
You also need to update the output (which is how I spotted the sub error ;) )
Templating hides optimization possibilities from the compiler. I agree that following an extra function pointer is also not a great idea.
How does template hide optimization from compilers? I might not be very well informed on this
Yes, although I most often write "const auto x = ...". The only problem is code completion in IDE's not 100% supporting it.
I already updated the screenshot. That is the cache of your browser. Use a different browser.
True... As at that point of time I was trying to transition from C to C++ :)
Be more optimistic. It'll be in C++42.
no way you know the language by 24h. not even 24 weeks
The Beast message container is perfectly capable of representing a complete HTTP/2 message (they are the same as HTTP/1). But since HTTP/2 connections are stateful, you will need to create a "stream" object which holds the state. This is a bit different from the current Beast HTTP interfaces, which are able to use simple free functions like \`read\` and \`write\` because HTTP/1 is stateless. You can model your \`http::stream\` the same as \`websocket::stream\` and take advantage of all the existing Beast facilities such as the test shims in the experimental/ directory.
The first link literally says that they never enabled compiler optimizations. I don't know what one should expect when you don't enable them.
What do you mean, depending on whether it's in a good mood or not? In my experience compiler do these optimizations consistently. Do you have a godbolt showing it failing to occur?
So you have created some keywords as an extension to C++. I have a lot of questions. - I assume you have good reasons and motivations to do so. But have you explained them well in the link? - Why do you make this particular design? How do you evaluate the design? - If your design is borrowed from other languages, are you aware of the historical contexts of and ideological reasons behind their designs? Are you aware of the criticism for and against those designs? - After paying your attention to purely abstract base class a.k.a interface, are you planning to put your effort in other popular usage patterns of class? Such as NVI base classes, type erasure, value types, type traits, advanced enum types, compile-time constant types, tag types for tagged dispatch, etc? These usage patterns arguably share similar popularity and importance as purely abstract base class.
Done. If I end up being the mod who posts Q4 and I forget to do this, please remind me again. Thanks!
&gt; he does things which are not even standard C++ and is undefined behaviour (reading from inactive union members). What shitty platform doesn't implement union in a sane way that allows type punning? I've yet to see any platform where it doesn't work, and it doesn't have the limitations of variant, or the verbosity of copying memory (which will be eluded by a good compiler but that's still longer to write). Pretty much everyone uses unions only for type punning, even if the standard says not to, because the compilers, in the end, are more important than the standard because they're the ones deciding what your code does. I think we should even allow reference type unions because it saves typing compared to punning on different pointer types (VS used to allow it by the way, and it worked well).
FWIW, you can have Automod do these posts for you. 
Is concept template parameter a thing?
They're mostly ok for initial learning.
well, that was actually fairly optimistic of me (hoping that somehow the captures of the lambdas would happen if the compiler could proove that they were constant across the overloads) but it's obviously not the case
One fairly trivial solution is to simply replace one of the two words with another one. If it wasn't the same word twice (with a different meaning each time) people wouldn't be so riled up about it. 
Exactly: https://godbolt.org/z/NgrWDk
Already exists: `std::remove_reference_t&lt;T&gt;`, typedef to rename if you want
Yes I also thought it is... no idea why i got downvoted !!
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9evryi/writing_a_lexer_how_to_lex_accessing_object/e5rwdwo/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
31 here, and nope
There's always going to be a demand for high performance computing, and for that you need low level control. C/C++ ain't going anywhere.
I would like to suggest two things. The first one would be to recommend to use a build directory that is outside of the source one rather than a build/ directory within the source tree, for two main reasons. First reason, as pointed by r/geokon in your first post, is that it may lead people to rely on a known build location, which inevitably will lead to projects that can not be compiled somewhere else, because of hard-coded relative paths. The second reason is that having a build directory within the source directory is a pain when performing searches in sources. For example I use Grep in the command line, or Ctrl+Shift+F in Visual Studio; a build directory under the source tree clogs searches. I know I could tweak my search commands, but it feels more like a workaround to avoid the real problem. The second one is to have a 'app/' directory, beside the 'lib/' directory. The idea is to have the source code of the executables under this directory, with possibly a sub-directory for each platform, if any. Any common code would be in the 'lib/' folder, and platform-specific and executable-specific source code is located under 'app/'. For example, I work on a multi-platform application (Linux, Windows, Android, iOS, Mac OS). Each platform requires its own CMake configuration as well as its own portion of source code for building the execuable. Under 'app/', there would be one directory per system: 'android/', 'linux/', 'windows/', etc. Each directory contains the CMake configuration specific to this platform, as well as its own main() entry (or equivalent). This would prevent a single CMakeLists.txt and main.cpp that are very long, with lots of mix of different platform-specific code. A project that would target a single platform, or have a single set of source code for all platforms it addresses would have only (for example) a CMakeLists.txt and a main.cpp, but in the 'app/' directory. In any case, thanks a lot for this initiative.
37 here and I always worked as a senior dev. Even now I am the youngest in all teams I worked on. Things change a bit on big tech but when you need strong talent, experience still counts a lot.
Come to the games industry! Experienced programmers are welcomed and most studios use C++!
I stared with C# and switched to C++ after around 2 years. I also don’t see C++ as “hard” - just complex due to the power and flexibility it offers. I frequently see programs written in Java C# and similar languages but they always have some high performance C++ or C backend that someone has to work on. Those jobs aren’t going anywhere and finding competent people to staff them is very difficult.
My background is similar to yours. You seem to be under the impression that you're a "C++ programmer" instead of a "programmer". You shouldn't be. I've worked in a variety of shops, some of which used C++ exclusively and others that used a wide variety of languages (web stuff, PHP, Python, VHDL, C, C#, etc.) If all you can (or want to) do is C++, you'll be limited in your opportunities and learning experience. Using other languages will change your perception of programming and will make you a better C++ programmer, and a better programmer in general. You'll learn that languages are tools and that different tasks call for different tools. These "newer languages" as you call them (_get off my lawn!_) have their advantages. If anything, some companies use them, so you better be prepared to start using them too. It's part of the job of being a programmer. You can be a _specialist_ in a language, but don't become a chauvinist. Or you'll end up like that old assembly guy who doesn't believe in high-level languages 'cause ain't nobody got time for that and I can optimize better in my sleep.
A null-terminated string is the empty string, so an empty string should be printed.
I agree but I think it depends on your local environment. Globally there's still much growth and activity and pride to be had in being good at C++ but if you are in an area where the dominant activity is making database-driven jazzy web sites and apps then you're going to feel like you're missing out on a (local) community.
Learn D. We need people like you :)
&gt;in the West is pun intended?
\&gt; My background is similar to yours. You seem to be under the impression that you're a "C++ programmer" instead of a "programmer". You shouldn't be. \&gt; I've worked in a variety of shops, some of which used C++ exclusively and others that used a wide variety of languages (web stuff, PHP, Python, VHDL, C, C#, etc.) If all you can (or want to) do is C++, you'll be limited in your opportunities and learning experience. \&gt;Using other languages will change your perception of programming and will make you a better C++ programmer, and a better programmer in general. You'll learn that languages are tools and that different tasks call for different tools. Here's the list of languages that I have used for building things over the year, whether as a hobbyist, student, or professional: Software: C, C++, assembly, JS, Python, Java, Go Hardware: ABEL, PALASM, VHDL, Verilog I'm far from a chauvinist. I don't have a problem with other languages necessarily, but at the end of the day, I get tired of dealing answering questions from younger coworkers who have no idea how computers work under the hood, how to use gdb to find a segfault, how to resolve a "symbol not found" error during execution, etc. I get tired of dealing with C++ code written by a guy who came from a Java background that is 3x as verbose as it needs to be, and wondering how much that is slowing down development as his team brings in new people. I get tired of having to cover for JS programmers around my age who can't figure out solutions in a day that take me an hour to debug, because he never had to grind through years of debugging native C++ code as a teenage hobbyist.
Maybe one day when I am settled down and have more free time. :)
Yeah -- I am interested in the digital nomad lifestyle, for example, but that is all geared toward the web stuff. My background is the exact opposite -- I started with low-level programming. I used to think "full-stack" meant all the way from hardware up to the GUI on one single computer system! I don't think I can find any high-performance or systems programming jobs (e.g. C/C++/even Python) to work from wherever I want. It's kind of sad.
Wait, are you complaining about having bad coworkers? If so, you better start your own company and work alone. But then you'll have bad clients who will ask stupid things, can't decide what they want, change stuff just before deadlines, etc. So maybe start a farm somewhere peaceful? It's just part of the game. Most coworkers you'll have will be okay, some will be great, others will be horrible. Teach them if you can, set up training if your boss is interested, or just be grumpy and stay in your corner. I'm not sure what else you expected.
What kinds of games have you worked on? That industry has also grown a lot, compared to the days when I was hacking away in Mode 13h by writing directly to memory at 0xA0000000 before switching to SDL as a hobbyist. Now people equate "game dev" with Unity -- I took a look and was shocked that it doesn't even let you program in C++.
I sure hope you were writing at 0xA0000 or 0xA000:0000...
Well, that has nothing to do with move. It's needed just to be able to call .str() function to deduce return type to std::string (to be precise - to deduce return type to same thing as `ostringstream::str()`). And we need to do cast, because call to operator&lt;&lt;() on std::ostringstream will return std::ostream&amp; instead of std::ostringstream. Something like `decltype((std::ostringstream() &lt;&lt; x), std::string())` should work also
On one hand I see a lot of people complain that there aren't enough experienced C++ devs to go around, on the other hand I see them offering peanuts compared to other language's offerings... so I think I know why there aren't enough experienced people to be found at that price point.
I mostly work with UE4. I have worked at Midway, CCP, Epic, and now for an independent contractor called Coconut Lizard where I have worked closely with several other big names as well.
I don't know if it's bad coworkers so much as inexperienced ones. People who get hired because they went through a CS program and don't necessarily have the experience or the self-learning ability. It probably doesn't help that I look 5-10 years younger and they probably think I'm around the same age, and hence they see me as a super genius rather than just an experienced programmer. All the long-time C++ devs I've worked with have been fantastic, though.
I had: char\* video\_mem = (char\*) 0xA0000000; This was in the traditional IBM PC architecture where the physical address was computed (segment) &lt;&lt; 8 + (offset).
How are the hours at these big-name game studios? How's the pay/benefits/vacation?
I don't think that's necessarily true especially as you've broadened yourself to Python though I can only speak from my frame of reference which is a long stable job in C++ and desktop Java (not web, that's the people around me). We certainly have a remotely operating contractor on Python too. I think it depends on how nomadic you want to be, your skills are universally valuable and you can move around but the tasks you'd pick up are likely specialised and not bite-sized and so you'd be staying in one place for a year/while then moving and repeat.
&gt; People who get hired because they went through a CS program Well, yes. That's kinda how it works. I don't know what else to tell you, because now I don't really know what you're asking. &gt; All the long-time C++ devs I've worked with have been fantastic The way I'm reading what you write (and I may misunderstand), you seem to be looking down on other languages, and so on the people who program in them. I think it's a mistake. You don't have a lot of choices: learn to work with other people who may not be as good as you want, or work somewhere else and hope their skills is closer to what you expect. Good luck.
That kind of thing is normal when you become widely respected within an org. If anything, you should be chuffed. But if it really bothers you, then contracting is the way to avoid it. You'll never be somewhere long enough to become a "go to guy". The exchange is that you become a worker bee, you spend your day clearing JIRA backlog and never talk to another soul. As is often the case in our industry, you get either extreme, there tends to be little middle ground for any length of time.
That's usually management or admin track though. Becoming a technical lead usually means little to no more programming. Only way to remain programming and keep getting more senior in terms of pay and position is contracting usually. Obviously everything I just said is a European perspective, and probably doesn't apply elsewhere.
&gt; These "newer languages" as you call them (get off my lawn!) have their advantages. The problem is that one of the main "advantage" is simplicity over perfomance. It is an advantage for some companies, but not for professionals.
Did you change job recently ? Maybe you can feel this way if you are in the same company/environment and don't see any real evolution... Are you happy with the software you are producing ? With the company policy ?
Not using a unit testing framework is fine if you only have ten tests, but doesn't scale well to 4000 test cases and beyond - compiling and running 4000 processes takes a shitload of time and you have to figure out what the problem is by checking the return code of the process, look at the output of that specific process and then in your case check the source code to see why that specific string ended up non-empty. The output of Catch gives you the actual value of variables in an awesome overview so you can much easier find out what fails and why. There are reason why you'd want to have separate processes for tests, but more often than not you don't need it in my experience. For doxygen, you can also simply use snippets - those are imho very readible in doxygen documentation. ``` TEST_CASE("part_of_lib/.../functionWithTooLargeInput") { /// [functionWithTooLargeInput] CHECK(myFunction(20000.0) == NOT_OK_RET_CODE); /// [functionWithTooLargeInput] } ```
My entire career ( except for the job I have now ) has been porting legacy c++ applications over to java on linux systems. Currently I'm working on a huge JVM based project. The only c++ I do is game dev stuff in my personal time... I love c++ though
It varies hugely by country - in the US hours are often longer and benefits worse than at the UK studios I worked at. The old culture of "crunch" (long hours for months) has largely fallen by the wayside as experienced developers get older and less willing to do that shit.
Again, that's par for the course in our industry. Orgs don't want to pay top dollar for developers lest they "waste" them on "mundane" work. So they perform cost-benefit, mixing as many cheap people they can retain with as few expensive people as possible, and basically have the expensive people do lowest hanging fruit cleanup on the cheap people. Very occasionally, an org actually wants nothing but top end talent because they actually genuinely want quality software, rather than just pretending they do. Everybody working on a piece of software is as good as the org can acquire for *any* money, and usually you only need about six developers if they fit well to achieve almost anything. It's a life changing experience to work in a place like that, the productivity is truly astonishing. You get to see how software really *ought* to be developed if the world were perfect and the industry actually wanted quality. After said experience, you'll either quit the industry, or accept that 95% of software is developed as cheaply as an org can manage it, and that comes with the work environment and tradeoffs that it does. If it's any consolation, exactly the same situation exists across all the professions, everything from medicine to government. That's the Western economic model for you. We try to employ as many people as possible with the least accounting cost, and we ignore or trivialise the overheads of coordinating more people, rather than having fewer, better, more expensive people. It is what it is.
&gt; The C++ type system is the essential feature of C++. Properly used, it's the single most useful feature contributing to program correctness. It guarantees that the type of the result you want/expect is in fact the type you get. This is a non-sequitur: using auto is still making full use of the power of the C++ type system. &gt; Never use auto - unless there is no other way. Why not? (Implicit conversions are also not an argument against auto - as far as I can tell).
At 37, I'm coming in from the other direction. Did C/C++ as a hobby when I was a kid, it was a focus in college, and then I never used them professionally. Most of my professional career was some blend of C#, PHP, Javascript, and only recently did I land some work where I get to do C and Rust. Looking in from the outside, what I would say is that it feels very difficult for a rank-and-file programmer to find an inlet into embedded work. It comes down to the chicken/egg of experience in a given language, and the people hiring want other skills like X years of Boost or Qt.
&gt; I get tired of dealing answering questions from younger coworkers &gt; I get tired of having to cover for JS programmers &gt; I'm tired of helping the sys ops guy You really need to ditch this attitude. It is __your job__ to help your coworkers. A part of working for a company is being a part of it. If you were only paid to produce .cpp files you'd be a contractor. 
Actually yes, but this post is mostly just from ruminating on my previous job and trying to figure out where I should go in the future. It was one of the shortest jobs I'd ever held (less than 18 months, and I started job searching 10 months in).
Unfortunately, salary is really low compared to other IT industries.
I was spending so much time helping them that it was burning me out. The constant context switching between helping them and getting my own work done. I don't think any of them were spending even a third of the time that I had spent mentoring. Which would be fine if they took that mentoring momentum and started digging deeper, but all I got in return was more questions. When I started out in industry, I didn't have anyone give me anywhere as much 1:1 mentoring. Mostly it was just searching online, following instructions in documentation, or people giving me brief answers over email and me being able to run with it. Tying that back to the original topic, there is still a part of me that believes that if every programmer had to learn C++ or quit, we'd have a much higher quality of programmers. Not that they can't use easier languages in the future, but it would weed out a lot of the people who can't get anything done without being spoonfed answers. I work for a company that is pretty well-regarded for software engineering talent, BTW.
It depends on the studio. Many "AAA" studios have proprietary game engines written entirely in C++.
&gt; younger folks at work who have all this background in JS, Ruby, Java, Go I'm not an expert but those are bad examples. JS is a bad language. Ruby is like Python, no need to study both deeply. Java is a bit like C++. In the end, only Go (or Rust) feel like new languages with interesting features.
38 here. Still learning cpp, although spent 16 years paid to write cpp code. Please learn other languages. This will make you a better dev, and a better cpp dev as well.
You can also use std::reference\_wrapper for a similar effect. You also avoid the possibility of a null pointer this way.
&gt; I was spending so much time helping them that it was burning me out. The constant context switching between helping them and getting my own work done. Ah there's a simple solution to that: don't answer any requests for help for 24 hours, or even 48 hours. Tell them you'll just finish up your work item you're in the middle of, then you'll be with them. An old boss of mine installed a "48 hour delay" filter on his email. So he received all email 48 hours after it arrived. He said it was the best productivity step he'd ever taken in his career.
&gt; if every programmer had to learn C++ or quit, we'd have a much higher quality of programmers [...] it would weed out a lot of the people who can't get anything done without being spoonfed answers. I've been typing and erasing my answer for several minutes now, because I'm not sure what kind of confusion could lead you to make such a statement, and so I'm not sure how to answer. Do you believe that C++ is the best and only language? That is has solved computer science? Or is it because you think you're a _really_ good programmer and you learned with C++ and so it's the only way to be good? Or that other languages are for morons? Or that people who learn or (god forbid) like other languages are morons? Do you even have an inkling of how you come across when you write stuff like that? I think you have a major attitude problem and that you need to get your head out of your ass.
They will hopefully improve the situation, but not solve the problem I have described.
you still feel stuff? be happy you do. 
From my experience, it's almost impossible to enter into games without previous experience. All the C++ job offers I've seen for game companies ask for a few years of experience in the industry.
A thing I have considered to do when I know some stuff more deeply (only with programming though) is trying to hold a training course. You could advertise yourself somewhere, organise a course and start teaching people stuff. You could also make a bit more money this way, and are also contributing to the general education of people (programmers, in this case). Ofcourse, in your case, you would mark that course (somehow) as more advanced, as in not teaching the basics of C++, but more advanced topics like assembly optimisations, building libraries, etc. That would depend on what you notice is missing from your coworkers' knowledge. I know my explanation sucks, but I hope I got the idea through.
Experience can be stuff you've done yourself - UE4 is free, after all. We've hired a load of people who haven't worked in the industry before but had good C++ skill and actually had a portfolio of stuff they'd done.
Maybe you need to find a company with smarter / more experienced people.
I like your idea. I could see myself retiring into a teaching role like that in the next 10 years. The only question is how to sell it? It's not as easy to get programming job as compared to Java or JS. Especially when C++ is popularly seen as a bit of a legacy language with a lot of problems (e.g. manual memory management -- by people not familiar with C++11 or newer). Maybe I'll wait for the current fad of 3-month bootcamps to progress to a phase of disillusionment, when people realize that you can't create a good programmer in that time period, and the pendulum swings in the other direction. \*fingers crossed\*
Lower than some, higher than others. I'm happy with my salary. Some games companies had a rather poor reputation for pay and hours but most of those have closed up shop now.
Well, here are the lessons. How are you going to spin this out into 24 weeks? Are you saying you should spend 40 hours on each of these subjects? A 40 hour lesson on pointers is going to be pretty boring. * Hour 1. Writing Your First Program * Hour 2. Organizing the Parts of a Program * Hour 3. Creating Variables and Constants * Hour 4. Using Expressions, Statements, and Operators * Hour 5. Calling Functions * Hour 6. Controlling the Flow of a Program * Hour 7. Storing Information in Arrays and Strings * Hour 8. Creating Basic Classes * Hour 9. Moving into Advanced Classes * Hour 10. Creating Pointers * Hour 11. Developing Advanced Pointers * Hour 12. Creating References * Hour 13. Developing Advanced References and Pointers * Hour 14. Calling Advanced Functions * Hour 15. Using Operator Overloading * Hour 16. Extending Classes with Inheritance * Hour 17. Using Polymorphism and Derived Classes * Hour 18. Making Use of Advanced Polymorphism * Hour 19. Storing Information in Linked Lists * Hour 20. Using Special Classes, Functions, and Pointers * Hour 21. Using New Features of C++14 * Hour 22. Employing Object-Oriented Analysis and Design * Hour 23. Creating Templates * Hour 24. Dealing with Exceptions and Error Handling
700k loc and hundreds of unit tests. It scales more than fine and compiles in a reasonable amount of time as well without all the damn template crap. Incremental refactoring is enabled by the multi executable model.
You can easily spend several hours learning the different initializations in cpp if you are not willing to open google every time you encounter a variable declaration. We can go on with the different behaviour of variable declarations in global/namespace scope, static function variables, linkage. inline variables, inline functions, constexpr variables, constexpr functions. thread local variables. And then. Then you start with templates. Here our learning time will skyrocket. Just because you can use a `std::vector&lt;T&gt;` does not mean you "know templates". Deduction rules for function templates. Deduction rules for class templates. class template deduction guides. auto type deduction. decltype(auto) type deduction. SFINEA. Perfect forwarding. Move semantics. Strict aliasing rules. Have i meantioned the memory model? Memory orderings combined with atomics. (of course we can add the cpp standard library to the list here) Sure you can write a programm without knowing the stuff above. But you dont "know the language" if you are not familiar with the features mentioned above.
Start doing code reviews then and offer constructive criticism and feedback. Every time someone does a MR/PR, highlight lines and offer comments as how they can be improved. Eventually as you grow your team as they tap into your knowledge, you'll find your complaints lessen.
If you use Python, JS, Ruby, Java,..., you will feel much much more older. Because even 5 years old boy is learning python.
&gt; Some of these guys were even at the same ladder level as me, and some were even higher. I found the problem. You are angry that people that are half the programmer you are have positions and salaries higher than yours and you feel cheated for it. None of that is their problem. That is your problem. Life isn't fair. You get what you get. If you aren't happy with what you have nobody is going to hand you something better. Prove to your employer how much you do and ask for a raise or promotion. When they refuse take your skills somewhere else. If you want more you need to go get it. Don't be pissed at the others around you that have it. You should be thinking 'good for them' instead of 'woe is me'. 
31 here and basically just starting out in CPP out of choice. Seems to be plenty of work around for CPP.
What if the project builds multiple executables from the same code base? For example: client and server executable for an online game? Would app directory be suitale for this too?
If your code requires a specific type, you would write: float f = foo(); This has always been the standard way of saying "pick the result of `foo()` and put it into a `float`"; and it is what you normally need, because your computations afterwards depend on a particular type. Your problem appeared because you **started to use `auto`**, and therefore you are changing the semantics of callers if you **don't** cast. Now, if your code wants to use the same type as someone else, it is typically because you are writing generic code and therefore you typically will have a `T` that you can use instead of `auto`. But yes, you can also use `auto` for this (and in other non-generic contextsO, that is fine and it what `auto` was meant for. Having said that, if we are talking about floating-point (or even integers where size matters) in particular, most code don't go around using `float` or `double`; but a `Real` or `Scalar` or similarly named `typedef` or custom type. In particular, note that optimizations, architecture and compiler flags get involved here: the actual operations done in the end might have nothing to do with the difference in size of a `float` and a `double`. In particular, if your program correctness relies on the difference between using `float` and `double` (i.e. you require a tightly controlled resolution for saved intermediate results), you should be making damn well sure that your casts and conversions are correct (and typically this is the kind of software that requires validation to some degree). `auto` is not going to help to make floating-point computations any easier.
Good point. This is part of why various multinationals have invested so many resources into new systems languages, because when transistor density stops growing exponentially, there will be a huge shift away from less efficient programming languages into systems languages. So said multinationals are investing effectively in a future land grab of programmer mindshare in developing software on fixed performance CPUs which only linearly improve year to year. In case people are thinking that C++ doesn't have such a multinational sponsor, they are partially right, but also partially wrong. Microsoft is the only tech multinational all-in on C++ as its championed systems programming language. You may have noticed the supporting purchases recently e.g. Github, and the supporting business process changes e.g. embrace of open source development paradigms. You will surely have noticed how many of the big new recent C++ features have been proposed by, and sponsored by, Microsoft.
The more I think about it the more I think public headers should be in a include subdirectory of a module. Because modules are coming, having deep directory structure to not leak headers won't be required anymore. Headers will be more rare, and in that case a special include folder seem even more tempting. It would allow the `lib/` folder to be much less deep. But then... I still got my headers alongside my cpp, and don't plan to change that until I got modules.
Are reference_wrappery implicitly constructible from the underlying object type? If so, that might deviate from one of the of the original purposes, which was to have a clear distinction for the caller between input and output parameters.
AFAIK there's no current implementation of C++2a concepts to check, but I'd be very very surprised if not: the function parameters are in scope after their declaration, so we should be able to use them in a trailing `requires` expression, just as we can use them in a trailing return type.
I'm 28 and I just did a hard shift from Java/C#/Web Development to C++ and I feel just as out of place as you do. Although it's fucking wild running a program that has a memory footprint of like 2.4 kb instead of 70 tb!
Just to be a contrarian, ill say there are other things out there that can keep up with C/C++ performance, and the list is growing, not shrinking. Don't get too complacent.
When did you ever hear of a carpenter who was an expert in hammers? The language is a tool. No more; no less. Pick the right tool for the job, be proficient or even passionate, but don't choose the wrong tool because of your own personal biases.
Okay and your actual job is already uninteresting ? What are you specializing in ? Maybe try to go for a job where you will make something you never made ? Personally I think getting old is a feeling you have when you're doing every day the same thing over a long period of time... So try new things... New architectures... New systems... It's maybe not easy to do at your job but the best job is always the job where you can experiment and craft your skills in something you find interesting.
Of course it would be, my point is that under a directory 'app/' (or whatever its name), you would find all source code that is dedicated to specifically build executables, and deal with platform-specific idiosyncrasies (entry-point for the application, and build configuration). My personal way to design softwares is usually to have a much code as possible compiled as libraries; executables are only entry-points to these libraries. I don't really have a specific folder hierarchy in mind, beside probably having one directory per executable. Then I guess it depends on the project we are talking about. It could be somehting like : - 'app/server/' for the server executable - 'app/client/windows' for the Windows client - 'app/client/android' for the Android client - etc. Another advantage I see with this approach is that it is easier to choose which executable to build (or not). With CMake it is only a matter of which sub-directories to include or not.
Moore's Law isn't dead because Moore's Law is about the number of transistors on a CPU, not the speed of the CPU. The fast exponential growth of CPU clock speed is dead though.
There are plenty of C++ jobs available at the companies running the largest distributed systems. Amazon, Google, Microsoft, Facebook etc. There are also lots of financial sector and gaming jobs available as others have mentioned. If you're really concerned about C++ becoming obselete I would go work in distributed systems, because even if the language changes the principles and ideas behind how systems of that scale work aren't going anywhere, at least not any time soon. 
This is the correct answer. I think a lot of people have this misconception. Didn't this happen a while ago though, that's why we went dual, then quad core as a standard?
Were you willing to employ a 100% remote C++ engineering team? If not, you filtered out 95-98% of the serious C++ talent available to you. As C++ becomes an ever more specialist programming language, wanting excellent people onsite is a bad value proposition: you either need to pay through the nose to get them, or you don't get them at all. I just don't get the reluctance amongst firms hiring to go where the affordable talent is. Why firms expect the talent to be flexible, and they not be flexible instead, is beyond me in a competitive environment. That said, if you were recruiting for a 100% remote role, and couldn't find a sufficiently qualified high performance C++ engineer, then I'd very much like to hear about why not. That would be *very* interesting.
Thanks, that's a great idea, I'll look into it. I actually use Gmail, does it support that?
Mate, you should be proud that you work with C++. Certainly for some tasks other programming languages are more advisable, but if you work with bringing serious stuff into production, thank God that you do it in C++. And be sure that other programmers feel intimidated when they hear that you use C++ mostly because they know very well what C++ can do, that is what hardcore programmers use! You might be wondering, should you rather go with a modern programming language such as Rust.. Sure, learn Rust, learn as much as you can about programming. Buy remember that C++ has decades of craftsmanship. Rust and many other low level languages have appeared out of frustration that C++ is an antique language that did not evolve. Well it started to, C++11, C++14, C++17, C++20 give the language the necessary impetus for it to remain relevant. C++ is the flagship of programming languages. As an instance, just read pandas2 documentation. It essentially says: we've done a mess here; we need to rewrite the stuff in C++.
I actually work at Google.
Thanks. I do hear good things about Rust, but am aware that it is a relatively new language that could use some time to mature.
I run a programming blog and a small YouTube channel and according to the analytics, about 50% of the traffic comes from 18-25 age range and the other half pretty much comes from 26-34. I joined a big programming discord and they kinda laughed at me when I said I learned QBasic in the 90s because most of them were born after 2000. &amp;#x200B; We're like dinosaurs who remember a pre-internet world. We're becoming the mentors.
Here's the thing -- I get a lot of recruitment solicitation over LinkedIn, etc. But so many of them are for things that I don't have a proper background for. And the people doing the recruiting don't seem to care-- they just want a quality engineer with a good brand (me) but I'm pretty sure they could be just as well served with someone with less understanding of how computers and operating systems fundamentally work, which is complentary to low level programming (asm/C/C++/Rust type stuff) Think a lot of web and crud apps. I can learn those things but they're better off getting a kid out of undergrad cs who has built a few of those in his spare time and has a teachable attitude.
Yeah, you could replace C++ above with so many other languages: LISP, Haskell, Eiffel, Prolog, Rust, Ada, etc.... Now if you changed the statement to say that every programmer had to learn a language from each category of the following families: LISPs, functional, logic, object-oriented, procedural, and multi-paradigm, then I would agree with it. The number of programmers though that have learned all those families though is very, very few. But, back to reality for a minute. I'm the C++ expert in my company; I stay up-to-date on the standardization proceedings, test out new features, experiment with new compilers, etc.... But there is *still* so much to know. I don't know how to analyze a core dump from the command line. That's OK -- there's another expert on the team who's great with gdb (and he set up our automated core dump analyzer). There's another expert who's great with setting up VM's and automated build systems. And there are other experts on the team (Git, hardware testers, low-level CPU &amp; OS fundamentals like ring 0 vs ring 1 ...). We each bring something to the table. Yes, I spoon-feed my co-workers answers which are obvious to me. But at other times they spoon-feed answers to me like I'm a freshman in high school taking a programming class for the first time. It's OK. It makes us a great team!
[Apparently they are](https://stackoverflow.com/questions/15646681/does-implicit-t-constructor-of-stdreference-wrappert-make-it-dangerous-to-u#). I thought otherwise but I guess I had boost's reference\_wrapper in mind. I didn't realize this subtle difference between them.
I'm a semi-recent grad who's working as a junior. Went through school using overwhelmingly C++/C# and now work full time with C++. My focus was graphics programming and gaming. At least in the games industry, most developers are probably younger than other fields and everyone is pretty much exclusively using C++ or C#. The AAA space is 90% C++. Truthfully though I hope for something like D, Zig, or Jai to pick up some momentum in our space. There are a lot of things about C++ that are just straight up not good or "traps" in game development. And the language means "The Build" is always problematic throughout development, often with what seems like a crazy amount of work dedicated to continuously improving it.
Do you know how much time I eagerly spent trying to teach world class engineers how to be more effective, and how a year later they're still cutting corners and then coming to me for help? Do you realize how demoralizing that is? And then realizing how much of a fossil you feel like because most of the industry doesn't need you? The road to learning C++ isn't easy, and it definitely self selects for people who are more persistent and self motivated. Having gone through that, I am at least somewhat justified in not liking working with people who probably couldn't have lasted half as long as I have. I also made sure to qualify what I wrote with "part of me". Maybe you have an attitude problem too.
Yeah, we pretty much flatlined on CPU speed over a decade ago.
and for those of us who don't use git?
Module interface units will take the job of headers, so the directory structure could still make sense.
I wasn't just answering questions in my domain of C++ though. I had to teach people how to do things or otherwise cover for them in Python, JS, and Java. No one else on the team was coding in all four languages over that time period afaik.
[removed]
Pls don't fall into thinking that top tier companies are the plateau. It's just not same, I was the same before in another industry, I thought that I have touched the ceiling. Then I started my own projects and realized that there is a whole world to explore. Nowadays I combine my knowledge in different industries in my own projects full time. Make something. IDK, create your own is for a raspberry for a example. Make it better. Remember that feeling of accomplishment that you felt 20-30 years ago when compiling something that works. Combine it with other hobbies. Buy a car a hack it. Wherever. There is a lot more to developing than writing code for others.
Self assignment is not ok. Use the builder pattern instead x.addThis().addThat().[...];
&gt; Were you willing to employ a 100% remote C++ engineering team? Yes. We are a fully remote engineering team. &gt;couldn't find a sufficiently qualified high performance C++ engineer We did. It just took a little while, though I'm sure for a larger company with HR resources it would be faster. 