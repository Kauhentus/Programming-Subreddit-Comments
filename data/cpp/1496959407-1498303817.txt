Sorry, I didn't mean RC1/2 -- I meant "2017 Preview Version 15.3.0 Preview 1.0" and "2017 Preview Version 15.3.0 Preview 2.0" If nobody else is having issues, then it's just my machine or my setup. And I do understand it's a "preview".
Using an up-to-date VS2017 Enterprise I've got quite a few problems with a pretty large mixed C++/C# codebase. The C# is absolutely fine, but in C++ I'm finding hangs, the occasional crash, and the crowning insanity that "Replace in file" will insist on reloading every single damn project in the entire solution. (I've also found that Intellisense in VS2017 is still not quite trumping VisualAssist with VS2015, but that's not entirely a fair comparison. When it isn't falling over on me or generally getting in the way of me actually doing some fucking work, I vastly prefer vanilla 2017 to 2015. But it's still not without problems, and that's after a couple of months of patches.) As a result, I'm still running VS2015 at work, and updating VS2017 as patches come through and reevaluating. On much smaller projects at home I've found VS2017 nothing but an improvement over VS2015.
You frowns/whatever to report problems. This subreddit doesn't seem like a proper place for this kind of thing, unless it's a bug in the compiler/STL lib.
I need c++ fixes in the previews, since my code is multiplatform, and g++ is ahead feature-wise
My approach is not usually intended for other CMake based third party project, but for any kind of projects(Like Boost or OpenSSL or autoconf projects). In such cases, I need to manipulate CXXFLAGS or LDFLAGS to pass them into their build tools. Sounds ugly but that is only way to build whole project with MSan or other project-wide hacks. They are "third party" libraries, so I actully don't need to coverage them or make them as a debug build. Only subset of current CMake envirment are needed.
I have used Wt for some fun stuff. Made a lot of tasks relatively easy
last time I did #2 (hehe) it screwed up and disabled all intellisense - which I fixed by installing Review 2, which crashes even harder. I'll remove it again
My C++ codebase is pretty small, and had no problems with 2017 before I wanted some fixes from previews and 14/17-ified the code, so can only push forward now
Well, you don't have all the flags in CXXFLAGS or LDFLAGS, there are also flags added in DIRECTORY properties, for example with `add_compile_options()` and many other options. So it's a little bit more involved than that. As for Boost, you could use that for example: https://github.com/Orphis/boost-cmake It will build Boost with your project automatically and should ease cross compilation issues.
Additionally #4, Return your source directories to a virgin state, including trashing the DB files, the .vs directory, all object files, etc. VS2017 does not play nicely with VS2015 databases and we found this a good way of improving stability (albeit not entirely to the level I'd like). I've also found issues running multiple instances of VS2017 on different repositories of the same solution. It seems far less stable when building one and editing another than it is working on either independently.
A quick implementation gives just over 4 cycles per `uint64_t`, which means it's pretty much where I guessed it would be, plus a tiny pessimism. Perf stat is telling me we're ~4 IPC (max ~4.12, min ~3.92), so this is simply running out of FUs. Here are some timings, both absolute and relative. --debugoptimized-- -----release----- gcc clang gcc clang geo. /Âµs simple16b 62554 8575 7302 8415 13474 paraddf 16879 17089 16536 16948 16862 lut 40426 35234 39892 31949 36706 paradd 36532 38140 35777 38750 37281 simple 63226 36261 62132 35947 47569 bucket 55350 55342 64061 55102 57343 multiply 80358 62748 66866 63179 67936 bitfiddle 68476 110956 34587 110901 73474 partition 445979 439769 420830 433296 434868 zeroing 480621 552109 448344 554015 506687 --debugoptimized-- -----release----- gcc clang gcc clang geo. simple16b 8.57 1.17 1.00 1.15 1.85 paraddf 2.31 2.34 2.26 2.32 2.31 lut 5.54 4.83 5.46 4.38 5.03 paradd 5.00 5.22 4.90 5.31 5.11 simple 8.66 4.97 8.51 4.92 6.51 bucket 7.58 7.58 8.77 7.55 7.85 multiply 11.00 8.59 9.16 8.65 9.30 bitfiddle 9.38 15.20 4.74 15.19 10.06 partition 61.08 60.23 57.63 59.34 59.55 zeroing 65.82 75.61 61.40 75.87 69.39 `paraddf` is the technique I give; `simple16b` is /u/rolandschulz's vectorizable version. You see that `gcc` doesn't manage to vectorize `simple16b` under `debugoptimized`, but manages under release mode proper, and that `paraddf` easily beats out the scalar versions and the LUT-based `paradd`. Unrolling helps consistency but how important it is varies by compiler. uint64_t parallel_add_lookup_fast(const uint8_t *buf, size_t bufsize) { assert(bufsize % 8 == 0); uint64_t result = 0; uint64_t running_sums = 0; const uint64_t *b = reinterpret_cast&lt;const uint64_t *&gt;(buf); constexpr uint64_t sign_bits = 0x8080808080808080ul; for (size_t i = 0; i &lt; bufsize / 8; ) { while (true) { { if (i &gt;= bufsize / 8) { break; } uint64_t x = b[i]; auto high_bits = x &amp; sign_bits; auto low_bits = high_bits &gt;&gt; 7; auto mask = sign_bits - low_bits; mask ^= sign_bits; auto to_sum = x &amp; mask; auto to_sum_hi = (to_sum &amp; 0xFF00FF00FF00FF00ul) &gt;&gt; 8; auto to_sum_lo = to_sum &amp; 0x00FF00FF00FF00FFul; running_sums += to_sum_lo; running_sums += to_sum_hi; ++i; } { if (i &gt;= bufsize / 8) { break; } uint64_t x = b[i]; auto high_bits = x &amp; sign_bits; auto low_bits = high_bits &gt;&gt; 7; auto mask = sign_bits - low_bits; mask ^= sign_bits; auto to_sum = x &amp; mask; auto to_sum_hi = (to_sum &amp; 0xFF00FF00FF00FF00ul) &gt;&gt; 8; auto to_sum_lo = to_sum &amp; 0x00FF00FF00FF00FFul; running_sums += to_sum_lo; running_sums += to_sum_hi; ++i; } if (!(i % 256)) { break; } } running_sums = ((running_sums &amp; 0xFFFF0000FFFF0000ul) &gt;&gt; 16) + (running_sums &amp; 0x0000FFFF0000FFFFul); running_sums = ((running_sums &amp; 0xFFFFFFFF00000000ul) &gt;&gt; 32) + (running_sums &amp; 0x00000000FFFFFFFFul); result += running_sums; running_sums = 0; } return result; } 
It's gone midnight where I am but I'll dig out some of my logs at work tomorrow, and work through the day with VS2017 and note what's happening, and get back to you at the end of the working day. Unfortunately with some of the issues it's been hard to pin down solidly reproducible circumstances, but I'll get what info I can - I'd definitely love to be able to shift to VS2017 at work as well as at home. The one that seems absolutely stable is the replace in files dialogue -- attempting to replace even a single character in a document is forcing a reload of every project in the solution, so what should take me a second is taking well upwards of a minute. There may be something I can't identify in our solution causing it, and I'm sorry I can't provide anything solid around this, but it's certainly frustrating.
I'll reach out later tonight with answers, thank you!
This one is even better: template&lt;class T, enable_if_t&lt;is_floating_point_v&lt;T&gt;&gt;...&gt; T sqrt (T x); ;)
You put your text in the quote. Check [line breaks on reddit](https://www.reddit.com/wiki/commenting#wiki_line_breaks).
Sure, until someone writes `sqrt&lt;int, void&gt;(10)`. Also moving the enable to the return type makes for a cleaner binary on platforms where return types do not appear in mangled names. 
It's not a matter of "hate". It's a matter of correctness and efficiency. The `GLOB` is evaluated one time when CMake is run. CMake will only ever run again if the timestamp changes on the CMakeLists.txt (or if your IDE is pessimistic and runs it every time). The globbed value doesn't magically keep up with changes to the filesystem. That leaves a huge area for weird behavior and bugs as others have pointed out.
&gt;Sure, until someone writes `sqrt&lt;int, void&gt;(10)`. Protect against Murphy; not Machiavelli.
If that works, it's a compiler bug. You are declaring a non-type parameter pack of type `void` if you get past the `enable_if_t`.
PS: For AVX2 slightly better than reading 128b and doing vpminsb, vpmovzxbw, vpaddw is reading 256b and doing vpminsb, vpand, vpsrlw, 2x vpaddw (after doing min adding both the lower and upper byte by logical-and and bitshift). Improving it from 3 to 2 cycles for 256b.
1. Code base is 3 weeks old, single project, 24 cpp/h files, 143K bytes of mostly pretty straight-forward C++ with some simple C++11/14/17 things, but really nothing special. One 31K cpp, one 23K .h, the rest mostly under 10K. 4,232 total "wc -l" lines, so prob &lt; 3500 LOCs. 2. I don't recall hanging in non-Preview versions (15.2), but #3 below happened there also. I always use the dark theme, and I have 8 24" monitors, with the VS typically in one of them. 3. I think there's some interplay between the "highlight current variable I'm on" functionality and code-completion (and maybe the brief delay). It seems to happen a lot when I right-arrow or CTRL-RIGHT and start inserting a new variable -- there's a tiny delay and then the highlight turns on, and the next time I type something, it auto-completes and overwrites it. For example, I've seen cases where I start to right-arrow to insert "dog.bark()" right in front of cat.purr(), and I wind up with "dog.bark.purr()" or "dog.bark().purr()" if (cat.meow() || cat.purr() || cat.hiss()) {return;} 4. In this code base, I don't have really anything that should hang on auto-completion, and it didn't seem to be anything specific. I submitted crashes earlier today - I don't know where they go in your system, but I can provide some information offline if it helps you guys find the specific ones. You can reach me at my reddit handle @ g m a i l 5. debugger blowups -- I've had periodic hangs, not often, but say once per hour or two * I want to say it got a bit worse when I added "/std:c++latest" and some "if constexpr", but that could be coincidence * I've seen where introducing a vanilla conditional breakpoint causes it to die 6. "Microsoft Visual Studio Opening the file..." -- this happened during debugging, and just as I introduced a series of bugs where I started iterating thru a std::vector with cached itr and end in an outer loop and inserting into that vector in an inner loop. The VS screen went dim, and a tiny window popped up saying: Microsoft Visual Studio Opening the file... and it hung there until I killed it by taskmgr a few minutes later. After I removed the iterator invalidation, it obviously stopped blowing up. Few minutes ago I added the buggy code back, reran it, and this time it hit the debug error on line 80 of &lt;vector&gt; ("vector iterator not incrementable") and popped up a window without blowing up. It's possible that it blew up trying to display the window for this error or maybe some other "invalid iterator" error earlier -- idk what "file" it was trying to open, so can't help there. 
&gt; No, it doesn't. That's allocator providing a garbage init policy, not vector. It's like saying `set&lt;T, greater&lt;&gt;&gt;` is sorted in ascending order, and the order is provided by Compare. It is technically correct, but to a programmer, this set is sorted descending, and that vector is garbage-initializing. &gt; vector::vector(uninitialized_t, size_t N); How would I distinguish this from the vector that is safe to read? 
!removehelp
No, I have not. No, after a quick look, it does not exactly look like what I want. Yes, it is certainly a good tool and I may want to use it.
Why not this instead? template&lt;typename T&gt; std::enable_if_t&lt;std::is_floating_point_v&lt;T&gt;,T&gt; sqrt(T const x);
https://embree.github.io/ will give you super-fast intersection and bvh building.
Can you add a Travis CI or something for automated build and tests? 
At least with gcc the symbol is clean sqrt&lt;double&gt;, and it is not possible to more than one template parameter. 
!removehelp
my bad, will do
 I'm also having issues with vs2017 IDE( Version 15.1(26403.7) Release) The primary one being that every time I compile there is a chance it will "fail to write log file", and once this happens I can no longer compile, and must restart the IDE. This happens around 10-20% of the time when I hit compile. I can see a few MSBuild instances running when this happens, so I suspect that it is hung, and not releasing some log file that is needed for compilation. The exact msg it prints is this(I've replaced my solution path/name with word LOG) where LOG = full path of log file, which is the solution name followed by .log 2&gt;Failed to write to log file LOG. The process cannot access the file LOG because it is being used by another process. It also seems very common in vs2017 for it to report that an error happened during compilation, but it does not show any error message or indication of what it means by "error". When this happens I have to compile again, and the 2nd time no errors is reported. This happens all the time:( The solution I'm working in has 61 projects, so moderately large. 
filesystem, variant, optional, apply and more. I'd rather depend on a new standard than drag boost around.
Lets start with the itch you're trying to scratch, what is it that you're missing? I prefer having humans in the loop to designing and debugging over-engineered processes. There are tests, but they are rather sparse at the moment, just enough to allow me to move forward with confidence. Dist builds are updated when I deem the code stable enough, there is really no need for automation yet.
I think this can be done with template specialization (TS). So you could also use other linear algebra libs and be more flexible. (Odeint, a numerical integrator from the Boost library somehow manages to do that. You can use whatever vector datastructure you like. With TS you can for example specify how vectors are resized. I had to so this with the aramadillo linear algebra lib.) Usually you don't put matrices in a vbo, only scalars and/or vectors. So the aligned data problem actually shouldn't be a problem. I think my hacky solution should already deal with glm vecs because sizeof(glm::vec3) should be 3*sizeof(float). The only problem is putting the data of glm::vec3 in my buffer. But here again TS could help. I'll try that today :)
Wow, missed this totally, thanks.
Very nice, but actually I fail to see why the restriction was there in the first place. Why wasn't possible to make find() a template that accepts any type that can be compared to the object without the is_transparent typedef? Or was this a design decision? 
An interesting, albeit simple benchmark. I whipped up a naive ISPC implementation of the test: typedef unsigned int64 uint64_t; typedef unsigned int8 uint8_t; export uniform uint64_t ispc_loop(uniform const uint8_t buf[], uniform const size_t bufsize) { uint64_t result = 0; foreach(i = 0 ... bufsize) cif(buf[i] &gt;= 128) result += buf[i]; return reduce_add(result); } Results for non-sorted input: ``` simple 44578 lut 32557 bitfiddle 101680 partition 363645 zeroing 458814 bucket 66618 multiply 59104 paradd 41573 ispc_loop 42575 ``` And for sorted input: ``` simple 44578 lut 33058 bitfiddle 101179 partition 79140 zeroing 113701 bucket 171804 multiply 59104 paradd 41574 ispc_loop 15026 ``` The ISPC object was build with: `".\\ispc.EXE" "-O3" "--opt=fast-masked-vload""--opt=fast-math" "--math-lib=fast" "--cpu=core-avx2" "--target=sse4-i8x16" "-h" "speedup@exe\\speedup.ispc.obj.h" "-o" "speedup@exe\\speedup.ispc.obj" "..\\speedup.ispc"` The results are obtained on Haswell 5930K, clang 4.0.0, Windows.
That's great! One question, is that still using your own fork of cmake? 
By day, I work on a distributed physics simulation for video games By night, I do machine learning, specifically trying to develop agents for use in games.
 std::map&lt;std::string, int&gt; map = {{"a", 1}, {"b", 2}}; map.find("a"); Here `"a"` is of type `const char[2]`. When find is called an implicit `std::string` is created **once** before the call. If the parameter to find was a generic template, `const char[2]` would be passed to the function and an implicit `std::string` would be created at **each** call to `std::less&lt;std::string&gt;()`. So mainly, to avoid performance degradation in older code.
I'm working on a C++ port/rewrite/thing of the tint2 X11 panel: https://github.com/jmc-88/tint3
Just because it is convenient, doesn't mean it's right, does it? There are lots of solutions that are convenient. Many of them ultimately lead to a badly architected mess. But hey, go ahead and throw some more template magic at it, surely that's much better than just using the correct data structure to begin with... 
There is but `std::less&lt;T&gt;` is defined as something like: template&lt;typename T&gt; struct less { bool operator ()(const T&amp; lhs, const T&amp; rhs) const { return lhs &lt; rhs; } }; The `const char[2]` would be converted to `std::string` before the `operator&lt;` is called (as `std::less&lt;std::string&gt;` is used). Now you would use something like [`std::less&lt;void&gt;`](http://en.cppreference.com/w/cpp/utility/functional/less_void), but it was not there before. See [N3657](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3657.htm) for more details.
Yes, I asked the question a couple of months ago but I still don't really know for sure why a similar concept was not added to `std::unordered_map`. But if you can use external libraries, you may try the [tsl::hopscotch_map](https://github.com/Tessil/hopscotch-map#heterogeneous-lookup) I did or [boost::unordered_map](http://www.boost.org/doc/libs/1_64_0/doc/html/boost/unordered_map.html#idp776224432-bb) with a `CompatibleKey` and `CompatibleHash`.
Very nice level editor, It seems very complete and look easy to use. I also love the look of ImGui, I use it too in my project but just for in-game ui for now, I still edit my levels in txt, like a Neanderthal. 
They don't do that anymore, and when they did that, it's with `enable_if_t&lt;..., int&gt;`.
@1: https://m.imgur.com/t/simpsons/b0DFaUQ
Harder to read, can't do it with ctors. Maybe there is better reason, I don't remember. [Check it out](https://rmf.io/cxx11/almost-static-if) yourself.
am i missing something? auto result = std::find_if(std::begin(employes), std::end(employes), [](const Employee&amp; e){ return e.getId() == 1; });
Thanks! Apart from a free version for students, does it have a community edition? 
Nope. That said, there is a free demo, and EAP (beta) builds that might be usable for free for a bit. For open-source projects, you are able to get a free license however, under some conditions (https://www.jetbrains.com/buy/opensource/)
`std::set&lt;T, std::less&lt;&gt;&gt;`
You can test it for a month, delete all files, test it for another month again. That's what I did before I saw the student thing. You also do not have to be student. An university e-mail address is enough IIRC. In fact I am not a student (but lecturer).
Just a wild idea, but maybe you could store a pointer instead for one of the two? How does your company deal with employees with duplicate names, I wonder? 
If you're on a Mac, use Xcode! It's free and supports Objective-C, C++, and Swift. NetBeans and QtCreator, Cevelop are also free and available for all platforms, CLion is nice if you wanna $.
&gt; it downloads and installs a CMake project. It can build a project directly with `cget build`. You can also refer to local directories and files. &gt; How the project is built depends on the used recipe, and probably cget uses vanilla settings when fetching by URL. No, a recipe just encapsulates a bunch of cget arguments. You can call all those settings directly. &gt; I've never used it as I need tight control over how my dependencies are built - I mostly compile them with the exact same settings of my project. Thats exactly how cget works. All your settings are transitive to the dependencies. So you can do `cget build -DSOME_SETTING=...` And it will use those settings to build all the dependencies. You can also initialize your setting with `cget init -DCMAKE_BUILD_TYPE=release --std=c++11 --cxx=clang++` and those will apply to all builds. &gt; It builds a CMake project in your system, but it can do so for many variations with a single command. Actually the multiple variations is nice, which cget doesn't do. It would be nice if there was a config file that listed the variations and when you do `cmany b` it would read this configuration file to build the multiple variants. This would be similar to `tox` on python.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
C++98 didn't have the technology to write a transparent comparator; it could take arbitrary A and B parameters (ignoring value categories), but couldn't express how to return the (potentially different) result. That required C++11 `decltype`. Now my `less&lt;&gt;` does the right thing.
It's possible to envision a situation where duplicate names are restricted. I'm dealing with a similar situation right now. I have components that are assigned unique textual IDs and I need to be able to index them by ID so naturally I used a map. But I also wanted to be able to have a component be able to determine its own ID. I didn't want to have to pass the index map around (or any data structure that would allow the reverse lookup, ie. component -&gt; ID), and I didn't want the component to have to store a pointer to its ID because this makes managing object lifetimes harder. I read this article and decided using a set would be a great compromise. I'm now using a set of said components sorted by ID (and the ID field is indeed immutable). It's kind of like an intrusive map, and if there was a standard template available for making such an intrusive map, I would use that instead, but that doesn't exist in the standard. If you think about it that way, it's not quite a misuse of data structures. I agree it's unfortunate that this solution is using a class called "set" in a way that's not quite like a set, but I think you should look past the name and see what's actually going on with the data. Maybe a typedef could make it more readable. I just think that bending over backwards to adhere to the rules implied by the names, while it sounds like good design, can actually sometimes complicate the design somewhere else in the code. It's also unfortunate that unordered_map and undordered_set don't also have this transparency feature as sorting components by ID is not necessary and doesn't make sense for my data. TL;DR, an intrusive (unordered_)map would be most appropriate here, but it's not available in the standard. An `std::set` makes a good substitute.
I'm a noob, but how does the is_transparent trick work ? How does the STL know it has been "typedef'ed" ? I don't really want to look at the implementation as I believe it'll just confuse me more
That won't help; in that world `map`/`set` would be using something like `less&lt;std::string, std::string&gt;` as default, and you still can't use `const char*` without incurring a conversion. The real question is "why doesn't C++98 `std::less` have a templated function call operator". And I suspect that the answer has something to do with the old adaptor protocol - in particular, `first_argument_type`/`second_argument_type`. There's no sane way to define them - and C++14 `less&lt;&gt;` doesn't even try.
W/ CDT, what problem were you having
No CMake support though. More or less unusable on non-Unix systems due to that, as the build scripts are automake/shell from the looks of it.
I don't think this problem is new either, I have it on VS2013. It's pretty annoying.
&gt; Actually the multiple variations is nice, which cget doesn't do. Yes, that's precisely the main focus of cmany, as I try to imply with the name :-) &gt; It would be nice if there was a config file that listed the variations Yes indeed! [There's already a way to store arguments](https://cmany.readthedocs.io/en/latest/reusing_arguments/) by using the environment variable CMANY_ARGS. cmany will pick up its value and use it together with any other argument you pass in the command. For example: $ export CMANY_ARGS="-c clang++-3.9,g++-7,icpc -t Debug,Release" $ cmany b # 6 builds If you write the export CMANY_ARGS statement into a file, then you can save it for the next session and then source it. With respect to the config file, I started developing this but then had second thoughts. Since cmany takes the compilers by path (ie, it tries to find a compiler with the given name in its path), and to prevent the file from being different between project devs, each dev would be forced to have compilers with the given basenames in their path. This is a minor inconvenience for sure, but it's still an inconvenience. Also, the full combination of build items can easily result in hundreds of build trees. Most of the time, we do not want to do build all those trees (if we wanted, then using a script is easy enough). I found that in my workflow I usually use CMANY_ARGS for some hours while iterating until I fix some problem in the project I'm working on, then change something in it for the next couple of hours and so on. So CMANY_ARGS has been covering my needs quite satisfactorily. But the config file definitely has some appeal, and I fully admit I'm on the fence here. &gt; Thats exactly how cget works. All your settings are transitive to the dependencies. Thanks for the clarification. I'm going to learn myself a bit about cget; if I find it useful I may come to add a cget backend for dependencies. I tried briefly to do conan, but found it hard to pass flags to it and gave up. For my dependencies, I usually write a separate CMakeLists.txt project with calls to ExternalProject_Add(). Then [cmany has a --deps option](https://cmany.readthedocs.io/en/latest/dependencies/) which will build and install the dependencies for each build tree, before configuring it. But this concept still has some rough edges. * EDIT: add link
why template&lt;class T, enable_if_t&lt;is_floating_point_v&lt;T&gt;&gt;&gt; T sqrt (T x); not work? sqrt(3.14); //compile error gcc7.1
when you expand the enable_if_t you get: template&lt;class T, typename enable_if&lt;is_floating_point_v&lt;T&gt;&gt;::type&gt; T sqrt (T x); so your second template parameter is a value of type void, which doesn't have a default value so has to be specified. but since parameters of type void aren't allowed this isn't even possible.
The presence or absence of a nested typedef can be detected by templates by using C++'s "Substitution Failure Is Not An Error" mechanism (SFINAE). SFINAE was originally added to C++98 in order to make it easy to provide overloaded function templates, but library authors (my people!) soon noticed that it could be used for compile-time introspection. C++11 added Expression SFINAE which is even more powerful - now we can detect whether arbitrary expressions are well-formed (like, "can I say `kitty.meow()`"), not just looking for nested typedefs. There are many ways to write the SFINAE code for doing this, but the most modern is the `void_t` detection idiom.
&gt; Underscores as a prefix is reserved by the standard. Using them is frowned upon. Not necessarily true. Identifiers beginning with underscores in the global namespace are reserved, as well as any identifier beginning with an underscore followed by an upper case letter and any identifier containing double underscores. Member names that begin with an underscore followed by a lower case letter are allowed.
the second template parameter no template&lt;class T, enable_if_t&lt;is_floating_point_v&lt;T&gt;&gt;&gt; T sqrt (T x); becomes: template&lt;class T, typename enable_if&lt;is_floating_point_v&lt;T&gt;, void&gt;::type&gt; T sqrt (T x); because the member typedef of enable_if defaults to void, so this becomes: template&lt;class T, void&gt; T sqrt (T x);
Still reading but: I think there is a small syntax error in first petra example in the README. The lambda seems to be missing its closing brace.
Nvim with the right plugins it will do more then anthing else out there.
I didn't actually outright delete the non trivial copy constructor, I have a setup like this: template &lt;typename T&gt; struct example { constexpr example(const example&amp;) = default; example(flag_type flag, const example&amp; other) { ... } }; The utility struct i described adds the flag_type param when desired.
Thanks for the clarification! Please continue to keep us posted on your thoughts on Visual Studio, your feedback helps us determine where to set our priorities and what changes we should make. I started a discussion internally on this issue. If anyone else feels similarly about IntelliSense deleting words just to the right of the cursor, please let me know. 
Yeah, `B` needs a default constructor and also some defaulted moves unless you want to disable those too, etc, just a quickie to give the flavor. Also I do not understand why it requires defaulting the copy constructor: #include &lt;iostream&gt; #include &lt;type_traits&gt; #include &lt;vector&gt; struct A {}; struct B { B(const B&amp;) = delete; B() = default; }; template &lt;class T&gt; using basetype = std::conditional_t&lt;std::is_integral&lt;T&gt;::value, A, B&gt;; template &lt;class T&gt; struct MyClass : private basetype&lt;T&gt; { T t; MyClass(const MyClass&amp; m) : basetype&lt;T&gt;(m), t(m.t) {} MyClass() = default; }; int main() { MyClass&lt;double&gt; x; MyClass&lt;int&gt; y; // auto x2 = x; auto y2 = y; } Seems to do everything. http://coliru.stacked-crooked.com/a/6b137ff12f8d8c62
This postmodern thing is catching on
God, no, seriously 
And according to "Reinventing Organizations" we are already behind the next wave. Cruel times we live in.
Good point.
&gt;it doesnât make sense to compare two employees and say which one is bigger Uh, this is how I perform ranking boards.
... Looks like I'm gonna be doing some refactoring on Monday. 
RAM is cheap though, but cache isn't. Looking up a single ID member in an object wastes a lot of cache, whereas if you have a list of IDs that are grouped together (as with `std::map`'s buckets) then the code may actually be faster.
Another common necessity for this is with smart pointers (ie. when you need to search by the raw pointer, or even by object).
Basically it is absolutely possible and if it seems like a good idea it probably is. I can't say anything about exceptions, but you do want to make sure that allocations in a shared library are freed from the shared library and vice versa. The reason is that different allocators could be linked in. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [jbandela/cppcomponents/.../**plugin** (master â 14531ab)](https://github.com/jbandela/cppcomponents/tree/14531aba5941aa85e77d9f87c002aaa8465ae7a8/examples/plugin) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dipe5rp.)^.
Map keys aren't stored like that. Each key is bundled with its value in a node, with no locality.
Aren't nodes stored next to each other? In the case where the value is a pointer (which I find to be pretty often, at least for large objects), then you lose some cache efficiency with the pointer, but you still grab some keys after it. If the nodes aren't stored next to each other, then I think at least it's possible to write a custom allocator that does it?
Fuck. That. Loading a shared library is one system call on windows and a couple at most on linux. It's super simple and few #ifdefs later you have cross platform shared library loading. There is no need to pile on these huge libraries for something that should add KB to your source and less to your binaries. 
this does not actually give you any software maintenance win over carefully separating out concepts among source files and groups of source files. It makes you deal with when loading and unloading happens, how to make the system robust to accidental misconfiguration of plugins, and it will likely add quite a bit of effort to your build system setup (which you're probably already spending a huge amount of time on because this is c++). Things like COM are examples of this architecture and while I'd argue that COM does provide some benefits for exposing platform APIs it's not exactly smooth to use, and writing COM objects is a real pain in the arse. Ultimately by using a plugin based approach you codify things in a very public way, and if your app ever gets popular then you need to stick with that plugin based arch essentially forever. Hedge your bets and enforce the code separation without exposing the plugin interface or dealing with ABIs. one nice (well sometimes not so nice) is that if you try and use multiple different versions of the same library your code won't link. This is not ideal in some situations (for example libs that provide a stable ABI but happen to link to different versions of the c runtime or the c++ standard library. it also sounds like you could end up duplicating a lot of the stuff that the loader already does for you, which again is not ideal. What is a kernel if not a big plugin loader :|. I would suggest that you instead build everything as one executable but keep track of the dependencies between various parts of said executable (in an automated way).
Regardless I thought `map` implementations usually stored the nodes in buckets, so the nodes would be next to each other in the bucket.
Map implementations are like lists: they dynamically allocate nodes and don't care where they come from. The allocator may internally be bucket-based (as Windows' Low Fragmentation Heap is, which is used by default). In any event, there is no real representation difference between a map and a set, and both are pretty hostile to locality.
Just have the key point to a value's member and use the proper data structure, i.e. map. 
&gt; How would I distinguish this from the vector that is safe to read? You don't. That's the whole point. If a function processes `vector&lt;double&gt;` why make doubles read from disk through `fread` second class citizens?
The original rationale is discussed in N2713 here: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2713 Reproduced below: &gt; An early version of the non-static data member initializer paper deleted âstaticâ from 7.1.6.4p4, which lists the places where the auto type-specifier may appear. &gt; &gt; One national body disliked allowing non-statics to be declared auto. From an e-mail to the author: &gt; &gt; template&lt; class T &gt; &gt; struct MyType : T { &gt; auto data = func(); &gt; static const size_t erm = sizeof(data); &gt; }; &gt; &gt; In order to determine the layout of X, we now have 2-phase name lookup and ADL. Note that func could be either a type or a function; it may be found in T, the namespace of MyType, the associated namespace(s) of T when instantiated, the global namespace, an anonymous namespace, or any namespaces subject to a using directive. With care we could probably throw some concept_map lookup in for luck. &gt; &gt; Depending on the order of header inclusion I might even get different results for ADL, and break the One Definition Rule - which is not required to be diagnosed. &gt; &gt; Because of this controversy, the current version of the initializer paper, N2712, retains the âstaticâ. &gt; &gt; Recently, it was pointed out on comp.lang.c++.moderated that one can get the same effect anyway, just with uglier code, using decltype. Because of that, the author believes that the objection to auto has softened. At WG21 the above paper was briefly discussed and it was noted that there were other technical reasons why this is a bad idea that I do not know.
since you can break the one definition rule anyways with "decltype"... I wish they could just cancel this restriction for "auto", I really luuuv "auto" as someone that learned Python as the very first programming language..
I have been considering making the plugins a compile-time only thing actually, and thus linking to them statically. Still, I will probably try to go with the dynamic loading road first (this is a greenfield hobby project so I have some room to experiment), the article was very helpful for that thank you!
Thanks a lot! I used Reveal.js: https://github.com/hakimel/reveal.js The slides are here: https://sinusoid.es/talks/immer-cppnow17/
And it is _very_ low level. This is an example for fetching a file and printing it: #include &lt;beast/core.hpp&gt; #include &lt;beast/http.hpp&gt; #include &lt;boost/asio.hpp&gt; #include &lt;boost/lexical_cast.hpp&gt; #include &lt;iostream&gt; #include &lt;string&gt; int main() { // Normal boost::asio setup std::string const host = "www.example.com"; boost::asio::io_service ios; boost::asio::ip::tcp::resolver r{ios}; boost::asio::ip::tcp::socket sock{ios}; boost::asio::connect(sock, r.resolve(boost::asio::ip::tcp::resolver::query{host, "http"})); // Send HTTP request using beast beast::http::request&lt;beast::http::string_body&gt; req; req.method(beast::http::verb::get); req.target("/"); req.version = 11; req.insert(beast::http::field::host, host + ":" + boost::lexical_cast&lt;std::string&gt;(sock.remote_endpoint().port())); req.insert(beast::http::field::user_agent, "Beast"); req.prepare(); beast::http::write(sock, req); // Receive and print HTTP response using beast beast::flat_buffer b; beast::http::response&lt;beast::http::dynamic_body&gt; res; beast::http::read(sock, b, res); std::cout &lt;&lt; res &lt;&lt; std::endl; }
Is Pacific++ a new conference? Will Aus. host 2018?
&gt; boost::asio::ip::tcp::resolver::query{host, "http"} We need to go deeper!
Probably a relevant discussion: https://stackoverflow.com/questions/6434971/how-much-is-too-much-with-c11-auto-keyword (To be honest, I don't like reading other people's code when they declare everything as auto and I have to check function headers or even their definition to find out what types they return)
This looks like a really cool idea. I find the decision of defaulting to `N` a bit strange though (I prefer *loud* errors). Alternatives could possible include: - passing an `InvalidInputType` like for `switch`, - throwing an exception, - return `optional&lt;T&gt;` instead of plain `T`. 
I totally agree with you on that before C++11, but I think cpp has gotten a lot more high level directly at the language level since C++11, about type-aware, I'm more of a "duck type" guy than "you define like 1000 interfaces to do generic stuff" kind of Java programmer, I can do that "static duck type" thing with templates and I'm happy with that, I rarely use features like "inheritance" or "virtual functions" or things like that, I won't use dynamic polymorphism (virtual functions) in cpp unless there's no other way, not because vtable slows the program down tiny little bit at runtime, but because I personally don't like the "you define an interface for everything" idea.
Eventually, yes!
Hmm `std::map&lt;std::string*, Employee&gt;` is near impossible to initialize (the pointer isn't available until after the node is constructed, but maybe `std::map&lt;std::string*, std::unique_ptr&lt;Employee&gt;&gt;` would work... I have to say I don't see a downside to that right now. I'm willing to change my mind in the face of new evidence. 
So is `std::map&lt;std::string*, std::unique_ptr&lt;Employee&gt;&gt;` okay do you think? I guess I'll try that.
What was the rationale of this module? Why was it needed?
I want a language that's near high level as Python and also gives me the freedom to mess with pointers (I'm currently a CS college nerd and I think getting to know how things work from the very basics is important to me, so I NEED pointers, like I wanna learn how to manually destruct an AVL tree without the help of automatic GC, and I don't wanna deal with a lot of low level details all the time, I merely want to know the low level details when I'm doing some data structure algorithm, so no, C and old fashioned C++ and Java (Java doesn't have type deduction and templates and nested functions and won't let me play with pointers) are too low level to me, Python is good but it's too high level and won't let me do pointer stuff, modern C++, especially C++17 feels right to me, the syntax is almost as high level as Python (type deduction, range for, nested functions via lambdas...) and also allows me to play with pointers).
&gt; version 52 Incredibly petty question I know but how do you deal with API changes using this version numbering? Is this still considered alpha and you are looking to bump to the big 1.0 at some point?
Personally I had bad experiences with its code completion. It doesn't seem to handle large projects, nested macros or obscure code (directly calling destructor ) too well
&gt; Things like COM are examples of this architecture and while I'd argue that COM does provide some benefits for exposing platform APIs it's not exactly smooth to use, and writing COM objects is a real pain in the arse. It sounds like you are judging plugin architectures by one complicated plugin architecture that was done very poorly. &gt; and if your app ever gets popular then you need to stick with that plugin based arch essentially forever. Hedge your bets and enforce the code separation without exposing the plugin interface or dealing with ABIs. I don't know what this is supposed to accomplish. There are dozens and dozens of examples of plugin architectures being incredibly successful with popular programs. 3D programs, Adobe programs, compositing software, VLC, winamp, touch designer, the list is pretty big at this point. It is completely plausible to expose a C API so that the ABI is not a big deal. A few examples and templates and most people can get up and running quickly. &gt; it also sounds like you could end up duplicating a lot of the stuff that the loader already does for you, which again is not ideal. What is a kernel if not a big plugin loader :|. How so? Loading shared libraries is not difficult or complicated on any platform. 
Loading a shared library is simple, but sharing a common c++ interface is not. You cannot just GetProcAddress a class method. 
I agree that `auto` should be allowed as part of a `struct`'s definition, especially considering that it is already possible through the use of macros. It would be very useful when dealing with generic metaprogramming stuff that requires wrapping some values into small structs where the types are dependent on template parameters and are annoying to type out. To everyone saying *"using this feature would make code less readable"*: **you can say that for any new feature.** Abuse of a feature makes code less readable. People can abuse lambdas, macros, `auto`, and many more things today. There's no reason to limit the expressiveness of a language because some features might be abused: whoever does that would already write poor code with today's standard anyway.
Qt Creator is pretty good, the integration with the *nix toolchains is top-class, ranging from having a Clang code model (much better than whatever JetBrains hacked up) and Valgrind tools (eg. memcheck and function profiling). Also notable is that Qt Creator is much more lightweight compared to CLion, both in terms of memory and processing power (mostly because of no silly Java overhead). While I had CLion consume ~3GB of memory after running for a couple hours on a medium-sized project, Qt Creator would sit at ~250M.
God please don't let this happen. Auto should be used with caution as it tends to obscure the expressiveness of your code. I certainly don't like the idea of having structs with 10 auto fields. It might be useful for TMP though. Also keep in mind that auto type deduction does not equal decltype deduction rules.
I prefer Xcode. It does not (yet) support cpp17 and has no refactoring tools(at least not for cpp), but it comes with a set of profiling and debugging tools that are pretty convenient. 
And it's a personal taste kinda thing like I said earlier, you may think it tends to obscure the expressiveness of the code but I think it would obviously enhance the readability of the code cuz that's how things are done in high level scripting languages like Python, you may care a lot about the types but I don't, but anyways, I hope you have a nice day today!
Summing of MerryMage's comment as I read it: it was believed that `auto` for non-`static` data members would require more work for the compiler (slower builds) and would add to the set of situations where one's code would be silently broken. The first belief has been shown to be incorrect, and the second is arguable. Though I think that the easier it is to break something, the greater the likelyhood of breaking. What I miss in this discussion is the viewpoint of *uniform notation*. Currently the C++ syntax limits Herb's advice to prefer `auto`, [Almost Always Auto](https://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/), to local and namespace scope variables. The same reasons for using `auto` for those, would presumably apply for non-`static` data members.
&gt; You see that gcc doesn't manage to vectorize simple16b under debugoptimized From the table it looks it's the other way around, clang fails, not gcc. 
&gt; I certainly don't like the idea of having structs with 10 auto fields. That's a weak argument. If you don't like that, don't do it. If other people do it, they're abusing the feature unless they have a very good reason to do so. If a programmer abuses a feature, it's not the feature's fault. There are good use cases for `auto` as an struct data member type.
I don't see how the title relates to the content.
[Argh](https://github.com/adishavit/argh) fulfills many of your requirements but does not attempt to be an all powerful library, preferring simplicity for fast and immediate lightweight use over complex features. 
To make the code more expressive we write things like `keep_if` as a separate function instead of rewriting the needed loop on our own every time. Thus we are less likely to make an error, since a generic function like `keep_if` has a very high probability to be bug-free. This results in an increased probability of correctness overall.
I agree, but going through the asm output would have been too much for this video in my opinion. But here are two version (range-based for and transform) with side effects: [`range_based_for.cpp`](https://gist.github.com/Dobiasd/1f1f0390f6fdeb42dfae4ef3311a781d) [`transform.cpp`](https://gist.github.com/Dobiasd/ab0677bac8d0e2d6003f25cc52a97de4) I compiled them as follows: clang++ -std=c++14 -S -mllvm --x86-asm-syntax=intel -O3 range_based_for.cpp clang++ -std=c++14 -S -mllvm --x86-asm-syntax=intel -O3 transform.cpp And this is the output: [`range_based_for.s`](https://gist.github.com/Dobiasd/1ec9d7ccb155f5d8b9deaa119ada3d95) [`transform.s`](https://gist.github.com/Dobiasd/e3147981c50f45028e4f02fabc2e8e65) It's a bit long but the diff shows that the generated code is similar: diff range_based_for.s transform.s &gt; range_based_for__transform.diff [`range_based_for__transform.diff`](https://gist.github.com/Dobiasd/f182fd282abf55fcd8b733b281cf8fc8) --- Thanks for the good remark by the way. I added the analysis from above as a resource in the video description. 
Why do people keep "using namespace std;" ð­
I would prefer the expressive form even if it were used just once, in which case DRY does not apply. This is more of an application of separation of concerns, or ["what not how"](http://wiki.c2.com/?SeparateTheWhatFromTheHow), or ["intention not algorithm"](http://wiki.c2.com/?IntentionNotAlgorithm).
Sure it is. OP is defining higher order functions to eliminate procedural code. That's a pretty standard example of functional programming in practice.
This is a good opportunity to become familiar with [Compiler Explorer](https://godbolt.org/g/nvjnXu) â with this view, it becomes readily apparent that the code generated is in fact identical. :-] --- EDIT: BTW, I don't think `transform_vec` is a terribly useful abstraction as-is, since it artificially limits the result value-type to be the same as the input value-type; far better to allow differing types, as `std::transform` itself does: template&lt;typename F, typename T, typename R = std::decay_t&lt;std::result_of_t&lt;F&amp;(const T&amp;)&gt;&gt;&gt; std::vector&lt;R&gt; transform_vec(F f, const std::vector&lt;T&gt;&amp; xs) { std::vector&lt;R&gt; ys; ys.reserve(xs.size()); std::transform(begin(xs), end(xs), std::back_inserter(ys), std::move(f)); return ys; } [Demo](https://godbolt.org/g/rzQAUC) (N.b. I've not watched the video, so I realize this may likely be overly complicated for your purposes.)
Meh, I prefer MS Notepad. ^^^^^/s
The software I work on (https://github.com/OSSIA/i-score) is based on a plug-in architecture. Pros: * Very easy to add new code without disturbing existing one, since the linker enforces strict boundaries between plug-ins (that is, if compiling with `-Wl,-z,defs` and default to hidden visibility, you won't be able to access any "private" class of your plug-in without a build error). * More generally, enforces good code hygiene since you have to define clean and simple interfaces, and a you get a neat dependency graph. * Possibility to build a plug-in marketplace where other people can add their own plug-ins to your software. * Linking is faster in debug mode if you only change one plug-in. Cons: * Sometimes a lot of refactor will be required if your users request features that would imply that a plug-in would depend on another. * Building &amp; running on some platforms (Android, iOS, emscripten, IncludeOS) can get a bit hairy. I personnally have continuous integration that enforces [both dynamic and static builds](https://travis-ci.org/OSSIA/i-score) of the software + core plug-ins. * It's harder to do quick hacks; and if there are hacks they will feel much more dirty than a non-plugin architecture. Some examples from my code : * [A core plug-in class. The 'factories' method lists all the available implementations of interfaces in a given plug-in](https://github.com/OSSIA/i-score/blob/master/base/plugins/iscore-plugin-js/iscore_plugin_js.cpp) * [Declaration of an interface that other plug-ins can provide implementations of. UUIDs are used to differentiate plug-ins.](https://github.com/OSSIA/i-score/blob/master/base/plugins/iscore-plugin-curve/Curve/Segment/CurveSegmentFactory.hpp) * [Using templates to have only very little code to write to implement factories](https://github.com/OSSIA/i-score/blob/master/base/plugins/iscore-plugin-midi/Midi/MidiFactory.hpp) * [Implementation of an actual class](https://github.com/OSSIA/i-score/blob/master/base/plugins/iscore-plugin-midi/Midi/MidiProcess.hpp) * [Plug-in loading code](https://github.com/OSSIA/i-score/blob/master/base/lib/core/plugin/PluginManager.hpp) 
I too use Xcode. It is a decent IDE. Once you have to do any source level debugging, you will understand why this is the right choice. Eventually, Visual Studio Code will support CMake and then I'll give that a try. It is an excellent editor. 
In your second example: I think `auto result = get_result(i);` should be `auto result = get_result(x);`.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [isocpp/CppCoreGuidelines/.../**CppCoreGuidelines.md#Rs-using** (master â 6907911)](https://github.com/isocpp/CppCoreGuidelines/blob/6907911089a1217463d48a439a344e78c4fd3bbf/CppCoreGuidelines.md#Rs-using) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply diq7url.)^.
"uniform notation" with many subtle inconsistencies. It's better to be glaringly inconsistent than subtly inconsistent.
That's not an argument, but rather an opinion. I agree with the comment above: use Auto when you really don't know the type, not when you're too lazy to write it.
&gt; especially considering that it is already possible through the use of macros Not really. 
I think you're accurately describing the motivation behind DRY, but I think there are distinct reasons for coding this way that are independent of the potential for reuse. Separating the concerns of iteration and element transformation means that the organization of the code will map easily to the conceptual space of the reader's mind. Iterative transformation is a process that is well known to me, so if I see two function signatures that denote "iteration" and "element transformation" I have to do very little mental work to understand what's happening. If these concerns are intertwined I have to do non-trivial mental work to confirm that the code correctly maps to iterative transformation. As long as these concerns are intertwined, any edits I do to this code requires me to mentally confirm that changes to the iteration don't interfere with the element transformation and vice versa. All of that applies regardless of whether I plan to reuse either part more than once. I agree that coding like this does promote reuse, but I think the clarity of communication and obvious correctness are the more important benefits.
Fixed
You don't have to copy anything around, just replace `std::transform` with `std::parallel::transform` for the error to trigger.
OK, thanks for the explanation. It makes sense to me. So `using`-directives should probably only be used in a limited scope inside a compilation unit, for example at the beginning of a function body or alike.
There is no reason a program in C++ needs to expose a C++ plugin interface.
&gt; Stability suffers due to arbitrary code being added. You can catch hardware interrupts with signals / structured exception handling so that a plugin crashing doesn't crash the whole program. &gt; Maintainability can suffer because the number of configurations of your applications becomes pretty close to infinite Why are the plugins not isolated from each other? 
Here's what the article said about the ID: "since it doesnât make sense to compare two employees and say which one is bigger, every employee has an ID, that provides a technical order by which the employees are sorted in the set." So, this is *not* an employee ID assigned by the employer. This is something added by the programmer simply to allow employee objects to be stored in a set. Ergo, there's no need or interest in finding an ID from an Employee--it's something nobody ever really wanted, just an accidental by-product of using a set where it didn't really make sense.
How? Can you elaborate on why not?
Have we hit the point where functional programming is so ubiquitous that it's unrecognized as such?
So I assumed the approach being used here was the classic direct method invocation of plugin code. So in that way you are still at the mercy of segfaults (you cannot safely recover from one of those). Going the Chrome route of using IPC and separate process is definitely possible but you still have an issue similar to browser extensions. At some point feature from plugins will interact and not always in good ways, if they could not really interact they would probably not need to be plugins in the application. Users can choose there plugin config, but as the team shipping the app you are always responsible for the final application behavior.
Postmodern C++.
&gt; What bugs me sometimes is, that it is not really working for C++17. I wish they just used Clang as a backend parser/AST instead of their own implementation. I guess its because Clion is Java and its tough to interface with the Clang libs without tons of JNI overhead but their parser isn't always up to speed with prominent compilers in terms of standard compatibility or ability to parse complicated code.
Awesome solution. Thanks!
One can't prevent a crashing plugin from taking down the program, this is quite naive. It can be done only in some situations, when one is lucky that a crashing part did not cause damage to the rest of the process. The correct manner to prevent plugins from crashing is using the system facilities (e.g. process isolation, running te plugin in its own process and using some form of LPC to call into it and back. tl;dr: no, code can't fight UB; it has to be modified to eliminate UB.
"Static linking" to a library normally means that the code of the library becomes part of your executable (or so/dll). "Dynamic linking" normally means that the code of the library lives in its own executable (so/dll) and is loaded into the program by the system when the program starts. "Dynamic **loading**" normally means that the code of the library lives in its own executable (so/dll) and is loaded into the program **by the program code** at whatever point (not the system). This is achieved using system facilities like dlopen/dlsym on Unix or LoadLibrary/GetProcAddress on Windows. Normally, talk of plug-ins only applies to dynamic loading.
anyways, I found another loophole here, decltype cannot be used to capture lambdas..
`nullptr` is not of a pointer type. E.g. during overloading resolution of a function `T*` can't match `nullptr`.
Fair enough, it was the first thing that came to mind. For the sake of example, `auto p = new int;` would express my intent just as well that `p` is deduced as a pointer.
It's unlikely you'll ever find those five characters to be the source of over-verbosity. Rather, it's usually when you start to have templates inside of templates (like ``std::vector&lt;std::vector&lt;MyObjects&gt;&gt;`` for a 2D array of objects) that things start to get ugly. I recommend using aliasing on a case-by-case basis. For example: using MyObjectMatrix = std::vector&lt;std::vector&lt;MyObjects&gt;&gt;; So instead of worrying about a whole namespace, just apply aliasing where it's relevant and helpful.
OK, I was not consciously aware of it, but I had a look into longer cpp files I wrote, and I mostly do not use `using namespace std;` there globally. For these videos however I was trying to use as few characters as possible in the actual code to be able to use a maximum font size for mobile viewers. :D So perhaps this is the reason why I used it by default there. Now since I am aware how frowned upon this is in the C++ community I will avoid it in the future. However I guess I will not remake all my videos, since the editing (synchronization of separate audio and video recordings) is really annoying to me. ;)
 void MyClass::OtherInstanceMethodForThisClass() { // Do stuff } void MyClass::MyInstanceMethod() { UseLambdaAsACallBackWhenSomeEventHappens( [&amp;]{OtherInstanceMethodForThisClass();} } I sort of expected the &amp; to capture a reference to instance. Works if optimization is off. Hmm. I think I'm getting a cold feeling about this.... Let me guess, it captured a reference to the this pointer, not to the object pointed to. Not quite sure what I'm suppose to do. Maybe capture this explicitly.
But why a low level library? I'm not sure I understand the need for a "middleware" http library based on asio. Why not a full fledged client/server library?
Funny, seems to be "in the air" now with C++17 `inline` variables and `constexpr` lambdas to init arrays in-class. I had been using `make_index_sequence` machinery before, but that doesn't work with entries that are recursively dependent. Here's an example for initializing [a table of binomial coefficients](https://github.com/rhalbersma/dctl/blob/master/include/dctl/egdb/binomial.hpp) by using Pascal's Triangle Identity inside a lambda.
I didn't make much sense of their post other than the part I quoted, but the bottom line is that whatever their problem, it's surely caused by the lambda passed to `UseLambdaAsACallBackWhenSomeEventHappens` outliving the instance of `MyClass` that created it.
GCC is written in C++, interestingly enough.
Agreed; likely, they should restructure their code so that the instance of `MyClass` outlives its given lambda. It's all guesswork without actual code though.
for "boostAsioIpTcpResolver" your IDE at least will show autocomplete options
just watched it...I...feel confused
Thanks! There were a lot of awesome talks this year. Lisa Lippincott's "Locally Atomic Capabilities and How to Count Them" was awesome, but is not yet uploaded. David Sankel's "The Mathematical Underpinnings of Promises in C++" ( https://youtu.be/2OY0Zn3oBCE ) was also great. Only because you mentioned my Call talk, I may as well shamelessly plug my other session, "Restoring Your Sanity: An Approach to Dealing with Reference Types in the Generic Programming Paradigm", which examines how to properly design generic code that you want to work both with Regular types and also with reference types. The talk was influenced by the kinds of discussions that took place in the standards committee when attempting to provide reference support to std::variant and std::optional (neither currently supports references, but may in a future standard). This talk is also not yet uploaded and it involved a lot of audience participation, so I'm unsure how great of a video it will be. I did feel like it went well at the time, though.
Thank you, I'll check both out :) would you (or anyone) happen to know how come there were no presentations talking about ranges-v3? Is that because they are a done deal and there is nothing more to talk about? or is it just not such a hot topic at the moment, waiting for the library to actually make it in the standard?
I don't think there was any specific reason. Neither Eric nor Casey were there this year and there was a Ranges keynote from Eric a couple of years ago, which might make a different presenter feel a bit intimidated. Maybe we can reach out to one of them for next year or encourage others to present on the topic.
Some may appreciate a command line alternative to raw cmake, ccmake or cmake-gui in some projects. Thanks /u/nemequ.
Yeah, this happens all the time if there is something right under the cursor. Intellisense then deletes it.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6gmb0h/good_text_for_a_beginner/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
 cmake. - DCMAKE_BUILD_TYPE=Release Isn't terminal enough for you? 
Lots of effort to avoid learning a new thing.
Working in autotools was my own personal Vietnam. 
Looks nice.
Kind of. It doesn't do anything to shield people writing the build system from learning something new (that part is still CMake). What it does do is make the project much more approachable for non-maintainers. People who aren't already very familiar with CMake are a big part of that, but even for those who are it provides a much easier way to discover relevant options than reading through the build system's source code. One of the big problems with CMake is that a lot of the "learning a new thing" part is project-specific, and undocumented. You may not care about that; if you're the only person building the project it can save a few keystrokes and the syntax is a bit easier to remember, but it's not a big deal. However, for open-source projects it's very important to avoid any barriers which could discourage new contributions. Also, I'm not sure about the "lots of effort" partâ¦ the script is already written, so the effort required is just dropping a copy into the repo. Adding a configuration file to support project-specific options is optional, but also pretty easy.
Both autotools and cmake provide several common parameters and each project has bunch of project-specific parameters. Borth of them can list all of that with descriptions of what does what. So in this respect these tools are pretty much same except "skin" is bit different.
I know there's a bit of criticism for the necessity of such a tool, but I came across a need for such a tool just last week, and I'm very happy this has been pointed out because I may well have been saved the effort of writing an equivalent script myself. I've been working recently on the conversion of a large project from autotools to CMake. Right now, both build systems are maintained in parallel. There's a concern about breaking building for users who have been using the autotools for over two decades, plus all the infrastructure reliant upon it. This script provides a drop-in shim around the configure step, and so serves a useful need. I can now propose deleting the entire autotools setup and dropping this script in its place. Most users would be completely unaware of the switch. The script looks well thought out, particularly with respect to customisation of extra options, and I may well try this out very soon. Thanks /u/getfuture ! What are the current main lacking aspects of the wrapper? Support for cross-compiling with GNU triplets?
Hey, _I_, at least, appreciated the sarcasm. 
Clion, Qt Creator, Xcode.
I'm not sure most JS programmers are being trained with any explicit paradigm. I think you're right that they will be exposed to a couple functional concepts and thus might not recognise what paradigm they belong to.
Why provide the low level implementation? A lot more people would be interested in a ready to go http server where you just wire up some endpoints.
My phone autocorrected. It was supposed to be valid cmake option stuff.
That autocompletion could be zsh when properly configured, it should be possible with bash as well but no idea
This is partially explained in the Introduction &gt;An absence of high quality C++ network protocol libraries has led to a patchwork of open-source solutions lacking suitable conciseness and expressive power for standardization. The reason you aren't seeing really great C++ clients and servers is precisely because a "middleware" HTTP library does not exist. I would like to fix that by presenting Beast - maybe **you** will be the person who brings us that very special client or server, by building on top of Beast!
https://github.com/Kitware/CMake/tree/master/Auxiliary/bash-completion
Is it the absence of a network library or a low-level http library? Your quote and your comment say two different things. &gt; The reason you aren't seeing really great C++ clients and servers is precisely because a "middleware" HTTP library does not exist. I disagree. The reason servers mostly suck is because C++ is not often used in the backend. It is dominated by scripting languages, all of which either depend on standalone http servers or have their own, well-developed libraries. There _are_ great client libraries though. Boost.Asio has been around for 10 years and there are [many other high quality networking libraries](https://stackoverflow.com/a/118968/4885801), some of which are also http libraries, so I don't think that's a problem. &gt; by building on top of Beast! I just don't see the need for yet another low-level library that has to be wrapped again to become something useful. I would have loved to see a high-level http client/server library in boost. "Beast" is just adding another library to this "patchwork of open-source solutions". [It solves nothing](https://xkcd.com/927/). That being said, perhaps "Beast" will evolve with time to have a better interface that wraps its internals. Then I'll seriously consider it. In the meantime, there are plenty of solutions already available that are good enough.
[Image](https://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 4583 times, representing 2.8598% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dis0qqd)
&gt;Is it the absence of a network library or a low-level http library? Your quote and your comment say two different things. Network library. Without a standardized network library, development energy has been split across multiple network implementations (libuv, asio, select, etc...). I think that has held back development a bit. 
they taught us that in college also it's convenient for small code samples like this
Iterm2 - Vim - Tmux - youcompleteme
Your post has been automatically removed because it appears to be spam. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6gq6ve/fuck_visual_studio_right_now/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
papa why i am just angery, not a spammer
I actually thought about if I should have static_cast or reinterpret_cast here before posting, reinterpret_cast&lt;/*pointer type*/&gt;(nullptr); works on visual studio 2017, and I didn't know that's a complier extension, thanks for clarification 
The type of `"some text"` is `const char *`, not `char *`. If you catch it as such it works.
I believe the point being made is that the catch is incorrectly catching the exception when it should only catch exceptions of type "char*" and not "const char*"
MSVC catches it, but shouldn't, I believe.
Quoting from http://boost.2283326.n4.nabble.com/beast-Request-for-Discussion-td4688242.html ----- Fwiw, I have observed many examples of this purely âtop-downâ design over the decades. I have even seen some of them result in reasonably functional software. All too often, not even that. The result nearly always works, but often the top-level API dictates an inefficient implementation, and the top-level API gets locked-in by issues such as backwards compatibility and/or resource constraints. These are not hypothetical concerns. When a 2GHz 4-core dedicated computer canât keep up with my wifeâs typing speed, something has gone horribly wrong in many places up and down the software stack. I am not alone in recognizing these shortcomings and many people have gravitated towards a âbottom-upâ approach: Build a solid low-level foundation first which emphasizes performance. Higher-level software layers can add functionality. I have personally participated in several low-level projects with this âbottom-upâ view: unique_ptr, mutex, condition_variable, thread, and more recently low-level date algorithms: http://howardhinnant.github.io/date_algorithms.html Iâve had considerable success with this approach, but it is not perfect. As I add the higher-level API I sometimes find a missing brick in the foundation. There is nothing like real-world testing of low-level foundation software to find missing or poorly specified functionality, and building that higher-level API upon the lower-level *is* that real-world testing. If that higher-level testing can be done prior to setting the lower-level API in stone, one can achieve a valuable feedback loop where the lower-level level API can be improved while the high-level API is under development. I have also found that a high-performance low-level API usually guides the higher-level design. It encourages the high-level API to not do things that are gratuitously inefficient, as long as the low-level API stands its ground on delegating expensive fancy features to the higher-level. In the end, the very most important thing for software to be is correct. However, the next most important thing is run time performance: http://howardhinnant.github.io/coding_guidelines.html Correctness can be achieved with top-down or bottom-up. But bottom-up combined with early feedback from the top-down lends itself towards a software stack that is both fully functional and high performance. &lt;shameless plug&gt; This is the philosophy I have followed for the software stack discussed in this Cppcon 2016 talk: http://schd.ws/hosted_files/cppcon2016/0f/Welcome%20To%20The%20Time%20Zone%20-%20Howard%20Hinnant%20-%20CppCon%202016.pdf &lt;/shameless plug&gt; 
Ah, on second reading I believe you're right. Hiding that information in the title, instead of in the 'article', put me on the wrong foot.
That's fine but why release something that's half usable.
&gt; T j{}; //value-initialization (C++11) Not necessarily true, even under the rules in C++11 as published. `struct T { T(std::initializer_list&lt;int&gt;); };` &gt; in order to be trivial (and therefore POD) [...], a class must have no user-provided constructors Incorrect. &gt; If they decide that they should not be default constructible, they should delete the constructors to avoid issues. This is questionable advice. Deleting the default constructor doesn't affect the formation of implicit conversion sequences, which means that it can have undesirable effects in overload resolution: struct C {}; struct D { D() = delete; explicit D(int);}; void f(C); void f(D); f({}); // ambiguous
It _is_ usable... Again, it's a foundational library, not a high-level API â set your expectations accordingly.
But what is the use of a foundational library? Literally the only thing it will be used for is building a client or a server so why not build those? Not trying to be a dick but I think this is half finished work.
&gt; But what is the use of a foundational library? This is really a question..?
Yet another case for [event-driven programming](https://www.reddit.com/r/ProgrammingLanguages/comments/m0f1o/how_about_a_programming_language_in_which/). 
I use nvim and YCM all the time, and I love it, but never tried the rtags indexer. I will give it a go :)
&gt;I just don't see the need for yet another low-level library that has to wrapped again to become something useful. What other low-level HTTP library that has to be wrapped again are you referring to?
A tour of C++. https://www.amazon.de/Tour-C-Depth/dp/0321958314
`char* test = "test";` is legal but deprecated in C++98, and illegal in C++11. 
Well, no. The [shown example](http://ideone.com/LIcDk5) does not have any problem. Its behaviour is well defined and the programm leads to the same output with and without optimizations. It only becomes a problem if `x` runs out of scope before `callback` is called, [like so](http://ideone.com/9aNA0X). Perhaps this is what is happening in your application? Your guess regarding the capture list of the lambda &gt; it captured a reference to the this pointer, not to the object pointed to. was wrong. As dodheim pointed out, `this` is handled as a special case, and your capture list indeed captures a reference to the object, not a reference to the this pointer to the object. So as long as your object is not destroyed, the closure does not contain any dangling references.
&gt; easily debuggable unless 0 happens to be a valid input value, in which case it's harder to determine whether the input is correctly handled, or the variable is just in its initial state.
`"some text"` is not a pointer. It is a `const char(&amp;)[10]` (well, `(&amp;)` is stretching it).
I don't understand what you mean, the stack allocation has to happen anyway and happens in a few instructions.
!removehelp
&gt; Interesting, if maybe disillusioning, article but it doesn't answer why? Yes it does; did you not read the part on user-provided constructors..?
How's the proposal doing? Seems like a great idea.
Has not been presented yet.
Ok I waffled a bit, sorry. To more succinctly state the question meant in my mind: I get that this behaviour is correct as per the standard, but it seems counter intuitive, so why was the standard written this way?
ALA java. Is that value really 0/null or did some condition in the constructor cause you to not set it?
**Company:** [zenAud.io](https://zenaud.io) **Type:** Full-time **Description:** zenAud.io makes ALK, the VST/AU software looper that knows your arrangement. We're a small company with big ideas, based at NoizeFabrik in Europe's creative capital: Berlin. Since the successful launch of our flagship MacOS app, we're looking to expand the development team and are therefore seeking talented C++ and audio developers. The ideal candidate will have a degree in computer science or something similar (STEM), and should have a true interest in *modern C++*. **Location:** Berlin **Remote:** No **Visa Sponsorship:** No **Technologies:** C++17, Objective-C++, Cocoa, OpenGL, Metal API, JUCE **Contact:** Send us an email to: jobs@zenaud.io 
 &gt; &gt; in order to be trivial (and therefore POD) [...], a class must have no user-provided constructors &gt;Incorrect. As far as i can tell, this is actually correct: http://en.cppreference.com/w/cpp/concept/PODType
If I'm reading the standard correctly, pre C++11 required no user-provided constructors of any kind, while post C++11 only requires that the *default* constructors be "trivial" (implicitly defined or explicitly defaulted); other non-default constructors *are* allowed. 
What happens when `bar::bar() = default;` is in a different translation unit?
I understand the reasoning, but would find it dangerous if it was the only reason why it is guaranteed to work. What if instead of the while-loop there is a for-loop that runs at most N times; would the compiler be allowed to re-order then? How large may N be for it to still be a "reasonable" amount of time? Sure, a for instead of a while would break the code in this example, but might well happen as part of an lock-if-available of a spin lock. 
&gt; it should only catch exceptions of type "char" and not "const char" It _should_ be caught by`const char*`. I think your last part is switched.
&gt;And then changing the standard to initialize by default I believe you missed the point of the article, which is about to NOT use the default implicit zero initialization. In particular how the "uniform initialization" have another corner case that can lead to subtle errors. Please re-read the conclusion of the article: &gt;Fortunately, thereâs a simple solution. At the risk of repeating advice which has been given many times before, initialize your variables. &gt; &gt;Seriously. &gt; &gt;Do it. &gt; &gt;INITIALIZE YOUR GORRAM VARIABLES.
*It's not a bug, it's a feature!*&amp;trade; Unfortunately, the [`/Zc:strictStrings` \(Disable string literal type conversion\)](https://msdn.microsoft.com/en-us/library/dn449508.aspx) compiler option does not apply in this case. Some workarounds: 1. don't `throw "string literals"` and/or never `catch (char*) {...}` ^((*duh!*)^) 2. ~~`throw (const char*)"meow"`~~ 3. `throw static_cast&lt;const char*&gt;("type-safe meow")` 4. [`/Za` (Disable Language Extensions)](https://msdn.microsoft.com/en-us/library/0k0w269d.aspx)
Thanks for the link! Hmm, but I can't get it to work: [bash]$ source /usr/share/cmake-3.8/completions/cmake [bash]$ cmake -Cbash: _split_longopt: command not found bash: _parse_help: command not found bash: _filedir: command not found bash: _split_longopt: command not found bash: _parse_help: command not found bash: _filedir: command not found bash: _split_longopt: command not found bash: _parse_help: command not found bash: _filedir: command not found ^C And with `-D&lt;tab&gt;`, nothing happens.
 I think they try to strive for binary compatibility, but will break it when needed. Hence, its more of a feature of this release. Any 2017 RTM/Updates will guarantee binary compatability, but future releases of VS might break it. See the original response on this by u/STL: https://www.reddit.com/r/cpp/comments/5sfvfe/stl_fixes_in_vs_2017_rtm/ddf1tro/
- The out-of-class definition counts as user-provided so that it is not trivial, and changing the definition will not break the ABI. - The in-class definition does not count as user-provided so that we can have protected/private trivial constructors.
Google bans exceptions due to the enormous amount of legacy code they have, which does not support exceptions. The first paragraph of the "Decision" section of Exceptions in the Google C++ style guide states: "On their face, the benefits of using exceptions outweigh the costs, especially in new projects. " So yes, use exceptions, they'll make your life easier.
You cannot make any guarantees about a trivial type if its trivial behavior could cross module boundaries, breaking a basic POD equivalence. Without such guarantees, you also could not (always) make the same compile time decisions around trivial types.
For number 3, I usually use exceptions as an assertionâ. I throw but never catch. I use them only to make the program terminate in a graceful way when encountering unexpected errors, without resorting on undefined behavior to make it crash. Using exceptions will effectively free all resources correctly like memory, file handles, etc. In production code, exception never happens. It's mostly for debugging purposes or reporting when they happen in production code. However, if you need unwinding semantics for example terminating a fiber or other stuff like that, use exceptions. This is the only language feature that allows this sematic. Take what a say with a grain of salt. My needs may be different from yours. Always test and try and do what's best for your project. 
What I can tell you is: you do not understand the relation between a signal or an SE and UB. First there is an UB - e.g. code overwrote who knows what. That causes the system to emit a signal - but it's already too late! Sure, you receive a signal/catch an SE, but the damage is already done, possibly for **any** part of the process code/data, "belonging" to the plugin or not. You seem to believe that only a plug-in is affected, but that is far from reality. Quite frankly, I am amazed that we are discussing this.
sub'd - looks great to me
A different short #3 bug video: https://drive.google.com/open?id=0B43Bzic6_s9NU21MWWYyclNMZ0k
I said T(){} in additional to initializing members, however you want. Outside of that, I'm still not seeing why they're beneficial other than reading something about how they may be more efficient. EDIT: Ah, syntactically I meant T(); with member defaults, i.e. int j = 0; in the class body. EDIT2: Benefit outside of explicitly requesting a default constructor when other constructors are already present. EDIT3: https://msdn.microsoft.com/en-us/library/dn457344.aspx explicitly states that something like A(){} is an explicit default constructor. But besides that, it seems that the benefit is that these initial constructor design choices will have an impact on the assign,move,copy constructors. Is that the main benefit?
No, I most assuredly did not. The article points out that initialization is fraught with surprises in C++, and I suggested that maybe the standard needs to introduce an initialization guarantee _unless_ the programmer specifically requests uninitialized variables. In other words, to let the computer solve the issue instead of having yet another coding guideline to make the humans do it, as the article suggests. 
Correct. But interestingly, this does not, in fact, catch anything (MSVC2017): try { throw ("x"); } catch (const char (&amp;) [2]) { cout &lt;&lt; "caught!"; } ...while this does: try { throw ("x"); } catch (const char *) { cout &lt;&lt; "caught!"; } The plot thickens ;-) 
&gt; I have a way-too-boring and detailed blog post I can put online if people really care to read all the details stretching back two decades :) I would definitely be interested in reading it. Release it!
The world, and C++, is full of `decay`.
You're lucky if invalid memory access causes a crash. In that case, you can catch the signals. But what happens if a plugin accidentally modifies the main application's data instead of causing a segfault? segaults only occur when a program attempts to access memory that hasn't been assigned to it, but a segfault will not happen if an application attempts to modify its own memory in a way that shouldn't have happened. It would corrupt the state of the application and you won't know about it until it's too late. When the plugins and application share the same address space, you cannot prevent plugins from messing with the main application's memory.
Thanks for that answer. So short answer is, you are safe if you are in the same major version.
&gt; /Za (Disable Language Extensions) Isn't `/Za` still bugged for general use? Also, the usual approach of `/W4` - our MSVC Lord and Savior - notifying you doesn't work here, unfortunately.
AppCode is its own standalone product and it's just IntelliJ with the C++, Swift and Objective-C code. Very good IDE but also very pricey.
Idk why you have these [find()s being variadic](https://github.com/rakhimov/scram/blob/develop/src/ext/find_iterator.h#L62), won't find always take one argument? I believe [this std::forward](https://github.com/rakhimov/scram/blob/develop/src/ext/find_iterator.h#L40) should just be a std::move, you've set things up so Iterator is never going to be an lvalue reference. [This is a bug](https://github.com/rakhimov/scram/blob/develop/src/ext/find_iterator.h#L41), you are comparing your moved-from iterator against end; you just moved it when you passed it to the base class constructor on the previous line. What I'd recommend instead is instead of having find_iterator take a second Iterator to compare against, just have it take a `bool found` and have the call to it do the comparison as in find_iterator&lt;decltype(it)&gt;(std::move(it), it != container.end()) 
Yep, that's subtle bug, slipped on refactoring. Thanks for the deep review and feel free to PR the code directly if you wish. 
I made it an iterator because that's what std::find returns. Maybe it would be better to rename the function to exists or something. // This is what I envisioned... std::map&lt;int, int&gt; m = { { 1,2 } }; // pos - null if not found, iterator to 1 if found if (auto pos = opt::find(m, 1)) { std::cout &lt;&lt; "value is " &lt;&lt; (*pos)-&gt;second &lt;&lt; "\n"; (*pos)-&gt;second *= 10; m.insert(*pos, { 3,4 }); } 
C'mon, this iterator is going to be on the stack. As I noted, the compiler should be able to optimize this bool away. If you need to store the original iterator, the copy constructor of the base iterator is available implicitly, which would remove that pesky bool.
I really don't like the double dereference w/ the 'optional' approach. Would it better to have std::optional&lt;std::pair&lt;int, int&gt;&amp;&gt; and use the entry directly. Maybe even use the structured binding? Edit: 'deference' -&gt; 'dereference'
Wow, that just sounds like a really bad idea. The Debug and Release libraries are different beasts. But I'm not sure if there's actually policy here. I'd suspect that they are incompatible but will page /u/STL for an expert opinion.
What about Â§4.7.1.10? &gt; *The implementation shall ensure that no program execution demonstrates a cycle in the âhappens beforeâ relation.* I don't think the compiler is allowed to [reorder those statements.](http://i.imgur.com/lzrfpTc.png) ---- btw... &gt; *An implementation should ensure that the last value (in modification order) assigned by an atomic or synchronization operation will become visible to all other threads in a finite period of time.* void thread1() { A.store(1, std::memory_order_release); while (!B.load(std::memory_order_acquire)); } void thread2() { while (!A.load(std::memory_order_acquire)); B.store(1, std::memory_order_release); } [They all seem to rely on âinterrupt-driven store buffer drainingâ](https://godbolt.org/g/NF4lkg) :D 
Hi Andrew! I'm curious, does cl.exe officially accept options started with '-' as well as '/' and since when?
Release (IDL=0) and debug (IDL=2) are incompatible. We inject extra data members to perform iterator invalidation checks. Since 2010, we've enforced this with linker mismatch directives, although this only helps object files and static libraries, not DLLs.
[@leapmotion's latest tweet](http://i.imgur.com/kmep6SI.jpg) [@leapmotion on Twitter](https://twitter.com/leapmotion) - ^i ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
&gt; What about Â§4.7.1.10? That's interesting, but I'm thrown off [by the part that says](http://eel.is/c++draft/intro.multithread#intro.races-10) "Note: This cycle would otherwise be possible only through the use of consume operations."
[*Single Instruction, Multiple Data*](https://en.wikipedia.org/wiki/SIMD) Think SSE, AVX, and how a GPU works to process a lot of data simultaneously across instruction-synchronized cores (afaik).
##SIMD Single instruction, multiple data (SIMD), is a class of parallel computers in Flynn's taxonomy. It describes computers with multiple processing elements that perform the same operation on multiple data points simultaneously. Thus, such machines exploit data level parallelism, but not concurrency: there are simultaneous (parallel) computations, but only a single process (instruction) at a given moment. SIMD is particularly applicable to common tasks like adjusting the contrast in a digital image or adjusting the volume of digital audio. Most modern CPU designs include SIMD instructions in order to improve the performance of multimedia use. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/cpp/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^] ^Downvote ^to ^remove ^| ^v0.2
I edited my comment, but I'll try to give you some more info. I'm not super knowledgeable on it myself but have used it before. If you need to add numbers A to numbers B to get C (i.e. a whole bunch of `C[i] = A[i] + B[i]` calls), SIMD allows you to pack multiple values into a register that is processed in one step, i.e. you can put A[i] through to A[i+3] all into the one register, let's call it Ra, and B[i] through to B[i+3] into Rb. Now, we can do some sort of `Rc = Ra + Rb`, and because these registers have four numbers packed into them yet have the same cost as if we did just `C[i] = A[i] + B[i]`, we're getting 4x the throughput.
One big example are GPUs which have thousands of cores that can execute the same instruction on many chunks of data at the same time, which is nifty for doing things with images that have thousands of pixels and often need the same instruction executed on different regions. It's faster than iterating through the pixels in nested for loops. In some cases you can get massive decreases in complexity, such as a dot product being reduced from O(n^2 ) to O(1). On other processors, manufacturers will provide special registers that allow the same instruction to be executed on multiple chunks of data. So for instance say you two vectors of four floats and you want the element wise product. Normally you would iterate through those in a for-loop, or unroll it by hand. Some processors have 128 bit registers that allow you to pack four floats into a single register, calculate the product of each packed float in a single instruction, and return the results in another 128 bit register. They will also provide intrinsics to access those registers and instructions. Depending on your data, it can drastically improve your code's performance. The hazard of course is that it ties your code to a particular platform, which isn't always suitable. In addition, some operations cannot be done with SIMD intrinsics, such as when subsequent data relies on previous data. 
I find the links to these videos do not usually work on the Reddit mobile app, or is that just me?
It's also to make the class copyable again if you've given the type a custom move constructor (which inhibits the implicit copy operations).
hello, I do "normal" C++ coding, but sometimes I go a bit down and optimize something. I've compiled a list with various perf resources, so you might want to take some stuff: https://github.com/fenbf/AwesomePerfCpp also, some time ago I've coded some particle framework and simd was one optimization used: http://www.bfilipek.com/2014/10/flexible-particle-system-code.html
Really awesome idea, thanks :)
So.. I have a project that uses a bunch of external dependencies, and I want to build those dependencies in Release mode only. But I obviously want to be able to build my own code for debugging, so how do I link it to the Release external libraries w/o problems occurring at run-time? Right now, I've defined "RelNoOpt" configuration for my code which links against Release CRT, but disables all optimizations. Kind of emulates Linux where there is no "Debug" and "Release" CRT. Is there a better approach to this? 
The debugger showed the functor contained crazy at the point of creation of the lambda. (Same crazy as at the point when the lambda was applied to the argument.) So it's not a object life time issue. Still will have to dig deeper / further.
Adjusting volume you say?
The easiest way is to return pointer to the value or null if it doesn't exist. You could also return `optional&lt;value_type&amp;&gt;`, but you'd need to use boost::optional or another alternative, and I'm not sure if it's any better than the pointer solution.
- Yet another Turbo C++. - Yet another `void main()`. - Yet another `#include &lt;iostream.h&gt;`. - Yet another `#include &lt;conio.h&gt;`. Enough is enough. Just stop it, please.
SFINAE really is ridiculously expensive. I have a template with multiple inner SFINAE specializations applied on approximately 4400 classes. Have not measured exactly how much of a difference it makes in seconds but I replaced everything I could with constxpr if and compilation time went down significantly.
Any advantage of using `std::gcd` over gcc's `__gcd` other than `constexpr`?
 struct float32x4 { float data[4]; }; float32x4 operator + (float32x4 a, float32x4 b) { float32x4 result; for (int i = 0; i &lt; 4; ++i) { resut[i] = a[i] + b[i]; } return result; }; SIMD means that basically there is CPU registers like float32x4 and that the CPU does all of the computations simultaneously for the data in the register. Above four floating point additions are done by a single CPU instruction. That's it in a nutshell. In practise there are many different CPU architectures with different instructions and register layouts. There are 64, 128, 256 and 512 bit wide SIMD registers. The data the register contains varies. A 128 bit register can contain 4 x float, 16 x 8 bit, 8 x 16 bit, 2 x 64 bit data which can be float, double, signer or unsigned integer. Different instruction sets support different data types and instructions that go with them. The code example above could be like this in assembly: // xmm2 = xmm3 + xmm4 vaddps xmm2, xmm3, xmm4 Or it could be compiler intrinsic: result = _mm_add_ps(a, b); // Intel SSE ... Or.. result = vaddq_f32(a, b); // ARM NEON ... Vectorizing compiler could generate the instructions from scalar code working with arrays of data of supported types.
Cross compiler support once C++17 is widely supported and maybe a more easily accessible documentation since there are a bunch of websites that do a great job providing details and even examples for stdlib functions.
Interesting. I have an iPhone so perhaps that is the issue. I find most video links on the sub work fine, but the c++ weekly videos consistently have issues with playback for me.
A C/C++ Developer. Ok. Didn't read further.
What makes `int i{};` bad and `int i = 0;` good? They're semantically identical.
So it's actually doable inside C++. The SIMD registers are specialized hardware present in modern CPUs (you'll see them advertise in their specs that they can handle SSE and various flavours of AVX, for example). Think of registers as slots in the inner workings of the CPU into which data can go and be operated on. Different 'slots' allow for different things, although most of them are general-use. The SIMD registers are built to be a bit bigger and can have more data stored in them (like in the 4x example above), and you can perform operations on them and between them (e.g. when I added Ra and Rb together, above). Here's an example in C++ taken from [this](https://stackoverflow.com/questions/1389712/getting-started-with-sse) StackOverflow post, however contrived: #include &lt;xmmintrin.h&gt; // two 128-bit vector registers __m128 vector1 = _mm_set1_ps(4, 3, 2, 1); __m128 vector2 = _mm_set1_ps(7, 8, 9, 0); // Addition: result = vector1 + vector 2 __m128 result = _mm_add_ps(vector1, vector2); The two sets of four numbers are being added in one step. You can have even larger registers in more recent SIMD extensions like AVX512, which is available on the more expensive Intel server CPUs. They can handle `[512 bits] = [512 bits] + [512 bits]` in a single operation, which is a lot of data! I've used when doing simple things like performing a lot of distance2 checks (&gt;1M) in a time-critical application (a game). Ended up being a smarter way to do things that cut the maths down to where it wasn't worth it. It was also slower at first because of how I did it :P You gotta be careful with how you use it! Not so sure how it would interplay with multiple threads (SIMD across different cores), but that could be cool too. Hope that helps!
I don't think using struct to implicitly mean PODs is a good idea. Personally I use struct when I want to use public by default, which is virtually all of my cases. It results more concise code.
And forever converts to how many years? 
So true!
There is another practical technical difference : on Windows classes and structs have different name mangling. 
What is POD? 
And as I stated, that is a lousy solution because it places even more cognitive load on the programmer. A much better solution would be to *implicitly* initialize variables, unless the programmer explicitly indicates he doesn't need this. That places responsibility in the hands of the person making the request, and removes one type of surprise from the language. Of course the additional standardisation work is likely to take a long time (if it ever happens at all, which seems doubtful since it would be a fairly significant change), so until then the proposed solution from the article applies. 
"I want to see how the candidate thinks..." I always wondered how these people classify candidates according to the types of thinking. Like, how many different ways of thinking are there, what are the important differences between them and why are they important, and which ways are the ones that good candidates possess?
&gt; Are we just missing something obvious? NDR == No Diagnostic Required. Not all UB yields compiler warnings.
Thx thats awesome!
sub'd, I hope this gets enough traffic to become a thing.
[_Aggregate_ initialization](http://en.cppreference.com/w/cpp/language/aggregate_initialization) works on any aggregate type, regardless of whether it's a `struct` or `class`. (And designated initializers are a C-only feature.)
FWIW, `return oi-&gt;get();` is valid there, which is slightly less hideous.
Thanks for mentioning invariants. Each time I read a comment criticizing classes and promoting simple POD structs without mentioning invariants I die a little inside.
I shudder to even think about the reasons someone might have to switch between the two without a rebuild. That's about as misguided you as you can get...
&gt; I went full retard Can you not.
If you wish to directly distinguish (non-)polymorphic types, there is also ` final`
`final` is purely a pessimization on non-polymorphic types â deriving from non-polymorphic types is 100% fine (and necessary to make use of e.g. EBO) as long as you don't use it polymorphically.
The social reason to choose one over the other: no one has ever been surprised to see class features applied to classes. There's nothing wrong with preferring code the greenest intern would recognize as idiomatically sound, and nothing especially smart about writing code that intern would find obtuse absent a really good reason to do so. In the case of structs standing in for classes in C++, you can fix the potential confusion by using classes and adding one line, "public:", as soon as you need any feature not compatible with C structs. Weigh the time spent doing that versus potentially years of educating a series of junior developers that they have *not* in fact found a hideous mistake that necessitates an immediate refactor of the whole project. I'm all for the learning, but the cost/benefit doesn't seem to work out in favor of this particular fact.
"I want to see how the candidate thinks..." means "I want to find a candidate that thinks like me".
I don't think encoding secret semantic messages in stylistic choices is ever a good idea. Doubly so when people are all using the same stylistic choice to encode different secret messages. I like the following scheme myself, which removes the overlapping roles of `struct`, `class`, and `typename` * the keyword `struct` is used only in class keys, enum keys, and elaborated type specifiers * the keyword `class` is used only for template parameters * the keyword `typename` is used only to declare that a dependent name is a type
If you have a program that is a collection of files in different languages such as C++, Swift, C, Objective-C, and Objective-C++, it's convenient to use structs for interface classes. You can pass pointers to forward-declared structs in your interface, and your header files will be usable in all of those languages.
that's the C side of cppreference.
My own litmus test: does this just contain raw data, or full on methods complete with inheritance/polymorphism? If the former, use struct, if the latter, use class. It's simple, but it works. Also, when coding data structures, a great move is to make the actual individual information *nodes* a struct before writing a class that contains methods that operate on those nodes and create sets of nodes with relations between the nodes. That way, the data node and whatever pointers associated with it remains intact and a separate issue.
Is there a reason you prefer `class` in `enum class`?
As I said, for one thing it makes your type ineligible for EBO, even if it's empty. But more to the point, disallowing composition via private inheritance is arbitrary and unnecessary.
While I agree and use the two keywords to express different meanings, this is just me trying to work within the straitjacket of the language. The "real difference" is only whatever you perceive it to be and whatever makes sense to you. This is a language that grew like a weed in response to the pressures and trends of the time, and here we are looking for meaning as if it was handed down to us by the Gods in Heaven.
Finally I can spread my passion for stuff! 
[@wikitude's latest tweet](http://i.imgur.com/7QmmtFp.jpg) [@wikitude on Twitter](https://twitter.com/wikitude) - ^i ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
I mean, not in a namespace? Is this 1990?
TouchÃ©! I'll put it in a namespace.
which is actually a bug (I like how [Exceptional C++ errata](http://www.gotw.ca/publications/xc++-errata.htm) says "some compilers are buggy")
Meh, only time I used the `class` keyword is when it's required to...or when some dumbass puts it in a coding standard I must adhere to. The only actually legit argument, in that I found it valuable, to use `class` where `struct` works is that you should default your scoping to private and expose only when necessary. The `class` keyword does enforce that...but it's not enough of a reason for me to switch. POD vs. non-POD is a nonsense argument. Very simple changes can make your POD a non-POD and then what...you switch to the `class` keyword? Why?? Most people don't actually pay much attention to when something's a POD and when it's not anyway so you have all these incorrectly typed things around (that are in fact not typed differently at all). Further, there's little reason to actually create a POD unless you're working with something that needs them and you can't change them to be more idiomatic. Finally...POD isn't even usually the difference you need to know. More often you want to have an *aggregate* type, and the rules there are slightly different. An aggregate does not have to be a POD. With initializer lists this is even less interesting now. So it's really just a silly argument. Stop using PODs first of all...as PODs anyway--make the fact that something is or is not a POD as uninteresting as possible. And stop depending on language features to document things they are actually incapable of enforcing!!! I mean, really now. The only compiler I know of that actually even treats them differently (beyond what the language stipulates) is VC++...and that compiler gets all sorts of stuff wrong so whatever.
Typically when someone says 'how', as though for style, it's a euphemism for 'how well', ie how smart the person is. 
Was wondering multiple times why it didn't exist yet whenever I randomly searched for a simd sub. Therefore thanks for finally creating it!
Wanting always to /use/ the new hotness can be a bad thing, but being aware of it and maybe having played with it indicates more of an /interest/ in programming and usually, probably, better smarts. Always wanting to use it though indicates a lack of seasoning - will this hot thing fizzle soon, replaced by something else? Are there enough other people out there using it that we can find them? Is it worth the technical mismatch to have the hot new thing in a codebase of older stuff where not everyone will know how to use it? Plus the novelty-seeking 'hotness' chaser will probably run off to another job and you'll be stuck with his ill-fitting code. 
OP didn't say POD (as in `std::is_pod&lt;T&gt;::value`) but "bundle of elements," so, e.g. std::strings are ok.
What is a multipurpose developer? 
*Who said POD?* What OP describes actually *is* an aggregate!
Forward declarations. Whatever minute meaning one might infer from the declaration keyword chosen is completely negated by the inconsistencies and annoying guessing game one plays with forward declarations. Consistency is king; pick one and stick to it. I personally use `class` for the vast majority of things because it tends to gel better with a majority of other C++ programmers and I slightly prefer private-by-default but I'd be just as happy overall on a project that mandated `struct` everywhere.
E.g. objects cannot be created by std::malloc. ([\[intro.object\]/1](https://timsong-cpp.github.io/cppwp/intro.object#1))
Just sent you an email to your email address, by the way - let me know if it didn't get through.
a jack of all trades?
Thanks for the additional information. If you reported the issues via Help &gt; Send Feedback &gt; Report A Problem from within the IDE, it all goes to this website: https://developercommunity.visualstudio.com/spaces/8/index.html. You should receive email notifications to allow you to track the status of the report as well, and you can participate in the conversation directly with our engineering team this way as well. If you didn't report the issues via this system, please let me know. We can follow up to ensure that my team is tracking these issues. 
As another comment, Java won't allow you to leave final fields unspecified, even if they have defaults. Final should be the status quo in Java (with some specifier like `var` or `mut` meaning non-final), but that ship has sailed.
Thanks. Im beggining to learn C++ (PPP2) and its good to know in advance what I need to reinforce as a skillset! haha 
The problem here is that you are assuming that just because the plugin is in the same memory space that any memory access bug is likely to be reeking havoc on the rest of the program, and pragmatically that isn't true. Most bugs will be null pointers, just out of bounds, access wildly out of bounds and division by 0. There is a good chance that these will be recoverable. 
Decades?
Is the cursor jumping ahead on its own in that video? 
&gt; Beware of a particular quirk that happens if you lock your screen or switch users. Certain activity causes Visual Studio to peg the CPU while you're logged in as the other user, and then crash when you log back in to the account running Visual Studio. Can you provide more context on what types of activities reproduce this scenario? Or are you saying it happens all the time when switching accounts? 
&gt; We plan to fix that off-by-five in the next release. You mean I'll no longer have to refer to it as Visual Studio "roughly version 14 through 19, depending on exactly what you check," anymore? Gosh, that spoils half the fun of deploying it when you get to go in circles arguing about what to call it.
For future reference for everyone, an easy way to report Visual Studio bugs (as of VS 2017) is to go to Help &gt; Send Feedback &gt; Report A Problem from within the IDE. This allows you to easily report any issues and attach screenshots or other relevant files. All the bugs go to Developer Community: developercommunity.visualstudio.com/ (you can report bugs to this site directly too, and upvote issues posted by others). That site allows you to directly interact with the engineers triaging and resolving the issues you report, and get status updates when bugs are resolved via email. 
&lt;speculation&gt; Does your antivirus software have a way to exclude build directories from being scanned? &lt;/speculation&gt;
Is there a list to view the list of the 100 speakers? 
The programme is due to be announced at the end of July. See here: https://cppcon.org/timeline/
&gt; I don't try to find meaning where there's none. You're fighting human nature on that point.
Great! Thanks! 
[Image](https://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 4585 times, representing 2.8577% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_divjznx)
Structs are a whole lot easier if you're doing TMP.
yes, all on its own -- once I CTRL-&gt;RIGHT to the text and start typing, I don't do any more CTRL-&gt;RIGHTS you should be able to reproduce it with a help of a couple of do-nothing classes (just for code-complete purposes)
Yeah, sorry, I haven't been using that Help feature yet
Nope, unfortunately not - I took care to make sure the scope was "Current Document" and it was still forcing a reload of each project. Actually that's not quite right; it was forcing a reinitialisation of each project.
Let's say you are coding a BST from scratch. You can use a *struct* BSTNode to hold the actual data, as well as pointers to the left and right child and a constructor for creation, and then build your BST *class* around that-with Rule of Five methods, Insert, Search, Delete, etc. 
[ffmpeg](https://ffmpeg.org/) is usually the standard for anything video related. It supports hls among multitude of other things.
I just opened standard and looked for "should". There are too many of them to mean what you think it means. :-)
We have not finished selecting speakers yet.
Class was there but I rarely went and have no idea about the subject, did not realise at the time. Thnx for replying.
Actually I never learnt it for some reason I don't know what but I think I can do it now if I get myself into it just some guidance is needed. Thank you for the reply, I'll check the link.
Your college exams you without teaching you? I am confused.
SO WHAT 
I have a theory that may explain this... or at least propose a model for understanding of what is going on. I dabbled in all this years ago when memory models weren't well understood and we were learning them by reading Intel (and other chipmakers) manuals. So, apologies if this approach looks archaic to you. I also apologize for length of this comment. 1. related wording in C++ standard is an attempt to formalize model that was already well-defined and probably evolved very differently from how it is presented in standard 2. lets forget about compiler and cpu reordering -- let's fuse them together into single 'execution unit' (EU). It executes our program and operations in our program have certain order. That is if operation A is before B -- A will be *executed* before B. 3. when there is only one thread -- there is no need in memory_order. Program executes correctly because EU sees 'natural' dependencies between accesses and takes them into account when planning speculative executions. And we don't care -- we do not observe change of order because it is done without violating these dependencies. So, from our point of view A still *executes* before B. 4. multiple threads -- second thread *observes* results of operations made by first thread. Now we need to define a _memory model_ -- effectively a toolset that allows us to write meaningful programs. We need std::atomic so that other thread can observe correct value while it is being changed. And we need std::memory_order to place limits on reordering of *observations* in other threads. It may result in additional restrictions on execution reordering. (Note how I separated *executing* operation from *observing* it's effect). 5. relaxed -- nothing is guaranteed wrt observation order. 6. sequential consistency -- all such operations are observed in same order as their execution (i.e. in program order). Note that nothing is said about _when_ result was observed -- it could happen 1 year after operation was executed (or any other finite period of time), but point is that if thread 2 observes result of B, it is guaranteed that it already observed result of A (even if they access different memory addresses). 7. acquire/release -- an attempt to relax restrictions imposed by (6). "acquire(A); B; C; release(D);" means that if thread2 observes B (or C) then it already observed A (but not necessarily everything before A and maybe some things after D) and if it observed D -- it already observed "everything before A", A, B, C and probably some operations after D. Note lack of additional guarantees wrt order of observations for operations that access different memory addresses. 8. consume/release -- .... it doesn't matter, tbh. 9. fences -- ... same. What you should take out of this is: - all these mechanisms were invented by chip makers to address various problems they faced - C++ committee tried to create a model were these mechanisms fit nicely and naturally (to facilitate adoption of these platforms -- i.e. to make compiler writer's life easier). - from second thread's perspective it doesn't matter when operation was executed -- what matters is when it's result becomes observable wrt other operations - ... which means you can completely ignore reordering of execution -- you could still assume that your program is *executed* exactly as it is written. This makes it easier to reason about your program - once operation is executed -- it's result will become observable by other threads (in finite time). This time is unspecified, but memory ordering adds certain guarantees (as noted above) - ... which basically means that if you observe B (and you haven't observed A yet) you will **eventually** observe A (because A is *executed* before B) -- lets call it "eventuality guarantee" :). This would explain why code in the article is not broken and will work. Now, once we have a decent understanding of promises made to programmer, we can take advantage of this -- compiler can actually reorder operations (i.e. change order of execution). Unlike CPU compiler can look much "deeper" and if it sees that it can reorder operations without breaking dependencies and memory ordering guarantees -- it certainly may choose to reorder. For example, if you rewrite your loop as: for(int i = 0; i &lt; 10 &amp;&amp; !B.compare_exchange_weak(expected, 1, std::memory_order_acquire); ++i) { expected = 0; } compiler may realize that it can be reordered with a store to A because A will eventually become observable and there are no promises made wrt order of observations of results of A and B. So, yeah -- with new memory model you can break your program in much subtler ways than before. :D
Â¯\\_(ã)_/Â¯
Is there any reason this functionality couldn't be part of Ranges TS? Would this be a worthwhile improvement over [Boost.Hana](http://boostorg.github.io/hana/)'s algorithms? 
First, about Boost.Hana. In the documentation of find_if: &gt; In the current version of the library, the predicate has to return &gt; an IntegralConstant holding a value that can be converted to bool. This implies that the very first example in my post can't be translated to Boost.Hana without substituting the C-array with a tuple and all ints with integral_constants. Do correct me if I'm wrong though. Also, if you *are* prepared to transform all your data in such a way (i.e. data becomes part of the type), remember that compile times will rise. And finally, it's much easier to make a step to runtime when you already have a std::array, for example, rather than when you have a tuple of integral_constants. Compile times is also the main argument against using Ranges TS with constexpr data. I.e. in its current form Ranges TS just doesn't mark functions constexpr, but that could (maybe) be fixed. But iterators at compile-time do seem like a lot more work for the compiler. 
More pleasant than what?
What is a "full fledged client/server library"? Beast provides exactly what I need for writing an application. It saves me from implementing HTTP and WebSocket, but it doesn't get in my way. Beast does *not* make unnecessary, weird choices for me just because it could. That's the C++ way. 
This is a great series. You always think you know stuff, but C++ is hard. There's always more quirks and edge cases. Looking forward to the next parts.
`Previously exception specifications for a function didnât belong to the type of the function, but now it will be part of it.` Can we SFINAE on noexcept as well?
I suppose its the job of the `std::is_nothrow_XXX` traits.
&gt; Previously exception specifications for a function didnât belong to the type of the function, but now it will be part of it. won't this also break the ABI of... everything and lead to mass recompiles ? 
&gt; &gt; &amp;foo can be stored into a void(*)() but &amp;bar cannot be stored into a void(*)() noexcept. Because the latter was not a valid type until C++17, this change is backwards compatible. I don't understand, but maybe I make wrong assumptions. If it's part of the type system, it means that we can overload on it, right ? e.g., in C++17, write : void foo(); void foo() noexcept; so these two functions will necessarily have different name mangling. Now, what happens if we link this with a library with the implementation : void foo() noexcept { ... } compiled today, with the C++11 abi where noexcept isn't part of the type system. 
&gt; find_iterator&lt;decltype(it)&gt;(std::move(it), it != container.end()) I don't agree with this suggestion. 1) It's implementation detail how ``find_iterator`` implements its ``operator bool``. In this case it just happens to memoize on construction. It could also have just saved ``it_end`` for later comparison. 2) With C++17 type deduction from constructors, the current interface becomes rather pleasant: ``return find_iterator&lt;&gt;(m.find(key), m.end());``. Edit: text formatting
Wouldn't an `auto` field would only be allowed when it's initialized right there (and not in an initializer list in a constructor), so you don't lose locality of reference. About the only tricky part is using certain kinds of initializer expressions, e.g. `auto a = foo(arg1, arg2)` might be very brittle if `foo` is looked up via ADL, 2-phase lookup, etc.
Of course it needs to be initialized right there, otherwise the compiler can't deduce the type. Great another complex set of deduction rules...
It's like saying that `std::unique_ptr` is half-finished because you still have to actually use it in implementing something else...
The compiler could deduce the type here: struct S { auto member; S() : member(1) {} S(bool bar) : member(bar ? 1 : 0) {} }; As long as all initializer list initializations of `member` produced the same deduced type, the language could allow it :)
We can already do that in C++11: `std::enable_if&lt;noexcept(func())&gt;`
A quote from your document: &gt; This is a list of some common idioms in the standard that **should** be used to specify certain cases, and corresponding anti-idioms that **should not** be used. I sense irony... Now lets grab a random "should" clause from my copy of C++11 standard: &gt; If it is not possible to represent U or V with intmax_t, the program is ill-formed. Otherwise, an implementation **should** yield correct values of U and V. If it is not possible to represent X or Y with intmax_t, the program is ill-formed unless the implementation yields correct values of U and V. Please tell me that this is just a suggestion and vendor is not required to actually do this. &gt; should I trust ... I don't ask you to trust me. I gave you an argument and instead of finding a problem in it you referred to authority. Which, by the way I can't easily verify in this case -- anyone can create a project on a github.
Sorry for being unclear. SFINAE within expressions within the noexcept specifier, not the operator. Something like: template &lt;class T&gt; void f() noexcept(SFINAE_here) { } Not: template &lt;class T&gt; std::enable_if_t&lt;noexcept(T)&gt; f() { }
That's your example? Of course that *should* is nonbinding. Otherwise the second sentence is completely useless. &gt; Which, by the way I can't be easily verified in this case -- anyone can create a project on a github. Wow. I suppose anyone can also post a random document on IEC's website too?
 std::vector&lt;int&gt; v {42}; int&amp; i = v[0]; v.push_back(0); // `i` is dangling.
So you are aggreeing then that this is half finished work...
1) I understood the `find_iterator` constructor to be an implementation details of `ext::find`, but if it's part of the public API then of course you can do it another way `*this != end`, or delegate 2) I believe for C++17 you don't even need the `&lt;&gt;`
&gt; Nope, unfortunately not - I took care to make sure the scope was "Current Document" and it was still forcing a reload of each project. Actually that's not quite right; it was forcing a reinitialisation of each project. Hmm that is strange. I forwarded this to the VS Platform Team to investigate. 
The CppCon YouTube Channel: https://www.youtube.com/user/CppCon The CppCon Channel 9 event page: https://channel9.msdn.com/Events/CPP/
This is a bit of a side question, but are there any std or boost libs that already use | operators for (runtime) LINQ-style operations? I've seen cpplinq, but I'm curious what you're basing your syntax on.
!removehelp
As my friend said it: I've been learning new things about C++ every fricking day for the past dozen of years - how is that possible?
Well there is [Linq](https://github.com/pfultz2/Linq) that builds on Boost.Range. It even supports the query language: struct student_t { std::string last_name; std::vector&lt;int&gt; scores; }; std::vector&lt;student_t&gt; students = { {"Omelchenko", {97, 72, 81, 60}}, {"O'Donnell", {75, 84, 91, 39}}, {"Mortensen", {88, 94, 65, 85}}, {"Garcia", {97, 89, 85, 82}}, {"Beebe", {35, 72, 91, 70}} }; auto scores = LINQ(from(student, students) from(score, student.scores) where(score &gt; 90) select(std::make_pair(student.last_name, score))); for (auto x : scores) { printf("%s score: %i\n", x.first.c_str(), x.second); } 
despite some cool parts it is mostly waste of time...
Proper communication with other human beings. And to have fun while you program!
These are indeed the two libraries I've *borrowed* the syntax from.
No, an error code is the entire return value. It requires that the output value be given as a parameter of input making the whole thing a semantic mess. Alternatively the opposite. apply(readFile(path), [](const File &amp;file){success}); or apply(readFile(path), [](const File &amp;file){success}, [](const Error &amp;error){fail}); 
Precisely.
If you believe it is unfinished work, consider participating in the Boost formal review! All comments welcome, even your negative ones (but be prepared to defend your position!) Subscribe here: https://lists.boost.org/mailman/listinfo.cgi/boost I'll see you on the list!
Darn. It wasn't random enough, I guess. :) Yes, you seem to be correct -- I went over ~20 'should's in standard and all of them were more like advice. Maybe with exception of this one: &gt; Algorithms on input iterators should never attempt to pass through the same iterator twice. They should be single pass algorithms. I didn't check them all, but I am hoping there should be other examples. &gt; I suppose anyone can also post a random document on IEC's website too? Maybe. Depends how secure their website is :)
Is the official CMake server now being used? From what I understood VS had a custom version of CMake with their own server earlier. Also, will the integration be upgraded to the soon to be released CMake 3.9 before VS15.3 release?
The on-going evolution of C++ is fascinating. I (for my sins) never previously considered the complexity involved to consider the even relatively minor modifications to language a language such as C++. 
Any news on when the preview will release as an update 3?
CoW is actually pretty useful, especially for strings. Guess what for some implementations of std::string cow was used. Now for compliant c++11 it is not allowed anymore. And for why reimplement? For the same reason many boost libraries exist: not everyone can use the most recent compiler yet some library features would still benefit a lot. There is even a blog post that also specifically mentioned why not to support rvalues in qAsConst: compatibility with the standard implementation. Thus your comments rather show your ignorance than actual Qt issues.
It's great that C++17 simultaneously fixes the fact that make functions are necessary (by class template deduction) and also that they could not return non-movable or copyable types (fixed by guaranteed return move/copy elision)
Why can't VS just use whatever version of CMake is already installed on my machine?
All those languages are emitting_ JVM bytecode. C++ _emits_ assembly, so technically any language that *emit* assembly is a candidate. (the only *problem* is name-mangling but most can use the C scheme).
and variant too: https://github.com/iodcpp/metajson/commit/542c45d79e550e6c4949cc12610378da30b02a7a#diff-fe539d13f87cc418209f5785ab37be6dR46
I'm not sure if you have read the article. At the end: &gt; If the designer of foo and bar decides that they should be default constructible, they should initialize their contents with some **sensible values**. struct foo { foo() : a{0} {} //initialize to 0 explicitly int a; };
&gt; is more modern Define modern.
I'm not sure what you mean: Are you looking for a program that will take your code in language X and will produce equivalent C++ code? That doesn't exist in a practical sense (there might be some scriptable code generation systems, but thats definetly not what you had in mind). Just to be clear: Java is the language and JVM is a virtual machine. When you write in Jave and "compile" you get code that can be executed by the JVM. You can also produce JVM code in Kotlin, Closure, Scala etc. You could (theoretically) even write a compiler that compiles C++ into JVM code. C++ is different from Java in that it skips the virtual machine step entirely. When you compile C++ (with any of the common compilers that are around) you get code that is directly executed by your CPU (and not by a seperate virtual machine). Hence your question doesn't make much sense: "Compiling for C++" is not a thing. Anything that is compiled directly into binaries is (from your Computers point of view) the same as compiled C++ code. 
elegant , declarative, functional ,concurrent i think. 
Yes. If you're trying to sfinae for a function pointer, you can have two templates, one with noexcept listed with the type and one without.
CoW is not a good idea in a multithreaded environment: http://www.gotw.ca/publications/optimizations.htm 
Ha Ha, you hit my world spot on. I do computer vision , and my unit tests require a large data (&gt; 1Gb) library to be loaded first (automatic download on first compile - no quick starts). Most of the tests which deal with results are mostly statistical and have subjective pass fail criteria. So most of my test just compare to the last best results, As we notice our algorithms improve, we make the test suite harder to pass.
D supports C++ interop; Nim supports C++ as a compile target
yes , it seems , something like that with both of these features. 
Integration in the IDE. If you use project files on the side, you'll get those messages saying the project file has changed and needs reloading all the time. Also, you can now use Ninja directly in Visual Studio, and that's great, because your Visual Studio doesn't spend time reloading project files (even in the background). And then, you can use some tool to run the compiler like "sccache", which is a MSVC compatible version of "ccache" that will make rebuilds faster.
No, you didn't misunderstand, on second thought it doesn't make too much sense :-). I guess it would be worth looking at the distribution and seeing how common it is to have over 50 children. If you are using a trie to store words it doesn't seem like that would ever really come up since there aren't that many letters, but I don't know exactly how the trie is being used.
The important thing is that you are retaining the effort of dealing with errors at _every_ call site. Instead of *knowing* that every function completes succesfully (or throw an exception, in which case it will be handled elsewhere), you now need to think for *every* function invokation whether or not it might fail, and if so, in what way. Doing so makes your program far more complex to understand, since there tend to be endless `if (error) return error`lines everywhere you look, and it makes it much harder to apply a functional programming style since the error return (whether you hide it as a boolean in optional or not) _must_ be inspected before you can use the payload part of the optional. So forget about chaining functions using this method. What are you going to do with your "no file returned" situation? You sure aren't going to read from it, or write to it, or do anything else to it, since all of those functions require a valid file pointer (or a valid file object or whatever you are working with). That's a situation that _must_ be handled; you cannot simply stick it in optional and wave your hands and ignore it. 
You got me chuckling pre-coffee. That's not easy to do. Thank you, Tony.
&gt; I can't find that info in cppreference could you give an example?
And that these arguments: foo(std::unique_ptr(new T{}), bar()); Should all evaluate separately, i.e. that `new` can't leak anymore because of bar() throwing.
Your welcome! :)
Why write a new library for this, rather than modifying range-v3 to make it more constexpr-friendly?
"Prefer writing functions as nonmember nonfriends" is one rare advice from Sutter and Meyers I never followed. It never made sense to me, nor does `find()` versus `map::find()`, or `remove()` versus `vector::erase()`. I also find that classes get difficult to maintain not when they have a large API, but when they have many member variables. When a class gets more than three or four members, that's when I think of splitting it up. I've never had maintenance issues from an API. In fact, I might _keep_ the large API and forward to the newly split class. Then you get into the arbitrary separation of the filesystem library where you have `absolute()`, but `path::is_absolute()`, or `equivalent()` and `path::compare()`. I don't have a simple rule to follow, but I think I use free functions when I think "okay, now I'm going to _use_ that class to do something". When I think "this class should be able to do _that_", then I make it a member function.
&gt; most of those members could easily be implemented as non-members without loss of performance. **Any** member function can be implemented as non-member without loss of performance lol
This is roughly the approach I'd prefer. For me by far the most common usecase of chaining is range composition, but then I'd prefer the pipe operator. I really hate UFCS.
I wonder if they're planning on going that direction. They did announce integration with ClangTidy in the next release.
Class template argument deduction shouldn't work for `unique_ptr` because there's a safety issue - both `new T` and `new T[N]` return `T *` which loses the information of whether `delete` or `delete[]` should be used. (We attempted to ban this during the proposal but I forget where the Standard ended up - still need to get this compiler feature and implement it before I get comfortable with it.)
The main reasons are compile-time performance and additional functionality (e.g. sorted and hashed views). Also, I don't think working with compile-time ranges is so common that it should be part of the standard library. Rather, StaticViews should serve as an extension to range-v3.
In response to your "perfect world": I've been toying around with Nim (the programming language) recently and it does almost exactly what you want: * it has uniform call syntax (`size(x)`, `x.size()` and `x.size` all do the same thing) * information hiding happens on a module level not on the level of individual classes * there is no such thing as a "member function" * if you want dynamic dispatch you simply use a different keyword (`method` instead of `proc`) and you can even have dynamic dispatch for multiple parameters
On "Allow polymorphic behavior for free functions" - There was a paper from Stroustrup on adding [multimethods to C++](http://www.stroustrup.com/multimethods.pdf). But I am not sure if it has ever been proposed for standardization.
The only problem is that you have to manually create CMake scripts. And it's easy to follow ancient guides that makes it a lot harder. Search for "modern cmake" in this reddit to find a lot of posts about it and some presentations! But a good CMake script is certainly worth it.
PureScript has a c++ backend
Are there practical performance figures for the COW on Qt containers that justify the madness? You'd be hard pressed to find a C++ compiler w/o (N)RVO *today*.
A very basic payroll program for an Intro to C++ course. 
youtube-dl is a Python program that lets you download locally Youtube movies.
Also, Eric has indicated he does not currently see much point in a compile-time Ranges TS. And as Louis found, code written to run well at run time rarely scales well in the mind of the compiler, so a single implementation for both use cases will be suboptimal.
Well since this is r/cpp, I am obliged to mention A Tour of C++, by Bjarne Stroustrup. It all really depends on what you want the programs you write to do. I tend to recommend people start with a project and look for the learning resources they need, and not the other way around. What sort of programming interests you most?
Please read the sidebar, this is off-topic (sorry).
Cow isn't why Qt is Java-esque.
It depends. VC++ thiscall passes 'this' pointer in ECX rather than stack, that may bring performance difference than free function.
Well I took some classes several years back in learning how to code in c++. I'm about to go back finish that but I wanted something that could give examples of the basics so I can refresh my memory. The book you mentioned looks interesting. 
subd - single user bijiallion data
Today? These containers exist since Qt 4.0, some of them even have a longer history.
That was pretty funny, thanks. :) (although the slides at the start were a bit too quick, I guess you didn't have much time).
That's good point. Nowadays I really like to use free functions to implement some kind of "polymorphic" but what annoying me is that it's harder to point out which classes a free function can work for by reading the code. Member functions don't have that problem, they are self-explained. EDIT: rephrased
Scroll down to "some actual numbers" for your practical performance figures. 
Yes, tuples are now encoded and decoded this way : https://github.com/iodcpp/metajson/blob/master/tests/encode.cc#L72 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [iodcpp/metajson/.../**encode.cc#L72** (master â 2dc2921)](https://github.com/iodcpp/metajson/blob/2dc2921f944eda728df8324b34317873f007dfa6/tests/encode.cc#L72) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply diz4mpc.)^.
Methods are more discoverable than free function. This is not neglectable.
Clion, or if you want to use Windows primarily and deploy to Linux, Visual Studio 2015+Linux add-in, or 2017.
u/STL posted about a week ago with a link to his 64-bit build of MinGW based on GCC 7. Maybe you can try using this toolchain if you want 64-bit.
My ide auto completes in free functions just fine. 
As you can see here [C++ Compiler Support](http://en.cppreference.com/w/cpp/compiler_support) MSVC is now C++11 and C++14 feature complete, but as you can also see it requires MSVC 19 or 19.1 that means Visual Studio 2017, at least in the end they did it :D
You have no need to create the strings teacher, principal, secondaryteacher, it, marketing.
I tried that but when i did it i got this error. Error: school was not declared in this scope. if (jobcategory == school) ^
That just means you have to make sure that both the "school" and "jobcategory" variables are defined *before* you try to do anything with them.
I just tried it and it looks really good. I didn't know that i can run it on Linux. Thank you
For shortness: Use a function that is given a list of options and returns the users choice, something like this: #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;vector&gt; // a helpfil container #include &lt;algorithm&gt; //not needed for this function but for the final version below using namespace std; string menu(vector&lt;string&gt; options, string promp) { string answer; cout &lt;&lt; prompt&lt;&lt;"\n" // Ask the question for(int i=0;i&lt;options.size();++i) { // for every option cout &lt;&lt; i &lt;&lt;". "&lt;&lt;options[i]&lt;&lt;"\n"; // Show the user the option } cout &lt;&lt; flush; // Make sure everything is displayed on screen cin &gt;&gt; answer; // collect the reply from the user return answer; // and send it back to the caller of menu(...) } You can then do for example: job = menu({"school","it","marketing"},"Please choose a job category:") for every one of your cout ... cin blocks. You should also consider guarding against faulty input. For example right now if the user answers the first question with "shcool" instead of "school", the program will terminate without any further comment. This could look something like this (using the above menu function): vector&lt;string&gt; choices ={"school","it","marketing"}; // this form of assigning a container is called "uniform initialization string job=""; while(find(choices.begin(),choices.end(),job)==choices.end()) { // while the user has not correctly selected one fo the options job = menu(choices,"Please choose a job category"); // ask them what job they want } cout &lt;&lt; "You chose "&lt;&lt;job&lt;&lt;endl; // tell them what they chose or do other stuff with the information I'm using some stuff here, which I dont know if you have seen it yet (since you seem to be a pretty raw beginner), but don't worry none of this is really complicated once you understand what loops and functions are.
You are stuck so deep in OO mindset! Other points of view exist, and work pretty well. Did you try any functional programming, for example?
Both are in VC15u0, VC15u3 preview 2 in: .../VC/Tools/MSVC/14.10.25017/include/ .../VC/Tools/MSVC/14.11.25325/include/
To compile code that uses these features you need to add the /std:c++latest flag. https://blogs.msdn.microsoft.com/vcblog/2016/06/07/standards-version-switches-in-the-compiler/ This should allow you to access those headers via your code usage as well.
From 1999. For a small test program. Are you serious?
Yeah the rule in [temp.deduct.call] that we all have to remember is: &gt; A forwarding reference is an rvalue reference to a cv-unqualified template parameter that does not represent a template parameter of a class template (during class template argument deduction) This leads to another new weird edge case: what wins between an rvalue reference and a forwarding reference? I think it should be the [former](https://groups.google.com/a/isocpp.org/forum/m/#!topic/std-discussion/QuwEdnyzLT0)
There are voices in the Qt community to deprecate their containers. Take Marc Mutz for example. Of course with any grown system there are many pros and cons for basically any decision, as I am sure the C++ committee can attest to. So I wouldn't hold my breath. Still looking at the development of Qt it becomes clear that they embrace more and more features of the standard library nowadays. Which is great. Die NIH die! :) They don't have to support crappy systems anymore where the standard library implementations were disastrous.
Make sure you installed the "C++ Development for Desktop" workload (or some such).
Thanks for that, it's not always easy to find all the parts of the standard that relate to particular features!
"avoid invoking undefined behaviour" is extremely difficult to do without transforming one's program into an unreadable quasi-assembler code. For a practical way to address this, see the Safe Numerics library at www.blincubator.com . This library has passed the Boost formal review process and currently undergoing alterations required as condition of acceptance. Hopefully it will be incorporated to the Boost Library suite by September 2017. In the meantime, one can download an test the current version found on GitHub.
VS2017 can run &amp; debug project on a Linux VM, server, or BFW though.
Do you need the code editor and compiler on Windows? You can do all on Linux and then cross-compile with MXE to get a Windows binary.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6hngmk/beginner_need_some_help_with_gcc/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; Autotools was never designed to be portable This is not true. Portability was the main reason why Autotools was developed. It's just that it predates Windows 95. It was designed in the late 80s/early 90s when portability meant supporting the 100 different proprietary Unix/VMS operating systems that existed at the time. It was designed to only require Make and bourne shell to run. Since Windows provides neither (nmake does not count), porting it is pretty much impossible.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
&gt; There is no good technical reason Because writing something once and deploying it everywhere **IS** a good technical reason.
The compiler team has a list of what they've added to `/permissive-`; they may have a blog post planned. In the STL, I'm planning to write a blog post about what we've fixed aside from added features.
There are a few valid use cases to put some web components within a desktop apps - for example, say you use oath, you need to display the authentication provider webpage. It make sense to use HTML to display marketing content, documentation, etc As for why people do complete applications with JS... I don't think it make sense long term, not at all... but, the long term state of an application is not often considered while taking those decision. JS is considered by a lot of people to be a better solution if you want to develop a quick and dirty solution, given the state of job market. What I mean is, using HTML to do a desktop app rarely is a *technical* decision, but rather a business one.
Qt Creator doesn't bind you to Qt at all. You can use it to work on Makefile-based projects, or CMake projects. You can also write your own plugin to import the project structure from any source you wish, it's not super complicated. I personally use it mostly as an Arduino IDE because it supports a debugger, code insights, and looks up library documentation in cppreference.
&gt; returns by value/copy instead of C++ way (i.e., const reference) Uhh, I hate to break the news, but the modern C++ way is to return by value in general, and by reference only in special cases. Qt used CoW mostly as a workaround to missing move support in old C++.
I didn't want to "justify" my desires. I guess it's hard sometimes to see what others may want vs your own needs, but I figured I'd respond with my thoughts, incase anyone's curious. With all the JS/HTML/CSS hate, one can't deny the impact apps like VSCode, Atom, and GitHub Desktop are having on the industry. Qt's been around for years (maybe not QML), and while it's open source, it still feels controlled by a single company who's seems to mostly care about embedded and automotive industries now. While I love Qt's ability to make fast x-platform apps, being locked in to another new "commercial" UI system is not something I'm a fan of. Second, one important aspect aspect not mentioned is programs that want a remote interface, and really the web is the best for that - nothing to install. This is something I'm interested in. Why design your UI twice with completely separate code bases? I agree that performance isn't great, but it will only get better. This is why I'm a fan of using the operating system's native web control. WebKit/Edge controls are pretty damn good. If you're writing a game or an intense graphics program, sure this isn't the best. Then again WebGL/WASM is here now... I used to hate desktop web apps, but now I understand it. But I want to use it with C++. I want Electron-style development with C++. I want the power of JavaScript accessible through C++. I don't want to use TypeScript, Dart, or the latest JavaScript alternative. I don't care about HTML, it's just the way of managing your view hierarchy (just like NSView/Android views/etc). I want CSS to make things pretty.
I've recently been playing around with having a window containing an QOpenGLWidget and a QWebEngineView on top of each other. There are some problems with the OpenGL version on macOS, but I got it working nicely so that I always have at least OpenGL 3.3 on modern systems. The reason for using HTML/JS/CSS with WebEngine instead of using Qt widgets was that I consider HTML/JS/CSS to be more easily customizable than the widgets, at least without taking ages by painting everything myself. I have not tried using QML or QtQuick. I tried QML once and it was awful, but that was when it was pretty new and incomplete, so it's not a fair comparison. How far can I customize the UI elements using QML? Do you think a QML layover on top of OpenGL content would work? How would I go about that in QML?
Run your program through valgrind. You'll likely find where your error is. 
There is a race condition somewhere were event A need to happen before event B for your program to work correctly and you get crashes when event B goes first.Those std::cout probably slows down a code path enough to cause event A to go first before event B avoiding those crashes.
&gt; How far can I customize the UI elements using QML? some examples: https://doc.qt.io/qt-5/qtquickcontrols2-customize.html although creating new QtQuick items is extremely trivial. For instance I'm working on a [custom object set tailored for multimedia applications](https://github.com/jcelerier/qml-creative-controls). &gt; Do you think a QML layover on top of OpenGL content would work? How would I go about that in QML? here's an example in the docs: http://doc.qt.io/qt-5/qtquick-scenegraph-openglunderqml-example.html Although sometimes you want to do this because you don't know that there may be better ways (for instance [Qt3D](https://doc.qt.io/qt-5/qt3d-planets-qml-example.html) ([simpler example](https://doc.qt.io/qt-5/qt3d-scene3d-animatedentity-qml.html)) or just using [shaders in your QQuickItem](http://doc.qt.io/qt-5/qtquick-scenegraph-simplematerial-example.html))
Typescript IS JavaScript. You should learn more about it before you bash it.
&gt; I also find that classes get difficult to maintain not when they have a large API, but when they have many member variables. When a class gets more than three or four members, that's when I think of splitting it up. In most of the cases I found this to be true as well, but sometimes you want to pass something around with the same interface but a different implementation (e.g a string that is created on the fly.) Then you have to implement all methods. What I now do, is to define minimal interfaces and add additional functionality proceduraly. (I have done that in python via metaclasses in c++ I would probably do it via CRTP). e.g: at, front and back can all be implemented in terms on [] and size template&lt; typename T&gt; struct extendIContainer{ reference at (size_type pos){ if (pos &gt;= 0 and pos &lt; T.size()) { return T[pos] ;}else {throw std::out_of_bounds;}; }; ...// here comes front and back ... }; class string: public extendIContainer&lt;string&gt;: { public: typedef ... // the typedefs can also be set in terms of traits_type, allocator_type, iterator reference operator [] (size_type pos){...}; size_type size() const{}; private: ... }; As this all is done via CRTP there is no runtime overhead. This works really well, if the methods are semantic additions (string.back() is no different from string[string.size()-1] but much clearer.) 
Yes. It uses Google benchmark, that provides benchmark::DoNotOptimize(), to ensure an expression is not optimized away.
There's actual, official documentation of doing just what I want, in a far less ugly way... awesome! Thank you! Now I just got to hope that it'll let me use core OpenGL on macOS instead of compatibility so that I can ditch the awful workaround I have for that at the moment. &gt;_&lt;
You "copy" make.exe to mingw32-make.exe? Do you mean rename? Also that shouldn't be nessessary when generating cmake files with `cmake -G "MinGW Makefiles"` and that run either `cmake --build` or `mingw32-make`
If you happen to be outputting some data via std::cout, when you remove the std::cout lines, check if the variables you are printing are now left unused. There's a chance the compiler is optimizing these unused calculations away, which means that your program won't run the code that's causing the crash if you aren't doing anything with the results.
There is a toolkit called [Sciter](https://sciter.com/) which i think is what you need. I've never tried it, but according to the author, It's lightweight if compared to Qt.
Who says I am sane ;) I have been a coder in various places for 17 years now. Maybe I left a lot of my sanity in the last teambuilding event our manager sent us on. I understand what you mean, but the author kinda to me seemed to want to do a Desktop App with a Browser plugin and then add another UI inside of that. And to me (maybe because I have to beat down various bad technical decisions every day) that was "triggering" or rather I wanted to point out that a UI maybe made in QML might be a better and simpler solution (if a bit heavy on the download side given the size of Qt's dll set).
Don't worry, you didn't :) It doesn't make sense. Returning data members (containers!!!) that are expensive to copy by value is rather superfluous because the users of the API most of the time don't need a fresh copy, so const reference is most optimal, which also gives a choice to the API user to make the deep copy themselves (instead of forcing them into). Moreover, in this instance move is irrelevant. Qt COW mindset for containers corrupts this common sense.
To avoid crashes involving the alien-looking EDINOFAULT signal, compile with -fno-triassic.
Just use QtQuick, your sanity and your users will thank you for it. The way I see it QML is what HTML reimagined with 21st century use cases looks like.
I want different things and no I could not stand spending a moment in Atom, VSCode or similar, but I also find that Eclipse and the rest are slow, high latency and kinda crappy UIs too. I have a huge powerful PC, my editor should be blazing fast yet because all these compromises a lot of these things are wasted by a huge stack of "good-enough-but-not-really" decisions stacking up the performance compromises to the point that I feel like there is actual input lag in these things. It is getting to the point where the only code that looks half-way optimized is often Games (and I know that is not always the case either). But you don't have to convince me either. If you build a cool application more power to you, I will applaud you no matter the technology because for all that we disagree on taste, it is just taste there is more than one way to implement all sorts of applications. . I have a personal bee in my bonnet about designing for performance, so I spend my time playing around with C, C++, D, asm and read about how to make my software smaller, faster and more optimized. You want to make your design and thumbs up from me. I hope you get a great project out of it. And yes I would still recommend a dive into QML because it may give you ideas on C++ and JS integration.
Yeah it can be a little finicky to setup with other compilers but it really has a lot of options to creating good cross-compile setups. I have a setup today where I can compile for Windows for simulations, for Linux for tests and for an ARM target. All in the same project just by setting up various kits, but I do need to maintain a set of instructions to make sure others can do the same as it is not immediately intuitive how to do that.
I've spent 16 years creating web apps and I don't disagree with anything you've said. In fact, I agree with **ALL** of it. But none of what you just said contradicts my main point, which is that I'd rather chew glass than work with most desktop UI libraries. It takes me so much more time to create a windows or a linux application that shows a simple form than it takes me to create that same form for the web. You may dismiss this as just 'speed of prototyping', but the time it takes to create something from scratch matters a lot, especially when you're paying somebody by the hour. If desktop UI libraries would address this and become easier to use, I think desktop app development would take off again. Qt and Microsoft are trying to take steps in that direction with QML and XAML, but I don't think either of them have quite hit the mark yet. Funny enough, I think the best language/framework combo I've ever seen for UI work was Adobe flex. It used XML components, similar to XAML and QML, but you could also create your own using actionscript. The whole app was compiled into a flash binary and ran in the flash VM. It's a shame adobe never open sourced the plugin (VM) itself. It's also a shame that the language (actionscript) was basically javascript and was just as slow.
CEF (Google "chromiumembedded" offers a lot more customization options) than Qt WebEngine. I suggest you to check it out.
I have worked with both QML and XAML but never tried Flex. Personally I can't say I would chew glass (and btw ouch that is scary idea) but I was almost turned off from UI development because of ATL and MFC before I started to work with other stuff, but I find HTML and CSS much worse than those, because they are so full of surprises and platform differences that I don't experience with native applications. I guess our experiences differ which is fine. I miss a C++14 GUI library close to but not quite like Qt and QML, meaning I would want a design where the lowlevel stuff and API is a combination of modern C++ and various GPU APIs (OS specific) with an easy to use set of standard components and a very thin markup language for the interactive scripting. All of its designed so that you could make the UI and interaction in an easy manner and the UI components but most importantly all the rest of the heavy loading stuff like networking, calculations, simulations and so on in C++. But there would be no concern for odd platforms or old compilers. Basically be hard about that only Windows and Linux in the modern versions get support and only C++14 and later compatible compilers are used. 
Note that VS 2017 15.3 (the first toolset update) will work very well with Clang/LLVM 4.0 due to their hard work, but we (MSVC) weren't testing that configuration. Now we are, so the second toolset update (no ETA yet) will be tested on both sides. Notably, I had to add a workaround to our `&lt;atomic&gt;` machinery for a missing compiler builtin (4.0 lacks `_interlockedbittestandset`, implemented in 5.0). The workaround is to include `&lt;intrin.h&gt;`, which users can do manually.
Yea, hooking it up to C++ is quite ugly though and with raw pointers everywhere. QML will only get you so far if your main backend/library is in C++. QML itself is really cool though and I wished they improve the C++ side of things :-)
what did not work is initializing it statically, like float color[3] = float[](3., 4., 5.);
I already know about it. But saying it's JS is like saying C++ is ASM...
Yup, that works as well for me o.o Are you sure you didn't do anything else that might've caused problems?
For curiosity's sake, what do you plan on making the UI for? Or is it a technology prototype? 
Can you elaborate? Will it list all all free functions taking a given type (as first argument?)? How does it work in practice, you write it as a member function and it rewrites the call when closing the parenthesis? What is the name of this IDE? For me discoverability is a big selling point for member functions, even if just forwarding to a free generic function.
I have some specific things in mind, but it's more about general future x-platform UI. After spending the last 5 years porting an app to Qt (widgets) I'm not thrilled with the UI. I don't understand the love for QML here though, it's still JavaScript, right? So if you're still using JS, the only advantage is no HTML and no CSS. But you're locked into Qt. So you can't bring that code to the web. You can't bring it to mobile without licensing costs. You're stuck. Am I wrong?
That sucks. No plans for MAS anyways (not a fan). What is the reason though? Private APIs? Non-sandbox file access?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
(Works @ MSFT) As pointed below, we are working on pushing our changes from custom branch into Kitware branch. Once that is done, technically VS can use any version of CMake from that merge onward. In general we wanted to streamline acquisition experience of cmake in VS to make things work out of the box.
Yes, we are shipping CMake server with custom fixes (based on CMake v3.8) in 15.3 previews. We are planning to update our version when v3.9 is released. We haven't determined the shipping release yet, but it will be soon.
...what's your point then ? In my experience, the same app takes 1/4th to 1/3rd less time to develop with QML than HTML.
All depends on the coder... but bad code can be written in anything on anything.
I don't disagree. I just reject the notion that there might not be benefits in taking some code that is already working and wrap it up in tools like Electron. Once you start talking to stakeholders about having to re-write things in a new language/framework like Qt they often start looking for the exits. Pragmatism is my primary motivation and driver as a developer (particularly as a consultant).
It's not a technical decision to not want to deal with a bunch of new languages? To have to hire and retain staff skilled in those languages? It's not technical to want to avoid re-working working code just to get a more "desktop" feel? In short... the management stuff is still technical, just as the technical stuff is quite often about how you organize and "manage" the technologies.
You can use user flair to identify your employer and position; see [my old post](https://www.reddit.com/r/cpp/comments/4tm8k9/user_flair_is_now_available/) for more info.
Write once, debug everywhere.
How does this address returning data members which are collections, which is what the OP specifically mentioned?
QtQuick-C++ binding is not ugly. And there are no owning raw pointers there.
Actually the app PgAdmin4(a PostgreSQL tool) is built this way and it uses JavaScript(frontend) and python(web server) and the QT browser library
Nice! Beast fills one of the most gaping holes in Modern C++. Good luck on the Boost review.
Phrasing?
It makes sense if you want front end web devs to make your UI for you to save on hires.
If anything is more sane in HTML/JS, it's layout. I've lost hours trying to coax QtQuick into pertforming a rather simple layout that I wanted, but never fought with Bootstrap. QtQuick is way harder to get started with and to use than html. In my modest experience, *nothing* in QtQuick works exactly as documented. IDK whether to blame it on implementation or documentation.
&gt; Qml is very easy to use, very powerful, has a, in comparison, sane API, very well documented and run on pretty much anything. Where do you start learning QML?
I'm sure this has been pitched at some point, but I'd be much more comfortable with UCS if it was restricted to a namespace with a name matching the class. The language already has 'enum class'... what about something like 'namespace class'? class Foo { // minimal API }; // Can only use the public interface of Foo to provide support encapsulation namespace class Foo { void ExtensionFunction(Foo* this) {} } Foo inst; inst.ExtensionFunction(); I know this is probably isn't sufficient for many and it wouldn't support the idea of calling methods as if they were free functions, but as someone with a lot of concerns about UCS from a usability/complexity standpoint, something like that would be workable. It would also align with the idea of a minimal API, support tools/autocomplete, etc.
https://qmlbook.github.io
This could be nice, but this is not UCS. This is more similar to extension methods in C# (in that you need to explicitly mark a function as an "extension" to an existing class).
X-Post referenced from [/r/cmake](http://np.reddit.com/r/cmake) by /u/berenm [An automatic build script for C/C++ projects with CMake, relying on convention over configuration.](http://np.reddit.com/r/cmake/comments/6hsgn9/an_automatic_build_script_for_cc_projects_with/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
`CMAKE_CXX_FLAGS` is old and bad, it sets flags for all your sub-projects and thus may in some use cases prevent 3rdparty libraries from compiling. It's better to use `target_compile_options`, which gives you much more control over which targets are compiled with what options.
So, if understand this correctly, you have a pre-build step that compiles all your `.ixx` (module interface unit files) to `.ifc` (binary module interface/BMI files). Then you pass a module search path when compiling the rest of the source files. The first issue with this approach is that `.ixx` files can import other modules. Which means you need to build BMIs in the correct order and pass the `/modules:search` option while compiling them. The second issue is the pre-build step: you essentially have a barrier between BMI compilation and the rest of the application. That is, all the BMIs have to be generated before any source files can start compiling (even though if some of them don't import all/any modules). This is going to hurt parallelism in real projects. In fact, right now I believe you are compiling BMIs *serially*. You could pass the `/MP` option to alleviate that though it will exacerbate the first problem discussed above (in case you workaround it by ordering your modules in the list). Also, don't take it as an attack on what you have done (I think you deserve a big thank you from all the CMake users for getting the ball rolling). Rather, it is to illustrate that build system support for C++ modules will be a lot tricker than many people might suspect. This is based on my experience adding support for modules in `build2` and, let me tell you, it was a rough ride. Though our goals were slightly more ambitious: support for all three compilers (GCC, Clang, MSVC), ability to import modules from libraries, etc. Also, if you want to play with modules in VC, get yourself 15u3 (currently preview 2, `cl.exe` version 19.11). 15u0 has a bug that makes modules with separate implementation units unusable.
Great to see another high level C++ library. How does it compare speed wise to[uWebSockets](https://github.com/uNetworking/uWebSockets), and does it support compression?
You should add getting started/building to readme
QML/QtQuick doesn't use that parenting thing with pointers in everyday code.
Have you tried it recently? You have anchors, Positionner, and Layout. Each of those have their uses and are very powerful. With the Wysiwyg in QtCreator, it's relatively easy to do what you want. 
The WebSocket implementation has permessage-deflate support, and Beast uses its own header-only port of ZLib to C++!!!
Defining my Q_OBJECTs and Models, instantiating them in QML. That doesn't touch any parenting. Maybe you're talking about the Qt scene graph API?
Ow, QtQuick is ugly and with raw pointers everywhere. 
Awesome, thanks! (also I'm the OP from that thread)
Paging /u/SEGFALT_WA, owner of CMake integration in VC++. Nice work! I'm glad to see you get this ball rolling But all the points /u/berium make are correct: while C++ Modules can't have cycles, you can have an arbitrarily deep build dependency graph. A CPP file can depend on a module IFC file that depends on two other module IFC files. MSVC has been focusing on correctness of the implementation rather than the build system. But we know that the build system will be a lot of work for modules. You really need to design a mechanism to detect (or express, though the computers should just do this work for you) dependencies between modules and their consumers. 
Someday I hope modern technology will find a cure for Boost-o-phobia!
yes
Original author here, I wanted to have your opinion on this idea. I think that for many simple C/C++ projects, a convention over configuration build system is possible, like what's available in other languages. Of course, the goal here is not to replace build systems for complex projects, but to offer an alternative for people like me, who don't want to spend time writing the same Makefiles over and over again for their pet projects. I tried to make it as simple as possible, while keeping it just a little bit flexible. The generated packages should be compatible with modern CMake packaging standards, and all the projects built with this script should integrate together very nicely, whether they are used in source or prebuilt form. 
thanks for the tip. I am like a little CMake baby, so I appreciate it!
Ah, you're right! I don't have any dependencies between modules right now, but I didn't consider the serial compilation issue. You're right that once module compilation order dependencies crop up, it's going to get more complicated. Thanks for your feedback. My next goal for this project is to try to eliminate headers entirely, except for one utility header that contains macros, so we'll see what that looks like.
As a creator of [one build system](http://mesonbuild.com) let me repeat things mentioned here and other locations. Whatever you do, do **not** make it so that the build system needs to scan the contents of files before knowing which order to build them in. FORTRAN does that. It is an absolute hell on earth to support. It can't be made both convenient and fast. In fact most implementation are not even correct 100% of the time. Saying something like "all files in this project need module file X to be preprocessed" is ok, just like PCH works today. Needing to know that foo.cpp inside a target needs file bar.cpp compiled first to get the module out is not.
Thank you for the advice! And yes, I agree. We haven't designed anything yet, but we're aware that there are many pitfalls to avoid. Heck, Microsoft's made many of these same mistakes themselves :) From a VS point of view, the project system controls the build. (MSBuild, not CMake or Open Folder, which are /u/SEGFALT_WA's problem.) A developer could add a reference in the project system from a source file to a module--we have that concept in VS already. And then if a missing reference was detected--that is, compiling source file S.cpp found a missing import of module M.ifc--the reference could be automatically added for the next build. But I agree, preparsing every file to determine dependencies is exponentially crazy. 
If all targets under the cmake file directory should use these flags, your initial approach is correct. The other option is to build your own cmake target macros using target_compile_options, which will get uglier.
Does it have TFS integration?
I don't know the distribution either. However I do know that some nodes have many children, hundred of thousands. 
I notice the zlib implementation doesn't allow setting your own dictionary. Is this a planned feature?
The zlib implementation has things removed such as the dictionary and support for the gzip file wrapper. I only included the stuff that Beast actually uses and needs, otherwise there would be a bunch of code there that was untested. I will probably give the zlib part more attention once the other parts have matured.
At some point I hope to really release it. Thanks for your encouragement :)
Build order isn't something prescribed by the compiler toolset or the Standard. Implementing modules support in MSBuild doesn't necessarily have any impact on other build systems. The depfile is interesting. I've not heard that request before. MSVC predates most of these build systems so it would have to be added, but it's an interesting suggestion. /u/SEGFALT_WA: we should talk. 
Why is headers-only a feature?
"Headers only" provides an easy integration experience!
I can't help but feel a bit sad that compiling a C++ library is considered so hard, that it's better to distribute a library as header files.
You store indices into the underlying sequence. It's a "compile-time analogue" of storing non-owning pointers. It's also an interesting question whether copying an `int[capacity]` is O(1) or O(capacity). You need to copy capacity ints, thus O(capacity), but capacity is fixed at compile-time, thus O(capacity) == O(1). It's all a matter of definition...
Not sure either but I recall std::copy keeps type info in the template parameters. Maybe can be used for alignment?
Very neat. Is there an `INSTALL` document so I can set up a local instance with just a few commands?
And if this requires that the build system parses their contents in any way, it is a fundamental design flaw. This is _exactly_ what Fortran does. It has been known to be a terrible idea since the 60s if not earlier. Let's not do it again. There are several ways of solving this. One is that all the module files are compiled into one output file which every source file then #imports. Or maybe you invoke the compiler on all module def files at once and it outputs all the result files in one invocation. There are a few inefficiencies here but at least the compiler, and only the compiler, ever needs to parse the sources.
Thanks for the feedback. I will take a look into it. But I was pretty confident this should not be the case. Did you take a look into the generated assembly? The symbols are annotated in the source files.
&gt; it is a fundamental design flaw [...] Let's not do it again. I think it's pretty much done. It would have been a fundamental design flaw if pre-parsing the transaltion unit to discover imports was somehow very difficult (like, say, with `#include`'s) -- but it is not: Imports (note that it is `import`, not `#import`) are top-level declarations, which means you only need to parse at the outsets. And, as I mentioned earlier, tokenization allows you to do very precise change detection. This will get even better once more and more translation units become preprocessor-free (with modules being the major enabling factor). Personally, when things fit like this, I don't argue, I just say *"Thank you, Universe!"*, and roll with it. 
&gt; No, the fundamental design flaw is that you need to do it at all. Why is this a fundamental design flaw? &gt; It also violates the DRY principle: for every build each source file should be processed at most once. Why is this important? If processing the file multiple times doesn't hurt performance, is reliable, results in a reasonably simple pipeline (vs the callbacks idea), and has added benefits (change detection), then *why not*? &gt; This breaks every build system that is built on the fact that file contents do not matter. Make breaks, Ninja breaks, everything breaks. Well, it doesn't break them, they may just have a hard time providing automatic module dependency extraction similar to how they do it for headers. But you can describe a perfectly precise module-based build in both if you are willing to specify the dependencies between modules manually. 
That's a good question! And now I feel like a fool for not forseeing this usage... There is no INSTALL. But you could adapt the `deploy` script, that prepares the storage (in /data/, you might want to change that), installs dependencies with yum and installs and runs a service called quick-benchd.
I hope the proposal "Down with typename!" Will be accepted in the future.
Great! Finally a video I can point my colleagues to, instead of having to explain myself each time this comes up.
www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0634r0.pdf
Interesting, so this simplifies syntax with no drawbacks.
&gt; Why is this a fundamental design flaw? Because it means that every build system must write a parser for C++ imports. This is pointless work that should not be needed. Suppose further that there are N build systems and M languages that require something similar to this module definition. That requires writing NxM parsers. The correct number of parser to write should be zero. The compiler should provide sufficient primitives for this. &gt; Why is this important? Because it makes things more complicated for _every_ tool that lives downstream of the compiler. It is worth spending time and effort on making this better. &gt; If processing the file multiple times doesn't hurt performance It does. If you are on Windows and have a project with 20000 files, simply getting the stat information takes a long time, let alone opening each file. For parallelization process spawning takes forever or alternatively you get to wrestle with a gazillion threads which is never fun. &gt; results in a reasonably simple pipeline (vs the callbacks idea) This is a [false dichotomy](https://en.wikipedia.org/wiki/False_dilemma), these two are not the only options. &gt; has added benefits (change detection) Nothing wrong with this, as long it is the build system's choice to opt-in to doing it, rather than being forced to by the toolchain. &gt; if you are willing to specify the dependencies between modules manually This does not scale and is an _awful_ user experience. The DRY principle applies here too. Module setup and dependency information (within one target) must be in one place: in the source files themselves. It is the job of the build system and the toolchain to do all the dirty work to make that happen so users don't have to manually fiddle with makefiles.
Your two graphs for the copy operations run the bars past the scale of the y axis, and so show no information. Maybe something got munged in correcting the other errors mentioned?
`A::B&lt;C&gt;` can be a function or (as of C++14) a variable.
Once you complete the statement by adding a variable name (`A::B&lt;C&gt; d;`), all bets are off: namespace A { int B; } int C, d; A::B &lt; C &gt; d;
Weak article
Cool. He didn't mention that when we spoke to him by email.
Actually they dnt look good I should correct. But they are showing the maximum do still the time that took to execute them. (20ms) I am not gnuplot expert. Will take a look tonight. South east asia time shift :D
those quick cuts when explaning code were glorious - so clear, so concise 
I was hoping for cheese
Do a 2d array. Its not hard to do
Is it 2 player chess? Or player vs ai?
Why not simply use a ``std::unordered_map``? Ok, probably the code has been coded long before C++11 - but then I would definitely try to convert it to more modern C++ ð
If we drop two phase lookup and act as MSVC, this may be true.
I noticed the goals seemed very different, so you are saying as the creator (I looked just at usernames), you changed direction, or you're building a monolith?
Yeah, I get that.
Thread safety should be paramount over performance. Citing performance for not using CoW is a fairly weak argument these days, unless we are talking about resources that are absolutely huge (like images). Even then, I'd be quite reluctant to give up CoW if it means enforcing thread safety. 
&gt; stay away from JavaScript, this is the opposite of learning Absolute rubbish. JS has become very sophisticated in the last few years. 
We banned it (although I suppose it is always easier to add later than take out...)
I have had to add library support for odd make systems to Yocto and comparing that to a header only solution means I would definitely consider header-only a feature.
I don't think waiting for the compiler vendors to figure it all out is constructive. They are definitely interested in making this work but unless build system authors actually try to use modules, ask concrete questions and make concrete suggestions, it will all be theoretical. I've gone (and still going) through that with `build2` and they are all very receptive.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [ripple/rippled/.../**beast** (develop â 7b0d482)](https://github.com/ripple/rippled/tree/7b0d48281049c3fec7fafcb7ce5cea045367ae1f/src/ripple/beast) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dj3qjsa.)^.
Yep! And his video was a source of some inspiration.
Change your output line to: cout&lt;&lt;"\n Your first name is:"&lt;&lt;firstname&lt;&lt;' '&lt;&lt;secondname; Notice the ' ' representing a space inserted between firstname and lastname. 
All you have to do is add another string with a space between the two variables. Firstname &lt;&lt; " " &lt;&lt; lastname. Cout lets you create whatever string you want but you have to add all of the pieces by hand
Just add a " " between the firstname and lastname using the stream insertion operator (&lt;&lt;) like this: cout &lt;&lt; "\\n Your name is:" &lt;&lt; firstname &lt;&lt; " " &lt;&lt; secondname;
IIRC you can still longjump from noexcept functions in C++.
I agree. JS === absolute rubbish. 
Here ya go, the best programming fun you'll ever have: https://www.amazon.com/Ray-Tracing-Weekend-Minibooks-Book-ebook/dp/B01B5AODD8
&gt; Do you need the low-level to understand a concept or do you learn better if the details are hidden so you can concentrate on the high-level? Yeah, I kinda do. I've tried to learn Python but always been stymied by "*Why* does it do that?" Nothing ever goes into why Python does what it does, just that it *does* it. Never makes me want to learn. I might only be on Chapter 4 of Stroustrup's Principles book, but so far there isn't anything I don't get though I am probably not too far into it.
&gt; I can only think of 3 industries that use C++: game development The hobby programming I intend to do is game development. I have several games that I enjoy that don't intend to add features I want, so I thought instead of pestering the developer or just being sad, I should ask them what language they used and do it myself - learn a useful skill while I'm at it. I've never really enjoyed Python - I get how it as a language works, and it seems simple enough to learn, but the sources I've learned from have never really taught *why* does it what it does. Just that it does it.
What about competitive programming? Good fun and a great way to fiddle with C++.
5HHello
Nice, If the concepts are making sense then I don't see any reason to stop! Stroustrup's book is great and I still recommend it as the best resource for learning programming with C++. However, some of the parts go from 0 to 100 really fast in weird places, particularly chapters 6 and 7. If you get to those ones and go "WTF?!" at any stage, feel free to skip the stuff that doesn't make sense. A lot of that chapter is teaching concepts that you'd learn later down the track in non-intro classes and is bizarrely out of place.
If you want to get some stuff done, go with Python. If you are interested in algorithms and data structures C++ is a great companion. I read the book from Stroustrup, took a class on algorithms and datastructures and then went on coding pages like hackerrank. Good fun.
C++ was my first language too and I think it was the right decision, as it taught me a lot about how computers work under the hood and made me a better programmer in the long term. But it's not really a good language for non-CS people who just want something that works. In the recent standards the syntax has become really confusing and it's hard to keep up with all the changes. Manual memory management also makes it pretty error-prone. However, what really makes this language annoying are the horrible standard library and tooling. 
&gt; C++ is very difficult to learn and use correctly. The barrier to entry of learning the tool-chain, how to manage external dependencies, the minutia of what is required when integrating external libraries, the complexities and nuances of different linking strategies and when to use them, how to package things so that they run consistently and correctly across platforms and environments, the list is endless. &gt; It's all shit that takes time and effort that could be better spent working on your projects. I guess that just isn't something I mind I guess. I'm not in this for a fast payoff - it isn't a job, I have my whole life to learn this (Unless life fires me by hitting me with a car or some shit for not learning fast enough.) And now I've been sitting here for an hour trying to finish this response. I think I'm overthinking this whole situation.
I have the latest edition of the Primer as well! Plan on using it as my second book - I've heard nothing but praise for the Primer other than that it is not a book for people who know absolutely nothing. Good thing I have nothing but time to learn it, too. I probably would've stuck with Python or something higher/easier to learn if I had a limited amount of time.
Although I am doing this for personal projects rather than professional, I do plan on learning other languages once I have a solid grasp on C++. Hearing about the backwards compatibility makes me feel a bit more secure in my choice. I'm also glad to hear it isn't as much of a grind anymore, though I'm ready for that.
Source: https://twitter.com/FelixPetriconi/status/876482327374909445 (surprised it was not already here...) Related to Adobe's concurrency library: http://www.stlab.cc/libraries/concurrency/index.html
Gor did not push us to write the proposal. The initiative is the result of internal discussions during the process of finalizing our library.
My interpretation of the last part of the proposal might be incorrect, will edit. Done.
&gt; I can only think of 3 industries that use C++: game development, financial trading software, and firmware. I work in the space industry and we use a lot of C++ too. 
Can you do like a summary table or something like that? All these console outputs take quite a long time to parse and make sense out of them.
/r/cpp
Please refer to the [book list](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) on the sidebar.
As per my post I have already looked at the book list and I'm looking more specifically for where I should jump in on that list.
I have found that it is quite easy to implement RESTful interfaces in C++ using libfcgi++ and Apache. This gives me all of the HTTP capabilities of Apache (SSL handling, Kerberos support, proper CORS implementation, caching, compression, URL rewriting, etc.) and a simple and very fast interface. And, for my needs, FCGI scales really well. The cost is that you have to work withing Apache and FCGI's framework, where scaling involves spawning more executables. If you need to cache large amounts of data or if process startup takes a long time, it may add some complexity.
Does the article actually have a meaningful response, or does it just delineate the evolution of language best practices?
Try r/cpp_questions then. 
Already posted [here](https://www.reddit.com/r/cpp/comments/6i8um9/performance_of_rangev3_in_comparison_to_stdfind/).
Just caught this when re-reading the sidebar, sorry about that.
You are welcome :) I am pretty new to writing blog posts, so still learning how to present information properly. I am too dissappointed with cpprestsdk performance. Its code is top notch, as well as documentation, but linux impl is slow. I saw several issues on their issue tracker regarding this, but it is not yet solved. If there was no problem with performance, I would definitely tell that this is best framework to use. Also, I didn't include Beast in review, though I was trying to compile and run it on Ubuntu 16, but it just stuck on 70% during make (one of stream.cpp files). Its HTTP server example is way too complicated if to compare with other frameworks.
Smart solution :) . I am not a big expert in FCGI, but should not Apache preload your module during server initialization, so you won't have any performance problems with processes spawning in runtime?
I wonder how much more painful it is in debug mode. Debug mode performance isn't super important, so long as the end result is still usable. If there are hundreds of function calls in a 'find' call though, then I can imagine that getting near the point of being unusable.
Modern C++ started in '98. We are in the Postmodern C++ era.
I'd be willing to dive into the deepest parts of the language and programming in general, to the point that "what works" might not even exist as a concept. I overthink it(the process of learning C++) all the time, because heck I love overthinking, and that's why C++ is the best for me, hah.
It would be nice to have some directive to specify which functions should still be inlined in debug. Although that might be hard to do for the STL since you can't really modify it. MSVC has an option to only inline functions marked with `inline`, which is better than nothing. Dunno about other compilers.
https://makecleanandmake.com/2015/07/20/leading-typename-dot-template-and-why-they-are-necessary/
&gt; MSVC has an option to only inline functions marked with inline, which is better than nothing. Dunno about other compilers. Does MSVC handle inline in a special way, because all compilers should understand they keyword inline. It's just a question of whether or not they will actually listen to it and make the function inline. And I don't think that MSVC produces significantly more inlined code than other compilers(?) Edit : I didn't ask what inline means....I just wanted to point out what you all said - using inline is no guarantee for inlined code. MSVC makes no exception for that rule.
Coders in Visual Effects and Animation are also using C++ exclusively, when writing high performance code. And we sure need a lots of that.
Out of curiosity, did you try the Windows implementation? What seems to be slowing things down is their port of PPLX, at least that's what I got from the GitHub issue. This could be significantly faster on Windows because their tasks hook into the Windows system threadpool.
Thanks for the shout out!
You can call FCGX_Accept_r on multiple threads. It should be fairly easy to scale libfcgi++ without resorting to multiple processes. 
If I'm understanding you correctly, if I just build it in alpinelinux it will automatically be cross-linux platform and statically link to openCV?
It's worth noting that pistache and restbed are using rapidjson for their JSON stuff while cpprestsdk is using its built in JSON library. It might be interesting to compare just the JSON stuff or to using rapidjson for all three to take that out of the equation.
I believe so.
Assuming Range-v3 isn't worse than a toy version I made, with a smaller amount of operations, it should optimize to at least a raw for loop (generated assembly was the same with one transform, and one transform with a filter). If you tweaked it enough, it seems likely that you'd be able to get a better optimization out. If you tweak compiler flags enough, you should be able to get this version to work.
You should add https://github.com/facebook/proxygen to your benchmarks. In my experience, it has very high throughput.
Hi! C++ REST SDK maintainer here :) On Windows, our listener is backed by the Win32 HTTP Server API, so it should have much better performance. On Linux/OSX however, we unfortunately have a custom implementation. I've chatted some with /u/VinnieFalco and I'm excited to see if it'd be possible to use Beast as the implementation once it's part of Boost (which we already depend on). I'd also recommend using RapidJSON instead of our built-in JSON object model for benchmarks. Our built-in model is really optimized for usability instead of performance; if you're willing to pay the "cost" of dealing with your own allocators, you can do a lot better!
C++ is a difficult language by any measure. Adopting that as a first foray into programming will be daunting. Furthermore do not limit yourself to one language. Prefer to have at least a nodding acquaintance with many computer languages. 
Man, I am about to give a deeply unsatisfying answer, so prepare yourself: if you learn how to think like a programmer, the language you know matters much less. I was a lecturer is computer science for years, decided to enter industry at the end of 2015. I came in confident, since I knew C++ and Java, both major industry languages. A year and a half later, all the code I've deployed is written in Scala or Python, languages I'd never touched before I came to this job. I've written exactly one piece of C++ code and two pieces of Java code, neither of which ended up being deployed. For what it's worth, C and C++ are used in a number of industrial applications, but so are a lot of legacy languages, and a lot of newer languages. C++ is a wonderful language in my opinion, and we teach C++ in 1st year CS so it's definitely possible to learn it with no coding background. However, a lot of people find it really tough. As I said, learning how to think like a programmer is more important than any single language. 'Learning to code' should be about getting good fundamentals, learning problem solving skills. You need to learn in some language, and the fact that your school teaches in C++ makes C++ a good choice *for you*. But ideally, you'll also at least familiarise yourself with other languages. If you know C++ but are too scared to look at Java, you'll have trouble. A lot of people think Visual Basic is a good place to start learning, and you know what? If it teaches you how to think like a programmer, they're right. As I said, your school uses C++, so it's a great place to start because you have professionals nearby who can help you. But as I said, make sure you don't get stuck in this one language. Learn how to express your thoughts as code, and be willing to learn a new language for that particular code when you need to. Edit: I can't spell early in the morning
The std code looks far simpler and easier to understand than the range version in this case.
&gt; all compilers should understand they keyword inline. It's just a question of whether or not they will actually listen to it and make the function inline Inlining a function is not really the point of the `inline` keyword. Yes, it's a hint to the compiler that it could be inlined, but that has always been up to compiler. The keyword's main purpose is to assert that the function is identical across translation units, which makes it _sort of_ work around the One Definition Rule. Multiple identical definitions are in a sense indistinguishable from a single definition. That's the reason some functions are implicitly `inline` and you occasionally need to mark functions (especially explicit template instantiations) in headers as `inline`: so they can be shared/duplicated across translation units and everything works out whether or not the function is actually inlined at the call site.
I provided user side [code of all samples](https://github.com/metamaker/cpp-rest-frameworks-benchmark/tree/master/samples/cpp). You can see that they have absolutely same structure and very closely comparable. True that samples are uncomplicated, so not all features are covered. Though not completely related to REST, cpprestsdk and restbed provide Websockets support, so this is not tested, as well as may be some other parts. Perhaps, more correctly to say, this is test of how frameworks work for specific use case that often occur when you build REST API.
Thanks for feedback! Got it, will do another test with RapidJSON impl.
I tried something like this a year back and the main problem I found is that as soon as users need an option you haven't considered they have to understand not only cmake but also everything that your script is doing. Power users just get annoyed by the additional layer of abstraction that they don't want to have to understand. Admittedly you have done a far better job of it than I have and it looks like a beginner could get quite far with the functionality you provide. TLDR I like the idea but in practice users still have to lean cmake anyway 
that's if you call web development development ^sorry
Many people have trouble understanding pointers. Most languages hide pointers these days, which makes them easier for beginners.
I think the same. The simple fact that there is a variable named "accumulated_length" says so much about code intention. And the "find" in "find_if". Actually, I find the C-loop even easier. It is shorter, and with more descriptive variable names is the easiest to understand version for me. It is also the most transparent in terms of what the machine will actually do.
Hi Vinnie! First of all, thanks for big effort that you put into Beast library :) I really like Beast's WebSockets client implementation, it is easy to use, yet very powerful! Hang up occurred during compilation of library itself, not an example. I will verify it once again and let you know details of my setup and how to reproduce the problem ;) . However, regarding HTTP server, I find [Beast server framework example](https://github.com/vinniefalco/Beast/tree/4c15db48488cf292af76a8f4509686306b76449f/example/server-framework) to be too complicated. 558 lines of code to implement HTTP server like http_async_port.hpp is too much if to compare with other available frameworks. And it is not even complete code, because it is only starting ground for implementation of real handler. All other frameworks provide capability to create simple server in less than 50 LOC (e.g. see [cpprestsdk sample](https://github.com/metamaker/cpp-rest-frameworks-benchmark/blob/106d52a0788c0f024d638c664a01a0ed8810bb01/samples/cpp/cpprest/main.cpp)).
&gt; Hmmm. i started learning c++ on websites when I was 13 years old, and the most complex thing for me IIRC was understanding the point of having classes and other sw engineering-like questions. It is uncomplicated till you find more advanced concepts like inheritance of private virtual methods, move semantics, templates arguments resolution and so on. There are a lot of tools inside C++ that you really have to understand deeply to write efficient and maintainable code. For school projects every language will work.
Yes, Stroustrup is a very gentle, humble, thoughtful and yet brilliant and entertaining scientist. I have watched almost all of his interviews and talks on YT, and I have red many, many of his inteviews and transcripts. I really admire him. He is only just below to Alexander Stepanov to me, as the "abstract" model of how a scientist should be.
&gt;might work fine if you're a student Er, the book is specifically addressed to novices and students, you may want to read TC++PL 4th if you think of yourself as an "experienced" C++ developer.
Yes it is a typo. Already corrected on the live page. https://github.com/FelixPetriconi/future_proposal/blob/master/proposal.md Thanks for spotting
A friend of mine was a student at a technical university, and was asked to implement a number of sorting algorithms. His professor had given him a framework that set up the thing to be sorted (not a vector) and provided an interface for the sorting function (it passed a bunch of non-const void pointers around). And sure, maybe he didn't want his students to have to understand templates... But providing this kind of example as a teacher at university level didn't do much to impress me.
Nice article. I really really want UFCS, as it would fix the "awkward syntax" issue and encourage free functions over member functions. What are the issues with an opt-in leading dot syntax? .foo().bar(); Guriwesu [mentioned some on Twitter](https://twitter.com/Guriwesu/status/875033098005733380) - are there more that need to be addressed? It would be nice to group up and try to propose something that clarifies these problems.
Oh! Okay, that's a fair point - HOWEVER, Beast is not really designed to be a server! Its a low level library. Its not a replacement for cpprestsdk. In fact, cpprestsdk could be written using Beast and the result would be more flexible and maintainable. Its not the intention of Beast to provide a server in its public interfaces - the server-framework example is there to show what Beast can do and also to serve as something that people can copy or writing their own servers.
This is so much more painful than it should be, on so many levels! (particularly the C glueing...) Kudos to you for completing it and thanks for posting this information.
With std::invoke -- assuming everyone used it -- is there still a need for UFCS?
Great article. I'm not seeing the benefits of this approach, though .. How does this improve encapsulation? Using a free function vs. a method does not change the amount of implementation detail exposed to the user? How do the free functions help with generic code? Wouldn't a sensible approach be to change template &lt;typename Shape&gt; to Circle inheriting from a Shape base class? The drawbacks of this approach are significant - always needing to ask yourself "is this operation a method or a free function?". Also it inhibits your IDE .. you can't just type "circle." and get a list of methods to use because they could be free functions. 
I'm sorry, but I'm not sure I understand this argument: &gt; Consider how much harder this would be to write such code with functions like getCirclePerimeter and getRectanglePerimeter. Just remove the `Circle` and `Rectangle` from the names and you get the same thing: template &lt;typename Shape&gt; void operateOnShape(Shape const&amp; shape) { double perimeter = shape.getPerimiter(); .... } Or am I missing something? I don't get why people seem to want to remove **everything** from OOP lately. Returning its own perimeter is a completely valid thing to ask of a class to do, right? I mean sure, `std::begin` and `std::end` do make sense because of arrays, but what's the benefit of going back to C-style `function(struct)` in general?
I don't like C function which require string without its length, but if I have to deal with such function, I would check sv[sv.size()] then pass copied string if it isn't null.
basic_string::data() returns a nul terminated string, contrary to what the article says.
Right, but if I'm designing my code from the start, should I still prefer this design?
No arguments there. It just feels like his real problem is "there's no guarantee that a `const char*` is a null-terminated string". He's going to have that problem, regardless, if he's interfacing directly with C APIs. It's just the world we live in. At least by using `const std::string &amp;` in his interfaces which need to accept strings, he'll always (for sufficiently small values of never) know it's safe to pass the `c_str()` along to e.g. the GTK functions.
An obvious solution presents itself: *Don't call C functions.*
Often unavoidable. You can avoid the C stdlib but you can't avoid using a C library like OpenGL for example.
&gt;How does this improve encapsulation? Using a free function vs. a method does not change the amount of implementation detail exposed to the user? I don't think it's intended to improve encapsulation. I think it's intended to improve robustness and minimize necessary changes to the interface itself. The namespaces thing would be an issue, but it is basically solved. UCS would make pesky interface calls simpler (for the user/programmer). I don't fully get it, but there are a lot of clever people thinking about it.
So this could actually be the equivalent to [C#'s Extensions](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/extension-methods)? &gt; Extension methods enable you to "add" methods to existing types without creating a new derived type, recompiling, or otherwise modifying the original type.
The argument you don't understand is, I believe, just about the decision to name a function `getCirclePerimeter(Circle)` vs `getPerimeter(Circle)`, or equivalently `Circle::getCirclePerimeter()` vs `Circle::getPerimeter()`. The general argument for free functions (apart from working with built-in or C-style types) is that they mean the type's interface is smaller. Since the `getPerimeter` function is not a member function, if I were to change the representation of the `Circle` type (preserving its interface) I would know immediately that `getPerimeter` would be unaffected. I could also easily add/remove/change higher-level functions that deal with the `Circle` type (e.g. `getPerimiter`)without changing the type itself.
It was a joke.
Me: *woosh*
something like namespace std { int numberOfOccurence(const string &amp; str, const char lookup) {return std::count_if(str.cbegin(), str.cend(), [=](const char c){return c == lookup;}); } } std::string wStr = "Allo 123"; std::cout &lt;&lt; "Number of character: " &lt;&lt; numberOfOccurence(wStr, 'o');
&gt; How does this improve encapsulation? Using a free function vs. a method does not change the amount of implementation detail exposed to the user? It changes the exposure of private data. Let's first consider an extreme example. Let's say you have a class with private data. Encapsulated, right? But what if every function of your entire program was a member of that class, which means every function has access to that private data. Still encapsulated? So the recommendation of both Scott Meyer and Herb Sutter is to prefer free functions. For best encapsulation, the number of member functions -- which is to say, the number of functions with access to private data -- should be kept as small as possible.
`std::invoke` is a pretty big hit to readability. In generic code, it's probably worth doing, but outside of templates I don't see it becoming very common.
 ab -c 1 Really? It means 1 concurency, i.e. sequentially polling services. You should try to set it up to more higher value, first. 
You can try and tell what results you get ;) I was interested more in results that implementation produces for single call of service per single user if there is almost no load. This is why I made it to sequentially poll HTTP server. Remember, I tested performance of framework implementation, not how implemented server behaves under heavy load and how scalable it is (though it is also important factor for production). So results of benchmark are pretty limited and can be further extended.
If we're talking about `std::string_view`, it's safe to assume everyone's in a post C++11 world.
So am I correct in understanding that full optimization sacrifices memory copy speed, but speed-focused optimization increases memory transfer speed? Kinda makes sense I guess, since O3 would be mixing best of both O1 &amp; O2
Most of the time I would also go for the inheritance based approach, however the article does mention one scenario where the template version can solve a problem that you cannot easily solve with inheritance; if you do not have control over the object you want to operate on. In this case, we cannot inherit from the Shape class, but we can write free functions which enable support for the template approach. I think this is a very valid issue to consider when weighing up to alternatives.
Yet again..., using sharedptr in a single-threaded scenario ? You're doing it wrong! :-)
So you just move the problem from one place to another.
No the problem is constrained to a single function, instead of littered across the code, as I have seen multiple times. Better, I can make use of safer C++ semantics instead of unsafe C ones, as those wrapper functions take the role of *unsafe* blocks in other languages.
These are not modules, but external processes that are spawned by Apache. Communication is done via a Unix domain socket. Apache can scale your service by launching additional back-end processes as load increases. If you don't need dynamic scaling, then you can spawn a fixed number of processes when the server starts. That's what it means to work within Apache and FCGI's framework. :)
But if you use a unique ptr you've always got to pass the thing around. Say you've got a global vector somewhere of unique pointers, anytime you'd use them you'd need to move them somewhere and then back to that global when you're done with it right?
Not necessarily. If you have a well defined lifetime you can just pass the raw pointer around.
Huh, I guess that makes sense. Cool.
Correctness first, with multiple owners shared_ptr is the goto solution. For single owner situations it is just plain overkill.
One time I got to take a look at cppinstitute's course material, saw a lesson explaining the C89 meaning of auto, and didn't want to read any more.
OpenGL is a bad example for this case: glShaderSource accepts non-zero terminated strings just fine.
I opine that multiple owners on a single thread are a design deficiency.
Different entities among the same thread. An example could be a program with multiple coroutines that all share a single thread sharing some information. But even without coroutines you can achieve the same thing using epoll and similar APIs. I'm sure there are other needs where a good owner for the pointer is hard to find, so you can't use a unique_ptr, but a reference counted pointer would do great.
In my experience, most people use shared_ptr in conjunction with with weak_ptrs to make ownership contracts, and most of these systems work on a single thread
The temporary is definitely dead after the semicolon, but those functions normally take a copy of the passed in `char*`. Doing otherwise puts too much lifetime management burden on the caller.
I remember watching a Cppcon presentation where Herb Sutter talked about such a non-locking refcounted pointer. Sounds like a good thing to add to the standard library.
With multiple owners thinking some more about ownership should be your go to solution. In my experience shared ownership is almost never needed and is just a sign of sloppy design.
One could get boost to do that (`!BOOST_HAS_THREADS` perhaps?)
I'm sure most of us could whip one up in no time, but having it as part of the standard definitely helps. I wish I could understand the reasoning of not providing one as most parts of the standard aren't thread safe either unless specifically dealing with threads.
I didn't read every word of the article to see if this is addressed, but one [minor] drawback of using external instead of internal methods is that external methods either need to be declared inline, or the function body put in a separate compilation unit. If either of these conditions are not met, and the header is included in more than one source file, the linker will complain. I'm not suggesting this is enough to refute the idea of external methods, but it can be a pain if you have many short methods.
Your code will be legacy one day.
&gt; And for cases where you explicitly want non-atomic updates even in multithreaded programs, GCC also supports This is awesome! Is there a way to get the equivalent make_shared as well?
You have to be careful about ADL. ADL won't work with fundamental types: &gt; 1) For arguments of fundamental type, the associated set of namespaces and classes is empty Example: #include &lt;iostream&gt; #include &lt;stdio.h&gt; #include &lt;algorithm&gt; struct B { int val; }; int adlFc(const int v) { return v; } int adlFc(const B &amp;v) { return v.val; } namespace nsA { template &lt;typename T_&gt; struct A { T_ val; }; template &lt;typename T_&gt; int adlFc(const A&lt;T_&gt; &amp;v) { //using ::adlFc; return adlFc(v.val); } } int main(int argc, char **argv) { nsA::A&lt;int&gt; v{50}; nsA::A&lt;B&gt; v2{50}; std::cout &lt;&lt; adlFc(v) &lt;&lt; '\n'; // Fail to compile unless you uncomment the commented line above std::cout &lt;&lt; adlFc(v2) &lt;&lt; '\n'; getchar(); return 0; } 
Constraining it to a single function does not remove the need for constructing an unnecessary std::string just to get that zero terminator. I consider that a much bigger problem than having a few 'unsafe' C semantics around... 
In fairness, the Java code is doing, if anything, semantic equivalents to far more than even shared_ptr.
Indeed, thanks. 
The fact that neither GCC nor clang can optimize the expanded loop from range-v3 is sad, but that they cannot even optimize the C-raw loop... that is just unacceptable. Chandler Carruth said a couple of years ago that "we know how to auto-vectorize loops", and that auto-vectorization is kind of a solved problem. It looks to me that modern auto-vectorizers cannot vectorize even the most trivial loops, and that if you want performance you should avoid "generating" these loops through tons of abstractions that prevent you from optimizing manually. 
The problem is that as soon as you access anything which isn't owned by some object in the local scope you're losing the ability to reason locally about your program. I don't want to dig through ten files in order to find out "ah, these two things are owned by the same object and thus this reference will never be outdated".
You can use boost::optional for that.
I don't quite see what you mean? Any ref/ptr not stored for later use (e.g. a parameter to a function) is safe for use. If i take a reference to something out of an object, it's very safe to assume it will live as long as that object lives. Otherwise, I likely need a copy. That alone resolves majority of lifetime questions on the spot.
I think just a `T&amp;` is the way to go in this case.
Or you could just call the method `perimeter` and have the setter called the same thing and just take a parameter, disambiguated by overloading. Not only is this terser, but it's more in line with established C++ naming conventions/practice (see: The standard library).
I would consider it a problem if the profiler would confirm it was an actual problem that affected the overall application and was worthwhile looking into.
If the lifetime of the program *and the data size* is small enough, then maybe, but Java is doing a lot with the memory management even with short lived programs that is pretty involved to replicate. Of course, if you are using C++ to replicate Java, you're already doing it wrong. C++ has the advantage that you only pay for what you use, and you can choose not to use all these things. The Java runtime can sometimes identify such opportunities, but you have to buy into the "Sufficiently Smart Runtime" to think it's going to be able to match for anything but trivial cases.
I've definitely seen C that looked and smelled almost exactly like FORTRAN in academia.
I dunno, maybe pistache caches responses or so. Why not exclude json-related part to prevent any speculations? I would put already prepared buffer or something. I understand that json-related functionality is an important part also, but with your 10000 loop around json construction it's hard to say what you're measuring exactly.
`std::reference_wrapper&lt;T&gt;` but now you're just multiplying bad decisions.
Heavily related imo. https://herbsutter.com/2013/05/20/gotw-4-class-mechanics/ https://youtu.be/5tg1ONG18H8
In the lifetime of a short-lived command, there's rarely enough time to even know where the "important" sections are... add to that the whole JVM initialization time, java is at a tremendous disadvantage for CLI tools. (As a frequent user of the `hdfs` command, I really wish java would just die a quick death in use as a language for the CLI.)
&gt; Also it inhibits your IDE .. you can't just type "circle." and get a list of methods to use because they could be free functions. Not necessarily. Using VS for C#, I remember autocompletion including extension methods, even though those are defined outside the class itself. The same could be (probably has been) done for C++. Edit: This is [already in R++](https://www.jetbrains.com/resharper-cpp/whatsnew/): &gt; Postfix code completion allows you to focus on your data, rather than the syntax. When you type a dot (.) or an arrow (-&gt;) after an expression, ReSharper C++ will suggest free functions that would accept that expression as the first parameter. If you accept the suggestion, ReSharper C++ rewrites your code so that the expression is passed as the first argument.
Nginx's fcgi module doesn't either, but both can (and do) open multiple connections to that socket, which can be handled in multiple threads on the other end. 
&gt; GCC's shared_ptr detects whether the executable is linked to libpthread and uses non-atomic updates when possible. What would it use besides atomics? Wouldn't mutexes be slower? Edit: I'm dumb.
Why would it need to use mutexes in a single-threaded program? It just uses normal integer arithmetic. There won't be data races if there's only one thread.
yes, it is guaranteed to be alive during the call, all arguments are.
Ohhh I'm sorry I got it flipped. I thought for some reason you switched to non-atomics if pthread was linked, not the other way around. My bad. Question though, couldn't you still make threads without pthreads? I'm sure it would be annoying but couldn't you do it?
Not as much as you might think. In fact, a fair bit less than what shared_ptr is doing depending on your GC settings. With pretty much all java GC settings, however, allocation on the heap is nothing more than pointer bumps. (IE, move top of heap pointer from 0x0000 to 0x000A to allocate 10 bytes). Java doesn't keep track of usage of pointers, it only does that when the given space is filled up. Java's allocation scheme for heap allocations is much faster than even solutions like jemalloc and a much lower overhead than something like shared_ptr. In the OPs case, java is likely so much slower than C++ for a few reasons. It hasn't had time to warm up the JIT; This includes time to load the classpath; And finally just generally Java's memory model sucks. But if I were to guess, the classpath loading and JIT warmup time would be first and foremost in slowdowns here. Java isn't a good CLI tool, it is a long running server tool. I'm not under the illusion that java is faster than C++. But I also know that many of these benchmarks are unfair towards java because they measure the wrong things.
http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197
I think one of the concerns people had in general (not for this idea specifically) was that code using `x.bar(1)` will change meaning if `X` adds a `bar` member function later on. Adding a function to a class becoming a breaking change isn't really desirable, though I don't have a good solution for that. All I can say is that C# has had behaviour like this for a long while now and I haven't heard of it being an issue in practice, though I think C# actually lets you provide an overload as an extension method and not have it completely hidden; the behaviour can still change if your added in-class method conflicts with that overload. 
The "attack surface", so to speak, grows with every member function. Sure you can inspect a member function to verify that it doesn't access member data, but free functions use the built-in syntax of the language to document that they do not access member data so they don't require any inspection of the function body to verify this.
&gt; Not as much as you might think. In fact, a fair bit less than what shared_ptr is doing depending on your GC settings. With pretty much all java GC settings, however, allocation on the heap is nothing more than pointer bumps. (IE, move top of heap pointer from 0x0000 to 0x000A to allocate 10 bytes). Java doesn't keep track of usage of pointers, it only does that when the given space is filled up. Java's allocation scheme for heap allocations is much faster than even solutions like jemalloc and a much lower overhead than something like shared_ptr. Heap allocations are very cheap in the JVM. I wasn't arguing otherwise. However, references in Java do a LOT more work, and heap management is much more involved. You've got thread safe memory manageMENT &amp; compaction going on there, and that's ignoring the mutex in every object... That'll will kick off the moment you fill eden space, which happens quite frequently in your typical software program. &gt; And finally just generally Java's memory model sucks. Interestingly, C++'s memory model borrows much from Java's, and had many of the same people work on it. ;-) &gt; In the OPs case, java is likely so much slower than C++ for a few reasons. Oh yeah, there are lots of reasons. &gt; I'm not under the illusion that java is faster than C++. But I also know that many of these benchmarks are unfair towards java because they measure the wrong things. Couldn't agree more.
It seems like your account posts a lot of links to this web site. Very fishy.
there's no vectorization happening there either way, just unrolling, and they'll unroll the loop just fine with `-funroll-loops`
Yep, I had the same problem when using my [parray](https://github.com/crusader-mike/parray). When reading and parsing files -- there is next to zero support from CRT because most of these functions expect NTBS. Ended up simply writing my own equivalents of atoi()/etc.
Blame Dave Abrahams - he fought with Andrei Alexandrescu back when shared_ptr was getting into Boost. Andrei wanted something like his Loki policy'd smart ptr, with policies on single / multi-threaded behavior (and heck, 4 others!) http://loki-lib.sourceforge.net/html/a00634.html and Abrahams wanted something foolproof and dumb. I caught just the tail-end of the conversation (on gmane) so I'm sure I'm missing details, but basically Alexandrescu got shouted down. Which is dumb. C++ isn't for noobs, it's for flexibility. You can always typedef (or 'using') your particular applicable variant. It's a real shame. Someone needs to take Andrei's Loki policy'd pointer and submit it for standardization - it's a stupidity that smart pointers can't be exactly what you need. (And no I'm not Andrei.)
&gt; https://www.reddit.com/r/cpp/comments/6idwzp/yet_another_java_faster_than_c_claim/dj6tva8 Yeah I'm spamming this but it's never too late to try to get something like it standardized. 
Why do I need to pass `-funroll-loops` ? Why cannot the compiler decide for me when it is profitable for a loop to get unrolled? The manual unrolling of the standard library implementations looks to me to be something that should belong to the past, but they are there for a reason.
Nowadays Andrei has taken that concept further in D with what he calls introspection driven design. Basically using compile type reflection with policy classes.
I understand what you are trying to say, but look at it from a user perspective: he has a small file which he wishes to compress. It takes longer when he uses java. The only thing that counts for him is wall clock time; he doesn't care if it's being spent on garbage collection, class path loading, JIT optimisation, or whatever else. 
Could you explain further?
In theory Java could observe how the program is being used and make specific optimizations at runtime. In practice it never works out to be faster, but someday it might.
Scanf isn't quite comparable to stringstream. Scanf can handle parsing values out of strings containing other arbitrary text. Example: "some location: ( %d, %d )"
One company I worked for had a simulator written in Fortran. The code is thirty years old... and still being maintained. It works, why change it? The UI around it was written in C#/C++ and generated the script files for it. It's only weakness was an inability to be made concurrent - so there were plans to replace it with a new version that could run on a 1000 node Linux beast.
And stringstream locales. Read my point with bechmarks. It is at the top of the project. I compare ways of doing things in traditional vs more modern ways. I am no trying to leave any of these styles in a bad place. In fact I expected this benchmark to be for C scanf and was deeply surprised.
"Policy-defined" are no always a good thing. Consider "volcabulary" types - libraries are supposed to talk to each other using these types. If they are highly customizable, then every library will use their own flavor of the type, and they could not talk to each other any more. 
TouchÃ© :)
If you don't have any other way of demonstrating your C++ knowledge, perhaps.
In previous discussions here that was the only advantage I could see with bidirectional UFCS that could outweigh the confusion they cause.
Member functions and free functions are fundamentally different and mixing notation just makes it confusion. There is no inconsistency because they're not the same. For generic code, I can see the point. But for those cases one-way UFCS where free function syntax also finding member functions is much preferable. For chaining, which mostly occurs for range composition, the pipe operator is superior since it captures intent better.
Why does he care about wall clock time at this point?
Sure, these are all my (subjective) opinions. Would you mind clarifying why you think free functions and member functions are the same?
Using shared_ptr in those cases is paying runtime cost for your design time uncertainty. 
It was turned into [a `std::basic_string&lt;&gt;` constructor](http://en.cppreference.com/w/cpp/string/basic_string/basic_string) (#10), so the functionality is still there, the dependency is just inverted.
We've had ideal UFCS since the beginning for operator overloads: members and non-members participate in overload resolution on equal grounds. Named functions are the unfortunate exception, which is probably why generic programming relies on operators, and when using named functions, uses member/non-member pairs like swap or begin.
x.f() is (more or less) syntatic sugar for f(x) where "x" is passed as the hidden parameter "this".
Thanks, this is a good page to read to be sure of things like this
This makes perfect sense when you consider what string_view was designed for. Consider a following string allocated with `std::string`. `$` is null terminator, allocated for `c_str` to work. &lt;&lt;Hello, world.&gt;&gt;$ Those `&lt;&gt;` brackets are somewhat ugly however, let's get rid of them by making a string slice (`string_view`). &lt;&lt;Hello, world.&gt;&gt;$ ^^^^^^^^^^^^^ I marked with `^` symbols the area of `string_view`. Now, how to pass this to C? Remember, you need a null terminator. But there is `&gt;`, not a null terminator. One of possible ways about it is to replace `&gt;` character in a `string`, but unfortunately `string_view` doesn't own the object, and temponarily even replacing that character will cause race conditions if somebody uses that `string` already. Multiple reads of the same object as long there are no writes shouldn't be race conditions, and yet doing so would cause a race condition. Not to mention, if you split a string into two parts, and then tried to pass both of those to C, they would overlap. So your only option is to copy the contents to a new object, i.e. `std::string`. Therefore `c_str` cannot work on `string_view` in many cases without copying.
Yes this is the viewpoint of those that always want to write y = x.f() for all function calls. I'd say there are many of us who thinks y = f(x) is cleaner when calling free functions and mixing the two leads to confusion. The advantages of always writing y = x.f() is (1) easier tab-complete, (2) simpler generic code, and (3) chaining function calls. The disadvantage is ambiguity and more difficult to read code. The point of this post is to point out that (1) is now moot.
Check out also my benchmarks https://bitbucket.org/sobjectizerteam/restinio-benchmark-jun2017 It includes Beast.
Personally, I don't really know if anyone cares about tab complete all that much in the first place. Certainly nobody is designing languages with tab complete in mind.
Two points, neither a particularly strong counter to the article: A number of libraries have invented a `cstring_view` or the like which guarantees to be NUL-terminated. The obvious limitations of course are that it can only be created a NUL-terminated string (like a literal or a `std::string`) and that slices can only be made off the front of such views since slicing from the end would require mutating the underlying storage. If those limitations are acceptable, though, it has all the other advantages of views compared to C strings still intact, which can be valuable. Second, a number of "good" C APIs either take an explicit length or have a second version that takes a length. A great example that pops to mind is Lua, which has functions like `push_string` which take a regular ol' C string and `push_lstring` which takes both a character pointer and a length. When working with such C APIs, a `string_view` works just fine and dandy, of course. I would go so far as to argue that any C API which doesn't offer the length-delimited API should have a bug filed against it, since even if you're using pure C you do sometimes want to work with slices of buffers or the like without making copies. The big sticking points are the POSIX APIs (`open` and the like) which don't have length-delimited versions and at this point probably never will; one might get Linux or a BSD or something to add them as extensions, but standardization is unlikely I think.
Sadly, that's all 90% of the people here talk about every time UFCS comes up...
Agree. for what its worth i like the terminology "foo has a converting operator" or "foo has a conversion (to int)". "Foo has an explicit conversion to int". Etc. I think of a cast as a piece of syntax e.g. "we used a static cast" or "that is a c style cast". I wouldnt say foo has an implicit cast to int, or foo defines an implicit cast to int.
Why stop there. We could use a regular expression to describe the type and value.
&gt; This clearly goes against the "only pay for what you use" mantra of C++. Only if someone is _forcing_ you to use `std::shared_ptr&lt;&gt;`...
RESTinio doesn't implement RESTful service instead of you. But a service supporting HATEOAS can be build on top of it.
This depends on: 1. The encoding of file, and therefore the string; 2. Console support for said encoding; 3. The font used by the console. There's a reason putting non-ASCII characters in ~~strings~~ in your source code is not recommended: it's brittle and platform-dependent.
&gt; There's a reason putting non-ASCII characters in strings is not recommended Citation needed. The language has support for UTF-8/-16/-32 strings. ASCII is simply insufficient. Not only should putting non-ASCII characters in strings not be not recommended, but code which assumes strings contain only ASCII characters should be considered broken.
Well in that case I agree with you that tab-complete is not a good reason. Languages shouldn't keep up with IDEs. IDEs should keep up with languages.
Okay let's modify the code snippet /u/scatters originally posted: #include &lt;iostream&gt; int main() { std::cout &lt;&lt; u8"\u03A3" &lt;&lt; std::endl; } This will still likely be "*broken*" on Windows by default however.
Because the user only cares about getting the task done, preferably as speedily and with as little grief as possible? You bring up a whole bunch of reasons why a slower overal execution time somehow shouldn't count, but I can assure you, for people who actually use software, it does. 
Nice!
It is a good deal to have exactly HTML as a language defining **semantic** of the UI structure. Think about accessibility and other cases. If you don't like HTML per se then you can use any processors like HAML ( http://haml.info/ ). In this case you will still have HTML as lingua franca for other cases. And pair of HTML and CSS is good in separation of concerns: HTML defines structure, code defines UI states, CSS defines how that structure and states are rendered. As an example, this Sciter UI application https://sciter.com/from-skeuomorph-to-flat-ui-evolution-of-one-application/ survived 10 years of UI evolutions with core practically untouched. From Skeumorphism to flat Metro style. And UI engine itself: from GDI to H/W accelerated Direct2D/DirectX and OpenGL. 
You can copy and paste these characters into cmd and it displays it fine. But when I try to print it using C++ it doesn't. I've tried countless solutions but this was the only one that worked and I could not find a complete list of codes so I made one myself. It's not that big of a problem with just little inconvenience to work around but at least for me and maybe some others - it is an issue.
For a moment I was disappointed because I thought this was a video about `itoa`. `std::iota` makes more sense given the title of this series ;)
We need header-only OpenSSL too. Well-done!
Option 2, because if you read my comment it was in the past tense. That is what I used to do when I was a C++ developer. Nowadays I use mostly managed languages for my daily work, leaving to C++ the role of interfacing with native code when required to do so. For example, .NET with C++/CLI or C++/CX, or Swift with Objective-C++. As such I am yet to play with a C++17 compliant compiler.
Interesting! Thanks for sharing!
First of all C++ is not necessarily that hard at all if you take it one concept at a time but there are far more moving pieces to a C++ program than a Java one. And you have to manage dynamic memory yourself, usually via a pattern called Resource Aquisition is Initialization(RAII). RAII ensures that when an object goes out of scope all of the memory and other hardware resources it acquired are properly released. C++ isn't necessarily harder than Java if you use it at an abstract level but it is different and you should forget everything you know or think you know about object oriented programming and start fresh. If you really want to learn C++ I'd recommend Jumping into C++ by Alex Allain, an award winning Harvard CS lecturer, and if you want more like a textbook use Programing Principles and Practice in C++ by Bjarne Stroustrup, he is the original creator of C++ and was a professor at Texas A&amp;M. 
Only the C++ community could complain bitterly about compile times while also simultaneously demanding that everything be header only. -_-
Complementing the two others comments in here, i think you should pick a simple project to learn and don't give up on it. There are good places to train and put in practice your knowledge like: https://www.codewars.com https://www.codingame.com https://www.urionlinejudge.com.br
Heh yeah I've been very busy trying to do as much as I can before July 1st, which is the start of its Boost formal review. Thanks for updating!
&gt; then just take the string_view parameter as normal and insert an assert statement checking that it's indeed null-terminated How do you imagine that's even going to work? The null terminator is not part of the string proper and therefore a null terminated string represented by a `std::string_view` wouldn't contain U+0000.
You're trying to make concrete assertions about things which are not concrete. Reading one past the end of an array, string, et cetera isn't guaranteed to be invalid and terminate the program due to a segfault. The fact that you're having to jump through all kinds of ridiculous hoops to make this idea work indicates that it isn't a good idea. You're trying to shoehorn `std::string_view` into a place it was never meant to be. If you want to accept a pointer to a null terminated string, accept `const char *`, there's no reason to shoehorn `std::string_view` in that case, there's already something that does that job acceptably.
Thank you, this can really help :) 
The codebase i'm working on has every type everywhere deduced by auto :(
You should provide also the .dll and the .so to use it right out of the box, no compiling no setup, only linking the library
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. (Also check out [this book list](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list))
I don't like the idea of certificates for programming. You aren't a C++ developer by just answering a couple of questions. It requires experience, lots of practice and dedication. I wouldn't accept someone on a junior position just because he has a certificate.
Shared future is copyable, no? How do you propose to get all exceptions for each of the when_any futures? Can you demux them? Future seems a combination of a deferred value *and* an expected. The strangeness of continuations consuming futures could be fixed by passing them autu-throwing expecteds or the like. 
LOL, no: it's USB 3.1 Gen. 2 Type C. 
How so, exactlyâ¦? 
Yes, there is ~~probably~~ a technical term for things like `operator int()`, and I should probably know it and use it.
There's [documentation](https://www.jetbrains.com/help/clion/postfix-completion.html) for it..
&gt; It's trivial to drop a new library into a project. Not always. Some libraries are annoying, especially if you need a wide range of platforms and versions. But I still agree with your point. I'd rather deal with the brain damage of a library that depends on ffmpeg when building on Windows, than effectively have to also deal with compiling it from scratch every single build, no matter what.
The problem is that those projects don't have modern build tools, they have quite often custom configure and makefiles. Recompiling those properly for an exotic platform is never trivial. Even for Windows, the instructions start with "Install cygwin...". I think it would be better to have other SSL implementations based on system crypto libraries from Windows or Apple when possible instead! I'm not sure if everything is available in those to do what's required, but it would certainly solve a lot of issues for some people on a few major platforms.
No problem. If you need help PM me. I'm just a hobbyist programmer but I have a pretty intermediate grasp of C++. 
Ah, [the law of leaky abstractions](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/)â¦
Oh, the horrorsâ¦; what if you decide to make it so that that function is no longer `noexcept`? (I presume nasal demons would likely pursue you in your nightmares for a bit after trying to debug _that_.) 
std::function, rtti and base classes. Man. That'd be fun. /s
I don't think you need cygwin to compile OpenSSL on windows, I've always used Perl and maybe nasm. Your point stands, header only is a trade-off I'm very familiar with other SSL libraries e.g. schannel and I had the worst time trying to make an asio SSL context compatible object (most of my trouble was with the stream service and the declarations of handlers, boostified or asioified) but wrote something similar async without asio. I'm certain Windows and OSX are full featured for what the SSL context exposes
[Here](https://github.com/jarro2783/cxxopts/issues/34#issuecomment-301265745) are instructions on how to setup your environment to display any Unicode data in Windows console. Alas, afaik, you can't do the same for input -- default windows console is too old and broken.
Great work, thanks! Since the discussion came up in this thread: many people think of "header-only" as a bug, rather than a feature. Would it make a huge difference for Beast?
Well most of Beast is templated on concepts so I don't see any other way
&gt; Visual Studio actually has support for Modules but the tooling/IDE itself does not really support it. Visual Studio is the IDE. MSVC (Microsoft Visual C/C++ compiler) is the compiler. VS doesn't support modules yet, MSVC does. They ship separately since VS15.
It's not just libraries, it's also all your internal code. And when searching for possible candidate functions that are being called (a common thing to do when debugging), the search space is much, much bigger for free functions than for member functions - and this 'feature' would take away your ability to even know which (free or member) is being called. std::invoke already provides a solution for library authors. Please have mercy on application authors, and don't give us the additional headache of not even knowing where a called function resides... 
Sounds like something a good Go To Definition would solve.
I am not a fan of `.` function chaining and I think its use should be minimized, not encouraged. I don't accept it as an argument for UFCS. auto desidred_data = data .filter([](auto const&amp; item){ return item.foo &gt; 42; }) .sort() .unique() .map([](auto const&amp; item){ return item.toUpper(); }); I would argue that that example is almost completely obfuscated due to chaining. * Is `data` modified by that sequence of functions? * Is `data.filter().sort();` equivalent to `data.filter(); data.sort();` ? * Does `filter` return a reference to `data`, or some intermediate value? * If `filter` creates an intermediary, when is it released? after `sort`? after `map`? * Is `sort` performed in-place? Is `unique` performed in-place? * How many different permutated copies of `data` are in flight during that sequence? * If copies are made, how much memory is allocated and where does it come from? * How are errors handled? Is it noexcept safe? * Maybe there is some lazy evaluation happening at the end? Compare that with a similar example not using chaining: https://ideone.com/3Ozg4w auto first = std::begin(data); auto last = std::end(data); last = std::remove_if(first, last, [](const auto&amp; i) { return i &lt;= 42; }); std::sort(first, last); last = std::unique(first, last); std::transform(first, last, first, [](const auto&amp; i) { return i * 100; }); data.erase(last, std::end(data)); // cleanup, invalidates iterators It has the general "noise" that comes with using std::algo and iterators, but otherwise I feel this code is much easier to reason about. (`data` is modified, no memory is allocated, it is noexcept safe if `data` is a std container). Chaining also hijacks your return value, making it difficult to use the return value for other purposes, like error reporting. And to top it off, chaining produces worse machine code: https://godbolt.org/g/cvWaqb struct object_t { int x; auto&amp; set_x_chain (int n) { x = n; return *this; } void set_x_nochain (int n) { x = n; } }; asm: object_t::set_x_chain(int): mov rax, rdi mov DWORD PTR [rdi], esi ret object_t::set_x_nochain(int): mov DWORD PTR [rdi], esi ret Just say NO to `.` chaining! 
Sounds like a solid objection to a feature with mild benefit.
I completely disagree with you, and I think that your `godbolt.org` example is **highly unfair as you explicitly disable inlining**. You should show the real code when trying to make an argument: #define NOINLINE __attribute__((noinline)) struct object_t { int x; NOINLINE auto&amp; set_x_chain (int n) { x = n; return *this; } NOINLINE void set_x_nochain (int n) { x = n; } };// struct object_t Many optimizations and "cost-free abstractions" **rely** on inlining nowadays. If you explicitly prevent it, then you can make anything look worse. With that out of the way, let me explain why I disagree with you. --- &gt; I would argue that that example is almost completely obfuscated due to chaining. No, the example is **very clear in its intent**. Many other languages and libraries like Range.V3 use chaining and are widely considered as better alternatives than imperative code. You can read this code top to bottom and it's completely obvious: The container is going to be **filter**ed by every item with `.foo &gt; 42`, then it's going to be sorted, then the duplicates are going to be removed, then every item is going to be transformed with `.toUpper`. It literally cannot be more straightforward and boilerplate-free than this. When you are looking at application logic and algorithms, boilerplate is what makes you miss subtle bugs and logic errors. --- &gt; * Is data modified by that sequence of functions? I agree that this should be clearer. Libraries such as Range.V3 clearly differentiate between views and actions that mutate the range. Regardless, this is **not** a problem with chaining, it's a problem with function naming. You would have the same problem with a non-chaining syntax. --- &gt; * Is data.filter().sort(); equivalent to data.filter(); data.sort(); ? &gt; &gt; * Does filter return a reference to data, or some intermediate value? &gt; &gt; * If filter creates an intermediary, when is it released? after sort? after map? &gt; &gt; * Is sort performed in-place? Is unique performed in-place? &gt; &gt; * How many different permutated copies of data are in flight during that sequence? &gt; &gt; * If copies are made, how much memory is allocated and where does it come from? &gt; &gt; * Maybe there is some lazy evaluation happening at the end? It doesn't matter and you shouldn't know. This gives implementations more freedom for optimizations. Maybe it's some intermediate view type that is lazy, maybe it is eager. What matters is that you want "to filter and then sort", not how you do it. Again, this is not a problem related to chaining - you can ask yourself these questions for any kind of function call. You need to trust the implementation and rely on the performance guarantees it makes. If profiling shows that the implementation is too slow, then you can start considering to write your own highly-optimized algorithm. --- &gt; * How are errors handled? Is it noexcept safe? This is part of the documentation. I see no reason why exceptions couldn't be thrown or why monadic return types a-la Rust couldn't be used. 
Atomics are permitted to be modified across threads; what are you getting at?
Did you intend to write const or static?
Did you intend to write const or static?
Did you intend to write const or static?
Did you intend to write const or static?
There is a [CMake port](http://www.valvers.com/open-software/projects/openssl-cmake/) of OpenSSL, which makes it very easy to use in a CMake environment. The caveat would be that only the C code is compiled. But one would actually have to measure to see if the hand written assembly files produce faster code than the modern C compilers.
So... What does this mean if you have a more complex (not single-step) parallel algorithm ? At some point you have to lock / unlock and perform "unsafe" operations in between.
You're right, it's an implementation detail... And we still have two pointers. Still, cache locality is greatly improved and on the same level as Rust's implementation.
Can you possibly ask a more vague question..? I linked you to documentation, do you have a _specific_ query?
Of course, and it's not that hard to write your own "slim" shared pointer if you need to :) 
The C++ implementation also allows for the `shared_ptr` aliasing constructor, which is incredibly useful.
I had my answer by going to the general docs : &gt; However Rust does not prevent general race conditions.
Who said it would, or could, in the first place? [Data races != race conditions](https://blog.regehr.org/archives/490), and the only claims made that I saw regard the former. ;-]
If we wait for real-world experience it would already be in the standard for a few years, and beginning to be supported by compilers. That's a bit late for objections, don't you think? Your use of the phrase "deliberately" suggests it wasn't an accident. I'm much more concerned for when someone adds a new function accidentally, and changes system behaviour without even realizing it. Your example, of container erasing, suggests you have a library mindset - one in which only a handful of concept exists, and they all have clear and concise names. That's great, really, but it's not realistic for a large C++ project. The problem that std::invoke is not constexpr can be solved by adding the word 'constexpr' in the correct location in the library. And as for code readability, that's exactly the problem I'm having here: code readability suffers massively if you cannot even determine if something is a member function or a free function, nor how many arguments it actually has by simply counting them. 
&gt; If we wait for real-world experience it would already be in the standard for a few years, and beginning to be supported by compilers. That's a bit late for objections, don't you think? That's what TSs are for. You could make this argument for any new major features (Concepts, Modules, ...). Make it a TS, try it out in practice, report eventual issues and then move forward/adjust the proposal. --- &gt; I'm much more concerned for when someone adds a new function accidentally, and changes system behaviour without even realizing it. The point I'm trying to make is that this is highly unlikely to happen, and if it does it can bring attention to potentially existing unclear interfaces/broken logic. --- &gt; The problem that std::invoke is not constexpr can be solved by adding the word 'constexpr' in the correct location in the library. It's not that simple. See ["Why is `std::invoke` not `constexpr`?"](https://stackoverflow.com/questions/40222989/why-is-stdinvoke-not-constexpr). --- &gt; code readability suffers massively if you cannot even determine if something is a member function or a free function I'm claiming that this is the wrong mindset. It shouldn't matter if you're calling a member function or a free function - what matters is intent. Calling `erase(f, x)` or `f.erase(x)` communicates the same intent: "erasing `x` from `f`". Syntax is irrelevant.
&gt; std::invoke already provides a solution for library authors. I don't see how `std::invoke` is related to UFCS. Also, `std::invoke` is awful - it's just annotation for "I am calling a dependent type here," it doesn't actually impart meaning. I would like to see it gone. 
I donât see the question at all in that post. Only some concerns about the possibility to prevent data races (which I tried to describe how are prevented) and how a shared mutable state can be achieved â which I also believe I described. The [linked documentation of the `atomic` module](https://doc.rust-lang.org/std/sync/atomic/#examples) even gives example of a program synchronized in a very similar way to what the post described (waiting in a while loop until shared atomic value changes).
It's as thread-safe as you make it; if you make your `intrusive_ptr_add_ref` and `intrusive_ptr_release` thread-safe then it's thread-safe.
I had to disable inlining to get any code to show up at all. In "real code" not everything will be inlined, nor should it be. Range.V3 and that style of functional composition is actually the best case use scenario for chaining, but at the same time it is a great example of how composition can be done, today, without UFCS and arguably with more expressive syntax than what you'd get with `.` function chaining. So if anything I would say that it makes a case that UFCS is not needed. We don't need code breaking changes made to the language just to enable the use of `.` instead of `|`.
&gt; The linked documentation of the atomic module even gives example of a program synchronized in a very similar way to what the post described (waiting in a while loop until shared atomic value changes). Well, that solution is quite terrible. For instance, if I know that on my architecture, `int` access is atomic I still get to type all the `atomic` fluff it seems.
&gt; In "real code" not everything will be inlined, nor should it be. Getters/setters/chaining methods will definitely be inlined even with low optimization levels. Regardless, my point was that your example was unrealistic and crafted to support your argument. I would have been fine with it if you clearly mentioned `NOINLINE` in your post. --- &gt; We don't need code breaking changes made to the language just to enable the use of `.` instead of `|`. That's only one benefit of UFCS (and, personally, I think it's a great one). There are many reasons why I feel like we shouldn't abuse operator overloading to implement chaining, but that's for another post. UFCS not only allows chaining, but makes it more easy to write generic code, encourages the use of free functions (as they increase encapsulation), makes it easier to extend existing classes without having user code unreadable due to a mix of "classic function call syntax" and operator overloading, and more. I'm convinced that some form of UFCS is going to improve C++ considerably and make it a nicer &amp; more powerful language. So far, none of the arguments have convinced me otherwise. I know about potential issues with the current proposals, but I think that in practice they're unlikely to happen and I'm completely open to non-breaking proposals such as the one with the "leading `.` dot" syntax. 
Even if it is atomic "in hardware" you still need software atomic behaviour from the compiler so that it is prohibited from reordering loads and stores. std::atomic also enforces alignment on architectures where it would make the access non-atomic.
Why can't we just declare additional member functions outside of class headers? Say we are using string, but it lacks string::split(string delimiter) -&gt; vector&lt;string&gt;. I can't modify string because it's not my library, and I don't want to make a subclass of it. I could make split(const string&amp; input, string delimiter) -&gt; vector&lt;string&gt; and write C++ code like I'm programming in LISP. But why can't I instead just write string::split(string delimiter) -&gt; vector&lt;string&gt;, and have it work, even though it's not inside of the string class header definition? If the library author comes along and adds the missing split(string) function later, then I'll get a compilation error due to the function being declared twice. Other code that uses the string class can keep using it as the original object, but since my new string::split function won't be in their object, it'll have no effect on them. They could make their own split function, or not use it at all. I understand why you need to declare virtual functions (vtable entries), and even private functions. But there is no technical reason why public functions that don't access any protected or private state shouldn't be allowed to be declared without having been defined in the class definition.
Except perhaps for tooling availability. Rust is still limited by available llvm backends, and C++ also is not necessarily available for some lesser known embedded platforms, while plain old C seems to be virtually everywhere.
The Visual C++ team is working on the IDE support - e.g. getting IntelliSense support, etc. I don't know of the ETA but it is coming.
General race conditions are a logic error. Unless you're using a language which allows you to formally verify the logic of your program you'll never get a guarantee that strong.
It's worth pointing out that there were 5 different alternatives in the [UFCS proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4474.pdf): * `x.f(y)` can find `f(x,y)` if the former doesn't exist (Herb's proposal) * `f(x,y)` can find `x.f(y)` if the former doesn't exist (nobody's proposal) * Both `x.f(y)` can find `f(x,y)` and `f(x,y)` can find `x.f(y)`, each preferring the syntax they're written in. * Have both mean the same thing, name lookup looks for both member and non-member functions and use overload resolution to pick the best match. * Both `x.f(y)` can find `f(x,y)` and `f(x,y)` can find `x.f(y)`, but both prefer `x.f(y)` (Bjarne's proposal) I find that different people discussing UFCS are arguing for or against different alternatives and I'm not actually sure which one people want when they say they want UFCS. 
I didn't quite catch how modules are going to work in practice. According to [clang documentation](https://clang.llvm.org/docs/Modules.html): &gt; **Binary distribution of modules**: Headers (particularly C++ headers) expose the full complexity of the language. Maintaining a stable binary module format across architectures, compiler versions, and compiler vendors is technically infeasible. &gt; So library author will be still required to distribute header files because only compiler vendors are able to deploy binary modules, is that correct?
&gt; You can move out of a non-mut variable. The value isn't considered mutated, it's considered gone. **And the compiler will complain if you try to use it after the move.** I've heard this before and I don't quite understand how it works out -- it seems to depend on the *gone* variable to be named which isn't always the case (or so it seems to me). x = array[index]; Is `array[index]` *gone*? How does the compiler (or anything else) know?
&gt; Is `array[index]` _gone_? No, but only because you unluckily chose _that_ example: you cannot move out of arrays, so that code will only compile if the type `array` contains is `Copy`. &gt; How does the compiler (or anything else) know? This is the nature of [affine type systems](https://en.wikipedia.org/wiki/Substructural_type_system#Affine_type_systems).
You can't actually do this, as the compiler will say "cannot move out of indexed content", that is, `[]` returns a reference to the spot at `index`, not the value itself. And you cannot move a `T` out of `&amp;T`.
So how do you move values around within arrays? E.g. insert/remove/swap?
&gt; There's no std::move in Rust. Moves are the default for non-Copy types. The behavior of a move or copy is always a shallow bit-wise copy; there is no way to override it. This can greatly improve performance. For example, when a Rust Vec changes address due to resizing, it will use a highly optimized memcpy. In comparison, C++'s std::vector has to call the move constructor on every element, or the copy constructor if there's no noexcept move constructor. This is a big one. Move should be default and copy should be opt-it, move-by-bitcopy should be default, you should be able to move out of const objects (destructive move). This is one area where C++ is severely lacking. Some of them may be fixed (e.g. I think Facebook's folly has a vector which can resize by bitcopy, you have to opt-in though), but some like move-by-default cannot. Also, C++ should add destructive moves.
There are methods with those names that do those operation. The first two are O(length) because they need to fill in the gaps.
&gt; insert https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.insert &gt; remove https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.remove &gt; swap? https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.swap I'm pointing to `Vec&lt;T&gt;` here because arrays have a fixed type in Rust, so insert/remove doesn't make any sense. You could use https://doc.rust-lang.org/stable/std/mem/fn.swap.html to swap between two elements in an array though.
Serious question, what is your use case for the alias capability of shared_ptr? 
Rust protects against the UB part of data races (write/read races without some synchronization). It still allows data races on higher conceptual levels. If you have an atomic Boolean, then you have the required synchronization.
I think that Bjarne's proposal makes the most sense for backwards compatibility and "specialized" functions (i.e. a `list::erase(x)` might be more efficient than `::erase(list&amp;, x)` since the member function has access to the `private` members). --- I don't think that the members and non-members should be overloaded on "the same level", has member functions have access to `private` members while free functions don't. They should be a "better match". --- The proposal with &gt; each preferring the syntax they're written in seems to go against the "uniformity" principle of UFCS. I'm convinced that function call syntax and member call syntax should be equivalent. If you need to choose a free function over a member function with the same name and signature, there is some underlying problem in your code base that UFCS just exposed. --- Herb and mr.Nobody's proposals seem unnecessarily limited to me. 
&gt; It still allows data races on higher conceptual levels. By "higher conceptual levels" are you pointing to race conditions, rather than data races? I'm not quite sure what you're saying here :)
Conversion function. 
Did you re-post this comment like 10 times? Everything I've written is as I intended.
Interesting, I'll have a deeper look at it soon since I wanted to do something similar to my boost-cmake project for OpenSSL (and maybe FFmpeg). But it seems to be unmaintained and using old CMake constructs, so it will require work to have something actually usable.
How does it compare to Crypto++?
Really bad name. It's unsearchable - it's a common material. I think it's also a trademarked by Apple for their propietary graphics API. Better rename before it's too late.
Firstly, that document describes Clang's "header modules", not TS modules. Regarding distribution, yes, it looks like library vendors, in general, will need to ship module interface sources and module consumers will need to compile them "for themselves" (with compile options that they use, etc). Though there could be compiler-specific relaxations of this.
Fascinating how it's the first time I hear about this Apple API. In any case I agree the name is far from great, do you have any suggestions?
yeah it is a 2 player game 
Not so much a fan of implicit anything here; I'd rather have context-sensitive `move` and `copy` keywords or something similar that would be required to disambiguate the "personality" of any assignment/initialization from a glvalue.
It's the same, except that this will potentially be used everywhere whereas operator overloading is used cautiously
Yes, you can download the slides here: www.effective-cmake.com/cmake-talk.pdf
We tried this with Rust, the usability was very bad. It's pretty much the definition of boilerplate, since in the end, the only difference between move and `Copy` in Rust is that you can't use something after a move, and the compiler will yell at you in that case. That said Rust is not C++ and so it might fit better there.
lol
The only difference between the two is whether the "from" variable is still accessible afterwards, and if it isn't then the compiler yells at you anyway if you don't comply. I fail to see why this would have any significance for the end product. FWIW, Rust has very little implicit behaviour compared to C++ (the few others being deref coercions and lifetime inference), if you don't count obvious stuff like integer overflow.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
There are three scenarios a CMake build script should support for building with dependencies: * System packages: works out of the box * Prebuilt libraries: need to be put into `CMAKE_PREFIX_PATH` * Subprojects: need to turn `find_package(Foo)` into a no-op And the prebuilt libraries scenario is important if you want to support a package manager as well, because a package manager will install the (pre)built libraries and make them available through `CMAKE_PREFIX_PATH` so they will be found with cmake's `find_*` commands(if your favorite package manager doesn't do this, you should report a bug). Subprojects builds are good for internal or proprietary builds, but not for open-source distribution, as no one wants to rebuild `zlib` for every project. Also, `ExternalProject_Add` is not a good recommendation for handling dependencies(unless you are using [hunter](https://github.com/ruslo/hunter)), because the toolchain settings are not transitive. Its better to provide a cmake script to install dependencies for users not using a package manager, which [cmake-get](https://github.com/pfultz2/cmake-get) can help write. I just think this approach in this presentation overcomplicates the cmake build scripts.
The singe-header distribution is nice, but installing the source tarballs no longer work if I want to install the multi-header version.
yeah, sorry, is there any way to fix it from my side? url: http://mainisusuallyafunction.blogspot.co.nz/2017/06/a-rust-view-on-effective-modern-c.html
It's the same, and more importantly, the objection to it is the same. But with operator overloading, at least there is the guideline to only overload operators in a way that doesn't violate their original mathematical meaning, whereas there is no way to even provide a guideline for function names. SuperV1234 seems to believe that names can be formulated in a mathematical sense, without any possibility of ambiguity. It seems to me that such a notion can only ever apply in very small systems: it would work in something like a container library, with relatively few concepts and functions, but it would be hell in something like a large application. 
Tarnish!
I'm going to approve this post because there's a bunch of interesting discussion here, but I'm grumpy about it - I think this article was off-topic.
&gt; Activating a symbol within Sumblime Text via plugin. Typo. &gt; A crossplattform source explorer Typo in the page footer (!!).
If you mean `make install` you're right, it will install the standalone header, but you can always manually copy `include/` from the source tarball somewhere else if you prefer the multi-header version. That said, I can't think of a reason why one would prefer not to use the standalone header though.
My criterion is "does this help me program C++ more effectively" and I didn't see anything that would help with that.
Well, yeah. But the only time you care about having a uniform lens is when the callable is dependent - because you need a uniform lens there. If I know `f` is a function, I'm always writing `f(x)` and never `std::invoke(f,x)`. So it kind of has everything to do with dependent types. That's roughly the motivation for the 2nd, and way better, draft of my proposal to just make pointers to members directly invokable. Will be in the next mailing.
Comments like these keep me here
An example of where that's insufficient would be a `vector&lt;unique_ptr&lt;T&gt;&gt;`. A `vector` reallocation can be correctly implemented for most implementations of `unique_ptr` as `memcpy` and deallocating the old storage, but `unique_ptr` is neither trivially moveable nor trivially destructible so the library can't know about that optimization. One could add an `is_relocatable` trait, specialize it for types like smart pointer templates, and use that in custom containers, but that obviously imposes a large burden on C++ developers compared to just supporting such semantics in the language or standard library.
&gt; But how is this any different to a situation in which library version N+1 adds a new overload to an existing function, which happens to be a better match? At least for member functions, a library *knows* the entire set of member functions called 'foo'. If a library decides to add a new overload of 'foo' it basically knows what existing calls to x.foo() look like. (if foo takes an int maybe you are passing a double or a class that converts to int, etc). With UFCS, if a Library decides to add a new overload of 'x.foo()' or even a new function completely, like 'x.bar()', the library author has no idea what existing calls to x.foo() look like. And doesn't realize you are already calling x.bar() even though it doesn't "exist". So there is a real non-zero chance that my new lib breaks your code next time you compile. And that may be a silent compiles-but-does-the-wrong-thing breakage. You can choose to weigh that concern low or high, but it is a real concern. 
[removed]
To your last line there, how many more memory corruption exploits have to come out before we start taking that seriously as an industry? C++ is a great but profoundly unsafe language. It is very possible to mitigate risks but to suggest you are capable of avoiding them with every line of code you write over a 30 year career flawlessly seems to be more arrogant than RIIR nut. Also, it doesn't take awful C++ to accidentally allow a critical security bug to slip on through.
No - translation is never a good solution. It wasn't back then when C++ translated to C, it isn't now. With Rust type and memory model it will also result in bizarre C code which you should able to read in the first place. It will also distance you from the targeted hardware, which may not be a good idea in embedded world, because of the hardware details. There are workarounds but I'm not convinced that after all this effort it's wouldn't be cheaper to write and test in C in the first place. If it's critical - you are going to test it anyway.
Threads like this do attract attention, don't they? I don't like the term "better language" tho, which is used in that article, and many others. There are no "better languages". They are simply tools for different tasks in different domains. 
I'm not trying to say that rust cures all security errors. That being said though the stream of memory corruption bugs still hasn't stopped. I'm not familiar with the latest bugs since it's not something I really follow but my MacBook "recently" required updates to fix those exact kinds of bugs. The biggest way to secure systems is to eliminate potential attack vectors categorically. Rust does that with race conditions and memory corruption, but obviously doesn't fix everything. It's also worth noting that C++'s battle against Java and Python is easily won in most cases by mentioning superior performance. This is not an argument that can be levied against rust since they perform virtually identically. Considering just how prevalent C++ is I'm not saying Rust will or even should replace it, but there are lessons within the language that are worth learning. I'm not sure how easily something like it can be added to C++ but it's worth looking into. If, as you said, C++ is tomorrow's COBOL, I would imagine that either rust or a language like it will be tomorrow's C++.
I think that's a good place to end this on. What was it though about my username that you were referring to? I honestly picked it almost at random a long time ago as a DJ name (without the numbers) and I'm unaware of what else it refers to.
To be honest, Rustaceans don't like that term either. But some people still use it, and it usually gets noticed. :(
... then C++17 arrives
Yeah, the compiler can't do copy elision with `make_unique` / `make_shared`, but that's not really the takeaway here. `makeS` is returning a stack-allocated `S` but you need it to be heap-allocated ("allocated on the free store" in C++ jargon). The real issue here is that the factory function `makeS` doesn't fit the use case. It should be returning a `unique_ptr&lt;S&gt;`.
Except objects which has pointers to self, everything else can be moved by bitcopy. And pointers to self are quite rare. `is_trivially_copyable` doesn't cover most of the cases, we need a `is_relocatable trait`, as /u/SeanMiddleditch said. However, I don't think compilers can infer which types don't have self-reference, so we probably have to manually mark types as relocatable. Also, IIRC, D does copying by bitcopy and then updating fields (like say a refcount). So copying the whole object is quite fast, as long as only a few fields need to be modified post copy. I find it an interesting approach.
You. I like you. 
&gt; Rust uses fat pointers too, most notably, the v-ptr of an object is not stored in the type but carried along the pointer to its data. This has numerous advantages, What are the advantages?
Your post has been automatically removed because it appears to contain profanity or slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6isgcp/a_rust_view_on_effective_modern_c/djaapj9/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thank you! Will get fixed.
&gt; I have nothing but hatred for you. I hope most of humanity dies and you with it. And thanks for making it perfectly clear that reading your horse shit, much less actively engaging it, is a waste of **everyone's** time.
Yeah, it's a big pain point. Rust is still a really young language, and there's a lot to be done. There's the Rust Lib Blitz, which is going over all those small crates and stabilizing them so that we can build bigger crates on top of them. That will hopefully make a nice base of libraries that we can choose from. And yeah, I agree with you. Rust's memory safety is overhyped. You'd think everyone would get over that already, but noooo. Truth is, memory safety is a big thing yes, but there is a lot more that the language can offer. It's just that it's taking a long time, and people get impatient. I mean, we already have a so-so ecosystem, especially with Rocket, Serde, Hyper, Tokio, and all the big names. They're quite good already, but what people get impatient on is that they can be a lot better, and they're in the process of getting that much better. Meanwhile, everyone programs with the mindset "Oh, I wish &lt;insert crate here&gt; had this feature already so I could do this thing more easily". And in the end all those crates are waiting are for some language features. So it's a really long train of dependencies, and there's only so many people working on it, but it will eventually bear fruit. It has a lot of potential that can be unleashed, and that's what people should be hyping for. And at least, in my opinion, one good thing about the "hype" is that it allows meta-feedback about the languages. Why is Rust getting hyped that much? What does it have that C++ lacks? Or what does it lack that C++ has? Can we extract some of the positive things and bring it to C++? How? Why not? - It would be unwise to not take advantage of this opportunity of improvement. Rust has learned a lot from C++, and C++ can learn a lot from Rust too. In the end, the goal of everyone here is to make something that works. So if the Rust people could stop hyping about it, and the C++ people could learn new things from this situation, everyone would come out winning. Focus on the important things: stability, maturity, and room for expansion. They're conflicting goals, but we must solve them no matter what, so everyone better get to it. &lt;This comment is between angle braces because it's a meta comment, like metaprogramming. Get it? Ha! :| - Anyways, I feel like I talked a lot more than what you originally brought up, but your comment was the right spark for me to dump all of that. Who knows, someone might find what I said above interesting Â¯\_(ã)_/Â¯ &gt;
Here's a gist: https://gist.github.com/anonymous/634eb50e015e0bdfd616b8f0e090786f
Alloy sounds like an excellent name for an awesome library indeed https://github.com/brunocodutra/alloy
Sigh... yes, it is a _new-expression_ 
Sometimes you don't want to be concerned with client's preferred memory handling approach. You just want to construct an object in memory provided by client and let him decide if he wants unique_ptr, shared_ptr or anything else. Yes, "semantically" in C++ return value gets copied into outside scope. But we all know it isn't the case on practice -- real behavior is "to construct a value in memory provided by caller". And all these complicated copy elision rules are just a way to get it into standard without breaking original statement.
Maybe the standard library should provide a `std::callback` that does this by default ? 
&gt; There are no "better languages". That's very strange logic. C++17 isn't better than C++03, right? They are just tools for different tasks?
Advantages: 1. **Storage**. When you have an instance `Concrete`, there's no useless v-ptr stored, so you shave off 8 bytes per such instance. This means that unlike C++, Rust truly applies the "What you don't use, you don't pay for" principle. 2. **Less Indirection**. In C++ calling a virtual function requires 2 indirections; if you have a `T* t` you need (1) to load `t-&gt;vptr` and (2) to load `t-&gt;vptr-&gt;fun`. This is annoying because of the data dependency. In Rust, `vptr` is local, so you have a single indirection and no data dependency. 3. **More Easily Devirtualized**. In C++, an opaque `t-&gt;call()` may potentially change the value of `t-&gt;vptr`, so an optimizer has to assume that the virtual pointer may have changed and cannot (1) avoid reloading the virtual pointer/virtual method or (2) completely devirtualize the call. In Rust, the desugared call looks like `(*t.vptr-&gt;fun)(t.data, args)` and thus with `t.vptr` being a local field it's trivially evident to the optimizer that it's not affected by virtual call unlocking the above optimizations. Disadvantages (ain't no silver bullet): 1. **Storage**. When you store references/pointers to trait objects, you use 16 bytes where C++ would only use 8. There have been discussions, and experiments, in bringing "thin" pointers to Rust for the cases where this doubling of the storage cost is an issue. I believe that a couple intrinsics could easily make it available as libraries, and it [doesn't require that much](https://github.com/matthieu-m/rust-poly), however there are more important issues to tackle at the moment.
There are two issues: The first and foremost is that even if `t-&gt;foo()` cannot change the dynamic type of the object (and thus its virtual pointer), to the optimizer it looks like `foo(t)` and thus you need special annotations (if available) added by the front-end to tell the optimizer that this `foo` function it knows nothing about cannot change the first 8 bytes of `*t`. If the optimizer doesn't have such an attribute, or from some reason the front-end doesn't set it, then the optimizer cannot assume that those bytes won't change. The second issue is that actually, it seems that the standard does allow a virtual call to change the dynamic type of an object in some sets of circumstances (I'm still not clear on which, to be honest). I couldn't find the last discussion I read about this, but the arguments seemed legitimate, unfortunately.
What's the difference to Hana?
Hey, wow, thanks for the resources. I guess you're the right person to ask: where can I learn template meta programming?
The fact Metal is very strict, as one soon realises by reading it's concept definitions [1], actually helps unexperienced metaprogrammers getting started, because it enforces the use of explicit patterns that make it easier to reason about what's actually going on. I'd therefore highly recommend you have a look at the examples [2]. I'd also recommend you take this advice with a grain of salt, because as the author myself, this is my biased opinion off course. [1] http://brunocodutra.github.io/metal/#definitions [2] http://brunocodutra.github.io/metal/#examples
Missed a chance to rewrite in Rust...
quoting from the article &gt; Now that our text storage has been ported to C++ (which also landed in 1.19), we could even move the rendering code to C++ (along with the DisplayLayerâs spatial index) to minimize overhead even further. this is the only mention of C++ in the entire article, so... &gt; How much of that was due to them just understanding the problem better when they rewrote it? It sounds like most of it, and this had very little to do with C++.
&gt; 2 questions - Is this legal? // Case A: Base base; base.foo(); // the lifetime of base ends here base.bar(); // undefined behavior: &amp;base is a reference to a dead object // Case B: Base* base_ptr = new Base(); // Base* to Base base_ptr.foo(); // Base* to Derived base_ptr.bar(); // access Derived through Base* &gt; And don't you have to do this -&gt; ~Base() before the placement new? IIUC, if you don't do it, the destructor doesn't run. This might result in a leak or lead to undefined behavior if, for example, a destructor not running violates some preconditions of some other piece of code, but AFAIK this is not undefined behavior per se. If you really want to do this "cleanly", then yes, you need to: - use an explicit destructor call to call the appropriate destructor (make sure they are virtual, etc.) - make sure that no matter how the scope is exited `*this` is always a live object. For example, if placement new throws, `*this` is not a live object because you just called the explicit destructor. If that exception is not caught, the stack will be unwound, and the destructor will be called, again, on an already destroyed object, which is undefined behavior. I'm sure there are more caveats (e.g. can alignment introduce problems here?), but they don't really matter much because _you don't want to do this, ever_. 
Sometimes I find it so odd when people use Electron because "it allows us to develop faster", but then they spend crazy amounts of time trying to make it *run* faster... (This isn't necessarily pertaining to Atom; it's just a general observation.)
Thanks for the explanation. &gt; Storage. I am not too familiar with Rust, so I didn't get this part. Why doesn't concrete classes need vptr? Is it because concrete classes cannot be further subclassed ? (so they are similar to final). 
Did you read the article? It's about speedups in rendering, and the only mention of C++ is at the end: &gt; Now that our text storage has been ported to C++ (which also landed in 1.19), we could even move the rendering code to C++ . The rendering code is still in javascript and coffeescript.
And the work /u/berium is doing is fantastic. Paging /u/SEGFALT_WA to maybe try this out early in VS?
Thanks, /u/tambry. Pardon a small clarification. MSVC does ship with Visual Studio as part of the Visual C++ product. In fact, it only ships with Visual Studio (though we have some alternative distribution methods, MSVC is licensed only as a part of Visual C++.) What you're getting at is that MSVC versions separately from Visual Studio ever since Dev15/VS 2017. If you install VS 2017 you'll see that you can install the v140 Platform Toolset that originally shipped with VS 2015, and/or the v141 that originally shipped with VS 2017. And even though v141 has many improvements over v140, it's still in the same family as the v140 toolset. I am sorry for the confusion. It really is Microsoft's fault. But versioning the tools and IDE separately is helping us to bring you a better compiler toolset faster so please forgive us : )
&gt; Is this legal? Thankfully not. See [basic.life]/8, in particular the 4th bullet.
"I rewrote my infinite loop in C++ and it's just as slow!"
Also Haskell, Ruby and lots of other tools and environments. 
That example you posted is proscribed in so-called "*modern C++*," use `std::make_unique` instead.
Both ctor and 'factory' function do the same thing, but latter is more flexible -- it can do a lot of things before constructing object (while ctor has to start initializing member variables immediately). Sometimes ppl prefer to expose factory function and hide ctor.
There are other memory handling tools besides shared_ptr and unique_ptr.
Thank you very much for the clarifications. &gt; MSVC does ship with Visual Studio as part of the Visual C++ product. In fact, it only ships with Visual Studio (though we have some alternative distribution methods, MSVC is licensed only as a part of Visual C++.) What I meant to say was, that you can install Visual Studio, but don't have to install the compiler itself. Looking back, my wording is definitely quite bad and doesn't actually express what I meant to say. Apologies. &gt; I am sorry for the confusion. It really is Microsoft's fault. But versioning the tools and IDE separately is helping us to bring you a better compiler toolset faster so please forgive us : ) It'd be hard to complain about faster compiler updates! :) Am I right in understanding, that both the compiler, the linker and the toolset versions will be bumped to version 20 in the next release compiler release?
Normally I hate these listicles, but every recommendation in this one is solid. The first recommendation remains the one true way of learning a language though. It's amazing how many people think they can just read up on a language forever without finding a project they care enough about in order to start applying their learning. Information that's learned but never applied doesn't stay learned for long. Dabbling in little one-off exercises for school assignments doesn't make it stick either.
I think I dated you once.
Not the only ones even... Didn't Facebook keep reinventing the wheel?
Rust doesn't have classes, only structs, and they cannot be subclassed. If you have a "trait object" in Rust, which is the way to get dynamic dispatch, then the object itself, that is, `&amp;Trait`, is a double pointer, not a single one. `(pointer to data, pointer to vtable)` This is sort of the opposite of what C++ does, where the pointer would be just a pointer and the vtable would be stored with the data.
&gt; Rust cares about these two cases by not allowing storing pointers to self Strictly speaking, you _can_ have references to self, but it results in an immovable struct and therefore isn't useful very often.
&gt; I'm really hoping Rust will get more out of that "let's hype about that language" into "let's use it for some of our infrastructure and share our experience" I think this is happening, but I think that we aren't doing as good of a job at showing the external world this. It's something I'd like to change but am not exactly sure how.
I'm not saying the current situation is ideal--it's clearly not. At the same time, it's pretty clear that most of this does not require a new language, nor really even a whole lot of change to C++ as it exists right now. We've already improved the library by adding and using some type traits. Adding a slightly different type trait and rewriting the code to use it instead of whichever one it's using now is a long ways short of rocket science.
Indeed, Rust uses a trait system similar to Haskell typeclasses: - on the one hand you have `struct` and `enum` (similar to a final struct in C++), - on the other you have `trait`, which have virtual methods (not necessarily pure), And then each `struct` or `enum` can implement multiple `trait`. Which actually constrains the implementation of dynamic dispatch in Rust: since there is no telling how many traits a `struct` or `enum` implements, and any client library may add further trait implementations, it's impossible to have A v-table. Rust solves the issue by having one v-table per trait implementation and never storing the v-ptr inside the item itself.
I have a feeling it's the startup culture, they want to get features out the door ASAP to get investment, planning to "rewrite" when they go for v2, but that will never happen, and features and fixes just get bolted on to the shaky foundation until it becomes unmanageable, then they would hire some expert to create a new system to make the whole thing faster, and the cycle continues (e.g. Facebook and their PHP-Cpp transpiler thingie)
If I can be honest - stop running around programing and HN taking notes and explaining Rust design decisions, or the thought process behind it. It may be interesting occasionally, but after a short period of time it starts to look like you are apologize for the language. Most of the time I don't care about the complicated insides of language designing. I'm interested in result. The gains. The problems. The proposed solutions. In real software. Memory usage. CPU utilization. The overall performance. Don't try to please everyone - C++ already did that and here we are. You are not going to repeat the same path, and honestly you shouldn't even try. Focus. Show the strong sides. Acknowledge the weak (this is what I'm currently don't see at all - RIIR became a meme in my opinion not because of how widespread it was, no, but because of how different domains were where this were proposed) sides. Move on on actually building something and talking about it. The language is a tool. Nothing more. Edit: additions. 
I could not find the discussion about it, but at the very least gcc `-fsanitize=undefined` does not prevent dynamically changing the type of the object: https://www.reddit.com/r/cpp/comments/6isgcp/a_rust_view_on_effective_modern_c/djb31io/
Bumping the toolset to 20.00 is our plan for the next major version of the MSVC compiler toolset. We will almost certainly release 14.11 (if we haven't already) and maybe 14.12 or 14.20 which correspond to the 19.xx versions of cl.exe. But the next major version will fix that off-by-five error with everything at 20.00.
You're very misinformed about Haskell...
And GCC's UB sanitizer doesn't claim to catch all undefined behavior, does it?
But in which industry is it used, besides the *cool kids* at startups? I mean, why one should for Haskell instead of C++ in production?
&gt; that can be pain in the arse to write That's what s/he meant I believe.
Every generation has a subset of people who reinvent the wheel a bit slower than before and convince themselves they've discovered something incredible. When 80% of your workforce are fresh college graduates with no experience, this is what you get.
I don't think "time to market" was a major constraint for GitHub when working on Atom. They used Electron because that's what their developers understood.
They brag about their feats because they're proud of them and they don't know any better. The managers who let them run wild is who should be ashamed. From what I've seen on the interwebs, that Android Facebook application is quite a piece of engineering. Wrong, misguided, but ... quite a piece.
Thank you. &gt; Don't try to please everyone Ironically, I think maybe just my interests mean that I can't please you :) I am incredibly interested in language design, which is why I read /r/cpp every day. I'm not the person writing applications and posting results. Others are. Did you end up seeing stuff like http://blog.burntsushi.net/ripgrep/ ? IMO, this is exactly the kind of thing you are looking for. Is there some way that this could be shown off better, or is it strictly a volume thing? I expect to see more of this kind of thing in the future, but part of the issue here is that building big production systems takes time, and so while we're seeing a huge increase in production use, it's taken a while for that to happen, and then will take even longer for it to be in production for long enough to make these kinds of comparisons. Anyway, thanks for your candor.
This is awesome. We could continue down this road by never updating C++ and instead just have our IDEs enable us to type in whatever syntax we want, and autoconvert to C++. We could each have our own favourite syntax!
You're welcome. Sorry if sounded a bit harsh. Yes - in fact I use ripgrep all the time, tho not because its fast, but because it's available everywhere I need it (windows and linux atm). VS Code which I use have a good integration with it, but I'm yet to check it out properly. Otherwise it's a very solid piece of software. 
SCM. My current company uses git, which I don't like (I prefer Mercurial). But I've worked with git, Mercurial, Subversion and Visual Source Safe. 
I am 99% sure exxplicit was joking.
Not at all, and I explicitly asked you for feedback, so it's all good regardless. :)
You're starting from a *thorough* misunderstanding of how things work. You're apparently thinking in terms of something that attempts to translate the C++ or Rust into C that closely matches it. That's not the case at all. What happens instead is that the source compiler will typically translate to an IL. In the case of LLVM, this is a form called SSA (Static Single Assignment), though if memory serves LLVM has a few extensions to SSA as it was originally defined. In any case, this is a *lot* closer to assembly language than it is to the original source code. Almost any higher-level concept like "ownership" is already a distant memory by the time SSA has first been generated. From there, LLVM supplies various tools to manipulate the SSA. For example, an optimizer reads SSA and produces different SSA that accomplishes the same thing, but more simply. From there, life is pretty simple: since we're already at something similar to assembly language, the output we produce is also quite a bit like assembly language. Yes, it'll use C syntax, so (for example) a multiplication will look like `a = b * c;` instead of `mov eax b; mov ebx c; mul ebx; mov a, eax;`, but that's (more or less) the level of code we're dealing with. Arguing that the C compile might not be able to correctly translate this output is tantamount to saying the C compiler is completely unusable for any purpose. Anything you or I write will cause it *much* more difficulty than what a compiler front end produces.
Having version macros is not bad, especially for libraries where you want those in an installed header anyway. Personally I like to have a separate VERSION file in the root directory of the project and then generate C++ headers/sources from that using CMake to avoid having to change that information in multiple places. The CMake scripts can then also add in the SCM revision/hash/whatever for development builds.
The first thing you want to do is to tag the release in your version control system. You can find an example/tutorial on how to manage the releases with git here: http://nvie.com/posts/a-successful-git-branching-model/ You also need an way for your software to include its version. The macro approach is the standard way to do this. It's also common to define a function that returns a version and a function that checks if to versions are compatible. Your build system can help you with that. It's one of the first things in the cmake tutorial https://cmake.org/cmake-tutorial/. To create a distribution package you can for example use cpack. It has configuration options for the version 
Hm, this is complex subject, but I can mention some examples: - Macros defining a semantic version (Major.Minor.Revision). This is often communicated to your customers if you ship software (or use these numbers to determine compatibility between services for example) and some version of this is how they know what they are using. - Use \__DATE__ and \__TIME__ macros, which gives you something but usually these are meaningless as often your code will be built by a server many times a day. So most people don't do only that. These are also difficult to tell a customer if you ship software. - Some use a built number that is written by a script running either on the developers computer or server usually creating some combination of the macros and the build number and maybe a special code for the source machine to be able to see the difference between developers that the build number does not give you. - A combination of the approaches above or some other good idea. Where I work we have a combined approach. We ship a lot of software for dedicated electronics. We make many different products so we have in-house standards out of necessity and experience. First of all there is always a way to get the name of the application along with any version information. We use a semantic version as that is how we communicate versions to our customers. Internally there is also a build number and build source encoded in the binary and our tools can read all of this and it is also included in for example log files so that we can version our log formats. We keep a similar header for all of them. Right now we are working on using git tags to provide additional information. For us all of this is important to allow us to automate software delivery, ease communication with our customers, aid in the use of our data and protocols and so on. But the most important thing is to not make this more complex than you need. If you don't have the need for more than a few macros then don't do more. Do yourself a favor and make sure any communication, data format or anything else your program produces has some form of meta data on it. And if you can make it all easy to control and automate but only do that when you need it.
To be fair, there are ways to force strict evaluation.
I work in a small company. For version control, we use subversion. We make a version string that is &lt;major&gt;.&lt;minor&gt;.&lt;svn repository version&gt;. On our about pages or in a detailed version switch that provides the svn url as well as number plus the versions of important libraries. All this generated automatically as part of the build process so a human can not screw it up. This allows us to look at an executable and have a chance of recreating it.
I normally have CMake variables for major minor and patch/revision version numbers. You can then use CMake to install a version config file that allows other CMake projects to require a specific version of your library
&gt; Haskell gives you extremely fast hahahaahahahahah one of my colleagues has been working with haskell for two years and he's litterally drowning in performance problems
CMake is confusing and while the de facto standard, poorly engineered . It's the Javascript of systems programming.
See http://semver.org
this is completely unrelated to what I've said
Idomatic fast haskell is ugly as sin. Forcing a couple of unboxed values and inlining of functions is usually good enough^tm for me, but it's nothing mission critical. My favorite part is that you can easily parallelize operations on lists. Making a large array operation parallel is as easy as adding in some `par`/`parseq` function calls. My biggest problem is the insane abstraction and layers to the onion you'll have to peel back often resorting to reading source because for some fucking reason the library author just thinks "types are enough" even though the base type is yet another abstraction over a simple type but not mentioned anywhere in the documentation because types are enough you idiot, git gud son. Or the library uses some weird abstraction only 100 people in the world truly understand but it's assumed to be OK because 'someone much smarter than I wrote it'. Who cares if it produces insane compile time error messages! Ask on IRC about something simple and get a million different super advanced answers that dance around your question without answering it and introduce 2-3 more abstraction layers to your thinking. It's a fun language, seriously, but I feel that the community focuses too much on getting it 'right' according to whatever doctrine they subscribe to than getting it done.
I won't downvote you for raising an opinion, but I bet it's an unpopular one :D
I upvoted you for your first paragraph, though I think you're out of line with the second. Using Electron to write a desktop app does not equal writing shitty code. It may be inefficient in resource usage, but that's a different concern. And like you say, time to market is often a much more important concern than resource efficiency, so here we are. Now, I kinda understand the dislike of developers "showing off" in blog posts when they optimize stuff that was built on a foundation that mostly disregards efficiency in the first place, but if you look at it in perspective it's quite understandable. If rewriting the entire thing in a more efficient language isn't worth it (and usually it isn't because of sound reasons), then this is what you get. Not saying it's ideal, but it makes sense, and given the constraints, they're doing the best they can. And I, for one, wouldn't call that crap.
Aww, I've got thousands of lines of CoffeeScript in production. I'm one of a select group of developers who really likes the language.
Pro tip: create a tag in your source code repository each time you increment the version number. That way you can check out and rebuild any released version for debugging purposes. 
Sorry, you're right. This thread started with the discussion of library vendors so my mind got stuck on the standard library modules. Right now the IFC file binary format has not been proposed for standardization. In fact, MSVC hasn't even completely stabilized its binary format as our devs have to have the freedom to break the format as we implement modules. It's easiest to require a hard binding between compiler version and IFC format so that people using modules already (e.g., Windows devs) don't accidentally take a dependency on the format not changing. I expect the IFC binary format to be submitted as a proposal for standardization at some time. But let's play out the two possibilities: 1. Assume the IFC binary format is never standardized. In this case, library vendors would produce files that can be consumed by a particular compiler. I'd expect for MSVC that IFCs we ship would work across an entire major version family, much as LIB files work now. There shouldn't be a need to ship sources for the module, though a library vendor may choose to do so. 2. Assume the IFC binary format is standardized. In this case, a library vendor (say, Boost) could ship one binary version of their library per ISA. That is, you'd have the Boost x86 library distribution and the Boost x64 library distribution. These IFCs would be consumable by MSVC, GCC, Clang, you name it. Obviously there are possible 1.5s here: e.g., the format is standardized but allows freedom for compiler vendors to change this or that, making IFCs incompatible across compilers. I personally really want #2 though : ) 
The one that provides, e.g., the malloc and free that heap operations implicitly triggered by many of those copies are going to be invoking.
Just to be sure, does this mean in order to use Beast, I have to use Boost asio? Isn't Boost asio actually not header only?
&gt; And I, for one, wouldn't call that crap. I would. The base of the application is junk, therefore all that they can do is polish the turd. It is still a turd at the end of the day. The only question is if they realize it. Most of them (blog posts) don't seem to.
You're splitting hairs, and they aren't even the hairs of the right animal.
Allocation is relevant, but copying is the problem, period (and the runtime doesn't copy). If a C++ programmer can't be pedantic, who can?
&gt; Or have I completely misunderstood what you were saying? A little bit. I have been not clear enough. Let me elaborate: - returning unique_ptr&lt;&gt; is like saying 'here is the data, you own it' **and** 'it is allocated in the way **I** like (not you) -- so use deleter provided with this unique_ptr'. Works well in majority of cases, since typically we use heap for everything. - I've seen code using multiple allocation schemes (and multiple non-standard smart pointer types) and these cases were well-justified - as someone who designs/writes a function that is supposed to construct an object -- I prefer to avoid imposing on clients my vision of how it's memory has to be allocated and what tools to use to control it's lifetime. I also would like to avoid duplicating this function for every known allocation scheme or having to pass some sort of _allocator_ around In this context 'just return unique_ptr' is not the best idea. Returning by value (and relying on (N)RVO) is a way to go. In this case I don't care how client wants to manage object lifetime and where he wants to store it. 
yep, plus git and some repository for artefacts (nuget/nexus).
Well, OK then. I completely agree - don't allocate at all, use value types. Let the owner allocate as they wish. (Hopefully they don't allocate either.) You did also point out one thing - if you do have a function that allocates with some allocator, make sure the right deleter is in the unique_ptr type. But I agree - just don't allocate. While you are at it, don't have a "make" function. Have a constructor. Typically.
You may be disappointed with Haskell's performance, nobody claims it's equivalent to well written C++, but putting it into the same bucket with Ruby shows that you're very misguided.
Writing Haskell to compete with C++ is indeed very hard, brittle and ugly, that's not what I'm objecting to. You can write very pretty Haskell and it'll still be much much faster than Ruby or Python. Putting then into the same bucket is wrong. If you like static types, you don't need hard real-time responses and OK with C++/5 performance (which is very high in many domains), then Haskell won't disappoint you.
Unfortunately Haskell's numerical/linear algebra libraries are still fairly immature and not highly optimized like OCaml, so as of yet that particular use is not feasible for anyone who's not planning to develop those libraries on the go. It has other libraries which are fairly robust, anything to do with parsing and apparently server type applications, but as far as I can tell it's main point of attraction is still it's elegant methods of abstraction and close relationship to programming language principles and other related theory.
All major compilers support UTF-8 source and setting the execution character set to UTF-8. Unless you're actually expecting to target one of the old or niche platforms that don't support UTF-8 no one should have any qualms about putting UTF-8 string literals in their source.
One common trend I've noticed in workplaces is trying to cut corners without loss of quality by offloading as much work as possible. For example, if you want to be a developer, it's more or less expected that you'll have taught yourself for many years and obtained a degree (or proven your competency). In contrast, if the work were not offloaded, developers would receive on-the-job-training. A couple projects started as a developer's spare-time hobby project and were eventually integrated in the codebase when they'd matured past existing projects. The game industry also has this trend. A person starts a backyard project and years later it's finally ready to be turned into a commercial game. They may get a profit on paper, but they've already sunk thousands of hours of leisure into the project without any pay. The only way anything becomes successful is to pay for it yesterday.
Vague question gets answers all over the place. OP needs to learn how to ask a question. First thing to do would be to say what they looked at so far and what wasn't clear or not applicable to what they're trying to do (a.k.a "what have you tried" part of the "how to ask a question on a forum").
I really hoped Outcome would've been accepted into boost :(
Sure we do, that is what CS does all the time. Industry calls them conferences instead. Now if you would say that many don't bother to attend conferences, watch the videos posted afterwards or get their employer to pay for them, then I would agree more.
Could this quarterly topic be broken into sections please? One Remote working, one North America, one Rest of World? North American jobs are pretty much unworkable for non-Americans nowadays, plus remote working keeps on growing bigger (thankfully!)
Im quite proud to say that the first programming language I introduced myself to was c/c++. Sometimes I wonder if teaching python as a first language is such a good idea.
Neither GCC nor Clang's no. However the promise from Chandler Carruth is that it should catch any instance of UB that is used by the optimizer. Which in this case means that GCC's optimizer does not assume that the virtual pointer is constant across calls. I couldn't test Clang's because some libraries are missing on Coliru :(
Of course they realize it. The thing they also realize, and you apparently don't, is that the efficiency metric really doesn't matter to most people. Not to most of the users, and certainly not to the investors. But it matters to you specifically, because you know the art of writing efficient applications. It certainly is a valuable art, but fewer and fewer people appreciate it. That's unfortunate, but you should accept that reality rather than call other's applications turds because you hold it to a standard most people don't care about, because frankly, the name calling makes you look kinda pathetic.
Time to market is important for some people. 
Do you know why? My rationale was that not running destructors in C++ is not UB, e.g., shared ptr cycles, not calling delete, etc. are all perfectly defined memory leaks, not UB. For example, for trivially destructible objects (which is not the case here) it is a common optimization to not call destructors at all, e.g., inside a `vector` implementation one can just free the memory. So I thought that not calling the destructor here just leaks the object (like `mem::forget` in Rust). Yet, if this was the case then all references to the object should still be alive after the leak right? But I think that even if one doesn't call the destructor, all references to the leaked object are invalidated here. So... I don't know. It might also just be that placement new requires the storage to not be occupied by an already constructed object (but then again I've often seen the optimization of not calling the destructor of trivially destructible objects inside of `vector`).