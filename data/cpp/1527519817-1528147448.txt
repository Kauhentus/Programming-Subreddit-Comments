asd?ddd ---- asd ---- |Vote Button| Poll Options|Current Vote Count| |:-----------:|:------------:|:------------| |**[Vote](http://redditpoll.com/vote/1Z4gC4n7)**|a|**0** Votes |**[Vote](http://redditpoll.com/vote/pok6soO1)**|b|**0** Votes ---- **Instructions:** * Click Vote to Register Your Vote. ---- **Note:** Vote Count in this post will be updated real time with new data. ---- Make Your Own Poll Here **[redditpoll.com](http://redditpoll.com)**. ---- See live vote count **[here](http://redditpoll.com/poll/asd-ddd)**
Correct.
Since your project has sponsors: did you ask them? If they say it's okay, I'd switch to C++11 for 1.3.0/2.0/whetever-you-call-it, and only backport bugfixes to the 1.2.x branch.
I do not mean that vocabulary types should never be added, nor that c++ shouldn't have a standard library. Although I can see why my post can be interpreted that way. IMHO an added vocabulary type should have to at least pass one of two conditions: either it is considered fundamental type-algebra (std::optional, std::variant, structs); Or fundamental to new or upgraded APIs (outcome, ranges). The upsides of adding the type should be greater than the downsides. One downside (vs using dependency management) is that it will probably never be improved (only fixed). What I mean by that is my impression of outcome vs expected, where I've read that [outcome might be a better](http://open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0762r0.pdf)
Just to set the context, I started using C++ in the late 80s and it was my language of choice for almost 3 decades. The last 10 years or so I was building C++/Python hybrids with data logic in C++ and management logic in Python. Over that time I have found that it is almost impossible to get people to write consistent code in C++. C++ offers so many ways of doing things that it is like every developer has his own language. It leads to religious clashes between style tribes (exceptions/templates/lambdas/smart pointers/... should be allowed/forbidden) and wastes time that should be spent productively. It leads to bugs that become harder to find, for instance when you have to trace memory through modules that have different approaches to memory management. And it is multiplied by 10 when you bring in an external library. The second problem is the ecosystem. C++ tools are an assortment of separate programs that all work in different ways leading to lots of googling to find that one option. Libraries is another place where things are problematic. Trying to build a system with third party libraries is a pain as most of them come with their own logging and a lot of them with their own, incompatible smart pointers. Code reuse is frequently more work. I could keep going, but Golang has been a refreshing change. It is kind of a simple language so there are very few religious fights about how to use the language. In most cases there is really only one way to do something. Multithreaded code is trivial and overhead is surprisingly low. The tools are pretty good. My last C++ project took hours to compile on a large, distributed system. My current Golang project is close in LOC and takes minutes on my laptop. Standard packages allow easy integration of common functionality (like a webserver) and third-party libraries generally work in a fairly painless fashion. Performance is roughly equivalent with C++. Don't get me wrong, it is not perfect. If you look at the things I mention, most of them have less to do with language and more to do with environment. There are lots of things in Golang that annoy me when I am writing code, but it has fixed a lot of the things that were wasting my time in C++, leaving me more time to write code. 
I do use CMake, CMake Tools, CMake Tools helper, Native Debug. For the text I like the Atom Dark pro theme :)
Nah. Screen is also ok albeit inferior :)
It depends: do you use a mouse?
Occasionally, but I'd rather get away from the usage of a mouse.
Having a long-term maintenance on the existing C++98 branch is at least always desirable when deciding to make a breaking release.
Then trying out vim (or emacs) might be a valuable experience. Unfortunately vim's learning curve is quite steep, so it comes with a price...
I'm mainly working in the game industry, and C++ has a long history there. Yet, I'm increasingly seeing projects written in languages other than C++, despite having hundreds (if not thousands) of engineers proficient in the language, and several million lines of code and libraries. One of the main disruptors as of right now is Rust, by directly trying to replace C++. And there are a lot of other languages used, which are replacing C++ in certain areas. A lot of studios already have a long history using C# for everything which is not performance critical (like user interfaces). And a couple even migrated towards using web technology, for example the Battlefield 1 UI is using react, and written in typescript. So is the Uplay Launcher, and probably many more. C++ is avoided if possible.
What engine is using Rust as underlining language? If any.
Emacs has autocomplete, M/, though it isn't that smart :\\ Don't know what you mean by tag search, it of course has regular search, Cs :\)
Huh some of those companies are about (or already are) to be obsolete. It’s cool to see how far C++ got.
Thank you. Im kind of in time where Im getting annoyed by exactly same things you described with C++. Looking to broaden my skillset. Started with python with work motivations and im willong to broaden faster, so Golang and Rust from these threads seems good avenues. Thanks.
This paper is merrily short. It's transparently true. C++ is too big. Every time some shortcoming is noted, the solution is to add something more to the standard. That might address the original complaint, but it creates another ripple of complaints/enhancements that the committee has to consider. The current process isn't scaling. Current System: Marxism. It's very similar to the the old style soviet economic system where everything is decided by one central committee which may parcel out aspect to subcommittee. Implementation of these facilities is delegated to vendors who are generally participate on the committee. Nothing moves until everything gets done. The idea is that by doing things this way the results are going to be rational and consistent. It doesn't turn out that way and it takes years to accomplish. By the time it's done, it's pretty much irrelevant. Proposed Alternative: Capitalism. The committee limits its efforts to * language syntax and semantics * library functions required to interface with the operating system - C already has all those defined. Other examples might be co-routines, semaphore or mutex, etc. They would be "primitives" not meant to be used by applications but rather expected to be used in the crafting of application libraries. These define the "rules" and are analogous to the rule of law under which capitalism operates. Application Libraries: Marketplace. Libraries which depend only on the language as defined by the committee as above would be called "conforming" libraries. These would be guaranteed to compile and execute their defined behavior on all conforming compilers. Libraries which depend on other conforming libraries would also be conforming libraries. Examples of Application libraries would be: * Networking * Ranges * STL * Futures, Threading, etc. * Serialization * Coroutines for applications, The committee's role would evolve from its current one of designing the facilities to be implemented by vendors, to setting the rules (language and primitives), moderating disputes (resolving ambiguities in language), and letting the rest of the language evolve in accordance to application developers demand. It would move from being a player to an umpire. This would change the landscape for C++ software development * The committee itself would be have a much, much narrower scope. This scope would grow at a much smaller rate that it has been growing. * Application libraries would proliferate almost out of control. This is already happening with GitHub and other services. * Most such libraries are unusable due to bad design, non-existent documentation, bad coding practices, or some other problem. * Users would pick among available application libraries - rejecting most of them. * Agreement to deprecate libraries would not be necessary. People would just stop using obsolete libraries. * If some mechanism for separating for portably separating library interface from implementation (perhaps like llvm) could be invented, fee based libraries could become available. This might compensate library writers such as writers of other creative works are. This would fund libraries which users would find more usable. This would create an explosion of C++ development. * New libraries would become available much sooner. Obsolete libraries would be replaced much faster. Currently popular libraries would be under pressure to stay current, relevant, and effective. * Actually this is already happening. Ranges, Networking, Serialization are available. The are constantly evolving to maintain competitiveness and they are always under pressure to stay relevant. This is a good thing. The only thing really necessary is for the committee to recognize this and just terminate efforts which are redundant. For each thing on Bjarn's list, ask yourself. What will happen if we don't get involved in this? If some one needs it, can he easily build it himself? If a lot of people need it, can some library writer build it? What value will we actually add? Think of it as the C++ equivalent of [tidying up](https://www.amazon.com/Life-Changing-Magic-Tidying-Decluttering-Organizing/dp/1607747308). Robert Ramey 
I'm not aware of any, that'd be to early. Especially since there is no official support for console platforms. However, I'm aware of a couple of internal tools and service, as well as server written in rust. 
How are they getting paid unfairly? What are they currently getting paid relative to what they should be paid? If you are a software developer then it's very rare for you to be unable to afford spending $90 a year on a tool like this. Software developers pretty much everywhere seem to be paid well enough, even in much lower col countries/cities, to pay that yearly. And if you are a student, then they have free student packs.
Thanks! :\)
Seconded. A version 2.0.0 based on C++11 or better C++14, while keeping the current release on bugfix only. 
&gt; semantically versioned modules No, no, no and no. Dependency/versioning hell. 
Another vote for 2.0 \(C\+\+11\) and long term support of 1.2.x \(C\+\+98\) that's bugfix\-only.
Probably. That's one area of new c++ features I've not delved into yet. Edit: Updated the code with a user-defined literal. Turns out there's some pretty serious restrictions on what you're allowed to pass to a udl, so I was only able to make one for the `CRC64()` variant that takes `const char*`.
That was 25 years ago. And we still don't have reflection in the language. That's not cool, that's sad.
NDAs are what's blocking official support, but we know that all current consoles run Rust, thanks to Chucklefish. I have given a talk internally at a big-name AAA studio. We'll see. Honestly, people are very split if Rust offers anything over C++ for this domain. Some people think so, but some are also very very skeptical.
&gt; IMO you should write your program expecting that you may need to change to a different RNG at some point. There's no way you can be sure that you won't. KISS &amp; YAGNI disagree with you :) 1. Many programs do not change their PRNG (any introductory/write-once program falling in this category). 2. Many programs do not expose their PRNG (only what is generated), and therefore switching the PRNG is a few lines of code. As anecdotal evidence, in 10 years of professional development, I have never needed to change a PRNG. Preparing for changing the PRNG would have been a case of over-engineering in all the programs I've ever hacked on.
The biggest thing C++ needs, IMO, and which helps to address this paper, is to reduce or eliminate meetings and modernize the proposal process. There is no reason all these papers and discussion can't happen online. It should happen online. They should be living breathing documents that adapt to the needs of industry, users, and compiler writers. If done correctly, this widens the net and gives a central location for discussion and updates to the proposal, making it much easier for people to point out possible problems, incompatibilities with other proposals, objections, missing items, etc, and to see how it evolves over time. As well as making it easier for everyone to communicate at their convenience. This would do a lot to solve the issues presented in this paper, i think. As it stands, proposals seem, to me, like static, unchanging documents, which doesn't quite fit the idea of updates and discussion and sharing. From a solid foundation like this, versioned standard library modules may become a possibility.
&gt; I just don't see the big deal – there's no "right" way for everyone, and doing your own "right" way is easy, so.....? Let's make a parallel with Boost headers: - There's no set of headers that every would agree is "the set needed", - It's pretty easy to include 4/5 headers. Yet, Boost provides convenience headers. Why? Because it makes life easier when you do not care for THE optimal solution, and just want a convenient off-the-shelf solution.
IMO C++ ought not to be held back in order to support older compilers. I actually quit my C++ programming job in large part because the company did not seem to care to support C++11 at any point. I'm not a huge proponent of just embracing the newest thing, but after 7 years it is just painful not to use C++11. When striving for compatibility, I use C. Many C++ constructs won't compile in broken compilers anyway (e.g. extensive use of templates).
&gt; Because it makes life easier when you do not care for THE optimal solution, and just want a convenient off-the-shelf solution. Which is perfect for something like Boost; not so much the standard library (IMO). Rust certainly does the same with encouraging crates over core/std for various things; the only practical difference with C++ ultimately devolves into rants about dependency management and package managers. :-]
infinitely decisive :D 62 to 0
AppCode https://www.jetbrains.com/objc/ never used it though.
Ok, then just use rand I guess?
For people who don't really know what they are doing and don't care about the details, why is `rand` a bad option? How would you want to improve on `rand` for such people?
C++11 should be your minimum requirement. If you can make use of 14/17 features then you can always put them in conditionally
&gt; I pay annually for the entire Jetbrains pack. The amount of time their tools save me in the course of a week, is well worth more than the cost of my annual subscription. it's good. &gt; they provide free licenses to open source project maintainers and students, and a few of their products have free community edition licenses Visual studio is free for everyone, QtCreator is also free. In terms of free features, You should not compare with Visual studio and QtCreator.
I believe that, as in many many cases, it's a question of someone's perspective and what someone thinks is a priority. This varies and is usually neither wrong nor right, it is all a little of both. Some will focus on the installation problems they have and fall in the camp of "I want everything in the standard library" because this is the only way for them to get the features. The other arguments are still valid, just not as important to them. Some will focus on interoperability and also be in the "I want everything in the standard library" camp on the assumption that everything in the standard library will inter-operate easily and practically. Again, other arguments valid, simply not as high a priority. Some will focus on the limited amount of time that the committee has and say "the standard library should be as small as possible, use external libraries", because otherwise, the languages changes too slowly. Some will have more philosophical arguments. I think with the same set of facts, depending on how you weight the different aspects of a decision/situation, you can come up with different answers. In any case, I think if the C++ world/community/committee is to find a solution to this problem, it cannot do it while completely ignoring one camp or another. I think this might be the attitude if one position or the other were really marginal, but it does not appear to be the case to me. It rather seems that both propositions (small STL, large STL) have a non negligible number of supporters, and that ignoring one or the other is not practical. One solution could be to solve the library sharing problem (which the new study group on tooling is looking into what (if anything) could maybe be done by the committee) so that the STL could be small and people could install other libraries easily, but even then, people whose companies do not allow third party install easily will not be satisfied. I know satisfying everyone is not a practical goal, and I am not advocating for that, but I don't think simply saying "this is best, here are the reasons, if you disagree you are wrong" is a good approach either. Things are rarely one sided.
&gt; What is a good library for making windows applications and or games? Libraries used to make games are very different from libraries used to make applications. For apps, look into Qt. For games, look into SDL for 2D games ; if you are going to make a 3D game you would be better served by an engine such as unreal engine or unity3d.
The thing you might want to put serious thought into: Why do you have complicated objects, with lots of configuration? Objects with only one purpose tend to be simpler.
&gt; For apps, look into Qt Or wxWidgets. I've always found that more intuitive, especially for beginners.
I am AM A ROBOT. I VOTE YES.
It may be obsolete, but there are no complete C\+\+17 implementations yet, at least that I'm aware of. Language support is pretty good at this point, but the std libraries aren't finished yet. 
Probably will never in my life use C++ for windows applications. I'm good, extremely actually with C# and when it comes to windows it's my preferred language.Thank you for your info it was greatly appreciated and helpful. Thank you and have a great day! 
Thank you so much for your help. It's greatly appreciated! Have a wonderful day. 
Be very careful doing that in library code. You can introduce gratuitous incompatibility between code compiled with c\+\+11 and c\+\+14, where those are otherwise generally compatible. I do think that mixing --std=X is a bad idea, because it's easy for conditional compilation to make changes, but it's worth considering if you want to be the one that introduces the incompatibility. 
I would not call it obsolete. A harsh word in a world where quite an amount of people struggle to even introduce C++11 :-( An upgrade to version 3.0 could be done in a year or so, based on C++17. This way compilers, users, etc. have time to adapt and it ensures a large enough user base. It's not like everyone is porting to C++17 the day after the committee finalizes a new draft.
Flair checks out.
C# is my preferred language for windows applications. Your info was extremely helpful and I greatly appreciate it. 
Even for a game, rand() is so bad that you can actually see visible artifacts if you're doing something like generating terrain with it. 
For games it's pretty much up to the libraries you going to use.. let's say it's a full-screen game, then you won't really be dealing with Windows UI code that much so the whole "Windows app" issue kind of disappears. The old WIN32 way of doing things was mostly OK but creating anything UI-like was like chewing glass. You had to literally create HWND-window for every button and widget, literally, and retarded C callbacks for every window, of course. Horrible. I used to do it, wasn't as bad as MFC most of the time but .Net really came to good use when it was released. Now that .NET is mentioned, you can use the API from C# and C++ just fine. It's language agnostic that way. 
It only makes sense to depend on the newer standard if some feature of the new standard offers substantial benefits, either in the capabilities the library provides its users, or in the library's maintainability. There's no sense in taking additional dependencies for their own sake.
But it is still a standard. You can tell your client that he needs a c++14 compiler to build your code and that's it. 
I agree, but the topic is about C++98 vs. "Modern C++". C++11 introduced quite a handful and very useful stuff, C++14 was more of "bug fix" release. While the step to C++11 surely would be beneficial, in 2018 it may be better to go directly to C++14, while C++17 as a newer and larger step probably would be too soon. In this sense, C++14 is not "additional depenencies", of the two (C++11 and C++14 if you can choose), C++14 is the clear winner (bug fix release, relaxed constexpr, etc.).
keep in mind that c++98 support for gameconsoles is still kinda shit. 
It's what the customers want. They prize stability over all else.
Ooh, I vaguely remember reading about that a while ago, rr looks super useful :) 
Visual studio Hands down. Nothing can beat visual studio. 
&gt; Not that these things rule each other out. If the majority of the work can be done away from the formal process, the formal process could perhaps spend more time looking at the big picture instead of the details. That's been my take. Rust for example does well with their online process of "postponing" proposals/RFCs that are good on their own but don't fit the current direction or vision for the year's iteration goals. C++ in particular is kind of a mess, because a lot of people who might contribute (e.g., in helping to cull non-vision-aligned proposals, or iterate on vision, or help folks write papers aligned to vision) can't or just won't put up with the expense and time of the formal meeting process; it also means that an incredible amount of the very valuable face-to-face time that the committee leaders have at the formal gatherings is spent arguing semantic or grammatical details of papers rather than actually working on vision or hard problems. Modern process can be used for the iteration of proposals and the formal gatherings could be repurposed into far more useful and powerful events.
Wouldn't that increase this particular problem though, by reducing the energy required to suggest an idea?
Please don't recommend something purely on the basis of it having a C++ API instead of C. - SFML's input translation layer had bugs so European and Apple keyboards will have some scancodes reported incorrectly. But it has more complex rendering operations builtin. - SDL doesn't have the builtin rendering features, but it supports a ton of platforms. Those the tradeoffs relevant to /u/Theinquisitor18. They probably do want SFML, but because they don't need SDL's portability and SFML lets you do fancier things with graphics without having to touch a native graphics API--not because SFML is C++.
I threw up in my mouth a little.
KDevelop is my personal favorite because CMake integration is easy to pull off and I prefer to make my projects as portable as possible.
Can I piggyback on this request and ask what open source IDE that has the least number of dependencies on the build system? I work on an open-source project with a very special snowflake build system, and the IDEs that I have tried **insist** on trying to understand the build system, failing, and then get very angry. Specific problems that I have had: * KDevelop refuses to even create a project if no file called "Makefile" exists. I can work around this with "touch Makefile", but it's a pain and I find KDevelop pretty buggy * qtcreator insists on having the build system tell it which #defines are defined for the build, and greys out any code that is under an #ifdef it things isn't defined. I can't find a way to disable this feature and as a result, a lot of code in this project is greyed out and hard to read and navigate. * eclipse I can't even manage to install properly under Ubuntu. The standard packages are garbage and I had problems trying to install the version on eclipse.org Don't bother suggesting emacs or vim; I loathe editing code in a terminal.
C++ Library is literally the headline of the topic. I was going off of that.
He doesn’t really add anything by writing this.
kinda off topic, but can anyone tell me why would people willingly stay on older versions of c++ when there are some very appealing features in newer versions? i learned c++ a couple years ago and never saw a reason to limit myself to older versions of c++ or any language for that matter.
IRC, VS2017 has complete C++17 support in the 15.8 preview branch.
do you run two separate language servers, for rtags and for ycm?
Very important point that often gets overlooked.
Definetively drop the c\+\+98 support. Connditional compilation is the bane of maintenance. I'd even suggest to go to c\+\+14 because it offers a lot of improvements that make coding more convenient. And consider this: Whatever standard you choose now, you'll probably want to support it until the next major revision of your project. Assuming that is a few years in the future, youll probably still have to support c\+\+98 in when c\+\+20 is out and c\+\+17 has wide support\- is that really what you want?
"Ok, children, \- a teacher says, \- here is a picture of a house. Well, it's only a shape of that house. I'll give you its copies. Think what details are missing here, draw few and come back to me." Children take theirs copies and start drawing. Some boy come to teacher and shows a chimney on his house shape. "Nice, Peter, a neat black chimney!, \- a teacher says. \- I'll copy it to my picture. Here. You can go to walk now." Another little painter was waiting until Peter frees the teacher. It was Susan. "Susan, what do you have for me? \- asks the teacher and examines the picture Susan did. \- Oh, it's a round window! So great! I'll copy it to my house, thanks. Go with Peter, go to walk!" Another boy shows his drawing to the teacher. "Oh my dear Steve, I'm affraid, Susan drew a round window already. I can't displace your square window on my picture. Look to my picture: we have a round window by Susan and a black chimney by Peter. I'll make a copy for you, try to draw anything else."
`vcpkg integrate install` `vcpkg install opencv[core]:x64-windows` How can anything be easier? :-)
On a first glance it looks like it is lacking lazy evaluation...
True, but as you said, that is rather the minority. In all fairness: A lot of proposals are already accompanied by an implementation on GitHub.
The funny thing is: The are better alternatives (c++14 &amp; c++17, but large parts of the industry doesn't want to adopt it (some parts are even stuck in pre c++11 mode).
How is this different from just taking `param` by value? Honest question. I'm not up on how coroutines are supposed to work.
That makes no sense whatsoever. No serious project is going to be built on top of a third party library without commercial support. No company is going to invest in creating a library just to "put it out there" without having some greater plan for it. Interoperability is a major driving force in software development and what you're proposing is nothing short of anarchy. There is a reason why nuts and bolts come in specific predefined sizes.
Compiler support is really good nowadays. Standard library support is actually the bigger problem. Some standard libraries don't even have a compliant `&lt;optional&gt;` yet.
The turmoil on the committee leaves room for those who [go through the fields and pick up leftovers](https://github.com/Ebenezer-group/onwards).
I vote yes! I work in a group that still uses visual studio 2010 (with only limited c++11 support), and the people in my group have no desire to upgrade their compiler, let alone any tools/libraries they use. In fact, making a breaking change would only make them happier, because now they have more of a reason to never upgrade! In summary, people who don't want to upgrade their compilers generally don't want to upgrade their tools either. 
Programming Windows of Charles Petzold is a lot of fun.
Just go to 2.0.0. Upgrading to C++11 is a non-backwards compatible change for those stuck on C++98, so semantic versioning says you should increment the major version number.
VS to a point of making one feel there's no real true competition. It's not perfect, but it's amazing.
It could possibly only do the copy when its required, still not certain on this being a good addition however.
I haven't done anything big in Rust, but I honestly like the language better than Golang. I feel like Go is C with just enough extra that you eliminate 90% of the stupid bugs, where Rust is C++ with enough removed that you eliminate a lot of common problems. The problem is that Rust feels a lot less mature and I have not found a single company using it. I think momentum is behind Go, but that is not the same as saying that learning Rust is a bad idea.
I do; it's not as onerous as it sounds because the ycmd one is handled entirely automatically and it's relatively lightweight. So the only one I ever really think about is the rtags one, which is fair because it's doing quite a bit more. I also turn on emacs' semantic mode (but I think not global semantic mode). I did literally zero setup for it; the only thing I use it for is to get a much better quick-outline. `SPC j i` and `SPC j I` are pretty amazing in my setup, and so is treemacs with auto follow mode.
Does vcpkg comes with a nice GUI in Visual Studio by default? Will it automatically download your package if you move your solution to another computer? I'm not saying vcpkg is bad, but it's hard to be more simple than NuGet for people who don't know anything.
Red is don't have. White with NA means not applicable. Several compilers are no library (or just freestanding library). Also, some things that were made illegal were always done 'right' by these compilers.
&gt;Excessive cost due to use of thread local storage in rand()s implementation. Thread local storage is basically free (in terns of cycles)... Do you mean memory usage?
I wrote that code. It's not great for the purpose you outlined, as while it would be quite easy to *build* a DFA that validates UTF-8 and get good performance out of it, Sheng is really lousy at being able to do much more than jump around inside states. It's possible that you could instrument the accept nodes in the Sheng DFA, and figure out how to spit out the right symbols, but much of what makes Sheng fast would be lost to branch mispredicts. I think most of the performance that's easily gotten for this kind of task is the cheesy kind that you get from handling ASCII really fast.
Looking down the page, I am left wondering how much you have to do with Rust to get included. I pinged a friend who is an architect at one of the companies and he could not think of a project that is using Rust. He was actually somewhat annoyed that they were on the page, not to mention that someone is introducing a new language in their stack without going through the architecture committee. Anyway, it wasn't meant as an absolute statement. There are obviously companies using it. There are companies using Haskell, but I don't consider that mainstream either.
In the current coroutines proposal, passing 'param' by value is exactly how you would solve this problem. (Or you could copy the string into a local variable at the start of the coroutine.) The problem is that coroutines currently look very similar to normal functions (which is by design) but the lifetime of parameters can be very different from normal functions. My proposal is just putting that difference directly in front of the programmer and asks them to be explicit about what lifetimes they require. Caring about variable lifetime is also something required when using lambdas. So I figure it would make sense to reuse that syntax when solving a very similar problem for coroutines.
Note that copying into a local variable at the start of the coroutine is _not_ sufficient (in general) to avoid the problem as a coroutine can suspend before executing its body.
Just a thought about the name: sounds too similar to Ramanujan, which would presumably be a math library.
Are you sure that is accurate? My understanding is that coroutines can only suspend once they hit the first 'co_await' or 'co_yield'. It is then up to the code being waited on to resume the coroutine.
Yes, this is accurate. From the current proposal par. 11.4.4.3 For a coroutine f that is a non-static member function, let P1 denote the type of the implicit object parameter (16.3.1) and P2 ... Pn be the types of the function parameters; otherwise let P1 ... Pn be the types of the function parameters. Let p1 ... pn be lvalues denoting those objects. Let R be the return type and F be the function-body of f, T be the type std::experimental::coroutine_traits&lt;R,P1,...,Pn&gt;, and P be the class type denoted by T::promise_type. Then, the coroutine behaves as if its body were: ``` { P p promise-constructor-arguments ; co_await p.initial_suspend(); // initial suspend point try { F } catch(...) { p .unhandled_exception(); } final_suspend : co_await p.final_suspend(); // final suspend point } ``` 
=&gt; /r/cpp_questions
Ramen!
Is the allocator necessary? Isn't this for the promise to implement?
Oh, if I'm interpreting that correctly, there is an coroutine extension point that allows the future type to force a suspend at the start of the coroutine. Peachy...
Your big customers need a little help modernizing. Encourage them to upgrade their compilers. Believe me, I'm in the same boat with an old compiler for work.
No formal proposal yet. I figured I run my idea by reddit first and see if it actually makes sense or if I'm a crazy person. (I have zero experience writing compilers.) &gt;Does this change the signature of the function? Is it only the implementation that changes? This wouldn't change the function signature, only the implementation. This is actually somewhat the point. In the current version of the Coroutines TS, you have to change the function's parameters' types to get the correct variable capture behavior. My idea would separate the function signature and the variable capture. 
I guess there's nothing too terrible about that. Is there anything we could do to make sure that if we added another `rand` with slightly different characteristics that is meant to be "easy easy easy", we don't have the same conversation again in 5 years because of perceived drawbacks of such a PRNG? Would you want the output of this interface to be standardized and portable, or just the broad characteristics of the algorithm? Would you want to allow stdlib maintainers to change it at will, since no one will be using this unless they don't care too much about the details?
Currently the TS specifies that the coroutine's frame is allocated on the standard heap (operator new) unless the compiler can optimize away the allocation. This lack of extensibility is one of the major concerns with the current coroutines proposal.
The allocation function is looked for in the promise type, so it is customizable at that level.
With a context, you can have a more memory local random number generator though. Different systems or objects could have their own contains in cache line rather than static/global/etc.
Well. In a lambda you know what happens. I agree that it is not as clean but I have been using asio with stackful coroutines and it works very well for me and it is more indicative of what happens under the hood. I forgot metaclasses in that list, maybe because I see them too far still :\)
[Chucklefish is using Rust for their new game](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/).
I do not think that memory leaks are such a common problem anymore. Though I can see some value there, I think the big value is in robust servers and the like.
My company ships support for older versions of Linux. We are looking at upgrading from gcc 4.4 to gcc 6.2.
GUI development, for example. C++ completely lost the war there. C++ was the language of GUI frameworks about 20 years ago. OWL, MFC, WTL, CSet++, PowerPlant, Symbian, Motif++, Qt, wxWidgets Nowadays, across iOS, watchOS, macOS, Windows, Android, Web, C++ has been pushed down the stack for the GPGPU programming part, with everything else being written in other languages. Even on Windows, where UWP is COM improved with lots of C++ underneath, even the Windows UI team mostly uses .NET Native. Qt the last golden standard of C++ GUIs has been transitioning to JavaScript/QML, leaving the C++ part for the high performance bits, and the C++ Widgets API seems to be in maintenance.
&gt; - I have to learn the borrow checker (I do not think this kind of safety is critical in most code for a game, but not sure) Game exploits? Ways to create cheatcodes, get new inventory items, write bots,...
In real world scenarios you often have complicated structures/objects, either in libraray or legacy code. That's not always in your control. Then there is 2D/3D image data/objects, which have a geometry, certain properties, etc. 
I went Java/.NET instead, back in 2006. Yes we still use C++, occasionally, as you say it is infrastructure code and the way we need to do bindings with the platform. Those C with classes subset is what keeps me away from pure C++ projects, because I keep meeting devs that their old school C++ is Good Enough™.
Embedded industry for example.
It literally is obsolete. ISO standards like c++ replace the previous version automatically. Just like standards for electric plugs.
Interesting article. But I would love to see the code for the benchmarks. Also it would be interesting to see the distribution of the stats having, min, max, median, stddev give a better feel for which is actually better or worse. 
If you’re quite happy, then you should keep using what makes you quite happy. Rust (almost) has allocators and coroutines that are portable, good scripting bridges, can do virtually the same optimization techniques, and many people see the borrow checker as helpful, even if you’re not thinking of security. But ultimately, if you don’t feel the need for what Rust offers, then maybe it’s just not for you. That’s super fine. 
We let the companies self-determine if they belong there; a representative asks, we accept. There are some companies who are actively using a lot of Rust who aren’t on there. We simply ask that it’s in production in some form. 
Has Google finally released their new has_map as OSS?
When is sol3 finished?
Because the compile time interpreter is unlikely to implement tail call optimization, so it would be a full function call, which is considerably slower than a simple goto. Plus the aforementioned recursion limit in the compiler makes the loop a better option regardless.
&gt; If C++ continues at it's current pace That's what the paper is addressing. It just believes the cause of the pacing is the opposite of what you seem to think it is. 
&gt; Robert Ramey Did you sign your reddit comment? And even with the same name as your username? That seems rather pompous.
This seems bad. If you want a yield before the real work begins, just add a yield at the top of your coroutine? Seems like I'll have to wait a while before I can feel comfortable using these. Let everybody else figure out the annoying corner cases.
You know that when people (especially beginners, since they don't care about the differences as much) are asking for a C++ library, usually anything callable from C will also do. So it's better to give an accurate representation of their options and the use cases each option is tailored to. Why is this controversial.
Rand is bad for the reasons listed voluminously in this thread. But it is simple to read write and understand so it is better for new programmers. 
Too little code, too much text. I like examples and facts smashed into my face :p
&gt;Google hasn’t open-sourced their hash table yet, so I had to implement their hash table myself. I’m 95% sure that I got their performance right. If he implemented their algorithm, you might be able to use his or do it yourself. I'm skeptical of his results because he implemented it himself though.
Thanks. I only skimmed the post and apparently overlooked it. I'm also looking forward to a comparison with the actual implementation. Hopefully, Google also publishes their benchmark code.
I charge the company I work with a fixed salary at the end of each month. It doesn't feel weird.
Then use it! I do not think it has the maturity needed yet. Just my opinion. If it is useful for you, I am not opposed to people like you using it :)
Well, you can't do IO without support in the language.
I really hope the committee release a specification for a new standard hash table interface that focuses on what is important (fast, armortized O(1) insert and lookup) and remove all unnecessary API surface that tires down the implementation. Let the standard library implementers pick the "best" design and let them pick a new one when things change.
&gt;Well, you can't do IO without support in the language. Sure you can. In the end, all that an I/O library is doing is calling some OS APIs. Just think ASIO and you could even implement `printf` or I/O streams in standard c++. Yes, boost comes close to what I have in mind. The thing about the current boost process that don't fit that model is that boost doesn't tense to newer standards: Once a type has been adopted into the standard library a separate (often slightly incompatible) implementation remains in boost and many libraries are investing a lot of effort in order to stay backwards compatible to old standards.
Ok fair enough! :-) I'm still wondering a bit about that use case though. People who don't know anything don't really have a business even installing VS. And let's say they're users of your software that need to compile it, let's say your open source software or something like that, but they're clueless. So your open-source software most likely wouldn't have a .sln file with nuget support because that's not cross-platform and not how it's done. Your project would have a CMakeLists most likely. And I'm not sure nuget integrates with cmake. But vcpkg does. So it would be far easier to write a 3-line instruction readme for your users how to download and set up your project with vcpkg. I mean maybe it would [work with nuget](https://stackoverflow.com/questions/18132987/cmake-and-msvs-nuget) but still it's a bad idea to put a .sln into the repo.
&gt; all that an I/O library is doing is calling some OS APIs Does C++ have a "make a system call" operator? 
You should check out this implementation: https://github.com/TooBiased/growt
That has nothing to with the programming language. You ship a binary and you cannot prevent the user from picking it apart.
Outcome **is** proposed to be standardised as http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf. Herb's proposal, quite literally, standardises Outcome into the language, and he partially wrote it in response to the Outcome peer review at Boost, and P0762. I've been busy filling in the gaps between P0709 and what we need from Core and indeed, WG14. You can see the latest draft of that paper at https://groups.google.com/a/isocpp.org/forum/#!topic/sg14/fBLwNO8Wu48. As you will see, Expected absolutely 100% is part of the proposed plan. So tl;dr; the process is working well here. This is how standardisation is supposed to happen.
It's more that for a vocal minority, it's a big pain point. But most on the committee would take the view that there is no point in touching serialisation until Reflection is done. I agree with this, but I think that the ground work can be done now in preparation for an iostreams v2 replacement later. See http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1031r0.pdf
Hear, hear. What would also be nice is a wide collection of benchmark data for hashing algorithms. Each benchmark would be a sequence of elements to be inserted into a hash table, and then a sequence of elements to retrieve. Then different hash table implementations could be compared by running each of them over each benchmark separately and measuring wall clock, cycles consumed, memory usage and anything else that came to mind. A benchmark would represent some usage pattern of the hash table. One might be "random"(*) strings coming in in a random order". Another might be "strings with a common prefix arriving in alphabetic order". --- (* - Yes yes, there are countless ways to do that, with dramatically different possibilities - each of these could be a separate benchmark.)
I write "which can be used". So I didn't dismiss it, I just provided an alternative. Sorry if SFML offends you, but I think I am allowed to give my honest opinion.
Yes, they use things that are proven to work for them. Upgrading may involve *lots* of paperwork
i think he has a really good point. c++ is already an incredibly useful and powerful language today. a slow, well designed, evolution will not hurt it. 
I actually just downloaded this last week. I haven't isolated the hash table portion of my runtime but I definitely saw a performance gain from swapping this in for unordered map. Looking forward to google open sourcing their new implementation so I can put them head to head.
Sounds sexist. Ramperons.
How do pick apart the binary from the game server?
Thanks for Devstyle, I never heard of it before. 
There seems to be some miscommunication going on between us, but what would you call the functions provided e.g. by `windows.h` or `sys/...` on Linux? (I said OS API, not system call)
Actually, I can think of very few places where metaclasses allow you to replace existing or proposed standard text with code.
More resilience to these kinds of attacks simply requires more processing power on the server side for checking. This is an architectural problem that has nothing to do with the language.
Have you tried vcpkg or Conan?
Eclipse/Cevelop, mesosphere here I come.
You're right it doesn't play nicely with cmake, but not every project needs to be open source. At least that was much less a pain to configure automated builds and tests on MS servers with NuGet than with vcpckg.
Because they are used to them.
Sure it does. A language that offers memory corruption for free is harder to protect from such attacks, as proven by the regular updates of CVE exploits. https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=c%2B%2B https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=c A properly prepared network package is enough to p0wn the server.
That's what she said
People who like this should definitely watch https://www.youtube.com/watch?v=bAE0qteS4Rk from C++ Now 2018. For me personally, I very much like the direction of travel, but I don't feel it goes far enough to be worth the break from STL allocators. I'd go much, much further.
Do you have an example of how much further you would go? I was thinking about implementing some of Bob's containers as a refresher exercise for data structures, and certainly wouldn't mind hearing other design considerations.
There was SG14 discussion on this, best to link you to it. Read https://groups.google.com/a/isocpp.org/d/msg/sg14/qye9CnCquiI/A8wB3fLjAAAJ, and read downwards.
Are objects larger than `SIZE_MAX` allowed by the standard? Anyway, since according to the standard: 1. `calloc` allocates room for an array 2. size of an array has to be measurable using `sizeof` 3. `sizeof` cannot return more than `SIZE_MAX` then I'd say `calloc`-ing more than `SIZE_MAX` is not allowed, and therefore there will be no overflow when `malloc`-ing
Yes, there is a problem. It means the programmers are not thinking clearly.
Nothing about this challenge required Cpp.
It isn't (necessarily) bad. Consider that the decision to suspend at the initial suspend point is performed by the coroutine promise, which is determined by the coroutine type, and it's you (the writer of the coroutine) who choose the coroutine type. As long as the coroutine type documents whether it initially suspends or not, you should not be surprised by that. If you have a good reason to yield before the first suspend but the coroutine promise insists in suspending at the initial suspend point, then you are using the wrong coroutine type.
Rand is only bad if you actually need good randomness, and if you don't want global mutable state. If you don't care about these things, `rand` is fine. So for demonstration, one-off programs, for newbies, use rand. It isn't "deprecated", and it isn't going away anytime soon. It's just that there are more powerful libs now with more configuration options. If you think that extra power makes it too hard to use, and you don't really care what quality of randomness you get, then just use `rand`.
The saddest part is that the above makes sense to me.
That wouldn’t help much. Unsafe doesn’t turn the borrow checker off; it gives you access to unchecked types. Every interface that is safe only takes types that are safe, so you’d end up needing to convert before and after every single API call.
&gt; Would you want the output of this interface to be standardized and portable, or just the broad characteristics of the algorithm? The signature should be standardized, but the underlying algorithm should not matter. The output should be of relatively good quality, that is the sequence produced should be pass standard randomness tests, but there should be no need to guarantee it is "secure" in any sense of the word (for example, the seed could be the timestamp of the first call). &gt; Would you want to allow stdlib maintainers to change it at will, since no one will be using this unless they don't care too much about the details? Yes, definitely. Actually, to *enforce* that nobody relies on the specifics of the implementation, I would encourage the stdlib maintainers to mix any seed received with a different "pepper" in each new release of the stdlib. Instability that is not exercised is de-facto stability. 
I agree
That's pretty much how I feel as well. I'm a huge fan of CLion and when I have filed support tickets, the folks at JetBrains have been very responsive. But if you're on a super-tight budget, QtCreator is an excellent choice as well.
Such warning can be reactivated later on when they realize their mistake. Right now, we have nothing from the compiler and \(according to OP\) nothing yet from static analysis. Imho: having to acknowledge \(with a cast to void\) a released pointer isn't too much to ask for. If necessary, add it to W4 only, if possible.
&gt; I find the curly braces to be ugly Even worse than just *ugly*: horrible and superfluous in probably the most use cases. I'm sorry, but these *heavy syntax* proponents make me feel really sad ...
Not if the warning shows them how to tell the compiler that their real intention is to discard the return value. After all is only necessary to prepend (void). 
&gt; Did that get rejected? Yeah. Vote to encourage more work in that direction was 8|18|12|23|7. 
&gt; A benchmark would represent some usage pattern of the hash table. One might be "random"(*) strings coming in in a random order". Another might be "strings with a common prefix arriving in alphabetic order". Also, from the ones I use in my code : * pointers (32 and 64 bit) * {u,}int{8,16,32,64}_t, either random as generated by mt19937, purely incremental ("0, 1, 2, 3, ...") or mostly incremental (eg, "1, 2, 4, 5, 6, 8, 13, 14, 15, ...") * same for pairs of ints * string_view with string literals instead of std::string * uuids (stored as uint8_t arrays) 
I have to say, the architecture of your library is pretty neat.
Will put it in the queue, but don't we already have a hosted vs freestanding distinction in the standard?
I think this could work well for something like `vector_view` (which I've written before). I'm curious as to how the inner workings for other data structures might work out in the end... In fact, since the container can't allocate or deallocate, you'd end up with some pretty amazing iterator guarantees for the duration of the underlying engine, provided you never need to grow your container...
What exactly are you missing? Lower-level engine types? They do not really apply here, as there are no complicated data structures involved.
&gt;valuable face\-to\-face time that the committee leaders have at the formal gatherings is spent arguing semantic or grammatical details of papers rather than actually working on vision or hard problems Not that I disagree. Just wanted to point out that semantic and grammatical details can actually be really hard problems... especially if the thing is set in stone forever after.
Sure, let's make c++ syntax even more complicated ... This time even without adding any new functionality. Why do people always think any new feature has to be made as ugly as possible because - well it is new and people might misuse it if we don't print in large friendly letters "THIS IS NOT C++98 CODE"? In all seriousness if one is modifying coroutine code and doesn't know how they work, lifetime is just one of many issues he'll run into. Please don't uglify the language more than necessary. In the end it makes the code less concise, less readable and more, not less error prone.
'standards' to 'papers'. well done.
&gt; ethereal "support of C++ standards" That's a weird way to write "new C++ features actually work".
In addition to the other answers, gdb can be configured to become very elegant and pleasant to work with! Please have a look at: https://github.com/cyrus-and/gdb-dashboard This integrates perfectly with ConqueGDB plugin for vim (which is basically terminal inside vim)
Do you have any example by any chance? vim is so adaptable, this is what I like with it. I often find myself having to ssh and do actual C++ work remotely, on different computers (debugging mainly). With the proper vim config, vim can be pretty much self sufficient. If an external tool is missing: "git clone &amp;&amp; make" are usually enough to get everything back, without any extra fuss!
You've replaced allocators with a policy. Which is an improvement, but still a variation on the same theme. I'd eliminate any understanding of parent allocation at all. Just give the container an address range to use. That's it for its lifetime.
`.get()` is a universal symbol of abstraction leak
How do you express "optional Foo parameter"?
Well, they do that. Notably, the container doesn't store the memory block. It asks the policy for it when needed. So instead of giving it top-down as a function parameter, it is given bottom-up from the policy. (They do currently store a pointer to the end, but I plan on turning that into a size anyway)
Sure, but the policy becomes part of the type. I find any notion of the container type knowing anything about allocation undesirable. The container should manage a range of contiguous bytes, and that's all it needs to know.
Yes that sounds good. I am currently thinking that views are all you need, but I'm willing to be shown that I'm wrong.
I have to disagree. 80% of what I do in an IDE is read existing code and 20% actually editing. I'd rather have an IDE that understands my language and make it easier to read / follow definitions than one that allows me to rapidly edit. (I have no idea about QtCreator just talking purely about text editing IDEs).
With an `optional&lt;Foo&gt;` ? I'm confused about how this relates, so I'll guess. `optional` has `.value()` (and `*` and `has_value()` and explicit bool etc) not `.get()`. `optional` (FBOW) tries not to be an abstraction at all. It tries to be a `T`. So unwrapping it isn't considered _as much_ of an abstraction loss as `.get()`. That's the point - optional uses `.value()` because it is conceptually different than `.get()`.
And if Foo is non-copyable? Or too large to be copied? Or you want to be able to modify the Foo?
In my opinion all this whining that `void f(X x);` wouldn't look like a template is a clear case of “Doctor, Doctor it hurts if I apply pliers to my eyelids!” If people where professional they would simply follow the otherwise universally accepted rule for naming\-conventions “Do what the standard\-library does!”. If you have this really tiny amount of professionalism, nothing about the original syntax is in any way, shape or form ambiguous: `void f(X arg);` is obviously a template, sinc`e` X starts with a capital letter an`d void f(x arg`\); is clearly not a template. C\+\+11 broke `std::make_shared&lt;int, int&gt;(3,4)` because it was a moronic misuse of a language\-feature. The only way this change would be different is that old code would still work. In exchange we might however get closer to a point where you can use third\-party\-libraries without creating a huge mess in your code base from naming\-schemes that are all over the place.
&gt;Over that time I have found that it is almost impossible to get people to write consistent code in C++ [...] It leads to religious clashes between style tribes. [Using GoLang] In most cases there is really only one way to do something. I feel like you hit the crux of it - there is only one way to do something because those religious styles were built into the language. 
Line height is exactly the useful feature for reading text. 
To be fair, that could be cleaned up with the \*\_t and \*\_v variants. But yeah, our reflection facilities are abysmal.
Oh certainly. I meant there that those very important issues are just as easily discussed online. Especially since written text and examples are so important to those discussions, it often just involves a lot of after-hours writing or follow-up papers anyway (and if papers are only discussed at meetings, that means that turn around time on some of this stuff escalates from weeks to months).
Lol, of course, me too. What I meant is, people have it very easy using high-caliber software tools for free all the time. E.g. all the Google suite, python libraries, email, etc. Only for few services MOST people pay, Spotify, Netflix, etc. wouldn’t you agree?
Yes. At work we are still planning our switch to RHEL7 for later this year, which is the first Red Hat to come with a GCC that fully supports C\+\+11 \(4.8\). We still use CORBA, too.
In a program, sometimes you don't need to access a stack allocated object. While copying, you can reuse the resources of that object by moving it. This is called move semantics. This is mostly useless in application development, usually useful in library development(a very performance sensitive code). The part of the code is modified rarely throughout the application life cycle. This is written once and reused over again and again. Other than unique_ptr and thread object, you will never see it. C++ developers have nothing to do all day, they keep themselves busy by talking about move semantics.
No argument there (to be more precise: I've never been to a standards meeting so I don't know how extensive those discussions are). On the other hand I'm pretty sure, that many papers also get feedback outside of committee meetings
You touch upon the meaning of move semantics when you say that "you can reuse the resources of that object by moving it." You are incorrect about everything else. Move semantics is about ownership. When an object is the sole owner of a resource and it is copied, the newly constructed object must create its own copy of the resource. When the object being copied will not be used anymore, copying the resource is unnecessary. Here, move semantics come in; with the move constructor, the old object transfers ownership of the resource to the newly constructed object, a cheaper operation than copying the resource. Move semantics can have important performance implications; for example, it is the difference between deep copying a container and all the elements inside it and simply setting a pointer. I don't see how the application vs library distinction and the frequency of which code is modified is relevant at all to move semantics. Move semantics can as easily be applied to heap\-allocated objects as to stack\-allocated objects.
Shared ptrs or similar are also ubiquitous in applicative/functional data structures, where your actual data structure is immutable and "changing" it is really creating a new object. To do this efficiently, you *share* as much structure as you can between the old and new objects -- hence, shared ptr.
So the are masochists?
That's likely to handle any possible rethrows from `puts` inside the `catch` block.
I don't agree with this article at all. If you look into the standard library, most member functions that lower the level of abstraction are actually called differently. E.g. \`std::vector::data\(\), std::string::c\_str\(\), std::chrono::duration::count\(\), std::thread::native\_id ...\`. Second, calling get on a smart pointer doesn't leak anything, nor is it dangerous \(other than e.g. release\). It just says "give me a native pointer that points to the same object", which is \- in most cases \- a much more reasonable function parameter than smart\_pointer \(of course most of the time you should use references\)
I'd love to see him actually explain what he's talking about here. The only thing I can immediately think of is that substitution proceeds in lexical order since [core issue 1227](https://wg21.link/cwg1227), and constraints are similarly checked in lexical order. That only matters if a later substitution (or constraint check) would have triggered a hard error (see CWG1227's example), in which case it actually provides a portable way for you to short-circuit and avoid that. Hardly "a serious gotcha".
Almost 7 years later they finally have C++11 working. [And that's under a month ago.](https://blogs.msdn.microsoft.com/vcblog/2018/05/07/announcing-msvc-conforms-to-the-c-standard/) As an example of how terrible their support has been, back in 2015 I updated my MSVC compiler and basic [variadic templates](https://en.wikipedia.org/wiki/C%2B%2B11#Variadic_templates) that worked before the update stopped compiling. Example code from [Stroustrup's own website](http://www.stroustrup.com/C++11FAQ.html#variadic-templates) stopped working. Things have become a lot better in the last couple of years, but they still have a long way to go before most people think highly of their compiler.
Not op however; I use RTags and company with the Irony backend. It just werks. Evil mode as well
In my opinion just the fact that there is such a thing as different syntaxes which innocently look the same but apparently have a slightly different SFINAE effect, is bad. How is any intermediate\-level programmer going to grasp or even know about this? \(I count myself one of them\). Or is it not important for average\-joe to know this? Or is it? Who can tell me \- the 100 people in this world that go to an ISO C\+\+ meeting? Reminds me strongly of the other post about C\+\+ and the Vasa.
As proof, it goes away if you cheat and tell the compiler that puts can't throw (don't do it like this in real code) https://godbolt.org/g/v9bJd3 Sounds like a good bug to file with glibc. They should be using their nothrow attribute macro.
Does not belong in /r/cpp...
Sorry if I am misrepresenting the history here, I thought I had read somewhere that initially only expected was proposed initially, but that that outcome was a more powerful alternative that was brought up as a better alternative for standardization later after the discussions following the boost review of outcome. Please feel free to correct me obviously, seeing as you are the author I guess :+) Regardless, what I meant to illustrate was that if libraries where easier to use without standardizing them first, they both could be available in a dependency manager, and therefore hopefully see wider use before one of them (or an improved version of either) can be brought into the standard library (if it even was necessary at that point). Obviously the example is incredibly poor if they are both complementing parts of the same library, but that was what I meant to illustrate anyway. I am not that familiar with parts of the standard that were later deemed to have been so bad they needed to be replaced, or of parts that in hindsight were deemed detrimental to the language, but auto_ptr comes to mind. And also I guess shared_timed_mutex might have had a nicer name (and a nontimed companion) if they had had more time in the field as easy to use standalone libraries (if the article about how that name came around is correct anyway).
Looks great, but would be better as east const.
/r/cpp_questions is the right sub for these type of questions. Although I don’t really understand why you post a link to SOF with already tons of good answers.
just to share it. 
Can anyone provide a tl;dw?
What do those numbers mean?
For years now, the committee has been asking for more proposals. The community has delivered.
rvalue ref/move IMHO was by far the best feature in c++11. I saw a 15-20% across the board bump in performance *before* hand tuning some few classes with move constructors.
He gave this as a talk at cppcon, there should be a youtube video eventually. Also the code is here: https://github.com/skarupke/flat_hash_map
i've had serious problems with the default MS memory allocators in windows and it seems that post vs2013 it's more difficult to replace ms's default implementations short of repackaging ms's core libraries (I believe this is what chrome does).
c++ needs to adopt go's := syntax to cut out more typing /s
in general anything that can allocate (even surprising ones like stable_sort) or throw an exception is out. most of everything else is in
He was also on cppcast ep. 150 a few weeks ago. Pretty good interview.
Why does the commitee hate us
I don't think they _need_ to learn. Just like there are subtle differences between function declaration with or without trailing return type, but we don't need to learn too much details to program.
Can't wait for this, great lineup so far! 
What I really don't understand from Stroustrup's paper, is why he likes `template&lt;Arithmetic_value N&gt; void f();` but doesn't like `template&lt;Arithmetic auto N&gt; void f();` The second version is actually shorter \- why use a naming convention to solve something that can be expressed as part of the language with no extra verbosity? Stroustrup describes the 'auto' version as "ugly and redundant"; whereas what seems redundant to me is having to define a "value concept" for each "type concept". What if the author of the type concept didn't care to define the corresponding value concept, are you supposed to go into their namespace and add it in for your use? I think it's a shame that we didn't get a version of the "adjective syntax" paper which only proposed the "auto" part and not the "typename" part. The ambiguity between `template&lt;ConceptName TypeParam&gt;` and `template&lt;TypeName ValueParam&gt;` would remain, but I never found that a problem in the first place.
C\+\+ =\&gt; Confusion\+\+
&gt; Sorry if I am misrepresenting the history here, I thought I had read somewhere that initially only expected was proposed initially, but that that outcome was a more powerful alternative that was brought up as a better alternative for standardization later after the discussions following the boost review of outcome. &gt; Please feel free to correct me obviously, seeing as you are the author I guess :+) Outcome v1 was both simpler and more powerful than the Expected of 2016 or thereabouts. But there is coevolution going on here, as often happens with "competing" designs. Expected was heavily influenced by the first Boost peer review of Outcome, and the standards proposed edition thus became much more like Outcome. Outcome then pivoted around those Expected changes to propose something much bigger than Expected, a library-based implementation of a universal failure handling mechanism for C++, one where failures of any kind from any source can be integrated into a "one true system". Herb liked the look of that, and so he proposed direct C++ language support for the same feature. I've fleshed out his proposal with supporting proposals such as the draft `_Either` so we retain the universality of the mechanism. Between C++ 14 and C++ 23 (hoped), if you need lightweight deterministic exceptions now, Outcome is definitely the right choice, and it already integrates well with Expected and the proposed `std::error`. &gt; Regardless, what I meant to illustrate was that if libraries where easier to use without standardizing them first, they both could be available in a dependency manager, and therefore hopefully see wider use before one of them (or an improved version of either) can be brought into the standard library (if it even was necessary at that point). We do have an interim staging area before libraries go to standardisation. It's called Boost. Yes it is hard to get into. Many years of work. But it sorts the wheat from the chaff, and makes standardisation at WG21 much more efficient. Is there a need for an interim interim staging area before libraries go to Boost? I personally strongly think so. I'm very keen on a `cargo` for C++. I wrote a paper on its proposed design back in 2014 (https://arxiv.org/abs/1405.3323). Nobody liked my proposal at all, most on the committee roll their eyes when I bring it up, which is fair enough. But we'll see how Modules vs True Modules goes first. I still think my proposed design for True Modules will end up being a serious contender, because we all know it works, and by desperately trying to avoid it as we have until now, we'll end up making it inevitable. &gt; Edit: I came over outcome as a better alternative to optional when empty return is an error, and not just another valid state. I guess I should queue the outcome cppcast episode next http://cppcast.com/2017/05/niall-douglas/ Ah, that was a v1 feature. The review recommended it be dropped, so v2 doesn't have that any more.
The historical rationale is that all objects in C++ can have a unique address in memory, even zero sized ones. That design principle will weaken in C++ 20 a bit, but it fits that overall goal. Most `malloc()` implementations do in fact return a valid allocation for a zero sized request. It makes the job of writing compiler optimisers easier if you know that `malloc()` either returns a valid allocation, or a null pointer for failure.
Next time, you should mention the hosting nation in the title.
No. Just no. Having written Go for the past several years, and several years of C++ before that I can safely say that while Go and C++ has some shared domains, the languages are extremely different in their use. Go model relies heavily on a runtime, which is not a bad thing, but it REQUIRES runtime. Handling OOM in Go is just impossible, even handling how much memory it reserves from OS is extremely hard and not reliable. Some may say that Rust may be a solution, but I disagree. Mainly because they acquire new features with speed that by far outpaces C++. Hence the Vasa argument still stands. 
With all due respect, if JS community taught us anything, it's that "GitHub marketplace instead of standard library" aka npm, is utterly horrifying and bad thing. We need standard solutions - tho maybe not in current shape - in which we can rely, knowing that it will work in 5-10 and more years. 
by what optimizations do you lose by adding the except clause? If the only objects that can have non-unique pointers are zero-sized that still means that pointers are unique *or* can not modify `this` (without UB) I believe. 
My biggest issue with build2 (which holds me back from actually trying it) is the line-noisy DSL: libs = #import libs += libhello%lib{hello} exe{hello}: {hxx ixx txx cxx}{*} $libs testscript and : basics : $* 'World' &gt;'Hello, World!' : missing-name : $* 2&gt;&gt;EOE != 0 error: missing name EOE CMake (rightfully) gets a lot of criticism for its crappy DSL but frankly, this seems like a much steeper learning curve. I can't even begin to guess what these simple examples from the documentation do without extensive research. It's no coincidence that Python took over much of the space the Perl used to occupy. I'm curious what led to the decision to create a custom language instead of using something existing. And even then, creating something that is so different from the mainstream languages.
&gt; Also, what you describe is "how things are", but it doesn't clarify "why are things this way" or "why is it a good thing that things are this way". I said "It makes the job of writing compiler optimisers easier if you know that malloc() either returns a valid allocation, or a null pointer for failure.", which is correct. If the optimiser can assume that all calls to operator new return a unique address, it can assume that none of those addresses will alias. That in turn enables more aggressive optimisation. This has been the case right back to C++ 98. I believe C++ 14 enabled operator new folding, so a sequence of operator new calls can, in some circumstances, be replaced with a single underlying `malloc`. And C++ 17 enabled dynamic memory elision, so entire sequences of operator new, malloc etc can be folded, reordered, and eliminated. I am unaware of anything on the C++ 20 horizon changing this again, but there are papers in the works for C++ 23 which substantially make more aggressive the optimsations performed by default, specifically, that UB reinterpret casting will always produce non working binaries. All of that stemmed from the original C++ 98 decision to guarantee that operator new will never alias. That's because the committee folk of that time were well aware of the future potential improvements if they chose that decision, the fruit of which is coming to pass now.
I've spent quite a long time implement a fast hashmap myself, and creating one that performs better in practically all possible use cases is practically impossible. Some more things to consider for usage in a diverse environment: * what if your value is huge, slow to construct and can't be moved? * What if most cases only create an empty map and destroy it again? * What if calculating a hash is really slow? * Fill the map up, then remove all but one element. How fast can you iterate this? * What if each allocation is very expensive? * What if constructing the key/value is very slow? * Can you query a map with string keys with const char* without having to construct a string? 
I’m especially bummed that assert and GSL’s Expects and Ensures end up linking in some abomination that throws or sigabrts or whatever at the expense of kilobytes of precious memory.
I don't know why you are being downvoted. It does indeed sound extremely fucking pompous.
\&gt; Rewritten from scratch So why not call it build3? :P
\- In which was is this better than CMake or Meson? \- what should make me try it instead of the alternatives? \- why another weird language a\-la CMake instead of something more familiar? Or maybe I miss it and the familiarity part is familiar respect to something I know less.
Agree about the obscure DSL. I did not try the tool myself though \(workflow\-wise\). I think Meson is the only one to get this part right.
These are the essential building blocks of the syntax/semantics and, this being a simple example, is all that you see. Being essential, they should be terse since you will be repeating them over and over again. It's like replacing `{` and `}` in C++ with `begin` and `end` -- it will make C++ more accessible to someone new but is not something an experienced user would welcome. If you are interested, here is a pretty hairy buildfile from [`libmysqlclient`](https://git.build2.org/cgit/packaging/mysql/libmysqlclient/tree/mysql/buildfile) -- as you can see, it is quite a bit more verbose. &amp;nbsp; &gt; I'm curious what led to the decision to create a custom language instead of using something pre-existing. And even then, creating something that is so different from the mainstream languages. Initially, `build2` the build system started as "let's fix what's broken in GNU `make`". While `make` is getting a lot of flak these days, its design is fundamentally sound (and, as the saying goes, those who don't understand `make` are bound to reinvent it, poorly.). So we've started with the core, the `&lt;target&gt;: &lt;prerequsite&gt;' declaration, and danced from there. The resulting language is what I would call hybrid: its mostly declarative but supports `if`, `for` and (pure) functions. Anything more complex/elaborate will have to be implemented in C++ (this may sound crazy, but we are actually planning to allow you to embed C++ in your buildfiles).
&gt; for constrained templates, the working draft of C++2a permits at &gt; least these three different syntaxes, each of which has a slightly &gt; different SFINAE effect What the fuck is a "SFINAE effect"? Can we please please please (pretty please) stop enshrining a clever (albeit useful) hack as some kind of principle of C++ programming? Now that we're going to have concepts, maybe we can actually talk about these things using the right words: template constraints. The author is also totally wrong about this. I see no difference in the way those functions would be resolved. Deduction is the same, constraints are the same... where are the different "effects"? I see no effort made to explain that claim. You can safely ignore it. I might know a little something about this. I wrote the Concepts TS.
&gt; - In which way is this better than CMake or Meson? [How is this better than CMake (or Meson)?](https://build2.org/faq.xhtml#cmake) &gt; - what should make me try it instead of the alternatives? A sense of wonder? Seriously, though, why not take a look at the introduction and a few examples? If you still prefer your existing build toolchain, that's totally fine. &gt; why another weird language a-la CMake See this [earlier reply](https://www.reddit.com/r/cpp/comments/8n7su6/build2_070_released_cargolike_integrated_c_build/dztho65/).
Oh, misunderstood it.
Automated install scripts and a better introduction were both sorely needed. Now I can actually try this thing out without having to feel like it's just a big hassle!
Why not use something like TOML for the build file? Does the build file really need to be that elaborated?
&gt; It's like replacing { and } in C++ with begin and end -- it will make C++ more accessible to someone new but is not something an experienced user would welcome. I don't agree with this statement. C++ is designed for million lines of code codebases. Thus being concise can help. However your buildfile, even if they are verbose (not DRY, just verbose), they should still be short. And anyway your argument of `begin`/`end` vs braces isn't valid, because if you take a language like ruby, you have something extremely readable, concise, witch is using the `end` keyword. I think that their is two think in the argumentation. The first is reducing the number of token needed to express something to make it more compact without losing readability that you got right. The second is to use symbol instead of words for the token. This reduce even more the apparent verbosity, but if the symbols are not used in a standard way, they dramatically decrease the readability. Unfortunately I don't have a good proposition (I lake experience with build2, and I would already have done it otherwise). They only think that I could propose is to replace `exe{hello}: {hxx ixx txx cxx}{*} $libs testscript` by `executable{hello}: {hxx ixx txx cxx}{*} $libs testscript` The `exe` keyword could still be recognized (for prototyping), but shouldn't be used for big project. It's the same idea with vimscript's `ts` vs `tabstop`, `au` vs `autocommand`, … For the unit test, it could be ``` : basics : 'World' : output = 'Hello, World!' : missing-name : '' : status != 0 error = { error: missing name : } : long-input : file-input 'Robin' : input = { Greetings, dear visitor! : } : output = { Greetings, dear visitor! Your name is Robin. : } ``` It is nearly as concise, but much easy to read in my opinion. I did not an extensive investigation, but I think you can get the general idea.
&gt; how does this detect any dependencies and is fast? I don't think I understand the question. `build2` is a well-integrated native build system and a dependency manager. Maybe checking the introduction/example will clarify this? &gt; In my opinion [wildcard patterns], this is a mistake [...] I thought so too until I tried them. We kept forgetting to list headers in our buildfiles. While the local builds worked fine (the files were there), once distributed, they no longer compiled. This hasn't happened once since we switched. These days I hardly ever even edit buildfiles. It's like the build system doesn't exist (which is, accidentally or not, the experience you get using Rust or Go). But in the end, with `build2` it is your choice -- if you prefer, you can spell everything out explicitly. &gt; How it would be even better? If you change a comment or adjust a whitespace in a source file, is Meson smart enough to recognize this and skip recompiling it? &gt; Meson is not just a build system either, it has wrapdb for dependency management [...] So I do not think this makes it, at least, better than Meson, but I could be wrong. I could also be wrong here, but I don't think wrapdb is quite comparable to `build2`. There is no versioning, constraint resolution, upgrade/downgrade management, support for central/archive-based repositories (in addition to version control-based), etc. 
Gamedev here too, and having tried build2's alpha in small tests I think it have major potential in our typical case. Just one thing among others: because it's based on the task graph idea behind make, it is possible that in the future build even the game resource baking with the build system but in a "natural" or "uniform" way. There are other advantages, you'll probably be able to infer them once you go through the new intro and try to setup your ideal workflow in a test project.
&gt; Does the build file really need to be that elaborated? It doesn't need to *per se*, but no matter how hard you try, in the real world you sometimes end up with something like I linked above. I leave converting to TOML as an exercise to the reader ;-).
Neutral side note: I find interesting that it's the terseness of keywords you find problematic more than anything else.
I am still of the opinion that one day when refactoring someone leaves code around and gets compiled into the executable \(wildcards\). I would issue at least a warning that you are using them every time someone uses the tool or it can go unnoticed. \&gt; If you change a comment or adjust a whitespace in a source file, is Meson smart enough to recognize this and skip recompiling it? I do not think so, but I can say Meson is pretty fast and also supports Rust \(I do not care for now\), C, D \(I care\) and Fortran :\) \&gt; I could also be wrong here, but I don't think wrapdb is quite comparable to \&gt; There is no versioning, constraint resolution... Well, you can choose which wrap to install and everything gets compiled, and I saw sometimes there are wraps for several versions. That should be enough. Anyway, your system seems more full\-featured, but, has that been tested in any real\-world projects? I think it is quite difficult to get right. And my last question: how is MSVC support? Is it supported already? Thanks for your time!
\&gt; I am still of the opinion that one day when refactoring someone leaves code around and gets compiled into the executable \(wildcards\). Could you clarify what kind of problem this would cause? Sorry, I might be missing some use case. So far I assume that if I modify a project to add a source file, it's an advantage \(because it appear intuitive\) if it is taken into account by the build system without me having to understand the build system, in particular when I have to work in other's project. Am I missing something?
So why does aliasing matter for zero-sized types?
&gt; You are welcome and I am glad we could keep this civil ;-) With me it is always like this :)
&gt; Your proposal does not satisfy all requirements. It misses the big one: My proposal was to remove that requirement.
&gt; If zero sized allocations could share addresses, the pistcondition "new returns a distinct address" would either be false, or require "except" clauses. We already have wording specific for allocations of zero-size.
&gt; It's like replacing { and } in C++ with begin and end I feel like that is not an apt comparison, although the line-noisy nature is part of the problem. The file you linked looks similarly obscure to someone not familiar with the build2 language. &gt; &lt;target&gt;: &lt;prerequisite&gt; Yes, that is very apparent, however, there are so many syntax elements added on top of this that makes learning the language and maintaining build2 scripts is a serious barrier to entry. &gt; supports if, for and (pure) functions Looking the history of other build systems it's very apparent that a multiplatform build system that supports cross-compiling requires a full imperative language. CMake (the language) sucks because it started out as a configuration file and then had all the control flow statements and data structures shoved in as an afterthought. And it seems that build2 evolved some of these constructs already. I know, in some cases the declarative nature of make-esque scripts work perfectly well and I do see their elegance. But I also know that there is no way in my current job we could even come close to supporting ~8 toolchains and 16 target architectures with different dependencies in some cases if we were to use a similar system. This is build logic and obscuring it just makes it worse. It doesn't help that make has fallen out of favor so a new hiree would have to be trained extensively instead of being able to guess what the build script does. &gt; this may sound crazy, but we are actually planning to allow you to embed C++ in your buildfiles It does sound crazy, why wouldn't you support a scripting language instead that is better suited for text processing / os tasks out-of-box than C++? 
I think premake is also worth a mention here. It is a Lua script.
&gt; I don't know why you are hung up on zero sized types. The question (see title) is about zero-sized allocations, which are explicitly allowed by the two C++98 `operator new`s quoted in the question. 
Thanks! I'll have to see for myself in production. As @berium pointed, the grabing syntax is not mandatory so I guess it's a team choice. At least having a relyable grabing syntax helps a lot when packaging other's code into build2 \(in my experience at least\). I cannot say the same for CMake \^\^;
Personally I think is like GOTO: it should be avoided and only used as a last resource to cover some niche scenario. 
Exactly! This is all one needs to know (until C++20). Any object is at least of size 1 byte.
&gt; Exactly! This is all one needs to know (until C++20). Any object is at least of size 1 byte. 
\&gt; Which scripting \(or not\) language is better suited for "os tasks" that is *portable and reliable* and doesn't require the user to install and, more importantly, maintain another "system" \(like Python, Java, MSYS2, etc., all would\)? You can embed Lua or Python without requiring the user to install it separately.
Also, you rightfully pointed out that "os tasks" is a bit blurry, but I couldn't find a better word for it; what I meant is tasks that are typical for shell scripts: moving files around, creating directories, parsing text files etc. C\+\+ is not very well suited for this without external libraries.
`operator new` always creates an object in the C++ memory model. `malloc()` returns something currently undefined, but I believe in C++ 23 they hope that it returns a `void *` to an array of `std::byte` objects. `operator new[]` always creates an array of objects, though that array can be zero sized. This is the only way, that I am aware of, that a zero sized allocation can occur. Note that in the C++ memory model, a zero sized array of type `T` is very different to a zero sized type. Zero sized types don't exist in C++ before C++ 20. Zero sized arrays do.
Please have a look at the OpenCV documentation page. You'll see the beauty of Doxygen.
Lua ok but Python is a difficult beast to embed.
Not that hard, really. https://github.com/pybind/pybind11
&gt; You can embed Python I see people repeating this "Python is easy to embed" statement but those that actually try it in a non-trivial projects seems to find otherwise. Check, for example, [Mercurial's Oxidation Plan](https://www.mercurial-scm.org/wiki/OxidationPlan) and make sure to scroll down "CRT Mismatch on Windows" horror show. &amp;nbsp; &gt; You can embed Lua I will admit I am not familiar with Lua (as, I suspect, are the majority of C++ developers) but, (and I may sound arrogant here) somehow I doubt it Lua can pull off half of the things we can do in [`libbutl`](https://github.com/build2/libbutl) (our utility library), especially on Windows. Things like emulation of directory symlinks with junctions. Or automatic process restart for MSYS2-based binaries to workaround the cygheap issue. 
Unfortunately, there's hardly any interesting news concerning C++ in this release. Xcode used to be great for C++ development, but Apple has clearly shifted most of its efforts towards Swift. Long standing issues such as the debugger misreporting the values of variables with binaries compiled using sanitizers have yet to be fixed.
&gt; I will admit I am not familiar with Lua \(as, I suspect, are the majority of C\+\+ developers\) but Just so you know: game developers having worked with C++ engines (or making them) are generally familiar with Lua. It's so lightweight (I worked on games embedding it on NintendoDS, see it's specs to be impressed) and simple to embed (copy paste + LuaBind or Sol2) that it's probably the only embedded scripting language that you might see in console (so, constrained) game code (even in some AAA). This is less true since Unity became popular for all kinds of console gamedev too (it uses C# as "scripting" language), but it's still true if you consider just gamedevs working with C++. It is indeed far less known to other C++ devs. (For non-extreme situations I prefer to consider ChaiScript.)
Good question. Currently you will need to email a git repo url and tag you want to published (e.g., `https://git.build2.org/hello/libhello.git#v1.0.0`) and we will publish it for you (or you can provide a package archive if you prefer). For the next version we plan to implement a CI/CD bot which will poll you git repository for tagged versions and automatically test and publish them to `cppget.org` (there will be some sort of a `control` file that you will be able to use to specify which tags should be published where, etc). And wouldn't that be the nirvana -- all you will need to do to have your package in a central repository is tag it?
&gt; They are just C++'s version of malloc, only, of course, defined with different semantics for some reason. For example, C malloc can return the same ptr value for all zero-sized allocations, No, C malloc does *undefined behaviour* when asked for a zero sized allocation. Returning the same pointer value would be a violation of the attribute that most malloc's are marked with which tell the compiler this function already returns unaliased memory. As I mentioned before, I cannot think of a commercial `malloc` implementation which doesn't pretend a zero input is actually 1 byte. &gt; The arrays that you dynamically allocate using operator new[] with a length of 0 cannot have a size of zero because C++ does not support zero-sized arrays: https://godbolt.org/g/hGF7Tu 
&gt; No, C malloc does undefined behaviour when asked for a zero sized allocation This is also incorrect, the behavior is implementation defined. Citing the original post: &gt; The C11 standard says about malloc (7.20.3 Memory management functions): &gt; &gt;&gt; If the size of the space requested is zero, the behavior is implementation defined: either a null pointer is returned, or the behavior is as if the size were some nonzero value, except that the returned pointer shall not be used to access an object. &gt; &gt; Which means either malloc returns null which should be interpreted as the allocation failed, or malloc should have the same behavior as if the size wasn't zero, which then again means that two zero-sized allocations via malloc that succeed must return two different pointer addresses (because that's what they would do if the size passed wouldn't have been zero). &gt; https://godbolt.org/g/hGF7Tu That's a non-conforming extension, and therefore, not C++.
&gt; I could also be wrong here, but I don't think wrapdb is quite comparable to build2. As the creator of both Meson and WrapDB, let me clarify a few things. &gt; There is no versioning Yes there is. All entries in WrapDB have a version number. You can have them in your own projects if you wish, even for Git repos. &gt; [no] constraint resolution True. Currently it needs to be done manually. &gt; upgrade/downgrade management Upgrade is there (`meson wrap update subprojname`). Downgrade is not. &gt; support for central/archive-based repositories (in addition to version control-based) The entire point of WrapDB is to have archive based repositories. They have been supported for years. In addition Meson's dependency provider is already being used in production in several large codebases. [Here is a sample video showing how it works with GTK.](https://www.youtube.com/watch?v=2dB80CjH_3Q)
Non-goals: "Not providing runtime-sized containers" : i'm sad about that. From what i understand with some fixes to allocator concepts we could easily have standard pooled allocator for vectors and already proposed dynarray / bs_array would be real handy as well. Compiler vendors, please implement -fno-heap and -fno-floating-point to complement -fno-exceptions and -fno-rtti to make all this easier.
&gt; We do have an interim staging area before libraries go to standardisation. It's called Boost. &gt; &gt; Yes it is hard to get into. Many years of work. But it sorts the wheat from the chaff, and makes standardisation at WG21 much more efficient. Which is great, but one of the problems I had with boost early in my career was that since we didn't use any dependency manager yet, and boost is as unique, if not even more, with regards to integrating it into our projects, I personally disregarded it as I perceived it to be easier to write small utility classes that covered exactly my use case, than to find out how to integrate boost in a good, sustainable* way in our project to use one of the small, basic, but more powerful boost alternatives, alternatives that I did not have any experience with using, or did not even know about, at the time. I was a newbie, with features to finish, and not in a particularly c++ savvy environment, and I think that might be the case for a lot of people programming c++. I think maybe that is sometimes forgotten by the experts who draft the standards, makes boost and are part of the groups prioritizing what should be included and not. There are many reasons for why python and javascript has become so popular these last years, but I'm pretty sure that one of the larger ones are how easy it is to compose new systems by simply reusing existing libraries using the available package managers. And AFAIK one of them has it standardized (pip for python), while javascript has multiple (npm, bower, yarn), and both I believe thrive in large part due to how much and how easy developers are able to re-use the vast amount of libraries that exists for the languages (some of them properly vetted and well designed, like boost; but also less vetted ones, that nonetheless solves problems they have) &gt; Is there a need for an interim interim staging area before libraries go to Boost? I personally strongly think so. I'm very keen on a cargo for C++. I wrote a paper on its proposed design back in 2014 (https://arxiv.org/abs/1405.3323). Nobody liked my proposal at all, most on the committee roll their eyes when I bring it up, which is fair enough. But we'll see how Modules vs True Modules goes first. I still think my proposed design for True Modules will end up being a serious contender, because we all know it works, and by desperately trying to avoid it as we have until now, we'll end up making it inevitable. I'm not necessarily talking about just a system for staging libraries which authors hope to standardize over time, I mean a system for _all_ libraries, as long as someone is willing to share them. And I'm not familiar with modules vs true modules, but IMO although I would love to get modules in c++, I do not think it is a prerequisite for having sane(r), easier to use, semantically versioned dependency management. I have to say though, I read the abstract, and a bit of the motivation in the proposal you linked, and I had a really hard time understanding that it was about dependency management at all, but I am not an academic, nor used to reading draft proposals, so maybe thats just me (the same way I have a hard time reading EULAS in lawyer language). &gt; Ah, that was a v1 feature. The review recommended it be dropped, so v2 doesn't have that any more. I had a look at the [github version]((https://ned14.github.io/outcome/reference/outcome/)) of the library, and I still think it is an improvement on our use of optionals most places where empty state is indicative of an error. I guess I do not know what you mean by "that was a v1 feature". * meaning no copy-paste into VCS, easy to upgrade to new versions, cross-platform, and not having to re-invent the wheel by having to basically re-integrate the library for every new project and boost version
I have nothing relevant to add other than OMG YAY somebody else knows about sol2! &lt;3
&gt; I personally disregarded it as I perceived it to be easier to write small utility classes that covered exactly my use case, than to find out how to integrate boost in a good, sustainable way That's by far the most common use case for Boost: as a study aid for writing local editions of Boost code. And that's okay, as a learning/crib sheet it's served its purpose and then some. &gt; I was a newbie, with features to finish, and not in a particularly c++ savvy environment, and I think that might be the case for a lot of people programming c++. I think maybe that is sometimes forgotten by the experts who draft the standards, makes boost and are part of the groups prioritizing what should be included and not. It's not forgotten. Deprioritised, maybe. You have to remember that until recently, direct use of open source code was forbidden in most corporations. Many still ban, specifically, large chunks of Boost. That has had the consequence of some Boost library authors not prioritising, as perhaps they should in the eyes of some, the ease of use. As I mentioned, I'm all for a C++ `cargo` precisely to fix this situation. &gt; There are many reasons for why python and javascript has become so popular these last years, but I'm pretty sure that one of the larger ones are how easy it is to compose new systems by simply reusing existing libraries using the available package managers. And AFAIK one of them has it standardized (pip for python), while javascript has multiple (npm, bower, yarn), and both I believe thrive in large part due to how much and how easy developers are able to re-use the vast amount of libraries that exists for the languages (some of them properly vetted and well designed, like boost; but also less vetted ones, that nonetheless solves problems they have) I hear you. You may not be aware of one of my projects designed precisely for web page packaging up of libraries ready for drop into a C++ project, just like Javascript libraries: https://pypi.org/project/pcpp/ &gt; I'm not necessarily talking about just a system for staging libraries which authors hope to standardize over time, I mean a system for all libraries, as long as someone is willing to share them. I was thinking of a pypi for C++ personally. A repository of prebuilt libraries with source, public *and* private, for every C++ library on the planet, all in one place. The private mention is how such a site would be funded. &gt; And I'm not familiar with modules vs true modules, but IMO although I would love to get modules in c++, I do not think it is a prerequisite for having sane(r), easier to use, semantically versioned dependency management. It's not about that. It's about ABI management and ODR violation. We need True Modules with a formal ABI layer if such a repository is going to be viable. &gt; I have to say though, I read the abstract, and a bit of the motivation in the proposal you linked, and I had a really hard time understanding that it was about dependency management at all, but I am not an academic, nor used to reading draft proposals, so maybe thats just me (the same way I have a hard time reading EULAS in lawyer language). It was aimed at the typical crowd attending BoostCon 2014. Sorry. If you persevere through the paper, it should become clear what I propose by the end. &gt; I had a look at the github version of the library, and I still think it is an improvement on our use of optionals most places where empty state is indicative of an error. I guess I do not know what you mean by "that was a v1 feature". Outcome v2 has no empty state. &gt; We now use cmake hunter, as it contains the libraries we need, has a concept of versioning of libraries and is very easy to use (from cmake anyway). If I am to use a library that is not yet supported by hunter, I'll probably just invest the time it takes to submit a version upstream to hunter itself, instead of trying to put it in-source in our VCS, that way anyone else can re-use the library and suggest improvements or patches (like we have already done for libraries in hunter), and maybe even end up fixing issues we didn't know we had with the library. &gt; &gt; Boost is also supported BTW, which is how we have integrated boost into our project =) Yeah I really need to get to finishing the cmake install support in my own projects. As always, other priorities ... 
Try jucipp
To me it happens the same: the DSL made a big difference. Not because of the language itself. When I was using CMake I had to fight the DSL, especially these things: - condition handling NOT, *_FOUND suffixes. Will NOT blablab_FOUND will work? It was really terrible and I cannot do it yet from the top off my head without hesitating - escape sequence handling when using custom commands... a lot of fun to say the least - cross compilation was incomplete (even in Meson in a couple of things) But look at that last point, cross compilation: I could customize the missing parts quickly in Meson, why? Because the DSL made sense so I could do a few things quickly. This kind of thing is much more work in CMake. I mean that, when CMake does not handle your case correctly, good luck with those macros, functions and weird stuff. With Meson, in theory you cannot, but you just plug a script and done, and scripts are well defined on how to use. Most of what you need is already anticipated, like variables for source and build dir, etc. So you do not start to try to guess and do weird things, you just write a script and done. You do not waste your time trying to do in a weird language what a script will do better. It looks like nothing, but these things can amount to a ton of hours. When I came to Meson I was skeptical about its non-turing completeness and so on... now I am convinced that with meson.build + meson_options.txt + subprojects *always in the same places* things have a well-thought structure. If I want more, I go down to scripting. It works very well. 
Amongst other things, it's a huge boon for generic code (be that template code or just otherwise abstracted algorithms). Special cases like zero or `void` cause a lot of problems when the bowels of generic systems have to work around them. This can happen even in C. e.g., allocations of arrays for zero elements, where that 0 is coming in after a number of calculations from the original inputs. Generic code might consider a `NULL` result to indicate an error, but the empty array in such cases may well be perfectly valid for the domain. It's just "easier" if all the code can continue using `!= NULL` checks to look for errors and without having to add all the special case paths for element count of zero.
No but it would imply building a python implementation as part of building Build2 (assuming that python implementation works with your dev platform...). Then depending on the implementation focus/properties, it might imply either use a python executable (aka not what I would call "embedded") or a library. Then there is the work to bind stuffs which is not automatic. This is heavy work. We were comparing with Lua, where you can basically copy paste the source in your project (or make a library), compilation is a breath, cross-platform support is maximal (it does not access the system api by default) and binding is made easy by libs like Sol2. Still work but clearly Lua is designed to be embedded and it shows when you actually try to do so. Thats not the case of Python. However it is super useful to bind C++ functions to python. This is where the pointed library shines.
Is that debugger bug in lldb itself, or is it in the Xcode GUI wrapper around lldb?
I figure it's more "likely to be a corner-case exercised by some template code (i.e., not written by hand) and we want code written for positive-sized objects to be as likely as possible to do the right thing when objects are zero-sized." Seems fair to me.
Do you actually have to allocate memory? It's not like the returned pointer will actually be read or written to, right? That would have to require some undefined behaviour. So really you could just have a fancy counter ("fancy" because the counter has to respect alignment), so long as you knew the counter wouldn't overlap with "real" memory locations somehow.
Definitely not more difficult than embedding c++.
Actually, on Linux (which is what Compiler Explorer uses for the stdlib) `puts` is a possible posix thread cancellation point, and thread cancellation is implemented by throwing a value of type `abi::__forced_unwind`, so `puts` can throw.
Ruby... Readable ? Wtf, the language is a mess of magic keyboards
&gt;&gt; In my opinion [wildcard patterns], this is a mistake [...] &gt; I thought so too until I tried them. We kept forgetting to list headers in our buildfiles. While the local builds worked fine (the files were there), once distributed, they no longer compiled. This hasn't happened once since we switched. That's weird. My experience is exactly the opposite. When you use wildcards, people forget to add new source files to version control (in large change sets). That results in a build that works locally, but is broken when checked out into a clean workspace.
Ugh, I always forget about pthread cancellation. What a terrible misfeature. I could even see it almost being usable if they didn't make `close()` a cancellation point.
&gt; That design principle will weaken in C++ 20 a bit, .... Could you explain this? (Or link to an explanation.)
It could be compared, though...
`[[no_unique_address]]`
Well, YMMV I guess. I find `get()` on smart pointers worth checking in code reviews.
Because you typically don't want it to be implicit. In particular, from your example: makeResevation(seat, film); makeResevation(film, seat); ie any old code still using ints, that hasn't converted to the strong types, is in danger of a mistake. Or things like `seat + film` etc. Which does seem unlikely, but maybe `price * seat` when you meant `price * seats`, etc.
Argh! takes a less verbose approach to cli parsing. Very suitable for small projects. Single header, C++11 and the minimalistest of all: https://github.com/adishavit/argh CLI Parsing: An Embarrassment of Riches. 
Cool! A word from the master :-) I'd really like to hear the blog post author's (Arthur O’Dwyer) comments on this, he's not exactly an unknown in the C++ world either. 
Thanks.
That makes sense, but any non `NULL` value would achieve that without having to make each address unique (which is what C does).
This seems like a moot point. `[[no_unique_address]]` can only be applied to data members of a class, so there is still no scenario where a call `new T` will call operator new with a size argument equal to 0. The only scenario this is possible in would be `new T[0]` (or a compiler extension to allow size 0 classes). I can’t think of a scenario where one would need to do that, so why even concern yourself with it? Are you arguing this should be explicitly disallowed?
&gt; Essentially a brand new toolchain, with new tooling, new workflow, and new documentation. A relaunch, if you will. This part sounds confusing then: &gt;Essentially a brand new toolchain, with new tooling, new workflow, and new documentation. A relaunch, if you will. 
&gt; Do you actually have to allocate memory? Well, per the wording in the std, you have to obtain a memory address that is unique, and not in use by any other live allocation. Also, until you free it, no future allocation should be able to use that address either. Allocating one byte of memory is probably the simplest way of guaranteeing all that. The downside is that, as you've realized, you have to allocate memory to satisfy a zero-sizes allocation.
&gt; so why even concern yourself with it? Note that I am asking about the overloads of `operator new` that return raw memory, they don't deal with types.
Using one magic address for all "empty" allocations is still a potential problem for generic code. Said code would then have to know about that special case if it ever compares two addresses, e.g. for a cache key or something. I don't know if that's at all _why_ C++ behaves as it does, but I personally think it's probably the better _default_ behavior.
&gt; a memory address that is unique, and not in use by any other live allocation Yeah, but it could just be some really big random number, right? Though I suppose there might not be enough of those, depending on the size of your address space.
&gt; Using one magic address for all "empty" allocations It can't be the same address for all empty allocations because of alignment. &gt; e.g. for a cache key or something I don't follow this argument thoroughly. Zero-sized types have, in general, one value (it's like `struct A {};` whose only value is `A{}`) [0], so if you use a zero-sized type as a cache key, and take an address to it, even if the addresses are different, the values of both keys are equal. [0] the exception are uninhabited types (sum types of with zero variants, bottom, etc.). 
As long as the guarantees are satisfied, it can be any valid address you want. The problem is that to satisfy this guarantees, this magic counter would need to be part of your memory allocator somehow.
Yes, but those overloads are still invoked by calling `operator new` to construct an object. So this statement: new (args...) T; roughly translates to a function call: operator new(sizeof(T), args...); So unless someone is directly invoking operator new with a size of zero (and then the question “why?” still applies), there are few scenarios where the requested memory is 0 bytes.
&gt; so why even concern yourself with it? Are you arguing this should be explicitly disallowed? Also for the "why" I am asking, well I haven't had to touch my last ISO paper much since January that much, so now that I had forces for another want I was thinking about zeros-zied types and whether `[[no_unique_address]]` could be extended to be used in other places.
Better link directly to the release notes - more useful than a generic link to the "News" site. https://developer.apple.com/library/content/releasenotes/DeveloperTools/RN-Xcode/Chapters/Introduction.html I'm not 100% sure this link is accessible without logging in as developer though. It seems like AppleClang got a minor update in this release. Most things, particularly C++17, optional and variant, are still broken though. Too sad.
This question is inappropriate for this subreddit and should be removed.
bug reports and questions are off topic try /r/cpp_questions instead
Ok, you have generic code that alocates raw bytes. I’m still having trouble imagining a scenario where that generic code calculates 0 bytes. Maybe an example? Regardless, I don’t understand why you’re so concerned. You aren’t doing anything useful with a 0 byte allocation; you can’t by definition. The performance of the actual new call is moot: since all the work you’re doing before the new call is wasted, why worry about what the standard library does under the hood?
Hey, I'm planning on using sol2 on my upcoming project! That benchmark post sold me on it (and made me aware of it).
Changing exe to executable does nothing for me. The name was the only part of that command I understood without explanation.
&gt; I don’t understand why you’re so concerned. I wasn't concerned. I just asked for the rationale about the current design. The only thing I am concerned is about the reactions of the community to the question. AFAICT I asked nicely =/ &gt; Maybe an example? The [C99 Rationale V5.10 document](http://www.open-std.org/jtc1/sc22/wg14/www/C99RationaleV5.10.pdf) has rationale on why `malloc` supports zero-sized allocation (section 7.20) and an example (you can just replace `malloc` in every example on the internet about it with `operator new`): &gt;The treatment of null pointers and zero-length allocation requests in the definition of these functions was in part guided by a desire to support this paradigm: &gt; ```c &gt; OBJ * p; // pointer to a variable list of OBJs &gt; /* initial allocation */ &gt; p = (OBJ *) calloc(0, sizeof(OBJ)); &gt; /* ... */ &gt; /* reallocations until size settles */ &gt; while(1) { &gt; p = (OBJ *) realloc((void *)p, c * sizeof(OBJ)); &gt; /* change value of c or break out of loop */ &gt; } &gt; ``` &gt;This coding style, not necessarily endorsed by the Committee, is reported to be in widespread use. &gt; &gt; Some implementations have returned non-null values for allocation requests of zero bytes. Although this strategy has the theoretical advantage of distinguishing between “nothing” and “zero” (an unallocated pointer vs. a pointer to zero-length space), it has the more compelling theoretical disadvantage of requiring the concept of a zero-length object. Since such objects cannot be declared, the only way they could come into existence would be through such allocation requests. &gt; &gt; The C89 Committee decided not to accept the idea of zero-length objects. The allocation functions may therefore return a null pointer for an allocation request of zero bytes 
&gt; To me a nameless get is almost always an anti-pattern. Hmm, and maybe that's the point. Can we use the anti-pattern for good? When I see .get() used on the strong type, it's questionable. ie maybe (in this case) the function isn't the anti-pattern (because it is sometimes needed) but its _use_ is (often) an anti-pattern. So use an anti-pattern name to highlight an anti-pattern. Maybe.
I meant an example where you allocate 0 bytes. I’ve never had code reach a state where it was allocating no memory. Also, the example you gave hinges on `realloc`, which has no analog in C++, so it doesn’t really apply here
The third line of that example allocates zero bytes.
You were talking about `operator new` though. `operator new` corresponds to `malloc` and `delete` corresponds to `free`. There’s no analog for `realloc` though. Aside from the one example that uses `realloc`, can you give a practical situation where one might allocate 0 bytes?
&gt; All you say makes sense to me for allocations of non-zero size, but I don't understand how any of it applies to allocations of zero-size (which is the only types of allocations I am asking about). Because you either disallow zero-size allocations, or make them consistent with the non-zero ones.
I've seen new programmers do that, and not realize why it's a bad idea.
With 64 bits, it'd be trivial to give a on purpose non valid value (it will crash if dereferenced) that is unique (using a thread local counter) and easily identifiable so `delete` will just ignore it.
I'd use the word "focused" instead of "slow". 
it's a meta-discussion and it's important to keep things headed in the right direction. 
Will the inner namespace `ranges` be dropped if Ranges TS is merged into C++ standard?
QBS also did a very good job with it's specification language.
I think the C++ standard should adopt a package manager already. I've seen a new build tool for C/C++ at least once a year now. Even if it doesn't 100% work with every project, it would at least be a starting point for people to contribute. My only concern is whether it might not play well with the lack of a module system. 
No. See [http://open\-std.org/JTC1/SC22/WG21/docs/papers/2018/p0896r1.pdf](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0896r1.pdf) for the current merge details.
Basically, CLion was stuck with CMake until recently. To open it to new build systems, they decouple CMake from CLion and add some build systems such as Gradle C\+\+. However, they can't support all build systems \(there are plenty of them\), and even if plug\-ins are created, custom build systems might still be unsupported. A good solution is therefore to offer a generic way to indicate project files to CLion, as well as related informations \(such as include directories and compilation options\). Compilation Database offer that: a description of the project \(by listing all files and their build command\) in a standard format that can be easily produced and used. Developers can then just set the option in their build system \(if it supports this format\), or use wrapper on their machine \(for *make* for example\), to create the database, which can then be loaded in CLion. CLion will therefore be able to work with any build system giving that this file is produced \(either by the Build System, the compiler, or a wrapper/intermediate tool\). PS: compilation info are required to index correctly the code \(to provide navigation, completion, refactoring, ...\) and offer an IDE experience. That's why they used CMake at first, which uses a well\-defined format to describe the project in opposite to Make which uses a very \(too\) flexible description of the project, hardly understandable by the IDE.
Australia 
Nice API but what about using boost beast instead of rewriting HTTP bits? 
Good catch! It was released before Boost.Beast which was included in version 1.66 I just added issue to this repo to add Boost.Beast support , hopefully it will land nicely as conditional CMake build ? This library is currently used by boost users &lt; 1.66 , so the old features will be left alone and Boost.Beast possibly added. Still researching ... 
 #ifdef STL_UNIQUE_PTR_NODISCARD_ON_RELEASE [[nodiscard]] #endif T* release(); I'll gladly enable an optional warning like this on my code. People who don't want to don't have to.
Ah yes good catch, I've didn't check the first commit of your repository. Nice work 🙂
I really love this thread, everyone cherry picking each other comments to show that they are the smartest people in the room! Doing anything to avoid understanding each other, the whole opposite of those boring Rustaceans! This is fun! My turn! That C example is a pattern, so it’s not one example, but many, like a Legion, do you C? Operator new(sizeof(T) * len) allocates raw memory for an array of len Ts, if len is zero, then you run into a raw allocation call of zero length. Capichi? I know you are really asking “but how can len be zero”! I know right? Where do bugs come from? What’s does memory smell like? Maybe we’ll never know! Unless your size_t (proper type knowledge bonus) traps on zero, it can become zero somehow, cosmic rays! So when your mind widens enough to get that, then the raw operator new is the right way to do that in C++, because the array based version (new T[len]) introduces object lifetimes and what not, so if you just want raw memory to then, use placement new on, then that’s pretty much all you can use. “But what about xyzrtus initialization?” Lame move, don’t do that. When do you need raw memory for arrays without creating any object you might ask? Well all the time! Variant! Networking, containers, etc. basically everywhere you would use aligned_storage for (c how smart I am? I STL dude!), but where the size needs to be dynamic. So aligned_storage is like the non existent array types of zero length, and operator new(size) is like dynamic arrays of runtime length, but rawww, like baby piglets. So bringt it on wizards! Give me your best shit! I won’t read your comments and don’t care, but this thread isn’t as funny as the other involving Ned, so I don’t mind if it burns! Peace out. 
I have and use all of these, but when you say work-flow that it provides i'm not sure what you mean. I may be missing something a 5 year old would get but could you run me through your workflow please?
Since that's so compiler-specific, you might as well just code your own unique_ptr... It's rather straightforward and small. I personally am not going to spend that much energy on an error that was cause by _one_ person _one_ time writing the wrong function.
To keep backward compatibility with older version?
Run a Win10 VM on linux. Or docker it.
I think it works well for a while now. Rust compiler and Clang are examples of front ends that work on windows. You can configure CLion so it uses Clang on windows.
Too bad. Tutus Winter's paper recently advocated for 1 level namespaces hope it will get some traction.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8nh1u1/c_masters_of_reddit_i_need_your_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
And we've got a more horrible one: `std::filesystem`
I agree, it's why I started with &gt; Unfortunately I don't have a good proposition 
&gt; I will admit I am not familiar with Lua (as, I suspect, are the majority of C++ developers) but, (and I may sound arrogant here) somehow I doubt it Lua can pull off half of the things we can do in libbutl (our utility library), especially on Windows. How does libbutl relate back to the buildfile language syntax/semantics? That's what people are suggesting Lua for.
You can pass `--driver-mode=cl` to clang and enable MSVC style flags. The support is somewhat new, so occasional bugs are to be expected. Besides that, if you're using MSVC STL, clang can even compile chrome.
Visual Studio, haven’t found anything better.
Another great post. Very simple for how effective it looks. I've used some of these tricks before but putting it together like this is particularly nice. 
Agree.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8nhlgp/can_someone_help_me_with_a_quick_coding_problem_i/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt;Sending "which IDE do you use?" to StackOverflow oh dear
Automatic message
The point I was trying to get at was that if you make a call `operator new(sizeof(T) * len)` where `len == 0`, then you have a big in your code. You shouldn’t be worrying about how new is going to handle a 0 length allocation, you should be trying to figure out how to return early when `len == 0` so you never get to the allocation at all.
I think you can debug linter issue using the :ALEInfo and debug commands, at leat ALEInfo will tell you which linter is failing. Here is my config for ALE: &gt;!let g:ale_cpp_gcc_options = '$(cat ~/.compiler_options)' "Options can be easily retrieved using 'bear' (github) let g:ale_cpp_clang_options = '$(cat ~/.compiler_options)' "Options can be easily retrieved using 'bear' (github) let g:ale_cpp_clangtidy_options = '$(cat ~/.compiler_options)' let g:ale_echo_msg_error_str = 'Error' let g:ale_echo_msg_warning_str = 'Warning' let g:ale_echo_msg_format = '[%linter%]%s[%severity%]'!&lt; So, yes you can hide your config away from your .vimrc! The key thing here is that you can actually execute your own script to parse the generated compiler option (instead of cat), or be lazy as me and share the same compilation option in one unique file filled manually by reverse engineering the compiler_option.json. Personally, I only need to update it a very few time. It would be great to have something automatic though, maybe a combination of "bear" + shell scripts? 
This is awesome. We use maven at work and I have to use a mess of cmake custom targets and custom commands to get everything to play nicely with CLion. Hopefully this now means I can just run the maven build with Bear and load the compilation db in CLion. 
What is your name?
Could you explain how persistent memory affects C++ semantics? I’m at a loss for any specific places I’d need to be aware of memory lifetime outside of application execution. From the way you explained it, it sounds transparent to most CPU’s never mind languages. It sounds very interesting though! Perhaps my imagination just needs a kick start.
Do nothing and use libraries. It would be ignorant to make changes at a language level for such new and unproven tech. Even Intel is still figuring out where it can be used, which is why they're throwing it at every problem they can find. We'll see in 5 years if this stuff actually holds up and becomes a common thing.
Cool, thanks for the feedback.
Interestingly enough committee members got aware of it too and submitted [P1005](http://wg21.link/p1005r0). There they propose to add a namespace alias so it gets shortened to std::fs. While certainly an improvement I would still prefer one level namespace only. The document even mentions people are used to do namespace fs = std::filesystem;
Should be working this way. Please let us know about the success (or any issues).
I forgot a big one: memory transactions. Hardware memory transactions on Intel CPUs work exactly as you'd expect on persistent memory, and let you update multiple locations on persistent storage in an all-or-nothing, completely atomic, memory transaction. Which is head wrecking in the potential applications.
Let the OS handle it? I don't need to adjust my code to account for differences in spinning disks vs. solid state drives. I don't need to adjust my code for ECC vs. non ECC RAM. I'd rather not adjust my code for this. The value of this hardware will be significantly higher if it can just be a drop in replacement, rather than require lots of code to be rewritten.
People may find a CppCon 2017 talk about Intel's PMDK useful to watch: https://www.youtube.com/watch?v=mn42HgAjDug I can give you my personal opinion on Intel's PMDK. It's fundamentally a C library, with C++ bindings, and my nicest way of putting it would be "C++ STL allocator hacks" which are used to make the STL containers somewhat work on a persistent memory backing. It's full of UB and I see all sorts of corner case quirks keep emerging, which isn't surprising as STL implementations weren't designed for this, and arguably STL containers can't work right if you want them fast on persistent memory. All that said, it's the closest thing to a C++ library with comprehensive support for this stuff, and its implementation is well worth studying for techniques. I am not keen on the public API design though, I find it un-STL.
I think for desktops and servers, this is a valid argument. The kernel will automatically recognise persistent memory storage, and stop using a kernel page cache etc. So you'll see benefits across the board, and by doing nothing. But for embedded systems - which are highly likely to use all persistent RAM very early on given the power advantages - I think you need language support if you're going to make full use of this technology. Of course, on embedded systems you can just call the CPU opcodes directly to persist cachelines, because UB on an embedded system is usually well defined for that specific system and toolset. But I find that, personally speaking, a bit underwhelming, and quite non-portable.
Looks like JonCaves fixed the "pack expansion into initializer\_list fails" bug in 15.8.
I think HTM is virtually a requirement for persistent objects, not just a nice-to-have. Otherwise, you'd need OS-level mutexes, etc. to sync across processes -- and then what happens if the holder of the mutex dies?
You are right that the C++ standard library has no standard way of creating shared memory. I propose such a mechanism in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1031r0.pdf, and we'll see how that fares. If you watch that CppCon 2017 talk by Intel, you'll see that STL allocators are completely unfit for this purpose. You'll hear Alasdair constantly asking questions about UB corner cases, and I believe he's right: you cannot make current STL containers works safely with persistent memory without completely breaking existing code. I *currently* believe that persistent memory algorithms are *usually* also concurrency safe. They are, however, not as efficient as algorithms designed solely for safety under concurrency. So, put another way: Racy (normal memory) =&gt; Lockfree (atomics, necessary for safe shared memory usage) =&gt; Interruption safe (???, necessary for safe persistent memory usage) *If* we built out a suite of persistent memory safe containers along the lines of Intel's PMDK containers, I currently believe that said containers could be placed into shared memory and they'd "just work". So, you'd get interprocess containers as well as persistent memory containers. I do want to stress that I don't think that said persistent memory containers would be as efficient in the shared memory role as those from Boost.Interprocess, but they would likely be very comparable. I'd imagine there would be some template parameters you could adjust to tell the persistent memory container not to worry about persistence, and only worry about concurrency. The optimiser would hopefully reduce the implementation to something more optimal than otherwise.
I don't believe ARM will be implementing HTM anytime soon, and given that ARM CPUs will probably be on persistent memory before most Intel CPUs, I think we'll have to assume no HTM. Lack of HTM is workable. You just need to carefully order your modifications, flushing to main memory in between each one. For example, https://www.usenix.org/system/files/conference/fast18/fast18-hwang.pdf implements a persistent memory B* tree without HTM, though I daresay if one had HTM one could do a more efficient algorithm.
That's an interesting paper but I'm skeptical that one counter-example is enough to show that HTM is not a general requirement.
I think you are focusing to closely on the low level implementation of this technology. Almost the same answer /u/ben_craig gave should apply for embedded systems. This is an API/driver implementation detail for that specific embedded hardware, not something that would matter at the C++ language level. I want these bytes at this address to be flushed to PRAM, I call a driver API function, it does whatever ARM cortex magic is required to make that happen... That magic could be inline assembler, hardware register bit twiddling whatever. C++ doesnt and shouldnt need to accommodate those implementation details.
My initial thought is that C++ could already benefit from libraries that offer memory control that has been available in operating systems for years. Things like: - memory mapping of files - de-fragmenting the virtual memory of a process (is that possible?) - allocating GPU memory (is that possible/useful in any pragmatic way?) - structure for other memory types like the high bandwidth memory that was part of Xeon Phi or the on chip GPU memory that was part of broadwell CPUs and may be part of integrated CPU / GPU combinations. While these all seem like exotic features to me (with the exception of memory mapping files) I think some underlying structure for different memory types might be a good place to start. On the flip side, thinking of it as a fast disk instead of 'slow' memory might be another way to go, but I'm not sure that would really change much from the programming side. This leaves the question of memory that is persistent (and maybe that is the only question anyone is really asking). My first thought is that typical data structures that aren't contiguous or serialized are going to be fragmented in memory. This leads me to think that maybe a place to start is with suspending and serializing processes, since their virtual memory space is a dividing line that makes them individual units. This might mean work would have to be done in suspending and reviving resources, but at the same time, this isn't necessarily new territory either, since a process should be able to have it's memory written to a file already and a 'faster disk' wouldn't really change that. __TL;DR__ being able to memory map files, suspend processes, and choose memory types through allocations might be the fundamental controls that are missing. 
If you look at how one would implement a persistent vector without hardware memory transactions, and retaining contiguous storage of the elements, it's a *very* different algorithm. Specifically, you need to additionally store a recovery index which lets you figure out when an insertion or removal was interrupted. This is sufficiently different I don't think it could be called a vector anymore, maybe `persistent_vector`. I also don't think the contiguous storage is worth that overhead personally, so I'd actually go for a `persistent_deque` which is far more performant because you can store the recovery index alongside each item, and keep each chunk of the storage in their own 4Kb page, which makes such a `persistent_deque` just as useful on page cached spinning rust storage as on persistent memory. And I find that a far better value add than targeting containers just at persistent memory. All that said, such containers are years away, likely C++ 26 or later. We would need persistent memory in the MacBook Pro - which is what most on WG21 use -- before you'd get committee buy in for anything past a persistent B* tree. And that's probably 2020-2021 before Apple would ship that.
HTM makes your life vastly easier. But one can design around the lack of it, and as I mentioned, I am unaware that ARM will be implementing HTM anytime soon, so we're going to have to get used to designing around the lack of it.
What is ultimately the problem that needs to be solved on an embedded system? If the memory is persistent, wouldn't the program just persist its execution between power being on and off? 
Even on hardware and on operating systems of the past twenty years, you can work at RAM speeds with an in-memory cached copy of some data elsewhere, and push the problem onto the kernel to get that cached copy to somewhere non-volatile. If you align yourself to the page size, tell the kernel the ordering of which pages need to be written in which order, you can get excellent performance. What I just described is, after all, a modern database. Most of what you asked for falls under heterogeneous compute. Michael Wong is the big champion of that. He'd know a lot more about it than I, but my understanding is that he's been part of building out reference library implementations for the features you asked for. I've seen blog posts on it, anyway.
Do you think it would be possible to have a wrapper, like atomic? Also, does recovery sounds somewhat like transactional memory, how would that play into it?
It depends. If you pull the power randomly, because the CPU caches evict caches lines unordered, you would be unlikely to have a consistent state when power returns. If you marked all memory as writethrough, you'd then have to be careful to always order things in an interruption safe ordering which is a big ask for a whole system. Controlled power off though is easy, just flush all the CPU caches, halt the CPU. Same as suspend on current systems.
What is the difference in accounting for persistence as opposed to concurrency? In my mind if atomic operations on shared memory are possible, then that should take care of both, since the atomic operation won't be interrupted and succeed.
I hope you make a new post about your updates then, I am interested in your results!
I'll be under a strict NDA, unable to tell anybody a thing. Sorry :(
Damn :( Is there anything that you can tell us though? For example, if you were happy with it, excited, etc, or is it completely forbidden to say anything?
Technically, a process might suddenly exit right in the middle of a sequence of atomic operations. For most algorithms in Boost.Interprocess, that means all other users of the shared memory tend to hang. Persistent algorithms are interruption safe, so you can interrupt at any moment, and all other concurrent users, as well as users after a power restore, recover from the inconsistent storage. As you can see, this is a stronger form of lockfree programming than ordinary lockfree. It requires you to be lock free no matter any form of arbitrary interruption. These tend to be even less efficient to implement than ordinary lockfree or waitfree algorithms, but they have (obviously) the very strongest of progression guarantees.
What is the importance of having a "connection_manager". Is it so you can close all connections? It seems unnecessary.
Fair enough. I think the concept of a static variable that can persist across executions is an interesting thought experiment. Something akin to a private heap that is backed by persistent storage. I have dealt with something along those lines using memory mapped files in the past. 
With transactional memory i mostly was throwing around stuff i haven't looked into much right now. Anyways, you were talking\(writing\) about the need of a recovery index and that does sound adjacent to transactional memory where either nothing or everything happens. Power outage seems like an extreme scenario and first of all the OS would need to have persistant knowledge of those pages. Which now does sound like an egg\-hen scenario.
&gt; it should be avoided and only used as a last resource to cover some niche scenario. 
In the middle of a sequence of atomic operations or in the middle of a single atomic operation? If there is an atomic compare and swap, can an interrupt happen that breaks its guarantees? 
Can I ask for a refinement on this? Do you prefer third party libraries, or *standard* libraries?
Is cutting power in an uncontrolled way while also not having some sort of error checking system really a reasonable requirement? I would think a tiny battery or even a capacitor, let alone a more controlled power down could be built in to have a negligible delay in power cycling. How are these things dealt with already? 
Transactions are a bit orthogonal to recovery. You can avoid the need in some algorithms for a recovery index if you have true hardware transactions. But for portability, recovery indexes or atomically swapped last-known-good-state are hard to avoid. I *believe* Linux has implemented tracking of all pages with potentially dirty cache lines, and thus can flush itself into a persisted state very quickly.
In the middle of a sequence of atomic operations. At the persisted level, the atomic unit is the cache line, so in theory an aligned AVX\-512 non\-temporal store should be atomic and persistent.
If your entire embedded OS were correctly ordered in all operations, it should be entirely possible to pull and restore power arbitrarily. You can see the attraction for say solar powered devices without any battery. There are research embedded operating systems which already implement this, and without persistent memory. http://www.capros.org/ is one such example.
I'm having trouble understanding the role of persistent data outside of file storage. I don't see how we could use it for internal data structures: our applications are not persistent, and each application, as it goes through various versions, already struggles to keep its external data structures in a state it will itself understand. For example, try loading an ancient MS Word file in modern Word. It might work - or it might not. Similarly, I've had plenty of applications crash on me over the years (including, occasionally, some that I didn't write myself). It would have been disastrous for the industry as a whole if each crash not only wiped out the running copy, but had the potential to also wipe out all data generated in that application simply because it is all persistent and you don't 'save' anymore. All of this points to a situation in which 'persistence' is something best approached through iron-clad mechanisms - like, for example, a file system. Or maybe it just points to the fact that I lack vision, who knows. As I see it that leaves us with three levels of usage: 1. Applications function as they do today, but all memory is persistent. If power is lost, no problems, the applications will just continue where it left of when you get back online. 'Saving' is still a thing, and ultimately all data is copied into some kind of file system or it risks getting wiped out by a crash or an upgrade. For this no particular language support is needed. 2. Persistent memory is simply another resource. Applications can specifically request allocation in persistent memory, and take responsibility for what happens in there. Application upgrades and crashes may wipe out that memory, unless the application is really careful. This is potentially the most interesting area for research, I believe: C++ currently has no pretty method for allocating memory from specific pools (other than placement-new, which I think is just ugly). No doubt people have been researching this already, but I imagine some kind of syntax like this might be possible: auto intptr = new int in persistent_pool; (it's a mystery to me why pools are not already first-class citizens in C++. They would be massively useful for all sorts of stuff, including heterogenous memory support, cache-friendly allocation, cheap freeing of large numbers of POD objects, limiting RAM budget for specific tasks, etc.) 3. Persistent memory is simply a very fast harddisk. Access is granted through the file system. No special language support is needed. I think (1) and (3) will come to us automatically, as a courtesy of operating system development. But (2) holds potential on the language level: at the very least we want a mechanism to semi-transparently allocate from persistent memory, and preferably in a way that's not as much like pulling teeth as the current allocator / placement new mechanisms are. Of course persistence demands OS support, so it is likely that (2) would ultimately be supported through memory mapped files, implemented through (3). 
Hi. Well, English are argued to be the language with the largest number of word and expressions, and not being a native speaker, probably I get wrong the definition of the "work-flow", sorry. What I mean is that with Vim, these plug-ins and some configurations, I'm very comfortable with the dynamic, efficiency and "fluidity" that Vim provides.
For at least Linux and Windows, the kernel will already automatically take advantage of persistent memory backed storage by eliminating a lot of work (mainly memory copying and page faulting) that it would otherwise do behind the scenes. I would also expect that persistent memory could be used as a fast durable write cache, so for example ZFS can be configured with a special fast device for writes which are asynchronously written out to slow storage in the background. So I'm gathering that you feel that C++ can safely ignore persistent memory for now?
No wish for persistent algorithms then, ones which can guarantee that your program's data structures will survive all sudden power loss or sudden process exit?
not op, but probably both. Let 3rd parties try it and then make a stdlib with hindsight.
I think so, I can't see how I would make use of specific controls for it, only how it could be used to speed up memory mapping + flushing the memory map cached pages, and I can't think of how that would change the way a program is written much if at all.
In practice programs will still be restarted constantly to get back to a known good state and because of new versions being released.
Do you know what I would need to do to give feedback on this proposal? I haven't participated before in the standardization process but I have some feedback on this -- they are currently going to miss some major use cases with their type requirements.
Of P0593? I believe you should send feedback to Richard Smith, as Ville has moved onto other responsibilities. I know it didn't get a new revision for Rapperswil, but last time I discussed relevant topics Richard pointed me at that paper, so I think it is still in active consideration. I suspect you'll see a big push on it after C\+\+ 20 has been laid to rest in its embalmed form.
The new CMake generators look great! Much less intrusive to the project's CMakeLists.txt
Thanks for your question ! The server registeres signal handlers for **SIGINT,SIGTERM,SIGQUIT** for graceful shutdown and the handler for shutdown makes a call to manager managing the connections. connection_manager_.stop_all(); [server::do_await_stop()]( https://github.com/venediktov/CRUD/blob/c5c90d176c5e5a6a71d007b2dea99de808122c20/service/server.hpp#L112) 
Citing Conan's Slack channel: The purpose of this feature is to automatically lock a particular package version to a git commit hash/revision/tag, without having to encode that revision/hash/tag into your recipe manually. You can simply point to the github repository you want without specifying a version/revision/hash/tag etc. But, once you've started working on that recipe, and tried to do `conan create` for the first time (specifically, once conan has called your `source()` method for the first time), it records whatever version/revision/hash/tag it received (which was the default at that moment), and will always target that hash for subsequent runs on the same machine. Then, when you upload to a remote repository, that information goes along with it as well. This attempts to introduce a a more native and automatic form of "reproduceable builds" by giving you "reproduceable sources" ... which we already had, but needed to specify the revision in the recipe.
I couldn't have said it better.
I haven't heard of this. How does it compare to other package managers? 
`copy`. `remove`. The latter is particularly egregious because of the `int std::remove(const char*);` we have from C, so we'd have // hypothetical std::path p = "foo.bar"; std::remove(p); // true if successful, false if doesn't exist, exception on error std::remove("foo.bar"); // 0 if successful, nonzero on failure And you'd likely need to rename things like `status`, `equivalent`, `canonical`, `absolute`, `relative`, `space`, etc., since it's pretty unclear what they do without the namespace.
The role of atomics is mainly to force ordering, or rather, to prevent the compiler reordering or eliding any of a sequence of carefully ordered writes. But otherwise yes, usually one must persist where one is in the process of changing something, such that it can be resumed after interruption.
Ok, thanks for the feedback!
Would this look like an allocator that is aware of persistence? Probably not easy to make this work nicely with stl.
Well yes, of course, if that's an option. But a sudden process exit will almost always be caused by some kind of corruption in the data, and how are you going to correct that? That's not a problem I think can easily be solved. Right now we solve it by restarting the application and reloading data from the file system. A huge amount of research has gone into ensuring no corruption occurs within the file system, and arguably we have a special class of applications (database engines) whose primary task is to ensure data is saved in such a way that it is guaranteed to be still there, later. The question then, in my mind, is not so much what special persistent algorithm support we need, but rather how we can deal with the inevitable corruptions our failing software will occasionally produce - assuming of course that we want persistent memory to be something more than a filesystem-like storage facility. 
There is also a short blog post summarizing the release: [https://blog.conan.io/2018/05/30/New\-conan\-release\-1\-4.html](https://blog.conan.io/2018/05/30/New-conan-release-1-4.html)
I'd say the main differences are: \- Build system agnostic, can manage different build systems natively, and cross build to arbitrary targets. It is also multi\-platform, is used in production by companies in Windows, Linux, OSX, FreeBSD, Solaris SunOS, etc. \- Management of binaries, can create, upload to servers and reuse any number of different binaries for different platforms, configurations and variants \- Decentralized architecture, with conan repositories in Artifactory, a universal repository for all types of packages \(npm, maven, docker, bower, pypi...\)
Not all languages are curly brace languages, scripting languages in particular often opt for something else. (see python, ruby, bash, and obviously lua) Also in a language not dealing with pointers, it technically doesn't make sense to view an index as a offset from the first element, unless you really, really love modulo. In scripting languages it's more of a trade-off between confusing either normal people or programmers. I'd prefer indices starting with 0 to, but for most applications you'd use lua for, you luckily rarely need to access array elements via indices
There are 2 places to put a package recipe: \- External to the source repo. In this case, the recipe will typically have a \`\`source\(\)\`\` method that will execute a \`\`git clone\`\` in it. This case can use the new SCM feature to declaratively define the repo and revision/commit to be cloned. A simplification over the \`\`source\(\)\`\` method. \- Package recipe inside the source repo. Conan can take snapshots of the source code via the \`\`exports\_sources\`\` feature, which copies the source code inside the package recipe for full reproducibility. But it is impossible to define the commit in the recipe, because doing so will alter the recipe which in turn changes the repo and would require another commit. The SCM feature allows to declare the revision \`\`auto\`\`, so changes can be commited, and the commit will be captured automatically by conan when the package is created. In principle using git submodules is a way of managing dependencies, kind of orthogonal to conan or other package managers. Using conan you might not need submodules anymore, the SCM feature is mainly for improving the workflows and reproducibility of builds while keeping the package recipes lightweight and safe \(not storing a copy of the source in them\)
Actually, I don't think data corruption causes most sudden process exits. I think loss of known good state does, and the automatic calling of `std::terminate()` by C++ is currently looking to rise in frequency very considerably from C++ 23 onwards. Contracts, logic errors, OOM, all are possibly ending in sudden process termination if recent WG21 papers come to pass. Most filesystems are actually pretty lousy at not corrupting your data. See https://danluu.com/filesystem-errors/, and feel afraid after you've read it. The only good news is that things are slightly better today than ten years ago. Some filesystems do take your data seriously. ZFS is better than most. I run ZFS on all my POSIX systems for the past decade. I disagree about focusing on corruptions first. I fundamentally distrust the kernel and filing system, I assume that they always lie about everything to do with data persistence. Remember a conforming POSIX implementation can treat `write()` as a no-op, either some or all of the time. Algorithms are what can save us. Assume that every second bit you write to the filesystem will be corrupted, or worse. Build your algorithms to handle that. Now you can build actually reliable software, because the filesystem isn't able to subvert you any more.
Um, having to add catches for `bad_alloc` and then differentiating _which_ alloc was "bad" is literally the definition of a special case. :)
Persistent memory might be a security risk if implemented badly. Now when a process is created it is reallocated at a different memory address to prevent some attack vectors (and probably other reasons). How can you access persistent memory if your task is not allocated at the same address each time? 
New memory returned to you by the kernel is zeroed, same as now.
Trying out conan. I want to use the [{fmt}](https://bintray.com/bincrafters/public-conan/fmt%3Abincrafters) and [Qt](https://bintray.com/bincrafters/public-conan/Qt%3Abincrafters). What should my `conanfile.txt` look like for a Linux dev environment? I'm having trouble filling up the `[requires]`, the bintray links don't seem to mention it. 
I know, I don't approve of this dogma of never using it but it is there.
&gt; Contracts, logic errors, OOM, all are possibly ending in sudden process termination if recent WG21 papers come to pass. But that means that something has already gone wrong in the program, and the state of the program is already corrupted (I think this is what /u/johannes1971 meant: logical rather than physical corruption). So there is not much sense in trying to preserve this state in the hope to resume the application later.
If you pick a specific version on those bintray pages the resulting page will have a "Reference" field with a string you can copy-paste directly into the requires section of the conanfile.txt.
Qt/5.11@bincrafters/stable fmt/5.0.0@bincrafters/stable On the bintray page, if you click on a specific version it will take you to a new page where the bottom line of the left column is "reference" which is the line you need to add to the conanfile
Non-volatile RAM is nothing new, one of the first C embedded systems I worked on had only NVRAM , which was used for working memory as well as storage. Incidentally the manufacturer collapsed because they couldn't compete on price with other devices that used a mix of cheap RAM and Flash. I don't recall the exact details now, but I think the way the OS set up was that certain address ranges would be marked as "don't reset on startup" , and we could assign variables to that address range via a source code extension. Then we could either just work directly in those variables, or (to support adding struct members in future). memcpy in and out of it with some primitive serialization. I'm sure people can come up with much better idioms nowdays though :) 
Eventually standard libraries, but only when there is enough experience in the field to be confident about what to standardize. Eventually, I assume there will be OS primitives that will need to be considered. We use OS primitives for naming the byte streams that we currently use for persistent storage. (i.e. files, filesystems, etc., on disks and flash SSD.) and the C++ standard library does a good job of exposing the OS file primitive operations (open, close, read, write, ...) as fstreams and such. (And only annoyingly recently the filesystem ones!) Until the OS is providing useful functionality to expose, rushing to implement language level features seems like the wrong order of operations. For example, absolutely don't want a filesystem implementation that looks like FAT32 baked into the libstdc++. But we do want the std::filesystem functionality that let's us traverse whatever filesystem implementation the OS uses. Getting the wrong level of abstraction into std:: for persistent memory would be like standardising a FAT32 implementation rather than the stuff in std::filesystem. It may also make it needlessly difficult to interoperate with persistent data stored from other languages, etc.
I believe it's the binaries that do it, but Conan downloads Boost incredibly quickly. It takes less than 5 minutes, whereas vcpkg and Hunter both took 30 mins to an hour.
Heh yeah. I guess it can break unity builds
I'm thinking along these lines. For most users, the OS handling it works the best. Most people will need no more than maybe 8 gigs of RAM, especially if your OS and page file are on a decent SSD. The large RAM parts and having optimizations would be very specialized applications. I'm thinking applications like massive video editing, heavy Photoshop work, audio tracking, compiler machines, possibly 3d rendering, etc. This would be best as a library The only thing I can think of maybe is some sort of persistence mechanism that's not tied to any technology. Linux has .conf files, Windows has the registry, and Mac has .plist files. Then again, you can piss people off and you can easily run into situations like the gigantic Excel files we keep hearing about. If you don't have this persistent memory, it's pretty easy to emulate
I wonder if this will lead to more people using a serialization format like Cap'n'proto. It can be mmap()ed just like a struct but it is explicitly designed to last longer than a process. 
Write a persistent storage library. In my field, we have to do this as part of regulatory requirements for power failure cases. The system needs to resume correctly, so storing data quickly and efficiently is very important. [I think this talk by Bob Steagall](https://www.youtube.com/watch?v=FPUBjPYBsGI) is a pretty good start. [He has a similar topic from CPPNow](https://www.youtube.com/watch?v=Uwe2gXNMeG4) that you need to check out if you want your mind blow with C++ black magic.
As a Linux C++ guy, I'd expect to be able to explicitly map persistent memory into my process's address space much as I do with shared memory or a memory-mapped file. Persistent memory is a hardware feature, not a computational or abstraction feature.
I want C++ to focus on facilitating third-party libraries to do cool stuff. I think there should be standardized c++ library collections which are independent from the core language and designed/developed/released on their own schedule. I don't want to lose out on things like concepts/reflection/etc because people are arguing about what should go into a graphics library. 
The `cmake_paths` generator looks nice. This means it can build cmake with just using a conanfile.txt and no special conan commands in the cmake. The `cmake_find_package` generator is just a bad idea. Its just guessing the usage requirements which can be wrong. And its hides the real the problem that the library doesn't provide usage requirements for its user(its not the package manager's job to provide usage requirements).
What effect would persistent memory have on efforts to standardize a C++ ABI that rears its head from time to time?
Thank you 
Fully agree with you, I'll just add this one here ;) http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0977r0.pdf which is quite recent. 
I did run a few tests and one thing that annoyed me is that solution analysis is not kept automatically after shutdown. For our solution it takes a long time so it would be great if it could start where it was left the last time. 
&gt;Actually, I don't think data corruption causes most sudden process exits. I think loss of known good state does "loss of known good state" is what I call data corruption. I'm not arguing that most errors are the result of cosmic rays striking memory bits, that would be silly. And yes, I know filesystems are lousy at not corrupting data. The really scary thing is that they are the best we have! Which is sort of my point: I don't think we are ready to unleash persistent memory on the world, not as a fundamentally new concept. I think it will always need to be backed by a more reliable, more _persistent_ layer that must necessarily be something like a filesystem, so you do at least have some hope of restoring once the inevitable problems begin. But where does that leave persistent memory? As a fail-safe for power loss? I'm sure that's useful for a few people, but it's been 15 years since I last saw a machine fail as a result of power loss (when, ironically, the UPS it was connected to burst into flames, in the middle of the cleanroom. There was general unhappiness all around, but at least nobody argued it was a software problem). And even if you manage to recover the internal state of the program, how will you recover the external state? All the connections it had open, all the I'm still very much in favor of having some kind of memory pooling mechanism in the language. I'm also very strongly in favor of not killing applications simply because an allocation in one of our many memory pools failed; in fact, constraining the amount of RAM used by certain subsystems would be a major reason for having memory pools, and that makes allocation failure a much more likely prospect. But ok, that's another discussion...
What's the workflow if you make a change that changes the compilation db? For example, adding a file.
I haven’t tried and it’s not specified but I think it’s automatically detected.
For hardware transactional memory implementation to be useful for persistent memory, the CPU caches need to be persistent or flush on failure (this is an ACPI property for custom systems, see the platform capabilities table 5.2.25.9: http://www.uefi.org/sites/default/files/resources/ACPI%206_2_A_Sept29.pdf). This is not a given on future platforms, not to mention that existing HTM implementations have size limitations that make a fallback option a must. And to answer your question: ` $ man 3 pthread_mutex_lock` &gt; If mutex is a robust mutex and the process containing the owning thread &gt; terminated while holding the mutex lock, a call to pthread_mutex_lock() &gt; shall return the error value [EOWNERDEAD]. 
The real value of persistent memory is in treating it as memory that does not go away, not as ultra fast storage. To facilitate faster adoption, just like you pointed out, operating systems have been enabled to transparently take advantage of pmem (https://www.kernel.org/doc/Documentation/filesystems/dax.txt). But to fully take advantage of the unique properties of persistent memory applications will *have to* be modified. This will probably first materialize in modifications to database engines (as an example: https://blogs.msdn.microsoft.com/bobsql/2016/11/08/how-it-works-it-just-runs-faster-non-volatile-memory-sql-server-tail-of-log-caching-on-nvdimm/) and other performance sensitive software, so that regular backend services will indirectly benefit from pmem just by using something else that was optimized. As it stands right now, there's simply no standard-compliant way to use persistent memory in C++, and Niall's current efforts are trying to address that. And we are not talking here about some new huge disruptive changes, but rather about the very basics: clarifying the language around shared memory, lifetimes (http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0593r2.html) and low-level I/O primitives (www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1031r0.pdf). Huge changes can come later, once we fully understand the problem. 
Piotr from PMDK team here. Those are all great points that I mostly agree with. The last one really touches on the crux of the matter in the context of C++. Before we start talking about object durability, we first need to address the fundamental issues are are present even today when using shared memory. My bias personal bias on PMDK is obviously in the other direction, but I do agree with you that there are some trade-offs that we've made that might not be a right fit for some use cases. The two that you mention are direct consequences of our initial decision to avoid compiler modifications so that PMDK is approachable and easy to get started with. Could you elaborate a little bit more on why you think 16 byte fat pointers are a non-starter? I've yet to encounter a non-synthetic workload where that is a large issue. Sure, I've seen performance degradation due to objects no longer fitting in cache lines (e.g., you can fit less tree nodes in the cache during read benchmarks), but it wasn't that large, especially compared to other costs. As for the redo log, yes, I completely agree with you. But at the time we've designed the library we couldn't conceptualize redo-based transactions in C that didn't have a myriad of problems with usability. Even in the context of C++ transactional memory, and even if we are OK with changing the compiler's frontend, redo logging has some challenges. But you might be happy to know that we have plans for the next release of libpmemobj to contain redo-style APIs that can have better performance than undo based transactions but also sidestep the read redirection problem entirely. We are also working on an experimental LLVM plugin that will use these APIs for seamless integration with C++. We are open to any feedback, and sparking the discussion around persistent memory semantics is one of the reason for PMDK existence. Keep it coming ;)
By shutdown do you mean after you close the solution? ReSharper does not preserve contents of the tool windows in this case (neither does Visual Studio), but you have an option of exporting inspection results to an XML report. You can load the report later to continue your work or share it with the team. You can even use command-line tools to generate an inspection report on your CI server, and use it later on your workstation to save time.
I like the general design of those layers of container implementation, but the xci variants just keep making the vocabulary type problem worse. As he was answering the question about needing two overloads for everything taking one of these containers, somebody in the audience said you don't have to worry about overloads if you're using taking iterators. Okay, but what is the type of the iterators? Seems like eventually everything in C++ will be a template.
Yet the evidence indicates that it is some kind of a big deal. That you can't see it just means you have to rely on the evidence, rather than your own assessment.
I used to be happy with this as well; for program that didn't matter. But in my experience, people execute as they learned, and using rand\(\) for learning in throwaway programs means people end up using it when it matters as well. 
Debug step filters o/ Finally. The reason to install and try Re\+\+ again! :\-\) It's the one thing that VAX has and you just can't debug without it.
What if a library supporting PMEM cannot be made not UB without changing the language? What would you prefer then? Should the language be changed, or should it be left as UB until more dust has settled?
Let us know if step filters don't work for you as well as in VAX, we're happy to iterate and make them better.
This is an interesting question. I think it self evident that trivially copyable types have the same persisted representation as in-memory, but there is a much wider class of types which this could apply for, if you can allocate out of a pool like Intel's PMDK does. In terms of my own personal opinion, I think it's *deallocation* is the problem. I think that mmap serialisation works great if it's write once, read many, which means copy-on-write semantics, which is fine for small data structures but doesn't scale well. I don't think, personally speaking, that it's wise to permit deallocation on persisted storage. It's far harder to get correct, not least that the filesystem can and does allocate new extents if you ever modify data after it's written i.e. the page being used for your data on a PDIMM changes, but the metadata to fetch that may not have been persisted to retrieve it later.
This set of feedback I have found immensely valuable. I had not realised the conservatism against doing anything at all right now, though of course I never had *any* expectation that *any* direct support for persistent memory was achievable before C++ 29, and that's even if we start now. The reality is that it'll be at least a decade after everybody wants this support before it can be standardised, such is the nature of standards. 
Aren't such things first appeaing as compiler-specific extentions?
Firstly, it's great to get feedback from someone with direct experience of the technology. Thank you. &gt; Concurrency and persistence are related but different problems. Solving for the former does not necessarily solve for the latter. It's *definitely* the case that solving concurrency does not solve persistence. It is also the case that solving persistence does not automatically solve concurrency. However, it is my *current* belief that it usually cheap to solve concurrency when solving persistence. Would my current belief be correct, in your opinion as a domain expert? &gt; Even if pmem had the same physical performance as DRAM, there's inherent overhead to maintaining crash consistency of data structures. As such, there are things you're going to _want_ to be ephemeral (i.e., not persistent). Excellent point, and I very much agree, which is why I don't think that the STL containers should be modified to support persistence. I think we need a whole new suite of containers which are usable outside of persistence e.g. for interprocess, but which are quite slow relatively speaking otherwise due to the very strong progression guarantees. &gt; Pmem is not storage. Anyone who starts talking about serializing to and deserializing from it have the wrong use cases in mind. This is tricky stuff ... my hope is that WG21 can embrace the concept of some object lifetimes exceeding that of the process. If we can get that for C++ 23, that makes a lot of other stuff to do with persistent memory much easier later on down the line. But this is very hard stuff to get right, particularly getting vtables to be correctly repointed at the new process so we can greatly expand the kinds of C++ objects which can be directly persisted. It may yet be that we simply give up, and say you can't persist objects with vtables (which would be a shame, and it remains my hope that we can avoid that) &gt; Shared memory is often a useful metaphor for some of the challenges As you probably know, the C++ standard specifies for thread concurrency, but not for process concurrency. I am hoping to get that into C++ 23, but it may be C++ 26. We'll see what people think at next week's meeting. Thanks for the feedback, and if we get the study group, I hope to persuade you as a domain expert to join and tell us when we're doing stuff wrong!
I know what you're saying, but I'm also thinking of *versioning*. So, if you segment your "my program can be restarted with this data and all is good" data from all your other data, and tell the C++ standard library that the former data is super important, the history of changes to that data can be kept over time. After your process suddenly exited, on restart the latest verified correct version of that data can be supplied to your process. Android implements something like this. I'm thinking it would be super useful if that facility was also in the C++ standard library. What do you think? You'll probably point out that if one wants that, just go use SQLite. And yes, that's the current best available option for that. But SQLite is way overkill, plus it's quite inflexible i.e. not very STLish to use, plus versioning using SQLite is not performant. I think we can do a lot better.
The word of people whose professional work I'm not familiar with does not constitute evidence, it constitutes hearsay. I have yet to see actual evidence that 4 dead simple lines of code are an actual problem for anyone.
Without doubt, it'll be a decade between widespread adoption of persistent memory and standardisation. I would be pleasantly surprised if support could be delivered in C++ 29. But that's how standards work, you can't standardise what isn't common practice, though you can do the groundwork to prepare for likely futures.
I'm old enough to have programmed in assembler small systems with non-volatile RAM. I was quite young, and the systems were slow, but the fact you could pull and restore power arbitrarily was very cool.
Me and Bob are of like minds on many topics! Thanks for the pointers.
On any recent kernel (Windows, Linux, BSD), mapping a file from a filing system on persistent memory will probably map the persistent memory directly into your process. That "just works", and has been in the various kernels for a few years now (with varying degrees of maturity).
I think the chances of standardising an ABI are virtually nil. At least once major compiler vendor would veto it.
&gt; And (once again) I've hit the wall with 'Cpp on Windows in anything else then MSVC is to be avoided'. I'm accepting this state. I'm not a fan of MinGW, but I definitely know people who use it as their daily compiler, so I don't know what the problem would be there. Personally I use Clang on Windows as my daily compiler, so I also don't know what the problem would be there. Maybe it would help if you post the actual problems you're having, as you seem to be leaping to false conclusions. Also, you want /r/cpp_questions.
It depends on the UB in question. For example, strict aliasing unsafety was sufficiently a big enough thing it got a compiler option, and MSVC still to this day doesn't break strict aliasing unsafe code. But for such a niche technology as PMEM will be at least initially, it would be hard to see compiler vendors moving any quicker than the standards committee. They'd want to see what standards will do before moving. And we especially need to see how ARM devices will implement PMEM support, they are far bigger and more important a market than servers, which tend to have much longer lifecycles.
Surely WSL can help with this?
I use CMake at daily basis to make project configuration platform agnostic. I tried conan to make managing packages easier. On Linux/Debian I had system package manager who provided me with working packages. For today on Windows most libraries comes with precompiled binaries (mostly on MSVC, some on MinGW) like ie. Qt or boost. On Linux I worked little under Yocto - so I had tool to make development environment. On Python I can use virtualenv or I saw in commercial Pycharm Dockers to make enviroment isolated to not pollute OS with configuration. I would like to create something like this for my self. Yes, I lack deep knowledge of configuration or available tools - that's why I'm asking. 
I've heard about this - but didn't work with it. Are somewhere complete examples of working dev enviroments?
Fwiw, there's vcpkg for Windows/MSVC or you can use the msys2 package manager for a MinGW environment.
I don't get it. If you remove a file, your unit tests shouldn't even compile or at least fail when they are run. How can you miss that? If you don't have a single unit test that test anything of a whole file, and you don't run the unit test before merging, you definitively have a huge problem. Or am I wrong, and it's possible to have a correct (not perfect, just ok-ish) test architecture that could not detect that a whole file is missing. And anyway, if you remove a whole file and it's not caught during code review, it's also extremely strange.
Good first program. Main point I'd make is to name your variables with meaningful names
A solid start :). I would say your next job is to move some stuff into methods. Also, Have you tried entering a letter or symbol instead of a number to see what happens ?
Just remember that with WSL you'll compile a **Linux** program, not a Windows one. And that means it won't work outside WSL.
As far as I can understand, multiple properties require OS support. For example: &gt; You can assume that programs, once started, will run forever and merely only ever get suspended from time to time. That would only hold true if the stored data is guaranteed to be immutable from the view of other programs and if the OS will guarantee to map the memory again at the same address, the next time our program is started. Additionally, whatever object is 'stored' in this manner must not point to any address that is not. I see the point this is trying to make, whether a concept of a lifetime longer than current static could be appropriate, but the exact semantics will depend on the program loader of the OS as far as I can tell. &gt; The current C++ memory model has no concept of making changes to objects visible to other strands of execution apart from kernel threads on cache coherent CPUs (atomics). How is this different from the existing problem (or rather throwing volatile everywhere) of MMIO access? Communication to other program for example already happens through the os.
OP made a thing!
It is not guessing not providing usage requirements, just translating the Conan info model (that the recipes declares always) to cmake. So, do you think that every package has to repeat the same information for the consumers in all the build system format that the consumers could be using? Doesn't sounds good... Anyway if the package contains its own cmake script it will be prioritized over the generated, so you are good packaging your custom scripts. 
I haven't really worked with methods, yet I'm currently running through some free c\+\+ tutorials and things, so eventually I plan to make it a lot more functional as at the moment it obviously only works with a square or rectangle. Also no I haven't tried entering these, I will try and see what happens, thanks :\)
Cheers for the feedback, yeah I noticed this, for double variables ect. can you use more than one letter so rather than double c = area I could replace c with something that is better fitting with area
CLion works with WSL. As of the 2018.2 EAP, it also works with the Ubuntu 18.04 app instead of just the Ubuntu one.
Yes, they can be as long as you want within reason.
Your comment on line 2 contains names for your variables already, Just rename them to these, So a becomes height etc. Then you can remove the comment as the code should be easier to read.
Okay thanks for the advice guys, as iv just been doing tutorials I wasn't aware the variables could be named as such
On Windows you have several solid choices, 1. MSVC. Why avoid it? 2. Qt and Qt creator. It gives you great IDE and debugger. 3, CMake + MSys2 and MinGW. pacman on MSys2 makes your life betters. 
 double area; area = a*b; Just write `double area = a * b;`
&gt; Can you expand on how this conflict of interest (standard vs. os implementation freedom) could be solved? I think when we get around to replacing RTTI with something deterministic, we can solve the problem of persisting vtabled objects in storage. I haven't given a deterministic RTTI implementation much thought however. &gt; Communication to other program for example already happens through the os. You're forgetting shared memory. Also, only on Windows can userspace processes ask for memory to be marked non-cacheable, so one would need the C++ memory model to understand more than one level of remote entity visibility, a level beyond cache coherent thread visibility.
For the near future I don't see persistent memory used for anything but a better and maybe more granular suspend-to-ram / suspend-to-disk, which already work quite well with existing programs (timing issues aside). So I'm not sure what level of language support would be needed here. That aside. A clarification on object lifetimes would be quite welcome in general (e.g. if I create an object in memory mapped to other processes it should be possible to cast that bitpattern into an object in the other processes).
Are you French? In English it is "program" :-)
No I just cant spell, are you sure iv always spelt it programme lmao
An excellent example of how we might need object lifetime to extend outside of program lifetime. Thanks for the feedback!
Sound promising - that's why I look at CLion with wider and wider smile.
Then I would have package management solved. Will it also protect other project folders and system from unnecessary polluting?
I find learning and mastering each of mentioned workflows tiring and tedious. I'm VIM enthusiast and love work without moving away from keyboard. Qt Creator and CLion and platform agnostic solutions, while CLion looks more mature and stable. Both doesn't work too good with MSVC as compiler (ie. CLion 2018.1 doesn't have debugging supported). Which forces me to use other compilers - which forces to recompile all packages - and so on... I'm exploring Docker and WSL as alternative for VMs.
I use Clang 6.0, CMake, Ninja and VS Code as my IDE. I write SIMD stuff too and I like to play with the latest features, so after these in general MSVC was not the way to go.
&gt; MSVC. Why avoid it? It still has a lot of bugs when it comes to optimization breaking binaries.
Do you use ISPC for SIMD?
This is an interesting article. To my way of thinking, pointers and references are separate from the concept of types and syntax. To this point, you don't need to use pointers or references to use types. In fact, I'm under the impression that a lot of people would be much happier if C++ was just more about values in general. Anyway, here's my taxonomy suggestion: T t pointerless dot accessed? T * t pointer arrow accessed? T &amp; t reference dot accessed? I think if you want to do more taxonomy, you might start by looking at the operators in the expressions [ none, *, &amp; ]. I feel like that's a better place to start. Not sure about *zeiger* as a name... I'd hate to start a religious war!
Option 3 is the one that I recommend as well. It's easy to setup, works fine and integrates with CLion great for Windows development. I'm currently using it to develop GTK applications for work. Only thing I'd say though is that installing CMake separately is unnecessary as CLion includes a copy of CMake.
programme is spelt like this when not speaking about a computer program. Whilst the US uses program in all cases.
is_empty
Do you know some articles worth reading about simd? Thx. ;)
Qt Creator [supports](http://doc.qt.io/qtcreator/creator-debugger-engines.html\)) debugging binaries compiled with MSVC using CDB.
British English has a television programme, a theatre programme, etc. We also have catalogues, dialogues and the like. It can be quite jarring for a new developer.
I use the visual studio c++ for Linux on 2017 with WSL or remote bsd. VS supports CMake projects, bit I've also use clang with this as well
My bad, never saw it written "programme" in Enlish!
CLion looks more mature and stable I rather consider Qt Creator to be more mature than CLion. I used IntalliJ in the past, and CLion is much less mature than JetBrains Java IDE unfortunetely.
MSVC. Why avoid it? [https://godbolt.org/g/Uh1Ht5](https://godbolt.org/g/Uh1Ht5)
&gt; optimization breaking binaries Well.. yes, kind of. Stay away from link-time code generation. That one *does* break binaries.
&gt; Question is - how to create productive development environment when host OS is Windows? What a loaded question. MSVC is by far the best C++ IDE, but you have to learn it, just like any other tool. If you want easy packaging, there's vcpkg. Anything else than MSVC is just pain on windows because it's not integrated with the native system.
One of the advantage of immediately assigning a value, is that you will not forgot later. ```cpp double area; // ... use(area); // oups, I forgot to initialize area ``` Whereas with ```cpp double area = a*b; // ... use(area); // it's impossible that area could be not initialized ```
Fall in love with a language is very dangerous.
Left as UB. Undefined means that implementations can try defining it however seems useful until there is a consensus about how to define it. 
Just fire up the WSL and let CLion detect it in the toolchain dialog, if I remember correctly.
No you're still correct. Programme usually refers to an events (theater, tv etc) details. Usually the order of when things happen but can also be information about the play in general. But from a tech stand point it is always program in English. While they technically should be interchangeable, in reality they're not when written.
I'm indeed talking about closing the solution. If I save the report can I start from where I left off by loading it? 
That would be a useful thing to have, I think. As would something with a C++-interface and database semantics, for that matter ;-) I wouldn't necessarily choose SQLite though, its thread safety isn't all that great. Let me ask you something else I was wondering about: do you think Optane will bring anything new to the table, compared to, say, storing data in a memory mapped file? 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The report itself is static, meaning that it won't automatically update after you make code changes - you'll need to rerun the inspections.
It is undefined behaviour, the temporary is destroyed before the foo call : http://coliru.stacked-crooked.com/a/14cbe478207a72ca
I like Insomniac's talk on the topic https://www.gdcvault.com/play/1022248/SIMD-at-Insomniac-Games-How
C\+\+98/03 94&amp;#37; C\+\+11 5&amp;#37; C\+\+14 1&amp;#37; C\+\+17 less than 0.1&amp;#37;
Nah I just use the simple intrinsics coming with the compiler. ISPC is definitely superior to any other compiler in vectorization, but I like Clang and havent played with ISPC yet :)
UB != implementation defined. UB means that it is not possible to write a standards compliant i.e. legal implementation of PMEM support no matter what you do.
Actually, in this regard, UB is similar to implementation defined. The standard itself makes no guarantee in either case, so you have a non-portable program. If the implementations you use define the behavior (they have to for implementation defined, but not for UB), then you still can predict the program's output (or set of outputs).
Me personally: I think it's too early to say for desktop and server systems i.e. those running our current very legacy OS kernel designs. I think for embedded systems it's a game changer, that nothing will be the same again for those once the price comes down. Battery less embedded devices which simply resume execution whenever somebody moves or shines light onto them? Game changing. The really hard question is what about mobile devices? And a lot of that depends on whether Google are intending to replace the Linux kernel with Fuchsia or not for Android. If they stick with Linux, I'd expect Linux to get much better persistent memory support, which will leak onto the desktop and kernel. If they go with Fuchsia - which as a capability based microkernel design is much more amenable to checkpointing the whole system regularly onto storage - then I'd expect Linux won't get much investment. But to answer you directly, the way you make best use of Optane is via memory maps. Which is also the best way to use SSDs, or spinning rust hard drives. So just use memory maps, and you're already as good as you can get, just even better if you're on Optane.
Thanks, I must admit I didn't know that casting doesn't prolong temporary. It makes sens when I see it low\-level. But still, the optimization that Visual performs is pretty miserable: [https://godbolt.org/g/hfoTTG](https://godbolt.org/g/hfoTTG)
My goto C++ setup on Windows is QtCreator and msvc as the compiler, even for non-Qt projects. It has everything I seem to need - debugger works great, cmake integration and support, vim-like keyboard bindings. I've tried to use CLion in windows a few times but can never seem to get a satisfactory setup.
There are many useful programs that depend on undefined behavior in the language because they have some well understood effect on a particular piece of hardware or one some OS. I have **zero** expectation of a first generation library using only portable constructs to be able to express persistent memory functionality. Likewise, I have zero expectation of a useful OpenGL implementation to be able to written using only defined behavior, because it will likely use things like low level SIMD intrinsics, and be talking to a piece of GPU hardware, need to worry about crossing between kernel space and userspace, optimal PCIe transfer methods, etc. That's all outside the scope of C or C++. OpenGL is still an extremely useful thing, despite depending on non portable implementation stuff that isn't defined by the language. PMEM is still very exotic. OS's will expose it in various ways. Alternate hardware approaches may become available. Things that seem like a good idea today on x86 with Optane may not be so great in five years when we all have 3rd generation McDonald's brand PMEM plugged into our MIPS-128 brainchips. I can't even just pop into Fry's to buy a PMEM device today to start hacking around on it to be able to form a strong opinion about any language spec proposals that might start popping up!
I usr Clion on Windows with tdm-gcc and CMake. All good, no problems.
Because if you can get past absurdly huge learning curve, you can edit code much faster than with anything else (discount emacs, that's like vim squared and you definitely need more than just 10 fingers to be proficient with it). 
I use whatever percentage of the random stackhub answers compile in vs2012.
&gt; It is not guessing not providing usage requirements, just translating the Conan info model (that the recipes declares always) to cmake. When using just a conanfile.txt, the conaninfo model only knows the transitive dependencies, which is incomplete for usage requirements. &gt; So, do you think that every package has to repeat the same information The build scripts know the usage requirements since they have to build the package. So build scripts can generate the usage requirements correctly and there is no need to repeat the same build flags in a conanfile.py file. &gt; for the consumers in all the build system format that the consumers could be using? There are only two formats for usage requirements: cmake and pkg-config(technically there is a third one [cps](https://mwoehlke.github.io/cps/index.html) that wants to encompass both, but no one uses it). Cmake is the only one tied to a build system. Pkg-config is build-independent and even works in cmake. There is a little repetition between the list of a dependency in the package file(ie conanfile.txt) and the `find_package` calls, unfortunately. However, if we have a [standard package file format](http://pfultz2.com/blog/2017/10/27/universal-package-manager/), the build system could parse this for the calls to `find_package` and `pkg-config`. &gt; Anyway if the package contains its own cmake script it will be prioritized over the generated, so you are good packaging your custom scripts. I am not sure how well that would work either. How does conan know which targets are connected to which dependency? Also, if my cmake package config file has flatten the usage requirements because upstream doesn't provide them, it seems conan would link the usage requirements twice.
A guess: *C++98/03: 70% *C++11: 20% *C++14: 10% *C++17: &lt;0.5 (Yes it doesn't add up to 100% - subtract &lt;0.5 somewhere... :P)
I’m likely to agree with this. But I think there’s more C++11 adoption unless you include old code bases which are no longer being maintained.
On Windows I use: QtCreator with CMake \+ MinGW\-w64 \(GCC 8.1.0\) \+ Ninja , and also the ClanStaticAnalizer plugin activated. https://stackoverflow.com/questions/38335424/how-to-use-mingw-64-with-qt-creator/38547137#38547137 *I do not use Msys2: if an opensource library does not compile with mingw-make, or if its not easy to write/adapt a CMake for it, I just avoid the library* I am waiting to Clang finish its MSVC dependency for to start using it in Windows.
I don't use gcc so I wouldn't know but what are its limits? Does it work for all standard library functions, a few common functions etc.
It appears so. If I compile the following program with gcc it prints try, catch, and catch2, but with clang it only prints try, and I don't see the catch block in the assembly at all: #include &lt;atomic&gt; #include &lt;thread&gt; #include &lt;cstdio&gt; int main() { std::atomic&lt;bool&gt; in_try(false); std::atomic&lt;bool&gt; is_cancelled(false); auto func=[&amp;]{ try { in_try.store(true); while (!is_cancelled.load()) { } puts("try"); puts("try2"); } catch (...) { puts("catch"); puts("catch2"); throw; } }; std::thread t(func); while (!in_try.load()) { } pthread_cancel(t.native_handle()); is_cancelled.store(true); t.join(); return 0; } 
`malloc` isn't guaranteed to be defined in `&lt;cstdlib&gt;` but `std::malloc` is.
| When using just a conanfile.txt, the conaninfo model only knows the transitive dependencies, which is incomplete for usage requirements. You have the information in the conanbuildinfo.cmake, or with the new generator, in each findXXX.cmake script. | There are only two formats for usage requirements Don't forget about boost build and the most important, visual studio. And I'm sure I'm missing some more. My point is, we cannot depend as consumers if our requirements have packaged the files for our build systen. Most packages will be unusable even when you already have all the needed info but not in the correct format. About standards, sure, let's define or adopt a format, but still you have to deal with 30 years of legacy.
The [release notes](https://gcc.gnu.org/gcc-8/changes.html) state: &gt;When reporting on unrecognized identifiers, the C and C++ compilers will now emit fix-it hints suggesting #include directives for various headers in the C and C++ standard libraries. So, answering your question would require further research. 
If it compiles without the include, what benefit do you get by adding it to your source?
&gt; I’ve probably seen hundreds of bugs stemming from people getting the object lifetimes wrong with string_view and its underlying buffer. For those who haven't read the post, in my reading, the author, who likely has more experience than most on the subject, has opinions on what it takes for reference types like `string_view` and `span` to be used safely in practice. Notably, he's concerned about data race safety as well as lifetime safety. He proposes a separate definition of "regular" for such reference types, which invariably fail to satisfy the criteria of the traditional definition. What I found notable is the implied "rules" for using these reference types safely seem to be (perhaps appropriately) quite restrictive. (Though seemly without enforcement mechanism.) I gather that he's suggesting that such reference types can be assumed safe when used as function parameters, and it's probably best to stick to just that use case. He also seems to want to prohibit any modification of the referenced container, at least while it's the target of one of these reference objects. Presumably to address the data race problem when passing these reference types among threads. Whenever the safety of reference types is the concern, I'm going to recommend taking a look at the SaferCPlusPlus library's [versions](https://github.com/duneroadrunner/SaferCPlusPlus#string_view) of these [reference types](https://github.com/duneroadrunner/SaferCPlusPlus#txscoperandomaccesssection-txscoperandomaccessconstsection-trandomaccesssection-trandomaccessconstsection). (Shameless plug.) They are [memory](https://github.com/isocpp/CppCoreGuidelines/issues/1038#issuecomment-390012944) and [data race](https://github.com/isocpp/CppCoreGuidelines/issues/924#issuecomment-369628692) safe, and they don't have any of these restrictions. That is, they aren't limited to being used as function parameters, and they remain safe even when the referenced container is mutable. Basically, if you really want safe `string_view`s or `span`s, there are options. 
I'd say, both Alias/Reference and reference\-like/pointer\-like are understandable, but "zeiger" definitely can't be seriously considered for any classification aiming to become standard in any sense.
Good point. In which case it could still be improved. $ echo 'int main() { void *x = std::malloc(100); }' | g++ -xc++ - &lt;stdin&gt;: In function ‘int main()’: &lt;stdin&gt;:1:29: error: ‘malloc’ is not a member of ‘std’ $ echo 'int main() { void *x = malloc(100); }' | g++ -xc++ - &lt;stdin&gt;: In function ‘int main()’: &lt;stdin&gt;:1:24: error: ‘malloc’ was not declared in this scope &lt;stdin&gt;:1:24: note: ‘malloc’ is defined in header ‘&lt;cstdlib&gt;’; did you forget to ‘#include &lt;cstdlib&gt;’? When we are pedantic about it, it's **int main()** in **C++** and **int main(void)** in **C**.
Cross-platform compatibility. 
Like checking arguments against parameters? And it certainly should not compile and if it does, it only means that some other header is pulling it in which case you don't get this message. BTW, including one system header hoping it will pull another is a bad practice anyway.
How would you define a "C++11 codebase"? Every line uses a C++11 feature? One line in a thousand? One line in a million? Plenty of codebases were written in C++98, but are now compiled by C++14 compilers simply because they keep their tools up to date. 
Why are GCC and Clang "to be avoided" (for you)? GCC, in my experience, works fine on Windows.
I define it as "compiling with C++xx" and the company allows you to use the features. At my current company we recently upgrading Visual Studio and now compile with C++14 althought most of the codebase is C++11 or C++98, BUT we are allowed to use C++14 features like generic lambdas and deduced function return types. Also, most codebase C++14 codebases won't have too many lines that are "actually" C++14 because most of the language feature already exist, its just incremental changes (although C++11 was a huge change).
You would think if a codebase made the jump to C++11, then going to C++14 would be relatively simple, as the differences aren't big. 
I understand it is definitely bad practice. I guess I am wondering why this is a warning and not an error. 
What makes you think it is just a warning? To me it looks like OP did get an error and just didn't copy-paste the whole thing.
&gt; You have the information in the conanbuildinfo.cmake, or with the new generator, in each findXXX.cmake script. How does conanbuildinfo know the usage requirements is say `-DFOO=1` when I do `target_compile_definitions(lib PUBLIC FOO=1)`? From the documentation it shows I need to add this in the `package_info()`. &gt; Don't forget about boost build and the most important, visual studio. Those are build systems not usage requirements. Furthermore, pkg-config is not a build system at all, it is only used by build systems. Boost build does use pkg-config to find some dependencies, and it can generate pkg-config as well(although its not builtin). Visual studio is lot more crippled build system as it can't integrate with other tools. So it will need more support from a conan recipe file to find usage requirements and install artifacts and usage requirement files. &gt; Most packages will be unusable even when you already have all the needed info but not in the correct format. There are only two formats, and really only the pkg-config format is really necessary for it to work across all build systems. So if a package doesn't provide usage requirements in the cross-platform, build-independent format of pkg-config, then this is a bug that should be fixed upstream, not by a package manager.
To be ultra-pedantic, defining `int main()` is also correct in C. C11 6.7.6.3 "Function declarators (including prototypes)"/14: "An empty list in a function declarator that is part of a definition of that function specifies that the function has no parameters. The empty list in a function declarator that is not part of a definition of that function specifies that no information about the number or types of the parameters is supplied."
Don’t use malloc in C++.
Cool, I guess I have never looked that deep or past **"5.1.2.2.1 Program startup"**: " The implementation declares no prototype for this function. It shall be defined with a return type of int and with no parameters: int main(void) { /* ... */ } or with two parameters..." It's a bit contradictory. Maybe purely theoretical question, but given that **main* is treated specially anyway, wouldn't that take precedence? :) Or could it be considered an issue in the standard?
The key part is the following "or equivalent" (with a footnote). The footnote mentions the argc/argv version for examples, but `int main()` is equivalent to `int main(void)` as a definition, so it counts.
Issue with fat pointers is more capacity than performance. In scenarios where you're trying to argue, "Hey, you should move that thing that's currently cached in DRAM to pmem, and make it a write\-back instead of a write\-through cache," if you then have to tell them their in\-memory size is going to grow by whatever proportion of their data is currently pointers, it's a non\-starter. Even if pmem is cheaper than DRAM, it's still precious. :\) \(also, my gut says that making the layout of the same data structure look different in pmem as DRAM will cause problems/headaches, for tools/debuggers etc. if nothing else\) Meantime: thanks for all the work, Piotr!
Ah, you are right. That makes sense.
Man, if I'm a domain expert, god help us. ;\) &gt;It's *definitely* the case that solving concurrency does not solve persistence. It is also the case that solving persistence does not automatically solve concurrency. However, it is my *current* belief that it usually cheap to solve concurrency when solving persistence. &gt; &gt;Would my current belief be correct, in your opinion as a domain expert? This is actually some decent work on the topic: [https://www.usenix.org/conference/hotstorage17/program/presentation/marathe](https://www.usenix.org/conference/hotstorage17/program/presentation/marathe) Admittedly, porting is a slightly different problem from creating something anew, but it shines some light on some of the challenges of intermingling persistence and concurrency. Specifically, it seems like they found waiting for things to persist really adversely affected concurrency. That said: some of the programming abstractions \(i.e., transactions\) seem nice tools to use for both concurrency and persistence since both force you to express which points in your execution should be executed atomically with respect to \_something\_, and maybe the implementation of those can be optimized? &gt;It may yet be that we simply give up, and say you can't persist objects with vtables \(which would be a shame, and it remains my hope that we can avoid that\) Eh, I hope not. vtables are merely a specific instance of the general problem of relocation of data across instances, which affects any reference/pointer, and that needs to be solved one way or another. Again this is a problem that will affect inter\-process shared memory in a very similar way, and I don't think the right solution for both cases is to say, "Look, just don't do that." There are many solutions to it; the PMDK has one, and my preference is to patch up such things at recovery/load time.
user-defined string literals can be used to do black magic like t[0_i] +=42; or t[1_i] = "howdy";
MSVC + WSL is an awesome combination. For me, MSVC is the most productive development environment due to its awesome code completion, etc (peek definition is amazing). Couple that with its powerful and easy to use debugger and profiler, and your productivity increases immensly. The latest version can natively work with CMake projects. My preferred setup is to have an MSVC project that I develop and debug, and use WSL with the latest GCC and Clang to make sure that I am not relying on a compiler specific behavior.
OP only gave an example. Could have been printf instead of malloc, but then you probably would have said that you should use cout instead. ;)
Actually IIRC C++03 lossened the requirement of putting every C std functions in namespace std, so it is guaranteed.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8nwn19/help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
No, implementations are permitted but not required to also place the functions in the global namespace. 
So it'll compile on other compilers/PCs.
I appreciate the good intention, but I honestly don't like the direction this feature is going.
OK, guess it's good enough for GCC.
Why? 
Well, you should. I can't think of a case where using printf would be the better choice. 
[No one is going to do your homework for you. Show you put some effort in and people might help.](http://lmgtfy.com/?q=C%2B%2B+inheritance+tutorial)
The first things that I could think of is the code size. Iostream make a tiny executable huge. If there is a lot of code then it does not matter, but for small executables the .text size cout and friends produce is ridiculous. 
And note that once proper effort is shown: &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. 
I'm going to go out on a limb and say it checks based on existing header contents and not the standard itself.
If I make a code mistake (e.g not defining a symbol) then the compiler should tell me exactly this. *Symbol XY is not defined!* I don't like that the standard library, especially just parts of it, are treated differently by the compiler than code from other libraries. It's a nitpick feature that I would expect more likely from an IDE, but not from the compiler.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8nwyfm/program/dzz02hm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yeah, and they'll need a lot more effort shown for StackOverflow because they won't be nearly as nice
We have a phrase we use for this... 'Lazy tw@t'
I imagine the response would be a pretty typical downvoted for lack of research effort, closed as unclear because there's no specific question, and a few comments about not doing homework for them, coming up with a specific problem and creating an MCVE, maybe one saying welcome to SO; please take the tour, and maybe a snarky one about accepting payment for providing code.
Have you ever tried to actually format output with C++ streams? It's horrible. The printf interface is much better. So much so that something like fmtlib is being considered for standardization.
This question is off topic for /r/cpp Questions should be asked in /r/cpp_questions
ITT: People who don't use clang and don't know there's something better than gcc and are amazed by all these crazy new things gcc does.
Also, why doesn't it complain about not returning an integer from main()?
Some people argue that `int main()` is non-standard in C. The basis of the argument is: * the C Standard says only lists `int main(void)` and `int main(int argc, char **argv)`, and "equivalent forms" as forms the compiler must accept * `int main()` and `int main(void)` are different (which is true) * Since those two are different they are not equivalent. 
There is implicit `return 0;` for `main` if execution reaches the end
Not sure why you are downvoted, as this is good advice. A common mistake in C++ is to try and write directly to malloc'd space, e.g.: #include &lt;stdlib.h&gt; int main() { char *p = (char *)malloc(1); *p = 'x'; // undefined behaviour } 
It's an error (or more precisely it's a note to an error). The title is misleading.
And it tells you exactly this. OP just pasted only the `note` part that suggests a fix. It's also an error, not a warning.
`int main()` and `int main(void)` are equivalent in a definition
I agree with you for the most part, but with the C++ streams you can define operations on your own classes which sometimes makes the code easier to read and little more pleasant to write.
Your comments about C11 behaviour in this thread are a bit unclear. To avoid doubt, in the following C11 code: #include &lt;stdlib.h&gt; int main(void) { void *p = malloc(0); void *q = malloc(0); if ( p &amp;&amp; (p == q) ) printf("non-conforming\n"); } cannot produce output on a conforming implementation. The behaviour of C and C++ is the same insofaras each allocation either fails; or succeeds giving a pointer that compares unequal to any other valid pointer. Reference for C11: 7.22.3/1 "Each such allocation shall yield a pointer to an object disjoint from any other object." (that paragraph goes on to clarify that this sentence still applies to non-null zero-sized allocations). 
You are kidding right? If you can't write to memory you allocated, what the hell are you supposed to do with it? That code is in no way undefined behavior.
No they are not. Minimal differing pair: int main() { if(0) main(5); } versus int main(void) { if(0) main(5); } The first must compile and run successfully. The second is a constraint violation (C11 6.5.2.2/2) and must give a diagnostic. 
Well f*** me then
Very true, but also something that you can support with a lib like fmt.
GCC uses a built-in dictionary for some well-known identifiers to print out this message.
You're supposed to create objects in it. In the C++ memory model *storage* and *objects* are separate concepts. A `vector` is the model example; it obtains storage (its capacity), and will create and destroy objects within that storage as required. Objects always have a type , and the expressions which create objects specify to create one or more objects of a given type. The malloc function obtains storage without creating objects. The *new-expression* (e.g. `new int;`) obtains storage and then creates an `int` object in that storage. The above code could be fixed by: char *p = (char *)malloc(1); // obtain storage new(p) char; // create object *p = 'x'; Of course this is unnecessarily verbose compared to `char *p = new char;`, which is where the advice "don't use malloc in C++" comes from. If you doubt any of the above, please follow the link in my previous post which will direct you to the relevant sections of the C++ Standard. 
To be ultra-ultra-pedantic, `int main()` is not equivalent to `int main(void)`: `int main() { if (0) main(42); }` is valid in C, but `int main(void) { if (0) main(42); }`
Special rule (in C99 and later, and C++). C11 5.1.2.2.3/1: "reaching the } that terminates the main function returns a value of 0." C++WP N4750 6.8.3.1 [basic.start.main]/5: "If control flows off the end of the compound-statement of main, the effect is equivalent to a return with operand 0".
`int main()` and `int main(void)` don't have different semantics *as definitions`. In C, for function definitions, empty parens mean zero args. (I was surprised to learn this rule a year or two ago.)
They do have different semantics in definitions. [I went over this in another comment](https://www.reddit.com/r/cpp/comments/8nv0v3/cool_new_warning_about_missed_include_with_hint/dzz4pjy/)
A character is by definition one byte. Copying the memory of a byte to another will produce identical results to using placement new of a character. Not using placement new doesn't mean it's undefined behavior. That section from the standard only mentiond objects, not built in types. Anything that is trivially copyable doesn't need placement new. If you ALWAYS needed placement new, even for characters, than std::realloc would be undefined behavior, as it internally just memcpys the data interpreted as a std::uint8_4, instead of constructing it as noted in that SO answer.
Did you bother to read to accepted answer in the link you posted?
Yes, that is why I chose that link as the accepted answer is correct. It clearly states that `malloc` does not create an object.
Objects can be of class type (also known as user-defined type) or built-in type. It seems like you are trying to say that objects of built-in type are not objects, however that is not true. You can easily verify this from the Definitions section of the C++ Standard. &gt;Anything that is trivially copyable doesn't need placement new. This statement contractics the C++ Standard (I have already provided references). &gt;std::realloc would be undefined behavior, as it internally [...] The internal workings of any particular implementation are irrelevant. It might not even be implemented in C or C++, e.g. it could be written in assembly. 
Let's break this down. char c = 'x'; void* mem = malloc(1); memcpy(mem, &amp;x, 1); So far, everything is fine. The value of `c` is equal to `x`, and this same value is copied to `mem`. It is guarenteed beyond unreasonable doubt that `c` and `mem` have an indenticle memory representation and size. `memcmp` would always return zero. Give these certainties, how could it be possibly true to say that interpreting `mem` as a character would be undefined behavior? Under the standards own rules, `mem` could be nothing but equal to `x`, which is very explicitly defined behavior.
Even Googling "zeiger offensive" doesn't clue me in to what you two are talking about.
I originally did post it in /r/cpp_questions but I cross posted it here as well.
After reading the sidebar, does it seem like it's appropriate to post here? &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. 
I thought of it as a grey area, this was more of "survey" to see what people thought that an actual C++ question. The /r/cpp says "Discussions ... about the C++ programming language" which is what this reddit post sort of turned into. No one really seems to know, just everyone sharing their opinion
It looks like you’re right about C. Good thing I abandoned it almost 2 decades ago!
I don't really see the pointer of all this. I don't think there is anything to be gained when the taxonomy is more complicated than what it's describing.
The way you _feel_ it _should_ work and what the standard actually says are unfortunately two different things. But, fortunately this time, what the standard says is UB has consistent behavior in practice because of sanity. That said, arguing about this is pointless, and the standard is clear that this _is_ UB. The downvotes on /u/OldWolf2's comments are Reddit in all its childish glory.
The taxonomy isn't more complicated than what they are describing, pointer types are that complicated. Consider the debate around std:: optional&lt;T&amp;&gt; vs T*. People say, you don't need optional&lt;T&amp;&gt;, if you want a reference that can be nullptr, use a pointer! While that is true, it only looks at one dimension. optional&lt;T&amp;&gt; has implicit creation, T* explicit. This makes a difference (see my talk for examples). It isn't just about T&amp; and T*, it is about all possible types that behave like T&amp; and T*. And the general guidelines are complicated because this is complicated. You have to look at all those properties to make an informed decision.
As /u/dodheim, I have no idea what you are talking about. However, I'm happy with dropping it all together, you only need a term when talking about the taxonomy itself.
It's not childish glory, it's a clear protest against the insanity of the standard in this regard. I'll explain why: 1. Up until now we have always pretended that we had a reasonable degree of compatibility with C. This particular rule obliterates that compatibility, yet somehow we still pretend it's so incredibly important that we cannot even fix the gratuitous UB in functions like isalpha() - they must remain as they are, "because C compatibility!" 2. It's not just malloc, it's _anything_ obtained from a C library. According to this rule, most of the C library ecosystem is no longer available to us. 3. "Consistent behaviour in practice" is only consistent until a compiler developer can think of a way to abuse it for some utterly misguided optimisation. Since this has already happened with other 'consistent behaviour in practice' that some people relied on (like signed overflow), and given that I can certainly think of scenarios where an optimisation can be achieved ("hey, a write to this structure is UB, let's just eliminate it!"), it's only a matter of time before it will be done. I'm sorry, but the standard is just _wrong_ on this. I guess it's trying to make some kind of rule about guarantees that an object must abide by to work properly, but the effects of this rule are just far too broad. We don't expect to obtain fully-fledged C++ objects (with RTTI, v-tables, etc.) to spring fully formed from a C library, but a basic type or POD is something you cannot simply take away without expecting a revolt on the part of us language users. And rather than beat people up for alleged shitty non-standard code that 'must be fixed', or getting everyone to call some weirdo 'launder' function on every piece of memory obtained from the environment, what is needed is action to get the standard fixed on this one. Before the clang folks figure out how to weaponize this particular bit of UB... 
Downvoting people on Reddit is "clear protest against the insanity"? Wow. In all that ranting, did you consider the fact that I already made a clear distinction between "should" and "are"..? Get some perspective; every time I get a comment from you, it's some preachy thing where you're basically repeating what I said and telling me I'm wrong.
Especially given this text, from the standard ("allocation functions"): &gt;The pointer returned shall be suitably aligned so that it can be converted to a pointer of any complete object type with a fundamental alignment requirement (3.11) and then used to access the object or array in the storage allocated (until the storage is explicitly deallocated by a call to a corresponding deallocation function).
&gt; From the documentation it shows I need to add this in the package_info(). Yes. And with the info filled in that method Conan can accommodate to different "usage requirements" formats. &gt; Boost build does use pkg-config to find some dependencies, and it can generate pkg-config as well(although its not builtin). Boost build uses the boost.jam language, call it X, but it is used to transmit info to the consumers. About visual studio, actually the build system is MSBuild, but the property files are the same, files with the info for the consumer. So no, unfortunately there are not 2 formats. 
I mean zeiger is simply the german translation of pointer. Not sure if that's what he means...
Interesting, that wasn't the vibe I got from "When reporting on unrecognized identifiers [...]", but it still works.
..literally every possible case printf is better. cout is safer at the expense of the entire point of printing stuff out.
The C++ developer survey had some numbers for this. Can't look it up now, but it's on isocpp.
Yes, but it's still more convenient to wrap printf in the &lt;&lt;-operator overload than using pure C++. For (print-)debugging on the other hand it's very handy. 
&gt; Boost build uses the boost.jam language, call it X, but it is used to transmit info to the consumers. Boost.jam is the language for the build script, and it provides no usage requirements to consumers after installation(this is why `FindBoost.cmake` is such as mess because it can only guess the usage requirements since boost doesn't provide any). Boost.build can get the usage requirements from pkg-config: exe a : a.cpp : &lt;cflags&gt;`pkg-config --cflags glib-2.0` : &lt;linkflags&gt;`pkg-config --libs glib-2.0` ; Boost.build can also provide usage requirements for consumers as well, which it does [here](https://github.com/boostorg/boost/blob/feature/pkgconfig/tools/pkgconfig/Jamfile) for boost. &gt; About visual studio, actually the build system is MSBuild, but the property files are the same, files with the info for the consumer. I am not a MSBuild expert, but I am completely unaware of MSBuild providing usage requirements to users after installation. Most visual studio users find the concept of usage requirements completely foreign, and either build all dependencies in the same project/solution, add the usage requirements manually, or use a tool to generate the build files with the correct usage requirements from cmake or pkg-config. It does seem a custom MSBuild task can be created to get the usage requirements directly from pkg-config, but I dont know of anyone who is doing that. Either way, I have never seen a visual studio project consume usage requirements from an installed or pre-built packaged through MSBuild files. MSBuild-only projects just provide the dlls and header files, and leave it up to the user to figure out what flags are needed to build. If they used a higher-level build to generate the MSBuild(such as meson or cmake), then it is more common to have the usage requirements provided either through pkg-config or cmake. &gt; So no, unfortunately there are not 2 formats. I dont see how boost.build or MSBuild is a format for usage requirements. I know of no example of them providing usage requirements to consumers after installation or from prebuilt binaries. 
Did some more research: The fix-its are defined in [known-headers.cc](https://github.com/gcc-mirror/gcc/blob/57607963bcceee73907726f7cb57c4cd043a5132/gcc/c-family/known-headers.cc), and were included by David Malcolm at [Red Hat](https://developers.redhat.com/blog/2018/03/15/gcc-8-usability-improvements/)
&gt; #include &lt;stdlib.h&gt; #include &lt;cstdlib&gt; 
If it's UB, the compiler is allowed to do anything it "thinks" it's appropriate or fun (as like spitting out a warning like: "Error: I'm a tea-pot."
Most maintained open source codebases on github are at least at c++11
[Clang](https://llvm.org/builds/) works very well with the VS-IDE.
Absolutely. It's the OS's job to worry about hardware details. User-level code shouldn't ever need to know the difference. Eventually, all systems will be 100% PRAM and DRAM will be an obsolete abandoned technology. It's useless to impose user-visible distinctions here that will soon go away.
If the size requested from cmalloc is lower that SIZE_MAX, and the allocation is successful, then you have an array with size lower than SIZE_MAX. But if the size requested from cmalloc is bigger than SIZE_MAX, then it is not defined what should happen. Typically, the cmalloc implementation will return failure. But maybe it can also not return a failure, and proceed, and allocate an array larger than SIZE_MAX. I think the program just invoked undefined behaviour, and so the requirement that allocated objects are smaller than SIZE_MAX does not need to hold. Also, you cannot use sizeof to measure the size of memory returned by malloc or calloc.
There’s some stuff in r/SIMD 
I’ve played with ISPC a little bit. It’s really great if you are going to do a lot of work with floats or ints. It’s not so great if you want to switch between ints, shorts and bytes. The SIMT-like model it provides works in lanes and doesn’t lend itself well to merging and diverging whole SIMD registers.
&gt; Reference for C11: 7.22.3/1 "Each such allocation shall yield a pointer to an object disjoint from any other object." I found that unclear. I interpreted it as pointers to "objects that are disjoint to other objects", but "all zero-sized objects are disjoint of each other", but maybe the standard means that two objects cannot share the same pointer value ?
Yeap, we know what Undefined Behavior is. The second example does not contain undefined Behavior though.
Why would one have to differentiate anything? If allocations of zero-size are not allowed some code somewhere trying to allocate something like it cannot be allocated, whether it was an allocation with zero size, or calling new with an alignment that is not a power of two, ... you just either let bad alloc crash, or log and terminate, or retry. But like with an alignment that's not a power of two, calling new with zero size would just be because of a bug somewhere that one would then just fix. 
&gt; It isn't just about T&amp; and T*, it is about all possible types that behave like T&amp; and T*. And the general guidelines are complicated because this is complicated. I really don't think it is. I think people are making it way more complicated than it needs to be. The debate between `optional&lt;T&amp;&gt;` vs T* is an example of that. I just see nothing in the taxonomy that makes things any more clearer than if you just explained things with the actual types themselves. The only taxonomy that makes things better in this regard is the iterator taxonomy, and I think this pointer taxonomy needs a lot more work before it becomes as good a framework for clarity as iterators are.
See https://cplusplus.github.io/LWG/issue9 , where that was the behavior of `new` before it was changed to the current behavior.
I'm not so sure "we", as in all, understand what UB actually "promises" to deliver.
My machine: Windows 7, CMake 3.10, Visual Studio packages, MSYS2 cmake -TLLVM-vs2014 .. will use cl-clang 5.0 cmake .. -Tv141_clang_c2, will use clang 3.8 cmake -G"Ninja" .. will use gcc 7.2
Just yesterday I wanted to try this out on a bare board embedded project I work on. Just including the iostream header made the release build jump from ~90kB to ~200kB. I knew that iostream could add bloat but I was blown away by just how much.
&gt; Is there a defect report or a clarification of the std that includes this example or somewhere where I can read more about it? I don't think there's any clarification needed: 7.22.3/1 says explicitly that a zero allocation behaves like a non-zero allocation except that you aren't allowed to dereference the pointer. You could post a question on StackOverflow about this if you like, using [c] [language-lawyer] tags; I searched for one and couldn't find one. Might be a good niche to get some karma 
Huh?
In your code the `memcpy` causes undefined behaviour by writing outside of any object. The issue is that **you are not allowed to write outside of any object**. For this issue it does not matter whether the method of writing is memcpy, assignment, or whatever, and it does not matter what the representations and sizes of types are. BTW `memcpy` is defined as being the same as a series of character assignments. (This comes from the C Standard, which the C++ Standard explicitly defers to in this instance).
&gt; What if a library supporting PMEM cannot be made not UB without changing the language? Given that libraries for PMEM already exist, are you saying that they have undefined behavior?
&gt; Specifically, right now if I want to use 100% standard C++ code, I cannot say "make this memory I changed here available to that entity over there" which includes hard drive controllers, and indeed persistent RAM sticks. How is this any different from interprocess memory?
&gt;it is undefined behavior to write outside of objects. So you are essentially saying you cannot write to any void*? I don't understand how that could be possible in any way shape or form. Most large code bases will end up doing it, and typically more than once. Either its some raw data from a library, or call a c api. If what you are saying is correct, there would be virtually zero c compatibility.
`void *` can't be written to anyway; you can cast it to `char *` and write through. So long as it is pointing to an object, and notwithstanding other rules about directly writing parts of objects. (memcpy behaves as if you cast to `unsigned char *` and assign characters). Having external APIs obtain storage is not covered by the C++ Standard. In that area you are in the realm of implementation-specific behaviour. If a vendor provides both C and C++ compilers then they normally go beyond what the standards require in order to ensure interoperability. 
Maybe, so it is good place and time to link smth like this here: [https://www.youtube.com/watch?v=ehyHyAIa5so](https://www.youtube.com/watch?v=ehyHyAIa5so)
It's C.
Has there been a (recent) proposal that replaces errno functions with versions that don't have side effects?
A few template argument lists are missing, e.g. I think template auto make_holder(T&amp;&amp; t) -&gt; auto { return holder(std::forward(t)); } should actually be template&lt;class T&gt; auto make_holder(T&amp;&amp; t) -&gt; auto { return holder&lt;T&gt;(std::forward&lt;T&gt;(t)); } (The coding style also looks a bit ... unusual)
I don't know, but here where i work we still are stucked on C\+\+11...
Thanks for pointing out the angle bracket problem, wordpress's been doing weird things, should be corrected now.
Thanks, very useful.
Hos about just having public properties(variables)?
I like this idea.
Yeah exactly! If you feel the need to have both a getter *and* a setter then you probably need the data to be public, unless there is something really special going on.
This is a C++ thread, my program was a C++ program
If your class has no invariants associated with a member variable, make it public. Getters/setters only make sense when you are maintaining invariants.
You mean like: int x; int y; ? Or like: Property&lt;int&gt; x; Property&lt;int&gt; y; ?
Sometimes you are required to support older toolchains which eliminates the possibility of a newer C\+\+ standard.
Well... How can you tell beforehand? You may know for sure, how it is NOW. But what if you will see later, that you need, let's say log changes... Or update associative variables on set. Or you'll see optimization opportunity to not store value at all, but calculate it on the fly, like len\(\) = end\(\) \- start\(\)... I think its all rather about interface...
How about a language change instead? All those arguments of "just make a library" are falling on deaf ears, and `__declspec(property)` only takes us halfway.
Yeah. public: int x; int y;
T&amp; get_value() { return value;} ? 
My approach is to design on how it is now, not how it might be a year from now since we can’t know.
&lt;stdlib.h&gt; is a C-header. Indeed, as you are pointing out, this is a C++-discussion. To that purpose &lt;cstdlib&gt; should be used in [the] code that needs something like std::malloc. There you have it. 
Agree, keep it simple usually turns out better
?
stdlib.h is a standard header in C++ also. An advantage of using it is that you don't need to type `std::` before the names it introduces. 
If not language change, then at least standardize interface / concept for Property.
Having both getters and setters is a massive code smell. Make the variables public and if there is an invariant to maintain then extract out those member variables to it's own type that enforces that invariant.
That's easy to say when it's your own small project. It's much harder when it's a library class that may end up with a hundred downstream users. That said, getter/setters are obnoxious. You don't just lose operator=, but all math assignment operators. rect.width += 5; //nice and simple rect.setWidth(rect.width() + 5); //gross rect.width() += 5; //you lose the ability to act on writes to width, might as well be rect.width again 
Why it is bad to have both setter and getter? Can you show example.
Well what's wrong with that solution? Not exactly what you want, but it does the job
Unless you care about ABI/API stability and don't want to tie yourself to a specific implementation forever.
But how you react on rect.width += 5; ? How you even know that width changed?
It only works as redirect. You can't react on mutations.
Having types that expose all/most data members with getters and setters or just have a large amount of them would be a code smell. Just having getters and setters is not. Exposing those variables directly is not possible if additional logic is required, like maintaining invariants (not all invariants can be maintained just in the type of the variable), settings flags or whatever. And you have to break compatibility if you switch from variable to setter.
I'm happy to take you take your word for it (although I would not mind seeing that documented somewhere). Leaving out std:: does not seem like a great idea to me (for clarity of code), and as you are undoubtedly aware of, you can just use using namespace std; and you'll never need to type std:: anywhere. You pointed out that this is a C++-discussion, in C++ for "real (wo)/men", you include &lt;cstdlib&gt; (and the others) and just type std:: in front of everything that needs it (IMHO). 
This breaks information hiding. However, it could be argued that for example a class holding only data does not need getters and setters, as there is no logic. (and there shouldn't be any logic)
The intention with properties is that you can expose them as variables while still performing processing when they are modified (and additionally when queried as well) Just exposing public variables doesn't achieve that.
I agree maintaining an ABI is an exception where it can make sense. This is only common in libraries though, usually not in application code.
 I like this, but let me add the perspective of someone whose library has stricter (memory) safety requirements for reference ("zeiger"?) types. &gt; Core Property Ⅰ: Object Access Syntax I agree that the distinction between explicit and implict dereferencing is important, but for a different reason. From a memory safety perspective the important thing is that (for the foreseeable future) C++ supports (user-defined) smart pointers, but not smart references. And if a pointer or reference is not "smart", then it is not, in general, safe. So if your code uses "arrow interface" pointers, then that code is "safety upgradable" in the sense that the pointer types can simply be replaced by safe smart pointer types. If on the other hand your code uses "dot interface" references, then it's much less "safety upgradable". From my perspective, the safety upgradability of interface types is much more important than their role as subtle indicators of the nature of their use. Convenience is another story. I think the relative value between safety upgradability and (the very slight) extra convenience is subjective. But it seems to me that the only legitimate reason for using reference syntax over pointer syntax is extreme laziness (of which I am, and I assume most of us are, personally guilty). As you point out, the lifetime extension of references is (very insidiously) unreliable, and therefore (insidiously) unsafe. The other issue I'd like to address is ownership. May I humbly request that you replace the term "ownership" with "lifetime ownership" (or perhaps more accurately, "deathtime ownership"), if that's what you actually mean? A (smart) pointer can have other very important types of ownership. In particular, it can have ownership of a (read or write) access lock on its target object. And I think that fact is underappreciated (and underutilized). Which brings me to your talk where, beyond just presenting the taxonomy, you make actual recommendations for which reference (zeiger) types to use in various situations. Might I suggest that those recommendations are valid with respect to a certain (unstated, high, and almost ubiquitous) degree of tolerance for (memory) unsafety. But for those that either have, or want to accomodate more stringent safety standards, I would suggest that there may be more [appropriate recommendations](https://github.com/duneroadrunner/SaferCPlusPlus#pointer-use-case-comparison-table). Also, one of the slides says "Always prefer unique ownership to shared ownership.", which you justify, in part, by noting that `unique_ptr` is faster than `shared_ptr`, which is true, but only obviously so for the "quirky" standard library versions of "unique" and "shared" pointers. I'll point out that if you consider memory safe implementations, it is not quite so obvious that a pointer with "unique lifetime ownership" is faster than one with "shared lifetime ownership". In a memory safe implmentation, the shared pointer would not have a thread safe reference counting mechanism (there would be a [separate pointer type](https://github.com/duneroadrunner/SaferCPlusPlus#the-problem-with-stdshared_ptr) for sharing between threads), and a unique pointer would have to check every dereference, where a "not null" shared pointer wouldn't. Just two cents from the perspective of those trying to achieve memory safety in C++. Keep up the good work. :) 
There is a lot of legacy code out there which is still used every day in industries where disruptive change is very hard because of a need to provide 100% uptime (airline reservation systems, banks [retail and investment], defence industries, ...). Almost all of it closed source and enormous. Maybe some of that can be classified as "not maintained" but it may well be built every night and have patches applied when things break.
Sorry I maintain that most invariants can be enforced by extracting out the invariant to its own type. Of course as usual with best practices it's a code smell, not an absolute. There will always be exceptions. Having variables exposed both with getters and setters should still be rare as you're either mixing responsibilities of the class or breaking encapsulation
I would love to have a language feature for that but just as with so many other examples, the committee apparently doesn't like to standardize things, that just make life easier for people if it doesn't solve at least a dozen other problems at the same time ;) What I actually believe is going on is that hings that just make things easier are usually not important enought for people on the committee to spend the time and effort required for standardization.
The purpose of making member variables private is encapsulation. Providing both getters and setters means you lose encapsulation but still have the boilerplate overhead. Now if you use a setter to maintain, let say, that an int should be positive or that two variables need to satisfy a relation then a simpler solution is to just wrap those variables in a new class for the single purpose of expressing that constraint.
&gt; Well, theoretically they can be forwarded too... rect.width() could return a special wrapper object that can understand assignments. But that leads to *more* complications, eg "auto x = rect.width()" captures the wrapper object, and is a *reference*, not a *copy*. So when you change x, you change rect. The more clever you get with C++, the more it ends up biting you in the end. &gt; How is this should be solved, on your opinion? Language support for getters and setters. struct Rectangle { property&lt;int&gt; x = [] { return this - 2; }, [](int val) { return this = val + 1; }; } rect; rect.x = 3; print(rect.x); //prints 2 //dumb example you'd never do, just showing that the getter/setters are called //despite X acting like a regular int type assert(sizeof(Rectangle) == sizeof(int)); //crucial The key goal is that you need to be able to change struct Rectangle { int x; }; into the property version, and all that is necessary is code recompilation, and no code changes (unless someone gets stupid and tries to get &amp;rect.x or something.) I would go further and add read-only semantics (eg readonly property&lt;int&gt; x), so you could expose rect.x as readable outside of Rectangle, but not writable unless inside of Rectancle or a friend class of Rectangle. 
okay, so tell me: I have this struct with two properties: struct foo { float readiness; int bamboozle_count; float whatever_member_function(); }; How do I : * add some logging whenever `bamboozle_count` goes over ten without requiring all the users of my API to change their code * enumerate the member variables and get them as string for serialization, e.g. in json * apply generic algorithms to properties, e.g. to generate a UI 
&gt; This is only common in libraries though, usually not in application code. I'd wager that most C++ code in existence is in libraries by far, even if these libraries are only shared among one or few applications
1. You can’t. 2 and 3. You cannot do that with just a bunch of “properties” either. Or did I miss something?
Correct.
That example is ok, the actual problem is with classes: struct Foo { int i; Foo() {} }; auto f = (Foo *) malloc(sizeof(Foo)); assert(f); f-&gt;i = 42; // UB Because you haven't constructed `*f` yet (i.e. calling the constructor), accessing anything from `f` is undefined behavior.
From my corporate experience this has not been the case. Everything has been compiled into single binaries and if some components are moved to shared libraries they are still rebuilt everytime so ABIs doesn't matter.
&gt; 2 and 3. You cannot do that with just a bunch of “properties” either. well it depends on the property framework you are using. With Qt this is possible for instance - at the cost of a macro.
I guess qmoc takes care of those features then?
it can be done [purely in C++14](https://github.com/woboq/verdigris)
Well... From one side \*\*yes\*\* ... But from another side \- your \+= operator still not work, even with language support. Language\-based property either will not accept operator\+=, either apply without tracking.
The reasons to have a "property" are: * debugging; wanna see who's changing or reading stuff? Breakpoint in a getter/setter! * if in the future some intelligence is needed, no need to change other code, it's ready for that change
1. Use data breakpoints, when data changes, break. 2. The future is the future, how should i know what is needed? :) But i get it, _if_ you're designing a library for others to use the requirements are different than for just in house development. 
1. On many instances?
Sure, that does not work then. 
I cannot find the operator\-\&gt; for your iterators. Is that a bug or did the standard drop that requirement in some revision and I missed that detail?
Do we have the reverse too? Unnecessary include detected '#include &lt;set&gt;', you do not use any of the functions.
This is brilliant. Also, math functions that return parts of their answers through pointers or globals (lgamma) could return narrow types. Then the whole of cmath could be made constexpr. In practice, we would need a little help from C library to provide these before they write to errno. The global and pointed versions would be wrapped around the C++ versions. Actually, C could use these just as well.
static_assert isn’t called, it’s a compile time construct resulting in a compiler error. You could come up with some involved mechanism where you dynamically compile code snippets containing statements that violate your static_asserts and check for failed compilation, or, better, check the actual compiler error. Basically what you’re looking for is a way to compile short strings of code.
Since static_assert makes the compilation fail, that is what you can test: compiling a source file with that statement should result in gcc, cl, clang, whatever compiler you use, to return non-zero. This would mean a compiler invocation for every such test case. If I'm not mistaken, CTest has a framework to execute such tests, but other than that I know of no tools that make this easier on you...
Nah, the += case can work if the compiler transforms it into a get + set call. A more elaborate API could also allow one to define the all of operators if one wanted to, eg: class Rectangle { property int { auto&amp; operator+=(int value); } x; }; There's a lot of things C++ *could* do for you to reduce boilerplate code: if you implement == and &lt;, C++ could deduce all other cases by simple logic: != is !==, &gt;= is !&lt;, &lt;= is &lt; || ==, &gt; is !&lt; &amp;&amp; !== 
[This](https://ariya.io/2005/11/property-in-c) may be interesting for you. It's an old problem with old solutions :-)
I think people don't like the argument "it works fine in C#" even though that's pretty much the best argument one can come up with when discussing properties. Plus, properties can be made zero-overhead unless special processing is required in the getter or setter. Again, the best argument for them as a *language feature* is that they are already a proven concept in C#, Kotlin, Swift, etc, etc.
Roland Bock held a talk about exactly that at Meeting C++ in 2016: https://www.youtube.com/watch?v=zxDzMjfsgjg
Again 100% agreement
If you use cmake then check this example: https://github.com/ldionne/libawful/blob/659333af04f41af793d861d947411d3d336fea3a/cmake/compile_fail.cmake
You can. In T's has assignment operator 
Indeed, you can tag a ctest as failing at build time 
I still don't understand why people use C++ for web application and Javascript for desktop application. It's like drinking soup in a fork.
you could replace it with a macro which throws an exception if false. this of course takes away the compile time error in your unit test file. 
Try LLVM FileChexkm
xkcd template
[Link to the proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0186r0.html)
Really? Xcode only uses about 300mbs on mine...
The future is the future, how should i know what is needed? :\) YAGNI
You can find comments regarding the recent papers in issues.isocpp.org Here is one for this paper: https://issues.isocpp.org/show_bug.cgi?id=155 &gt; - Paper looks good so far, some feedback provided, suggest it is brought back at the next meeting with some revisions and cleanup (esp. filling in the "TBS" sections). From the paper: &gt; **Is the target C++17 or the the Ranges TS?** Deferred until the committee decides if the Concepts TS and Ranges TS are included in C++17. I suppose that dependency is the reason there haven't been an update. It might come again, after Ranges TS gets accepted into the standard. 
&gt; In particular, object lifetime is currently assumed to not extend past the process lifetime. SHM segments used by two processes will cause things to persist beyond the lifetime of the first to terminate. The fact that something in a SHM segment could have been put there before the system booted rather than merely before the current process started wouldn't necessarily be a shocking change in semantics.
Note that `holder(What&amp;&amp; w) : what(w) {}` makes a **copy** of `w`. If you want to use move semantics, you should use `what(move(w))`. Also, you can disallow the lvalue reference structure by specializing the holder structure: template&lt;class What&gt; struct holder&lt;What&amp;&gt; { holder() = delete; };
Having getters and setters may also allow you to change the implementation of your class without changing the interface. That's an important aspect of encapsulation. In many cases I agree about combining interdependent variables in their own class (example: calendar dates). However, if those constraints particular to the interface of a given class, I would rather combine their setters (example: setAB (int a, int b=0) where b only needs to be set for certain values of a). 
It does achieve that of course. You just can’t expose raw C types. Make the variables a fancier type and they will do all you want and then some. 
`Property&lt;x&gt;` is close. That class would need an optional template argument for the traits you need for a given property: code to run on change, etc. 
Why not use `expected`? 
It’s trivial once you understand that types denote functionality. A float won’t ever do it. Make it `P&lt;float&gt;` and then you can have all of it and then some. 
People are missing the point of why getters and setters are an anti-pattern all over this thread. If you have trivial setters and getters, the response should not be "just make the data public". The response is: it simply shouldn't be a member of the class. The primary purpose of a class is to maintain invariants and expose behavior, and a trivial setter prevents that member from participating in meaningful invariants, and a getter limits your ability to change the data members that provide the behavior. If you have non-trivial logic, then it's not really a setter or a getter; these by definition refer to functions that set/get a member variable. A good example of something that is not a getter is something like vector::size; it could return a data member or not depending on how it's implemented, but regardless it returns the conceptual size of the vector which doesn't necessarily have to correspond to a member (the big advantage of returning by value and not reference). There will still be times when you need a setter or a getter for various reasons, but it shouldn't be anywhere near often enough that you need a library or language feature. If you feel like you do, you're almost certainly writing a lot of sub-optimal classes.
&gt; That's an important aspect of encapsulation. Encapsulating is for isolating side-effects and making them obvious, not for sweeping them under the rug. Having side-effects occur when it looks like you're accessing a field is the _epitome_ of bad design; encapsulation for its own sake is not a goal.
Thanks for your very valid question. I agree with you 100% C++ should not be used for web development . However , CRUD is not about web development , it's about adding rest handlers for your C++ application . Say you have an app written in C++ that needs to be administered via HTTP . With CRUD you can simply create endpoints . Also , because this library is light weight you can probably use it for real 'embedded systems' , the performance was our main concern , we've used this library for our project where 50K QPS were needed on 2 core machine .... we've looked at so many other solutions on GitHub and could not get anything close to 20K QPS , so we decided to write small CRUD library - it's not perfect , but we hope with comments and issues created on GitHub we could make it usable for others.
Nah, it wouldn't work as you think. The main reason \- it needs pointer to the class where it stored, like so: struct Data{ int m_i; void show(); Property&lt;int&gt; i = { [](const Data&amp; d){ return d.m_i; } [](Data&amp; d, int i){ d.m_i = i; d.show(); } }; }; At first, EACH Property is \+ 1ptr to sizeof\(Data\); at second \- you need somehow to update pointer to Data in Property. At third, you'll have problems with lambda and auto at class level... I would say \- it can't be done, without metaclasses.
encontrado will be TRUE if (clave==actual-&gt;claves[*k]) , otherwise FALSE. more specifically, 1 if true and 0 if false. 
so... \(clave==actual\-\&gt;claves\[\*k\]\) it's a implicit if? 
Well... something telling me, that compiler will not allow you to do anything besides simple =. C# does not allow. Proxy type \- is type that mimic \(forward most calls to\) other type, but can hook any of that calls \(read/write value is op too\). Metaclasses, I think maybe allow to do this: we can make class which have all members/values as original one, and all calls are forwarded to original. But on operator= we hijack call, and execute our logic. Maybe not...
Show me.
Thanks for your comments. Yeah, as I wrote, the code I posted has other problems and is not pretty in any sense, but was the smallest illustrative example of the problem that popped out.
No it is not an "if" it is a "boolean statement", that is, will return 1 (TRUE) if is true, or 0 (FALSE) if is false.
I understand Thanks for your help.
a == b is not a statement, it's an expression that evaluates to 1 if true and 0 if false.
But.... At first, it stores data inself, which may be undesirable. At second, it stores parasite pointer to "holder" object. At third, I don't see that \*owner pointer being updated. What if class copied or moved? At fourth \- after all this \- how this approach is better then [functional](https://github.com/tower120/cpp_property) ? In both cases to access data, you at least have to do cast. Problem may be old, its true. But solution is different, at least, because in 2005 was no lambdas.
You should just make those variables public. 99% of the time, changing the implementation of classes with trivial getters/setters requires an interface change as well. "I might need to change the implementation later" is just a misconception. You might want to have only getters or only setters on a class, which is fine, but if you need both, making the data member public makes a whole lot more sense.
&gt; changing the implementation of classes with trivial getters/setters requires an interface change as well. How does interface linked to implementation? &gt; "I might need to change the implementation later" is just a misconception. Why? What's interface stands for, then? Do you change your electrical outlet each time you buy new electric kettle? I think, interface is a thing that allow you not to play oracle, which try to predict future.
In practice, that rarely happens. You write a class, and then you use it. If you really need to separate interface and implementation, you would know at the point of writing the class. Writing getters and setters everywhere is being paranoid. Do you write ::std::addressof(object) when you want to get the address of an object, because that is the **only** "correct" way to do it?
No, it evaluates to true or false. If you then try to assign the result to an int, it will be implicitly converted to 0 (for false) or 1 (for true).
OP clearly stated that this is C code and there is no bool type in C.
OP also posted in a C++ sub-reddit, so... Yeah.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8o6kxp/problem_when_understanding_a_sentence_in_c/e015w2p/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
As lons as we don't have `operator dot` this kills readability. I did a oroject like this and it was terrible.
Floating point types have equality operators so that you can check for equality. Don't believe those who claim this is never a valid thing to do, it just has to be done with care. Telling when a Newton's approximation has converged is one reason, here are a couple of other examples: https://randomascii.wordpress.com/2014/01/27/theres-only-four-billion-floatsso-test-them-all/ https://randomascii.wordpress.com/2017/06/19/sometimes-floating-point-math-is-perfect/ 
He's comparing 1.3f to 1.3f. The fact that 1.3 cannot be represented in a float is not relevant because he is comparing 1.3 as a float to 1.3 as a float. The fact that this is problematic on x87 FPUs is a tragedy that I am glad we are moving away from. So yes, it is absolutely a compiler biting, triggered by a problematic FPU design. 
completely untested: template&lt;T&gt; class property { const std:: reference_wrapper&lt;T&gt; ref; property(T&amp; v) : ref(v) {} // Most likely you actually really want to std:: forward ... Left as exercise property&lt;T&gt;&amp; operator=(T&amp;new_value) { // log writing ref.get() = new_value; } operator const T&amp; () const{ // log reading return ref.get(); } } Usage could be something like class foo { type barmember; property&lt;type&gt;&amp; bar() {return barmember;} ... } 
On Windows there's plenty of precompiled binaries for MSVC. CMake with find_package() makes finding them and attaching to project fast and easy. MSVC and VS Code are quite nice IDE. However - precompiled binaries are installed system wide. I would need some kind of project separation (like virtualenv on Python). Again - MSVC with conan works rather well. Even compilation not existing binaries for log4cplus,boost or gtest. With gcc there's little more work - ie. Qt by default ask to install mingw, the same with git (but I didn't saw g++/gcc inside those installation). Suddenly it becomes crowded with mingw installations. On Linux I can create docker image with everything needed to compile (with ie. qtcreator). How to achieve the same on Windows? WSL will compile Linux binaries. I don't know if Docker for Windows allow to create isolated compilation environment with Windows binaries - I need to check it. I would like finally to have like 1-2GB file ie. on pendrive which I can download on Windows OS and work in isolation. Without interfere with my other works. Without polluting system with plenty of binaries/librariers, etc. I know I can achieve this with VM - but they are little too complex, takes little too much space and are little too slow.
Compiler guy here. The biggest slowdown with pseudo random number generation comes from the fact it is sequential. One generation must wait until the previous one is complete (as it updates the internal state). The easiest way to speed that up is to have multiple parallel internal state, and generate a vector at a time. You may want to have more than one vector computed per cycle, to account for pipeline depth. Usually compilers try to do that for you, but pseudo random generator are near impossible to expand.
An interesting read. I'm certainly not going to argue that one can't write good and safe C code. It just requires discipline and some willingness to learn some good design patterns. I liked the code I saw in your example. Different stokes for different folks I guess, but when I write C++ code, I rarely have "feature anxiety." I simply stay away from features I'm not really comfortable using yet, but I certainly know enough modern C++ to write APIs that are pretty much impossible to use incorrectly. It's not a terribly difficult skill to acquire, but it does take time to properly learn. Just like with C, you typically need to see and learn from good examples. And as you point out, there are some pretty awful C-based APIs out there, just like in many languages (including C++), with which we can learn what *not* to do, I guess. I'll certainly agree that the price of C++'s robust set of features is a higher degree of language complexity, but again, I think it's worth pointing out (and I think STL made this point in one of his video lectures) that there are two degrees of difficulty in C++. There's the difficulty of *using* libraries, which actually has a pretty low bar, and there's the difficulty in *writing* libraries, which has a significantly higher bar. You talked about boilerplate code in C++. Yes, certainly more boilerplate code than in C, but then again, you get the benefit of an object that automatically cleans up after itself without fail when it goes out of scope, or is deleted when all references disappear, etc. No matter how you dress up the issue, a C programmer needs to be responsible for their own cleanup code in some way, because you can't always avoid dynamic allocation - especially not in large, resource-intense projects. Not a huge deal, of course, but it is what it is - an opportunity for a mistake to be made. C++ has plenty of those as well, but I feel they tend to be focused around designing and implementing your classes. The benefit and purpose of much of that "boilerplate", of course, is that once your class has been written correctly once, it's a bit harder to mess up the code which *uses* that class from there on out. In short, I think C++ classes are certainly harder to *write* than equivalent C functions, but they're easier to *use* without errors. Personally, I find that the ability to wrap up my code into neat class-based packages, the improved type safety, and the protection that encapsulation-type features provides helps to keep my cognitive burden lower, especially when I'm working on very large-scale projects. I'm pretty sure I could do the exact same thing in C, but it seems like I'd have to work a bit harder to focus on some of the low-level management that I get for free with C++ because the compiler manages many of those details for me. I'm glad you're enjoying a return to C, but I'm not planning to follow you there, sorry. Thanks for the article! 
I share a lot of the views in this article. This is why it really pisses me off that the best potential we have seen for c++ to really become readable ... true terse concepts ... is being poo-pooed away by high minded people in the c++ committee. sort (Sortable&amp; container); ... is the only thing clients of my code should have to write. On the other hand, writing C in C++ world is pretty easy with the exception of having to work around some of the void stuff. So I guess the main point of writing in pure C is that it forces you to buy in 100% to the C mentality, and that can have some very positive benefits on productivity in certain applications because C is small enough that the cognitive load is relatively low. 
I get the aspects for C around smaller binaries, smaller language and the not mentioned faster compile time. However for someone like me who is growing up in a modern C++ world what is the advantage with pure C vs C-like code in C++? I didn't get that from the blog post.
And who this related to T&amp; get_value() { return value;} ?
It wraps T&amp; so you can react on assignment. The example bar() is the get_value replacement. It also provides an example of an operator= for a type. But since you might want to react to assignment for types where you cannot change the assignment operator, my original post was probably a bit unpractical. 
Since whatever he wrote in C could also be written in C++, I don't get why he says C is better than C++ for writing building blocks code. If people over-engineer their code because C++ has so many features, it's their problem, not the language's. 
I mean, you can try and restrict yourself to C as much as you can and still enjoy some features of c++ (references, stl containers, smart pointers etc.) There are indeed so many things wrong with some of the stl methods though... 
Because he is a hipster and want to differentiate himself from others and look cool, that’s why... This: “I have no intention to go ‘all Modern C++’ though.” 🤮
How? The user just uses the normal notation, e.g. `foo.x = 5`, and under the covers some `P&lt;int&gt;::operator=(int)` does what you need. 
There are two approaches: either it’s the size of `T` and takes extra functionality (custom setters, getters, and parent class offset) as template parameters, or it’s a virtual interface that gets specialized by a template implementation on the fly, and then it adds the vtable pointer. Personally, I use the first approach. It’s the C++ way: zero overhead and you pay only for what you use. 
[You can use std::offsetof only for standart layout types](https://en.cppreference.com/w/cpp/types/offsetof) .Hence whatever you personally do \- is UB for sure, unless you only work with struct. And without access control \(aka all public\) \- there is no need in properties at all.
I’d say that if you’re writing complex constructors/destructors in non-low-level-resource-managing classes, you’re doing it wrong to being with. The argument that the author makes is that it’s cool to be limited to structs of PODs, and essentially using those as argument packs for constructors instead. He still writes constructors, only they take a single argument. How is that better - I can’t quite see. 
There is no need for `offsetof`, ugh — this is not C. Templates can take more complex non-type parameters than integers. A member pointer can be a non-type template parameter. No UB. 
I think he was talking about small building block libraries here. In that context, nearly every language in existence has a way to import C libraries. If you wrote said building block in C++ you would need to write a small C wrapper in most cases. 
&gt; I have no intention to go ‘all Modern C++’ though. Well, enjoy shooting yourself in the foot then
most of us just make it up as we go along dude
How templates linked to getting parent class offset at all? How do you get pointer to parent object?
Afaik designated initializers are accepted into 20.
story of m'life
Are you sure? Please point me at widely used library like Qt / wxWidgets / UWP / etc. where **values** are exposed, as part of interface. For example, take a look at this QPoint [http://doc.qt.io/archives/qt\-4.8/qpoint.html](http://doc.qt.io/archives/qt-4.8/qpoint.html) class \- it can't be simpler, yet not a single free standing value exposed. In particular pair x\(\) / setX\(\) \- surely they are trivial setter/getter. I mean, there is a reason for this \- and its definitely not logic triviality, or invariants, it's **INTERFACE.** 
Gosh. I hope it doesn't mess anything else up, and won't close any hitherto open doors.
You go backwards from the pointer to the member, and yes, it can be done in non-UB way.
"true terse concepts" have major issues. I'd recommend reading Herb's P0745.
Well? How you go backward from member pointer to parent object pointer?
Typically the program is divided into logical units/modules that perform a given set of tasks. this can correspond to a class, possibly a group of classes/structs and global functions. For each of those units, its implementation (function definitions) would go into a ".cpp" file, and ith interface (class definition, function declarations) into a ".h" header file. This file is included by other modules that use it. A makefile is written so that it compiles each ".cpp" file into an ".o" file, and at the end links all the ".o" together into the final executable. This way, if one file is edited, it only needs to recompile the ".o" for that file, and relink the executable. CMake is a layer on top of Makefiles: By writing a CMakeLists.txt file for the project, CMake can automatically generate Makefiles (or other), which can then be used to compile it. The CLion IDE uses CMake. Visual Studio is Windows-only and has its own build system instead of Make.
The best advise is to just start the project and see where it gets you. Don’t be concerned about these things until you actually need them. On windows I’d just pick Visual Studio. You have a nice GUI, where you can set include path, compiler options, etc. No need to bother with CMake until you really need it.
Get something working (minimalistically) and re-factor as you get along. Data structures you get from the STL. Algorithmic analysis? Wikipedia is your friend, GitHub as well (get parts (i.e. libraries, written and tested for you to use) of what you would like to do from there, if and when available. Interfaces go into headers, implementations in "code files". IDE's are handy things, but they are tools and it takes time to get used/familiar with them, but definitely use one. Use an IDE that's free (VS f.e.), CLion costs money and code-blocks is sub-std. Use clang, also on windows with VS (https://llvm.org/builds/). Style and Workflow, that's your job, look at other projects (like on GitHub) and adopt something that appeals to you (I like SFML style, it's simple and stupid, stick to that, before complicating details), but write clear code with comments about **what** you are trying to do, the names should support the latter. Split the problem in bits that you are able to bite of (and test). If you get stuck, go to stackoverflow.com (and learn to effectively ask a question)Since you are asking this question (or you'll get dissed). I would suggest to try your hand at some more modest projects. You should because if you did not need to do that, you would not ask this question. Otherwise, happy programming and let us know how you're doing.
Code designing and structuring is important in any larger program (in any programming language). Multiple files should divide program into logical components and make code easier to read. In larger programs it is also useful to separate different larger components to libraries. In C++ header files provide interface for using the component in other compilation units (== source files). Basic rule is declarations in header files and definitions in source files. So declare functions and classes in header files so they can be used by including the header file and define function implementations in a source file with the same name as the header. I recommend looking into CMake build system because it is the most used Makefile generator currently. Most opensource libraries are build using it so learning at least its basics are required for compiling many libraries. Also multiple IDEs can use CMake files as project files. IDE choice is matter of preference. I prefer QtCreator but Visual Studio, Visual Studio Code and CLion are good also. Try some them and use what feels best for you. Writing a hobby project and writing large scale commercial software as a member of large team have quite different workflows in terms of writing an application. Also you were to go out into industry your first task wouldn't definitely be designing a large application from scratch. Likely first task would be fixing some scripts or some small component of a larger program. In hobby projects it is more reasonable to write not so clean code and just hack something working because it is important to get something working fast so you can keep being interested in the project. But anyway from software designing perspective it really helps if you can properly divide components into good (small) classes, functions and files (and name them reasonably). Good basic rule is that classes and functions should do one thing (which can be read from the name of the class or function). IMO best way to learn these things is to write code. You definitely wont be doing perfect software the first time but hopefully you realize what went wrong and figure out how you could do it better. Eg. build a painting software (something like mspaint) (good way to try out eg. Qt framework). First iteration of the software probably doesn't allow much else than drawing pixels on a canvas and implementation is hard to expand to support more painting tools (at some point just adding one more 'if' to mouse press handler doesn't work well), so you start to refactor code and move painting tools to different classes with abstract base class. Then you realize that 'undo' would be a nice feature but creating 'undo' feature with you current design isn't possible and so on. 
Sorry but that is too dismissive. You didn't address any of his points but just mock his preferences and interests. He is not trying to convince anyone to anything or bash other languages just to simply share his experience. I personally found it very interesting even if I will never have a chance to use C. 
Because writing a C-like code in C++ is frown upon and considered bad practice. Actually many times people put forward the opposite argument then yours. If you want to write C, use C rather than C++. Also, putting all the fault for complexity on the user is ignoring the fact that there is a serious discussion in C++ community about its complexity. 
&gt; C fits into a multilanguage toolbox better than C++ because integrating C with other languages is usually much simpler than trying the same with C++ This is basically why even C++ people recommend doing **hourglass** interfaces: "&lt;frontend&gt; &lt;C89 thin layer&gt; &lt;C++ backend&gt;" https://www.youtube.com/watch?v=PVYdHDm0q6Y
Mhm, And who writes unit tests for the generated test cases?
Visual Studio 2017 also supports CMake files as a project file so using CMake with Visual Studio is much better experience currently than it was a few years ago.
so you're saying this idea was bad to begin with? I was thinking something that may be just generates the instantiation of what need be tested...?
Trump is your friend (couldn't resist)!
Actually, people mostly say to write C, but use C++ compiler because all things being equal C++ compiler gives you better type checking.
GTest supports type-parametrized unit tests so that will probably solve most of the issues. You just need to list all types that you want to test. If you eg. have to generate test cases for templated matrix classes with multiple different sizes you can use template metaprogramming to generate them so you don't have to type them all. Hopefully you can also somehow reasonably create instances of tested types easily. Template meta programming might help with this also. One example of type-parameterzed unittests: http://anadoxin.org/blog/type-parametrized-unit-testing-in-gtest.html
Even that isn't always sufficient, there are few modern C language features that aren't supported by bunch of FFI bindings (notably zero/variable length arrays at the ends of structs).
You should use C++ compiler even when you write C (if you can get away with it), that is not always possible, small embedded chips don't even have C++ compilers and bunch of arcane platforms doesn't have one either.
This, start with the smallest working version and iterate from there. Have the app executable at all times. Don’t blindly code for months..
Honestly, just go look at other big open source projects in C++. I believe some of them might be mumble, VLC, and krita. https://github.com/KDE/krita krita is probably more modern.
My advice is to start with the foundations: logging, error reporting, debugging facilities, abstraction layers on top of platform-specific bits, stuff like that. It helps immensely in keeping the development process smooth throughout. 
Why would it? Honest question.
I was talking about the common case where you have a class that has setters and getters for only some member variables. If you have trivial getters and setters for every data member then you have no class invariants and in the vast majority of cases you should have a POD struct. This is pretty well understood, in fact (even directly discussed in the core guidelines). A lot of libraries are writing Java in c++, it doesn't make it a good idea. A point class is the canonical example of something that should be pod.
It locks a certain kind of syntax in stone. It won't be available for anything else.
Use git as a versioning system. Use CMake as a build system generator. Use Google test and Google mock for unit testing. Use clang-format to automatically format your code. Setup a build bot that is green when compilation, format and testing all pass. Design your program as a library, and link the final binaries on it. This helps tremendously to recycle code, build small helper programs and in general test it. Have the following folders: - src/ for .cpp files and private .h files - include/ for public .h files - test/ for unit testing - share/ for resources (images, translation text) - scripts/ for executable scripts - doc/ for documentation In src/, include/ and test/ you will create subfolder/subsubfolders when things are correlated. A new class start it's life as private header with methods code of more than 2 lines in a separate cpp. Once it is big enough that you want to test it, make the header public. You will want to see coverage of your tests once in a while (it is slow, but useful to find missed bugs), you may want to run a daily buildbot on that. You will want human readable textual representations of your program binary file formats. Do not hesitate to not include a header but instead forward declare a class if you can (to speed compilation). In a .cpp file, any helper function you write must be static, any class most be in an anonymous namespace. All in all, the more you do testing, the easier your life will be. Do code review (if you work with somebody) and ask for testing of anything added. When you code, comment your code with: - what a function or class do - how (small snippet), when and why to use it And any assert count as a comment, so put as many of them as you can. A bug that trigger am assert failure is a bug you can fix in 5 min. A bug that don't is a bug you may not fix in a day.
Some years ago I wrote a small blog post about this: https://petriconi.net/?p=118
Have an executable branch at all times, for instance master.
&gt; I know how to use the libraries One way to think of a full-scale program is it being many libraries. Rather than thinking of a convention to handle debugging output, make a debugging library that works for what you need (or borrow one and write a wrapper for it that works for what you need). The trick is when you get libraries that need to interact with other libraries and need to handle your includes correctly, which will vary based on whether you're using (C)Make or Visual Studio. The reason you want an IDE is basically so it can detect whether your code is valid or not before you try to compile it. If you're using vim or emacs to write your code, it's not going to be that smart. An IDE is also very helpful because you can easily navigate to other files, eg, by clicking on an `#include` line, you can also easily lookup the definition of a function, and if you have comments on a function or variable simply highlighting the name will show you the comment and signature. Visual Studio also has a debugger built-in so you just need to start debugging and all of a sudden you can step into code and inspect the state of objects. Real-world reality check, though: If you go out into industry you won't start a large-scale project by yourself. You'll join a project that's well established. I joined one that has 1M+ LOC already written and this kind of basic architecture was decided years ago. While I may have some opinions on it, they don't need me to do that because everyone is very capable.
Also, know a little about patterns was a great start for me. That way you don't get stuck reinventing the wheel. 
Be prepared to rethink everting you have learned writing small programs.
&gt; I don't know when I should be using header files The generic guideline is "declaration in the header, implementation in the .cpp". They're also the right place for declarations that need to be accessed from multiple source files. &gt;I don't know the logic behind having multiple code files or a makefile Generally, a class should have its own .cpp and .h file, and pieces of code that are not related to each other probably shouldn't be in the same file. Sometimes there are good reasons to ignore the guidelines. Sometimes there are solid engineering reasons, and sometimes it's just a matter of taste. People tend to be able to feel the difference when they become more experienced. &gt; I don't know why I would use an IDE or which IDE I should use \(CLion, visual studio, codeblocks? what are the differences?\) IDEs are tools, but when to use them is really a matter of opinion. The only real answer is "when they help you build software". Personally, I usually stick to a bunch of terminal tabs, some files open in vim, and use of Unix tools. Some others never step foot outside of an IDE. They can both be viable strategies. As for choice of IDE: Try them. Everyone will have their own opinion. You should form your own based on experience.
&gt; I don't understand how ”INTERFACE” justifies this stuff. INTERFACE allow you to change underlying structure at any time. Interface allow you to postpone decisions. Imagine that, at some point Qt would decide to switch from using bunch of bool's to packed bit field... Without stable interface in form of getter/setter they would have to reject that decision, either you should to rewrite your code, which use that Qt class .
I like to have an executable for almost every C++ file, simply by having #ifdef _FEATUREX_TEST int main() { (simple example of functionality doubling as test) ... return nonzero on failure ... return 0; } #endif And then in my build I have it as separate target to verify that stuff compiles, works as intended (passing -D_FEATUREX_TEST to compiler). This is super simple and yet it helps a lot both during development and if you ever decide reuse that part the code. It also serves as simple litmus test, if you can't write a simple test code into that function, you are probably doing something wrong and should refactor the code (every source file should have some _purpose__).
This is the best answer. Its a continuous process. The fundamental issue is the technical debt as you go along. Never be afraid to refactor and push back against manager types who hate allocating time for "refactor". The growth is always organic but you have to maintain a balance between navel gazing and actually executing the idea. Tools of the trade are source control, a decent build system, Google and an evolving thought process which is atleast 2 steps ahead of the code you are writing. Don't get lost in cutting edge C\+\+ features; Good software engineering has nothing to do with the latest compiler tricks or reading through C\+\+ standard proposals. 
I haven't read this full paper yet (i'm reading it now), but I have seen its summary. The reasoning behind the people, including Herb, who don't want that syntax is primarily that people will be confused into believing that they aren't using templates. I think this reasoning is entirely bogus. Clients don't care. All they care about is satisfying the concept and being given good errors when they don't. The reality is that a type is not really much different than a concept. Allowing this syntax emphasizes this fact. Certain people in the C++ world can't wrap their head around the reality that people other than library writers don't really care about the distinction. 
How should one skin a cat?
That is not the reason. Here are some actual reasons: First: Forwarding References: void foo(Type&amp;&amp;); // doesn't take lvalues void foo(Concept&amp;&amp;); // takes lvalues Second: Consistency with `template`s template &lt;Concept C&gt; // defines a type C that follows Concept void foo(Concept c); // defines a value c of a type that follows Concept Three: Supporting functions that have more than one type of parameter template &lt;typename Iterator&gt; concept ForwardIterator; template &lt;typename Output&gt; requires ForwardIterator&lt;Output&gt;; auto copy(ForwardIterator first, ForwardIterator last, Output d_first) -&gt; Output; // this is how you have to write this under Bjarne's proposal // also notice how first and last are the same type... for some reason auto copy(ForwardIterator{In} first, In last, ForwardIterator{Out} d_first) -&gt; Out; // nice! no template syntax!
Another small thing related to header management: Generally, I always try to minimize the api that needs to be exposed by each header. If there are helper free functions or classes that are only used internally by a class defined in the header, I make them static or put them in an anonymous namespace within the class' .cpp file instead of making them members of the class or global functions with a header decl. This not only keeps the header clutter-free and ensures most of the declarations/defs in it will actually be of use to those who #include it, but it can potentially improve link times when less symbols are exported from each translation unit.
Well, apart from all that's been said here, there are some things that are no properly programming. In developing a big application you should: - Use Source Control. Git is were everybody hangs out now, but anything is better than no source control. - Do tests. Don't take it as a religion, but your main functionalities should be tested. It helps in more ways than one. Become familiar with a framework and stick with it, they all do the same thing, basically. Google Test is a good place to be, as it's probably going to be maintained for a while. - Know your libraries. You say you do, but nobody does, there are too many of them. When you have something to do, try to abstract it, and probably somebody had that same problem at some time. If it's going to take you more than a couple of days, look for it before doing it yourself. Pay attention to licenses. - Separate concerns. Big things are unwieldy. Extract common functionalities into libraries. Don't have that big global object with all the interesting data. It's convenient, but in a big project will come back and bite you in the ass. Testing will help you avoiding it, as testing will be made more difficult with setting up the object and all that. When test setup is complicated, you are usually doing something wrong. - Separate IDE from kernel functionality. Try to leave the IDE as bereft of functionality as you can. - Don't do threads, that can of worms only to open if absolutely necessary. - Build from day one. If your program is a generic drone controller, you build an empty window the first day with an empty menu. Then you fill up the menu, then you make the menu items do things. Programming has a way of becoming a rabbit hole, your empty window is the light above that helps you not getting too deep. - Program. It's too easy to become embroiled in design decisions, or language decisions, or database decisions, or OS decisions, or IDE decisions, or methodology decisions, and not getting anything done. You take what is widely used, and move on, or you become the big guru that can explain all the shortcomings of everything, but never produces anything that runs. - If developing in C++, know template metaprogramming. Even if you are not going to use it, you should at least understand it, so you can read what others have written. Also, at least have a conceptual grasp of what can be done with it. Sometimes it can simplify your code mightily. - A function should do only one thing, and if at all possible have no side effects. Become familiar with RAII. Invariant objects make your life easier in general. Use smart pointers. I'm sure I forget a lot of things, but. Good luck. 
Upvoted the post just because of this answer.
To your first point. The fact that that concept hides a type shouldn't change the reference collapsing semantics. That is arbitrary, and could just as easily play by the same rules as everything else. Your second example is an opinion. It should be allowed either way. Concepts are a core feature. Your third example is arbitrary as well. It could just as easily be auto copy(IsInIter first, IsInIter last, IsOutIter d_first) -&gt; Out; // nice no template syntax, even shorter 
&gt; I don't know why I would use an IDE How are you writing code then, notepad?
Check out Lakos’s [Large-Scale C++ Software Design](https://www.amazon.com/dp/0201633620). It may be helpful to you.
This is almost exactly the work flow I follow for many of my projects. 
I agree with this, except template metaprogramming. You can do alimony everything without it, and it's generally clearer. Using the standard libraries will mean you need to know a little bit about templates, but only the basics, which is enough.
Half\-backed and broken.
Yeah, I know. Even for me, the jury is still out on that, but I stand by my opinion that at least you should be able to read the code of others without wondering if that's a different language :-)
The fact that the compiler enforces the same order isn't broken in any way. It doesn't reduce usability and it avoids misleading code. Lots of issues are caused by constructor initializer list ordering being misleading, which why every compiler has a warning for the exact equivalent thing. They can't change that because it's a big breaking change but they can get it right the first time with a new similar feature.
That strikes me as a very backwards way of thinking. If I implement a class and document how it works, whoever is using it should not depend on how the functionality is actually implemented, as long as it works as advertised. Why should the user of a class care if some data is stored in a plain array inside, in a std::vector, in a database or wherever? It just doesn't matter. This is also doesn't necessarily have to do with side effects. The getter may still be read-only, and the setter may still only set the value you intend to set. You broad statements about side effects sounds like you don't see any value in properties to begin with and just prefer direct access to public members. If that's your thing, suit yourself. 
One library at a time. Model your data into objects, write unit tests for your data objects, write factories, write unit tests for your factories, write controllers for your UI, write unit tests for your controllers, et al. The test first people say you should write your unit tests before you write your objects. I agree with plenty of testing, but I haven't quite drunk that kool aid quite yet. Give it a try if you want to, though.
1. Pick whatever IDE and stick with it. Your choice won't matter much as long as the IDE has basic C++ function (autocompletion, type deduction for when you use auto, and show all uses of a function). My favorite free option is KDevelop. 2. A good rule of thumb is a class per header file. As you learn you'll realize when to break this rule and when not to break it. 3. Plan your data ownership (i.e. who holds the unique_ptr's and if a certain piece of data needs a shared_ptr). If you can tell ahead of time who owns which data it'll save you lots of headache later on. 4. From this point forward... start writing your program slowly and carefully one feature at a time. You'll develop expertise as you go.
&gt; passing -D_FEATUREX_TEST to compiler Identifiers starting with underscore followed by capital letter are reserved for the use of the compiler ... Sorry, writing code that is portable across five hardware architectures means I see undefined behaviour everywhere.
We're all hackers and studying an open source app is a good way to see how others have structured their codebases.
It's broken anyways: &gt;I don't like having to know order at call site, doesn't make sense for the feature it's trying to provide, it's putting ordering constraints at every call site, while constructor initialization list, where that should be, isn't. C designated initializers are still more usable. That's part of an old discussion I was having [here](https://twitter.com/pepper_chico/status/972672199827054592), and don't have anything left to contemplate anymore. It's broken because intent of the feature can't be fully attained due to C\+\+'s own thwarts.
I noticed the same thing. I'm not by any means a C++ expert and I definitely understand the point of using C in situations where there's very little storage space available, though most of us will not have to deal with it. If your biggest criticism against C++ is *C fits into a multilanguage toolbox better than C++ because integrating C with other languages is usually much simpler than trying the same with C++*, then I really don't understand the point of picking some obscure new language when you want *C extra* instead of C++.
everyone has their own methods. it depends on whether you have all functionality of software planned or not. usually you would split topical functions into one separate file, with separate header file. you either do it at the very start, or when you reorganize the code fore better maintenance.
As a user of a supposed high level language, I want order enforced **only** when it matters, only then I'm open to go check back the data structure declaration to learn what the dawn order it should be \(written **on every call site** one is to use such kind of initialization\), otherwise I don't want it bother me.
&gt; I don't know when I should be using header files It's easy: Every class of your program belongs into its own .h/.cpp file. The .h/.cpp files should have the same name as your class. The class declaration obviously belongs into the header and the member function definitions into the .cpp file. This is very important for large scale C++ projects because otherwise you and/or your teammates will loose time to find the code you need to modify or even worse you will feel overwhelmed by any code change request.
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8o6yb5/one_year_of_c/e021ni8/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
"A fool with a plan can outsmart a genius with no plan." T. Boone Pickens Developing discipline in your life will help. I workout several times a week.
True, true. Also making C interface to you C++ library is easier than use a completely different language...
You are correct, it's a bad habit. I never do that for variables/function names (symbol mangling...), but still sometimes do it in this specific case because -D_SOMETHING looks a lot better than -DSOMETHING on commandline. And just to be complete, you should have probably mentioned that "__[a-Z]" is also problematic (probably even more so).
When I see these types of post ("simplicity of C is an advantage compared to the bloat of C++"), usually there are few points repeated that I don't understand. Minor rant ahead. ##### C++ is bloated First, I'll say beforehand that C++ is a big language. It supports many programming paradigms, and one of its main selling points is backward compatibility. This causes a really long release cycle compared to other languages, and if some feature does make it into the language it is here to stay - even if it is slightly broken. Moreover, I feel like many C++ library features should've been compiler features (`std::variant`, for an example, or [the recent properties thread](https://www.reddit.com/r/cpp/comments/8o0u97/properties_in_c/)) and this puts C++ in a disadvantage compared to other languages. But, do I prefer a language that doesn't support any of these features? Do I prefer a language that is designed with the mindset of "too bad, just re-implement it yourself"? Of course not! Copying and pasting code is not a valid alternative to the lack of generics or polymorphism. It's a code smell in the good case and a bug in the worse case. There's a reason `null` is referred as the "billion dollar mistake" ! Shouldn't we try to move to languages which try to prevent these problems? If you don't like the feature, don't use it. How is that a problem of the language? ##### Liking C, considering switching to a Better C As far as I can tell, C++ is a nice language which can also work as a "better C". Most C code actually compiles as C++ code, except that [functions without parameters work as you expect them to](https://www.reddit.com/r/cpp/comments/8nv0v3/cool_new_warning_about_missed_include_with_hint/dzype2n/). Moreover, features such as (non-nullable) references, scoped enums, range-based for loops, arrays that don't decay to pointers, `std::variant` and `std::any` are extremely easy to use features which provide both extra safety compared to their C variants and a nice productivity boost, as they help you detect errors as soon as they happen - even at compile time! ##### Boilerplate in C++ One of the things my coworkers like to complain about is that in C++, you *must* encapsulate the members and methods of your types using `public` and `private`, which introduce a lot of boilerplate. They also *need* to type `large_names_of_casts&lt;type&gt;` instead of just `(type)`, and they *have to* put each class in a separate file. It gets even worse. In order to cleanup a resource, you can't just `goto cleanup`, but you *need* to create an entire class with a constructor and a destructor (2 new files!) and use that. I think you can see the theme of these statements - all assume that when you program in C++ you must do things in some way, and in C you just "get a pass". I just don't understand why. Why any of these rules is a "must"? You can put multiple classes in one file, nothing is stopping you! But, usually, someone came up with these rules for good reasons: 1. Encapsulation is great, in my opinion, but my rant is long enough. 2. Specific, verbose casts force you to check you are performing the correct cases, and prevents accidental, incorrect casts. 3. Classes in separate files reduce compilation times (as a change to a single class doesn't force a recompilation of dependents of the other classes) and reduces namespace pollution when including each header file. 4. RAII reduces code duplication and provides exception safety, which `goto cleanup` usually don't. &amp;nbsp; To summarize, I can't relate to any each of these points which I usually see in this kind of posts, and therefore I'm very skeptical of the rest of the article. Note that other statements from the writer are problematic on their own: &gt; I developed my own pet-coding-patterns and bad behaviours (e.g. ... add a full set of constructors or copy-operators, even when objects weren’t copied anywhere ...), Imagine someone complaining about the code bloat in C, but later stating that: &gt; Well, I developed my own pet-coding-patterns and bad behaviours (e.g. ... adding a clone method for each type I define, which deep-copies the type and the resources it manages, even if I never call it, ...), &amp;nbsp; I hope that the writer will face a harsh code review, hopefully mitigating their bad behavior and guiding them towards the subset of C++ that is both easy to use, efficient, and safe. 
Do you know why GCC beats Clang so much in SPEC2006? In other benchmarks, they are almost same. GCC 7.2 with O3 - SPECint 33,2: https://i.imgur.com/uJEQhsb.png Clang 6.0 with O3 - SPECint 31,4: https://i.imgur.com/8NTdVBD.png
My usual workflow is: 1. Sketch out on paper or in a document how I want the program to work (in english and/or pseudocode) 2. Write class/function declarations in the header file 3. Implement the code in the .cc file For an IDE, I use Vim with a heavily modified .vimrc file. Some people get religious about IDEs/editors. My opinion is: start with the editor you feel most comfortable using. Figure out all its features and how to integrate them into your workflow (e.g. find-and-replace, text search, code completion, etc.).
all the cool kids use vim
That's a simplified way of looking at it. In practice it's all leaky abstractions and I as user of a class often need to know about the implementation as it impacts things like performance characteristics. A getter absolutely sends the signal that it's a quick access if the underlying field. If you do heavy calculations you end up with a interface that is very easy to misuse.
The STL seems to be a counter-example here. It give some assurances about performance without forcing a particular implementation. Of course I agree that the implicit understanding of a getter is that it's quick, and any other behavior needs to be documented. For classes that are performance critical, I also agree that abstractions are often not helpful, and that the benefits of having direct access to the data may well outweigh the cons. 
This is really cool! And really useful. A smaller range-v3 alternative that compiles with all major compilers is really extremely useful. One question: How does it play together with the C++17 parallel `&lt;algorithm&gt;`s? I suppose it might not at all because you reimplemented them? Or are you forwarding the calls to the `std::` versions, so that if my C++ compiler/standard library supports C++17 parallel algorithms, like for example the latest MSVC, then I'll get that too when using NanoRange?
Not sure how relevant, but there is also this https://github.com/kks32/cpp-software-development
Thanks :) The short answer is that NanoRange doesn't know anything about the parallel algorithms at all (and nor does the Ranges TS or any of the current C++20 proposals). While some of the more complicated algorithms are currently implemented as wrappers around the STL, they will only call the ordinary single-threaded versions. I believe some folks have been investigating parallelising Range-V3 (or at least Eric Neibler mentioned it in a couple of recent talks), but it seems unlikely anything will be proposed in the C++20 timeframe.
Write factories? Why do you say this without qualification? In my experience, factory pattern is only needed in certain circumstances when a high degree of implementation hiding is desired, e.g. at a framework boundary or app/plugin boundary. Certainly not something to apply without thought to all project.s
Nice. I'll take a look soon. What about compilation performance? I used to test Range v3, and it was horribly longer to compile than CppIterTools which of course has less possibility but still provide some cool views.
If you're creating objects from database rows or files (or both,) use factories. Because later on you're going to create the same objects from some other data source, and it'll be a lot easier if you already designed your code around factories. Also, if you're deserializing your objects from JSON or XML (or whatever. CSVs. Whatever,) doing that from factories seems (to me) like a better idea than trying to put 14 (OK 3) different kinds of parsers in your object constructors. Then you can just dump a big bag of json into your json-thing-factory and let it poop out a bunch of little objects. OK kind of mixed my metaphors there. Pretty much any time I have a big bag of data and need objects, I'm going to use factories. Sure I could not do that and couple IO to business logic, but why would I want to do that? My dream is that eventually we have factories for every type of object and I don't have to write input routines anymore. Plus factories tend to thread better.
I really dislike it when getters try to hide some complex operation, if something is complex, make it look complex. Don't hide it behind `get_foo()`
I'm not even going to remove this thread, because this answer is so good.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8o8v23/metaprogramming_generating_test_cases/e02avwm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; What about compilation performance? I had a feeling someone would ask about this, so I took the liberty of preparing some [numbers](https://github.com/tcbrindle/NanoRange/wiki/Compile-times). TL;DR: NanoRange is currently faster to compile than Range-V3 (but quite a bit slower than just using `&lt;algorithm&gt;`). The longer answer is that there are two parts that combine to slow down compilation: parsing and template instantiations. NanoRange simply contains a lot less code than Range-V3, so it's much quicker to parse if you use the "everything" header (i.e. `nanorange.hpp` or Range-V3's `all.hpp`). That's not to say NanoRange couldn't be better in this regard: unfortunately the P0896 spec for the `View` concept requires specialisations for various standard library types, for which we only really need forward declarations. But sadly forward-declaring standard library classes is forbidden, meaning we have to drag in otherwise-unnecessary headers like `&lt;set&gt;` and `&lt;unordered_set&gt;`; I'm not really sure of a good way around this that doesn't break the rules. With regard to template instantiations, there is a *massive* amount of work the compiler needs to do in terms of instantiating types and using SFINAE in order to check concepts. Because NanoRange targets C++14 (rather than C++11 like Range-V3) we can use variable templates, which seem to be quicker to deal with than class templates. NanoRange also uses `std::enable_if` on function return types rather than in template parameter lists wherever possible, which also seems to be [quite a bit faster](https://twitter.com/ericniebler/status/958490446107361280). But again, I'm sure NanoRange could be improved in this regard: if any TMP experts want to take a look at my implementation and suggest better ways to do things (Odin Holmes, are you reading? ;-)) then I'd be very happy to make changes to improve compile times.
Ah yes, good old [stack sort](https://github.com/gkoberger/stacksort)
You should see similar behavior as if the functions were not overloaded. i.e. the compiler will give an error if the functions are ambiguous and it can't determine which one to call. Example: #include &lt;iostream&gt; struct Base { virtual int Fuu(int a, int b) = 0; virtual int Fuu(int a, int b, int c=3) = 0; }; struct Derived : public Base { int Fuu(int a, int b) override { return a + b; } int Fuu(int a, int b, int c=3) override { return a + b + c; } }; int main() { std::cout &lt;&lt; "Hello, world!\n"; Derived d; std::cout &lt;&lt; d.Fuu(1,2) &lt;&lt; std::endl; std::cout &lt;&lt; d.Fuu(1,2,3); } gives the following error: source_file.cpp:22:27: error: call of overloaded ‘Fuu(int, int)’ is ambiguous std::cout &lt;&lt; d.Fuu(1,2) &lt;&lt; std::endl; So to answer your question, you shouldn't be able to compile and test such a thing.
Note that `d.Fuu (1, 2, 3)` *does* compile since that's not ambiguous. Only the other call is ambiguous. Note that struct Base { int Fuu(int a, int b, int c) { return a + b +c; } int Fuu(int a, int b) { return Fuu (a, b, 3); } }; Base x; x.Fuu (1, 2); x.Fuu (1, 2, 3); is **not** ambiguous and thus should be preferred. - avoid default parameters (instead, forward between functions and reimplement behaviour with them) - don't overload stuff with the same argument types, it really rarely makes sense.
Homework? Why don't you write test code like /u/RyGuy_42 did and try yourself?
/r/cpp_questions
Thank you. 
You don't need a macro, you can use SFINAE and test if something compiles and do some `if(fooassert::false_type) throw;`.
There are plenty of demanglers that will make it easy enough.
You have to run every stack trace and function signature through a demangler though, and the mangled symbols change depending on compiler and platform. This becomes tedious relative to having more readable names. Meanwhile in C, with unmanged names, a symbol is the same everywhere - its the same in the source code as it is in the binary.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8odhc8/classes_and_objects/e02mbee/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You can have a regex-based demangler that will work pretty well and you just pipe your output through it.
That's not a bad idea, but then I have to start my debugger in a regex-based demangler and hope it does the right thing? That seems more annoying than just having the unmangled symbol names from the start. Plus you have to teach people to use those tools. I had to show an intern how to use a demangler after she was confused why she had undefined symbols which she had no idea what they meant. It's just unnecessary extra cognitive load for the average developer.
Fair enough. I think with practice your brain just parses the mangled code anyway.
It is around N times slower to instantiate a call to `nano::*` algorithm than to `std::*` (N = 4 for `sort`, 5 for `find` when compiling with msvc). Here is how I measured: #define PRECISION 20 #include "nanorange.hpp" #include &lt;boost/preprocessor/repetition/repeat.hpp&gt; #include &lt;algorithm&gt; #include &lt;vector&gt; #define DECLARE_STRUCT(z, n, text) enum class s ## n { a, b, c }; BOOST_PP_REPEAT(PRECISION, DECLARE_STRUCT, _) int main() { #define GEN_VAR(z, n, text) std::vector&lt;s ## n&gt; vec ## n {s ## n :: a, s ## n :: b, s ## n :: c}; BOOST_PP_REPEAT(PRECISION, GEN_VAR, _) #if defined(USE_STD) #define DO_SORT(z, n, text) std::sort(vec ## n .begin(), vec ## n .end()); #else #define DO_SORT(z, n, text) nano::sort(vec ## n); #endif BOOST_PP_REPEAT(PRECISION, DO_SORT, _) } It might be slightly better than range-v3, but imho, still not worth the trouble. 
It's such bullshit that microsoft goes around bragging about how MSVC is '17 compliant yet common libraries aren't even close to compiling. MS needs to fire some PR people since they obviously have too much time on their hands.
Well, look at generic lambda today: // Rvalue only [](int&amp;&amp; v) { } // Forwarding reference! [](auto&amp;&amp; v) {} Or even better, again, today: [](entity e) { e.component&lt;transform&gt;(); // okay } [](auto e) { e.template component&lt;transform&gt;(); // need desambiguator } And generic lambdas also generates templates implicitly, without the template keyword. Also, generic lambdas has all the problems described in the terse syntax, yet generic lambda were welcomed by the community. ---- My personal opinion is that the adjective syntax was the best for simple, and most cases. I could just add the concept name to all my generic lambdas, and it would work. And I could start using `Concept auto` as function parameter, just like I would with lambdas. It would almost close the gap between normal functions and lambdas.
Forget about MSVC, just use clang. Oh, wait, it crashes: clang++ -std=c++17 nanorange.hpp Assertion failed: !Init-&gt;isValueDependent(), file C:\src\llvm_package_333363\llvm\tools\clang\lib\AST\Decl.cpp, line 2322 
Yes, you can easily go through the list of bug reports for any compiler and they provide the exact code snippits to make it ICE. There's a huge differential between compilers which are "not perfect". 
This is why I worry about the trend of new C++ features encouraging more and more templates. Modules had better speed things up a lot. It's essential to fix the compilation model if this is the direction the language is going.
I don't know which debuggers you used but all the ones I know demangle automatically
We use that also, but we find it to be painfully slow compared to a similar setup on native Linux. Do you have the same experience?
Well, it's not bad at all. There was a discussion on RangeV3 repo about compilation time, here is an interesting comment from [krzysztof\-jusiak](https://github.com/krzysztof-jusiak) who explained some tips: [https://github.com/ericniebler/range\-v3/issues/332#issuecomment\-214881665](https://github.com/ericniebler/range-v3/issues/332#issuecomment-214881665) I just saw that `view::zip` is not part of the proposal nor your todo list. Any chance to see it in the future or will you keep `nano` as small as possible to fit only the proposal?
&gt; Because writing a C-like code in C++ is frown upon and considered bad practice. Actually many times people put forward the opposite argument then yours. If you want to write C, use C rather than C++. The choice of language depends on how well a problem can be solved, including complexity and robustness as criteria. If I can write something in C++ which is less complex and more robust than the same feature set in C, while preserving the simplicity of C, then why choose C? In other words, you don't have to use all the C++ tricks if you are creating a program which does not require those tricks. &gt; Also, putting all the fault for complexity on the user is ignoring the fact that there is a serious discussion in C++ community about its complexity. I seriously doubt there is a serious discussion, except if you mean on places like Reddit, where most C++ developers are not that much experienced in C++ anyway. I have not seen anyone experienced in C++ calling C++ complex. 
This C++ question fits better to... you know... r/cpp_questions.
It depends on how you write it. If it's simple structs and functions, all you need is 'extern "C"'. But even if you need C wrappers, if the C++ code can be more maintable than your C code, then why not?
I have my Windows 10 install at work on an i7-4710MQ based machine but haven't found it slow compared to an Arch Linux (using Budgie) install on my i7-3770K at home. CLion performs very similar in both environments for me. Same for gcc compile times. I'm not sure what could be causing the issues for yourself but hope you figure it out.
What I liked when I was programming in ruby was that you could create getter and setter who use the same calling convention than just attribute. So you start with a simple struct (because YAGNI), but if you ever need a fancier getter/setter, you just add it, rebuild and done, no client side modification to do. With c++, I don't think we can add a getter/setter that doesn't require parenthesis at client side. If you need ABI stability, it's another beast (getter/setter are probably required from the get go), but most of the time only API stability is required.
&gt; Some possible uses &gt; &gt; - Polymorphism without vtables and inheritance (thanks to visiting pattern) How does `std::visit` and variant actually work beneath? I know it must have another member where it stores which type is currently active but can't easily think how visit can do it's job on the runtime, especially when passed a generic lambda. Isn't variant using own, in-place vtable? What about `std::any`? &gt; While `std::get` needs a reference to the variant, `std::get_if` takes a pointer. I’m not sure why we have this inconsistency. Anyone here knowns why? I also found this to be a little disturbing.
 That's a really interesting test, thanks. I gave it a go with GCC 8.1 on my laptop: It takes around 5.2 seconds to compile this test program for the NanoRange version and around 2.4s with `-DUSE_STD`. For Clang 6, the times are 4.3s vs 2.3s. So that's a slowdown of around 1.8-2.2x with these compilers, which is better than the 4-5x you reported for MSVC. One thing that's very important to note though is that this test only measures the cost of constraint checking on the *first* algorithm call. Once the compiler has worked out that, for example, `RandomAccessIterator&lt;std::vector&lt;MyType&gt;::iterator&gt;` is `true`, it shouldn't need to calculate that again if you use the constraint again in another call in the same TU. So yes, there is a cost to calculating constraints, but you only need to pay it once. (You can try this in the above test by getting `DO_SORT` to call `*::sort()` multiple times with the same arguments.) &gt; It might be slightly better than range-v3, but imho, still not worth the trouble. Well, obviously I'm going to disagree on that one :)
Modules will cut down on *parsing* times, but they won't help with template instantiations, which is what the above test is measuring. Having concepts and requires expressions built into the language (rather than abusing SFINAE rules) may speed things up though.
That's a really interesting link, thanks. I had no idea using long names would affect compile times! Regarding `view::zip`, it's not on the radar at the moment, but do agree that it's useful. There's still an awful lot to do in NanoRange, and I'd rather get all the proposed views finished first before thinking about extensions (and who knows, `view::zip` might have made it into P0789 by then).
Great question! Check out this article : https://mpark.github.io/programming/2015/07/07/variant-visitation/ 
Why not?
Hmm, building N-dimentional array of pointers to make a visitation. It this more efficient dispatch than ordinary vtable OOP?
yes, because there's only one indirection vs two in case of vtables
&gt; i realized that the C++ eco system has a problem: There are no handy established tools that let the developer declare which libraries (and versions) are required for a project which can then be automatically installed in a portable way &gt; Nix can be installed on Linux, Mac, and other Unixes. (I guess it can be installed in the Linux-Subsystem on Windows, but i am not sure as i am no Windows user) I don't understand how can someone seriously say "portable" while excluding windows. If it only works on *nix, it's *not* portable.
It seems to me that posting this off-topic post here, is actually more time consuming compared to just test this yourself on [godbolt.org](https://godbolt.org).
Is the building array itself expensive?
IIRC doesn't it work fine with most of boost now, just not boost's crazy metaprogramming lib?
I used to agree about this a couple of decades back. Then I've understood a few things later about OOP. What's important is indeed the interface, or more exactly what the object can do for us. Holding data is not really doing anything. I've seen too many classes that are just aggregates of data with no invariants, but yet cluttered with setters. Let's say we have a kind of mathematical class with invariants where accessing to the sub-parts makes sense. A rationale number. Let's say that I've chosen to implement the class with two invariants: denominator &gt; 0, and a highest common divisor of 1. Let say I start with `r={2,3}; // 2/3` and that I want to mutate this number to `3/4`. r.set_den(4); r.set_num(3); What number will I really end up thanks to _lying_ setters? It'll be `3/2` because the first setter will make sure the number is reduced. If the setters aren't lying (i.e. if they don't do more that just setting, i.e. if they don't try to enforce the invariant by applying some defensive measures), well they won't justify any more their existence. Dare I say the designers of boost.rationale made the clever choice by not providing any setters? Even `std::complex` which don't have invariants tying two properties (in re() and im() cases), don't have any setters. _Lying setters_ is a problem, it means we have functions in our interface that have side effects that don't appear in their name. Here the true names are `set_and_reduce_X()`, not `set_X()`. All the justification I can read about setters is about: "later we may need to change the underlying representation, or even to do more stuff and lie about what the operation does (like checking defensively the invariant before doing mutating the state)". Please, no more lies. Anyway, while they sometimes make sense, I really dislike setters (or properties that can be written-into). Most of the time this means we are not reasoning in terms of behaviour (what OOP should really be about), but in terms of data. What's important is what an object can do for us, not what we can do with the data of another object. We _must tell and not ask_. Setters, getters and properties are much too often a sign we are thinking about what we can _ask_. In the end, do we really need to put so effort into a feature that will be abused? I'm not so sure. We just have to see what is done in some other languages/frameworks to see the extend of the abuse, it's of an order of magnitude much worse of the abuse done to operator overloading.
i may be wrong and the article just uses this as an introduction, but aren't the two union examples in the beginning violating the strict aliasing rule? 
Okay, thanks! Wouldn't that most likely mean for C++20 though that we would get e.g. `std::sort` for ranges, but only the sequential version - so if one wants to use C++17 parallel algorithms, they have to resort to using the iterator-based `std::sort` version. Basically that would inhibit people from using ranges - anybody that wants to use C++17 parallel algorithms couldn't use ranges and would need to resort to the old iterator based stuff. That creates quite a rift in the language. If something is in C++17, the committee should in my opinion make sure that whichever features are added in C++20, play fully well with what's already there in C++17. I hope my understanding is wrong here!
compile time probably
They break the rule that only the active member of a union may be read. Union aliasing is UB in C++. It's not clear why the author even gives those examples, since std::variant does not allow aliasing either.
why is that? can you explain? such unions worked fine in MSVC, but could be not portable
in the function: int RawMantissa(SuperFloat f) { return f.i &amp; ((1 &lt;&lt; 23) - 1); } the integer is read, but (given the context i assume that) the float was set prior the call. that breaks down to accessing an object through a lvalue of a different type (there are allowed exceptions, but this is none of them). i think in C it is allowed by the standard. yeah i may be working. but there is no guarante that this will be the case. theoretically, msvc could push an update following the standard in a stricter way and then may have a problem 
&gt; I never saw such a simple and elegant extension to an existing language that is so useful (it puts all the different ways to initialize a struct or object C++ came up with over time to shame). Isn't this feature already placed in C++20 draft? Reading this article, I still wonder how owners in C are treated. Is there any pattern where you should allocate/deallocate in C? I know most functions take non-owning pointers but in many situations dynamic memory is inevitable and you must have a clean way to manage resources. About boilerplate - the article doesn't cover the most important aspects that C++ templates help much: data structures and algorithms. About Emscripten - it's a translator, not a good (re)compiler. There are better tools/technologies than this.
yes I agree, that's another disadvantage of using unions - that you're entering "unsafe" ground a lot. But I've seen many of similar tricks, especially in gamedev or low latency code.
They should improve it, in [my case](https://www.reddit.com/r/cpp/comments/8m0x7p/is_spellcheck_a_good_feature_in_the_compiler/) it proposed `nullptr_t` which would not even compile.
&gt; There's a reason `null` is referred as the "billion dollar mistake" ! Haven't heard of it. What's it about? Some overused OOP? 
CPL.1: Prefer C++ to C __ Reason C++ provides better type checking and more notational support. It provides better support for high-level programming and often generates faster code. https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#cpl1-prefer-c-to-c
I have no idea what the article is about. Some compiler implementation-relate stuff but can't really understand the text.
No one because such code will not compile. FYI such question posts belong to /r/cpp_questions
One of the great things about std::variant is that it can be used to build up tree line hierarchies. [See this example](https://wandbox.org/permlink/Cac85dSskaOxio3y). Note that *graph_container* is only forward declared when the variant *graph_t* is defined. Note also that *std::visit* is called recursively in *main_visitor* . A fact that can be used if behavior for certain types shall be changed like for *circle* in *der_visitor*. 
That's not the same feature.
Not that it is something I am interesting in doing, but using C++ as a "better C" is one of the legitimate uses for C++ as stated by Stroustrup himself.
That's kind of obvious. But I still see no reason why you shouldn't use `malloc()` when you need to do so.
Essentially, yes. As things stand, in C++20 you'll have * The original, C++98 unconstrained `std::sort(iter, iter, comparator)` (but made `constexpr`) * The C++17 unconstrained parallel overload `std::sort(execution_policy, iter, iter, comp)` * The Ranges TS constrained version `std::ranges::sort(iter, sentinel, comp, projection)` (not `constexpr`) * The Ranges TS range overload `std::ranges::sort(range, comp, proj)` (not `constexpr`) (I strongly suspect the last two will be made `constexpr` before C++20 is released; if no-one else proposes it, I will.) No-one has yet proposed adding constrained parallel overloads of `std::ranges::sort()` which take an execution policy; I don't think there's anything fundamentally standing in the way of it, other than lack of implementation experience, but I could be wrong. As I alluded to earlier, people have been experimenting with adding parallelism to the Ranges TS, and there's a [paper about it](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0836r0.pdf). This is a strictly superior solution to the C++17-style parallel algorithms, and while I don't think it will make it into C++20, I'd love to see it in '23.
I don't think it mentions that the latest version of Xcode doesn't support it. Was pretty bummed about this. 
I feel like a lot of demand for these “alternative package managers” comes from the fact that macOS doesn't have one build in. [Get yourself a better computer](http://dilbert.com/strip/1995-06-24).
Xcode (out of the box) uses an old (and modified) version of Clang/LLVM. It [appears](https://github.com/niosus/EasyClangComplete/commit/bd2eaef71883b4323a5ce7a55e33ab7ed000fb6f) Xcode 9 is using Clang/LLVM 4 as a base.
What’s wrong with macports?
Still there is no guarantee that that code will continue to work, even across different versions of the same compiler. The reality is that no compiler will go out of its way to purposely hurt you, and generally it will try to do what you intended, but since trying to access an inactive member of a union is undefined behavior, you get zero guarantees about its portability and stability. The optimizer certainly won't care, and if it can assume that that access never happens (because UB), it will declare it dead code.
I think he did: https://stackoverflow.com/q/50610274/1422197
Yeah I didn’t say most. 
Being cross platform means a lot of my code is stuck at '03. There's a good chunk, fortunately, that doesn't have to be. We still spent about a year doing work to move from gnu\+\+11 to gnu\+\+14. Starting with OS upgrades and retiring systems. Then a lot of test builds and small fixes.
Who actually uses Boost.Hana? Have you ever used Boost.Hana?
What I saw in my C++ project with a C wrapper was a clunky interface into the library because interfaces were getting designed in C++ and then you had to find a way to make that C++ interface fit into C. In hindsight maybe we could have mitigated that with better API design, but it is a pitfall of having a C wrapper.
Honestly, I wish everything was implicitly `const` by default, and be explicit with mutability.
Usually you are responsible to do the allocation yourself and give a pointer to a valid memory area, then do the destruction yourself (either malloc/free or stack based). If the function return something allocated by `malloc()`, it should be written in the documentation that you either need to call `free()` or any library-provided clean-up function (and it's the same rule for non-memory related resources like network interfaces).
Qt is not the best example of C++ modern design.
There are parallel algorithms that could help, such as Leapfrog, Random Trees, or by seeding basic crypto hashes (such as TEA) with a linear ramp across several threads.
`select()` is an obsolete interface. Cool for a proof of concept, but plan on dropping it long term, or only retaining it for legacy Unix builds. Don’t use it on either Linux or OS X. 
&gt; allow you to change underlying structure at any time It's an illusion. You can only change internal representation of members. Not that a big deal. Such changes are often rather trivial. You still cannot decide that your class from now on should not have a certain member at all. An interface should expose what the class does, not what the class has. Setters defeat this objective. For the record I don't agree that public members are better than setter/getter pairs. Both are suspicious and should be avoided if possible.
Absolutely. Also, GPU are quite good at generating those massively.
There's a lot of defaults in C\+\+ that are unfortunately backwards.
That's the cost of being based on C. You can look at Rust.
In a nutshell: it generates the visitor code for each type, and chooses them at runtime based on the value of the type tag. 
I think, a long time ago, the original definition of portable was simply that it would be source-compatible with any implementation of Standards-Compliant UNIX.
That’s an extremely dangerous way to approach it. You have no proof that it worked. It just happened to in the few cases where you properly looked. 
&gt; Usually you are responsible to do the allocation yourself and give a pointer to a valid memory area, then do the destruction yourself And is there any pattern in C for this?
https://doc.qt.io/qt-5/plugins-howto.html
One thing to note is that WSL compiler performance is absolute garbage, at least as of Feburary. https://www.phoronix.com/scan.php?page=article&amp;item=wsl-february-2018&amp;num=2
now how did I miss this? 
&gt; 5.2 seconds for 20 instantiations (assuming you didn't change `PRECISION` macro). It is like 250ms per instantiation or 4 instantiations per second. I like how [this guy](https://github.com/ericniebler/range-v3/issues/332#issuecomment-289741071) puts it: "this compilation times forever added to your codebase". &gt; 1.8-2.2x with these compilers, which is better I'm not sure what is exactly better here. It might be that lib[std]c++ implementation of `sort` just takes way too much time to compile, lowering the ratio. It hard to tell what is going on here. I think, even 2.4s is ridiculously high price to pay. &gt; `RandomAccessIterator&lt;std::vector&lt;MyType&gt;::iterator&gt;` is `true` I like metaprogramming very much, but this computation is not useful (at least not in context of `sort`), it just warms the room nicely. &gt; you only need to pay it once Right, once per TU, per compilation, per developer, forever. &gt; Well, obviously I'm going to disagree on that one :) This is fine. I just wanted to give you guys some motivation behind my own ranges library: template&lt;typename T&gt; void sort(std::vector&lt;T&gt; &amp; v) { std::sort(v.begin(), v.end()); } template&lt;typename T&gt; void sort(std::list&lt;T&gt; &amp; v) = delete; It already covers 93% of my range needs and has near-zero compile-time overhead. 
I will say their documentation does not refer back to nice, general articles like that frequently enough. Google does not always do the greatest either.
Nix is so much more than just an alternative package manager. You owe yourself to check what Nix has done to package management. Then what NixOS has done to OS distribution. If NixOS were there from the beginning, today's OSes would be regarded as Stone age tools.
Came here to say this. Don't use `select(2)`, while `epoll(2)` isn't exactly great, it's the best alternative.
Best use of const is in functions/methods definitions. foo Bar(const int x, const std::vector&lt;z&gt;&amp; y, const float t, ttt&amp; w); clearly marks input vs output parameters
You can also refer QtCreator's plugin based architecture, it will be a very nice exposure to real life versatile plug in based architecture. 
Chromium style guide :)
some teams at $dayjob follow https://github.com/isocpp/CppCoreGuidelines and some have an in-house extension (with some rules dropped and some added)
I find it hilarious that anyone would attempt to deride flooh in this way. You clearly do not know who this person is.
I usually go for Core Guidelines with a bit of Linux Kernel style added in
C++ does not allow you to initialize structs in anyway like modern C does. That is really a pillar of the Sokol approach he took.
Thanks. I didn't know about this.
Maybe it is a frenemy. Const is often helpful, but sometimes causes headaches. The sun is a frenemy imo also. Most of the time it's helpful, but can be blinding around sunrise/sunset and cause skin cancer, etc.
this could be very useful too :)
There's some irony in using Boost.Preprocessor in an example complaining about increased compile times, but anyway... ;-) &gt; It is like 250ms per instantiation or 4 instantiations per second. For Clang, the overhead of using `nano::sort()` instead of `std::sort()` is 2 seconds, so that's 0.1 seconds per instantiation -- which I actually think is surprisingly fast considering the amount of extra work the compiler is having to do (and also that `RandomAccessRange` and `Sortable` are the two most complicated concepts in the library). And again, that only applies to the *first* call; subsequent calls have negligible overhead. In exchange for this, you get generic range-based overloads and vastly improved error diagnostics if you try to call an algorithm with types that don't meet the requirements (the README contains a nice example of this). I personally think that's a price worth paying, but if you don't then I doubt I'm going to be able to change your mind :). The bad news I'm afraid is that with concepts making it into C++20, you're going to be seeing a lot more constrained templates in future... &gt; I just wanted to give you guys some motivation behind my own ranges library I don't think I need to point out that with 90-odd algorithms and a dozen standard containers (not to mention whatever custom containers users might have) this approach doesn't scale at all. And if you try to do it generically, you'll rapidly find you need *some* sort of constraints on your overloads, otherwise you'll get ambiguous calls all over the place. There are certainly ways to do that that are less complex than the Ranges TS requires, but then they're also going to be less correct -- a lot of very smart people spent a long time working on defining the concepts in the Ranges TS correctly.
The proposal says `std::u8string` is not convertible to `std::string`. None of your interfaces taking `std::string` are going to work with new code written with `std::u8string`, even though `std::string` is entirely capable of handling UTF-8. In fact, the codebase I work on every day does this quite successfully. http://utfcpp.sourceforge.net/ plus some small convenience functions and you are set.
We use a modified version of the Autosar C++14 guidelines. 
&gt; Don’t use it on either Linux or OS X Use select() on OS X, poll is [buggy](https://daniel.haxx.se/blog/2016/10/11/poll-on-mac-10-12-is-broken/) on some versions
So I looked at epoll and saw it was going to be more trouble to program to than select(), which turns out to be rather easy to use. So I weighed whether to bypass select() for epoll() as commentary was suggesting, but one thing is that my eventual intended target is not something like a Web server accepting socket connections - where can tend to need to scale to high level of connections, but instead, my target is Spartan, which is an alternative Java program launcher. spartan enables a java program to fork child processes, so the connections are going to be the stdout/stderr output pipes per each forked child. The level of forking won't get that high - typically might fork as many worker child processes as their are detectable CPU cores, or maybe up to 30 or 50. I've tested it to about 300 but will start running out of file descriptors beyond that. So for the level of scaling that Spartan will do, the select() call will be entirely adequate. I guess I need to weigh if embracing the tougher programming model of epoll is really worth it for my use case scenario 
LLVM (with 4 spaces instead of two) because it's the default provided by `clang-format` and it suits my needs.
The Google style guide for support c++11 and also most of c++14. It doesn't support exceptions though, that's true.
From first example: int bar = foo; // OK: assignment does not modify const variable This is not assignment.
So I looked at poll()/epoll() and saw it was going to be more trouble to program to than select(), which turns out to be rather easy to use. So I weighed whether to bypass select() for poll()/epoll() as commentary was suggesting, but one thing is that my eventual intended target is not something like a Web server accepting socket connections - where can tend to need to scale to high level of connections, but instead, my target is Spartan, which is an alternative Java program launcher. spartan enables a java program to fork child processes, so the connections are going to be the stdout/stderr output pipes per each forked child. The level of forking won't get that high - typically might fork as many worker child processes as their are detectable CPU cores, or maybe up to 30 or 50. I've tested it to about 300 but will start running out of file descriptors beyond that. So for the level of scaling that Spartan will do, the select() call will be entirely adequate. I guess I need to weigh if embracing the tougher programming model of epoll is really worth it for my use case scenario 
I try to be const correct as possible. 
Quoting the wiki page of [Tony Hoare](https://www.wikiwand.com/en/Tony_Hoare (read it for more background and info): &gt; I call it [inventing the null reference] my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language (ALGOL W). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years. In my opinion, the issue with `NULL` is that works like a pointer even though it behaves completely differently - it is really not clear how a `NULL` pointer should be dereferenced. In the good case it is defined to crash your application, causing inconveniences and financial damages. In the bad case, it is undefined behavior, which could manifest in various issues which are hard to detect and debug (such as [this example](https://www.reddit.com/r/cpp/comments/6xeqr3/compiler_undefined_behavior_calls_nevercalled/)), causing even more losses. Moreover, `NULL` is (usually) the default value for pointers/references (in many programming languages), which leads for even more tricky bugs - an uninitialized variable is probably a problem, but it's a shame you'll detect it only when dereferencing it and only if you're lucky.
I suggest you post this in /r/cpp_questions It's off topic here
Style Guide \- If you are working on an existing project, use the style already being used. If you are working on a new project, use the style your team has used on previous projects. If you are working on a new personal project, use whatever format you want, just be consistent. With that said, clang\-format with version control hooks go a long way to keeping the style synchronized. Coding Standards \- Again, use whatever your team uses, as they may have specific requirements for their use\-case. If they/you don't have one, use CppCoreGuidelines and modify it for your use\-case.
LLVM with only the "seen" parts, like I don't follow theirs technical guides, just the styling.
I realize this, which is why I said depending on the exact specialization of `basic_string` is already likely wrong. Unless it's actually _persisting_ the data, most code needs a string-like thing, not some particular specialization for some particular character type for some particular set of character traits; the rest of the time, tying an algorithm to just `std::string` or `std::wstring` or `std::u8string` is usually a leaky abstraction.
I'm the only person I've ever talked to who likes [Ellemtel](http://www.literateprogramming.com/ellemtel.pdf)
All right... What about properties as a "views"? Let's say this: class { int32_t hex; void update_hex(int r, int g, int b) { hex = ((r &amp; 0xff) &lt;&lt; 16) + ((g &amp; 0xff) &lt;&lt; 8) + (b &amp; 0xff); } public: auto red(){ return Property( [&amp;](){ return ((hex) &gt;&gt; 16) &amp; 0xFF; } [&amp;](int32_t color){ update_hex(color, green(), blue()) }, ); } auto green() auto blue() } 
I would also like to point out that const can result in copies instead of moves, since there isn't many places where using const&amp;&amp; can be implemented with any gains over copying \(so it is usually not implemented\). So one should be cautious with using const when the value is to be moved from.
Stroustrup and PEP8 (Python), because I honestly couldn't find a good one when I started looking.
&gt; Who actually uses Boost.Hana? Have you ever used Boost.Hana? What's a fallacy? Have you ever seen a fallacy? /s
Crap. And just when I thought I was doing some good :) Time for... a configure check. Yet another.
oh boy - maybe have a look at some big projects and see how they do it 
At this point though I disagree with new things being `const` by default for example lambdas. I still forget to put `mutable` sometimes because I never use that keyword anywhere else. You can debate all you want about the mutability of lambdas but I really don't like that it is backwards from everything else in the language.
Malo self promo al ajde
Cool, thank you very much for this awesome explanation &amp; update on state of affairs! :-)
There was a proposal a couple of meetings ago for something along the lines of ``` int main(std::command_line_arguments args) ``` where `command_line_arguments` was a "magic type" that behaved roughly like `std::initializer_list&lt;std::string_view&gt;`. I was keen on the idea, but unfortunately it got shot down in flames. Sadly I can't remember the paper title or the author now though.