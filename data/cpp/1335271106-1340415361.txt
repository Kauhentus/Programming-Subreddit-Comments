Whether or not you're using stdio or ifsteams, exceptions are not typically involved. So, it seems a weird question. If I'm not mistaken ifstreams use RAII, so if that's what the interviewers were after, they should have asked it. I just don't think some of these questions are very good, they're basic and only help you weed out people who don't know C++. What if you want to find someone who's really good with it? 
&gt; I know that this is more of an implementation problem, but no standarized name mangling. You can't call code created by msvc from mingw and vice-versa. The problem is (lack of adherence to) a standardized ABI. Different name-mangling is a small part of the problem, and actually a good thing as the breakage caused by name-mangling is obvious, compared to say "virtual base class offset". For the specific case, MinGW is to blame as it is Microsoft's platform, hence they get to define the ABI. Then again, MinGW is excused as Visual C++ was badly broken for a long time.
Well it was a phone interview he said, so it was probably just to weed out people who think they know C++ but don't know an object from their own butt.
&gt; auto words = word_counts | sliced(0, 10) | map_values; This is neat, but which part sorts the values?
I have it and find it brilliant. It covers the stl not the whole language though. I pre-ordered and am completely happy with the book. So much so I am considering getting the electronic version as well (if there is one).
&gt; No you don't mean that. Yes, I do. &gt; Biggest problem with 'd' is the forced garbage collection disqualifying it for systems use. First off, the statement that garbage collection "disqualifies" a language for systems use is absurd. For *some* systems, like an Atmel microcontroller with 1k of instruction memory... sure, it obviously does. But nobody's even using C++ in that space, it's almost always C or assembly. When I think of a "systems" language, what I really care about is a language that gives me control over memory layout, and D does. Secondly, I'm not sure where you heard that GC was *required* in D, but that's not accurate. D has garbage collection, but it's not mandatory to play in the GC's sandbox. D interfaces seamlessly with the C ABI, so you have access to malloc() and free() (not wrappers, but the actual C library calls). Want a garbage collected pointer? Great, "new" it off the GC heap. Need to do manual memory management yourself? Fine, malloc() and free() raw pointers. I believe there are a few parts of D's standard library (and very rarely the language, such as array concatenation if I'm not mistaken) that obviously require memory off the GC heap to work. Honestly, though, if you're working in an environment where you absolutely can't have *any* GC'd memory running around, then just avoid those parts of the library. God knows we already jump through far worse hoops than that to define "safe and sane" subsets of C++ (which of course, everyone disagrees on). And I'm well aware that my changes would make a language that "isn't C++ anymore". One of C++ biggest strengths *and* biggest weaknesses is its backwards compatibility with C's syntax. I think D took the better approach here and has *binary* compatibility with C (making FFI code trivially simple) but intentionally breaking source compatibility to resolve some of the irritating parts of the language, such as favoring symbolic imports over textual inclusion and using the binary ! operator for compile-time arguments instead of the ambiguous foo&lt;bar&lt;baz&gt;&gt; debacle (surprise! right shift!) that only *just* got resolved in C++11.
Maps keep their elements sorted
Generic programming is far superior, imo. I just never really find myself in the situation where I need polymorphism.
Gotcha.
Aren't the heap layouts for the `new` and `make_shared` cases a bit off? The `shared_ptr` implementation needs to tell both cases apart if they heap layout is different. If there's just a single pointer, you'd have to use a colored pointer, which impacts performance of the dereference operation, so this seems an unlikely implementation strategy. I suspect that most implementations embed two pointers into a `shared_ptr` instance, one to the data and one two the reference counts. `make_shared` just puts both bits back-to-back, with a single heap allocation, saving a bit of heap management overhead (both in time and space).
They get zeroed automatically, so you cannot obtain a strong reference from anymore. But staying around longer is the whole point of the weak pointer concept.
yeah. Makes me wish I posted with my main account but I was unsure about any disclosure issues with the questions asked. This might be the draw back of a interview question sub reddit.
Looks like a good interview, seems like you've found a good company :) ---- &gt; If you could change one thing about the C++ language, what would you change and why? Build Model. For the record, the next two are Build Model and Build Model. It's a massive time waster for large projects, and C++ isn't exactly the language you pick for small projects. 
The answer to "when should you make a destructor virtual" is correct, but there's more to the story if you want to impress an interviewer. Virtual destructors are different from all other methods in that they have overloading *refinement* semantics rather than *replacement*. Whether you make a destructor virtual or not makes no difference to the super classes; they *will* run at the appropriate time (starting with subclasses and going up). (Which is unlike normal virtual methods, where only the concrete method runs unless it makes explicitly scoped calls).
Fair enough, though I think you're mostly getting downvoted because people hate compiler errors for templates. Although, I would like to ask, could you identify a problem most people would use polymorphism to solve that you would use templates to solve instead? All I've heard are template horror stories, so I'd like to hear the other side's argument.
It also can be smaller (as opposed to larger scenarios pointed out elswere) if compiler knows the dynamic type of the object you call the function on. Its disscusable whether it still counts as a 'virtual call' but there you have it.
Building large projects in c/c++ is a nightmare. header files, 1000+ line long makefiles, ugh. This is one thing that Java really does a million times nicer than c/c++, and would be the first thing I'd fix if I had my way.
I'm curious why you argue against something so strongly that you yourself recognize your own ignorance of. D offers compile-time "introspection" but not much in the way of run-time. You can create a class by name at runtime since that support doesn't really come with much of a performance penalty. Full blown reflection isn't offered currently because there are too many performance concerns. D doesn't compile to byte code (unless you count ldc, which uses llvm for codegen). You can trust the language to not do these things if you'd bother to research them.
&gt;unless you are talking about using Boehm, I suppose Well, afaik dmd uses Boehm currently, so C++ gives you pretty much almost the same thing. Im not arguing against GC, just that it sucks when you are in environment where you cant GC (lets say, you are a AAA game, far-fetched, picked only for the sake of argument) and need to parse a line with a regular expression, when the libraries depend on GC. What then? You roll your own? You enable GC for a little bit? Having two versions of everything isnt even remotely a solution (its probably ok for simple cases, like array) - i dont want to learn 2x as many apis even if having GC means one of them can be significantly nicer. My whole point is that the choice D is offering is only superficial because its not yours - the choice is made by library writers (and im not talking only stdlib). In general you will need to have GC enabled.
Then can also be inlined by the linker and/or the runtime. IIRC Herb Sutter had a great article on this that lead with "when does code get inlined?" or some such.
There's also the issue of when whatever else is going on dwarfs the price of the virtual function.
&gt; what about bounds checking for containers It does bounds checking in debug builds just like many C++ STL implementations do. The only difference is D actually defines this behavior whereas with C++ you need to look up your vendor documentation. Everything you are saying applies to any language. Remaining informed about how your tools work is just a part of being a programmer. There is no way to avoid having to keep yourself educated.
It's is somewhat of an art and often you go horribly wrong but there are some tricks to improve. For the standard library it is often enough to just keep the concepts operate on in the back of your head and look at the expressions that trigger the errors. Continue from there to look at your type and try to figure out where you are not fulfilling a requirement and how you got there. (Think: Error statement uses operator&lt;, dang, my class doesn't have it! I need to pass a functor.) For long chains of type transformers I usually hook "type printers" (class templates with undefined bodies) into the chain and check my assumptions. static_assert helps a lot. Check your assumptions regularly, but them in debug macros if they are hard on the compile time. Just like regular debugging. If one of the beasts (Phoenix, Spirit, Proto, MPL) is bugging you... Well, get your headphones and follow the instantiation trail. Be careful when you code and think about every statement. Never write things you are not really sure about, it is going to take you ages to find the bugs.
I'd take out the preprocessor. Most of what is was used for is now possible within the language itself (declaring constants and generic code) and the remaining things (delimiting modules) can easily be done through a limited and much more high level mechanism. The reason to take out the preprocessor is because it makes it impossible to evaluate header files without knowing in which context they are included. As a result, tools that operate on your code (IDE, compilers, refactor aids, ...) are difficult to write, error prone and most importantly very slow.
I think #import would be a great addition, not a replacement. It would be nice though if the standard library header files were deprecated and import files were provided instead. Then we could have the advantages of #import while maintaining backward compatibility with old C++ programs, C libraries, or header files that require the use of pre-processor magic. 
I think as soon as you are going into user interfaces, polymorphism just makes sense.
You really need to do some research, because you're making a lot of stuff up. &gt; the default value [GC] is wasteful You are confusing the ideas of memory wastefulness with memory release. You can be tidy or wasteful with memory in any language, regardless of your deallocation strategy (explicit with free() or implicit with GC). &gt; C++ adheres to "you don't pay unless you use (and specifically request) it". D apparently doesn't. I don't understand why you think this is the case, even after I explicitly stated that you have access to raw malloc() and free(). If you don't want something GC'd, then don't allocate it off the GC heap. It's that simple. It's not like C++ *actually follows* the "don't pay unless you use it" advice, either. Want to use map::at() without exceptions? Too bad! It throws std::out_of_range! &gt; What about introspection? What about it? D has compile-time introspection features, but not much in the way of runtime ones. &gt; Compilation to byte-code by default? Where on *earth* did you pick that one up? It compiles to **native code**. There is no D interpreter or D virtual machine. It's a native, systems language. And I've got some disappointing news for you. Every language (save assembly) gets compiled to "byte code". It's called IR and it's used internally by the compiler for code gen and retargeting. &gt; I don't know if it actually does that Ah, ok. So you acknowledge that you're just making things up at this point. &gt; I can't trust my fellow programmer to remember all the cases where you need to work against the language to write optimal code. The **why on earth** are you using C++? It's at the bottom of the list for safe, sane, and efficient defaults. &gt; D is known for breaking backwards compatibility. As are all languages in their first revision. But D2 is stable and they're not really considering any changes to the language at this point. They're focusing mainly on bug fixes and they've seen an explosion in contributions since moving the project to GitHub. Look, I'm a C and C++ programmer. I'm a graphics guy, so native languages are my bread and butter. I understand why people like C and C++, for many of the same reasons I like it. It's native, it's fast, and it's close to the hardware. But I think a lot of people forget that there has been *30-40 years* of programming languages research that has happened since then, and we can bring some of the great new features to native languages without giving up what we need to get the job done. Even the ISO C++ committee sees that by adding language features like type interference, lambdas, and move semantics. Herb Sutter is going to propose adding optional GC to the language in the next revision, specifically to foster more rich library support. For example, wouldn't it be *awesome* to have a standard lock-free containers library? Yes it would, but some lock-free containers are *not implementable* without GC. It's shown to be impossible. In a language that is all about performance, wouldn't you be willing to give a *little bit* and let a lock-free container do some GC allocations to get the huge benefits of writing correct concurrent code? The productivity and runtime efficiency boost would destroy any concerns about having that tiny bit of memory GC'd.
What experience level was the job for? This seems kind of tough for someone right out of school without a class specific to advanced C++. I say that because I'm learning *some* of these things in an advanced C++ class, but I have an intro c++ software eng job that didn't ask language specifics like this.
What is the second word needed in the multiple inheritance case? On VC at least, there is no second word; rather, the vtf table entry points to a short stub that fixes up the offset by a constant, then jumps to the main function body. 
4 ns vs 1 ns on my box, provided the call is monomorphic. And, of course, inlined calls are generally negative cost ;-) 
Yeah, but that will make compile times worse, break even at best. 
Behold [this active proposal (pdf)]( http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3328.pdf).
Could you elaborate what you mean? 
To be fair, most implementations of STL aren't suitable for OS kernel work. Perhaps you might say "then write a kernel safe STL", but the same could be said about writing a kernel safe GC for D -- it's been done for other languages, so why not D? 
I don't get the comment about the Makefiles. Honestly, my Java POM's are way bigger than equivalent C/C++ Makefiles. If you need the massive Makefile you're doing it wrong somehow.
Scheme is GC'd, and I've heard of folks using it on microcontrollers. As [seen]( http://lambda-the-ultimate.org/node/2124) on LtU: &gt; The PICBIT paper talks about running \[Scheme] with 2K of RAM. and &gt; We have a Scheme implementation for AVR-based Mica-series wireless sensor nodes. It's entirely interpreted, with primitives written in C, and pages to serial flash for virtual memory. Programs are stored as lists, and can in fact transmit themselves over the wireless network; 
Actually, it doesn't need to know the pointed-to size -- a forward declaration is fine: class Foo; Foo* p = 0;
True, compile time for *ill-formed* programs might improve. I generally don't worry too much about their performance though ;-) 
I think the whole point of `at()` is that you want the exception. That is the behavior across the STL. Otherwise you would use methods that adhere to iterators, i.e. `find()`.
Nice! A toy academic language I learned in college (CLU, written in 1976) had the "yield" feature and I've really missed it programming in C++. It might take me a while to get used to "resumable" and "await" but it seems to accomplish the same goal. 
Try LLVM/Clang. So fast!
Which negates the originally claimed advantage of having GC for these applications. There are a very few real problems where GC is actually advantageous for really solving the problem, dealing with certain cyclic data structures.
That's the same thing implemented differently.
True, but memory accesses are expensive. At least with the stub you've got the cpu front end optimizing away the jump. 
Very cool. Learn something new every day. 
Of course I know what it is. Red Alert 2 was one of my favorite RTS games.
And Clang on Linux, Windows and Mac OS X, and MSVC on Windows. :-)
Unfortunately, only for Linux. Boost.context is not part of boost yet, is it?
I thought it was a decent talk. For anyone like me that prefers to watch these offline using VLC (which allows to adjust the playback rate in fine increments), you can download a copy with rtmpdump -r rtmp://shadow-technologies.tv/play/179_252/mp4:encoded_streams/0/30/179.mp4 -o jungle.mp4 
`void *`? I doubt it's good practice in C++ though.
It depends -- there are costs to anything else. - in general, `void*` indicates a poor design choice somewhere. However, changing designs mid project introduces delays and oversight risks. - make `myFunction` a template. Now it has to go in a header, can't be virtual, etc. - wrap the pointer in some polymorphic interface. Now you're stuck with virtual dispatch, which means no inlining. You're probably right, but software isn't always about being right ;-) 
_edit: nevermind, I was thinking of [lthreads](https://github.com/halayli/lthread) or [posix contexts](http://en.wikipedia.org/wiki/Setcontext), not pthreads. You can ignore the rest of what I said._ But possibly a _lot_ faster. I'm using fibers on Windows instead of pthreads on linux, but they're basically the same thing -- and they can context switch around 100x faster. As well, the upper limit for fiber creation is the amount of memory you have available for creating their stacks -- so hundreds of thousands of fibers are not unreasonable. But yes, the semantics are about the same as std::future. :-)
char* data = 0xFFFF0000; Shouldn't be a compiler error.
I don't think that's quite correct - name mangling was introduced to support overloaded functions, so that eg foo(int) and foo(char*) are distinct to the linker.
Pretty clever! But I can't help but feel that there is some suboptimal design decision hiding in the use cases for this feature. I mean, is there any use case which couldn't be solved significantly more elegantly?
See my reply - how would you do it?
What do you mean by "remembers which object its points"? Do you mean something like: class Foo { public: void bar() { cout &lt;&lt; "hello world\n"; } }; Foo* foo = new Foo; Pointer p = foo; p-&gt;bar(); // prints "hello world" If so... then you and me both!This is generally referred to as [dynamic typing](http://en.wikipedia.org/wiki/Type_system#Dynamic_typing). I was talking with a colleague about this very topic, where he wanted the ability to write a little bit of very dynamic code in an otherwise static typed language. It would drastically complicate the language though. C# has added this in the form of the [dynamic](http://msdn.microsoft.com/en-us/library/dd264736.aspx) type, and in practice the results can sometimes be [quite surprising](https://msmvps.com/blogs/jon_skeet/archive/2009/06/17/dynamic-type-inference-and-surprising-possibilities.aspx) (more [surprises](http://stackoverflow.com/questions/4892704/why-is-dynamic-not-covariant-and-contravariant-with-respect-to-all-types-when)). ~ If that's not what you meant .. could you clarify? In which sense does it remember, and which sense does it forget?
I'm afraid I have to agree with simonask, but it's a weak_agree. :) Same here. First I was like, "wat." Then I was like, o_O Then I was like, &lt;:-| Then I was like, &gt;:-| Then I read this thread and I changed my mind several more times. I'll have to think about it some more. I agree that your use case here justifies the alias constructor, but I'm not convinced that use cases like this are common enough for the feature to be worth it. I imagine that for every time it's used well, there's going to be a half-dozen bad uses out there. Considering your case, I'd say that the memory block be a class that has a reference sub-class that acts like a smart pointer. It'd take an hour or two to write and test which isn't that bad. I think I'd prefer this to having this feature be available to everyone who uses smart pointers. I dunno. I may change my mind again by morning.
Why not just return a `shared_ptr` to the entire block? Then various things would be able to access whatever they needed from it. Or perhaps, a small wrapper class with that `shared_ptr` and a function object to pull out the data you needed?
&gt; Maybe I should have described the scenario more clearly: Alright, that makes sense. I think the decision to use `shared_ptr` in this case was pretty sane. &gt; The main overhead of a shared_ptr is a second allocation at worst, and doubling a few dozen small allocations won't kill an app. Well, I think all of these are overheads that should be considered: * Double allocation. * Double dereference with a potential cache miss. Both of these can be alleviated by using `std::make_shared`. * The overhead of performing refcounts (again, potential cache miss). * The overhead of performing refcounts atomically for thread safety (hardware lock contention). Indeed, you are quite right that a few dozen shared pointers of this sort will definitely not kill an app, nor have a measurable performance impact at all. But a few hundreds or thousands of them will, so again it depends on your use case. I generally agree with your API design tenets.
&gt; Posted on February 12, 2011, 10:11 pm, by Chaker Nakhli, under **Troll**. This article is wrong, and the author knows it. Just downvote and move on.
Can you explain why this article is wrong?
What the article tries to say is that the compiler is not the most efficient tool for avoiding bugs. Compiled languages do not lead to less buggy applications.
"The compiler cannot help you write better code or avoid bugs. " You have no idea what you're talking about. struct Rocket { void Launch(); } struct Process { void Launch(); } void DoSomething(Process &amp;p) { p.Launch(); } DoSomething would in your favorite untyped language happily launch either a rocket or a process. So stop talking bulls*t.
consider a common ILaunchable base class (interface pattern) for both Rocket and Process and a DoSomething that does: void DoSomething(ILaunchable &amp;p) { p.Launch(); } Ill design is not prevented by the compiler as you can see. This code will still launch a rocket or a process. 
main must return an int according the the std, this is right. Does this make the article point wrong?
&gt; the compiler is not the most efficient tool for avoiding bugs Fully agreed. &gt; Compiled languages do not lead to less buggy applications. Here, I have to say that this is technically(!) not correct. I'm mainly working with Python and had my fair share of runtime errors due to typos or some type mismatch. These are bugs that rarely, if ever crop up with a compiled language. Now that I'm done nit-picking, I would like to say that you are absolutely correct in saying that unit-testing, code reviews and similar tactics will be far more effective in catching mistakes than any compiler or static analysis tool. I'd even say that the (usually) higher developer productivity with non-compiled languages will outweigh the time saved by a compiler catching trivial errors.
Because I have to manipulate the descriptors separately. 
Indeed, you are absolutely right. What I tried to show though, is that runtime crashes due to easy to make common mistakes do not only happen when you use dynamic languages. In C++ also you can inadvertently double delete a pointer or call a virtual method in a constructor (like Adobe developers did).
Alright, how about this use case: I have some threads which communicate with each other. They communicate over pipes which do blocking communication. Because the pipes are shared between threads, no one thread clearly owns the pipe, and since threads can terminate in any order, if we arbitrarily pick a thread to own the pipe and it happens to die before the other threads, those threads will have undefined behavior if they try to write to the pipe. Since threads can be started and stopped dynamically, keeping all pipes allocated will result in memory leaks. Shared pointers ensure that a pipe will remain valid for as long as necessary, but will deallocate memory when the appropriate threads die. EDIT: Here's another use case that doesn't involve multi-threading: I have some resources. These resources can be grouped, and a single resource can be in multiple groups. This is easily solved with a bunch of sets of shared pointers to a resource. If a resource is removed from every group, it's released, but resources that you have a reference to will continue to be valid. Sure, you could check them manually, but that doesn't scale well if the sets are individually named variables (and it's too easy to forget to add a new set to the deallocation check, *and* you'll need to deallocate all of the resources manually in the case of an exception). Again in this case, it's not clear which group owns the resource, so letting the resource manage itself is the easiest and probably fastest option.
Ever heard of the Halting Problem? if yes, then you should know that it is mathematically impossible to catch every error at compile time. There is never going to be a programming language that does that. With that in mind, it is important to distinguish between bugs such as the one in the lisp case and bugs such as that in the c++ case: the lisp bug is preventable at compile time, the c++ bugs are not. 
So what happens when the reference count drops to zero, but the pipe still contains some messages? They disappear, of course, but should it have been allowed to happen at all? Is it a bug in the logic of some of the threads? And how are you going to detect it if it automagically disappears when the last thread exits?
Imagine the following "raw" implementation: class SomeDevice { void * m_allDescriptors; SomeDevice() { m_allDescriptors = malloc(GetDescriptorBlockSize()); GetAllDescriptorData(m_allDescriptors); // all descriptors, in a sequence, in a single block } FooDesc * GetFoo() { return FindFoo(m_allDescriptors); } BarDesc * GetBar() { return FindBar(m_allDescriptors); } } The pointers returned by GetFoo and GetBar are valid only as long m_allDescriptors is valid. Now add that SomeDevice also holds other resources (e.g. a device connection handle), and you need FooDesc and BarDesc beyond the lifetime of SomeDevice. Clients may want to store one of the descriptors. Functionality-wise, there is no point exposing an "DescriptorBlock" entity to the caller. Is that understandable?
Sorry for the emotional rollercoaster ride - unless you enhjoyed it. Then not so sorry ;) &gt; I'm not convinced that use cases like this are common enough for the feature to be worth it As I understand, the underlying pattern (as stated in another repy already): "Pointer A and Pointer B are valid as long as X is valid" If the caller is interested in A and/or B, but not in X, the aliasing constructor is a wonderful tool. However it's not that hard to implement it with a custoom deleter, so your question whether this is worth adding is justified. 
&gt; (NB. atomic increments/decrements are also somewhat of a sync point - so it's not "completely local", but still they are usually easy to optimize away locally.) Just curious, do any compilers actually do this? Or did you mean manual optimization?
You are arguing a hyperbole. There is no general way to prove that two mathematical expressions are identical, yet x=4, and x=4 are identical. Wow, how'd I do that? The halting problem just tells you that you cannot build a general algorithm which could determine if an algorithm carries on forever or halts for all possible algorithms. It doesn't mean that you cannot catch at compile time bugs that would cause your program to halt, or bugs that would cause it to run on forever. And of cause, there are infinitely many algorithms that provably halt, and just as many that provably don't. 
Both :) Manually, passing by `const &amp;`. Traditionally, copy elision (RVO and NRVO) by the compiler. Not sure about the std::tr1 or current boost implementation, but on C++11 they can support move semantics for guaranteed copy elision in more cases 
here are some tips: * Stop using arrays, they are terrible in this use case. Use the std::vector, they are a part of the language and a part of the standard. * you can still have a print_ints function by splitting up my original code * don't include namespace std that is just bad practice Here is the code with the print_integer function. #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;iterator&gt; #include &lt;vector&gt; inline int round(float a) { return static_cast&lt;int&gt;(a+0.5); } void print_integers(const std::vector&lt;int&gt;&amp; x) { std::copy(x.begin(), x.end(), std::ostream_iterator&lt;int&gt;(std::cout, "\n")); } int main() { std::cout &lt;&lt; "Please enter floating point values " "separate by newlines ending with 'q'" &lt;&lt; std::endl; //input std::vector&lt;int&gt; ints; std::transform( std::istream_iterator&lt;float&gt;(std::cin), std::istream_iterator&lt;float&gt;(), std::back_inserter(ints), round); print_integers(ints); return EXIT_SUCCESS; } Is that OK? let me know if not, I would far rather explain stuff to you than have you dumb it down into Java or C style code, this code is much cleaner and safer.
The thing about the array is that its the main focus of the chapter of the book I am studying this week, and is also required part of the program. I should have mentioned that part sorry. 
is this homework? I really really would urge you to read this first: http://en.cppreference.com/w/cpp/container/vector then try and use this in conjunction with the exercises from the book. Arrays just aren't used in (good) production code any more like you are using them. It is much better to encapsulate them inside of a unified wrapper interface (there are other containers too). TBH I program A LOT of C++ but I aren't even really sure about the rules and syntax (such as passing them to functions) concerning arrays because it is a rarity that I have to use them.
Yes its the project I have to do in a intro to C++ class, and I have a test next week. So a vector is just a better array, that sounds like something I need to look into. I think I can get away with not using the array because I did a bubble sort array for a number sorting project earlier this semester. 
Well technically it is a wrapper around a dynamic array, so it essentailly replace this crap: std::cout &lt;&lt; "how many elements" &lt;&lt; std::endl; std::size_t count; std::cin &gt;&gt; count; int *i=new int[count]; //blah blah blah delete[] i; instead you'd have std::size_t count; std::cin &gt;&gt; count; std::vector&lt;int&gt; v(count); //safely provides it's own memory. it allow you to do bounds checked accesses v.at(5); //out of bounds exception and gives you the iterator interface as I have shown in my previous example. However my favourite reason to use them is that when passing to them functions they behave more like normal objects rather sort of like pointers. For example you can pass them by const ref, and return safely by value. You can also resize them when necessary with having to manually copy the value across. If you are just learning C++ to pass a course then I would just jump through the hoops, but if really want to learn the language then you need to learn the idiomatic ways of writing C++ to be effective. (incidentally there is a good book called exceptional C++ well worth looking at).
Oh thanks for that recommendation. I'll check it out too!
It doesn't look like you read the article, and if you did it you're not intelligently countering any of the points made in it. Address any of the specific recommendations made in the article, for example.
He addresses the drawbacks and recommends using functional techniques where it helps in productivity and even performance with parallel programming. For example, it's not a good idea to use functional programming techniques in modifying lists in C++ (while it makes sense in haskell), but there should be many cases where you can move to a safer, more functional form (e.g., void normalize vs vec3f normalized()). It still seems like you haven't understood Carmack. &gt;agree with everything he said, except for his implication that it's actually a better plan than using a language more suited toward functional programming. He explains in the article why functional languages are a no go, currently at least, and shows that functional techniques can help in achieving goals like safety, productivity, and parallel programming even in languages like C++.
Refusing to use a better style of coding because poor programmers won't understand it doesn't sound like a fantastic reason. If you follow that logic all the way, we'd all still be coding in assembly. In reality, it makes many common programming tasks today much simpler. The traditional "killer feature" of functional languages is parallel computation, and it does vastly simplify the work needed for it. My favourite feature of functional programming, though, is simpler code. I can write a function and, if it is small enough, guarantee that it cannot fail under any circumstances. Null pointers can't be passed in - I don't use pointers. The state can't be wonky - I don't use state. It just simplifies the amount of things I have to worry about when writing code, and I find it vastly simplifies debugging.
This does what I want it to, its not vector but at least it follows the directions. I think vectors are in the second C++ class my college offers. I am not taking anymore programming classes. I only took it because it was offered online. #include &lt;iostream&gt; #include &lt;cstdlib&gt; using namespace std; inline int round(float i) { return static_cast&lt;int&gt;((i&gt;0.0f) ? i+0.5f : i-0.5f); } void print_integers(float a[], int size) { for(int i=0; i&lt;size; ++i) std::cout &lt;&lt;round (a[i]) &lt;&lt; std::endl; // eventually call round(a[i]) } int main(){ float numb[3]; for(int i=0; i&lt;=2; ++i) { cout &lt;&lt; "Please enter a float: "; cin &gt;&gt; numb[i]; } print_integers(numb, 3);// we will add more here system("pause"); } 
Exactly! Because a compiler can only catch some bugs and not all bugs, it is better to go with the solution that catches zero bugs! I totally get it!
Because the compiler catches minor bugs, you should not select your language based on the fact that is compiled or not. Select a language that fits your purpose and boosts your productivity, be it compiled or not. Compiler help is too small to be an outstanding choice criteria.
Didn't you understand that the '...' in the second example stands for 'some computation of arbitrary length'? :-). What am I trying to tell you is that from a practical stand point, static analysis tools cannot catch the 'important' bugs. 
well ok, once your finished with your course I recommend reading Effective C++ it might teach you some of the good practice your course may of glossed over.
It really depends on what you mean. Say I write a little math function: int Add(int a, int b) { FormatHardDrive(); // Oops, meant to Log, but the keys are right next to each other return a + b; } Few languages would be able to help with that sort of logic error. C++ can't really catch it in the usual case, Haskell could in some cases, but not all (and then, only because of mixed pure and impure code, not anything special about the format function). That the compiler can't catch this isn't a point against static typing, nor is it a point in favor of dynamic typing, so we are net 0. Then there are simple typos: // Rarely run and out of the way, but important, code int Add(int a, int b) { return a + bee; // Oops, typo } C++ and most other compiled languages will catch this very early on in the development cycle. In many (all?) dynamic languages, it is possible that the developers and testers never happen to run this and it escapes to customers. And maybe your language blows up when the code is run, or maybe it default initializes the value to 0, causing your financial app to miscalculate a payment, causing your customers to be sued by their customers, who in turn sue you, and suddenly that typo becomes very expensive. My example may be unlikely, but being able to catch even half of my mistakes before even running the program is a huge time and cost saver in the long run. If you are arguing that it shouldn't be the only consideration, then sure, I doubt people would argue with you. But it absolutely should be a consideration, even if it turns out to not be a big enough concern in your situation. Dynamic languages are great, but they have a cost. Static languages are great, but they have a cost. We need to count the cost and choose accordingly. 
The point is, dropping C++ is just not a realistic option, period. Functional programming has advantages, some advantages that could possibly be leveraged by C++, like the concept of pure functions. The article discusses some of the problems with moving over to a functional language like you suggest, if you're curious as to why what you're suggesting is a bad idea.
What does the triple tilde mean/do?
It's nothing. He was just using it to omit the rest of the class definition.
Doh! Thanks. 
This is probably the weirdest response to an article about placement new I have ever seen. You are explicitly calling the constructor every time you use new, whether it's a placement new or not. All the placement new does is let you specify where to store the object you're (again, explicitly) calling the constructor for.
I don't care for his attitude that programming is subtle magic. If you don't understand, then figure it out.
[Boost.Phoenix](http://www.boost.org/doc/libs/1_49_0/libs/spirit/phoenix/doc/html/index.html) enables functional programming in C++. I tried it out today by writing a [little program](http://code.google.com/p/stacked-crooked/source/browse/trunk/Playground/Phoenix/main.cpp) for solving 2nd degree equations. The laziness and composability of the functors is quite cool. The downside is compilation time. My little test program already required 2-3 seconds of unoptimized compilation on an Intel i7 machine. That's not very promising.
&gt;double Point::distance(const double x, const double y) const { This is one use of const i wouldn't recommend (params). It serves no purpose there, and leaks information about the implementation to the interface - yuck.
Luckily for us, C++, though expressive as any high-productivity language, retains the spirit of the machine, unlike many "too high-level" languages. There's no room at all for magic.
It's true in *this* case that the compiler doesn't see `const double` differently from `double`, but that's not generally true. Both the `const` and `volatile` qualifiers to a parameter are part of the public interface to a function. E.g. (using the CodeSourcery ABI used by GCC): $ echo '_ZlsRK1XRV1X' | c++filt operator&lt;&lt;(X const&amp;, X volatile&amp;) $ echo '_ZlsR1XRV1X' | c++filt operator&lt;&lt;(X&amp;, X volatile&amp;) The [ABI Reference](http://sourcery.mentor.com/public/cxx-abi/abi.html#mangling) hints that CV-qualifiers are optional, but if you try compiling a class with overloaded methods that different only the `const`/`volatile`-ness of *non-machine types* you'll see it works just fine, since that information is actually retained by the compiler. (It's actually useful to the compiler in terms of non-machine types since it knows whether it can assume the objects passed as parameters may have changed or not for use during optimization passes)
It is a non-sequitur to claim that if something can't catch all problems then it can only catch easy problems. But for sake of argument, lets say that is true; a that a static analysis tool can only catch problems that are easy for static analysis tools to catch. This reveals another non-sequitur; that bugs that are easy to catch for a static analyzer are also easy for a programmer. On the contrary, there are some things programmers are better at catching and some things a computer is better at catching. Having overlap is a good thing. But lets even grant for sake of argument that most bugs are easy for programmers and the static analyzer. Even when a bug is easy for both a programmer and a machine, often the machine is faster at it. I might take 5 minutes to notice a typo that the compiler caught in 5 seconds; and while it was catching my typo, it was also doing 100s of other checks that might have taken me hours or days to do to the same thoroughness, and the compiler didn't get distracted by meetings, coworker's questions, emails, boredom, Reddit, or any else that would have vied for my attention. In fact, the compiler just found the easy problems for me, so I can focus on the remaining hard problems! Win!
OP is a faggot.
Im not sure what type safety you are referring to. The preprocessor is just textual substitution. If you need more type safety you can tag the datastrutures, but that is just generally used for generic algoritms.
This is a list of things that should be considered for anyone writing new code. Too many times have I heard of people that treat C++ like it was the same language prior to standardization. That is like somebody complaining about Fortran as if it was Fortran 77 instead of the four standards since then.
I'd agree, especially with range-based for loops being widely available now. I don't have a lot of use for std::for_each anymore. // standard for (auto i = v.begin(); i != v.end(); ++i) { } // better std::for_each(v.begin(), v.end(), []{ }); // best for (auto i: v) { }
The reason I still prefer for_each over range-based for is that it's still possible to terminate a range-based for early with break, or cause steps to skip with continue. When all you want to do is visit every element in a range, or have a strong guarantee that every element gets visited once and only once, and in order, I would still use for_each. I agree that range-based for loops are prettier though.
&gt; You should declare things const to make contracts more clear. Yes, I absolutely agree. I often use const when computing, e.g., iteration bounds. Not so much to declare a contract or to facilitate optimization; it's mostly to prevent myself from doing stupid mistakes ;) &gt; Sure, gcc and MSVC may perform these optimizations, These two, LLVM and icc are the only ones I really care about. ;)
Gimpel's tools do it if you're ok with paying money. Other than that I don't know, but [here](http://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis#C.2FC.2B.2B)'s a list to start with.
&gt; If you just want to find what methods could be declared const given a bunch of methods written by someone who shouldn't be coding in C++ in the first place (i.e. none of them const), I suppose you could declare them all to be const and then see where the compiler complains. Delete the constness from those methods, and viola, you have declared const on all the methods that don't change state. Yes, this is the case and why I'm looking for a tool. Unfortunately, the codebase is way too large to put const everywhere, though that is a good strategy for small bits of code. P.S. I'd argue that "shouldn't be coding C++" is a bit harsh. These particular programmers have been programming in the embedded world since the early 80's -- originally with assembly and C. They very talented, but do need to update their skills. They are learning, but much of the codebase was written prior to them learning how to proactively use const.
I'll give this a whirl. I already use CppCheck, but don't enable everything (there's a lot of noise with our existing codebase). Thanks. EDIT: I just tried CppCheck on the code below with the --enable=all option and it did not report anything. ([Gimpel's PC-lint for C/C++ did though](http://www.reddit.com/r/cpp/comments/t08cy/static_analysis_tool_to_recommend_places_to_add/c4ifv6a).) #include &lt;stdio.h&gt; void printit(double* pDbl) { printf("Value = %f\n", *pDbl); } int main() { double pi = 3.14159; printit(&amp;pi); return 0; } 
woops, my bad.. like I said, never used it.. I guess I didn't read it carefully enough
If they won't pay for PC-Lint, a) buy the tool with your own money ($299, right?) and steal office supplies to make up for the cost, and/or b) just run out of that place -- if they don't value quality &amp; proactive mindset like yours, find a place that appreciates &amp; benefits from your attitude.
I'd suggest looking into [SFML](http://www.sfml-dev.org/), I've used it with decent success. It's cross platform so you should be able to use it in whatever OS you're using.
There are tons of great tutorials out there. I am taking a graphics class in school right now and these tutorials have been helpful supplements: * http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Chapter-1:-The-Graphics-Pipeline.html * http://nehe.gamedev.net/tutorial/lessons_01__05/22004/ You can also check out http://www.reddit.com/r/opengl/
But the company has already paid for 2 other commercial static analysis tools, and we use CppCheck as well. They all offer different advantages, but running 3 different static analysis tools on our code base already takes quite a bit of time. Convincing management to purchase another commercial tool will be challenging.
Not sure if trolling...
&gt; Dynamic languages are great, but they have a cost. Static languages are great, but they have a cost. Totally agree, no silver bullet. One remark though: static analysis for dynamic languages (yes you can do simple static analysis for dynamic code) can prevent most of these typo problems. Modern ides for instance can help you catch those typos. RubyMine (ide for Ruby from JetBrains) helped me see those problems in my Ruby scripts.
Indeed. The problem with static typing (and static analysis also) is verbosity: Declare your interfaces, annotate your code etc. Duck typing is probably more dangerous but it really boosts productivity. At least this what python/ruby communities advocate.
Out of interest, what other tools are you running? This would sound like deficiencies in the other tools to me. Especially as the granddaddy of them all (pc-lint) does it.
There is nothing "web" in Casablanca. It's an HTTP client/server library with asynchronous capabilities but nothing more. If you want a true web framework for C++, use [Wt](http://webtoolkit.eu) 
Using Direct X us one of the wrote things you can recommend. You want to use OpenGL as it is cross platform.
You could make an argument that the tool should find places that can't be const! Make const the default, make mutation as abnormal as possible!
Nehe also use immediate mode rendering, which is really counter productive as soon as you render more than a single quad. 
&gt;I would really rather know how everything works before using a tool like that Not trolling, just answering the OPs question. The c++ books don't talk about graphics because they are architecture specific. People are suggesting low level libs like SFML, but that doesn't answer the OPs questions, it moves them into wondering how the lib works. 
Frank D Luna has a really good series of book son how to use DirectX. http://www.amazon.com/Introduction-3D-Game-Programming-DirectX/dp/1936420228/ref=sr_1_1?ie=UTF8&amp;qid=1335886210&amp;sr=8-1 He has versions for previous versions, too. They also exist in pdf form in places. He goes through the linear algebra in the beginning that really helps if you're not familiar with it, and he explains how a lot of the graphics works really well. Great read.
The 'metal' these days is a bunch of shader execution cores. So I wouldn't call either very 'close to metal'.
mode 13h tutorials certainly do not help learning how modern graphics libraries work.
Seems like an interesting idea, but until it's open and works on multiple platforms, I don't know how useful it will really be.
&gt; You could make an argument that the tool should find places that can't be const! A compiler will tell you that! ;-) &gt; Make const the default, make mutation as abnormal as possible! That's the practice of the team now, but we have a large legacy code base that I'd like to make const-correct if possible.
There's nothing wrong with suggesting DirectX, XNA, whatever. OpenGL can be a bit overwhelming to start with. I'd suggest maybe a framework built around LWJGL too. Honestly he should try whatever gets him productive the fastest..then move down the stack if he needs to. Cross platform only matters when you know what type of game you want to make. 
QT is very easy to pick up, all the documentation is available online, and the QT creator program is extremely easy to use. I had to use it for school and was pleasantly surprised. 
Seconded. Nehe's tutorials were awesome in their day, but they're incredibly outdated and will send people down a dead-end path.
Yeah there's nothing different with library includes from express to pro/etc.
Eh, I would argue that DirectX is a better API than OpenGL on api merits (it covers 2d, 3d, sound, input, animations... OpenGL covers 3d and pixel transforms). When I recommend things to beginning programmers I don't let my advanced opinions get in the way.
TextBlock^ -- that's not C++.
It is not c++/clr. It's native code, what you see is component extensions for C++, but it looks like c++/cli.
See my other comment.
1) No C++ compiler can compile that code, not even Microsoft's; it's missing a semicolon. 2) Microsoft's C++/CLI compiler and Microsoft's C++/CX compiler could parse that code once the semicolon is added, as could any other compiler that chooses to support those languages. 3) You are right to say the article's code is not C++. 4) You are wrong to say it is C++/CLI. 5) It is C++/CX.
I did mention that it is running 100% native, hence no CLR. But you are right, there is room for answers to questions like those you are asking. I don't see why you wouldn't be able to use your old data models and logic but when doing stuff against the presentation layer, the code is a bit different from what we've seen before.
This will get you started, sir: http://www.lazyfoo.net/SDL_tutorials/
Heh, I was expecting pushback on my #2, not my shorthand in #5. :-)
This book: http://www.amazon.com/Problem-Solving-C-7th-Edition/dp/0321531345 (though there are newer editions I believe). And this tutorial: http://www.cplusplus.com/doc/tutorial/ have helped me a ton over the past year. The cplusplus.com tutorial is downloadable as a PDF (which I've printed and bound thanks to my university's $40 print quota).
[The Definitive C++ Book List](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list)
I have no doubt that Dx3D may well be a better API, but that isn't the point I was making. Often (especially when you are new) it is better to have to have the flexibility of something that is portable and learning HOW to write portable code and have written small amounts of both getting off the line wasn't much easier in either. BTW: I wasn't recommending raw openGL, but a openGL based framework like SMFL or SDL which are better comparisons to Dx alone.
The definitative C++ beginners book (and for anyone who learnt wrong) is Accelerated C++, once you have have the basics down Exceptional C++ is a great follow up. Soureces: * http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list * http://jcatki.no-ip.org/fncpp/Resources 
The tutorials on cplusplus.com are a horrible way to learn C++ Try to stay away from them. The same goes for the outdated reference they provide.
Hmm, thanks, I'm glad you brought this to mind. 
Visual Studio. Why fix something if it ain't broke?
Eclipse is fine, Netbeans has a working remote building feature, QtCreator is just skyrocketing lately (but doesn't support any build systems apart from qmake). I definitely wouldn't use CodeBlocks (it's just an awful IDE).
[C++ Programming Language, The (3rd Edition)](http://www.amazon.com/Programming-Language-The-3rd-Edition/dp/0201889544/ref=sr_1_3?ie=UTF8&amp;qid=1336011507&amp;sr=8-3) Great book, read it cover to cover for a class. So many bits of wisdom sprinkled throughout.
Qt Creator also supports Cmake and autotools. Also, if you can compile by running a command(s) in the terminal, you can do that too.
Qtcreator is an awesome cpp ide.
I use Geany
What is your gripe with Code::Blocks? I use VIM almost exclusively now, but I remember loving Code::Blocks because I could use it on *nix and doze.
Visual Studio kicks everything else. Though I'm a little off-put by the sluggish responsiveness in 2010. What I highly recommend though is adding Tomato Software's Visual Assist. It greatly improves VS, to the point that I consider it a must have.
I work on cross platform c++ and for efficiency sake this is the best. I still can't figure out why people like stuff like VS. Always seemed counterproductive and counter intuitive.
1. Works on one OS 2. Performance gets worse with every version 3. IntelliSense still sucks 4. Mediocre source control integration 5. Not free as in speech 6. Not free as in beer Still has the best debugger, though.
Damn. I left my mindreading device at work today. Maybe you could tell us what book you have &amp; what sucks about it?
yeah, using Eclipse and CDT which has nicely matured.
As "growingconcern" said, Whole Tomato Software's Visual Assist X is must-have add-on to address the IntelliSense complaint. All valid points, though.
So you can fix #3 by spending $100 or $250, on top of the cost of the IDE itself. So if you do that I think it's fair to say "REALLY not free as in beer", and while VAX is not as much of a performance disaster as IntelliSense it can still cause very noticeable typing lag :)
Well, you can use Eclipse, Netbeans and QtCreator on both Windows and Unix. The problem with Code::Blocks is hard to define. It's just weird. Some people like it, and I don't know why (and when asked they couldn't explain it either). The problem is mostly the constrols, every time I needed something more complex I just couldn't find the place where it was configured. Usually it turned out to be in some completely counter-intuitive place.
Application domain matters quite a lot. For example VS is basically forced for video games, in part due to D3D, and that 360 Certification requires VS2010 compiled binaries.
SlickEdit. Has flexible build system support, auto complete for C++ works great out of the box, and is fast (most of the time). of course, no C++11 support yet, but it recovers gracefully. 
Lets not forget that Microsoft also drops features from release to release, while expecting the developers to blindly updagrade, like the Intelissence disater, removal of printing with syntax highlighting, XP support, ... But if you already paid for it, then just use it.
Jeez. I *just* did a presentation on what C++ books to read. On the plus side, my list was pretty much exactly the same. :-)
I'm surprised no one said KDevelop. Pretty powerful IDE with a very good auto-completion (especially for Qt signals/slots). It also supports C++11 pretty well.
Emacs.
I can't imagine using anything other than VS if given the choice. I've been using eclipse at work (though for Scala, not C++) and have managed to progress from intense loathing to reluctant acceptance, but it still just feels broken in a lot of ways compared to VS. For the people saying "Intellisense sucks", what is there that does a better job? I've certainly had issues where it fell apart before, but every version has gotten better, I'm impressed with how deep into macros and templates and such it is able to sort out definitions... I'm completely willing to believe that there is something better out there, just haven't seen it. Unless there is something that blows it away, it's not really fair to say that it sucks.
It's awesome under both windows and Linux. When I tried it on OS X, it was super slow, and the [cmd]+arrow keys (like home/end on a non-mac keyboard) didn't work.
I use Eclipse
I work on a large (around 500 classes in the core product) piece of software. I do most of my work in vim. It's just always felt comfortable, with just the right amount of features to make programming less painful (plus, we support about 25 platforms, between OS vendors, versions, and architectures). Vim keeps it simple.
Basically any other full developed IDE.
Visual Studio Express does not come with the CRT redistributables, nor does it come with the rights to redistribute them.
C++ Primer
Well other compilers _could_ choose to support them(like you said), since most other compilers have their own set of extensions. I see nothing wrong with that :P) Just because microsoft is "going native" doesn't mean they can't do it in their own way :) Not that I mind, I'd rather have to deal with some hat syntax than the obj-c I'm subjected to on apple :( Some people in this thread seem to be getting too emotional about their pure c++ ...ITS JUST CODE GUYS and it saves alot of bullshit! In the end I bet 99% of people will use the hat other than the alternative code. So I quite like your list, it tells them how it is. :)
of which any version of Eclipse isn't.
code blocks and codelight both suck, don't let the xcode people fool you either..that IDE crashes more than anything I've ever used; Other than VS I haven't found another acceptable c++ IDE other than netbeans or eclipse. 
Yes, came here to say KDevelop. You beat me to it. 
I know this is very different to what you are asking, but I would urge you to giving NO IDE a go. I personally used to use VS but when I migrated to Linux I found myself just using Vim + Compiler. Once you learn how to use a real text editor like VIM or Emacs then you will be much more productive (I assure you). It forces you to read the documentation of the API you are using, as well as even read some of the code you are using. And by doing so you become a much better programmer, you learn what makes a good API, you learn how to write code that is easy to debug, (because GDB is a PITA tbh) and easy to debug code is usually good code. Further more doing it this way also teaches you things that are sort of getting lost amongst many new programmers, stuff like how to write a good Makefile, and how to make programs that are designed to be piped in a part of a tool chain rather than big monolithic programs.
Well, OP is already using VS, so I made the wild assumption that he's not using Linux.
&gt; I have found that when I use VIM + compiler then I write code that is by it's nature easy to debug, IE most bugs in my code can be solved with cout's. Do you work with other people?
The typos in that article..
it handles them just fine. There is special support for them (the debugger supports plug-ins) since VS 2005 or so. 
They were too much. I stopped reading. 
Huh, I didn't realize you could do that with statements as well, I assumed it was something fancier than that, thanks!
Yes, using GIT. we don't have project files littering src directories UNLESS it is a UI in which there is QT junk hanging around, but that is separated from the back code and updated with scripts as though that back end is a library and the UI is a separate project it works very well.
yes, but are those plugin there by default or do you have to download them from 3rd parties? (I am glad there is facilities for that, beginners have no excuse not to use std:: containers.
What I mean is C++/CX is going to be a standard C++ extension in Windows. I expect, that even if we don't like it, major C++ compilers targeting Windows, will support it.
I had this book many moons ago (it was recommended since the version 2 was thought to be good) and found it to be the worst book too. Get C++ Programming Language, The (3rd Edition) as posted above, it was clear, concise, detailed, and easy enough reading, if a little large, and made my life a lot easier, after that then move on to Sutter's Exceptional C++ or Meyers
Could you please provide me the output of g++ --version -v I'm investigating this because my [distro](http://www.josuegomes.com/mingw/) is also affected.
As of VS 2010 the debugger visualizers have built-in support for STL containers (at least std::vector and std::map, not 100% sure about others). There is also supposedly a [way](https://svn.boost.org/trac/boost/wiki/DebuggerVisualizers) to add support for some boost types, though I have not tried that yet. I just found out about it. Should come in quite handy if it works! 
Fair enough :-). I was talking more generally
Qt Creator.
I've been using Sublime Text 2 and it is amazing.
Another vote for Accelerated C++
Creator is no more Qt centric than Visual Studio is .NET centric. Arguably much less so, in fact. And I'll take the minimal fischer price GUI of Creator over the Office level UI disaster that is Visual Studio... Either there are a lot of programmers that click on the scissors button to cut text **or** Visual Studio's GUI is the result of irrepressible design apathy and feature checklisting. The latter sounds more realistic to me.
vim + windbg
This. This is the most important part. Read and learn something basic. Test how it works. Have something in your mind, like "what if I did X with pointers, what would happen"? Test it. There's no better way to learn than experiment and work by hand. Books are fine and will give you insight on what is going on, but they'll carry you only so far.
OP sounds like they want to learn on Windows...Windows C++ dev almost exclusively uses Visual Studio, and I don't see why you'd want them to start learning in an environment different from what they'll end up developing in eventually. The only real benefit I'd see would be the understanding of the separations between the preprocessor, compiler, and linker. To be clear, vim/emacs, make, etc etc have their places, but their place isn't on a Windows machine, IMO.
&gt; Having read a post at Stutter's Mill I got thinking about method chaining in C++. I am very keen on method chaining in Java and so was pleased to see the future().then() pattern turning up in C++11. This got me thinking about chaining futures x.y.z etc. The idea being that each task (x,y and z) could be run on a different thread according to the load of the machine. It is a bit like thinking of the tasks as very simple actors. I think you're a little confused here - that is exactly what future().then() does in Casablanca. It works along similar lines to .NET's TPL (`Task&lt;T&gt;`).
cmake based build + KDevelop (for writing) + QtCreator (for debug sessions)
I'm not even a C++ programmer and I know RAII as a pattern. Who have you been interviewing? :\
You are making a huge mistake and wasting your money. Accelerated C++ was a mediocre book when it came out. It is now an outdated mediocre book. The gold standard for learning C++ is Stroustrup's Programming: Principles and Practice Using C+: http://www.amazon.com/gp/product/0321543726/ 
How is confused - seems like the two of you are in violent agreement to me.
tl;dr "we recommend that you consider using a different compiler such as Intel or gcc"
Accelerated C++ is one of the best beginner book I have seen for C++, it is the only one I have seen that teaches people in the modern C++ style and uses abstractions from the off. Other books either try and teach you Java in C++ or C with Classes, those approaches make terrible results. 
&gt; The only real benefit I'd see would be the understanding of the separations between the preprocessor, compiler, and linker Well there is a lot more to a tool chain than that, but even so that is something very important to get your head around. I would argue that development in general isn't for the windows machine, Microsoft make there operating system very un-programmer friendly. I would strongly recommend that the OP learn to program on linux, it is a MUCH better development environment. Writing games for Linux is more than possible, it's just there isn't much market for it. In fact to say writing them for linux is a bit misleading, you can write games that can be cross platform, something that is hard to do with VS. 
500 classes isn't really all that large. I have typically worked on projects with hundreds of thousands of lines of code, and I don't think they qualified as large either.
Makes sense. Some people feel it is Microsoft's duty to support C99 and Herb is openly saying this is not going to happen. Visual C++ is a C++ compiler - if you want a C99 one, there are plenty to choose from.
Is there a way to compile c code as c++, and avoid name mangling without source changes? Haven't looked into it much, more just curious.
&gt;It used to be so that any C++ compiler vendor also had a C compiler available. It used to be that C was quite close to a subset of C++. C99 changed that -- it's too different from C++, and thus, making a C compiler out of a C++ compiler isn't trivial any more. &gt; Why to pay Microsoft for the compiler You do whatever you want. If you want a C++ compiler, Microsoft has one. You can buy it, pirate it, use the free (Express) version, or use another compiler altogether. If you want a Python "compiler" (not sure the word is adequate, but you get my point), then Microsoft doesn't have one. You have to ask another vendor. Same goes for other languages, like Ada, Lisp, or C. At this point, it's like complaining that Mercedes-Benz doesn't make ice-creams, or that you don't get free ice-cream when you buy a Mercedes car. 
Yep. As simple as that. Why did no one think of that?
I'm curious mostly for porting/compiling C code meant for gcc/linux on vc/windows.
OK. So looks like there are many choices of compilers and platforms so am not sure why folks are complaining.
If you wrap everything in: #ifdef __cplusplus extern "C" { #endif #ifdef __cplusplus } #endif it should compile without changes on either.
Well that's shitty logic, why aren't you building a C99 compiler? Maybe you should become a better developer. It's a policy matter and a business decision, and has nothing to do with the level of competence of the developers at Microsoft. 
If all the C code is compiled as C++, why would name mangling matter? All of the code would be mangled and accept mangled names, so it should work regardless.
Because it's meant for implantation in a larger engine context, not as a standalone solution. Keeping this specifically in a namespace separate from the rest of the engine would complicate some things a little bit, and I didn't want to deal with that right now. Furthermore, certain small niceties depend on macros, which pollute the global namespace anyway… A long-term solution would definitely encapsulate this in a namespace along with the rest of the engine. :)
Even with macros it would still be better to put it in its own namespace. If someone wants to make it "global" they are free to use a "using namespace" directive to import it, however, the reverse is not true: one cannot easily move all of the global symbols into a different namespace. This would minimize global pollution: only the macros would be a (potential) issue. In terms of putting it into a larger context, placing it into its own namespace facilitates this. One is free to use "using namespace" within other namespaces so he/she can "import" your code into his/her code easily. Even better, because namespaces are used, name clashes can be avoided or dealt with easily by the user of your library. Additionally, (argument dependent lookup) can (and should) be exploited by programmers using your library to avoid having to always qualify the namespace as well.
What I mean is that this: int sum = 0; std::for_each(v.cbegin(), v.cend(), [&amp;sum](int x) { if (x % 2 == 1) return; sum += x; }); is equivalent to this: int sum = 0; for (int x : v) { if (x % 2 == 1) continue; sum += x; } I.e. an early return from the function supplied to `std::for_each` is equivalent to a `continue` statement in a loop.
Are you aware of the Cern ROOT framework and its reflection capabilities? You can find it at root.cern.ch. Its documetation on the technical aspects of reflection isn't great, but it has an enormous user base, good forum and is very comorehensive. It does reflection and serialization. I don't think it has serialization to json, but I believe that it should be possible to write a plugin. If you contact the primary developers through their forum, I'm sure they would be happy to help you a bit with the plugin if you're willing to contribute to plugin back to the project.
Care to explain how the reflection actually works in this implementation? Can you just query the type of object, or methods etc?
I have considered implementing automatic reflection by writing a Clang or GCC plugin, maybe in combination with C++11 generalized attributes. But neither compiler supports them yet (although they do support plugins). It would be extra neat, though!
I was not, but looking at ROOT, I don't think I'm interested in using it either. :) The main goals here are to remain simple and to avoid preprocessing build steps, which ROOT seems to require. Also, the design of ROOT seems quite inconsolable with my personal taste (and many others', judging from the criticisms voiced against the framework).
Replying just to "... as in any such system." I was hopeful that some magic would provide class member functions etc. automatically, a bit like qt does (contradicting to the quoted text). I know it uses a preprocessing, so it's cheating.
&gt; Not free as in speech Irrelevant; back to /rms/ &gt; Not free as in beer The express version is free. The compiler is free. A student can get the advanced editions free through DreamSpark. Seems to me that it's free for everyone who wouldn't legitimately be using it for profit.
Nirvana fallacy. Eclipse/Netbeans/Vim plugins don't have anything near IntelliSense/VAX to begin with (at least for C++).
virtual calls can be inlined if the compiler can prove that the indirection is not needed.
Very much so. I'm running it in Windows 8 consumer preview, and it's really smooth. Why wait?
Divide each byte by 16? edit: bit-shifting would be faster.
Read and keep a good book: http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list Also learn data structures and algorithms while you're studying C++. Then learn C++11. Then learn the basics of Win32 and DirectX programming. I found this site helpful: http://www.directxtutorial.com/ Do a bunch of smaller projects along the way. Then you will be ready. You can definitely do all this in one summer as long as you commit a few serious hours per day.
Something like [this](http://ideone.com/zdHIn) maybe? Bit twiddling is not my strongest field, and I have not actually verified that it works correctly, but the idea should be valid.
Intellisense is so bad that it has to be turned off. VAX is a little bit better than Qt Creator's C++ code completion on really big projects, but Qt Creator is free, so... But yeah, clearly I was comparing Visual Studio to Vim.
Shift the red and blue right by 3, shift the green right by 2.
You have to think about the ranges in each case. For 24 bit (or 32 bit if you include alpha), each colour has a range from 0-255. In 16 bit colour, red and blue are ranged 0-31 and green is 0-63. So let's look at one component - the red component. What we want to do is conserve the percentage of red that we have. So let's say we have a value of 153 for red in 24 bit. That's 153 of a possible 255. What's that as a ratio? 153/255 = 0.6, or 60%. We have 60% of the possible amount of red. Now to transfer that 60% red to 16 bit colour, we do 0.6 * 31, because the maximum for red is 31. That gives us 18.6, or 19 when rounded. So there's your new value. You would then do the same for green and blue. To summarise, the equation is: color16 = (color24 / maxColor24) * maxColor16 
I disagree with this method. Try this testcase: #include &lt;stdio.h&gt; int main() { for(unsigned i = 0; i &lt; 256; i++) printf("%3d %2d %2d\n", i, (i * 31) / 255, i &gt;&gt; 3); } This shows the input from 0-255 and the output using both your method and using the standard method of simply truncating the three least significant digits. Your method results in the values being unevenly distributed, such that there's only one input that results in the value 31, while every other output is produced by groups of either 8 or 9 inputs. In contrast, the standard method distributes the values evenly across the range, such that there is no clipping or distortion, and every group of 8 inputs maps directly to one output. The standard method is also much simpler to implement: return ((r8 &gt;&gt; 3) &lt;&lt; 11) | ((g8 &gt;&gt; 2) &lt;&lt; 5) | (b8 &gt;&gt; 3); 
For ultimate correctness, make sure the gamma of the source color is as close as possible to the gamma of the result color. ;)
Truncating is simpler, but I can't help but cringe at the information loss. The distribution unevenness is a feature more than a bug, but your method may yield better results in some cases.
&gt; To summarise, the equation is: &gt; color16 = (color24 / maxColor24) * maxColor16 Yes, but if you do that, you're going to get a lot of very black pixels unless you convert everything to a float first.
Yeah. Not so much to put your answer down (because it is right), more just attaching a note to explain why copypasting this code doesn't work as expected. That sort of bug has caused all kinds of hell for me.
You'll also need to add the resulting values to get 2 bytes: typedef uint8_t BYTE; typedef uint16_t RGB_PIXEL; RGB_PIXEL convertPixel(BYTE r8, BYTE g8, BYTE b8) { BYTE r5 = r8 &gt;&gt; 3; BYTE g6 = g8 &gt;&gt; 2; BYTE b5 = b8 &gt;&gt; 3; RGB_PIXEL result = (r5 &lt;&lt; 11) + (g6 &lt;&lt; 5) + b5; return result; } 
Because the man is busy on reddit making posts about how he is clearly unimpressed with r/cpp trying to find people awesome jobs doing what they love. He would also like to point out his preference to working on Clang, even though he gives no indication that he has done or will do such a thing. Lastly, he ponders why such silly mortals would ask such a question.
This version does rounding off. #include &lt;cstdint&gt; uint16_t rgb_565 (uint32_t val) { uint16_t result; val &amp;= 0x00ffffff; // prevent overflow // val: rrrrrrrr gggggggg bbbbbbbb val += 0x04; val &gt;&gt;= 3; result = val &amp; 0x1f; // val: 000rrrrr rrrggggg gggbbbbb val += 0x40; val &gt;&gt;= 2; result |= val &amp; 0x07e0; // val: 00000rrr rrrrrggg gggggbbb val += 0x2000; val &gt;&gt;= 3; result |= val &amp; 0xf800; return result; }
GCCs optimiser couldn't do a whole lot with this (-march=k8 -O3) .cfi_startproc andl $16777215, %edi addl $4, %edi shrl $3, %edi movl %edi, %eax addl $64, %edi shrl $2, %edi andl $31, %eax movl %edi, %edx addl $8192, %edi andl $2016, %edx shrl $3, %edi orl %edx, %eax andl $63488, %edi orl %edi, %eax ret .cfi_endproc Would be interesting how it handled the trivial bitfield case, but I'm too lazy to try it.
Not add, or. RGB_PIXEL result = (r5 &lt;&lt; 11) | (g6 &lt;&lt; 5) | b5;
This is not the correct answer, for example passing in 0xFF00FF (purple) results in a 0x0000 (black). When you start adding to "val" you run the risk of propagating bits from one color channel to another.
Both ways work, although OR'ing might be faster. I will have to profile it when I'm back in the office. Edit: Nope, both take about the same time.
This will stream live in addition to all sessions being made available on-demand after-the-fact.
Yeah, any more info on this? The website is pretty sparse. (who the hell uses Codeplex for project hosting?) I mean, I get that this is a debugger, but why would I want to use this over gdb? What features does this have? What does it even do?
http://www.zero-bugs.com/2.0/product_intro.html This was around for a long time. It did work quite nicely last time I used it, many moons ago
You're naive if you think that working on Visual C++ is an awesome job. 
Personally I don't because I've worked on compilers before and its probably one of the most thankless(and boring) jobs ever.. :) But this is reddit, where nerds far and wide find pleasures in all sorts of technology bondage.
For a lighter weight IDE there is [Zeus](http://www.zeusedit.com/). It can import Visual Studio solution files and with a [simple tweak](http://www.zeusedit.com/zforum/viewtopic.php?t=2707) it can do compiles/builds using the VS command line tools. It also integrates with the [MSDN](http://www.zeusedit.com/zforum/viewtopic.php?t=2833). 
[There](http://www.zero-bugs.com/2.0/screenshots.html)
I'm not saying you can't make a nice build system for a large c++ application, but sadly most build systems aren't carefully planned and are nightmares. Also, the fact that you even have to write and carefully plan a program to compile your program seems a bit ridiculous.
I've spent the last hour or so trying to get it to build and have given up because it seems to require gtksourceviewmm-1.0 which isn't available in debian/testing or debian/unstable. That's after unsuccessfully trying to install the deb (it required some other thing that wasn't available). 
&gt; but sadly most build systems aren't carefully planned and are nightmares. I can't argue with this, but isn't this an issue of project management and not so much a problem with the build tools? &gt; Also, the fact that you even have to write and carefully plan a program to compile your program seems a bit ridiculous. I suspect a lot of these nightmares begin because the project management is left up to the IDE. For example Visual Studio does a great job of managing the build process for small and medium size projects so it is easy to leave the management up to the IDE. Where things start to go wrong is when these medium size projects grow into large projects with many inter-connecting components and Visual Studio starts to struggle. At that point you either re-think the way the project gets built or start to live a build nightmare. 
Same problem here, I installed gtksourceviewmm-2.0 and 3 hoping that it will be suffice but the error stays :( I tried to play around with GTKSOURCEVIEWMM_CFLAGS and GTKSOURCEVIEWMM_LIBS but to no avail. 
From the notes at the [2011 GCC Gathering](http://gcc.gnu.org/wiki/GCCGathering2011), it appears the reason is because GCC is already emulating many C++ features in C. Specifically: * Overloading: macros * Run-Time Type Identification: testing TREE_CODE * Templates: VEC macros * Virtual Tables: hooks From my personal experience, this emulation is not very pretty, to put it mildly. Perhaps the GCC developers also feel that language-level support for these features would make GCC source code cleaner. 
Maybe they want to be compileable by MSVC++?
It looks pretty decent to me, but if I am being really pedantic, I wouldn't have capitalised BIGNUMSTRING, whilst it is constant it is still an automatic stack variable and doesn't require the all caps grandeur. I would have made a largest product a function taking the string too and returning the largest product. you do a reserve on the vector, which is great!, however you specify 1000 potential elements, but you know the exact size will be BIGNUMSTRING's size so why not: allnumber.reserve(BIGNUMSTRING.size()); Personally I don't see the need to write `unsigned int` when `unsigned` alone does the job (the standard guarantees that they are the same). Finally, this is more of a C++ism but the function `productOfFive` would be better off in my opinion take a range of iterators rather than an container and idices. So for vector you could do unsigned product_of_five(std::vector&lt;unsigned&gt;::const_iterator start, std::vector&lt;unsigned&gt;::const_iterator end) { unsigned int ans = 1; while (start!=end) { ans *= *start; ++start; } return ans; } So to do it generically it would look like template&lt;typename IT&gt; unsigned product_of_five(IT start, IT end) { //as before This function would allow you to pass in iterator from an container and even some other sources. Also, I think product of five is a bad name because I could pass in any range size, product of might be better. Other than that, that is pretty decent code for a beginner! 
Thought I'd be nice and show you another approach you could take. Not necessarily better, but definitely more efficient (by a constant factor), and worth considering if the size of the consecutive region were larger than 5. Your code is good, but you should definitely try to find more exploitable structure to these problems, because the later problems are based on it. You won't get much further than #20-30 if you take the naive approach to the problems, so let the early ones be a warmup to "clever" algorithmic thinking. http://ideone.com/7oIhS
i'd be tempted to solve it through * transform to vector of uint * loop using accumulate() with multiplies() with push_back (&lt;algorithm&gt; seems to always dereference) * max_element to scan for max product use that as a baseline and play around to see how much optimization really improves things. i'd be curious if the accumulate calls would auto-vectorize. and of course there is a very fast way to solve this but that is up to you :-p
I was under the impression that current MS C++ compiler has fairly good C++03 compatibility. Do you happen to have any references of the "lot of glaring incompatibilities"? MSDN has some of them [documented](http://msdn.microsoft.com/en-us/library/x84h5b78.aspx), but those do not seem all that significant imho.
The best reference I can give are from cross-platform libraries themselves. The one that best documents them is Boost. Check the number of BOOST_WORKAROUND for MSVC and DIKUMWARE (Microsoft outsources the standard library to Dikumware). Of the mainstream compilers (Intel, clang, gcc, MSVC), MSVC has the highest number of workarounds.
Thank you very much for your response. I'm just starting to learn about templates (I'm reading Accelerated C++) so this helps a lot! C++ is my first programming language. I can't begin to express how happy it makes me that this was considered decent!
Being able to optionally compile with a C++ compiler means stricter type safety enforcement, particularly with enums and const-correctness.
When I started learning C++, the most useful resource I found was 3D Buzz's "C++ Programming Issue" series: Introduction to C++, Intermediate Techniques, and Introduction to Game Development. As I see from this link http://www.3dbuzz.com/xcart/product.php?productid=30, they added more tutorials, which I didn't watch but judging from the first 3 parts which I **loved**, they should be good as well. What I liked most is that it's fun, straight to the point, and you actually have to type out all the code, since it's a video tutorial. I've read a couple of C++ game programming books by then, but none of them actually helped me write a simple and fun game. It was either overly simplistic 'guess the number' games or complex beasts with custom direct3d engines using templates and 3d math. So what I'd do if I were you is watch the tutorial, write that game, and then go and read these books suggested by other folks here Books actually do help, but most of the helpful ones assume you have some knowledge and experience in C++. In my experience I never really found The One Right Book, it was the bits and pieces from all of them combined. Be prepared for a lot of googling of cryptic errors and all, it's not an easy journey. I'm programming in C++(not professionally) for 4-5 years now, and while what I do know in C++ increased significantly, so is the knowledge of what I still don't know increased as well =)
OS X doesn't support sane hot keys for text cursors in general, it's not the program's fault. By far the most aggravating thing about working on a Mac...
That was his point. WOOSH
Qt Creator has the best C++ intellisense of any IDE today. by far. hands down. Nothing else is even close. 
From personal experience, reinventing RTTI with templates is cleaner and generally faster than the solution that macros would lead you to. But that's just my experience.
Well then sir/ma'am you are in the wrong subreddit. Try here: [http://www.reddit.com/r/c_language](http://www.reddit.com/r/c_language) and gl.
hmm....after looking at the subreddit it seems like there has been very little activity for 3 months o.O so yeah, you can post it there but Idk if there will be a response. Try here too: http://www.reddit.com/r/C_Programming/ This one has more recent post and activity.
And what are those useless tasks? I assume you mean like writing Makefiles, however I do not consider that useless having fully control over the build system is great. And know how to write a great make file is a great skill.
To be fair though, I think C++ have to be like that at times because it isn't really easy to describe some that is code in words. For example Template and inheritance aren't easy to differentiate using words.
MSVC used to be a disaster with regard to C++ standard conformance. That changed right around the time MS hired Herb Sutter.
I don't find mingw+gdb on windows too bad. But I have gotten QtCreator working with both Visual Studio and Intels C++ compiler without any problem
&gt; Why should the compiler let you implicitly cast an unsigned integer as a char pointer? Becase there is no difference between an unsigned integer and a pointer (char or otherwise.) Because when you are trying to setup 1000 hardware registers, it's easier and more intuitive to use pointer types. When you try to set the value its silly that there is no way to do this without an explict cast. &gt; Also, this is a compiler warning, not an error, on both clang and gcc. It's a warning when you compile in C, in C++ it's a full error. In anycase, it shouldn't be either.
I'm referring to VS 2008 and up. You can forget about VC 6 and 2003 and 2005 for obvious reasons (no compiler was remotely standard compliant). MS really dropped the ball on compliance with VS 2010 and from what Stephen Lavajev posted about VS 11, it's not going to get much better for at least another few years.
It seems you have never used Qt Creator. It's free and it's as good as VS with VAX (and way ahead of plain VS).
I've been looking for a you for awhile. Keeping fresh on the beginner stuff keeps me fresh as well. Shoot me a PM!
Just get a good book (there are literally thousands of them). You don't need someone to explain it, you have to do it yourself. Only through try &amp; error you can learn any programming language. A lecture/book will only get you some theoretical stuff, not more not less.
Pretty straightforward, small nitpick: Use atoi for converting a string to an integer.
I'm interested in seeing your course work. Give me a PM. 
AFAIK LLVM decision not to use RTTI is because of code bloat: with RTTI each class (with virtual method) generates RTTI information in the library/executable whether you actually use it or not; whereas their approach is pay-for-use.
Post some more info so we can answer it in-thread.
No I haven't. So Qt Creator isn't specifically for Nokia products? I can download it at home and create some random x86 application for instance?
http://www.instapaper.com/text?u=http://www.altdevblogaday.com/2012/05/07/cc-low-level-curriculum-part-8-looking-at-optimised-assembly/ This alternate link will work without requiring javascript. This comment generated by an [automated bot](/r/link_unscripter).
Sent, thank you!
I agree, and I've gone through C++ wikis. It's worked but it is painstakingly slow. I taught myself Photoshop and I understand teaching yourself is possible; but if I could go back in time there are a few things I wish I could have told myself that would speed up the process drastically. That is kind of what this is. If that makes sense?
Accessing a deleted pointer is undefined behavior - any output here can be considered correct. Whats happening is that, most likely, when you do delete x; new int(5); the allocator frees the int and immediately uses the same memory to fulfill the allocation. It is just by luck that you allocated in the same place again, and get the '5' output. If you want, you can intersperse some extra code (say, outputting 'hello, world!') between the delete x and new int calls. That will most likely change the result. 
This is because using a deleted pointer is undefined. Remember undefined means *anything* can happen. In the case of microsoft's c runtime implementation(or more specifically new), what that means is that when you call new for an address of 4 bytes, it will return the top entry on it's free list. In this case, that happens to be the address of the last deallocation of size 4. Remember, with pointers there is no automatic cleanup. So the address that is stored in global x (which was not overwrote with null as is best practice) now happened to be re-used when line A executed.
Why VC? Why cant i just view disassembly on demand, like i can during application debugging?
You talked about something called 'Visual' but don't actually say what this is. There is no context that I can divine what you are even asking about.
&gt; Using closed source libraries in the teaching curriculum is a pretty bad idea Why would you say that?
because you can't crack open the source of the libraries to learn from them.
I certainly wouldn't say that unconditionally makes it a "pretty bad idea." First of all, if you need to look at the source code to be able to understand a library then it is a bad library with a poorly designed API, regardless of whether it is open-source or not. No exceptions. Libraries should keep low level details away from you; if you need to learn those low level details in order to use it, there isn't a whole lot of point in using that library in the first place. If all you want is to learn *how* the library does whatever it does, than it doesn't matter if it's open-source or not. Just Google another open-source library which provides the same functionality and study *that* instead; this will serve the *exact* same purpose. Second, and this is only from my own experience with teaching, well over 90% of students will *never* crack open the source code for a library they are using in class. The ones who *do* have the curiosity and initiative to, will most certainly find another source of the same knowledge regardless. Simple roadblocks do not sway true curiosity or thirst for knowledge in my experience. In other words, using a worse library simply because it's open-source and one or two students may benefit slightly from not having to try as hard to get at the source code is *not* a good idea. The *best* library should always be used, regardless of the license it is released under (assuming nothing unreasonably restrictive of course). Finally, there's really just no point in many cases. If you're teaching a data structures class, there's no need to provide the source code for the XML parser a single assignment uses. That's not what you're teaching. You could argue that you should still give kids the opportunity to look at the source code, but, as I already stated, how hard is it to Google "open source XML parser" or "how parse XML"? (The answer is "none"; "none hard".) Libraries are just tools you use to teach your class. They don't have to be part of the class itself; just like we don't need to provide the source code for the calculator we use in our math classes even though many math students certainly *could* benefit from it.
The 565 to 888 conversion here is naive. A 16 bit 565 white (31,63,31) won't be (255,255,255) with just a left shift on it's own (because 31 * 2^3 = 248). Doing (R * 255) / 31 gives better results.
Why do you not just add a parameter to the constructor?
You meant cout &lt;&lt; *x &lt;&lt; endl; instead of cout &lt;&lt; x &lt;&lt; endl; ...right? I'd imagine that simply printing a pointer isn't UB.
Using "stdafx.h" ... why don't use clean C++ code and keep the crap put there by VS ?
Not quite... for example, there are architectures where pointers are 8 bytes, and an int is 4 bytes.
Pick a different major?
http://www.amazon.com/Algorithms-Structures-Prentice-Hall-Automatic-Computation/dp/0130224189
You do make very good points. Your first point I agree with: if I need to actually read the source of the library to just understand how to use it, it is poorly designed. Your second point I can understand. However even if 1% of your students have the curiosity to open up the hood of the library to see how things are actually done, it was worth it to use an open tool rather than a closed one. This is coming from an educator (well, a TA held in pretty high regard, but I would love to teach full time if I can swing it) also. Your third point is also good: in most cases it's the concept that you want to convey, not the unimportant details. And that's okay too! However if the library is, say, a data structures library, then I think openness is very important because once the students have been taught linked lists, and implemented their own, they can get a look at how one is written in a codebase that has lots of users. Hopefully this comment wasn't too incoherent - I'm really tired tonight :/
&gt; Just Google another open-source library which provides the same functionality and study that instead; this will serve the exact same purpose. Except that, if the students are not using *that* library, only studying how *someone* solved the problem, they are less able to understand what they are doing. The freedom to understand the processes at work are doubly, perhaps even more, important in a CS classroom. &gt; well over 90% of students will *never* crack open the source code Well over 90% of students will never open a U.S. law book, but that's not a good reason to replace them in the library with French ones. For those who care enough to truly learn the material, why not let them? In fact, why not *encourage* it? By the end of an introduction to C++ class, why not offer extra credit for fixing a bug in one of the libraries they used? That's *real world* experience that you just couldn't have without digital freedom. &gt; assuming nothing unreasonably restrictive To an academic, being completely unable to see the processes at work underneath your own reasoning *is* unreasonable. This is why a huge number of people have lined up behind Open Access journals, and Free Culture in general. It doesn't make sense to learn from something if it's a skyhook, because you can't learn from a floating hook...you should be able to see that it's a crane. Every piece of software is a tool. But teaching people the importance of each aspect of a tool is a huge part of teaching them how to use those tools. If you ignore the fact that your students can't learn from a tool, or even properly *control it* most of the time, you're letting them down. Math professors are letting their students down, too, if they require use of non-free calculator software, and simply gloss over the freedoms the students give up.
I love failing, failing means I learned something. "breaking" things in code will teach you more then anything else.
Really! Well I admit that I haven't been up on it, I just assumed that since Herb Sutter has been there for a few years, it'd have been straightened out. He made it one of their goals to compile Boost, after all. Huh. 
Simple rule: You cannot access deleted memory and expect to make any sense of it.
it is possible and is used in VM's. Look up "pointer tagging". You can store information in the least significant bits of a pointer as pointers are usually (always?) aligned, i.e. a. 64-bit ptr gives you 3x zeroed bits to store whatever you like. Here's some of the tagging techniques in V8: http://wingolog.org/archives/2011/05/18/value-representation-in-javascript-implementations
It's GPL so that severely limits its usefulness. I'll stick with Qwt for now, which is LGPL.
I'd rather flip a switch on the Standard to make it standard actually ;) But nice to know there is a compiler switch equivalent to `-pedantic`.
It's an extremely uncommon architecture which uses different sizes for pointers and ints. It's also a bad or extremely specificly designed one. Regardless of that lets get back to the main point. 0xFFFF0000 isn't an unsigned integer per se. Indeed it is an inline literal which is a perfectly valid value for *any* &gt;=32bit architecture. 
I worded that sentence wrong. I meant to say that certain features, such as move semantics, are for efficiency, but some features are not exactly for efficiency gains. EDIT: I edited the post to clear up that wording. Thanks for pointing it out.
Why do you think it's boring? Are most compiler related problems solved? There's nothing new to be done? I don't develop compilers. I want to know. Thanks.
I think it speaks to the FSF's propaganda ability that a lot of open-source projects pick the GPL by default. If I'm giving software away I actually want people to use it.
Do you really buy books based on page count? I suggest considering (a) what other books are available on this subject and (b) how much time this book can save you and (c) what value you can derive from it. 
works for me. Your standard library might be using a crappy random number generator that has some kind of even/odd cycle or limitation. I got well into the 20's before things started getting slow enough that I didn't go further.
Works for me. [pooerh@havira]:&lt;~/my&gt;$ echo 5 | ./flip YAY! After 139 flips. [pooerh@havira]:&lt;~/my&gt;$ echo 10 | ./flip YAY! After 3024 flips. [pooerh@havira]:&lt;~/my&gt;$ echo 15 | ./flip YAY! After 16821 flips. [pooerh@havira]:&lt;~/my&gt;$ echo 16 | ./flip YAY! After 70211 flips. [pooerh@havira]:&lt;~/my&gt;$ echo 20 | ./flip YAY! After 2267544 flips. [pooerh@havira]:&lt;~/my&gt;$ echo 25 | ./flip YAY! After 361644522 flips. [pooerh@havira]:&lt;~/my&gt;$ The last one took like 8 seconds but the other ones were instant. I don't want to try more than 25 because it would take... well, long. Edit: Compiler &amp; OS info: [pooerh@havira]:&lt;~/my&gt;$ g++ -v Using built-in specs. Target: amd64-undermydesk-freebsd Configured with: FreeBSD/amd64 system compiler Thread model: posix gcc version 4.2.1 20070831 patched [FreeBSD] [pooerh@havira]:&lt;~/my&gt;$ uname -v FreeBSD 9.0-RELEASE #3: Fri Jan 27 07:50:44 CET 2012
Also, more info about the deficiencies of common rand() implementations on [wikipedia](http://en.wikipedia.org/wiki/Linear_congruential_generator#Parameters_in_common_use)
thanks! it fixed the problem, but i hit the same problem at 27. very cool to learn more about the random number system.
freebsd. nice.
Works for me too, I tried all the way up to 35, which took around 69 seconds and a number of iterations of -740673629 using long int, so I guess it took a lot of them (I'd expect something like ~2^35 )
Yeah, there may be no way to get around the fact that [Linear Congruential](http://en.wikipedia.org/wiki/Linear_congruential_generator) generators aren't really all that random. If you want real randomness you may need to use a more rigorous algorithm like [Mersenne Twister](http://en.wikipedia.org/wiki/Mersenne_twister). Probably easier to just grab a crypto library though. Maybe something like [libtommath](http://libtom.org/?page=features&amp;newsitems=5&amp;whatfile=ltm)? It's small enough, kind of...
There is MT in [Boost](http://www.boost.org/doc/libs/1_49_0/boost/random/mersenne_twister.hpp) as well.
The Boost-style new random number generation mechanisms are one of those things that seem very elegant on paper, and yet I really don't much like using it. The problem is that while making the provider of random bits independent of the distribution seems like a great idea, it means that if you have a simulation that does things like while true x = uniform(0.0, 1.0) y = gaussian(0.0, 5.0) z = gaussian(10.0, 2.0) w = uniform_int(0, 6) ... end It becomes enormously cumbersome because you have to keep creating new generators for every minor change rather than just calling a different method on the generator object. There are advantages to it of course, but yeah, the first time I used the Boost versions for something a few years ago, it was a bit of a shock how much code I was writing just to declare variables.
No, by doing return std::move(str); You are actually stopping the compiler from performing copy elision, the holy grail of return type optimisation by obfuscating the code. http://en.wikipedia.org/wiki/Copy_elision The end of scope/return statement is a special case which the compiling looks out for to implicitly move, so if copy elision can not be performed `return str;` will return an rvalue without need to `std::move` it. 
An OS just like any other if it suits you. I use Windows 7, Linux (Gentoo) and FreeBSD, I try to love each of them the same as each has its uses for me.
You need three objects to spit out numbers: the underlying source of random bits, a distribution, and a combination of the two that actually generates numbers. You can share the first one, but you need a new distribution object if you need numbers from a different distribution, and then you still need an object that combines the new distribution with the existing generator. **Edit:** Correction -- it looks like you can get by with only declaring a new distribution. There are functions of the form distribution(engine) that return a sample directly without having to create a new generator object. I don't recall that being in the Boost version however long ago I was using this, but I could be mistaken there. In any case, it's definitely an improvement over my recollection.
Seriously? The point of GPLv3 is to say, "no, you don't get to release your code under the GPL &amp; then use your patent pool to extract rents from anyone that uses the code, that's not ok.". Companies that want to use their patent pool to do precisely that (hey, look, it's Apple!) naturally regard the GPLv3 as beyond the pale.
I personally hate RTTI in general I really don't like it. Switch on emums is much nicer in my book.
Very nice blog post :-)
Hey. You can also send me a PM, if you haven't gotten enough responses already. Feel free to just bounce questiosn off me. I'll do my est to answer or at least point you in the right direction.
I'm not sure what you mean? I use Windows 7 at work, but when I'm working on my Mac I love the keybinds for moving around and tend to miss them on other platforms. What is missing in your estimation?
Sublime Text 2 is great -- it has replaced Notepad++ for me, though not Visual Studio.
I keep VS open for debugging but I edit all my code files with Sublime now. Works wonderfully for me. I was a little thrown off by the lack of Intellisense but I find I am remembering more of the language that way.
1. put the key into a 64bit int? 2. use a hash_map? 
This is the linker saying that it can't find the function that would be declared like: std::string md5(std::string plaintext); There must be a declaration of this function somewhere, because the compiler didn't complain about it, the linker did. It appears you're using Visual Studio. Did you add the MD5.cpp file from that site to your project? How are you compiling MD5.cpp? 
You could use a trie where each level is indexed by one of the bytes in the MAC address. A naive implementation would use a lot of memory but you could make it space efficient with some tricks. 
What sort of benchmark are you running to verify this? Have you done any profiling to verify that the map is really the bottleneck?
right on brother. right on.
thanks for testing!
You should probably put the 1000-digit number in a file instead of hardcoding it into your program for the sake of it looking cleaner. You can still read it into a std::string with getline().
Howdy, would you mind /x/posting this to /r/fortran? Thanks!
So how do you express ownership over a shared pointer?
Well, that's exactly what the shared_ptr is for - you don't need to express ownership.
However - passing a lot of shared_ptr's around (by value) does come at a cost. [Here](http://stackoverflow.com/questions/2502394/the-cost-of-passing-by-shared-ptr) is a discussion on the subject. So I think you should not use them anywhere you find appropriate.
10/10 i'm converting a million lines now... 
Try the unordered map along with the 64 bit int that tjhei suggested.
&gt; In most (probably all) compiler for x86-64, you are correct sizeof(int) &gt; sizeof(void*). Sorry to be pedantic, but don't you mean: sizeof(int) &lt; sizeof(void*) ? &gt; I actually disagree with this choice and it goes against the guidelines laid out in K&amp;R but that is the way it is. Can you elaborate on why you think it was a bad choice? &gt; . . . not only is it aloud (no compiler error or warning adding/subtracting ints from pointers) but it is actually very common . . . True, but having the type system set up to keep you from converting an integer to a pointer without a cast can still save you from having data turn into addresses accidentally. Adding/subtracting integers from pointers is still address manipulation, and as you know, the rules are a little different than normal arithmetic (i.e. the resulting address depends on the size of the thing being pointed at). &gt; All I ever said was that one should be able to initialize a pointer with a literal value without casting. I suppose there's two ways that you could achieve this. 1) allow implicit conversion from integer types to pointer types (which I think is a bad idea, and I have been trying to defend this), and 2) allow integer literals to also be pointer literals. I had assumed you were advocating (1) when in fact it now seems more likely you are suggesting (2), hence my comments about the type system seeming like a red herring.
Here's [my test code](https://stacked-crooked.googlecode.com/svn/trunk/Playground/MACCompare/main.cpp). It compares performance of map and unordered_map.
if you need performance in this area (over size); you could statically allocate a structure before hand and read/write to it as needed. if you dont need it to be ordered then you could drop the sorting
Huh. That was my complaint about VS, but I guess to each his own.
Mostly force of habit, but also because Intellisense makes it easier.
[Here](http://www.cpprocks.com/2012/05/07/9-reasons-to-start-using-c11/)'s what the OP probably wanted you to see.
This is a wild card but I bet it might be fruitful, have you tried using a `std::vector&lt;std::tuple&lt;std::array&lt;unint8_t, Dispatcher*&gt; &gt; &gt;` linear iteration through a vector is incredibly quick, and if you are just comparing some values then it might actually be the fastest. The cache misses you will get when traversing dynamic trees might out weight the time taken in comparison. typedef std::pair&lt;std::array&lt;unint8_t, Dispatcher*&gt; &gt; my_pair; auto it=std::find(my_vec.begin(), my_vec.end(), [](const my_pair&amp; p) { return p.first==packet-key(); }); if (it != myMap.end()) { it-&gt;second-&gt;dispatch(packet); } Vectors are extremely fast and 500 elements really isn't that mean especially when performing arithmetic comparisons 
Selecting words is option-shift-left (option doing word movement like control on windows), end/start of line is .. Uhh.. The Mac key? Can't remember what it's called, but: Mac key and left, right. It's Mac key up and down for document start/end. It's true these are different than elsewhere, but what I like about them is I can navigate documents without moving my hand to PgUp/PgDn/Home/End keys. They're right there. I really miss that on windows. 
I agree that memory locality is a good thing. If I change the default comparison (memcmp) to this: // UB according to the standard :S inline bool operator==(const std::array&lt;uint8_t, 6&gt; &amp; lhs, const std::array&lt;uint8_t, 6&gt; &amp; rhs) { return reinterpret_cast&lt;const uint32_t&amp;&gt;(lhs[0]) == reinterpret_cast&lt;const uint32_t&amp;&gt;(rhs[0]) &amp;&amp; reinterpret_cast&lt;const uint16_t&amp;&gt;(lhs[4]) == reinterpret_cast&lt;const uint16_t&amp;&gt;(rhs[4]); } ... and use a vector for doing the lookup, then I get these times: Size Time for 1 million iterations. 1 2 ms 2 2 ms 4 3 ms 8 8 ms 16 16 ms 32 26 ms 64 44 ms 128 83 ms 256 139 ms 512 225 ms My goal is to enable 20 million lookups per second in a container of size 500. So in above table that means a time &lt;= 50 ms for container of size 512.
Oh it is also worth doing this, std::vector&lt;std::array&lt;uint8_t, 6&gt;&gt; keys; std::vector&lt;Disp*&gt; Disps; With symmetrical indexes. I think they should make it a little fast, but you are probably still better off with an unordered map
Where is 9th reason?! Even if we count from 0, there is no 0th reason... 
You mean Boost.Optional? http://www.boost.org/doc/libs/1_49_0/libs/optional/doc/html/index.html
Yes, this was my first thought. It also doesn't look like it addresses the alignment needs of the stored T. 
My head hurts.
This. boost::optional does this but properly takes care of alignment, and is smaller! (it's smart enough to store the bool indicating whether the memory is null in the alignment padding bits for the object)
With the exception of the 2 `get` functions, everywhere that `ptr_` is used it's accompanied by a null check anyway. This wouldn't be significantly more complicated. You could even avoid the typecast with a reference parameter or a union (and using a union would also solve the alignment issue as well).
Woah, this is so awesome, thanks for sharing !
That requires you to construct the object though. Which means you end up having a default constructor and then an 'init' function that's the 'real' constructor, and you open yourself to bugs where people construct the object but forget to call init ;p Edit: Actually how does your example work? What is my_func returning?
Very cool. Some minor feedback: As others have mentioned, alignment. You need `typename std::aligned_storage&lt;sizeof(T)&gt;, std::alignment_of&lt;T&gt;::value&gt;::type`. Second, the maybe_if dispatch is unnecessary in this case. Void returning functions _are_ allowed to return the void result of another void returning function. 
Well I never program with an init method in mind, I do however program so that there is a default constructor which should be as light weight as possible. It can then be 'init()'ed by assignment (usually from a generator function or the like). you write function like that like this: std::tuple&lt;bool, type&gt; my_func() { type t; //blah blah return std::make_tuple(true, t); } //else where bool success; type t; std::tie(success, t)=my_func(); However now I come to think about it, if the function is unable to generate a type because of bad state or input, I would far rather throw a `std::invalid_argument` exception. It is rare that `no return value` is a part of normal flow control. 
How is short s{2} a narrowing error? Wouldn't it be something like s{ 100000 }? Also why is F( T&amp; ) preferred over F( const T&amp;)? Its not like it wont work for non-const params
Thanks a lot for the response. I care more about learning programming, but was just thinking about this to myself. I assumed Unity would be so much more helpful if someone actually wanted to make a game. You made good points and I can see why, now, there are downfalls. I was on youtube also and typed in C++ OpenGL game and saw some of the games people made. Most were pretty "one person project" looking. However I typed in Unity 3d game and saw some amazing professional looking stuff. I'm sure that has to do with C++ and OpenGL being much harder to master too. But anyway thanks for helping me understand the downfalls of premade game engines.
short s{2} is a narrowing error because integral literals without the L, LL, u, or U suffixes are treated as ints, which are larger than shorts. It would be nice if we had a suffix for shorts, something like short s = 2s; // s == short. but alas :/
Also relevant: http://preney.ca/paul/archives/662
On a, not so unrelated, note. While looking through the N3337 draft I pushed some examples of new and interesting features to github over the last week. https://github.com/daniel-j-h/cpp11-snippets Learning best by simple examples myself, I hope that some of you will find this helpful, too.
You are right, "short s{2}" isn't a narrowing conversion as the source is a constant expression, 8.5.4/p7 says: "except where the source is a constant expression and the actual value after conversion will ﬁt into the target type and will produce the original value when converted back to the original type." (which is the case here)
With C++11 I would certainly welcome a safer version of boost::optional. You could implement a safe version of boost::optional using lambda expressions in the way that this article does it. One thing I don't like about boost::optional is that you can accidentally forget to perform the check and end up crashing your application. With an Option&lt;T&gt; type you could ensure that no operation is ever performed on the underlying type if it's not initialized.
Checking for nulls statically is not the right way to put it. What is meant is an Optional type that doesn't allow for accidental dereferencing. Basically anything you wish to do on the underlying value must be passed in as a lambda expression which only gets evaluated if the underlying value is initialized.
`maybe_if` is very similiar to the `apply_visitor` from `boost::variant`, which can't be done using `boost::optional`. Now if the `maybe_if` function was implemented as a functor, then you could compose functions like the Maybe monad in haskell.
As I said in an earlier post, I am not sure it is necessary, between `std::tie(bool, value)` and throwing exceptions there really isn't much need for optional return types, and when they are need diligent usage of boost optional is fine.
I noticed that they talk about 'final' not being a keyword, and I was puzzled by that.
Pretty much every RAII class I've written. Open file, mmap, etc. There's no "default file" to open or "default mmapped memory region". Any other methods you would call on them would be invalid in the default constructed state so you open yourself to bugs. For moving RAII objects pre-C++11 I've used auto_ptr or shared_ptr, in C++11 I would probably prefer unique_ptr. But most of the time your RAII objects don't need to move, and if you need to conditionally or late initialize them you can use boost::optional.
final and override aren't keywords but special identifiers that have special meaning in certain contexts. You're free to create variables with these names, but when used with classes and virtual functions their meaning is special :-)
So now they can say that they didn't steal a keyword from Java? :P
Are not exceptions meant to be for things that are exceptional?
Ants in hats
Accelerated C++ seems to be the popular one around here. Having said that, the order of the book isn't exactly standard, but it's more geared towards getting working programs quicker and explaining things fully afterwards.
lol! Probably because final and override are common enough terms that introducing them as reserved keywords would cause old code to not compile. decltype on the other hand... who would use that for a variable name? :p
 private: T* ptr_; struct Placeholder { byte _[sizeof(T)]; }; Placeholder memory_; Not good.... T may have a certain alignment while Placeholder now has an alignment of 1. This can produce problems if T happens to have 8-byte alignment and this object is compiled on a 32-bit OS where ptr_ will be 4 bytes; memory_ will now be placed 4 bytes offset from the beginning of the object. This needs to be addressed with C++11's **alignas** or by some other compiler tricks / non-standard extensions for compilers that do not yet support alignas. 
I heard that C++ primer (Not to be mistaken with C++ primer plus) is like Accelerated C++ but more detailed. I'll probably wind up going with that. Thanks for the reply!
It's rare that trading memory for speed actually works. In what way did RDESTL two years ago manage to use several times more memory while actually being *faster*? EDIT: You people who are downvoting an honest question are doing it wrong.
&gt; It's rare that trading memory for speed actually works It's not that rare. &gt; In what way did RDESTL two years ago manage to use several times more memory while actually being faster? I'm not familiar with the internals of RDESTL, but the usual way to write a fast hash table is to store a vector of element, tag pairs where tag is information indicating whether an element is absent, present, or deleted. Both tag info and unused positions in the vector consume memory (although in some cases tag information can be encoded into the value). The ratio of empty to non-empty elements in an open addressed table also presents a speed/memory tradeoff, with more memory allowing for less resizing work. The improvement in speed comes from memory contiguity: searching a collision resolution chain becomes iterating forward in memory (in some variations, taking a jump every N elements) instead of following pointers. Note that there are implementation considerations other than speed and memory use. Elements of a std::unordered_map enjoy nice properties like reliable addresses that open addressed hash tables can not provide.
&gt; It's rare that trading memory for speed actually works. I'd rephrase that to "dumb trading memory for speed rarely works on todays architectures. You have to manage locality."
I am trying to make a career shift back into C++ because the focus of a .NET programmer is rapid deployment, not technical design. Also all the interesting jobs are C++, whereas .NET is often hurr durr web develerpments and user interfarts Haven't really worked with Java enough to have an opinion. Also I agree with that quote because programming languages ARE just tools, designed to do something in a certain way. I hate when people get into arguments about one language being better than another. Apples and oranges.
this looks extremely complex for a programming language...
Thanks ! 
Wow. The standard's example loop makes Java look succinct. But, unlike Java, at least it can be *made* tight...
Seriously?!? That's hideous. Stop trying to write C and learn the C++ standard library. #include &lt;string&gt; #include &lt;fstream&gt; using namespace std; int main() { ifstream infile("myFile"); string strA, strB, strC; getline(infile, strA); getline(infile, strB); getline(infile, strC); }
&gt; I keep it all up here. *DrNewton points to his head*
 At least you got an Interview...because I don't have commercial experience of C++ I'm stuck as a fucking Perl developer. --- If you could change one thing about the C++ language, what would you change and why? What are some limitations of c++? 1. possibly remove initialisation lists so that when object's aren't expected to be "consistent" during construction. You then add the code there... so it's consistent on exit. 2. *possibly* look into if it's feasible for virtual functions to work in base class objects during construction... 3. the enum hack.. Could you explain to me how virtual functions work? and why you would use them? An object memory contains a struction called the function pointer table which has a pointer for every virtual function. In a subclass, the pointer for a base class function is updated to reflect the new value. then the caller calls which ever function is pointed to and the result is "type specific behaviour". What is the overhead of calling a virtual function? 1. You have to look up the function address in that pointer table before calling the function so there is a level of indirection. Are there any situations when this overhead is larger or smaller? 1. If you have a long inheritence tree it's possible the table has a record for every implementation of the function. When should you make a destructor virtual? 1. When you write a class you want to be subclassable. If you do not make the destructor virtual in the base class then if you call delete on the base class object the destructor will not run at higher levels because it will not be virtual. 2. Vice versa, if the type you are calling delete on is the subclass.. but the base classes destructor wasn't virtual, what you get is function name overloading/hiding. Therefore the base classes destructor doesn't get called. Could you explain to me the difference between static_cast and dynamic_cast? 1. fuck. I forgot How would you implement a class that opens two files if you could not use exceptions? 1. Use the RIAA pattern. (Resource Aquisition is Initialisation). I create an object with a constructor that opens a file and a destructor that closes the file. Then in my code I create two files on the stack. If the second file fails to open, when the first files object goes out of scope, it's destructor free's the file handle. How would you implement that class with two files using exceptions? 1. ughhh, maybe still use the pattern above ? Use a try catch foreach file so I knew which of the two failed so I could close them appropriately if need be. How would you handle one of the files failing to open in the case where you have exceptions? 1.. I think I already answered and I am confused about the answer. Could your constructor throw an exception after one of the files had been opened and the 2nd one failed? Which destructors would be called in this case? (assumes use of RAII for file handling (which is how I answered the previous questions)) How would you find the 10 most used words used in a large text file (which was a novel)? file -&gt; words -&gt; hashmap&lt;string word, int count&gt; -&gt;keep track of top 10 using a vector 1. agreed on solution.
Auto has been supported as a compiler extension for a few years (for GCC, at least since GCC 4.4). Even if you're using C++03, you could get the same functionality using BOOST_AUTO. If you insist on only using the base language, then it's still not too bad if you typedef the iterator type. Without a doubt, C++ is an ugly language. Citing code samples from the specification, however, is not a good way of making that argument.
Of course nothing is absolutely required and you can simulate functionality if you really really want it... I mean I can simulate dynamic typing in C++ if I want to, but the point is it's incredible cumbersome to do so, to the point where you often have to fight against the language to get it to work. But I'd be more than happy to be wrong in this case. Can you show me how to use the new range based for loop over two containers simultaneously? Here's a code snippet: vector&lt;int&gt; listA; vector&lt;int&gt; listB; .... vector&lt;int&gt; sumList; for(int i : Zip(listA, listB)) { sumList.push_back(std::get&lt;0&gt;(*i) + std::get&lt;1&gt;(*i)); } Hell I'm the first to admit I don't know C++ all that well so if there's an easy way to do it, I'd be happy to learn. The best thing I found was boost::zip_iterator, which is unbelievably bloated and doesn't work with the new range-based for loop. Honestly using the zip_iterator is much more complex than just using two iterators. In Python it really is as easy as: for i in zip(a, b): ...
Well you can do that if you write yourself a zip function. This is an example using std::vector and int, but you could "templatize" this: const std::vector&lt; std::pair&lt;int, int&gt;&gt; zip( std::vector&lt;int&gt; c1, std::vector&lt;int&gt; c2 ) { std::vector&lt;std::pair&lt;int,int&gt;&gt; collection; std::pair&lt;int,int&gt; item; size_t length = std::min( c1.size(), c2.size() ); for( size_t i = 0; i &lt; length; i++ ) { item = comma( c1.at(i), c2.at(i) ); collection.push_back(item); } return std::move( collection ); } And then: std::vector&lt;int&gt; one = { 1, 2, 3, 4 }; std::vector&lt;int&gt; two = { 2, 4, 6, 8, 10 }; for( auto it : zip( one, two ) ) { std::cout &lt;&lt; it.first &lt;&lt; "," &lt;&lt; it.second &lt;&lt; std::endl; } This obviously simply outputs stuff 
Well honestly if that works then that's awesome. I'll look into using it. Thanks.
Look into the boost range adaptors. There isn't one for zip, but someone did write one [here](http://lists.boost.org/boost-users/2011/01/65826.php) You could then write exactly that code, except you'd want `auto i` instead of `int i`. EDIT: And, yes, it's lazily evaluated.
VS 2008 supports auto too. Edit: thanks oracleoftroy
Price of idea is 0. :-) I have hundreds of ideas. The problem is choice. So I want try understand that the most important.
There are no comments yet. Come on, I'll give a few examples to get started (from todo-list). double *fduf = ....; memset(fbuf, 1.0, N * sizeof(double)); x = a / b; if (b == 0) {} //too late... Next mistake I personally made ​​by programming the PVS-Studio. Yes, you can laugh. :) I'm also not perfect. if (i == 0) { items.append(apostrophe); items.append(itemStr); items.append(apostrophe); } else items.append(", "); items.append(apostrophe); items.append(itemStr); items.append(apostrophe); ...... 
1. For example, mistake in "for" loop like this: for (size_t i = beginLine; i &lt;= beginLine; ++i) 2. Incorrect hex value as string: "\0x0A" instead "\x0A". 
Can you find functions with many arguments let getAllParams(int &amp;a, int &amp;b, ... , float &amp;z, ..., double &amp;z27)?
His channel 9 code examples has: #ifdef __GNUC__ and he many times "criticizes" MS decisions in his channel 9 videos. He is a great man and I think that his videos are the best advertisement MS ever had to their dev tools.
&gt; The other relevant complaint about C++'s syntax and conventions is that its begin/end iterator things aren't really amenable to chaining. With eager evaluation like in your example you can map/filter/reduce/whatever in one big expression, but I don't think you can do that so well lazily. Ranges (as in D) look like a better solution. You can use [Boost range adaptors](http://www.boost.org/doc/libs/1_49_0/libs/range/doc/html/range/reference/adaptors/introduction.html) for that. It would be nice to see this sort of thing in the standard.
So what you're asking here is for us to do the designers' / analysts' work and offering nothing in return? Your software costs 3500 EUR for a very small team. Things do not add up here.
 switch (decision) { case 1: beAwesome(); break; case 2: beVeryCool(); break; case 3: beSomewhatCool(); default: beTotallyNotCool(); } I know this may be intended, but forgetting that break after a case is something that gave me a huge headache in one of the projects.
Did you mean VS 2008, aka VS 9?
I envy the intern or junior dev who gets to shadow this guy.
How about making it a feature that is disabled by default, but can be enabled?
In the future you should C&amp;P so small differences like that don't creep in.
yes, there is some open source competition: http://clang-analyzer.llvm.org/
This is reasonable. Perhaps we do so.
There is a neat approximation trick I learned a while back to solve this problem without using division or floats. Instead of zero filling the least significant bits of the 8 bit colors, replace them with the most significant bits of the lower precision color, i.e. for red: R_8 = (R_5 &lt;&lt; 3) | (R_5 &gt;&gt; 2)
On my Linux core2 duo at 2.2MHz with gcc4.7 and original hash. It seems that std::map on linux is much better. Size Map Hash 1 17 ms (253/1000000). 21 ms (228/1000000). 2 34 ms (508/1000000). 27 ms (465/1000000). 4 47 ms (984/1000000). 38 ms (939/1000000). 8 61 ms (1949/1000000). 51 ms (1905/1000000). 16 82 ms (3895/1000000). 52 ms (3855/1000000). 32 114 ms (7888/1000000). 59 ms (7842/1000000). 64 135 ms (15521/1000000). 62 ms (15729/1000000). 128 158 ms (31126/1000000). 62 ms (31281/1000000). 256 176 ms (61295/1000000). 84 ms (61365/1000000). 512 193 ms (119212/1000000). 64 ms (119348/1000000). 1024 215 ms (222206/1000000). 67 ms (222400/1000000). 2048 236 ms (395769/1000000). 73 ms (396163/1000000). 4096 253 ms (636777/1000000). 77 ms (637355/1000000). 8192 263 ms (864365/1000000). 71 ms (864713/1000000). 16384 266 ms (981114/1000000). 65 ms (981468/1000000). 32768 267 ms (1000000/1000000). 62 ms (1000000/1000000). 65536 267 ms (1000000/1000000). 62 ms (1000000/1000000). 131072 267 ms (1000000/1000000). 62 ms (1000000/1000000). 262144 267 ms (1000000/1000000). 62 ms (1000000/1000000). 524288 267 ms (1000000/1000000). 62 ms (1000000/1000000). 
Your results aren't the same which means your program is obviously doing something different. The fact that the time taken doesn't grow beyond 16384 is suspect. Practically speaking you should be getting 0/1000000 for all results because the probability of two random 6-byte sequences colliding is practically zero.
Yes, something different. I don't know what I should be getting, but there are only 4096 possible MAC values. Because GenRandomByte() is not so random and returns only bytes in [0...3] range. It seems that we have seen different code at the link. After changing line: static std::uniform_int_distribution&lt;uint8_t&gt; dist(0, 3); to static std::uniform_int_distribution&lt;uint8_t&gt; dist(0, 255); I've got following results: Size Map Hash 1 24 ms (0/1000000). 21 ms (0/1000000). 2 37 ms (0/1000000). 28 ms (0/1000000). 4 51 ms (0/1000000). 38 ms (0/1000000). 8 66 ms (0/1000000). 53 ms (0/1000000). 16 84 ms (0/1000000). 51 ms (0/1000000). 32 109 ms (0/1000000). 56 ms (0/1000000). 64 124 ms (0/1000000). 62 ms (0/1000000). 128 136 ms (0/1000000). 61 ms (0/1000000). 256 153 ms (0/1000000). 64 ms (0/1000000). 512 170 ms (0/1000000). 62 ms (0/1000000). 1024 191 ms (0/1000000). 67 ms (0/1000000). 2048 216 ms (0/1000000). 71 ms (0/1000000). 4096 242 ms (0/1000000). 74 ms (0/1000000). 8192 265 ms (0/1000000). 76 ms (0/1000000). 16384 288 ms (0/1000000). 79 ms (0/1000000). 32768 325 ms (0/1000000). 82 ms (0/1000000). 65536 387 ms (0/1000000). 92 ms (0/1000000). 131072 542 ms (0/1000000). 167 ms (0/1000000). 262144 764 ms (0/1000000). 253 ms (0/1000000). 524288 980 ms (0/1000000). 285 ms (0/1000000). 
Have you used KDevelop ?
I suppose you cleared your browser's history?
I take that back, if I use the history search I can go back further, but just paging through it seems limited.
See [my post](http://attractivechaos.wordpress.com/2008/10/13/the-rdehash_map-hash-library/). Hash table especially benefits from large memory: a more sparse hash table leads to fewer collisions and then to better performance. In case of RDESTL, it caches hash values, which is particularly favorable to string keys, but the cache adds memory. Actually I am sure I can write a hash table that beats RDESTL on speed with a similar memory footprint. I just think a competent implementation MUST consider memory, but RDESTL does not. BTW, in my field, trading memory (within certain range of course) for speed almost always works.
Hey jjt, thanks for your interest. That's just a small collection of snippet codes I keep on google code mainly for my students. Btw, I was wondering to move them to a github repo :-)
That's not not not what it was used for in the article.
In line 23 you're only creating the shape, you're not telling SFML to actually draw anything. It should be something like this: App.Draw((sf::Shape::Rectangle(centerx-width, centery-width, centerx+width, centery+width, sf::Color(rand()%256, rand()%256, rand()%256), 1, sf::Color(255, 102, 51)))); But if you want to draw a really big amount of shapes, you should try to create only one shape, save that one and then modify it's properties (same with Color and Rectangle). If you need even more performance, use direct OpenGL functions as it's soo much faster!
I quickly knocked this together after seeing [this](http://dlang.org/lazy-evaluation.html) in r/programming. Comments, suggestions, pull requests welcome.
It allows you to delay computing the value until the point at which it's actually needed, if at all. In essence, instead of passing the value you're passing a callback that will generate the value, and a wrapper which calls the callback the first time the value is needed and caches the result. If it so happens that the function never needs the value -- for example if it returns early -- then the computation never happens. 
You'd do well to write a constrained converting constructor. `std::function` has a catch-all converting constructor and perhaps you're already familiar with the pain that this kind of thing entails. The unfortunate bit being that there is no Standard trait to constrain on what we care about: that the passed functor returns a `T` (or something convertible to `T`) when called with no arguments (`std::result_of` can't be used as it doesn't guarantee soft errors, so no SFINAE). What is *doubly* unfortunate is that the Standard itself gives the name for such a concept: `Callable`. So assuming you do write e.g. an `is_callable` trait the converting constructor could look like: template&lt; typename U , typename std::enable_if&lt; is_callable&lt;U, T()&gt;::value , int &gt;::type = 0 &gt; lazy(U&amp;&amp; u): func(std::forward&lt;U&gt;(u)), evaluated(false) {} As an example of the nicety that this buys you is that you could overload a function `f` on both a type `T` and `lazy&lt;T&gt;`, and naturally call the lazy version with `f([&amp;foo] { return foo })`.
I saw a blog post here, but I forget where. Basically, if you have a constructor that takes something and stores a copy of it, you now should take it by value (rather than by const reference), and use move. Here's an example: class MyClass { public: explicit MyClass(string name) : name_(move(name)) {} private: string name_; }; Here's why: MyClass c1("temporary string"); string name = "non-temporary string"; MyClass c2(name); This is optimal because when c1 is constructed, the temporary string is constructed, then since it's a temporary, when the "name" argument to the MyClass constructor is created, it calls the string move constructor, and then again calls the string move constructor to initialize the name_ member. This is better than C++03 would have done when taking it by const reference, since that would have entailed two allocations/string copies. The second example, where the string is not a temporary, is as efficient as taking it by const reference in C++03. Here, the copy happens when the MyClass constructor is called, rather than inside the constructor, but it's the same amount of copying. The pattern is, if a function takes something and copies it, take it by value and move it in so an expensive copy can be avoided for temporaries.
First, some rules of thumb on writing overload sets: - Observer functions (which don't copy/move the value) should take `T const&amp;` if a `const`-view is enough -- this will accept both lvalues an rvalues. `T&amp;` is acceptable when a non-`const` view is needed, and I suppose in some (hopefully rare) cases you'd overload that with `T&amp;&amp;` (which implementation can delegate to the `T&amp;` overload) when you do care about rvalues - Functions that would copy their argument or move from it in their body should instead take `T`, then move from it. For instance a typical constructor could look like `explicit foo(T value): member(std::move(value)) {}`. You have to resist the temptation of writing a `T const&amp;`/`T&amp;&amp;` overload where the bodies would respectively copy or move from the argument. You violate DRY to an extent and you may not gain anything from it (so premature optimization to boot). Don't just take my word for it, this is the advice that [Dave Abrahams](http://cpp-next.com/archive/2009/08/want-speed-pass-by-value/) gives, and he also has measurements IIRC (although that's later in the series I think). So as you can see something like `std::vector&lt;T&gt;::push_back` doesn't exactly follow those guidelines and is somewhat of a bad example. But you have to keep in mind that the `T const&amp;` overload came first, and the `T&amp;&amp;` one was bolted on later. So I guess there's somewhat of a grandfather clause. In the case of `operator+`, which has two parameters to consider, I suppose T operator+(T lhs, T const&amp; rhs) { return lhs += rhs; } is the new 'canonical' `operator+` implementation with an added twist to follow the above guideline. If you don't want to miss further optimization possibilities however (i.e. rvalues on the right-hand side) then it gets iffy. The brute-force approach is to write the four overloads (two parameters, either pass by `T const&amp;` or `T&amp;&amp;`) and forget about DRY altogether. If you do choose to do that, remember that you can use CRTP (if you need to do it for several types) -- and hopefully Boost.Operators will one day be move-aware. Don't do it unless you're sure you're going to need it, this is boilerplate, not added functionality. As a final note, I recommend against writing *any* special member other than the constructors that are not the copy/move constructors. It's much more convenient to pick the right type for the members (`std::unique_ptr&lt;T, D&gt;`, `std::vector&lt;T&gt;`, sometimes even `std::shared_ptr&lt;T&gt;`) and have the special members implicitly generated. Some of the times I've been writing special members like the copy/move constructors and assignment operators for several types, I found in some instances that there was something I could refactor: e.g. I needed a member to be of type `clone_ptr&lt;T&gt;` instead of doing the cloning 'by-hand' in several places, which is a kind of smart pointer that the Standard Library doesn't provide. (Of course to write a `clone_ptr&lt;T&gt;` you would need to in fact write copy/move special members -- but that's why it's refactoring, you put it all in the one place.) Finally if you're writing function templates remember that in the case of template&lt;typename T&gt; void foo(T&amp;&amp; t); `T&amp;&amp; t` might as well be yet another kind of reference. The above guidelines don't apply to that (i.e. perfect forwarding means you never need to overload to accept both lvalues and rvalues). I might need to write something separate just to handle those!
Perhaps you're referring to this post: http://cpptruths.blogspot.com/2012/03/rvalue-references-in-constructor-when.html Also, when using rvalue references on strings, don't forget about [small string optimization](http://john-ahlgren.blogspot.com/2012/03/small-string-optimization-and-move.html) that can make move performance worse ~~than copy operations~~ for small strings than large strings.
&gt; that can make move performance worse than copy operations. This is misleading. The conclusions in the link you posted are that moving a small string is worse than moving a large string (for an SSO-enabled string type). There is no comparison (or measurement) made between moving a string (small or large) and copying a string.
Same error but with window not being declared in this scope :/
Well yeah, your class members aren't class members but simple class-less funtions since you forgot to put SquareDrawer:: before each function.
You're absolutely right, thanks.
Thanks for publishing them, I find the code very easy to read and learn from. If you move them to github, you should submit the link to /r/cpp. I'm sure others would find them useful and educational.
I'm not sure what you mean here -- a catch-all converting constructor on `std::function`? Something along the lines of `std::function&lt;Foo()&gt;` converting to `std::function&lt;Bar()&gt;`? I was assuming that the `std::function&lt;T()&gt;` constructor would be a sufficient constraint on the type of `func`.
The catch-all constructor of `std::function` is of the style `template&lt;typename F&gt; function(F f);`, with no constraints at all. This is problematic if you have e.g. a function `f` overloaded on `std::string` and `std::function&lt;Sig&gt;` (doesn't matter which signature), because then `f("Hi")` is ambiguous: there is one conversion from `const char(&amp;)[3]` to `std::string` and one to `std::function&lt;Sig&gt;`, and none is preferred over the other. Which is silly because a string literal is not usable as a function, no matter the signature. (Some implementations are however taking care to hide that matter from the user.) You don't have that problem since you only have a conversion from `std::function&lt;T()&gt;` (and even though `int` is convertible to `std::function&lt;T()&gt;`, it's however not convertible to `lazy&lt;T&gt;`). My advice applies if you do want a more general converting constructor, to enable e.g. `lazy&lt;int&gt; l = [] { return 42; };`.
Thanks you so much for your help, nothing seems to be wrong with the code anymore but I received an error which I believe is something wrong with the libraries themselves. Thanks again for your troubles
That's interesting. Thanks for the info.
@Tom: Thanks for the interesting comments, you're definitely right there does need to be a lot more unit tests. However there are some minor ones found in the following: * https://github.com/ArashPartow/strtk/blob/master/strtk_tokenizer_test.cpp * https://github.com/ArashPartow/strtk/blob/master/strtk_tokenizer_cmp.cpp * https://github.com/ArashPartow/strtk/blob/master/strtk_serializer_example.cpp But as you said, they don't cover everthing, that said I do plan on writing a larger set of extensive tests in preparation for a c++11 rewrite. 
Great work, but why use your library instead of the [Boost String Algorithms Library](http://www.boost.org/doc/libs/1_49_0/doc/html/string_algo.html)? Does it perform better under certain conditions, or is it just an alternative?
@Stormblaast: The BSAL has a wide variety of algorithms, some of the common pieces of functionality found in both libraries have comparisons in the article provided above. In short performance is the main differentiator, but also simplifications for doing certain things like simple linear parsers et al can also be of interest.
Taken from *Desktop application development* section &gt; Visual Studio 11 Express for Windows 8 provides tools for Metro style app development. To create desktop apps, you need to use Visual Studio 11 Professional, ...
Upcoming XP support is great, but I'm not too keen on the other news. They are making some pretty disappointing decisions in devdiv lately. I can understand that they want to monetize their platform more, but this is not the right approach. The target audience of the Express editions will not buy the Pro or Ultimate editions if they want desktop apps. They will either use something else or pirate it. The dev tools for a platform should not be viewed as substantial source of income, because the developers take up only a marginal percent of the users of the platform. No matter how high you raise the price, and how many editions you make, it will not keep the company afloat. A much better (and tried) approach would be a Windows marketplace for desktop and (from 8+) tablet and phones unified. With easy and fluent deployment right from Visual Studio and tight integration with the OS. It is the applications that keep a platform alive, and that is what could be monetized effectively for Microsoft (by taking a cut for distribution).
Then in your situation perhaps you should use the following version 'bool type_to_string(const T&amp; t, std::string&amp; s)' 
I see, so that that is your issue.
Did "make install" also install the header files, i.e. do you have a file like "phash.h" in /usr/include or /usr/local/include?
I did understand your point and would like to clarify: that is the intended behaviour. 
&gt;that is the intended behaviour. Whoa. Care to give a rationale for that? The last thing i would expect from any library is to shut down entire process without a trace of message anywhere on failure of pretty simple functionality.
I see no reason for rambling around when you can present your point in two sentences.
Here you go, different elements of the stack frames are aligned to a certain chunk size this is compiler dependant and I believe it gets larger on most compilers on x86-64 systems. On my compiler to get an int to be contiguous with a array the array had to be 7 elements. If the code did not have this overflow error then you would expect the results of `over_run` to be 99. but instead it is 7. #include &lt;iostream&gt; int over_run() { const std::size_t size=7; int a[size]; int j=99; //Classic fence post error causing overflow for(std::size_t i=0; i&lt;=size; ++i) { a[i]=i; } return j; } int main() { std::cout &lt;&lt; over_run() &lt;&lt; std::endl; } I tried this on x86-64 Arch Linux with gcc 4.7 but it will probably work on many other system too, try altering the size off the array if it doesn't work.
&gt; some implicit casts are applied only if the operator definition is outside the class. In first case, compiler looks through all known pairs of a and b. Seeing that b has no operator defined for a, but it knows that a can be constructed from b, effectively doing this: C(b) ^ a; But since many classes can be constructed in same way, it doesn't know which one to make. It could be a string, a vector or anything else. In second case, it finds something matching the triplet (^, C, C) and it also knows that C is made from int, so it does the same as before. Takeaway here is the importance of explicit constructors. From design perspective, operators should definitely be free functions, to be open for extension. Class members cannot be modified without either extending (creating a new type) or modifying original source. Operators as free functions however can be tacked on as needed, they can even be defined in separate file. So if I get a third-party class, I can trivially integrate it into operator-based code (streams at least).
Except it *is* trivial when you understand what a method is and what a function is. As a class method, `unsigned int` has no way of knowing how to `bitwise xor` itself with a `C` because *it* doesn't know what a `C` is or how to convert to it. A `C` however has a constructor for an `unsigned int` so it can happily convert as needed. It's `C`'s `caret operator` that's being used (when it works), and `unsigned int`'s `caret operator` doesn't know what to do with a `C` (where it doesn't work). As a separately defined `caret operator function` knows that it can and needs to convert both operands, and now it isn't a method of a class, it's a function which takes two arguments, either of which can be converted into `C`s. Trivial.
This is not an explanation, just a bunch of observations. antheus_gdnet provided an [explanation](http://www.reddit.com/r/cpp/comments/tvusw/c_operator_definitions_inside_and_outside_the/c4q72nm). As a sidenote, I'm blown away by the fact that two people can debate what my opinion is. Reddit FTW.
Call me old-fashioned, but in my day, C/C++ didn't have methods - it had functions.
The definitions on the "article" are indeed not equivalent because the in-class operator is not a 'const' method and the outside definition receives a const reference. The correct equivalent definition would be something like that: class C { public: C(unsigned a) {} friend C operator^(const C&amp;, const C&amp;) const { return *this; } private: C(); }; No one ever said that they should be equivalent, the standard says that "a @ b" is equivalent to either (a).operator@(b) or operator@(a,b). If you think about it, the problem with the article becomes obvious. (1).operator^(b); // does not make sense. operator^(1, b); // it makes sense.
 * Code is undocumented. * Code is untested. * Code replicates functionality of a bunch of different libraries. 2/10 WNB
Is SSE support just coming to MSVC? o.O
Good thing I switched totally to Linux one year ago... 
so we're back to pre-express editons where developers had to pay to develop for windows aka pay MS to do them a favor instead of the other way around?
The express edition contained a 32bit compiler for the previous release, but I don't know whether they will include a 64bit version in the express version or whether people will have to buy the full version for that.
Well, you can just install them separately…
yes they do, but apparently the compiler will be removed from the windows 8 sdk AND the new express versions will only target metro applications.
Surely not, because there's been an SSE/SSE2 flag for ages. This presumably includes the newer AVX too. I don't know what they do in VS10, though.
How? VS Express no longer comes with a C++ compiler other than for Metro apps.
Can you provide a reference backing this claim? I believe that would garner more upvotes.
you're right i should have posted source, it was on [/r/programming](/r/programming) let me see if i can find it.. here it is: http://www.reddit.com/r/programming/comments/ty7qa/visual_studio_11_express_free_editions_will_only/
If that's true, they've made it really difficult to find the "native" c++ compiler SDK.
Okay, thanks for the link. My BS detector was going off. Well, looks like I will be sticking with VS2010, or doing a side-by-side installation if I ever decide to try my hand at Metro apps. I don't really understand what Microsoft's thinking is for crippling the Express editions- probably millions of people have learned how to program with their quasi-professional IDE, now that will be impossible. At least they are keeping the 2010 downloads around...
I hear you like intolerance in your intolerance. 
Yes true, but the Microsoft C++ compiler is the only one that can build the Windows SDK. MS filled the SDK with a boat-load of undocumented extensions.
Cool. I was actually going to do a Clang build this morning, but I saw that 3.1 wasn't out yet and decided to wait. My patience was rewarded swiftly.
Really, most my issue is really just with his use of the word "retard". I do agree that they have to consider how they selling it. At the same time, do engineers cling to their tools so much that they can't consider other options. There was no interest or curiosity about the possible motivations. It was just "I'm going to assume it's bad because I don't immediately see the good". 
Ya, I guess I get burned for coming up with "clever" one-liners rather than explaining myself.
Initializer lists are in as well. Nice.
I tried building clang on windows about a month ago but I couldn't figure out where the standard c++ headers were, does anyone know?
Finally we get lambda in Clang...hooray!
I've had it for a few days from svn, compiles successfully on both windows and linux. As for the new headers and stl implementation, if you're on mac you can try libc++, if not libstdc++4.7 is your best bet [mingw+gcc-4.7 for windows](http://nuwen.net/mingw.html) Also, clang fails to compile files that include and use stuff from &lt;chrono&gt;.
Great news! I was wondering why waiting so long for lambdas? It was my impression lambdas were relatively easy to implement.
The question "How many other programming languages are you familiar with?" is misleading. The answers seem to indicate it's asking how many languages you know total, including C++ (i.e., there's no "1" option).
Well, initially the 32 came from the maximum number of characters given 4 sets of XY coords, because after the program is completed in the future, the user will be entering 8 numbers at 4 digits each (32 digits). It was also requested by the 'project manager' to use char, but int should be ok if needed. 
Thank you for spotting that - I removed "other" from the question text. The first answer should have been "0" followed by "1", but now quite a few people have answered already, and I don't want to change the form at this point. 
Off-by-one error in which there is no option for those who know exactly ten languages. I've been very careful to avoid learning anything new without forgetting old languages, you see.
Does C# really count as a different language? What about javascript? I just put down 2. (C++ and java)
So I guess that points to a little of the confusion. If you were reading in just the ascii strings and storing them then you'd need the 4x8 characters and you should use an array of 32 chars. But frankly that seems silly and I think you're doing the correct thing that if you eventually really want the numeric value for the screen coordinates you should process them one by one (with atoi) and store 4x2 ints. So what you want is 16 ints (arranged however you like). If you are really tight for memory for some strange reason you could store the numbers as 16-bit shorts which should have enough room for a screen coordinate number (less than 2^16).
How long are you going to run the survey until we see the results ?
C# is vastly different from C++, and quite different from Java. So yes. :)
Right - I think that was supposed to be 10 or more, but I see now that I managed to screw that up :)
I'm going to release the results here on /r/cpp on the 31st of May (next Thursday).
Hey EVERYBODY SHIT YOUR PANTS!!!!!! THE BETA...doesn't have something? Oh. No.
If you thought that they were the same you might want to reconsider how well you know them. The only similarity is the name.
Oh, I'm happy with it, but I'm curious about what others are doing, for similar applications.
They are not the "same", but the inspiration and structure from C++, which C# and Java blossomed out of, make them imo syntactic siblings. Now when it comes to their bowels, the libraries, garbage collector, polymorphic nuances, and developing enterprise solutions, there is a vast distinction. I think that poll question was really too shallow. Maybe a series of check boxes should've been used instead inquiring about which API's you've used and feel familiar with. The hardest thing I've ever done in Java was making a MineCraft plugins, while in C# I've made a web portal utilizing ASP.Net. It allows users to login securely, upload Excel files that use a predefined format, which are then programmatically parsed and uploaded to an Oracle database. I'm learning how to use WCF and have spent the majority of the past 26+ hours I've been awake disassembling a .Net DLL without the source code (... so tired...). That being said, depending on the resources available, I feel like I'm 20 - 30 hours of study time away from being able to do something similar with Java.
thanks
I do a lot of work with Cplex for linear programming. The rest I usually put together myself or use boost. I've had good luck using their uBLAS library in the past for some heavy linear algebra.
We have our own fairly straightforward matrix libraries with a hand tuned svd (extra precision work). It just so happens to be cross platform, cross hardware and cross compiler. For general operations its not as break neck fast as some of the other but certain types of matrix operations can be tuned (multiply chains). getting lapack to compile on windows has historically been an utter nightmare.
_Talk to me!_ Where can I find out more, especially about the numerical features? What's the equivalent or Armadiilo? How about NLopt? OpenMP? Thanks for mentioning this!
I am glad to see none of the examples had a global level using namespace std.
 http://dlang.org/d-floating-point.html http://dlang.org/phobos/std_numeric.html 
The C++ library still does not work 100% on Windows. 
Setup move constructors (c++11). Using std::string is much nicer than doing char*.
would you hit your minions for doing things like this? std::string str1 = "my string"; editString(str1&amp;); void editString(std::string* str); // if that's even possible? or do you still recommend the c++0x move constructor?
std::string is probably faster in most cases because operations on std::strings don't have to deal with the null terminator.
std::string str1 = "my string"; editString(str1&amp;); void editString(std::string* str); like this?
&gt; faster to use references instead of pointers: Why?
They can allow the compiler to perform additional optimizations because a reference, unlike a pointer, only ever points to a single variable.
Really, you want to systematically use `std::string`: Whatever performance difference there might be, is completely offset by the reliability and ease of use. Remember, clear code is easier to modify -- and thus, to optimize. Now, if there is a measurable performance difference (which is dubious), it'll probably only matter in a tiny part of your code. Use your profiler to find it, and then try your best to optimize that small piece of code.
C++0x applies the move constructor to all objects that have a move constructor, which all stl classes do. It doesn't exist in older revisions of c++. However, the way I understand move constructors it only works if the rvalue is a temporary. I.e. std::string getString(void); std::string mystr=getString(); will use a move constructor (or actually a move assignment operator in this case) where the internal memory of mystr is just made to point at the internal memory of the string that was assembled in getString(). In theymos' example above however, you'd still be best off using a reference argument. I may be wrong about this though. If you are able to use C++11 in your projects, you probably best read more about move constructors elsewhere.
I'm surprised nobody has pointed out a major advantage: std::string has a destructor, making it easier to manage the allocated characters. Also, most implementations use reference counting, which has pros and cons. 
A reference is similar to a const pointer, except that it can't[1] point to NULL. So use a reference if you want to communicate that NULL is not valid. The compiler might use that knowledge. So "usually better and sometimes faster". [1] It is pretty easy to contruct code with NULL references in most compilers, but not without getting into "undefined" or "implementation defined" semantics of the standard.
First determine whether or not using string operations everywhere is really necessary for your application. Optimize the algorithm then the code. I strongly recommend std::string over char *: it is safer and won't likely crash your program, has a ton of existing methods to operate on them, and most implementations use copy on write semantics to minimize copying. This means your copy constructors and assignment constructors don't needlessly copy data, but only construct a small pointer to the existing string data. As others have mentioned, if you need improve performance you can drop down to references to strings instead of strings themselves. My issue is that this may leave dangling references if you're not careful, which will invariably lead to crashes.
I'd point out that these two are not the only choices for handling strings. There are other string libraries too, each having their own advantages. [Here](http://bstring.sourceforge.net/features.html) is one comparison table, which might be bit biased, but is still informative about the tradeoffs involving in choosing your string library.
sometimes someone has already passed stuff to the function before you (that is, you are reading code instead of writing it)
&gt; Moreover, a lot of C++ programmers, including myself, use references only for const parameter passing, and use pointer for non-const I strongly disagree that this is a good idea. Use pointers when NULL is permittable. Use references when it's not. That's a good convention, because it allows you to enforce another convention: Don't dereference a pointer unless you've checked that it isn't NULL.
&gt; If you know what you're doing, then char * is faster simply because it is just an integer that you're carrying around. That completely depends on what you want to do and how you are going to do it, std::string for example completely blows char\* out of the water when it comes to getting the string length, as it's O(1) with std::string and O(N) with char\*. And a const&amp; is no more expensive then a char*. And when you want to dynamically generate a string something like std::ostringstream might be the better choice anyway. As a general rule: Always start with std::string. When you are worried about speed, don't guesss, *always* benchmark and compare the different implementation, intuition more often then not, is completely off when it comes to executio speed and there is no general one-size-fits-all recommendation that can be given.
Yes this is what is important. the string may have some structural complexity but that affords it much better book keeping for stuff like strlen etc...
Yes I love how the following has absolutely no manual memory management despite actually being quite tricky. std::string str1="hello ", str2="world!"; std::string cat=str1+str2;
std::string is just a wrapper class around char[], so it has null terminators as well.
The purpose of source code isn't to be clean, it's to be meaningful. Otherwise we could make everything more succinct by only using one-character identifiers.
Well put it this way, it's a convention used by a lot of software companies, including Microsoft, Google and Amazon. Microsoft even designed C# to be explicit about passing ref parameters. I doubt they all went to this trouble unless it was empirically demonstrated that pass-by-reference having the same syntax as pass-by-value but having entirely different semantics did not result in a loss of productivity. Furthermore, the entire use of naked pointers T* is heavily discouraged. A better alternative in C++ about how to properly deal with a sentinel value is to use a boost::optional&lt;T&gt;. It might seem like it makes no difference, but a boost::optional&lt;T&gt; makes it explicit that there is no need to worry about ownership and that the value may be uninitialized. A raw T* just conveys so little information that its use is likely to be error prone.
std::string does not carry a null terminator with it. For example, an std::string can be used to store a raw binary blob, which may have many '\0' characters.
Evidence of what, specifically? Can you be more specific regarding the overhead?
Eh?
&gt; It's usually better and faster to use references instead of pointers It's not faster to use references instead of pointers. They should compile to the exact same code. As far as "better", yes, it's sometimes nice that C++ allows references. But on the other hand, by using mutable references you lose clear visibility at the call site that a function or method mutates its arguments. [At least one company](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml) mandates that arguments to functions which mutate them must be pointers, not references, and in my experience it's *genius*: it makes a codebase of tens of millions of lines of code far easier to understand than it would be otherwise.
&gt; The compiler might use that knowledge. Explain how. It's not like the compiler is inserting null checks on behalf of the programmer.
&gt; I strongly disagree that this is a good idea. Tens of thousands of programmers working on hundreds of millions of lines of code at the best tech companies in the industry disagree with you. The fact is that it's *extremely* beneficial to be able to tell at the *call site* whether a function or method mutates its arguments. It points out obvious places where assumptions that are true at the beginning of function execution might be violated in the course of execution.
In practice, it works extremely well, making the code much clearer and easier to understand. Give it a try :)
Could you give an example of a time where i'd want this? If a computation was expensive, i'd probably just put it right where it's needed. Perhapse i want to call a function with one such expensive argument, which may or may not be used in it. That might be helpful, but i'd need the foreplanning to make that function accept a lazy value. Since this basically works by passing lambdas around, I think i'd find it simpler to just do that.
&gt;&gt; Logical fallacy: Appeal to authority. &gt; No, it's not. It's an appeal to experience. When the experience is dogmatically pushed without good explanation, then it is exactly Appeal to Authority. I'm not saying advice from authority is wrong. Of course, they have found good reasons from experience. But one's experience in certain context may not apply equally to all other contexts. And if that context is not explained, it is impossible to judge why the advice would still hold in different contexts.
In GCC implementation of stdlib, std::string is always null terminated. c_str() does the same as data(), just returns a pointer to data array. However that doesn't mean you can't store multiple null bytes in std::string. Null byte terminator is there, but it doesn't have special meaning to std::strings, as it used to have in C strings.
There is no need to insert NULL checks. Unless you abuse the language, static checking can tell if the parameter is null or not by tracing through the memory references.
I have given both empirical data, Google's coding guideline is made publicly available with the rationale, C# is a publicly available language that does provide the rationale for explicitly marking parameters as mutable/out, and there is a logical justification for not wanting to use the same syntax to represent two very different semantic meanings. Yet some how it is me who is using the appeal to authority because I dare to point out that as a convention, where popularity is actually relevant to the subject at hand, it is widely practiced by top engineering firms to not use the same syntax to represent two differing semantic meanings. Yes... when discussing conventions, it is okay and valid to point out the conventions used by companies known to work on large code-bases. My argument was not strictly to just do something because Google does it, but it seems simonask only cared to focus on that and then reply to it by going on a rant about his 10+ years of programming.
I am speaking strictly about C++, not a particular implementation that may make various trade-offs depending on version, compiler flags, platform etc etc... Simply put it is undefined behavior to dereference any data beyond the boundary delimited by the string's beginning, and its end, where the end is strictly the beginning of the string + the size of the string.
No but you get absolutely no advantage by using a pointer over a reference; it is also not more meaningful either. It looks uglier it isn't faster, non of the recommended C++ books I have ever read have suggesting passing by pointer for non const. If I saw this in production code I would be looking up functions source to figure out why it needs a pointer wasting time.
This is not entirely correct. Compiler is free to assume that pointer you dereference is non-null as well because its undefined behavior. This gets us to performance benefit of references - the check for null will not be there, at least not in the library function. Clients will check or will know that pointer is non-null before dereferencing it and passing to your function thus potential performance benefit. When you accept a pointer you always want to make sure somebody didnt pass 0. That said, it probably doesnt matter at all. Id be _very_ surprised to see one 'if' checking for null making a difference. 
Yes you are right, data() has been modified to carry a null-terminator at the end in C++11 just like c_str(). However it is still undefined behavior to use operator [] beyond the range, and the string::at which performs a range check will still throw a range_error when trying to access s[s.size()]. I tried it on GCC with C++11 enabled and while GCC permits s[s.size()], MSVC does not allow it, throwing an assertion error if this is done in debug mode.
The usage of passing a pointer instead of a non-const reference is to make the calling code more readable. And it does, very very much so. Non-const references should never be used. They completely obfuscate what is going on with the data and make debugging a total pain in the arse. Debugging time is massively reduced when you can guarantee that *every* variable passed to function will remain unchanged unless there's a &amp; prepended.
In the grand scheme of things there are many other things that will be slowing down your program than your choice of string or char*. However, I would imagine that std::string is highly optimized and if there is a difference it is negligible.
Well, what can I say. Been using them happily since forever, never had problems so far… Could this be C programmers who just aren't used to the possibility of references rather than pointers? I don't know. But I'll keep my non-nullable pointers for the foreseeable future, in the situations where they make sense. 
Neither appeal to authority or appeal to experience are fallacies in and of themselves. They could be fallacies or they could be legitimate arguments. There is nothing wrong about believing something is true because an expert on the matter says so, like when my doctor says I have cancer and I believe it because of they are an authority. Here's a better definition for you: http://www.iep.utm.edu/fallacy/#AppealtoAuthority In particular note: &gt;Most reasoning of this kind is not fallacious, and much of our knowledge properly comes from listening to authorities.
You need to learn the concept of connotation and diction. "General" and "always" are not a good match. EDIT: you remind me of people who would ridiculously say, "I think 90% of the time it's 100% that it is true."
Are you trolling or something? When using char*, you still have to manually allocate and deallocate heap memory. You say that char* is faster that std:string, my question is simple, when and for what kind of processing is this true? Like others pointed out, there are examples of the contrary, like getting the length of the string which is O(1) for string and O(n) for char*. 
Are you trolling or you just don't know how C++ works? With `char *` you don't need to allocate memory. You can use `char []` on the stack or even just on the static memory as is the case in lots of C library that requires speed. And as I've said before, you simply paid for the O(n) with string length at the string creation. You still paid for it, rather you need it or not! You win if you ever ask the string for the length more than once, but if you don't need the length, you've just paid something for nothing!
You miss that the accusation was that you were making a **logical** fallacy, that is, a formal fallacy. From your own link: &gt; Formal &gt; Formal fallacies are all the cases or kinds of reasoning that fail to be deductively valid. Formal fallacies are also called logical fallacies or invalidities. http://www.iep.utm.edu/fallacy/#Formal Inductive argumentation is generally fine, and you are correct that appeal to experience or authority may be valid when making inductive arguments, but they are always fallacious formal / deductive / logical arguments. I was just amused that you traded one deductive fallacy for another, instead of arguing that you weren't using deductive arguments at all. After all, how can one deductively prove this case one way or the other at all? The original accusation was a little silly in light of the nature of your argument, but your response amused me nonetheless. * edit - clarifying
For further reading on this, the site you linked has some pretty good articles to get you started. http://www.iep.utm.edu/ded-ind/ http://www.iep.utm.edu/val-snd/
I would go on to suspect that if everything was inlined, your code could probably look exactly the same in assembly as if you used char*. Maybe I should look at this to check :-).
I don't think so. AFAIK, `std::string` stores the length of the string as an integer, while you need to find the special character `'\0'` for C-style strings. Which also means that `'\0'` is an acceptable character in the middle of a `std::string`.
One of the good things about C++ is there's no guess work in stuff like this. It's not exactly implementation defined (ie. that's how your STL implementation does it), it's actually standardized. So yes, `std::string`, in addition to the string data, stores `(sizeof size_t)*2` bytes extra, in addition to whatever padding it's added (use of member function `reserve()` can dictate how much, if any padding). So the answer the OP's question, the difference is negligible and you should prefer `std::string` over `char*` in almost all cases. 
This is the practice that is recommended by Bjarne Stroustrup, but he is the only authority that I know of that advocates it. (Perhaps he is sensitive to the criticisms of C programmers. In C it is possible to tell by reading what values may be altered and following this practice yields that benefit.) I think most authorities advocate that pointers be used when 0 is a legal value and references be used otherwise. This is what I follow and advocate.
Your statements are a bit too general - in this case, context matters, and the choice of platform and project type is important. Anecdotally, I once had a problem with a game crashing on a Nintendo DS (in debug mode, but still), which turned out was caused by a stack overflow. The game had only 8KBs of stack defined (the default I believe, as the NDS has 4MBs of ram total), and we were eating most of it up with a semi-recursive function that used around 10-20 strings inside, each taking about 32-48 bytes of stack.
&gt; You may have used them "forever" (how long is that exactly?), and that's fine if you only ever deal with your own code and know your own functions, but try debugging someone else's code when you have no indication that a variable is going to magically change. *It just isn't that hard.* Yes, I've worked on very large teams writing complex C++ code, and yes, we used non-const references where applicable, and no, they just weren't a source of debugging frustrations. Good debuggers (MSVC, gdb, lldb) all allow you to step through your code and see how variables change, or you could simply set a memory watchpoint on a location and get notified when it changes. Again, I understand that it can be confusing if you have no idea what the API is doing, or if the API is designed in such a way that it is confusing (as people would sometimes feel it was necessary before move semantics were invented, for speed reasons), but if neither of those are the case, *it's just not that big of a problem*.
/r/learnprogramming or /r/cpp_questions is probably a better place for this. /r/cpp is more for discussions, articles and news. :)
wait for hacks? the 2010 compiler is kind of bad. I think they introduced more than a few bugs with their partial implementation of some c++11 features. 2008 was their last stable compier that didn't compile crashing applications from valid code. Thankfully I was able to single out several crashes using our unit test framework and implement some workarounds (I can only speculate they screwed up some "automatic" rvalue ref stuff).
I'm starting to think you know little about C++. Both `std::string` and `char *` are two ways to represent a string in C++ and both come with a set of API for string manipulation. Yet you're trying to split hair with semantics. Your false statement saying a `char *` requires heap allocation show you don't seem to know about memory on the stack. Do you have an exclusive background in java where all objects are allocated on heap exclusively? It might benefit you more to try to write this test C++ program than me.
boost::program_options http://www.boost.org/doc/libs/1_49_0/doc/html/program_options.html
I wouldn't return a pointer at all: IP4Address IP4Address::GetFirstAddressInRange() { .... IP4Address _addr (_addressString); _addr.netmask = this.netmask; return _addr; } If you absolutely need to return a pointer, then you have a specific reason why, and that reason should tell you whether to use a smart pointer.
&gt; https://github.com/thefossproject/LibIPvX/blob/master/ipv4address.cpp A .cpp is not very interesting to read. OTOH, I did check your .h. &gt; bool InSameSubnetAs(IP4Address *&amp; _addr); WTF? From its name, this function should inspect both `*this` and `addr`, and tell something about them. Then, why isn't this function `const`? Why the heck is the argument not `const`? WTF is with the argument being a non-const reference to a pointer? I just hope you were drunk, and you did mean "`bool InSameSubnetAs (IP4Address const&amp; _addr) const;`". &gt; ~IP4Address(void) This is C code. In C++, you'd write: ~IP4Address() 
lol no! I'm not drunk at all! Thank you though. I'm not employed as a cpp dev (but as a glorified sys admin) and I just do this jazz in my own time, and therefore don't have superiors (except you guys) to tell me when I do stupid things! again, thanks! | me: "hey it compiled! it must work!"
Returning a pointer, you mean? Typically, when you make Java-style code, and create a factory that returns a pointer to a base class: class Base { ... }; class D1: public Base { ... }; class D2: public Base { ... }; some_smart_pointer&lt;Base&gt; Factory() { if (...) return new D1; else return new D2; } Or, when you return an interator, which is more or less a pointer. It's the same idea, anyway. Anyway, I recommend that you grab a copy of Accelerated C++, by Koenig and Moo. It's a quick read, that should put you right on track. 
Remember, every local variable, every parameter, and every member function must be `const`, unless it has a good reason not to be.
Yep. Thanks!
Are you able to share any more of that function?
**SOLUTION** Uncomment this line: //cout &lt;&lt; "&lt;BR/&gt;";
If I add flush(cout); anywhere inside the function, everything works fine. I can even remove the unnecessary cout. But if I remove the flush AND the cout, then the problem persists (it stops outputting text).
I can change it to a space or flush(cout); (as suggested by another poster), it seems that doing ANYTHING with the output stream helps.
 setvbuf(stdout, NULL, _IONBF, 0); And there is also: cout &lt;&lt; flush;
Do you use code like this often? IP4Address* _addr(new IP4Address(_addressString)); I'd suggest just using assignment here, as the syntax can be confusing when someone starts looking around for constructor invocation and not simple assignment (i.e.): IP4Address* addr = new IP4Address(_addressString); 
Spaces instead of tabs? What century is this, medieval?
your output is being buffered. It can be buffered by the webserver, the cgi wrapper you're using (fast-cgi?), the browser or even cout. I would suggest outputting to a std::stingstream and then outputting all at once with a std::flush for good measure. You can also try this if you're doing long-polling and want a streaming effect: std::cout &lt;&lt; mystingstream.str(); std::string antibuffer(1024,' '); std::cout &lt;&lt; antibuffer &lt;&lt; std::flush; you will earn +1 hacker armor
Some people get into the habit of the former because it involves a pointless "default constructor followed by assignment operator" from happening, instead passing the necessary information directly to the constructor used to initially create the object. In this case, of course, it's just a pointer so that doesn't apply, but there are definitely reasons to use the former sometimes (even some objects for which you *have* to). Though a bit weird to my C-honed eyes as well, I can see why someone would consistently use that initialization syntax. That said, I am not sure how either one is more or less obviously a constructor invocation, since both have "new IP4Address("...
Just a side note: the HTTP protocol requires "\r\n" after each header and "\r\n\r\n" after the last header. Not "\n", not `endl`. Browsers tend to be lenient, but it's still wrong. 
I'm wading through the land of undefined behavior now. :(
You should nearly never use a pointer anyway. You might want to pass your parameter by const reference though. And, for the copy constructor, you have to.
As a general note, if your library function allocates memory, then you should provide its own memory freeing function as well. Your library (or dll/so) might be using a different heap to the caller, so they wouldn't be able to free the memory your library allocated.
Very nice blog post :-)
From the code that's been commented on in this thread, I don't think you know enough about C++ to write libraries. I don't mean that as an insult, but you're in over your head. If you want to get up to speed on contemporary C++ coding and idioms, books like Koenig's Accelerated C++ and Sutter's Exceptional C++ series may help. For your particular library, I'd look at what the [boost.asio](http://www.boost.org/doc/libs/1_49_0/doc/html/boost_asio/reference.html#id831987) library does in that respect.
Then you're learning C++ in the hardest, slowest, most failure-prone possible way, Senator McCain. It's a large language and many pieces of its syntax and semantics are not intended for regular use.
&gt; Yes, but isn't returning by reference faster than returning by value? [Not necessarily](http://en.wikipedia.org/wiki/Return_value_optimization). 
While Fabien4's advice is sound, he is kind of being a dick about it, which is why he is being downvoted — but mad propz to you for being the bigger man and seeing past that! Const-references and by-value semantics are indeed a much better way to design the API you're designing. :)
Upvotes for you, good sir! I looked at CUDA and it seemed far too low-level, given my willingness to invest time in the coding part of my work. Maybe this is different. I will investigate.
Thats not true, passing it as a reference is basically the same thing as passing as a pointer, if you want to you can just pass as a pointer, yes its more C than C++ but it achieves the same thing
&gt; passing it as a reference is basically the same thing as passing as a pointer Using a pointer is just a way of making stuff more complicated for no reason: - You have to dereference it all the time. - It can be NULL. - You have to add `&amp;` when calling the function. 
Just make sure that you either construct it directly in the return statement or declare the object at the beginning of the function and have only one return statement returning that object and any decent compiler will not need to actually call the copy constructor.
With C++, returning by value is generally preferred since it avoids dynamic allocation, which is much slower than static allocation. You can always make return-by-value use dynamic allocation by using copy construction (this copy constructor won't actually get called either) but you can't go the other way.
That's a great idea. I'll implement that for sure. Perhaps you can help me with this one too. I'm going to have a base class (BobAddress&lt;T&gt;) which the IP4Address class and the forthcoming IP6Address and IPSubnet&lt;T&gt; classes inherit from. Something all the child classes inherit from BobAddress is two std::bitset&lt;T&gt; members that represent the address bitset and that of its netmask; obviously the length of the bitset will defined by the child class as per either 32 (ipv4) or 128 (ipv6). To do this, I'm going to use argument-dependent name lookup so the child classes specify what the length of the bitset member in the the parent object. My concerns with doing it this way relates to the constraints imposed by templates, in that I don't want to have everything defined in header files alone, as you know templates keep you from implementing outside of header files. What would you recommend for accomplishing this? I don't have my heart set on this design, and am happy to change it based on your recommendation. 
Uh...look at the github page that was linked. Tab length of 8.
C++ is just so wrong. So many pitfalls it is hard to believe.
I know. I actually like C++ in a way, but from a language design point of view, it is just the damdest language. I hope that some day, there will be a language that can interface nicely with existing C/C++ libraries, is as fast, and sane. I have not checked out golang yet, but maybe this is it?
I believe in this area, i.e. in static overloading based on types, c++ is not designed correctly. In all these years I've been programming in c++, what I always wanted was to have a generic implementation and a specialization that respected the type conversions. But this is not possible in c++ without template tricks like the one shown in the example. The correct way to have done this is to go from the most specialized to the least specialized function, respecting possible type conversions. C++ has it the other way round, partially because templates are not considered generic types, but a sort of macros that allow code to be replaced in a sort-of organized way. 
2 people over 25 years? Do you elders care to introduce yourself?
Hm, I think this completely invalidates my rash explanation!
In C# switch statements, only empty case statements are allowed to fall through. Everything else must either break or goto another case. http://msdn.microsoft.com/en-us/library/06tc147t(v=vs.80).aspx I quite like this idea. Our internal coding standard requires comments whenever switch/case fallthrough through non-empty cases happens, to make these things easier to see. So C#'s behavior is a reasonable middle-ground, I think. 
Hey OP, did you solve the problem? It has to be memory corruption or uninitialised data used for a conditional jump. I'm interested because, like I said, I had exactly the same symptoms. 
I did answer with 36. Nowadays I mostly use C++ on hobby projects, as the IT consultancy area where I work is all about JVM and .NET based languages. Anyway C++ used to be my main work language up to 2005.
I'd be more interested in the tricks used to make it work, rather than just a lame usage example with no performance numbers to back it up...
Hold up. Andrei Alexandrescu is a redditor?! *fanboy squeal*
There is a link in the first paragraph of the article to the CUBLAS webpage, were you can find a comparison between CUBLAS and MKL (between matrix multiplication on GPU vs CPU). To make your life easier here is the link: http://developer.nvidia.com/cublas 
... and the point of the article is to show off Thrust, so there should be perf numbers showing what the difference between using it and cudaMemcpy, etc. are.
It makes no sense to compare the time required to allocate memory. First it is extremely difficult to get an accurate measure of this and second it requires to ensure that the OS does not use the GPU when you try to allocate memory on GPU ... You will need a separate GPU (I don't think two GPUs systems are so common) if you want to be able to do meaningful comparisons.
Then don't benchmark the allocations (not that I suggested one should). What's more interesting is how well it moves data between host memory and device memory.
My guess is Thrust uses cudaMemcpy under the hood or, when possible, the asynchronous version. Since Thrust is open source you can check the actual code if you are interested: https://github.com/thrust/thrust/tree/master/thrust BTW Thrust is endorsed by NVIDIA and included in the CUDA SDK. 
&gt; put your faith in move semantics in the standard library, and pass std::string by value There seems to be a lot of confusion regarding this lately. Doing what you suggested only makes sense if you know for sure that f() makes a copy of its argument. If it doesn't, and you pass an lvalue as an argument, you will incur a copy overhead compared to the const std::string&amp; version. I am busy writing a post that discusses this and related issues. 
I've done switches where one case does some manipulation to allow it to conform it to do something for the next case, or just sets a flag before falling through. It would make a lot of sense to use goto to hop from case to case, but some people consider any use of goto to be a hanging offense.
I got this link from the German website Heise, they said videos will be added later on. If you can read German, the link is here, http://www.heise.de/developer/artikel/developer_artikel_1586999.html
Lots of people do the same thing to vim though, just check out how many people in /r/vim have 15000 plugins installed and dynamic language-specific custom colorschemes. I mostly agree with your sentiment (although I'm fine with minor cosmetic customization) but this is by no means an emacs-specific problem, and you can use emacs uncustomized.
I had gotten used to the C-W, M-W, and C-Y. It's really not that bad.
I love you &lt;3
Apparently the comments were not "clean" and there was still one there that said "You are doing stupid things and are repeatedly trying to force your customers into something, twisting their hands. This is bad." I'm not entirely up and up with the C++ scene, why are people upset?
Because MS is really falling behind when it comes to C++. The new Visual Studio will no longer be free unless you develop Metro apps, and who the heck wants C++ for a Metro app. It's also the furthest behind in terms of C++11 support, it's very buggy and has plenty of compiler crashes or runtime crashes and it doesn't adhere to the standard. It will also not compile for Windows XP.
Great: indentation, autocompletion, highlighting, tags. Sucks: doesn't write the code for me.
And they are hiring people to staff their team, probably to make things better... I'm far from a Microsoft fanboy, but I see a lot of hate against them in here recently. I'm really glad they're pulling the plug on xp. The system is 10 years old, it's a pain in the ass to support. On some technical points it prevents you to use advanced features introduced with later iterations, etc. It sure is widely used, but it's only due to the fact that there are still apps coming out for it. XP needs to die. Fast. As for C++11 support and legacy system support, it's the same game at Apple. Sure you have to pay if you want to develop anything but metro apps, but guess what, Microsoft is a company, and they're entitled to do what you want with their ecosystem, they want to push their new products and tech and I understand that.
While I am pissed with Microsoft for the way they deal with C and C++ hobby community, I appreciate that they still invest in the language. Another thing, is that when we get mad at Microsoft for their compiler extensions, we seem to forget, myself included, that everyone else does it.
I think VS express edition *was* a very nice gesture for the C++ (not C!) hobbyist community.
Why not C? Do you mean do to the lack of C11 support? That affects everyone that still uses C, not only the hobbyist community.
&gt; lack of C11 support? AFAIK, Microsoft has never tried to implement C99, let alone C11.
Say, what?! How much effort does it take you to share a single 1 or 2K config file?
Would it be possible to overload `f` for string literals? Or would that require overloading `template&lt;unsigned N&gt; void f(const char (&amp;&amp;)[N])` for every N? (Not sure if my `&amp;&amp;` notation is right in that function signature here.) Or perhaps overloading on `void f(const char * &amp;&amp;); `? (Again, I'm not sure if that `&amp;&amp;` syntax is right here.) 
The compilers are still free... The Visual Studio Express IDE only supports Metro projects, but the complete fully-featured compiler toolchain still ships with Express like it always has. Nobody's forcing you to use the IDE when the command-line tools are right there.
I have used it every day for a year now, after 10 years of misery with Visual Studio. I greatly prefer Emacs: fast, stable, highly customizable, integrates well with other tools. It's also simple enough that you can get a good mental model of what it does and change it to your liking. Some things could be better though. Code browsing/intelisense does not work (CEDET is crap) and the gdb mode has a few quirks. But overall I find it a pleasure to work with. Customization is a must to get the most out of it though. 
if all your config for emacs is 2K and you don't have trouble manually syncing it between machines you are doing it wrong. The major selling point of emacs is that you continuously tweak it to fit your current needs. 
If the tool is getting in the way of your progress, replace it. I don't understand Emacs fanboys.
[yasnippit?](http://emacswiki.org/emacs/Yasnippet)
&gt;but it is a pain when trying to port C software to **Visual C++**. FTFY. Basically, if you want to compile some software, your best bet is to use the same compiler as the author. Usually, gcc.
Honestly, I would suggest getting a modern editor with simple features. The key bindings on emacs were designed for ancient Lisp machines that had different keyboards than modern ones (think Ctrl in the place of Capslock, for example). If you want a pleasant and familiar experience, use gedit or geany or Sublime Text 2 or notepad++ or Netbeans or Eclipse or anything except Emacs.
&gt; vs2010 is fundamentally broken, producing crashing runtime code (i suspect bugs with their rvalue ref stuff). I am extremely interested in such bugs (as I work on the STL, which is inevitably the first victim), but I am not aware of any in VC10. If you can construct a self-contained test case, I would greatly appreciate it if you could send it to me at stl@microsoft.com . VC10's rvalue references v2.0 differ in a few ways from C++11's rvalue references v3.0, but not in ways that should be capable of runtime crashes.
All of the talks where the authors gave permission were videoed. They'll be on the [C++Now! web site](http://cppnow.org/) eventually, although I have no idea when that will happen. **EDIT**: They're starting to upload them to [YouTube](http://www.youtube.com/user/BoostCon).
&gt; * You have to dereference it all the time. To be fair, you are dereferencing a reference as well, the syntax just looks like you're not doing so (even though you are). &gt; * It can be NULL. As can a reference. Although, it is more difficult to send a null reference. &gt; * You have to add &amp; when calling the function. I would say that this is the most powerful point, although not in the trivial added syntax of `&amp;`. Consider the functions `foo(const int* px)` and `bar(const int&amp; px)`...both will be called with some form of indirection to an `int` -- in both cases, it will be some memory address which is dereferenced inside of the function. The key distinction is that C++ allows you to make a const reference to a temporary value, while it does not allow this with pointers. In other words, while `bar(8)` is valid, `foo(&amp;8)` is not (`&amp;` is not a binary operator for rvalue integers). That is what makes pointers "inconvenient."
Thanks!
Ah, the undoing is something I also ran into... quite a few times, with a lot of speed ;)
&gt; void editString(std::string* str); // if that's even possible? That line tells me you don't really have a C++ level high enough to be worrying about this kind of optimization. You probably have huge, glaring inefficiencies somewhere else in your code; don't worry about trying to outsmart `std::string`. If you want to avoid useless moves use const references to std::string wherever possible, it's very efficient.
That rarely works. Static checking cannot extend beyond dynamic library boundaries, and in practice compilers can only detect easy cases.
I double-checked the the ISO C++11 document (section 21.4.5) operator [](i) is defined as requiring i &lt;= size(); at(i) requires i &lt; size(). So nicely you can access the size() position with [] if needed. Clearly one should not be allowed to with at() (as it is a container of size() elements and should behave as std::vector::at would.) The standard specifically states that operator [](i) returns *(begin()+i) if i &lt; size(), otherwise a reference to a value constructed by "charT(); which shall not be modified". So it is not undefined behaviour at all: MSVC is not C++11 compilant.
Um... Do you happen to be a Haskell programmer? Just noticed your username. Didn't know Haskell has a monad for that. ;)
Nothing keeps you from hosting your emacs config remotely and loading from remote.
Urk - more specific link: https://github.com/facebook/folly/blob/master/folly/docs/Overview.md
I'm sorry if it 's a stupid question but: MinGW is a compiler? Isn't the compiler gcc anyway (g++)? 
I don't suspect this works with VS2012, which is unfortunate yet understandable. Format.h is the part that interests me the most.
It requires a lot of stuff from C++11 that no version of MSVC can't do yet.
Ok I have taken note of that. I was using the double endl because that's what the CGI tutorial I was referencing used. EDIT: cout &lt;&lt; "Content-type: text/html\r\n"; results in an "internal server error" on GoDaddy's Apache server. cout &lt;&lt; "Content-type: text/html\n\n"; worked
&gt; protocol requires "\r\n" after each header and "\r\n\r\n" after the last header. The content-type header is the last header before the body starts, so it needs to end with "\r\n\r\n", not "\r\n". In other words, the line terminator is not "\n" but "\r\n". 
Yes the problem is definitely related to the MergeSort functions. Commenting out all calls to MergeSort helps. This was a quick &amp; dirty hack job, but you are nonetheless right about potential for overrun. Preferably I'd be using the POST method rather than putting all the raw data in the URL, but time was short and POST wasn't working at the time. Maybe I'll go back later and change it.
Just part of the website I guess. Free service and all.
Facebook Folly eBook: http://www.heronote.com/files/Folly.htm 
If you've not used Valgrind before, you should find it a very useful tool. It should be the first stop in finding any memory leaks and/or memory corruption. It has other tools that sound useful but I've never tried. 
Hmm. Are the provided operations (select, where, join etc) comprehensive? In D and C# you have UFCS and extension methods so anyone can add more at any time, but in C++ I'm not sure how you'd do that. I'd much rather be able to write stream.newOperation1([](int i){...}).newOperation2([](int i){...}) than have to write newOperation2(newOperation1(stream, [](int i){...}), [](int i){...}) assuming there are any new stream operations I might want to introduce. And oh my, but this really shows how the lambda expressions are a little verbose. I really would like some "magic" automatic/implicit variables like "`_0`" so the "`(int i)`" was unnecessary. Would be even better if we could somehow write stream.newOperation1({...}).newOperation2({...}) but that'll never happen in C++. EDIT: I also wonder about solving the ProjectEuler problem more efficiently. Something maybe like (in pseudocode): int product = range(s, s+4).select({_0-'0'}).product(); int max = std::max(product, join(s, s+5).select([&amp;product]{ product/=(_0-'0'); product *= (_1-'0'); return product; }).max()); Something like that should be several times faster than the solution given in the video, because we're aiming for something that generates code similar to int product = 1; for(int i = 0; i &lt; 5; ++i) product *= s[i]; int max = product; for(char *i = s+5; *i; ++i) { product /= (*(i-5)-'0'); product *= (*(i)-'0'); max = std::max(max, product); } Admittedly, the LINQ-like solution isn't much neater than the imperative solution, but they're both nicer than the one given in the video... Also: The test for "`.contains('0')`" in the video as a "little optimisation" is ridiculous. *No way* does it make the code faster.
I tried to implemented LINQ in C++ with very similar syntax. Since the only practical compiler I could use was pre-C++11. I tried to use boost::phoenix library to emulate lambdas. However without native lambdas and auto keyword, the syntax got very noise. I am happy that someone in MSFT is trying to do the same thing with more their expertise. I think the syntax can be more natural with polymorphic lambdas.
From your username, you seem to be the author of this library. I haven't finished the video since i am at work so you might have answered these questions already. I suppose that compiler can already do a lot of micro-optimisation since the query expression is given. However, is there any plan to symbolic/algebraic transformation of the query expression template? If so, how would you implement that backend? Now suppose that you have all that figure out for linq for object. How would you know how to switch that at runtime if the linq is applied to a database backend? 
Some of that stuff is a little intimidating - the idea of keeping random access until a `where` filter forces you to lose it is pretty scary, but I'm sure it's awesome for the end-user. Ditto *anything* above what's required for an input iterator, really... As for the lambda thing, it was mostly a complaint about "C++ The Language" more than a complaint about "C++ As She Is Spoke". I think C++11 lambdas are better than boost::lambda in almost every way and almost every circumstance, but I'm still a little dissatisfied with how verbose it all is. In C# you have x =&gt; x * x //C# and in C++ we have to [](int x){ return x * x; } //C++11 which is totally inadequate, really. If nothing else the type of the parameters should be inferred/templated/whatever: [](x){ return x * x; } //not a real language and the "`return`" should be inferred if it's just an expression, maybe the semicolon should be optional for expressions too... [](x){ x * x } //still not a real language Maybe we could standardise on default parameter names if we wanted to leave the parameter list off, []{ _0 * _0} //still not a real language... though this causes problems - if we capture everything by reference and there's a variable "`_0`" in an enclosing scope, how do we know whether that lambda has zero or one parameters? Perhaps variables with these names can only be captured explicitly. Finally, the capture-list is a great idea, and I appreciate that requiring empty capture-lists makes the grammar nicer, but wouldn't it be really nice if we could just write { _0 * _0 } I'm not a D programmer, but there's an example [on their website](http://dlang.org/phobos/std_algorithm.html#map) that goes a little like auto squares = map!("a * a")(container); //D Now, that compile-time string expression thing is *weird*, but it's concise. If I could write auto squares = map({_0*_0}, container); //Pretend language I'd be happier, really, but even the weird string thing is better than auto squares = map([](int i){ return i*i; }, container); //C++11
Why would you lose the c++11 lambda by rewriting the expression tree? I was thinking about algebraic transformation from relation calculus and such. Anyway it is all beyond me now, good luck hacking and would love to hack them myself someday.
Pardon, I only mean that you can't introspect C++11 lambdas. If I write f( [](int x){ return x + x; } ) Then at most, `f` sees an opaque lambda type. It can't introspect it at all. On the other hand, with f( _0 + _0 ); Then `f` sees something the types from a lambda library, perhaps: `expr::lambda&lt;expr::plus&lt;expr::argument&lt;0&gt;, expr::argument&lt;0&gt;&gt;&gt;`. Then I could use [template metaprogramming](http://en.wikipedia.org/wiki/Template_metaprogramming) to transform that expression. Contrast in C# where the same lambda syntax can be used to construct either delegates or expression trees. f( x =&gt; x + x ); // calling void f(Func&lt;int,int&gt;) g( x =&gt; x + x); // calling void g(Expression&lt;Func&lt;int,int&gt;&gt;) On the one hand, it's a shame that I can't introspect C++11 lambdas. On the other, I can only imagine the complexity it would introduce.
I note that Microsoft have released a C++11 library. Aren't they killing off C++ in the next Visual Studio?
here here man
Threads, Atomics, Mutexes, async() and more are included in your favorite modern compiler (VC++2012, GCC4.7) by default today. All is standardized and portable. So you don't need any of this, correct me if I'm wrong please.
[Folly](https://www.facebook.com/notes/facebook-engineering/folly-the-facebook-open-source-library/10150864656793920) According to the main author " I don't think it compiles on anything but Linux x86_64 with gcc 4.6.2 or later; we (at Facebook) surely haven't tested it on anything else."
this could be nice for game programming. On PS3 hardware, task management is the way to do parallelization. This would be a great feature for an OS game engine
I'm kinda surprised they haven't given it a swing on clang++ at the least.
http://www.humblebundle.com/
[Sphere Online Judge](http://www.spoj.pl/): a problemset archive, online judge and contest hosting service accepting solutions in many languages. It has been a very long time since I last participated, I don't recall if they provide solutions for submissions. Looks like xmichelo [posted](http://www.reddit.com/r/cpp/comments/un5zz/are_there_any_free_websites_with_c_problems/c4wtyel) a link to a similar site.
Using the preprocessor you can get rid of the verbosity and boilerplate of lambdas. So you could transform this: vector&lt;int&gt; numbers = { 1, 2, 3, 4}; auto r = from(numbers).where([](int x) { return x &gt; 2; }).select([](int x) { return x * x }); into this: vector&lt;int&gt; numbers = { 1, 2, 3, 4}; auto r = LINQ(from(x, numbers) where(x &gt; 2) select(x * x)); I might try to write something up this weekend.
Can't seem to comment on the thread, but why would the decltype((*(T*)0) + (*(U*)0)) return type only work for arithmetic types? It looks like the '0' represents a pointer to a T and pointer to a U, which is then dereferenced. Though I am not very experienced with decltype yet, so I could be misunderstanding.
Can someone explain why variable length arrays aren't ever going to be in C++?
Because you have vector and array (in C++11). Also: http://stackoverflow.com/questions/1887097/variable-length-arrays-in-c There always are some pros and cons in one or the other solution. Life. :P But what I don't get it is complex type at the bottom of the first page. It is all about casting or what?
std::array is not variable length, and std::vector has stringent requirements about the type it can hold, such as having both a copy/move constructor and assignment operator. While all of these are related, they serve a different purpose.
Hard. Syntax is different, but that's just the tip of the iceberg. You have to think about a lot of things that you're not used to think when coding in Java (memory management is the first thing that comes to my mind, but there's plenty of other things), since you're closer to the hardware. I would suggest trying to use as much as the modern features as possible (and as far as using C++11), but you will probably need to interface with C at some point if you're doing game dev, in which case your beautiful, modern code will crumble to a pile of low level shenanigans. However, this can be largely avoided with a modern C++ game library like [SFML](http://www.sfml-dev.org/index.php). I'll suggest reading [Accelerated C++](http://www.amazon.com/Accelerated-C-Practical-Programming-Example/dp/020170353X). It will give you a good overview of the language, while being smaller than a dictionary. After this, [Effective C++](http://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876) is a good follow up. In fact, look inside this book to see what I'm talking about in the first paragraph. I used to hate C++ for it syntax and cryptic compiler messages, but now I love it for the power it gives me, from the superfast speed to the infinite amount of libraries.
std::unique_ptr is probably the closest competitor. auto arr = unique_ptr&lt;T[]&gt;(new T[10]); 
It is a close competitor yes, but still pretty brutal. You also need a custom deleter in this case. But ah well, matthewpl's point that there are trade-offs no matter what is a good one. Nothing in C++ provides the same performance/safety as variable length arrays in C, but then again C++ has some stuff I wish C had.
Not just syntax is different. Some of the paradigms are very different too. * C++ uses RAII ubiquitously. * Use of destructors ensures exception-safe code that is done differently in Java. * C++ STL can have quite a functional programming feel. * C++ macros and templates can create things that feels like magics, e.g., Boost::Spirit, Google mock. * Last but not least, C++11. lambdas, auto, unit, just to name a few, new, very fancy features that will introduce eye-opener libraries in the hands of some experts.
No no no, unique_ptr is what you want, return the unique_ptr itself as in: http://stackoverflow.com/questions/4316727/returning-unique-ptr-from-functions You should never need to return a raw pointer. Calling release() defeats the automatic management and safety. Scoped pointer would be the wrong choice since its semantics are exactly: only use in the current scope. 
I would recommend learning and becoming good with C first. Some of the oddities and design choices of C++ make much more sense if you're coming into it from C.
The major compilers all support it. So yes, I would say it's safe to use.
Because many people do not even like c++. Torvalds refused to use it in the linux kernel, etc. http://yosefk.com/c++fqa/defective.html If someone downvotes me for answering a genuine question then you know what, yall bitch niggas. 
With respect to design patterns, while many can be easily converted over do realize that you likely can implement those patterns in many different ways in C++ with numerous benefits. Nicely, using C++ libraries (e.g., Boost) can and will give you such design patterns for free (i.e., you don't have to know the details) with numerous efficiency benefits. Many of the best design patterns do lots of things with templates and heavily exploit various language features/definitions --so it is nice to be able to get such "for free" when using libraries written to exploit the C++ language fully. :-)
"Because many people do not even like c++" is certainly an emotional answer, and I believe that Torvalds is wrong in his position. I was looking for a more technical discussion. Your link has been described very well by many, and here is just [one](http://discuss.joelonsoftware.com/default.asp?joel.3.557377.81): &gt; Most of it is BS. &gt; Developers are defective - not C++. &gt; Simply, do not use questionable practices. &gt; Also, who cares how many times the files gets compiled or 'passed' by the compiler. What's important is a quality of produced binary at the end of the process. &gt;The very first C++ standard included all what's needed for object-oriented programming. The "features" accumulated over the years are just useless gunk. That said, it takes dedication to make a page like that.
&gt; The functional bits of C++ are almost unusable without lambdas in C++11. Well, they are not that bad even in C++98 if you use them with the right libraries, such as [Boost.Lambda](http://www.boost.org/doc/libs/1_49_0/doc/html/lambda.html): std::transform(v.begin(), v.end(), v.begin(), _1*5); Of course, if you have to do more complex things like access members of the parameters then things can get quite ugly, but for simple cases the library is quite neat.
Protip: prefer begin(v) and end(v) instead of v.begin() and v.end(). It does the same thing when v has begin and end member functions, but the free functions are compatible with more types (arrays, for example).
Thinking in C++ vol. 1&amp;2 ( http://www.mindview.net/Books/TICPP/ThinkingInCPP2e.html ) are very didactic, yet go deep into details. Plus Bruce Eckel is nice enough to give away the PDF version for free... Note that these books doe not cover the innovations introduced by C++11, but they will give you some solid background to understand the latest features of the language.
I agree with you in general, but still, if e.g. developing in an old API which passes around raw ptrs, using a `scoped_ptr` in the implementation and returning `ptr.release()` one will still benefit from the extra exception safety *inside that function*. But yeah, APIs which pass around raw ptrs suck ...
&gt; Obviously it wouldn't work for any algorithm that expected the end iterator to be a bidirectional or a random access iterator, but for the aforementioned map/filter/reduce there isn't really a reason to store actual data for the end iterator when the string is zero-terminated. I just want to object to this mode of thinking. It's great to be knowledgeable and aware of size implications, and try to think in terms of optimization, but for things like iterator objects, their size is irrelevant in practice. The performance difference between 8 bytes and 1 byte is negligible on any current architecture, to put it very mildly. The added complexity of a separate separator type for the `end` point is *never* worth the effort, with the exception of a few very unlikely edge cases (for instance, why would you want to store a bunch of iterators all pointing to the end of a string? when would you actually cash in on those memory savings?). Add to that the fact that very few containers are actually likely to want to limit their iterators to be unidirectional (singly-linked lists or generator functions are the only two examples I can think of from the top of my head) — it's just useful to be able to go `end()-1` to get the last element, and that comes for free if you use a single type for all iterators of a container.
`std::unique_ptr` is the same as `std::auto_ptr`, except not broken because move semantics. :)
Oh, definitely pain management.
The array sits on the heap, though, which can be inappropriate for some use-cases. If you used placement new with alloca you could do it, though: auto arr = unique_ptr&lt;T[]&gt;(new(alloca(n*sizeof(T)) T[n]); Of course, alloca is non-standard and often discouraged... EDIT: not sure if it's standard, but [designated initialisers](http://gcc.gnu.org/onlinedocs/gcc-4.1.2/gcc/Designated-Inits.html) are pretty damn cool. EDIT2: You need a `const unique_ptr` to disallow move-semantics, as well. Don't want someone thinking your stack memory will outlast the current scope. Not altogether sure that the `unique_ptr` will do the right thing, though - the objects get destructed properly, apparently, but it also tries to free the stack-allocated memory, probably crashing the program. Ugh. EDIT3: You can fix that problem with a custom deleter on the `unique_ptr`, calling the destructor without calling delete. It's a pain, though...
&gt; I'd really rather we passed containers than iterators Except that that doesn't work in general * your container might be a c-style array which doesn't know about its own length (and this is an extremely common case). * you might be interested in iterating through (sorting, etc) only a subset of your container. &gt; Is it really right to force our begin and end iterators to be of the same type (as we do in most algorithms)? It would make actually writing many of the algorithms to be very difficult, wouldn't it? Consider, say, binary_search. How exactly would that work if your begin and end iterators were of different types and not assignable?
"It depends." I would lovelovelove to do this in my project (and also use "auto") - but unfortunately I need to compile in XCode 3 as well as VS 2010 but there isn't a solid way to get XCode 3 to support a more modern compiler - and you can't just drop in the code for unique_ptr as it needs move semantics. I'd say that _if_ all your target systems' compilers support this feature, then you're in the clear - that there are no partially baked versions of unique_ptr out there in current compiler versions.
A whole page of code so I can write: a &lt;swap&gt; b; instead of std::swap(a,b); Plus I know that std::swap(a,b); is a function that swaps variables. If I saw a &lt;swap&gt; b; in some code I was maintaining I would have to go to look up this custom trick. Is this a joke?
SL? don't you mean STL?
&gt; Except that that doesn't work in general In all of the cases it doesn't work you can use (something like) the `range` class I outlined. Works for arrays, works for subsets of containers. I wrote that bit for a reason. And this is largely beside the point, but the container thing technically *does* work for arrays if you write the right overload. That is, something like template&lt; class T, size_t N, class Y &gt; void for_each( T (&amp;array)[N], Y f ) { for(auto i = begin(array); i != end(array); ++i) f(*i); } Writing those array-specific overloads might not be worth it, of course, but the `range` thing is easy enough, and it makes a lot of other things a whole lot nicer. &gt; Consider, say, binary_search. Again, *I did* - I said, "Obviously it wouldn't work for any algorithm that expected the `end` iterator to be a bidirectional or a random access iterator". `std::binary_search` performs O(log n) comparisons only if the iterators are random-access iterators. Obviously there isn't much point in allowing the type of the `end` iterator passed to `std::binary_search` to be different to that of the `begin` iterator (so long as you want log-time performance), but that doesn't mean we need to enforce the same restrictions on functions like `std::transform` and `std::copy` and so on. Those functions only need input iterators, they don't need bidirectional iterators or random access iterators. (Again beside the point, but the `std::binary_search` falls back to a linear search if you give it forward iterators, and why not let those forward iterators be of different type?) I'm not advocating we change the `end` iterators on any containers in the STL, I'm just saying we should allow it on the functions it makes sense to allow it on. Let people do it with their own containers. What exactly do we lose by adding a template parameter and making them more general? More code works, and no code that currently works stops working. I don't see a downside.
So long as you don't use what you don't need, and the system doesn't require you to pull in features you don't use or need, using a C++ environment as a *better* C can work well. There were two primary features of C++ that I always wished were in native C - method overloading and the ability to auto-cleanup on exit from scope like how the RAII model works. The _Generic macros may get partially towards the overload model, now if we could just register a *leaving-scope* handler to be used to do some cleanup then I'd have what I've wanted.
The *whole page of code* you're so worried about would go in a header so I'm not sure what you're so worried about there? Anyway it strikes me as a fun gimmick. Hardly recommendable for actual usage but a neat bit of overloading nonetheless. I do wonder if there are many situations where it would trip up while std::swap wouldn't, but that's over analyzing this bit of fun.
SL = Standard Library: iostreams, string, functional, threads, everything that is shipped with C++ (including the STL, which I will define next). STL = Standard Template Library: containers and algorithms. See Stepanov's [Elements of prgramming](http://www.elementsofprogramming.com/) for details.
The nice bit for me is using raii for automatic resource management, such as the large number of pool allocated objects. Using Java is a pain for this task because you still end up manually managing memory to avoid GC latency. 
I'm not sure I agree with all of this: I don't allow exceptions in the code base. I won't go into all the reasons here, but it's not uncommon in game development to avoid use of exceptions. Also, that last bit should be: std::ostream&amp; operator &lt;&lt; (std::ostream&amp; out, const T&amp; t) {...} Also, there's a lot more to the STL than just using iterators. The container classes are just a part of it. Also, despite the other advice people are giving here, don't go nutty with wrapped pointer types (shared_ptr, etc.). You will find that debugging those is just as complicated as finding memory leaks with raw pointers, and, you pay a cost for using them. If you learn to use valgrind and are diligent about understanding object lifetimes, raw pointers are fine. C programmers have used them for decades and know this. 
I expected them to at least get the most important part right. No such luck. void operator()(T&amp; a, T&amp; b) const { using std::swap; swap(a, b); }
Can you do a better job of explaining it then? Right now your comment is pretty worthless.
You are right, my apologise. Stupid mistake.
I know I expected the post to be about ADL. 
Java provides you a shit-ton of infrastructure for doing everything from graphics to audio to networking and more. C++ does not. You'll need to hunt down 3rd-party libraries to support that type of functionality.
Use, and then transition into changing, free software. The two best programming lessons I've had came from free software projects. The first was when I finally understood linked lists, because I patched [rsstail](http://www.vanheusden.com/rsstail/) to make version 1.7 (though apparently there was a bug). That patch came from a realization I had while using the software, a need that I had, that I was then able to fill. If I had been using a non-free solution to RSS reading, I would have been unable to learn that lesson. The other lesson was how to navigate huge projects, and that came from the C++ game [minetest](http://minetest.net). I added in several different features that I wanted in the game, and they're all still around, in one form or another. The moral of this story isn't just "follow the above links and find something to do," it's that you can find plenty of things to do just by fixing up the software you use every day. In fact, one project alone would give you enough material for a final project in any C++ course.
I fixed the stream typo. Thanks! Exceptions: The person is coming from Java which forces one to at least handle exceptions. In my experience Java programmers will use exceptions at least initially because they are so used to using them --and so my comments are based on such. Experienced C++ programmers will always try to minimize the use of C++. Newcomers from languages that use them won't necessarily until they get to better understand the language. Iterators: While the SL has a lot more than iterators, iterators are a huge part of it and if one understands them, using most of it is straight-forward. This is why I emphasized learning about iterators. For someone coming from another language and is constrained with respect to time I think it is good to note that iterators should be learned early. Then all of the containers and algorithms are at their disposal. Most of what remains is more niche or advanced and not an initial concern for newcomers to C++. Wrapped Pointer Types: Personally, I would emphasize that a newcomer to C++11 coming from Java should try to pass by value (and/or rvalue) first, by reference (i.e., &amp;) second, and only if managing memory (e.g., using new and delete) by pointer (i.e., *). If managing pointers then wrap them with unique_ptr or shared_ptr. For someone coming from Java (where nearly everything is dynamic/run-time), this should help them considerably with C++ coding and efficiency concerns. Java newcomers: Steer away from using new for everything! Simply declare most of your variables like you would see them in C code (e.g., on the stack): std::vector&lt;double&gt; v; I mention this because I've seen Java programmers coming to C++ try stuff like this when starting out: std::vector&lt;double&gt; v = new std::vector&lt;double&gt;; which is totally incorrect but understandable for newcomers guessing the syntax using their Java knowledge. Java newcomers: Be aware that in C++ you cannot "call" another constructor using the syntax you use in Java: struct Foo { int i; Foo() { i=2; } Foo(int k) { Foo(); } // INCORRECT! Foo(int k) : Foo() { } // CORRECT! }; When you write the name of a type in C++ followed by () or {} (possibly with arguments) you are declaring an instance (i.e., variable) of that type in C++. Thus, the INCORRECT line above, declares an unnamed variable of type Foo() in the constructor code --it does NOT call the Foo() constructor! To call the Foo() constructor use the initializer list method given in the CORRECT line above. Java newcomers: Remember that any objects in Java are technically references, i.e., they are truly pointers in C++. Thus, to write code that does EXACTLY what wants to do in Java requires making every object a POINTER. Know that this is a LOT of (typically) unnecessary work and often results in inefficient code when compared to other methods to accomplish the same thing in C++. Thus, don't try to code everything exactly the same way in C++ as you would in Java. You'll find new patterns/solutions that you can use that are much better in C++ to do what you want. If you're unsure, then ask others that know C++ for some quick thoughts/suggestions. :-) 
I think it is safe to assume that the original poster is a newcomer from Java and wants some quick advice that doesn't require knowledge of anything that is not in Java (for he/she hasn't learned it yet). So I gave a quick-and-dirty explanation. If you have a better way of saying such, then please suggest it! :-)
You are of course right about using ADL for swap - I've updated the source. I find it ironic that while joking about C++ abuse I messed up the part that was actually relevant to the title.
&gt; Is this a joke? Yes, it's meant as a funny experiment in declaring your own infix operators - not something to be actually used.
&gt; You can throw any type in C++ --unlike Java where exceptions must inherit from java.lang.Exception (or, more technically, java.lang.Throwable). At least this guarantees you can call .getMessage(). In C++ catch(...) isn't very helpful. 
Certainly not, though it sounds like OP has *some* experience with C++ already, which is why I figure an up-to-date reference wouldn't *hurt* anything :)
The second edition of the [C++ Standard Library](http://www.cppstdlib.com/) is pretty much the only C++11 dead-tree resource available. So until the books get updated, I would suggest reading the stuff posted in this subreddit, stack overflow, etc. And of course, trying things on your own. If you're really ambitious, you can obtain a licensed pdf copy of the 2011 ANSI standard for roughly $30. EDIT: Also check out [cppreference](http://cppreference.com), it's a pretty good wiki.
Provide a rough example please
Sure thing :-) In Java all of your objects are heap-allocated, but in C++ there are two ways to allocate an object (or built-in type): 1. Heap-allocate them using new 2. Stack-allocate them For example, if I have a struct Silly, and I want to allocate an instance of Silly on the heap (or free-store, whatever terminology you want to use) I would use the 'new' keyword as such: Silly* s = new Silly; And then I would have to make sure that I delete the allocated object after I'm done with it: delete s; Failing to do so is a memory leak. However if I don't actually need that object to exist on the heap, C++ allows me to allocate it on the stack, just like any other local variable: Silly s; Once the stack unwinds after my function exits, the Silly object on the stack will have its destructor called and thus I don't have to worry about cleaning it up. Now, let's talk about exceptions. When an exception is thrown in C++ the stack unwinds until a suitable catch block is found to handle the exception. All of your stack-allocated objects will be handled fine, but any heap-allocated objects will have to be handled manually. For example, consider the following code: void foo() { Silly s1; Silly* s2 = new Silly; // Some code that can throw an exception... delete s2; } If the code above throws an exception, the stack-allocated Silly s1 is safe, but I lost s2! However there's a better way: RAII. RAII stands for "resource acquisition is initialization". In a nutshell, if I acquire a resource (memory, file handle, etc) in a constructor, and free it in a destructor, then as long as I stack-allocate the object that does the acquiring and releasing, then I'm exception safe. For example, std::shared_ptr: void foo2() { Silly s1; // same as before std::shared_ptr&lt;int&gt; s2(new Silly); // this time wrapped in shared_ptr // Some code that can throw... } Now I'm safe because the shared_ptr was allocated on the stack, but it holds onto some memory that was allocated on the heap! When s2 goes out of scope, it automatically deletes the memory and I'm leak-free! C++11 introduces std::shared_ptr, std::weak_ptr, and std::unique_ptr, each for different purposes, but all solve the problem of leaking memory. Now, resource leaks aren't just memory leaks. I can also leak file handles, sockets, etc. However the C++ std::ifstream, std::ofstream, etc objects follow the same principle: open the file in the constructor, close it in the destructor. Therefore, if you plan to use new, and want to be exception-safe, it is highly recommended that you do so while constructing an object of type std::shared_ptr, or any of the other smart pointers. The resulting code will be safe from exceptions and memory leaks. 
thanks! Very interesting.
ok so I read this article: http://www.learncpp.com/cpp-tutorial/79-the-stack-and-the-heap/ To learn more about stack versus heap and it states that the stack is "relatively small" - any advice on how this factors into things? 
What do you mean by unit?
[User-defined literals](http://en.wikipedia.org/wiki/C%2B%2B11#User-defined_literals). For the first time, you can have the compiler check your mathematical formula ([stolen example from stackoverflow](http://stackoverflow.com/questions/237804/user-defined-literals-in-c11-a-much-needed-addition-or-making-c-even-more-b)): css::Font::Size p0 = 12_pt ; // Ok css::Font::Size p1 = 50_percent ; // Ok css::Font::Size p2 = 15_px ; // Ok css::Font::Size p3 = 10_em ; // Ok css::Font::Size p4 = 15 ; // ERROR : Won't compile ! Another example: Mass m = 10_kg; Acceleration a = 9.8_m_per_sec; Force f = m * a; // Ok, Newton's third law of motion. Force h = m * m; // ERROR : Won't compile! 
No, the propper way is using std::swap; swap(a,b); 
In the free version, MS are pretty dedicated to C++ now, esp' with Herb Sutter involved.
I laughed.
If your interested in C++11 the you are basically out of luck for a well respected text that covers that language. Some books are due out late summer or fall from what I hear, however being out means nothing with regards to quality. It will be sometime before the community can digest and recommend what will be come the standards for C++11. Now don't let that stop you, at this's point learning C++11 ought to be highly recommended. My gut feeling is that C++11 will be adopted much faster than previous versions of C++. So your only recourse at the moment is the net. That is the blogs, sites and forums dedicated to C++. Hopefully you are malleable when it comes to the changing definitions as to what is accepted practice for C++11. It will certainly be tougher to pick up the language this way but two to three years from now you should have a strong understanding of the new language. Further you should understand and appreciate what will have become accepted practice. 
I go even further and keep all of my system related config files in version control. I checkout and symlink the files or directories in my repository to the correct locations. Works amazingly well. Because I use Arch, setting up a new system is as easy as installing Arch, grabbing a few packages from the repo, git clone, symlink stuff and done. Really quick.
TIL some people think CoffeeScript is "general-purpose"...
&gt;Make sure you learn C++, not C. C-style strings, C-style arrays, C-style ("naked") pointers are to be avoided. Well, they are pretty simple, you just shouldn't use them unless you have a good reason to not use the alternatives.
Could it have to do with this: // Variables const int iNumElements = iEndIndex - iStartIndex + 1; int aiTemp[iNumElements]; iNumElements is a const, but it is not necessarily a compile-time constant? This gives me an error in VC++, not sure about GCC though. 
I miss the comparisation with other static languages that also target native code generation. Anyway it is a nice blog entry.
Yes, it's a big c++ flaw. There is big room for a native programming language that offers control from assembler right down to the highest level functional code. Whoever makes that first will storm the market like a hurricane.
Hmmm... good point. To my school's credit, the last actual CS-related class I took (I'm still chuggin away on an AS myself, though I've been doing this crap for 20+ years :)) was straight C -- they avoided that temptation of "C with std::cout". But yeah, I agree -- they're probably not covering much OO or C++-exclusive features in the class(es) OP has taken so far.
&gt; was straight C -- they avoided that temptation of "C with std::cout". Good. While I don't like C, at least it's a coherent language, unlike the infamous "C/C++" that teachers like so much. &gt; they're probably not covering much OO TBH, I'm not sure C++ is the best language to learn OO. OTOH, it's a good language to learn when to use OO, and when not to use it.
That's like saying "why bother with objects when you've got globals. :-) 
MS always does the right thing after exploring every possible alternative.
Didn't realize they were even taking it away. Thanks for the explanation.
it's a weird world we live in where increased demand for a product causes an inverse reaction in the price.
So the tradeoffs include the cost of the copy, possibility to elide the copies, cost of indirection, and the possibility to vectorize the body. Not exactly trivial problem to analyze. 
typical day in the c++ neighborhood.
&gt; "... From the machine perspective, these references are pointers." Is this necessarily true? Clearly in ICC it is otherwise both examples would be vectorized, but it doesn't make sense that this is a requirement.
It's not technically required, but I don't think any compiler implements them any other way.
There is a whole subreddit dedicated to your needs... http://www.reddit.com/r/learnprogramming
I actually wanted to use python first too, but I heard that C++ is used more widely (especially for games). And on top of that my brother already got the book with the software and instructions for C++.
Thank you sir! I didn't know about that.
C++ has higher performance and gives you more control over the hardware, so it's more useful for games in that sense. Unless you're planning on writing Crysis, the performance won't matter that much (the efficiency of your algorithms will have much more effect than the speed of the language). If you still really want to try C++, I'd go with Code::Blocks instead of Dev-C++ (You can download it here: http://www.codeblocks.org/downloads/26) Dev-C++ is fairly antiquated at this point. Codeblocks uses a newer version of the same compiler as Dev-C++, so the examples in the book should work with little fuss. Alternatively, you can go for Microsoft's Visual Studio Express (Free, and MS's development tools are damn good). Anyhow, either way, have fun! Don't get discouraged; You can learn to program pretty quickly. It'll take a while before it actually feels *comfortable*, and it will be a long time before you're as good as you thought you were when it first became comfy. Just keep at it!
Alright thanks, I definitely will! And it's good to know it gets easy quickly. Alright well if Dev-C++ is really outdated is it even worth me trying to learn with this book? I can start on something else if it is easier and better like python, I just felt like this book was the only thing I knew for sure I could learn from cause he explains it so nicely and usually I get confused by the countless internet articles on the topic. So what do you recommend for absolute beginners like my brother and I to start out with so we can learn to program simple games in the coming months? HTML, Java, Python? And what compiler should I use since mine's outdated, the one you listed? Thank you so much by the way, I'm very excited to learn this and I just want to see improvement and my understanding grow quickly.
Alright cool and yeah I never cared for Javascript either haha, but I know Notch used Java for minecraft so I know that has potential. I don't really need the book, it's just all I had and it was nice having detailed step by step instructions and diagrams. I've heard that python is easier though so I'll check out those links tomorrow. What IDE should I use for python then?
Stupid company with stupid staffs made stupid decisions.
[This one](http://eric-ide.python-projects.org/) seems to be fairly popular. It looks like it has a few prereqs, though. At its core, all you need to do is install Python and use a normal text editor.
Unlike others I don't think that C++ is a bad language to learn first, however it definitely requires a good deal of commitment (more than others, there is no dipping in and out). The first thing you will need is a good book, I have seen many of the online tutorials on my travels and TBH they all suck without exception. The best book I have have come across for learning the language is `Accelerated C++`. However take a glance through here: http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list Avoid any sort of 'for dummies', '21 days', 'games programming', 'for Java programmers' etc... they suck also. Whilst you are learning the ropes I would strong recommend you do so on *Nix of some sort (like a good linux distro) with just a Compiler (gcc or clang) and a text editor (vim or nano...). This will teach you some really important basic concepts. But I will admit it will require dedication. Once you feel comfortable with the language basics you can go onto use whatever IDE, toolchain or API you desire. 
Dev-C++ is an especially poor choice since it hasn't been updated in some 7 years.
So, first off, Dev-C++ is a literally horrid IDE. The compiler is ANCIENT and its just terrible. There are other open source alternatives that are much more up to date, including eclipse and code::blocks, or even just command-line compiling with Notepad++ and TDM-MinGW. Another favorite if you want just want free as in price and don't care about open-source is Microsoft Visual Studio Express, which is the free version of the tool most professional developers use under windows. Under windows, I personally use Eclipse configured with the latest TDM-MinGW.
It's true that C++ is the thing to use for games, but realistically, programming games is hard, requires a lot of skills, dedication and time to waste, so unless you have a few years, that's probably not a realistic goal to aim at in the first place. If you think you're a very tenacious person, go for C++. If you're a kind of person who might get overwhelmed and frustrated by having to spend a few months or a year on learning the basics, who wants things to work in the big picture and not care about the smaller-type stuff, start with a simple language like python, C# or whatever instead, which is more "Instant fun" because you can create fun stuff with it right away -- "batteries included". You don't need any special software other than what you can download from the web for either C++ or python.
Actually, you're totally correct. Anything regarding advertising or promotional material and such I delegate to other people. 
Not to be pedantic but you originally said this: &gt; Just remember that you shouldn't be using new very much (if at all) in C++. and then your good code looks like this: std::shared_ptr&lt;int&gt; s2(new Silly); so maybe the advice actually *Put all new'd objects straight into a smart pointer*
Seriously if that book had Dev-C++ on it, then just chug it out of the window. Please don't use Dev-C++, it's old and unmaintained. If you want to pickup programming fast and want to go the C++ route, then download Qt creator.
Yeah, start with something other than a book with a decade old unsupported and outdated IDE and an easier language like Python. Starting with C++ is like trying to start with Quantum Physics with zero knowledge of physics at all.
I believe the point was to say more than that. Such as 'why'.
typedef itself is the same as it was in C and before C++11. In C++11, they wanted to add support for typedef templates so one could write something like this (silly example): template &lt;typename T&gt; typedef std::vector&lt;T&gt; mytype; mytype t; There were issues however, so they used the using keyword instead to do type aliases: template &lt;typename T&gt; using mytype = std::vector&lt;T&gt;; using INT = unsigned long long; // i.e., equivalent to typedef unsigned long long INT; mytype&lt;int&gt; a; mytype&lt;INT&gt; b; INT c; where you can have template parameters or not. Its syntax is also easier since you list the newly introduced typename first followed by what it is --which matches the style of assignments, etc. in C/C++. The reason why such things are important is that the Standard Library makes extensive use of typedefs/type aliases in nearly all structs/classes. Once one starts using template types, then one needs to know what type inside a container. These are typedef'd. So, every container type in C++ has a value_type typedef. Thus, given some container C, the container contains elements of: typename C::value_type and so one can process a container's elements without knowing their actual type except by referencing the alias (in this case value_type). Iterators, function objects, etc. in the Standard Library use this (along with a "type traits" technique) to permit access to the types used for those structs/classes. A Java programmer is used to using .getClass() or .class and this cannot be done in C++. Instead, typedefs / type aliases are used to accomplish the same (or similar goals) at compile-time (not run-time) in C++. Java programmers: typeid() and type_info are not that useful in nearly all C++ programs. Exploit the aforementioned typedefs, type aliases, and templates instead. :-) Hope this helps!
That was a great explanation. Thank you!
Yes, very much true. I haven't checked out Stroustrup's new book, but the oft-cited *Accelerated C++* takes the same approach (i.e. high-level modern C++).
In addition to this, if one has access to it, a great teacher or otherwise informed person can make a great deal of difference for one's understanding.
I share a lab with an instructor who teaches the C++ course at our local university (he teaches it really well btw) and every once in a while a book shows up in our lab from the publisher. I can tell you just by looking at the table of contents whether a given book is shit or not :-) If they wait until chapter 24 to introduce the STL then it's a terrible book.
Defining complexity like that is quite interesting. I've spent the last year learning Perl and it's more akin to C++ in complexity than say C#, Java or Ruby are. It's old, it's ugly, it contains a lot of mistakes so I'm wondering now if there's a interesting way to visualise it.
&gt; You need to understand some of the underlying theory such as un-managed memory, pointers, etc Sure, that kind of theory is useful, but you don't need it straight away -- It can wait until the advanced course. &gt; (Theory you would not get if you just used java, python, C#, etc). I think you need to understand that theory regardless of the language. Also, "theory" is the right word here: Something you know to understand how it works under the hood, but that you don't use in everyday programming. At least, not in C++. &gt; And imo the best way to teach that kind of theory is with C rather than C++. Possibly, yeah. You definitely should learn a bit of C at some moment of your instruction. But if you need to learn C++ and C, I'd highly recommend to learn C++ first.
&gt; Something you know to understand how it works under the hood, but that you don't use in everyday programming. At least, not in C++. C++ is by design an unsafe language. You NEED to know that stuff for C++.
Nope. You need to know, and use, safe practices to program in C++. Sure, having a deep understanding of what happens under the hood is useful to create the safe practices in question. That means the teacher must have that deep understanding, not the student. 
Java programmer's: Note with respect to template errors the following... If you find yourself getting "error novels" (i.e., a "million" pages of error messages that are largely unintelligible to you), then ignore it and just go back to your program and look at what might be wrong and fix it. (For this reason, if you are new to C++, write small pieces of code and then compile your program. Make sure that you remove all errors before adding more code. This way you won't have to understand the errors.) You might wonder how could the C++ community tolerate such error novels?!! There is a solution being worked on, but, it was/is not ready for C++11 and was voted out (it is called "concepts"). When it is added to the C++ language, the error novels will disappear. The shortest way to describe concepts is this: Concepts are to types what function prototypes are to functions (approx. translation: concepts type check the usage of types and powerfully enable many more really cool things). Hopefully concepts are in TR2. NOTE: After you get more experience the error novels will start making more sense and you'll start recognizing some patterns in the "novel" that will help you know what the error(s) is/are. Newcomers panic initially. I tell them "don't panic" --just go back and fix what is likely wrong (and/or ask for some quick help). Believe it or not, very quickly the error novels become largely a non-issue for the newcomers.
Pointers have some advantages, that are mutable for one and they can be null for another, but yes I tend to use references for any sort of function call or anything like that. Further more owning pointers are always wrapped in a smart pointer like unqiue_ptr or shared_ptr. Also you can always extract the address of the data of a vector using the `.data()` function call, this can be use in any function that only accepts a C array. So I would argue that it is very practical.
&gt; the best way to teach that kind of theory is with C rather than C++ The topic is about teaching somebody how to use C++; not about teaching them the minutiae of manual memory management. In modern C++, manual memory fucking-with is a sign of bad design or *very* specialized needs.
I started with C and moved onto C++ thereafter. I think that was a good approach because starting out, there is a lot to learn in terms of syntax and keywords and what operator does what. All of that knowledge carries over. Once you start with C++, or objected-oriented programming in general, in requires a shift in how you conceptualize a program. It's no longer a linear recipe -- it's a lot of little mini-programs cooperating. It takes a long time to get your head around that! So learning straight up procedural programming first might give you a good foundation. 
You don't need to maintain different projects for different IDEs. Just use a good build system like premake to generate them.
Just checked it out.. it's pretty awesome! There seems to be support for XCode and QtCreator in the works as well.
So I kinda wish someone had told me C++ wasn't a good beginning language before I started learning it as my first language. I mean I actually understand it, and I don't know what all the fuss is about it being too hard as a first language as long as you focus on higher level features from the beginning. However, I definitely admit that learning python from the beginning would have been easier.
I was going to say something along the same lines but with [premake4](http://industriousone.com/premake). I guess, whatever works. Also, you can always use QTCreator on Windows as well. edit: it was already mentioned in the other comment. :| Well, I guess emphasis is good. 
Did you read the article? He explained the platforms that he needed his project on, and why JRE wasn't on one of them.
Isn't that only when he does some weird stuff? If he sticks to simple but disciplined style, like maintaining the order of member variable initialisation, then he should be fine, no?
&gt; C++ has so much undefined behaviors. Don't write code that has undefined behavior. Simple as that.
I was using cmake until I ran into some problems generating xcode projects. I am sure I could have resolved the problems given enough time, but chose the "easier" option of creating an xcode project manually. Hopefully I will get some time in the future to take another shot at it.
I am curious... were you able to generate an xcode project on OSX 10.7 for Xcode 4.3? I had trouble with that.
Spot on!
When I was looking for a cross-platform build system, I chose premake4 over cmake, because it was a lot simpler to work with. Probably has less features though, but it was enough for me.
For Qt Creator? That's weird, because Qt Creator uses qmake files as project files, which in turn generate GNU Makefiles, for which there is already an output type available in premake.
&gt; OP is going to run into trouble since C++ has so much undefined behaviors. With a bit of experience, it's rare that you run into *undefined behavior* (a.k.a. "the generated code may publish your browser history to facebook") What takes a bit more care is compiler-defined behavior: where the standard *requires* "sane" behavior, but leaves the actual implementation hardware dependent to match the execution platform. In practice, 80% of that is the size of primitive types (which is the reason most major projects typedef a bunch of integer types). The rest is representation of negative integers (usually 2's complement nowadays), availability of IEEE floats, and random assorted stuff. C++ inherited the fundamental C portability requirement: the code must be able to run on a toaster. So yes, it is designed for portability as well, but not in the same "platform ignorant" way. The big portability problem of C++ is the comparedly small size of the standard library. 
It is quite understandable. The task of maintaining headers manually, for example, can easily make one 30% to 60% less productive, when compared to, let's say, Java.
Premake does not yet support iOS. I'm not sure about its support for other mobile platforms. There are patches and forks supporting iOS, but they are yet unintegrated.
An extremely basic start with it would give you good reason not to oop bloat systems where it is not needed. A little malloc research helped me understand new, it's good to get it and not just think- "if I type this, this will happen", understanding past that is essential. Not saying you can't do this with c++ but I think the abstractions get in the way of learning to some extent.
Saying C++ is small since the JVM is large is a misleading comparison. A system that supports the JVM would probably already include it (same goes for .NET CLR). The delta between the system with your application and without your application will be bigger for C++ applications. A .NET assembly tends to be much smaller than a C++ DLL.
I think it has been nothing but marketing exercise all along
Actually yes - I believe that some default paths have changed in the latest Xcode, and CMake did not work (No more /Developer, its now all in /Applications/Xcode.app/Contents/Developer). So I found some CMake (or possibly some other project) bug report which might be fixed now, but I had to: sudo mkdir -p /Developer/Applications/Xcode.app/Contents/ sudo cp /Applications/Xcode.app/Contents/version.plist /Developer/Applications/Xcode.app/Contents/version.plist You can try this out, and see if it fixes your problem. But I don't use Xcode much on OS X, I just let CMake generate makefiles instead.
I suppose having a full scripting environment available is nice, and if it's easy to get going with then I suppose I'll have a look. Thanks. As you say, I guess CMake has more features, such as built in support for a lot of stuff, such as building Qt projects (running the moc compiler, etc). 
Why won't you just stick to Qt Creator? It's easily the best C++ IDE. The only thing that even comes close is MSVS + VAX, but it's really slow compared to Qt Creator.
What is VAX?
Those fucking jerks...wait what are we complaining about now?
This is like saying, "Don't write code that has bugs. Simple as that."
you make zero sense
Well, you have to know about what undefined behaviors are and what unit tests are to understand what I said.
I probably should've kept a far better eye on this considering this impacts me considerably, but it's good to know that they've done this. 
I'm not sure why you're being downvoted, since this has been my experience. C++ compilers often link in everything and the kitchen sink, and God help you if you use templates, which increase binary size like crazy.
Dude, that's the name of my web site (CppRocks) :)
I totally agree, and made the same point in my post on C++ complexity (http://www.cpprocks.com/cpp-ruby-coffeescript-language-complexity). The now-standard smart pointers, std::function and std::array allow moving even further away from C, often without a compromise in performance.
I guess some people did not like his comment; facts be damned. Well, I am not 100% sure if his/her opinion is factual or not but sounds logical to me anyway.
You need to state what you're trying to achieve. You're question right now basically is "how do I manipulate data that I read and stored in a C++ arrays?" which is extremely vague and unanswerable without specification. 
Sure. I'm working with a device on a serial port that reads data in hex bytes. (I can't remember the length of a command off the top of my head but...) I'm trying to read the data (through a microcontroller) and store the data in an array or vector in order to convert the data stream into different parts such as a few floating point numbers in some cases, or integers in other cases. What I am trying to achieve is a proper method of storing the data, converting the data into a float (for example), and going from there. I hope that clarifies it a bit.
A very well written article!
http://stackoverflow.com/
std::array&lt;int, constexprCalculation()&gt; arr; will not compile on some platforms
If `legacy_function` is asking for a `char*`, it seems to me that `vector&lt;char&gt;` is adequate. If `legacy_function` is asking for a `void*`, you may be right, but honestly, `char` will do nicely most of the time. &gt; (and can be larger than 8bit) Do you have an example of a system, currently in use, where a `char` is not 8 bits, and that has a `uint8_t`? What would be its `sizeof`, since, by definition, `sizeof(char)==1`?
sizeof(char) is always 1 but CHAR_BITS can be larger than 8. That's highly uncommon on normal systems but you can find it on DSPs. Those systems probably lack uint8_t but it's better to get a compiler error than your compiler producing code that behaves different from what you expect. So always use uint8_t if you want to talk about (unsigned) 8bit bytes.
To be clear (since your post did not use the code feature), the code in question went from this: for(int i=0; i&lt;size; i++) { av[i] += to_add; } ... to this: array_view&lt;int&gt; av(size,v); parallel_for_each(av.extent, [=](index&lt;1&gt; idx) restrict(amp) { av[idx] += to_add; }); What nonsense that syntax is. Had I not seen the former code, I would have NO IDEA what the latter did. Was that really the best way to do this in C++?
I don't understand why Microsoft introduced new, proprietary syntax to duplicate something that could have easily been done with normal C++.
They're not "parallelizing the for loop" exactly. You can't do that. The way a for loop is written, there is no guarantee that any given iteration does not depend on the one(s) that came before it. You need semantics that define a set of operations that are independent without any temporal couplings. I think the parallel_for_each does that nicely.
When dealing with game creation, you should probably use some sort of "professional-grade" memory management system. The [Boost](http://www.boost.org/) libraries are quite good and very user friendly. For graphics, the best option (in my opinion, at least) would be [SFML](http://www.sfml-dev.org/). The SFML site has a few tutorials on using its components for game creation, so you can learn a thing or two from those. Hopefully this helps.
oonumerics.org was the place where the Blitz++ and FTensor libraries had been hosted, but as you can see it is has expired and is now a parked domain. Unfortunately my Google searching for a mailing list that I might use to learn more only returned references to oonumerics.org, so I am hoping that someone on reddit might be able to give more information on what is going on.
Ok, I'll probably get downvoted for this, but if you already know C# and XNA, I *highly* suggest you keep using C#/XNA for your game development. Stick to the language you're already familiar with while you get used to the important gaming concepts. You'll need to learn important basics like 3d modeling, lighting, animation, transformations, camera manipulation, the game loop, input. All of this can be learned with the XNA training wheels. When you find that C#/XNA can't do the things you want to do or simply can't handle the epic scope of your game, then you're probably ready step into c++/Direct3d. Or, if you're feeling particularly masochistic, you could even learn OpenGL. If you try to learn C++ *and* 3d game development, you're going to fail, hard. Stick to one until you're familiar enough to move on. 
I actually want to stick to 2D game development for now, but just want to learn C++ because it will probably be better for projects in the future. I already have learnt the game loop, 2D animation, and input from XNA which is most of the 2D stuff, so if I ever attempt a 3D project I will probably use something like Unity or XNA, but I really want to try to make 2D games in C++
Hmm... in that case I agree with @massive_potato -- SFML is probably your best bet. I've also heard decent things about [Polycode](http://polycode.org/features/) but have never researched it in depth. I cut my C++ teeth on C++ How to Program, but that was many editions ago. I also highly recommend you practice programming c++ outside of doing a game, particularly learning the standard libraries, and ask targeted questions on [StackOverflow](http://stackoverflow.com/). 
I thought it was so absurdly and blindly obvious that it's intended as a short example that nobody would be daft enough to mistake it for real-life code that actually needed parallelization. Guess I was wrong.
"I'm gonna assume that you don't know anything about the API" He certainly assumes I know what AMP means. Armpit Media Presenter? Autonomous Master Peep? There are only 17K TLA's, It doesn't hurt to spell it out at least once on a medium where anyone could stumble by. 
You don't count from copulating 0 to noncopulating size-1, you add the same value to all elements of the vector. What makes the code "ugly" is the lambda, not the parallelism. The syntax is something to get used to, but it sure beats callbacks and functors for every little nilly-willy operation. 
Thank you, but Eigen does not offer support for tensors (only vectors and matrices) so it is sadly not at all replacement for Blitz++ and FTensor.
Have a look around http://sourceforge.net/projects/blitz/ and you can dig out plenty of email addresses with which to make enquiries.
Temporal coupling == foo(); bar(); has different side effects than bar(); foo();
That's pretty much the C++ bible. Stroustrup invented the language.
In this case AMP is: "Accelerated Massive Parallelism"
This is a very quick first attempt at making a wrapper which transforms a lambda into a curried function. I imagine there's a lot that could be improved, especially in terms of move semantics. Suggestions welcome!
You might also consider std::array&lt;T, N&gt; instead of std::vector&lt;T&gt;, if using dynamically allocated memory is an issue.
Ah, great idea! Thanks. :-)
Ah, very helpful; in particular, I may need to take a more thorough look at Boost::Multiarray. Thank you!
Is it mandatory to use std::function internally? I know it's a nice convenience, but it does add overhead. Using stuff like std::result_of, variadics, etc. you might be able to get away with making your function type just another template type. Edit: Great job though :-) It's nice to see functional programming leak into C++ :-)
I feel like this article ends very abruptly. The discussion of scope is very thorough, but storage and linkage are sort of left hanging. Linkage gets a single paragraph at the end, and storage is left hanging. What happened to the discussion of `static` and `extern`? How about look-up for instance and class variables in methods? The rules for how C and C++ decide which variables get linked together are non-trivial and could use an explanation. I understand that this article is mainly about scope, but the author brings these topics up in the introduction, then doesn't deliver. In all, this is definitely a useful article. Many of the beginning C and C++ programmers I teach don't understand scope *at all*, so it's a topic that can't be written about enough. But it feels like this article was meant to be longer, or perhaps part of a series.
Which compiler did you use to write the code? It fails to compile with the latest snapshot of GCC v4.8. The first issue is with this in curry.h: template&lt;typename TFunc&gt; auto curry(TFunc&amp;&amp; f) -&gt; decltype(curry(typename lambda_helper&lt;decltype(&amp;TFunc::operator())&gt;::func_type(std::forward&lt;TFunc&gt;(f)))) which gives this error: curry.h:53:5: error: use of ‘curry(std::function&lt;TRet(Arg1, Arg2, Args ...)&gt;) [with TRet = int; Arg1 = int; Arg2 = int; Args = {}; typename curry_helper&lt;TRet(Arg1, Arg2, Args ...)&gt;::type = std::function&lt;std::function&lt;int(int)&gt;(int)&gt;]::&lt;lambda(int&amp;&amp;)&gt;’ before deduction of ‘auto’ It appears that you are trying to define the return type using the same function that you are defining. When I've wanted to write code like that, I written a "helper" function prototype using a different function name (no need for a definition in many cases) that "computes"/returns the proper type so you can use std::result_of&lt;&gt; with it. If you're using GCC but not the v4.8 snapshots yet know that error reporting is substantially improved with v4.8. This is a good thing with heavy template metaprogramming code. :-)
Interesting, works with clang trunk. I'll have a look.
I think one of the cool things about such things (e.g., standards, compilers implementing it, etc.) when they are new is determining who/what is at fault: one's code, the standard, or the compiler(s) --or a combination of them! :-)
It should be possible, I only use std::function internally because that's what I started with, the lambda overload was hacked in last night when I had an epiphany on how to do it. I'll have a go.
How about something like: float read_float() { uint8_t bytes[4]; for (int i = 0; i &lt; sizeof(bytes); ++i) bytes[i] = serial_read_byte(); float* floatptr = (float*)bytes; return floatptr[0]; } (flip for endianness if needed, make sure float is the same size and format on both platforms, etc.) If you get incorrect floats out you should post your actual code so we can check.
[Here](http://ideone.com/mYEhW) you go. (Tested with a snapshot of GCC 4.8.) Cv and ref-qualifiers left as an exercise. Caveats include: - not compatible with std::result_of / *Invokable* - a bound argument may be left in a moved-from state after a final call to the underlying functor. Caveat callor.
What I want to see on top of that is toggleable overlays for each of the compilers to show which features they support.
[Image without the bullshit so you can print or save it](http://www.cpprocks.com/wp-content/uploads/Cpp11.png) (direct link to image in question).
iirc OkCupid have released a web framework-like stuff too. But overall the C++ web ecosystem is quite barren.
..but have they sorted out pkg-config support yet?
Ah I knew I had seen this, but I kept googling node.cpp, and nothing showed up. Thanks. 
Technically Wt is free, unless you want a commercial license instead of the gpl this is similar to the pre-lgpl days of Qt. Payed service I think also implies some level of support beyond the forum for it. That said, I'm not sure it solve the node.js replacement problem as I am wholly unfamiliar with node.js :/
Thanks for the link, it is just what Alien Blue needed. 
http://www.justsoftwaresolutions.co.uk/threading/multithreading-in-c++0x-part-6-double-checked-locking.html
If you're going into gaming, you may as well take the plunge and learn C++; almost all the AAA games are written in it. Plus, if you learn C++, you'll be able to map your C++ experience to Java more easily than the other way around (at least, this has been my experience). There are a bunch of reasons as to why C++ is the main language used for games, but your main reason for leaning it should simply be that it's just so widespread in that industry.
There are many people who would argue that C++ is a bad first language, but I am not one of them. It is just very important that you learn it correctly, starting with the abstractions (std::vector, std::string...) and then work down into the complexities of detail. A good book to learn from is Accelerated C++, I would higly recommend you stay away from online tutorials, books that teach C++ for games and and book that claims to teach you in 21 days or similar. This is because you really need to learn C++ first, then learn how to apply it to games.
I'm not sure about this, I think Java taught me more about OO than C++ did, mostly because it is so easy to do C with classes in C++.
Aren't those apples and oranges? Sinatra is a web framework, Node.js is more of a general-purpose runtime (that happens to be used mostly for web development).
I hope this can help : http://www.parashift.com/c++-faq-lite/big-picture.html#faq-6.9 The whole faq is really great for c++. I learned a lot. 
If *sizeof(short)* yields 2 I'm reasonably sure it's because 5+5+5+1 = 16 / 8 = 2 which means that no packing is required, whereas if *sizeof(char)* yields one, you have 5 bits with 3 empty bits (because you can't pack 5 more bits into a byte), then 5 with 3 empty (same thing again), and then 5+1 with 2 empty (i.e. 3 bytes total). I could be totally wrong though it's been a long time since I've had to deal with struct packing...
&gt; There are many people who would argue that C++ is a bad first language, but I am not one of them. It is just very important that you learn it correctly, starting with the abstractions (std::vector, std::string...) and then work down into the complexities of detail. But your first sentence contradicts your second. C++ is indeed very unforgiving, and you are quite right that you need to learn some fairly large parts of it completely correctly before you start doing it. This is exactly what makes it inappropriate for a first language. (There's also the issue that decoding compile errors is so hard that it seems impossible to learn on one's own without some third party guidance... and I say this as someone who can now flick his eye over a few hundred lines of C++ error and know exactly what's happening.) If I were going to learn to be an artist, I'd start with pencils, move to oils, then do modeling clay, and eventually get to stone carving. Putting me in front of a block of marble with a chisel would be the best way to stop my artistic ambitions dead in their tracks. The best way to get going in programming is to start with a simple, forgiving language (I suggest Python), write a lot of programs and make a lot of mistakes that you can correct. Once you're a journeyman programmer, you can start on C++ when you already have well-developed programming skills, and the confidence to spend time on the small details.
I think this is essentially correct. Microsoft has a [good illustrated explanation](http://msdn.microsoft.com/en-us/library/ewwyfdbe%28v=vs.110%29) on MSDN (look at nYear). A field won't be packed into its neighbour unless it will fit *wholely* inside any remaining space in its neighbours underlying type. e.g.: char R : 5; ... means 'pack the 5 bit field R. If it doesn't fit create a new char'. If your code is more than an exercise then you could avoid bitfields all together: #include &lt;cstdint&gt; struct HighColorPixel { explicit HighColorPixel(uint16_t val): val_(val) {} uint8_t r() const { return (val_ &gt;&gt; 11); }; uint8_t g() const { return ((val_ &gt;&gt; 6) &amp; 31); }; uint8_t b() const { return ((val_ &gt;&gt; 1) &amp; 31); }; uint8_t a() const { return (val_ &amp; 1); }; private: uint16_t val_; };
Firstly OOP is not the only paradigm that C++ supports, in fact I rarely use it. My class heirachy are very flat and I will try and use templates before I use inheritance. 
Slightly better with c++11, although sort should have an overloaded version that defaults to begin() end() as that's what you'll want most of the time. #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;vector&gt; int main(int argc, char *argv[]) { using namespace std; vector&lt;int&gt; numbers={4,3,2,1}; sort(numbers.begin(), numbers.end()); for (int i : numbers) { cout &lt;&lt; i &lt;&lt;","; } cout &lt;&lt; "\n"; }
&gt; To get basic applications working you do not need to know what const char * is, just use std::string First, consider that you have to include some line like int main(int argc, char **argv) { // ... to get your application working, then you either have to understand pointers, or mindless copy that chunk of code from someone else and wait till later to understand it. Suppose you have that bit of magic - but then you make a mistake. #include &lt;string&gt; int main(int argc, char **argv) { std::string s = argc; // ... more } This is perfectly reasonable code for a beginner to write - but they will then get the following errors (in GCC): test.cpp: In function 'int main(int, char**)': test.cpp:4: error: invalid conversion from 'int' to 'const char*' test.cpp:4: error: initializing argument 1 of 'std::basic_string&lt;_CharT, _Traits, _Alloc&gt;::basic_string(const _CharT*, const _Alloc&amp;) [with _CharT = char, _Traits = std::char_traits&lt;char&gt;, _Alloc = std::allocator&lt;char&gt;]' Now look at how difficult this error is for the beginner to decipher. The first error. First, note that `std::string` is just not mentioned in these errors, and neither is the variable `s`. The error tells the programmer that they're trying to convert an int into a const char* - but, as you said, this person doesn't understand const char* - even if they did, the only "const char* in sight is argv, so suspicion immediately goes there. Then that next error! I still remember seeing my first STL error, and my response was, "WTF?" Well, it still hasn't gotten much better than that in any of the production C++ compilers out there. All right, so you've explained the error to your young programmer. Now they ask, "OK, how do I get a string representation of argc?" And here's the response: #include &lt;string&gt; #include &lt;iostream&gt; #include &lt;sstream&gt; int main(int argc, char *argv[]) { std::stringstream ss; ss &lt;&lt; argc; std::string s = ss.str(); // ...more } Imagine you're sitting in front of someone learning their first programming language. Are you really going to explain how this all works? or in practice are you going to say not much more than, "A stream is a thing you can write variables into as characters - don't worry about the details, copy this." Compare this to the Python code: import sys s = str(len(sys.argv)) # ...more And note that since you aren't required to declare s, it's not clear right now that you do need to make s into a string - so you might as well write: import sys s = len(sys.argv) # ...more and simply cast `s` to a `str` _only at the time you need it in that form_ - which is much better programming style.
what are you going on about, why the fuck would you want to convert the int to a string? But if you did you would obviously use the aptly named why the hell would you use streams?: std::string s=std::to_string(argc); but having the number of arguments as string is some rarely needed you are just making abstract examples. I am not arguing that C++ is easier to learn than python, it isn't, but if you want to learn C++ then you are better off learning C++ from the off then learning a completely different language (with different syntax) then trying to retro fit C++ over that knowledge.
Personally I think C++ is a better language. There's good and bad in both but when I weigh up the differences it's my *preference* that C++ wins: C++ | Java Compiles to highly optimised | Has the overhead of a JVM binary code Recent language features lessen benefits of JVM (e.g. smart pointers for memory management) Syntactic baggage | No concept of undefined behavior Not suitable for web apps as undefined behavior increases chance of exploits. | Write once, run anywhere platform | independence Insanely fast | Very fast Optimisable for small binary | Tiny deployment sizes for free. Always employable after first years | Easier to convince recruiters you know it of experience Feeling of "talking to the machine" | Feel like not wasting time on anything other like a "real programmer" * | than business logic Slightly more suitable for FPS, high | Suitable for Android games, Facebook games performance simulation games. Difficult to debug | Easier to debug \* *personal thing*
Section 3.9.1 of ISO 14882-2011: &gt; There are five standard signed integer types : “signed char”, “short int”, “int”, “long int”, and “long long int”. In this list, each type provides at least as much storage as those preceding it in the list. So I could make a C++ implementation where all of these are the same size.
Its documentation is relatively poor, but [cppcms](http://cppcms.com/wikipp/en/page/main) is stable and has a nice API. It shares a lot of design ideas with Sinatra.
Well we could talk about what it means to be "OO" and whether the Java et al. version of "OO" has been a good thing for the industry, but let's just leave it at this: "software written in an OO-style performs badly". Perhaps you don't care because you're making "Enterprise" software, or your making a game with no performance requirements, but if you actually care about how data flows in and out of your application, and how fully utilized the hardware is, you don't want to write in a OO style. OO by the most basic definition available means to think of your problem domain in terms of objects that communicate with each other; however this method maps poorly to the hardware you'll be running on -- modern hardware, again at a high conceptual level, is a heavily parallel series of cache-fronted pipelines (and at a lower level fraught with technical details like alignment, cache line size, not to mention GPGPU). If you care about performance, you're probably using C++ because the language has been designed for low overhead, you will want to avoid OO anywhere you have a hotspot, and the fact that C++ doesn't force you into that mentality will be a *feature*.
I think you missed the point. He's trying to create a string from an int to demonstrate the incomprehensibility of C++ compiler messages. 
I totally agree that python is a very good language to learn first. And its similiar to C++ in some ways(especially in overall programming concepts). Python and C++ are not OOP languages but provide OOP features. Besides OOP, they both have polymorphic functions, lambda, and operator overloading. Also, its much easier for a beginner when code fails at runtime, than at compile time.
I think you've forgotten what it like when first learning to program. C++ compiler messages can truly be incomprehensible to the newcomer, even with google. 
Templates and OO both have their right place. OO is very powerful and simple and should not always be replaced by templates. 
WTF are you talking about? Mistakes happen, and bad compiler messages ensue. You sound like Dwight Schrute: "False. No one would try convert an int to a string". 
Well that depends what you are using it for. OOP heirarchies are useful for run time polymorphism, but if that is not your use can than similar systems can be constructed easily with templates. For example the following is a great use of inheritance: std::vector&lt;base*&gt; bases=//populate for(auto b_p : bases) b_p-&gt;my_virt_function(); However if you don't need that sort of runtime polymorphism then you can constuct similar systems with templates that are much cleaner and faster. instead of void my_func(base&amp; b) { b.my_virt_func(); } you can simply write template &lt;typename T&gt; void my_func(T t) { t.my_func(); } Or even basic inhertitance template&lt;typename Extend&gt; struct base { Extend e; my_func() { e.specialised_action(); } }; This is the way the C++ standard library is written and the way the writer of the STL Alexander Stepanov recommends in his book The Elements of Programming.
It isn't a problem I run into frequently, nor one I her commonly grumbled about. (Error messages in C++ yes, but int to string no).
I'm [not dead yet.](http://www.wlandry.net/Projects/FTensor) I do not know anything about Blitz though.
&gt; I at least understood the reasoning behind wanting to push ahead and leave XP behind. That's only half of it. The new C++11 threading model does not mesh with XP's threading model. Condition variables is one very notable challenge. XP just can't emulate condition variables. [Vista and 7 have condition variable support](http://msdn.microsoft.com/en-us/library/windows/desktop/ms683469(v=vs.85).aspx) in the kernel. And C++11's standard library includes condition variables. I'm really curious how Microsoft will support XP with VS11. Will they disallow the use of certain parts of the C++11 standard that conflict with XP's threading model? Will MS develop a kernel patch and runtime library for XP that will allow XP to support the C++11 threading model? Or will they try to emulate condition variables a best they can and warn developers about using them with XP.
I mean there is no way that I can objectively argue my point its all opinion but when I was learning I never had any one to help me decipher those messages and I had no problems whatsoever finding information on my errors on google if I couldn't figure it out on my own. I will give you that sometimes its not he first page of google that the answer comes up on, or you might have to read a whole big article to get it, but I would say 99% of the time you can find it on google. Also I would say 100% of the time so far that if I couldn't find my answer on google I just went to stack overflow and within 3 hours I normally had an answer to my question/error with multiple examples of how to fix it. There is a huge base over at stackoverflow which will help you almost instantly and provide well thought out help.
VC11's condition variables are powered by ConcRT's user-mode scheduler, not Windows's kernel-mode. Therefore, this does not introduce a Vista+ dependency. (I *want* to introduce one for call_once() - our current implementation is extremely slow - but I didn't have time in VC11.) We will be able to get C++11 threading working on XP, no matter what it takes - we will go all the way down to atomics if we have to. (Having &lt;atomic&gt; handy will sure be convenient - that depends on compiler intrinsics (and inline assembly that I want to nuke), not the OS). Currently, the STL's Vista+ dependencies are few and far between. We added some calls to InitializeCriticalSectionEx() that we'll have to downgrade, and there's some FlsAlloc() that needs to be TlsAlloc() again. I can't think of many others off of the top of my head, but there aren't many. The CRT and MFC have much more work to do.
Remember that in order to perform operations on a field, it probably has to be extended to int. You may end up saving space *in the struct*, but adding extending/packing code wherever you use it. That adds code, and adds time. If you have a lot of pixels, that may be a good trade-off. if not, maybe not.
Yea I had a feeling there weren't going to be many books. I knew about the online gnome tutorial thing but when I learn stuff I like an old fashion book, even during school if offerred an online/ebook or a textbook I take the text book everytime, especially since I can use it when I'm travelling with no issues. But thanks anyway
Not exactly my teacher, this is a project for my CBSE Boards, which is like a standardized 12th standard exam every student has to give. I'm totally at the mercy of an external examiner, who may or may not disqualify me for using one. I'd like to be on the safe side. I also refuse to make a by the numbers railway schedule, so yeah :P Edit: This is in India, btw.
Other than the language being old, it was a very nice in the day.
I'm not a game developer, but it doesn't sound like you are expected to be one either. So the approach I would take would probably have some sort of a MovableEntity based class with Ship, Asteroid, Projectile, etc implementations. They would each implement some sort of a move function and a draw function. Then a game loop would just need to check for user input to modify the ship's angle and/or velocity, check for input to create a new Projectile entity, and then iterate through all existing MoveableObjects and invoke move and draw. After that you can put in some collision detection and go from there. Not saying that's the best approach (check out /r/gamedev), but if I were in your position I would go that route.
I don't have any big qualms with it, but there's that feeling of 'std::vector/&lt;algorithm&gt; would have done this in 5 seconds' every time I have to do something manually. Other than that, its fine.
What school is that just so I don't send my kids there?
Its in India, so you're clear :P. **Every** school here has to teach this. Standardized national curriculum.
That creates a flicker which I was trying to avoid. Constant flicker.
Well, it kind of works out. Those who are actually going to take up programming learn C++11 on the side anyway. Those who won't don't care. Although it sometimes frustrates me to death to manually have to do something when a standard library function could have accomplished it much easier and faster.
Yes you could. I worked on such a system. All integer data types were 32 bits. (This was before 'long long' was standardized.)
Again, I'm doing this just for a school project. That's it. Learning SDL and SFML on the side.
start here: http://www.delorie.com/djgpp/doc/ug/dpmi/farptr-intro.html edit: this is more on topic for turbo c http://ctechnotips.blogspot.com/2012/04/graphics-video-memory-in-c-using-far.html 
For Node.js: http://tufao.googlecode.com/
Ah, changed 0x0F to 31 now. Pfft, like I test any of my code. Have a bunch of upboats.
&gt; That creates a flicker which I was trying to avoid. Constant flicker. Ahh yes, I have some real nostalgia for the classic days of DOS graphics programming. What you need to do, to prevent flickering, is to implement a technique called double buffering. It works like this: * Create a buffer in memory that is big enough for the entire screen. The formula for the size is (screen width) * (screen size) * (bits per pixel). This buffer is now known as the "back buffer". * The actual memory that represents the screen (the memory your putPixel() function writes to) is called the "front buffer". * When you draw a sprite onto a memory surface, it's called blitting. You can blit your game sprites directly to the screen, but that causes flickering. * From now on, *don't* blit directly to the screen. Blit every piece of every frame to the back buffer instead. * When you're completely finished drawing the frame, blit the back buffer to the screen as a whole, and continue on, The question of how to move around an object like a spaceship is a different question. A spaceship is something called a sprite or "bitmap". They mean the same thing. It's just a block of memory. It's not actually rectangular, but it helps to picture it as a rectangle. That rectangle of memory has an entry for each pixel that tells the color. To draw a sprite, you draw each pixel in the sprite's buffer to the corresponding position in the target buffer. So pixel 0, 0 in the sprite might be drawn at 0, 0 in the buffer. When you want to move the object, you apply an offset. So say your spaceship should be drawn at coordinates 10, 10 on the screen. When your putpixel function goes through the sprite and draws its pixels, it should add that offset to each pixel position. So pixel 0, 0 of our sprite would be drawn at 10, 10 in what's called "screen space". Honestly, your teacher seems to have things out of order. You shouldn't have to write your own sprite loading and blitting code before you understand concepts like "screen space". Not to mention that loading and blitting sprites from disk is a laborious and complicated process, unless you're happy to use .bmp and limit yourself to a single bit depth.
The normal way to do it is to clear the whole screen between frames. Long, how to move with math: http://blog.wolfire.com/2009/07/linear-algebra-for-game-developers-part-1/ Short: Keep an x,y value for each object, add or subract from/to these values each frame, or while a key is pressed for the player. use a speed variable to know how much to add or subtract (and use a acceleration variable to increase the speed var if you want), Redraw the whole screen and everything will move. back in the mid-ninties when i used TC++ for gfx development we prefered mode13h where you have the screen mapped to a memory buffer and use memset/memcpy to draw sprites to the screen as it was way faster then graphics.h
It's extremely slow. edit: I have tested it and it was very slow. I remember it was doing something like 20-100 requests / second. Also, the license is very bad. I don't use code which is licensed under a restrictive license, is bloated and is slow. edit 2: The author seems to be criticizing nginx. I don't think he's in a position to do that given how bloated and slow his framework is.
You might call me retarded or anything at all, but that's exactly the OS I wouldn't run any kind of web server on. 
How is LGPLv3 "very bad?" I confess I've not benchmarked it, but I thought its API was a bit simpler than Wt. It doesn't look bloated to me.
My mistake, I'm not sure which part required licensing for commercial use. I believe it was the cppdb. Either that or cppcms' license has changed. The API might be simple and nice, but the resulting binaries, libraries and the performance really make it look like something bloated and slow. I have tested it on a quad core i7 950 on Ubuntu with kernel 3.3. Even node.js is faster than cppcms.
Nope, cppdb switched from LGPLv3 to boost/MIT. There's not really any reason to use the commercial license - all it does is remove the LGPL requirements. I'll have to benchmark cppcms myself. These claims of it being slow and bloated are news to me.
&gt; The whole point of introducing them was to move the issue of reducing expensive copies over to the class designer rather than having every application programmer fretting about premature optimisations. This is not true. The whole reason std::vector&lt;std::auto_ptr&lt;Foo&gt;&gt; doesn't work (and is actually forbidden by the standard) is because of a lack of move semantics. std::unique_ptr has move semantics and is able to be used safely in containers without reference counting. Bottom line: There are multiple areas that benefit from rvalue-references and move semantics.
&gt; This still won't achieve 'optimal' performance. You're still denying operator+=(...) the opportunity to optimise "last" and "addr" because it will have make copies of those. Yes, but by passing them by-value you are assuming that operator+= is implemented in such a way that it makes a copy of the passed argument. And if you are wrong (which is assured in this case), then you added two copy overheads. In fact, this is another example of the pass-by-value drawback: we may "forward" the argument to another function and we cannot or don't want to make any assumptions about whether it will make a copy of it.
&gt; This is not true. The whole reason std::vector&lt;std::auto_ptr&lt;Foo&gt;&gt; doesn't work (and is actually forbidden by the standard) is because of a lack of move semantics. This doesn't make what I said untrue and isn't true either. auto_ptr's only sensible use was to facilitate RAII for resources allocated dynamically. auto_ptr *could* have had a reference counted implementation, and been used in containers safely (without rvalues or move semantics being available). That wasn't a design goal though. vector&lt;Foo&gt; is now what you'd hope to be writing in most C++ these days, moving unique_ptr/shared_ptr to members inside the Foo class to ease expensive move operations. This is what I mean by the class designer handling the expense of copying or moving objects.
&gt; I think you are one of those confused people I mentioned in the post ;-). Nope. I said *almost* ;). All of the cases in your post should use pass-by-value. The email example in particular. &gt; if you are not planning to make a copy of the argument, pass-by-value will give you a copy overhead every time you pass an lvalue. No disagreement here. Every example in your article, however, mandates that at least one copy needs to be made at some point. You then went on to point out that if you take references you run in to a bunch of 'combinatorial explosions'. Pass-by-value or take r-value references (since many of your examples are basically glorified forwarding functions, you *can* just use std::forward()) and you avoid those headaches. &gt; There is nothing std::string can do to avoid a call to the copy constructor when I do something like: string s ("foo"); cerr &lt;&lt; s; I wouldn't advocate passing by value in this case. Clearly you need to take an r-value reference. It is worth pointing out though, that if you did this... cerr &lt;&lt; string("foo"); ...that we'll still get a nice move instead of a copy. From your post: &gt; The only catch is that it works at compile time. So what seems to be missing is a similar mechanism that works at runtime. Overloading (diverging code paths), or pass-by-value (where we 'pay' by way of unconditional copies and/or moves at the call site, determined by the compiler, for any combination or lvalue or rvalues) is how we do this. How would you prefer it to happen? I'm 90% sure you could emulate what you want with a smart pointer but thoughtful API design still seems to hold all the answers.
&gt; auto_ptr could have been had a reference counted implementation No*. auto_ptr was specifically designed for single-ownership. It transfers ownership on assignment. &gt; vector&lt;Foo&gt; is now what you'd probably be writing in most C++ these days, moving unique_ptr to members inside the Foo class to ease expensive move operations. Again, that is not true*. While values are certainly preferred in containers, there are cases where storing dynamically allocated objects is very helpful. One could write their own wrapper I suppose, but why re-invent the wheel when std::unique_ptr already exists? *NOTE: Well, I wasn't part of the standards committee (as I strongly suspect you were not), so I can't obviously say for certain why the committee made their choices. I did follow the papers and standardization process though and would be very surprised to see any standard committee members (or anyone close to the process) agree with you. Andrei Alexandrescu, Walter Bright, STL... any of you care to clarify?
Me too, it ran fast for what I was using it for. The binary file is big but that was just because I linked stuff in statically.
1) You can't depend on RVO. It's implementation defined. But yeah. 2) In C++98 binding a temporary (rvalue) to a const&amp; can invoke a copy. The standard allows for both a "double temporary" scenario and binding to the original temporary. I think C++11 was supposed to address this, but I'm not sure if it did. I don't have a copy of the standard in front of me atm. In practice I'm sure every compiler out there will elide this copy. **UPDATE** Try compiling this: #include &lt;memory&gt; class T { T(T const&amp;); public: T() = default; }; void f(T const&amp;) {} int main() { T t; f(std::move(t)); f(T()); } // compile with: g++ -Wall -Wextra -pedantic -std=c++11 GCC has no problem with this code even though the copy constructor is private to main(). I think the decay and binding of rval refs to const&amp; without an additional copy is guaranteed as of C++11. I've found a [draft of C++11](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/n3242.pdf) (Feb 2011) and you can check this out in section 8.5.x (Initalizers) &gt; The process of initialization described in the remainder of 8.5 applies also to initializa- tions specified by other syntactic contexts, such as the initialization of function parameters with argument expressions (5.2.2) or the initialization of return values (6.6.3) -- page 200 &gt; In all cases except the last (i.e., creating and initializing a temporary from the initializer expression), the reference is said to bind directly to the initializer expression. -- page 209 Our example seems to fall under the case described on the bottom half of page 208, so should be directly bound (no further temporary or copy is made).
Take a look at whatever you do that you would give you dominant arm up for and make a program to help with some part of it. For example I love playing the RPG Exalted so I made a program that tracked some of my players info throughout the game. Basically find what you love and make a program for it. When that is done do another.
Try to build a collections library. Start simple with just a dynamic array and linked list, then build up to associative containers. If you get that far, just start picking features from the STL and try to implement them on your own. Nice thing about this project is that it's incremental in difficulty and scale. It'll also give you tremendous insight into the patterns implemented by the STL.
I like this idea a lot. I could eventually make a library for all of my audio samples that I use in music creation and it would be useful when organising presets in a VST plugin. Could even to frequency and transient analysis to automatically organise into categories. Thanks, this is a great idea!
I would be very wary of using common data structures (lists, vectors, maps) that are home rolled. The STL almost certainly has a faster, more efficient implementation. By all means, build your own data structures so you can learn and grow. It is a great learning exercise. Regarding suggestions for projects: text adventures are fun when learning a new language. Simple command line tools (perhaps clones of popular Linux tools). 2D OpenGL games are fun and don't require too much graphics programming knowledge to get going. 
And now for my shameless plug for /r/compilers!
Yeah I am somewhat lazy and would generally try to find the fastest way of doing things and I'm sure the STL has a bunch of shortcuts. That said, despite my laziness, I find that to understand something I have a need to understand the principles that underpin whatever it is that I am exploring. 2D OpenGL games sound interesting. I imagine a text based adventure to be quite simple but creative. Thanks for your input :)
If you need reading material, I would suggest looking into the "Effective C++" series by Scott Meyers and "Exceptional C++" series by Herb Sutter. They are require knowing the language already, but are not too advanced and gives a lot of tips and examples of the many "gotchas" of the language. But of course, as others have mentioned, getting experience is the best way improve yourself. Just thought you might need some reading material when taking a break from the code and these books have helped me quite a bit.
Tetris? ~ Peano
I agree that writing something is a great way to deep understanding. For my degree, we had to implement all of the data structures before we could use them from a library. It will help you later in your career when you have to design and implement more complicated custom data structures. Also, the advice above re: "Effective C++" is a great idea. I wish that I'd read that book earlier in my academic career. The same author has a "More Effective C++" and "Effective STL" as well. They are also gems -- read those after the first one.
Scratch a personal itch. What problem would you like to solve? Take something from your labview experience, either redo something or create something that enhances your work with labview. Don't forget UI, get to know wx or qt or something along those lines. There are really good video series on [concurrency](http://www.youtube.com/watch?v=80ifzK3b8QQ) as well as on the [STL](http://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Standard-Template-Library-STL-/C9-Lectures-Introduction-to-STL-with-Stephan-T-Lavavej) both of these by brilliant instructors. These are just 2 of many really generous people out there willing to share their experience. Keep learning.
The point, I think, was to learn *how* implement it; not to try and replace the STL.
Is there an executable on disk? What happens if you run it manually (e.g. from the Terminal)? Does compilation works out fine, without any errors? Are you targeting the right platform?
If you have the incorrect version of The Unarchiver (if you're using that), Eclipse might not be configured correctly because of a bug in The Unarchiver itself. I had an issue with Eclipse when trying to learn to program for Android; I updated The Unarchiver, reinstalled Eclipse, and now Eclipse works just fine. This might be completely unrelated to your issue, but it might be worth a try. Also, Xcode does C++ and, in my opinion, is much better to use. If you have OS X Lion, you can download it for free from the App Store. If not, it should be in your original OS installation disk in the Developer folder; you should get that entire folder onto your computer.
try ./nameOfFile Edited: slash.
OK, are you going to make us assume what language you are using? I know this is a C++ forum but you post has no details what so ever for us to work with. In any event Eclipse is great on the Mac, I use it regularly for Python and web files. I would imagine it would work well with C++ however do realize Apple has XCode which is pretty good. XCode is far easier to get going, supports command line programs and the LLVM/CLang tool chain along with GCC. 
People will [pay you to solve their problems for them](https://www.innocentive.com/ar/challenge/browse). Disclaimer, I am not in any way associated with that site and so forth.)
&gt; I think you are missing the point. If you pass a string by value, a copy will be made, unless you pass an rvalue. I never missed that point, I said it myself ;-) &gt; There is no instance in my version of "email" where a copy construction will occur, unless the caller passes an lvalue or operator+=() can't handle r-values My points are: * In C++ with Rvalues, you would really *like* to assume that everybody will eventually leverage them, or already does. * If you take a const&amp; you can't switch to an implementation that is Rvalue aware later on (without overloading.) * In this particular example anyone using either version of "class email" can reason that you're going to take a copy. How? Well, you're going to return some of that data later on (as you said), and you can't take a reference to something for which you have no ownership (const&amp;) without implicit lifetime guarantees (bad). Given this, throwing a const&amp; in to the API and obscuring the obvious and unconditional copy seems weird conceptually to me. Like your API, it's not a secret. * Maybe the caller can restructure their code to dump their lvalues to you with std::move()? * Maybe an string::operator+=(&amp;&amp;) will be introduced that makes a simple move when the left hand side is already empty (not allocated). If I was writing a std::string implementation, I'd do this. In addition, there are a number of cleaner ways to deal with this issue when using PBV: * Construct the "email_" member more lazily and avoid operator+=(). That's is a private implementation decision. * or: Create FirstName, LastName, Addr classes with your own string ownership and move/copy semantics. That way you can introduce conversion from shared_ptr&lt;string&gt; (urgh), or whatever the hell you want, without ever having to change the "email" constructor signatures ... and all the while avoiding all this fragile, implementation dependent, string reference nonsense. &gt; Also, another point I have to make is that depending on the object structure, a move is not free and can in fact in some cases be as expensive as a copy. *As* expensive, but there's no reason to believe it'll ever be *more* expensive. In a a thread-safe COW implementation of std::string you don't necessarily need any locking to perform the move, for instance.
That is strange... You're probably missing something really simple, like forgetting to save. When you start a new project, do you pick a C++ terminal tool?
Maybe forgetting to build?
OS X is a Unix based system, so you need a forward slash for directories. ./nameOfFile
Yeah... I have reinstalled probably three times and Xcode around twice. If its a matter of the OS, I can muster up the thirty bucks, or wait til next month when mountain lion comes out or whatever animal it is next.
Do you have to click "start a project" or something?
Just installing XCode won't do it. You need to install the command line utilities. 
4.5 or 4.6, I need my libraries to work on GCC and MSVC so I haven't tried to see if it's changed in 4.7.
It would be more efficient to make SomeLargeData movable instead of using unique_ptr. Also the code would be much cleaner.
An oldy but a goody, from the mid-90s. The C++ standard insists that empty objects (no data members) occupy space. When composing objects, this can cause bloat that can be avoided using this optimisation. This is one instance where a private base class could be better than a private member (composition). This optimisation is used throughout the GNU C++ standard library. &gt; Like any good optimization, it makes the implementation a bit messier, but doesn't affect the interface.
4.5 definitely doesn't work even with vectors, in my experience. Dunno about 4.6, but it's worth making the jump directly to 4.7.1
Works for me in gcc 4.6.1.
This is interesting, but I'm not sure that I understand the point. If you're in a such a grueling environment that 4 bytes per object instance is worth these hurdles, wouldn't you be a lot better off simply working with C? 
&gt; If you're in a such a grueling environment that 4 bytes per object instance is worth these hurdles, wouldn't you be a lot better off simply working with C? What good would an empty struct{} be in C? ;)
Boost.Context didn't make it. :-( Hopefully 1.51..
MSVC uses Concurreny Runtime. It seems to be a fairly thin abstraction of the Windows API.
The standard does not specify an implementation. AFAIK, MSVC has an underlying thread pool (or something similar to utilize free hardware threads) which is used when async() is called. GCC does not implement a thread pool, and defaults to running the task synchronously.
C++ can be just as space-efficient as C.
The standard doesn't even guarantee that execution will happen in a separate thread, let alone in a thread pool. If you really want a thread pool, you'll have to write your own or get a thread pool library.
Another thing is being able to stash an 8 byte object in to a CPU register.
Yes, VC's async() is powered by ConcRT. But ConcRT is not a "fairly thin" wrapper around the Windows API. See http://msdn.microsoft.com/en-us/library/ee207192.aspx for VC10 ConcRT's overview: &gt; The Concurrency Runtime uses a cooperative task scheduler that implements a work-stealing algorithm to efficiently distribute work among computing resources. For example, consider an application that has two threads that are both managed by the same runtime. If one thread finishes its scheduled task, it can offload work from the other thread. This mechanism balances the overall workload of the application. &gt; The Concurrency Runtime also provides synchronization primitives that use cooperative blocking to synchronize access to resources. For example, consider a task that must have exclusive access to a shared resource. By blocking cooperatively, the runtime can use the remaining quantum to perform another task as the first task waits for the resource. This mechanism promotes maximum usage of computing resources. Basically, Windows' kernel-mode scheduler is great for dividing computing time between different processes that can't cooperate, but it's heavyweight for dividing computing time between different threads in a single process. When we switched from our original implementation of async() (which directly spun up a Windows thread for every future) to ConcRT, we found that overhead was dramatically reduced.
However, the Standard recommends that when calling async() with the default policy, "implementations should defer invocation or the selection of the policy when no more concurrency can be effectively exploited". The Standard provides recommendations very rarely, so when it does they carry great weight (this is a polite way of saying "hey implementers, be smart and use something that looks like a thread pool here").
I keep getting compiler errors when using unique_ptr in maps. Here is a minimal example to reproduce the error, I tried it in GCC 4.7 and it works, but in MSVC it does not. Using Google it looks like it's an issue with MSVC. #include &lt;memory&gt; #include &lt;unordered_map&gt; int main() { std::unordered_map&lt;std::string, std::unique_ptr&lt;int&gt;&gt; container; std::string key = "hello"; container[key] = std::unique_ptr&lt;int&gt;(new int(5)); } I mean if I can't do something as simple as the above example, there's not much use in trusting the implementation to do anything more complex.
Why would it be more efficient? It might be more user friendly, but it certainly won't be more efficient.
The tutorials at NeHe aren't bad. http://nehe.gamedev.net
This is for SDL but I think it is relevant: [http://lazyfoo.net/SDL_tutorials/index.php](http://lazyfoo.net/SDL_tutorials/index.php)