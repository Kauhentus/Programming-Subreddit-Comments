You've got it the wrong way around: an unhandled exception will terminate your program, so you have no choice in providing at least a minimum of handling. With these error-monads, on the other hand, you can simply leave out the test at the end and use the calculated value, even if there isn't one. Sure, it's UB, but worst case that means that actually it may work, in the sense that some value will be returned, and you'll never even know that something is wrong. I also do not find your example in any way compelling. It is still utterly unclear, using far too many symbols to express in a very non-obvious way something that was crystal clear before, when we were using exceptions. I'm getting the sense that we are entering a new era of `#define BEGIN {` and friends, except now we are using all sorts of weird overloads and doubtful language extensions to simulate functional programming languages. The same advise that was appropriate back then still applies though: if you want to program in Haskell or Lisp so desperately, it would probably be best if you did just that instead of trying to bend C++ all out of shape. 
The `operator*` in `std::optional` is confusing. It's like a pointer dereference. I'm sticking to `value()` and `value_or()` and treat exceptions like asserts. I think `std::optional` needs some more work.
Purchased it. Thanks. 
Type inference should almost always (in conjunction with variable immutability) be preferable.
No! In typical lisp there would be only closing braces without semicolon noise 😉
Chaining together raw lambdas with the bind operator is ugly in Haskell too. Unlike C++, however, Haskell's support for currying functions and do-notation takes away a lot of the explicit plumbing.
Actually about `1.cpp` again, I was thinking about it and realized that there is a constant time solution using a bit of math (which is a theme of project euler). Here are some hints: - (n-1)/d == how many multiples of d are BELOW n and ABOVE zero - There is a formula for the sum of numbers 1+2+3+...+n, an arithmetic series - careful about numbers that are both a multiple of 3 and 5 (multiples of 15), to not sum them twice. Think about it, I was found it really satisfying once I got it. [Here's my solution](https://github.com/Jonathan-Weinstein/OnlineJudges/blob/master/ProjectEuler/1.c), but I encourage you to discover it for yourself first. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [Jonathan-Weinstein/OnlineJudges/.../**1.c** (master → 3b083aa)](https://github.com/Jonathan-Weinstein/OnlineJudges/blob/3b083aa184654a2a0db934a923e6bac0665bb596/ProjectEuler/1.c) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djs18fg.)^.
Why though? I've worked on codebases which do this, and it uniformly seems bad - it makes it significantly more obtuse to figure out what a function is doing If there's cases where auto makes something cleaner (iterators) then i'm all for it, but hiding types like auto v = a.get_int() just obfuscates things
The codebase is bad, not this practice. First, `v` and `a`, or in general any single-char variable name, are just plain bad. Second, `get_int` makes it quite clear what the type of `v` should be. The addition of type names when you are not trying to explicitly cast is pointless manual effort, akin to braces/semicolons. Sure, it's usually not that much extra effort and it may, in a few cases, improve readability, but I'm saying variables should be inferred by default, not strictly inferred whenever possible.
Its not a literal example, i'm talking about a case where you have a function that returns an int, hiding the type in that case seems to make the code more obtuse not less
If the return type of a function is not obvious, then the function should probably be renamed. Without specific examples, it's hard to say anything more.
As I was talking with you on #rust, if you have that debate even at the formalization level, imagine it released to the public. It has its technical merits but it's a gate over opinionated stances on `a.foo()` vs `foo(a)`, a question of style that gets into the language (**for call-site**).
In many areas, some of them that I don't have any experience. Some examples: videogames, computer vision, data processing, video processing, finance, industrial programming, networking, desktop applications.
I'm not sure what /u/Porges is referring to specifically, but you can see a working (on clang trunk) example of this at https://github.com/toby-allsopp/coroutine_monad.
both styles exist; the point is the draw to x.foo() is 'a carrot', for *existing conveniences* : ease of discovery through IDE, ease of reading and writing. ```a.mul(b).add(c.mul(d))``` - much closer to ```a*b+c*d.``` no one wants to write ```(+(* a b)(* c d))``` ... operators/functions are easier to comprehend when closer to their operands. The convenience when writing that expression in an IDE is amazing, you get context-relevant suggestions at every step. It's a godsend when dealing with big sourcebases and complex APIs (like graphics,GUIs). **the fighting already happens**, because the IDE feature is SO good, people have a strong draw to put everything in the class. The draw to foo(a,b) is "the stick": in the C++ world *we know there are hazards with class coupling*. Just adding the UFCS feature *eliminates the hazard*, simplifying the decision about style. There exists a means of **having our cake and eating it**. Allowing the IDE-friendly, reader/writer friendly syntax for **all functions**. With the 'middle ground', a compromise where ```foo(T* this,..)``` must be used to enable UFCS , there is no ambiguity; 'a.foo()' would still tell you 'search the for class, or search for ```foo.*this``` .. pretty easy to add to your 'grep script' or whatever - infact it's much easier than searching by class, because it's an extra step to find the 'class name' associated with the function name. We have solid IDE's nonetheless. If people really want simple search ability, they could stick to C, without all the polymorphism/overload ... C++ is complex to use but it's power gives us nice tools *like* QtCreator or the clang-based plugins. you're going to use a C++ compiler to compile the program - as such the whole program information is available to resolve everything, and tell you whats what.
&gt; opinionated stances on a.foo() vs foo(a), **conflict that we already are stuck with.** The purpose of UFCS *is to reduce the conflit*, by eliminating the ```a.foo()``` disadvantage (*coupling*). But because the . style "advantages" exist, *the conflict continues*. The real conflict is not over the *style*, it's over the *location* (inside the class, or outside). And that is why we are cursed having to refactor code back and forth. If it *was* just style, it wouldn't matter. you can keep your callsites *however they are*, and fix the coupling/access-rights issues *independently*. Free-functions are already polymorphic thanks to overloading, i.e. foo(Foo), foo(Bar) and x.foo(), y.foo() foo(x) foo(y) mean you haven't been told anything by the calling style. it could even have access rights, because of 'friend' :- https://www.tutorialspoint.com/cplusplus/cpp_friend_functions.htm .... *it could still equally be part of the internal interface* foo(x) could also just be a wrapper to an x.foo() that happened for refactoring :) As proved by operators and the rejection of classic LISP by the mainstream the infix-approximating style is superior. And actually Functional languages and modern lisps also go further allowing the chaining style - * clojure threading macro ```(-&gt; (foo a) (bar b) (baz c))``` * F# piping ``` foo a |&gt; bar b |&gt; baz c``` * C++ mbrfn calls ```foo(a).bar(b).baz(c)``` (for comparison) ... **everyone wants this style**, where it's possible. No one complains about the existence of those styles in clojure or F#.. they just get on with using it, *because it's so helpful*. haskellers work the other way by default (clearer for lazy eval i'm told) ```baz c $ bar b $ foo a``` but I usually implement F#'s thing for clarity there. their default '$' looks gross initially, but after a bit of time dabbling with the language , it grows on you (the elimination of parentheses). But to me the forwards style is just more intuitive, because of unix pipes (and familiarity with OOP calls :) ) https://clojuredocs.org/clojure.core/-%3E http://theburningmonk.com/2011/09/fsharp-pipe-forward-and-pipe-backward/
another benefit to the 'a.foo(b)' style is clearer naming:- ```copy(a,b)``` ... what does that do? .. because we can put trailing prepositions:- ```a.copy_to(b)``` ... much clearer ```a.copy_from(b)``` .. as is this It's much more obvious that the preposition applies to the *following* arguments, not the *preceeding* one. It doesn't really help with 'free function' style:- copy_to(a,b) .. does that mean 'copy to a... (from b)?' or to b (from a) ? copy_from(a,b) ... does that mean 'copy from a (to b)' or a (from b) ?
You can try `#pragma message STRING` or `_Pragma("message \"STRING\"")`. The latter can be wrapped up in a `static_print` macro, even; the only drawback is that Clang will trace the ever-loving intolerable fuck out of it if you have to pump the argument.
`#pragma message` works on GNU 4.0+/-compatible, MSVC, Clang, and -compatible/-derivative.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/functionalprogramming] [Functional Programming using C++ - Introducing functional programming • r\/cpp](https://np.reddit.com/r/functionalprogramming/comments/6la7p2/functional_programming_using_c_introducing/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Nice, have been meaning to look more into FP, will add the rest of the videos to my TODO list. I particularly like the use of Sublime rather than slides, have never seen that before.
_If_ it happens, this kind of discussion, which is my point, is what I'll look to evade as much as possible. Regarding your point on "we already have it", we don't have freedom to switch at call site, which is what I meant.
sure ;what we already have is *conflict*. Bill: where do I put this function? well, I want 'dot-autocomplete' to work, so everyone can find it (and I can remember it a month from now), so i'll put it in the class. Fred: argh.. now my class has 5000 members and it depends on every system. lets cut it up. lets refactor all the calls. **lets throw the whole sourcebase away and start again**. As an intermediate step, let's make a wrapper. foo(a,b){a.foo(b);} Bill: arghh.. f, now I can't read it or use the library. lets start again. but next time I write a function.. I'm ready for the argument. i'll write (bar(a,b){a.bar(b);}) just incase, so that we've got both options.. All we need is UFCS, and 'fred' and 'bill' both get what they want. easy to read and write, easy to find everything by pressing '.' ,and classes that *don't* explode drawing in whole project dependancies (* and yes, I'm speaking from real world experience) C++ has lots of things like this... 2 options that are kind of broken. so you bounce between them. The solution is to FIX one of them. Yes it's more features, but the world already pays the cost in workarounds. Better to have a bigger language where the features actually *work*. Like it's taken however long to finally get move semantics forwarding etc to get RAII to do what we need.. it's way more complexity, but now we can really use std::vector well with emplace back etc etc. Imagine if we stoped and said "nah, it's too complex now."
I'm not totally agree on that, create and enter in a directory and invoke cmake with "../" so the build is generated in the current dir require more abstraction that simply saying I want my build system to be this folder, hence the simplicity
It is driven from the result type. There's a talk about the implementation details here: https://youtu.be/ZTqHjjm86Bw
It seems to me that part of the argument you go about resonates with knowledge such as [Data/Object Anti-Symmetry](https://books.google.com.br/books?id=_i6bDeoCQzsC&amp;pg=PA95&amp;dq=%22Clean+Code%22+%22Data/Object+Anti-Symmetry%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjkhcPtwO7UAhWFx5AKHcd8Dv4Q6AEIKDAA) and code architecture as a whole. IMO, IDE features is low in my priority list to be decisive about it.
&gt; never capture a std::shared_ptr&lt;&gt; in a lambda This only matters if you're actually storing the closure permanently, like you are with the std::function. Typically the closure goes onto a queue, gets invoked, and then comes off the queue, and gets deleted, which in turn will release any shared pointers that have been captured. Case in point, the standard patterns of usage for ASIO capture shared pointers to the connection which get decremented/deleted when the callback goes out of scope
True. But in order for it to matter you have to know beyond doubt that your lambda won't be permanently stored. Queues are not always used. I consider this good defensive coding practice; if your lambda doesn't have an explicit reason to hold a reference to the target, then it shouldn't hold a reference to the target. It saves you from getting surprised later when someone makes a subtle change.
It's quite straightforward to reason about when a lambda will be stored - if something takes a callback and is known that it will run it only once, it won't store it. If it is going to invoke the callback multiple times, it's reasonable to assume that the function will be stored and therefore the lifetime of the captures will be extended to the lifetime of the function invoker.
If executor is taking a shared_ptr and calling 'on_complete', then you can be certain that the instance of 'my_class' exists at the time in which it is called using a raw pointer would be fine here. Using a weak_ptr sends the wrong message to the user, saying that obj/weak_obj might not exist when the callback is called, in which case who owns that std::function&lt;&gt; that is being called? For this code, why is 'my_class' even needed? Why not just have executor take the std::function&lt;&gt;? EDIT: Another approach is to use std::function&lt;void(my_class&amp;)&gt; then pass 'this' to the callback
It's only straightforward if you wrote the code that's calling the lambda, and that happens to be your standard pattern. If you're talking about libraries, someone else's project, or a team of coders working on your project, all bets are off. You never know what one of them might do; pattern selections that seem obvious to one person will often be far less so to another. This way works for me; it's safe and predictable, and that particular badness vector is totally eliminated, regardless of what other coders may do in the code I'm passing lambdas to. Safe habits are good IMO. *shrug* To each, their own. 
It's a deliberately simplified example to illustrate the problem; not an actual use case. (edit: I should probably clarify that the reason this issue came up in my code is that I have a number of callbacks involving polymorphic objects. The object that `executor` is a placeholder for operates on the base type; the callbacks need to operate on the subclass type. It's simpler if you capture that pointer rather than try to deal with a fun solution for polymorphic callbacks or force the callback to cast the pointer.)
I didn't state it was _just_ style. I said "_a_ question of style" that will do get into the language. As I've already stated, __technical merits aside__, the time we start see codebases where there's a mixture of `stderr.fprintf("%s %s", "Hello", "World")` and `fprintf(stderr, "%s %s", "Hello", "World")`, or people arguing over one another, instead of pondering over useful things like [Data/Object Anti-Symmetry](https://www.reddit.com/r/cpp/comments/6l22gi/whats_the_situation_on_ufcs_these_days/djsasv1/?context=2), will be strange times, at last for me.
 &gt;The object that executor is a placeholder for operates on the base type Sounds like your real problem here. Either be the executor, or the subject. Not both. This has little more to do with a lambda than any other data type that can hold a shared_ptr.
Anyone using this library? Any real world examples?
I don't think that the recommendation giving by the op is correct. The reason for this assumption is the way that the code is perceived by the reader. Passing as shared pointer to the capture doesn't have a visual side effect same fore storing the lambda in a variable. Now, if you look at the generated code by the compiler you will see that lambda functions are more or less syntactic sugar over functor classes. Basically, the compiler will create a class for you that contains the body of your lambda in the operator() overload and capture variables are passed to the constructor. If you're assigning a lambda to a variable you're constructing this object. Now, if you keep this model in mind you would immediately notice that if you store the instance object to your functor that has a shared member variable that as long as this value does is not destroyed your keeping a reference around (with the given memory implications). 
The code shown in the article is an example, *which is contrived for the sole purpose of showing why the problem exists and how it might be triggered.* Nitpicking the context or presumed purpose that a contrived example might exist in or serve, thoroughly misses the point of the article. That code was written as an illustration for the post, and never even compiled. It doesn't exist in a real-world project. As for the real code I have that uses a similar technique, it exists for a reason. Polymorphic callbacks do not, AFAIK, exist in C++11. I had a choice: either put in a lot of ugly code (templated and otherwise) to arrange for unique callback signatures to be correctly applied, or just capture the correctly-typed pointer when the lambda is created, where I already have it and don't have to cast it. I did the former first; it ended up being black voodoo magic that nobody less than expert-level in C++ is really going to get without a whole lot of effort. So I ripped it out, and the latter has proven much simpler to understand and trace, as well as less code to maintain. 
A fair view, I suppose; as I said above, to each, their own. :) It is my personal view that (in a memory management context) a lambda should not have either partial or full ownership of anything when it isn't executing. I feel that it needlessly complicates object lifecycles. To me, a lambda should be something that is owned by things, not something that owns things. Seems that isn't as common a view as I figured it would be, but oh well.
It's not nitpicking. You've presented a single "contrived" (by your words) example and nothing else. What else do you expect a response too? In this sentence you capture the real mistake: &gt;If you then store such a lambda on the object for which it has captured a shared pointer, you’ve just created a scenario where the object owns a reference to itself, and thus can never be deleted. Two mistakes were made in the example. 1) "Don't store an shared_prt in a data member that could be owned by that ptr." 2) "Don't store a shared_ptr in an object that should not be maintaining the life times of that object" &lt;- related to the first point - You fixed issue #2, which repaired your memory leak. Saying don't ever store a shared_ptr in a lambda is stretch and is in no way support by your single example (the only thing provided, besides some brief text exampling the example). It's like saying don't drive your car because you might drive off a cliff. Going off the cliff is the problem not driving the car. The car is the thing that brought you off the cliff, but you could have also walked off it or ridden a bike. The real advice would be to not do things with a car/bike/walking that would put you in a situation where going off the cliff is possible.
&gt;&gt; stderr.fprintf("%s %s", "Hello", "World") and fprintf(stderr, "%s %s", "Hello", "World"), Thats a great example of a case where you can separate 'output/modifictaion' from inputs. The stylistic switch has great utility. There's a big difference here between 'the first parameter' and 'the rest'. stderr.print("hello","world"); outputstream . printstuff( ..sources .. ) ^^ ^^ mutable immutable maybe another way would be ```stderr &lt;&lt; format(fmt, params).``` the worst case is where inputs and outputs are mixed in the same parameter block, IMO. Having those options will let people make it clearer, where in the past omissions in the syntax system have made it harder (hence the ambiguity, and existing confusion of styles) stream operators themselves .. i'd argue are a case of awkward syntax which happened because we didn't have 'variadic templates' at the beginning. Overloading the bit-wise operators for file IO is an extremely messy decision , but now with variadic templates we could clean all that up.. ```file_object. write( a,b,c,d,e,f,g,h)``` instead of ```file_object &lt;&lt;a &lt;&lt; b &lt;&lt; c &lt;&lt; d &lt;&lt; e &lt;&lt; f &lt;&lt; g ``` r.e. any sort of piping i vastly prefer the functional languages idea of piping values through functions, if we really did want an arrow like operator to indicate direction of movement we could have nice consistent naming rule that arguments are always immutable, unless you postfix it with '_into' or something like that
it's also not just stylistic, it's discovery herb sutter's paper clearly explains this point: when you type 'file-&gt;' , the IDE will give you the drop box of suggestions. He does explain he does expect the proposal to make the old C stuff easier to use. let me find it,
https://isocpp.org/files/papers/N4165.pdf here we go. If you are still skeptical , please please please read this. I cut paste but you can read the original with better formatting etc. He's a better communicator than me. 3. Discoverability and tool support: “Start with the argument” puts intent up front This section may sound philosophical at first, but it isn’t about philosophy. It’s all about practicality. More importantly, I am becoming convinced that member function call syntax is actually preferable in any language, because it puts the argument first rather than the function first. When you start with the func- tion name, the list of “objects/expressions you can pass to that function” can be undecidable and possibly infinite. When you start with an object or expression to be manipulated up front, it’s easy to narrow down a useful list of “things you can do to that object.” This aids programmer productivity, discoverability of APIs (what can I do with this object), and tool support. It’s friendlier to editors and tools First, “start with the argument” is friendlier to editors than “start with the function.” Consider the follow- ing examples, where ▓ is the current cursor position: Which is easier to provide autocomplete for, A or B? Let’s start with A: A: f(▓ Case A is fundamentally hostile to providing useful autocomplete suggestions. I speculate without proof that it might be halting-hard, because the possible valid set of expressions that can be passed as an argu- ment is often infinite. For example, to decide a candidate list of “what could the programmer intend to pass to f?”, perhaps we might try to enumerate all possible variables in scope to see which could possibly be validly passed as a first parameter to some possibly-overloaded f in some scope—including via ADL on each such candidate object, and including after conversions, etc. That heuristic alone would be very diffi- cult in itself, and it would be completely insufficient in real code where often the programmer actually intends to pass not just a simple variable x to call f(x), but rather to pass an expression such as to f(x + y * z)... how would autocomplete reasonably find such a valid suggestion, and come up with a usefully short list of possible intended parameters? Now consider case B: B: x.▓ Case B is friendly to providing useful autocomplete suggestions, and our editors do it all the time: Note: This means we would immediately get another carrot to migrate code from C to C++, namely by making many C libraries (even large parts of the C standard library) easier to use, and with much better autocomplete and other tool support by doing nothing more than adopting the new C++ member call syntax. For example: // C code void f( FILE* file ) { fseek(file, 9, SEEK_SET); // proposed new C++ code void f( FILE* file ) { file-&gt;fseek(9, SEEK_SET); // arg is buried; no autocomplete help // nice autocomplete after “-&gt;” This example uses the C standard library just to show how well it works “out of the box” with C code, but larger C libraries would benefit even more by making their code more navigable and discoverable (and put them in a position where it’s easier to start adopting even more C++).
&gt; the time we start see codebases where there's a mixture of stderr.fprintf("%s %s", "Hello", "World") and fprintf(stderr, "%s %s", "Hello", "World") .. and as I keep explaining *that already happens*, we do have a mix of styles, because some people stuck with the older C functions .. quite rightly because the C++ 'standard' idea of using bit shift for file io is utterly fugly, (and of course there are constant arguments between the people using 'fwrite', and the people who insist it's "obsolete"). But now in 2017 we can write much better libraries using the variadic templates .. so yes, we will hopefully clean things up, and it's for the better. The arguments will end when the language has the right features, such that one option is unambiguously *better*. 'fwrite' is crap because it doesn't give a clear indication of where the output is. '&lt;&lt;' is crap because it is originally the bit shift operator in the domain of C-like languages, and some more general (powerful) form of piping in functional languages .. but it does at least let you avoid specifying a parameter over and over again. But now we have a much better means of doing that - 'the variadic template'. everyone sane should agree that a.write(args...) is much clearer than the flawed past options, and a cleanup/modernization will extend the lifespan of a sourcebase.
I'd also like to know
&gt; A lambda that captures nothing is simply a function pointer; This is not true. A lambda expression produces a function object, no matter capturing things or not. It is an extra special rule that allows object created by capture-less lambda to be convertible to a function pointer.
what i can imagine here is : you make your nice 'file object' ``` class File{ ... value read&lt;T&gt;(); .. write(const T&amp;) } ``` then the 'variadic function' to 'write multiple' can be a templated free function, useable with all file objects, *without having to be a member.* tempalte&lt;....&gt; write(Y&amp; output, const T&amp; src, const Args... rest) {.. output.write(value); output.write(rest); } file.write(a,b,c,d); console.write(e,f,g,h); string.write(a,b,c,d,e,f); // no more temptation to abuse Addition Operator for string concatenation! what happens at the moment of course is that people will have to go through hoops to get that sharing (embed the file object in some wrapper that gives the helpers, or further pollute their implementations)
Fair point. But when using it, it's equivalent from the perspective of what you're writing. The type matches, whether literally or by a conversion under the hood.
**because we want the exact opposite: a.foo() -&gt; foo(a), for reasons explained here** https://isocpp.org/files/papers/N4165.pdf herb sutter explains it in greater detail, more clearly than I can. it's all about autocomplete, which vastly improves the discoverability and usability of libraries with modern tools, and the times when you *can* clarify the intent by the position of the parameters. And the ability to reduce parentheses, writing in an infix style. a.mul(b).add(c.mul(d)) .. distance between functions and their parameters is reduced, just as with infix operator style, "```a*b+c*d```" I personally argue that the ability to use trailing prepositions makes inputs/outputs clearer. e.g. "```a.copy_from(b)```", or ```a.copy_into(b)``` .. instead of "```copy(a,b)``` (what does that do?? do values flow from left to right or what? " copy_from(a,b) .. does that mean a from b or b form a?? In the member-function syntax, from is trailing, so it is clearer that 'from' applies to 'b'. &gt; for library authors, any large program has layers of internal 'libraries'. the ```a.foo(b) ``` is superior, but results in excessive coupling: in order to get that 'dot-autocomplete' discoverability (the benefit and demand for that scales as your your program gets bigger), people risk the hazard of excessive coupling (stuffing things *into* the class, just to get the autocomplete). I give you an example of 'file write' and then separating a convenience using the variadic args (from the conversation above) file.write(a,b,c,d....) ^^ ^^ output inputs console.write(a,b,c,d..) the actual 'objects' need only implement 'write(single parameter)', the 'variadic template' to apply multiple parameters could be a free-function template, but you'd get the benefit of that convenience for all potentially writable objects, without needing to go in and cut/paste or deriving/embedding in some stupid wrapper just to extend the interface with helpers. Some people fear confusion, but I would be 100% happy with a middle ground where you must opt-in to UFCS with an explicit "```this```" argument, then it isn't 'applied by accident'. In my use-cases of 'clearer naming', that would be highly advantageous.
My point is that you have to *know* what "`-H.`" means, and what "`-Bbuild`" means. So what would an interested reader do? They'd look it up... and fail to find an answer, because the flags are internal-only and undocumented. With an explicit command line it is more clear what is going on. Yes, you still have to know when you call `cmake` that you're passing the path to the source directory, but that *is* documented with CMake, and in fact that's the canonical usage of it in other CMake-using projects.
If you want a base type to be used for this sort of thing you could do something like this: https://godbolt.org/g/kw9TSi #include &lt;functional&gt; class INotification { public: virtual void onCompleted() = 0; }; using INotificationHolder = std::function&lt;INotification&amp;()&gt;; template&lt;typename T, typename... Args&gt; INotificationHolder make_inotify(Args... args) { return [impl=T(std::forward&lt;Args&gt;(args)...)]() mutable -&gt; INotification&amp; { return impl; }; } class Implementation : public INotification { void onCompleted() override {} }; class Executer { public: void submit(INotificationHolder holder) { holder().onCompleted(); } }; int main(int argc, char * argv[]) { Executer executer; executer.submit(make_inotify&lt;Implementation&gt;()); } With clang this all compiles away, you also eliminate allocations for small implementations, only things that don't fit inside std::function&lt;&gt; will need an allocation
I feel like there is a better way. shared_ptr should not be the default. You want clear ownership. The problem described in the article is pointer ownership. If instead the author used unique_ptr, the problem would have clearly come up when trying to keep the pointer in the lambda.
 template&lt;typename T, typename Args...&gt; auto foo (T t, Args ...args) { return t.foo (args...); } .. also, as clever as this is, it means ***"jump to definition"*** will no longer find "foo" from the callsite (tested in QtCreator, unless there is something smarter out there which can deal with template instances better). I realise I suggested something similar (before I sound hypocritical criticising your suggestion too harshly), so on reflection I might have to write 'write(output,Args...)' per type aswell :) But at least in my instance, the template is there to handle multiple calls to the same routine without repetition. You might just be talking about templated code, but I'm talking about code *everywhere*; the routine use of functions, from any functions, is often guided by 'dot-autocomplete' in an IDE.
The catch in my real-world scenario is that there are a number of objects that have to hold references to any given instance of the class, so unique_ptr wouldn't be appropriate. 
I don't buy into this because the analysis is shallow, without experience. Just imagine the negative consequences, not only the possible good ones. Imagine that out of a sudden the programmer that was used to get from its IDE the old classic member suggestions, starts to get those suggestions polluted with other random ones because an included header now includes another header that have prototypes of utilitarian functions whose first argument type is the same as the type of the object being completed. For some people, this behavior may be fuzzy and unwanted. And this I'm saying restraining myself to this context of IDE goodness, which for me isn't much worth an argument when the issue at hand is code architecture. Architecting code with the IDE as the argument is equivalent to architect the house with the hammer as the argument. I rest my case because I don't want to go further. Thanks for the discussion, but it's what I want to avoid.
I think we might have a miscommunication on what I'm trying to accomplish (though I'm not a master templateer, so I might just be missing your point). Imagine, for example, that you've got an interpreter of some sort. You have a base class that represents a program, and then you have a bunch of actual programs that are subclasses of that class. Those programs then get passed to an interpreter object that executes them (for whatever reason, it's not part of the base program class). When a given program has completed, it issues a callback. The callback is stored on and called via the program object, and the implementation of that is part of the base class. The callback signature is therefore not customized to the program in question (trying to avoid implementing explicit callback code in every single subclass). That's not what I'm doing (which would be too time-consuming to explain), but it would use roughly the same pattern. Ideally, the program object would pass its own pointer via the callback -- but since the callback signature is in the base class, it would be a generic base class pointer instead of a subclass pointer. If I want to access values on the subclass, the callback would need to cast to that pointer (or get access to it some other way). My solution was to just capture the thing in the callback, since it's already available in that context without casting. It made the code very readable. What I'm not seeing is where the above solution helps with this. Again, I'm not a master at templates, so I might just be misunderstanding your point -- I *think* I get what that code does, but I don't see how it helps. Or we might be going for different things entirely. 
Have you tried weak_ptr?
Wt tries to make both frontend and backend programming to use c++. It's kinda laggy(something like a frozen destop UI) on slow or unstable connection, since each event will be sent back to server side slot.
That's what I'm currently using; it's the solution I suggested in the article.
Oh okay, that's a little bananas. Rewriting everyone's build scripts into CMake seems not very maintainable. I don't want another piece that will break from time to time What I was imagining is that you had some cmake library link using something like the interface keyword and a reusable mechanism for forwarding your build environment to other build tools
Still not true when using it. The typical way to hold a lambda to use auto type deduction. The resulted object has the exact type without conversion. We convert it to function pointer or hold it in a `std::function` only when we have special needs.
Let me generalize that statement for you: f(things you don't understand) = Set{bad things}
Doesn't use Boost.Asio, Asio, or Net-TS
As the author of the blogpost said above - to each, their own. Here is a point of view based on my experience. I've been using ASIO for 5-6 years writing bittorrent and http cache proxies. I follow the pattern, if I may call it so, shown by Chris Kohlhoff where you capture a shared_ptr to the connection object in the lambda passed as a callback. In some cases I use boost::intrusive_ptr to avoid atomic reference counting when the connection object is always used by a single thread only, but it's the same. I've never had memory leak issues so far from this pattern of usage because of the way ASIO callbacks work. It feels much more natural and safer to me to use it in this way. As long as there is a pending callback the connection has some work to do and is kept alive, otherwise it's "automatically" destructed.
&gt; The type matches, whether literally or by a conversion under the hood. You oversimplify. The type of a captureless lambda does *not* match a pointer, although it is convertible to a pointer. It's a big difference, whether you see it or not. There are contexts (for instance template argument deduction) where conversion doesn't kick in.
The title is misleading. Reference counting in the context of lambdas create memory leaks only if the lambda objects are stored somewhere where cyclic trees are created. 
I think any reader will understand what that do without going to read anything in the manual. I talking about forward thinking. If I change to the other way I may need to explain to the reader what I actually trying to do, like "making the build in this directory referring the parent that includes it" this is not about teaching the right way to use cmake, far from it, its about how to put things together. If the reader will try to understand more he will find it out
The only advantage of using unique_ptr is usually to avoid the need for using delete. The problem with writing delete after you send the data, is that if the send function threw an exception, you'd have to make sure to delete the data anyway - it's error prone, and makes the code needlessly ugly and complicated.
We use it at our company, it gives us C++ developers an easy way of creating web frontends integrated with our C++ code, with a syntax similar to Qt. 
&gt; The type matches, whether literally or by a conversion under the hood. no, this is wrong. int bar() { return 0; } int (*f1)() = bar; // ok int (*f2)() = [] () -&gt; int { return 1; }; // ok, function pointer // fails: int (*f3)() = [=] () -&gt; int { return 1; }; // fails: int (*f3)() = [&amp;] () -&gt; int { return 1; };
Here is a little known trick which can make solving this problem a bit easier. You do not need to define and clutter the local scope with an additional std::weak_ptr. Instead you can define it in-place using the following syntax: std::shared_ptr&lt;my_class&gt; obj = std::make_shared&lt;my_class&gt;(); obj-&gt;on_complete([weak_obj = std::weak_ptr&lt;my_class&gt;(obj)]() { auto obj = weak_obj.lock(); if (obj) { obj-&gt;clean_something_up(); } }); EDIT Proof of compilation: http://cpp.sh/7gupu
I admit that the current website is not very good at showcasing real world uses of Wt. We're working on a new website at the moment. The wiki contains some links to publicly deployed projects: http://redmine.webtoolkit.eu/projects/wt/wiki/Sample_Wt_Applications. It doesn't do a good job really showcasing Wt, though. Wt is used most often in internal (intranet) applications, or embedded in devices, so there are actually major companies using Wt, but it's not in the public eye that much.
There are some mechanisms (stateless slot learning, JavaScript slots) that do allow you to do some things (e.g. navigating between already loaded pages) without having to contact the server. Wt is indeed designed for applications with a high level of client/server interaction, though. With WebSockets enabled, these updates can be quite small (Wt does not fully refresh pages unless Ajax is unavailable), but of course, these kinds of applications will be laggy if you have a high latency connection. Personally, I'm used to having a relatively high bandwidth, low latency cable connection. Many Wt applications are deployed on intranets, so in those cases it's not really an issue. It would be nice to explore technologies like WebAssembly in the future to see if we can get a full Wt application to run client side, or even achieve some sort of hybrid, where client side code can be written in C++. I'm not quite sure what that would look like, though.
do you have a websocket server example?
Maybe, but that sounds like a problem for IDE's to solve (recognizing functions of the type I mentioned, and treating them differently, should be easy enough), rather than a reason to change the language. Do we really want C++ to be a language where you can only figure out which function is being called is if you use an advanced IDE that correctly(!) finds the right function? I know Visual Studio (2017) still gets that wrong on a regular basis, with F12 ('find function') happily directing me to a function with the same name, but in a completely different namespace that could not possibly be in scope. Basically, if I write f.foo (), I expect a function 'foo' with zero arguments to exist on f or one of its ancestors. I _really_ don't want it to somehow call template function foo&lt;T&gt;(T) behind my back, where that template may be hidden in a header file that gets included from a stack of header files 20 levels deep. Also, OO finally freed us from having a single giant namespace containing every function in the entire program. Don't bring that shit back by promoting functions that are now safely contained inside an object into the global namespace at the drop of a hat. There was a reason people really liked this encapsulation business, and about the last thing we need is a language rule to undo it all. 
Can the mod unban my other thread which is posted today as well? https://www.reddit.com/r/cpp/comments/6lbicx/c_perf_tip_return_by_reference_or_through/ *Edited* Thanks the mod who unbanned my thread. Thanks again!
Wt rocks, in the same way Qt rocks! 
Lifetimes and ownership are hard (maybe not _that_ hard, but still easy to get wrong). I wonder if there are languages which try to express and manage these relationships more explicitly. Seems like going a bit further than Rust would make whole thing unusable due to complexity.
Wouldn't this confuscate the code in comparison to a traditional for loop?
It is quite maintainable actually. Libraries don't change that often and it doesn't take much work to rebuild something actually. That's the price to pay to be able to rebuild a library properly on all platforms easily.
&gt; With these error-monads, on the other hand, you can simply leave out the test at the end and use the calculated value, even if there isn't one. That's incorrect and depends on the API of the monad. Here's a trivial example: auto open_file(const Path&amp;) -&gt; optional&lt;File&gt;; auto parse_file(File&amp;) -&gt; AST; // ... const auto f = open_file("./foo"); const auto ast = f.map(parse_file); You can only call `parse_file` if you have a `File`. You can only have a `File` if `open_file` returns a set optional. The **type system is preventing you from errors**. In contrast, you would have to explicitly add `try...catch`blocks with exceptions, and if you forget to do so... you program will crash. --- &gt; I also do not find your example in any way compelling. I agree that the example in the article is bad. The one I have just written above is much nicer and superior to its equivalent using exception handling. --- &gt; I'm getting the sense that we are entering a new era *[...rambling...]* * No, people want monads and functional paradigms in C++ **because they're useful**. * No, this has nothing to do with `#define BEGIN {`, "weird overloads", and "doubtful language extensions". * No, I don't want to program in Haskell or Lisp. * No, C++ doesn't have a "shape". It's a multi-paradigm language. I want to program in C++ combining the best of imperative/object-oriented/functional paradigms thanks to zero-cost abstractions. Things like monads are really valuable and it makes me sad that people still don't understand how useful they can be for safe and expressive APIs.
Thanks for your work on the channel
&gt;I told him he is making a copy of Info object in each call. He told me reference parameter is a pointer which is cheap. We bought in another coworker, into our argument, who also say his function is equivalent. This is the problem. You can not vote something correct democratically. IMO you should have helped your colleagues understand that copy is being made and why, why argument that 'pointer is cheap' is meaningless and how references behave. 
What it is the problem you get? You probably are missing some libraries, i suggest you use Vcpkg to install any of them if they are avaliable, it will install all the stuff you need and it will compile
Qt can do that. I'm using it to create invoices.
Thanks!
One has PhD in Physics and the other has Engineering Master while I only has Bachelor degree, does not help at all. And they are more seniority than me. They even volunteered to demonstrate coding on my PC to show me how reference parameters work.
Yes this sucks. At such times, having strong support of reference documentation helps. It is a pain in the ass to search for quotable fragments of standard, but it works. Been there, done that. Also, they are likely not stupid, if you give them better arguments than 'i say' they should work. If such arguments do not work, you will at least know who to try to not deal with.
Benchmark both versions and show then they got it wrong. Also add a third version using pointers instead of references for their version of the code and show then that it's faster than their version with references. Or, if they are ok with some assembly, put the three versions on https://gcc.godbolt.org and show then how the assembly is doing a full copy.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
A lambda is nothing but an anonymous class with an overloaded operator()(). It will be created with the parameters you specify, and it will keep those parameters until it is destroyed. This is the exact same behaviour as a normal class. How would "only ownership while executing" work? If you pass a lambda to a thread, should it somehow acquire ownership when the time comes to execute it? How would it do that? If it is executed multiple times, should it repeat the acquisition/release cycle of parameters for each time it is executed? Bottom line you made a mistake, thanks to a misunderstanding about the language. No problem, that happens to the best of us! But you also put some very bad advice online, and when you post about it here and get corrected you don't accept the help you are offered, but instead pretend that your side of the argument also has merits. It doesn't: the advice you give is plain wrong. There is nothing inherently unsafe about using shared_ptr with lambdas. The correct advice, on your website, should be to ensure there are no shared_ptr loops in your software. This is hardly a new discovery though, and in fact the language also offers weak_ptr as a way out of this predicament. 
Your coworkers are correct in that there is 'only' a reference in the function signature. More specifically, there is a reference _to the target object to which all the data will be copied_. The copy still takes place, just in a different place. The fact that they apparently believe the reference itself will be changed as if it were a pointer signifies a rather disturbing lack of understanding on their part, but that won't help you much. You can stick a log message in the copy constructor, clearly demonstrating the copy taking place. Moreover, you can precisely localize it in your function, so you can have before and after logs as well. You can also print addresses of objects to show that the returned object is in fact a copy (i.e. it has the same address as before the function call). If that, plus some timing statistics, does not convince them - well, you can't win them all. It will still work, just painfully slowly. Perhaps you could simply return a pointer? That gives you the option of returning nullptr when no data is available. 
So, this is C++. Lifetime is your job as a programmer. Always. Shared ptr *does not solve make lifetime simpler*, and definitely does not mean you do not have to think about it. It simply makes some complex lifetime arrangements possible. You could state "never store a shared ptr without seriously thinking about it", and you'd be right. Lambdas are nothing special here. However, the lifetime of a lambda *is something you must think about*, because this is C++ and you always have to think about lifetimes for *everything*. If you are using a lambda and passing it to an API, you should have explicit knowledge of the lifetime of the copies of the lambda, *or* a serious understanding of why lifetime cannot matter, *or* enough knowledge that you can bound the lifetimes involved. If your answer ever involves "there is a ptr or reference that is not a unique ptr", this is a huge red flag, because that implies a complex lifetime situation. What I do with stored callbacks is to determine who "outside" the broadcaster owns the callback. They get a shared ptr, or an unregister function, and are responsible for removing the callback when they die (I actually use shared ptr tokens to unregister callbacks, the broadcaster holds weak ptrs). They are also responsible for managing lifetime invariants for the lambda; they are the one thing the lambda can assume "exists" when invoked. 
Those two functions are not equivalent. std::string key1, key2; //your version const Info&amp; val1 = getInfo(key1); const Info&amp; val2 = getInfo(key2); // his version Info val1, val2; getInfo(key1, val1); getInfo(key2, val2); Yours is not thread safe and has global side effects. Why not return a pointer (or nullptr if not found)?
You should just take them up on it then. It should't take more than 5 minutes to demonstrate their misunderstanding. And after that a day or two while they come to terms with the whole situation (five stages of grief), followed by several weeks/months of code review while they try to figure out where else they've made major mistakes ;-) BTW, I'm not entirely certain why qualifications in an unrelated field would be at all relevant when it comes to programming (or indeed, any endeavour outside said field). 
Alright; so both of your coworkers don't know how C++ works. First, reference is not a pointer. Both are abstractions for memory location aka. 'address', sure, but they are not equivalent enough to say that a reference is a pointer. He implied that assignment to the reference will assign the address of the info object to the reference - he was wrong. The value will be copied to the object referred. He would have been right if the parameter was a reference-to-reference but the meaning of '&amp;&amp;' is move in c++11 and later. What he proposed can be achieved using the pointer abstraction to memory location: void foo(Info **info) { *info = &amp;info_value_somewhere; } But that just sucks. Returning the info value by const reference is THE way to go. You are pro. They are n00bs. End of story. :) 
https://godbolt.org/g/EX3xWX Holy ****. Your way is literally one assembly instruction. // your way mov eax, OFFSET FLAT:g_info ret // their "identical" way push rbx mov esi, OFFSET FLAT:g_info mov rbx, rdi call std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_assign(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) lea rax, [rbx+56] movsd xmm0, QWORD PTR g_info[rip+32] cmp rax, OFFSET FLAT:g_info+40 movsd QWORD PTR [rbx+32], xmm0 jbe .L10 lea rcx, [rbx+40] cmp rcx, OFFSET FLAT:g_info+56 jb .L9 .L10: movzx eax, BYTE PTR g_info[rip+40] mov BYTE PTR [rbx+40], al movzx eax, BYTE PTR g_info[rip+41] mov BYTE PTR [rbx+41], al movzx eax, BYTE PTR g_info[rip+42] mov BYTE PTR [rbx+42], al movzx eax, BYTE PTR g_info[rip+43] mov BYTE PTR [rbx+43], al movzx eax, BYTE PTR g_info[rip+44] mov BYTE PTR [rbx+44], al movzx eax, BYTE PTR g_info[rip+45] mov BYTE PTR [rbx+45], al movzx eax, BYTE PTR g_info[rip+46] mov BYTE PTR [rbx+46], al movzx eax, BYTE PTR g_info[rip+47] mov BYTE PTR [rbx+47], al movdqa xmm0, XMMWORD PTR g_info[rip+48] movups XMMWORD PTR [rbx+48], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+64] movups XMMWORD PTR [rbx+64], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+80] movups XMMWORD PTR [rbx+80], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+96] movups XMMWORD PTR [rbx+96], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+112] movups XMMWORD PTR [rbx+112], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+128] movups XMMWORD PTR [rbx+128], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+144] movups XMMWORD PTR [rbx+144], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+160] movups XMMWORD PTR [rbx+160], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+176] movups XMMWORD PTR [rbx+176], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+192] movups XMMWORD PTR [rbx+192], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+208] movups XMMWORD PTR [rbx+208], xmm0 movdqa xmm0, XMMWORD PTR g_info[rip+224] movups XMMWORD PTR [rbx+224], xmm0 pop rbx ret .L9: xor eax, eax .L6: movzx edx, BYTE PTR g_info[rax+40] mov BYTE PTR [rcx+rax], dl add rax, 1 cmp rax, 200 jne .L6 pop rbx ret Show them the Godbolt link. Try to be subtle, don't humiliate them, don't gloat. Do it constructively to get good karma. ;) 
Can't you do a performance test and see that yours is clearly faster? 
&gt; IMO, IDE features is low in my priority list to be decisive about it. but this is *huge* in practicality. **ironically this whole issue is probably one of the main reasons I started looking at Rust **, the promise of being able to bolt many impls on outside the class, to use method call syntax more. safety doesn't bother me - *obviously* we could write tools to do the same checks in C++, and use smartptrs to annotate if explicit lifetimes were needed. Most cases I think about are accessors or constructors, where lifetimes wouldn't be needed if you just had a formal way of distinguishing.. again it gets much easier if you can separate inputs/outputs.. IDE support is also **why Rust has not become my main language**. I can code faster in a C++ IDE than I can in Rust using emacs, either whether writing something new myself, or trying to change something in an existing program (where 'jump-to-def', and 'dot-autocomplete' are even *more* important, never mind when i'm just trying to remember what I wrote last week, when i'm trying to discover things I never wrote myself). **navigation and discovery** is the hardest part of programming, not segfaults. 'i want to do X... but what functions exist that might help that.. WHERE do I do it.' Now we have the tools in C++ to clear the raw pointers away. (e.g. I used to make my own 'vectors' return a raw pointer to 'construct in place' .. e.g. ```ptr=my_vec.append(1); ptr-&gt;init_stuf(..) /* NO COPIES */```. but now that temptation is gone, because ```vec.emplace_back( ...)``` is clearly superior. but I really like generating vectors from lambdas. If only I could add "vec.from_fn(count, lambda...)" !!!! missing helper methods is a reason I still have temptation to roll my own) The IDE communicates between library and programmer. A programming language has 2 purposes,'communication between programmer and machine, and communication between programmers'. The splitting of the argument locations *helps* this communication. That (I think) is why we have a synergy here; and a parallel between OOP-method-call-syntax, infix-notation in maths, and **"subject, verb,object"** in natural language (.. which is why a.foo(b) is making the naming easier ). &gt; It seems to me that part of the argument you go about resonates with knowledge such as Data/Object Anti-Symmetry and code architecture as a whole. imagine writing "seems it to me (go to part of the argument you (with (and resonates (such as knowledge Data/Object Anti-symetry (as code architecture whole)))))" 
&gt; knowledge such as Data/Object Anti-Symmetry ok, clicking your link - sure, can you see how much better it is when you can use one coding style - it allows the interfaces to evolve. interfaces change *both ways*. sometimes, details that were part of the 'class' get simplified out; but also, sometimes the exact opposite happens : users demonstrate patterns that the library writers have to absorb ("your users know more than you..")... libraries evolve in dialogue with the users. So we should be using one calling style everywhere really, to facilitate moving forwards and backwards. Given the option of both, there is a clear favourite; the one that is easier to read, and write - the OOP notation , which approximates Infix style.
IIRC, there was another C++ web framework out that that was built upon Qt. It looked kind of interesting.
I hope you're being sarcastic
How is his version not thread safe?
Why does this function even exist? What is wrong with returning the iterator, or using [ ]? 
 if (it == sortedVec.end() || (it != sortedVec.end() &amp;&amp; *it != n)) You don't need to compare to `end()` second time. Remember, logical operators short-circuit. The following is enough: if (it == sortedVec.end() || *it != n) 
&gt; Data/Object Anti-Symmetry ok i flicked through that link, it seems to contain defence of OOP accessors as an abstraction tool. I think it's a happy accident - how fields (which are sometimes just memoizations of other calculations) in turn resonate with method-call syntax. Also, **Interfaces change both ways.** Sometimes, details that were part of the 'class' get simplified out; but also, sometimes the exact opposite happens : users demonstrate patterns that the library writers have to absorb (*"your users know more than you.."*)... 'this is something that gets calculated a lot' -&gt; 'ok, lets have the option of pre-computing that in the object..' // 1996 entity.matrix.ay // the entities' Y axis vector // hmm. should it be an accessor? entity.matrix.y_axis() // thats better, great now I can store the axis in a different format, // e.g. maybe the machine favours row vs column major, maybe the matrix is somewhere else, // // maybe we don't even want a matrix, maybe its' more compact to store (quaternion, position) ?? // but that could equally of happened backwards. // 2007 .. after many throw-aways and re-writes // // gameplay coders: "we want to get the up axis a lot of the time!!!" // // library writer: "NO!!! we want to store Row-Major matrices, because it plays nice with 'dot-product' 4x3 transforms!" // "we also want it to be a per-platform detail , because some platforms don't have that." // // (&lt;&lt;&lt;conflict between the two&gt;&gt;&gt;&gt;) // users go and add a helper-function 'y_axis_of(e) { return e.get_matrix().y_axis(); } // but if they had the 'infix style' // // they could have kept e.y_axis() all along // // paving the way for the library writer to learn from use. // // "storing explicit axis vectors is of greater benefit to the users" // // 'the 'matrix transform point' case is done in bulk, where the conversions happens once, // // whereas the game-code needs ad-hoc access.. // // ... and actually the transform case happens on the GPU,mot the CPU !!! // so contrary to the library-writers guess, // // it's actually more important to keep the axis vectors around. // // entity.matrix.inv_mul(target.pos()) is an even more common operation // // 'where is the target, from my POV?' // // vs compressing it with a quaternion+position or storing row-major for dot-product transforms. // // the library writer could gather all the helpers, and instrument, and measure performance with both options libraries evolve in dialogue with the users. Some people say "foo(a,b) is better because it's symetrical", but if you need a default, *symmetrical functions are the exception, rather than the rule*.... **most functions are NOT symmetrical** if we reserve foo(a,b) for the symmetrical case, we're going to find it under-used :) The example you showed me (fwrite) has clear anti-symmetry. **Even many mathematical operators are not commutative.** matrix.mul(vector) matrix.transform(point) // even better, and now we can encode 'different types of transform, not just a matrix. // 'mul' might mean componentwise.. which we might want for abstracting general purpose SIMD. point.transform_by(matrix) // use a clearer alternate naming if we wanted to present the operands differently // // note that arithmetic code has huge opportunity for chaining // as such there's great value in having this flipped version *aswell*. vec1.cross(vec2) != vec2.cross(vec1) //not symetrical // ... and very often used in a chain.. vec1.cross(vec2).normalize() // SO common that when I first did vecmaths libraries in C i had // separate functions postfixed with '_norm' to generate normals.. // "vecSubNorm(..)" etc. but with chaining you don't need it so much, a.sub(b).norm() // make a normal to a triangle:- vertex2.sub(vertex1).cross(vertex3.sub(vertex1)).normalize() // For chaining, I actually often want to distinguish vec1.sub(vec2) vec2.reversed_sub(vec1) // sometimes useful in a chained expression.. point.get_axis_toward(target) == point.rsub(target).normalize() entity.get_centre().get_axis_toward(target); // is that 'centre' encoded in the 'matrix' or not :) // RENDERING.. render(a,b) // WHAT DOES IT MEAN???? entity.render(drawing_engine) // or.. drawing_engine.render(entity) // better:- entity.render_into(drawing_engine) // if it is that way *say so* // otherwise lets assume LHS is the 'target', rhs is the 'source'. drawing_engine.render(entity) // again this is more helpful with autocomplete // "i'm thinking about rendering something. ok, I need a rendering engine. drawing_engine DOT &lt;IDE tells me the graphics API.. as i'm thinking about now..&gt; entity DOT &lt;IDE tells me about all the game update functions of an entity.. less relevant suggestions&gt; // 'receiver' being modified is a good default, because we can have more than one 'input', // and usually 'things being modified' are a minority, whilst inputs are a majority. 
I'm not sure what you mean; writing the value into the reference is obviously a lot more work for the CPU. If you mean that it does not make any difference in practise then I suppose it could been seen as sarcasm. Not sure if you just referring to the part about being subtle and trying to keep the workplace atmosphere constructive and in good spirits. If you gloat "I told you so" it doesn't help bringing the point across on the contrary people will reject your perfectly valid information out of spite. We humans are like that. So I would try to keep it light and informative instead of underlining my own knowledge.
one more thing to say about coding style changes - again coming back to ```fwrite``` (I'm so glad you picked that example :) ) the conflict we have is because the C++ library is a terrible design: not only bit shift abuse, but 'bool coercion' abuse:- if (file &gt;&gt; value) { ... } Very unclear! is that checking the value? nope. the operator returns a reference to the file, which coerces to the bool. No wonder people resist using this, leaving the mix of styles. but they did acheive the allow passing the file reference between multiple calls, so we don't have to keep mentioning it again as we do with the obsolete C api. fwrite(,a,1,fp) ; fwrite(b,1, ? fp); fwrite( c,1,..fp) // ^ ^ ^ unecaserily repetition // , which is what motivated the C++ fp &lt;&lt; a &lt;&lt; b &lt;&lt; c // // ALSO, opportunity for the user to forget the order // IN MOST FILE FUNCTIONS, the file comes FIRST, not LAST. // // fseek(fp, a,b); // fput(..fp,) // fprintf(fp, ....) // fwrite(..., fp) // argh!! where do I put the file arg??? // // LETS THROW THIS SHIT AWAY!! There is a *huge* incentive to clean things up throwing this terrible design away. a new library based about variadic args can make the return value clearly 'status' (or better still returning an optional.. and if you're into rust, you should know how well the optionals play with chaining) // should I write this.. read(file, vec3) // or make it symmetrical with the system 'fwrite ' .. read(vec3, file) // lets consider the IDE support, it gives clear utility to one way over the other:- file DOT &lt;IDE tells me all the things I can do with it.. reading, writing, ..&gt; // more logical to start with the FILE when I'm thinking about file IO than starting with any other argument. // obviously, there's more things i can do with a vector or any other parameter not relevant to the task of IO. vec3 DOT &lt;IDE tells me about maths operations , like subtract, normalise, cross product..&gt; vector&lt;vec3&gt; points; //vector of vec3's points DOT &lt; IDE tells me about dynamic array operators &gt; points[i] DOT &lt;IDE tells me about maths operators &gt; file . write( points ) // much better than the C way, // ' fwrite( &amp;points, sizeof(points[0]), points.size(), file)' // but we could have clarified it further with a file.write_array(..) // .. and that possibility could have been shown in the dot autocomplete if I didn't know about it. 
Before I dereference iterator, I have to make sure it is not end().
https://godbolt.org/g/4WB2U7 of course it's only one instruction, it's just returning, but what's the purpose of a functions that returns something if you never call it?
I don't understand; why the downvote? The point I was making is that how C++ works is not a democracy - bringing in another just as clueless coworker to have a major consensus for being wrong should be shut down immediately. Bad practises like that spread like that. Demonstrate how their approach is not what they claim it to be should be a valuable information thay could take into heart. The important part is how to get that point across; don't be like me, I am not like me, when dealing with issues like this firsthand. That said, OK, was the problem what I wrote or HOW I wrote it? I am asking this because I will take constructive criticism into consideration in the future. I might not act upon it but I will reflect on the issues raised. =)
[Logical](http://en.cppreference.com/w/cpp/language/operator_logical) operators [short-circuit](https://en.wikipedia.org/wiki/Short-circuit_evaluation). This means the part after `||` will not even start to evaluate if the first part (`it == sortedVec.end()`) is true. 
Same with iterating over multi-dimensional data. A linear iteration is not always appropriate; I might want to move forward or backward in a particular higher-order dimension.
As a hobby, I've been working on a backports library for C++ for a number of years already. Other than that, I'm trying to get better at interacting with POSIX and taking advantage of generics / templates. Also, relearning streams. For the near future I want to work on a couple of things, primarily a integers library and a "text game"-like map parser ("Go north", "You're pwned by a grue" sort of thing). 
Is there a transcript or something to read this offline? 
You just moved the assignment outside of the getter. Say, you want to do this: const Info &amp;info = get2(); std::cout &lt;&lt; info.foo &lt;&lt; std::endl; Now the compiler only accesses the data it needs. If you must make a copy you make a copy - but don't ENFORCE it by your interface because then the copy is always made regardless of you needing the whole copy or not. https://godbolt.org/g/XQ8XL8 
Basically, you return by const reference so that the decision to "go expensive" can be deferred to the caller instead of making the decision for him and always going "expensive". If this is something that is done on setup like once or twice per application lifetime or once per second, I wouldn't care, of course not. But I wouldn't say that the two approaches are the same or equivalent because I would be wrong and spreading false information.
Live in at 18:00 cet (~90 Minutes from now) Stream at: https://www.youtube.com/user/MeetingCPP/live
https://github.com/vinniefalco/Beast/tree/9d082fd7d2d61e4d047eb09fe425620a4c2b6c91/example/websocket-server-async
I'm disappointed that you Boost Safe Numerics Library hasn't been mentioned. This library addresses all issues related to undefined behavior with regard to integers while imposing minimal runtime costs. Altering one's application to use this library will entail minimal effort and guarantee that the application will never produce any arithmetically incorrect results. This library has been reviewed and accepted into the collection Boost Libraries and is currently being modified to address issues raised during the Boost review process. More information can be found a the Boost Library Incubator website www.blincubator.com.
&gt; const Info &amp;info = get2(); get2() takes a parameter, but regardless, all I'm saying is you can't compare the assingment of one object to another and the returning of an address to an object. In get2 the "heavy work" is done inside the function, in get1 there's no work done at all, and how you designed the interface needs you to do whatever you want to do outside of get1
Title is misleading. You don't owe this leak to lambdas in particular, you owe it to circular references of `std::shared_ptr`. Which also can easily happen without lambdas.
So what you are essentially saying is that you want me to demonstrate the difference of writing into reference vs. returning address of the information in context of the original piece of code? You know that won't chance anything, right? https://godbolt.org/g/fqHKJp example1() is ~133 assembly instructions and example2() is ~370 assembly instructions. The number of instructions does not of course directly correlate to performance advantage of one over another but gives a rough idea how much more bloat the other approach adds on top of the std::map usage. Nearly three times more instructions for the CPU to churn through because of different convention of returning the info. Just for the record I wouldn't write this piece of code using either of proposed alternatives but as I said in the first place they are definitely NOT EQUIVALENT. I think I proven this already quite succintly. Just out of curiosity; what's your point exactly? 
If you want to see a concrete example where this makes a difference, try passing a captureless lambda into `std::sort`, versus an actual function pointer. The generated code will be affected (it will be inlined in the former case but not the latter).
The technical aspects are not even quite correct: &gt; The object allocated by that std::make_shared&lt;&gt; call? It’ll never get deleted. As others have said, a lambda is an object. It gets destructed. Even if you put it inside a `std::function`, it will still get destroyed eventually. And then the object will be reclaimed. The blanket recommendation is not justified. Grabbing a `shared_ptr` by value is a completely reasonable thing to do. It just all depends on your use case. If you want the object to die naturally and the lambda to simply no-op at that point, then `weak_ptr` is correct. If you want the lambda to always execute, then `shared_ptr` is. By using `shared_ptr` you are already making some kind of agreement to care less about the exact moment your object is destructed. So simply saying "just keep this alive until I'm done using it in callbacks" seems reasonable. If you really care about when something is destroyed, well, my recommendation contradicts another piece of advice in the article: &gt; The most obvious (and the one I do not recommend) is to capture the raw pointer for your lambda to use. This has a major downside, though, in that the object might be deleted before you try to reference it, and you have no way of knowing it. At least it won’t hold an extra reference, though. If you simply move the ownership of the object up the call/object stack, eventually you hit an object/function whose scope covers the entirety of the time over which you need to use the object. At that point you can make the object uniquely owned (either a `unique_ptr` or a stack variable, depending on other details), and simply handle it by reference/pointer deeper down, including in lambdas, which will be perfectly safe. I actually usually far prefer this solution because `shared_ptr` introduces so much complexity in terms of understanding when things are destroyed.
&gt; Just for the record I wouldn't write this piece of code using either of proposed alternatives me neither &gt; Holy ****. Your way is literally one assembly instruction. My point is that you compare returning an address (get1) vs copying an object (get2), there is work done in get2 whereas get1 is pointless if you're not using it anywhere, that's it, nothing more (I'm not even talking specifically about OPs problem) Maybe we're talking past each other here, idk 
I do not think this is a win. I see it as worst case O(n^2) Why not just sort it when needed, at least that's n*lg(n). 
Probably. The OP should be well-armed against the PhD-guy condescending him when he has the compiler output on his side. I'm just trying to help the guy being put down there above. I think he's right and the pompousness of his so-called colleagues should be checked. That's all, have a nice one.
I quickly tinkered that : http://cpp.sh/6iqby and I don't understand : My object is supposed to be deleted but yet I can access it again ?
I don't know much about WebSockets, but if you're only making HTTP calls, wouldn't code be a lot simpler in C++ REST SDK (https://github.com/Microsoft/cpprestsdk)?
You [define a macro that starts with a double underscore](https://github.com/Cylix/cpp_redis/blob/master/includes/cpp_redis/logger.hpp#L93), afaik this is not allowed (these names are reserved to the implementation).
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [Cylix/cpp_redis/.../**logger.hpp#L93** (master → 727aa5f)](https://github.com/Cylix/cpp_redis/blob/727aa5f06c8ce498168cbab5a023cad5b9c00bc0/includes/cpp_redis/logger.hpp#L93) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djt8opb.)^.
Btw. I figured the mystery out.. I think the PhD guy thinks C++ references work the same way than in Java. He most likely has a strong Java background and knows "some" C++ too, enough to be dangerous. :) OP; is this a possibility? 
**Company**: [Cruise Automation](https://www.getcruise.com/) **Role**: C++ Software Engineer, **Type**: Full time **Description**: We're the driverless car company. We believe in improving people’s lives by making transportation safer, more accessible, and more convenient. Our team is small and we move quickly. We’re currently testing a fully driverless solution on city streets in San Francisco. We're looking for smart, ambitious people to help build the world’s largest fleet of driverless cars. We are looking to hire C++ engineers across the entire company so please check out our [open roles](https://boards.greenhouse.io/cruise)! Check out [this video](https://www.driverless.id/news/video-analysis-new-gm-cruise-self-driving-video-shows-more-mastery-sf-roads-time-with-pip-proof-0176178/) of our car driving fully autonomously through SF! **Location**: San Francisco **Technologies**: C++ on ROS **Visa Sponsorship**: We can transfer Visas **Remote:** No remote work **Contact**: Anthony@getcruise.com
&gt; When you pass a shared_ptr what you are really saying is: "you own this object with some other thread in my internals. Just keep it around for as long as you want or get another one if you want." What I want to say is "here is a shared_ptr to the hardware interface - since you absolutely need this thing to work, you can now guarantee this thing sticks around as long as you need it because you have (potentially) shared ownership, and the enclosing scope doesn't need to worry about managing it anymore, but if it wants to it can" I agree I could use any of the 4 options you listed, but I'm specifically reaching for this idea as ownership/lifetime bugs often plague projects: Is it good practice to pass the ownership semantics into the library via shared_ptr to relieve the enclosing scope from needing to manage lifetime? If not, why? 
A great deal here depends on what you need to optimize *for*. On one hand, you're right: this is fundamentally an insertion sort, which is quadratic. On the other hand, it's also linear on any single insertion, so if you need to support searching after (nearly) every insertion, it's not too terrible. On the other hand, if you want to support searching after (nearly) ever insertion, it may be worthwhile to consider an alternative. For example, you can keep the majority of your data sorted, but as you add new data, leave that part unsorted. When the unsorted new data reaches some limit, you sort it and merge it with the main body of the data, then repeat the whole process. In this case, if you limit the size of the unsorted chunk to the logarithm of the size of the sorted chunk, you can still limit searching to O(log N), and insertions to something like amortized O(log N) (technically, O(log N log log N), but `log log N` is so close to constant it's usually safe to ignore it).
&gt; For embedded stuff, I would tend to reach for the first approach (user MUST handle the lifetime properly). In the past, I'd agree completely. Lately, after profiling how expensive using a shared_ptr is (very cheap at init), this seems like a tool to reach for more often. &gt; To my mind, you are making a mistake of reaching for shared_ptr for wrong reasons (e.g. "toys! Looks easy!). Think of it this way: how well did your code work without it so far? When did you encounter lifetime management problems and how did you solve them? How much would shared_ptr have helped as opposed to the way you solved it then? I appreciate the question, and I also question if I just want to play with the new toys :) What I want to do is solve ownership/lifetime bugs with a very small overhead. Did code work without it? Of course. We forced the user to manage lifetime of these objects by either statically allocating them or allocating them on the stack. The problem comes in 6 months when someone else is managing code. They need to come up to speed with the ownership scheme used and have more technical details to juggle in maintenance. main() gets pretty busy if you allocate all your stuff on the stack. shared_ptr might save us from some of this complexity. If we pass by shared_ptr, the enclosing scope no longer needs to deal with ownership. It CAN, if we need to, but it's not required anymore. This seems like a logical step toward clear, maintanable software. So where does my idea fall down? 
Tl;dr don't create a cycle or your code will leak
&gt; Accessing out-of-bounds storage and *even creating pointers to that storage are UB in C and C++* That means int* somePtr = /* ... */; size_t somePtrSize = /* ... */; std::fill(somePtr, somePtr+somePtrSize, 0); is UB? So I'm writing hella lot of UB code?! What about std::vector iterators? Please enlighten me
I wonder why he mentions this TIS interpreter but not the development of complete semantics for C and specifically the k framework (https://github.com/kframework/c-semantics). Afaik, kcc is also really good at finding undefined behavior. Regehr even wrote about it in the past (https://blog.regehr.org/archives/523).
I assume that the claim about thread safety is due to the static duration variable declared in the function. If two threads both call this function there is potential for a data race for the instantiation of the variable.
If your API doesn't document how long it will store the passed-in function then your API is broken, much like an API that returns raw pointers that you sometimes have to delete and doesn't even document which ones.
Since C++11 (i believe) initialization of static local objects is guaranteed to be performed safely.
And the finished episode, C++17 with Tony van Eerd: https://www.youtube.com/watch?v=uSYCjHOgdh4
Huh! If that is true, it is handy to know :)
IIRC off the top of my head, there's an exception for pointers to one past the last element of a storage region (or object, as I think the standard puts it).
static_print doesn't cache the result itself. It's just the standard behavior of gcc with regards to constexpr functions, so it is unrelated to static_print. 
your code is valid: &gt; If both the pointer operand and the result point to elements of the same array object, **or one past the last element of the array object**, the evaluation shall not produce an overflow; otherwise, the behavior is undefined. says the standard
Does anyone have any information on how this would handle a long running time? There isn't a great way to handle a single location overflowing (he chose to just clamp it to the maximum value) and according to the author removing items allows false negatives. It seems to me that the ability to remove things would be outweighed by now allowing false negatives (the lack of which are a regular bloom filters greatest strength IMO)
The both versions are not threadsafe because someone can mutate the map during getting. I think this part of code is single threaded, and nobody is going to store the returned references. Because if they do, they are in whole world of pain... 
There's a comparison of some features to cpprestsdk here http://vinniefalco.github.io/beast/beast/design_choices/http_comparison_to_other_librari.html 
Also note that it's entirely legitimate to treat a single object as an array of one object, so something like `int i; std::fill(&amp;i, &amp;i+1, 0);` is also fine. While you probably wouldn't use this directly a whole lot (`i=0;` would obviously be a lot simpler) it's helpful for a function that just gets a pointer to T, and doesn't know whether it's part of an array or not.
To my mind, your idea falls down at "they need to come up to speed with ownership scheme". Yes, they need to. Magic `shared_ptr` dust means "we don't know when resources go away" and a potential for cyclic reference bugs. People need to handle resource lifetime even in managed environments e.g. try-with-resources of Java and `using` of C#. To each its own, but a pervasive use of `shared_ptr` "just because" is my idea of unclear and less maintainable software. I have an old codebase at work that does it and it's just... why?!
Graph-based iteration may not fit the iterator-based model at all. In C++, we sort of expect the InputIterator, etc. interface and I can't imagine that porting well to any type of graph, binary trees included.
I guess you are talking about this one: http://cppcms.com/wikipp/en/page/main It seems they are the most famous. I don't know if they are also the best ones.
The need to choose a saturating count up front is one of the big limitations of counting bloom filters in certain real world scenarios (especially those where highly-skewed distributions are common). We recently developed a new approximate counting data structure --- the [counting quotient filter](http://dl.acm.org/citation.cfm?id=3035963) (CQF) --- that overcomes these limitations. It has a number of practical and theoretical advantages over the counting bloom filter in most cases, including the fact that one need not choose a saturating counter value and that highly-skewed distributions can be represented efficiently. False negatives are very difficult to avoid completely in any approximate counting data structure (including both the counting BF and the CQF) that allows deletions, since the approximate nature of the structure, which allows false positives in queries, is also what allows false negatives once deletions have occurred. However, these events can be made very rare by setting the parameters of the data structure correctly.
I don't think that's based on Qt. Their approach, as far as I can tell (I never actually tried to use it), is more similar to frameworks like Django or Ruby on Rails. I'm not sure how active CppCMS is developed, it seems that there hasn't been a release in years.
I came across this one: http://qtwui.sourceforge.net/. Is that the one you're thinking of? It seems abandoned. 
And, as usual, boost has this case covered for when you do not want to roll out your own implementation: http://www.boost.org/doc/libs/1_56_0/doc/html/boost/container/flat_set.html
C still has certain advantages in situations where resources, in particular memory is extremely limited. The other situation would be where you are interacting with an existing C code base. Beyond that C++ (in particular the STL) has a lot of features to make your life easier so I personally would just use C++.
I think it was called "Treefrog" or something like that.
It's true, that's why they call "magic statics". Static initialization uses something akin to double-checked locking under the hood to handle these case.
I just want to add that anything published in SO falls under creative commons to my knowledge. So, you are right, atributions should be made.
&gt; Thanks for the report! BTW I hit some transient ICE(it works after clean/rebuild), and since it is not my work project I would be happy to send the source with the bug, but the problem is that IDK if you support some easy way to export the current project source + ICE text. If not you may want to add that in future VS. Note that I know you prefer small bug examples, but I am not on MSFT salary, I think people willing to spend time to report a bug should not be ignored just because they do not have time to play until they get reliable repo of a transient bug on a reduced source. btw this is the ICE output: https://pastebin.com/fPw65xv0 
This sums it up: https://softwareengineering.stackexchange.com/questions/113295/when-to-use-c-over-c-and-c-over-c
Do you have examples where C++ uses more memory then C? The only things that I know about are vtables and RTTI
You certainly write a lot about this. How about summarising it in a blog post instead?
Thanks! It looks to me like if your primary use case is making REST calls (which is a pretty common use case), then cpprestsdk probably matches your assumptions and will result in easier code to read/write, but beast offers more control for a wider set of use cases. Have you guys thought about adding some defaults to beast to make these simple use cases a bit more compact?
You don't need an IDE to write C++. You just need a text editor and a compiler, and just using those is the recommended way to start. [This](http://www.learncpp.com/) is a nice (free) beginners resource. [This](http://www.icce.rug.nl/documents/cplusplus/) is another free book that is more advanced. [Here](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) is a list of other recommended books.
Welcome to C++! Please read the sidebar; beginner questions are off-topic in this subreddit.
Thanks, looks like an ICE in the optimizer during LTCG. Generating a repro--if you have the time--isn't quite that hard. Check out [https://aka.ms/compilercrash](https://docs.microsoft.com/en-us/cpp/how-to-report-a-problem-with-the-visual-cpp-toolset#link_repro) for details. If not, no worries. 
It necessarily uses more memory out of the box, because C++ needs some additional runtime for various things. Its probably possible to get as close to C overhead as necessary by cutting exceptions and things you mentioned. Also, C designated initializers are nice. Other than that, i think the main advantage to C is that it would be well supported on fringe CPUs that you may need to write for. Even if C++ is supported, its riskier to use it, if everybody else works with C there. Other than historic reasons, and personal preference, i wouldn't expect C to come out 'better' anywhere, on popular hardware.
Returning iterator would expose more interface than necessary (presumably) and subscript operator of map is non-const only. std::map::at would work fine, but then, OP may not want it to throw, and so on... They could probably be used in some way, but there may be things 'wrong' with either, depending on stuff OP didn't show us.
I've already got 90% of my code written in visual studio. Porting the Gui to QT would take weeks, especially since I've never used QT Creator. Edit: I'm also generating I invoices! 
What additional runtime do you mean?
It's more a matter that using STL objects has an additional memory cost over the c equivalent. Strings would be one example, smart pointers another. 
There are many minor things. Like say, std::set_terminate. Plumbing for this is probably always present in the end program, regardless of features actually used.
Some points that I recall reading about somewhere that I can now no longer find (and that haven't already been mentioned): * C compiles faster which in certain workflows is a massive boon * C++ is a lot more reliant on compiler optimizations (e.g. many 'zero-overhead' abstractions aren't really zero-overhead on -O0), which can be problematic if you want to debug in -O0 but also need performance in those same debug builds. 
I do wonder how much these little things actually persist when you don't want them. In particular, if I understand correctly, set_terminate does something that is more or less useless on most platforms where such tiny amounts of memory are significant (i.e. if you care so much about memory, you will be running bare metal. If you are running bare metal, 'terminating the process' is not a meaningful concept). More generally my question is, how much of this runtime overhead do you really need/incur on the type of platforms where such small amounts of memory are significant?
Drastically increased compile times are a prerequisite for getting accepted into boost.
The counter-argument to that is that C++ doesn't force you to use those (or std for that matter). Even without std, there are quite a few features in C++ worth having in many use cases (in my opinion).
I don't think it matters very much. I believe it should be possible to get very close to plain C program by just cutting features (were not technically C++ then, but its still much better language than C). Though at that point i would be very cautious about choosing target language. I mean, if you write for say Xtensa processor, and nobody around works in C++... i don't want to be discoverer of a compiler bug there ;)
&gt; Do we really want C++ to be a language where you can only figure out which function is being called is if you use an advanced IDE that correctly &gt;Maybe, but that sounds like a problem for IDE's to solve &gt; template&lt;..&gt; auto foo (..) { return x.foo(..) } Self contradiction in your post.. your *own suggestion* complicates the search process :) we're already there, finding definitions/code paths with C++ **templates**,**macros**,**includes**,**virtuals**,**overloads**,**template specialization**,**SFINAE**,**ADL** is already very hard. But if we didn't have these tools, we couldn't work on software as complex as we do. **The language is powerful - which in turns allows the development of better tools for reasoning about it**. forget the macho idea of using a simple text editor and expecting people to keep these m-loc sourcebases in their heads. Computers are there to make life easier by calculating and searching for us, and *that equally applies to the tools within computers*. If the program *compiles*, the machine *can* reason about it. if the program is truly *too* big, you might be able to consider a plugin architecture, but I'm sure you know the drawbacks with that. There's no way around this: either we write stupidly long , but unambiguous function names (i.e going back to plain C), or we add more layers of metaprogramming and polymorphism, or we give up on writing large programs.. call it a day .. &gt; where you can only figure out which function is being called But think about my intermediate suggestion - **UFCS is only available for functions with an explicit ```*this``` parameter.** when using emacs , I have various regex shortcuts in my setup for searching from a symbol. It would be very easy to add ```"(thing-at-point 'symbol)" ".*this"``` , infact that's actually *much easier* to find than other C++ member function definitions. &gt; Basically, if I write f.foo (), I expect a function 'foo' with zero arguments to exist on f or one of its ancestors. I really don't want it to somehow call template function foo&lt;T&gt;(T) behind my back, where that template may be hidden in a header file that gets included from a stack of header files 20 levels deep. Utterly irrelevant because the neccessity - hence use of **foo(x)** in addition to x.foo() *already exists*, so you have to deal with it *now* (And they are writing those wrappers for templates *anyway*, again by necessity). My intermediate suggestion simplifies that. &gt;&gt; Also, OO finally freed us from having a single giant namespace containing every function in the entire program. C++ uses overloading, so it's already more complex than that. The namespaces are hard to comprehend for plain text search tools. Only an IDE can really navigate them. Many functions are bound to multiple types, essentially. we can already have "foo(Bar,Baz) ", "Foo(Foo,Bar)" etc etc. It's a false idea that a function taking multiple arguments can be 'owned' by a type (but it is amazingly useful syntactically to put one type in front). &gt;&gt;" There was a reason people really liked this encapsulation business, and about the last thing we need is a language rule to undo it all." encapsulation means nothing. You can't organise programs by a single heirarchy. C++ keeps the free functions as a workaround.. we suffer the inconvenience of 2 calling syntaxes to get it. http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197 Haven't you run into this issue?? putting things *in classes* actually *backfires*. **This side of OOP has failed**, and that knowledge has long since reached the mainstream. (In short the benefit you seek of 'things being in the class' means the problem re-surfaces as *the classes get too big and too inter-dependant*). ... which is why newer languages added ideas like **interfaces / typeclasses / traits**. The issue is adapting types to work in frameworks that the original authors didn't know about - what library-writer can possibly predict every use case? We need to able to switch between both cases, because we need types to be extended outside of their original definition; and no, **inheritance doesn't cut it**. And there are cases where the users extensions eventually get absorbed into the core library (if there are common access patterns, the types may want to re-work what they present to make their use more efficient.) Looking into haskell a bit.. what they have is much better:- They've got the type classes, and *any function* can be called via the prefix or infix style (and anything can be used in pipelines, which is what our 'dot syntax' emulates pretty well, which is the *real* motivation for putting things in classes.). *The syntax is completely decoupled from 'how it's declared'*. you use whatever syntax makes it easier to read , or write, in the context in question. And I don't see anyone complaining there "I can't get a hint where bar vs `bar` is.." whilst they can write ```foo a (bar b c)``` ... ```b `bar` c `foo` a ``` (or stuff like ```bar b c&gt;&gt;= foo a``` in monads) at will. ( they can also implement the F# style ```a |&gt; foo b |&gt; bar c```)
Ok, I see where you're going with this. The cyclic references are something to be aware of. My concern is far less about when this resource goes away and the fallout from destroying it as most of our systems will have power pulled and never invoke the destructor. My concern is much more about guaranteeing we don't let the resource go away until the the Communication class goes away. If we pass it in at construction and don't expose access to it, it's simply not possible (barring Machiavelli) for the resource to go away too early. I see using shared_ptr as clear and maintainable in main, as I create the thing and pass a shared_ptr to the Communications object at which point I don't need to worry about ownership in main anymore - the shared_ptr in the interface tells main AND the Communications object what the ownership/lifetime semantics are, and enforces them through the library. What I'm fundamentally trying to figure out is if it's a good thing to try to simplify the burden on users dealing with ownership of these resources. If our factories create and return objects, they should be in smart pointers - shared or unique. If we're using smart pointers, a class like this should accept the smart pointer to keep it around long enough. If we use shared_ptr, we can still support unique_ptr and raw pointers with the custom deleter solution above. Or, it's not worth it - make users of the library deal with it. Maybe provide some external helper/owner objects?
So this is UB? int *a; // probably out of bounds, so UB int *b = nullptr; // certainly out of bounds, so UB Get real... What architectural need is being served by forbidding the construction of pointers to non-owned addresses?
I don't know what "drastic" is. I haven't noticed this as problem. But even if that were true, it's a small price to pay to have correct code.
That URL is unintentionally confusing.
C++ is your one and only hope for salvation. e.g. you'll get to catch tons of errors during compilation, not runtime.
&gt;roughly 100% of large C and C++ programs take a flexible view of types somewhere Citation needed. 
Looking at these examples makes me question if not a "cage" library is needed for beast. I feel like this is too much boiler plate, I'd prefer a library that does not expose the asio boiler plate code. 
Unless this is embedded, go for C++
didn't you read? he gave you a citation...
How does the Boost library compare to the [SafeInt](https://safeint.codeplex.com/releases/view/125522) class which has received quite a bit of engineering attention to try to be safe against fun issues like the use of signed integers in intermediate calculations introducing UB?
LOL @ cage...
1. "you guys" is just me, and 2. Newer versions of Beast have constructors for setting up the message but you still need the asio boiler plate. I feel that addressing the cpprestsdk specifically is out of scope for Beast, but certainly not for another library which might be written on top of Beast. This will not be the only library I propose for Boost!
Your first example is simply uninitialized (I believe the exact verbiage is "trap representation"), so it is not UB by itself. If you had stored a nonsense value to it, that would make it UB. This is because C and C++ both support hardware where pointers are processed by a separate MMU that will raise a hardware trap as soon as an invalid pointer is passed in, even before the CPU sends a memory read request. C/C++ makes this UB so that the compiler doesn't have to embed wasteful MMU validity checks, runtime code to handle unexpected hardware traps, or optimization barriers to force MMU accesses only just prior to actual memory access. For the second example, `nullptr` doesn't point to into the free store by design (`nullptr` exists precisely to be a name for a freely-addressable invalid pointer), so it does not cause UB.
&gt; MSVC has a real problem with Ryzen. [citation-needed]. Need to compare compiling projects of similar kind to say anything here. My 1800X is quite a bit faster building and running our tests than my E5-1650v3 (that is, I get results like that from Phoronix, not like AnandTech). It all boils down to whether the thing you're compiling lets the compiler data structures fit in L2. For a lot of projects they'll fit in L2 and that'll be great. Chromium apparently does things too big for that and benefits from lots of L3. (EDIT: I'm not saying MSVC is not at fault here; I don't have that data. I'm just saying the answer is more complex than MSVC vs. GCC/Clang here) 
I myself would quite like a compiler flag for C++ that turns possible undefined behaviour into where possible simply 'what everyone expects' (integer overflow, aliasing rules, using the value of a pointer after a delete etc) This would be great for security code as you don't have to worry about weird edge cases (loop non termination, accessing oob memory and immediately discarding the result in a way thats fine on a processor level but UB in C/C++), but anyone who wants level 100 optimisation can turn it on. Same as -fno-strict-aliasing
Are you talking about "For a thorough overview see Sections 1-3 of this paper." ? I read said paper and it didn't appear to say anything supporting the quoted statement.
&gt; I just wish compilers would always report the instantiation point first, and then print a stack trace, since 90% of problems are on the call site. gcc seems to usually have a "required from here" first, but both clang and cl show the line on which the error occurs first, followed by a stack trace and/or a list of candidates. &gt; Level 100 this. I swapped to MSVC for a recent project... I'm so used to GCC saying "this is where you invoked the template" I couldn't believe I wasn't doing something wrong. I spent ages hunting around for this
Just put the tiniest amount of instrumentation into the constructors and assignment operators. Add a little `std::cout` for instance. *Show* that yours prints fewer statements. Not too hard. In theory, they'll believe evidence. Credentials and seniority don't dictate the facts.
C89 conforming compilers are more widely available across platforms than modern C and modern C++ compilers. Partly because both C and C++ are very backward compatible, making modern C and modern C++ also mostly C89 conforming. Mostly because some companies never upgrade their compilers. :(
Even if it's embedded, C++ is fine. You might not want to use st(d|l) containers or something, but that's no reason to handicap yourself.
The latest newcomer is [cutelyst](http://cutelyst.org/). It's inspired by Perl Catalyst, and takes the classic MVC, template way.
So each of these lines has undefined behavior?: `int* a = 0;` `int* b = 0x12345678;`
the citation is 100% of large c and c++ programs, just go look at one; the man said 100% of them
Huh? Finding one example of a thing does not prove that there are no counterexamples. For example my shoes are black, does that mean that all shoes are black? Or even that most shoes are black? 
The first one is just another way of referring to `int* a = nullptr`, so that's fine. In fact `0` used to be the name for the null pointer, `nullptr` was added in C++11 so that there's be a way to unambiguously refer to null *pointers* in contexts where confusion with `int` would be problematic. Your second line is almost certainly UB, yes.
Returning the iterator exposes the underlying data structure used. If we change that container, all the function callers has to be amended as well. [ ] actually inserts a default constructed object into the map which we do not want. That is why we always use find().
I do not understand why many downvotes in this thread. Perhaps people are not happy that they are reminded they are wrong? Other than 2 coworkers and another one (in HQ) who wrote strange std::set getter, there are at least 3 person in my company who do not understand reference parameters. How many % of C++ dev does not know this? I wonder.
you just have to find one proof that counters his claim and you've won! then you can rest easy that c++ isn't a dumpster fire... a nice prize AM I RITE?
Part of the problem is I cannot explain very well. And they strongly believe in their understanding of reference parameters and pay not much attention to my explanation.
His claim was "roughly 100%", so a single counterexample (or even a small number of counterexamples) wouldn't suffice either. In fact, a survey of all large software products would be required. The sample size for a claim "roughly 100%" would need to be quite large too, and also it would need to be ensured that the same wasn't biased.
Maybe you should look at the D language which arose from a similar design goal? Everything's a trade-off. In most cases, to eliminate undefined behaviour you have to curtail the power, performance, and/or portability of the feature in question. Nobody would use the hypothetical "boringcc" compiler -- they'd complain that either it gave too many errors for existing code (since language features that unavoidably included UB cases had to be disabled) , or the resulting binary ran too slow. Preventing UB due to out-of-bounds pointer accesses would be a simple example. You want to catch this, you have to store meta information with every single pointer value that allows the bounds to be checked at runtime. This has a severe memory and time cost.
The original quote was imprecise, probably for brevity (it'd take more than 17 words to give a full specification of which pointer operations are valid or not). Your examples are OK.
`int* b = 0x12345678;` is ill-formed. An integer may not be implicitly converted to a pointer, except for the special case of literal `0`. Maybe you meant to ask about `int* b = (int *)0x12345678;`. In C++ the result of the cast is *implementation-defined*, and is not a *safely-derived pointer value*. It's also implementation-defined whether or not the implementation has *relaxed pointer safety*. If it does then your code is OK, if it doesn't then your code will be UB unless the result of the cast happens to refer to a valid object (or be a null pointer). 
C++ doesn't use the term "trap representation". (C does). Instead, it specifies whether or not a particular use of an uninitialized variable is defined.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6ljh59/need_help_in_coding_patterns_using_cpp/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Purchased and shared the link around at work - thanks!
the boost library is the direct descendant of safeint. That's why it's named safe numerics. I used SafeInt and found it useful. However I felt it need more. It needed tests, it needed documentation, it needed easier to read code. But using more up to date techniques, boost libraries and other things I was able to remedie these issues, decrease the lines of code and make it more maintainable and portable. This is described in the documentation for safe numerics. After spending some time with it and getting some feedback, I took the next step and address this usual complaint - but it slows my program down! Leaving aside the observation that a fast program which produces an incorrect result is of little value, I approached this issue with pretty heavy duty template meta programming to the point where the actual impact on performance seems quite small. Though I should note that I haven't done much performance testing. Of course now people (that haven't actually tried the package) complain that it takes too long to compile. I'll have to get some real feedback on this issue before I can respond to it. Short version - If you like SafeInt, you should love Boost Safe Numerics.
Thank you too! And I hope you enjoy the course.
Your discourse is being the epitome of xkcd 386.
Well... to me, the key part was, in your post, that hardware interface MUST (your words, your capitaluzation :-)) outlive the Communication. If so, no need for pointers at all. Your initial code is the best, except perhaps the hw interface should be a reference in the Communication (don't know if you need to copy Communication, if yes, then a reference is too much, but new C++ has `reference_wrapper` for that). I understand there could be other considerations, but I don't think I should discuss them without looking at the code and its past (bug reports), which is too much for reddit, so it has to be up to you :-). As for the unique ptr and factories - yes, if the function who receives it becomes the owner, then `unique_ptr` is the best way to express that.
I don't remember specifics, but I heard somewhere before that there were a bunch of pit falls using C++ for embedded.
At work I'm stuck with C++03 and every time I use a functor instead of a lambda, I die a little inside. Can't wait for my project to be updated, but I don't see that on my near future, unfortunately :(
Welcome to r/cpp, where objective facts get downvoted.
If you like OOP, C++ is the obvious choice. If you need **extremely** tight control over what happens in memory (as in you're writing code for the boot sector), then you might need to go for C. If you need zero-overhead abstractions, C++ (especially newer standards) comes with features that enable very high level code, seamlessly interacting with low-level. As for libraries, I find that C++ libraries are easier to use, but C libraries are useful more often. That's because in C++, authors tend to think they're doing you a favor by handling memory management for you, or burying the functionality behind an impenetrable hierarchy of classes.
Why is it wrong to expose the container to the user? It is only wrong if there is a possibility that there is no container, but I understand that MyClass is almost a kind of container by itself. You could also write in MyClass using iterator = std::map&lt; std::string, info &gt; :: iterator; using const_iterator = std::map&lt; std::string, info &gt; :: const_iterator; That hides from the user that std::map is used (instead of std::unordered_map). In case the null_object is returned, is something done with it? Or is it used only for indicating that there was no info? If you are certain that the key exists, you can use at( ).
B.t.w, your initial observation, that the second function copies the Info when it is found, is correct. It depends on what is in Info, how bad it is. Apart from that, one should prefer functional style over procedural style, so the first is also stylistically better. (But I still don't like it.) 
Depends entirely on the specific hardware platform. See what it's capabilities are and choose accordingly.
Where comments spreading misinformation are downvoted, i suppose. For example, people implying that C++ programs are necessarily larger, or that the use of STL and other features are mandatory when you can use the language in the same way that you would use raw C without any problem. Good reasons to use C in this case would be if the OP work with a team and the other programmers only now C, or he don't know C++ well enough and have experience with C.
Exception handling can also add a little. More to the point, although it's not entirely endemic to the language itself, a lot of C++ libraries are designed with quite a few features that are rarely used, but can still drag in a fair amount of code for those unused features. This tends to have little effect when you're using a desktop or server OS that provides (for example) the entire standard library in a shared object (or DLL, etc.) With static linking (e.g., for a small system that doesn't provide/use a shared object for the standard library) the impact can be considerably greater. In fairness, I feel obliged to add that if you're targeting a tiny embedded system, you frequently end up making little or no use of the standard library, and libraries that provide the "stuff" you typically need for such a system usually concentrate on minimizing overhead anyway.
I'll go on record as saying if there's ever a real *need* to use C instead of C++, it's exceedingly rare. Keep in mind that most C code will also compile as C++. At most you need to make cosmetic changes that have no effect on the generated code (e.g., somebody named a variable `new` or `delete`, and you have to change its name). If you have *really* old C code, you might also have some functions without prototypes, in which case you'll need to declare the parameter types for C++ to be happy. Nearly the only cases I can think of where this would produce different code at all would favor C++ over C though. For example, if you had a C function that didn't declare the type of a parameter, and you passed a `char`, `short` or `float`, the compiler would insert code to promote that to an `int` or `double`. C code that doesn't specify parameter types is now pretty rare though (and has been for quite a while now, truth to tell). As long as the parameter types are specified, we can expect C and C++ to produce similar code.
Definitely true. Sometimes you also find that the library you need exists as C and C++, but the C++ version is just a horrible wrapper around the C library and is sometimes even incomplete (looking at you zmq you piece of shit). Once you're writing *some* of the code as "C-style" and bending over backwards to convert back and forth between you decide "fuck it, we're going back to C" and you reminisce about how nice it is to use `printf` again. Or you just compile with a C++ compiler, using modern C++ style when you can and C when you have to. Gross, but the job gets done and the code sucks slightly less than it might otherwise. Resource constrained embedded environments for sure They always *claim* to support C++, but most of the device manufacturer and community support is C, the libraries in C are better, etc. "Stay in the middle of the Gaussian" my coworker says. Use the tools that are most popular for any particular task, and use them the same way everyone else does. When you try to be clever you find yourself alone in a hurry. 
Dunno what you call embedded but I've done c++ on 8kb AVR chips without problemd. Arduino is c++ for instance.
And just because it's possible doesn't mean it's worth it. You end up waist deep in C++ libraries trying to rebuild them smaller thinking "all I really need is printf and a socket..."
&gt;Part of the problem is I cannot explain very well. That's fine. Its something you can work on! If you are a language enthusiast it helps to get in touch with someone on similar level, so you can both dig into it and discuss openly. If you happen to have boneheaded colleagues then tough luck i guess.
&gt; That's because in C++, authors tend to think they're doing you a favor by handling memory management for you, or burying the functionality behind an impenetrable hierarchy of classes. C++ libraries sometimes make it difficult or impossible to get a file descriptor. I don't want a fancy receive or a callback function thread pool. I have other things I'm polling for and I can't take the latency hit!
If you want to run your project on a usual computer, use C++. I think one should use C only when you are directly dealing with hardware, or writing in an extremely limited environment. (Think device drivers, graphics cards, embedded systems.)
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6lgpof/what_is_the_current_state_of_proscons_between/djuft21/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I hate it when people do that, but they are always arrogant. Such people give C++ a bad reputation. Thanks for your post.
I'm using a PIC18F4550, coded with C. However I've been leaning C++ for the most part, I found it to be rather similar 
Your anwsers show that you obviously lack grasp at what makes C++ a giant bag of scorpions, as the OP rightfully said. [Proof on type deduction](https://www.youtube.com/watch?v=wQxj20X-tIU). If you just want to slides, [click here](http://www.aristeia.com/TalkNotes/C++TypeDeductionandWhyYouCareCppCon2014.pdf). Either you don't fully understand C++ type deduction, and suffers from some sort of Dunning–Kruger effect, but if you fully do understand C++ type deduction, you can't say there are no "gotchas in the language". 
Oh god, stream formatting. Yes it's type safe so hooray for that but it is hideous, I tend to use fmt if I'm having to do a lot of carefully formatted output.
The code example is undefined behavior. Your code is always allowed to assume that UB never happens. &gt; And also, `std::optional` doesn't allow for `T&amp;` Yes, uch, worse decision ever.
Thanks a lot for the link. Could you point me, in the slides, where the gotchas are? 
I know this is a it pedantic and these are only small examples but it would be nice to have more descriptive variable names instead of `b` and `r`. I was trying to check where the flat_buffer was used and even in that small bit of code it was annoying to check it.
Yes, the examples should use longer names. Could you please open an issue?
See, he says "extremely limited memory". There are very minor sources of overhead in C++ that are too low to be important for most applications. But some people are programming heart implants, you know.
That's a really clever data structure. Does it have a name? I wonder if you can generalize it to include a removal operation by keeping a O(log N) buffer of removed elements and when it gets too large, "unmerging" them from the sorted vector. EDIT: I don't understand how you achieve the amortized O(log N log log N). If you merge linearly every log N insertions, then you get amortized O(N / log N), I think.
&gt; Altering one's application to use this library will entail minimal effort and guarantee that the application will never produce any arithmetically incorrect results. What about third party libraries outside my control? How do I change them to use Safe Numerics without modifying them?
*sigh* In real world applications, this is largely a myth. Some boost libraries are hard on compile times (spirit, Xpressive, etc), most of the others are not. Usually what happens is someone does a test where adding a boost convenience header to an empty cpp file is a massive increase to compile time. In this case you've just included a ton of stuff so ya, it's slow to compile. But two things are wrong here: A) Avoid the convenience headers. One should included exactly the headers that are needed, not the header that represents the whole sublibrary. B) Test in a real cpp file. Adding a boost header might drag in system headers that are usually already present in existing cpp files. Something like &lt;vector&gt; for example is almost certainly already present in your cpp so counting it in the cost of the boost include is wrong. I've gone through this many times; long compile times on a big project is usually due to our own code or misuse of a library and not the fault of the library itself. 
Perf Tip: do not use std::set never ever.
I would downvote this 1000 times if I could. Suggesting people to use O(n) insert should be crime in all 9 planets of the Solar system.
yep, basically the whole thing boils down to a bad understanding of how lambdas work, plus a normally-horrible-to-debug circular shared_ptr ownership.
;}
I get that. All I'm saying is that I heard there were more pit falls. That you basically had to use a subset of c++, and if you used more than the subset, you'd have issues.
Don't know anyone using Makefiles directly (no matter what editor). CMake and optionally ninja seem to be the winner in my direct environment (CG research). Regarding vim: use it for everything and throw away the rest!
With all due respect, I took into consideration the help rule, but felt my inquiry was discussion-worthy and not simply a "help" post. I respect your decision, but just wanted to voice my take on the matter.
Thank you very much for your feedback, everyone. I really appreciate everyone's time and input!
Depends on the use case, if you do a million access in between insertions of a single element it's better than O(n log(n))
LOL - well that's a pretty tall order. But sometimes its possible. Some libraries take template parameters for some underlying type. For example, consider Boost.Rational for arithmetic on rational numbers. This library is useful to doing exact calculations on non integer numbers. This is a library written 17 years ago and still maintained by boost. It's very well written. Numbers are represented by a pair of integers representing numerator and denominator respectively. The signature is template&lt;typename I&gt; struct rational { rational(I numerator, I denominator); // constructor ...// other arithmetic operators }; So you create a rational number with int as the underlying type with rational&lt;int&gt; x So reducing your question to this specific case would be "Can I do the following?" rational&lt;safe&lt;int&gt;&gt; Short answer is YES. This will "infect" your instance of rational to detect invalid arithmetic operations inside the definition of rational. It's an illustration of the power that only C++ can bring to bear. The same has been tested with Boost multi precision integers.
The O(log n log log n) derives from sorting the previously unsorted part. If we call its size M, then sorting it is O(M log M). Since we've limited its size to log N, we can substitute `log N` for `M` to get `O(log N log log N)`. If we include the linear merge, it would look like O(log N log log N + N). For some reason I was ignoring the `+ N` term, but in reality it's *greater* than the other, so it's probably the term we want to keep. Thinking about it, however, the sort time is also amortized over `log N` insertions, so it's O((log N log log N)/(log N)). The `log N`'s cancel, leaving just O(log log N) (an even stronger case that we ignore this term, and pay attention only to the merge). As far as names go, sorry, but I haven't thought anything up yet (as far as I know, I invented this particular sort of mess).
Exactly, and it gets worse if you need to get an error value from `f(3)`. I keep thinking there must be a better way to do this that allows you to use the `optional` approach, which I like. Something like auto b = f(3); auto c = f(4); auto d = call_if(g2, b, c); auto e = call_if(h, d); auto k = call_if(h, e); Where `call_if` checks if parameters are valid and proceed to call the function with them if so, propagates an error if not. Does roughly the same but the code does not make my head explode.
I actually don't believe this needs a citation. When one writes any non-trivial application in C/C++ that must be proven/demonstrated to not fail, he'll find that avoiding UB behavior which can produce incorrect results is just about impossible to avoid. Take a look at https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=270 to get an idea of the hoops one has to jump through to make a correct program which uses integers in C/C++. It should be clear that it's not practical to do so. Until now The safe numeric's library implements these rules "under the covers" so one can still preserve the intuitive of C/C++ arithmetic expressions while at the same time having the certainty that no erroneous arithmetic results will be undetected. 
It was specifically about "take a flexible view of types", meaning strict aliasing violations -- not all possible UB. I'm skeptical of the "roughly 100%" figure; I don't do that in my own code and would be very surprised if I was almost the only person in the world. 
The linear merge is `O(N)`, as you mentioned the `+N` term dominates the rest. If you amortize over `log N` insertions, you arrive with `O(N / log N)`.
&gt; It saves you from getting surprised later when someone makes a subtle change. But then this introduces further surprises when you execute the lambda and it then tries to access a resource that potentially no longer exists because you never gave the lambda ownership of the resource.
std::bind is candidate for deprication, and you misspelled exercise.
That's for pointing out the mistake. I corrected it. I didn't knew about the fact that std::bind would be deprecated. What would be the replacement of std::bind?
As of C++14 lambdas can use r-value references and move semantics, so you can write any std::bind as a lambda. Edit: also, it isn't deprecated, but a lot of people think it should be in the future.
[removed]
&gt; As of C++14 lambdas can use r-value references and move semantics, so you can write any std::bind as a lambda. ohk. I will add this a comment there and will read more about it. Thanks Also, can you please add this point in the blog too. So that readers too get to know about this?
[Here's a good starting point.](https://stackoverflow.com/questions/17363003/why-use-stdbind-over-lambdas-in-c14)
In addition to lamdas vs. bind it might be worth mentioning the transparent/diamond operators, like `std::plus&lt;&gt;`.
Agreed. Will cover transparent operator too when covering lambdas. Thanks
Accessing an element of an array is just dereferencing a pointer to that element. `foo[2]` is exactly the same as `*(foo + 2)`.
Have a look at [this](http://www.cplusplus.com/doc/tutorial/arrays/). A raw array is nothing more than a pointer to a memory location. By dereferncing the pointer you get elements of the array. If it helps, you can consider `array[index]` to be syntactic sugar for `*(array + index)`. Unless you are doing low-level stuff or dabbling in legacy code, you should be using an appropriate [container](http://en.cppreference.com/w/cpp/container) though. 
Please read the sidebar; beginner questions are off-topic here.
`git clean -dxf` tho.
Isn't there an internet rule about any correction of grammar or spelling will include a grammor or speeling mistake? deprication -&gt; deprecation.
Thanks for your hard work and making it avaliable to all the community
**Company:** Stevens Capital Management LP **Type:** Full time, internships **Description:**Stevens Capital Management LP (“SCM”) is a registered investment adviser that manages a multi-billion dollar hedge fund that has been in business for 25+ years. SCM specializes in the rigorous development and disciplined implementation of empirically based quantitative trading strategies. C++ Software Developers Primary Responsibilities • Utilising your in-depth knowledge of C++ you will design, develop and implement proprietary trading programs, encompassing trade analysis, price validation, order routing, monitoring and risk analysis. • Develop and support multi-threaded applications with a strong emphasis on high performance. • Optimize our trading strategy implementation and performance analysis platform using network and systems programming. • Create tools to process, store and analyze quote, order and financial data. • Work closely with our quantitative research analysts, engineers and other groups to provide software solutions. **Location:**Radnor, PA **Remote:** No **Visa Sponsorship:** Yes **Technologies:**C++, Linux **Contact:** recruiting@scm-lp.com 
I may have been ambiguous here. When I say the hardware interface MUST outlive Communication, I mean "bad things will happen if the hardware interface goes away early so make sure it doesn't", and not "it is not possible for the hardware interface to go away early so don't worry about it". The hardware interface is an object the user must create, and a Communication object requires a hardware interface to send messages.
&gt; std::bind is candidate for deprication Is this actually being discussed? I'd like to read the proposal to understand the motiviation
&gt; In theory, they'll believe evidence. Leave theory to the theoreticians. Practice is quite different. &gt; Credentials and seniority don't dictate the facts. And yet, in practice, they usually do dictate what is interpreted as fact.
And I believe it's being proposed for the standard. Manipulating data linearly in caches is more efficient, even for middling sizes, than having to use the random addresses of nodes in tree-based data structures, whatever big O says. 
I've been where you are. The things you're writing about are trivial, so if you're doing what you appear to be--blogging instructional rants to your superiors--I have to say that you're better off just not doing it. Just realize you're under people who don't know what they're doing and decide if you can live with it. If they're not responding to rational argument then nothing else is going to work. In my experience trying down this road just results in headache. They should already know what you're trying to tell them. They don't. They have seniority, and you don't. You can wait around for respect...earning it as you go...but for people and companies this dug in...well let's just say that improvement is unlikely in my experience. So start updating your resume and beginning the search for the next job. See if you can't get an idea what their code is going to look like to see if you're just dealing with another group of bumble-heads or not. It's tough. Several times I have gone to a job excited I'd learn new things and such...and of course I did but none of it was shit I even wanted to know. Like the fact that most people just don't care how good a job they're doing and don't want people rocking the boat they've gobbled together with duct tape and bubble gum. And frankly, the higher the degree the worse it is. The idea that you're smarter because you have the higher degree is just too tempting to most people. Ego gets inflated.
Modern hardware really likes sequential memory access. You may find that your insert is much faster in a vector than in say a list or something due to how the memory is accessed: random vs. sequential. Even though you have to do more to insert into the mid of a vector, it can be much faster...depending on your needs...than inserting into the middle of a list or even in a map...any "linked" data structure. Big O notation isn't all that useful in gaging how fast something's going to be. Not all operations are created equal, especially now.
&gt;So, this is C++. Lifetime is your job as a programmer. Always. So, how would a similar case work in Rust? Will it help you more with this? I invoke /u/steveklabnik1 so we can have an answer.
well for array of size 3 bubble sort is good... In other words nothing you wrote is useful as general guidance. Yes what you claim holds in some circumstance, but are you really gonna put that kind of profiling/maintenance effort instead of simple replacement of vector with a set?
Actually that container has wrong design. I mean I use it and it is fine, but I think it should be immutable(without insert member functions). I know boost people probably wanted to allow drop in replacement of std::set but I think they made a mistake. 
This would be wonderful. I love the flat containers, and they make great building blocks for other things. 
Immutable would be neat for some situations but I think it's a stretch to say the design is wrong. 
Well, I both agree and disagree. We do need a high quality immutable collections library, but I think it needs to be a whole library (got high hopes for immer), not a lonely class in boost. I think that flat_set just followed the std:: and other boost:: collections.
We've now pushed it to July 9th. Don't delay!
 std::transform(vec.begin(),vec.end(), vec.begin(),std::negate&lt;int&gt;()); for (auto&amp; x: vec) x = -x; &gt;It’s so easy and much more readble than doing same thing without using STL. I don't know... the example probably needs some work.
Yes. Lifetimes are a language-level feature of Rust, with special syntax, and so th many compiler checks their validity and fails to compile if there's an issue. Some might argue this is the distinctive difference between the two languages. I'm on my phone so that's all I'll say for now; I'll check out the context and add more detail later.
It's not being deprecated by any current paper. There are proposals to deprecate the old binder features like `bind1st` and so on that are superceded by `bind`. The reasoning that deprecation of `bind` itself given in the past comes down mostly to: - `bind` offers no strictly-necessary functionality over modern lambdas and keeping it in the standard is considered by some to be "bloat." - `bind` is a PITA to implement and maintain and imposes a burden on implementers. - It's a teaching snafu were new users have to learn two ways to accomplish the same goal. - `bind` mechanically is much heavier-weight than lambdas, requiring more translation overhead, and worse runtime efficiency when optimizations are disabled/weakened/failing. The counterpointers can be summed up as: - Real in-the-wild code uses `bind` because the necessary lambda features are really new. - Some simpler expressions are easier to express with `bind` than with lambdas. - It isn't broken or entirely outmoded and doesn't really warrant removal at this point.
This is an interesting alternative: https://github.com/seiflotfy/cuckoofilter https://www.cs.cmu.edu/%7Edga/papers/cuckoo-conext2014.pdf
The old binders were deprecated in C++11, then removed in C++17 by my [N4190](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4190.htm) "Removing auto_ptr, random_shuffle(), And Old &lt;functional&gt; Stuff".
you people are overcomplicating... all you need is some google style macros const int a = OASSIGN(f1()); const int b = OASSIGN(f2(a)); 
Watch out, combining weak_ptr and make_shared is dangerous as the refcnt and object are stored together, and must be deallocated together, making the weak_ptr's existence prevent the objects memory from being freed.
If your program links in a data compression library of any kind, that by itself is probably enough to put you across the "flexible view" threshold.
Just curious, what makes std::strstream hang around strongly? Is anyone looking to remove it? Edit: oh, [nevermind](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0619r0.html#3.6), i suspected that would be the case.
Okay so, some more context: Rust has a type like shared_ptr, called `Arc&lt;T&gt;`. Rust has closures, but they operate differently than C++'s; we don't make you write out capture clauses, we infer them. A sort-of-but-not-quite translation of the sample code into Rust looks like this: use std::sync::Arc; struct Leak { callback: Option&lt;Box&lt;Fn()&gt;&gt;, } impl Leak { fn on_complete(&amp;mut self, f: Box&lt;Fn()&gt;) { self.callback = Some(f); } fn clean_something_up(&amp;self) { println!("cleaning"); } } fn main() { let mut obj = Arc::new(Leak { callback: None }); obj.on_complete(Box::new(move || { obj.clean_something_up(); })); } The compiler will not let you compile this: error[E0504]: cannot move `obj` into closure because it is borrowed Rust sees that the call to `on_complete` would borrow `obj`, but the closure is trying to take ownership. This conflicts. We can solve this problem by calling `clone()` on the `Arc&lt;T&gt;`, which bumps the refcount, and gives us a second handle. `shared_ptr` does this whenever you copy it, but in Rust, it's always explicit. Furthermore, it complains about something else: error: cannot borrow immutable borrowed content as mutable Unlike `shared_ptr`, `Arc&lt;T&gt;` requires that its internals are immutable, for thread safety reasons. We can convince Rust that this is okay by using "interior mutability", which is a type that is immutable, but lets you mutate it in certain circumstances. A `Mutex&lt;T&gt;` is an example of this. If we didn't need thread safety, we could use `Rc&lt;T&gt;` and `RefCell&lt;T&gt;` instead of `Arc&lt;T&gt;` and `Mutex&lt;T&gt;`, and they'll be less expensive. I kept the threadsafe ones to try to keep the comparison equal. With these two changes, you get this: use std::sync::{Arc, Mutex}; struct Leak { callback: Option&lt;Box&lt;Fn()&gt;&gt;, } impl Leak { fn on_complete(&amp;mut self, f: Box&lt;Fn()&gt;) { self.callback = Some(f); } fn clean_something_up(&amp;self) { println!("cleaning"); } } fn main() { let obj = Arc::new(Mutex::new(Leak { callback: None })); let obj2 = obj.clone(); obj.lock().unwrap().on_complete(Box::new(move || { obj2.lock().unwrap().clean_something_up(); })); } This compiles. And it has the same problem the C++ has; you now have a structure that contains a reference count to itself. The advice from the OP to use `Weak` here is a good one; you could do that in Rust as well. Note that lifetimes don't come into play at all here; we're using types that have ownership. What does make these examples different is the level of ceremony involved: * Rust makes you explicitly bump the reference count * Rust makes you lock the mutex It's subjective, but one of the things that I got out of the OP was &gt; While it may not be immediately obvious, the implications of this are extremely important! I think Rust makes it a bit more obvious what's going on here. I would, of course :p On the flip side, maybe leaking is okay, and this behavior is what you want: if that's true, Rust makes you do a lot more work than C++ to get this behavior. So that's a downside. However, if I wanted to do something like this in Rust, I wouldn't write this code. I'd start with this: struct NoLeak { callback: Option&lt;Box&lt;Fn(NoLeak)&gt;&gt;, } impl NoLeak { fn on_complete&lt;F: Fn(NoLeak) + 'static&gt;(&amp;mut self, f: F) { self.callback = Some(Box::new(f)); } fn clean_something_up(&amp;self) { println!("cleaning"); } } fn main() { let mut obj = NoLeak { callback: None }; obj.on_complete(|obj| { obj.clean_something_up(); }); } This doesn't need a `shared_ptr` at all. Instead of capturing `obj`, we instead define our callback to take a `NoLeak` as an argument. Then, later, (not shown in either example), when we actually invoke `self.callback`, we end up passing it in instead. Notice that `'static` up there? This is a lifetime. This is needed, and if you don't include it, Rust will complain. Why? Well, callback: Option&lt;Box&lt;Fn(NoLeak)&gt;&gt;, is shorthand for callback: Option&lt;Box&lt;Fn(NoLeak)&gt; + 'static&gt;, Which basically says "hey, this closure can only capture `'static` references if it captures any references at all." We don't get the shorthand in the function definition. Without this annotation, it'd be similar to the first solution given in the post, but with the same problems: &gt; The most obvious (and the one I do not recommend) is to capture the raw pointer for your lambda to use. This has a major downside, though, in that the object might be deleted before you try to reference it, and you have no way of knowing it. At least it won’t hold an extra reference, though. We're promising Rust that anything we capture is owned, or is alive for the entire program. If we tried to capture a shorter reference, one which might end up being dangling, Rust would complain. This restriction is onerous though: we can do better! Here's some lifetime-fu: struct NoLeak&lt;'a&gt; { callback: Option&lt;Box&lt;Fn(NoLeak) + 'a&gt;&gt;, } impl&lt;'a&gt; NoLeak&lt;'a&gt; { fn on_complete&lt;F: Fn(NoLeak) + 'a&gt;(&amp;mut self, f: F) { self.callback = Some(Box::new(f)); } fn clean_something_up(&amp;self) { println!("cleaning"); } } fn main() { let mut obj = NoLeak { callback: None }; obj.on_complete(|obj| { obj.clean_something_up(); }); } Note the `'a`s now. This tells Rust that we want to be generic over a lifetime; and so you _can_ pass in references to things that are shorter than the lifetime of the program, but Rust uses those to check things are okay. Like this: fn main() { let mut obj = NoLeak { callback: None }; let x = 5; obj.on_complete(|obj| { &amp;x; obj.clean_something_up(); }); } Here, we create an `i32`, and inside of the closure, we take a reference to it, so we capture a reference to it. Why is this bad? Well, let `rustc` give you the answer: error: `x` does not live long enough --&gt; &lt;anon&gt;:21:14 | 20 | obj.on_complete(|obj| { | ----- capture occurs here 21 | &amp;x; | ^ does not live long enough ... 24 | } | - borrowed value dropped before borrower | = note: values in a scope are dropped in the opposite order they are created As the note mentions, things are dropped in the reverse order they're created; this means that `x` will go out of scope before `obj` will, and so `obj` could observe a dangling reference! This is exactly what I alluded to earlier: Rust checks that your lifetimes are okay, and if they're not, will fail to compile. We can fix this by moving `x` above `obj`: fn main() { let x = 5; let mut obj = NoLeak { callback: None }; obj.on_complete(|obj| { &amp;x; obj.clean_something_up(); }); } Now everything is cool. `obj` goes out of scope before `x`, so it will not dangle. Finally, I agree with the other posters in this thread, both for C++ and Rust: "The correct advice, on your website, should be to ensure there are no shared_ptr loops in your software." (quoting someone above) That's much better than "never use shared_ptr", which is genuinely useful! Whew! That was a lot of text; I hope it was helpful! Happy to answer any more questions.
Please include a Remote line, as listed in the template, even if the answer is No.
Please include a Remote line, as listed in the template, even if the answer is No.
Please add a Remote line to your posting, as requested by the template. I am not sure why all 3 postings so far have omitted the Remote line; I suspect some amount of imitation happening, so the early postings should be corrected before it gets out of hand. Thanks!
Because category theory is becoming more popular, we now refer to functors as callables, function objects or if you're feeling cheeky, funjects or fubjects. I clicked on this link and was severely disappointed by now Future functor T_T
Yeah, the other example isn't much better. std::transform(vec1.begin(),vec1.end(), std::back_inserter(vec2), std::bind(std::plus&lt;int&gt;(), std::placeholders::_1, ELEM_TO_ADD)); versus: for(auto&amp;&amp; val : vec1) vec2.push_back(val+ ELEM_TO_ADD);
Thank you &amp; you are welcome. I enjoy working with and for the c++ community. Yet, some things are less work then they used to be, as my lazyness lets me automate things often ;) It felt a bit strange, when I was able to decouple my work from my income, but it was worth it, as the conference scales well. When you work as a freelancer, its quite the opposite. Meeting Scott Meyers in 2014 was one of my highlights of the recent years. But also one of the down sites: I know a lot of things I didn't ask for. Like that Scott wants to retire, quite a shocker, but also well, can't tell anyone that... Boy was I happy when he went public with that. And 'Fame' is a topic of it self, had really good conversations about this with Scott, but also Sean Parent, and just at this years C++Now with Jason Turner, about that weird second where some stranger knows your name and who you are. From meeting and working with most of our "famous C++ folks", the one thing that amazes me, is that all of them stayed normal. And that they enjoy the contact and exchange with C++ programmers at various conferences. I think the sharing of knowledge and willingness to learn new things is some of the core values of the C++ and other programming/nerd communities.
Great, thanks for the feedback, I didn't realize it was descended from the existing codebase.
Snarky answer #1: What's he doing in the video? He is speaking. Snarky answer #2: It turns out we can't put video of the 2017 conference in the 2017 promo video. Something to do with laws of physics related to time. We have to use video clips from earlier conferences. There is no guarantee that everyone (or even anyone) in a particular year's promo video will be attending that year's conference. Snark free answer: Scott is not scheduled to speak.
Is "functoid" still free?
Yes, exactly, the statement in the post sacrificed precision in order to get the point across in a readable fashion, sorry if that was confusing.
Making the videos available om youtube is insanely valuable, thank you for doing this. Also, I'm loving your passion for C++ and its community.
[removed]
`void main(...)` is non-conforming. https://isocpp.org/wiki/faq/newbie#main-returns-int Stop teaching that!
&gt; #include&lt;iostream.h&gt; &gt; #include&lt;conio.h&gt; &gt; void main(){ &gt; int a=10,b=20,c; &gt; c=a+b; &gt; cout&lt;&lt;“The sum of a and b is:”&lt;&lt;c&lt;&lt;endl; &gt; getch(); &gt; } Do you intend us to make fun of this example?
This is the worst: int a=10,b=20,c; Why not int a = 10; int b = 20; int c = a + b; In my view, one should avoid the (,)-operator, and one should avoid uninitialized variables. 
There was no comma operator in that code. Those commas are just punctuation, not operators (though, in fairness, they do lead to ordering, so they sort of act like a comma operator, unlike some other places where commas are just punctuation).
"Because of one man's quest against the windmills, some really sad people are now trying to change a word we've been using for the last twenty years to mean something else because they feel their use is better than ours." Next they'll try to convince us that we should stop using 'integer' to refer to integers, and use 'finite Abelian group' instead...
 int a=10,b=20,c; would be the same as int a = 10; int b = 20; int c; not sure how you got the `a + b`.
But [undefined behavior can result in time travel](https://blogs.msdn.microsoft.com/oldnewthing/20140627-00/?p=633)!
I hear you. However, this type of thread is fairly common. We have this discussion a few times a year.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6lrn8j/c_program_structure/djw5flq/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It is in the next line. Variable c is first declared without initialization, and initialized in the next line.
Thanks for the info. Wasn't trying to be snarky, sorry if it came across that way. Just that with Scott Meyers being retired, I was curious whether he would be speaking there (since he *was* a keynote speaker at DConf). Otherwise, the promo fragment is a borderline case of false advertising, IMO.
Use of non standard headers - Check Use of ancient standard (iostream.h, no namespaces) - Check void main() - Check Improper/missing indentation - Check What a great way to start my morning.
Is this audio only?
The L2 caches are private by design. It would take a lot of reworking (and be pointless with a public L3 design that was a victim cache) in order to do it. Also, no way to determine from our side why certain silicon was downgraded - defect, VF scaling, other etc
I was sceptical about your last post, but this is really neat. It might be worth pointing out to readers that you are using fold expressions in make_failable. The unfamiliar syntax caused me to do a bit of a double take.
yes.
&gt; Note that this particular implementation accepts functions, but not more general callable objects. You should be able to support arbitrary `Callable` objects taking the `Callable` as a template parameter. Something along the lines of: template &lt;typename F&gt; constexpr auto make_failable(F&amp;&amp; f) { return [f = FWD_CAPTURE(f)](auto&amp;&amp;... xs) -&gt; std::optional&lt;decltype(FWD(f).get()(*(FWD(xs))...))&gt; { if ((xs &amp;&amp; ...)) { return {FWD(f).get()(*(FWD(xs))...)}; } else { return {}; } }; } Where `FWD` is a macro that expands to `forward&lt;decltype(_)&gt;(_)` and `FWD_CAPTURE` is [a way of capturing objects either by lvalue reference or by move](https://vittorioromeo.info/index/blog/capturing_perfectly_forwarded_objects_in_lambdas.html). This makes the overloading trickier, but something like [CallableTraits](https://github.com/badair/callable_traits) could probably be used to detect the arguments of `F`.
Yes, it's [Muphry's Law](https://en.wikipedia.org/wiki/Muphry%27s_law).
[removed]
Yeah, this is handy for an actual implementation, but it really does distract from the idea the blog post is trying to get across. 
Agreed, I'm not suggesting to replace the snippet in the blog post. Just thought I'd share :)
Em, in Haskell, that's fmap and join？
are you going to do one for every single programming language....
You're welcome &amp; Thats really important to me. One of the motivations for starting Meeting C++ as a Content Network was also to have better distribution of C++ content. Back in 2012 I saw this as one of the main problems with the new standards, that wasn't really solved. And its still an interesting question, on how are we going to bring all that knowledge to the community? How are we reaching the C++ programmers out there? Conferences themselves don't make a dent, they barely scratch the surface. The videos then make the difference. Also I still do the editing, so its also a ton of work, but got me into doing video and now the recording/live streaming formats. Also that way I get to see a little bit or all of most talks.
Yes, I can feel the issue now as you wrote same thing without functors. I wanted some example which are good for newbie (not tough to read and understand) and at same time the example should prove worthiness of the functionality. But I think I was not able to achieve same. From next time I will work more on example. Thanks for your valuable comments. 
What is the advantage of an immutable flat_set over a const flat_set?
&gt; Just Thanks for letting me know. I will make sure that I work more on example and will write better examples. 
According to this stackoverflow discussion this should be a non-issue? https://stackoverflow.com/questions/13535827/do-stdweak-ptrs-affect-when-the-memory-allocated-by-stdmake-shared-is-deallo
Immutable whould have a function to create a mutated version which would not induce a copy-then-insert (it would have less moves). The benefit I see here from having an immutable API (besides the usual benefits of immutable/persistent data structures) is that it would 'dictate' the best-use for a structure like this one - search often, modify rarely.
Thanks. I'd be interested in seeing some real uses for this, but the contrived examples don't work very well.
There's never enough Discord servers
&gt; Immutable whould have a function to create a mutated version which would not induce a copy-then-insert (it would have less moves). Not a super intuitive API though. Much like immutable strings, making a change requires assigning back to the original. &gt; The benefit I see here from having an immutable API (besides the usual benefits of immutable/persistent data structures) is that it would 'dictate' the best-use for a structure like this one - search often, modify rarely. It's possible I don't get it, but I really don't see the benefit of immutable APIs, because they do exactly as you say -- dictate their use. In my experience, this is a bad call because *you* can't possibly know the best solution to *my* problem. I think it's generally better form to build an API that encourages the intended use, but doesn't prevent edge cases that I might *need* to solve my problem. 
No. The original can not be changed - proper immutable structures are single-assign. It is not like immutable strings - with strings, the immutability is an implementation detail, with immutable data structures, it is a *philosophy* :) Namely, a lot of functional programming concepts focus or rely on immutability. And (obviously, depending on the use-case) make software design much cleaner, though initially completely counter-intuitive. One of the things that people claim to be the reason behind the rise of FP in the recent years is that immutable data works much better with parallelization (since we are in the multi-core era) than mutable data [1]. Now, it is a fact that an immutable vector-based flat_set would not be a proper immutable data structure since it has no data sharing, nor efficient copies. But that is how it 'suggests' that updates should occur rarely. &gt; In my experience, this is a bad call because you can't possibly know the best solution to my problem I completely agree. That is why I love C++ more than other languages - you can choose exactly what you want: - which data structure you want for a particular use-case - flat/vector-like, hash-based, rb-tree-based, a trie, etc... - whether you want a mutable or an immutable one (that is why I'd like immer to become an immutable equivalent of std:: classes - to be a viable choice) - do you need allocators or not - do you want access checking or not - etc. Other languages put limitations which are really hard to bypass. [1] You can check out a nice post from John Carmack on the topic http://www.gamasutra.com/view/news/169296/Indepth_Functional_programming_in_C.php
Another option (pun not intended) is to use the range syntax. Since `optional` is kinda like a collection with zero or one item, it would be ok to have `|transform`, `|filter`, `|join` etc. on it.
Use `std::inplace_merge` when you want to insertion sort. Can I get a code review of this alternative to the OP code? #include &lt;vector&gt; #include &lt;iostream&gt; #include &lt;algorithm&gt; #include &lt;array&gt; void display_vector(const std::vector&lt;int&gt; &amp;v) { std::copy(v.begin(), v.end(), std::ostream_iterator&lt;int&gt;(std::cout, " ")); } int main() { // imagine you read unsorted contents from file or network // std array is used for convenience and keep example simple std::array&lt;int, 6&gt; unsorted_collection{ 51, 23, 46, 32, 76, 18 }; std::vector&lt;int&gt; sortedVec; for (int n : unsorted_collection) { sortedVec.push_back(n); std::inplace_merge(sortedVec.begin(), std::prev(sortedVec.end()), sortedVec.end()); display_vector(sortedVec); std::cout &lt;&lt; std::endl; } return 0; } It should be more future-proof to the requirement that we get chunks of data which we want to sort and then insertion sort into our vector. 
This is more like `&lt;$&gt;` and `&lt;*&gt;` for Applicative (like `liftA2`). He's taking a function that is invoked like `f x y` and turning it into a function that is invoked like `f &lt;*&gt; x &lt;*&gt; y`.
Before, we had (assuming abbreviated lambdas) ox &gt;&gt;= x =&gt; oy &gt;&gt;= y =&gt; f4(f4 (f3 (f2 (f1(x), f1(y))))) Now, we have to initially pre-wrap all the functions (hopefully none are overloaded!), which is something you'd have to do inline everywhere. So you have to introduce a lot of new declarations or wrap each function at the point of call. This doesn't seem very practical to me, sorry.
You cannot reliably pass C++ classes between components that were compiled differently. You're correct that they may be using a different definition and implementation of the class but more subtly, the padding between the members of those two objects may be different. Instead you need to marshal the data via a format that is the same between these two components. For a DLL in your process a char array is often used to represent a string.
Personally I have just one thing I dislike: I think the abbreviated lambda should default to empty capture `[]` and not capture everything by reference `[&amp;]`, to follow the spirit of "only paying for what you use". Otherwise, I'd be happy if something like this made it into the Standard. I often feel that lambdas are unnecessarily verbose.
This syntax is in dart, and it is helpful. In fact, I'd like to see it in regular functions too.
I would vote against that. Two ways to express the same thing means "added complexity", which defeats the original purpose. 
Quite similar to the javascript lambda. I would personally rather like it, but there's the usual "auto" caveat applicable here that sometimes knowing the type is better for readability instead of worse.
You already have two ways for expressing this. (lambdas and function objects)
Applied many times through the website, but most of times, I've got no reply at all
http://en.cppreference.com/w/cpp Not that "quick", but C++ is a large language and I am not sure is any "quick cheat sheet" would be of any use. 
That's fantastic, thank you. And I continue to learn how large the language is and I have much to learn. This looks like a great reference though.
&gt; I completely agree. That is why I love C++ more than other languages - you can choose exactly what you want: &gt; which data structure you want for a particular use-case - flat/vector-like, hash-based, rb-tree-based, a trie, etc... &gt; whether you want a mutable or an immutable one (that is why I'd like immer to become an immutable equivalent of std:: classes - to be a viable choice) &gt; do you need allocators or not &gt; do you want access checking or not &gt; etc. &gt; Other languages put limitations which are really hard to bypass. Heh, these are the reasons I too prefer C++ over other languages.
This is a syntax enhancement. Is that really too complex? Is std::array also added complexity?
&gt;Functions with arguments that could fail `std::optional` isn't a particularly good way of handling this since it can't communicate anything about **why** the operation failed. Perhaps you should look at something like [Outcome](https://github.com/ned14/outcome) which already has support for map and bind.
What makes you think that `[&amp;]` captures everything by reference? &gt;A *lambda-expression* with an associated *capture-default* that does not explicitly capture `this` or a variable with automatic storage duration (this excludes any *id-expression* that has been found to refer to an *init-capture*'s associated non-static data member), is said to *implicitly* capture the entity (i.e., `this` or a variable) if the *compound-statement*: &gt; &gt; — odr-uses the entity, or &gt; &gt; — names the entity in a potentially-evaluated expression where the enclosing full-expression depends on a generic lambda parameter declared within the reaching scope of the *lambda-expression.* §5.1.2 [expr.prim.lambda]
No, boilerplate is the real added complexity. Less boilerplate = simpler code. I'd gladly have a slightly more complex language for simpler code.
Yes you're right, it's mentioned now.
Personally I don't see a huge advantage of implementing this new syntax. At first glance it is clearer sure but I don't think it is by a large margin that worth the benefit. Also like @sztomi said if we ommit the capture, it should not capture anything at all, so other variables aren't captured by accident.
&gt; I think the abbreviated lambda should default to empty capture [] and not capture everything by reference [&amp;], to follow the spirit of "only paying for what you use". you won't pay for stuff that isn't used in the lambda anyways. void f(); auto nocapture(const int&amp; bar) { int x; return [] { f(); return 123; }; } auto value(const int&amp; bar) { int x; return [=] { f(); return 123; }; } auto ref(const int&amp; bar) { int x; return [&amp;] { f(); return 123; }; } void check () { static_assert(sizeof(nocapture(2)) == sizeof(value(2))); static_assert(sizeof(nocapture(2)) == sizeof(ref(2))); } 
That's an interesting point you're making, where to declare the wrappers. Thanks for pointing that out!
TemplateRex, I wan't implying that your question was snarky. Yours was a legitimate question. It was my answers that were snarky. (If I'd felt that your question was snarky, I probably wouldn't have bothered labeling my answers as snarky. I only labeled them as snarky to point out that you deserved a better answer than I was giving.) I did think about this when I first saw that video myself. Background: The promo videos are produced by Bash Films. I give them a long list of quotes (the favorable ones, of course) from attendee surveys and they have all the video that they have recorded at past events and they try to make something creative and compelling. Technically, we could ask for changes and perhaps we have asked for minor ones, but mostly, we've used what they give us. To them Scott is just another speaker. (They know he is important, because he was our first ever keynote speaker.) You could argue (as you have) that showing Scott speaking is "is a borderline case of false advertising," but my snarky answer was to point out that, any video that we show *has to be* from previous conferences and viewers should be able to figure that out. The implication of any clip you see in the promo video must be, "this is what happened in previous conferences (so if you like you might want to attend the next one)." If you think about the interpretation of the video as "this is exactly what you'll see this year," then it obviously falls apart. Even if Scott were to attend, he wouldn't say (again) *exactly* what he said in the clip. If you happened to spot someone you recognized in one of the crowd shots, you couldn't assume that they will be at the next event. Consider, we are going to have the Jim Basnight Band again this year. But if we were to change bands, would we have to not show Jim's band in any promo videos, because it would be false advertising that we'll have Jim again? I think the only rational interpretation of seeing Scott in the clip is "Scott spoke here before and you can draw conclusions about what kind of speakers will be presenting in the future." At least that is the path that my mind went down when I saw the clip of Scott in the video. Perhaps this just sounds like rationalization. Perhaps it is. See you in September. Jon 
&gt; Two ways to express the same thing means "added complexity" it's only added complexity for the implementors. for the users it's "added simplicity".
Good to know, I guess I misunderstood that syntax. Thanks for the clarification.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; to follow the spirit of "only paying for what you use" You have it backwards. You pay for copies, you don't pay for references.
This syntax would make so much of my code easier to read. I really hope it will be added to C++!
An empty capture list won't capture anything (neither by value nor reference)
&gt; &gt; &gt; for(auto&amp;&amp; val : vec1) &gt; vec2.push_back(val+ ELEM_TO_ADD); &gt; what's the point of &amp;&amp; if you aren't going to move it ? const auto&amp; would be better here imho.
Habit mostly, but auto&amp;&amp; doesn't move, it just accepts either lvalues or rvalues. See https://stackoverflow.com/questions/13230480/what-does-auto-tell-us
From this answer: &gt; The problem with using a const reference is that it's const! I'd say that something being "const" is quite desirable, and certainly not a problem. It should be const by default, and `auto&amp;&amp;` if we need to use it.
What do you think about range-based for loops? Or, for that matter, for loops in general? It's just another way to express a while loop...
Yes, these complications aren't needed. I don't like the situation with operators in Haskell, but this proposal is even worse: it lacks composability and regularity.
Actually for range loops do more than simplify the code, they prevent logical errors like accessing out of bounds.
It resembles [C#'s expression lambdas](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/lambda-expressions) quite closely. I personally don't mind it. Though in practice (in C#), I find myself rarely using this notation, as you often need more than 1 statement in "real-world" use-cases. I don't believe we gain anything of great value with this proposition.
&gt; it works as long as x is movable, but it fails if x is not, so &gt; `auto blah = std::mutex{}; ` actually this works in c++17. My favorite is option C though (the less typing the better): std::mutex blah; std::string foo{"bar"}; 
Ah I see. Thinking about UB, I should remember to put aside thinking about well-known architectures like x86 and ARM. While in x86 and ARM we can define invalid pointers without any side-effect (as the pointer values are basically integers stored in a memory without any dereferencing), in some unknown (but possible) architecture, this could lead to system exceptions (e.g. SEGFAULT), OS crash, or anything. C++ standard doesn't assume anything in this case which in essence is: Undefined Behavior. 
Thanks Jon, much appreciated to have such a thoughtful answer. I know how much work organizing a conference is (not at that scale though), and w/ or w/o Scott, CppCon will be the highlight of the year for C++ programmers. I'll be watching from home, but I enjoyed all of them so far. So good luck with organizing it again this year! 
I'd support this feature if the parsing rules are defined such that it'll be useful for writing monadic code. optional&lt;int&gt; my_result = some_optional_int &gt;&gt;= [](i) =&gt; i &gt; 5 ? optional&lt;string&gt;{to_string(i_)} : {} &gt;&gt;= [i](key) =&gt; some_map.lookup(key) &gt;&gt;= // lookup returns an optional&lt;int&gt; [i](val) =&gt; i + val; Let's see... for that to work, we'd need to be able to nest these lambdas, and they should have lower precedence among all existing operators, so that `[](x) =&gt; y &gt;&gt;= z` is parsed as `[](x) =&gt; (y &gt;&gt;= z)` instead of `([](x) =&gt; y) &gt;&gt;= z`.
&gt; auto blah = std::mutex{/*whatever*/}; &gt; actually this works in c++17. How? If Move and copy are not available its interpreted asif it was: &gt; std::mutex blah{/*whatever*/}; ?
What benefits does discord have over IRC? From what I see it only has a major drawback: It's not free software.
My reading of the answers there confirm my warning; when allocating using make_shared, the object will be destroyed when all shared_ptrs to it are destroyed, but the memory it occupied will not be reusable until after all weak pointers created for it no longer reference it.
I tried CppCheck and one of the first few things it pointed out was a failure to parse C++ correctly - it doesn't handle delegating constructors and thinks all member variables aren't being initialized in any constructor that uses them. It also fails to handle variable reassignment within if blocks: if (!this-&gt;value) { this-&gt;value = *expression*; if (this-&gt;value) { ... } } And reads the 2nd if as broken since it fails to see the reassignment.
I quite often find myself writing something of form `[] (anything something) { return nothing(something); };` and thinking "oh, I wish I could omit the `{}`".
http://en.cppreference.com/w/cpp/language/copy_elision
C++17 has guaranteed copy elision in this case. Note that this means that the class in question no longer needs a copy or move constructor because this is no longer just an optional optimisation, the creation of a temporary no longer takes place. Therefore, as doom_Oo7 showed, the "almost always auto" initialisation style works in C++17 even with non-copyable-non-movable types. Edit: see the first section of http://en.cppreference.com/w/cpp/language/copy_elision
I like it.
… just right now on_scope_exit guard{[&amp;] { png_destroy_read_struct(&amp;png_ptr, nullptr, nullptr); }};
&gt;C++17 has guaranteed copy elision in this case. Cool.
Omitting the return statement still returns a value? What if you don't want your lamba to return a value?
A default capture won't capture anything either--unless it's actually used inside the body of the lambda.
I'd go a step further and permit the omission of the parameter declaration completely. A few languages have this type of syntax. From Elixir: ``` &amp;(foo(&amp;1 + 2)) ``` Defines a function taking one parameter (which is substituted for `&amp;1` in the expression). C++ already has a lot of uses for the `&amp;` symbol. So maybe we could use `@`? That's not used ATM. If C++ has a similar syntax, we'd be able to: // Old, sad sort-by-length sort(a, [](auto&amp; a, auto&amp; b) { return a.size() &lt; b.size(); }); // Magic!! sort(a, @(size(@1) &lt; size(@2))); We also have sadness with not being able to pass overload sets as function parameters (They must be cast to a function type). We can kind of get close with a super-abbreviated syntax: template &lt;typename Num&gt; auto one_more_than(Num a) { return a + 1; } auto numbers = get_some_numbers(); transform(numbers, numbers.begin(), @one_more_than(@1));
Not having to memorize archaic obscure commands to do the most basic things like register and login. Supporting unicode, multi-lines, inline-formatting (including syntax highlighting), easy to invite people, easy to create your own server. And most of all, more people use Discord than IRC. What _does_ IRC have over Discord? Discord's API is public too, so being "free" doesn't affect 99% of users.
The existing syntax is still available for that case. Do you have any examples of when this would make a difference, though? It sounds like a really rare scenario. 
&gt; The L2 caches are private by design Well Infinity fabric means all cores in chip are connected. Problem is that IDK if IF is just for accessing RAM or it can get data from other core L2. Plus many other problems... :)
Please note that this is C++, not Python, so there is no inherent philosophy imposed by a benevolent dictator forcing us one and only one way to do something. Also, there are valid reasons to have multiple ways of doing things. Sometimes, it's expressiveness. And sometimes, it's the price we pay for having both backward compatibility (yay! functors!), the current spec (yay! verbose lambdas!) and going forward (yay! abbreviated lambdas!). We should not let ourselves be fossilized into one notation just because, at one time, it was standardized. People makes mistakes, change viewpoint. Let's accept that, and go forward. This way, we can simplify the notation, and never tell the newbies how verbose the language was before their birth.
Seems to me that the return value of `x =&gt; foo(x)` is `decltype(foo(x))` allowing one to return void as well. You could even use a void cast to make it explicit in the case of valued expressions.
Though the new syntax won't be worse than the status quo, as one already can omit the return type in the lambda (and sometimes get surprising result, e.g. `[](const int&amp; x) { return x; }` returns `int` instead of `const int&amp;`).
I guess you never used LINQ? `ienum.Where(n =&gt; Filter(n)).Select(n =&gt; Selector(n)).SkipWhile(n =&gt; Skip(n))` etc.
Yeah, I considered saying you could do `foo(x), void()` or something similar, but full lambda syntax would be cleaner IMO.
While I typically use the query syntax, I have to agree. I use this syntax all the time with Linq stuff
&gt;\&amp;#8212; Same.
C++ static analysis tools should really be using something like libclang... parsing C++ is difficult enough you should really only be doing it in one place: your compiler. Visual C++ afaik still isn't available in a "library mode" like clang is, but I think this is changing, they've [already begun](https://blogs.msdn.microsoft.com/vcblog/2015/09/25/rejuvenating-the-microsoft-cc-compiler/) this refactoring internally for their own built-in static analysis.
but this fails on both GCC 7.1 and Visual Studio 2017, and both compilers claim that they support guaranteed copy elision https://godbolt.org/g/d7wevp
It's a C++17 feature. With GCC 7.1, compile with --std=c++17. 
okay, it works on GCC 7.1 now but still no luck with Visual Studio 2017 15.3 Preview, even tho I have specified /std:c++17... compiler bug in vs2017?
Is the feature supported on that version of VS? I'm a Linux dev, so I don't know off hand. 
C++17 guaranteed elision/prvalues means that `[&amp;]{return pr_expr;}` and `[&amp;]{pr_expr;}` differ only in that the dtor for the pr_value happens after the other temporaries in the expression, as far as I can tell, assuming the return value is not used. This should rarely matter. 
### TL;DR Don’t use C or C++. Use (safe) Rust instead, and have a 100% compile-time guarantee that none of these will ever happen.
&gt; Perhaps you should look at something like Outcome which already has support for map and bind. Alas, due to Boost peer review feedback v2 has lost all things monadic. Changelog can been seen at https://github.com/ned14/outcome/blob/master/Readme.md
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [ned14/outcome/.../**Readme.md** (master → 05c37e6)](https://github.com/ned14/outcome/blob/05c37e619f0178dcd9ce332a18dad869d6cd5ff5/Readme.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djxjojl.)^.
Rust is the language that meets that goal. It is, IMO, the true successor to C++.
According to [this](https://blogs.msdn.microsoft.com/vcblog/2017/05/10/c17-features-in-vs-2017-3/), support for that feature is coming in VS2017 Update 3, which is not yet released.
Time to fork v1 and never update I guess. Why would anyone prefer standard if-based handling over map &amp; bind with lambdas? 
The wiring language in arduino is C wrapped around C++. If you check the core drivers it's C.
MSVC is unfortunately a ways away from "library mode", but the refactoring you link to has helped make static code analysis (and the compiler!) far more accurate. Nothing annoys me more than code analysis tools that don't parse the language correctly. I agree with your sentiment completely.
Changing the lambda's return type can make a difference in contrived scenarios where the code taking the lambda introspects the return type and tries to be smart. I've seen some examples of this kind of "overloading on steroids" that work out pretty well, but nothing as extreme as introspecting the return type. The simplest case of this would be a function whose return type is inferred from the invoked object's return type (e.g., `std::visit`), but that just bubbles the problem up a layer - why does it matter whether that one returns something or nothing? 
Yes it is a small improvement, just like range-based for or `static_assert(cond, msg);` (vs. `char _unused[bool(cond) &amp;&amp; msg];`). But as a frequent user of lambda expression, I think the `=&gt; expr` form is an important improvement that make simple things less noisy and less error-prone.
I really like the idea and the use case of error handling with linear code flow (much like exceptions), the unintuitive syntax less so. So we're on the same page here. This example is pretty much an application of the insight that a presenter tried to convey on one of last year's conferences (totally forgot his name and where he gave his talk, may be ACCU): co_await and friends are metaprogrammable control flow. Now throw in some metaclasses, stir carefully and let it simmer for a while ...
I don't think pattern matching is relevant to this proposal, neat as it would be
Forgot about one thing earlier, the shortest and prettiest way to do "std::string" should be auto foo = "bar"s;
Do you plan to support `GEORADIUS`?
There's no pattern matching involved in the code I gave above. Just nested lambdas.
I think this kind of thing is a killer app for coroutines and it's a real shame that the keywords are (currently) named in such a way as to make it look horrifying. For an implementation that works with plain optional, see https://github.com/toby-allsopp/coroutine_monad. However, this only works with clang because, as you point out, MSVC converts the return object too early. I have confirmed with Gor that this is a bug in MSVC that will be fixed in an update, hopefully this year.
&gt; I have confirmed with Gor that this is a bug in MSVC that will be fixed in an update, hopefully this year. That's awesome! I didn't expect that at all. Off-topic, Gor is an MVP for his work on all of this, especially improving LLVM instead of only MSVC. That has definitely boosted Clang's coroutines progress extremely well.
&gt; If co_await had a less misleading name, this would lead to more readable code. Why is `co_await` misleading? You never really explained that. `co_await` creates a suspend point that acts on an `Awaitable` object. The suspend point generates calls to each of `await_ready()`, `await_suspend(...)`, and `await_resume()`. Perhaps the `co_await` nomenclature isn't perfect because it can be used in cases that don't require "waiting" on an asynchronous operation (or perhaps for other reasons). Maybe `co_suspend` would be better? &gt; Think co_await makes absolutely no sense when reading that code? Yes, because I think using `co_yield` makes more sense in your examples. Why aren't you using that? &gt; The reason I'm unhappy with this is that in order for convenience, I pay the cost of a shared_ptr every time. That's pretty hefty. And it's frustrating because it feels like I shouldn't need one. I can think of a couple of ways to get around this. [This is the best way I could come up with](https://gist.github.com/EricWF/ab67d85ae3fea249669e51a0b71b8715). But this only works for coroutines which are never explicitly resumed by the caller (which is what your examples do). Could you provide fuller examples? The parsing example you discuss on reddit seems quite different from the provided code. PS. Unless you explicitly `co_return` or reach the end of a coroutine, you have to manually destroy the coroutine (and free its memory) via the coroutine handle. (Which you don't do in the sum example).
&gt; Why is co_await misleading? You never really explained that. The feature is designed around asynchronous code, where `co_await` fits perfectly well, although many would prefer plain `await`. It fails to convey the semantics being applied for arbitrary monadic purposes, at least to me. &gt; Yes, I think co_yield makes much more sense in your examples. Why aren't you using that? I didn't think of it. Then again, I infer unconditional suspension from the name, so it doesn't fit very well for me either. &gt; I can think of a couple of ways to get around this. The easiest is to provide the `std::optional&lt;T&gt;` destination as an input parameter to the coroutine, either directly (ex `optional&lt;int&gt; opt; my_coro_fn(&amp;opt);)`. I realize this violates your main intention, but you can figure out ways to hide it. That being said, the status quo for writing this kind of code is not user friendly and needs to change. That's interesting, and I'll have to think about it. Toby has pointed out in another comment that my need for workarounds like this is due to an implementation bug in MSVC, which is great news. &gt; The parsing example you discuss on reddit seems quite different from the provided code. The provided code was really a proof of concept that I could linearize some code with the idea. The parsing example was my attempt at a more real-world example of where you might find this coding style really handy. I came up with that on the spot rather than building and testing it so that I'd have something a bit more interesting for discussion. Certainly I've seen parsing examples come up in other monadic error handling discussions, and finding monadic error handling articles or discussions would probably be my best recommendation if you're looking for more examples of this kind of coding style. What I added here is some glue that can be applied to any instance of this style of coding to get it to work in C++; it's the style that's really important. &gt; Unless you explicitly `co_return` or reach the end of a coroutine, you have to manually destroy the coroutine (and free its memory) via the coroutine handle. (Which you don't do in the sum example). Thank you for the tip! I wouldn't be surprised if Gor mentioned this during one of his talks and I promptly forgot it. That's definitely important here considering any suspension is permanent.
&gt; The feature is designed around asynchronous code, where co_await fits perfectly well, although many would prefer plain await. It fails to convey the semantics being applied for arbitrary monadic purposes, at least to me. "The semantics" `co_await` defines are the same regardless of what purpose the keyword is being used for, because the keyword does the same thing in both cases. I really don't think people, after fully understanding what `co_await` actually does, will get caught up by misconceptions based on the name. Could you suggest a better name for your purposes (keeping in mind standardizing keywords doesn't come easy)? EDIT: I edited the above comment. Check out the example in the link.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0650r0.pdf (the proposed standardised Monadic programming extension) will work with any Expected contract implementation, including Outcome v2
Are you claiming the standard demands a diagnostic when a function returning non-void has an empty body?
Hi Andrew. Couldn't you make a companywide policy how things need to be named in official press/blog posts? And that version numbers always need to be prefixed with a consistent name? Often when I stumble upon Microsoft versioning numbers I need to smile. Have you looked at the last 4 post how many inconsistent numbers there are? People will get their mind blown up by this. Correct me, but as far as I understand there are only 5 different entities: - We have a year (no prefix): Its 2017 - We have a c++ standard (c++ prefix): That should be called c++2017 (Official its c++17. But that’s not the best as c++98 sounds much newer than c++17. And with a 3 year release cycle we will end up with c++98 again within 27 cycles. Great) - We have a compiler (cl prefix). Currently version cl19.xx - We have an toolchain (msvc prefix; Maybe this prefix becomes obsolete if toolset and compiler have the same version number in the future) Currently version msvc14.1 (Should be named that way in the visual studio properties box. Don’t call it v141 or 14.11 because that’s confusing and mix up with internal development numbers of visual studio) - We have an visual studio ide release (prefix vs) Currently vs2017 (And the next release should be called vs2017.3. Not Dev15 and definitely not 15.3) Now with settled definitions: - I assume all cl19.x and corresponding msvc14.x releases will keep binary compatibility? - I assume the cl20.x and corresponding msvc20.x releases will break binary compatibility with cl19.x - Is it possible to reach full c++2017 conformity with the cl19 compiler, or does this need to wait for cl20 - Will cl20 be released within the vs2017 timeframe or do we need to wait for vs2019, that will be released around 2019 Thanks :) 
In this instance my understanding is that the program should not compile (although it is kind of cool that it does...) as the instantiated class needs to be returned using the return statement. In this instance GCC is transforming: template&lt;typename fn_t&gt; inline auto on_scope_exit(const fn_t fn) -&gt; decltype(scope_guard&lt;fn_t&gt;(fn)) {} Into: template&lt;typename fn_t&gt; inline auto on_scope_exit(const fn_t fn) -&gt; decltype(scope_guard&lt;fn_t&gt;(fn)) { return scope_guard&lt;fn_t&gt;(fn); } Essentially since the GCC know exactly how on_scope_exit becomes scope_guard&lt;fn_t&gt; it essentially glosses over the actual function body instantiation of the object. You can see in this link: https://godbolt.org/g/xT3DDD that without the -O3 folding and aggressive inlining at line 40~ of the disasm, the decltype(scope_guard&lt;fn_t&gt;(fn)) code generation initializes and returns the object, which is incorrect (as far as im aware) as the instantiation of the object should only for deducing the correct return type.
If you invoke undefined behavior, the compiler is not required to detect it. Plenty of programs that invoke undefined behavior will compile. gcc is not in the wrong at all. 
This is not undefined behavior though, this is a function return type deduction leading to code generation and as far as I am aware this should not lead to code generation without at least a return statement object instantiation. e: it is UB, i have thusly learnt.
Many of them tools were developed long before clang was born.
This is a really great post. I did a lot of arm flailing to Gor trying to explain exactly what you just have some C++ Now's ago. He got the idea in principle, but the above makes it so clear. Thank you! Here's hoping a more generalised solution to TRY operations can now be developed that hooks together P0650R0 C++ Monadic interface in with coroutines via the same generalised extension mechanism.
&gt; This is not undefined behavior though Where did you get this idea? C++14 [stmt.return]/2: &gt; Flowing off the end of a function is equivalent to a `return` with no value; this results in undefined behavior in a value-returning function.
&gt; In this instance GCC is transforming: `...` Into: `...` No, it isn't; why do you think this?
This is not undefined behavior because a function with the type int foo(); Must return int, thus: auto foo() -&gt; decltype(int); Must also return int to be correctly formed, afaik you can only omit a return statement if the function returns void and only then is it undefined behavior.
I am getting this from: template&lt;typename fn_t&gt; inline auto on_scope_exit(const fn_t fn) -&gt; decltype(scope_guard&lt;fn_t&gt;(fn)) being the function declaration. In order for this to result in code generation the function body afaik must state 'return scope_guard&lt;fn_t&gt;(fn)'. From the standard: "Note: in the case where the operand of a decltype-specifier is a function call and the return type of the function is a class type, a special rule (5.2.2) ensures that the return type is not required to be complete (as it would be if the call appeared in a sub-expression or outside of a decltype-specifier). In this context, **the common purpose of writing the expression is merely to refer to its type. In that sense, a decltype-specifier is analogous to a use of a typedef-name**, so the usual reasons for requiring a complete type do not apply. In particular, it is not necessary to allocate storage for a temporary object or to enforce the semantic constraints associated with invoking the type’s destructor." - N3797 P166 (emphasis mine) I have yet to get across all of the function return deduction rules however.
There is no ambiguity from the part I quoted — a non-void function that lacks a return statement yields UB, plain and simple.
_Read_ what I quoted: having no return statement is the same as having a void return, which for a non-void function means UB, _not_ ill-formed...
Falling off the end of a non-void function is most definitely UB. 
Clang is actually more impressive. Try replace `-std=c++17` with `-std=c++1z` in the command-line options: https://godbolt.org/g/pbZ1fX
I think `await/co_await` is pretty appropriate in the case of futures (you're awaiting a result that could be coming in the future), but when reading this code, it's nice to be thinking at a higher level than all the inner workings of coroutines. It's very simple to read `co_await file.write_async("foo");` and have your mental model be that this function will await the completion of that operation before continuing, without blocking. When I'm looking at inferred semantics, I'm looking more at the keyword's name than how it works. If someone new to coroutines were to read `co_await`, they could get that high-level mental model of what the code does when awaiting future results, but trying to read "await this optional" doesn't make much sense at that level. As you say, it makes more sense when you consider what's actually going on under the hood, which is definitely important for using it effectively, but not clear just from reading the code. If I had to pick a name for this more general use, I'd pick `try` to match existing practice, but I don't have a good name for it that would be perfectly backward-compatible with C++. It would be easy to half-copy Rust and use postfix `??`, which shouldn't clash, but two question marks looks pretty weird. If getting a more general form, though, I don't think having it tied so closely to coroutines is necessarily the right way to go. At a logical level, all it's doing is taking advantage of `co_await`'s ability to short-circuit the entire rest of the function. Without thinking too much on this, if a dedicated feature came in, that's all it would really need to do. No coroutines necessary, just the ability to either evaluate to a value or to end the function right then and there. Given that difference, I think there's value in keeping `co_*` to coroutines and this facility to its own purposes, even if you can technically use coroutines to accomplish it. Not to mention this language facility, unlike coroutines, could not be tied to the `&lt;coroutine&gt;` header, which is not a freestanding header, so bare-metal programmers could use it, too. Coroutines need the ability to dynamically allocate memory, so it makes sense there, but plugging your own type into this whole-function-short-circuiting behaviour wouldn't need any special runtime capabilities. We already have this problem with the structured bindings customization points being in `&lt;tuple&gt;`, which is also not a freestanding header, unnecessarily limiting the language feature in that context. Thanks for updating with the link. That gave me a better idea of what you were getting at, and it's pretty cool in its own right.
Thanks, that's sort of what I was going for. I know papers like the `expected` proposal have mentioned such a language feature for some time now, and coroutines at least gives us *some* form of pure-library implementation, which can go some of the way in getting some usage experience and thinking how the language could improve it. Given the popularity of things like Rust and Swift nowadays, I wouldn't be surprised to find some new `TRY` macros popping up from time to time.
I concede that which is fine I wasn't aware of it and had to read through that part of the standard. I do not see how '[...] a return type with no value' ends up equating to scope_guard&lt;fn_t&gt;(fn) from the decltype as I commented earlier: "Note: in the case where the operand of a decltype-specifier is a function call and the return type of the function is a class type, a special rule (5.2.2) ensures that the return type is not required to be complete (as it would be if the call appeared in a sub-expression or outside of a decltype-specifier). **In this context, the common purpose of writing the expression is merely to refer to its type. In that sense, a decltype-specifier is analogous to a use of a typedef-name, so the usual reasons for requiring a complete type do not apply.** In particular, it is not necessary to allocate storage for a temporary object or to enforce the semantic constraints associated with invoking the type’s destructor." - N3797 P166 (emphasis mine)
Once you invoke UB, all bets are off. You can't reason about what happens after that. The compiler can do anything, and there are plenty of testcases out there of compilers doing crazy stuff in the face of UB. It's a result of having numerous aggressive optimization passes that are all specifically written with the assumption that there is no UB. If that assumption is violated, things can go off the rails very quickly and the result is very unpredictable and logic-defying. (But it doesn't have to obey any logic.) 
0. "scope_guard&lt;fn_t&gt;(fn) from the decltype" is the return type, and it is non-void (it is `scope_guard&lt;fn_t&gt;`, spelled out in a strange verbose way) 0. Having no return statement is the same as having `return;`, which is UB for a non-void-returning function. 0. Your function has no return statement. What is confusing about this? The part you keep quoting from "N3797 P166" is really orthogonal here.
You inserted an extra word when you read the first quote. It's *not*: &gt; [...] a return *type* with no value It's simply: &gt; [...] a `return` (statement) with no value [...]
Just for a bit more evidence here -- removing the `decltype` does, in fact, [not change how GCC handles this](https://godbolt.org/g/aF7SC1). The `decltype` doesn't change how GCC handles the undefined behavior here.
In the link the returned object is initialised with the lambda passed to the function as 'fn' it then invoke this lambda on exit scope, so what GCC is doing is using the type deduction as initialization of the returned object per UB, but that is not equal to a non-value return type which would be scope_guard&lt;fn_t&gt;(); The reference to page 166 of standard draft N3797 describes what the life time of a trailing type deduction and it's intended use. Now i'm not a language lawyer, but using a trailing type deduction for code gen UB or not seems off.
- The trailing return type _declares a return type_. - Declaring a non-void return type then not actually returning anything is UB. The fact that you're using a trailing return type is irrelevant; the point is that you have a non-void return type at all. That's it, it's really that simple. `int foo() { }` has the exact same problem.
To be honest I don't particularly care what GCC does or doesn't do under UB and quite honestly everyone here seems to have a pretty confrontational tone for what I thought was just a neat little language optimisation that I assumed was incorrect because it was quite surprising and since the other compilers didn't do it. I guess that will learn me for assuming GCC did something incorrectly...
Yep it's an amazing compiler and LLVM in general is just really cool. 
&gt; In this instance my understanding is that the program should not compile (although it is kind of cool that it does... it won't if you use -Werror=return-type (as you should)
Either way, "[...] a return (statement) with no value [...]" is equivalent to "return scope_guard&lt;fn_t&gt;();" not "return scope_guard&lt;fn_t&gt;(fn);" Which it in fact does return and this is what it deduces this from the function trailing return type.
&gt; a return (statement) with no value [...]" is equivalent to "return scope_guard&lt;fn_t&gt;();" No it is not; it is equivalent to `return;`. As has been pointed out repeatedly, this is UB, _not_ value-initialization (or any other initialization).
I don't understand, why is that undefined behaviour? What does the language gain by not defining it? What possible case could you have where *not* returning a value in a function defined to have a return value is not a bug?
This is more along the lines of what a clean optional syntax would look like to me: https://www.reddit.com/r/cpp/comments/6ly4rz/it_had_to_be_done_abusing_co_await_for_optionals/?st=j4uqi4w6&amp;sh=82f65a06
OK... this appears to be a different claim than you were making before, but it's an interesting one, so let me re-quote the standard here to think about this a bit: &gt; Flowing off the end of a function is equivalent to a return with no value; this results in undefined behavior in a value-returning function. This blurb explicitly states that a *missing* `return` statement is *equivalent* to `return;` . From that perspective, I can understand why one might think that these two should result in the same code-gen: template&lt;typename fn_t&gt; inline auto on_scope_exit1(const fn_t fn) -&gt; scope_guard&lt;fn_t&gt; {} template&lt;typename fn_t&gt; inline auto on_scope_exit2(const fn_t fn) -&gt; scope_guard&lt;fn_t&gt; { return; } *However*, the last statement points out that *both* of these are undefined behavior. It is a little interesting that in two scenarios the standard states is "equivalent", GCC produces different code gen, but this doesn't change the fact that this is undefined behavior. When the compiler encounters undefined behavior, it's allowed to do whatever it wants -- including behaving differently on two things that are supposed to be equivalent :)
dodheim, I am not confused with how a trailing return type on a function works, do not attempt to patronize me. I wrote this code. "The fact that you're using a trailing return type is irrelevant;" I contest that this is extremely relevant as this is how GCC know how to initialise the class. Without the type deduction statement in the trailing return deduction, on invocation of the destructor nothing would happen as the scope_guard would not be initialised, but here it clearly generates code from the "scope_guard&lt;fn_t&gt;(fn);". I can certainly appreciate that under UB anything can happen and I can see why GCC would provide this short cut. 
I think OP is pointing to the fact that if you add a `return;` to his example, [GCC suddenly behaves differently](https://godbolt.org/g/1AdsDM) and is trying (but failing) to do `return scope_guard&lt;fn_t&gt;()` So -- GCC treats two cases of "equivalent" undefined behavior differently, but I don't think that's an issue.
&gt; but here it clearly generates code from the "scope_guard&lt;fn_t&gt;(fn);" According to [stmt.return]/2, which I've quoted for you, it _clearly_ yields UB. It's entirely _unclear_ to me why you think the standarese you quoted is relevant to the discussion or has to do with anything more than _declaring the return type_, but just, wow... I'm done "patronizing" you. ;-]
"[...] or has to do with anything other than declaring the return type," because as I said earlier GCC also uses this information to generate the function body in lieu of the return statement. Such that (https://godbolt.org/g/UHicHN): auto foo(int i) -&gt; decltype(int(i)) {/* return omited for demonstration*/} int main(){ printf("%i", foo(1)); //prints 1 } I accept it is UB that is fine, but I simply found this behavior surprising and though it was a bug as clang nor MSVC do it.
This is a little bit tricky, see [DR 2017. Flowing off end is not equivalent to no-expression return](http://open-std.org/JTC1/SC22/WG21/docs/cwg_defects.html#2017).
Yeah I accept that, I didn't realize it was -just- UB to not return a value from a function as I avoiding doing so as a matter of course. I'm not sure why: template&lt;typename fn_t&gt; inline auto on_scope_exit1(const fn_t fn) -&gt; scope_guard&lt;fn_t&gt;{} Knows to call the constructor with the input argument, but hey it's UB and compilers are crazy smart. It's still not equivalent to a simple 'return;' but at this point it's just surprising i guess. 
Consider this function: int foo(int x) { if(x == 2) { return 20; } } Is this function valid? You can't say. It depends on how it's called. If all call sites are `foo(2)` then this is a perfectly valid and well-defined program. But the compiler can't know that, because it can't see all call sites when it's compiling this function. Moreover, the call sites could be quite complicated, e.g. depending on user input. There's no way for a compiler to work out whether a program containing this function invokes undefined behavior or not, which is why the standard does not and cannot require the compiler to do that. It's up to the programmer, just as it's up to the programmer to ensure that all kinds of other UB does not happen (e.g. signed integer overflow, accessing an array out of bounds, etc.) In both this example and OP's example the control flow is rather trivial, but it can be much more subtle and complicated in real code. If you're asking why C++ is not like Java, which requires all possible code paths out of a non-void function to return a value, even those that are never used, that's because the legacy of C. In C, it's only UB to fall off the end of a non-void function if the return value is actually used by the caller. If the caller ignores it, it's not UB. This is due to the legacy of C, which did not even have "void" until ANSI C; it was added as part of the standardization process in the mid 80s. Prior to that, in K&amp;R C, it was common and expected to fall off the end of a function returning int (which was the default return type, and often omitted.) [Have a look at the source to `ls` from the Fifth Edition Unix](http://minnie.tuhs.org/cgi-bin/utree.pl?file=V5/usr/source/s1/ls.c), circa 1974. Every function defined there lacks a return type, which means every function returns int. But there are numerous cases where control just reaches the end of a function without a return statement. It was expected that the caller knew what they were doing, and to ignore the return value in such cases. There was no other way of doing it, because the language didn't have void. ANSI C had to allow that style of coding because there was a bunch of existing K&amp;R code out there, so the compromise is that it's only UB if it's not ignored. And C++ compilers are often used to compile C or C-ish code, so they can't take a radically different stance like Java. 
Ikr, I guess it's a left over from C.
Removing the decltype does however prevent this nice little example: auto foo(int i) -&gt; decltype(int(i)) {/* return omited for demonstration*/} int main(){ printf("%i", foo(1)); //prints 1 } 
Oh cool, I will use that in the future thanks.
&gt; Consider this function: You can go even more in this direction. Is this function valid? int foo() { bar(); } 
You absolute mad lad.
LINQ can be even cooler than that. Since the functions only expect a Func with the correct signature, you can even skip the lambda declaration and pass the function directly: ienum.Where(Filter).Select(Selector).SkipWhile(Skip)
I think the reason clang doesn't compile is not related to the code you've pasted but instead the compiler parameters. When you replace -std=c++17 with -std=c++1z it compiles but just gives a warning. It would've been weird if the compiler rejected a valid program that contains an undefined behaviour. However, their treatment are different: in GCC (on my machine) it prints: &gt; scope finish. &gt; scope start. in clang it says &gt;Illegal Instruction (core dumped) in clang when optimizations are enabled it prints nothing (probably removed) https://wandbox.org/permlink/jH6fy6VtKM5B0Yw5
There were a couple of people mentioning this (I mentioned it at some point as well). The monadic control flow is quite cool, and thanks to Gor, co_await is full of monadic goodness. This will be rather useful (abuseable :) ) for much more things than futures and optionals.
I asked what I believe is a clear yes-or-no question. I do not see a "yes", "no" or even "I do not know" in your answer. In fact, you appear to be answering a different question than what I asked. What the compiler did and why you think that is not my question. I believe that to be a red herring. The program is clearly ill formed. The remaining question is "does the standard mandate a diagnostic?" If it does, then gcc is broken. If it does not, then *any program generated is legal under the C++ standard*, the standard places no restrictions on the resulting program's behaviour. There are additional flags you can pass to compilers to get helpful warnings or errors that cover cases like this. This is also not my question. My question was, and remains, do you know if the standard mandates a diagnostic here? I would be surprised myself; the standard tends to permit functions that fail to return, because in theory proving a function cannot fall off the end without a `return` is Halt-hard. Plus functions that call `exit` may fail to return, etf.c And the standard tends to punt in those cases. But an empty body might have some special wording in the standard that applies, hence the question. 
That's very interesting, especially clang not outputting code gen with -O3. You can in compiler explorer you can see Clang cycling through available ctors and matching them against available inputs. https://godbolt.org/g/evRtKY 
Oh, I don't mean to throw stones! Especially not from my glass house. Yes, a lot of these tools are older--one popular tool only barely supports C++11 and reportedly going through a rewrite. But there's a Visual Studio add-in that I tried recently on ChakraCore that doesn't understand conditional code. Chakra's a JIT so it's filled with `#ifdef _x86` and the like. It wasn't pretty. VC++ /analyze did make the right decision to tie itself to the compiler's parser, I think. It definitely has drawbacks but in the long run it will turn out to be a huge asset. 
You *may* see a paper regarding a generalised solution in 2018 ... we have a preceding paper to write for the Albuquerque meeting first.
Ok, fair enough. My answer is I don't know. The big suprise for me was and always has been that GCC and Clang have auto-magically deduced the correct ctor for use and automatically applied the function argument without providing diagnostics of their own. I now understand that this is undefined behavior and they are perfectly with their right to do so. I believed at first they were using the template deduction instantiation incorrectly, but after looking into the matter further they simply are just matching functions inputs to the valid ctor's of return type as a special case and if you add a second argument then it just doesn't compile. As shown here https://godbolt.org/g/6rXboQ
I rarely use LINQ indeed. We don't have LINQ in C++.
Cool, I hope to listen to some stunning talks on this subject then at Meeting C++ - maybe you are giving one?
Can't I make a company-wide policy? Nope. Sorry. Satya doesn't take my calls anymore. I also can't fix the fact that people drop the century when referring to years. '98 will always be less than '17 when you cast it to an integral type, and this is not just in the world C++. If you want to prove that Obama was president before Clinton then you'll gain a lot of followers on Twitter. We can and will fix the compiler toolset versioning: the next version will be v20.00 all around. But **the compiler toolset versions separately from Visual Studio**, so don't expect Visual Studio's version number to match the compiler's. There is no concept of a compiler release being tied to a VS release anymore. Note that v140/cl19.00 shipped originally with VS2015, and still ships in VS2017. And note that v141/cl19.10 and cl19.11 shipped originally with VS2017 and is installable side-by-side with v140. They version independently. VS version != MSVC version. Your questions at the end are pretty easy to answer without any version number confusion. I'll continue to use your convention of "clNN.xx" although it's not exactly how we type it. * Major versions of the compiler toolset are binary compatible. That's true for cl19.xx, cl18.xx, cl17.xx, etc. Just look at the first number, whatever it is. Does it match? It's binary compatible. * Different major versions of the compiler toolset have no guarantee of binary compatibility. Usually it works, but eventually you'll run into problems. Objects produced with cl19.xx should not be linked with objects produced with cl18.xx or cl17.xx. * We intend for the MSVC compiler to conform to the C++17 standard in the year 2017, with the few notable caveats I've discussed elsewhere (e.g., lack of a conforming preprocessor, bugs in two-phase, SFINAE, and extended `constexpr`.) Our current plan is to do this in the cl19.xx toolset but I can't guarantee what my dev team can deliver. * There is no guarantee that the next VS will be VS2019. I do not know when the VS team will ship the next major version (nor do I know what the VS marketing team will call it.) That's why the C++ team refers to it as "Dev16". And I mentioned above that the compiler toolset versions independently of Visual Studio. We'll ship cl20.00 when it's ready to ship. And we'll ship it side-by-side with cl19.10 and cl19.00 (both of which are available in VS 2017 as the v141 and v140 platform toolsets) if it's ready to ship while VS2017 is still shipping. If we've started shipping Dev16 before v20.00 is available to ship, then it's really unlikely that we'll patch VS2017 to install v20.00. The general rule here: * We will continue to make new versions of the compiler toolset and ship them in whatever version of Visual Studio is currently in the market. * We will continue to include every supported C++ platform toolset (currently going back to v140) in future versions of Visual Studio. **We want you to be able to upgrade Visual Studio without having to move your existing code to a new C++ compiler.** There are a lot of improvements in each version of VS that you should be able to get your hands on without having to migrate your code to a compiler with new features and bug fixes. I hope this helps. Don't get so tied up on tracking and understanding all the version numbers. It's madness everywhere. Don't believe me? Ask what version of Linux I'm running. 
[Very Demotivational](http://imgur.com/a/NAVw9)
&gt; full of monadic goodness I can see how you could use this with something like Maybe and Either, but how would you use it with List? Let's say I wanted to write a product of two Lists: template &lt;class T, class U&gt; std::vector&lt;std::pair&lt;T,U&gt;&gt; product(std::vector&lt;T&gt; const&amp; xs, std::vector&lt;U&gt; const&amp; ys) { auto x = co_await xs; auto y = co_await ys; co_return std::make_pair(x, y); } Is that at all doable? I'm not suggesting it's not - I'm just saying I have no idea how to do it. I know you could rewrite this using nested loops and `co_yield` the pair, but that's not monadic (it's not bad either, it's just not monadic). 
The proposal mentions this as well.
Thanks for code snippet. I wish there are more examples of using coroutines. Just curious - maybe you know how we can avoid that extra `get()` call ? The only thing I can imagine is to make implicit `operator std::optional&lt;T&gt;()` instead of `get()` and restrict caller to not use `auto`: operator std::optional&lt;T&gt;() { // ... } int main() { std::optional&lt;int&gt; opt = sum(); std::optional&lt;int&gt; opt2 = sum2(); } But this is weak 
Of course. Those were just placeholders for the actual expressions. `ienum.Where(n =&gt; n.Age &gt;= 18).Select(n =&gt; n.Name)` etc.
This was quite helpful for me! I am still getting the hang of R-Value References and this helped catch me up some :)
C++ is powerful enough to have LINQ implemented as a library: https://github.com/pfultz2/Linq
CppCheck also generates many parsing related false positives with uniform initialization. I've had bugs open for almost two years on the issue. :(
I hope we will have some nice monad/coroutine talks as well. Last year I promissed to talk about functional data structures, so I went with that this time.
If you enjoyed this, you must also check out [Effective Modern C++, Scott Meyers](http://shop.oreilly.com/product/0636920033707.do). This is a must for anyone who want 'C++ programmer' on their resume :)
I really want to use this stuff in a project!
I haven't had the time to play around with coroutines in clang yet (finishing the book and a few other high priority things) - I've just analized the writtien proposal and it looks like much of haskell's `do` notation will be possible here (though, with strangely named keywords :) ). Lists *are* special. I expect that the idiomatic way to handle them will be with a yield/await combination. I *do* recall Gor mentioning that coroutines will be usable with reactive streams (the monadic bind / continuation part of the function will have to be invoked multiple times) if the function is pure, and I've seen that there has been some work in the ranges library to support coroutines (generators).
&gt; GCC and Clang have auto-magically deduced the correct ctor for use and automatically applied the function argument Probably just a coincidence. On some optimization stage function parameter just happened to be represented by same data as returned value.
Scott Meyers has some better explanation in [Universal References in C++11](https://isocpp.org/blog/2012/11/universal-references-in-c11-scott-meyers)
Thanks for this tutorial! Finally had the time and motivation to get into this, and fuzzed beast today. Successful!
On a poor 3G connection this lag can be annoying, but on even pretty marginal DSL it seems to be on par with any other kinda complex/responsive website. I've rolled out a few pretty complex apps for my work using Wt (sorry, not open-source/released yet...), and its pretty much like anything thing else I do in c++: make the initial version (which is surprisingly fast to do in Wt), then "profile", and go through to make un-smooth or slow things into stateless slots (pre-load content/js client side so no round trip is necessary), or write some JS or use a JS library to polish remaining items not well suited for the stateless slots. My users (and management) have been very happy with the results, and I usually can then also make native apps for Window/macOS/iOS/Android/electron that dont need an internet connection pretty easily (well, easy after the first time - getting all the Android or iOS boilerplate, and interactions with the OS right was a challenge the first time).
LOL - I think it's more correct to say I was inspired by SafeInt. The SafeInt code was very long and hard to read and harder to verify. My approach was to use Boost and template meta-programming to address these issues. So though it's inspired by SafeInt it has no code in common with it. I don't mean to critisize SafeInt, just the opposite. I think it points the way to something much bigger - solving the single most glaring weakness in C/C++ since it's inception. With a different set of tools - boost and TMP - this can now be addressed - which is what I did.
Oh okay, so you're using `array[index]`, but really what it's doing is `*(array+index)`?
Awesome - would love to hear your findings from the fuzzing when the time comes 
Very nice. You might throw in `std::invoke` in it as well.
[removed]
Oh neat. Glad to hear it's being thought about. 
I use ICU.
OP is the prereq for Scott's article!
So... why would the compiler even generate code in this case, given that it is both UB and a condition that is trivially detectable? Why isn't it mandatory to both give a diagnostic, and refuse to generate code? I understand that UB is occasionally needed because the alternative would involve some degree of runtime checking, which would slow down our programs. But why do we have to put up with this kind of UB?
2GB of ram? Sounds like win7 and above is not an option, right? Can you go with Win xp and the newest VS Code?
[Looking at the Microsoft website](https://support.microsoft.com/en-us/help/10737/windows-7-system-requirements) it looks like it should run fine, and I've seen mentions of it working fine on the 1000H. It's Visual Studio I'm worried about running, might be too resource hungry. I can happily go with Windows XP, just more use to using Windows 7 but it isn't that much of change. I'm tempted to install all 3 and mess around to see which one works the best.
I'm curious: Niall bashes ASIO quite heavily - saying its design choices were good in C++98 era but nowadays we're much smarter and the design is completely bad and outdated. Yet - isn't the ISO committee adopting nearly 100% ASIO for the Networking TS? Or **are** they making very significant changes after all to modernize ASIO? Or will they take C++98-era ASIO and make it part of the standard, when its design is actually considered totally outdated nowadays? Or is Niall the only one with this opinion about ASIO?
I forgot to add that VS Code on my win10 machine uses only 20mb of memory (while notepad++ uses 18mb). VS 2017 uses a lot like 120mb.
What exactly is VS code? Is it simply a super stripped down version of Visual Studio? I only need basic functionality like debugging etc.
Yeah, it's nearly identical to the full VS Studio. It's a competitor to lightweight IDE setups like sublime 3, Atom, etc. I dropped sublime use for VS Code. I used VS Code with minGW compiler. I wish I could just use one, the debugger is very similar in both Code and VS Studio. Code has all the same shortcuts as web browser chrome (CTRL+pgup/pgdn to go through tabs, CTRL+W to close tab) so I love that. I would find that I setup all hotkeys and window pane arrangement to match VS Code. If you hit F11 to step through to debug it seems VS Studio is slightly nicer.
Ooo interesting, I'll definitely look into that as Visual Studio is by far my favourite IDE on Windows. And as its requirements are so small I should be able to run it on whatever OS I end up installing, thanks for bringing this to my attention!
Well we all know reviews where Niall is involved get, let's say temperamental. Your post doesn't really add anything to mine though. I was asking for other opinions, ignoring the flame-wars that may or may not be going on. I suppose what you're saying with your reply is that you think Niall has no basis to bash ASIO? If so, what would be your counter-argument?
I'll blog about this later, so far it seems I got lucky to hit some low hanging fruit, will continue though.
Hello. I have experience with old PCs and C++ development. IMHO, Linux is the best. Win7+ requires more than 2 GiB RAM and you can't​ reduce this. And it's dangerous to select WinXP with vulnerabilities. And I think, Linux is better for programming, and especially C++ programming. Probably, Xubuntu will be good. More beautiful UI. Geany instead CodeBlocks. Or CodeLite instead CodeBlocks if you really need IDE. P.S. Netbooks is very bad solution of your problem.
Don't Xubuntu and Lubuntu (the OS I'm looking into installing) have the same UI? I would like an IDE just to help out as I have only just started coding in C++. Yes I know but if you look at my post you'll see why I decided to get one.
Thanks for sharing, well worth reading. 
You could also opt for FreeBSD, clang, and VIM. That's what I'm using to learn C++. I'm using a old laptop and FreeBSD and Xfce works great on it.
TL;DR: ACCEPT.
From I can gather - the ASIO is chosen by design, not by implementation. N4588 intends to change some things. More importantly I really hope that we get some experience with coroutines so that std networking will be actually adjusted to the "new reality". In short - I hope so. 
There are so many distros out there it's a bit overwhelming. I'll probably do some more research into them before I start installing IDEs and such.
More actually: - accept, but I think it could be done much better (because I may or may not done it better in the past). 
Why post only this review? (honest question) There are other people at boost considered to be C++ gurus, aren't there?
You mean a snoop filter, which a read-only operation. Because the L2 is private, only the core it is attached to can prefetch data into it - that core alone controls the TLBs and tag caches to it's L2, no other core has that control unless the CPU supports something like Cache Stashing recently shown on the ARM Cortex A75/A55 through the new coherent network topology. L3 are able to be shared because each core can automatically read/write (well, read-only, because Ryzen is a victim cache and automatically populates with evicted L2 cache lines) and is a bidirectional operation of one core to many L3 tag buffers. The L2 is not built this way, for many reasons.
&gt;&gt; Also, OO finally freed us from having a single giant namespace one more detail I forgot you know that with "Argument Dependant Lookup", overloaded free functions are effectively potentially in the namespace of the type already :) (it's not just controlled by the types of the arguments as I used to think, as per overloading.. you really can have foo(X) and foo(Y) and even a foo(X) in a different namespace.. http://en.cppreference.com/w/cpp/language/adl ) the comment about name spacing doesn't really affect the situation. It's already very complex. the 'foo(x)' that people have to use already could be literally anywhere. i used to think 'there is no practical difference between ```Foo{ foo()}``` and ```foo(Foo)```, but someone said 'foo is in the namespace of Foo', but thanks to ADL Foo can affect the name spacing of foo(Foo) aswell , lol..
Xubuntu and Lubuntu have different UI with similar intent (gtk vs qt, respectively). IMO, Xubuntu is more mature. In Linux, you're likely to find people suggesting using an editor + command line tools, especially on older hardware. That's a good setup, but it may not be for you. 
I love Lubuntu, personally. My 2001 HP desktop is still alive and rockin' on it. I don't think your specs are bad enough to where you legimitately *can't* install most IDEs, but I do think you won't enjoy the experience on most if not all of them. I would recommend Sublime, 100%. It's not an IDE, just a code editor, but it's very lightweight and will most likely run okay/well on your computer. There's also the added benefit of getting good at manually taking care of the build system via make/cmake, I'm not sure how much you're prioritizing that learning experience right now though. You're probably going to have a bad time on most if not all actual IDE's though.
I'm going to have to figure out what to sacrifice; less functionality for smoother operation, or more functionality but slower operation. My plan is to work from the top end of IDEs, like Visual Studio, and slowly work down the ladder to basic text editors and hopefully find a good compromise in the middle somewhere.
More mature? I might go for a 'baritone' IDE so to speak, something like VS code that apparently only requires 20MB to run.
The confrontational tone is somewhat deserved: once you have UB, the compiler is free to generate code that writes random junk to your SSD and prematurely wears it out just to spite you. You're arguing that the compiler doing something less drastic is somehow interest-worthy.
OK, thank you for detailed answer. 
Ha good summary, it does require a spoiler alert though. If I'd volunteered 6 hours of my time to review a proposal, I'd want a platform to speak my mind.
Ooof. I'm running 16gb of Ram, Intel i7 6700, and a gtx 740, I think, so not the greatest build in the world, but definitely recent, and Visual Studio still runs slowly on my computer from time to time. Resharper tends not to help either, but Visual Studio definitely lives up to its hype of being pretty slow.
I 100% agree. Advantages with GLOB, GLOB_RECURSIVE include: 1) No unnecessary cmake merge conflicts. 2) Never having an orphaned source file in your repo. 3) Simpler and shorter CMake files. 4) Having an easier time creating generic cmake files that work for all your library projects, for instance, in your project. The disadvantage is: 1) a) You have to have a build server that builds from absolute scratch to catch any missed files, and occasionally you'll have to fix a build break. b) or you'll have to force cmake to run again. And that's it. I listed that as not two issues, but one issue with two solutions. And with a reasonable cmake strategy and with a good tool, such as an IDE, or a simple script you can avoid that too. Just have your tool touch the first CMakefile.txt it finds going up the directory tree. Some cmake strategies are more complex but the right tool/IDE can handle it. With friendly developers this solves 99% of the problem. I know that it is possible to construct scenarios that will bypass my ideas above. However, seriously, think about the problem cmake guys. You can fix this. ClearCase created their own file system. I know your problem could be solved by a CMake file system. And I'm pretty certain that there are solutions that are 10 or maybe 100 times simpler than having to create your own file system. I'm sorry cmake guys. You are climbing up the wrong tree. Come down from your filename tree and climb up the GLOB(_RECURSIVE) tree. 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6m46pq/programming_on_an_old_2008_netbook/djz4kf0/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I use Qt.
Something feels off with this post.
I would be interested into knowing what could "current design choices" be for a network library. AFAIK ASIO is modeled around async paradigm stemming from the fact, that such API is provided by the underlying OS. AFAIK Windows is fully IO async (IO completion ports) and Linux can fake it well. But I should probably ask on the boost mailing list, not here :) I like his take on imposing a stream I/O as a bad idea. It is actually so obvious.
It took me a while to work out what you were trying to describe, but I *think* I understand it :) Tell me if I do... This is where I may be completely missing the point, but where does the "cross productness" of this live? What part of code understands that your intention is to do a cross product and not a zip? The way that coroutines works is that the types can be taken into account in the implementation of the underlying control mechanism but the function name can't. The problem with the API is that you have to construct the return type when the product coroutine is entered, but you don't at that point know enough to have filled in the vector. I think you'd need to return some sort of future type that you could fill in later on. Take a look at [this page from the start of my coroutine tutorial](http://www.kirit.com/How%20C%2B%2B%20coroutines%20work/My%20first%20coroutine) on how `co_return` works. Although you have `co_await`s in there too, this doesn't alter the behaviour of the `co_return`. I think what you'd need to do is to return a generator which could then be used to yield the values of the cross product, `generator&lt;std::pair&lt;T, U&gt;&gt;`. Once you have that I'm not sure why you'd need the `co_await`, you could achieve the same effect without. I think this would make a good more advanced tutorial if I could understand a bit more about the intention.
There is something to be said about the UX of libraries. My impression is that not too much thought was put into it with this library. Compare this with the C# or Python HTTP libraries. Why not follow the "simple by default, powerful when needed" design priciple?
Considering I've already seen a tutorial pop up on adapting ASIO to coroutines, I'm faithful that it will at least be pretty simple to write a couple of specializations once in order to use the networking TS with coroutines, although I won't be surprised if that interop becomes standard. The Ranges people (Eric, Casey) have been pretty good with looking into this already.
It seems to me that a simple library could be built on top of this rather than the pretty layer being provided directly.
Yes, but somebody has to decide to write it. And then you have to standardize it separately, and we don't get a user friendly library for a couple more years. All while almost every other major language has had one for years. Or even worse and more likely, it doesn't get standardized and the user needs to choose between 4 half-baked attempts. And then you have to import three libraries and memorize what is in which namespace. The development effort of the libraries is spread thin, and when somebody needs some changes upstream, it's not easy anymore. I'm not a guru of any sort, but as a run of the mill developer, I don't like how high effort this is by default. 
Another excellent reason to limit the use of free functions, I'd say.
&gt; the insight that a presenter tried to convey After some digging in the interwebs I found the video again. The name is Dominic Robinson and he gave this great talk [Coroutines and C++ DSLs for Human Scale Concurrency](https://www.youtube.com/watch?v=d76cJ_RBGbY) at ACCU 2017.
Linux has full [async I/O](http://man7.org/linux/man-pages/man7/aio.7.html). It is a relatively recent addition to the kernel, (ASIO predates it), I wonder why no one wrote an ASIO backend for it. My main issue with ASIO is that requires handlers to be `CopyConstructible`, if you want to stick a promise into the handler you need to use `make_shared&lt;promise&lt;T&gt;&gt;`, which is a bit silly.
&gt; Another excellent reason to limit the use of free functions, I'd say. did you read this?http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197 The point is **you need to use free functions more than member functions** . Most people in the C++ community understand this now. member functions backfire because they cause **excessive coupling**. free functions are **superior** for modularity. they are **inferior** syntactically, they don't show up in the IDE dot-autocomplete and require more parenthesis nesting. The point is functions have many parameters; you can divide the dependancies up per 'intersection' of parameters e.g. consider 3 functions with 2 classes Foo,Bar.. ```something1(Foo&amp;)```, ```something2(Foo&amp;,Bar&amp;)``` , ```something3 (Bar) ```... those can go in seperate 3 modules (Foo, FooBar, Bar), such that modules containing classes ```Foo``` and ```Bar``` remain **independant**. A 3rd module 'FooBar' handles the overlap. If you make the mistake of putting 'something2(Foo&amp;,Bar&amp;) as a method of either', you couple one to the other. this happens *all the time* because people want the 'dot autocomplete' in their IDE (which makes functions much easier to find). Also note the effect on **compile times**. decoupling = reducing the information that each module needs to consider to compile correctly; also increases code **re-usability** (avoids the 'gorilla-banana problem' of OOP) **You can't use inheritance to fix this**, because your 'something2' wont work on code using plain 'Foo'. Sometimes people try to help decoupling through **virtuals** or **pimpl** but this introduces **performance hits** through extra indirections. Again, well known now are the techniques of **data oriented design** needed for high performance. Data needs to be sorted by type; we want static calls and cache-coherency; this strongly conflicts with classic 'OOP' design principles (which originate from before the era of deep pipelines and caches). Hence the conflict we are stuck with in C++.. we bounce between both styles. Note that source bases evolve too over time. The separation may be discovered retroactively, and people may re-factor. **THIS IS WHY WE NEED TO BE ABLE TO USE ONE SYNTAX FOR BOTH CASES, SO WE DONT HAVE TO GO BACK AND RE-WORK ALL THE CALLS WHEN WE CORRECT THE COUPLING ERRORS**. .... This solved in **C#** with the exact variation of extension methods I propose ( functions with explicit 'this' - very easy to search for, regex ```functionname.*(.*classname.*this```), or in Rust with 'traits'/'impls' (bolt on as many as you need, other modules may extend other types with their own traits without needing to make entire new 'derived types'), etc etc. People like you are keeping us in the stone age whilst other languages press on with solutions.
As far as I can see, there's been only one reject vote--but it's from Artyom Beilis (author of CppCMS) so it may well carry quite a bit of weight. I don't know though--one big part of his complaint is basically about over-use of templates, which most Boosters seem likely to discount. His other big point is simply that it doesn't supply enough, and what it does supply is basically the easier parts of the job, so it leaves most of the hard work to the user. Reference: [Artyom's review](https://lists.boost.org/Archives/boost/2017/07/236811.php). 
and you might wonder why I don't just use C# , Rust, Go, Swift. I don't want a JIT or Garbage Collector like in C#, or the reference counting of Swift. I don't need the extreme safety checks of Rust - I know there are safe patterns that can't be proved safe at compile time. (e.g. array indices that are known to be inrange by virtue of how they are generated). Rusts templates aren't as powerful as C++'s yet. There aren't any IDE's for Rust that reliably handle **'dot-autocomplete'** yet (because it doesn't have much demand behind it). This isn't a problem of complexity, because it's a simpler language than C++; C++ IDEs handle everything fine, with a much harder job. swift &amp; C# have great IDEs but are garbagecollected/ref-counted languages. What I want is the raw performance of C++, with the overloaded free functions for decoupling and extending, AND the superior navigation of a modern C++ IDE with it's dot-autocomplete, able to search those freefuctions aswell as the members.
[removed]
&gt; - Abuse of static polymorphism where classing object oriented design with virtual functions can do better job. I think the much better design principle is to use static polymorphism by default, and only resort to "classic OO design" when required. I see no reason to do "classic OO" by default, it results in OO-heavy code, which is often not good design. OO is _one_ tool in one's toolbox and shouldn't be used by default. That being said, it may well be the case that Beast would be suited better with dynamic polymorphism, but I don't see Artyom giving any concrete arguments. Other than that, good review - it's always good to have some balance (i.e. many people voting for ACCEPT, while some also giving (constructive) negative-leaning reviews.
Yeah I think I can scratch VS of the list, at least the latest editions.
&gt; if you want to stick a promise into the handler you need to use make_shared&lt;promise&lt;T&gt;&gt;, which is a bit silly. bam! right in the performances
&gt; Why not follow the "simple by default, powerful when needed" design priciple? you can build simple libraries over powerful libraries, but you can't build powerful libraries over simple libraries. 
&gt; And then you have to standardize it separately, ... why should all libraries be standardized ? 
Who's talking about all libraries?
Yes, I agree. This does not contradict what I said. Simple by default, powerful when needed means that the library should be easy to use for the simple use cases, but also expose the more complex way doing things for when this is necessary.
I really think you should be using more capitals, your point is just not clear enough now. 
whatever it takes to get you to understand it , &gt;Another excellent reason to limit the use of free functions, I'd say. as 2 hours ago you still didn't, after all my attempts to explain over the past couple of days
Taken from a different part of the review: &gt; I also would say as a former SC22 mirror convenor that an accurate way of looking at ISO is that it's the place multinationals send their people to slow down or prevent standardisation of things which could harm their interests. A lot of people express frustration with WG21, but it makes sense when seen as a place mainly to stop and delay change. That's how ISO configures things, multinationals overwhelmingly dominate the national votes through being multi national. That... actually explains a lot about the rate of progress across the decades. Source: https://lists.boost.org/Archives/boost/2017/07/236764.php
It's worth pointing out that there are some differing design decisions in `std::variant`. They have the same name, but some different behaviour. For example, `valueless_by_exception` and the lack of double buffering during assignment.
I think Beast is the most promising of these proposed libraries(boost.http, cpp-netlib). I hope it will get more features, like uri decoding/encoding, cookies.
Artyom mentioned why he didnt like static polymorphism in this case. The arguments he gave are pretty good. He found the code difficult to follow and noticed object code duplication on http variants and would be much simplified by use of virtual functions. &gt;OO is one tool in one's toolbox and shouldn't be used by default. I find that _experienced_ C++ guys get that rule very well, but then fail to notice the same rule when it applies to templates heavy code. 
Before getting into variant and compilers, know that this way of doing benchmark might be flawed because some lines could be reordered for performance. I suggest using a benchmark framework like google benchmark or simply try this: http://quick-bench.com/
It seems passive aggressive because of a heated discussion before it, with the library author reacting ridiculously to criticism, like here: &gt; Reviewer: Generally I've kept a headers() collection and a body() collection. &gt; Author: Words are cheap. Please provide a serializer which compiles and runs, with tests, and operates on Beast messages and does not use &lt;boost/asio/buffer.hpp&gt;. I've provided something that works, time for you to do the same. https://lists.boost.org/Archives/boost/2017/07/236774.php
Jesus Christ that's unprofessional.
My take on ASIO, based on my personal experience using it in the workplace, is that it's biggest drawback is that it is incredibly difficult to *teach*.
I find reading Boost library reviews fascinating. My language here is quite deliberately neutral. 
My favorite 'feature' of symbols in MS DLLs is probably that they can have no name. 
This fragment should be viewed in the context of the whole thread. There was quite a bit of trolling prior to this outburst by the reviewee. Also, Niall's final verdict is a case study in logical fallacies, from strawman to appealing to authority. It's hard not to lose one's cool.
&gt; more mature? I don't use either, but based that on: 1. More polished (not the same thing but i was tired). See, for example, http://www.linuxandubuntu.com/home/lubuntu-vs-xubuntu 2. I thought I read recently that LxQT is still in the transition stage of the LxDE and Razor merge. What I read was that it is still usable and impressive, but the small team means that the technical improvements happen more slowly. 
I recommend against XP. The lack of security updates, and support in current applications, will likely give you troubles. 
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6m7ovk/summer_project_need_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You might also look at KDE's [KCodecs framework](https://api.kde.org/frameworks/kcodecs/html/classKEncodingProber.html) (which depends only on Qt and a bit of CMake support in "extra-cmake-modules"), it includes a class that can probe through binary data trying to determine the charset the data uses.
Hah, TIL. What's the intended "feature" here?
/u/dodheim, I wanted to let you know the status of the service. 1. We’ve got packages matching released builds (VS 2017 RTW, VS 2017 15.3 preview 3) on NuGet.org. 2. The dogfood server is running again, and I have an idea of what may have been causing the instability. I’m uploading packages there when there integrations to our release branch—every week or two. 3. We’re still looking into getting an external server (e.g., MyGet.org) to replace the dogfooding server. That will be scripted to get daily builds again. Sorry for any disruption with this. It’s a new kind of process for our team—and for VS, frankly—so it hasn’t been quite as smooth as we’d have liked. But we will endeavor to make it reliable from here on in. 
&gt; Yes, I agree. This does not contradict what I said. It's funny how on Reddit people can make a comment agreeing with or confirming someone's idea and their response is "how is that a counter-argument?". Maybe /u/doom_Oo7 is agreeing, not arguing. Proof of this phenomenon is that I assumed you are now disagreeing with his disagreement when in fact you could have been agreeing with his agreement :)
I'm strongly against more design-by-committee changes to ASIO. ASIO is a fine library and design, and far more importantly **it is the standard practice**. So it should be standardised as-is in my very strong opinion. WG21 should stop tinkering with what is known to work.
&gt; Or is Niall the only one with this opinion about ASIO? No, there are substantial misgivings about the design of ASIO. Not much agreement either on what those are of course. For the record I *like* ASIO. I think it great, and always have done. But it was designed for its era, and it has not aged well with hardware and kernel changes. Doesn't matter. It's standard practice. It therefore should be standardised, and not messed with by well intended people without sufficient domain experience in high performance networking.
In my system I did 5 runs and in four of them std::variant is faster according to your code (with g++ 7.1.1) and in all the cases numbers were quite close to each other, you shouldn't raise your pitchforks for small differences. Edit: I've also tested with clang (4.0.0) and it was faster (around %20), so there *might* be a missing optimization by gcc
Linux kernel aio is not a relatively recent addition to the kernel. Been around for years. Never actually was async most of the time, and though it's getting better it's still not async much of the time. It also only works with file i/o. Not socket/pipe i/o. The network stack in Linux is incapable of async i/o, its design does not make it possible.
Sure, I make the effort to say things which are not popular. And I get hate rained down on me as a result. But never think I voice any opinion not widely held by many others, though I absolutely accept that the *form* I have chosen to voice unspoken opinions is not widely agreed with. But in the past "they" were not listening, so one needed to push through. In the past year they are now listening, real change is happening behind the scenes finally. And as you probably haven't noticed, I've been all sweetness and nice this past year. I no longer need to push through, so why upset people for no gain? So I don't, and haven't, nor will do so long as real change continues.
I couldn't agree more. There was also lots of preceding discussion including of technical points and history and analysis of ASIO and HTTP and previous Boost reviews of HTTP libraries.
I know that. I also know that ASIO is quite hard to learn and teach. With C++ current goal (one of many) on simplicity, we should make things easier to understand, easier to argue about, and of course easier to implement. That doesn't mean we should do it in expense of library power, no. There should be some sort of balance. The problem is not that "learning is hard". The problem is finding specialists now and in the future. People who will be able to write (async) C++ code and will not be as rare as developers who can write Cobol today. You can use salary as an argument or interesting job, but that require you to have people who have knowledge already. Or you face the language market shrinking. IMHO and I can emphasis on word "opinion" enough, is that currently ASIO is quite hard to use it for personal projects, and most of the time it's not worth it. And it saddens me. 
`[...] for me as a developer`. There is the point. Install is for mantainers. It is there to answer the question: "Which files do I need to put in the installer?". Main executable ok. Oh wait, these are tests, I do not need them. Any dlls? Any config file? What about images, artwork, etc. So yes, it just "copies" stuff around, but it is supposed to copy the right stuff. If you are using CPack you can get a .deb, .rpm, a windows installer or whatever thing they are using on mac out of the box.
What's not on the thread is what went on out of public view. I sat on that review for several days to also cool down because I was very angry. I could have excised all mention of annoyance as Michael Caisse would surely have counselled, but you must remember me and Vinnie *know* each other. And I expect to work extensively with him in the future, and I believe he does with me too. So if I didn't care about our personal relationship into the future I'd have let it go, but I do care, so I raised it. And we're good by the way, all settled privately and off list. I'm sure it won't be our last clash, but to be honest, it makes both of us better engineers I believe. It's a good thing.
I know for a fact other reviewers have invested over forty hours into their review by porting their entire codebase to Beast. Six hours is also pretty low for a Boost review, just for the Outcome v1 library which is vastly smaller and less complex than Beast we saw 800+ messages and individuals investing 20+ hours each. Boost is amazing when it works like that, but it's very draining no doubt. And we all have day jobs and families on top.
I always wondered - why would you want to stop or delay the change? It's not like C++ is forcing you to use newer standards. And most of the features I've seen so far are making "code writing" an easier process than it used to be. For the big companies it's quite a gain, in my opinion, because you can hire and teach people easier than before. More streamlined process. So, again - what's the point? Im pinging /u/14ned - maybe you can clarify a bit?
Poors man hiding of API? I dont know honestly. MSDN [claims binary size optimizations](https://msdn.microsoft.com/en-us/library/e7tsx612.aspx) xD.
Thanks for trying to explain it. I guess it's a way of specifying what's to be distributed and what's to be used "internally" - but I still don't understand why is this part of the build system. Seems irrelevant? It's another independent layer to the pie when it comes to creating software. You mention CPack, which creates "installers". This is a separate program that does that job - and that I can understand
You're not wrong in any of what you've just said. Back when ASIO designed, non-blocking/async socket i/o was scarily faster than synchronous i/o. But that isn't true today, kernels have improved immensely over the early 2000s, and now async i/o is usually *slower* than sync i/o because the kernel must unavoidably do more work. The main value add of async i/o now is the *discipline* enforced onto the programmer by programming towards that model. And yes, it's hard to learn and teach and do because fixed overhead programming is always hard to learn and teach and do. That's why top end networking specialists earn more than a grand a day on contract. Still, if you started ASIO today it would reflect today's hardware and today's kernel inefficiencies, and definitely it would not look so async. It might look more like AFIO v2 which appears to be mostly synchronous to the end user. In fact, under the bonnet, it may not be, but the end programmer usually need not care. But that's the advantage of starting the design today with C++ 14/17 and knowing Coroutines are just around the corner. I can make a much richer experience than Chris could back in the day. It isn't a fair comparison as a result.
Oh god, what have you done. XD ... *save the article for later usage*
the difficulty of teaching or learning ASIO is its async nature, which shared by all async libs. Although with current emulated stackless/stackful coroutine, this has been simplified a lot, there are still some gotchas. That's why coroutine is such an important feature for modern c++.
What comes to my mind is some vendors may create language and library extensions tied to proprietary compilers, which are used as a leverage over competition and increase the cost of getting out of the walled garden. Getting those extentions standarized would drive companies away from those vendors towards other more open tools. Another example would be proprietary compilers for specific embedded devices which usually are far from supporting the newest standards. It would be great if companies could switch from them to modern solutions but I'm not knowledgeable about what it takes to support a specific processor architecture in an open compiler. 
Do we really have that amount of people who work for compiler vendors in WG21? 
A better person to reply would be anyone from Microsoft ... but look at the *enormous* costs they've expended on modernising their C and C++ codebases in the past seven years. Hideously expensive, and for no really obvious customer gain either. All partially forced by the C++ 11 standard landing, and the fact that much of their code wouldn't compile on a C++ 11 standards conforming compiler. Multinationals view that sort of tech debt as a competitive disadvantage. New upstarts trying displace them don't have that tech debt, so to slow them down and raise barriers to entry, you try to pace global engineering standards to lower the competitive advantage the upstarts have. Another reason is that competitors try to standardise things which won't cost them much but will be punishingly expensive for their competitors. So you need to send people to ISO to prevent nasty surprises turning up which eat billions of cash for you. For all these reasons of inhibiting progress, most programming languages have left SC22 in recent years. C++, COBOL and Ada are the only ones I believe are still really active. There has been discussion of C++ doing the same in order to remove many of the dysfunctionalities in achieving change in C++, but the multinationals are deeply opposed to that change. So it won't happen until the multinationals decide such a change would be in their interests.
I think I understand but that sounds like a extremely short sighted policy - if a language has no change, people will start to move into another and you risk losing your market entirely. Rewrite is hard, but finding people who can support your legacy code is even harder. It's also much harder to convince somebody to come back to you after they had moved on. And with recent "raise from the ashes" of native code (Rust, Go, D, Nim, Pony and so on) it's even more dangerous because this languages compete with C++, in C++ sphere unlike Java or Python. In short - there is no point in getting competitive advantage in market which is shrinking or even disappearing. I may be wrong, tho. 
Keep doing you.
I don't like it. I think ASIO is the wrong level of abstraction.
&gt; &gt; &gt; Proof of this phenomenon is that I assumed you are now disagreeing with his disagreement when in fact you could have been agreeing with his agreement :) But... he said "Yes, I agree". I personally disagree with the reasons for his agreement, though :p
This post was submitted by cppinterest. I'm curious who this is and what the interest is in posting it here. The problem is that posting one review loses a lot of context and doesn't give a complete picture of the review process. So as it stands, I don't think it's a great idea. But, maybe if we went the full monte and conducted the whole review on reddit. Hmmmm.... this would make it easier for those who don't subscribe to the mailing list to follow and participate. I might draw in more reviewers and reviews which I think would be beneficial for library and documentation quality and for boost. Of course this would not be without downside. Dealing with spitballing from drive by reviewers would consume a lot of time of more serious reviewers and authors who would have to (re)explain the same thing 50 times.) Also the other hand, it's very useful and important that the we keep a historical record of the review process and I don't know if reddit supports that. But I question the value of posting just one specific review here.
You can set where CMake install stuff. In my projects, I'm telling CMake to install libraries in a `extern/` folder in my project directory. Then I tell it that there's libraries there so `find_package` searches there. 
Backward compatibility, I would assume. Import-by-ordinal was already used in Windows 3.x, and when you have to run in 640k RAM, not having to waste precious kilobytes for symbol tables sounds like a good idea.
How exactly do you compile the code? Did you try different optimization levels?
I never said why I agree, I just said that I agree.
&gt; Does "installing" lose it's meaning on Windows? well, no, but in Windows you generate an installer (e.g. with `make package` and NSIS when using CMake).
I'm going to answer this from my limited perspective of install with autoconf (my understanding is that cmake is the new autoconf, and is used similarly) Firstly, 'installation' is a much more general concept and people provide installation mechanisms in their make and cmake scripts. An installation is simply moving the files somewhere useful for the user. In particular, libraries (both the headers and the actual library objects) can be installed to a location that will be automatically searched by compilers, so that users do not have to specify the library's location when the need to use it, just its name. Additionally, after software has been build, the source is no longer necessary to users and does not need to be kept around. Installation 'removes' (in a way) those files (since the useful files are moved, and the project directory can be deleted). make does not (as far as I am aware) have any built in mechanism for installing things. 'install' tends to be a phony dependency that then implements the installation mechanics. It does appear that cmake has some [install](https://cmake.org/cmake/help/v3.0/command/install.html) tools, but I'm not sure to what extent it does things for you. As you've described, yes, it *can* be just that simple. If the thing being installed is a library, then the installation prefix (under which all files and directories are copied to) is /usr or /usr/local. But users also like some control, and would often like to set that prefix somehow (which allows them to install things locally, such as to ~/.local, and therefor not needing root access). This is often done during a configure stage. Speaking of which: workflow. In the autoconf use-case, the developer writes an autoconf script (configure.ac) and a makefile template (Makefile.in). The developer, before creating a 'release' runs autoconf to create a configure script (configure), which is created from the autoconf script, and is then packaged with the software and 'shipped'. The user will then run configure, which takes the makefile template and creates a usable makefile from it. At the configure stage is when the user will specify how they want specific things setup (in our case, the install prefix, which is likely to be /usr or /usr/local by default). After running make, and make test if the developers were kind enough to include a test suit, a user will run make install to install the software to the prefix path. I have no idea what an installation looks like under windows. I'm imagining things get installed to C:\Program Files\MySoftware and then a path variable gets modified, but that's just conjecture. I'm curious about these generator functions. Can you link some examples? If you intend for people to use your software, you should absolutely have some way of installing it. I currently work with [Google's OR-Tools](https://github.com/google/or-tools) which does not have an install script, which makes it annoying to use.
&gt; I guess it's a way of specifying what's to be distributed and what's to be used "internally" - but I still don't understand why is this part of the build system. Two things: * CMake isn't just a build system; per its authors, "CMake is an open-source, cross-platform family of tools designed to build, test and **package** software." * Imagine that you want to create and distribute a library for other developers to use. Since the library has some complex stuff in it (or maybe it's proprietary), it may take a bit to recompile so you want to distribute pre-built binaries. So as an user of a library, what do I want to see ? Ideally a .tar.gz with inside: lib/libfoo.so lib/libfoo.so.1.0.0 include/foo.hpp include/foo_export.hpp doc/index.html examples/ex1/ex1 (compiled) examples/ex1/ex1.cpp and on Windows the same thing but with a .dll and a .lib, etc etc. Well, CMake 'install' can generate this automatically every time you build, for every platform, from your CMakeLists.txt 
this is the best explanation of "installing" I've come across http://foonathan.net/blog/2016/03/03/cmake-install.html It explains generator functions a bit as well The CMake documentation has a page as well https://cmake.org/cmake/help/v3.8/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions(7) But like most CMake documentation it's written from the perspective of someone who already knows all the lingo and knows everything else (ie. it's not very useful :/ ) The more I read about it, the more it feels like this should be a completely separate step. It sounds like historically it's been hacked into "make" with the phony dependency - and so now it's wrapped into CMake/autconf as well. Unfortunately it seems to create more headaches than it solves
[Boost.Locale](http://www.boost.org/doc/libs/1_64_0/libs/locale/doc/html/index.html) Documentation with examples: [Glyph/Word/Sentence Iteration](http://www.boost.org/doc/libs/1_64_0/libs/locale/doc/html/boundary_analysys.html) [To/From UTF8](http://www.boost.org/doc/libs/1_64_0/libs/locale/doc/html/charset_handling.html)
Right, I'm not disputing that packaging is something people want to do :) That makes sense on a high level and with a toy example it seems fine. But when you have external dependencies - and CMake is no package manager - suddenly things are a lot messier. If the packaging step were to be decoupled from the build step then both things would end up looking much cleaner
So you have to manually install all your dependencies first and then configure your project so it can find then?? That sounds messy. How do you keep track of configurations? With scripts? Why not just have your project build it's dependencies and use add_subdirectory() ? Something akin to this setup: http://foonathan.net/blog/2016/07/07/cmake-dependency-handling.html
&gt; But when you have external dependencies - and CMake is no package manager - suddenly things are a lot messier. On the contrary; for instance I write a software which uses Qt with CMake and it's very easy to copy all the needed DLLs because CMake is aware of them : https://cmake.org/cmake/help/latest/module/BundleUtilities.html ; creating installers that work on all platforms "just works".
All absolutely correct analysis. But you must remember that the multinationals which sponsor the C++ compilers don't necessarily have exactly the best interests of the C++ the language nor C++ the ecosystem in mind. A lot of the time they align, but some of the time they don't. Now, as to whether that will become an actual problem given the new competition is yet to be seen. I can tell you that the threat is widely appreciated, but it is also recognised that the quality of tooling and library ecosystem in the competitors still falls well short of C++'s for now. So there is still time, perhaps even plenty of it. And if Herb gets his metaclasses or something like it, C++ will be springing rapidly ahead of any of the competing languages, yet with all the benefits of its vast library ecosystem and thirty plus years of experienced developers. So I wouldn't count C++ out by any means. C++ is slow. But there is great wisdom in letting the upstarts make big mistakes in their rush, then surpassing them with a superior implementation using hindsight gained from watching them incur tech debt.
&gt; where does the "cross productness" of this live? It lives in the monad part. If `co_await` could operate like Haskell's [monadic `do` notation](https://en.wikipedia.org/wiki/Monad_%28functional_programming%29#Syntactic_sugar:_do-notation), that function would be equivalent to something like return monad::bind(xs, [&amp;](auto x) { return monad::bind(ys, [&amp;](auto y) { return std::vector&lt;std::pair&lt;T,U&gt;&gt;{std::make_pair(x,y)}; } } And here, `monad::bind` loops over the list, applying the function to every element and then concatenating the lists they return, so the cross-product comes from the nested loops. But if `co_await` doesn't do this, then it isn't true monadic control flow, it's just a subset that only works with single-valued monads (and possibly only a subset of single-valued monads). This is also why it's not zip; to zip the lists with bind, the first bind would have to loop but the second bind wouldn't.
That actually is pretty reasonable.
Hehe, I interpreted "yes I agree" as a smart ass "you don't know what you said" comment.
Woah.. okay.. the CMake rabbit hole just keeps going. I hadn't seen this feature... but.. well that's cheating :) I mean you're showing a method of avoiding dealing with your dependencies by bundling everything. You can also just build everything statically to get a similar result (well maybe not Qt b/c of licensing mumbo jumbo..) Again, I'm not saying this isn't useful - it's actually pretty cool - I just feel like it's something that should be done afterwards in a separate unrelated process. CMake already can't be read sequentially as a series of instructions - but now with the build and install steps intermixed and with a healthy peppering of generator functions it makes it really hard to reason about what's going on. You may in one case want to package it as a bundle, in another case you want it to be up on a some linux distribution's repo linking to other hosted packages, in a third it's getting installed into some android app and hooked into a JNI wrapper. Maybe for some cases some libraries need bundling and some are available on the whole system (common on windows) so just pointing at an install directory isn't sufficient Why does all that logic have to be intermixed with the build though? Seems like the wrong place to do it, no? If someone wants to make an installer for my program in their own setup - why do they need to muck around with my build? 
+1 for reviews to be conducted on reddit :)
&gt; This is where I may be completely missing the point, but where does the "cross productness" of this live? What part of code understands that your intention is to do a cross product and not a zip? That's what monadic bind does. Take this Haskell code which is hopefully correct: product :: (Monad m) =&gt; m a -&gt; m b -&gt; m (a, b) product ma mb = do a &lt;- ma b &lt;- mb return (a,b) Then depending on the monad, you get different behavior. product (Just 3) (Just 'x') = Just (3, 'x') product Nothing (Just 3) = Nothing product [2, 3] "abc" = [(2, 'a'), (2, 'b'), (2, 'c'), (3, 'a'), (3, 'b'), (3, 'c')] That difference is encapsulated in the implementation of `bind` (or `&gt;&gt;=`). But I don't think you can do that in the current coroutines structure? 
Most of the libraries I use can be installed with my distro's package manager. If there's a library that cannot be installed this way, sure, you can download the source and install it system wide. I prefer installing it for that project only. I only have to add another prefix to CMake and it works. Plus, this setup works on windows too. Sometimes `add_subdirectory` is not enough. If the exported package name is different from the target name, then when adding a subdirectory you won't be able to use that exported name, only the target name. And not adding `find_package` when you want to use a library is wrong, you won't be able to use any other installed version but the one in the subdirectory! Plus, if that library's CMake file messes with variables and expose option, it will leak into your CMake variables and options, and expose them to your tools. At first I was doing that manually, so I have a small bash script (20 lines long?) That find which libraries missing from the system, clone and run CMake + make install. I don't know what config you're talking about. So... You have to first clone every dependencies before running CMake? And build them even if they already are installed on your system? How do you manage versions and tags? With git submodules? That sounds messy.
I'm not clear how you deal with versions and tags when you use your distro's package manager (where u seldom get anything except the "latest" version they updated at some point). I almost never use *any* system libraries and build all my dependencies. A good fraction of the libraries I use don't have packages and even when they do the package manager provides only one version and with some default flag (at least you'd hope.. I'm not even sure). Besides, if you want to support windows you need to have a setup that doesn't require a package manager. Most importantly I want the source so I can use it while debugging and navigating my code. And yes, you can use use gitsubmodules. I don't really see the problem.
Lol, I really didn't mean it that way. I honestly do agree with them. I also think it does not contradict what I said. You can have powerful libraries with simple defaults.
For example, the usual packaging script for making some Debian Linux package contains a line: dh $@ --parallel --buildsystem=cmake Internally it gets from cmake the information about what files must be installed, so it includes them into a Debian package. Historically it originated from the `make install` target that gave everything we need to build a package. When you executed `make install` on a live system - it installed files on it directly. But the packaging script executed this command to install all files into a temporary directory and then zip it as a package. The dependencies in Debian Linux are not bound to some specific programming language. Instead, packages depend on each other, so one package pulls other packages to get the required libraries or tools (sometimes programs in one package just want to execute another program that comes from different package). Dependencies of the package are defined in the packaging script of that package. This information is usually not extracted from the cmake/make build systems.
May I ask what tool you used for creating the function assembly diagram?
It was a pretty significant savings in the Windows 3.1 days. It isn't any more, and you should no longer be using the feature.
&gt; I mean you're showing a method of avoiding dealing with your dependencies by bundling everything. Well on Windows and macOS that's the only reasonable thing to do. &gt; You can also just build everything statically to get a similar result sure &gt; (well maybe not Qt b/c of licensing mumbo jumbo..) Qt is LGPL, and contrary to popular belief [you can statically link LGPL libraries to proprietary code](https://www.gnu.org/licenses/gpl-faq.en.html#LGPLStaticVsDynamic). &gt; I just feel like it's something that should be done afterwards in a separate unrelated process the less software I have for my build pipeline the better I feel. &gt; You may in one case want to package it as a bundle, in another case you want it to be up on a some linux distribution's repo linking to other hosted packages, in a third it's getting installed into some android app and hooked into a JNI wrapper. Maybe for some cases some libraries need bundling and some are available on the whole system (common on windows) so just pointing at an install directory isn't sufficient CMake handle all of these cases, even the Android one. &gt; Why does all that logic have to be intermixed with the build though? Why do you say that it has to be intermixed ? For my own stuff I put all the build commands in a file and all the install commands in another file, and call the first then the second one. &gt; Seems like the wrong place to do it, no? Traditionnaly (even with autotools, and certainly even before) you have a `make install` command. Since CMake generates makefiles, it only makes sense that it also generates the code of the `make install` command. 
Let's just shift to one practical point and stop with this useless opinionated stuff. If there was UFCS, what's your view over the many completions that would come up due to it. You realize how C++ (nested) header inclusion works, many of those suggestions if globbed together with actual member suggestions would be overwhelming not only from user's point of view but from compiler's side too (e.g. for libclang to do it), so much so that I wonder whether it would be practical or whether anyone would care to implement it correctly. This has been pointed twice already.
Just imagine that the necessity of a library author do an inclusion on its header would forever interfere on all user code completions. Turning them potentially polluted and slower.
What you're describing is almost completely disconnected from reality.
No, but the compiler vendors wield oversized power because they implement the standard, and if they very strongly disagree with an idea, it's dead, no matter how otherwise worthy. In the past if any major compiler vendor felt strongly enough against a proposal they'd organise the country votes to kill it at national voting level. But it never usually gets that far, and I'm not aware of that happening at WG21 in a very long time now. More common in other WGs though, at least historically.
Whether you identify the function as `25` or `"25"` doesn't make much of a difference. 
&gt;&gt;what's your view over the many completions that would come up due to it. [1] I would sort the member function methods first. [1.1]if the number of matches is above a certain threshold, they can go in a submenu (foo() bar() bar() &lt;more&gt;)- but I think sorting would be enough; [2] Remember I have an intermediate suggestion which is **explicit opt-in for UFCS** (which I think I actually prefer tbh), i.e. only ```something(Foo&amp; this)``` will be eligible, ```something (Foo&amp; f)``` would not; no change in behaviour to existing sourcebases. Remember the completions are being narrowed down by using the type - even if templated stuff would be applicable, we can use the same rules of specificity to prioritise.. Foo::foo() first, foo(Foo&amp;..) second, Foo&lt;T&gt;(T&amp; ..) last (if at all) [3] We have project-wide completion for free functions too :) people don't complain about that. we still get the same 'alphanumeric narrowing down' for members that we do for free-functions, any work that has gone into writing a decent sorted menu for that should just go across to the '.dot' completion menu aswell. (e.g. what if it looked at the locals, ranking the functions by the number of types of your current locals that they use) [4] remember concepts are coming which will even help narrow down templated suggestions; (it could be members, then free functions, then templates of implemented concepts..) remember that with UFCS, functions that already exist would be moved out; the other chap seems to want to put things into classes, using inheritance. I'm guessing in my 'something(Foo&amp;,Bar&amp;)' example, he would have derived a class FooBar :Foo , and the completion list would still have to show FooBar methods, then Foo ancestors (all the way down); you could get into all sorts of malarky with builder patterns I guess ('make a FooBar object to collect 2 parameters together').. but I find this sort of thing to be convoluted clutter.. something(a,b) ---becomes --&gt; class FooBar{..constructor malarkey..} --user does this--&gt; FooBar(a,b).something(). you'd have separate objects for every permutation of operands and hence you've shifted the problem into naming classes, additional boilerplate. more steps to do the same things. What if there are 3 operands.. which 2 do you group, horrible.. do you basically try and emulate a postfix language.. [4.1] UFCS and Concepts will play well together : we're basically retrofitting the rust-style trait system (but I would personally consider C++ with UFCS to be superior to rusts's current idea for reasons that need an entirely different thread to explain) [5] remember these functions exist anyway, and the hazard we're trying to avoid is that people already want to clutter the classes with them, precisely to get them to show up with autocomplete (the AC is what they want, the class coupling is the undesirable side effect). If you're not searching them in the autocomplete, you're searching them in the docs. 
[2] based on identifier name?? That looks quite an ugly suggestion. It's hard to believe committee would accept it. [3] As I've repeated ad nauseam, I frown upon architecting its own house based on how its hammer works. I'll simply ignore [3].
&gt;&gt; You realize how C++ (nested) header inclusion works, [6] and yes as I was explaining, this would allow more decoupling hence reduction in the number of headers included.. more potential intelligent use of the headers to actually narrow things down instead of having to include everything everywhere. e.g. in my example, code that just uses 'Foo' never needs to include 'Bar'; code that just uses 'Bar' never needs to include 'Foo'. you could sort things by the intersections of systems more easily
OK, now [3] has become [5] after the long answer edit.
_A symbol has no name_
&gt;&gt;[2] based on identifier name?? That looks quite an ugly suggestion. It's hard to believe committee would accept it. or you could copy exactly what C# does and use 'this' like an extra keyword, ```something (this Foo&amp; f)``` , which has the benefit of crossover experience if people move between languages). I like the identifier name though, it emphasises that it is really just like a parameter. or we could make something like Rusts impl blocks.what to call it , I don't know. class Foo += { } more contextual keywords? I wouldn't object to having to write something wordier:- how about class(extention) Foo { ... } or class Foo extention { } I haven't studied the 'concepts' proposals, maybe they already included a way to do this (the rusty- route would be that 'extension methods must be in a concept' .. the problem with that IMO is you end up having to name many 'traits' with one function each , which gets silly, but if you could implement partially it might not be so bad.) swift:- &gt;Extensions can add new instance methods and type methods to existing types. The following example adds a new &gt;instance method called repetitions to the Int type: extension Int { func repetitions(task: () -&gt; Void) { for _ in 0..&lt;self { task() } } } (i accept we can't just copy that because we can't add a new 'major' keyword late in a language's life, but we should be able to do something very similar.)
[0]: Reminder that I don't dig/read homeric arguing. Sorry but, I don't know for who you have written it except for yourself.
It hasn't, apparently, occurred to you that I might simply disagree with your reasons? That I might simply have another point of view, and that your position is neither provably correct, nor universally shared by everyone around you? And that I am simply not convinced by the article you've linked to twice now? "Whatever it takes to get me to understand it" is a tall order, given that I'm just not going to waste an entire afternoon writing a rebuttal for the countless (and to be honest, often rather random looking) points you bring to this discussion. There is one point, however, that (against my better judgement) I'm still curious about, and that's this: when you wrote about implementing "any function" as either a member or non-member, does that also imply that under UFCS rules, free functions can access private data? 
&gt;&gt; "I frown upon architecting its own house based on how its hammer works. I'll simply ignore [3]." on the contrary, considering how architecture and tooling interacts is smart IMO
&gt;&gt; does that also imply that under UFCS rules, free functions can access private data? I would not suggest that. keep their access rights the same as regular free functions. from the POV of the caller it shouldn't matter. i do get how keeping certain key details internal can lead to stability, but then you have a huge array of conveniences layered ontop; and you might have access to some details that can be expressed in terms of others. Over time you might want to move things both ways. Some 'helpers' might be recognised to be so fundamental that you absorb them, vica versa you might find some piece of the class can be removed (and relegated to helpers).
The real reason to link by ordinal instead of name is to improve load time. The ordinal table is sorted, so it is much faster to find a ordinal than to search for a string. 
"25" doesn't look like much of a function name to me. I think it makes more sense for the following: std::vector&lt;std::pair&lt;std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt;, unsigned int &gt; &gt;&amp; std::vector&lt;std::pair&lt;std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt;, unsigned int &gt; &gt;::operator=( std::vector&lt;std::pair&lt;std::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt; &gt;, unsigned int &gt; &gt; const&amp; ); 
&gt; I would like to handle a variety of encodings with a focus on UTF8, UTF16 and UTF32 but I would also consider other encodings (Latin-1 and so on) a bonus even if it just converts them to an UTF encoding. Just *emulate* an **internal** unicode data type - what C++ simply lacks. Just build your stuff all around **one** encoding and *decode* every input data into it and *encode* every output data into the original encoding. I would suggest of course UTF-8 as internal encoding as it can handle all unicode code points but optimized for ASCII graphene clusters.
Haha yea! That's a very good point and something to watch out for.
+1 for explaining/elaborating, thank you!
DLL exports jsut map a name and/or ordinal to an offset, they don't come with a type. C++ compilers tend to use a [mangled name](https://en.wikipedia.org/wiki/Name_mangling), but that's not required since the DLL binding is compiler specific. So if "THEY" wanted to hide APIs, there's really nothing stopping the linker to export that `std::vector ...` as "25", and import it as such. (or, more practically, use a hash of the mangled name). /u/Plorkyeran is right: that's a holdover from Win 3.1 days when memory was at premium (a reason for many design decisions carrying over from that decade) that's rarely used nowadays. 
 optional&lt;Point&gt; parse_point() { TRY parse_lit('('); auto x = TRY parse_int(); TRY parse_lit(','); auto y = TRY parse_int(); TRY parse_lit(')'); RETURN Point{x, y}; } How about a keyword on the function, which then implies co_await everywhere: optional&lt;Point&gt; KEYWORD parse_point() { parse_lit('('); auto x = parse_int(); parse_lit(','); auto y = parse_int(); parse_lit(')'); return Point{x, y}; } You could even separate the error from the valid case: Point parse_point() KEYWORD(nullopt) { parse_lit('('); auto x = parse_int(); parse_lit(','); auto y = parse_int(); parse_lit(')'); return Point{x, y}; } Hmmm.
Doing installs properly is an important skill and difficult task in and of itself. As a developer, _you_ won't see a lot of benefit from making install rules for _your own_ projects, _**but many users will**_ (As well as package maintainers). CMake installation works by generating a `cmake_install.cmake` script at configure/generate time. When you run `make install`, it executes `cmake -P cmake_install.cmake`. If you take a look inside the script, you'll see it executes `file(INSTALL ...)` for all of your files. Roughly: Each time you call `install()` in your `CMakeLists.txt`, one or more `file(INSTALL ...)` commands will be generated in a `cmake_install.cmake` in the corresponding build directory. You can insert arbitrary code into the install script using `install(SCRIPT)` and `install(CODE)`. This gives good customization point when you need more complex install behavior. A lot of the magic lies in the `file(INSTALL)` command: - If given a _relative path_ for ``DESTINATION``, the file will be installed in `$ENV{DESTDIR}/${CMAKE_INSTALL_PREFIX}/&lt;DESTINATION&gt;` - If given an _absolute path_ for `DESTINATION`, the filE will be installed in `$ENV{DESTDIR}/&lt;DESTINATION&gt;` The `DESTDIR` is a semi-standard environment variable used to retarget all installations to be different from the root filesystem. This is how packages are created: `DESTDIR` is set to a temporary directory, and that directory (which represents the root of the filesystem) is archived and stored in the package. You won't have to worry much about playing with `DESTDIR` unless you're a package maintainer or testing your install. For example, to test your install, you can: env DESTDIR=$(pwd)/test-install cmake -P cmake_install.cmake This installs everything into the `test-install` directory, and you can poke around inside to see if it all looks good before you commit install changes. `CMAKE_INSTALL_PREFIX` is far more common for customizing the install destination. Use it well. Important to note: - On Windows, this is initialized to `C:/Program Files/${PROJECT_NAME}`. - On Unices, this is initialized to `/usr/local` - `/usr/local` is for install files that are outside of the purview of a system package manager. These are usually things installed by `make install`, `pip`, etc. - **Do not** install to `/usr` _unless_ you are generating a package and using `DESTDIR`. - If you'd like to customize the `CMAKE_INSTALL_PREFIX` for your project in your `CMakeLists.txt`, check if `${CMAKE_INSTALL_PREFIX_INITIALIZAED_TO_DEFAULT}` is true. This variable is only true if a user _has not_ specified `-DCMAKE_INSTALL_PREFIX` on the CMake command line. This way, users are able to override the install prefix if they'd like. `CMAKE_INSTALL_PREFIX` has no effect until `cmake -P cmake_install.cmake` runs. So, if you'd like to install with a custom prefix just once, you can do so by running the install script manually: cmake -DCMAKE_INSTALL_PREFIX=/my/different/prefix -P cmake_install.cmake For this important reason, you musn't commit _one of the most grevious_ CMake-sins: # This is evil! install( FILES foo.txt DESTINATION ${CMAKE_INSTALL_PREFIX}/share/things ) Instead: install(FILES foo.txt DESTINATION share/things) There's a lot of magic that can be done with install as well. It's very useful to be able to install multiple versions of a single library and have them sit happily beside eachother. This can be done by setting install paths correctly. For example, I can have a `Foo` library version `1.1` and `1.2`. To get different versions to install properly, the install paths should be qualified by the library version. For example: set(qual ${PROJECT_NAME}-${PROJECT_VERSION}) install(TARGETS Foo EXPORT FooTargets RUNTIME DESTINATION bin/${qual} ARCHIVE DESTINATION lib/${qual} INCLUDES DESTINATION include/${qual} ) install(DIRECTORY include/ DESTINATION include/${qual}) install(EXPORT FooTargets DESTINATION share/${qual}/cmake) This isn't _all_ that needs to be done, but it's a start. Know that `find_package(Foo)` does a glob search for `&lt;prefix&gt;/(lib|share|)/Foo*`. Since the version qualifier follows the package name, both `Foo-1.0`, `Foo-1.1`, and `Foo-WhateverVersion` will all be searched, and a `FooConfigVersion.cmake` can help CMake know which one to chose. You can also install a single package with multiple configurations, because `IMPORT` libraries can have multiple imported configurations. CMake will then chose at link time which library to load based on the build configurations.
You are still very confrontational in that review thread. You seem to like escalation, where one could de-escalate instead. Agreed with you that that's sometimes necessary, but in my opinion not in this case or not to that degree. But yea - you're not wrong - just consider how you treat people and how you approach conversations (online).
&gt; Coroutines are just around the corner Since you are an expert on performance can you comment on coroutines and performance? I know they are advertised as low overhead, but the fact that the entire function context needs to be restored/packed away makes me doubt that they are as fast as some uglier C++14 code. 
that explains the co_ bullsh*t :)
does it work with functions that return void, not optional?
Probably, maybe. I never was able to measure anything measurable there, but i guess, somebody must have cared enough... maybe.
Agreed. I have some where a lamba (declared as auto in a function) is passed as a function pointer to setup a POSIX timer. I'm quite sure that this is incorrect: when the timer expires the lamba expression will be "out of scope.
very nice writeup
I reckon you'd have to specialize for plain void, which wouldn't be a good idea. If optional had map/bind, that would do it, just not running the callback of empty. 
It's not quite the same, but there is also `sccache` built in Rust that should mostly work with GCC on Windows. Getting Rust on Windows and then building anything with Cargo is easy. Might give it a try since it supports Visual Studio as well!
This seems like it wouldn't play well with all of the functions that have extra calls, like adding some logging etc. You'd have to convert everything to the old style when adding any function call that doesn't return optional unless that's figured out, plus cannot work with a returned optional directly in any special cases because it will be implicitly unwrapped. 
Installing anything into /usr/{lib,bin} not using the package manager is generally a mistake. That's what /usr/local/{lib,bin,etc,..} are for. And even then, you probably want to manage them somehow, like if you want to upgrade, you want to be able to get rid of things no longer part of the install. And `make uninstall` is rare. 
There's long history here. In the dark ages, `make install` was how you installed things, although usually into /usr/local, which was reserved for the local administrator. That's still a terrible way to deal with the system, as cruft accumulates. So package management was born. There's also the assumption that things deployed via package management are broadly interoperable. They will share the same ABI for everything. For things with C linkage, otherwise known as OS linkage, this is pretty straightforward. Complex objects get passed by a pointer that erases details, and only the library manipulates them. See, for example, FILE*. C++ is more complicated. We want to expose more information, like object layouts, so that things can be inlined, and optimized effectively. This means that C++ libraries must, in general, be built with the same compiler, with the same options, and against all of the same underlying libraries. That's hard. There's also the issue of co-development. The result of an 'install' is something that can be consumed by a different project, which will not be making changes to the first. That's usual for 2nd and 3rd party libs, but unusual for 1st party ones. If you find a flaw with your own code in libA when you're consuming it in exeB, you want to just change it and rebuild. Not go to the libA project, change things in those files, build and install, then try it out in exeB, and iterate that a few times. You really want to pull libA into the exeB project and work with it inline. CMake supports both models, at least to some extent. You ought to be able to pull the CMake libA project into the exeB project, and go from there. This is better supported with more modern CMake usage. All of this will really bite you if you're trying to use something other than the system C++ compiler, like on a Linux system trying to use clang with libc++. 
The top-level Makefile is, traditionally, the way you interact with everything in a package. Not just compilation, but docs and testing. A good summary of the expectations can be found here: https://www.gnu.org/prep/standards/html_node/Standard-Targets.html#Standard-Targets
Ah, well I guess I don't really like software that's trying to do too much :) But I see the legacy reason to have install support - since it maps directly to make Do you have any publicly available examples where u split the build and install into separate files? I'd love to see how that's setup
My subtle point was: - it still has lots of boilerplate - as you remove the boilerplate and add some language help, it looks more and more like exceptions And thus, why not just use exceptions.
Depends on perspective Stephan. I don't think individuals like you actually walk into WG21 meetings thinking "how will I best serve my multinational employer today?". Not even close, they're there to do (hopefully great) engineering. But equally Stephan, if WG21 took a decision that was *really* bad for Microsoft, I mean like costing them billions of dollars, are you going to claim that no one in upper management isn't going to give someone (probably Herb) a ring and ask "what the hell is going on here?" Well of course they would. Which is why such an event never happens. No really radical, really expensive nor really disruptive change ever happens as a surprise. Because lots of people have taken lots of small actions like communicating expectations, setting boundaries, directing and focusing change in one direction and not another, and all that happens silently with it rarely being obvious. Still, cumulatively, in aggregate and when all rolled together, it without doubt slows down progress. That's not a bad thing like most people feel, but it does come with costs. You've often heard Bjarne mention those costs and his frustration with them. I'm not talking out my ear here.
I've raised several concerns with Gor about his choice of implementation, mostly about what I feel is the avoidable malloc per coroutine instanced. But the Coroutines TS isn't meant to be the fastest possible coroutines implementation. It *is* meant to be a safe, predictable and then fast coroutines implementation. It will therefore not be as fast as say Boost.Coroutines2 which does lots of UB, and thus makes for brittle code. It's the same distinction as between using raw socket APIs as ASIO. You will unavoidably give up some performance for the convenient abstractions in ASIO. Same with the Coroutines TS.
I choose my words and tone a lot more carefully than most realise. They think I fly off the cuff. I think I've done that three times *ever* on boost-dev, once due to an unexpected interaction between cough medicine and codeine (I hadn't realised the cough medicine had so much alcohol in it), and for each of those three occasions I made a grovelling public apology and did penance privately off-list for those I had wronged to make amends. If you look around, you'll find me in a wide number of communities on the internet both past and present. Something like twenty five years now. You'll find I'm a lovely guy almost everywhere almost all the time. But on boost-dev I've been a lot nastier because that's the culture on that forum. It was a big reason I avoided Boost in fact right up to 2012, despite Dave pestering me to join. I personally disagree with the long standing tolerance of toxic behaviours, especially when some past and present steering committee members are the worst offenders, but I also know when in Rome you must do as the Romans do if you are to get anywhere. If you are sweetness and nice on boost-dev all the time, you'll make very little progress on anything. Doesn't work like that there. You have to be "robust" (whatever that means). I am hoping it will become less tolerant of toxic behaviours in the near future, as I've mentioned finally big changes are happening behind the scenes, so I am very hopeful. I've long hoped for a more inclusive, positive, and supporting culture there for making great new C++ libraries, like the culture I've hopefully made as GSoC admin for the students these past four years. We'll see how it goes. 
Your C++ isn't like the Haskell type though. The Haskell equivalent of your C++ function signature would be something more like: ([a], [a]) -&gt; [(a, a)] I think you'd have to have a function that looked more like: template&lt;typename Monad, typename A, typename B&gt; auto product(Monad&lt;A&gt; a, Monad&lt;B&gt; b) -&gt; ??? The return type would be a bit problematic, maybe you could do something like this? `template Monad&lt;A, B&gt;::return_type`. I think though that the actual type depends not only on the monad in question, but also on the implementation of the coroutine, and that basically rules this idea out. You have to specify a concrete return type (see [my tutorial](http://www.kirit.com/How%20C%2B%2B%20coroutines%20work/A%20more%20realistic%20coroutine), the section called "Control the return type, control the coroutine")) because you have to tell the compiler the relationship between the type in the `co_return` and the type that is returned from the coroutine. There might be a way to get something akin to do notation in C++, but I don't think this is going to be it.
I replied to sphere991 below about why I don't think it can be. The type signatures are difficult. If the return type can be described wholly based on the monad then you'd be a step closer. I don't know enough to tell for sure, but I suspect it can't. If the return type depends only on the input types then there's a chance, but from what I see the type also depends on the expression in the `co_return` itself and then it can't work.
Ah, I see what you were getting at. There are several things I have in mind. First, I've focused on monads that can be used for error handling, but I can conceive people finding other uses as well, with different monads. (Edit: Exceptions provide this sort of control flow for error handling, whereas this is for just the control flow, which can then be used for error handling purposes. They're really similar, but this would probably lend itself better to those situations where people complain about using exceptions for control flow.) Second, there's a strong voice from those who can't use exceptions, and this provides a close alternative. I'm not going to go into performance, but the author of Outcome has done exception benchmarks more recently. If exception performance is a problem in your case and error code checking is not (because that's all this really is under the hood), then this is a pretty viable choice. Explicit error code checking with minimal boilerplate. That leads up to the third point: this is explicit, and I would argue that the small bit of boilerplate around callsites isn't a big deal, less so with a shorter syntax like `try foo()` or `foo()?`. Keeping this explicit means that functions with the possibility to return an error include this in their type. It also indicates code that can fail explicitly at the callsite. In a code review, you can see exactly which lines can fail, unlike with exceptions, and without the huge amount of boilerplate error codes have. Just by looking at the types, calling code doesn't get a success value directly, but can do so with minimal hassle. `co_await foo()` (pick your syntax variation) propagates an error, `*foo()` assumes success, and `(void)foo()` ignores the result/error even in the face of `[[nodiscard]]`. Given `[[nodiscard]]` on return values that might be errors, either this will be explicit or you'll get a warning. All of these call-site syntaxes are short and explicit. Handling the error right there can be done by using the returned object as you normally would. It's possible to emulate a try-catch that encompasses the entire success path with a function that coerces an empty optional to a value, or a regular if statement: string f() { return ([&amp;](const auto&amp; result) -&gt; optional&lt;string&gt; { auto res = co_await foo(); auto res2 = co_await bar(res); co_return co_await baz(res2); })).value_or_eval([&amp;] { log(...); return ""; }); } Admittedly, try-catch looks a lot nicer here, though you lose the error explicitness of the success branch. Some advocate putting these encompassing try-catches into their own function so that the wrapper is responsible just for error handling and the wrapped function is responsible just for the actual operation. If doing this, it's as simple as calling the original function and an if-else on the returned optional/expected, returning the result in one branch and handling the error in the other: optional&lt;string&gt; f_impl() { auto res = co_await foo(); auto res2 = co_await bar(res); co_return baz(res2); } string f() { if (auto res = f_impl()) { // try return *res; } else { // catch log(...); return ""; } // Or return f_impl().value_or_eval(...); } Finally, this satisfies those who prefer exceptions be used for exceptional cases. A parsing error and many others like this are usually not exceptional. You can certainly choose to throw an exception here, though many choose not to. This is especially true when there are no errors in the text, but the parser tries multiple strategies to parse a piece of it. For example, a parse that takes two others and tries them both (satisfying an OR in the grammar). It is almost expected that at least one of these fails. It often depends on the caller whether it is exceptional to receive an error here, and in a tight loop, having many iterations fail and actually throw is not expected to perform well. C# actually has both `int.Parse(str)`, which throws, and `int.TryParse(str, out int result)`, which returns `bool` and stores the result in `result` if successful. This also allows for checking the format of a string without throwing and catching an exception to determine it's not formatted like an integer, which is something I've always found feels very wrong. Edit: I feel like Joe Duffy goes over the error handling side of things really well [in his Midori article](http://joeduffyblog.com/2016/02/07/the-error-model/). It's long, but it kept me interested the whole way through. It turns out that Midori ended up with something similar for recoverable errors, but based around exceptions, and with exceptions being designed around so well, it sounds like exceptions worked well for them. They had the usual try-catch notation, but also the benefits of this notation, mainly immediately knowing all of the places that could throw. Definitely an interesting read.
C++ progress is primarily slowed down by: * The language and libraries' focus on compatibility * The ecosystem's resistance to upgrading tools, modernizing codebases, and purging old ways of doing things (some of this resistance is due to lack of tooling) * The extreme interconnectedness of the Core Language and the extreme complexity of its corner cases * The size of the Standard Library (it is large for a *Standard* library, anyone who says it is "small" is not comparing it to anything that is delivered via specification and not implementation), and variation among platforms * The high complexity of Standard Library corner cases (i.e. what LWG spends all of its time dealing with) * Development via consensus and not dictator None of these reasons have anything to do with invisible influence from multinational corporations. The scenario you're describing is more or less impossible. Something that broke the world would be widely opposed in plenary, not just by major corporations.
Educational and entertaining. Excellent work. I think a improvement could be making it dynamic i.e. manual relocations with a dynamic load pattern. to properly locate the desired area or areas on a failed load. 
So I'm a Linux guy not Windows, but this looks a lot like what `ld.so` or `dlopen()` / `dlsym()` do.... Am I missing something or is Windows just that different?
I think you are missing the part where the underlying file is not locked while it's loaded. When using dlls normally it is indeed very similar.
Actually export table names are also sorted, both are an O(logn) binary search.
I think this is awesome, but **I would want to go further and consider "a=&gt;.."** if it parses ok it would save me wanting to do things like #define FX(E) [&amp;](auto&amp;&amp; x){ return E;} lambdas are such a powerful feature that they deserve extremely compact syntax (haskells currying being the ultimate expression of that.. but with such a compact lambda, saying ```x=&gt;do_something(a,b,x)``` would again 'begin to close the gap'.. this is the argument in rust, 'their lambdas are already so compact that they don't need currying' ... ```|x|do_something(a,b,x)``` is only 4 extra characters ). I realise currying wouldn't work well alongside C++ overloading. 
Shared libraries are not locked when loaded on Linux, as far as I know. 
but lambdas themselves are a composable component.. being able to write them more easily makes other patterns easier to accomplish. the nice thing about this is the syntax is so light that it begins to 'melt away' , it ceases to be clutter, just like we don't think twice about using braces as a shortcut for all sorts of stack frame manipulation/jumps which we never want to be 'explicit' about. When you can write a lambda as easily as any other statement ... many other patterns become instinctive/clearer
maybe we should try to retrofit move-semantics/borrows to Haskell 
ICU is the de-facto library for text encoding conversion.
Which uses ICU (or its own internal thing if you disable ICU).
&gt; So if "THEY" wanted to hide APIs, there's really nothing stopping the linker to export that std::vector ... as "25", and import it as such. (or, more practically, use a hash of the mangled name). Both of these look like they would have collision issues unless you keep track of already assigned IDs. Could it speed up linking? You end up comparing a short number instead of a mangled name. 
After more thinking about this list monad there is another problem, apart from the types I already mentioned. The coroutine is suspendable but you can't save that suspension state and then come back to it. Every time you resume you have to carry on from the point you last suspended. This means you can't build a looping control structure out of a `co_await`. It suspends and your only option is to either move forwards or stop altogether. You can't re-invoke the rest of the coroutine from that point giving a different element of the `xs` vector each time. So, if you want a loop then the coroutine has to loop somehow. `for`, `while` etc. are all good. You can't even do something like this: auto x = co_await xs; auto y = co_await x, ys; In your example both `x` and `y` would be some structure that deferred the looping behaviour and the coroutine machinery (the type actually returned) would need to know how to unpack the `pair` so that it performed the right loop from the deferred types.
When you build your project there are source files, object files, binaries, resource files (images, music, etc.) are all around your `/home/geokon/git/my-project/`, and what's more, the places they are generated at depend on build systems: cmake might put your binaries in `/home/geokon/git/my-project/build/foo`, autotools in `/home/geokon/git/my-project/.bin/f/foo`, etc. (those are just fictional examples). You want your software to be used by someone, you want to distribute your built software, so how do you put all these little pieces of executables, libraries, resource files (images, audio, etc.) together such that the user could run it and it would just work? You `make install` into a target directory, which you then zip and ship to the user. Now that I have explained what is the point of installing, let's talk about some differences between platforms when it comes to installing. The main difference is the behavior of the default install directory. - For \*nix systems, it's common for users to build the software, so when no install directory is specified, the build system defaults to installing your software into the system directories, so that the user or other software would be able to find and use your software. - On Windows systems, it's very uncommon for users to build the software, not to mention that there are no common directories for binaries, libraries and resource files like on \*nix, so when no install directory is specified, the build system should default to installing your software into some sane sub-directory inside the build directory, so that the one who built your software could either package it for others or copy over to the appropriate place on their system for their own use. For Windows you might also consider creating an installer as the result of the install step, since that's the common way you distribute software on Windows aside from pre-installed .zip files. However, when the install directory \*is\* specified, the behavior is the same on *nix and Windows -- you just install your software into that directory instead of the default one. &gt;It also doesn't seem to flow well with dependencies. If you have 2 unrelated projects that both use the same external library with different configurations - what will happen when you install both? You don't have to install the libraries system-wide, you can specify different install directories for each, and make one program to load libraries from one directory, and another from another. That's what you do on Windows. On Linux, such issues are of concern of the distribution packagers: when a distribution packages two software that require different configurations of the same library, they are the ones who are resolving this issue. I'm not a packager, so my knowledge here is a bit limited, but the obvious solution I see is to build the library such that it would be usable by both programs, e.g. enable both `--flag-one` and `--flag-two`. It's quite uncommon for a library to provide exclusive features (either `--flag-one` or `--flag-two` but not both), so this should work in almost all of the cases.
Back in the days when Amigas roamed this land, AmigaOS _only_ supported linking to libraries by offset. Each library came with a jump table (holding not only the address of the function, but also the JMP instruction to get to it), and those jump tables were carefully documented in the ROM Kernel Reference Manual (part 2: Libraries and Devices). Calling a library function involved opening the library to obtain the library base pointer, and then calling directly into the jump table. Compilers pretty much automated this process so it was invisible to C(++) programmers. It didn't just make linking faster, it eliminated the whole step to begin with. The only thing AmigaOS does when loading a library or executable is relocation, which only involves adding or subtracting a few offsets here and there. The astute reader may recognize that a jump table is in fact the same kind of thing as what we now call a V-table, and AmigaOS supported this kind of object-oriented programming at the OS level. In particular, "devices" (anything that does raw IO), "filesystems" (anything that does file IO), etc. all had standardized jump tables, fully decoupling the OS itself from the device driver implementation. So far our history lesson. Back in the day I speculated that the people at Microsoft just threw in _everything_ that was also present in other operating systems, just in case - thus ending up with the jump tables from AmigaOS as well as the name linking of Unix. That might be wrong though. 
&gt; Both of these look like they would have collision issues unless you keep track of already assigned IDs They have to anyway since runtime binding doesn't rely on the mangled name being an representation of the type (as much as I understand it, at least) - it just needs to be unique per DLL. Nowadays it wouldn't matter much, but yeah, link times would benefit, too. 
&gt; My main issue with ASIO is that requires handlers to be CopyConstructible, ... I used a workaround for this, by declaring the copy constructor/assignment but not implementing them. Never got linking errors, so I suppose ASIO called only move operations. I wonder if this would bite me later.
They are not, Linux only has an advisory file locking system as far as I know, you can still open the file like normally. You can delete the file while it's open, but it's only removed after it's been closed by all processes using it. In the meantime you can already make a new file with the same name.
`pacman -S mingw-w64-x86_64-clang` would've done the trick to get clang on MSYS2.
Yeah I know about that, but AFAIK it does not work for `strand::post` 
Any amount is better than my effort. I'm hoping to find the time to put it to use soon!
also think of haskell currying , which haskellers rave about.. if they do the extreme version it's only 4 characters off currying ..x=&gt;foo(a,b,c,x)
&gt; There is a reasonable fear that attributes will be used to create language dialects I don't understand this fear. This is how attributes are used in other languages: to make nice embedded DSLs. Why are people in the C++ commitee afraid of this ? It's not like creating eDSL is foreign to C++, but allowing attributes to "create language dialects" would certainly alleviate the verbosity of template-based DSLs...
not exactly the same but rust does sort of monadic code using option chaining, ```blah_blah.and_then(...)...``` ask for UFCS for this sort of thing to be easier in C++ (without having to put all the helpers into the underlying classes). (I want the =&gt; aswell)
Unity uses C# not C++. This subreddit also don't allow questions, help and advice. Walk step by step through your code and do the math. You should than realize why its wrong.
ah i do apologise
+1 from me.
*Valar Progarmis*!
Some people make a difference between "attributes" that the compiler should be able to ignore and still produce valid code, and "annotations" that would be the feature that would allow people to write DSLs. Sure, there isn't something akin to annotations in C++ yet, but the "it produces valid code anyway" is a nice guarantee to have when you encounter foreign attributes.
"Installation" can get complicated really quickly though. For you it's only copying, but still, he who installs does not really know what, from the build, they should copy. All test programs? Probably not. Then, imagine that your product needs to interact with the system on other ways. So you want your program to worrk with some database on the target environment. Installation could execute whatever scripts with the database, change configuration to point to it etc. Stuff like that. Installation of software packages in wildly different from building them :-).
The problem with that kind of chaining is that it's not possible to accumulate past outputs in your scope that way. And I guess it's also technically incorrect to call that a monadic chain, since you can't lift all functions from the language into the "monad".
how do you feel about the new syntax proposed for modules in P0584R0? There seems to be a requirement to distinguish between the interface and implementation part of a module so the proposal suggests to use module M [[interface]]; The proposal says "...the notation addresses that concern. The syntax is no less first-class than a use of keyword." I myself find it quite ugly so I hope it won't get accepted and export module M; wins. What do people think about it?
&gt; malloc per coroutine instanced The one to keep the state of the function in? How would you avoid it? Pool allocator? 
I feel that it would be a bit ironic to introduce standard attributes with real semantic value, which can't be ignored, while requiring that non-standard attributes can be safely ignored. It weakens the guarantee and probably encourage implementers to add attributes with meaningful semantics anyway, even though it's kind of forbidden. I would also be in favor of `export module M;` to preserve some kind of consistency.
Oh sure, you can override the allocator. I had been trying to persuade Gor to eliminate the need for allocation entirely. But his counter was that it's merely the default behaviour, if you really want to you can avoid it.
&gt; I had been trying to persuade Gor to eliminate the need for allocation entirely. OK, but how do you do that? From my limited understanding coroutines need memory to keep their state stored there while suspended.
I heard a lot of good stuff about PVS-Studio, but it isn't free for use.
Do you have single header generation working? I can't buy into quickcpplib, not yet at least.
I feel like the `[[fallthrough]]` attribute could be implemented so much better as a keyword, as an alternative to break: switch (c) { case '`': e(); break; // No warning. case 'a': f(); // Warning! fallthrough is perhaps a programmer error case 'b': g(); fallthrough; // Warning suppressed, fallthrough is ok case 'c': h(); // No warning. (Maybe pedantic warning?) } Implementing it as an attribute looks like a hack (which it is). I appreciate that some legacy code might be broken in some limited circumstances; but any impact would be extremely limited, especially since it serves only as a warning suppression.
You've literally just summed up exactly how C++ evolution is configured by the major players for their collective benefit. It is somewhat correlated with what is best for the language, ecosystem and C++ devs, but it is not at all identical. Let me posit a thought example. Imagine if half WG21 came along and said "we need a v2 C++ without that awful 'template' keyword, so in C++ 25 the keyword 'template' will be banned and all code using it must fail to compile". Now that would be a controversial position to take, it comes with big upgrade costs for all big C++ users. They would likely lobby against it, and hard. If WG21 went ahead and pushed the proposal through committee, it would land before the national vote. What would happen now? When have national representatives in the past voted down changes at WG21? When those changes were controversial, non-obvious, breaking, unnecessary ... etc etc. Which is all what you just said of course: "something that broke the world would be widely opposed". But the thing is Stephan, other languages don't behave like this. They *do* go ban things like the template keyword because it is an abomination and it needs to die for the future betterment of the ecosystem. Python did it with v3, that was a huge breaking change that spread huge conversion and upgrade costs on every big Python v2 user, and Python has a much larger standard library than C++, and four major implementations too which is more than the three major implementations in C++. Python also delivers by specification not implementation, and variation between the major implementations is much higher than in C++. Point is though, they still did it, they created the buy in in the userbase, they enforced the change, and the ecosystem invested the conversion costs over something like seven years and still counting. For the betterment of the ecosystem long term. A Python v2 to v3 type of breaking change is unthinkable in C++. It shouldn't be, there are lots of very feasible ways to eliminate the 'template' keyword from C++, I discussed a few with Bjarne and Gabi last CppCon (they disagreed with the idea, but had thought deeply on how to implement an incompatible C++ e.g. via namespace attributes). But it is still unthinkable, precisely due to all the reasons you just gave AND the reasons I gave. Two sides of the same coin. Different perspectives, that's all. 
Not yet, nor is the scripting for standalone-to-Boost conversion written yet. But as it won't take me more than half an hour to implement, I've logged that to https://github.com/ned14/outcome/issues/55. Watch that issue and I'll implement single standalone header generation very soon.
Oh, my idea was that the state should be preallocated by the compiler in static storage at compile time. But Gor scotched it.
Am I correct in assuming that this was born of the twin notions that introducing new keywords is dangerous, and that 'export import' is ugly? The one with the attribute has considerable disadvantages: - It's ugly. And this is not just a minor disadvantage, as I'll explain in a moment. - It changes the nature of attributes from "additional information" to "vital information". It's hard to extend C++: any word the committee might want to use is undoubtedly already in use, somewhere, and 'standardizing' it will therefore break someones application. The only way out seems to be keywords that were not legal keywords before: anything that starts with __, and attributes. So clearly there is very great pressure to ensure that any new keyword either starts with two underscores, or is enclosed in double square brackets. Of course, there is a major downside to this: once we discover a 'free' way to add keywords, albeit ugly ones, there's nothing stopping anyone from adding as many as we like. [[But]] __if __we [[allow]] __this, [[__future]] [[code]] __will __[[suck]]. This is not, I think, a road we should travel. Personally I find the notion of context-sensitive keywords (such as 'final' and 'override') to be the most attractive. It doesn't introduce name clashes, and it allows the use of normal English words instead of gobbledy gook to convey meaning. In this case, 'interface' could be a context-sensitive keyword that only has validity after 'module'. If that's not possible, my next choice would actually be to standardize existing words, and in doing so risk introducing incompatibility with existing source. Perhaps we need a mechanism that source can use to indicate its readiness to deal with such new keywords - something like prefixing new keywords with 'std::', and allowing 'using std::keyword' to bring them into the global namespace. 'std::keyword' is still ugly but at least you can escape from that, and in a well-defined, standard way at that. Only after that would I consider a future where new keywords are written in [[this]] __form. And of course there's always this: https://www.reddit.com/r/cpp/comments/62s9wc/a_modest_proposal_for_future_expansion_of_c/ 
I think the issue with cbegin and cend is that there's no way in general to get a const iterator from an iterator, so if you absolutely need a const iterator, you need some sort of standard way to get one. As you've shown in your post, there is already a way to get a move iterator from an iterator, so this would just sort of be extra cruft in the standard.
There has already been a proposal for soft keywords in 2015, keywords that lived in `std::`, but it was rejected IIRC: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0056r0.html
&gt; something like prefixing new keywords with 'std::', and allowing 'using std::keyword' to bring them into the global namespace I think the committee already rejects this idea. Anyway I don't want some 'using std::keyword' at some random place to turn my normal declaration into something magic.
Attributes make more sense in the presence of metadata, so they actually persist in the binary and you can query them at runtime. As it stands, they all look like compiler hints replacing various `pragma` directives.
`fallthrough;` looks too much like a normal statement (especially since `fallthrough` is not highlighted). I think it's a good thing to make it stand out a bit.
I think range-v3 kinda covered and simplified the use case: your_range | range::view::move; 
hmmm, i found this [page](https://ned14.github.io/outcome/tutorial/) to be pretty unhelpful. Is there any example usage code there? Edit: also, doesn't this overlap optional? Are there ideas to deprecate optional?
Edit: Actually Andrezj has placed a usage example on the front page at https://ned14.github.io/outcome/. That's actually pretty much all you need to know. Sadly not yet. The tutorial for v1 was based on Expected, and so has to be completely rewritten. But the v2 objects work much the same as the v1 objects, it's running the v1 test suite ported to v2 for example. You may find https://github.com/ned14/outcome/blob/master/doc/md/04-tutorialC.md of use though, the code examples should still mostly compile. Just replace any `make_*()` functions with `in_place_type&lt;...&gt;`.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [ned14/outcome/.../**04-tutorialC.md** (master → 1369c66)](https://github.com/ned14/outcome/blob/1369c66da865016b94f70f3f58e107b3b38d4a85/doc/md/04-tutorialC.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dk105xt.)^.
Regarding optional, no the Expected/Result/Outcome types all complement optional, they don't replace it. Optional will be around for the foreseeable future.
You see a grand conspiracy where there is none. Of course the major players want a great deal of stability for the source code they've spent billions and decades developing. Well, guess what? So do the small players, even if they have no voice! This is not scripting land, where a hundred line program counts as huge, and where just rewriting it is an option if you have a few spare moments. Even smaller shops have huge investments in code and want to see that protected. As for how well those huge breaking changes are working out for Python, not everyone is convinced yet: https://learnpythonthehardway.org/book/nopython3.html 
Agreed. So why it's mixed in with the build configuration is a mystery to me. Seems like it should use a separate tool
`move_iterator`s are weird and icky. Let's not make them even easier to (mis)use. 
&gt; But it clearly needs another library, building up on beast to provide client and server primitives to the end user. That library could be called **cage** ;) That got a good chuckle from me.
I believe it would complicate the grammar *a lot*. With `auto`, the grammar is still roughly the same, with `auto` used as a "type" (in place of the actual type like `int`). The fact that `auto` is a "magical type" is ignored by the parser and just acted upon later by the compiler.
But there is a general way to get a const_iterator from an iterator, it's just a static_cast! This is a requirement for containers https://stackoverflow.com/questions/7759246/c-iterator-to-const-iterator/7759474#7759474 Maybe you meant that std::make_const_iterator(it) (where it is a non-const iterator) is unimplementable? If yes then I agree, but I'm just making a case for std::mbegin.
Consider `[](const T){}`. Currently, this is a lambda taking an unnamed parameter of type `const T`. You're suggesting that this becomes a generic lambda taking a parameter named `T` deduced as `const`.
Upon seeing this thread title and before reading your description, I intuitively thought the 'm' prefix would stand for "mutable" rather than "move" because of the existing 'c' prefix for const iterators.
What did you mean by &gt; * Stuff removed &gt; Anything even faintly smelling of monads 
libFuzzer runs all the tests within a single process, while AFL spawns a new one each time. This makes libFuzzer much faster, but makes it a bit more limited since you can't test things which may modify global state or exit the process. Other than that difference they're pretty comparable.
This was a really nice project and I learned more about fuzzing. And Beast got a bug fixed!
It would be cool to have an example of how one of those functions actually worked, too. For example, `parse` to keep things short and simple.
I suspect that page will change soon, because [Learn Python **3** the Hard Way](https://www.amazon.com/gp/product/0134692888/) was recently published (july 7 2017).
http://boost.2283326.n4.nabble.com/outcome-user-s-experience-td4694755.html is pretty close, specifically https://github.com/akrzemi1/__sandbox__/blob/master/outcome_practical_example.md
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [akrzemi1/__sandbox__/.../**outcome_practical_example.md** (master → 505c6d8)](https://github.com/akrzemi1/__sandbox__/blob/505c6d81af99cc629caf0d8f5ee47aa2cd2d7eab/outcome_practical_example.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dk1ghiz.)^.
Outcome v1 had a monadic programming API. That's been removed. Monadic smelling member functions like .error_or(E) are also removed. Operators like | and &amp; for composing monadic logic are removed. Nothing monad influenced nor related remains, that's all in P0650 now.
Oh, this is great. Thanks!
There is no grand conspiracy. Just the aggregation of incentives upon individual actions and behaviours and beliefs. Some who have been on WG21 since the beginning would recognise instantly my analysis, even though they'd probably think it a little overwraught (it is, for clarity). I think you underestimate "scripting". Python is just as deep a well of complexity and corner cases as C++. Have a look at Zope, they've been around since Python 1.x days and they've seen lots of work forced on them when each Python 2.minor revision would completely break their very mature codebase. It took them a ton of effort to adopt Python 3 especially. Yet they did it, they could see it was the future. That link you posted was exactly proof of what I was saying. The first complaint is that Python 3 primarily benefits Python the language, not Python developers. Absolutely right. Same should be possible and practical for C++: really breaking change where old code will not and can never compile. So much could be fixed in C++ if we could do that sort of transition e.g. bye bye `template`, default move semantics except for POD types (to keep C compatibility), language built in DMA friendly default over alignment of storage. So much stuff.
theres some limitations they have from a lack of HKT, but we have template-template parameters so there might be a middle ground where we can take it a little further
&gt; Oh, my idea was that the state should be preallocated by the compiler in static storage at compile time. That is quite clever... But IDK how much it would help without somebody implementing it and doing benchmarks. 
My concern was that there is a big potential use case for fire and forget coroutines, so specifically I was thinking of ASIO or AFIO completion handlers where you might instance a new coroutine per i/o scheduled. A malloc per coroutine is therefore very expensive. But the problem with the static storage is that damn annoying halting problem: you can't always calculate statically how much state a coroutine may need.
&gt; This but is related to handling "obs-fold" in http fields This doesn't surprise me at all. This a notoriously nasty part of the grammar that makes writing an absolutely *pure* streaming HTTP/1.1 parser (one that doesn't require backtracking or buffering) impossible. Basically the problem is that one might expect any arbitrary sequences of whitespace between e.g. "foo" and "bar" in a a header line like X-SomeHeader: foo \t bar to be preserved, but you have to buffer all that whitespace until you hit "bar", because the RFC also says that all leading and trailing whitespace in the header field value part should be trimmed. This is true even if "bar" is replaced by a line break sequence, because leading whitespace on the following line (an "obs-fold") should be treated like a continuation and the CRLF ignored. Here is a commit that highlights the misfortune in Node.js's HTTP parser: https://github.com/nodejs/http-parser/commit/5d9c3821729b194eef60f41fcc5f8b4657c3d8ff Relevant quote: &gt; For http-parser itself to confirm exactly would involve significant changes in order to synthesize replacement SP octets. On a related note, it's great see Vinnie [posting issues](https://github.com/nodejs/http-parser/issues?utf8=%E2%9C%93&amp;q=is%3Aissue%20author%3Avinniefalco%20) against Node.js's http-parser project. I think all of this really shows that parsers should always be generated directly from a declarative form of the grammar unless performance really really matters. 
We're in 2017 and this guy is in 1997. 
Would you like to try doing just pure simulation and some minimalist UI? You could ditch the graphics and go for ASCII. That is a Very good way to get your feet wet and also have something working pretty fast. Adding better UI can be done later when you already found the fun in your game. I think neither SDL or SFML have any of the "widgets" that Football Manager has in it's interface. Stuff like dropdowns, lists, etc. You would probably have to build these or find some lib to do so. If you want libraries that offer those kinds of "widgets" you might like to check QT or your native form library. One could say that SFML has a more "modern" style than SDL but the later is in in no way inferior. It all depends on your requirements. In the end it boils down to what kind of code you want to write, and what kind of problems do you want to tackle.
https://github.com/ocornut/imgui This might also be a good option. 
Could `continue` be re-purposed instead? It pairs well with `break`. I guess it would still break stuff.
A good idea, but unfortunately it couldn't work because there are valid uses of `continue` inside a switch statement. Poorly coded example: int i = 0; while (i &lt; 10) { int res = try_thing(i); switch (res) { case 0: std::cout &lt;&lt; "Success!\n"; break; case 2: std::cout &lt;&lt; "Retrying " &lt;&lt; i &lt;&lt; "\n"; continue; case 1: std::cout &lt;&lt; "Failure!\n"; break; } ++i; } In `case 2`, the compiler is unable to distinguish between `continue` as a fallthrough keyword, or `continue` as a keyword to continue the loop.
https://www.reddit.com/r/cpp/comments/35pya1/abbreviation_for_const_auto/?st=j4yuav3w&amp;sh=d4c35122 https://www.reddit.com/r/cpp/comments/69jlm7/const_by_default/?st=j4yuam5j&amp;sh=fd6b77d2
because ISO did a bad job... they should have picked var and const, but they either did not think of this and/or they have this insane fear of new keywords. It is quite pathetic actually that users that are too incompetent to rename their variables get a consideration from ISO, but...
wait, what, i thought views are not for mutating? in other words i would expect range::action::move
Your argument doesn't hold. Using const would result to an extremely ambiguous grammar.
Yeah I did a ninja edit once I thought about it a bit more and how it would be undetectable. I don't like the look of the fallthrough attribute though, it just looks nasty and better addressed with a keyword. Maybe `continue case;` or `continue switch;` or even something added to a `case:` itself like `case 2 continue:` or `continue case 1:`. Anyway it is only a minor concern and don't even remember the last time I needed to fallthrough on a case. I am sure people much smarter than me who have much more intimate knowledge on c++ than me have thought about all this before and came up with attributes as the solution.
Single header edition can now be found at https://github.com/ned14/outcome/tree/develop/single-header/outcome.hpp
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [ned14/outcome/.../**outcome.hpp** (develop → 44d2fe7)](https://github.com/ned14/outcome/tree/44d2fe7f32b5b13e4ccba8558b59bc94523bf529/single-header/outcome.hpp) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dk1whgt.)^.
&gt;I think all of this really shows that parsers should always be generated directly from a declarative form of the grammar unless performance really really matters. And if performance really matters, maybe we should be optimizing our generators to produce efficient code.
because auto using the rules for template argument deduction from a function call
&gt; Monadic smelling member functions like .error_or(E) are also removed. There goes literally 100% of the reason I had for using the library and/or following its development. ;-] Does v2 keep this functionality available but hidden as v1 did (or was intended to)?
Actions are eager. Views are lazy.
That also exists, but is the [`std::move` _algorithm_](http://en.cppreference.com/w/cpp/algorithm/move), as opposed to the [`std::move_iterator` iterator adapter](http://en.cppreference.com/w/cpp/iterator/move_iterator) (which in turn applies the 'usual' [`std::move`](http://en.cppreference.com/w/cpp/utility/move) to each yielded element).
First of all, make sure you distinguish between counting, ie the size of a collection, and indexing, the position of an item in a collection. Internally a collection with one item should always be size 1 and its index 0. Sometimes an index might be shown on the user interface. For users this item is naturally the first item and should be displayed as #1. Make this conversion as close to the user interface as possible, preferably in such a way that the 1 based index is never assigned to a variable, but for instance in the same statement converted to string. You should do the same for measurements. Internally always use SI units (for instance meters) if the UI is in inches or kilometers, convert at the last possible opportunity.
You can wrap your units in different classes so that there is no way to accidently intermix them
The other interesting use of ```=&gt;``` is in Rust's amazing match statement, I wonder if the two would be compatible or not ( I note that =&gt; has some special status in rusts' macro parser, i.e. there a places where it can read that as a separator where other features wont fit) match is one of the things I would also seriously like C++ to copy eventually (including the fact that it's an expression); but if I could only take *one* for all time, it would be the compact lambda, without a doubt.
write a RAII wrapper once and your problem is solved forever?
Actually, I use it like that also with strands: strand-&gt;post([data = std::move(data)]() { doSomething(std::move(data)); }); 
There's a library called sfgui you can use with sfml that provides various widgets. It's not perfect, but i haven't abandoned using it yet for my latest hobby project.
what does renaming have to do with anything?
Boost peer review was not keen on the monadic stuff. To get accepted it would have to be removed in any case. I've left open a door, v2 Outcome is designed to be subclassed easily, much more easily than v1, with additional localised behaviours. But it is what it is I am afraid, this is how peer review works.
The syntax is confusing me: When do we put [[xxx]] before the method/variable and when do we put it after?
So this now supposed to complement std::expected rather than replace it? Mind expanding a little on that?
I think there are some pattern match proposals for C++ as well. I'd like it if they didn't use the same syntax though, it could be confusing for the human reader (even if it's parseable).
A new version of the standard shouldn't (lightly) break existing code. Python did that and there are *still* (almost 10 years later) a significant number of codebases using Python 2.
Just nitpicking, but kilometers *are* SI units. I disagree that you should always use SI (or worse, unprefixed SI units) internally. You should use the units customarily used in the field, since these will usually be conveniently sized and/or have useful relationships (e.g. in physics where you might use natural units in which certain constants are equal to unity), and converting to SI may introduce inaccuracy.
How would we know? Hopefully it will be discussed this week at Toronto (the committee is gathered this week there) so you will have some feedback soon.
RAII wrapper for a thing that I use only once? Besides, that's by far not the only example.
A must read reference.
I'm not sure what else to add other than the initial description. Expected has variant storage, Outcome/Result has struct storage. They are thus complementary, and Outcome/Result is the much lower load on compiler through its bare minimum simplicity.
Agreed. As always the biggest debate will be over naming. The concepts are well accepted.
better also include the compilers support status
Concur with /u/Velglarn that you understand the difference between indexing and counting. The diagrams from this unexpected source (found through a Google image search) should help you understand: - https://www.biostars.org/p/84686/ - https://postimg.org/image/stn8jkxkl/ Indices are sort of "in between" the objects. Some practice with Python splicing should help: https://repl.it/JW41
This is basically how futures are implemented in Rust, as a zero-cost abstraction. For this approach to work in C++ one needs 1) a `Future` concept, 2) concrete zero-cost future types (i.e. no type-erasure, allocations, ...) that model the `Future` concept, 3) a way to manually type-erase futures if you need to (e.g. `std::any_future&lt;T&gt;`) [*]. This would mean that as long as `boost::future`, `hpx::future`, and `std::future` all model `Future`, asynchronous libraries would be able to interoperate (at least to some point). I really cannot understand why `std::future&lt;T&gt;` is not a concept. Everybody talks great about generic programming, how important it is to know the C++ STL, raves about how insightful reading Elements of Programming was, has watched all the Stepanovs A9 lectures... And then when they design their own libraries for standardization just bite their tongues and throw it all away. Like that Google executors proposal that made executors a pure virtual base class... Some people stood up for this madness, but nobody stood up for futures. [*] Rust doesn't need this because they can just use a pointer to a concept for type-erasure: `Concept*`.
I agree comletely. Is there any reason to use type erasure here, other than avoiding the 20 levels deep nested template instantiation?
- In an API if you don't want to expose the details of where the future comes from, but just say, this is a `std::any_future&lt;T&gt;`. - When the callback of a future is a closure, either you remain generic or you just cannot name the type. - In a stream (e.g. `std::vector&lt;std::any_future&lt;T&gt;&gt;`), a task queue (e.g. std::queue&lt;std::any_future&lt;void&gt;&gt;`), ... Type-erasure for futures is not really different of type-erasure for other types. Sometimes you need it, and in those cases you are happy that you can pay extra for it. But having to pay for it when you don't need is not how C++ features are supposed to be designed. We have learned over and over again that type-erasure should be opt-in, yet people still write proposals that add new types to std with non-optional type-erasure. When somebody cannot use their type because of type-erasure, it is as if nobody saw that coming ("oh jeez! somebody combined C for loops with feature X, and then type-erasure became too expensive because it inhibited Y optimizations, who could have foreseen that!"). The std committee should have a check list for new papers, and the papers should be rejected it if they do not check all the boxes. After the whole formalia there should be a box that says "This paper does not _sneak_ type-erasure into the standard library in any way". If this box cannot be checked, the paper should be rejected, so that a paper that proposes `std::any_future&lt;T&gt;` and is explicit about it introducing type erasure can be accepted, but a type proposing `std::future&lt;T&gt;` that skims over the fact that it does type-erasure cannot be accepted.
this would needlessly duplicate http://en.cppreference.com/w/cpp/compiler_support
Thank you so much...I really needed this. I am well versed with the old C++ - "C with Classes C++" and haven't had a comprehensive knowledge of the modern C++. This resource will be really helpful ! 
You'd think, right?
it might be a bit much, although it still sort of fits IMO.. "symbol maps onto this expression using the symbol" vs "this pattern maps onto this expression". I'd be ok with it, but I can see why people might object (i think the parsing might be ok, because the outer block would introduce the context? you might just need braces or semicolons to split the arms) Haskell does have -&gt; for functions and -&gt; for pattern matches (although arguably the lambda syntax is more deliberate with \t-&gt; ... )
I do not get why: std::vector&lt;int&gt; results = f1(1) &gt;&gt;= [=](int b) { return f1(2) &gt;&gt;= [=](int c) { return f2(b, c) &gt;&gt;= [=](int d) { return f3(d); };};}; and not std::vector&lt;int&gt; results = f1(1) &gt;&gt;= [=](int b) { return f1(2) &gt;&gt;= [=](int c) { return f2(b, c); }; } &gt;&gt;= f3; Ie, nested lambdas are needed to handle 2 parameter cases (and a cross product of arguments), but not one parameter cases.
what is wrong with using std::as_const() ? e.g. std::vector&lt;int&gt; vec = /* ... */; for(auto &amp;x: std::as_const(vec)) { std::cout &lt;&lt; x &lt;&lt; '\n'; x++; // compiler error }
I have a feeling partial linearization is coming next time.
Baby steps, though. You need to build a compiler before you can build an optimizer for that compiler. And often enough, certain optimizations are architecture specific.
Interesting, thanks for your link. I wasn't aware it was already proposed and rejected. I cannot find any reason for the rejection; do you recall what that might have been? 
One actual problem of ASIO is its incomplete and beginner-unfriendly documentation and APIs. How is composition supposed to work? How to write custom asynchronous objects and adaptors? How can you do wait_all or wait_any in a coroutine? How to avoid unnecessary copies of buffers? How can you test your code? 
Not really. I guess that they simply didn't like the idea of having different semantics depending on the context. I can't find the response to the proposal.
Order of evaluation. You'd need parens around `(f1(1) &gt;&gt;= [=](int b){ return ...;}) &gt;&gt;= f3`
Second bullet sometimes has something to do with corporations. The latest example: IBM resisting to remove trigraphs.
I'm not an expert but this really seems like a hack to me. std::set is never meant for key-value mapping and the comparator is only supposed to compare values of the same type. Even using a dumb value seems to be a better solution. 
C++ v2 already exists and it is called Rust.
I would prefer separate libraries for separate issues: Boost.Uri, Boost.Web, ..
Something like this, IMO, should wait until concepts are finalized and baked into the language. Being able to write higher level functions like template &lt;Monad m&gt; auto sequence( /* ... */ ) { /* ... */ } would be awesome.
I completely agree. There's no real starting point for someone unfamiliar with asynchronous programming, and little help beyond following a few examples. For something so large and which introduces unfamiliar concepts to many people, it makes ASIO very daunting and difficult to get right. 
Ha! As someone who has written in Rust before, you are a long way off.
N.b. that would need to be strand-&gt;post([data = std::move(data)]() mutable { doSomething(std::move(data)); }); if you want that second `std::move` call to actually move anything. :-]
I think this is the most pragmatic solution. imGUI is so easy and inuitive to use and works wonderfully with Cinder You can write the whole application and the just inject the GUI stuff where u need it later. No frameworks and call back and all that messyness
Argument for co_yield was that incompetent clowns in the finance and farming industry have a lot of variables named yield. I am not f joking, this was one of the reasons. 
This is a problem without being a problem most of the time. My types are not named a/b/in/out/lhs/rhs... compiler could error on ambiguity(for example people naming input argument string is realistic problem). 
And always always *always* document the units. Not by including them in the name (this is bad if the units might ever change or if they are not part of the abstraction), but absolutly by including them in a comment in the single place in your source where you declare the variable. ( you can tell I've been burned *bad* by undocumented and inconsistant units ... ) 
Yes, it is clearly a sign of incompetence to do things like name variables after what they actually represent. Clowns, indeed. What is wrong with you?
Nobody is forcing them to upgrade to C++17, if they are incompetent to rename yield to yi3ld they should stick to their C++14 compilers. If they are incompetent so much that they can not refactor their code I doubt they will use any of C++17 features.
"... not sure why to use pointer..." What do you mean by that?
Author of the article here. I completely agree with you from an idealistic point of view. Realistically speaking, there are some shortcomings in C++ that probably steered the committee towards a type-erased future. Firstly, familiarity: `std::future` was inspired by `boost::future` which was reviewed by C++ experts and successfully used in multiple domains. Another major issue is compilation time - I don't have any real benchmark but I imagine that without type-erasure and with deeply nested continuations compilation times might suffer greatly. --- &gt; I really cannot understand why `std::future&lt;T&gt;` is not a concept. I suppose that there was no advantage in doing that or no proposal for it. The Standard Library doesn't provide any "generic" functions that can act on a "future-like" object. The lack of UFCS prevents continuations such as `.then` to be defined in a generic manner for any object satisfying an hypothetical `Future` concept. --- &gt; Rust doesn't need this because they can just use a pointer to a concept for type-erasure Yes - I really like that about Rust. Unfortunately we don't have anything similar, so we would have to write `std::future_ref&lt;T&gt;`, `std::unique_future&lt;T&gt;`, and `std::shared_future&lt;T&gt;` manually. Then, again due to the lack of UFCS, we would have to provide a `.then` implementation for all of them. It just (currently) isn't practical to do this in C++. --- I think that the sad reality is that the language isn't yet powerful enough to support a `Future` concept with opt-in type-erasure which is fast, easy-to-use, doesn't have awkward syntax, and doesn't blow up compilation times.
Hopefully 0%
Nice, but shame the example code isn't clean, modern C++, that they can show vectorises to AVX-512 code by the compiler ;-)
&gt; but I still don't understand why is this part of the build system. make is not a build system; it's a tool for executing a dependency graph of commands. You can arrange it so that the dependency graph and commands carry out a build: You ask it for the installer program; make sees that the installer program doesn't exist, and creating it depends on an executable and documentation. Make sees those don't exist, and creating the executable uses another command that depends on source files. The source files do exist so it runs the command to create the executable. Then it sees that the documentation depends on some other source and a different command, so it runs that command. Now the dependencies for the installer program exist so it runs the command to create the installer. You can also arrange it to carry out any other series of commands that depend on each other. And given any such dependency graph, why would you split the graph up between different programs?
In the abstract, `make install` is doing exactly the same sort of thing you're familiar with from Windows-style installers. The difference is simply that by default it's doing that thing directly from the build output directory rather than from an intermediate file. All a Windows-style installer is is such an intermediate package that wraps up the necessary build products and carries out the install steps as defined by project definition. The project defines the particular steps that constitute installing that project. The defaults for make/CMake are geared toward the conventions used on *nix. You don't have to depend on the defaults. If you want installation of your project on Linux to mean creating a new directory `/C/Programs\ (x86)/YourProgram` for the executable and creating a desktop shortcut to the program then you can have `make install` do that. There are tools that can work with a make-style definition of installation to create Windows-style installers. CMake, and specifically CPack, can take the installation steps defined for a project and produce Windows-style installers that carry out those steps, as well as creating other sorts of packages for distribution. The project's definition of the installation is used for all kinds of packaging. --- make-style installation originated in the days when software in the nascent open-source community was distributed as source. End users obtained the software by building and installing directly from source, even if they had no intention of modifying the software. Separate installer programs were unnecessary. &gt; On a Linux system is it just copying what you build to some system default locations? Usually, though it's possible that installation can involve running arbitrary commands to take care of anything else the software might need. &gt; Does the workflow expect me to run "make install" as root each time? Does "installing" lose it's meaning on Windows? You can run the install with a custom prefix so that the software is installed somewhere that you have rights to. You generally shouldn't run make install with root privileges. &gt; Does "installing" lose it's meaning on Windows? No. Software definitely gets installed on Windows.
AVX 512 is great, but can they add a few x86 intrinsics? For example, JO and JC - will help a lot in catching integer overflows. For a long time, the ADC instruction didn't have any intrinsic, till Intel came out with the ADX extension. And even now, doing ADC in a loop will result in bad codegen. I couldn't get the compiler to generate a JRCXZ instruction.
I agree with all the points in the article. The problem with `(std|boost)::future.then` is that it requires some synchronization, it has to decide if by the time we call `.then` the future is ready or not. But most of the times we know before hand the entire execution graph, and I should be able to construct it first and *then* launch it. Someone posted in this sub an interesting [continuable](https://github.com/Naios/continuable) library, which as far as I can see follows the same ideas of the article. I think `future::then` will still be needed in the cases where one needs to build part of the execution graph as its being executed, but for everything else a 'continuable' approach is superior.
I didnt want to go in too much detail(on my phone), but in general floating point is used for measurements, in which case clarity and avoiding bugs is more important. Let the exponent handle the multipliers. It was an example of a similar best practice anyway. Sorry if it caused confusion instead.
Also ChaiScript.
Those results look way too good to be trustworthy. 
I just want SSE4.2 intrinics that return the mask or index value and tell you if a zero byte was encountered all in one.
I would also like to have 128-bit (and 256 and 512-bit, for that matter) integer support, similar to what gcc and clang offer on modern architectures (`__int128_t`). Oh, and `constexpr` versions for all the bit-twiddling intrinsic functions.
&gt; I'm not 100% sure why to use pointers As opposed to references? The reason is that SDL is a C library, so it can't use references. SDL shines best as a platform-abstraction library, use it to create an OpenGL context, open a window, get device input, etc. The graphics routines in it are good for prototyping or debug drawing, but it doesn't take much work to do much better. I've always had problems with SFML keyboard events, it mistranslates some keys on Macs and others have reported problems with international keyboard layouts. It's graphics features work fine, though and are more sophisticated than SDL's (i.e. has a shader management system and supports transformation hierarchies). You might also want to look at Raylib: https://raylib.handmade.network/ It's a really thorough game programming lib written in C with copious documentation and examples.
I think you misinterpreted what this is.
They are not all `noexcept(false)`. The defaulted copy and move ctors get an implicitly computed exception specification.
Go to /r/cpp_questions for questions...
[removed]
Was a strong motivation for me too, learning beast and fuzzing in one effort. win-win.
I tried in the past to generate Xcode projects that generate app bundles correctly in CMake, but I didn't grok how these bundle functions were intended to be used, and what `install` was used for outside of unix-y package management. Are bundle utilities for install, and is the idea that you set an install prefix to something like "packages/${platform}/${configuration}/${exename}" and it will dump out .app files on Mac and folders you can drop in C:\Program Files on Windows?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Ok, fair point. But do you see what I mean about `make_tuple(...)` et al?
Your language might be awesome, but there were only so many times I was willing to follow links without seeing any code before I giving up.
Implementations are permitted but not required to strengthen noexcept specifications, so the absence of noexcept in the Standard is different from the absence of noexcept in actual code. Nothing happens without an LWG issue or paper. The STL's specification is gradually being updated in light of our modern understanding of how important constructor constraints are. noexcept is less important, although given the type traits, we should probably be consistent about it (for move constructors it is the most important, due to vector's horrible guarantee). The usual answer to "why is X missing" is "nobody has done the work yet".
Hi, in case you see this reply, I installed the latest VS2017 update the other day and suddenly realised this morning why work is going more smoothly -- the find/replace bug has vanished. At the same time, for a few years (since one of the 2013 updates I think) there's been the irritating issue that selecting a block of text and then pressing CTRL-F has not defaulted to replace in selection -- that's also now fixed and acting as we'd expect. So whatever you fixed in the most recent update, thanks!
Interesting, thank you. My GSoC student ran into this you see, he's using std::tuple inside his constexpr-only Ranges TS implementation and it was not behaving as he had expected due to the traits returning potentially throwing construction. I also remember Louis saying that std::tuple has some weirdnesses which required Hana to implement its own tuple locally.
noexcept spec is also undesirable on inlined functions
Can you also upload the graphs in log scale? People are interested in knowing what performs the best and nobody cares for the bubble sort
I found it as part of the Urho3D game engine so here's a deep link to some of that code. [Script Code Directory](https://github.com/urho3d/Urho3D/tree/ea783ae69fb955c40c19de93a0069e88f41a8dd6/bin/Data/Scripts) [C++ Bindings directory](https://github.com/urho3d/Urho3D/tree/ea783ae69fb955c40c19de93a0069e88f41a8dd6/Source/Urho3D/AngelScript) [Angelscript Source Code as integrated](https://github.com/urho3d/Urho3D/tree/ea783ae69fb955c40c19de93a0069e88f41a8dd6/Source/ThirdParty/AngelScript/source) [The complete source is zipped up here.](http://www.angelcode.com/angelscript/downloads.html)
Nice library, really like the way it handles native calling. Worth a browse through the code just for that.
If you can't understand that the process of renaming, especially within a *huge* codebase, costs real money, then I would say you are the incompetent one. WG21 looking to not clash with real world code in such ways helps adoption, and is a sign that they know what they are doing. It's also, by the way, why we have unordered_map and not hash_map, because lots of third party and home-grown code already used that name.
out of interest, what is the sizeof the type that generated the error at the end?
Because?
Waiting for concepts would have frozen C++ for 9 years at this point. No thanks.
You can add `#define yield co_yield` and not be bothered by it... You can write an IDE that displays `co_yield` as `yield`, `yeild` as `y3ild` and generates errors if anything is called `y3ild`. There are many solutions to your allergy to `co_`. Reactine also.
Nice but as always you are quite late to the party. GCC supports it since over 3 years.
There really isn't a common best practice like with that maven stuff in Java. If you stick to common stuff in linux distro package managers grabbing dependencies is a one line shell script. Maybe also a couple additional lines to do a git pull from some other online repos (github, what-have-you). If you're on windows the best you can probably do is have separate repo where all the dependencies are staged. Maintain that periodically. There's no standard way of tagging versions for C/C++ stuff or specifying inter-dependencies or posting a package. So it's pretty much impossible to make some magical generic tool for updating dependencies.
The assembler version is actually way cleaner and easier to read than the C version.
What does "crescent sorted" mean? Edit: ok, from context "crescent sorted" means sorted smallest-to-largest, "decrescent sorted" is sorted largest-to-smallest? 
&gt; "decrescent sorted" is sorted largest-to-smallest? Yes, I'm Brazilian, isn't there a better sentence to describe this type of data?
I'm new to plotting so, what is the benefits of using a logarithmic scale? You said: &gt; People are interested in knowing what performs the best Using a log scale is better for that? From Wikipedia: &gt; A logarithmic scale is a scale of measurement that uses the logarithm of a physical quantity instead of the quantity itself. So what I need to do is use log in the Y axis for my graps?
Open source. gcc and LLVM are developed by paid engineers from a number of large companies (Red Hat, Apple, IBM, Oracle, SUSE, Intel, etc.) in addition to a long tail of volunteers. MSVC is just Microsoft (and indirectly, Dinkumware, but I think that's only really a couple of people.) 
[log-scale plot](http://i.imgur.com/qfMUZRg.png) When the scales of each graph differ by a large amount, it makes easier to compare each other. Yes, you just need to log(x).
if somebody owns 10MLOC and does not care enough to maintain them with complicated tools like rename to quote Linus "nVidia you", you can keep using gcc 2.95, just dont hold back people with brains on your level.
 * smallest -&gt; largest : ascending(increasing) order * largest -&gt; smallest : descending(decreasing) order But I like "smallest -&gt; largest" and "largest -&gt; smallest" better because it's more explicit. 
Ohhhh now I understand, thank you! I'll implement this type of graphs in the python script. I've never used a log scale, I appreciate your time to help me.
Hello frenzy, great to hear things are working better for you! :) If you experience any further issues please let us know.
I'll use "smallest -&gt; largest numbers arrays" in the graph titles, thanks.
Language or library features? On the library front, MSVC implements and releases new features at about the same rate as GCC and Clang. On the language front, MSVC does lag behind. Allegedly, the code base is really old, and has only started getting "refreshed" in earnest in the past few years (post C++11). That results in features coming out slower than in GCC and Clang.
What's your deployment target? Where do you intend the software to run?
Well, yeah, but being a monad is a concept that types adhere to, with associativity laws and operators and all that. It fits in so naturally with what concepts are posed to be. I'd hate to see a shim put in for now, only to have it be deprecated later when the machinery for doing it properly finally exists in the language.
Top 3 (in the world) not fast enough for you? Why would you think MSVC would always be 1 or 2? 
I use the very latest compilers and libraries precisely because of considerations such as the ones we are discussing.
The top 3 in no order are Intel Compiler (is better than VC), Clang and GCC but there are more compilers out there, AMD or Apple has one too, even Oracle has one so at least VC is 4 of ¿7?¿8? Being a very rich company it doesnt say anything good
You have to decide what you want to do, i suggest a video game based on text/console like classic board games Or doing katas of code
I'm just askin', man. I didn't realize the power behind the other compilers - I thought they were purely open source folks in their spare time versus the power of Microsoft and was confused.
That makes more sense - I didn't realize the scale of the work behind gcc and LLVM - I had naively thought that they were worked on purely in peoples' spare time.
can you wrap smart pointers?
I work for Intel and would have a HUGE problem with someone claiming that ICC has better standards adoption than MSVC, particularly lately. AMD's compiler is clang+optimizations, Apple is simply Clang + a few extensions. Code generated performance, ICC is WAY better than the others, but language compliance is not something it is known for.
because if compiler can prove that you don't throw -- it gives you nothing (unless somewhere else some is using _noexcept-expression_ on your func) , and if it can't prove (for whatever reason) -- you lose on performance due to unnecessary (semantic equivalent of) "try{ ...your function body... } catch(...) { std::terminate(); }" Edit: *near* semantic equivalent (no stack unwinding)
Open source and "hobby" are very different things.
Beginner questions are off-topic here; try /r/cpp_questions as the sidebar advises.
Yepp, I can see that now. It's obvious but I just didn't think of it :)
I have started using buckaroo for dependencies and buck to build, it isn't too bad but not polished enough like pip.
A few interviews from CppCast talked with people from the Microsoft compiler team and from what I gather they are mostly steered by what their corporate clients want most, which (apparently) is not 100% conformance. However I'm no Microsoft employee, so I could have totally misinterpreted the interviews... Oh, they also have the challenge of having various parsers that they have to keep in sync (IntelliSense vs compiler) and their compiler still mostly is stream based (again, from what I gathered, feel free to correct me).
I wrote a blog post that rolls up [C++ standards conformance progress in MSVC](https://blogs.msdn.microsoft.com/vcblog/2017/03/07/c-standards-conformance-from-microsoft/) when I was at the last C++ standards committee meeting. Rather than rehash it all here, please look at that post. The first major section pretty much addresses your question. For the lazy: It's only recently that compiler vendors cared about getting conforming compilers before the ink was dry on the standard. It took years for anyone to implement C++11 correctly, and that latency has been dropping quickly. Now everyone else is standards-conforming before us. Except for the ones that aren't :) Microsoft started at a disadvantage both from a code point of view (our codebase is 35+ years old) and a "company position" point of view. But we've got religion, and we've got it bad. We're catching up quickly, and we're bringing Microsoft teams (e.g., Windows, Office) along with us. And we're active participants in the committee and we propose features and implement Technical Specifications and whatever we can do to be the best compiler and compiler team. And at the same time we're aware that millions of developers have billions of lines of code that compile with our old, less-than-conforming compilers and were doing our damnedest to not leave them behind as we move forward. That's why you can install multiple compiler toolsets in VS 2017, and why you can grab daily builds off a NuGet server to try out our compiler as it is right now, and why we have created standards version switches and backwards compatibility switches and documentation out the wazoo about any changes that might break your code and what you should change. Time to sleep; the committee meeting starts in less than nine hours. 
Those need wrappers. Someone made a wrapper generator. I just saw it but haven't looked into it yet. http://www.angelcode.com/angelscript/resources.html https://www.gamedev.net/forums/topic/617111-more-angelscript-binding-wrappers/
The new upcoming star in the sky is probably [conan](https://conan.io). It provides an easy way of dealing with dependencies respecting ABI compatibility. Conan is open source, actively improved and well supported and integrated by JFrog (the makers of Artifactory and Bintray). ~~Technically, it's based on CMake.~~ Integrating dependencies into existing CMake projects is a matter of very few lines (&lt;10).
Can you give any examples? Smart pointers (for example) were invented by Bjarne Stroustrup (in one of his C++ books).
Trying to implement something like the List functor in C++ may not be the best application of category theory to the language. I think the iterator mechanism is more versatile and performant for the language. Instead, I'd like see forays into strict usage of something like a Future functor. But it would likely be in direct comparison to something like stlab's concurrency lib.
I know it's not C++, but is there any chance for C99 in the foreseeable future?
So a scripting language that is as inconvenient as c++? I fail to see a purpose here.
I'm not saying the Boost authors invented the ideas, most of which have been around for many decades, but rather that Boost shipped a practical implementation, which served as a testbed and either became or served as the inspiration for many language features. Boost has been like a trial run of new stuff before it becomes much harder to change because it's standardized. And lessons learned from MPL were a large part of the design for variadic templates. Aside from shared_ptr/unique_ptr (auto_ptr always sucked), the examples that come to mind for C++11-14 are foreach, threads, regex, chrono, function/lambda, ratio, array, random, tuple, prev/next, exception_ptr, system errors, and to_string (lexical_cast). For C++17, there's also concepts, optional, any, variant, coroutines, ranges, filesystem, and asio. 
But why? If you just need wide multiplies, you have the mul128 intrinsic (among many others listed here https://msdn.microsoft.com/en-us/library/hh977022.aspx) EDIT: I'm genuinely interested in the use cases for the land between say 64 and 256 bits where it feels like an overkill to use MP library, but it's also annoying to hand-code wide arithmetic.
Are you aware of string instructions? Or is this &gt; the mask or index value and tell you if a zero byte was encountered *all in one* the catch?
At least according to [cppreference's status page](http://en.cppreference.com/w/cpp/compiler_support), Oracle's compiler seems to be quite a long ways behind Microsoft's in terms of supporting C++14 or (especially) C++17 features. That said, there's probably a fair case to be made that VC++ is in fourth place with regards to language conformance. In no particular order the top three are Clang, gcc and EDG. EDG, however, is really a compiler front end, mostly without a back end--it's sold primarily as an OEM product. Then various vendors (including Intel, if I'm not mistaken) write code generators for it to produce complete compilers. It's largely up to that vendor, however, to decide which new language features they want to support. At least the last I heard, Microsoft was also an EDG licensee. They use their own front end for the compiler proper, but the EDG front-end to do the parsing for the IDE (to support Intellisense and such). This is why (among other things) the IDE and the compiler sometimes disagree about whether some code is correct or not. It's also worth noting that (like AMD and Apple) Microsoft also ships a version of Clang, with their own code generator (`Clang/C2`). This currently uses Clang 3.8; its conformance should be similar to anything else built around Clang 3.8 (which is a couple of releases old, but hardly ancient). I believe Microsoft has pretty much stopped work on this project though, with the expectation that their own front-end will achieve (at least approximate) parity fairly soon.
What's the schedule for these "No" features. Will they be implemented? It's really behind other major compilers far away.
How did he keep motivation throughout such a monumental task?
I think the issue is that MSVC implemented a lot of features over C++98 which their clients used in their code-base, which now have to be maintained in the compiler. It's hard to keep a compiler up to date without breaking old non-standard code. My experience with maintaining a piece of software in time is that it's a costly thing to make a change, and writing code that will not break your current features can become very hard, especially when you have a new, consistent, set of features to add. It's a hard job, yet MS is doing quite a fine work at it.
Honest question (no pun intended). Why would you need C99 nowadays on *Windows* machines?
Clang and GCC have also been used by a lot of the games consoles (customized of course). They are _huge_ projects.
We have a library written in C with ~2M LoC that is compiled to several targets, one of them is Windows with MSC instead of the Intel C compiler. That is currently blocking the C89 to C99 transition of our codebase. (Some embedded targets without proper C++ compiler are blocking C++ for us.)
&gt; Edit: near semantic equivalent (no stack unwinding) I thought the point of noexcept and deprecation of throw() was to get rid of the runtime overhead involved with throw().
Maybe it is already known but since he is the inventor of C++, does he use C++ for his day to day tasks or even in his free time*? And/Or does he even code on a regular basis? If not, how can he keep up with the fast changes the language is going through currently? *The majority of people think of C++ as a difficult language which is better used for "heavy" tasks and if you just want something done in a small project pretty fast, some other language might be better suited. Still as the inventor you could think of: "nah its my baby i will use it"
But speaking about it. It's very easy to join the effort of making LLVM (and Clang) better. The people behind it are very open to new people joining and very helpful when you are getting started. It's a fun project to work on!
I think people are a little unfair on MSVC nowadays. They've made great progress, and it seems they're becoming more agile with adopting and distributing new features also (structured bindings, copy elision, if constexpr and more all being added in a minor update instead of requiring we wait for the inevitable VS 20xx successor). I've even been writing code recently, using as many new features as possible, that MSVC manages less errors or more conformant outputs than Clang (though, at least in my work so far - GCC is still ahead). I think that we'll see a pretty significant improvement to the compiler once these massive rejuvenation efforts are finalised. I honestly wouldn't be too surprised to see them keep toe to toe with the competition thereafter. On a slight tangent - any MSVC compiler devs here have a timeline for template&lt;auto&gt; ? It's the last piece of the puzzle for my library :)
yes, I just cut some stuff from the source code, it had also a this capture there, thought that removing 'this' makes 'mutable' needless. Nevertheless, the point was that I can use strand::post without any copy construction/assignment being called. Hope it will not change.
Last time I installed VS 2017 it made the C++ compiler disappear from VS 2015. Reinstalling 2015 did not help. It claims that C++ support is installed, but CMake cannot find a compiler. I can imagine the amount of unnecessary defects you have to fix or work around every day.
Do you actually run that code on Windows or is it there only for a purpose of strengthening the code with multiple compilers?
There is no good soultion yet, since there is no good crossplatform package manager. For downloading via cmake, you may try [cget](https://github.com/pfultz2/cget)
Well, those results are easy to misinterpret. Here is a list of things ~~you~~ the author did wrong: - not reproducible/ seedable - `rand()` is a bad RNG - just one run per algorithm? - Your quicksort stack grows linearly - missing baseline: add `std::sort` - use `std::swap` - read more Knuth!
It actually runs on windows. It's a library for controlling industrial processes, and customers run it on all kind of systems, whichever they happen to build into their machines.
I don't understand how concepts can make a difference here.
I haven't found any videos of him speaking Danish. I have already heard his life story multiple times, all about C++ and everything else. It would be interesting to hear him speak a sentence or two in Danish. 
By the way, aren't you the person who interviewed James Gosling recently? That was an interesting interview - though you did come across as a bit too servile or fawning (no offence intended, just an observation). It was also remarkable how he did not stammer once during the whole interview (he is apt to stammer a bit in every one of his video lectures). In any case, continue the good work!
The one question I would ask him is: what was the point in time you decided to invent your own programming language and why?
on the same topic. Does he still have roots in Danemark (like family or so)? Does he go back from time to time or never? Does he has homesickness?
The size seems to be `23`, which is the number of chained continuations: [on **godbolt.org**](https://godbolt.org/g/C3qvB8). I think this happens because lambda captures cannot really make use of EBO - I'll see what I can do regarding that. Also, I forgot to mention in the article that clang generates a much shorter error (collapses the nested lambdas into one). This is usually a good thing, but sometimes the added information is useful. [On **godbolt.org**](https://godbolt.org/g/kq4s2i). --- My assumption was correct: replacing the lambda with a good ol' function object makes the size of the entire chain become `1`: [on **godbolt.org**](https://godbolt.org/g/ziyKSr). Quite sad that lambdas don't do EBO for you...
Microsoft isn't small either. If they can't afford the development, they can just build their own compiler upon these open source projects. Sadly, the clang/c2 toolset support for vs is terminated, since they consider msvc will soon be as standard complete as others.
It needs to be said that MSVC is not the worst in regard to language features. You should check out the Intel compiler - used primarily by the HPC and academia crowds, it lags behind in terms of standards support even more. Furthermore, it's a lot less stable, with lots of inexplicable showstopper errors that only Intel can fix. Still, we continue to use it.
 Ya that's what they said-- but in reality noexcept is basically throw() version 2. If the compiler fails to inline, a not so uncommon problem with MSVC, you get slower code if you use noexcept. 
To compile ffmpeg.
Who wrote this article? Who is the target audience? It opens with vapid nonsense ("Both Microsoft and Intel® are in the business of change. By changing what computers can do, we change what people can do with computers, and that changes people’s lives."). But scroll down a bit and we are being given examples in raw assembly. But don't let your eyes glaze over!
That addresses prefixed units (though it's still harder for someone familiar with the field to reason about your code than if the normal units were used) but it doesn't address the extra constants needed due to not using natural units.
You can install VS 2015 C++ toolset INSIDE VS 2017. This way, you don't need two separate installations. In fact it works very nicely: I have "solutions" with multiple projects inside, some using VS 2017 and some using VS 2015 toolset so that I can use the newer toolset for the main part but still maintain compatibility with external libraries such as CUDA that need the older toolset.
I believe that most professional C++ programmers don't think of the language as a punishment that they try to avoid if they can. Is it really so much more difficult than other languages? I personally find C to be much more complex: the lack of basic features such as RAII makes it incredibly hard to get anything done. Every single resource must be carefully, manually tracked, there are numerous paths through a function that would have a single path with exceptions, you must remember which function returns zero for error and which returns non-zero (or -1) for error (or set errno, or a library-specific version of errno, or something else altogether), etc. And yet, somehow, C has the name of being easy, while C++ is hard... 
i wasn't speaking directly from my perspective, since i like c++. i came late to the party and pretty much started directly with "modern c++" and i liked it. but lets imagine you want to develop a small application in your free time for lets say manage the movies you watched then surely its easier to just open your visual studio c# project, drag and drop some windows and buttons and gridviews here and there and boom you have a perfect responsive gui application with lots of functionality. in the end, i still try to do as much with C++ as possible and i would be interessted if bjarne think this way too.
&gt; Another major issue is compilation time - I don't have any real benchmark but I imagine that without type-erasure and with deeply nested continuations compilation times might suffer greatly. If compile-time was a major issue all of us would be using `void*` and C. The proof that this wasn't an issue is that they added, together with future, `std::async`, which is a template, and lambdas, which can be used to easily explode that template into an infinite amount of functions even if they all do exactly the same thing. Also, they added `std::future&lt;T&gt;`, but if compile-times were a problem they could have made it a concrete type, type-erasing the `T` as well, yet they didn't. Finally, this argument can be applied against the STL itself, and Boost.Iterator and Boost.Range have had `any_iterator` and `any_range` by the time C++11 was released, so this problem "was known" and the solution was also known. IMO C++ gives you the tools to write code that compiles fast, but this comes at the cost of making code slow. This tradeoff is inherent to software, and the way C++ does this is the _right way_ to do it. If, like `std::future&lt;T&gt;`, one makes things to compile fast at the expense of performance, those who need the performance cannot reuse those things. So they make their own things, so compile times go high again because now instead of having one future type, you are back to having many of them. OTOH if you make things perform fast, and provide the tools to make them a bit slower but compile faster, those who need the performance are happy, those who need the fast compile-times are also happy, and those who need their own thing are also happy because they can reuse at least the type-erasure part of the feature. &gt; The lack of UFCS prevents continuations such as .then to be defined in a generic manner for any object satisfying an hypothetical Future concept. C++11 did not have `.then`, so I doubt that future not being a concept has nothing to do with `.then`. Also, by the time C++14 was released, we already had a couple of concept emulation layers on top of C++11 including range-v3 which even allowed dispatch based on concepts. We also had a paper about the design of customization points that shows how to solve this problem, so we could have had any syntax we'd like, and we had lots of libraries using all kinds of syntax (like Boost.Range). &gt; I think that the sad reality is that the language isn't yet powerful enough to support a Future concept with opt-in type-erasure which is fast, easy-to-use, doesn't have awkward syntax, and doesn't blow up compilation times. - "fast" Type-erasure is slower than not doing type-erasure, but you cannot do anything about that _in any language_ beyond devirtualizaton, which is a compiler optimization. A non-type erased future also allows you to have a `std::variant&lt;futures...&gt;` for when you need to support multiple future types, but dynamic dispatch is too expensive. - "Easy-to-use" ? Most users won't write future types, but they all find it easier to be able to combine future types of different libraries, so IMO this makes things easier for most users. - "Akward syntax": `future.then(f)`, `then(future, f)`, `future | f` / `future | then(f)` (Boost.Range is from 2003...), ... all of those can be supported at the same time, so any of them can be supported as well. - "blow up compilation times": those who want to trade compile time for performance can use `any_future` everywhere So which part _exactly_ isn't supported by C++? C++ supports all of the above just fine. C++ also supports zero-cost abstractions, `std::future` just isn't one.
What kind of office or work environment does Bjarne Stroustrup find relaxing?
As a game developer for 20 years who is forced to use different compilers across different PC and embedded platforms can I say a quick thanks for all your hard work. We're in a lot better place than 10 years ago because of it. Give the committee my love.
Check out the e-mail addresses of folks posting to mailing lists of open source projects. You will see quite many big companies. Especially compilers are highly sophisticated software and could not be realistically developed with people's spare time.
Though it was answered a few years back on [Big Think](https://www.youtube.com/watch?v=NvWTnIoQZj4), I'd be interested to know if he still feels the same as he did about programming languages to learn.
VS + VAX is my weapon of choice, but the compiler is seriously lacking. It's kind of a lost cause, they're making progress, but not fast enough. 2015 was really buggy, but to their credit they're incredibly swift &amp; transparent when handling bug reports. Anyway, standard compliance &amp; feature set is only part of the problem. Error reporting for example is way ahead in at least clang. As soon as it's possible to seamlessly install clang as a toolset in VS I believe MSVC will begin to slowly but surely die. Especially for multi platform development.
1. I am not the author. 2. It's a student project graphing the rough timings of the classic sort algorithms, presumably because they completed their data structures course recently or something.
Afaik, there is no reason that runtime overhead is better with noexcept than with throw(). Violations of both need to be detected in more or less the same way. The gain is through detection of noexcept functions and selection of different functionality if thats the case.
Also, id recommend doing a dedicated benchmarks/plots for small arrays. This should give quite some additional insights into the algorithms. Edit: Also, ploting with y-units as nanoseconds, and then starting numbering from half a milion of units is silly.
I think he meant that you should put some sample AngelScript on the home page to make it more attractive...
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6mjtuc/zero_and_one_based_counting_in_the_same_project/dk43yzf/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Another honest question, can't you use a C++ compiler for windows, while restricting yourself to the C99 subset (to be able to use the C compiler for your other architectures), or is C99 not a subset of C++ (I read that they are some differences, but I don't know if the gap is really big in practice)?
Has he bothered to learn Rust? :P I'm half joking. But does he and his coworkers take time to learn other languages that have introduced interesting features? Maybe that can be worded a bit better
What's his opinion on the now famous fake 'C++ was a joke' interview? http://www.ganssle.com/tem/tem17.htm Edit - Oooh what does he think of Linus Torvalds firm rejection of C++ in the Linux kernel - does he think any of Linus's reasons are legitimate or does he need to 'see the light'. -link to one of his rants, this is more to do with Git though. http://harmful.cat-v.org/software/c++/linus
Does he read reddit? Does he recognize us? &lt;3 
Sweet thank you MSVC people for getting this in.
C99 isn't a subset of C++. In particuar, [Variable Length Arrays](https://en.wikipedia.org/wiki/Variable-length_array) are part of the C99 standard, but they were never supported by C++. Subsequently, VLAs were even relegated to an optional feature of C11(which is the most recent C standard). There might be other differences but that's what comes up from the top of my head.
Do you happen to have any good benchmarks on nontrivial code bases? The ones out there tend to be simplistic to the point of useless. The main code I work on has runtime on the order of 1000s of CPU hours (primarily heavy use of eigen libraries and running mostly on AMD clusters, mpich+gcc) so even a modest speedup will get me to switch. I realize the answer is I should probably just benchmark my own :)
I'd like to ask Bjarne to tell stories about the most interesting/controversial interactions that happened at ISO committee meetings, especially regarding Concepts and UFCS. 
https://www.reddit.com/user/bstroustrup
Could be interesting to look at other techno to be honest, it may inspire some new features.
MSVS really is probably the best IDE out there though. Minor compiler concerns aside, if it weren't for space considerations (juggling 128GB of SSD aint easy and is *very much a me problem*) I'd be gleefully using it now.
Thanks for the reminder, but I actually need the 2015 IDE because one important extension is not available for 2017 yet.
Please read the blog post. We aim for complete conformance on 2017. There will be some soft spots (bugs and bugs++) but the schedule is generally "this year". If there is a specific feature you want to know about I may be able to provide more specific information. I can't say more about all of it than I've already said. 
I think what would be most welcome is some sort of addition to `&lt;cstdint&gt;` (or not quite, since it's not integer-only) that would provide us a way of declaring both the *size* of the type we're allocating as well as whether it's a vector or not. So being able to write `p512&lt;int32_t&gt;` would result in a packed 512-bit structure that would expose its members as individual `int32_t`s. Next up, it would also be nice if we had *actual operators* work just as they do in ordinary C++, so that `a * b` would work correctly even if both of these are 'packed' data types. Because right now, the whole `_mm_mul_ps()` business is just dreadful. Finally, it would be cool if someone thought about having some compiler switch to the tune of 'arrays are vectors by default', so that any array of, say, type `int32_t` would actually be fitted into whatever architecture-supported vector is. This would *also* require additional operators on arrays that are hitherto unavailable.
Yes. Also discussed in the blog post (IIRC) but we're targeting C in parallel. It's way lower priority due to way lower usage but we are making progress. No timeline yet, sorry. Getting a conforming preprocessor is a huge start for C conformance and a long pole for C++ conformance. We've started on the preprocessor already. 
What does he thinks of GNU/Linux and the criticism from Linus Torwalds on C++ 
I would like to ask, "Why is the state of software development so awful?". We often hear about public sector IT project disasters where millions are spent on systems that turn out not to work. Health care and income tax systems come to mind. 
Why don't they release a new language, which uses all "good" C++ features and without all the deprecated stuff?
While I can't disagree with Andrews point of view, I've always have seen MSVC as a platform tool. Until recently that means they supported the platform not the standards. The simple thing to do here is to avoid MSVC, for cross platform work, if you can. That appears to be a problem in the original posters case. If that is the situation I'm not sure there is any good advice to be offered.
You'll definitely have to benchmark your own application, but anything that is vectorizable is where ICC shines. It won't likely help as much on AMD clusters (a huge amount of our optimizations are based on understandings of Intel's processor internals), but I'd imagine it would be helpful. Typically, the 'spec' benchmarks are the best place to look. ICC has a significant performance gain (10+%) on most of Spec2006, and Spec2017 shows significant gain.
&gt; The AngelCode Scripting Library, or AngelScript as it is also known, is an extremely flexible cross-platform scripting library designed to allow applications to extend their functionality through external scripts. It has been designed from the beginning to be an easy to use component, both for the application programmer and the script writer. &gt; &gt; Efforts have been made to let it call standard C functions and C++ methods with little to no need for proxy functions. The application simply registers the functions, objects, and methods that the scripts should be able to work with and nothing more has to be done with your code. The same functions used by the application internally can also be used by the scripting engine, which eliminates the need to duplicate functionality. &gt; &gt; For the script writer the scripting language follows the widely known syntax of C/C++, but without the need to worry about pointers and memory leaks. Contrary to most scripting languages, AngelScript uses the common C/C++ datatypes for more efficient communication with the host application. &gt; &gt; AngelScript is completely free, released under the zlib license. I only ask for your recognition, nothing else. However, if you would like to make a donation I would be very grateful. Your donation gives me more inspiration and will allow me to spend more time working with AngelScript. TL;DR: * embeddable scripting language * C++-like syntax and types, but with a garbage collector * supported platforms: (...?) * can easily call into C and C++ * permissive license (zlib) * donations welcome 
&gt; Technically, it's based on CMake. No, it is not based on CMake, it has the best integration with CMake, but you can check support for other build systems: http://docs.conan.io/en/latest/integrations.html, or this blog post using pure Visual Studio projects: http://blog.conan.io/2017/05/11/C-C++-Binary-Package-Management-for-Visual-Studio.html
You're welcome! Tell your friends, especially those who don't want us to make any changes so as to not break their C with Classes code :P
You mean like D? (Yes, it's a joke.)
/u/TyRoXx, if I remember correctly there was a bug in our layout that was causing a VS 2017 install to whack VS 2015's compiler. It's been fixed. If you're still having trouble, please PM me an email address and I'll get you in touch with people who can help. Also, I'd love to know the extension that's not available. 
I would actually like to know his opinion about Qt and its push of the boundaries of C++ to the point of requiring its own preprocessor.