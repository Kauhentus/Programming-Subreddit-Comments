Can you give us a summary answer?
Unfortunately I can't share any code directly, but I'll try to dig up a decent reference. I should note that there is some runtime cost. The hand derived Jacobians are generally faster. But computing those Jacobians usually isn't the largest cost, it's solving the linear systems (isn't it always!)
[Shenanigans!](https://gist.github.com/jrandom/62d6741e5d1eb65a8060) (granted, that was to get around a dumb limitation in C++ templates...)
Release and Debug?
*cringe*
A vector will be contiguous in memory, while a list's elements will be placed where there's "room" available, meaning it will not be contiguous. **vector pros**: * random access is O(1), meaning if you organize your data well with indices, you cannot go faster than that. * segments of memory are the fastest because you work in batches, it's compact and simple so it's very cache friendly, meaning it will always be fast (I think even if it's larger than the cache size, since the cpu will copy segments of memory much faster, so vector will win from this, where list are just fragmented all over) **vector cons**: * You can't insert in the middle (or it comes at a great cost), instead you need to use an "object pool" if you need to remove and add data often. * You need to preallocate if you want things to be fast, so you need to plan how much memory you will need. Once you have a vector, you cannot move it around too much, and should use indices instead of references and pointers * You cannot delete in the middle * Working with integer indices is painful and requires more thoughtful data types when you're doing something, so it's more work. **list pros**: * You can insert in the middle and easily erase (but remember than malloc calls should be avoided in general if you want speed), so it's very easy to manage memory that way. * You don't risk de-referencing a null pointer because list pointer check themselves. * Much faster to sort in general since you don't move data around, you only change pointers. **list cons**: * You don't have random access, meaning you need to run through the list to find what you want. So lists are useful if your algorithm relies on sorted data, or if you always run through the entire list * Lists are the most cache unfriendly container you can find. Bjarne Stroustrup talked about this: most of the time, you should use a vector, not a list. For more complex cases, use a map. You rarely need to use a list. Maybe list are useful for graph data, but it's a very specific case.
Well not everyone have access to a good education, and some programmers are self taught. So can know awesome stuff and have good experience in programming, and still miss out the basics. I did not go through university to know the difference between vectors and list. In short, not everyone is well educated, but it doesn't only educated people have access to jobs.
Language support for declaring shared_ptr .. I'm not even a c++ programmer :-)
Huh, I had no clue. I'm not sure my life became a happier one now.
&gt;Private data members: Too constraining. I don't get that one. What kind of constraints are we talking about, and what is the alternative? Exposing every implementation detail?
Creating objects without smart pointers.
I would second a vote for this, especially since template metaprogramming was practically an emergent feature of the language as I understand it. In other words, it wasn't exactly planning, people just figured out you could do it. I've never used it or seen it used. I don't really understand it.
My most favorite thing is that thanks to C++11 and C++14, the language is starting to feel more like Python in that I can express things in a much more elegant and concise way. My least favorite thing about C++ is how most other people use the language. Especially formatting, which seems to be considered an optional thing or a vehicle for personal expression. (p.s. The project I'm working on was stuck on an ancient version of gcc and Visual C++ until recently, and it's like Christmas morning getting access to all the new features.)
Except for the smart-ass who would say "pi". 
Is it able to handle digit separators and raw string literals? These are probably the most annoying features that syntax highlighting usually get wrong...
I use `and`/`or` a lot. I find them much more readable than `&amp;&amp;`/`||`. Note: I mean "alternative operators" and not trigraphs (which are removed in C++17) nor digraphs.
He is not there for jokes... 
Fear not, `#include` will always have to be there for backwards compatibility and C interoperability.
It is the next feature I want to include in the package. It should be available soon. 
I actually tried Runtime Compiled C++ and found it to be great. That said, you need to keep in mind that Edit and Continue in Visual C++ is actually pretty functional - more functional than E&amp;C in .NET (which is *really* embarrassing). And on the subject of .NET, I've been doing 'runtime compiled'-like stuff for years, it works just fine and is a completely different way of doing development where it takes a lot less time to test an idea.
How does this change what I said? Even if you had good education or delf-taught the difference between vector and list is still very basic and I wouldn't bother asking that.
I agree. But it also makes sense to think list as an abstract data structure and array and linked list to be concrete ones. Well, this is off topic and I agree with you nevertheless.
Though in this particular case, I believe we should be unrepentant. If you give a hash table a poor hash the hash table is not obligated to do well by you. Of course the "3x performance difference in comprehensive benchmark" claims are on the table when `&lt;xhash&gt;` gets overhauled.
They teach ML and Java in the first year, Prolog and C++ in the second. Take a look at their [website](http://www.cl.cam.ac.uk/teaching/1516/), a lot of the courses have excellent teaching material online.
[Compare and exchange is considered "lock free."](https://www.infoq.com/news/2014/10/cpp-lock-free-programming) 
The template doesn't fit in, but I only had one question... And only the instantiation needs to be thread safe. Look, I just compressed a 45 minute interview into one question, *because that's what OP was asking for...*
Compare and swap (CAS) used outside of a loop is clearly lock free. When it's used inside a loop, it really just depends. You can implement a mutex using a CAS instruction inside a while loop, so if CAS in general is lock free, then so are mutexes! In the article, it's something of a grey zone: the compare and swap is not used to guard any other resource, but rather it itself is the goal. What you are suggesting is definitely a lock though, as you are using the atomic to make sure that only one thread accesses the constructor. Edit: I guess I should further qualify. It's a lock if other threads cannot make progress. You wrote in your post that other threads would check the status of the instantiation. This means that other threads cannot make progress, and therefore it is a lock.
&gt; Still not sure if we should use identity instead of FNV-1a for integers. If "*If you give a hash table a poor hash the hash table is not obligated to do well by you*" is the genuine sentiment then it seems clear that identity is useless. Not being able to use `std::hash&lt;int&gt;` for an `unordered_map&lt;int, T&gt;` even though it's the default because they don't have/fulfill the same set of expectations is not what I would guess to be the intent of the committee...
TL;DW He is not happy with C++17
I don't find Java code simple, just dumbed down and more abundant for the same task. D code is both simple and expressive. 
`static if`.
Does this mean we'll be able to see symbols in minidumps from mingw binaries?
If your structure has a pointer member, you need to have a move or assignment operator else it will leak memory. Clarification: this applies to owning pointers.
Best practices are not just about performance but numerous other things. * Common patterns which other people can recognize * Code readability * Safety There is more that could be in this list, just all I could think of currently.
"The only "raw pointers" I work at my job, are always non-owning, and the lifetime of the pointed-to object is always guaranteed to be longer than the lifetime of the pointer." Sounds like you are using raw pointers as references. Why not just use references?
Pointers can be re-assigned. You can store them wherever you want. Etc.
Adding to what /u/millirobo said: I use const T&amp; ref; for any const ref, and T* ptr; for something I intend to mutate. I keep to this pattern in ~99% of cases -- but for things where the action is painfully obvious (such as std::swap) I'll pass a mutable reference. If you have this pattern throughout your codebase, it makes understanding a large codebase much easier.
It seems relevant when talking about performance implications, no? One may say - "if I was writing a factory method that yields a (non-polymorphic) object, I would use return-by-value. In C++11 (and for decent C++03 compilers), returning by value forgoes the copy-on-return, so it's not less efficient than other options (like passing in a pointer-to-a-pointer)." Certainly I wouldn't *expect* an applicant to say something like this, but I guess it's possible.
It would be relevant, but I would expect most people (including experts) to give an answer like: "always take inputs by const reference unless it is an in/out parameter in which case it should be passed by reference or pointer as the style guide dictates or it is an optional parameter which should new passed as a pointer or an optional types. Outputs should always be returned by value unless profiling says this is a problem or they are in/out parameters."
None. But he's been a software consultant for more than most of us.
I've used astyle for my last two projects. Put a [c]make target in and use it before commits. Pretty flexible.
.
A lot of times you have several ways to do things, each with similar development costs. However, one is accepted to be the best practice way. Usually this is to prevent you or team members blowing your legs off in the future or preemptively avoiding a needlessly costly operation. Senior C++ programmers remember a lot of these things by heart and should catch them in code reviews. If you're going to do something, do it the right way.
C++ gives you great power to achieve high performance code but if you don't wield it correctly you can easily end up with code that is much slower and buggier than higher-level languages. C++ allows you to choose when to use references/pointers and avoid copying and when to use values and potentially achieve better data locality.
Plenty of other people with plenty of enterprise C++ experience have independently verified the utility of his advice. Scott Meyers cleaned up a lot of *really* bad C++ code in the early 2000's. Regardless of whether he has finished large enterprise projects or not, his advice holds and countless C++ programmers rely on it. I'm not sure what more you need?
I actually think learning Prolog was very useful. Sure, nobody uses it, but it teaches you another way of thinking, another tool in your toolbox to solve problems. Especially writing my own (simple) prolog/logic programming interpreter was very interesting and educative.
I look at it this way, he took the time to write the books so rationally he must believe in the concepts. What is more important is that people read his books because it is accepted that there is good wisdom in the materials. If nobody read the books then there might be real questions as to the value of what is written. Instead the books are seen as industry standards of wisdom. That by the way doesn't mean there aren't exceptions to the rules. Rather it means applying the rules should lead to better code. 
Collecting N samples and applying Window function and FFT is done from the getData() function in draw.cpp. But glutIdleFunc() is bit hard to synchronize. fftTest.cpp is a program just to calculate the time required to compute the FFT of the samples. The a.out is its binary. 
I'll check it out! 
Another way of putting it is that the reason certain code performs better is because you're describing your problem with the most correct solution - so the compiler and standard library will output exactly what you need, no more and no less. Sometimes explicitness and clarity of purpose can decrease performance instead, but in the case of C++ that usually doesn't happen, because that's how it was designed. But performance is usually just an added benefit. To be fair, it can sometimes be hard to tell what C++ practices are good conventions and what practices are just based on "performance myths" that people mindlessly repeat on the Internet.
std::move is also about semantic. You can't give away an unique_ptr ownership without moving it. But moving everything that we don't need anymore would make the code less readable, so we usually only move what matters for performance (except in move operators, move everything). It's like taking a function parameter by copy or const reference.
That is just marketing. They implement "new" C++11/14/17 features but don't implement old C++03 features that are still available in C++11/14/17. Without C++03 support lots of libraries that do actually use C++11/14/17 don't work. Pretty misleading. 
&gt; how about a possibility of compiler to optimise virtual calls on a final type. Isn't a `final` virtual function enough for this?
&gt; extremely inflexible It is extremely configurable, but if a feature is missing you should file a bug report. &gt; being aggressive With the current package you can either indent a whole file or a region. I can see how having to mark a region to indent might be annoying, but if you want something like "indent only the current scope" it shouldn't be to hard to implement. &gt; I've tried to use it to approximately implement the C++ coding standards at my last two jobs, and in neither case was it possible to get close enough (and in the second case we had a clang-guru who didn't believe me, and he failed too). If you cannot reproduce your current style with clang-format you should file a bug. If you can, the only successful way I've seen of integrating it on already existing projects is to set up git/svn to trigger clang-format on _new code only_. Losing `blame` information to get better formatting is a tradeoff that is not worth it for most projects, but for new code this is fine.
Great :)
If you aren't latency critical / resource bound my question would be - why are you using C++? The tooling isn't good. The language is more complex. The developers are more expensive. The TCO is higher.
Where could I get the slide?
Strongly disagree. In Java, there is some argument for avoiding making things final because components are generally consumed in binary forms. In C++, there is no such thing. If a class is final and you really need to use it in an inheritance scenario, just remove final. It serves as a warning that deriving from the thing could be problematic.
I'm sorry, but this logic on final is backwards, and stems simply from inertia and the fact that non final is the default. If the default were final, and there was a nonfinal keyword instead, do you really think people would be in favour of just throwing nonfinal everywhere? When in doubt, start with a narrow interface: widening is not a breaking change, narrowing is. Policy classes are obviously useful, but in real life code they are generally a tiny, tiny minority of classes. Most classes have state (not including pure tmp classes). Omitting final for consistency with this tiny minority makes no sense. In non user facing code, any class that is not designed for inheritance should just be made final. Worst case, the guy who wants to inherit gets a compile error, thinks for a minute whether inheritance is a good idea, and then possibly changes it. 
&gt; It is extremely configurable, It's configurable within what the maintainers think of as acceptable use, but there were at least four issues that I and another developer were unable to get past. The underlying issue is it always rewrites all of the code - and that isn't going to be fixed. In other words, if I take the output of clang-format, make a bunch of whitespace-only/reformatting changes, and then run in through clang-format with the original settings, it will always rewrite every line to get back to the canonical form. I understand entirely that you want this and that's even a specific goal for you, but be aware that for a lot of developers this is a deal-breaker. I personally like the idea of "a canonical form for each file" and might be willing to give up a lot for it, but for my previous team that was basically universally unacceptable. There are specifics too. In the last team, they always brought out "boring" keywords involving a function or method definition onto the previous line: static inline SomeComplicatedResult func(ComplexSignature....) I don't know if I like that, but there's no way to do that in ClangFormat. The previous team had a rough convention where either you fit a function signature on one line, or if you had intricate parameters that were too long to fit, you had "one per line" - so either this: uint64_t glueTogether(uint64_t x, uint64_t y, uint64_t z; or this: uint64_t glueTogether(std::shared_ptr&lt;boost::optional&lt;Value&lt;uint64_t&gt;&gt;&gt;&amp; x, std::shared_ptr&lt;boost::optional&lt;Value&lt;uint64_t&gt;&gt;&gt;&amp; y, std::shared_ptr&lt;boost::optional&lt;Value&lt;uint64_t&gt;&gt;&gt;&amp; z) but ClangFormat tries to fit as many things as it can into one line and I personally hate that. (Yes, I'd probably use a typedef to avoid this in this specific example I made up, but sometimes signatures really have to be long...) &gt; If you can, the only successful way I've seen of integrating it on already existing projects is to set up git/svn to trigger clang-format on new code only. Quite so!
std::swap But more importantly, reassigning things you don't own just seems weird.
So, your convention comes from *not* interpreting a non-const object by ref as a signal that the object is mutable. That's the larger convention that would make understanding the code base easier.
thanks! will definitely check it out
In [the original statement](https://www.reddit.com/r/cpp/comments/4le6xp/how_important_are_these_c_best_practices_really/d3mmg72 "The only raw pointers I work at my job, are always non-owning) these were always cases where they were non-owning.
Usually, if you aren't using it anymore, the compiler will figure it out and you'll get equivalent to move semantics anyway.
He owns the pointer itself, not what it points to.
Interesting - are you developing to target linux or windows? Which tools? Open to persuasion...however I think compared to java it may be found wanting. Although to be fair java sets the bar high.
This video doesn't play for me, shows an error message at the bottom of the window. Is there a mirror somewhere, maybe on Youtube?
I think you've misread it. It's the pointer that is "non-owning".
Yes but he owns the pointer itself, meaning he can reassign it to point at something else he doesn't own.
&gt; The underlying issue is it always rewrites all of the code No, it does not, it only rewrites the code that you tell it too. In particular within emacs you can tell it to only rewrite the lines that you indent, or within svn and/or git you can tell it to only rewrite the lines that you edited (which is what for example Chromium and LLVM do, both million LOC code bases). &gt; I don't know if I like that, but there's no way to do that in ClangFormat. Yes, there is: http://clang.llvm.org/docs/ClangFormatStyleOptions.html there are actually _multiple_ options to control that but my original question remains, if none of them worked for you, did you file a bug report? &gt; but ClangFormat tries to fit as many things as it can into one line and I personally hate that. There is actually a lot of options to to tell clang-format not to do that: `AllowXXXOnASingleLine`. Idk, to me it sounds like either you didnt tried hard enough, or you didnt reported the bugs that you found. In both cases, it seems to be your own fault.
I know, I was just replying to his "no language needs null" statement.
Not sure why this is downvoted, but it is absolutely true. Any embedded system is going to require code that is performant and memory aware.
I agree, I find it quite contradictory that a lot of developers insist on making all member variables private but don't consider making the member functions final by default as well. A subclass can mess up the correctness of it's parent class just as fine by overriding a member function as it can by having access to it's member variables. I think, either you have confidence in the skills of the writers of subclasses, then you should generally prefer protected over private and leave the member function non-final or you don't trust them, then you should use final and private for everything that is not designed as public API.
Hmm. I can't stand eclipse, I use intellij. Valgrind I've used and like. What exactly are you looking for with static analysis? Potential bugs, or bottlenecks?
Mostly bugs, but bottlenecks too.
&gt; But for MSVC that might be more complicated. A "runtime" version would be a new implementation. MSVC supports `constexpr`, just not C++14's relaxed `constexpr`.
&gt; The only "raw pointers" I work at my job, are always non-owning, and the lifetime of the pointed-to object is always guaranteed to be longer than the lifetime of the pointer. Sounds like std::reference_wrapper candidate.
I don't understand your point. This article is about asking one question to determine C++ level of a programmer. Your goal is to ask a question and filter more than fizz-buzz-level-programmer. "What's the difference between std::list and std::vector" is just too simple to do that and I would never ask such a simple question in an interview. Being self-taught or having gone college is completely irrelevant. Self-taught or not you need to know certain things to get a job and it should be more than fizz buzz. Period.
old but gold.
I wonder why JAVA?
This is so awkward!
&gt; **BinPackParameters (bool)** If false, a function declaration’s or function definition’s parameters will either all be on the same line or will have one line each. 
It's not awkward, it's awesome, people having fun and creating something creative and wonderful. I wish I'd have been there :-)
Yep. Though I'm told that Chinese and Russian universities still teach C++.
LOL
Very gracious followup foonathan. I agree that in your particular case, where you are both writing many policy classes, and a library author at more arms length from users that can't just pop a new release as easily, not using final very much makes sense. I had been thinking of writing a post about final for a while actually because I have noticed many developers that have argue similarly; they feel strange "cutting off" the interface. This difference between the passive and active action in our perception is similar to a well known thought experiment in ethics: https://en.wikipedia.org/wiki/Trolley_problem.
This is weird considering doing thing in java is usually faster.
This statement is not true since 2011.
So you are saying programmer has to take more things into consideration when using java and thus productivity is lower than in c++?
Writing code is faster? Debatable. At runtime? Lolno.
&gt;Any tips on if I should keep learning C++ You're on /r/cpp -- you might be getting biased responses here =) &gt;learn the most important concepts about programming Many schools are using python or Java (which is very similar to C#) to teach this, as (often) these languages let you focus more on the concepts and less on the implementation. My school kept with C++, and I like it, so there's that. &gt;so I can get started with developing software This is actually the most important part of the post. What kind of software do you want to make? If you already have your mind set, you can pick a language best suited to what you want to do.
Depends what kind of software you want to develop. If you want to develop web api then there are better tools for that. C++ is only the tool, you need to ask yourself first what you want to do then you pick the tool, not the other way around. About the concepts, you need to answer yourself another question, concepts on which abstraction level are enough? For example, do you want to know what happens in C++ when you push to vector one element over it's capacity (relocation) ? Or you want to know how assembly looks like for this operation ? Or maybe you want to use other language, maybe higher abstracted with GC? and you don't need to know that. Lower you go things will get more complex, but as i said if you want to develop web api you don't need to know concepts that people working on embedded platforms need to know.
dude you might want to direct him to /r/cpp_questions - just sayin'. EDIT: forgot the underscore even!
No, I would say it's about the same. * Both languages have a big standard library (ok, you might want to add boost for productivity). * Both languages don't require manual resource management. * The syntax is quite similar. I really cannot imagine a scenario where prototyping/rapid development in Java is easier than in C++11.
&gt; It's a long story, but mingw-w64 forked from mingw.org. Although my distro was based on mingw.org for many years, I now consider mingw-w64 to be the one true MinGW. I don't think it does much good to conflate MinGW and MinGW-w64 like that. They are separate projects, and [the MinGW project really does not appreciate it](http://article.gmane.org/gmane.comp.gnu.mingw.user/44932) when you use the terms incorrectly. Also, there's a trademark involved, not that it necessarily matters much for casual conversations. 
I've had that paragraph since distro 11.0 on Aug 2013, and you're the first person to comment about it. Given that paragraph and the Contents section, plus the intentional lack of any mingw.org hyperlinks, plus the removal of my dependence on original MSYS, I don't believe that there's any real opportunity for confusion. I'll think about renaming things so that I can eliminate any discussion of mingw.org entirely.
You're welcome, thanks for using it.
Removed; beginner questions are on-topic for /r/cpp_questions, not here.
&gt; There is an alternative - use Boost.Thread, which has a native and well-tested implementation, and compile with `-DBOOST_THREAD_VERSION=4` to request semantics that closely align with the Standard. Until those semantics align so closely with the standard that `boost::thread` is called `std::thread` and is provided through `&lt;thread&gt;` I wouldn't really consider this good enough: It's not going to fix code that uses `std::thread`.
To fix this, someone needs to contribute a native implementation to libstdc++.
You are awesome, Thank you.
Awesome!
IMO it'd be good for your page to cover this issue, as (based on browsing SO) a large number of people conflate MinGW and MinGW-w64, and/or form incorrect beliefs (e.g. "MinGW-w64 is the 64-bit version"). I'd say something that clarifies the two are separate projects and briefly explain why you use the one titled MinGW-w64. 
I thought that's what that paragraph was doing. I considered it counterproductive to go into detail why I dislike mingw.org.
Thanks for the update. Curious if you are considering packaging clang as part of the distro. More compilers = better diversity and given clang's improved integration with visual studio.
I'd like to know too. I use MSYS2, I like the fact it supplies me with a terminal that accepts Unix commands, that it uses pacman to manage my MSYS2/MinGW-w64 (don't have to worry too much about checking the website, just pacman -Syu a couple of times to freshen up pkgs), etc. And by using the MinGW terminal I don't have to worry about changing my PATH variable either, I think the necessary stuff is appended to it while I'm on the terminal.
Thanks for your time. I really appreciate your efforts. Do you think it is possible to add a cross compiler for Linux to your distribution??
Yea, too many. Some of them have different use cases though. This one is very lean. Since I've discovered [MSYS2](https://msys2.github.io/), it's the only one I use anymore, it provides everything and has a fantastic package manager (pacman!) with up-to-date packages. The only thing that's sadly missing is XMing (or something similar), so for that you indeed need a second distro... annoying :\
I'm using MSYS2 too and in my opinion, there's no reason anymore to use this one. Except if you want a really lean distro and this is your only priority. STL is doing a great job in this regard. Well, actually, if you install the base MSYS2, it's lean too... as lean as STL's. So yea, I'd like to hear a reason too :D
Really nice article with focus on C++ games programming tunning. Well written and it makes references to good books. btw love the illustrations. :)
Out of curiosity, since you're (presumably) not allowed to look at the GPL source code for libstdc++ etc, how do you deal with any build failures that crop up in this project? (Not to suggest that you're doing anything improper, I'm just genuinely curious about how you deal with it.)
It's possible to build such a thing, but I don't have enough time to maintain that. My distro consists of what I personally use, with very limited exceptions (e.g. I added gdb so people would stop asking).
My distro is **not** a fork, and doesn't fragment the work on mingw-w64. If you look at my build scripts, I have zero local patches for mingw-w64 and gcc. For the rest of the components, I have been steadily reducing the number of local patches that I need to maintain; e.g. I reported a problem to Boost.Build's maintainer who took the time to reproduce and properly fix it, so distro 14.0 is the first one to build Boost without local patches.
* Ease of installation without modifying your system (what git calls "portable"). It's possible to install MSYS2 by extracting an archive instead of running an actual installer, but the procedure is [somewhat complicated](https://github.com/StephanTLavavej/mingw-distro/blob/master/README.md). * Size. For what it contains (primarily Boost and git), my distro is very small. * I've made certain choices, like x64-native (absolutely no 32-bit) and static libraries (no DLLs, except as implementation details of non-library components), which I feel are superior and simplify things. * The exact mix of libraries and utilities that I support, focused around building an OpenGL game engine. * My build of grep is the best one in the world on Windows (due to my patch for color highlighting). If you prefer MSYS2 over my distro, that's perfectly fine. I literally don't care, as I release the distro as a side effect of maintaining my personal environment, and I don't profit from it in any way. (I suppose distro users are testing my environment, which is nice, but I also have to answer their questions in exchange.)
It's clear, although I'm probably assuming too much familiarity with compiler terminology. I've added a todo to explain this in more detail. Every compiler has three platforms: build, host, and target. In the distro's case, the build platform is my computer, which is used to generate the compiler itself. This is interesting insofar as it affects my build scripts, but is not relevant to anyone else. The host platform is your computer, which runs the compiler. And the target platform is your end user's computer, which runs the stuff you're building with the compiler. Ignoring the build system, any compiler for which the host and target systems are identical is a "native" compiler. Any compiler for which the host and target differ is a "cross" compiler. By referring to my distro as x64-native, I'm indicating that it's x64-hosted, x64-targeting. I've intentionally disabled support for 32-bit targeting. (Unsurprisingly, my build system is also x64. However, I don't consider the build system to be relevant to a compiler's nativeness. Although I try to preserve my sanity by not looking at the build system too closely, I'm pretty sure that VC's checked-in toolsets are x86-hosted, and they're used to build all of our compilers: x86 native, x86-&gt;x64 cross, x64-native, x64-&gt;x86 reverse cross, and the ARM crosses. The term "Canadian cross" refers to a compiler with 3 different build/host/target systems, though.)
I might switch to Clang in the future when libc++ supports Windows as a first-class citizen. (libstdc++'s support is second-class.) I wouldn't build GCC and Clang simultaneously, that's way too much work.
Binet's formula falls apart pretty quickly due to precision issues, so using it is usually bad idea... anyway, if you really care about Fibonacci numbers, get a bigint class and write yourself fast exponentiation algorithm together with matrix multiplication to get absurdly large Fibonacci numbers quickly with full precision.
Removed; please go to /r/cpp_questions as the sidebar advises.
in the spirit of the OP, it would have to be a compile-time bigint!
&gt; We can compute AN in logarithmic time using only integers This is assuming that you will only work with native sized ints, with bigints its a bit more. 
It's just a plug for a book.
I'm curious what your setup is - I just double checked my implementation from the video and get 55 for fib(10). Similarly if I upgrade it to be all `long long` and `long double` for Fib(76) I get the correct result as well.
The algorithmic complexity of the algorithm does not change, only the time of the arithmetics changes. `int`s also take some time to compute, some bigint implementations just take more since they're not native CPU operations.
Try doing complexity analysis on the algorithm while counting bit operations. We don't usually do this, because from the usual PoV the complexity of adding two numbers together is O(1). However, once you support arbitrary sized integers, it is O(n) in number of bits. 
Of course it's O(n) but a decent bigint implementation would use 32 or 64 bit integers to store such number and manipulate it efficiently on the CPU so the constant factor is pretty great. Also, unless you're actually trying to calculate Fibonacci numbers going to infinity (which is an useless waste of resources), you're going to be looking at some upper limit of values you need your bigint to work at. Setting any practical upper bound on the bigint size allows treating operations on it essentially O(1).
Isn't he just compiling the source code of mingw to a Windows target using the provided build scripts and uploading it as a package? Why wouldn't he be allowed to look at the source code he is compiling?
&gt; Last I checked, libstdc++ still doesn't support Windows threads natively, and I am highly skeptical of wrappers that attempt to adapt Windows threads to the Posix API. There is an alternative - use Boost.Thread As time has gone on this has gotten to be more of a pain and I had to switch off this distro, too many C++11 and newer constructs break without this and I didn't want to bring boost as a dependency for my projects when I just needed threading. Unfortunately all of the other distros are behind yours in ever other matter. I hope libstdc++ gets patched eventually.
Sadly, no mentions of ostringstream. :(
PS, this is for Windows :D
Cool article, although I feel that Boost kinda solves many of the performance improvements that he talks about specifically with stuff that *hasn't* become part of STL (yet).
I might accept a pull request, if someone would show me exactly how to enable such support in my build scripts.
Following the rules isn't that hard. They weren't "never look at GPL code ever", even in the bad old days. Building the distro rarely requires looking at code, and the stuff that's in my area is the least problematic (whereas coreutils is a train wreck). I've never run into a situation where something broken would require looking at stuff I didn't want to look at (and I'd know who to complain to upstream if that happened). Note that I am about as tempted to look at libstdc++/Boost/libc++ product sources as I'm tempted to eat spiders. It's not that their sources are bad, but I believe I can do a better job by knowing nothing about their techniques. I wrote a better nested_exception than either of the other STLs (and duly reported my improvements to the maintainers and LWG, without source code), even though we were last to implement it.
&gt; I heard on SO that the pthreads version of mingw-w64 now supports `std::thread` etc. out of the box. As a user of mingw-w64 I can confirm that this is true.
There is another (old) trick, the assumption of `b` being `0` or `1` can be enforced with the double negative: a += ((!!b)-1) &amp; c; It does not cost much more, and the assumption can be dropped. 
&gt; but also knowing it's very convenient for development that these do everything deterministically, unlike the std::unordered_*, where iterating gives you your data in an indeterminate order... That's actually a good reason to use `std::unordered_*` early: You don't accidentally write code that assumes the data is in a certain order. This is even more true if you're writing code that other people are going to consume: You don't want to accidentally provide a property that they depend on and then coerce you into supporting to your own detriment.
It's been over a decade since I built a cross, sorry.
Wow. I see. Thanks for the reply. :)
You pointed it out, doesn't make it true. Do you have any benchmarks showing that the ordered containers are faster for small data sets? My money is on the unordered, even at size sixteen. It's probably 2-3 cache misses versus 4-5. It's also a bunch of work to go back and change your containers if they are getting slow. If you don't need ordering, than unordered containers are strictly better and should be used. 
When you compile as an executable, you need a main ... GCC enforces this. Plus in order to visualize program flow (the entire purpose of the page) you need a starting point, which is what main is, (excluding constructors from global objects) 
&gt; My money is on the unordered, even at size sixteen. FWIW: at size 16, I'd bet on vector :-). 
My example on godbolt was supposedly using gcc. If you want to compile without main on GCC -nostdlib will get rid of the standard library. This will allow GCC to compile without main and without error. But it doesn't look like C++ Tutor allows me to pass compiler options.
&gt; The only sane implementation of an unordered_* that I can justify Actually, there are other implementations of hash tables (which were IIRC discussed in Knuth, with "moving to the next bucket in case of collision" coming to mind), but yes - this one is very popular (though IIRC it is usually a single-linked list rather than double-linked one). &gt; The lists will not be more than 2 - 3 elements long Except for the worst case, which we need to make-sure-doesnt-happen when dealing with hash tables :-(. 
THANKS, I've added a note about !!
I would have liked to see some discussion on matrix operations for calculating Fib numbers! 
Can you refer to specific boost:: containers in this regard? (boost:: is HUGE...)
&gt; If anyone has sample code/example/project where this is the performance bottleneck please share, I'm dying to know! FWIW: I've seen this kind of stuff helping for Galois field calculations (the ones of mod p style): IF there is an overflow, THEN do something weird etc.
&gt; My idea is to do development prioritizing correctness - without of course picking containers that I know for sure are going to perform badly in my application - then once everything is undeniably correct, find the very best containers for each purpose. And using an unordered container over an ordered one doesn't prioritize correctness _how_? If anything, developing with e.g. `set` when `unordered_set` is actually the "best" container for your purposes _de_-prioritizes correctness to favor ease-of-debugging. For one, you're developing without involving the hash function you'll eventually use – what if it's problematic, or pathological? To prioritize correctness, develop with the "correct" datatype to begin with; if that happens to be an unordered collection, then develop with an unordered collection.
 - `boost::containers::flat_set` - `boost::containers::flat_map` - `boost::containers::static_vector` - `boost::containers::small_vector` - `default_init_t` overloads for all vectors types in [Boost.Container](http://www.boost.org/libs/container/) to allow default-initialization of elements when constructing or resizing rather than always value-initializating Not in Boost, but also noteworthy is [Howard Hinnant's `short_alloc` allocator](https://howardhinnant.github.io/stack_alloc.html), which can make allocation overhead and locality issues of any container completely moot.
Heh, got to answering this before me, cheers :)
I thought it's not a good argument while choosing a container in C++.
I liked the article's answer to that question better.
The correct answer is, `std::pow` is slower than matrix exponentiation. This is no surprise as `std::pow` is more complex than integer matrix exponentiation... Big O notation is not a measure of performance, stop treating it like it. It measures how an algorithm scales with N.
I'm just going to statically link in an int64_t array of the fibonacci numbers. I win.
I did clearly specify that we're talking about a situation where it's evident that performance characteristics are unimportant, so I don't think your comments about performance are really fair. And I do realise they have different implementation details, but if I can see that someone has built a map from, say, 20 values from a config file, I'm going to assume they didn't really have any concerns for the data structure characteristics. In those situations the 'interface' might be more important.
&gt; There is a clear link between big O notation and performance From experience (I don't know what the theory says): I doubt there is a link, because &gt; O(log N) will always be slower than O(1) given a big enough N Writing O(X) is better than O(Y) (with X and Y and amongst 1, log n, n, n², etc.) is only true for some *(over-simplistic) modelisation*: when benchmarking, real-world implementations of algorithm just doesn't seem to follow the matching curve, even after N = 10^6 or 10^9 elements. Or maybe it's because we never reach a decent N in benchmarks (if N is a number of element, then we are capped by our memory / size of an element) (Edit: given the downvote, I'd be interested in a counter-point)
&gt; `+ 0.5f` Careful with that approximation : http://blog.frama-c.com/index.php?post/2013/05/02/nearbyintf1 Edit: I explain: using the `+ 0.5f`trick is a bad idea, as it will results in inaccuracies similar to OP article. If you want to know more about (some of the) edge cases of floating point, I recommend reading Bruce Dawnson's blog post on the matter : https://randomascii.wordpress.com/category/floating-point/
&gt; As for stack_alloc - THANKS for reminding about it, I've added it too. No problem. :-] Note, however, that it's `short_alloc` rather than `stack_alloc` – the latter was Howard's first, _non-compliant_ proof of concept which has been superseded by the former, which is C++11-compliant and plays nicely with `std::scoped_allocator_adaptor`.
Thanks! Wasn't sure whether to post this here -- my thinking is that some of the discussed issues (say, [pointer provenance](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2012.htm#clarifying-the-c-memory-object-model-pointer-provenance)) may be interesting and equally applicable. On the other hand, other parts may refer to perhaps too C-standard-specific wording (like _effective type_, a wording not present in the C++ standard, to my knowledge). What do you think? Naturally, feel free to remove the post if it's not a good fit here.
Ah yes, the good 'ol noty-noty trick
But how are you going to compute it? I propose using the article's `constexpr` function! (Note: I wonder if a compiler could be smart enough to realize that the valid domain/number of outputs of a `constexpr` is very limited and just turn it into a quick look-up into an array)
&gt; how are you going to compute it? I propose using the article's constexpr function! Copy-paste the actual numbers as a comma delimited list.
Exactly.
It's a floating point literal (which isn't used a lot). Reference: http://en.cppreference.com/w/cpp/language/floating_literal
Didn't know about the hex ones. It says C++17 though... Not supported in VS 2015.
hash+tree sounds like a good idea (assuming you can implement both operations!), but keep in mind that the people who do databases professionally have discovered that a B-tree alone will match the power of a hashmap. There *is* one real arguments against 2-ary trees (i.e. what most people implement) though, since they have high constant factors due to cache unfriendliness. Hm ... I've always heard that the problem with B-trees in C++ is that they can't offer the no-move (i.e. stable reference) guarantee. But, if you force each node to allocate the actual datum separately, you're still winning the moment you eliminate a single level ... which happens the moment you have more than 1 node.
Yea, the cache unfriendliness is a bad thing. But there is also the third possibility of using something like eastl::vector_map.
I checked the reference very quickly, hexa representation has been an extension of gcc, added only recently into the standard. https://gcc.gnu.org/onlinedocs/gcc/Hex-Floats.html
In that case, it's better to use a cache-friendly binary search (middle element at front of the array, followed by quartiles) rather than a naive binary search.
I have google benchmark (mostly) working with VS15. I am only getting into this kind of thing so can't give much of a review. Will have something you can use in a day or two if you are interested. In a similar fashion to [this](https://github.com/mkn/google.test) Edit: [here](https://github.com/mkn/google.benchmark)
&gt; Only if the function is virtual and not private. It is 100% legal to override private virtual member functions. Meyers even recommends making pure virtuals private so that the implementor of the derived type is not tempted to invoke the base implementation as a default behavior.
&gt; data locality can be a huge factor for performance (as well as many other things), That blog post that looked at that was quite interesting, didn't they plot the distance to the processor or the area taken by the storage with the access time and showed it was r^2 or something? Big O, despite it's failings, is still quite useful as a starting point though as a guess how long two algorithms will take.
I mean, that's the number of collisions in the table, which should almost always be smaller than the number of elements, right? Edit: I guess I've just been missing all the jokes recently. 
That was a boss ass article!
Sorry, it's my weak attempt at a joke, O(k)?
Compute? Google! :-)
Since it's using constexpr, a given compiler may well be doing the same thing.
 #include &lt;iostream&gt; #include &lt;utility&gt; #include &lt;array&gt; #include &lt;stdint.h&gt; template &lt;size_t N, size_t K&gt; constexpr uint32_t addp(const std::array&lt;uint32_t, N&gt;&amp; arr) { if(K==0)return 1; if(K==1)return 1; return arr[K-1]+arr[K-2]; } template &lt;size_t N, size_t... IDX&gt; constexpr std::array&lt;uint32_t, N&gt; genFibArrImpl1(std::index_sequence&lt;IDX...&gt;) { std::array&lt;uint32_t, N&gt; arr { addp&lt;N,IDX&gt;(arr)...}; return arr; } template &lt;size_t N, typename IdxType = std::make_index_sequence&lt;N&gt;&gt; constexpr std::array&lt;uint32_t, N&gt; genFibArr() { return genFibArrImpl1&lt;N&gt;(IdxType()); } uint32_t fib(int n) { static const std::array&lt;uint32_t, 47&gt; arr=genFibArr&lt;47&gt;(); return arr.at(n); } int main() { for(int n=0;n&lt;15;++n)std::cout&lt;&lt;fib(n)&lt;&lt;std::endl; } p.s. Don't take it seriously though.
I wouldn't say it's a 'bad idea' though. It's inaccurate, yes, but that's mostly due to floating points themselves being inaccurate (sort of). It only really screws up on huge numbers, and to be fair if you really needed the list of Fibonacci's number you wouldn't be calculating them every time anyway, so it's just an example.
Yea, I basically interpret the sequence as a binary tree that was traversed breadth-first in my own implementation. Works great.
If I wanted it fast, I would probably do a mixed approach. For very small n, I would either lookup the solution or compute it outright. For n whose result can be safely derived using benit's formula (using architecture supported float sizes) I'd do that. For everything else, I would compute it outright and store off every 100/1000 result so that recomputing is faster (I'd have to play with that number to determine a good memory/speed trade-off). The right answer to how all this should be done depends on use case.
OP appears to be a time traveller from the late 90s.
I've used IMGUI, though I had to make changes to it as it had some bugs surrounding named objects and making buttons. It works. It works better than every other UI library I've tried. Though I'd still rather have a good, simple "retained-mode" stateful UI library. 
What about it? In practice, tree maps often start losing once you exceed 100 items or so, and they don't stop losing after that. And if you can find a good capacity to reserve, you can often entirely avoid the O(n) case in a hash map.
Thanks for the link. The best part is &gt; This article focuses not on C features and then ranting about C++ not being C and how C is superior. The "References" section has more text than the article itself...
Removed, thanks.
Er, no, that's not how it works.
Thanks. I'm interested in your follow up *with more diversity of object size*
Honesty. C++ has evolved *dramatically* since 2009. Your best interview would probably be one where you were up-front about when you last used C++, and offered to show your proficiency with C++03, along with a willingness to learn.
I find the book didactically horrible, a very bad book to learn or refresh. It's a good technical reference though. But wrong thing to learn if you only got a day I think. My suggestion: Watch the last 5 CppCon/GoingNative keynotes from Bjarne, Herb &amp; co. That'll take you 5+ hours. You can watch a couple more after that if you still got time. And be honest at the interview =)
Does ImGui support all the usual keyboard shortcuts that you expect from an UI? If not, I would not use it.
I think you have the wrong idea about what ImGui is. https://github.com/ocornut/imgui
Lying is bad.
I haven't checked how it handles the rendering on that side, yet. My presumption is that it assembles vertex buffers for primitives, and then transforms them in the vertex shader. I used it in a high-performance 3D application without any major issue (UI was a tiny part of the frame). If it were copying vertex data every frame, that would have been incurring a substantial stall.
I found that reporting bugs for all issues I encountered works exceptionally well, too :'), at least for cases where the particular issue was not known yet.
which parts did you fail? exotic syntax? or super-hard algorithms? 
https://en.wikipedia.org/wiki/C%2B%2B11 and https://en.wikipedia.org/wiki/C%2B%2B14 are good quick overviews of the extensions to the language.
I may have misunderstood the description on their github page. They say it outputs vertex data, which gives the impression that it doesn't handle the buffering and render calls.
Does Imgui internally cause any pipeline blocks (eg glfinish, or any sfml functions that call this)? If it just renders stuff to sfml windows in the 'sfml way' without blocks (.display()/glflush/glfinish/glget), I'm sold I've been looking for a good UI solution for my game (which uses sfml so that's convenient), but its mixed opencl/opengl and pipeline stalls (other than a single .display()) are critically bad for performance
Very bad advice. Source: I interviewed few dozens of candidates. Those following this strategy always leave bad impression (mostly because they waste more interviewer's time than necessary).
OK.
I don't think it that way. It might happen that you nail the question though, either by educated guessing or you're asked something similar to a field of your knowledge. Saying "I don't know it" will just buy you a -1 with a moron interviewer.
That's the fun part: **I have no idea**. Thanks to this moronic fad of not giving out any feedback.
I thought of that, but ouch if the code is like that.
You are also presuming that there are only quads. Preparing an index buffer in advance in hopes of drawing a massive number of quads would only work in that situation, otherwise you require multiple draws (or a MultiDraw call if the system supports it). The cost of drawing quads is not the issue, it's the population of the data, which potentially introduces a synchronization point between the GPU and the CPU if not handled correctly, and can stall the frame. We saw this all the time when profiling Scaleform.
Oops, I derped on the first one. I was mainly trying to avoid putting the template part in the example and didn't think when I switched it to `int`. I'll fix that. In the meantime, here's your Unicode character of the day: ™
If you use dynamic buffers, that's sort of what the driver is going to do anyways, at least on PC hardware. I prefer using large ring buffers, myself. There's a number of papers about what exactly the driver does during DISCARD ops, and the behavior is going to differ between AMD, NVidia, and Intel. This also becomes vastly more complicated if you are using deferred contexts, or D3D12 command lists. Also, on consoles there is no equivalent to WRITE_DISCARD or DYNAMIC. You multibuffer, or you use ringbuffers.
I quite like C++11 and up. I didn't care for earlier versions, but auto and lambdas and a few other things make all the difference in the world.
C++ is **fucking awesome**. It took me a long time to understand that the simplicity of a language isn't equal to the simplicity of code written in it.
I *like* C++. It's currently the language for high-performance code. When Rust catches up, or surpasses it, I think we're going to see some more people migrate. C++ is a pretty easy language to learn though, and it is decent for a lot of things. I prefer C# over it in just about every way though. C# feels so, so much more polished and thought-out than C++. It doesn't have a ton of wacky, rarely used features, and the ones that it does have are very well-done. If I could get the speed of C++ out of C# code, that would be my language of choice. I think D is a step in the right direction when it comes to the C family of languages. It seems to be right there with C# when it comes to features, but it is actually native. Rust is way too foreign to become mainstream for a long time, but I don't doubt that it eventually will! You can go between C, C++, Java, D, and C# pretty easily compared to switching to Rust. It seems so close to being familiar, but then you start getting a grip and realize how different it is, which isn't a bad thing, but makes it very hard to pick up.
It's the compound assignment operator with bitand. You can do `const int &amp;a = 2;` just fine.
**Company:** [Align Technology, Inc.](http://www.invisalign.com) **Type:** Full time **Description:** We make Invisalign for teeth alignment and iTero intra-oral scanners for digital dentestry. My team develops Automated CAM component, programs backend in C++11/14, focuses on geometry and numerical stuff (compute surfaces and curves), runs manufacturing experiments as part of Agile, deals with cluster computations and HW/SW integration. Level of math - can find volume of 3D shape and solve non-linear equation numerically. Level of C++ - can implement smart pointer and factory. **Location:** Raleigh, NC, USA **Remote:** No **Visa Sponsorship:** So far, no **Software Technologies:** we use C++11/14 STL, Boost, MSVC2013, Windows, Git, Jira, Bamboo **Hardawre Technologies:** we use 3D printers (SLA), 5X CNC mills, 4X/5X CNC lasers, vision systems **Contact:** Apply [here](http://www.aligntech.com/careers). Select North America, Engineering to filter positions. Use any with 3D CAM tag in a name - I have many similar reqs.
I like it. I originally started in languages such as Perl, PHP, JavaScript, and Python, but recently I began learning and working in C++, and since then I've become a big fan. I think many of the "improvements" other languages tried to make over C++ are turning out in hindsight to be mistakes. Forcing all code into a class was a mistake. Getting rid of destructors was a mistake. Limiting to single inheritance was a mistake. Removing operator overloading was a mistake. It seems that other languages end up introducing new, highly specific features to compensate for the original, general purpose features they removed. Proxy objects to compensate for the lack of operator overloading. Traits to compensate for the lack of multiple inheritance. Auto-closables to compensate for the lack of destructors. And so forth. It turns out C++ made a lot of very good decisions early on. I also really like the wisdom that's in the C++ community. It's great to learn from people like Stroustrup, Sutter, Alexandrescu, Meyer, and others, not just for language specific details, but for ideas about software in general. That being said, if someone were to write a book about all the ways a junior dev could screw up your C++ program, as well as a book about all the ways a junior dev could screw up your Python program, I suspect the C++ book would be *much* thicker. And as I write this, I also realize that Python has made none of the hindsight-mistakes that I mentioned a couple paragraphs ago.
Whoa, I thought 1 would not compile, but it's actually a warning: http://coliru.stacked-crooked.com/a/f4339e4d33e73049
Could you please explain why the last one prints 2? 
I find it a very *comfortable* language to write some sorts of code in. I sometimes use it for "glue logic", because it's the right language for a particular problem, and I've used it for web apps occasionally for the same reason. In those cases it's not about performance at all, rather about programmer efficiency. Once you're comfortable with the language it's the "right match" for some small problems (much the same as e.g. perl, go or sql are for others).
(From the sidebar) There is a useful list of books on [Stack Overflow](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list). In most cases reading a book is the best way to learn C++.
I would say 123 for #11.
Where do you see the second increment?
Nowadays I prefer to work in JVM, .NET and ML derived languages. However I still like C++ a lot and use it quite often in personal projects. Back when C meaning outside AT&amp;T, specially in home computers, was meaningless and most compilers produced worse code than someone learning Assembly, my higher level programming language was Turbo Pascal. So when C started to have any real meaning in MS-DOS and I looked how primitive it was versus Turbo Pascal 6.0, I wasn't convinced. But thanks to a teacher, I got hold of a Turbo C++ copy, and got to learn a language that contained most of C, yet could be made as safe as Turbo Pascal and contained most features I had come to love in Turbo Pascal 6.0. I was sold and joined C++ ranks in the "C vs C++" war. Always had to ask for permission to use C++ instead of C in university assignments (not always possible), gave C++ classes to first year students and used quite often in many work projects. I also remember from those days as C++ was seen as bad by other developers in terms of performance, as C++ devs nowadays look to other newer languages. What keeps me away from C++ at work, is that many developers just use it as "C with C++ compiler", what I deslike a lot both in code quality, as well as, in writing exploit friendly code. Also the lack of modules, caused by compatibility with C when C++ was trying to gain adoption is a big pain point. It might eventually come, but only after C++17. So at work I rather use Swift, C# (specially now with .NET Native), Java, OCaml, Haskell, .... But when writing portable code for private hobby projects between all mobile OSes, C++ it is. Rust it still isn't quite there in terms of one expects from a systems programming language, for those of us on Windows. A Windows systems programming language needs to have native support for COM, WinRT, tooling integration for .NET mixed debugging.
Sorry for being pedantic, but with .NET Native, CoreRT and Mono AOT, C# is also native. Hardly any difference from D other than inline assembly and a few other minor tricks.
I like my style of C++. Modern, no virtual inheritance, RAII everywhere, no raw pointers, etc. Anything else just seems too cumbersome.
In the for-loop.
You jump to `case 1:`, print `1`, hits the `continue;`, which does nothing since you are already at the end of the loop body. Then you increment x, go through the loop body from the beginning, print `2`, hit `break;`, jump out of the `for`, fall out of the `switch` and print `2` again. There's no second increment.
this 100x
&gt; Rust is way too foreign to become mainstream for a long time Ehhh, I've heard this but having played with Rust it ain't that bad coming from most mainstream languages. The main issue I run into with Rust is the lack of good libraries (especially numeric libraries). Need some obscure weird library for some random topic? C++ has probably got it. I had to deal with some crazy geometric data recently, and C++ had a few nicely vetted libraries at my disposal. When I work on hobby projects in Rust I find myself spending lots of time writing bindings for packages in other languages, def not how I want to spend my time.
I like C++, have doubled down on it professionally. Architecting a large system well in c++ is pleasing, but difficult. C++ is a workshop with all the tools in it. Maximum freedom. Every other language I've used has some freedoms removed. I likes my freedom, even if I cut myself with it!
I personally use gcov from gcc. It works really well. The problem is more in the tooling that you have to use to process the coverage data. In this area, it is mostly bad in my opinion. You often have to use several tools, or scripts, or both, to go from the gcov data files to a usable report. And if you have to do some complex things like merging coverage reports or filtering it, you are mostly left with a bunch of bad options. I have not tested it on neither OSX nor Windows though.
Just like many others here in the thread, I also enjoy C++ very much. However, what I typically do NOT enjoy is reading other colleagues' code that is full of memory leaks, e.g. every double member variable is pointer that is never deleted and what not... So having to deal with people who obviously do not understand and do not care [sucks a lot](https://shop.gwbi.de/gwbi-portlet/i/a/9604_0_detail.png). - Maybe this is not even related to C++, but I experience it in C++. Is it the same for you too?
I actually **love C++**, especially now with C++11/C++14!
What is it equal to then?
C# and python are wonderful.
Languages like C (or even assembly) have simple rules and their semantics are easy to learn, but that doesn't make it easy to actually write useful code. C++ as a language is complex - one of the most complex popular languages in use - but that complexity is what allows powerful low-cost abstractions like the STL and other libraries. The power of C++ is that it enables library developers to produce powerful, efficient, and easy-to-use interfaces but without exposing the complexity of the implementation to the users. For example, if you're implementing std::vector then you need to have a complete understanding of how rvalue references and move semantics work. But a *user* of std::vector doesn't care about those arcane rules - std::vector is just magically faster even if you've never heard of rvalue references.
I work in robotics. I need a language that is close enough to the metal for real-time control. I also manipulate vectors and matrices a lot so any language without operator overloading is painful. I think I would prefer Rust, not so much for its memory safety but for its expressive power. Tagged unions, pattern matching, and `if` expressions are all really appealing to me. Also sane modules. However, it is not popular in the robotics community, making collaboration more difficult. Whenever I do a serious project, in the back of my mind I am always imagining that I will release the code as an open source library some day. It just feels wrong to use a structureless dynamic language that becomes rickety after 500 lines, or an easier but slower language like C# that can't handle the most demanding problem sizes.
I agree with all of your "hindsight-mistake" observations 100%, except multiple inheritance, where I have no opinion. I've never felt a strong need for it. Can you explain your feelings?
Oh got it! Thanks! 
Most platform-provided libraries have a common interface (e.g. OpenGL and DirectX, POSIX vs CreateFile, etc) that once identified will make it easy to compile and run on multiple platforms. I've had more issues with wanting all warnings as errors and the variance in what warnings I can get compilers to emit. Regarding managing the actual build itself, there's several meta-solution generators out there (cmake, scons, etc). I wrote my own open source one I've been kinda lazy about pushing to github, but it's a solved problem nonetheless.
C++ is a great language if you're interested in being an expert at the language, but probably not so great otherwise. I love having complete control over almost every aspect of the software I'm developing and it being very clear and explicit what my code is doing.
coveralls has a nice gcov integration
I enjoy C++ a lot more than Java. It's both far more rewarding and fun to write in. Python is a breeze, I absolutely love it for entirely different reasons. And C will always be more rewarding for me. But C++ is a good balance. 
So I am just a beginner but what's wrong with virtual inheritance and raw pointers? In the ("modern") codebase I am working on, raw pointers are used when it is clear that its lifetime will surpass the context its being used at and I (so far) see no problems with that.
I just feel at home with RAII and deterministic lifetimes. I also come from a hardware-oriented, almost embedded background so it's about control for me. I never really embarked on the *low level* thing. Even C is pretty high-level. C++ is a choice for me, there are in my experience few cases in which you are 'forced' to use it as a last resource. In general I'd say you're more often forced in using Java or C# or JS. I've used a few languages. A couple of years ago I went back to C++ for an exercise and I'd say I have enjoyed it. Where the new language revisions are going, no other has ever been.
Bcause that is the exception to the norm of 20 years old code that passes everything by naked pointers and gives no fucks about signifying ownership. Also, why not references/optional types when you want optional semantic?
I like that I can make a C++ program really really fast. There's so much room for optimization. 
i love c++, but there are a few features i'd like added... c++ does not deal with with complex relocatable data. something to fix this would rock, like a compile time for/each over a structure or object by data type. a method of strong typedef an operator that passed in the a set of pointers, ie: if something like a-&gt;b.c(), c() would receive pointers to a and b. (obviously, this isn't a complete thought or spec, but would be very nice for complex relocatable data.) ps: i know boost does some of this, but i'd like it built in.
I don't think so. If you look at these pictures, my questions are: Does it support tabbing through the elements? Do the elements (for example the drop-down list) support navigating with the arrow-keys, jumping with typing letters, etc.? Can I easily add Alt+Key navigation elements (I don't know the name for this, but what I mean is when e.g. a button says "Ok" with the O underlined and then you press Alt+O to press it). This is all stuff that I expect from a UI framework.
Totally agree with simplicity of language is not equal to simplicity of code. The only language I can think could replace C++ some day for my tasks is D, which is not that simple either. But the GC keeps me away from it for now, among other things. The two best selling points from D for me: metaprogramming and Alexandrescu working on it --&gt; I am sure he knows what to do, though it is going to be a tough time. When I saw Rust and others I got kind of disappointed. Rust has a lot of niceties, but later you want to initialize your types at compile-time or do compile-time calculations and metaprogramming and you simply cannot the same way you can in D or C++. 
2. might be fine, depends on the guy's honesty 3. google and microsoft. Their size however probabilistically ensures they don't hire only morons.
Yes, I experience it similar. The picture you linked reminded me instantly of former work colleagues. After long debates and educating them, the stubbornness of them won. Just to give me another opportunity to practice refactoring. On the other hand, there are the occasional people, writing really elegant/nice code, and I learn a lot, even after two decades of C++. I enjoy C++ and its ecosystem, even if it is more heterogeneous than others. "Easy to learn, hard to master". 
Still lacking a universal GUI . I wish there was something with Embarcadero's GUI builder and component library, but not tied to a particular IDE, compiler and platform. Obviously this is a big technical challenge (Borland tried it with Kylix and failed miserably). At the moment I actually use g++ for my engine and Visual Basic for thin GUI (windows-only), or HTML5 + WebSockets talking to my engine for universal GUI. Would welcome better options ! 
Just because performance isn't required doesn't mean that I don't still like having some! I'm sure there are ways around it, but java always feels a little slow. Takes awhile to load, interface is just ever so slightly laggy. C++ is just snappy when done right.
yeah, I'm still stubbornly holding out final judgement of rust, but I honestly don't ever see it replacing C++. It has a lot of really good ideas, I just don't think it'll come close to replacing C++. 
Yes, but people tend to forget that there are languages that might be easier to learn, their runtime libraries are so huge that it equally hard for anyone to understand them fully, let alone third party libraries. Also many other languages share C++'s feature size (minus C's inherited gotchas of course).
Thanks
Yes, it supports lots of keyboard shortcuts. [Check this out](https://github.com/ocornut/imgui/blob/master/imgui.cpp#L54)
This is exactly what I meant.
To be honest, my love for C++ was almost certainly an accident. I started off programming with the Visual Studio express IDE and the way it was described led me to think "Ah, after BASIC my ultimate goal should be C++". Not even Java could really rub off on me after I cozied up with C++ syntax in my early days, and I found C to be too restrictive/primitive, so C++ just sorta became my weapon of choice. Kinda like an imprint of the first person you really get to see. My introduction to Python was so far later than my introduction to C++ than I'm proud to admit, so much that my first thought about it was "Holy God, where did my type safety go?". And that was the moment I knew I was a C++ programmer.
Qt has a GUI builder and is not tied to a particular IDE, compiler or platform. You can do GUI : - directly in C++ code - graphically in a [GUI designer](http://doc.qt.io/qt-5/qtdesigner-manual.html) for C++ widgets - in QML, a declarative language suited to UIs - there is also a (somewhat limited) [designer for QML](http://doc.qt.io/qtcreator/creator-using-qt-quick-designer.html) - in web pages with deep integration with C++ code using [Qt WebChannel](http://doc.qt.io/qt-5/qtwebchannel-index.html) 
&gt;"Hey, if performance isn't your utmost goal, why not use C#/Java/Python instead of C++?" I write distributed memory (MPI) code for large clusters, so performance is always a top priority. And needing to use MPI mandates using C, C++, or Fortran to use the interfaces natively or having to use one of the others as a wrapper. I actually really like modern Fortran, but it lacks all the really awesome libraries C++ has that make coding easier - my last major Fortran project found me mixing in a lot of C++ stuff, and I'd rather avoid using multiple languages whenever possible. The OOP of modern Fortran puts it miles ahead of C for my work. Basically I use C++ by default. 
RAAI and smart pointers are things that makes C++ awesome. High level languages with try finally or similar flow handling to force manual resource managment is pain in the ass. Of course C style memory managment is hardest thing to get right. But still proper modern C++ minimize impact of these problems. On the other hand add Boost as library and your compile times suddenly get way worse (they were pretty bad to begin with).
I love C++, I find myself missing features of it when I work in other languages.
It's hardly a solved problem. CMake, Scons, and their ilk are more complicated than the languages you're trying to build with them. This is all made worse by the fact that each of the libraries you're trying to use is built with a *different* complex tool being used in a completely different way. Look, Java has complex build tools. Ant is for the birds and one could write doctorial theses on how Maven works. At the end of the day, though, they're *optional* tools. Need to load some Java library? 99% of the time all you need to do is make sure the JAR is in your class path. The only time this gets complicated is when you get C++ code involved. Most of the rest of the stuff tools like Maven and Ant do is just move assets around. I'm not asking for a whole lot here. I just don't think that it should take six hours to figure out how to build a project that happens to use libraries.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programmerhumor] [Fun C++ Syntax : cpp](https://np.reddit.com/r/ProgrammerHumor/comments/4m739k/fun_c_syntax_cpp/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
When heavy user interface design etc come in to play, I avoid C++ at all costs. Or do an option where the majority of the code is written in C++ and interop with C# via pinvoke for a better looking design/ui. Qt is pretty much the only way to go for cross platform UI or writing your own by hand. Otherwise C++ is the W2G!
Concerning 7) Did you mean `3[arr]` ?
Good to know I'm not alone :-)
Oops, not sure how I did that. Thanks for pointing it out. 
I enjoy the language. Sometimes I do choose to program in kotlin or Java when I don't want to fiddle with build tooling and want some easy dependency management though. If c++ had a widely supported more maven/grade type build system, I would use c++ for just about everything. 
That is looking quite interesting! Thanks, I'll try it out. 
If your main argument for C++ is that it has static typing and a syntax you appreciate, I don't think you've learned enough languages to make a educated choice of which you would enjoy most. If you want to learn more, I'd recommend you try as many glaringly different options as possible. Be aware of the biases that your C++ education has inevitably introduced -- an aversion to different paradigms or styles is most likely not due to rational consideration, but rather to irrational anchoring. Iff you don't, I don't see any particularly pressing reason to do so, but do remind yourself that you're a devout C++ programmer, and not a programmer of another language, only because you made it so.
He answered your question before you asked it. :)
I don't know if I like C++, but I definitely don't like other programming languages. Java is overly verbose. The standard library has a million small, cohesive classes which give me no hints on how to use them. There's API docs for everything, but sometimes those docs don't tell you anything more than the name of the method does and they don't give you any hints as to how all the countless Java classes are supposed to fit together. When I do finally figure out how something works, I have to rework my code to do things the Java way instead of the DethRaid way. Python is usable, but I've found that it's really easy to write bad python code. I don't even think about it - I just look back at my code and go "wow, I really need to refactor this before it explodes." Additionally, the docs for a number of common Python libraries (e.g. scipy) are written as if I already know everything that's happening, and I just need a reminder. They don't really tell me anything useful. I also strongly dislike dynamic typing. In C++, if I make a typo in part of my code that's called after some computationally-intensive process, the compiler immediately lets me know. In Python, the computationally-intensive bit would run, then it would tell me about my error, meaning I waste a lot more time developing Python. C++ doesn't get in my way. It's standard library isn't overly verbose. Its documentation, and the documentation for popular libraries, tells me how to use those libraries. Compile-time checking means I don't have to run my code to find a tiny mistake. The language doesn't get in my way. Why, then, am I not sure if I like it? Simple: compiling C++ code is a bitch. I use CLion on top of win-builds, which means I use CMake build files. Those work pretty well, but some of the libraries I try to use don't. I'll often try to compile something and get pages of errors about templates deep within a library. Maybe it's a problem of a compiler version, but the error messages tell me nothing to that regard. When I tried adding SDL to one of my projects, I had to spend a couple hours searching online to figure out how to build it for use in my project. Python has pip and easy-install to acquire libraries, Java has Maven and Gradle, other languages have similar systems, but there's nothing for C++ (at least, nothing that I've found which works better than downloading things by hand). C++ is my language of choice unless I have a very good reason not to use it, but that's mostly because every other language is worse.
&gt; strong, static type-system. There is no legit reason to use something else. This 1000%. I don't understand why so many languages throw away the safety of static typing.
C++ was my first language. I always liked it.
Compile-time calculations in Rust are sought after by many people, and will happen sooner or later. The thing is, Rust didn't yet have as much time as e.g. C++ to develop all those nice features; but the language is evolving rapidly, even much faster than C++ I'd dare say, so don't take what's currently possible in Rust as the end-all status of the language. Just as an example, a new version of procedural macros are currently in the process of being worked out, and, once done, will be _extremely_ powerful: https://github.com/rust-lang/rfcs/pull/1566
C++ is an incredible language - by and far my favorite to work in. I get the fine-grained control over memory like in C (which is a "with great power comes great responsibility" situation, but extremely powerful if you know what you are doing) combined with the robustness of classes, polymorphism, the STL, as well as the awesome features that 11/14 have brought us - such as autos, lambdas, std::move (underrated), a more robust string library (alleviates some annoyances surrounding stringstreams), the list goes on. I write every project in C++, short of small netsec scripts (python for those).
code never dies, c++ will never be "replaced". but rust has the potential to take a lot of popularity away from c++. also not sure what was meant with rust not initializing types at compile-time, it's required by the language.
I'm a MS dev so I will say that when I write portable code I mean between different platforms but normally (not always!) the same compiler but my experience is that writing portable code is incredibly helpful but often impractical. If I write native code for desktop, xbox, and phone the c++ code can be the same - normally. The problem is different platforms have different characteristics that a one-size-fits-all approach doesn't address. Desktop code has huge memory caches, essentially unlimited memory (I can use as much as I need to), multiple cores, and generally isn't CPU bound. Xbox has very strict size requirements, cpu deadlines are tighter and more important to hit. Which core I'm running on is important, and blocking calls are generally frowned upon. Phone is even more different. Tiny cache sizes and a small memory footprint require small code size. Expensive memory leads me to want to optimize to use a small working set. You can probably tell I work low in the stack but these problems exist higher as well (especially with regard to threading). Writing portable code is only half the battle, I still need to go into each platform and fix the platform specific issues. Compilers make this even more confusing - out of college I used primarily Clang &amp; GCC, now I use primarily MSVC. These compilers work differently, support different STL implementations, and have different performance characteristics. I highly recommend that your code 'work' on every platform you're interested in - ie it compiles and runs but as you write more complex software you'll begin to realize that portability is way WAY more than cross compiling the code.
I find it disheartening how many people are willing to purposefully abuse semantics rather than choosing to partake in actual, useful communication.
we live in a semantic world. i don't think it's useful to take things personally, why do you feel that my comment was not useful?
That's a passive aggressive response, I won't be responding to you further.
lol. Well, at least this "tool" has documentation coverage
&gt; On the other hand, the Safe and Fast Multimedia Library (SFML) offers headers for individual platforms. I'm pretty sure that the headers are the same. They just provide binaries for different OSes, so you don't need to compile it yourself. When working with C++, I use only libraries that work on the main desktop OSes. It's easy to do nowadays. Then write a standard-compliant code, and it'll be fine eventually. (can someone please tell me how to test Mac OS X builds without Mac and pain?)
?
I have a medium ish C++ that I'm the lead dev on. It uses plain gmake with my own helper scripts as a build system. If I had time, I would probably replace it with CMake, but for now it works. Having to target only our own platform makes this possible. I wouldn't dream of keeping this system if I had to be cross platform. 
There is nothing wrong with virtual inheritance. Maybe he means multiple inheritance? Raw pointers are dangerous because of this: Func() { Widget *p = new Widget(); Func2(); // throws exception delete p; } Oops: delete is never called.
the c++ standard is a mess. why would the compiler think that &amp;= is a compound assignment in place of a function parameter that should be an unnamed reference with default value? that makes more (but not too much) sense.
I love that C++ let's me program to the problem and not try to fit the problem to the language. I find it infuriating when in other languages and I am treated like a child and not allowed to do something at all; some just make sure I wanted to and that is fine. 
Interesting how Fortran managed to evolve, adapt modules, OOP and modern paradigms while C, even C11, has hardly improved.
http://stackoverflow.com/questions/3413470/what-is-stdmove-and-when-should-it-be-used Best answer links to: https://en.wikipedia.org/wiki/C%2B%2B11#Rvalue_references_and_move_constructors http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2027.html#Move_Semantics And I think they are pretty good. Especially given that the second one explains a little more a bout rvalues if you are less familiar with them! An example where I've used it is in messaging protocols where a connection is established with some unique identifiers - then if I want to put them in a container, I can use std::move where a copy constructor would fail (duplicate of unique identifier).
Are you building on all cores? My Boost builds for example are ~8 minutes.
One thing I'm curious about is where implicit moves occur- not just cases like RVO and passing temporaries. Your example is a good case, and I've "optimized" existing code like: std::vector&lt;std::string&gt; v; std::string s = "blah"; v.push_back(s); // move or copy? // code doesn't read from s afterwards before it goes out of scope into std::vector&lt;std::string&gt; v; v.push_back( std::string("blah") ); // implicit rvalue On VC2012 and VC2013, I don't see any differences between performance. I don't want to assume the implicit rvalue conversion is automatic if I'm not constructing the object anonymously, so I'm continuing to construct temporary in the argument list (or explicitly calling std::move). But if the compiler can detect cases like the one above where a move would be more suitable- shouldn't it? I guess I *could* test with my own class, create a move ctor and operator, and break on those to see if the compiler is automatically performing this optimization. edit- I just realized std::string is a funny case since it performed COW often long before move semantics were implemented. But replacing std::string with any arbitrary object containing heap (with move operations explicitly defined), I still see the same thing.
I think Grady Booch had it about right. Multiple inheritance is like a parachute. You hardly ever need it, but when you do, you *really* need it.
I really like C++, but I use Java because I'm more knowledgeable about ginning up web front ends for Java+JS apps. it's a matter of practicality.
Because of the small string optimization, copying and moving short strings has the same cost, because the SSO stores the string inside the std::string object itself. For longer strings (e.g. &gt;16 chars long) it requires a dynamic allocation which is what's elided by move.
Type safety is woefully neglected in our industry. Too many developers have bought into the lie that dynamic/weak type systems result in increased productivity.
We don't use any delete in the code base though. So in this case this is simply passing a reference while retaining the ownership.
First of all, this is a fantastic thing to at least be thinking about and be aware even if you don't always do it. Writing cross-plat code can certainly be easy for trivial projects but often gets more difficult/costly as project complexity grows. Whether you want to take the effort to do this or not largely depends on your goals and the effort/reward trade-off. It's certainly not a bad thing to work on, and will be a fantastic skill to talk about when you go looking for jobs. However, for your average one-off college assignment, I personally wouldn't usually bother with the extra effort unless I had some other goal in mind like learning how to use a survival library or cross platform programming technique because there really isn't much to be gained in a project you'll never touch again. But again, it's really up to you and is a good thing to practice sometimes. &gt;However, this becomes difficult when attempting to use more complicated libraries such as memory maps, audio/visual libraries, since they are often written with a specific environment in mind or provide separate versions for each environment. As for using components that aren't cross platform in cross platform software, you'll either have to find a cross platform replacement or roll a cross platform solution of your own. This often takes the form of making a think wrapper interface, which you then implement using the platform specific components for each platform. That way, you isolate platform-specific code, and allow the rest of your code to be platform agnostic, coding against the same interface even though the underlying implementation is different. I work at a major software company on a massive cross platform C++ project that ships on three OS families (Windows, Apple, Android) so if you have any specific questions, feel free to ask.
I enjoy coding in c++.
If I'm prototyping I hate it, slows me down too much. If I'm actually *making* something it's great. Having said that the projects I've done so far have either been C# using Unity or C++ using OpenGL or SDL (or none at all) so they have complete different requirements. Getting into UE4 soon so I guess I'll see how that works out.
&gt; .NET Native is useless; it's only for Windows Store apps. There are some of us actually writing them.
I'm so sorry.
Yeah my problem with Rust matches yours slightly. I think the meta-programming / compile-time / generative aspect is weak and I do not think their partial rejection of object oriented theory and terms nor their syntax choices is helping rust. I understand functional programming and can see its elegance, but I mentor a lot of embedded developers, who code to get their real-world stuff to work. They do not care about elegance, type theory or anything except having their code be easy to think about and predictable. They have come to find objects intuitive (their way of modeling is often very flawed but that is another matter) and with a coding standard our C++ code is actually very safe (basically use the stack allocator for each thread, no raw pointers use references, no new or delete and only the experts are allowed to make templates, operator overloads and so on). But this traits stuff in rust along with the entire memory safe combined with the syntax being kinda unfriendly to guys trained in C and C++03 means if I show rust code to them they shake their heads. Now C# and D are much less surprising and so would be easier to teach (although there is no demand where I am, we are busy enough showing/teaching C++11/14 where auto in particular is very popular).
Frankly, I like it much less now than I did ten years ago, but it is pretty much lingua franca for the kinds of projects I want to work on, so C++ it is.
Never heard of job security?
Well the platform is way better than Android, and C++/CX feels like Microsoft finally discovered what C++ Builder was all about. On my case it has been mostly side projects, some with C++/CX and some with .NET Native. It is anyway the future of Windows development, regardless of how the Win32 die hards might resist, specially now that Win32 will also get UWPed in the upcoming version. Although the WP mobiles are now dead.
The worst part is seeing people code like it is 1995 and we don't have STL or templates. Second worst is seeing people turn in C++11 code that uses tonnes of raw pointers yet they imply ownership or take resources but do not apply RAII. All of that and then they claim to be good C++ programmers. Sometimes getting people to write nice C++11 code is all about making them unlearn the old badness and embrace a new elegance. I've convinced at least three programmers to switch their STL heavy code bases over to C++11 just by showing them (and yes I know there is for_each and so on) how: for(my_vector::iterator it = vec.begin(); it != vec.end(); it++) { my_value elem = *it; } becomes for(auto elem : vec) {} But they still seem to insist on writing the old stuf even after having seen the new work, having been on courses and having had me pairing with them for weeks. You turn your back and next code review is a bad surprise. Old habits suck.
Do you ever go in search of interesting C++11/14 code bases to read? Maybe that is an idea for the subreddit. A collective review of a suggested code base to discuss learning, pitfalls and so on.
Most of the low-level world is starting to look at high-level more because a lot of them are acquiring so many features that while they still need the low-resource, high-speed of C like languages their massive in terms of lines of C codebases are really dragging them down because they lack the syntax to express the abstractions they want or the generative programming to remove boilerplate and repeated code. C can't deliver this as a standalone language.
Uh hadn't heard the Kenny Kerr thing, that is very interesting. 
The big danger with raw pointers is that they are still the original thing. Meaning if you borrow them from a smart pointer and pass them around some old library or programmer working in isolation (in terms of information) will do something to it (like call delete when he is done because he wants to avoid a memory leak) and the system is kaput. I used to do the same thing, but these days there are no raw pointers in my APIs at all. It is 99% references and reference wrappers, if a pointer is wanted or needed (don't ask) then its a guard_ptr, a super-dumb smart pointer that just disallows delete and protects its inner raw pointer. As for virtual inheritance I still use that, but always with thoughts to the cost, but a lot of designs are better off with a virtual inheritance only if you can't turn the design into a situation where the class that was supposed to call the virtual interface can't receive the type to call as a template parameter. Basically instead of: class ConcreteA : public class VirtualBase {}; class Container { .... public void call() { pBase-&gt;something(); } private: VirtualBase* pBase; }; you do: template&lt;typename T&gt; class Container { .... public void call() { Obj.something(); } private: T Obj; };
Maximal munch is pretty common, actually. This simplifies things because you lex, get a disambiguated token, and move on. Otherwise, you have one token for both compound bitwise and assignment as well as reference with default. Either that or you have two tokens, but need the parser to give information to the lexer. Admittedly, C++ already does this. 
I love c++, but I hate C... 
I didn't mean how many interviews you had been to, I meant how many you've been in charge of.
On OSX (and clang in general) there's llvm-cov, and I've found gcovr to be a good enough solution (it can write xml files that jenkins can understand, for example). 
I love C++ more than C.Didn't like so much C maybe because I can't find any good IDE probably unlike C++/C# that have Visual Studio
Don't get me wrong, I think the idea is good. But how would this differ from the subreddit as it is now? I mean, just this week, there have been posts/discussions about optimization of fibonacci (pros/cons of different implementations), or an article about `final` classes, or about best practices, just to name a few. 
Very true, well I have the time as I am on sick leave, but I am also on morphine so I am a bit loopy. I will consider it.
POCO
Visual Studio Community imo
Do you mean CMake or [https://github.com/waruqi/xmake](https://github.com/waruqi/xmake)? CPack is part of CMake.
I love that there's always something new to learn. I never get bored -- well, OK I get bored, but not with the language.
Emacs
What would be the one for a Linux user?
This belongs in /r/cpp_questions.
Virtual inheritance is mainly a personal preference for me. My coding style tends towards using composition more than anything.
You can use travis ci to have your builds and tests run on a os x instance
No, but including Boost in your application sure is.
To be honest, I miss writing C code, but it feels like C in the world of Windows has been left behind, I am constantly having to learn new C++ features, and while I enjoy the learning, it is very overwhelming and a bit confusing when I look at someone's source repository and see a bunch of crazy looking C++ code, I am the type of person who learns by doing or taking things apart to see how they work, so when I come across some fancy C++ code, I feel stupid. Never felt that way with C and later Lua. I write C++ instead of C because I am using MSVC and I may as well.
In C++11 they changed the lexer and added an exception for &gt;&gt; so you don't need the space in nested template type names, e.g.: std::vector&lt;std::map&lt;int, int&gt;&gt;
Yes, C++ lexing and parsing is already a complicated story. In fact, I [once asked](http://stackoverflow.com/questions/13634548/must-always-be-interpreted-as-an-operator#comment18702793_13634679) about that for this situation. The reality is that no one would want to do this anyway, but everyone wanted `&gt;&gt;` to work.
About the metaprogramming: I find macros kind of weird. I think templates in D and C++ are, without being easier, easy to understand. Because it is part of the type system as such. I think it flows better as a natural extension to the way we are used to code, at least since C++11. Macros in rust look like something apart. Metaprogramming in D, is, definitely, ahead of anything I have seen before. A note about lisp: metaprogramming is possible, but I think Lisp being homoiconic makes it difficult for a human to read. With macros everything is possible. But I think that metaprogramming the way you see in C++ and D are much more sane. Nim and Rust took kind of the Lisp road.
99% of the time all I need to do to link C++ libraries is make sure the the .a or .lib is in my library path, and the .h is in my include path. But it was definitely confusing when I started using it.
Yes, the big thing is when you start working with others and reading other code that you have expectations. As was mentioned below, if you just send a value to a function, you do not expect it to get modified. Hence why we use: void foo( const int &amp; bar ) {...} Because if some asshat coded: void bug( int &amp; bar ) { bar += 1; } You would be pretty pissed off and not know how to find the bug when you call that method just from looking at your own code. Whereas if the input to the method is a pointer, one would check to see whether that value gets modified or not inside the method. It's more about making sure you're doing things in a predictable way and allows you to predict what other people's code is doing.
Ok, that counts as not using raw pointers for ownership. There's a proposal `observer_ptr` for that use case.
Just take a look at Java's implementation of the Observable pattern. To be an observer, you have to extend Java's `Observer` class (so that `Observable` classes can add your objects to their lists of observers). But, if you have a class which already extends a base class, how do you also extend `Observer` when only single inheritance is allowed? "Easy"! You define another class which composes your class and extends `Observer`. Now you'll need to make sure every instance of the original class is updated to an instance of the "mixin" class. Luckily you're writing Java, so you're probably using the Factory pattern everywhere anyway (pedantically in case of things like this), so at least that shouldn't be too painful... right?
I mean: while (cond) { try { … } catch (…) { … } } It acts the same way as: while (cond) try { … } catch (…) { … } The difference is that the first is more familiar to everyone and looks less like a special case in the language. That said, the second is not a special case in the language like a function try block is - it's simply a `while` loop whose statement is not a compound statement. I could see the first being used just like any other exception handler, but function try blocks are not common at all. You'll probably see more uses that wrap the entire function body rather than use the special syntax. 
Generics in Rust are for containers of Ts. I recall there was not even partial specialization if I am not wrong. You cannot compute types then. That is my understanding.
Is the linked P0025R0 the version of std::clamp() that was voted into the standard? The wording is underspecified for NaNs and the example code gives std::clamp(NaN, 0, 1) -&gt; NaN. :( 
I never interviewed anybody, if that's what you were asking. I wish I had the chance to do the same to my interviewers and let them feel the joy of being evaluated by an asshole. Not any one of them, some did it professionally and politely. But most were just bored hateful dicks.
&gt; creating real-time *nix-based systems and pushing them to production for 8 years Wow, that's impressive! I think I wouldn't even be able to validate one in that timeframe. And that of course assuming I specialized in OS programming instead of GPU stuff!
The project I'm on takes an hour to build, on a Mac Pro. Not everything is as small as Boost...
I encourage you to watch Andrei Alexandrescus talk about error handling in C++ at https://vimeo.com/97329153. It might change your view on this.
yeah... no. I wouldn't call a callback wrapper "signals" and "slots". There's no event loop, no thread safety...
Actually, they meant to vote in R1 but actually voted in R0. That's why we have [LWG2688](http://wg21.link/LWG2688) :)
One of the basic features of signals is that you can connect multiple slots to one signal. And when the signal is emmited then ALL slots are invoked. The method "connect" should be called "bind". You implemented functor. Like std::function and not signal.
This is why although I enjoy using C++ (since Turbo C++ 1.0), I rather work with other languages at my current employer. At the enterprise level, 2016 code still looks like 1995.
RAII is also manual resource management to some extent. You need to have handle classes allocated on the stack, structure/class fields and global memory to handle RAII, while having to deal with circular dependencies. Also implement them if they don't handle the resource you need to manage. No different than making use of macros or higher order functions / trailing lambdas to handle resource management in FP languages.
Ok. Writing portable ( in term of compiler and system ), is easy. First step is choosing the feature set you want to have, you will need to have a define a minimum compiler version for your compilers. VS 2015 is a must if you want almost all of c+11. Don't use features not available in every compiler you choose to support. * Use a cross platform build system * Have macros to detect each os / compiler. there are existing headers for that. * Use cross platform libraries. If a library is not cross platform, don't use it. * You will have platform specific code at some point. What you do is have a cross platform header and an implementation for each platform. There multiple way to do that. The simplest one is to have a singe header and multiple source files. File.h, File_win32.cpp, File_posix.cpp, etc * Avoid mixing system-level code with the logic of your program. * If at all possible, have a CI run on your code before it's committed to the repo. Untested code is broken code. You will find that the initial setup is a bit tedious. But once you will start to have a proper build system and a properly architected code, portability will comme for free. If you don't do that, and try to port your code after the project is done, you will be in a world of pain. 
 There is no easy solution in C++ to this problem
here is my project if you are interested : https://github.com/OSSIA/i-score/blob/master/.travis.yml Basically, in your .travis.yml : os: - osx osx_image: xcode7.2 # there are some new ones I think And then there is : - a shell script to install the dependencies via apt or homebrew : https://github.com/OSSIA/i-score/blob/master/tools/travis/deps.sh (But I cached the homebrew one because it was taking way too much time) - a shell script to do the build : https://github.com/OSSIA/i-score/blob/master/tools/travis/build.sh This one runs the build with a configuration given in the .travis.yml The configurations I made are here : https://github.com/OSSIA/i-score/tree/master/tools/travis/configs but maybe you don't need something that heavy :)
Exactly. And without MacOS machine it's really hard to know everything necessary to set it up correctly. If you'd be able to make simple OpenGL + GLFW/GLEW/SFML/SDL setup on Travis, i'd love to see it's config files. :)
&gt; I don't understand why so many languages throw away the safety of static typing. Well, there's actually a simple answer: For cases where initial development speed is more important than correctness.
TIL. But IMO it should have had a comma from the beginning - unless, do you have a good reason why the comma should be optional?
Also make a PKGBUILD for Arch Linux and port said PKGBUILD to MSYS2 and then make a pull request to MSYS2.
This is an example of Signals/Slots in C++11, Apache 2 license, so feel free to re-use it: https://github.com/gpac/signals/tree/master/src/lib_signals https://github.com/gpac/signals/tree/master/src/tests Thread-safe, executed in an "Executor", several way to store results.
Well, macros are not higyenic in Lisp, so that is a double-edged sword, but templates are still regular types, instantiations, etc. It is C macros what could be really surprising. Also macros can capture "by reference". FWIW, Lisp is sooo regular, so, so regular, that it is even difficult to read because when your eyes scan it they cannot figure out what they are looking at. That is another double-edged sword: adapt it as much as you want, at the expense of noone understanding anything. I must say I really like the Lisp idea, one of the best I have seen. But in practice, you end up writing code that is socially useless, because not many people can work on it. 
I notice that YouTube says "Category Comedy". I'm not sure whether the author intended that classification to be appropriate or not....
Nice documentation...
It is unlikely not to get an asshole after a day interviewing other people, being stressed the hell out by a corporation and having to nail 5 interviews out of 5. Probability of getting one is too high. And it's unfair to spoil all my work and skills just because he's a dick.
I actually don't get why it's a bad idea, I'm not fighting with you I'm just plain curious why. Could you please explain what's wrong with a document to waiver your legal actions if you're arbitrarily discriminated? Afterall they have the power to decide, it's not like they're obliged to hire me by the law.
Because it allows the organization in a position of power (the employer) to exploit someone by making them preemptively give up their rights.
I would accept if the clause was: "we will share feedback with you". If they give me a laconic &gt; No, because you're black I would share it with the world and it wouldn't be pretty although I can't sue them.
When might you see the following? template&lt;&gt; template&lt;&gt; template&lt;typename T&gt; When you have a stutter and only the third attempt produces the desired code line.
&gt; When is a function try block useful? When you want to confuse your co-workers and assert your dominance in the workplace.
Haha. You tricked me.
Nice
It seems that there is no proposal about making the standard library benefit from template argument deduction for class templates. 
Looking at this one: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0330r0.pdf for a proposed size_t suffix, I don't feel that their examples are that convincing, and I'm left thinking that if you're in a situation where you have to fill an auto variable with a size_t constant, just declare the variable size_t. That is, auto x = 0uz; doesn't save you any actual effort over size_t x = 0;
I wouldn't call that "lots". I'd call that a good start. Keyboard shortcuts (consistent with native OS behaviour) are an integral part of a good UI experience.
You're mentioning at the beginning that someone suggested Bob Nystrom as guest! Definitely get him please! I would be looking forward to that podcast :-) His (or one of his) page: http://gameprogrammingpatterns.com/
so is there a toolchain to use with CMake for this ?
Paging /u/munificent !
I found myself using this frequently when I have one line unit tests of functions with arguments that take size_t with conversion warnings on. 
I just didn't get to it yet. But I'm actually in the process of porting it and it's going much better than I anticipated. I already have the examples and some benchmarks running on Windows. Edit: one thing that may become an issue is that Visual C++ has no 80-bit long double, which may put a significant dent on the double-to-string conversion quality.
I find [this paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0376r0.html) by Matt Calabrese very interesting. Accessing `std::tuple` elements via run-time values, thanks to the creation of a `constexpr` function pointer array is quite astonishing.
The platform toolset name is still 3.7, as is the installation folder. To verify you have the latest installation, check the version of c2.dll directly (19.0.25317.0).
My coworker is responsible for keeping this up to date and mentioned that even members of the committee aren't familiar with it! The purpose of it is to maintain the master list of Feature Tests for the proposal for C++17, however the C++17/C++14/C++11 features list (and before) would likely be very useful to many people as well! 
And preferable as build-in, because writing `using namespace std::integer_literals` sucks, runtime-errors for overflows in literals suck and there is no danger of any collision with user-defined types, as all UDLs outside of the stdlib are required to start with an underscore.
Oh, the break; there will be break out from the for-loop? Of course. Makes sense. Cunning.
&gt; `DllGetC2Telemetry()` That sounds like Microsoft...
Nope, not yet. We've been investigating integrating CMake better with VS but don't have anything to report yet. 
The platform toolset name still reads as 3.7. We had interaction issues between the update feed and the VS host. That in part is why we're removing the version number from the platform toolset name. /u/Ameisen, can you send a repro for the internal compiler error you're seeing? 
I always love reading these when they come out. Just a few miscellaneous observations and questions after a quick skim of a number of them: Does anyone have a feeling for how Howard Hinnant's date/time proposal [P0355R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0355r0.html) compares to Google's earlier CCTZ-based proposals [P0215R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0215r0.html), [P0216R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0216r0.html) ? Regarding [P0372R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0372r0.html), the UTF8 type, I can only say that this would be unspeakably awesome for cross-platform development if u8string etc. were to be implemented correctly on all platforms. Similarly for [P0353R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0353r0.html) that would make it very easy to follow the goals of [UTF8 everywhere](http://utf8everywhere.org). The latest proposal for destructive move, recasting it in terms of "relocators", also sounds very neat: [P0023R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0023r0.pdf)
libstdc++ maintains a [status page](https://gcc.gnu.org/onlinedocs/gcc-6.1.0/libstdc++/manual/manual/status.html). libc++ also maintains a [status table](http://libcxx.llvm.org/cxx1z_status.html). And I regularly publish [tables for VC](https://blogs.msdn.microsoft.com/vcblog/2016/01/22/vs-2015-update-2s-stl-is-c17-so-far-feature-complete/) on VCBlog. (MSDN later imports this info.)
http://libcxx.llvm.org/cxx1y_status.html http://libcxx.llvm.org/cxx1z_status.html But I have no idea where C++11 is or why they are not on the same page.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well the specific things Rust wanted to achieve required a different syntax. If they would have made everything look C-style: a) people would not realize that they needed to think very differently, and b) some functionality simply wouldn't be possible.
Is "deobfuscator" your second name?
Where is libstdc++'s page? The only one I've been able to find [just lists what's in trunk](https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html), and not what version things were added in.
The libstdc++ status page is part of the manual. Go to [the online documentation](https://gcc.gnu.org/onlinedocs/) and click on "Standard C++ Library Manual" for the version you care about, and then click on status. There's also an [API evolution section](https://gcc.gnu.org/onlinedocs/libstdc++/manual/api.html) in each version of the manual. 
I'm a bit surprised by Jonathan's claim that `&amp;s[0]` is invalid for an empty `std::string` `s`. It's perfectly valid.
I like the template class deduction proposal and dot operator, but I do not see anywhere the implicit non-type parameter deduction, which I think could be in next standard: http://open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3601.html I recall that I read somewhere that implicit non-type parameter deduction would be discussed. Is this still the case?
That's just the nearest exported symbol in the module. Any time you see entries in a call stack with huge offsets from the function name, it's usually a bogus decode due to missing symbols. 
&gt; Is this desire to write portable C++ code naive? Impossible? Too limiting or costly? Am I (and should I be) pushing the responsibility onto the libraries that I choose/use? It's definitely a good thing to try at least, but you will quickly learn that writing a completely portable code is increasing the cost greatly or even impossible in some circumstances. So you will find some healthy balance in that. And it looks like you already did.
Well, it's a TS for now. So hopefully VS and clang support the TS soon (GCC already does) so people can play with it and refine the specification so it can make it into the language sooner.
As a counterpoint, try watching the first ten minutes of [this Andrei Alexandrescu talk](https://www.youtube.com/watch?v=AxnotgLql0k). 
/u/xon_xoff, intrinsics are a weak spot. There's a lot of one-off work there--implementing each intrinsic has to be done individually. (OK, not quite, but close.) And yes, Clang is a nice lever to help get headers to become more standards-conformant. 
/u/Ameisen I expected that was the case. Thanks anyway!
Pretty snazzy! Thanks for posting this.
The C1XX compiler devs are working on conformance, modules, and coroutines. While we're very interested in concepts, you shouldn't expect to see them in MSVC soon. Can't do everything at once.
hire more devs :-)
I'm glad you find the paper interesting :) I've got a draft of a revision in the works that changes the return type deduction mechanism a little and makes it a bit simpler to use... and also more powerful (it needed updating to cover a specific kind of return type deducer that may end up being commonly used if the facility were to be adopted). I'm working on releasing the code so that I can upload my implementation somewhere. If/when that happens, I'd like to get it into the boost review queue so that a wider audience has a chance to play around with it. The proposal needs some work still and the library needs more user experience. I only submitted the paper in its current state to get the committee's eyes on the core functionality as early as possible.
Fyi I am not thinking of "better ways" I think this IS the better way already. It's a really simple and flexible system. I don't see the problem with it. You can push indices/ptr/string into the id-stack and once you understand how it works I don't see a blocking problem with it. Add to your list the ### operator to create an idea independent of the label. What could be improved is to provide a visual report of id collision when they happen, but they are trivial to solve (more so if you have Edit&amp;Continue or similar tech active, I personally add lots of tooling within running processes).
I'm not sure why you think p0376r0 is a step toward a "more generic addition operator" with an overload for tuples. The direction it pushes for is the opposite. The idea of `std::call` is that you wouldn't need your "more generic addition operator" because you'd just invoke your add function using `std::call` and `unpack` (you already don't need your specific example because of `std::apply`). One of the motivations of `std::call` is that we wouldn't have to keep introducing things like `std::apply` and `std::visit` to the standard. Instead it tackles the issue more directly: how to call any existing function with an argument list that just happens to be partially generated through any arbitrary means (whether it be tuple unpacking, variant access, tuple access, or some user-created form of generation).
So we can't really know what will be added until it's officially added. Before its just a draft / proposition am I right ?
Nothing can be added if it hasn't been proposed. Anything that's proposed may or may not be voted in. Anything that's voted in is *very likely* to ship in the next International Standard, but it's possible for something to be reverted (happened to old concepts, optional the first time, and dynarray).
Wikipedia generally has a great summary. https://en.wikipedia.org/wiki/C%2B%2B17 C++17 is a dull minor version, nothing to see, sorry. Come back in 2019. Hopefully. 
**[C++17](https://en.wikipedia.org/wiki/C%2B%2B17)** --- &gt;C++17 (also called C++1z) is the informal name for the future revision of the C++ ISO/IEC standard. The specification for the C++17 revision is under development and "nearly feature-complete" to be finished in 2017. --- ^I ^am ^a ^bot. ^Please ^contact ^[/u/GregMartinez](https://www.reddit.com/user/GregMartinez) ^with ^any ^questions ^or ^feedback.
Hmm... I have a personal project that while large, I may be able to send a branch to MS. It is also failing with an internal compiler error.
I have an online textbook from my c++ class, tell me the general bits you know and i'll find some good practice. If you want something completely new to code, look at all the software and see if there is anything that would make it better and code that, you probably won't be able to publish it in c++, but you can use it yourself.
I know how to use ifs, arrays, functions, classes, basic cout and cin getline stuff, im still iffy on using and creating functions, i can do variables well as well, and can do randomness and switch statements. Edit: for loops and while Loops as well
Okay, so what I'm about to say will only make sense if you live in a country that has both paper and coin money, I live in america so I'll just use those names of coins, if you live somewhere else you can look up the price of each of them. So write a program for a "change" algorithm. It takes in the TOTAL amount of money you are putting in (Make sure it can go down to the lowest cent) and have it output the different ways it could dispense your change. Say if you entered '$15.34' it would output the following '$10 bill?' then you say if you would like the ten dollar bill, or if it should go to a lower amount then it might say '$5 bills?' and if you said yes or something like that, it would output the following lines $5: 3 $1: 0 25¢: 1 10¢: 0 5¢: 1 1¢: 4 (sorry for the long post) 
I'm not sure what you're asking for. A span&lt;&gt; which only supports compile-time sizes is a view of an array&lt;&gt;. span&lt;&gt; is intended to support dynamically-sized arrays, too. EDIT: Correctness
Proposed, with an active TS.
You won't be too harsh on me for an insane and very unclean codebase? :D
question from someone very out of the loop: Is the current standard for lock-free concurrency to use atomics? If so, at the end of the day, do these atomics become locks under the hood, and the user simply never has to see them in code, and therefore avoid mental overhead? Are these atomics supported all the way down to hardware (I think modern CPUs have support for atomic operations in the assembly they run?) Or does the actual "atomic-ness" get enforced at compile time? Thanks, these were all just questions from the curious.
Why was optional reverted? (Alternatively, where can I look up the answer to questions like these?)
Insane and unclean...like parts of Windows? 😛 
Is it best to send a 7z or a repo link
I will be messaging you on [**2016-06-08 04:33:12 UTC**](http://www.wolframalpha.com/input/?i=2016-06-08 04:33:12 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/4mkpjb/practical_lockfree_concurrency_in_c_part_2_fedor/d3wicpz) [**CLICK THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/4mkpjb/practical_lockfree_concurrency_in_c_part_2_fedor/d3wicpz]%0A%0ARemindMe! 3 days ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d3widay) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I vaguely recall that it was concerns over comparisons. It'd be in the non-public minutes (and any trip reports at the time).
On any normal platform (x86, x64, ARM32, ARM64), 1/2/4/8 byte operations are supported by the hardware, without spinlocking.
Nothing to see there, just "Sign in to Register". Why link an article/webcast with mandatory registration?
ANSI C never permitted the comma to be omitted. Are you sure that the C++-specific syntax is older, and not just a CFront quirk?
&gt; What is the type `char(*(*s::*(*[3]))(int))[2]`? Find where to put the variable name, start from the innermost parenthesis and read right-to-left ( * VAR [3] ) (* s::* ( 2 1 )) (* (4 3 ) (int)) char (6 5 ) [2] 8 7 VAR is: 1. An array of 3 2. Pointers to 3. Member pointers of s 4. That return pointers 5. To functions taking an int 6. That return a pointer 7. To an array of 2 8. Chars struct s{}; using X=char(*(*s::*(*[3]))(int))[2]; using A=char ; using B=A [2]; using C=B * ; using D=C (* )(int) ; using E=D ( s::* ) ; using F=E * ; using G=F [3] ; static_assert(std::is_same&lt;X, G&gt;::value, "err");
If it's huge, a repo is probably best. But we can work with anything. 
1. You can disable .ini saving by NULL the IniFilename field in ImGuiIO. You haven't clarified what "screwing things up in the tool" means. 2. Don't remember that specific bug but yeah, it's posible. 3. You can only go off min-max when text inputing a value with the keyboard, which is intentional because it is more flexible. Ideally the option should be provided. 4. I don't understand this "button flags/retained" ? There's no button flags exposed in the public api. I'm not sure what you are talking about. 5. That would also needs to be clarified through a repro but most likely there's something you didn't understand about the ID-stack at the time. The ID-stack system work is a really simple and rather documented way. 
Remind me that you exist.
And a separate question - do people actually use C++ for competitive programming? My C++ is my best language, but if I had hard time constraints for writing the code, I'd pick a scripting language like, say, Python, with a huge library built-in and no compilation phase. (This article is educational even if no one ever does this... I'm just curious!)
So I was at a competition. They had run time constraints and all. My python implementation timed out, and was correct according to the post-competition walkthrough. During it, they even mentioned that you could brute force the task if you used c++. So yes, it matters. 
Yes, it's a typo. I fixed it. Thanks!
Seems like a decent question but one problem is implementing a smart pointer is full of tiny minutia that even the author gets wrong. For example the copy constructor and assignment operators both exhibit undefined behavior if other.m_ReferenceCount is `nullptr`. There's no need for a virtual destructor, there's no need to set the objects to `nullptr` after doing the delete in the destructor.
Andrezj made a blog post about this issue some time ago that is quite readable: https://akrzemi1.wordpress.com/2014/12/02/a-gotcha-with-optional/ IMO if this is what they were concerned about then I'm glad they decided to wait on this -- this is a subtle and potentially very annoying problem, and honestly I kind of expected the standards committee to just ignore it. If they decide to make it so that optional are not comparable by default, in order to avoid this issue, I think they will have done the right thing and done everyone a favor.
Well in competitive programming context, there won't be utf-8 characters. Implementing utf-8 handling isn't really a fun challenge.
It's broken in UTF-8, but that's not the point. It only wants to know if the string is a palindrome *as a byte sequence*, independent of the encoding.
Even the most perfect knowledge about C++ does not make a good software developer. We had someone in our company that had good C++ knowledge, but everything he touched turned out to be broken. Even a 1.5 years later we are fixing bugs that his bad attitude about refactoring and handling of the legacy codebase introduced. You can clearly see his good intentions, but he was not diligent enough to keep all important features working. My idea about an interview question involved a small C++ project/example code with bad code in it. So we can talk about ways to improve the code and refactor it. These skills are more important to me than knowledge about C++ template meta programming or implementing smart pointers (implementing a smart pointer and failing is a great exercise and lecture however - so you know what to look out for when using the standard library implementations of them).
I have written a plugin for C++ autocompletion because I could not find anything simple to setup and that works out of the box. This is essentially what I pursue. Please tell me if you think there is a way to improve it (open an issue). Please don't be silent about your critics! Tell me where I should improve or why you don't care about this plugin. Critics makes the world better! Thanks and I am open to discussion!
I've been using it a couple of days. I appreciate the seamless installation and use. Thanks, good work. 
Thanks! It's always cool to get positive feedback! Hope you will keep liking and using it :)
Yes, because we all know the way that adding devs to a project magically increases its velocity. [The Mythical Man Month](https://en.wikipedia.org/wiki/The_Mythical_Man-Month).
Aren't those tiny minutia what makes this such a good question? For a junior developer, you have what the author has supplied. It shows a reasonable understanding of the topics that he mentioned. If you were hiring someone who claimed to be experienced in multi-threaded programming, you'd expect them to straight away have a thread safe refcount (or allow compile time switching between an atomic counter and non atomic counter). 
&gt; there's no such thing as “the stack” or “the heap” in C++ Can you explain this further or provide a link that explains what you're getting at?
I would say your efforts would be better focused developing a better user experience for using an existing completion engine with sublime text. For example rtags or ycmd. Both of those support build system generated compilation databases that make sure include paths and defines are properly setup for every file automatically. Both already have plugins for sublime text and they are popular in other editors, which gives them and edge on supporting all the edge cases, of which there are many, in this space.
Yes, this is a valid point and this is what I was thinking about right from the start. However, the monsters like `ycmd` or `rtags` are quite huge. It is hard to tweak their setup (at least for me) and I really wanted to produce something that would be working out of the box. Originally I wanted to have the user doing exactly one thing: installing clang. `ycmd` has this file `.ycm_extra_config.py` that is from my opinion hard to parse for a human and causes lots of confusion with the users (check out their issues). `rtags` also has a compex setup process that I never could finish on my own. I may have missed something somewhere but that is exactly the point. I wanted an out of the box experience. For now it is far from it. Actually, the user needs to configure include paths for the plugin. I really want to get rid of this. This is a complex problem, but I think it is solvable. It depends on the build systems that users are using and knowing those I could generate include directories automatically (to some degree). At least for system-wide includes like boost, pcl and so on. Also the project itself gives some info. We could include all subfolders or the ones that have "include" in them. This costs nothing for compilation times and should enable out of the box completions for projects. I don't know how to easily achieve this in any other plugin that is already out there, so I ended up writing my own.
I'm not used to the functional annotation. Could you explain by example? map_contains : (Map a b, a) -&gt; Bool Checks if a map contains a key. What does the `(Map a b, a)` mean? Does it take two maps? Or just one? 
Hmm. Is there a way to diagnose problems with clang? I have clang installed, I installed this plugin and here is what I've got: While typing: #include &lt;ve selected completion proposal 'vector', and got this: #include &lt;std::vector&lt;char&gt; v; While typing: std::ve selected completion proposal and got this: std::std::vector&lt;char&gt; v; Also, methods for vector aren't showing up. Ah. There is an error in console: Traceback (most recent call last): File "C:\Soft\Sublime Text 3\sublime_plugin.py", line 333, in on_activated_async callback.on_activated_async(v) File "C:\Soft\Sublime Text 3\Data\Packages\EasyClangComplete\EasyClangComplete.py", line 97, in on_activated_async file_parent_folder=parent_folder) File "C:\Soft\Sublime Text 3\Data\Packages\EasyClangComplete\plugin\plugin_settings.py", line 242, in populate_include_dirs "(\$project_base_path)", self.project_base_folder, include_dir) File "./python3.3/re.py", line 170, in sub File "./python3.3/re.py", line 309, in _subx File "./python3.3/re.py", line 296, in _compile_repl File "./python3.3/sre_parse.py", line 801, in parse_template sre_constants.error: missing group name 
This is Haskell syntax, where they are trying to saven on parens. "Map a b" ist "Map(a, b)" and (a, b) is a tuple. So it takes a Map with Keys 'a' and values 'b' and a Key 'a', to tell you if there is something in the map for 'a'. - I assume, since they always use f***ing one letter variable names, "because types are documentation", or some such....
How does this compare with Paul Fultz II's [ClangComplete](https://github.com/pfultz2/ClangComplete)?
`Map a b` stands for one map with key type `a` and value type `b`. `a` and `b` are free type variables. That means `map_contains ` works for any key and value types. So `(Map a b, a) -&gt; Bool` is compatible to i.a. all of the following: (Map a b, a) -&gt; Bool (Map x y, x) -&gt; Bool (Map Int Float, Int) -&gt; Bool (std::map&lt;x, y&gt;, x) -&gt; bool (std::map&lt;int, float&gt;, int) -&gt; bool (std::map&lt;string, string&gt;, string) -&gt; bool Edit: The annotated type signatures for `std::map` functions are now changed to more descriptive type variable names like so: map_contains : (Map key val, key) -&gt; Bool
Thanks. That makes sense :)
range-v3 and FunctionalPlus do have some overlap, e.g. `view::intersperse` and `fplus::intersperse` basically do the same thing. But ranges are more like a "view" into a container, saving memory. `fplus::get_range : (Int, Int, [a]) -&gt; [a]` as an example however stupidly copies the requested part of the container. On the other hand FunctionalPlus provides many functions, Range v3 does not. Some examples are: fplus::maximum_on : ((a -&gt; b), [a]) -&gt; a fplus::group_globally : [a] -&gt; [[a]] fplus::cyclic_shortest_difference : Float -&gt; ((Float, Float) -&gt; Float) fplus::compose : ((a -&gt; b), (b -&gt; c)) -&gt; (a -&gt; c) fplus::count : (a, [a]) -&gt; Int fplus::all_the_same : [a] -&gt; Bool etc. So which one to use depends on your needs in the particular use case. One could always simply use both libraries in one project.
Mine is in Package Control :) To be serious, the only notable difference apart from possible subtle interface differences is that it needs to be compiled. I wanted to avoid it. It also seems to be abandoned, and I wanted something running and being able to fix it when needed. I hope I will have the power to not abandon this plugin at least until it is working for 99% of people.
&gt; Therefore Qt 5.7 requires C++11 support from the compiler, and has removed support from older compilers not providing adequate C++11 support. Finally! This is huge news. Finally, the project can get rid of so much cruft. &gt; Qt Quick Controls 2 I would love to hear the reasoning behind this. Was Controls 1 not good enough? Is Controls 2 an alternative, or a successor? The APIs are not compatible. What's the recommendation, best practice? Should Controls 1 no longer be used? Or is Controls 1 more for desktop and Controls 2 for Mobile/Embedded? Doesn't really make sense either.
&gt; I'm not sure why it is used here, though, since the data types in the library are not curried. Simply because it looks nicer to me and does not make much difference otherwise, since only types (i.e. fully applied type constructors of kind `*`, as opposed to `* -&gt; *` etc.) are used. If one prefers, one can still enter query types C++-style, for example `(std::map&lt;a, b&gt;, a) -&gt; bool` and will find `map_contains` nonetheless.
astyle may be ok, but clang-format it is at least worth mentioning as well. Personally, I don't see the point of anything (astyle, uncrustify) besides clang-format. Since I use clang-format, I just don't care about formatting, the tool does it for me, and it integrates really well (vim, QtCreator, ...). 
Controls1 was ported from Qt4 and is backed by a style plugin that wraps QStyle + QPainter to draw for the Quick components. Due to historical reasons you could only have one "Style" per application without incurring a large performance penalty. Controls2 works around this and abstracts the styles further from the old QStyle API backend. While the API is not directly compatible, its very very similar if you're using QtQuick.
You can read about the new controls here: http://blog.qt.io/blog/2015/03/31/qt-quick-controls-for-embedded/ http://blog.qt.io/blog/2015/11/23/qt-quick-controls-re-engineered-status-update/
Just a note about Google style - Google doesn't hate exceptions (source: I wrote C++ there for five years). Craig Silverstein who originally wrote the guidelines was quite open about the fact that if they were writing them today, they'd use exceptions everywhere! No, the issue was that when they first started going, exceptions in C++ were poorly supported on the first compiler they used, and by the time they got a compiler that did a good job on them, there were literally hundreds of thousands of lines of exception-unsafe code. Please remember also that their style guidelines are made for very large codebases and teams of people with very disparate C++ skills. Once you understand that, some of the weird rules (like the rules against overloading and default parameters) make much more sense. For example, if you can potentially get symbols from millions of lines of code, you really want to make sure that you are linking to the right function and not someone else's overload or some unexpected default parameter fill-in.
Yeah, it can be hard for people to appreciate the maintenance cost/inertial of massive codebases. I'm in a 3 million line codebase that began over 25 years ago. Its actively developed by 20 engineers. Our target platforms have only supported exceptions for 5 years. We have some use in new code but we can't allow exceptions to propagate through 95% of the systems. I'll be shocked if we're at a point where the majority of our code is exception safe within 5 years. Our scale is bad enough. I can't imagine what it is like at places like Google. 
My main criticism of the question is that it's hard to call an interview question perfect when the person asking the question doesn't have a solid grasp of the solution, because then it's simply arbitrary. This question is so full of minutia that it's hard for the interviewer to actually assess whether the candidate did a good job or not. For example if you're asking this question to someone and they answered it the way that the author did, how would you assess that person? The author clearly thinks this solution is acceptable and shows a good understanding of C++. I, however, would think it's a fairly poor answer containing multiple bugs (undefined behavior as well as a memory leak) and a poor API (lack of `noexcept` and `const` on certain member functions along with virtual destructor). The minutia needed to implement a comprehensive and complete smart pointer is so fine grained and nit-picky that evaluating someone on it is going to, in all likelihood, end up being fairly arbitrary unless the candidate ends up implementing a flawless smart pointer just like `std::shared_ptr&lt;T&gt;`, but at that point this is no longer a good interview question and implementing `std::shared_ptr&lt;T&gt;` is suprisingly difficult. Maybe one interviewer values thread-safety a great deal and arbitrarily emphasizes that, another values coding conventions/API, another values strict correctness and no undefined behavior. The solution put forth by the author lacks all of these things to one degree or another and if the interviewer themselves can't properly tackle this interview question, how is anyone else to objectively evaluate someone who writes up a solution to this question which isn't perfect in every single way?
Looks like a very useful library, thanks! Would you be open to submitting to https://conan.io ? 
It seems to me that this does far more to show Robert C. Martin's prejudices/thinking than much of anything about the code. In particular, his metrics place a strong emphasis on inheritance from abstract classes/implementation of interfaces as the way to separate interfaces from implementations. That fits well with (for only one obvious example) Java (which is how Robert C. Martin's been spending most of his time for years now) but quite poorly with C++, where inheritance tends to be used much more sparingly, and other techniques are used to separate interfaces from implementations. The article does point toward part of this: templates basically deal with their parameters via Concepts. C++ doesn't (yet) provide a way for a programmer to directly express and name the Concept required by a particular template, but the Concept (i.e., the interface required by the template) exists nonetheless. For better or worse, without a way to express concepts directly in the language, it's essentially impossible to measure them via any sort of automatically extracted code metrics.
The main issue with clang-format over the alternatives has always seemed to me to be its lack of good preprocessor formatting - at the moment I believe it just flattens all preprocessor usage to the current indentation level. You can just turn off clang-format for preprocessor heavy sections, but that kind of defeats the point of automated formatting in the first place (unless there's a better way of handling preprocessor stuff, in which case I'd very much like to know).
&gt; Android: Qt can now be used to easily create Android Services. Finally!!! Was waiting for this one so i can port my project properly.
Wow, then this is huge. In Controls1 you had to invent your own styling system. I work with Qt, but haven't paid attention and somehowe missed that this thing is being developed...
Yeah, that's what I meant by turning off the auto formatting. I was basically just referring to the ifdef hierarchies which can get pretty hard to read when flattened. I agree that clang-format beats the alternatives. I've always felt like most C++ auto-formatting tools have almost *too* many options, so being able to just pick a template (like LLVM or Google) and modify it helps a lot. It really shouldn't be such a load off of my mind when I don't have to manually format stuff (since it's so unimportant) but it really is, and the added of bonus of clang-format coming with a quality compiler suite really lowers the entry barrier. Just put a commit-hook/script and a .clang-format in project root and \*Bam\* no more style arguments... Well, besides naming anyway...
Searching for `(Map keyType valueType, keyType) -&gt; Bool` will also bring you to `map_contains`. ;-) Since most users probably know that std::map always takes its key type as first parameter and value type as second parameter and thus do not depend on this redundant information, I prefer to stick to the already established format of function signature notation.
i believe it's `conan export` from [here](http://docs.conan.io/en/latest/packaging/creating_in.html)
Ah OK, so simply export again. Cool. I thought it perhaps could automatically sync from the github repo. I will have a deeper look into conan.
I hope conan becomes popular, it's something c++ really needs.
I just used `/usr/bin/time -v` to verify the assumption about the memory footprint advantage, and was unable to verify it. The following three examples were compiled with clang++-3.6 -O3 -std=c++11 -Wall -Wextra -pedantic -Werror -pthread per value: https://gist.github.com/Dobiasd/7de58bc5644998602e2e7b2d365fcfda Maximum resident set size (kbytes): 1308516 per const reference: https://gist.github.com/Dobiasd/4749cd616937d338d4cfc5f74a029a45 Maximum resident set size (kbytes): 917720 per value using std::move https://gist.github.com/Dobiasd/dcd5f8df2794d0e9e41cc9306e46931b Maximum resident set size (kbytes): 917788 So it looks like there is no need for the proposed optimization. The compiler seems to do something similar on its own, at least in this very simple example.
It would require a slight rework - you'd have to use the xs vector using something like remove_if.
Is resizing still super laggy? All QtQuick apps I ever used were super choppy when resizing them.
Company: Akuna Capital Type: full-time Position descriptions: Click on link for full description [C++ Developer-Chicago or Champaign, IL](http://www.akunacapital.com/job-details?gh_jid=86052&amp;gh_src) [C++ Developer-Data &amp; Measurement Team-Champaign, IL](http://www.akunacapital.com/job-details?gh_jid=80356&amp;gh_src=) [C++ Developer-Gateways-Chicago or Champaign, IL](http://www.akunacapital.com/job-details?gh_jid=86058&amp;gh_src=) [C++ Developer-Infrastructure Team-Chicago or Champaign, IL](http://www.akunacapital.com/job-details?gh_jid=65800&amp;gh_src=) [C++ Developer-Trading Core-Chicago or Champaign, IL](http://www.akunacapital.com/job-details?gh_jid=86067&amp;gh_src=) [C++ Developer-Trading Strategies-Chicago or Champaign, IL](http://www.akunacapital.com/job-details?gh_jid=86061&amp;gh_src=) [C++ Developer-Shanghai](http://www.akunacapital.com/job-details?gh_jid=39363&amp;gh_src=) Location: In each position description link We have offices in: Chicago-Champaign,IL-Cambridge, MA-Shanghai Remote: No Visa sponsorship: Yes Miscellaneous: www.akunacapital.com 
I read this, and got crossed-eyes as a result. Abstracting is all well and good, but abstracting too far also brings you far into the realm of pain. Look at Windowing systems as an example. Sooner or later you need a native handle and have to delve into platform specific crap because the abstraction broke. 
You are right. It works. https://gist.github.com/Dobiasd/ad8abbff994a70cd8d3ad72942118088 Maximum resident set size (kbytes): 391700 Nice idea, I'm currently thinking about how to use it. :)
"the C++ projects" sounds like the place poor c++ code lives :(
&gt; To be serious, the only notable difference apart from possible subtle interface differences is that it needs to be compiled. It looks like your plugin is async as well. How do you control the timeout for when querying for completions that take too long? I didn't see a setting for that. &gt; It also seems to be abandoned Its not abandoned. I use it daily, and the last commit was in February of this year. 
I have written a fractal generator for mandelbrot, julia set, burning ship, mandelbar using modern C++ code. I didn't reinvent the wheel it is just my attempt on this subject. These are the libraries I am using: * [cxxopts](https://github.com/jarro2783/cxxopts) - Simple command line parser (included) * [CTPL](https://github.com/spektom/CTPL) - Thread pool library (included) * [Catch](https://github.com/philsquared/Catch) - Unit tester framework (included) * [SFML](http://www.sfml-dev.org/) - JPG/PNG Images (optional) The generator allows you to render the fractals using different coloring algorithms and/or to export the escape time values and the magnitude of the complex numbers as csv files. The README has lots of information (basic math for example), diagrams (performance comparison among other things), images and there is a demo video (low quality). https://www.youtube.com/watch?v=X55JtZ7qRPM You can find different [jupyter](http://jupyter.org/) notebooks in the resources sub folder that allow you to play around with color algorithms 
Yes, I do understand your point and even support it to some degree. There was a good reason to start anew. Some systems are just too complex. For my purposes my plugin is enough. I do not need functionality like "find all references". Everything else comes with sublime text out of the box (symbol/method definition). So I wanted to make something simple. It should still be able to chew a bigger project as clang only cares about stuff included in a single file. When I started I knew nothing about clang and how to work with it. I started with another plugin which was easy for me to hack around and diverged from it. Now that I know this stuff much better I may indeed consider contributing to rtags. However, I cannot get away from needing to compile the rtags upon installation and I really don't like it. But it is an option that I am considering. So thanks to pointing it out, this is a good point.
If you bundle ssl, your application will remain insecure when security patches are applied to ssl on the system. Every application bundling ssl is a security nightmare.
&gt;If using lambdas, do it SPARINGLY. Lambdas do have their use cases, but they tend to be overused these days. What's their dislike regarding lambdas? If the reasoning is that "they're tricky", that's insufficient imo. That can basically be remedied by hiring more competent developers or doing a few lunch and learns. &gt;Readability trumps everything else until proven otherwise. Yes, it MIGHT be necessary to have barely readable highly optimized code – but ONLY AFTER it has been demonstrated to be a bottleneck Somewhat disagree here. There are many valid times where you know before profiling that it's something that needs to be fast. Things like updating AI for thousands of entities or basically anything that needs to happen a lot per frame (in the context of a video game). If you architect everything with the assumption that you can optimize it later, you may end up with an extremely painful refactoring process that may or may not actually be feasible. For example, if you know ahead of time how your data is going to flow, the data-oriented approach would be to use this knowledge to build a cache friendly architecture. This means that the way you build your objects, what they store, etc, are all built with this in mind. This will look radically different from the naive solution. Worse is that you have heaps of code that build on these classes. If you go with the naive solution and then try to optimize performance later on (which would mean moving everything around to make it more cache friendly), the refactoring process ends up as almost a rewrite. Additionally, who defines what is readible? That sounds like something inherently subjective. I could find some code incredibly hard to read or understand but a mathmatician may find it obvious.
Depends on goals/targets/features of your application[s] but in any case pure platform independency with languages producing native code is not achievable. You only can speak of percentages of platform independent code in your application. If you are writing command line utility that has no or quite limited user interaction then you can get up to 99.9% of platform independent code on your side. UI or any other interaction with the user is limited by console's cin and cout. If your application has UI that can be expressed in platform independent manner and you want to stay strictly in pure C++'s std or boost namespace then you can use something like my sciter ( http://sciter.com ) for the UI and C++ for the rest. If you are OK with using non-std then you can use QT and so on. Otherwise you should architect your project to have non-overlapped and isolated platform dependent and independent areas. Particular percentage of platform specific code is obviously dependent on functionality of your application. 
You should really add runtime and memory complexity for worst case (and maybe average case). Nub on fixed size integers for instance easily be done in O(N), O(N log N), and O(N^2 ). I had to dig through the source to realize it uses the naive O(N^2) algorithm. 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/functionalprogramming] [FunctionalPlus, a C++ library, now has a (i.a. type based) search website for its over 300 pure and free functions • \/r\/cpp](https://np.reddit.com/r/functionalprogramming/comments/4mw8wa/functionalplus_a_c_library_now_has_a_ia_type/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Thanks for bringing up those very valid points. I purposely did not do any review of the iteration to keep it realistically what someone can code up in 45 minutes. (Basically spit out the code straight from IDE as soon as I had the base test case working) Valid points around nullptr check, noexcept and const and unnecessary virtual destructor - I'll add those to the list. Where did you notice the memory leak ?
You use c++ if that's the path of least resistance or if you need speed or control over memory
Why not just std::array ?
I develop using Qt, supporting OS X, Windows, various Linux distros, Solaris and occasionally FreeBSD. Most everything is virtualized. I have three ESXi boxes on the network, with all the supported versions of all the OSes, both build machines and QA machines. Everything is built natively on the OS/distro it's being built and packaged for. The build environments everywhere are all text-based. That's pretty usual everywhere other than Windows, but I do that on Windows too (ssh, qmake, jom and some perl tooling). Jenkins runs CI and production builds, with some magic to spin up VMs as needed. It's a couple of commands to build and package for a dozen platforms, deploy the packages to newly imaged VMs, run some basic tests on the installed software and prep for release. I use an OS X laptop as my main machine, which gives me a decent local environment both for unix-esque server dev and GUI client dev. The code works mostly unchanged on all platforms, so I do a lot of work on that machine (with a couple of "local" vmware fusion VMs - Windows and Linux - for testing when I'm not on my home network). I work on the VMs via ssh much of the time, but when I need GUI access I have either the local fusion VMs or I X11 or remote desktop into the main ESXi VMs. I mostly use Qt Creator on all the platforms, but sometimes switch to other IDEs when they're better suited to debugging. If you have the sort of development team that would suit the approach it could scale up pretty well, but I'm not sure it'd be an easy sell into a primarily Windows focused team. It seems odd that you're targeting primarily Linux while developing on Windows. They're very different platforms, and the Windows way of designing an app is often going to be quite different to a natively thought through Linux app. Linux or OS X are a lot closer to the target OS. (And OS X can handle most of the business apps you need too, as well as having a decent unix-esque toolchain).
The last year I have spent maintaining a Java EE application built on Jboss with Hornetq as the Jms middleware. It runs on both windows and RHEL. It has been an interesting experience to say the least. We use netbeans as our development IDE and overall it is fairly consistent between the two operating systems. We did have one problem with regards to Hornetq and how the application handled a complex failover scenario that behaved very differently between the two operating systems. It was my first experience with the old Java myth about compiling once and debugging everywhere. Overall though Java is pretty well behaved between operating systems. 
OK openssl is bad example. I think we can rely on distribution providing it anyway and ABI is stable right? What about swath of other shared modules. Let's take Qt as an example. Lots of big modules, lots of versions, can't rely on distribution having your particular version. Like I said gets fun real fast...
&gt; should
I don't see the problem. A package for a distro (like a deb package for Debian) solves this easily. There are also more generic solutions like [Flatpak](flatpak.org).
We're not there yet, although even now it's safe to say that GHC is just an amazing compiler. For example, in GHC with fusion you can write your algorithm in the pure, high, abstract world of Haskell, and the compiler will generate a *completely different algorithm* which is much much faster on the machine. I am not kidding. (iirc Don Stewart demonstrated that in his blog).
Would be nice to maintain such a list either in isocpp.org or e.g. on http://en.cppreference.com/w/cpp :-)
You are right, nub can be implemented differently depending on the type class of the value_type (Eq, Ord, Hashable). Some functions already had their time complexity class annotated like `group_globally`, for some others (including `nub`) I just [added](https://github.com/Dobiasd/FunctionalPlus/commit/17728ac1136372e4c821cca94e690b69159f33bb) them. For some functions like `elem_at_idx` it depends on the container type (`list` or `vector`), so I left them out for now. Would you be interested in contributing (annotate complexity classes or improve the alogirithms)?
&gt; if anybody has a better suggestion than `inline_vector` please ping me. I think `inline_vector` is potentially confusing because “inline” already has a different meaning in C++ (referring to code rather than data). Here are a few ideas: * `monolithic_vector` * `unitary_vector` * `unified_vector` * `compact_vector` * `fixed_vector` I think I like `fixed_vector` best.
OK, I understand and think you are right. More descriptive variable type names will make things easier to understand. For things like `keep_if : ((a -&gt; Bool), [a]) -&gt; [a]` I will stick with the current notation, because the type does not carry much information anyway. But for the functions using `std::map` I [changed](https://github.com/Dobiasd/FunctionalPlus/commit/0e78db75a717efb482f97c9c0e4cec90b54f3aed) the type annotation to reflect what is the key and what is the value. So now we have map_contains : (Map key val, key) -&gt; Bool transform_map_values : (old_val -&gt; new_val, Map key old_val) -&gt; Map key new_val etc.
Unlike you, I know what it is: A terribly naive and inefficient way to calculate primes that is [**not**](http://www.cs.hmc.edu/~oneill/papers/Sieve-JFP.pdf) the sieve of Erathosthenes. 
Yes, few debs for debian, 5 more debs for recent ubuntus, some bunch of rpms for fedora/centos.. I mean look at [this](http://nuitka.net/pages/download.html#stable-packages) - it gets stupid real fast. I really do flatpack gets off and becomes big. Sounds like it could solve all this madness. What is more important - applications could bundle required runtimes and installer could install them if that runtime is not present on system. This could be it. 
&gt; Visual Studio Code I really doubt when OP says "Visual Studio" s/he means Visual Studio Code.
I use Code::Blocks and compile on my target platforms. Using cross-platform libraries allows trivial cross-compilation.
&gt; I've showed him different desktop environments, xfce|Unity|Gnome, and showed him how similar the workflow is to Windows but for some reason they can't see it. It really makes me sad and I feel helpless as I'm the only developer who is pushing for it. I agree with your manager :-) Even more importantly, VS is just too good, it is the highest productivity IDE/workflow, at least for many. And that's coming from somebody who has been using Linux for years and I'm very comfortable on the shell, I've run Linux from scratch for years. But yea, if your primary deploy target is Linux, at least _some_ developers should use Linux as their primary dev OS.
To be honest, writing C++ in visual studio have always felt like a curated, luxurious experience. Like here's this most amazing IDE with an excellent interface and my company is paying $10,000/yr so that I get to have this experience. It's really like a vacation compared to writing C++ in vim and gdb. That is what I do now and I have always preferred gdb over VS debugging, but damn is it nice having a static analyzer with machine-learning code completion writing code. I suspect that abandoning the curated experience of VS development is what your peers do not want to do. I would just go with it, instead of trying to turn the tide.
 I don't see the issue. VS is generally superior to other C++ IDEs, make sense to use it. VS is also going to have Linux debugging soon, so using multiple IDEs won't be required.
* We have a Makefile based build as well as an XCode project and a set of Visual Studio projects (I'd personally like to switch over to CMake, but the old Makefiles are quite old and horribly complicated). * Some developers use Visual Studio on Windows, some use a Mac and some use Linux. * We have a continuous integration system (Jenkins) building the source on several slave nodes running Linux, Windows and Mac, with 32-bit and 64-bit variations. The Linux and Mac builds use the Makefiles, while the Windows builds use MSBuild. * The build system generates Windows installers on the Windows machines, and tarballs with install scripts for Linux and Mac. * We have a test system which takes these installers, sends them out to Windows, Linux and Mac slave machines and runs tests on each environment. We used to have one developer who used a Mac, but wrote his code using Visual Studio inside a Windows VM.
I also work with Qt and it's so bug ridden...
It still gives the correct answer. What happens in **time** between point A and B is irrelevant and a side effect. Haskell is for smart people who are pragmatic. We care about correctness. We don't care about the interim state - just hard facts. I'm looking for work in FP btw. Feel free to PM me
All programmers should learn FP so they can understand that certain aspects of it are highly valuable. They should then incorporate those valuable pieces into their own designs -- and discard the rest. Same rule applies to virtually every other programming paradigm known to man.
I think this is due to several factors * Visual C++ probably provides the most productive development experiences for writing and debugging C++. * With C++11/14 and Boost, you can write a very large portion of your application in a platform independent manner. * Most of the Modern C++ libraries (Facebook folly being the main exception) are cross-platform. In the past, they had trouble working with Visual C++, but that was mainly due to a lack of standard compliance with ISO C++ rather a platform difference. With Visual C++ 2015, a significant portion of these Modern C++ libraries will work across Visual C++ (Windows) and clang and gcc (Linux). I have seen people who will develop the main algorithmic parts of the code in Visual C++ testing and debugging and making sure the logic works. With C++11 threading, std::experimental::filesystem, and Boost ASIO, you can write the vast majority of your code in cross-platform C++. Then, you can use something like CMake to build the code on multiple platforms and test and tune each platform-specific part Microsoft's recent investments in such stuff like gdb debugging (https://blogs.msdn.microsoft.com/vcblog/2015/11/18/announcing-the-vs-gdb-debugger-extension/) and Bash on Ubuntu on Windows have made scenarios like this more useful. Personally, for my stackless_coroutine project (https://github.com/jbandela/stackless_coroutine) I have done the main development in Visual C++ and then used Bash on Ubuntu on Windows to test with gcc and clang on Ubuntu on the same source files. I have cmake files that build the test code, so it is easy for me write code for a feature, test and debug it in windows, and then switch to a bash window and run "ninja unit_test &amp;&amp; ./unit_test". 
&gt; Haskell is for smart people who are pragmatic. holy shit
Why use a sieve at all, if you don't care about time. Trial division will give the same result as well.
I used it and liked it much, it's easy to start getting productive. The collada importer works ok supporting some format features quietly not rounded in other engines (morph targets and skeletal skinned meshes), and the api is clean and well documented. For more complex projects I would however go to things like unreal engine.
Looks awesome!
Once you learn emacs or vim to a significant level of depth and add a few plugins you won't want to use IDEs anymore. Then you can use them everywhere.
uh, I will find a job in functional programming eventually it starts with having smart people understand now if you're some crappy guy from full sail or hostgator, i understand it doesnt apply. but i do deep systems theory and complexity, so need critical safety for industry applications
Ogre is pretty great, but it is important to know going in that its design is all based around inheritance and pointers to class instances, which someone doing games in C++ hopefully knows can be performance kryptonite if enough objects are in use. 
Summary: * [Added /std:c++14 and /std:c++latest switches](https://blogs.msdn.microsoft.com/vcblog/2016/06/07/standards-version-switches-in-the-compiler/) * Better support for [expression SFINAE](https://blogs.msdn.microsoft.com/vcblog/2016/06/07/expression-sfinae-improvements-in-vs-2015-update-3/) * [Nested namespaces](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4026.html) (hurray!) * [Generalized range-based for loops](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0184r0.html) (`begin()` and `end()` with different types)
*sigh* 1. If you read the comments of that post, you'll see his claims cannot be independently replicated. 2. You Haskell guys don't even like eating your own dog food: https://www.reddit.com/r/haskell/comments/45q90s/is_anything_being_done_to_remedy_the_soul/ Dude, really... everything you've said so far in this thread has been at best a half-truth, if not comically and ironically wrong. You need to stop.
Thanks for the explanation. I've added google cache links for now. Do you think the posts will be back today? If not, it might just be better for me to delete the post.
Interesting question. I'd say yes, but then I thought about it more, now I'm not sure. Linux definitely has a "mindset" to it. When you use Linux as a developer, you're exercising the same type of thought as you are when you're programming (or something like it). Because Linux was kind of born from those ideas to begin with. Windows has its nooks and crannies for developers to learn, like Powershell. But Powershell isn't so much a universal standard as, say, Bash... I guess it all stems from this: "Learn Linux" sounds to me like learn piping, learn that "everything is a file, even devices," learn the filesystem layout, etc. "Learn Windows" sounds more to me like... "Learn Powershell." From a developer's standpoint. So I don't know. I guess it depends on the circumstances. Interesting question. EDIT: and I guess it also depends if the question is just about "using" Linux/Windows, or if its about "targeting" Linux/Windows, which makes things different again...
They should be back today. Edit 11:36 am PDT: The posts are back up now. 
From my experience, the windows/closed-source mindset is "try to change random things, and maybe it'll eventually work"; the unix/open-source one is "directly see what every small piece does".
The C++17 draft standard is 1500 pages. That doesn't imply simplicity in the language.
There's a lot of support inside Visual Studio for cross-platform development. We've got a Clang/C2 code generator that uses an almost-unmodified Clang 3.8. We've got Linux targeting with integrated debugging. And we've got VS Code with debugging and some IntelliSense-like experiences for the Linux boxes when you have to go there. If you end up staying in VS, let me know if you have questions. Just mail firstname.lastname@microsoft.com or visualcpp@microsoft.com--I'll get it either way.
Ah, I got it.
Off topic, but the bug fixes reminded me... What's the best way to report compiler bugs? I've reported through the feedback feature in VS but didn't even get an ack mail or something. Is there a better place? 
Apparently I lost the comprehensive version of notes I made for a presentation about dynamic analysis tooling, but I found the short version. Unlike Valgrind * Asan finds when you try to write/read past stack allocated array. * Msan finds accesses to stack allocated objects after their destructor has been run (this has helped me found some pretty bad fuckery involving exceptions, where Valgrind was completely silent). * Basically everything UBsan finds is ignored by Valgrind. * Sadly, haven't really tested TSan/Helgrind, so no idea there. Unlike sanitizers, Valgrind screams on mismatched malloc/new/free/deletes... There might be some more, but quick testing hasn't found more and the comprehensive notes are gone. 
Telemetry, sign-on, media, compute, AI, search, etc. etc. etc.
Horde is a graphics engine. UE is a game engine. Apples and oranges.
This is awesome! The only thing I don't like about it is "Step 1 - bind", where you have to add code to each of your files / classes in an intrusive way. Would it not be possible to do that non-intrusive/automatically?
That's awesome work. Cool! And the big question: Does range-v3 compile now? ;-) Sadly still not: &gt; We went through all range-v3 tests and identified various issues in it. We logged over 50 bugs internally to track our progress and have fixed about half of these bugs. Issues remain in many different feature areas, such as name lookup, friend functions, variadic templates, alias templates, default template arguments, constexpr and noexcept. That's quite a huge list. I hope Update 4 will finally be the one. Thanks for this great step forward.
In theory yes, it would be possible to automatically analyze C++ headers and generate one or more new source files just to define the bindings. I see two problems: - Parsing C++ is difficult, so such a tool would probably have to rely on Clang and overall it would be annoying to install and/or maintain, providing binaries for different platforms. The current way extracts necessary information alongside a normal build. - You'd still want to somehow choose which classes and methods to expose to JavaScript, for example annotating them with comments. Currently you don't have to put the bindings in the same source file as your class definitions. The source file with the bindings simply has to see the class declarations (for example by including headers). You could even put all NBIND_CLASS calls and a bunch of #includes in a single separate file. Actually it should be pretty easy now to make a shell script that reads all headers, extracts some particular kind of comments and generates such a file, but then that would be intrusive regarding the contents of your headers... 
&gt;Not having version switches was a much better feature. Why? If it was set to use the latest standard version by default, it would give you more options without affecting normal usage.
As a person who writes code which will be compiled by other people, I dislike version switches because it's yet another set of configurations which I have to test. As a person who sometimes has to work with people who are overly cautious about updating anything, I have had the argument "well actually we've been building as c++14 on Windows for months now because VC++ doesn't let you use older versions" be quite useful in calming fears that it would break everything. 
Targeting embedded arm. Develop in a Linux VM with a cross compiling tool chain. Cmake to build, qtcreator as an IDE. We run gdb on the target and either command line debug with it, or connect remotely with qt creator
Thanks for your comments. Yes, it's only Linux and yes it is odd. But people here hate Linux and love Visual Studio. I've tested a large part of our libraries with Valgrind and Address Sanitizer on Linux using small dummy programs. I have made them start working with CppCheck. They did not know anything about static analyzers. They couldn't believe how is it is to find bugs with CppCheck. A lot of mismatched deletes... The problem I'm having with Valgrind and Address sanitizer is that most of our apps are 32 bits that require old 32 bit libraries that we don't have the source code for. When I run our app with Valgrind it makes it super slow and it crashes after 15 minutes without even getting out of initialization. Address Sanitizer does not even start. I am not sure yet but I guess it gets out of virtual memory address and it just stops because the is 32 bit. The same with Valgrind. Do you have any tips how I can get around this problem?
There are several reasons that makes moving to Linux hard. The first one is that our company was recently bought by a big corporate and all of our laptops must be connected to their stupid network and they encrypt everything. None of our Linux machine has internet access because of that. It's very annoying. On the other hand I don't have a degree in CS or Software engineering. Although my manager has told me several times he is satisfied with me and I'm one of a kind they always talk to me as if I don't really understand what I'm doing and it's just my 4th month. What I've shown them is that how easy it is to setup a CMake project and how easy it is to see everything in the CMakeLists.txt file instead of going through menus and stupid options and missing stuff. I have shown him how clang analyzer can find stupid bugs so easily if compile on Linux. Our toolchain does not support C++11, I've showed him the good points of C++11 and the benefits we can get from it. What else can I show him?
&gt; ... calls it `inline_vector` to denote that the elements are stored within the vector itself, as opposed to existing practice (e.g. `boost::container::static_vector` due to static storage ... What? No, `boost::container::static_vector` does contain the elements directly, it does exactly as you describe `inline_vector`'s behavior. This is why it takes a `size_t` template parameter rather than an allocator. ('Static' in this context refers to the fact that the container has static _capacity_.) Hinnant's `short_alloc` must be given an arena, which is typically but not always statically-allocated – maybe this is what you were thinking of?
&gt; The proposal suggests fixed_capacity_vector as an alternative name As in statically_sized_vector, as in `boost::container::static_vector&lt;T, N&gt;`? ;-]
Thanks for your comment. I've tried CLion and it is great but some of our projects are huge with a few hindered 100K LOC files. Unfortunately CLion can't handle that. Starting CLion takes around 1 hour, I tried to use it for a few days but it's not functional. Searching/replacing and stuff like this take a long time. Do you use Visual Studio on Windows? If so, why do you still use CMake?
we're working on some updated guidance on how to file compiler bugs, but yes, connect is the best place.
we are working on it. - Steve, VC dev mgr
Another library that decided the standard library's naming scheme wasn't good enough for it.
Oh OK, thanks. I did not find them when I skimmed the [doc](https://ericniebler.github.io/range-v3/) for my [comment](https://www.reddit.com/r/cpp/comments/4ms934/functionalplus_a_c_library_now_has_a_ia_type/d3xzjxf). Then let's take the following ones instead. ;-) transform_map_values : (old_val -&gt; new_val, Map key old_val) -&gt; Map key new_val carthesian_product : ([a], [b]) -&gt; [(a, b)] combinations : (Int, [a]) -&gt; [[a]] transform_and_keep_justs : ((a -&gt; Maybe b), [a]) -&gt; [b]
&gt; Craig Silverstein who originally wrote the guidelines was quite open about the fact that if they were writing them today, they'd use exceptions everywhere! By any chance, do you have any public link to such a conversation? It would make a good addition to the book :-).
Great reply! I'm very comfortable reading lambdas and find that due to their inline nature, they capture the context of their usage better than named functors. Perhaps this is just a personal preference. However, I agree that captures can be tricky and there can be a cognitive burden to keeping track of what the variables inside a lambda are actually referring to. It's also very annoying that capturing with move semantics is not supported in c++11. If you want to "move-capture" a large data structure, you have to do it in a rather roundabout way, or upgrade to c++14. Regarding avoiding micro-optimizations, I agree they hurt readability and should only be done when required. Converting scalar code into vectorized code can lead to some difficult to read and confusing code blocks, but you only do this when you've identified that as a something slow. My post was referring more to times when the readable way may be closer to the naive solution and further from the optimized solution and you need to decide early on which solution to implement. In a lot of cases, you can hide the complexities behind an interface like you mentioned, but I'm not certain that applies 100% of the time. I admit these cases are rare enough that they would be exceptions and the person implementing them would be in a position to know when it's fine to break the guidelines. 
Thanks, will check that out then! 
Move to 64 bits or slim down your application :-D Asan theoretically works in 32 bit applications (no idea what it does if you build 64bit app and try to load 32 bit libs), but doing so gives up on leak detection and will run out of addressable memory rather quickly, because it is made with 64bit address space in mind. Valgrind is ok in 32bits, except that it still has its own memory overhead over the binary itself, so if it uses significant part of the 32 bit space... well then you get exactly what you see. Take it from the bright side, it hasn't found errors in these 15 minutes before it munched through all available memory. :-D ------ edit: I have no idea how two version of the post got munched together.
Hate SFINAE. If overused it makes code so unreadable. 
I see the signature of the method is not mentioned in the binding code - how do you handle overloads?
In what way? The naming scheme seems fine.
Ah, the smackdown I am remembering is from the C++11 era, I guess they just wanted to cook it longer.
&gt; The size is not static (it is a run-time parameter), the capacity is (as in compile-time static). Indeed, my terminology there was wrong. &gt; complex lifetime requirements happen only in the static memory segment (in which things like initialization order are implementation defined). Since it contains its elements directly, whatever storage you give the `static_vector` will apply to its elements. If that happens to be static storage duration, so be it; if automatic duration, so be it.
While I stick to snake case when coding in C++, I have to say after a few hours it gets to be a bit of a bitch typing that _ so often. I don't blame anyone for switching to camel case.
Yes, that doc page is not in any way complete. It lists only views (which are lazy), but there are also [algorithms](https://ericniebler.github.io/range-v3/group__group-algorithms.html), [actions](https://ericniebler.github.io/range-v3/group__group-actions.html) (modifying underlying data in place), [utilities](https://ericniebler.github.io/range-v3/group__group-utility.html) etc. PS. Or instead of looking onto Doxygen (which shows weird internal names) you can look at directory structure, where one header corresponds to one view/algorithm/action. 
I worked with Qt for a long-time so the naming scheme kinda stuck with me :) On the other hand, OpenGL, OpenAL and Vulkan all use CamelCase, so why not?
You should pick up a project. You learn programming languages best by real world practice. You should stick with C++ but don't overdo the OOP thing. 
&gt; DO have your own project-wide header (or several ones for different purposes), and DO prohibit all the #includes except for these few headers for the rest of your project. I cannot disagree more with this. For several reasons. 1. This makes dependencies within your code very obscure. If you see `#include "everything.hpp"` it gives you no information on what other parts of the code this file actually depends. Basically, this makes you code an "everything-dependes-on-everything" kind of mess. 2. This *does* harm you compilation times. If you change any of your header files, the whole project would have to be recompiled. And precompiled headers don't help here at all. &gt; In addition to limiting #includes to your-project-headers, I also suggest to limit using directives to your-project-headers too. In other words, I suggest to adopt a guideline when all the using namespace std; SHOULD belong to your-project-wide-headers, and ONLY to your-project-wide-headers. This is absolute NO. `using` directives should not under any circumstances be used in any header. And, by the way, there is an interesting tool: [include-what-you-use](http://include-what-you-use.org/) which automatically fixes your includes.
The proposal that got rejected did more than this simple use case. As I recall, you could even have invalid syntax in the untaken branch. This one has its scope limited to functions and a couple other things tightened up.
If you need to save some money (temporarily) while you get up to speed, then grab the subset of TCPL: [A Tour of C++](http://www.stroustrup.com/Tour.html)
Would you accept some embedded Linux hardware as donation?
Do you know if these switches also affect VS extensions to C++ ?
&gt; To be honest, writing C++ in visual studio have always felt like a curated, luxurious experience. For me it's always been the opposite, with a startup time of at least a minute, giant project directories, a bloated interface and slow build times. The autocompletion works well, but takes forever to refresh.
Can I be tentatively excited about a possible replacement for Connect?
Didn't I read a while ago that intellisense uses the cl dll? I think there was a series about getting rid of ifdefs that were there specifically for intellisense.
I'd actually suggest taking a look at our other extension that has a more tailored Linux experience: https://blogs.msdn.microsoft.com/vcblog/2016/03/30/visual-c-for-linux-development/ We also released an update yesterday: https://blogs.msdn.microsoft.com/vcblog/2016/06/07/visual-c-for-linux-updates/ The GDB extension lives on as something we're currently using to experiment with targeting IoT devices. I say experiment as there is still a non trivial amount of config needed to set it up, it basically just makes it possible (with work).
Thanks for the note. I'll send a nastygram internally. 
Adding the "more than 6,000 #if preprocessor blocks" from yours and the "thousands of #ifdefs polluting the front-end code" from mine gives some scary stuff indeed.
 &gt;I'm currently an EE undergrad and I just took a quick course on C++ (where we also delved into some of fundamentals of C) and I learned most of the basics of things like OOP, creating/managing small files, dynamic mem allocation, object reference passing and pointers, simple linked lists/stacks/queues , inheritance/polymorphism and overloading. Sounds like a lot crammed into one course. Normally, for people still in school I suggest taking a Minor in Computer Science. This way you cover a good portion of a CS program from the ground up. Since you have already taken a course I'm not sure that makes sense, but a minor looks good on a resume. &gt;* What are some good resources to learn more C++ on my own ( i hear the book accelerated C++ is good) Accelerated C++ "was" an excellent beginners book. I'm not sure if it could offer you much now. There are two issues, it looks like you covered much of what the book covers and frankly the book has become a bit dated. Sad really because I really liked that book. Unfortunately I a little dated book wise so I'm not going to suggest a book I haven't read. Just make sure the book covers modern C++. &gt;* What kind of things should i be looking into, embedded systems or hardware controlling or what? and How should i move on next? Embedded systems programming and things like custom micro operating systems are a subject in their own right. You will want to look for separate texts covering embedded programming and likely operating systems, monitors and the like. &gt;* Is it worth learning C for employment or should i just stick with the C++? and does knowing C++ mean i pretty much know C Modern C++ is nothing like C. The two languages are evolving in different directions. More importantly C like programming in C++ is frowned upon. Learn C++ well before you even consider C. &gt;* How much of the programming should i know before i can say i really know it and can put it on my cv? Any verifiable skills should be noted. &gt;* Whats a good way to keep practising programming since its not in my curriculum and i would be doing it in my own time? Build something! An alternative is to get involved in a open source project. The trick is it find something that is if personal interest to you. &gt;Any advice or help would be much appreciated! Advice depends upon your goals. A minor in CS is a good thing to have on a resume. Baring that programming requires practice and developing into a good programmer requires code reviews by people you respect for their opinions. You can practice all you want but a third eye can highlight bad habits of mistakes you may not see. 
Sorry, I meant we are publishing a guide soon on how to file actionable compiler bugs. Connect is less than ideal but nothing to announce there... sorry. 
**Company:** [StorageCraft](https://storagecraft.applicantpro.com/jobs/) **Type:** Full Time **Description:** We are a backup and recovery software company. Our C++ developers work mainly on the core code which runs our products. We do mainly whole-image based backups and a lot of work with Virtual Machines of various types. C++ is mainly used for systems level programming. **Location:** Draper (Salt Lake City/Provo Area), Utah **Remote:** No **Visa Sponsorship:** No **Technologies:** We use C++98/03 for the most part but are transitioning our build system to C++11/14. Some projects can use C++14 today. We develop software for both Windows and Linux. We have different positions for each, but developers will occasionally work on both platforms. We also use C and some Python experience would be nice as we have other groups that use it. **Contact:** Submit directly to the above website.
And we removed the ifdefs for static analysis in vs2015 rtm. Huge huge work item :-)
&gt; The lesson here is that supporting two different compilers in the same source base is only slightly smarter than supporting two completely separate compilers, and neither is a good choice for long-term maintainability (actually it was three compilers, since ANSI-C was another set of ifdefs – and truth be told it was actually four if we include the /analyze compiler). How true is this now? Were you guys ever able to untangle all of this? And by the way, these blog posts about internal stuff are always fascinating. I wish there would be more of them.
If they coordinate well then yes. I've definitely been in circumstances where I am more productive alone than me and another developer, who I spent more time hand-holding than coding with. I've also had developers leave such cruft that it's taken weeks or months to undo the damage.
Nonetheless, I would never expect 2 programmers to be as productive as one programmer given twice the time. There is always overhead with teams. Adding developers to VC++ would likely, for a while at least, slow the team down due to the need for knowledge transfer and extra coordination. In the longer term, yes, I would expect to see benefits. But if people expect to see features/conformance delivered faster by adding developers, that's very close to the situation described in TMMM, and I would expect it to suffer similarly. I'd love to see a citation that the modern practices you describe "eliminate" Brook's law - they will certainly help mitigate it, but I've never seen a claim that it can eradicate it. Seems nonsensical to me.
Do you really think that MSVC is developed by single developer? :-) 
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Hah! &gt; Issue: Compilation errors point to unrelated code. &gt; Workaround: Curse and do random edits until it compiles.
and it's the basis of all your beloved generic libraries
ppl.h still uses std::auto_ptr which prevents it from compiling with /std:c++latest switch
Yeah, we know. We're working on cleaning up such usages.
In the Tick library to get things like `std::is_pointer&lt;T&gt;()` to work with [`TICK_REQUIRES`](http://pfultz2.github.io/Tick/doc/html/requires/index.html#tick_requires) or `enable_if`, it would put the bool expression in a non-type template parameter inside of a decltype, then the value of the parameter is then extracted like this: template&lt;bool B&gt; struct requires_bool { static const bool value = B; }; template&lt;class T, long N&gt; struct requires_unwrap : T {}; } #define REQUIRES_BOOL(...) \ requires_unwrap&lt;decltype(requires_bool&lt;(__VA_ARGS__)&gt;{}), __LINE__&gt;::value It is used in the `TICK_REQUIRES` macro [here](https://github.com/pfultz2/Tick/blob/master/tick/requires.h#L78). This actually helped smooth over the problems MSVC had with constexpr expressions inside of `std::enable_if`. Of course, this post makes it clearer why it had those problems in the first place. Although, I am not quite sure if the above is valid C++ code or not. Of course, sometime some invalid C++ code is needed to overcome MSVC's shortcomings. For example, [`FIT_LIFT`](http://fit.readthedocs.io/en/latest/lift/index.html) is define like this for C++ compilers: #define FIT_LIFT(...) \ [](auto&amp;&amp;... xs) -&gt; decltype((__VA_ARGS__)(std::forward&lt;decltype(xs)&gt;(xs)...)) \ { return (__VA_ARGS__)(std::forward&lt;decltype(xs)&gt;(xs)...); } However, referring to auto parameters in the trailing decltype does not work for MSVC. So instead for MSVC, `FIT_LIFT` is defined more like this: #define FIT_LIFT(...) [] { \ struct local_lift_t \ { \ template&lt;class... Ts&gt; \ constexpr auto operator()(Ts&amp;&amp;... xs) const -&gt; decltype((__VA_ARGS__)(std::forward&lt;Ts&gt;(xs)...) \ { return (__VA_ARGS__)(std::forward&lt;Ts&gt;(xs)...); } \ } \ return local_lift_t(); \ }() Of course, local template parameters are not valid C++, but it works on MSVC.
Although code written without considering auto-vectorization often isn't much improved by it, I have had good results making a modest effort to ensure code is easy for auto-vectorization to optimize. The result tends to be fast, readable, and portable.
It's a pretty name, and we aren't allowed to put arbitrary pretty names in std - only implementer-reserved _Ugly names.
Obviously YMMV, but: &gt; targeting a specific language version tells you very little about if your targeted compiler versions will actually be able to compile it. I have a different experience. As long as you stay inside the limits of your choosen standard version and best practicies, there is rarely disagreement in the compilers. Unexperienced Developers usually stay well away from the darker corners of the language, so they very rarely encounter actual compiler bugs or disagreements. The most common reason they do stumble into these corners is because they followed bad advice or documentation which used compiler specific extensions or newer or older language versions (often without marking them). Both gcc's and clangs warnings help a lot to flag this kind of errors. More experienced developers generally know when they are writing non standard code, or approach the areas where compilers might diverge. When they do they will switch compilers more often, but still, suitable warnings help to catch several cases even earlier. &gt; If there's an unpleasant amount of friction involved in doing so (testing with the actual compilers) There is always friction in testing with more than one compiler, even if it is just the multiplied compile- and test run- times. And it increases with the project size. Also local deployment is not always possible or easy, so CIs are often the only option. This does not mean that having the compiler options relieves me from proper target testing, but it greatly reduces the burden. 
More than half the time you shouldn't need to type it because your IDE will auto-complete it for you. For example have a variable named "my_local_var": Type "mlv" -&gt; "Enter" and you're done. Most often even the first one or two letters are enough.
It was not accepted into the standard.
It is more complex than that. There are things the standard could do to make it _easier_ to achieve better performance, which in practice will result in better performance more often and at less development cost. There's also plenty of issues important to game developers that have little to do with raw performance. A big one is development iteration time, for example. Another is ensuring fine-grained control over all allocations (for memory constraint profiling) and error tracking (ensuring good feedback for QA and content creators without interrupting engineers). Finally, there's a lot of "gray area" around performance. Exceptions are a big one: they both have performance implications _and_ poorly fit many kinds of error handling that a game might want (e.g., exceptions lose forensic information, interrupt code flow in non-obvious locations and can introduce bugs, or simply lack the ability to easily ensure all your errors are ignorable or traceable directly at the point of failure). SG14 has a pretty big umbrella and crosses over with other groups, such as SG1, quite a bit. The SIMD, GPU, and fixed-point work for instance is all being influenced by SG14 input and research, even though technically those work items are all under the purview of other SGs. SG14 perhaps might be best thought of as the "industry outreach SG" rather than being focused on a particular area of the standard.
To level out the learning curve for those looking to develop something that can run on Linux but aren't looking to switch or delve particularly deeply into the OS?
No that's Visual Studio and Intellisense. Visual C++ is their compiler suite. 
All the components are open source. Go right ahead.
In this case they're not actually using the Visual C++ compiler. They use gcc and gdb. I'm pretty sure that, at least lately, they reference the ide, compiler and such all with the same Visual C++ name anyway. 
Development for Linux using Visual C++. You write the code in Visual C++ on Windows and build it remotely via SSH. 
&gt; No that's Visual Studio and Intellisense. Which happens to be _exactly_ what this link is regarding, poor title not withstanding.
Everybody has their likes, dislikes, and prejudices. Some people like Visual Studio and others, apparently like yourself, don't. 
That is absolutely on my list of stuff to purge, but the fact that it serves as a base class for uniform_int_distribution means that it'll require more work to untangle, and can't be done in an Update.
&gt; he day there is no refactoring, poorly working code formating and no good way to design snippets. Besides that there is a lack of defining different start configurations for a project. &gt; &gt; With VS 2015 even Intellisense started to work less smoothly and consumed much more resources and periodically freeze the IDE for some moments. &gt; &gt; I would agree that the debugger works quite well. &gt; &gt; But for a commercial application there is a lack of things that other IDE offer for C++! the kool-aid is strong
Hate overusing it and side effect does not equal that they are useless. On contrary. I am stating SFINAE is more complicated than it should be, and I find it annoying to use, read. Yet most awesome stuff is built with it.
Just from a quick look https://connect.microsoft.com/VisualStudio/feedback/details/2591761 , https://connect.microsoft.com/VisualStudio/feedback/details/2390989 has testcases already with no comment. Well also my bug report with a standalone testcase https://connect.microsoft.com/VisualStudio/feedback/details/1637097/injected-class-name-problem is also still open with no comments.
Last I checked it is also laggy, takes a long time to load,eats up a lot of space, is a pain to remove and vs compiler doesn't fully support c++11 and c++14. 
There is no switch named `/std:latest`; I think you meant `/std:c++latest` :-) But, "c++latest" literally means 'what is the latest C++ the community is working on or is considering. The dated/numbered standard C++ versions will be given obvious switches from C++14 onward.
I've had speed issues with Reshaper++ (unfortunately). Since I've switched back to VAX, it's fast as hell again. I only have ~medium-sizes projects though.
One more point, Embind calls malloc for each string and such passed as a parameter, while nbind uses a custom linear allocator for arguments taking less than 64 kilobytes and pops the entire "stack frame" at the end of the call. 
Seems cool. Sad about libclang though; I'm still hoping that rms will give his approval to have gcc dump its ast. Perhaps we have better luck with that.
&gt; Even when writing the first prototype, I quickly ran into limitations of libclang. &gt; &gt;While it is great for parsing C++ code it doesn’t expose all the information I need. For example, whether a constructor is explicit or what the expression inside a noexcept is. But when writing the documentation, I need this information. Are there bug filled for these issues? They are bugs. &gt; Sorry for this “rant” on libclang. Don't be sorry for ranting on a blog post. If you didn't fill those bugs in the LLVM bugtracker don't be sorry about that either, just please fill in those bugs. Making libclang better makes a lot of C++ tooling better.
I never thought C++ devs as good as Casey Carter actually existed, I am curious about what is he like in person, seems to be an exceptional individual. 
Do you think it would be possible to use exclusively libclang for parsing if these issues are fixed?
I gave examples; these are far from complete, but you even have shorten them further and sustained your judgement about me based upon that! So my other given examples are ok, but the one you disagree makes me a fanboy? Lol! If somebody speaks about the **best code editor with code completion** I feel still right to show a different point of view - and I did it with far more arguments than the OP 😎 So please rethink the criteria for your judgements! One is allowed to say the **best** without arguments‽ Probably you resemble more the kind of person you damned than you suspect... 😈
How does popularity is measured? By the number of stars from the Github page? That would explain why Qt is relatively low (5/10), as Github isn't their main repo. Imho: the star score generally convey the idea of evaluation; a soft may be rarely used but appreciated, while another may be more used despite its numerous flaws. Ideally, we'd need 3 metrics : - what's the general opinion of the software (0 : poor, 10 : great) - how many devs are using it (0 : only a handful, 10 : core tool for the language) - and how active it is (which is already included)
Spans can be either compile or runtime sized. Arrays are not views. They own data.
Ok, then I say VS offers the worst code editor for C++ in the world. Following your argumentation this is totally harmless and ok, as I didn't emphazised anything, nor have I provided any nitpicking thesis or used the word *imho* like I did in the beginning 😈 Ok, let's quit peacefully now, as we won't come up with an agreement! 😇
&gt; poorly working code formating I *highly* recommend the clang-format extension for Visual Studio ([available at the bottom of this page](http://llvm.org/builds/))
If you are trolling, my hat is off to you, you've really hit it out of the park with both the headline and your comments.
Your post does not justify this action by Microsoft in any way. You're being an apologist post-hoc, that does not negate the fact that 'this should not exist'. Oh, and putting it in with minimal fanfare is.. deceit.
It's stupid to say "I HATE FEATURE X" because you've seen it be overused (ie misused). If that were a good reason to hate something I would hate every feature in C++.
Good thing no sane person would use a proprietary compiler anyways.
Yep, that was the idea.
This has always struck me as an interesting argument. Haverjhold recently made similar comments regarding the VW scandal: "The engineers believed in a responsible automotive industry and we just caved (to borrow your terminology) on a few issues" I'm confident that your coworkers feelings ex Windows were pure (whatever that designation might imply) but the core of integrity in a software requires more than just delicately handled conflict, more than just a quid-pro-quo "caving" of dueling opinions. Bad intentions? No, but the external view of Microsoft and our concrete understanding of everything that is not Microsoft Research leads me to believe that whatever good intentions existed, they were never the ambition.
Great response, but pass a word to the Windows 10 dev team that perhaps they should make the telemetry snooping in the OS as a whole - an option. Until then, many people like me are unlikely to switch back from UNIX.
Hi, I'm the PM for this extension. Unfortunately this extension has it's own project system that I haven't seen other tools start generating yet.
&gt; data about how you use Windows, such as how frequently or how long you use certain features or apps and which apps you use most often Right, because how else will you know where to allocate resources if you don't know what programs/features people actually use?
You have to select the open source version. Yes, it is free for private use.
&gt;c-smart-pointers Why would anyone want a C library to provide what's already in the STL? How is ASIO not in the "Networking" section? 
Yet a lot of people still use their products don't they?
To piggyback this, does it work with Visual Studio?
&gt; laggy, takes a long time to load,eats up a lot of space, is a pain to remove All of the above are hard to argue with though.
This might be slightly off topic, but how relevant are questions like this for job interview questions? My gut says these shouldn't be the focus, but my experience says these are too common. I understanding throwing a few of these kind of things into the mix, but why do so many interviewers depend on things like this to demonstrate general knowledge of a language? Interesting thought exercises though...but it just makes me cringe to think that there are so many places that pass up decent talent because they don't necessarily untie spaghetti code as well as the interviewer.
I certainly hope they're completely irrelevant. 
It says that FLTK is GPL2, but it is in fact licensed under the LGPL.
Just look at std::string as a container of bytes, you can even use it as a variable-size byte-buffer if you don't mind that the buffer is always initialized to something (zero by default) and it will have an extra byte initialized to zero at the end. The std::string is NOT BROKEN for UTF-8, just look at UTF-8 as a layer above your byte container whose type maybe std::string. Even if you are using UTF-32 for each code point there are characters that are actually two code points that merge into one. The operations for std::string are simple and fast and work well for the first 128 UNICODE code points (When each byte is 8bits and because those are ASCII). The operations required to deal with the rest of UNICODE characters cost a lot more CPU and memory, also you will need a separated proper UNICODE library and you should use it only when necessary.
depends on what parts...iostreams? yeah bloat city. algorithm? perhaps not as much...
/std:c++explodingfootguns
Mom? Is that you? When did you get a Reddit account?
If you are only on Windows there are two better ways: - [C++ Builder](https://www.embarcadero.com/products/cbuilder), the best RAD experience for C++ - [C++ UWP Apps](https://msdn.microsoft.com/en-us/library/hh875012.aspx), VC++ catching up with C++ Builder, but with XAML instead. Yes, both require language extensions, but all C++ compilers have language extensions and Qt relies on moc anyway. 
I'd be quite interested to see what takes a day in c# and a month in qt ! It would make for some good bug reports I think. Care to explain the project?
It's stupid to ignore feature X problems because, it is used in std lib...
I'm raging. Only github contributions are supported? How hard is to store an URL string in database. One contributing non-github could fill required fields manually for review.
Another big absence is SOCI library in the database space.
Currently we do not support Windows. However there is a Docker container available. 
Wow, what a shitty list. A not-actually-curated (I hope) list of not-so-awesome libraries...
Doesn't compile for clang/g++, seems that the code is written against MSVC and at a glance some of the code is indeed ill-formed.
If you hate writing Makefiles - and I don't blame you, because make is horrid - try [cmake](https://cmake.org/). You'll hate writing cmake files too, because cmake is also horrid. Well, what can you do? It's a build tool. There appears to be no getting away from this. But it's popular, so you've got plenty to copy and paste from. The ecosystem is decently sized, and it's got a primitive packaging/library system, so there's a fair chance you'll be able to find *something* that supports whatever it is you're trying to do, and it'll be easy to integrate. And, best of all, you can get it to target [ninja](https://ninja-build.org/) instead of make. Ninja tends to be a lot faster for builds that only involve a few files.
Take a look at https://moderncpp.com/ Microsoft recently hired the developer who was creating a way to easily write WinRT in C++ without any C++ extensions. Hopefully, it will be released in the near future.
There's also this project: [RuntimeCompiledCPlusPlus](https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus), which lists support for Windows/VS, OS X/XCode and Linux/Eclipse in the readme. They also have a list of other C++ hot-reloading solutions [here](https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus/wiki/Alternatives).
Great Job! Are you guys planning to write a Jupyter kernel for jyt? You could draw the attention of a large crowd by doing so.
Also keep in mind that even without Modern one can write UWP apps in native C++ using COM.
Find what your enjoy. If you like games, make games. Simple arcade games will challenge you and keep you interested. If you enjoy challenges, try doing math related problems, such as fibonacci or prime number challenges. Try cryptography, perhaps. You're much more likely to succeed when you find things you like. Second, if you haven't already tried it, go to hackerrank.com. It gives you plenty of challenges to hone your skills and get you in touch with potential employers.
you need to add all include directories in project options
Last year someone from Microsoft warned me against telemetry in Visual Studio and in general in the MSDN subscriptions. I don't want to brag, I just want you to consider this as a real possibility.
&gt; Also, I believe using std::cout causes flushes in the way that "\n" does not I think you meant `std::endl` there.
Yeah I managed to get the speed up on cout by using sync_with_stdio(false), so that helped. I was really looking if there was something even faster. As in... is there a way to use inline assembly to output in a way that's faster than cout or printf? At least print out integers faster. Or maybe I'm even doing this with the wrong language... would C be faster? or another language?
Oh and I have a habit of defending Microsoft, but not here. Now you're starting to burn *my* bridge.
thinking about making an awesome list of awesome C++ lists m(
Totally! We definitely won't be _finding_ it again!
From gsl.h: namespace std { template&lt;class T&gt; struct hash&lt;gsl::not_null&lt;T&gt;&gt; { size_t operator()(const gsl::not_null&lt;T&gt; &amp; value) const { return hash&lt;T&gt;{}(value); } }; } // namespace std Specializing `std` templates isn't kosher, is it? 
I just tried it and it does help! It is being printed to the console, and obviously I don't expect a human to actually read it. It started as a competition with a friend on who can print all the prime numbers up to 100000000 the fastest.
and no, I'm definitely not on Windows. I run it either on my Ubuntu or my Fedora. 
What terminal are you using? Or are you redirecting to a file? A quick local test showed that printing 500000 numbers (no optimisations, IE still localised/with stdio sync enabled) took 0.75 seconds on gnome-terminal, 0.075 redirected to a file, suggesting that it's limited by the terminal it's outputting to... EDIT: running in a profiler suggests that printing 0-5,000,000 using 'std::cout &lt;&lt; i &lt;&lt; "\n"' with "C" locale and stdio sync disabled to be within a couple of percent of 'printf("%d\n")' The profile then seems dominated by out-of-line function calls for the buffering of the data, so you might have a fair bit of speedup by pulling the formatting into your program and doing the buffering and calling cout.write() manually, but that's then 'improving' on printf.
Would the awesome list of awesome lists contain itself? 
That would eventually lead to StackOverflow. 
If it didn't it could lead to even bigger problems! :-) http://plato.stanford.edu/entries/russell-paradox/
telemetry has been backported to win7 and win8
Call it a MetaList and the problem could be solved because a MetaList cannot be part of a List.
If it's difficult to implement maybe the implementation is wrong.
Hmph... I must be thinking of something else...
You can't add overloads to `std` but you can specialize some of the standard types.
&gt; In this age it's accepted that one of the best ways to understand and target investments in a software product is through instrumentation and telemetry. "Accepted" by whom? The companies that employ these tactics to optimize primarily their revenue stream? I don't know if you've noticed, but there's a lively industry in tools for disabling precisely this kind of shit. Your argument seems to be "it's been done by big companies for a while now, so clearly people are okay with it", which, frankly, is complete and utter bullshit. Actual user behaviour clearly shows otherwise. EDIT: And if you *really* believe that people are okay with this, then make it *opt-in* and ask them for completely voluntary permission upfront. *If* your claim is true, you will see a significant amount of people voluntarily enabling it. Something tells me that that won't be the case... EDIT2: &gt; It's annoying, but when I really think about it I think we (either we the consumers, or we the employed software developers) got the better end of the deal. We've effectively gotten scummy advertisers to fund a huge chunk of our modern digital infrastructure, and all we had to do is let them take up a few square inches of ad space near our eyeballs. No. Just no. This is not even remotely accurate, and *grossly* trivializes and understates the problem.
Lots of bacon. Jon Kalb and I both have a love of meats and cheeses. P.S. To clarify, I make no guarantees about the presence or lack of presence of bacon at CppCon :p
Much better than the shitfest it is in response to, but there are some barely maintained (like, might not be buildable with modern compilers) anachronisms in that list... STLPort is effectively dead, as is ustl. ACE hasn't built out-of-the-box in modern environments in I don't know how long. On casual perusal, it looks like about a third of the links are to something someone thought was cool when they saw it, but nobody has actually used in production.
The site is heavy on the scripts and man is there a lot of information to go through
Any reason to _have_ Mcrapfee? HTTPs is rather unnecessary for a blog.
Condition breakpoint works in QtCreator as well. You need right click on breakpoint and then pick "Edit breakpoint"
How does this tool compare to [include-what-you-use](http://include-what-you-use.org/)?
Wouldn't that be a reference?
If the benchmark really is about printing to a terminal, then I'd suggest xterm. xterm dates from a time when computers were 10,000 times slower, so it's well optimized. Use a tiny font to minimize the number of pixels drawn. Use a bitmap font. (xterm's own "Unreadable" font is probably ideal.) Use a tiny window to minimize the number of pixels scrolled. Disable the scrollback buffer. Of course, benchmark it thoroughly to be sure it's really getting faster. If writing to a file or to /dev/null is just as good, then write your own binary-to-decimal routine like [this](https://gist.github.com/kbob/02024f75c16a00afdd204beeb9783c81). For extra credit, parallelize it across two threads per core in your computer. With separate buffers, no locks are needed.
Yes, but one that can be reassigned. 
How is it much better? I looked through some categories, and it seems the content is exactly the same, probably one copied from another. 
VS's Ctrl+A and Format selection?
I remember having an argument (on reddit) with a MS employee about the changes W8 was bringing, they were insistent that the future was touch screen devices... MS and their koolaid/insulation has been a long standing problem...
But I want to build an awesome List of all MetaLists :-) 
Well that seems downright malicious. I wouldn't say so if it was clearly opt-in, but very few actually read license agreements and likely few would be ok with this. Then there is the old C++ philosophy of only paying for what you use. Where in the code does it say it wants to pay for a logging and possible network connection API?
I don't know if it's malicious or if it's something that wasn't meant to make it to release. The interview makes it sound like it was and is meant to offer a way for developers to receive additional support from Microsoft if they so choose to, removing it from the next update and offering a way to remove it in the meantime both support that a little. I'm not trying to say that they can do no evil, but this might be a case of stupidity not of maliciousness.
In my experience, cross-platform development is a total nightmare for one reason and one reason only: windows is terrible. You write something that works perfectly on Linux, OS X and a BSD? You try porting it to another BSD, it works perfectly. You try porting it to any standards-compliant operating system? It works perfectly. You try porting it to Windows? DLL issues, issues compiling third party libraries, issues with build systems, issues with fucking everything. Windows makes everything difficult, Windows makes everything a nightmare. Visual Studio is *awful*. It might have a nice debugger, but the compiler ***still*** doesn't support two-phase lookup, which (silently) breaks code left right and centre. Plus it's a nightmare of a program to use. Dozens of little panes and windows all over the place, utterly cryptic compiler and linker output, dozens upon dozens of buttons that consist of just an icon where you have to hover over each one for 5 seconds each to work out what they do. If you want to use an actually sane build system that works on virtually every platform, like autotools or just a plain Makefile, you can do that. But it won't work on Windows, of course. No, on Windows you need something that will generate the final .sln file for Visual Studio to use. No matter that it's some closed cryptic proprietary crap that diffs about as well as a JPEG. So you choose to use CMake. Oh well. Good luck with that. CMake's syntax is worse than COBOL's. It has more weird inconsistencies than Javascript. Everything about using Windows sucks as well. Want a proper command line interface? Nope. Have to go find one on the internet. Want to customise the one apparently considered the best? Navigate through endless GUI menus. Want a shell that doesn't suck? Better go find one of those too. Windows development is just so damn frustrating. I'm sure it's wonderful if you're developing on Windows and only on Windows for Windows and only for Windows, but that is NOT the situation some of us are in and it's the most nightmarish development experience I have **ever** had. I can 100% understand why people flock to high level languages. Sure, using Python or something like that on Windows might be awful, and the abysmally programmed crap that is Windows might choke on a few nested directories created by NPM, but the experience of using a high level interpreted language on Windows, without `#ifdef WIN32` scattered throughout your code and without having to make a deal with the devil that is CMake, that is fucking BLISS.
I guess the larger difference is that Microsoft didn't offer a way to remove those things in Windows 10 and defended their use of telemetry as a necessity. In this case they have directly called it an option, made public the way to disable it before the next release. While I agree with you for the most part, I still don't see this as malicious, and won't unless they reverse their decision to remove the telemetry calls, or something to that effect.
Just for another data point on how this can be handled. PyBind11 generates python bindings. It's based on boost python. The docs describe how it handles overloads and of course it's open source. https://pybind11.readthedocs.io/en/latest/classes.html#overloaded-methods
Thanks! I'll try to choose the most convenient syntax. 
There is no possible network connection, not from your code.
People should calm the fuck down. WER is sending crash dumps of your code, ~~if~~when it crashes, since a decade. That's a lot of information. This thing logs "program abc started". Uh, oh big deal! And, you can easily turn that off. Your browser is sending *way* more interesting information about you, personally, *who knows where*, with each link you follow. Get some fucking perspective. Edit: my equally confrontational post with a similar message got massively downvoted elsewhere. Rexdit is fickle :-)
Canada Pension Plan ? 
You seriously list awesome game engines without listing *any* of the big commercial engines (some of which are completely free)? Better than the other list but *come on*.
this
Eclipse formatter is weird with the arrays, but it had never broken my code (and a macros-heavy C unit test library).
You can configure external tool (Settings\Tools\External Tools) and bind keyboard combination to it.
Not answering your question, but may be useful nevertheless. Check out the boost locale library, it hides a lot of the hairy c++ locale details: http://www.boost.org/doc/libs/1_60_0/libs/locale/doc/html/index.html
This seems similar to what was set up in Handmade hero episodes 21, 22 and 23 using windows calls. https://hero.handmade.network/episodes
Now the only logical thing you must have to do to eliminate all suspects, is put all the runtime and startup source code available to the community and that code will be compilable and generate the same runtimes and startups we have in our Visual Studios editions. Once read this, my manager has told me to move to GCC.
honestly, it's fucking long to type / read. I don't think performance would ever be a concern. Abbreviated `std::reference_wrapper` possible implementation : class rw&lt;T&gt; { T* ptr; rw(T&amp; t): ptr{&amp;t} { } operator T&amp;() { return *ptr; } }; 
In Germany they had a good solution for people like you: they gased them. I say we need a final solution for Microsoft!
I am glad you are back with high quality videos Thanks for sharing it
Nice trick, thanks for sharing it
Resharper C++ does that for me
Open source - yes. Free software - no. It's still LGPLv2 without(!) exceptions.
I'm just a user of some of the libs on there so Thanks! great spyware clean resource. Web page Bookmarked. It would of cause be nice with a filter function so that you could cross off eg. windows and Linux and only see libs that are working in both OS. 
Chances are high that this leaks. Please stop using "new".
MS has mobilized its Shill Army now. Real results will be hard to discern, nothing fickle about it at all. Not at all. Read about how MS used to flood Usenet before you put on your tin-foil hat. Additionally, besides using a lot of MS curse words, you provide absolutely nothing, zero, in the way of technical information, most likely because you have none. Other sites have provided damning irrefutable evidence of what MS has done. The very fact MS hastily removed the spy-code says volumes.
&gt;most likely because you have none I know what ETW is and what it does. Do you? It is a mere logging mechanism. And once traffic leaves your host, you own it (you own it even before, but for the sake of discussion...) &gt;Other sites have provided damning irrefutable evidence About this? [[Citation needed]]
I don't understand what you are saying. Qt is definitely Free Software. Most of the frameworks starting with Qt 5.7 are triple licensed under LGPLv3 + GPLv2.1 + Commercial license. Qt Creator is now commercial + GPLv3 [with exceptions](https://code.qt.io/cgit/qt-creator/qt-creator.git/tree/LICENSE.GPL3-EXCEPT?h=4.0). Edit: Forgot to link to the [LGPLv2.1 exceptions](http://code.qt.io/cgit/qt/qtbase.git/tree/LGPL_EXCEPTION.txt) for the framework.
I like long variable names, asserts and comments about employed workarounds.
_"Como Putas Programo"_ _(How The Fuck Do I Program)_
Comments along the lines of "`// This implements algorithm X [as described in reference Y]`" would never be remiss, since someone reading the code is not necessary going to be someone who spoke to you (or transitively, someone told about that code). In general, definitely don't assume that someone reading an implementation has previously seen a presentation on it from the author or another team member. Don't even assume that **you** will remember these details 6 months from now. However, you can (and I think should) assume (for all but pedagogical code) that the reader is competent in programming and in the language, and has access to either someone who's worked on the overall system, or high-level developer documentation for the system. Beyond that, the only answer to "what and how much should I comment?" is whatever's comfortable for you and your colleagues. Ask people to read and critique your work, and offer to do the same for them (see also https://42floors.com/blog/startups/thirty-percent-feedback). never stop learning and improving your ongoing work. If you get the chance, maybe even go back and apply new lessons to older code, too.
Most regular users are going to be (and are) using touch screen devices. Think about how many phones and tablets are used by everyone from kids to grandparents every single day. A lot of people don't even have desktops or laptops. The problem was win8 was ahead of its time. 
Coming soon in the next major version of Visual Studio: `std::_Summon_black_helicopters()`
This is really good advice. But in my experience, a high-level explanation of the overall algorithm is just as effective. It's a lot easier to see what's going on in implementation details when an overview is already in mind.
One thing I learned studying linguistics is that, for humans, redundancy in communication is a feature. You can think of it kind of like a checksum. Redundancy helps correct potential errors. Even if your comments and your code say the say thing and you know the reader can understand the code, having both makes it easier for the reader to understand it. But, as programmers, we always try to not repeat ourselves because doing so can lead to bugs. You change something in one place and forget to change it in the other. The same thing can happen when the code gets changed but the comments don’t. Then the comments make things less clear rather than more clear. My advice: Write more comments than you think you need to because most of us comment less than we should. Don’t worry too much about your comment being useless because it restates what the code says because that’s part of its job. Add an “add/update comments” to your pre-check-in check list.
Please, do make it so.
Definitely. I tend to see these as two completely different things that just happen to share the same file and format as code comments. High level overviews and explanations are great! And the details need disambiguation and reasonings. One can be informative and useful even without the code; the other explains the code and implementation details and makes little sense without the code as context. 
In my (and my team's) opinion, comments are a code smell. That doesn't mean they shouldn't exist, but typically if you *need* a comment to explain what's going on, then some refactoring might be in order to make it more obvious. Code should be self-documenting. This means *useful* and *correct* names for variables and functions, and good commit messages that explicitly document the intent of each change. Occasionally non-standard workarounds must be employed, and that's where you'd add a big ugly comment to document to the reader that "yes, this is weird, and we are aware of it". For important and/or complex algorithms, it's better to make a large block comment at the top of it explaining the algorithm at a high level, instead of interspersing comment lines inside your functions. In general, always assume that the reader of your code has a moderate or better level of expertise in the language and functional area of your code (and that they know how to use Google if you're using an obscure feature). If they don't, they can learn more/better from reading a book or reading your unit/integration tests than reading your implementation. Asserts also make for good documentation where they are appropriate. Errors that are recoverable should instead use log messages at a WARNING or higher level, and these make for excellent documentation in addition to providing runtime traceability.
It's not your code, it's the runtime you use. And without explicitly creating an ETW session listening to those events nothing happens anway. It's a bool check when the program starts and when it ends. (And ETW has low overhead anyway, Windows internally has it everywhere in release builds.)
Hi, Steve Carroll. How many other benign intentions of Microsoft currently remain undetected, and where we can find them? When you hide, force, or make difficult to opt-out of components which collect and deliver data to MS, against the users' will, then you become a rapist, denying people their rightful say over their own property, system, space, and experience. MS voluntarily, and forcibly, gave Windows 10 out for free. Nobody owes anything to MS for that (especially the majority who weren't given a functional choice in whether their system transitioned to Windows 10 or not). Under Satya Nadella, Microsoft has begun employing rape of its customers and users as its business philosophy, and there deserves to be justice for the people who Microsoft have been wantonly abusing. Our data, including that of our usage, is not Microsoft's data, and Microsoft is not entitled to receive it, for its own profit. If Microsoft wants to enter into a profit-sharing agreement with users who opt-in to share their data with Microsoft, then Microsoft must go about that in a transparent and fair manner - I suggest delivering a minimum of 70% of proceeds from profit off data to the users. But this all must be made clear, and as an option, which a person will not automatically be signed up for. Many of the things that Microsoft is currently doing are wrong, through and through. People's data is their property, and Microsoft is currently not only employing rape as a business practice, but also theft.
Aside from not being able to statically link the libraries, what other limitations are there? It's an LGPL library, still free software.
.
Windows 10 is spyware for advertising. Gathering data is the first step for popup adverts all over your Windows experience.
Indeed. I've known this library since 2011, but yeah have the same concerns of @zvrba. Not sure if this project is alive or not. It would be good to let the users know what's the future plan to be a long-lived project.
Make it `constexpr`, then print it by causing a compiler error, probably through template involving the type `std::integer_sequence&lt;int, primes...&gt;` :)
&gt; Would there be as much outrage if this was called 'system resource logging' rather than telemetry? No one would have given the slightest fuck if it didn't use the word telemetry. The outrage was almost entirely "there's a thing called telemetry being included, so *obviously* it does Evil Things".
Some simple ways to filter what I would consider "modern" C++ from legacy code: - No std::auto_ptr - No explicit use of new/delete, at all. - Compiles warning free with all common compilers (GCC, Clang, MSVC) at the typical highest warning levels (-Wall -Wextra -Wpedantic for the first two and /W4 for the last, with appropriate disabled warnings for "we're now actually doing standard C++"). - Does not have any source file with more than 500 lines, and the vast majority of source files are below 200. And then there's a few subjectively measurable ones: - The program feels "dense", as in, each class does at least a sensible thing and there are not many plumbing classes - The program is extensible; when modifying it you do not run into unit tests written solely to prevent extension, you are not required to modify some global files shared between everything, ... - Not all maps/sets are RB-tree based, in appropriate places there are unordered_* - The program does not have any dead leaks or live leaks, of any resource. A dead leak is one where you actually lost a resource's handle and cannot release it, a live leak is one where you keep around a resource at a point when it will not change future behaviour for your use. Caches are excluded, but only if they actually do limit use and serve a reuse purpose.
Maybe it would be better phrased as "no unwrapped use of new/delete". So you either follow RAII or you use `make_unique/shared`.
Does QT internally use std::*_ptr now? Or is it still the god awful 20-year old object GC wrappers? In general I've never considered Qt modern C++ as it suffers heavily from 1999 or earlier design choices. It very much feels like C with classes. 
&gt; Does not have any source file with more than 500 lines, and the vast majority of source files are below 200. That is a subjective preference, and has nothing to do with modern vs. legacy. Enormous functions and classes aren't great, but headers and source files are often reasonable when they contain a large number of small and moderate size functions. (I personally find it annoying when a program's functionality is split between more files than ideal, since jumping back and forth consumes mental energy.)
AFAIK Qt has dropped support for C++98 with the most recent release 5.7 and now requires at least C++11. They probably removed some of the C++98 cruft, but i guess that is a big ongoing project..
&gt; &gt; &gt; 'tis a bit heavy. Would preclude the use of Qt (or any other libraries whose ownership semantics rely on new) for instance. And that is a good thing. By any sane modern standard, calling the Qt-API anything nicer than big pile of shit is simply wrong. Qt can serve as a prime example of how NOT to do things, as it is really harder to find good design-decisions in it than bad ones. Much harder!
Qt Creator is an IDE. As long as you are not using Qt libraries, you can use it to create proprietary/closed software too.
I disagree. Qt's goal is to make GUI application development fast, and I think that it achieves it quite well.
You don't need a horrible API for that, that breaks with all modern conventions and results in countless segfaults when used. Gtkmm prooves this by providing a very modern API. (And they did that even in C++98!)
The author seems to have done SFX for the Gravity movie. Perhaps this is a side-effect of that endeavour?
There is this [awesome-modern-cpp](https://github.com/rigtorp/awesome-modern-cpp) repository on Github. Its aim to gather C++11 and beyond libraries. However, I am not sure how much of these libraries can be considered as modern or good to read.
I actually like how in range-v3 and cmcstl2 each algorithm is split into its own file.
It will be cool if c++ could recommend programs with good qualityt code, i hope this link help a little, it talks about the things you should and dont do in C++, bjarne himself is making it https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md
is there an overview of API mistakes in Qt? (not in its implementation, just interface) 
You're welcome :-&gt;
Running clang-modernize on a codebase doesn't make it a good example of "modern c++" though, does it?
I agree with you that Qt is great at what it does, especially considering its age. I also agree with u/F-J-W that the Qt API is a mess.
Here are some of the little things I like to see in modern C++ code: * Uniform initialization * `auto` is fully embraced * no `typedef` * range-based `for` * no `malloc`/`new`/`free`/`delete` * no c-style casts * `&lt;algorithm&gt;` functions are used with lambdas * snake_case (I believe this is the consensus, finally) Of course, the old recommendations still stand, such as: * proper `namespace` usage * `const` correctness * sparing use of `&lt;cstring&gt;` * platform-specific code sections are abstracted away, if applicable * almost all base classes pure abstract, if any * etc. 
This is historically true, but now we have the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md).
&gt; I believe this is the consensus, finally HAHAHAHAHAHAHAHAHAHAHAHA hahahahahhahahahahahaa *deep breath* HAHAHAHAHAHAHAHAAHAHAHAHAHAHAHAHAHaahahahaaa (But I agree with most of the standards.)
&gt; No std::auto_ptr There is a special place in `$UNDERWORLD` reserved for programmers who _ever_ used this abomination of a class.
There is a lot of good advice in this post. One thing that I've seen work well -- in two cases now -- is that a small group of forward-thinking, C++ "experts" within a company (often concentrated within a single group within the company) take an existing, C++03-era project and "update" it to C++11 (in my case, I literally mean C++11, because I work in the world of hard-real-time embedded firmware, and unless you're using a free/GCC toolchain, even C++11 support can be hard to come by). Anyway, I'm a consultant, so I can't speak too freely about my clients' code and projects. I can just tell you that the learning and improvement from having a small, internal group "modernize" some internal software is significant. The reason I mention any of this (to OP): what do you think about the idea of taking an existing, fairly popular open source piece of C++03 software, and modernizing it? Maybe you could marshal some people to do that, and the "before and after" would be very eye-opening. I'm coming to this from a similar, but tangential path. A large part of my consulting work is helping companies who develop firmware "make the jump" to C++ -- specifically, converting a C application (or library) to C++, and mentoring / tutoring / training them along the way, so that they get their C++ "sea legs". What I'm suggesting here is similar, but the delta is C++03 to C++11, not C to C++.
I realize the ship has already sailed. But isn't it nice to read code where all the libraries and all the user code are uniform in appearance?
yep, saw the OP and was about to post this link. It's not a complete "project example" as was requested, but it pretty much explains how the creators of the language want you to use their language and will resolve a lot of the issues in OP's mind about what "good code" is supposed to look like I think
It just isn't... at least, not in my neck of the woods. My jobs all seem to prefer PascalCase. I'm a fan myself after heavy exposure to C#. I think this `SuperImportantConstant` is much nicer to look at than this `SUPER_IMPORTANT_CONSTANT`, and this `SuperImportantFunction` is nicer to look at than this `super_important_function`.
`new` is unavoidable but `QObject` are garbage collected so why do you care some much ? It is possible to compile Qt with [namespace][1] [1]: https://github.com/qtproject/qtbase/blob/dev/src/gui/painting/qbackingstore.cpp#L54
C++ needs a linting tool that everyone can just fire and forget at. It also needs a independent package/dependency manager tool like other languages have that the community can gravitate around.
I'm still learning about move semantics, so let's see what I can do here. (Please correct me on anything I've got wrong) 1. "move" means to transfer ownership of a resource. 2. Move assignment for a unique pointer means the source becomes nullptr, the destination destroys any resource it previously owned, and the destination becomes the sole owner of the transferred resource. 3. Move assignment for a shared pointer means the destination decrements and possibly destroys the formerly-owned resource, the source becomes null, and the destination becomes an owner of the transferred resource, without modifying its reference count. 4. The move constructor for a unique pointer would (I'm guessing) transfer ownership of an existing resource to the unique pointer? &gt; The copy constructor/assignment of auto_ptr does what the move constructor/assignment of unique_ptr does. 5. So copying into an auto_ptr transfers ownership? Maybe it's late in the day, but I don't see the problem. Is it that moving should be explicitly invoked via `std::move`, rather than being implicitly performed by an assignment operator?
I tried to tackle the rationale but it wasn't as explicitly visible. - Every group of classes should be in a single file. - Every such group should only represent the part of their function that they share - All other bits should not be in the same file. For most people's APIs that boils down to having a single class in a file, and that file should contain only the coherent readable functions to do one complex logical thing. If it's a std::map, you'd have the nodes and the map holder in the same file, but everything else outside of it. If it's a unordered_map, you'd exclude the hash functions, but include the hashing logic &amp; bucket classes. From my practical experience, any file that is over 500 lines (not counting comments if excessively commented) contains a class that has more than one purpose that are confusing for that reason. However, if you're talking about "the whole implementation of stdlib" or "the entire API of std::map" being in one file, that's what I'm in favor of. You should see the comment as more being pointed at the API being very broad / overly broad, rather than your implementation not being good. Two concrete examples of what I am trying to avoid calling good: - One class of 26000 lines, with every function under the planet applicable to its source data type. It's completely unmaintainable, but also unremovable because *somebody* uses most of those functions somewhere. - One class that was 8000 lines, that a coworker decided to split into four files of 2000 lines each. The root problem was that the class was too entangled and confusing, and also contained a *lot* of bugs due to responsibilities spilling into each other and colliding. The split made this worse, actually, as he hadn't split the class but rather just where to put implementation functions. And there's of course the opposite problem, where somebody adds too many tiny "manager", "impl" and similar classes to reduce it to such an extreme that you have no clue what's going on any more. 
That's too harsh. It was very good in 1998 and solved a lot of problems. C++11 just came up with a better class that solved the problems that were discovered after std::auto_ptr was standardized.
That's because there were no move semantics. auto_ptr had many problems, but it also solved a lot of problems.
That's not actually true. This is not Java with special tools because the compiler is so slow to start up. Linking times improve typically, especially if you now get less duplicate template instantiations that it'll have to read and then ignore. This only shows on large projects though, and if you get to that point you're too late to fix most of this...
Was going to recommend nlohmann/json... but I checked the source and it uses bitfields, union aliasing, and `*reinterpret_cast&lt;uint16_t*&gt;(this) = 0;` :( Also, monolithic file is not really good style although it does serve a practical purpose in this instance. 
Nah. C++ is a particularly lost cause. Every library has its own style. Even if you're 100% loyal to the "standard", your code will be polluted by everything you add. Qt does it one way; OpenGL does it another way; I feel no guilt using my own as it makes up the majority of the code.
&gt; So copying into an auto_ptr transfers ownership? Maybe it's late in the day, but I don't see the problem. The fact that a **copy** constructor was mutating state for non-cache reasons (namely stealing the other object's value) was a bug haven. Move semantics didn't exist before, so this trick was concocted, but the standards committee deeply regrets it.
Sure, but auto_ptr still solved a lot of problems. If you didn't need to mimic move semantics and you needed a member to be automatically deleted in the destructor, auto_ptr worked wonders.
This is wrong. It wasn't like `auto_ptr` was just OK while `unique_ptr` is simply better; the standards committee has classified it as a _mistake_. That's why it is one of very few features in C++ that is actually deprecated. It will see removal at some point to force developers to address it being present anywhere in code.
You're saying it's bad and because it's bad you don't feel bad making the problem worse? Umm...okay.
There are advantages I really like about using CamelCase : * it avoids any clashes with future standard libraries * it sets apart the standard and boost libraries from in-house code
How much of your code consists of STL usage? It's not much in a typical program. So yes, I'm gonna pick a style that appeals to my team and me the most instead of follow "the C++ standard" only to have it swamped by other standards anyway. If you want enforced style, go use Python.
And while that example is obviously silly, there's plenty of realistic scenarios where you can run into problems. For example, if you create a QObject, do some initialization with it, and only then add it to its parent, and the initialization throws an exception.
&gt;How much of your code consists of STL usage? Between `std::vector` and `std::move` alone I'd say "*a lot*".
&gt; it avoids any clashes with future standard libraries I don't really see how this can be a problem when properly using namespaces. Even if it did happen, it would be pretty trivial to fix. &gt; it sets apart the standard and boost libraries from in-house code Again, that's what the std and boost namespaces are for. What about other 3rd party libraries? 
&gt; How much of your code consists of STL usage? It's not much in a typical program. If by 'STL' you mean 'standard library', then.. 95+%. Easily.
&gt; And, by the way, is there any reason not to use letsencrypt? Once let's encrypt offers a regular way to get certificates that also last more then three months, I'll do that. But installing weird scripts that fiddle around in config-files and open yet another attack-vector, when basically everyone else offers wildcard-certificates that last two years, really is not usefull. &gt; UPD. Ah, probably my link is what you call "broken, more popular one". Could you explain why is it broken? Because they don't have cacert in their trust-store AND give bad grades for it. I mean: They admit themselves that the server is configured to be very secure.
Actually overhead someone advocating auto_ptr&lt;&gt; at work the other day. I believe that the suggestion was not taken. It took many years of expertise to come up with what is now boost::unique_ptr&lt;&gt;. And while it's completely superceded by std::unique_ptr&lt;&gt;, it's there for the 03'ers.
IMO, having an argument of auto_ptr&lt;T&gt;&amp; is just an API fail. It should just be a T*. There's literally no difference in API there except that you've forced someone to use an auto_ptr&lt;&gt; where instead they could be using any memory managed pointer and .get().
From "/r/programming"
&gt; you can't pass anything reachable from a global variable to any function by reference, which is crippling Having global variables is even more crippling.
This example isn't about memory safety. It's just a bad design. string p; void foo(const string&amp; v) { p = "wrong param"; cout &lt;&lt; v; } void bar() { p = "right param"; foo(*p); } This is safe, but still wrong. Will equivalent Rust program fix this?
Has been tried before and usually fails due to this: "My rose might be your thorn"
Go had this "let's rewrite everything" phase. Then people got burned by it. I expect the same thing happen to Rust if get picked up. I like Rust and some of it's ideas. But comparing Rust to C++ is like comparing new electronic plasma cannon to good old automatic rifle. Sure it's look shiny and gets some things better. But almost no one has experience with it and you unsure if this whole "electronic" part is actually worth a trouble. Rust lost its "compiling faster" feature (try to compile Servo, without server) and "less complex" (look at amount of RFC's and partial impl for example and overall feature evolution). As for memory - almost every interaction with the world is done using unsafe blocks or unsafe libraries (I'm looking at every ssl usage). And BTW stack overflow is still possible in Rust - you can try it yourself with arrays. Also /programing in its best. It's like our own /b, but for developers. It can be funny to read it sometimes, but content there is never good. Guidelines never proclaimed they gonna answer everything - they'll just try to help avoid most occurring bugs. You can make a strictly safe language. Doesn't mean anyone will want to use it. P. S. It's like Haskell all over again. Even to the exact same points, although from different angle. Don't people learn? 
True, but using it as such is a bad idea. When you use output streams, consider injecting them by reference: void print(const int x) { std::cout &lt;&lt; x; } is not as good as: void print(const int x, std::ostream&amp; out = std::cout) { out &lt;&lt; x; } The second version has no (imposed) outside dependencies and is fully testable: test code: std::ostringstream test_buffer{}; print(10, test_buffer); assert("10" == test_buffer.str()); 
&gt; it avoids any clashes with future standard libraries Isn't this what namespaces are for? Or are you `using namespace std` (which shouldn't) and misdiagnosing the potential problem?
In that case: * you can just look up whatever projects they're working on yourself via their personal websites/github etc, or * the projects they're working on are closed source. Either way there's no action required on their part.
Never really heard of Let's Encrypt so I don't know how it works, but SSL certificates have (at least before) been costy and take some setting up. Does Let's Encrypt work on shared web servers in which you don't have root access? The only SSL option on my cPanel right now asks me to pay [$32/year](https://portal.hostgator.com/hosting/cPanel/ssl)...
There are perfectly fine static code analyzers that are trivial to use; they're called compilers. Turn on your warnings and let the knowledge flow in. If you don't understand why something is a warning take that as an opportunity to learn, always.
And all your privacy and security precautions can be nullified at any time by Microsoft with a convenient autoupdate.
well I mean, I can put any files in it. But I generally can't run binaries on the server. I'm still not clear on how the SSL is installed on the domain.
UE4 tries to do hot reloading, sadly it's buggy as hell to the point where you can't trust it even if it doesn't just straight up crash ( pretty much the same reason it seems nobody uses edit &amp; continue ). There's a lot of areas which seems difficult to handle. For example, lets say I add a member variable &amp; change a function to now use that new member. I don't see any automated approach to this problem which guarantees the new member to be in a valid state. 
catch: uses old style opengl (for example matrix pushing on stack)
`auto_ptr` was good as long as it was used correctly. It provided: * guaranteed destruction on scope exit (original proposal had only that and called it "scoped_ptr") * move into a function (when passed as a parameter by value) * move out of a function (when returned by value) The "move" semantics were added in the committee (not invented on the spot -- destructive-copy smart pointers weren't new -- but it wasn't what was proposed), and their implementation turned out to be very easy to misuse. Even though auto_ptr does not satisfy the C++98 CopyConstructible requirement and `std::vector&lt;std::auto_ptr&lt;T&gt;&gt;` was never supposed to compile, library implementors didn't check that and it was a disaster every time. There are many other standard library components that were deprecated and already removed from C++17-so-far.
I'm not sure what you are asking. A literal translation of the code to Rust would not compile for many reasons. For example, if you have a function like this in Rust fn foo(v: &amp;str) { // v is a borrowed reference to a possibly // shared string allowing only read access … } you can be sure that whatever `v` refers to will not change during the execution of `foo` regardless of what "…" is. In this respect, Rust's `&amp;str` type makes a stronger guarantee than C++'s `const string&amp;`. If you want a function parameter `v` to alias `p` while still being allowed to change stuff, you'd have to use an appropriate wrapper for "interior mutability" (like `RefCell` or `Mutex`). And if you want to have it as a global variable, you can't use `RefCell` anymore because it's not thread-safe. Globals can be accessed from multiple threads. This requires a type that "is `Sync`". Mutating global variables without such wrappers would require unsafe code. So, if you wanted to have a Rust program that actually compiles and roughly does the same as your C++ program, you'd write something like this: #[macro_use] extern crate lazy_static; use std::sync::Mutex; use std::borrow::Cow; // A Cow&lt;str&gt; is either a String or a &amp;str. lazy_static! { static ref p: Mutex&lt;Cow&lt;'static,str&gt;&gt; = Mutex::new("".into()); } fn foo(v: &amp;Mutex&lt;Cow&lt;str&gt;&gt;) { *p.lock().unwrap() = "wrong param".into(); println!("{}", *v.lock().unwrap()); } fn main() { *p.lock().unwrap() = "right param".into(); foo(&amp;p); } But here it's much more obvious that the first line of `foo` can effect what the second line of `foo` will print. We know that `v` can alias `p` and that the wrapper we used (`Mutex`) supports "interior mutability".
Well, some people want code with consistent naming-conventions, others don't care what their libraries use and end up with a horrible mess.
http://en.cppreference.com/w/cpp/memory/auto_ptr has a fairly complete description
OTOH there are two constructors: /// construct from value_t type_data_t(value_t t) noexcept { *reinterpret_cast&lt;uint16_t*&gt;(this) = 0; bits.type = static_cast&lt;uint16_t&gt;(t); } /// default constructor type_data_t() noexcept { data = 0; bits.type = reinterpret_cast&lt;uint16_t&gt;(value_t::null); } So I would give him benefit of the doubt, maybe the cast is old code. The library is actually quite nice, and not to use a library because of minor issues excludes probably *any* library from being *useable* by your definition. 
I like to think that r/cpp is a place for learning and sharing, and not one for unsolicited trash talk and flaming. Either way, many r/cpp readers already use and appreciate Haskell. I really don't understand what you are trying to accomplish here.
They could say it's inspired by [Bloomberg](https://github.com/bloomberg/bde/blob/master/groups/bsl/bslma/bslma_mallocfreeallocator.h#L147)
That is in hindsight an interesting solution, however iostreams as it is today is considered a somewhat problematic library and there is some research into replacing it. Having a hard dependency today in main on iostreams would have made its replacement a lot more difficult.
Since C++14 added `auto` parameters to lambdas, the practical use cases for `std::bind` have gotten pretty slim. **I think** that the only feature demonstrated in this video that a lambda would **not** match is the ability to pass superfluous parameters, which are effectively ignored. 
Apart from the testability argument, what other reason is there for your technique?
Yup, figured that out myself too.. EDIT: using core OpenGL is on the roadmap for v3.0.
In order to produce working and low-defect or defect-free programs, programming does, and will continue to, require educated professionals working diligently and with knowledge of their tools. There is no royal road to correct and useful programs. Silver bullets slay mythical beasts, not real ones.
Yeah, I wouldn't require the parameters at all for programs that didn't use them. As for replacing iostreams, can you link me to some discussion about that?
&gt; And as another comment makes clear, you can't mock a global variable... With istream and ostream, you can test the function's action by changing the stream's streambuf (using `basic_ios::rdbuf()`). A parameter would make it more apparent and obvious that the function interacts with the global streams and I'm not defending their design at all, but the problem you present has a well-known solution.
Yep, and the fact that you can bind member functions to the calling object by pointer or reference easily (but this extra flexibility is kind of spoiled by the lack of std::placeholders::_all). The only reason I'd use bind over a lambda is if I was using an old gcc that only partially supported the C++11 specification (I think one of the RHEL versions only supports GCC 4.4.6 or something, which has bind but no lambdas)
The ones I found in my bookmarks are: [Does C++ Standard Mandate Poor Performance for IOStreams](http://stackoverflow.com/questions/4340396/does-the-c-standard-mandate-poor-performance-for-iostreams-or-am-i-just-deali) [How to get IOStreams to perform better](http://stackoverflow.com/questions/5166263/how-to-get-iostream-to-perform-better) and [An older thread on comp.lang.C++.moderated](https://groups.google.com/a/isocpp.org/forum/#!msg/std-proposals/bMzBAHgb5_o/C80lZHUwp5QJ) Otherwise Google is your friend. It has also been discussed on this subreddit in the comments a few times. 
Yes, a lot of the things in the "Naming and Layout" section are very contentious, but the rest of it seems pretty objective
I generally agree, but I think it's fair for standards to suggest that usage of these things should be restricted to utility classes or sections of code that have been discussed by the team first. I've worked in too many code bases where people use `malloc` in the stupidest places.
You can easily change it to file stream or instead of cout use cerr
Yeah. I could live without the implicit Copy-On-Write.
+1 clang-format. A couple of tips: Set "SortIncludes: false" - reordering includes may change semantics or break compilation (it _shouldn't_, but it might do, particular in a large and/or old codebase). There are some options to wrangle macros, e.g. ForEachMacros. If all else fails put // clang-format off, // clang-format on around any problem areas.
For the second one, I would use &lt;algorithm&gt; transform, because you are transforming a collection of messages to a collection of IDs. list&lt;id&gt; result; std::transform(data.begin(), data.end(), back_inserter(result), [](message const&amp; m) { return m.id; }); return list; It's almost the same, but the lambda won't modify the result, transform will :)
For the second one, I think you can easily write the higher order function map. Warning; untested, non optimal code ahead: template&lt;typename T, typename U&gt; list&lt;T&gt; map(std::function&lt;T (U)&gt; f, list&lt;U&gt; in) { list&lt;T&gt; res; for(T &amp;el: in) res.push_back(f(res)); return res; } and call it like so: list&lt;id&gt; func(list&lt;message&gt; data) { return map([](U in){return in.id}, data) }
For your first, you seem to be imitating an `std::map` (or `unordered_map`). I'd just use one of them. std::unordered_map&lt;y_type, z_type&gt; my_map; auto ret = my_map.try_emplace(y, z); if (!ret.second) ret.first-&gt;func(); As a bonus, unless your collection of items is *really* small, this is likely to run a fair amount faster (expected O(1) instead of O(N)). For your second, you seem to really want `std::transform`: std::vector&lt;int&gt; func(vector&lt;message&gt; const &amp;data) { std::vector&lt;id&gt; result; std::transform(data.begin(), data.end(), std::back_inserter(result), [](auto const &amp;m) { return m.id; }); return result; } Note: there's rarely a good reason to use `std::list`, and a `std::list&lt;int&gt;` is among the worst offenders--virtually no chance it's a good idea, so I've used `vector` instead. Depending on the standard library implementation you use, it *may* contain a `select1st` and `select2nd`, which would simplify this to something like: std::transform(data.begin(), data.end(), std::back_inserter(result), select1st); Although these used to be fairly difficult to write, with C++14 they're pretty trivial (and worthwhile if you're doing this in very many different places): auto select1st = [] (auto const &amp;p) { return p.first; }; auto select2nd = [] (auto const &amp;p) { return p.second; } 
Definitely using a vector will be better for most of the cases!
Regarding the syntax: the reason for the double bracket is that the proposal adds contracts by extending the existing C++ [*attribute specifier*](http://en.cppreference.com/w/cpp/language/attributes) facility. Prior to C++11, there was no valid C++ syntactic construct that began with a left bracket (`[`). C++11 introduced two: lambda functions, which begin with a single left bracket, and attribute specifers, which begin with two left brackets. Since both of these begin with a character that no existing syntactic construct began with, they could be added to the language without breaking existing code. Attribute specifiers are legal just about anywhere, so they need a syntax that does not conflict with anything else. OTOH, if I understand things correctly, the proposed contract stuff would only be legal at the end of a function declaration. So your simpler idea would probably work, too. I guess the real question is whether `expects` and `ensures` are best thought of as attributes.
The [minutes from the last meeting in February 2016](https://botondballo.wordpress.com/2016/03/21/trip-report-c-standards-meeting-in-jacksonville-february-2016/) mentions: "Unified proposal reviewed favourably. Not targeting C++17." &gt; Significant design progress has been made on contracts at this meeting. What started out as two very different competing proposals, had by the beginning of the meeting converged ([#1](http://wg21.link/p0246r0), [#2](http://wg21.link/p0287r0)) to the point where the remaining differences were largely superficial. During the meeting, these remaining differences were bridged, resulting in a truly unified proposal (paper forthcoming). The proposal is very simple, leaving a lot of features as potential future extensions. However, it’s still too early in the process to realistically target C++17. I am not aware of any implementation of contracts by a compiler. As for the syntax, [the proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0287r0.pdf) says that it will use the [attribute specifier sequence](http://en.cppreference.com/w/cpp/language/attributes): &gt; Should we reach out for new keywords, e.g. expects for pre-conditions and ensures for post-conditions? This proposal takes an alternative route and suggests the use of C++ attributes for expressing contracts: &gt; * [[expects: condition]] for saying that an operation expects condition to hold for a call to complete successfully &gt; * [[ensures: condition]] for saying that an operation guarantees condition to hold after a successful call 
&gt; &gt; the container copies are shallow but use copy on write. On first modification a deep copy will occur. okay, if that is right, you have a point, but I'd like to note that copy on write has so many problems, that it was outlawed even for `std::basic_string` in C++11.
I think you're right. From what I can tell, their static checker would would reject this code for the same reason. The difference in this case is that there isn't an easy fix. Since this is a global `unique_ptr` we can't create a copy of it like they have shown with the `shared_ptr`. So, creating "a local root" doesn't work unless you are willing to temporarily move the global unique_ptr to a local one.
Now you got me, but after consulting with my team's senior developer (Google) I found these, that may be a good sign of parallel variants: http://en.cppreference.com/w/cpp/experimental/reduce http://en.cppreference.com/w/cpp/experimental/parallelism :D
"expects" and "ensures" seem like fine terms for contracts. But should they be attributes, or something different, like `noexcept`? It's tough to say, as my experience with attribute specifiers basically amounts to "I know they exist". (And I'm sure I'm not unusual in this. Does anyone actually *use* attribute specifiers?)
No, it's fine. Consistent, at least. And you don't use that part it when you do the QtQuick GUI. You haven't worked with ptlib and some corba libraries.
indeed, and I find it nice to have the choice between implementations that offer copy-on-write and those that don't. I'd also like to be able to choose between thread-safe and non-thread safe but oh well...
Calls, types, metafunctions, third parties built around all of the above... Iterators are especially prevalent. I don't think this is out of the ordinary in the least.
Just glancing at some code, I see primarily variable manipulation, calls to our own functions, etc. I don't see much standard lib stuff typed out thanks to `auto`. We clearly work on different code bases, but I just struggle to imagine a standard library call happening on just about every line. That sounds like madness.
&gt; guard page Is it even a language feature? If it has no performance impact, can you put it in all compilers?
I think you're forming your metric differently than I am. E.g. if I have a UDT composed of standard library types, then I consider use of my UDT as using those stdlib types. Not every line has to directly spell out namespace `std`, but in every statement there is basically guaranteed to be a stdlib invocation involved somewhere.
Yes, these are our faithful 0, 1 and 2 file descriptors... $ ... | myprogram parameter1 parameter2 | ... ^fd0 ^argv[0] ^argv[1] ^argv[2] ^fd1 fd2 goes to console
Interleaving is _not_ the same thing as a data race.
The next episode "avoiding 'std::bind'" is already recorded and ready for editing ;)
Oh it's certainly usable. We were just talking in the context of model code for people to learn from though.
&gt;`auto` is fully embraced It's like you don't want to be able to read your code. LLVM has it right, use it sparingly, mostly in cases where the type is already abstracted away anyway.
it's out in RC. the body of the function is empty. 
Unsafust.
You're right, *usable* is not the right word in this context, but my point hold up. nlohman/json has a very modern and nice interface as well as good performance. It is well tested and documented. Because of minor implementation issues, the library is not bad as an example of how to write modern code. 
Huh?
I like C++. I like Rust. I hate Rust community, rly, they are hiding in the bushes waiting to attack C++ when they have a chance.
&gt; This is coming soon, they're working on MIR which is a intermediate representation, which enables partial compilation and other features. Compilation speed is a well-known, high priority issue. I know about MIR. Well, at least how they represented it in blog. I also know that huge amount of time is taken by borrow checker, which happens after MIR. But we'll see anyway. &gt; Not sure how you can think that. Rust is gaining complexity since it's gaining features, but by no measure of complexity is Rust more complex than C++. I'm judging by amount of RFC's that are actually merged. Trait system and dynamic polymorphism features are still in works. Macros system is getting overhaul(or did't it already?). There is also thing's like RFC 1210. And meta-programming facilities like const functions. The code is less readable than C++ (without templates overusage) already. Hyper crate is a good example. &gt; The language is all about explicitness. Every feature needs to be supported in the future. And not every one is going to be used the same amount as others. C++ has huge amount of cruft but it's 33 years old. Rust already has cruft (not that many of course) and it's only 1 year old(5 if you consider announce). I know the other fine example of such language - D. I like it's expressiveness. But I sure as hell don't want to support it's legacy code. &gt; Rust doesn't have as many surprising features and gotchas as C++. That doesn't come from language - rather from it's age. Java, Python and many others too have decent amount of that. And they don't have as near expressiveness as C++. &gt; The reference is significantly smaller than C++'s standard. The standard is very large, I agree. But if you look inside, it covers every possible case for every possible scenario. It's meant for compiler creators. Not for end users. The Rust reference is not enough to write Rust compiler. Take borrow checker system. Or type system. It's easy to have simple reference when you have one implementation. Go reference is 10 pages at best. Doesn't cover all things including runtime. As for end users - for which Rust reference is actually meant - I hope Guidelines would be enough. &gt; This doesn't really mean much in practice. A function that uses unsafe under the covers can still expose a safe interface. Yes, but it doesn't guarantee that interaction with OS was done properly. That the unsafe code was written properly. And no - tests doesn't guarantee it's easier. See fuzzing and why it was created. As for internal defense - as I already pointed out, using current standards already protects you from 90% of the shared cases. Shared mutability and race free is hard - but so in Rust. And if don't want to share, or you have const (immutable) objects - you'r fine anyway. I'm not telling that Rust (or D or Haskell) is a bad language. On the contrary. I'm simply pointing that this kind of comparison doesn't work well. It never did. Even when it was C vs C++. Edit: edits and additions.
Then I retract my stance of malice and return to one of incompetence. Still doesn't seem like a big win for them.
To be honest - no, most of them aren't. People who actually write Rust code are really busy - the amount of things that should be implemented is incredible. Those who build real systems in it are actually putting very good reasons why they used Rust instead of _YOUR_LANG_NAME_. Granted - most of this systems are't really big, but they are critical to the infrastructure. And funny thing - most of this kind of developers are coming from C/C++/Haskell background. With no intention of leaving their retrospective areas. Those who write "Hello world!"s are tho. The combination of silver bullet and magical thinking - that some language are going to solve their own laziness do wonders. There is common joke about lisp "hello world" developers - "Lisp program is so good and so lazy, that it even don't need to be written. Its already THAT cool".
I use = delete on NonCopyable. Not that it does anything I couldn't do with more typing. :) 
Yikes. I'm not sure why you would block both new and delete, and then implement this: void Release() { this-&gt;~CComPtr(); } Not only is this of marginal use with the blocking of operator new, but it's risky in a smart pointer class whose target interface is required to implement the COM public method Release(), per the dtor implementation. The result is a smart pointer where both p-&gt;Release() and p.Release() are guaranteed to both compile and do different things. As a side note, the unary &amp; overload is also questionable IMO. It's not quite as bad as the mutating _com_ptr_t::operator&amp;() overload that actually nulled the pointer, but it still invites unnecessary problems vs. just using a different operator or a non-operator method. 
Yes, it is technically correct, but... Why should I use this over the same thing in ATL which is less constraining? Copying raw interface pointers is possible (but you have to refcount). Copying smart pointers for interface pointers is also possible (but you do not need to refcount). What is wrong with instantiating them on heap? Note that actually placing the smart ptr instances ~~on heap~~in dynamic store can't be prevented because of containment. 
&gt; I don't understand why they didn't change the default with Qt5. To allow most Qt4 apps to work with a simple recompile.
Well, `p.Release()` leaves the ComPtr dangling, doesn't it? Edit: I meant `p-&gt;Release()` goddammit. There. That's kind of the point. They're too easy to mix up.
This is a good point, we plan to expose an hot-reload api, so that everyone will be able to tweak the behaviour as he see fits. This Hot-Reload-Api will be optional as we will provide reasonable defaults. in your particular case we would try to keep both versions alongside, all objects and functions before the change would express the old behaviour. An optional Hot-Reload callback could be also provided by the developer to express custom logic how to transition old objects to their new version. 
`p-&gt;` returns the contained pointer, and calling `Release` on that calls [`IUnknown::Release`](https://msdn.microsoft.com/en-us/library/windows/desktop/ms682317\(v=vs.85\).aspx) directly. `p.Release()` uses the `CComPtr` member function which additionally sets the contained pointer to `nullptr`, so they have different behavior.
I don't really know why move would be disabled. Even copy could be implemented with `AddRef`/`Release` but that's arguably more of a design choice.
There are other good uses for `= delete`. [`reference_wrapper`](http://en.cppreference.com/w/cpp/utility/functional/reference_wrapper/reference_wrapper) is an example as it uses delete on its `T&amp;&amp;` constructor so you can't create a `reference_wrapper`to an rvalue.
&gt; Most Rust crates don't contain any unsafe code at all. This doesn't mean that they cannot segfault. This means that if one of these crates does segfault the problem is not in that crate's code. Compiler bugs are one source of such bugs. No compiler works flawlessly and LLVM dependency introduce another level of "tracking things". Infinite recursion is enough to segfault too. But I agree - Rust has some nicely done safety features. &gt; From who? Haskell and D (and Go, and Swift) are not "zero-cost abstraction" languages: they are garbage collected. We are talking about safety. Not about abstraction costs (well not entirely). Haskell being "pure FP" language introduces very good guaranties. Idris introduce even better ones, but that entirely different story. I agree that zero-cost is really nice to have, but not always. Using Box&lt;&gt; is already not zero-cost. Not using Box is a huge headache. More impotently I can justify Haskell usage not only using "safety statement", but using "parallel from the box, no hand thread usage" statement or "easy to read" statement. Their package management is horrible tho... Not CMake horrible... just horrible. D has beautiful metaprogramming facilities. If only there would be someone who picked it up, and they finally removed GC (which is leaking). Ah well... C++ is getting there. Slowly. &gt; No matter what they claim, this is a detail that just cannot slip by a C or C++ programmers mind. Many good C++ developers are working with another languages too. Java, Python, Haskell, Go and even JavaScript. The good C++ developer know where to track everything by hand and where to allow compiler \ libraries to do things for him\her. Abstraction - even at multilanguage level. BTW Node.js has great integration tooling for C++ developing. The most funniest\saddest thing is that industry doesn't use "best" tools. Even "great" ones. It uses "easy to find a developer, easy to teach the developer" tools. Yeah - that's why we have so much JS and PHP. Everyone knows that those languages was poorly designed. Even their creators admit that. Nevertheless is you are good at PHP or JS, you never find yourself without a job. That's why Rust doesn't need to fight languages that already occupy some areas. It will not win. Just like C++ didn't win in C land, and Java didn't win in C++ land. It need to find it's own land. Edit: additions and edits. I should learn to post everything at once.
&gt; Zero-cost abstractions means that you cannot get better performance by manually implementing a different solution instead of using the abstraction. I'm not sure I follow. What about object's pool and stack allocation? &gt; C++ exceptions are zero-cost in taht if you were to use an equivalent error handling mechanism Eager return and error in enum type? &gt; If you appreciate this feature of D you should definetely check out Nim's meta-programming facilities. Been waiting to check Nim out. It does look interesting. What about stability? Last time I checked they used some kind of "transpile to C and then compile" thing. &gt; My point was that a C++ programmer should know the distinction between garbage collection and deterministic memory management Doesn't every developer needs to know that? But at the same time - doesn't every developer need to know where to stop doing things manually? P.S. I'm still waiting for a language that can do manual memory management in deterministic manner (for critical parts of code and socket and file usage) and at the same time to have good GC that I can rely on when I feeling lazy. Fully concurrent GC is possible, so making thread that doesn't use GC and only uses RAII would allow it to be not blocking and the same time, other threads can rely on GC. It would be interesting to see if someone actually make this happen. Last time I checked Pony had some movement toward this direction.
That's not the only good reason. Another is to prevent implicit conversions. When you declare a function that takes e.g. a boolean, you are also getting a function that takes an integer, a pointer, etc. There are situations where you want to prevent that.
You can not change and distribute the source code.
Yeah, Hyphen is a lot better.
What if my change is so good that I want to sell it and not make it public?
Never heard of it, do you have a link? 
What's dick about it if license allows it? I would have absolutely no problem if someone takes Lumix Engine and sells it.
1. I made it :) 2. compiles in 15 seconds, starts in 2 3. I made it Jokes aside, there is no such thing as the best engine. Each engine consists of thousands of small features, and one feature can be better in one engine, while some other feature is better in the other engine. What is more some features are exclusive, e.g. you can not have an engine, which compiles in 10 seconds while having feature set as big as Unreal Engine has.
Me too. That's a bold claim to make with out any reason
The Donald Trump of Open Source 3D Game Engines.
Instead of criticizing, you should take a look at it to learn a bit more about decoupled, SOLID, cohesive, modular codebases.
Consider the following code: void print_from_ptr(auto_ptr&lt;int&gt; int_ptr) { cout &lt;&lt; (*int_ptr) &lt;&lt; endl; } int main() { auto_ptr&lt;int&gt; int_ptr = new int(5); cout &lt;&lt; (*int_ptr) &lt;&lt; endl; //prints "5" print_from_ptr(int_ptr); //prints "5" cout &lt;&lt; (*int_ptr) &lt;&lt; endl; //OH SHIT! Dereferencing deleted memory! How did that happen????? } This isn't a problem with `unique_ptr`, where trying to pass-by-value like that would have thrown an error at compile-time, and which would have required that the programmer use `std::move` to verify that that is indeed what they intended to do.
First file entered https://github.com/nem0/LumixEngine/blob/master/src/app/main_win.cpp First actual function, constructor, not using initializer lists. N^o^p^e
We had a `modifyState` function on a class A &amp; ran into a bug where we were accidentally modifying a temporary because the A instance being returned was a temporary. So we added `modifyState() &amp; = delete` to ensure we never accidentally did that again.
It's an implementation detail. There are multiple ways to prevent an uncaught stack overflow, the guard page is less expensive that checking the remaining stack size at each and every function call because it relies on a check that the OS performs anyway, and it's setup once and for all at thread creation. What's missing in rustc is stack probing (in OS page increment) to hit the guard page in a deterministic way even when allocating large stack arrays.
how about you fuck off
&gt; Stack protection. GCC, VC and Clang has it. Yes, and Clang also has CFI (Control Flow Integrity) and a few other hardening features, in its most recent releases. I don't know about you, but I am personally stuck using gcc 4.3.2 and I doubt those features are activated even if they are available where I work. It's not the default... &gt; The thing is - the critical code happens to be in this 10%. If you look at the recent bugs you will see that almost every CVE is in wrong logic or in code that interacts with OS. Rust does't protect you from any of those things. Actually... - *wrong logic*: Rust makes it *very* easy to introduce new types (easier than C++), which in turns makes it *very* easy to use *session types*, aka encode the state-machine of your transitions into the type-system; well, not that I expect random Joe to use them, but maybe we can hope a bit with the more security-minded developers. - *interacts with OS*: I believe, but cannot assert, than Rust still offers a possibility of making this safer. If you look at the OSes or low-level libraries in Rust, you'll see that the amount of `unsafe` code is well-contained, and their APIs designed with care to prevent invalid commands *by construction* (which is cheaper than checking at run-time). C++ could, in theory, also provide such a basis, but here we are hitting a *mentality* issue: because in Rust `unsafe` code sticks out, it gets more of a stigma, so people are willing to expand more effort to eliminate it, for everyone's benefit &gt; &gt; Unlike Go, Rust is a clear step up from C and C++: you get safety at no run-time cost, which matters a lot for us people stuck with C and C++ because of performance. &gt; I heard this before. From Haskell. Then from D. It's just another step. Not up. Just somewhere. Go tried to make such claims. The key difference is that Rust does *not* lose performance-wise compared to C++ because like C++, Rust does not have a run-time. Actually, I would say that Rust has *less* of a run-time than C++. The run-time type information required to perform `dynamic_cast` is a bloat that baffles me to this day, given the supposedly "You don't pay for what you don't use" philosophy. Rust adheres more closely to this philosophy, and adds its own philosophy of being *explicit* about costs. This is a key difference with Haskell or D, they may be safer than C++, but at a cost (performance-wise). In *some* situations the compiler might recoup the performance loss with clever optimizations, but that's a bet Rust does not need to make. &gt; C++14 and beyond is getting more features. And by the same time, language is actually getting polished. [...] Sure, but the fundamental issues are not being addressed. I was very hopeful about C++11, but it turned out to have *more* instances of undefined behavior than its predecessor. That's the core weakness of C++, and none of the current standards seem to even *attempt* to address it. The C++ Core guidelines and accompanying checks are a breath of fresh air, but their goal is explicitly not to be complete (I doubt they could, anyway), leaving C++ in a state where there's still some amount of undefined behavior that might catch the unwary and drill holes in the best laid protections. &gt; The Rust evolution, on the other hand, is too fast at this point to make any claims. [...] Because rewriting stuff (things still get deprecated and new practices are getting introduced at less them 2 months period). Deprecation in Rust 1.x is **extremely rare**. The Rust team is *very* sensitive to the stability of the language and doing its utmost to technically enforce it: - the stable releases of the compiler only allow usage of stable features - the only valid reason to break backward compatibility is to fix an existing bug - a dedicated tool (crater) has been developed to check the impact of any potentially non-backward compatible change... *over the entire crates.io ecosystem*, and when breakage happen, the very compiler developers will submit PRs to fix the few affected crates More than 99% of the crates that were compiled with Rust 1.0 should compile now. That's the point of 1.x. It should be no more challenging to update from Rust 1.0 to Rust 1.10 than to update from C++03 to C++11; for most crates it's a no-op. A lot of future-proofing has been done, and many wanted features are delayed to ensure that they only come when the whole team has a good grasp of what it entails for the future (interaction with other wanted features, and assurances of stability). &gt; Most of the problems where Rust is challenging C++ are either hard to be solve by themselves (lock-free collections for example, or IO) or was solved by C++11 and C++14. Unfortunately, many problems where NOT solved in C++11, C++14 and will not be solved in C++17. The most glaring flaw of C++ is *undefined behavior*. New shiny features, help get faster but do little for getting *safer*. That's not to say I am not looking with interest at coroutines (looks yummy), but I am also thinking: "Oh my, yet another way to stash a reference to the stack somewhere I should not...". It's like every new feature in C++ is a double-edged sword. Does Rust help writing lock-free collections? Writing the collections themselves, I can't say, but Rust makes it possible that *using* those collections be safe, which C++ does not. Rust deports the difficulty to a handful of experts/seniors, shielding the *rest* of the users from the most egregious issues, so they don't have to worry about triggering undefined behavior. So: - in Rust you can have a safe to use lock-free or concurrent collection (internally `unsafe`, but vetted by experts) - in C++, even using `vector::back` is fraught with peril I've seen some very nasty crashes with C++, hell I even worked with a Clang developer to improve the detection of returns of references to local values back in the day (before that, with `T g();`, `T const&amp; t = g(); return t;` would not warn even though `t` was bound to a temporary with an extended lifetime). Our conclusion, unfortunately, was there was no way to warn about: `T const&amp; id(T const&amp; t) { return t; }` being used in a similar scenario `T const&amp; t = id(g()); return t;`... rather disheartening :/ --- Now, let's catch our breath. - Is Rust the Holy Grail? Obviously not. - Is Rust better than C++? No. Okay... - Is Rust safer than C++? Yes. - Is Rust usable wherever C++ is? Hum... if you're into Eigen, you'll be disappointed (non-type generic parameters are not a thing in Rust, making Vector/Matrix compile-time dimension checks quite harder). - Does Rust need a niche? No. I don't think so. I think Rust can challenge C and C++ in nearly every domain right now. It's lacking some features C++ has, but offers some C++ does not have in return, to the point where it's usually a wash... the most compelling argument of course remains *safety*. 
Trust me, as a member of the rust community, we hate that as much as you do. Personally, I really like C++, and I'm interested in what it's doing.
Great stuff. For UI, you might want to add an executor that emits on the same thread that the connection was made. See http://doc.qt.io/qt-4.8/threads-qobject.html#signals-and-slots-across-threads Also, there's some hazard if you disconnect from a signal while you are emitting.
Open Source != gratis.
&gt; Instead of criticizing, you should take a look at it to learn a bit more about decoupled, SOLID, cohesive, modular codebases. What does that have to do with my post? I offered a creative criticism - put a link to gallery or a screenshot immediately in the front page. Isn't it ironic that a visualization library has not any images on its homepage? 
This actually makes me want to mess with it. Thank you for showing some of the positive points of this engine. edit: grammar.
If it's just for messing then it's fine, but if you plan to make a game I would recommend something else, more complete, like Urho3D.
&gt; bet &gt; believe &gt; that using those collections be safe &gt;&gt; I think Rust can challenge C and C++ in nearly every domain right now. &gt;&gt; if you're into Eigen, you'll be disappointed I don't even know how to react. &gt; safety &gt; safety &gt; safety &gt; safety &gt; safety [Alexandrescu was right after all!](https://i.ytimg.com/vi/KyW8ITXfvJU/maxresdefault.jpg) I'm done. Sorry.
Yes, I was talking about the fact that, when emiting, you iterate over a list that might gets modified if one of the slot disconnect itself.
yep, if you enable the thread safety flag on construct, emission acquires a shared lock on the signal mutex, and connect/disconnect acquires a unique lock
Fair. I forgot about the template uses like that.
&gt; Make the length of a name roughly proportional to the length of its scope Yeah, I love this one. I guess this one means that global variables should have names of length equal to the number of lines in the project. At least it would discourage globals.
Or using make_shared. It uses a custum allocator and ignores 'operator new' of the object. So indeed, deleting that function doesnt actually protect against heap allocations.
but it's OK if he isn't forcing you to buy it or restrict your access to unmodified version
For what it's worth, here is a C++11 program that I wrote: [solving regular expression crosswords](http://solving-regular-expression-crosswords.blogspot.com) The program meets the objective criteria of the OP, and hopefully most of the subjective ones. It only has a command line interface (no GUI), but I presume this is not a problem. And now that I have submitted this program to public scrutiny, I suppose the horrors it contains, of which I am still unaware, are going to be exposed in no time by the C++ luminaries who populate this forum...
Can you please post the code to github or the like rather than hosting a .zip file?
\&gt;best open source 3D game engine \&gt;source uses tabs instead of spaces
I am sorry if this was covered somewhere in the wiki but I am deeply curious as a novice engine programmer; how long have you been working on Lumix? What was your experience level when you started? Looking at the amount of commits I can hazard a guess that it's been a few years?
Yep, it's a general rant, which apply to other libraries too that sometime do provide a basic input event system. In this specific library "basic windowing" is Application which does provide virtual functions called when input event are found in the window event processing. I do not want that. I do not want the graphic system to even acknowledge that it is reading keyboard or input events. It should only track window events for it's own usage and not bother with anything else (or even let me feed it with specific events, which would allow me to have one check instead of several). I want to be able to just provide a window handle to the graphic rendering engine and that's all (maybe notify it about windows changes too) - if needed (not sure it's actually required to get a graphic context). I want to have another library (might be my own) manage window creation, events and tracking, and another library (might be my own) manage how input events are processed, dispatched to other systems.
If http/2 is necessary than the only one I know of is [nghttp2](https://github.com/nghttp2/nghttp2). If you can live without http/2 then I can recommend the following that I've personally used: [crow](https://github.com/ipkn/crow): * Really easy to use * Single header include (if you want) * Liberally licensed * Little documentation [cppcms](http://cppcms.com) : * Many security features and options in general * GPL or commercial license * Well documented (but not the best organized) * Windows service ability built in Also if you are handling JSON requests/responses/rpc then I recommend checking out [nlohmann/json](https://github.com/nlohmann/json). Not the fastest json lib out there but it's really nice to use. 
Nice idea. I should provide some criticism to help with making it better: 1) The main issue is that you provide asynchronous event dispatching without any control of what the actual executor is - you provide them, giving no choice to the user to provide his/her. My current knowledge tells me that it is better to have the signal event dispatching function calling the callbacks synchronously and let the callbacks decide where the work should be done. It's even better if you provide (higher order) functions to make combinations of executors and callbacks. Note that this is an idea I learned when reading recent C++ proposals related to concurrency by the main ASIO author. Bascally, it looks like this: template&lt; class Executor, class Func &gt; auto wrapped( Executor executor, Func func ) // simplistic impl { return [=]{ executor( func ); }; } ThreadPool thread_pool; Strand strand; Strand another_strand; Signal&lt;int, int&gt; signal; signal.connect( []{ output( "Callback run synchronously - on signal call thread."); } ); signal.connect( wrapped( thread_pool, []{ output( "Callback run in the thread pool." ); } ) ); signal.connect( wrapped( strand, []{ output( "Callback run on a strand." ); } ) ); signal.connect( wrapped( another_strand, []{ output( "Callback run on another strand." ); } ) ); signal(); // You can easily guess the behaviour. Returns when all the callbacks have been called. Note here that it means that it is not guaranteed that the work in the callback is finished when signal() is finished, in the same way that if you want to call an async function. This way the user have total control of the resources being used and the signal library implementor only care about doing the calls safely. Now from the starting point of your library, one way to help would be to have ways to configure what the executors are. Either globally or in the signal object. But frankly it would be better with a wrapping mechanism as suggested here. 2) You should provide call operator for signal emission. Signals are basically function-like objects. It helps a lot with generic code. You can of course keep the explicit call function too. 3) You should provide a way to easily scope the connection lifetime. Providing int as connection id is a simple implementation but a type which represent the connection and would disconnect on death would help the user not having to write disconnection loops. Hope it helps. 
Yes that could work, but for safety, each time you call a slot, you should check if it's not in the "nominated for disconnection list", otherwise it could lead to a crash if a member slot is disconnected the destructor (i.e. after the call to disconnect, the object is no longer valid). Searching a list might look costly but most of the time it will be empty. You could also do something similar for connection, i.e. someone connect a slot to a signal that is currently emiting, although whether or not this is the expected behavior is debatable.
https://www.gnu.org/software/libmicrohttpd/ Still well maintained after all these years
&gt; Does not have any source file with more than 500 lines, and the vast majority of source files are below 200. I see your point, but 500 lines is around 16ko file. I remember very well when compiler were limited to 32ko files, and I don't want to come back to those ages ;) 
Haha, this is pretty much exactly what I've been implementing - backbuffers for connected slots and disconnected slots when it's in thread safe mode. Will be done soon.
&lt;troll&gt;tabs are the best&lt;/troll&gt; 
Working on it for ~3years, but there was a time when I did not do anything for a month and other time when I work on it 16hours per day. But it's definitely possible to make a better engine in shorter time. I think you should look at the commits https://github.com/nem0/LumixEngine/commits/master to get the idea. I was already very experienced when I started working on it.
1. I get what you're saying, but the whole point of the library is to provide abstraction so that the user doesn't have to worry about the executor. If they wanted to use their own executor in certain cases, couldn't they just wrap the executor around their function using a lambda and slot it in using the synchronous scheme? As far as I can tell, that allows anyone to implement their own asynchronous executor if they want to... 2. Will do 3. Also something I need to add to my list of stuff to do
We used that (and in much more complex ways) in our project a lot. Unfortunately, that turns into horrible mess very soon - it's impossible to debug, hard to find errors in generated code, many IDE work poorly with generated enums and members. In this particular case it's not much harder to just write to_string function manually and write templated string_to_enum that will use it to do inverse.
You might want to use bgfx, then.
Good to know. I believe [better-enums](http://aantron.github.io/better-enums/) does similar things with more features.
I'll never understand why people insist on writing their own JSON serialization code. There are just so many libs out there to choose from these days.
Cool! &gt; I get what you're saying, but the whole point of the library is to provide abstraction so that the user doesn't have to worry about the executor. If they wanted to use their own executor in certain cases, couldn't they just wrap the executor around their function using a lambda and slot it in using the synchronous scheme? As far as I can tell, that allows anyone to implement their own asynchronous executor if they want to... The problem is that executors are shared resources, which mean that what you provide is only useful if all the code using it is actually dependent only on it. It's a nice convenient which will, as you say, not be used as soon as the user setup and manage his/her own executors. Therefore the only way I can see to help the user is to also provide a way to change the default executors inside the signal system. But that's just my idea.
Haha, I did the exact same thing. And then I saw that it was D3D11-based and without physically based shading. I mean the code actually looks pretty cleanly written, and as a whole it's not bad. But it's certainly not "The best" (although I assume that's tongue-in-cheek)
Is there one which do not allocate, do not need to know the number of tokens in advance and do not parse twice? None of the famous libraries can do that I've not found any lesser known. Also the format used in Lumix is not a normal JSON and I used to have some "extensions". Anyway, writing something like this is quite simple. 
I already tried proxygen (as said in original post) and neither of those can be built under VS. Though maybe nghttps2 can.
I can attest to this being the easiest to use out of all the options listed so far. Plenty fast too.
* it's using bgfx library for graphics, you can run it in OpenGL mode too, it runs on Linux * PBR is WIP * of course I am not serious about "The best" 
https://github.com/scylladb/seastar
 I like the look of your Imgui windows, how big a modification did that take?
I use Thrigt. You can build classes for C, C+=, Java and other languages by using an interface language. It foesn't support Http2 but it uses Boost and OpenSSL to deal with async communication and security
It's a stylistic preference for sure, but I have no problem reading clean code that uses type inference for local variables. As long as variables and functions are well-named, I don't generally want to know the exact type of something, especially when I'm just reading code. When I do need to know, it's pretty easy to find out -- just look at a function declaration, or let your IDE tell you. I don't think think it's generally wise to use inferred return types for functions in application code. But locals? Yes, please do! I enjoy reading C# code that uses type inference everywhere. I believe Microsoft even recommends it now, for whatever that's worth. Even though you are floating around 0 points, I upvoted you. What is LLVM's rationale for their style choice on type inference?
Initializer lists are an evil for game development, as they are currently the only feature that is dependent on the standard library, and cannot be rewritten without it. 
Wt at webtoolkit.eu is a good c++ library with built-in server that supports websockets. It's been around a long time, too. You could then use a HTTP/2 reverse proxy with nginx for your second bullet point.
HTTP/2 is binary protocol -&gt; allow multiplexing requests. It can be very useful.
&gt; Defining how an executor interface should be formed is a job for Boost and the C++ committee (and I hear even they are having trouble coming to a concensus, so it's probably not something I should touch) Indeed, it's definitely hard, even if I think they will get to a consensus before the 2 next versions of the standard. Meanwhile you can at least provide your own "concepts" as optional api to plug them in your signal system. Otherwise, it's just not composable with other executor implementations, therefore not that useful of a library. Anyway, as long as you think about it it's cool.
May I ask why nginx would be required? My intent is that this is a service provider that also provides internet-facing web services (as well as intranet web services). I'm not sure what nginx would offer that any other HTTP library would not that I would be concerned about. I'm also, mind you, a huge fan of multiplexing.
I know this is a somewhat old thread, but I wanted to follow up with some benchmarks. I benchmarked four versions of fib. `constant` which just uses a hard coded vector of values, `iterative` which uses a basic iterative approach to fib, `binet` using the formula, and finally the `matrix` version of calculating fib. I benchmarked with both clang 3.8.0 and gcc 6.1.1. | method | clang 3.8.0 | gcc 6.1.1 | |-----------|-------------|-----------| | constant | 444 ns | 630 ns | | iterative | 4487 ns | 8869 | | binet | 37624 ns | 45044 ns | | matrix | 10515 ns | 9304 ns | The benchmark calculated fib of 1-100 a million times for each method then averaged the timings. `constant` is obviously the fastest since it only really has to do a memory lookup. `binet` is by far the slowest. What is interesting is that the `matrix` implementation is still slower than the simple iterative version. Using `perf` to investigate, the matrix version slows down due to two main issues, the multiplies are a lot slower than the adds, and there end up being a lot more memory assignments in the matrix version. The iterative version the assignments are largely in-place in the same registers. As far as a real world solution goes, I would implement it with just pre-calculating the fist hundred fib numbers, then use binet after that. Using binet for larger fib numbers is probably fine (depending on the requirements), since you cannot fit the result in a `uint64_t` anymore anyways. The code for the various implementations constant uint64_t fib_constant(uint64_t n) { if (n &lt;= 0) { return -1; } // this will break for anything &lt; 0 or &gt; vector size return fib_values[n]; } iterative static uint64_t fib_iterative(uint64_t n) { uint64_t prev1 = 1; uint64_t prev2 = 1; uint64_t tmp = 0; for (uint64_t i = 2; i &lt; n; ++i) { tmp = prev1 + prev2; prev2 = prev1; prev1 = tmp; } return prev1; } binet uint64_t fib_binet(uint64_t n) { if (n &lt;= 0) { return -1; } else if (n &lt;= 2) { return 1; } else { const double sqrt_5 = std::sqrt(5); return static_cast&lt;int64_t&gt;( (std::pow(1.0 + sqrt_5, n) - std::pow(1.0 - sqrt_5, n)) / (std::pow(2, n) * sqrt_5)); } } static std::vector&lt;uint64_t&gt; fib_values; static void fib_init_constants(uint64_t n) { fib_values.push_back(0); for (int i = 1; i &lt;= n; ++i) { fib_values.push_back(fib_iterative(i)); } } matrix void multiply(uint64_t F[2][2], uint64_t M[2][2]) { uint64_t x = F[0][0] * M[0][0] + F[0][1] * M[1][0]; uint64_t y = F[0][0] * M[0][1] + F[0][1] * M[1][1]; uint64_t z = F[1][0] * M[0][0] + F[1][1] * M[1][0]; uint64_t w = F[1][0] * M[0][1] + F[1][1] * M[1][1]; F[0][0] = x; F[0][1] = y; F[1][0] = z; F[1][1] = w; } void power(uint64_t F[2][2], uint64_t n) { uint64_t i; uint64_t M[2][2] = {{1, 1}, {1, 0}}; // n - 1 times multiply the matrix to {{1,0},{0,1}} for (i = 2; i &lt;= n; i++) multiply(F, M); } uint64_t fib_matrix(uint64_t n) { uint64_t F[2][2] = {{1, 1}, {1, 0}}; if (n == 0) return 0; power(F, n - 1); return F[0][0]; } 
Mesh loading? You can just use bgfx::createVertexBuffer. In fact, mesh loading is completely separate and is only available if you include bgfx_utils.h.
Wow, you need to do this more often, many things are old but nobody knows that was there like the drag and drop feature and are very cool
Of course this is for a "perfect" project, and keep in mind that it's a guideline. I fully expect many bigger projects to have files larger than that, but they should be in the +1.5sd to 2+ sd range, not the common size. As with all guidelines, they're there to help you. If they don't help you, wonder why they exist &amp; find out - so that they can help you.
You're right about that, I had the exact same thought in the shower afterwards. Off to check my old code ;)
&gt; why nginx would be required? I think this always depends on deployment environment and there is no authoritative answer here. I'd rather always use nginx for public access to such services for the following reasons: security (compare the number of security fixes in nginx and in your embedded server of choice for the same period of time), performance fine tuned for browsers (there are years of R&amp;D in nginx), config familiar to devops with a lot of stuff out of the box (like let's encrypt integration), possible static files serving, possible load balancing. But your mileage may vary.
'Always auto' will be accepted as the One True Style. This assumes that the problems auto has with move-only types and expression templates will be fixed in the next 6 years. Then we can drop the 'almost' from 'almost always auto' and in 20 years most style guides will recognise it as the only truly consistent style. Trailing function return types will also be accepted as the One True Style. Same reason: the only way to be consistent. No /s here, but probably wishful thinking. 
&gt; non-Boost fork Where is that "non-Boost fork" ?
Nope, interfaces do need to be well defined. There should be a mix of concrete types and concepts, while auto params should be reserved for truly generic functions. There is a fundamental difference between auto for variable initialization and for interfaces. Choosing between auto i = 1; int i = 1; is a style choice, while auto foo(auto bar); auto foo(int bar) -&gt; int; completely changes `foo`.
Can't we just disable all implicit conversion warnings and say that we have polymorphic numbers in general? \*ducks for cover\*
You want /r/cpp_questions.
Hm... True. I was thinking in something like this though: Instead of having a templated function with concepts like so (I don't know concepts pretty well, so forgive me if this is wrong) template&lt;Comparable T&gt; auto cmp(const T&amp; lhs, const T&amp; rhs) We can have something like auto cmp(const auto&lt;Comparable&gt;&amp; lhr, const auto&lt;Comparable&gt;&amp; rhs) I dunno, I'm just throwing ideas here =P
https://github.com/sandym/pion-standalone/
I know. I'd like to read about 1 paragraph on 2 of the topics, now I get to watch a video. Sigh. Generational gap.
 - full equivalence of user-defined and builtin types (operator dot to get perfect proxy references) - uniform funtion call syntax (`f(x,y)` equivalent to `x.f(y)`) - a fully `constexpr` language and Standard Library (including memory allocation and I/O) - function specifiers like `constexpr` and `noexcept` fully deduced (no more `noexcept(noexcept(bla))`) - task-based parallelism with an optimal runtime scheduler (through work-stealing) over the full available architecture (GPU, CPU, network) 
I meant my own fork ( https://sourceforge.net/p/pion/mailman/pion-users/thread/5571D52F.5080008@staticlibs.net/#msg34179362 ), but this one may be closer to original pion.
How could compile-time I/O work? Isn't program input and output something that, sort of by definition, needs to happen when it's run? Other than that I agree with your list. I'd also love to see virtual concepts one day. 
Lookup Mike Acton, preferably his comments on Ogre.
Page seems to be down currently though -.-
Compile time IO, as I understand it, lets you include assets directly in the executable without the need to ship them as separate files. Examples include: Icons in a GUI application, GLSL files in a game, a ready only database.. etc
Oh, yeah. The examples suck. Not only it's a mess full of globals and terribly organized code, they also managed to abstract what should not be abstracted. Their docs also suck. I guess the best way to work with it is to just download the library and inspect the headers yourself inside your IDE. Their build system also sucks, so i recommend using the amalgamated version. As for their shader tool, it's useful, but i wish they had chosen GLSL and just converted from GLSL to HLSL and others.
You can [already do that](http://coliru.stacked-crooked.com/a/1c46b623c7aedc0f) with the Concepts TS.
Works-for-me(TM)
I know Mike Acton and DOD very well, what does that have to do with model.cpp? By the way have you seen the source code of other engines, even the big, commercial ones? I guess Mike Acton would not like it at all :) maybe except the Stingray, but I have not seen that one. 
In 20 years modules will be available for a long time, so we could expect a new way to build project. So why not the complete removal of "files and headers" to have only one object with all source that our editor present us in the most readable way to our personal preferences.
I don't know. My hopes for future C++ are * language rules, compilers and tools that make it harder for programmers to screw up. For example, programmers still need to remember the rule-of-three to avoid some kinds of errors. This is silly. Change the rules or at least add a compiler warning for it. I'd like a C++ that is less complex in terms of things you'd have to remember in order to use C++ correctly. Sane defaults, please. "Trust the programmer to know all rules" is a bad strategy if the language grows in complexity and it's not really newbie-friendly, either. * Modules * Concepts * easier cross-platform development w.r.t. dependencies and building Until then, don't mind if I continue to play with Rust. :D
Nice work guys. Hopefully the releases become more predictable. For some time, Qt did a great job of releasing every six months or so.
not sure about the HTTP/2 support. It's indeed very easy to use.
Shipping Qt with namespaces wouldn't require any more changes. It breaks the ABI, but Qt5 already did that anyways. 
Ah C++ is comming :) I would love to see the moc go with the help of bind/mem_fn/invoke as it would make build systems so much simpler. Is there any progress in mainline Qt on this?
Qt headers would contain something like this: #ifdef QT_IN_GLOBAL_NS using namespace qt; #endif
Makes sense
I know there is a blog post by one of three maintainers of moc about replacing moc with modern c++ features, they are at least looking into it.
Build system is simple, it's not an issue at all. The whole build-system integration of Qt fit in 10 CMake lines (**edit:** 6 lines, actually). The implementation will be swapped when the C++ reflection is ready.
&gt; problems auto has with move-only types What problems are those? For example, `auto p = std::make_unique&lt;Foo&gt;(...);` works fine, and I have had no trouble with my own move-only types.
5.6 was delayed so much for its LTS status and how it was the last 03 release. So at least there was cause for the exception.
 template&lt;class T&gt; concept bool NewConcept = Concept1&lt;T&gt; &amp;&amp; Concept2&lt;T&gt;; or you can use `requires` directly on the function. There's a pretty good overview of concepts here: http://en.cppreference.com/w/cpp/language/constraints
Different syntax highlighting colors.
Are you wanting to get into programming, or are you looking for a career in software development? If the former, then it looks like you're on the right track. Keep at it, and write lots of code. No amount of books can replace actually *doing* it. Coding challenges are a really great way to flex your noodle. /r/dailyprogrammer is a really great place to find some. As for getting a *career* in software, you're going to have to take a few more steps. First, learn you some linux. There are a lot of low-level IT jobs that can help you propel your career. The pay isn't awesome, but the opportunities are there, and they generally don't care about career history if you can prove that you know what you're doing. You might have to move to a big city. With a few years of IT under your belt, you shouldn't have too much trouble getting a job as a junior developer. From there, it's up to you.
+1 for /r/dailyprogrammer
TROLL
Yes, that was one of the nice features in 5.1. More problematic is the following case that is currently *forbidden* to work: auto rd = std::random_device{};
Can you compare it with a comercial database like SQL Server or Oracle DB? It will be interesting to see the results
6 lines? How?
If you want a free resource that's a decent enough introduction to C++, try this: [Cave of Programming.](http://courses.caveofprogramming.com/courses/c-beginners) It's about 20(?) hours worth of video tutorial. I really don't know what the rest of the sub thinks about that site (and I have no affiliation with it), but, for free, it is a decent enough intro. If you have any problems understanding a certain part (including installing/using Eclipse or MinGW), just Google your question and you will find an un-ending stream of answers. By the time you complete this course, you'll have a better idea of what type of book you'll want. Personally, I used C++ Primer Plus and I found it really useful...but I'm not real programmer. Edit: Sorry I didn't see the part of your post where you are taking this same course on Udemy.
Because the idea of _textually_ including files using `#include` is not a good one with many drawbacks - slow compilation times, issues with data hiding and macros being, essentially, global.
When you import a module you should only get what it exports while with headers you get everything in it and all headers it includes transitively. In theory it should allow things like local macros (currently if you include windows.h it will break every use of min/max in your code and all clients' code), cleaner library code (eventually it may even solve the underscore hell in STL), more fine-grained control over API and potentially faster builds.
It's really a miracle that anything works as fast as it does when you look at the output of a source file after preprocessing. Even something relatively simple can result in millions of lines of code that the compiler has to chew its way through. And that's even assuming that you only edited a source file and not a header that was included in multiple places. It's no surprise that large programs end up taking many minutes to hours to compile. 