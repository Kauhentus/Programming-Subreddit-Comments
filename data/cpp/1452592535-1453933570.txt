Just a quick note. For enums, compilers will generally warn you if you are ignoring a value in an enum, or creating dead code through an enum (for example having an extra else, where you have if for each of the values). 
I guess that answer largely depends on whether your use case requires a team of salaried Eiffel/Spark/Smalltalk/Brainfuck developers.
At most there's a bug in the standard wording and CWG needs to fix it, that's all. The [Itanium C++ ABI](https://mentorembedded.github.io/cxx-abi/abi.html#closure-types), for instance, specifies how closure types are mangled to ensure that this works. I imagine that other ABIs (like MSVC) do something similar.
&gt; Think about what would go into a renaming tool - how the hell are you going to rename a class member if the type has been passed into the black hole of a template? Off the top of my head there is refactoring support inside Eclipse, Qt Creator and (I believe) Visual Studio. Eclipse (the one I vaguely know) can be occasionally a bit touch and go - I'm not even sure it supports some refactorings for templated code. As you mention, the situation will possibly improve in the future thanks to clangs flexibility on exposing some more of the underlying mechanism for tooling.
Sounds like this person just didn't know how to write cpp. What's funny is most languages try to mimic features and stuff based on C/cpp...
And splitting a string.. oh god C++14 and still no easy one-line method to do that with the STL...
Unfortunately, it seems that MSVC don't have special mangling for closures. For example, https://gist.github.com/telishev/a320c802bb5991bf384a - if compiled in debug version, both strings are the same but in release are different. I see it as a clear sign of UB. Maybe this is just a bug in MSVC though. I guess changing mangling is not a simple task - it breaks compatibility at the least. If this is indeed a bug in standard then it should be reported, but I don't know how to do it, maybe someone here will help.
I think it's a little unnatural that a function checking if all elements are null in some container cannot be written like `bool is_empty () const { return std::all_of (v.begin (), v.end (), [] (const auto &amp;p) { return p == nullptr; });}` in header file and can be in cpp file.
I don't understand, there shouldn't be any reason why you wouldn't be able to have that method in a header file...
But those are two different definitions, as is_empty is an inline function. Inline functions can have different definitions in different TUs, or am I wrong here?
Nope, it's exactly the opposite - each definition of inline function with the same name in the same scope must be equal (with some complex definition of being equal). It's called One Definition Rule (ODR). You're probably confusing inline with static. Static functions can be different in each TU.
&gt; the complete definition of a template must be visible at the point the template is used. Sorta. foo.hpp template&lt;typename T&gt; int foo(); foo.cpp template&lt;&gt; int foo&lt;float&gt;() { } bar.cpp #include "foo.hpp" int main() { return foo&lt;float&gt;(); } 
Thank you, I've amended my post to reflect this.
Hence the "sorta". I didn't really want to get into why this isn't really a problem. The biggest gripe with templates is that they need to be parsed a lot of times, and instantiated via complex transformations. Hopefully modules help at least with the first part.
This guy just doesn't know C++ very well. And it is a "language war" type rant. No doubt the guy prefers some other language and this rant is in light of how his favourite language does things. Also, many of the complaints seem to actually be complaints about one particular compiler . Nothing of value here, it's not worth the time trying to write a point by point response. He would ignore it anyway.
You could write a function that does the split in the way that you want it.
I already read what you wrote.
&gt; So there's no excuse anymore There is, it's called "backwards compatibility", and it's a big deal to a lot of people.
I think the correct answer is given in the [chat section](http://chat.stackoverflow.com/rooms/100403/discussion-on-answer-by-columbo-does-using-lambda-in-header-file-violate-odr). This is not an ODR violation because lambdas are not _named_ (emphasis mine): &gt; (6.2) - in each definition of D, **corresponding names**, looked up according to [basic.lookup], shall refer to an entity defined within the definition of D, or shall refer to the same entity, after overload resolution ([over.match]) and after matching of partial template specialization ([temp.over]), […] I.e. the name lookup has to be the same. There is no name lookup in the case of lambdas.
name lookup is applied to `std::for_each`, and in different TUs different overloads will be selected (corresponding to different lambdas) 
So, you're saying it's a bug in MSVC?
Do you include in major compilers aC++, TI C++, ARM DS, Sun C++, xlC++, Green Hills, ...?
You see that difference in the choices between C++/Objective-C and Java/Python - they still allow interoperability, but not flat-out including C headers and preprocessor stuff. 
&gt; Are these points true? Yes. No. They are true, but presented with limited context, and made to be bigger than they actually are. Also, the importance of the issues he presents, is exaggerated. Example: &gt; Yeah, it has a fucking preprocessor. So does C#. If you do not abuse the preprocessor, it won't bother you. I use `#pragma once` instead of include guards, and (partly due to this) I haven't written a #define or #ifdef in _years_. &gt; Nobody cared to include tools in C++ to make the preprocessor obsolete, so it still lurks around and takes your firstborn children. Actually, templates were introduced in the language to combine the flexibility of preprocessor macros with the characteristics of (actually) written code (strong typed code for example). In other words, **there has been a concentrated effort for more than a decade to include tools in C++ to make the processor obsolete**. These days, people are working on modules; one of the major advantages of modules is exactly the fact that you no longer `#include` your files. &gt; An uninitialized bool variable may be neither true nor false. An uninitialized bool variable is however undefined behavior. So is an uninitialized pointer, integer, char, double and so on. This is not a matter of how bool _is the most idiotic boolean type you will ever see._, it is the fact that undefined behavior is undefined. 
Many of the C design decisions already did not make much sense vs Mesa, Algol, Modula-2, CPL, CLU.....
It does not solve the issue of allowing easy iteration over enum values, but generally yes I agree with you.
There's basically zero value in making this into a reference. It's a keyword, so you already know it can't be null, and you can't assign to it. Changing this would break piles and piles of code as well. Yes, we wouldn't have done it this way from scratch, but it's just irrelevant. The same is true about many of the points made.
As far as I know, using functions from anonymous namespaces inside inline function is ODR violation. They don't have a name too. How is that different from lamdbas?
Fucking xlC just added #pragma once it in v13. I don't know about "major compiler", but it ain't minor if you need to build for AIX ;-).
I meant anonymous namespace doesn't have a name.
At a casual perusal, I'd say that C++ implementation is appalling. Using std::string to store an array of special characters, then string::find to search for each character has awful ramifications. Simply not idiomatic C++ code at all. Its almost like its written to game C++ into looking slow.
There was a `std::split` proposal that worked on more than just strings. I'm not sure what happened to it, but it would be nice to have. There's one in `ranges-v3`, so we'll probably have that in the standard eventually.
No, by major I meant clang/gcc/icc/msvc. If you're using something else, you most likely aren't writing portable code anyway, so the point is moot.
Let's see your [Pull Request](https://help.github.com/articles/creating-a-pull-request/) and then compare results. &gt;i don't want to do super hacks to win benchmark. i want to implement algorithm idiomatically (vector is not good, because bf code can be super big), in the same way in different languages, and see, what performance they give. and may be apply little performance tricks (like: #4). &gt;yes, my way of benchmarking is not fair, but it is what i wanted to measure. code readability also have meaning for me. &gt;if you want to compare bracket_map as vector, need to implement vector in every other implementations.
&gt; If you use a template parameter... The reason is that without `typename` there’s an ambiguity that the compiler **cannot** resolve with a single pass over the source code, it would require multiple passes (very inefficient). That’s the same reason, but even worse, as for requiring declarations before use. To wit, the without knowing all the specialisations of `X`, the compiler cannot know whether `X&lt;T&gt;::foo` refers to a type or a value. So when you write X&lt;T&gt;::foo * z; How is the compiler to know whether you’re attempting to multiply two values, or trying to declare a pointer? It cannot know this even if the class template `X&lt;T&gt;` is defined before (because `X&lt;T&gt;` could be specialised) so it assumes that `foo` is a value unless you prefix the usage with `typename`. See also [Usage of `typename` in `typedef` versus inheritance](http://stackoverflow.com/a/22374759/1968)
&gt; The preprocessor is a POWERFUL tool when used right. Powerful, right. But it should pretty much never be used, except for #include, where there's no choice. For mundane uses, there are many alternatives. For powerful uses, it is never worthwhile. I've seen an awful lot of powerful and very ingenious uses of the preprocessor. They are never worth it, for example, trying to use it as a metaprogramming language. In my own older C/C++ code, I've been making an effort to remove/replace all uses of the preprocessor. The results are much more pleasing and understandable code. 
Modules aren't the only work to replace the preprocessor. - C++17 got `std::source_location`, meant to replace most uses of `__LINE__`, `__FILE__`, and `__func__`, meaning loggers can finally stop using macros to get these. Unfortunately, there's still a big problem with testing libraries like Catch, where testing `x == 5` actually gives Catch access to the string literal `"x == 5"`. I think it might be the Reflection study group working on the area of testing. Whatever fixes this would fix `assert`. - There's a Reflection study group. Whatever they produce should eliminate the need for macros to define an enum that you can introspect (also fixing the enum problem mentioned here). It will also eliminate the need for structures defined using a macro or adapted (think `BOOST_FUSION_ADAPT_STRUCT`). - There was a proposal to make `assert` a language construct instead of a macro. - Concepts will replace existing `CONCEPT_REQUIRES` macros and the like, used for the same purpose. - I don't know too much about what existing Contracts solutions are like, but there is certainly work being done on a language feature for these. - There are people trying to replace `mpl_string&lt;MPL_STR("abcdef")&gt;` with `mpl_string&lt;"abcdef"&gt;`, where the former expands to `mpl_string&lt;'a', 'b', 'c', 'd', 'e', 'f'&gt;`. `constexpr` can be a big help here in providing a completely different method of processing a string at compile time. However, you might simply require a template. - There have also been numerous proposals for a completely new way of generating code. I don't think any of them has made much progress toward standardization. In terms of generating code, I would appreciate at least something that can be coupled with compile-time reflection to generate a new type based on an existing one. For example, [easily making a stub](http://nsubstitute.github.io/). --- When all is said and done, not many people enjoy the preprocessor, and everyone's trying really hard to replace it. However, it is still a very useful tool. One amazing thing it does is allow for language feature emulation. Just look at how much of C++11 through macros Boost had in C++03. `BOOST_AUTO(x, 5);` is pretty much `int x = 5;`. It's not perfect by any means, but is extensible, and the implementation sure is a nice exercise. On the C side, [you can emulate](https://gustedt.wordpress.com/2012/01/02/emulating-c11-compiler-features-with-gcc-_generic/) C11's `_Generic` in C99 with a couple of GCC builtins. Without thinking on it too much, it's probably possible in portable C++11. Admittedly, I find macros to be a really fun mind exercise as well. The pure power of the preprocessor that is only brought out through unintuitive ways makes for some very interesting techniques. For example, since macros aren't recursive, nested loops seem impossible without the user passing the current dimension. However, it is possible to detect the current dimension (by combining cleverness with trying the highest supported, then the next highest, etc. until one expands differently). Things like that make figuring out these techniques really rewarding. That said, while some of these macros you produce can be useful for now, it's best left to libraries like Boost.Preprocessor.
Coding in C++ is like playing DarkSouls. It's hard, but it's fair and when you conquer it it's incredible gratifying...
In other words, the choice is simply annotative.
I have a strange, insatiable appetite for language rants. Even if it's directed toward a language I love. I think the author was just having a bit of fun.
What's your opinion on using the preprocessor to write code that works in multiple compilers that don't all support the same version of C++? For instance, I've seen a number of projects that have a macro along the lines of OVERRIDE that will evaluate to either nothing or the 'override' keyword depending on whether the compiler supports it. With sane macros like this, there's also the advantage that once the old compiler is no longer needed, it can be cleanly and completely removed.
Visual Studio renaming tuckers out pretty quickly after a few templates and auto declarations, in my experience. It has been a while since I've used QtCreator, and I recall having luck only in non templated code. If they are using clang tooling now, I expect support would be better. Still, if you have two types passed into a template, each at different sequence points, and both have a .foo member accessed inside, how do you properly rename foo for only one of those classes? It's hard enough just to determine whether that case occurs in your code, especially at the top of a multilevel template "stack."
Did he really complain that it has a preprocessor and then use some preprocessor stuff in place of enum?
The preprocessor stuff is not all true. I know plenty of C++ programmers who still have their first-born child.
That's surely better than old-style CMake but still... Whenever I create a CMake project, I feel like I have more CMake LoC to write than C++. And this idiomatic CMake style is making things even worse (per-target compilation_options, include_directories, no variables, ...) I like CMake because it's the least horrible of all the build systems out there, but I dream of a day when coding in C++ doesn't involve learning another shi**y language to describe how to build the three sources and two header files that compose most projects. 
I tend to use the preprocessor nowadays mostly for shortening boiler-plate code, and mostly in CPP files - I find it often reduces copy-paste bugs. I rarely let header macros escape out of a particular use case into client code.
They are not meant to do that. Otherwise there is C++11 std::array.
I wish c++ would be like vim, you could "set nocp" somewhere and get rid of a lot of old and bad stuff.
It's usually with boilerplate that binds name strings to types/enum values. Basically a glorified `#define str(name) bind(#name, name)`. And yeah, I use #undef to make sure header macros don't escape.
Getting rid of preprocessor usage: * makes the code look nicer and more modern * makes compiler error messages more understandable * 3rd party source code analysis tools work better on it * refactoring tools have a chance * the code is more easily translated to another language * fewer leaky abstractions and better code hygiene * fewer bugs * syntax highlighters aren't confused by it
I've used things like that, e.g. the [X macro](https://en.wikipedia.org/wiki/X_Macro), but wound up eventually taking them out, too, and replacing them with regular code.
&gt; Object Orientation &gt; this is a pointer &gt; Truth: Legacy cruft. Nothing to do about it, I'm afraid. &gt;References are not pointers. They are completely different beasts, even if they seem similar. Could you elaborate on these two points?
I meant "meant" as in iterate through it. if you need a fix arbitrary list of value std::array&lt;int, 3&gt; a = {1, 4, 12}; should do it. You ca replace the values by the wanted enumerator. Don't remember about java, but python has no enums IIRC, only tuples. C++ has those two but they are different beasts.
That's a very common limitation. If you want to build a plugin for something like Maya, you'll generally need the matching version of Visual Studio or gcc, as appropriate.
&gt;There are languages people complain about, and language that nobody use. Bjarne Stroustup
&gt; An explicit specialization must be declared before an implicit instantiation But here, there cannot be any implicit instantiation of the template.
&gt; this can be null Not in legal code; if `this` is null, then your code is surely exhibiting undefined behavior.
I am waiting for the second version, *******.
Because in Maven it's hard to do easy stuff outside of the "convention". Because Gradle is a language (groovy), it's easy to just include java.lang.* or java.io.* and do things outside the box that you must, without having to build a custom plugin. I get far more done far faster with Gradle than maven these days. Maven was a GREAT advance over ant, in some respects - if you were building the standard J2EE app archetypes. Once you started doing something out of the box, or polyglot and TDD came along, it started being more of an encumbrance than a help. Not that it doesn't work. It took me a long time to leave the comforts of my maven nest for Gradle. 
That's the groovy startup, I think. I note that Groovy takes a while to start up on any platform I use. That's why gradle has a daemon mode now. Using daemon mode there's no difference. But groovy startup. even if it's just println "hello world" is scads slower than just the JVM startup. Not sure why that is... 
Aren't those the *enum class* he's mentioning?
C++ never ceases to amuse me. But I gotta ask why there are two different keywords doing same thing on the first place and 'See "template template parameters". You cannot use typename in that instance and must use class.' - what problem this suppose to solve?
&gt; every language Except for C and C++, which is exactly what this thread is about. &gt; Why not unify them under apt or yum Because then they end up being system packages and there are all sorts of inter-compatibility issues you have to deal with. There's a reason that major distributions don't distribute more than one major.minor version of a given package, e.g. 1.3 and 1.4 at the same time. &gt; I know it 's not that hand-wavingly easy. :-) but something could be done, even if it's a matter of installing them to some scratch directory, versus installing them to the system directory. What you have just described is what this tool is, and I'm now confused what point you think you're making.
&gt; 'C++, just the good parts' language - although the fact that it doesn't exist seems to indicate it's not quite as easy I might guess. it would be easy but unused, because C++ gets used thanks to compatibility with older libraries. 
To add to that ... &gt; Strings are still C strings. Thanks to `operator ""` in Core, we now have `std::string` literals, so you can use `"xyz"s` everywhere. You'll incur some unnecessary allocations, but if it's not ultra performance-critical code you're writing, you basically have Java-style string literals at your disposal. &gt; You have to put the complete implementation into the header. Maybe with modules, we'll get some bytecode after the preprocessor and lexer stages, but the bulk of the compilation can't be done until instantiation *anyway.* &gt; If you use a template parameter... Because the compiler doesn't know whether a particular token sequence represents a typename or not, until the template parameter is known. Makes it easier for the lexer and possibly prevents subtle bugs. &gt; The smart pointers (std::unique_ptr et. al.) are a sorry excuse for a missing language feature. Love the passive-aggressive implication that GC is a "missing language feature." I consider RAII a missing language feature in all GC languages that make handling any resources *other* than memory a pain in the ass.
Aside from the complexity of the lexer in clang, you also have to deal with platform SDKs that will probably fail to compile in your minimal C++. If you choose to allow everything for system includes then the testing scope has dramatically increased since all these features now still exist under the hood.
So this answers the age-old questions of "how to convert enum to string", among other things? 
Honestly, the author isn't wrong for the most part (with a few exceptions). Those are real warts on the language, although I would argue that most of them had a strong justification at the time they were added, and don't actually detract as much from day to day use of the language as he seems to think. Plus, I'd challenge him to show me a language without warts :P
One strategy that some of our users like to do is to enable Weverything ( http://clang.llvm.org/docs/UsersManual.html#diagnostics-enable-everything ) and then suppress individual warning categories that they don't like with Wno-*. 
Well, it does: I'm saying the 'point' is not important. The task can be achieved easily and tailored to your own requirements, what does it matter whether or not there is a function that implements one possible sort of split?
What is the rate like for a senior dev with 10+ yrs of exp?
I was actually hoping to contribute improved documentation, and this was partly gathering external thoughts on the idea. It does sound like creating exhaustive reference documentation may not be a waste of time - though few people see the need for numeric identifiers.
You should have highlighted &gt; shall refer to the same entity This points out where the issue is &gt; An entity is a value, object, reference, function, enumerator, type, class member, bit-field, template, template specialization, namespace, parameter pack, or this. Because the type of the lambda is different each TU, the type of the templated function called is different each time.
Shooting yourself in the foot is a very effective way to stop you walking.
IIRC std::vector&lt;bool&gt; is not like any integer type. It can be a heartache if you forget this is not really a container in the proper sense but of you need a few million books it's really rather handy. 
Is there a plan for string_view literals? Or is char const* still the way to go?
&gt;String splitting doesn't need to be "tailored to your needs" in 99% of cases, What are those 99%? Are you splitting by (a) character, (b) string, (c) regex? Do you need to split based on a begin-end range, or are you only ever splitting an entire `std::string` object? (What about a C-style string?) Do you want to allocate all new strings for the output, or just store views for each member of the result? (Could be a big difference for a long string). Is the result in a vector, a deque, a list, or what? Already the things I listed lead to dozens of different possible parameters for a string split function. I think I have *never* required to split a string simply by a character or string delimiter, in production code. More common a string that needs splitting by delimiter also has other requirements, e.g. ignoring/amalgamating whitespace, treating quote marks specially (delimiter can occur inside quotes), or escaped delimiters. I see it as a strength of the language that there isn't a function to implement just one of those dozens of options. &gt;my point still stands about you not answering the initial question. There was no question in the post I was replying to. 
Auto tools solve a lot of problems that have nothing to do with C++ and don't easily solve problems with C++ libraries. If you ever tried to write software in the 90s that talked to the OS and wanted it to run on all the systems out there you'd think autotools were gods gift to software dev. 
Err, GCC is popular for embedded targets.
VS considers it an error only if no control paths return a value. If not all control path return a value, then it's simply a warning. I'm guessing it's like this because the former means you _definitely_ made an error there, whereas the latter might mean "you may know that this control path will never be taken, but I'll warn you just in case".
Smart pointers != GC. Screw GC.
I'd imagine more than a few features in C++ originated from creative use of macros.
I see people use this as a point all the time. Where do you actually _use_ such a thing though, practically? When's the last time you needed to check the primeness of a number at compile-time? These applications are just so rare it's not even worth mentioning, IMO. The only time I've seen this is for 'fun' projects.
C++ is popular in robotics applications which are blowing up at the moment. If you can turn an academic paper into C++ code I imagine there are a wide variety of companies who will hire you. A master's degree is going to help here.
Electrical engineer here. C/C++ are used for a lot of embedded systems work and also for a lot of semiconductor device testing/fabrication automation. Cheers
You can get GCC/clang on commercial unices; I know at least solaris shipped with gcc pre-installed, OSX ships with clang and gcc (if I remember correctly). I've never used AIX, but [this](https://www.ibm.com/developerworks/community/blogs/mhhaque/entry/how_to_use_gcc_or_g_compiler_on_aix_7?lang=en) and [this](http://www.ibm.com/developerworks/aix/library/au-gnu.html) IBM page indicates that it's easy to install. HP-UX also offers packages for GCC, from a quick google search. But even if you don't want to bother installing gcc/clang on HP-UX/AIX, the default compiler on both HP-UX and AIX support `pragma once` anyway. So from what I can tell you can get "#pragma once" at no effort (or at some effort, if you're running an old version of AIX) on all currently existing commercial unices, or did I forget one? Also, I think at least on IBM mainframes you get the same compiler as on AIX, so that gets you "#pragma once" on those as well, it would seem. According to wikipedia, IBM mainframes make up 90% of the market. For embedded, GCC (and/or various forks/derivatives) is pretty much the dominant compiler, as /u/thenickdude already pointed out, so you get "#pragma once" there anyway. If you want to use Keil, that also supports it. That really doesn't leave much out, IMO. TCC also supports it. Digital Mars' and Embarcaderos compilers support it. I'm sure there are others out there, but I think you'll have to make a strong argument for their relevance... Pathscales compiler doesn't support it (I think, I didn't test it) and neither does sunstudio. I think sunstudio is probably the only one that deserves to be mentioned as relevant, but as mentioned previously, you get gcc there as well.
Sure, but C++ is a tool and not necessarily the job. This sounds a bit like looking for "hammer", "nail", "level", "wrench", or "screwdriver" jobs instead of "carpentry" or "plumbing" gigs. Usually jobs are more in specific areas, and C++ is one of the supporting skills that might be needed/desired. That's usually mixed with lots of other supporting skills like Python, revision control, particular operating systems, etc.
So, here's an example. I have a state machine that gets messages, and based on the current state, different messages are valid and invalid. I can do this all statically at compile time without having to do any checks. This is great because in a given run, I can expect millions of messages to be exchanged. Without templates, I'd have to rely on actual if statements and all that stuff. Blah. Templates allow for the compiler to do so much. It's actually amazing. Take a look at PIConGPU. 
There is some correlation between language, application and business domain. C++ is great at systems applications but less productive for business logic and terrible for UX stuff. Supporting skills can be learned on the job (obviously depends). 
They do, but are obviously rarer. C++ is like a lightsaber, until you can be trusted with it, you're more likely to cut your or someone elses hand off. If I was really junior I'd probably look for QA positions where you can get your feet wet with the codebase and learn the ropes, before transitioning to real development.
&gt; What you have just described is what this tool is, and I'm now confused what point you think you're making. Except for all languages. &gt; There's a reason that major distributions don't distribute more than one major.minor version of a given package, e.g. 1.3 and 1.4 at the same time. I get this point. It doesn't mean, however, that I can't install them to a different install root (arm-v6-hf into a folder I load into Qemu to cross compile, maybe - I know, super contrived example but ... ). 
I started my career in Office, right after graduating.
What about remote C++ jobs for not Seniors developers?
Financial industry
Sounds like you don't know how to write C++.. He has valid concerns for most of his arguments. #pragma once is supported by pretty much every major compiler, i see no reason for why it can't be included into the standard. Header guards are annoying to write, there's no reason i should have to make up a unique name and such. Hopefully modules solves this somehow to be standard.
C++ is the language of choice in the game industry.
Have you seem remote C+o jobs? 
&gt;Usually jobs are more in specific areas, and C++ is one of the supporting skills that might be needed/desired. That's usually mixed with lots of other supporting skills like Python, revision control, particular operating systems, etc. I know of a few available positions that require that, C++ is used for the main application, and Python for automating the surrounding infrastructure. Preferably, we would like one to be proficient in both to be effective.
Yea, but that's just typical template condition checking. I'm speaking of the "let's compute with templates" stuff. Like the 8-queen's thing, prime number checking, or running game of life on the compiler... PIConGPU seems to do its computations on the GPU, so I don't really see what you mean.
Didn't you teach us that X macros are cool? :)
Yes, they do. I work on a [parallel computing framework](http://charmplusplus.org) based on it. We've got job openings in both the [originating research lab](https://ppl.cs.illinois.edu) and a commercial startup (PM me).
C++ is one of the 4 major languages that Google uses. That said, the interview process doesn't have anything C++ specific.
If you're in the area of Westminster CO, I'm currently hiring for a Linux/OpenGL c++ programmer for high performance computing, medical imaging. Hiring immediately. Some experience necessary. PM for details.
Linus would have **hated** this dude. :-) I was a bit, but not much, surprised that the very first example with std::accumulate was faster, but much of the rest, absolutely not, and I think a competent C++ person should not have been either. In particular, I felt that the array sorting was cheating against C, because macros to sort just copy-pasted *a lot* of code around (but then again, that's what macros do). The "correct" thing to do would have been to put a macro inside two functions (one for int, another for double) and call that. But that is more silly work, bleh (that said, "more silly work" is exactly what C makes you do, so C++ "wins" again). But at the end, this is a *really* good thing to show to glib (not GNU glib, I mean real world glib :-)) C people (and there's many of them still). Edit: haha, judging by the questions at the end, some C people got their feathers ruffled somewhat :-).
&gt; Do C++ jobs exist for not Seniors C++ Developers? The thing is that development in C++ is about as easy to go wrong as open-heart surgery. One wrong move, and you've cut a major blood vessel, or introduced a huge security vulnerability. It takes skill to avoid those wrong moves, and of course no one wants you to train on their body. Therefore, an employer really needs an experienced C++ developer to be able to even use that person's code in anything more than a toy project. It requires a lot of trust, which you can't place in a person who hasn't trained themselves already. However, that's also why an experienced C++ developer can command a hefty salary.
Yep! In fact, we're hiring. :) https://www.google.com/about/careers/search#!t=jo&amp;jid=3256001 https://www.google.com/about/careers/search#!t=jo&amp;jid=42165 
It actually uses templatized metaprogramming. When you specify your "experiment", you don't do it via config files, but you setup all your values in an "extension" that gets compiled in and the compiler ends up solving a whole slew of equations. The GPU stuff is for core PIC computation. Yes, people use templates to make the compiler compute stuff. That's the beauty of it. 
Also MachineLearning is dominated by C++ (and Pythin) Frameworks.
&gt; (Tired of writing ifdef guards? No need to go into #pragma once unspecified behaviour land, just get an editor that makes them for you. I haven't written one in years.) Even if you have an editor that does have it auto generate, when moving around files or renaming them, the guard no longer matches. That's the problem i have with header guards.
Yes. We almost always have openings for entry-level C++ developers here in central IL, USA working on embedded controls, networking, and displays. On the displays we use a mix of C++98 and C++11.
Is the position open for either remote employees or H1B candidates?
You mean [The X Macro](http://www.drdobbs.com/cpp/the-x-macro/228700289)? Yeah, I wrote that, and it is cool. But it's not worth it.
If anyone watched the whole thing, what makes C++ better than C for embedded?
What kind of pay are we talking about here?
I don't code in C++, but there are plenty of people in my company who do. Our servers are mostly in Java, but the computational core is all C++, and there are plenty of non-senior engineers on that team.
Until I saw the username, I thought you literally meant all of your work was done WITH Office initially. Sounds like some of the worse Programming for Engineers classes in college :)
Yet Maven requires no such workarounds and still beats Gradle.
I have worked with many customers that only allow the OS vendor SDK. A very compelling story is usually required for their IT to allow anything else on their systems. The development environments are also only provided by the customer due to security reasons. So it doesn't matter if gcc exists on the said platform. Yet we might want to use libraries that are expected to be usable by any ANSI C++ compiler. 
Yes, but that doesn't mean customers IT allow to use it. In consulting one is many times bound to existing infrastructure. 
Well he now writes the standard library implementation for Microsoft, so there's that.
Started mine too, and it was a lot of fun and work, mostly fun until the final year of shipping Office 2010. Working on a boxed product, I can safely say was a fantastic decision to start my career because I learnt a lot about shipping code and working on the Office code-base in particular got me exposed to some of the best (and probably some the worst too) code and engineering practices I have ever seen. Furthermore, the senior devs were truly a class apart. Highlights: learnt about writing portable C++ code, Office had to run on Mac and Windows, 32-bit and 64-bit (ARM was being brought up as I left). Layered software architecture, i.e. the UI layer had absolutely no abstractions leaking into the rest of the code base, in fact, a lot of the "Client" C++ code later became was shared with the server codebase ... that went mostly well. And finally, debugging ... this was a skill I feel most junior and even quite a few senior developers don't now possess. Being able to navigate memory dumps, reading the disassembly and sort of jumping into a memory leak investigation, crash/hang or perf problem is probably the most valuable skill I learnt there. Lowlights: Dealing with an aging codebase, the monstrosity that was the build system and my reason to leave: painfully slow ship cycle (this has of course changed since then). My 3 year and so stint, I only shipped once, so I had to derive professional satisfaction from other things: side-projects, tools, process improvements ... but seeing your baby ship is a different feeling. In short, I would do it again!
Hello, i develop adobe plugins using C++.
I was deeply unhappy in Outlook at first (2004-me did not react well to being told that he couldn't use the STL, or even operator overloading). It wasn't so bad by the end (2006), and I picked up several useful skills (like how to use source control, the debugger, and Source Insight). I switched to VC in 2007, still as a junior dev (L60 SDE I).
It's a shame the hipster web community doesn't get this. &gt; 6 months exp in angular 2 required But I've been solving similar problems you have for more than a decade. &gt; nope, we're going to save money by hiring the Jr dev who has 8 months experience in angular 2 
Any area that makes use of OS device drivers, HPC, game development, compiler development, portable code across mobile OSes, portable desktop software (usually Qt). Note that in many cases C++ is no longer used alone, rather together with other languages, even in performance critical areas like games and HPC.
If anyone is in Sydney (or elsewhere in Australia and wants to move) PM me, my work is always looking for C++ developers with a broad range of experience.
Not usually for non seniors though.
&gt;couldn't use the STL wat
I'm just curious. I do like that about C++ :)
[removed]
&gt;competitive salary How competitive?
in continuation to /u/carutsu 's question, how do i find jobs in google which support H1B?
It doesn't sound like it -- but that's a very cursory reading on my part. &gt; Like C, all stack variables in Rust are uninitialized until a value is explicitly assigned to them. Unlike C, Rust statically prevents you from ever reading them until you do -- [rust docs](https://doc.rust-lang.org/nomicon/checked-uninit.html) Even if it does -- reading about "drop flags" already makes me think Rust wouldn't suit for an embedded language. There are times when you need control of every single byte of memory, and a language that maintains hidden flags for every variable seems like it's already separating you from the bare metal too much. I'm working on a project right now for example where every single byte of memory is precious, I can spend a day squeezing a byte out of a repeated record. If C++ went around adding extra flags without my say so, I'd lose a good percentage of my storage. Again though, forgive me if I'm wrong. I'm definitely not familiar with Rust. --- Edit: to give a concrete example, here's the sort of thing I'm talking about that I'd be very surprised if rust can do it: struct Settings { static unsigned int mMagic; int mResetCounter; Settings() { // Detect unretained RAM == hard reset if (mMagic != MAGIC) { powerOnConstructor(); } else { restart(); } } void powerOnConstructor() { mMagic = MAGIC; mResetCounter = 0; } void restart() { mResetCounter++; } }; unsigned int Settings::mMagic __attribute__ ((section(".retained_ram"))); // Dirty, dirty hack to prevent GCC from doing the static construction // of gSettings uint8_t gSettingsBacking[sizeof(Settings)] __attribute__ ((section(".retained_ram"))); Settings &amp;gSettings(*(reinterpret_cast&lt;Settings*&gt;(gSettingsBacking))); void manualInit() { // Placement new call of the constructor under our control new (&amp;gSettings) Settings(); } Not tested, but you get the idea.
Sure, look for crossover. They search for experts in C++, Java, C#, Javascript, Lisp, PHP.. oh and they want you to know them all.
Yes, scientific simulations are another example. 
Yes, there are - for example - to_string(e_1::e_1_a) = "e_1_a" and from_string&lt;e_1&gt;("e_1_a") = e_1::e_1_a methods (however, you must use one of the SMART_ENUM_* macros to define "smart" enum, it doesn't work for "normal" enums).
I work in CAM. We use mainly C++ and most of our team is young. Our hires should have some C++ knowledge (professional experience not needed).
Yep, I've seen several ATmega328p libraries that use full C++ (OOP, templates, etc.)
&gt; my area there is nothing at all. You could always move. It could be a huge difference in quality of job and pay.
I plan to, but first I'll need some money, since moving isn't cheap. That's why I'm focusing on working in remote now.
Better abstractions allow the compiler to generate smaller and faster code. Amazingly, dude shows that the biggest gain is on the smallest chip (8-bit!). To be noted that he turns off exceptions and rtti, which means "no stdlib". But that is OK, as his target is (among others) a very small chip with virtually no memory at all. If you will, he shows how C++ as "C with classes (and templates)" beats C from speed, code size, and code readability standpoint.
I gotcha, you might want to study up and apply for Microsoft at some point. I'm still a student, but I went in for an internship interview and got it. I live in Redmond, but I know they fly people out if they make it through the phone interview, they even do it for internships. Now I just need to bump into /u/STL on the job when I start and buy him lunch for all the work he puts into my beloved language. :P
Yeah, I don't after programming for more years than I've almost been alive... /s Also those valid concerns, although valid on most, are like "Don't use an oven because you can burn yourself" is the way I read the entire article (twice because a friend also sent it to me). Coming from other languages to C++ may seem like a huge turnoff/pita but if you started with C, and then C++ you tend to already know the dos and donts (not really any donts, just you have to know how to handle it) All I'm saying. Also I never said anything about the #pragma once lol.
Thanks.
Link?
Embedded C++ vacancies require experience in Embedded area. But how to get experience in embedded?
No, age is irrelevant. Except for the Valley perhaps, companies don't care much about age if your skills are great.
I am always on the lookout for a good hammer job. 
EXcellent. Thanks.
Get in the sunday lane, gramps!
We're using a mix, as are most of the places I've been. C++ classes, but usually no exceptions, STL, Dynamic memory allocation, or streams (all memory/performance/determinism killers) The chip I'm working on right now has 8K of RAM... ran out yesterday and going to have to re-balance my stack and heap.
If like your handle suggests you know Javascript and entry level C++, head straight over to the (open source) PowerDNS careers page -&gt; https://www.powerdns.com/careers.html it lists exactly that.
your soul, if you work in HFT.
Wow. If I'm reading the article correctly, QtCharts, Data visualization, Virtual keyboard etc. are now available in the open-source package? This is absolutely great news for OSS developers using Qt!
&gt; You have to put the complete implementation into the header. This slows down compilation considerably, because **all the fucking implementation of the fucking template is parsed every fucking time it is fucking used**. Oh, you can of course try to use precompiled headers and open the door to hell. It is parsed once per inclusion of the header file. At this point the compiler has an abstract syntax tree of the function/class, and will use that to stamp out instantiations. &gt; The compiler generates some methods of a class automatically based on complicated rules. Examples are the assignment operator, a copy constructor and such. You can also instruct the compiler to not generate these methods if they would be automatically generated. Some of these methods are needed for using the class in the standard container structures like std::vector, so you have to check all this stuff every time you declare a class. If I am not mistaken the following explains the full set of "complex" rules relating to automatically generated member-functions: class Blah { public: //default-constructor, generated if you do not declare any constructors Blah(); //copy-constructor, generated unless you declare one yourself or you declare either a //copy-assignment operator/move-constructor/move-assignment operator Blah(const Blah &amp;rhs); //copy-assignment operator, generated unless you declare one yourself or you declare //either a copy-constructor/move-constructor/move-assignment operator Blah &amp;operator=(const Blah &amp;rhs); //move-constructor, generated unless you declare one yourself or you declare either //a move-assignment operator/copy-constructor/copy-assignment operator Blah(Blah &amp;&amp;rhs); //copy-assignment operator, generated unless you declare one yourself or you declare //either a move-constructor/copy-constructor/copy-assignment operator Blah &amp;operator=(Blah &amp;&amp;rhs); //destructor, generated unless you declare one yourself ~Blah(); //all the the above are not generated if they would be ill-formed }; &gt; The smart pointers (std::unique_ptr et. al.) are a sorry excuse for a missing language feature. A class usually has no idea about whether it is accessed with a smart pointer or not, but when it passes a reference to itself somewhere, it needs to know. So you suddenly have to derive from std::enable_shared_from_this to be able to convert this to a smart pointer. Interestingly I have never had to use std::shared_ptr ever, but even if I were to use it I do not think I the class would need to know if it was owned by a std::shared_ptr. This seems like an attempt to have something similar to garbage collection in managed languages, but forgetting that C++ is a wholly different language where the same approach to a problem is not necessarily the right (or even a good) approach. &amp;nbsp; Other than these few points every point I would like to make has already been made by other commenters already.
as a computer engineering grad trying to move into the higher level side of things, this made a lot sense 
[removed]
&gt; Linus would have hated this dude. :-) Can you elaborate why?
What I could figure out: * ODR = [One Definition Rule](https://en.wikipedia.org/wiki/One_Definition_Rule) * UB = [Undefined Behavior](http://stackoverflow.com/questions/2766731/what-exactly-do-ib-and-ub-mean#2766749) Related (defined in same link as UB): IB = Implementation-defined Behavior * CWG = Core Working Group (thanks, /u/millenix) * TU = [Translation Unit](http://stackoverflow.com/questions/8342185/translation-unit-in-c-and-c#8342233)
Without concrete numbers, better than google.
Starting base + bonus for fresh grads in the 150-200 range, + signing bonus.
Some guy who learned everything there is to know about HFT from Michael Lewis' Flash Boys, don't take it seriously.
&gt; Yeah, I don't after programming for more years than I've almost been alive... /s Is /s even necessary when that statement is obviously false. I don't know you, i don't know what you've done. You sound like a whiny kid with the statement you made saying he doesn't know how to program. &gt; Also those valid concerns, although valid on most, are like "Don't use an oven because you can burn yourself" So you agree they are valid, so your statement that he doesn't know how to code isn't true then? And not most of them aren't like that. Really only a few points there about the type system, which even then i have to agree. There is a lot of stuff with the type system that can go wrong, i'm sure i'd be able to trick you with it even. It becomes a pain especially when you get templates involved, cause the type passed can be anything. If you started from C then no you most definitely do not know the dos and donts of C++. Unless you write entirely in C style in C++ otherwise a C programmer will know nothing about the hellpits of C++. That statement is just completely false, the same mistake C programmers make thinking they can write C++ code just cause they know C, that's not the case at all. &gt; Also I never said anything about the #pragma once lol. No you just insulted the author and didn't bother to say anything intellectual or constructive. :)
That's fine by me. Welcome to reddit. And obviously you don't know who I am or what I have done, but the obvious is shown here. (Its very easy to look it up). Everyone on reddit jumps and gets their pitchforks to be right all of the time. Well, I'm not a whiny kid at all. I don't know you, but I may be older than you, who knows? Just because everyone does not want to talk in full paragraphs with correct punctuation on the internet all the time (especially when I wrote that lying down on a small phone screen) doesn't make them a kid, or any of that. You have your opinions on the subject matter, but even posted below in other comments you can see that this was just a rant, dragging C++ down and those who write C++ code. C++ has some issues, which are valid. But that does not mean that you know how to write in C++ properly. Pretty much anyone now-a-days can just write "hey I'm a coder", or "hey I'm a programmer" with having 0 real knowledge or experience of how the internals work, or were supposed to be implemented. Which does not make my statement false at all that he does not know how to code. (Which was just an general statement) I see people all the time posting issues left and right with C++ that aren't really issues, there obviously could be things that could be made easier for the developer. But I wouldn't say "just because this doesn't work the exact way I want it to" that the entire language is stupid. Once again my "don't use an oven, because you can burn yourself" comes into play. If you knew anything about C (as in un-managed memory) that should call and roll over. I haven't seen anyone who has written C have a HUGE struggle to moving over to C++ even C# (which is a hell of a difference). So yeah, I said and meant what I said. And if you get butthurt over "sounds like" which wasn't a direct attack on OP in the first place then you have other issues, welcome to the internet. EDIT: clarification
Could you explain how it is still an ODR violation. If lambdas have a different type in different translation units - for example `type_1` in translation unit 1 and `type_2` in translation unit 2, the calling `g` in translation unit 1 will really be a call to `g&lt;type_1&gt;` and the call in translation unit 2 will be to `g&lt;type_2&gt;`. Thus no ODR violation.
This is related to an on old and well known [tale](http://thread.gmane.org/gmane.comp.version-control.git/57643/focus=57918) (at least in C/C++ circles). [Here's](http://www.realworldtech.com/forum/?threadid=104196&amp;curpostid=104208) another such response and a newer one from his [G+](https://plus.google.com/+LinusTorvalds/posts/GkLj5pyvJ7D).
I don't have the knowledge to answer this. It depends on many many things. Optimization experience is nice, good C++ is better. There are roles that are more hybrid quantitative + software engineering where optimization experience would be a bigger plus, but you need a strong quantitative background for that. Most of the people on that team have PhD's (I used to be on that team, I have a PhD in physics). If you're going for a role that's primarily software engineering than the primary determinant of salary will likely be how strong we feel your programming is. C++, SDLC, experience, etc. There are some very specific skillsets where if you have experience it would be a huge (majorly salary altering) plus, but it would have to be a really significant amount of experience, at a more senior level.
&gt; in my area there is nothing at all You'd be surprised how many smaller companies are looking for C++ devs but don't advertise the positions well. There are a lot of small companies that just throw the positions up on the "jobs" page of their website and call it a day and then when they don't find someone in 6 months decide to finally hire a recruiter (who may or may not put it on Monster/Indeed/Craigslist/etc).
That sounds pretty awesome. Obviously the challenge comes with figuring out how we keep the docs up to date as the code changes but I'm sure nobody is going to upset if someone wants to write it in the first place. I'd recommend starting a discussion on the clang cfe-dev list too ( http://lists.llvm.org/mailman/listinfo/cfe-dev ). It's generally pretty friendly! While I personally don't see the need for numeric identifiers right now, maybe I'm in the minority :)
Does companies only hire fresh grads? What professionals who wants to switch career, for example, from network to C++?
Every inline function/function template/etc. calling `g` is now itself an ODR violation if present in multiple TUs, because they would be calling a different specialization in each TU. So it's viral. It also doesn't work, because the function template's definition itself must satisfy ODR, and if the original function doesn't, then adding a dummy template parameter doesn't make it so.
All of those are correct. You can remove the question mark after Translation Unit :) 
"Error novel"... that's a great term. :) Yeah, I'm not sure why g++ needs to spit out literally a hundred lines of errors for very simple mistakes, but clang++ seems to do it a lot better. While experienced programmers can dig through all those template substitution errors to figure out what's going on, it's death to new programmers, and is probably one of the best reasons against teaching C++ to new programmers.
I'm just laughing that I've actually gotten you to reply back for shits and giggles. Yeah I'm an asshole, I'm a dick and you got trolled.
It seems to still allow for ODR violations as explained by tcanens, but nonetheless this is a cool trick.
Thanks, and edited. 
That's taken care of with this part of the announcement: &gt; Qt for Start-Ups &gt; &gt; Over the last years, we have heard comments from many small companies and start-ups telling &gt; us that they would love to use the commercial version of Qt, but can’t afford the price of a full license. &gt; For these companies, we will in the coming months introduce a commercial start-up license for &gt; Qt for Application Development. This reduced-price offering will be limited to small companies &gt; and start-ups with annual revenue less than **$100K**.
Google doesn't hire remotes, even nearby ones willing to come in once a week. A friend of mine hooked me up with an interview there and they told HIM that they did telecommute but I'd need to come in once or twice a week. Then I ask them about that and they said no, we don't--so I said no thanks. Was very frustrating and probably burned at least one bridge--but you know, I was very straight forward about my requirements before they networked. I was pissed too for wasting my time on a lie.
If you just have some ideas to try out it's completely free. You just have to put the source online. If you want to make money from it, you obviously have to pay for it. ;-) Oh and for mobile-only there's a special, cheaper license available IIRC.
I thought LGPL license allowed commercial uses as long as Qt was linked dynamically, without the need to open source the rest of your code. Can anyone confirm if this is the case?
That's true, you can develop commercial applications with the LGPL license. See the [qt.io/faq](http://www.qt.io/faq/) for more information. /u/darthcoder wanted to buy Qt, and today the only option is to buy a license and pay $350/month.
&gt; But you can be sure those instantiations will be of the same specialization because you cannot possibly discriminate between two anonymous lambdas with the same signature. Huh? static_assert(std::is_same&lt;decltype([]{}), decltype([]{})&gt;::value, ""); Any compiler that doesn't assert is broken, and different types means different specializations.
Not really, that 100k is laughable. Your quickly over it. Its like the costs + your own salary for your self if you run your own company. But ofc. as a start up you don't pay your self ;) 
&gt; Interestingly I have never had to use std::shared_ptr ever, but even if I were to use it I do not think I the class would need to know if it was owned by a std::shared_ptr. This seems like an attempt to have something similar to garbage collection in managed languages, but forgetting that C++ is a wholly different language where the same approach to a problem is not necessarily the right (or even a good) approach. This is slightly naïve. Think about closures – you return a functor that captures `this`, thus `this` needs to live as long as the functor does. Creating a `shared_ptr` directly from `this` is wrong if `this` wasn't created as a `shared_ptr` to begin with. None of this has to do with GC. And if this seems like an unlikely scenario, do some async programming.
The output of g++ historically is "complete"-- it's showing you everything it's tried. g++ has improved as well, but without Concepts there are limits to what the compiler knows and so at some point it's hard to improve on them. Nobody likes this, and there's huge effort put toward making it better. That said, if your reason for avoiding C++ is because error messages sometimes can be hard to read, that seems... well, "interesting".
so your point is that 300 bucks is too much for someone generating 100k+?
Generating 100k? After my costs and taxes? (which is not what total revenue is). 350$ * 12 = 4200$. Per Developer. That is 4,2% of 100k. If you run a company and have 1-2 employees, you are already above this. Yearly revenue does not mean income after tax, its like what your company generates in this year. So if your business is cost heavy (say you buy and sell a product, or organize a conference like me), already your costs are way above 100k, even before you have paid a dime to your self or went anywhere. So if you write more then 100k in invoices a year, your above that line. So, long story short, no I don't have 4200$ for a license, running Meeting C++ is expensive, and lots of my work for the community is not paid. I was looking into ways to support the trolls, and going commercial for Apps other stuff was an option. That's why I asked them about the options, and Indie license is no more. So, if you don't have something that's build with Qt and generates this, no real option to go commercial. 
What I mean, is that you cannot discriminate between two anonymous lambdas when specializing a template. template &lt;typename T&gt; class Foo { … } template&lt;&gt; class Foo&lt;Type1&gt; { … } template&lt;&gt; class Foo&lt;Type2&gt; { … } Considering these template specializations, there's no way you could instantiate two different specializations with a single lambda definition such as [](){}.
That would be perfect if they actually helped me move. I need to be much better than I currently am though.
It's true, but IIRC it's not really "true" for mobile. The Apple Appstore forbids dynamic linking or something like that, and even on Android the legality is questionable because you can't offer re-linkable code that will work on the phone again because of signing and stuff. From what I read online, it's at best "grey zone" and the general advice is "Do not do it".
My imagination fails me, when would you **absolutely** want to link to Qt statically? Why not just link dynamically and provide the libraries and skip the costs?
I'm the author of said question's answer. I rectified the answer (again) after discovering core issue 765; It should be accurate now. I also filed a core issue and await response from the CWG chair, who will (being the author of the aforementioned DR) hopefully shed some light onto what is defective/intended. Sorry for the confusion, I didn't do my research well.
If you're going to use macros for compatibility, please don't disguise them in lowercase, because the environment changes but the code stays the same. If five years from now you upgrade to a BRAND_X_COMPILER that implements override, you will now be silently stripping keywords that the compiler supports and that people would never guess are being #defined away. Better to stick with OVERRIDE until you don't need the macro at all in my opinion.
Basically whatever you want, within reason. I think I roughly do 930 to 630 but it varies a lot in both directions. E.g. if I have no plans in the evening I'll often stay later to try to finish things, but other days I might arrive late because I'm at the doctor, or leave early to catch a flight. Some people work fewer hours than that, some people work more, it's really a large element of personal preference. You need to be making reasonable progress on your tasks is really what matters.
On the other hand, you may #include some third party header that deep down inside #define's its own OVERRIDE. These problems are embedded in the very nature of the C preprocessor, and the best solution is to avoid using it as much as possible.
It's not really a cure, either. Giving everything involved internal linkage would actually cure the ODR violation, but that's also viral.
answer the simple question then... where does any profit made by HFT come from?
I'll answer this simple question, then you'll have some stock rebuttal, and it will go on. Let's not pretend like you are asking out of curiosity. I'm not interested in helping you grind your axe.
Great that, I like his speed! :-D The only thing I didn't get is, he always has a single translation unit in his examples, right? How is LTO supposed to help in that case?
You can subscribe to the LLVM mailing list http://lists.llvm.org/mailman/listinfo/llvm-dev
Is there anyone you would like to nominate?
&gt; I would say however that using a `std::shared_ptr` for this purpose is not necessarily a good design decision. In 2016, for new code, using a modern compiler? Of course not. However, `shared_ptr` became _idiomatic_ for async code long ago because of the lack of move support and/or chaining completion handlers, and idiomatic matters. And, consequently, the usage of `enable_shared_from_this` in async code should be in no way shocking. Or maybe I'm missing your point altogether... ;-]
If you want to link the CRT statically you'd also have to link Qt statically, no? And linking the CRT statically is not terribly uncommon, at least on Windows.
in other words, you mostly do business with people that did not want to do business with you. It is called stealing. Enjoy your life.
Unfortunately, `strcmp` doesn't seem to be constexpr in MSVC 2015. `constexpr auto x = from_string&lt;e_1&gt;("e_1_a");` fails when using `strcmp`, but works with `equal`.
&gt; I'm 6 minutes in but if we're talking embedded I want to imagine the reason they choose C over C++ is similar to the reasons why I'm contemplating using C over C++. I'm on windows using GCC and I just can't figure out how to get the runtime out of the program and am struggling to get the size of the program down Did you watch [Bartosz Szurgot - C++ vs C the embedded perspective](https://www.youtube.com/watch?v=PDSvjwJ2M80), he mostly dispels that myth. &gt; Although even worse since I'm on windows portable executable specification says 500 bytes per section and there are 7 sections bringing the file to 3500 bytes on top of not even being a working program. Probably for alignment reasons, but more to the point, why does it matter to you at all?
I do agree with the thrust of his talk overall, and am a big advocate personally for c++ in embedded projects, but some of the examples he gives are really quite bad IMO. The main offender for me was the "NotNull" stuff - the c++ version with the class he presents is semantically different from the C version, it only checks the pointer is not null on construction. So, in the C version you can re-assign to the pointer before the function call and the check still happens. In the c++ version, you can't re-assign to the pointer at all (given the code he had there. And sure, he did say "you'll probably need a copy constructor/copy assingment as well" or similar). But if OTOH in the C version the pointer argument is just there to avoid copying a value around (which is much more likely), the correct C++ solution is surely to pass it in via const reference, which might actually be even faster and smaller than the object version. 
When a party sends an order to the exchange, they do so with the desire for someone to fill it. They don't pick any particular person to fill it, the whole point of going to an exchange is it's a big centralized place where people gather (digitally nowadays) so that their order has a chance to be matched by as many people as possible. Placing an order is in effect asking ANYONE to please be the other side of a trade. Sometimes that is an HFT. If you send a limit order at best you will get a fill *at the price you asked for*, at worst you will *just not get a fill.* What here is unfair? What exactly happened that wasn't asked for?
It makes sense. I replaced `equal` with `strcmp` (in `dev` branch yet).
&gt; Sure, but C++ is a tool and not necessarily the job I read an interesting blog post a while back on how programming languages are not tools but materials. Tools go away when you finish building something, but the materials it's made from remain for its entire life. But in that case looking for a "C++" job is more akin to looking for a machinist's job rather than a carpenter's job. Of course that's stretching the analogy somewhat. 
[Soundhound](http://soundhound.com/careers) is looking for C++ developers to work in a variety of roles in Santa Clara, San Francisco, and Toronto. Currently no remote. Junior to senior and everywhere in between wanted, including internships. We're on CentOS and use gcc. The majority of the developers are focused on server-side work. I've been here for a couple years and work on a data processing pipeline. If you're interested, PM me.
Heh sure
With C++14 (or was it C++11) you got enums that are scoped and therefore better than #define. Claiming that having to name the enum is a bug strikes me as being overly concerned with syntactic magic. It's hard enough for a compiler to parse C++ as it is, polluting the namespace even more is going to be ugly... I'd also say that SFINAE gives you the ability to get pretty close to concepts. The syntax is cumbersome for humans and arguably worse for compilers, but it can give you a degree of contract enforcement. At the very least, templates work out a lot better than macros in this regard.
&gt; &gt; I just can't figure out how to get the runtime out of the program and am struggling to get the size of the program down &gt; Did you watch Bartosz Szurgot - C++ vs C the embedded perspective, he mostly dispels that myth. It's not a myth that u/MINIMAN10000 can't figure it out. Though I do agree that Bartosz's video shows that the problem can be solved.
**Company:** Voony Games **Type:** Full-Time/Internship (we have both available) **Description:** Developing mobile games, cross-platform framework written in C++, scriptable via Lua. Relies only on a few commonly used third-party libraries, like SDL2, FreeType, etc. **Location:** Hamburg, Germany **Remote:** No **Visa Sponsorship:** We'll help you applying for a Visa. Contact me for more info. Contact me at arvid@voonygames.com More about us here http://careers.voonygames.com
Are the internships available for your Toronto Positions? If they are available in Toronto, are they 4 month or 8 month contracts?
I'm looking for a internship in the Netherlands, preferably in *Gelderland*. It's for a +/- 20 week period after the summer holidays. Feel free to send a PM for further contact. I study Technical Computer Science at HBO level. ^(I'm sorry if this thread is not meant for requests)
Is Noord-Brabant acceptable? Eindhoven area. You're from the HAN?
Some guy pointed out it might be a ocd sort of thing but I want to minimize my use of assembly - I like C++ so I choose that - But I also want to get everything out of the way that I can, Also inspired by the demo scene particularly [OpenGL 1k Mandelbrot](http://www.humus.name/index.php?page=3D&amp;ID=85). I also like cross platform so I choose GCC. I want the runtime out of there as it will run code that I didn't write adding size I don't want. I want all the padding out as it doesn't need to be there and it will get me closer to the [minimum Windows portable executable size.](http://www.phreedom.org/research/tinype/) I just want to create a project that is a blank slate as small as it gets and work on other projects using it as a starting point. One guy recommended "Merge" which is a visual studio command Resulting in this C++ Code &gt;int main() { &gt;int i; &gt;WriteConsole(GetStdHandle(STD_OUTPUT_HANDLE), "Hello world!", 12, &amp;i, 0); &gt; ExitProcess(0); &gt;} User this command line to compile &gt;cl hi.c /Ox /link /nodefaultlib /align:4096 user32.lib /entry:main /MERGE:.rdata=.data /MERGE:.data=.text /SECTION:.text,ERW /NODEFAULTLIB /dynamicbase:no kernel32.lib pause Resulting in this program http://imgur.com/pk9cdSw It's 1k, and there's no assembly but It's not using a cross platform compiler and I've got no idea how to replicate this with GCC.
I hate this analogy. C++ is not a tool, it's a language. Languages have intricacies. Sure, you can be proficient at software development. And many of the same concepts will transfer, but someone who works primarily in C++ every day is going to be more proficient than someone who has only used it for one class, or whatever, but has more experience in another language like Java, Python, C#... whatever. C++ is one of the hardest languages to master, in my opinion. Especially when working on projects where you could trace back most of the code to the early 90s. You're going to see so many different ways of doing things. Furthermore, the support for C++ is just not at the same level as some of the more popular languages.
Don't forget that the 4k demo guys use visual C++ on windows. They use lots of windows API functions, but the fact remains that you can create a 1kb hello world - I've done it myself. And that is before a compressing linker.
I really liked this talk. It did not teach me anything new, but will hopefully be watched by its intended target audience, "old school" embedded C programmers, and persuade them to change their mindset. It introduces a few of the unique advantages and zero-cost features of C++ in a very accessible and didactically sound way. However, I am one of those people who strongly believe that C++ should be taught as a new language, and not as a "better C", so I have to disagree with what is being said in minutes ~7-13.
Yeah with a little help from GCC IRC a guy threw me a few links on how to modify the results with a linker script so I should be able to do this now. He also told me GCC has nothing to do with LD the linker. So I learned that too. Side note - I don't like the idea of compressing linkers I much prefer the raw data than having to decompress. But I understand why the demo scene uses it after all the only limit they've got is the size of the file.
Eh, so you're looking to generate .COM files? Is that not an easy enough thing to search for? o.O http://nullprogram.com/blog/2014/12/09/ is the first Google result I see, and seems to be exactly what you're looking for.
I don't want .COM files those are outdated - I simply want the smallest portable executable. I guess I should have also mentioned I wanted to use modern executables? Windows has portable executables or PE also known as EXE, Linux has ELF, Mac has Mach-O. Now that I know about [linker scripts](https://sourceware.org/binutils/docs-2.25/ld/Simple-Example.html#Simple-Example) I can finally solve my problem There was even a page on [alignment](https://sourceware.org/binutils/docs-2.25/ld/Forced-Output-Alignment.html#Forced-Output-Alignment)
Hm, I'm pretty sure that the imgur link shows a PE file, you can clearly see the DOS MZ header and the PE header... A COM file would be just raw machine code.
owner&lt;T*&gt; is essentially a type-alias for T* used as an annotation so that a static analysis tool can make sure that, at compile time, (a) there is only one owner for a given pointer, (b) there is at least one owner for a given heap allocated pointer, (c) a non-owner copy of a heap allocated pointer is never deleted, and (d) before the owner copy goes out of scope, the pointer is either deleted, or has ownership transferred to another instance.
I think what he is saying in those minutes is that *when you are teaching old-school embedded C programmers* to use C++, it's OK to teach it in a incremental way. Otherwise, if you try to teach it as a whole new language, you will lose their interest and never get traction to switch to C++. I suspect (though can't guarantee since I can't read his mind) that for people coming on board new projects or who have never learned C, he'd say that teaching C++ as its own laguage is OK.
If the original `countof` was written to return `std::integral_constant` instead, like this: template&lt;typename T, std::size_t N&gt; constexpr std::integral_constant&lt;std::size_t, N&gt; countof(T const (&amp;)[N]) noexcept { return {}; } Then wrapping it in `decltype(...){}` will get you the `constexpr` value: struct S { int a[4]; }; void f(S* s) { constexpr auto s_a_count = decltype(countof(s-&gt;a)){}; int b[s_a_count]; // do things... } Or you could stuff it in a macro if you like macros: #define COUNTOF(...) decltype(countof(__VA_ARGS__)){} Either way, its another reason among many that at API boundaries, integral constants should be preferred over raw constexpr values.
Agreed. I think the question though is what are the static analysis rules that allow this to be guaranteed safe? Some cases are easy, but others less so. For example, what if you have a function like `void f(owner&lt;T*&gt;&amp;)`. Is the static analysis required to look into `f()` to determine whether the pointer is deleted? Is `f()` required to delete the pointer? Or is having such a function illegal?
Do you have this internship every year? I'll be studying in Freiburg next year and I was considering trying to do an internship while in Germany. 
I don't know, sorry. But when I said he's given the talk a few times, I was mostly thinking of [this talk at CppCon](https://www.youtube.com/watch?v=1OEu9C51K2A). It isn't exactly the same, but he is talking about a lot of the same stuff and using a lot of the same slides.
There a several posted for the UI team for c++, but here is one: https://www.teslamotors.com/careers/job/senior-softwareengineer-mapsandnavigation-25700
What are you trying to do where you are worried about every kilobyte in your binary and portability?
Like /u/WrongAndBeligerent says &gt;I'm just saying that C++ should be able to compile to a bloatless binary. and I'm working on doing my best to get as bloatless of a binary as I can get with mingw.
Kate's talk is awesome. It's something I shared with my co-workers. But I do understand that teaching someone incrementally who is already a hard-core C developer *and who has strong influence on a project coded in C already* is probably the right approach (or else you never get C++ in there anyway). Otherwise, I agree Kate's approach is best!
I'll be that guy. I'm there because I wanted to be, and not because I had any particular problem to solve.
Conversion from size_t to int is correct warning on 64 bit machines. This is not a bug.
I'm curious about that too. If an owner\&lt;T*\&gt; was initialized with nullptr and then get a pointer to an object conditionally (using if or by accepting a return value of another function), how would static analyzers guarantee that delete will be called exactly once only when it has an actual pointer?
Questionable if the value being converted is a compile-time constant, in which it's statically verifiable that no loss of information occurs.
pragma once and include guards will be obsolete when we have modules, so it's probably not a good idea to include it in the standard at this point.
&gt; Although I love the control we have with copies vs. all the forms of indirection, it is annoying to think about the consequences of copy constructors in nearly every line of code you write. Moves are still "new" in the mind of C++ programmers, but here's a tip. When writing a new class, ask yourself if it should be copy-able or movable or both. Want move but not copy? Make sure the copy constructor is deleted. Just apply the rule of 5 to very class and implement what you need and delete what you don't need.
It's not correct if the value is known to be between `0` and `INT_MAX` .
Thanks for the reminder. :)
That C++ version is terrible. Non op-code characters should be stripped out during loading, not checked against in the program loop!
keep telling that to yourself and it will all be good... "I just injected myself into a transaction with superior knowledge so I deserve to get paid". 
I did this some time ago, hooking up a javascript interpreter to a c++ opengl program and providing functions in javascript to draw rectangles and get input. While there were some rough edges, the end result ran very well and was almost trivial to port to web (although the drawing wasn't replicated 100%).
Can you provide any resources / articles on the topics of how one can navigate memory dumps, read disassembly and memory leak investigation? These seem like useful skills to know, and I'm not sure how one would go about them.
I'm curious to see how "No resource leaks" is going to be guaranteed under what conditions. I've been following what the Rust folks have been doing. As for resource management, Rust and C++ are very similar. While creating leaks in the safe subset of Rust by accident is hard, it's not impossible. Just create reference cycles using shared ownership smart pointers (Rust's `Rc` and `Arc` are similar to C++'s `std::shared_ptr`). This is not limited to memory. One of these objects in the reference cycle could be the owner of an opened file or some other non-memory resource. For guaranteeing that a compiling C++ program that passes all static checks is free of resourse leaks, there has to be a way of detecting (potential) "owhership cycles". In an ideal case there would be no false positives (no static checker should reject a perfectly valid program). But I have my doubts whether this is possible at all. My guess is that they won't be able to deliver on that promise. The Rust people have learned their lesson when the old "scoped thread" API was deprecated. They were *relying* on a particular destructor being called to guarantee safety (the destructor would block until the spawened thread finishes to avoid lifetime problems in which the spawned thread would access some parent thread's stack memory that's would otherwise not be valid anymore). But if you load off such a guard object into a reference cycle, you're screwed. What happened is that the Rust people realized guaranteeing freedom of leaks is not practical. The lesson was: Don't rely on destructors being called. Leaking was declared safe. So, safe code could easily leak using a reference cycle. That's why you now get to invoke the `std::mem::forget` function from safe Rust. It just swallows a value without ever invoking its destructor. This function used to be marked `unsafe`. But since you can implement it in safe Rust (via reference cycles), it might as well be a safe function. 
you can also return an anonymous struct from a function using return type deduction which kind of makes named tuples even more of a niche in C++&gt;=14.
While John Lakos is working on the [new version of his book](http://amzn.to/1OTKErh), it may be a good idea to look at what he's talking about at various conferences today (whether you agree or not, it's something to know if you're in this space). For example, "Applied Hierarchical Reuse" talk from C++Now 2013 is fairly representative: https://github.com/boostcon/cppnow_presentations_2013#wednesday (slides) https://www.youtube.com/watch?v=ASPj9-4yHO0 (video) 
Well what's your version of SimAnt them? 32 bit?
Hi @DinoStray, what exactly did you do with Application.mk to fix this? Just ran into this trying to publish to Fire TV.
Very interesting, GPU programming always seemed enticing from a performance point of view, but I never got a good grasp of it. For someone with little knowledge about the current technologies used in programming GPUs, this was very helpful!
ms vc++ dev mgr here. /u/TemplateRex , we'll try to give updated forward guidance on conformance around the //build timeframe (it's end of march). constexpr14 won't make update 2 as STL says. thanks, Steve.
[removed]
Look at how `std::scoped_allocator_adaptor` (and `std::experimental::pmr::polymorphic_allocator`)'s `construct` slice and dice their arguments before passing them on.
Its a talk on a bunch of APIs, CUDA being one of them. 
Ah I was just skipping around til I saw them finally mention an API, all I saw was "We're not talking OpenGL, We're not talking Vulkan," and then "We're talking CUDA" looks like after CUDA they talk about OpenCL, thrust, HCC, OpenACC, Boost compute, SPIR-V, C++17. Thanks for telling me I blame the fact of it not being a good idea of saying we're not talking about these which work on AMD/Nvidia and then going going to CUDA which isn't AMD/Nvidia. Unfortunate but I'm sure it wasn't on purpose lol.
The behaviour is consistent though, which I think is desirable.
You could probably use the implementation from libc++: http://libcxx.llvm.org/
LoL
Without context these restrictions seem artificial though I'm sure it isn't so simple or you would have already worked around it. One thing to note is that you can actually template constructors, and of course give the template argument a default parameter. 
Just skimming through, this seems like a pretty lackluster, barebones introduction to C++. You're probably better off getting a good C++ book, like Bjarne Stroustrup's (creator of C++) ["Programming — Principles and Practice Using C++"](http://www.stroustrup.com/programming.html).
&gt; What justifies the existence of construct/destruct? There are definitely use cases that I can think of: * You want a debug-allocator that prints when objects are constructed/destructed. * You have private keys in your code and what them to be zeroed out when the destructor is called. * You are using a C-API that requires you to path in a buffer that will then be filled. An allocator with an empty construct-method allows you to use this with `std::vector` without pointlessly zeroing the memory before it will be overwritten anyways. * During debugging you want to write `0xdeadbeed` to the memory after destruction, so that finding use-after-free bugs in your container-data-structures becomes easier. * Instead of initializing floats to zero, you want to set them to NaN, so that the use of default-initialized floats (instead of ones from actual data) become obvious. * … Now Andreij Alexandrescu gave a talk a while ago where he also complained about those methods being pointless, but let me put it like that: “Andreij says a lot of very good things, but not everything he says is equally good.”
That's actually an excellent idea for anything that has made it into the standard.
Wow, actually had to make a reddit account to apply. My first every comment is to a thread for my own material :). Realized it was on Reddit when Google Analytics started blowing up this morning. I'm open to suggestions on the name...hate to change it since we've already published a few papers with that name. Unfortunately we both started around the same time, well the full compiled language version started sooner, but didn't have time to finish it (darned thesis wouldn't finish itself)...the Raft consensus folks beat me to first publication (2013 vs. 2014). Maybe hermes or mercury...was trying to keep with the "streaming" theme. Like I said...definitely open to suggestions involving stream/raft/torrent, etc. Could go with "hover" but then the top 10 google hits at the moment would involve things catching on fire. If anybody is interested, I'm working weekends to get the distributed pieces parts put back in so you can run multi-node with the same code. It works, at the moment (code not in repo...pulled to clean up), but the implementation is pretty basic (done by an undergrad as a summer project)...and the machines need to be the same arch wish is unfortunate (maybe I'll go to fat binaries). Either way, sorry for the confusion (Raft consensus vs. RaftLib)...and thanks for checking it out!
Welcome to reddit, it's a fucking awesome place where you can do X and express your opinions and nature to the fullest extent allowed by the law. Be that as it may, it has many marvelous and wondrous features. 1st off, thanks for commenting on your own stuff. It might be good to associate yourself with things catching fire.. Just saying.
scoped_allocator_adaptor indeed is a very good example. I'm still not sure I consider it a worthwhile tradeoff, but it's definitely a very interesting non-trivial usage of construct.
As opposed to the previous post on the topic, the FQA as I remember it comes more from a place of irrational hate. The points it makes usually forget what the goals of the language are, what the language is used for, what it's best at, and what the history of the features is. It usually targets solutions that are clunky but meet the goals of the language, and criticizes them for not being perfect, without ever providing an alternative or a solution.
I also think that Allocators should only handle allocation and not construction/destruction, they shouldn't get the type at all. One can definitely argue that it is useful to customize the construct/destruct behavior, you gave valid examples. But this customization shouldn't be done in an allocator since it has nothing to do with allocation per sé. Putting those things there *requires* that the allocator is templated on a given type and in general violates the one responsibility principle. Instead, the customization point should be done by a different policy, not by Allocator.
You need to build a good web presence, such as a complete LinkedIn profile and submitted your CV to various jobsites. Recruiters use search tools on these sites to find relevant and potential candidates for their jobs. EG: a recruiter has a role that requires C++, CLI, Visual Studio knowledge. The recruiter can use LinkedIn search tools to search LinkedIn users that have mentioned such criteria on their profiles. They read the users profile, possibly contact them for the role etc. Once you have a strong web presence with enough detail as possible you will very likely get spammed for opportunities. When I first graduated my software engineering course I spent a few days flooding all these popular sites with my details. I would on average get several phone calls and emails each day for C++ job opportunities. When I got my first job I actually had a tough time stopping the recruiters from spamming me about jobs because my CV was passed to agencies I never heard of -_- Keep in mind this happened to me fresh out of uni, i'm not some senior engineer with tons of experience! Just make sure you put as much detail as you can, even if it seems redundant.. If you list C++, it's also useful to mention if your good at C or even C++11, you may think it's obvious you could know this stuff, but a recruiter who isn't a programmer hasn't got a clue, they are just following their script.
Writing allocator aware classes [is difficult](http://foonathan.github.io/blog/2015/10/05/allocatorawarecontainer-propagation-pitfalls.html), you have to take care of so many things. That - as well as the problems with writing Allocator classes - was one of the reason I started to extract the concept of (de-)allocation into a separate class so that it is decoupled from construction and type information. This RawAllocator just handles raw memory and does not care about certain objects. You can find the full library here: https://github.com/foonathan/memory/ With it writing allocator aware classes is [much simpler](http://foonathan.github.io/doc/memory/md_doc_internal_usage.html). &gt; It's bad enough that I am seriously considering just using placement new, and static asserting that my instance of the allocator does not have a construct method I must admit, this is what I am currently doing as well. If you try to use an Allocator as RawAllocator, the Allocator must not have a custom construct() or destroy() function.
It just seems like the common theme of all the use cases is to take things that probably belong in the container or the object, but since those aren't user controlled, to do them in the allocator. And since the allocator doesn't really understand the insides of the object (unless you specialize it), it's all POD related things. I don't quite follow the private key argument, why it would involve a lot of code duplication, but this seems a bit abstract without talking about how it's actually structured. So then, would you generally advocate for injecting the allocator type into the user defined type, in the scenario that I've outlined in my original question? Or do you think this might be a reasonable restriction since for example, it's not possible for class B to be a POD?
I'd have to see some code to give a well-funded recommendation, but as far as I understand it, `Allocator::rebind&lt;B&gt;::construct()` might work; you might have to add a destructor to `B` for that, if that doesn't currently work, but from my limited understanding of your situation, that shouldn't be possible?
Which just goes to show the huge agenda this guy has. It was clear that he has some sort of a personal beef with the language just from how disingenuous the whole thing is, but I didn't expect it runs *that* deep. It's been 8+ years, and he still cannot let it go.
The issue is not rebinding the allocator to B from A. The issue is just that B has no idea of the allocator's type at all, it is completely disconnected. A virtual function is also being used, so a template function is not possible either. So the only thing left is to inject the allocator type into B by making it a template class, but B is a user defined class that I injected a few hooks into via CRTP. So I am intruding on the user defined class, but minimally. Forcing the user to turn their class into a class template is a lot more intrusive in my estimation.
Glad to see that someone who knows a lot about allocators is doing something similar. I read through your page on the library, it's good reading, but I was slightly turned off by the fact that you have an allocator reference rather than an allocator, this seems a bit unnecessary to me. But defining a template to give saner defaults is something I'm going to look at. Btw, this might be of interest to you: https://groups.google.com/a/isocpp.org/forum/?fromgroups#!topic/std-proposals/PuJCLBC1glc
&gt; they shouldn't get the type at all. They *need* the type in order to ensure sufficient alignment; It also allows to create different memory-pools for different types of objects hidden behind the same allocator. Even if they would not construct and destroy objects, you'd still want to keep that property. Regarding yet another policy-argument: people are already now complaining about too much junk in error-messages and don't think that a somewhat bigger area of responsibility for allocators is enough of a problem to sacrifice for either dropping that customization-point entirely or further bloat the templates. 
This makes me think of Doom 3's source. It's delightfully sane and clean to consume.
Because that would be a heterodoxy.
Quoting ISO/IEC 14882:2014, [namespace.std]: &gt; The behavior of a C++ program is undefined if it adds declarations or definitions to namespace `std` or to a namespace within namespace `std` unless otherwise specified. A program may add a template specialization for any standard library template to namespace `std` only if the declaration depends on a user-defined type and the specialization meets the standard library requirements for the original template and is not explicitly prohibited. Which "standards" were you referring to?
wouldn't that be Ĉ++
I see ok. I always thought you could. Thanks.
One thing's for sure: Orthodox C++, done right, will produce the most readable code out there. Done wrong, it'll still be readable, but will leak resources like crazy! EDIT: Oh look, the "use stl only" gang strikes again!
Please summarize the purpose or application of this framework in your title. 
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
An improved version can be found [here](https://www.youtube.com/watch?v=01zI9kV4h8c). Reddit thread for new version is [here](https://www.reddit.com/r/cpp/comments/41c2p9/sfbaccppu_jan_12_2016_bjarne_stroustrup_on_no/).
On Doom 3 the lead programmer was an experienced C coder who was just starting out with C++. Naturally, he strived for readability, but that was readability as seen by basically a C guy (which he still was at that point of time).
8 years ...okaaay I didn't knew FQA existed from that long time.
It says &gt; Copyright © 2007-2009 Yossi Kreinin revised 17 October 2009 at the bottom, I'm assuming it's true. I don't know when it appeared exactly, though I'm sure I first read it a very long time ago. Edit: ok, I actually checked using Wayback Machine, it was first indexed in October 2007.
The thing is, it will work fine for experienced C or C++ programmers that know what they're doing and are ready to spend some $$$$$ on tools that detect memory leaks and are trying to improve their StackOverflow profile. I have no idea how will this help others.
&gt; Don't use exceptions. This leads to "Don't use RAII" which leads to very complicated and unreadable resource management code which leads to leaking resources.
Nice, thanks.
&gt; They *need* the type in order to ensure sufficient alignment; No they only *need* the alignment value. An allocator that gets size and alignment is enough. &gt; It also allows to create different memory-pools for different types of objects hidden behind the same allocator. You do not need different pools for different *types*, you need different pools for different *sizes*. I have implemented pool allocators working only on certain sizes just fine.
Thanks for posting!
Yes, but it means a crash on every resource acquisition failure.
looking for comments, suggestions for example apps, and even interface enhancements....there's always room to improve, especially at the alpha stage. 
This document is quite old but I am curious if there was any feedback on this approach. How does this compare with the current way we are doing dynamic casting ?
At least you can maintain readable code and fix those leaks. Now imagine that you have to fight unreadable code
It is possible to do following as long as i is public. But may be this not what you want. class C { public: int i = 0; void(*func)(C &amp;c) = nullptr; public: void setFunc(void(*f)(C &amp;c)) { func = f; } void callFunc() { func(*this); } }; void main(){ C c; auto f = [](C &amp;c) { c.i += 1; }; c.setFunc(f); c.callFunc(); }
this is generally not appropriate content for this sub - so i'm going to remove it. you should repost it to /r/cpp_questions
Ç++
I think he puts way too much effort for an average hater. Because the FQA is obviously meant to scare people off C++, I always assumed he wrote it to serve as a go-to argument in discussions like "Maybe we should consider using C++ instead of C on this project". But that's just that, an assumption. Maybe he's just *real* passionate about the things he hates.
Looking at his Github, it seems that FQA has already been there for two years without much activity, so maybe 6 years is more fair. Still a hell of a lot, though. Most people would have moved on already.
Use of default int in c++ in 2016...? And can someone tell what the difference is from this: std::for_each(threads.begin(), threads.end(), std::mem_fn(&amp;std::thread::join)); to for(auto&amp; i : threads) i.join() ? Not to mention that men_fn has been deprecated.
In two paragraphs then: "The reality is that between investors and the market sits a layer of middlemen who earn fees, commissions, and rebates from order flow and volume. This labyrinth adds little actual value to the market or the larger economy; middlemen profit from the complexity they have nurtured and sustained". And the other: "The greatest tragedy of high-frequency trading may simply be the wasted capital, both physical and human, in the quest for arbitrage profit. The $300 million cable from Chicago to New York added no tangible societal benefit despite its price tag. Wall Street firms have accelerated their recruiting of the best academic and technological talent in the country in order to run HFT groups, often siphoning these employees from universities and productive businesses."
&gt; And can someone tell what the difference is from ... Given ~~that mem_fn as you mention has been deprecated and~~ they're using for_each to iterate the threads vector I'm guessing this is just someone's pre-c++11 approach to launching/joining threads copy-pasta'd into this project. You could perhaps give them a nudge in the right direction .-) Specifically - they wanted to focus on CPU affinity and stats, and the code took a back seat.
No decent way to do in modern c++? I'm ready to learn anything but I don't have a starting minimal code to start with :/
I just wish we could set thread affinity for Windows OS, like it's possible on Linux, so that we can have truly dedicated cores/thread to a single application.
/r/cpp_questions
Isn't that already possible? Quick Google search led me to [this](https://msdn.microsoft.com/en-us/library/windows/desktop/ms686247\(v=vs.85\).aspx). (not a Windows developer here, but I thought this was also possible)
`B` should never allocate, construct, or destroy a `value_type`. It should be a dumb storage buffer, albeit with the ability to *access* a `value_type`. Injecting the `allocator_type` into `B` precludes nice things like SCARY iterators. For real use cases, see your standard library: `scoped_allocator_adaptor` defines a protocol where it passes itself to the `value_type` constructor, and containers such as [`list`](https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/bits/stl_list.h#L554) separate value construction from the node class. Note that libc++ has a little UB in [its](https://github.com/llvm-mirror/libcxx/blob/master/include/list#L1378) `list` implementation: It allocates a `__list_node` and then accesses its members without constructing it. The problem is that `__list_node` has a member of type `value_type`, so it's not trivially constructible if `value_type` isn't. The bugfix is to use `std::aligned_storage_t&lt;sizeof(value_type), alignof(value_type)&gt;` instead of a direct `value_type` member. Then the node type would always be trivially constructible and it's fine to access it immediately after allocation.
Since you're new to reddit, you should read the sidebars on each subreddit before you post (which usually will include submission guidelines). Questions aren't allowed in /r/cpp, for example.
`std::cin` is actually thread safe, contrary to what article says. It can, however, result in interleaved output, and the mutex there is to prevent that. From C++11 N3337 [iostream.objects.overview]: &gt; Concurrent access to a synchronized (27.5.3.4) standard iostream object’s formatted and unformatted in- put (27.7.2.1) and output (27.7.3.1) functions or a standard C stream by multiple threads shall not result in a data race (1.10). [ Note: Users must still synchronize concurrent use of these objects and streams by multiple threads if they wish to avoid interleaved characters. — end note ]
cpusets or cgroups are probably what you're thinking of.
&gt; I remember having read that linux could do this (and it required rebooting IIRC). [You can dedicate a core to a particular process](http://stackoverflow.com/questions/9072060/one-core-exclusively-for-my-process) using cpusets. No reboots necessary. Very handy when used with a real time capable kernel and dedicated IRQ servicing.
Some people prefer `&lt;algorithm&gt;`ic approaches where they can use them in lieu of a loop.
&gt; They need to be really fast. That implies the question: **Why** you wanna implement those functions in a different language? This will of course slow down speed, as it will always introduce an overhead... of course it depends on the complexity of the function, how much the overhead counts... So perhaps try to explain, what your overall goal is - perhaps your approach is wrong and we are dealing with an XY-problem here...
FWIW, I agree that the for range loop is nicer and shorter - I'll fix up the samples when I get the time. I took this from the book "C++ concurrency in action" which is weird, right :)? (because that book is about C++11 also) What do you mean by "use of default int"? 
Yep, I think this is bad wording on my behalf. By "unsafe" I did mean "won't give you the output you expect", rather than something nastier like crashes. I'll fix up the wording in the article and samples to be clearer
yes, you are right, only some overloads were removed for mem_fn.
The use of "unsigned" as a implicit int-type. Should be "unsigned int" or just "int" in this case. Btw, the question was genuine one, I genuinely thought there might be some magic hidden somewhere in the more complex code.
`unsigned` is *not* making use of implicit `int` or default-`int`. Rather, it’s a synonym for `unsigned int`, and always has been.
thats what i mean, shouldnt be used, should use auto if that is desired.
Do you like Dark Souls?
I'll have to disagree here. Overuse of `auto` is one of the pitfalls of C++11 in my mind, and I really prefer to use it where it increases readability. There's nothing wrong in using `unsigned` explicitly where it makes sense.
agreed, but 'unsigned' instead of 'unsigned int' goes against all of my intuition. However, I checked stroustroup guide and they are happily using 'unsigned' on some occasions, so you are probably right and its just fine.
Neither do I say 'signed'. ;)
I am using clang 3.5.2 because it is the only compiler that currently works for me. Hana doesn't compile with gcc and clang3.7 is broken on arch, so I am currently just using clang 3.5.2.
Just a quick thought, but you could probably create a precompiled header with hana included in it. AFAIK It's an entirely header-only library and therefore might see a speedup this way. Other than this, not much else I can suggest [besides working on your fencing skills.](https://xkcd.com/303/) You won't get D speed compile times, the language was purposely designed by Walter Bright to be capable of compiling template-heavy programs fast.
Modules are unlikely to reduce template metaprogramming compilation time in my opinion. You could try GCC &gt;= 5.1. On my heavily templated code, I found out that clang is using much more memory and is slower than gcc while on "standard" c++ code, clang is much faster than gcc. Are you using static if in D ? You can greatly reduce compile-time by using it in C++ in some cases. 
I'll keep that in mind :)
&gt; The with statement provided a way to explicitly manage the lifetime of an object in Python. This is not true! The goal has been to introduce a context for execution blocks. In fact you can use this to ensure the reliable execution of something before an object will be destroyed, which is of course similar to a dtor in C++. But it has nothing to do with lifetime in general (which you cannot control in Python at all!) &gt; This is the default behavior for C++, all the time. This is not true either, as RAII holds not when dealing with ``new``!
Right, by default I mean simple variable definitions on the stack. RAII is something you have to take an explicit action to avoid (namely, heap allocation). Reliable destruction and explicitly scoped exception handling is very much about lifetimes. 
I'm not sure how you came to these conclusions about what B should do. B is constructing a copy of itself, and it is the only entity capable of doing so, because it's a polymorphic object, so A does not know its real type. Someone mentioned scoped_allocator_adaptor; it is a good example though I haven't seen it used in the wild, nor am I sure that you can't accomplish whatever you need to do nearly as easily without it. The fact about UB in libc is interesting but I'm not sure what the direct relevance is?
It's rather sad, weak exception safety is a joke to get in modern C++. RAII does 99.9% of the work, and for what's left you have ScopeGuard.
Yes, but now you've replaced one type of error - forgetting to free - with another kind of error: forgetting to init. The point of RAII (ideally, C++ has structural problems that prevent it from fully achieving this) is that every entity in a given scope (i.e. every object name) corresponds to a valid object, and vice versa (that is, there is no object that doesn't have a name, that would imply resource leak). When you have a vector, you know it's always in a fundamentally valid state. You can always query its size, call push_back, iterate over it, and so on. Imagine if vector had an init method instead how much more bug prone it would be to use. vector is lucky in that it has a meaningful empty state (note: different from null state) that never throws. Not all objects are so lucky.
Aren't the mmx* registers per core? Why does the latency point there matter? (I would have thought the slowdown was due to cache eviction on the various L* caches, assuming the array is large.)
RAII is unnatural for Pyton, so it has a word "with" for it. Nothing to see here.
Yes, I run into the same problem. You have to compile clang yourself or downgrade to 3.5.2
That's because `int` is an option, and is shorter. What is shorter than `unsigned` for `unsigned int`?
Thank you for the positive feedback:) Debug integration is under way, lldb is not commonly used yet, and Arch Linux for instance have a issue they are working on. We are waiting for this to be resolved. Also, hopefully, MSYS2 will support lldb soon. 
Clang is broken? How? Did you create a bug report? It seems that you are building clang from source, can't u use precompiled packages? Also have you tried clang 3.7.1? If you can't compile clang with clang from source, maybe try gcc to build clang ?
Good catch wrt the break and continue statements... that's pretty embarassing. I've updated it in line with your suggestion. My only concern is whether or not the compiler, seeing the boolean conversion operator, is allowed to remove the construction and destruction of the guard object entirely...
Did you really mean to use xor in that sample function?
I don't think so, since creation of the temporary object has side effects and the lifetime of the temporary object is extended by the named reference. Would love to hear from an expert if that is wrong. 
I was always kinda sure that programmers job is to solve data transformation problems and try to do it in most effective way, not to be fluent with as many languages as possible :)
Spotted the HFT coder. 
Note that clang still re-parses headers, even when using modules.
But, given that with your method you still have to define `int_dec`, what's the advantage over the following? int main() { int i = 0; std::cout &lt;&lt; i &lt;&lt; std::endl; { int_dec i_dec(i); std::cout &lt;&lt; i &lt;&lt; std::endl; } std::cout &lt;&lt; i &lt;&lt; std::endl; } I guess there's the variable name and the extra line of code, but on the other hand there's no macro or weird if-based scoping tricks.
Thanks everybody! I guess I will start with luajit. Also tcc seems to be a valid alternative. 
In many languages, this is called "zip". See, for example, [zip in Range-v3](https://ericniebler.github.io/range-v3/structranges_1_1v3_1_1view_1_1zip__fn.html).
You should try using gdb to traceback the issue in the assembly code. Just to make sure your processor isn't execution instructions it actually doesn't support. That was my case back in December where gcc/clang had ICEs because it used faulty instructions which were not supported by my cpu. A microcode update fortunately fixed this. If it's not your processor's fault you should definitely report this.
It actually reads in the header files from disk, I verified it using strace (clang 3.7.0). I'm not sure why this is done, as I too would have expected it to store sufficient information (parsed tokens for templates as you say) in the serialized module files.
&gt; Some observations: [...] there's quite a bit of migration going on. *When the threads sleep most of the time.*
While I applaud the effort that went into miterator, it has to be said that Range-v3 gives real iterators, solves the proxy reference problem, and provides convenient adapter/facade templates to roll your own lazy ranges.
I upvoted you because I thought _you_ were advocating "use stl only", or something close to it. Now I see why your post is tagged as controversial – your point is entirely unclear, to everyone!
TFS-not-TFVC is pretty good. TFVC is what I have issue with. I can't think of a single good reason to switch from git to TFVC. 
Could you explain how concepts is a faster option? I thought they just constrain some types? For example if you try to pass a type to a function that does not satisfy the concept it will throw a nice error message at you instead of blowing up. At least that is my understanding of it.
If only registers are duplicated what's the point of hyperthreading then? Most usefull operations need to do math (e.g. like the sine example in the article). 
Like I said, it might not be helpful to you. Before Concepts, you'd do that sort of thing with metaprogramming. See `std::enable_if` for example. Making it part of the language should speed up anything that used metaprogramming to do a similar job. But Concepts is also about more than just giving errors. It also aids in overloading, template specialization, etc.
[Correct link](https://turingtester.wordpress.com/2016/01/18/writing-good-c-by-default-in-the-stl/)..?
&gt; auto who = successor(alex); Wouldn't that be `auto sean_parent = successor(alex);`?
We're not in disagreement that git does source control better. I was just giving you reasons why my company switched and why, to me, switching isn't that important.
That'd be my guess, his talks always inspire me
What's the "proxy reference problem"?
Aren't you being too pedantic? E.g Wikipedia article on thread safety speaks of the data races as one of thread safety concerns.
why are the launched thread and the main thread have same ID? I tested it on my machine and they are the same thread too
See `std::vector&lt;bool&gt;`. Iterating gives a proxy reference to the "elements" (which are bits), not a reference to the bits themselves, because that's impossible.
The standard guarantees that standard streams are race-free, but only starting with C++11. That is rather the point...
Like 7ddf32 said, one example is that some iterators do not return references to original objects, but some sort of proxy objects which should only act as references. This creates problems with STL in its current form: there is trouble with move semantics, some algorithms are not properly constrained, reference_type does not equal value_type&amp;... Range-v3 aims to fix this. In short it uses common types and common references to make STL algorithms and proxy references talk with eachother, introduces iter_move() as a customization point to pin down move semantics, and defines the needed Concepts to constrain all its templates.It's a complicated beast with its own issues, but a big step in the right direction. More here: http://ericniebler.com/2015/01/28/to-be-or-not-to-be-an-iterator/ and in the followup posts.
Thank you. I was not aware of boost::combine. Anyway doing a quick test, it seems combine does not work if the containers have a different number of elements.
I have very small personal library that I can use in code to measure performance. It outputs to a file periodically. This is way more useful than synthetic benchmarks. I wonder if there's any decent libraries that can do the same (can any of those you listed do periodical benchmark on running applications?), as mine is still quite primitive.
they have runners, so you could configure them to run periodically I think. Nonius is quite interesting because it even performs statistical bootstrapping on the sample, so the results should really mean something.
this-&gt;
I think its Eric Niebler, which has more less written the range implementation, which will complement the STL in future C++ Standards.
&gt; One thing I find problematic is that IDE "go to definition" features become a lot less useful when everything's auto and the type in question is nowhere in sight. There’s certainly a disconnect between the language and the tools with regards to C++. This is becoming better though. In particular, “go to definition” is a red herring in this context — what you actually want is type-aware auto-completion and a tooltip that shows the static type of the object, which are completely different operations that a good IDE can and should support, despite the use of `auto`. I haven’t got a clue how many IDEs support these operations, in particular the latter. But my IDE^(1) does support it. --- ^(1) Vim with YouCompleteMe
Actually it was `isolcpus` kernel parameter (which is done at boot; see [here](http://stackoverflow.com/questions/13583146/whole-one-core-dedicated-to-single-process)). Not really sure what the difference ends up being.
Eric and Sean are amazing guys, but they are no mathematicians :-/ it's more of the programming=math vision that we need now that Alex won't be pushing any longer
You can basically develop "console" applications e.g. for data processing.
Fair enough. I sort of assumed that, glad you confirmed it.
&gt; That being said, I am curious what can be achieved using only the C++ standard library without including other external libraries? In the end everything is based upon this and system calls.
you say "everything is based upon this" meaning everything is based upon including external libraries or based upon using the standard library?
Writing Bad HTML By Default, in the wordpress.
&gt; gcc practically gains no speedup from precompiled header That used to be the case but not any more. In [this experiment, for example](http://nibblestew.blogspot.fi/2015/11/build-speed-comparison-on-raspberry-pi-2.html) there was a 30% improvement on gcc on arm. &gt; majority of time is spent instantiating unique_ptrs, vectors and maps You can tell the compiler not to instantiate those duplicates with [extern templates](http://voices.canonical.com/jussi.pakkanen/2012/10/01/building-cc-what-really-happens-and-why-does-it-take-so-long/) (near the bottom). That is unfortunately manual work.
Interesting, maybe need to test again with new gcc version. I'm not sure about how extern templates work - never seen detailed expanation about it. If it works as simply as not instantiating template functions, then it prohibits inlining (using LTO is not an option, it's super slow and on msvc is practically single-threaded). Another question is how it deals with template classes - it can't possibly take that from another file and so it should be parsed anyway? If that's true then it's practically useless. Are there some bechmarks about using them in real projects?
If we're going to write good C++, maybe this: &gt; unique_ptr&lt;A&gt; pa(new A()); Should read: &gt; unique_ptr&lt;A&gt; pa = make_unique&lt;A&gt;();
The point is that you don't need stl in order to make safe code.
I haven't tried to use extern templates myself, so I don't know how they actually work in real world usage, sorry. From what I can remember pch with gcc on amd64 is faster than not using them but the difference is not as massive as on arm. I did use pcd with boost::python and the difference was huge, though. Compiling a single file went from seconds to a fraction of a second. That's probably an isolated case, though.
Probably, but it's not my code, and irrelevant to the point being made there.
That's why I hate 64-bit honestly! DX
&gt; Overuse of auto is one of the pitfalls of C++11 &gt; &gt; There is little evidence to support this; and decade-long experience with other statically-typed languages that allow implicit typing has shown no evidence either. I mostly don't have a problem with `auto` to the point of avoiding it entirely, but at the same time, I think that experience of other programming languages (that you also mention as relevant) may be worth taking into account. For instance, in Haskell (which has a rather advanced type inference): "It is considered good style to add a type signature to every top-level variable." - https://wiki.haskell.org/Type_signature - https://wiki.haskell.org/Type_signatures_as_good_style - https://github.com/tibbe/haskell-style-guide/blob/master/haskell-style.md#top-level-definitions (Note that "variable" in the above can also be a function.) There are some good reasons for this: - https://stackoverflow.com/questions/19626801/why-do-my-top-level-functions-need-signatures-in-haskell - https://stackoverflow.com/questions/23401698/what-is-a-good-reason-to-use-a-type-signature-for-functions-when-the-compiler-ca - https://www.quora.com/Why-should-I-add-type-signatures-to-top-level-bindings-in-Haskell?share=1 That being said, I think that in the future C++ declaring concepts may be a good compromise, similarly to the style described here: https://stackoverflow.com/questions/842026/principles-best-practices-and-design-patterns-for-functional-programming/842506#842506 Still like the "programming with placeholders" idea: https://www.reddit.com/r/cpp/comments/3oc63x/overload_journal_129_october_2015_includes_two_c/
Hi, I haven't read you're whole message however check-out [FASTBuild](http://fastbuild.org/docs/home.html), we are using it more and more in the games industry, it can auto-generate unity builds too. Also note that eventually C++ (possibly by C++17) should have a better solution to this by adding a real module system not based on textual inclusion of header files.
&gt; I also have no idea why people even try to extol any virtue of unity builds. Unity build made my build going from 30 minutes to 5 minutes. Which is necessary because the service I use for continuous integration is limited to 40 minutes per build.
Thanks, I'll try it! Unity builds have a problem of needing to recompile all cpps included in a unity file after a single change (though in moderation in really speeds up compilation and the whole work process), and problems with static functions\unnamed namespaces. Modules only help speeding up parsing and do nothing with template instantiation. This proposal is trying to solve that problem, not parsing. In fact, it works best together with modules. 
Well, I've got two reasons really Firstly I'm making a game and I need a dev blog Secondly I built a gpgpu only cross vendor deferred 3d renderer that can run the sponza atrium with dynamic lights at 6 ms/frame @1080p (or 3.5ms with frame reprojection, hd 7970) (a big improvement over when I shared this a while back on reddit), which the above game is based on. The game possibly isn't super interesting, but I'd say the renderer is at least a little
In the general case, you never want to look to the proposal papers for implementation code. Use the proposal papers (or the standard) as the guide by which to write your implementation. If you want an existing implementation, use one from a C++ standard library (which has a permissive license) or Boost.
Your service is building **everything** after **any** change, isn't it? There is **no way** that a well organised project takes as much as 30min on smaller changes (which is what a CI build is for) otherwise.
Well yes, like every online build services under the sun (Travis, Circle-CI, etc...)
Hm, after reading carefully Microsoft proposal on modules, they allow using template instantiation from module if it was used instantiated (implicitly or explicitly) in that module, but not others. So if you just export std.vector, it will be instantiated every time you use it, but if your module contains for example std::vector&lt;int&gt;, it can be instantiated only one time inside module (though not required). I guess it will solve a lot of performance issues with templates (at least with unique_ptrs). On the other hand, as I understand, Clang way (there is no proposal) is basically precompiled headers and doesn't help with templates.
Not really. Just use [sourcecode] blocks. I switched to wordpress from blogspot for just this reason.
FWIW, there's a study group working on a 2D Drawing/Input API. Last I heard, it was going to be based on Cairo.
Try enabling LTCG on large projects and you will easily see even worse linking times. With unity build you don't need LCTG at all, and linking is super fast.
&gt; I know there's a debate if such microbenchmarks are really useful I’m not aware of such a debate. In the context of high-performance libraries you occasionally *need* microbenchmarks to reliably assess whether particular implementations make your algorithm more or less efficient. For instance, I used to work on a library for DNA sequence analysis, which relies heavily on fine-tuned string search algorithms. We used microbenchmarks to perform micro-optimisations in the algorithms in that library. That said, outside of the context of such libraries (or maybe stuff like high-throughput services), microbenchmarks make less sense. In particular, the relevant metric for user interfaces is whether they are *responsive*. Microbenchmarks won’t help you assess this.
Well, the one we have at work is capable of building just the delta. You sure yours can't do it!?
First, there're those nasty kinds of bugs that occure only in release, or it takes too long to reproduce in debug (I remember recently debugging a data race in a 2-day long computation on a 20-core computer). Second, even in debug linking time of 1.5 minutes after practically any change in a header (like adding a private function to a class) is not really satisfying (incremental linking stops working after some threshold of changes I guess). 
what interpreter did you use? I looked into using v8 a while ago - but it was a lot to wrangle through :( thinking of using chaiscript as an alternative ...or duktape
You're certainly right, though right now on my machine linking takes one third of a time of a full rebuild in many cases, and if I just use unity build for everything, full rebuild with linking will hopefully be faster than just linking now). It maybe because I have too many cores though.
&gt; With unity build you don't need LCTG at all, Yes or no, there are optimisations that only get enabled if -flto is passed to the compiler in LLVM iirc
If true, Alex's retirement would be sad, a big loss for the community. Here are a few pointers to his recent work: * http://www.amazon.com/Elements-Programming-Alexander-Stepanov/dp/032163537X * http://www.amazon.com/Mathematics-Generic-Programming-Alexander-Stepanov/dp/0321942043 Also, his A9 lectures are linked from here: http://www.stepanovpapers.com/
I'm just trying to say that both full rebuild and minimal rebuild time are important (not exactly equally, but it differs for various usages). About linking - yes this is one huge executable, like 70 mb, but with everything statically linked (qt, /MT, and minor stuff). Unfortunately we (programmers) can't change it, it's company policy to put everything in one self-sufficient exe file.
Inb4: hipsters extolling the virtues of microservices :-) 70 is definitely unusual. Bleh. Inept policy (but hey, I've seen and made more of those than I care to remember, who am I to judge?)
Are you sure it's actually reading the file and not just stating it? The implicit modules model will still stat all the headers to make sure they haven't been changed. Clang only actually reads the files if it needs to produce diagnostics.
But this breaks cases where the temporaries are inside a function call! For example: Foo(TempObject()); If TempObject has an operator that converts to what Foo takes, and that operator is &amp;&amp; = delete, then you now have to store TempObject in a scope in order to pass it to Foo. Previously this would have worked fine, since Foo completes before TempObject() gets destroyed, but this syntax will make it fail to compile. So I'm not sure this is a win win idea.
Well, you can choose to implement it and return by value, and then it will be ok. To take your particular example literally: if Foo takes Bar, and Bar is not a polymorphic object, then it's safe to write the conversion operator and return by value. You don't need to resort to a function call though: auto x = *make_unique&lt;Blah&gt;(); This works perfectly (if inefficiently) right now. x gets a fully copy of the object so nothing dangles. If my suggestion were implemented, this valid line of code would be a compiler error. I think this is ok; it's eliminating a very minor amount of convenience (and really you only have to give this up for polymorphic types) in exchange for avoiding a significant class of dangling reference errors.
&gt; One thing's for sure: Orthodox C++, done right, will produce the most readable code out there. Done wrong, it'll still be readable, but will leak resources like crazy! Tell me, how does the above convey that at all? In fact, it implies the opposite – that an approach avoiding the standard library will leak like crazy if not done perfectly. I agree, you don't need the standard library to make safe code, but it sure makes it a hell of a lot easier!
[Programming -- Principles and Practice Using C++ (Second Edition)](http://www.stroustrup.com/Programming/)
I remember being in the same shoes as you when I was 14. I got interested in C++ after playing Half Life and that's how I became a programmer. Keep practising and practising. It's like a foreign language where the more practise, the better you get. I suggest to learn from a book while also building a 2D game with [SFML](http://www.sfml-dev.org/index.php) so you can apply what you've learnt. Go to [Stack Overflow](http://www.stackoverflow.com) if you get stuck.
Also this tutorial might help too: http://lazyfoo.net/tutorials/SDL/index.php
The sample in the article queries the launched thread's ID from the main thread. The main thread's ID is not reported 
Yes, it's definitely calling read on those file descriptors. Merely including a module's header does not cause the read, but using one if its symbols will.
I don't think Stepanov has done any significant new work for some time now. Therefore his retirement is not really a sad event, especially after him summarizing all his brilliant work in the books mentioned in the comments and in a little more broad manner in the a9 lectures. The retirement is well timed and well deserved. I am really grateful for him showing me, that there is more to C++ than just taking care about making your destructors virtual. Also I always giggle a little when I write: while (first != last) { ...
I would say, reading a tutorial, or doing a tutorial can help you get the language basics, and symantics down. However, finding small projects to do like, flip a string of text, manipulate a string of text, or move files from one spot to another. Write a file, read a file, encode a file, would be good things to work on. Go through the tutorials, learn how the languages work, then put it to practice. Look at things like /r/dailyprogrammer or Project Euler for some challenges that should exercise your resourcefulness, and also your ability to learn things. C++ is a powerful language, so make sure you don't dive head first into some big projects and get overwhelmed. Do remember that the best projects take a while, but cowboy coding can get you instant results, but usually not the best. It can be a way to quickly test a theory out, or see a process, but I wouldn't use it in production. Reading, and asking questions on sites like Stack Overflow, or perusing through Stack Exchange will help you learn how to ask questions to get the most out of what you're wanting. Sitting in an IRC channel that is dedicated to C++, I'd look on irc.freenode.net, and just "listen" to them as well. Try to find an active one as just sitting in a quiet channel doesn't help. 
In my example Foo would take a pointer or a reference to the object passed in, and Foo doesn't want to own it. So any function where you pass in stack based temporaries would have issues if you block &amp;&amp; methods. void SomeFunction(A &amp;a); SomeFunction(*std::make_unique&lt;A&gt;()); // Error, no more parameter temporaries I know my example would be best solved other ways, but the concept holds. You can't use parameter temporaries that have &amp;&amp; restricted since they will now fail to compile but never had any dangling pointers. 
**Company:** Rogue Gaming Studio **Type:** Full-Time **Description:** Developing casino games for Linux and Windows platforms written C++. Older code bases focus on C++98 standards while newer code bases embrace Modern C++ approaches. See our [Software Engineer](http://www.indeed.com/viewjob?t=software+engineer&amp;jk=be5b012d1c4ba864&amp;_ga=1.154261240.1995162285.1442246049) job posting for more information. **Location:** Reno, NV **Remote:** No **Visa sponsorship:** No **Miscellaneous:** * PM me for questions. * Relocation assistance available. * Knowledge of Modern C++ is a plus. * Casino gaming experience is a plus.
The biggest reason for not worrying about performance until after everything works is that very often, once the software works the customer will realize it should work a different way. It's a statement about UX, sales, and customer service more than a statement about engineering. It's fruitless to micro-optimize your milliseconds if the customer realizes they want their workflows rejiggered to save them days, and the product redesign creates a new bottleneck that uses orders of magnitude more CPU than the entire old system. If you are reasonably confident that your requirements are not going to change, it makes sense to do microbenchmarks and design up-front to ensure that you've got the most efficient architecture. Just be aware that many teams who thought their requirements were set in stone found out that the business reality was anything but.
&gt; The point is that you don't need stl in order to make safe code. &amp;nbsp; &gt; Considering the fact that I never even mentioned the stl library in the comment, it should have been rather obvious ... Yes, **not** mentioning something is what makes something obvious. You **must** be trolling. If not, then good god, learn to communicate.
There are tons of nyc low level C++ (and C) jobs, they just don't seem to be getting posted here.
Oh I see, thanks for clarifying that!
Also, for those who are stuck on C++11, making your own `make_unique` is relatively easy. template&lt;typename T, typename... Args&gt; std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp;... args) { return std::unique_ptr&lt;T&gt;(new T(std::forward&lt;Args&gt;(args)...)); }
Yes! Even if you don't want to get into C++ career this is the book you need to start programming - from the author of C++, the best programming book ever!!!
You can't help those who won't help themselves
&gt; Sure, it is slow, but who cares!? Anyone whose time and money can be better spent doing something else. Do you honestly think that 2 hours build time is okay? I work on a project that simultaneously maintains an Objective-C and a C++ codebase of similar size. In fact, Objective-C is bigger, and yet it builds 20x faster. This is the speed-up potential that C++ could theoretically have; and yet, as it is now, build times in C++ is beyond fucked. People should care. C-like header dependency is completely ill fitting for a complex, template capable language, such as C++. I'm really hoping that modules will fix this soon. 
Where do you think those libraries and APIs came from? Somebody wrote them. Using c or c++. 
I thought this was a good presentation. I do have some questions however about code that I do not understand. At ~33:30 in the video, he is talking about a "declare" vector that inherits from the base class vector and uses it's protected constructor. I do not see where this protected constructor is called. To me, in the declare scope vector, I simply see a C array of type T, and in no way do I see the protected constructor being called by passing in a data and size parameter. So to clarify, my misunderstanding is with where the protected base class vector constructor is called. Also, where is the declare::vector actually declared at, and how does it effect the non-base class vector? Sorry if some of these questions are blatantly obvious, I come from primarily a C background and am trying to improve my C++ techniques.
The advise here is good, but I would recommend one small step first. Read Charles petzolds book "Code". C++ is a much smaller abstraction of core computing principals than higher languages. Understanding why some things are the way they are could increase understanding thus speed up the learning process.
That 2-hour build is done overnight, it rebuilds our "world" and creates a bug in the ALM system if it fails for someone to pick it up. **Yes, this is acceptable**. As I said in the very beginning here (*please* see top post), when working on a particular module (or a set thereof), build drops to a handful of seconds, because then I compile a couple of files I changed (and their dependencies if public interface changes), those are linked in their modules and I use all build help I can get (care of modularity and elimination of gratuitous compile-time dependencies being the biggest). Yes, I know that other languages build faster. Yes, I know that header inclusion is the core of all problems. What I am saying is that issues are worked around by using tools and working smarter, and I saw improvements in doing that, with my own eyes, in numbers. He who comes up with "Rah rah, my build time is always 5min" (for 200-300KB codebase) are doing shit work.
thank you for this, repo is awesome as a guide! cheers
I will try and summarize what I think is important here. I myself landed an internship at EA DICE when I was 22 and did my Master's Thesis on the Frostbite game engine. Everyone has a different idea of what learning C++ might entail. I think there's a lot of things in the C++ language that doesn't have anything to do with game development that you should stay away from. One such thing is template meta programming because it tends to lead to code bloat which here is a situation where the executable binary grows unnecessarily large. As with all kinds of advice, there are of course cases where C++ templates do make sense. Nothing is that black and white. Any beginners tutorial will do just fine for now (if you are just starting out) and unavoidably you will probably learn about classes and inheritance. The trick really is learning how to deconstruct complexity into simple units of code that you can more easily understand (not necessarily reuse) and this is in no way limited to object-oriented class designs (it's the bane of our existence). In the words of a much more experienced game developer, game code is disposable. A means to an end. The best advice I can give you is that you should not focus so much on the language itself. Instead learn about how to organize your data in an efficent manner. Learn how state changes happen throughout your games. But most importantly of all, create games. It doesn't matter whether it's a great game or not (you don't have to show it to anyone) but do it as an exercise to grant you the experience. The best game developers can do almost just about anything. They learn new things quickly and are proficient with more than one programming language. As you dig deeper into this whole mess I hope you find some joy out of it. I did, I always had a lot of fun learning these things and I think it's an important key to success. That you have fun doing this. Let's me know If I can help. Ping me. I leave this here for future reference. Maybe none of this makes any sense right now but it will. 
Our project is About 10 million lines of c++, on a 40 core machine with 32GB ram and an SSD. It takes about 3 minutes to link our executable, never mind compile it. Our compile time from a fresh sync is about 10 minutes using a unity build, and about 40 minutes without a unity build. 
Well said this time around! :-]
very good point, since we often don't know the final specification it's better not to optimize. And it seems that such benchmarking is good for specific app areas: like servers, high performance computation, low level stuff... but definitely not for UX - there you need some other tests...
The Module proposal (greenlighted by the Evolution Working Group to proceed as a Technical Specification) allows you to export an explicit instantiation. In which case, the semantics is essentially as if you had written an explicit extern template specialization, which allows sharing of that instantiation - so the work is done only once. The spec is written so that further sharing is permitted and possible, for example if all arguments to a template specialization involve only exported entities. Also, we are working as a community because this is an issue that plagues the entire C++ community; there is no Clang vs. Microsoft proposal. Only one C++ module system that we are all working on.
I think you shouldn't start by learning C++. It's great that you are interested in programming and that you know what you want to do as a job later, but C++ is, in my opinion, not the best language to learn how to code. If I were in your position, I would start by learning C and how to use a UNIX system. I know it's not as sexy as C++ and that you won't be able to do whatever you wish for now but these are the fundamentals. C is simpler than C++ to learn the basics as there is no object paradigm involved, as well as simpler internals. Yet, you will be able to learn about data structures, how to manage memory, pointers, programming flow, and so on without any interference of more complex concepts introduced by C++. Once you feel confident enough in your understanding of lower level concepts, code some simple projects such as FTP server/client or small games using SDL (for instance), start learning C++ again. This way, you will be able to focus on the object oriented programming part and you will be able to learn it better and faster because you will have strong fundamentals. Don't forget that you will not start to work before you're around 22-25 and by then, nobody can tell you for certain which technologies will be around. Having a good understanding of algorithms, software architecture and programming flow is much more important than knowing one specific language. You might also discover some other programming areas that you could have more interest in than video games during your time at university (it was the case for me). I wish you a lot of fun and learning :)
I would suggest - Stroustrup "Programming: Principles and Practice Using C++" - to learn C++ in general - Scott Meyers "Effective Modern C+"+ - extremely important to understand critical concepts. - Herb Sutter "C++ coding standards" - to make your source code nice For the beginning it is more than enough. Just to recall you have to know not only C++ itself. Network, OS API, third-party libraries, hardware, concurrent programming, debugging and so on
&gt;I feel like I don't understand well and quickly forget codes and all This gets better with practice. It takes some time until you are able to look at code and immediately understand it, and even then it's not a given depending on the code. The most important thing is to understand the concepts, it's doesn't matter much to know how to write everything as that can always be googled.
Eric may be no mathematician, but he certainly is a magician.
What does it mean to iterate over a group of ranges where each range *doesn't* have the same number of elements?
Learn, then work with people who know more about it than you do. Repeat.
Thanks for the help, so does this book give you sort of a head start or a better understanding of the language so you can later write good code?
I'll give it a try, thanks for the help :)
Sure, i'll look into it, thanks for the help :)
Thanks alot, so in which way can I learn algorithms, software architecture and programming flow, through learning languages or is there another way.
Thanks for your post. Have you tried the Play mode within the C++ app? This can be a good refresh and a fun way to practice and compare with others. 
Thanks for the advice :)
Effective Modern C++
Effective Modern C++
Effective Modern C++
Effective Modern C++
Effective Modern C++ 
Effective Modern C++ Jk. I'm in the same boat so yeah, here are some resources in no particular order - - https://isocpp.org/ - https://www.pluralsight.com/courses/accelerated-introduction-cpp - https://www.pluralsight.com/courses/cplusplus11-language-features - http://www.stroustrup.com/C++11FAQ.html - https://isocpp.org/wiki/faq/cpp14-language - http://stackoverflow.com/search?q=c%2B%2B17 - https://www.quora.com/What-are-the-key-new-features-in-the-C++-14-standard (sorry) - http://www.bogotobogo.com/cplusplus/cpptut.php Btw pluralsight courses were free for developers (about 6 month subscription), just search for "visual dev essentials" :D
There's a book by some called called Scott Meyers. Can't remember the name though
Effective Modern C++
Effective Modern C++
Get Tour of C++ from Bjarne.
How does shutting down engin.io signal the failure of qml?
Is there one where they're not using made up words? 
QML is a success, and especially used on embedded touchscreens. Qt is alive and well, the Qt Company is profitable in 2015 according to what I heard. I think its just the case, that you can't compete with AWS, Azure &amp; co. They were already cheaper when engin.io started...
Effective Modern C++
Effective Modern C++
Tour of C++ (Bjarne Stroustrup) was pretty good at a broad overview of C++11
Agreed, it's a good overview of what's new without delving into new best practices like EMC++
Modern C++ Effective?
3 years isn't old. I been working in it for 15 and am still a young one.
These things are not correlated with languages and need not to be mastered before starting to code. You will learn them as you code, have your code reviewed, or by reading books. I would also emphasize the importance of failure in your learning process. It's definitely OK to fail while you're learning software programming, as long as you really searched for the answer to the problem you have before asking for help / searching google.
After reading *Effective Modern C++* by Scott Meyers, you can also refer to the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) led by Bjarne Stroustrup.
I don't know if someone has already mentioned this but what you want is Effective Modern C++ by Scott Meyers. Seriously though, the book assumes you already know about most of the new C++ features, and is more concerned on when and where to use them. Still recommended. 
Thanks for providing it. I actually did manage to understand a part of it thanks to knowing English and German. :) &gt;All too often C++ is used as if it's still 1990 This is why I rather use C++ on personal projects. CERN was the only place I have seen C++ being property used vs all the other places I have worked. 
If you create struct/class and then create some objects of this type, then each of those objects will have it's own set of variables defined by you (unless you mark them `static`). Simple example: struct Pokemon { // same thing with classes // functions int getLevel() { return _level; } // function to get pokemon's level void setLevel(int level) { _level = level; } // function to set pokemon's level // variables int _level; // per-object variable static int something; // static variable means that each Pokemon object will share this variable }; int Pokemon::something = 42; // you have to initialize static member variables Pokemon p1, p2; p1.setLevel(10); p2.setLevel(8); p1.getLevel(); // returns 10 p2.getLevel(); // returns 8 p1.something = 3; // now p1.something == p2.something == Pokemon::something == 3 I personally suggest you take a look at good tutorial becouse this is very simple concept and you should learn it from there.
ANSI Common Lisp by Paul Graham
No more porn...
You definitely need to read a good book on C++ first. Refer to the right column for the choice of the book. As your question: objects are not *derived* from a class. They *are* instances of a class. For example std::vector x; means `x` *is* a `std::vector`. Member variables, however, are stored per object: class monster { public: int level; }; monster a; monster b; both `a` and `b` *are* monsters, but each has it's own level. a.level = 10; b.level = 80; assert(a.level == 10); // a.level is still 10 
Is there any interest in creating a mode of C++ (enabled with a compiler switch) that breaks backwards compatibility in favor of some lessons learned that could make the language a bit more clear and approachable? As Scott Meyers might say, to "break some eggs": http://scottmeyers.blogspot.com/2015/11/breaking-all-eggs-in-c.html
And after reading the core guidelines, use the [Rust Compiler](https://www.rust-lang.org/) to validate your code.
do you get the same results when run under valgrind?
Good thing it's ANSI Standard with vt100.
All words are made up.
Here is the result of valgrind (program rebuilt with Clang sanitizers disabled). https://gist.github.com/TheBuzzSaw/aa1b566a0af0f48073dd
Watch all Going Native 2012, 2013, and CppCon 2014, 2015 videos. Most GN videos are for exactly people like you who already know C++. This has been posted multiple times before :-)
I love playing around in rust, but it really isn't ready to fill C++'s role as a low-level, performance-critical language yet and won't be for a long time.
Yes, fontconfig does sort of leak memory per font. It deallocates them when the library is deinitialized, but that's a process-global thing so it's very difficult to actually do safely, so I wouldn't be surprised if Qt doesn't (even if it knows the application is exiting, something else in the process could be still using fontconfig directly when Qt itself is deinitializing).
I'm talking about finding out that the page you spent optimizing accounts for ~5% of pageviews, and soon after writing it, the customer realizes that if you add a real-time endpoint (running a different algorithm) that gets 20x the traffic, their business becomes three times as efficient and they will pay you double. At that point, you're much better off optimizing the *new* feature which gets more usage, but you can't do that if it doesn't exist. This happens all the time: if you deliver a workable solution that meets their needs, customers usually want you to deliver more. Oftentimes, the new stuff gets a lot more usage than the old stuff, and it's more computationally intensive. Optimize when it becomes a bottleneck to further sales; not just for the hell of it. The customer doesn't care if a page takes 10ms or 20ms to render when a human doing that job would've taken 2 weeks.
Most "system" libraries generally "leak" a fixed amount of memory (which does not matter at all because the OS reclaims it at the end anyway). 
 ==29825== Process terminating with default action of signal 11 (SIGSEGV) ==29825== General Protection Fault you have a segfault at the end so maybe some stuff does not get the time to be freed ? 
I don't really disagree, but where do you think Rust falls short at this point in time? I'm curious at how you see Rust's development versus where it should be before you see it as a viable alternative to C++. I guess my real question is, what features/libraries do you think are "must haves" before it can compete?
i like this thread, i'm gonna sticky it.
Anything that wasn't on Sesame Street is a lie
Thanks for the link. Great info.
It's performance ~~is currently~~ [edit: *was*, currently nearing C++] on par with java, and it's not clear that there are significant enough advantages in other areas to using rust over the well-understood industry standards, and the knowledge base and toolchain support that comes with them, to warrant using it over C++ or C.
Basically every big-endian CPU architecture has dedicated instructions for reading little-endian data. So, for Cap'n Proto, it means we would use those instructions inside the inline accessor methods for numeric fields. So the data is still stored in memory in little-endian format, but this doesn't hurt performance. With that said, basically every widely-used CPU architecture today is little-endian. As for other differences, all modern architectures agree: * A byte is 8 bits. * Integers are encoded using two's complement. * Floating-point numbers are encoded using IEEE-754. * Primitives should be aligned to a multiple of their size. It turns out that's enough agreement for Cap'n Proto to come up with a reasonable cross-platform in-memory format.
&gt;It's performance is currently on par with java This stands out to me as particularly interesting given it's a stated goal of the Rust project that sub-C performance is to be considered a bug.
Classes, specifically the definitions of a class, are a cookie recipe. Objects of that class are the cookies. If your recipe says to add chocolate chips your cookies don't all share the same chips unless you tell it to (static).
That's completely untrue, at least on the performance part. Rust is on level with C or C++. http://benchmarksgame.alioth.debian.org/u64q/rust.html
My sources are out of date, from the 1.0 benchmarks. I can't find good benchmarks on the current stable v1.5, but from the way it is being discussed it sounds like they're nearly on par with C++ now.
Any member function of that template that is declared (and therefore defined) inline remains inline. Compilers typically use tricks such as weak symbols and/or extern inline to make it work. Of course, if everything is inline, you don't gain much depending on the compiler. With modules, the compiler is required to give the illusion that the inline function is compiled once. I expect most compilers to do just that: compile once, while retaining enough info for inlining. So, no linktime code generation is required. 
"no-opt performance" ?
That's because it's a falsehood. Rust does have C/C++ like performance. A little better, a little worse, depending on the specific benchmark.
I personally don't trust that particular benchmark suite much, and I've never reimplemented one of my nontrivial java programs in rust so I can't offer my own anecdotes, but it does sound like the people who would know these things do say that performance is now close to that of C++.
Boost is definitely too big for my use-case. I want to drop the header (ideally 1) into my project, but boost has too many headers. It is not even clear if boost containers depend on other parts of boost. 
I think everyone in the cpp reddit should be proud of themselves today. I got a very good chuckle reading, good job everyone. 
How do you expect any non technical users to adopt applications wriiten in rust if there is no GUI. Unless you adopted some form of multiple part system. Long way for a shortcut if you ask me. Not everyone is a developer, i feel like a lot of devs seem to forget that. 
Recent versions are better split up, it's "Modular Boost" now, with separate repositories [https://github.com/boostorg](https://github.com/boostorg). Specifically: [https://github.com/boostorg/container](https://github.com/boostorg/container) I don't see any mention of what the dependencies are in the docs, though: [http://www.boost.org/doc/libs/1_60_0/doc/html/container.html](http://www.boost.org/doc/libs/1_60_0/doc/html/container.html) I haven't used it, but this looks interesting as well: [https://github.com/boostorg/boostdep](https://github.com/boostorg/boostdep)
They're still teaching C++ this way in my university.
Can you elaborate on why you can't use STL? Because "it has linker component"? What does this mean? That it requires a linked library? STL, being templates, don't have a library to link to. They may require other components to things like dynamic memory allocation, but I truly dont understand what youre asking for, here.
modern C++ is older than 3 years. You've been working with C++ for 3 years and you've been using the C++ of 1992?
Unfortunately libstdc++ and libc++ are not header-only. They both require linking with corresponding library. The code that I'm writing is "lower level" than libc++ and due to some compiler shenanigans it has to be 100% self-contained and has to produce a fully self-contained library (module some system calls of course). 
Thanks. I'll check it out though boost never was a small library. 
A lot faster but limits how complex your type hierarchies can get as you start running out of eligible typeids IIRC. I think it would be awesome to be able to turn this sort of thing on for small/embedded work though.
A number of these were meant for people who hadn't caught up with newer standards, too. 
&gt; 1. In many circles QT is considered to be crap. What is the platform these circles use? Or do they just try to minimize the crap they are stuck with . . 
"I can't write solid C++, therefore it must not be possible for anyone else"
Why is "C++ is bad" becoming a theme on this subreddit?
You should also find resources for new programmers useful, since you are new to some of the concepts being presented .
What's making you think that this is becoming a theme?
After reading it, you will understand that with great power comes great bad ideas.
&gt;[**Qt 4 dance [4:34]**](http://youtu.be/NbTEVbQLC8s) &gt;&gt;Boy-band style singing and dancing programmers! Viewer comments: "eurotrash", "beyond embarrassing", "best viewed while under the influence of a mind altering substance" and "Let this serve as a lesson to all". Personally I think it's pretty cool. &gt; [*^Eivind ^Throndsen*](https://www.youtube.com/channel/UChWEY130aSc8cT3k4b0MrKg) ^in ^Howto ^&amp; ^Style &gt;*^36,753 ^views ^since ^Aug ^2006* [^bot ^info](http://www.reddit.com/r/youtubefactsbot/wiki/index)
I don't need full STL compatibility. It is desirable for the library to have the same idioms, but compatibility is not required. 
I was looking at uStl (https://msharov.github.io/ustl/) but it seems to have a library too. Need to dig deeper to see what for. 
Just the amount of posts along the lines of; "I'm using C++ for X, am I crazy?" and "C++ is soo bad [for the thing I'm doing]"? Even /r/cpp has a few "Is c++ really as bad as everyone say?".
you still didn't say why you can't use the CRT, just changed the wording to "lower level" and "compiler shenanigans". What, exactly, is your problem? If by "lower level" you mean "need to do syscalls myself", that is not exclusive to using a CRT. If your problem is a dependency to CRT \*.so-s, why can't you link statically? Strange requirements are more often a sign of mistakes than of particularity.
Nice, still waiting for inline ASM support for x64 though as my ICC license expired.
I thought my C++ was half-way decent but I didn't understand a fucking word of that.
Don't intrinsics cover all interesting instructions? Plus, the optimizer does the register allocation and spilling for you.
You know you can statically link libstdc++ thus not need to depend on any thing else besides glibc
You might *also* want to read, or at least skim, effective c++. Effective modern c++ only covers c++11/14 features (as far as I can tell from reading the contents page) but effective c++ covers things that I wouldn't consider part of "c with classes" but aren't new in c++11/14 (e.g. like RAII, ADL, and exception safety)
I deny the competence of anyone who thinks that manual resource-management is superior to RAII.
&gt;standard library pointers There's no such thing. It's called smart pointer.
Ok this is like, "If I boil water and put my hand into the water I'll burn my hand". C++ is not easy, if you want something easy, use any of the "new languages" everybody claims to be better, hey remember, but slower. If you want a simple and fast language use C, but remember you will not have the same tools to abstract concepts. I have been repeating this for 15-16 years, C++ is fucking complex, if you fail don't complain about the language, it is your fault. 
The RUST community is pulling strings. 
Memory leak is unbounded memory consumption. Allocating memory, using it during the runtime, and not to freeing it before program exit is not.
You sir are awesome for reminding me about it. Thanks a ton. :)
What's the purpose of that?
Yeah, I'm just a beginner with Qt but here are a few things to keep in mind. - If you want Qt to handle the deletion of a heap allocated object, give the main window / whatever is your main Qt object as a parent to the Q_OBJECTs you create. If you want to use the delete operator to delete them manually, don't give a parent. - Always make sure that methods that return something else than void aren't used so that the return value is not captured.
so, is there a way to use this with CMake already ? 
I... uh... I think I need to lie down for a while. 
It's just a link I was making, so much the better if it's not true.
No, but you are free to reflect only the stuff you really need. Especially adding metadata to your reflection items, which is a common case (certain properties should not be available in UI or should not be serialized), has to do manually anyway. 
I had a similar problem a few years back working on firmware code for IBM's Power servers. We ended up writing our own implementation of some of the STL. The code for it is here: https://github.com/open-power/hostboot/tree/master-p8/src/include . It supports vector, list, map and some of the algorithm utilities. I wrote this all around 2012 and the cross-compiler we had for Power at the time didn't support C++11, so needless to say this doesn't either. I've recently updated some of it for the C++11 but it isn't on github yet. Let me know if you are interested in that. 
How do you get a DLL to write on the program before the program gets to run?
and what is MPX: - https://software.intel.com/en-us/articles/intel-memory-protection-extensions-enabling-guide
The papers and thesis are linked from the README.md: https://github.com/VcDevel/Vc#publications The vector objects store vector builtins or Intel intrinsics (e.g. __m256). Scalar access is implemented via [[gnu::may_alias]] attributes rather than unions. This is certainly meant as a complete replacement for programming with SSE/AVX intrinsics. Benchmarks show that code developed with Vc is as efficient as when written directly with intrinsics. That's because the Vc classes act as thin wrappers that the compiler completely optimizes away.
I have a library that is made to do exactly that: http://baptiste-wicht.com/posts/2015/06/continuous-performance-management-with-cpm-for-cpp.html You have to write benchmark functions (like test case) and the generated executable will generate benchmark data that can then be accumulated to create a website (done by the tool). I then use Jenkins to run the benchmark and generate the website on every push of my program. 
Oh yes, I didn't read well, they say it almost working, but not working. &gt; Did you miss a word here? Yes: You can greatly reduce compile-time by using static_if (emulated by templates) in C++ in some cases.
It should not be that long if you use the -j option. On my laptop with 8 threads, it is about 25-30 minutes.
This. I'd just add library suppression to Valgrind's memcheck and clang's LeakSanitizer, if the warning messages pollute the log files so much it's impossible to pinpoint the actual memory leaks.
Unless you're doing something on an embedded or otherwise weird system, you're misunderstanding the nature of the links required for the STL. It's *absolutely* possible to link statically and have a fully self-contained binary. 
Yeah... We've got all the problems, and none of the benefits. My coworker and I rant about it too reach other a lot when adding stuff like for_each and container versions that never default construct 
No. https://crazycpp.wordpress.com/wtf/
Especially since RAII can help you do more advanced forms of resource management correctly.... Where I work we have some pretty IoC-style allocation schemes where all you can do as a developer in your context (at times) is inc or dec ref counts. Even this is handled much better via constructors and destructors than manually ESPECIALLY with exceptions involved.
See my answer to Gotebe - I can't use any libraries at all. I must produce a fully self-contained .so file from my code. 
&gt; Second, how do we handle the state of the RNG in our code? If we do it like this, then we (or at least it seems to me that we do) have to pass through mt to every function in which we want to generate random numbers. That's extremely inconvenient. The other alternative is to make it globally available, but then we have to explain to the students why this is okay to do for mt but not for most other things, etc. If random number generation is a cross-cutting concern, making it global (like a static class in C#) in such a way that your tests can easily replace it with a stub is one way to go. Others will argue that you should still pass it to everything that requires random number generation. This concern is akin to getting the current time - you often want to be able to set the time returned, but do you really want to pass this service into the many functions that require it? One possibility that I advise against is the Service Locator (anti)pattern (depends on whom you ask), where you have one thing that knows how to create or fetch all of the services and you pass that thing around. When a function needs a service, it would call `thing.get_xy_service()`. There are tons of resources available if you want to see both sides of the argument around this. Unfortunately, I don't have an answer for how to explain any of this to students without diving into the rabbit hole. On the same topic, there's a proposal for a more `rand`-like interface wrapped around `&lt;random&gt;`. You could also wrap it yourself and come back to the implementation when the students are ready for it.
See [here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3701.pdf), especially section 2.2.1.
&gt; This particular macro is used to register the reflection information before main is called. Did you think about guarding against the infamous "Initialization Order Fiasco"? (one might wish to use reflection information in the constructor of `static` variables)
I take it you mean that you want to instrument the compiled shared objects (what else?). If so, you can build your own version, just rename it so that I'd doesn't interfere, or you can link statically. Similar to other dependencies you might have. No? About not trusting people: yeah, I do that and it serves me +- well. Sorry about that (I guess).
This looks like a solid way to produce abysmal quality code and waste lots of development time on writing boilerplate code...
I'm producing a special version of compiler that generates additional instrumentation. System libraries would also be compiled by this compiler. I can't have a non-instrumented copy of libstc++. Everything but this runtime support has to be instrumented (security). 
I agree. Using mt19937 as static variable and seeding it with 32 bits is still much better than using rand(). Considering how bad the most rand() implementations are (RAND_MAX &gt;= 32767, distribution not even close to even, etc), it should really never be used if it can be avoided.
But they're part of the standard library, correct? I was thinking about `std::unique_ptr`, `std::auto_ptr`, etc.
They would be helpful if I found the right one. A lot of the ones that I have found are going over things such as loops and compilation though.
Damn. That has to be one of the longest wikipedia articles I've seen. I'll check it out!
That is true and C++11 was out 3 years ago, but I started learning C++ with http://www.cplusplus.com/doc/tutorial/, which seems to pretty much entirely miss the standard library. I didn't even know about most of the standard library until I started working with Unreal Engine a while back.
Pretty much. I think it's largely due to starting out with C++ [here](http://www.cplusplus.com/doc/tutorial/) and avoiding newer versions due to hearing about lack of MSVC support.
Any danger in that it's from 2001, so the latest C++ would be 98?
Wait, effective what?
Exactly this. It is easy to use correctly, does the right thing by default, and serves as a springboard for complex uses. I sincerely hope that something like this gets standardized.
When you register your reflection information in your particular ctor, you can use it directly afterwards. Also when it is a global static variable. This is what the macro `RTTR_REGISTRATION` in fact does. However, you can of course not assume that other reflection information is already present.
&gt; STL in the code I write (it has linker component). This is wrong. The STL is the `&lt;algorithm&gt;` and containers part of the C++ standard library, and it is header only. That is, it has no linker component. It's only requirement is a C++ run-time. Even then, by disabling exceptions and defining a global operator new it can be easily adapted to work with just a C run-time (in case you don't have a C++ run-time available). Some parts of the standard library like I/O, chrono, concurrency, ... do have a linker component (libc, pthreads, ...), but the standard containers it's not one of them. &gt; Unfortunately libstdc++ and libc++ are not header-only. They both require linking with corresponding library. You can just clone libc++ github repository, put its `include/` subdirectory in your include path, and use those headers without even building libc++ at all and without linking anything into your binary as long as you have a C++ run-time available. Since you say that you can do some system calls I can adventure to guess that you at least have a C run-time available. If you don't have a C++ run-time you might need to implement some parts of it your self, e.g. by providing a self contained global operator new or one that relies on libc and linking then your program against libc. Anyhow all the advanced instrumentation systems that I know of like MSan do need to link against libc anyways, but they typically provide instrumented wrappers around it to their users.
Basic programming is explaining to the computer in his terms what you want it to do. Advanced programming is explaining to the computer how you want to explain things, and then to explain in those terms what you want. RAII is solidly in the advanced programming - first you explain to it how resources maintain their lifetimes and how to open/close your resources, and then you use this in explaining further how to read, say, a json file. You don't repeat the lifetime or closing of resources (nor memory management), you use the building blocks you made before.
I love how rants on how everybody has their own subset of C++ that they like to use and how that's a problem. And then he says he wants to take C and add function overloading, operator overloading, default arguments, namespaces, something that looks a lot like C++14 `constexpr`, and a module system like C++17 will likely have. So ... a subset of C++. If you were to take everybody's subset of C++ and do a union, you'd pretty much have the entirety of C++.
Can this be optimized for stack based polymorphism using references ? I think it can be using addressof and is_pointer kind of things. I haven't thought it through though.
Is cpm Linux-only?
Hmm how do you mean stack based polymorphism?
I didn't flame anyone. I read what you wrote. Guess what, people DISAGREE WITH YOU.
Without new and delete at all ? poly_vector&lt;Base&gt; vec; vec.push_back(Derived());
DllMain() gets called before main()
What's your opinion on [this blog posting](http://www.pcg-random.org/posts/ease-of-use-without-loss-of-power.html) discussing a simplification of the `randint` proposal? 
Not sure what type poly_vector is so I can't answer to your code snippet. But sure, polymorphism without new/delete using pointers is possible, but you have to store them elsewhere then. 
Baby's First RNG isn't really a stepping stone towards greater power, just like a toy truck isn't really a stepping stone towards a commercial driver's license. There's value in giving beginners something simple (and non-toxic). The nice thing about libraries is that unlike core features, it is fairly simple to deprecate and remove machinery as better stuff becomes available.
That sounds tailor-made for jenkins. 
Or someone champions her cause before the committee.
But you can compile libstdc++ with your instrumenting compiler, can't you?
Previous thread: https://www.reddit.com/41l584/
The size of std::function serves a purpose though... to allow at least a member function and an object pointer to be stored without requiring heap allocation. The GNU implementation of std::function doesn't even use virtual functions.
Flattered, thanks. I'm not Sean, though, and I'm certainly no Alex. Alex's retirement leaves a big hole.
Because instrumented STL will call instrumentation runtime, which will call STL, ... which instantly gives a recursive headache.
In my case it stops at syscall level (Linux) and this part is already taken care of - the code doesn't depend on libc. However I think it is stupid to roll my own vector &amp; string classes on my own in 2016.
Yes, this is what I do. But the runtime support for instrumentation shouldn't call the code that will call back.
It wouldn't be the first sample program with bugs. Even Apple has sent examples to developers that have had issues. In any event what I was trying to point out, that many apparently missed, is that there could be many reasons for these errors trying to blame QT or CLang or whatever before looking into it is silly. If the article actually explored one or more of these errors and found out what caused the error then we would have something useful. Posting a bit if terminal dump that basically says hey look what happened isn't exactly useful. 
Oh okay. There are online services you can run for Jenkins as well as you can easily just download like a turnkey Linux vm but it sounds like I'm not fulfilling your needs anyway. For testing I use boost test to set up my regression tests. I have also heard good things about Google test and cpp unit but I have no experience with them. For my end to end tests I use a python script
TL;DR: if you just need `&lt;algorithm&gt;` and containers you don't need to link against `libc++.so.1.0`. Your program compiles and runs fine without linking against it. &gt; I just did: &gt; &gt; `nm libc++.so.1.0 | awk '{print $3}' | c++filt` &gt; &gt; And it looks like libc++ is far from being header only. Several things stand out: &gt; &gt; * delete/new operators You don't have to link against libc++ to use its `&lt;algorithm&gt;` and the container headers but as I said before you need a C++ runtime library, that is, you need a global operator new (and a C++ ABI available for `throw` and unwinding). In UNIX that will mean that you need, or your C++ runtime library will need, to link against libc for `malloc` since `new` will be implemented by calling `malloc`, and `delete` will be implemented by calling `free`. Still if you don't want to link against `libc` for these you still can define your own global operator `new`/`delete` and then you don't need to depend on `libc` for these. &gt; lots of basic_string methods &gt; streams You need to link against these only if you use `&lt;iostream&gt;` and/or `&lt;string&gt;` or `&lt;sstream&gt;`/... in your program which you probably don't. &gt; errors If you don't use C errors and/or `&lt;stdexcept&gt;` you don't need any of these. Containers throw exceptions from `&lt;stdexcept&gt;` but you don't need to link against these yourself. You can just include `&lt;stdexcept&gt;` into a TU and compile it yourself if you want. &gt; (insertion_)sort parts Actually probably only `stable_sort` since it calls `std::get_temprary_buffer` which calls global operator `new`. If you have a C++ run-time library this is fine, otherwise if you only have a C run-time library it is also fine as long as you don't call it. &gt; some parts of vector. Same as above. Either you have a C++ runtime library that provides `new` or you define your own. Basically it seems to me that you are still missing the point. You don't need to link against `libc++.so.1.0` unless you are using anything that requires linking to it. The algorithms and the containers only need a C++ runtime, which means you can just include them without linking to it. Of course if you compile it into a library then you will need everything, but you don't need to use that in an application that doesn't require most of the components. You can just include them without linking against them. That's kind of the point of header only libraries.
You seem to be missing the point **entirely**, but I personally don't know how to articulate it better than /u/Gotebe already has...
It seems that GCC's (libstdc++'s) implementation [works this way](http://melpon.org/wandbox/permlink/RkodwRW37mLiZ7Lb) at least: #include &lt;experimental/type_traits&gt; template&lt;typename T&gt; struct foo; template&lt;&gt; struct foo&lt;int&gt; : std::true_type {}; using bar = std::experimental::disjunction&lt;foo&lt;int&gt;, foo&lt;double&gt;&gt;; // no error using baz = std::experimental::conjunction&lt;foo&lt;int&gt;, foo&lt;double&gt;&gt;; // no error int main() { static_assert(bar{}); // no error static_assert(baz{}); // invalid use of incomplete type }
Ah, thanks for the reminder – I meant to go give that a proper read once it was fixed, and completely forgot. :-]
I thought your complaint was about the functionality of Concepts, not the speed. That paper only briefly touches on compilation time, just enough to say that it shouldn't slow compilation. I think there's a video that discusses speed, but I don't remember which one.
No worries. It's not like I haven't done that a million times. 
Wow, rapid releases from Microsoft! Nice! What about https://llvm.org/bugs/show_bug.cgi?id=25384 Clang/C2 choked on `#include &lt;boost/shared_ptr.hpp&gt;` and header hacks were needed...
Sorry, by "Baby's First RNG" I was referring to randint only (in retrospect, what I wrote was unclear). Years of chronic exposure to Standard radiation have burned away my ability to reason about libraries without documentation and class definitions, so I have no opinion about random_generator, what it is, or how it behaves. (I see that there's an example implementation linked at the bottom, but I prefer to avoid looking at other library code for hopefully obvious reasons.)
[rand() Considered Harmful](https://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful) at GoingNative 2013.
Base* can be used polymorphically regardless of the storage duration of the underlying object. I'm not sure what your code is trying to do there - what behavior are you seeking that isn't in the blog post? In your example, if Derived inherits from Base then you're probably slicing the Derived rvalue (assuming you don't have any special overloads in Base, and assuming poly_vector behaves like std::vector). You mention references, but one can't really store a reference to the prvalue you are passing to vec.push_back - you need to move-construct or copy-construct with that, otherwise the object is going to pop scope immediately, invalidating any reference you keep. Do you wish for poly_vector to make a new object from Derived(), and keep around a Base&amp; pointing to it, instead of a unique_ptr? Edit: As far as I know that is not possible under the semantics provided by OP's blog post. At some point you will either have to slice or leave a reference dangling. 2nd Edit: smart pointers - the references we need, not the references we deserve.
Only for Windows 10. :(
If you do not do what I propose in the last paragraph, then the instrumentation runtime will call the non-instrumented CRT it has been built with and the "recursion" stops there. If you link your instrumentation statically into the CRT, end of story. If you *do* what I propose in the last paragraph, you *still* eventually end up with a non-instrumented runtime (but yes, you need to make sure that you don't create a cycle, simply by e.g. using different so names). Honestly, I think that something confused you horribly, but I do not see what that is.
I believe this is what he was referring to https://www.reddit.com/r/cpp/comments/4205ot/using_templates_and_lambdas_to_make_a_safe/cz6vsov
hi! thanks. I don't see that we've pulled that fix in yet. I'll point this out to the team. connect bugs or mailing clangc2 helps if you see particularly impactful bugs. steve, vc dev mgr.
Yes. Though I am not sure how commonly its used or used at all (maybe embedded , gaming ? ) 
No (not without storing the objects outside the polymorphic wrapper). This is because most(*) derived classes are larger than their base class, so the polymorphic wrappers would not have the same dimension, if instantiated over different specializations.
Sigh. Tamper protection and obfuscation isn't good for our industry. It's good for Hollywood, but it's bad for security (think malware and pen testing), bad for interoperability, and bad for tinkering with games.
He is talking about the storage of polymorphic types where each derived type gets stored in its own bucket in contiguous memory to avoid the pointer indirection like [this](https://github.com/ztdwu/polycontainer), which I guess sort of related to OPs topic but not really. I think continuous is really what he meant when he said stack based.
"6th generation Intel Core Processor based system" is much harder to pass limitation for most of the people I think :)
I immediately noticed the C# inspiration - the interface is incredibly similar.
The claim was that compiler throughput would improve because of concepts; my counterclaim was that concepts are sugar for static asserts you can write today, so magical throughput improvements didn't make much sense.
Like it or not, Windows 10 will be the only Windows in a very short time, Microsoft has made this one clear. It's time to upgrade (and once you turn the right privacy knobs, there are really no issues, the Windows 7+ compatibility level is stellar.) That said, I mostly ignore VS now that CLion works so well.
I think we can do, use references (read reference_wrapper) or even plain pointers. Using some little bit clever type traits we can just use the address of the object. For heap allocated objects, it would be double pointer and for stack allocated a single dereference. Let me try working on its mechanics, it might not even work in the end :P
Which is a waste if you don't need that.
This is nice to have until C++17 hopefully gets us std reflection capabilities.
Ah yeah, seems to be a relatively similar approach.
I'm not sure what you're asking for. CMake is a build system. The Clang tools are sitting right there in the install. If you want to call those tools from CMake, go ahead. You don't have to be inside of VS to run the compiler. 
What are the status of the following for C++17 / C++2x: * Language support for sum types and pattern matching * Language support for pure functions * Compile time noexcept checking * Arbitrary precision integers I remember seeing proposals / discussions for these, I can google up the papers if anyone is interested, but I haven't heard much about them recently, leading me to believe that they have been abandoned.
Hi. Is there a vacancy for same/similar position in your Noida office? 
Modules? Any new in modules. I'm really excited for it.
&gt; Also Macros are a problem, so you need to have an additional macro header with your module in GDRs Version. Thats a feature, not a bug. Exporting macro's by default is horrible.
All I want from C++17 is asio in std lib. I'm not asking for much, but I'm asking for that. Please pretty please, make it actually happen.
That's not true at all. They are helpful in a bunch of other ways, will improve diagnostics, etc. New language features being expressible in terms of other language features doesn't mean that the new feature shouldn't exist -- look at the range-based for loop, for example. I just don't expect throughput improvements from concepts, and no throughput improvements are claimed in the paper.
If I'm understanding GDR's proposal correctly, it looks like #include&lt;foo.h&gt; still does the same thing, it's just that you typically don't want #include you want import. Basically clang's module version "overloads" #include to make it be identical to import when given a module file, GDR's module has #include do the same behavior it always has...it's just that's no longer the behavior you want when compiling with modules. Am I understanding that correctly?
Basically, any current Intel CPU is a spyware that you can't disable: https://libreboot.org/faq/#intel
Yes, and the internships are flexible on timeframes.
Yay for variable templates! A major feature added in a minor update, that's awesome. Kudos to the compiler team and STL.
[removed]
I'd like to remind you all that **what you’re doing here is against [the reddiquette](https://www.reddit.com/wiki/reddiquette).** * Do not downvote content because of your personal dislikes or opinions * Especially do not downvote someone who thought the content was relevant to this subreddit and posted it in a nice manner. Why are you punishing this person? I trust that you are all a lot more intelligent than that. Please adjust your behavior accordingly. Thank you for your cooperation.
&gt; There are also some things, which cannot be done with Qt. IIRC you cannot invoke a method which takes a reference and have the argument adjusted. That's because the signal-slot system represents a 1:n binding. There's no simple way of making it work for references, especially when slots might live in other threads, etc. It'd be a big mess that people would be sorely confused about. You can trivially pass pointers around, if you're willing to live with the consequences. I'd consider it a minor inconvenience: actually making your code work like that is much harder than merely getting the notation right.
What are they used for? I understand [the example on cppreference](http://en.cppreference.com/w/cpp/language/variable_template) but I'm struggling to think of something I'd use them for.
Probably but I'm not familiar with their plans. If you want to forward me your resume I can forward it to the managers there.
Msvc implements all the features of latest c++spec? This is not Microsoft I know. What kind of sorcery is this?!
A handy thing they can do is allow something like `std::is_enum_v&lt;T&gt;` instead of `std::is_enum&lt;T&gt;::value`.
They did it before back in 2006, they just fell behind since then.
Based on Eclipse. Meh. There is a reason why [ihateeclipse.com/](http://www.ihateeclipse.com/) exists. Tools for C++ developers should be written in C++, so that the developers of those tools can benefit of their own work (dogfooding). Qt Creator 1.0 was launched on [March 3rd, 2009](https://blog.qt.io/blog/2009/03/03/qt-creator-10-is-out/). There is no excuse in 2016 not to use Qt Creator. It's all open source. 
Thanks! Rolling my own string_view is simple enough; I mainly just want the hash function.
Wow, really? Stupid question, maybe, but is it C++**14** feature-complete? (Seeing as VC++ 2013 wasn't even C++11 FC, I'm thinking perhaps this question is not so stupid.)
Yeah, true. I've used xcode, obviously mac only, clion (expired). Eclipse is more cumbersome to set up. But once that is done I find that it strikes a fine balance between helping me and not being too helpful and not being too slow trying to be helpful. I downloaded qt creator but I haven't found a way to show output in the editor. It opens a terminal windows which I have to exit. Searched but did not find a solution. I use sublime text 3 for small snippets. Very powerfull editor.
Yes (really) and yes. The STL in 2015 RTM/Update 1 was C++11 feature-complete, see my [RTM features post](http://blogs.msdn.com/b/vcblog/archive/2015/06/19/c-11-14-17-features-in-vs-2015-rtm.aspx). We were missing C++14's result_of/function Expression SFINAE. Now that I've implemented that, and Billy/Steve/I have implemented the other features, Update 2's STL is cumulatively C++11/14/17-so-far feature-complete, with the small caveats as noted in this post. The STL in VS 2013 was actually pretty close to being C++11 feature-complete, but we were missing nested_exception which I implemented in 2015. (The compiler is not yet C++11 feature-complete, just to be clear.)
My post is talking about the STL's status, as I'm an STL maintainer. (It's right there in my name!) After some Standardization archaeology, I'm *pretty sure* that VS 2005 had all of the STL features in the C++ Working Paper as of 2006, before TR1 was voted into C++0x that year (we didn't get TR1 until 2008 SP1, at which time atomics/threads had been voted in, which we didn't get until 2012, at which time nested_exception had been voted in, which we didn't get until 2015, at which time we were missing result_of SFINAE, which we didn't get until Update 2 just now). The C1XX compiler front-end has always lacked two-phase name lookup (it's on their list of stuff to do), dynamic exception specifications (deprecated in C++11, and absolutely nobody likes them), and export (we were vindicated by its removal in C++11).
I must correct. While data structures are important when I talk about organizing data we're actually touching on data oriented designs rather than data structures. For example, you can achieve an order of magnitude performance by simply writing a function that takes three different arrays of floats rather than an array of structs of X, Y, Z (3D coordinate). You'd think that this doesn't matter but it does and it's how modern console development has evolved. It enabled people to write high performance code on the PS3 back in the day. I will simply link this guys blog https://deplinenoise.wordpress.com/ He's a very smart and accomplished engineer. I had the opportunity to learn a little bit from him when I did my thesis at DICE. He's now working at Insomniac games. They seem to run a really tight ship. He did a presentation at last years GDC about how you can arrange your data to get the most out of your functions. It's a very large slide deck +200 slides but I want to convey the idea that game development is a very different domain than your run in the mill software workshop. https://deplinenoise.files.wordpress.com/2015/03/gdc2015_afredriksson_simd.pdf I think it's a good idea to skim through this because it gives you an idea what an experienced game developer might do. You then have to take the long way around to get there but it gives you an idea. I call this orientation and it's very important to do.
To some extent yes, you will have to learn the language but you don't need to know everything about it. You can get away with simply knowing a little. Besides, you'll find that most programming languages are very similar and even if they are different they always build on the same fundamental computer science principles. The reason I say that go for the game is that the goal is not to learn a programming language the goal is to learn how to be a game developer. You will learn, I suspect, more than one programming language in the process but it's a by product of making the game. You'll also have to learn a graphics library unless your planning on reinvigorating the MUD genre. Jokes aside, start small. Like really small. Watch this presentation by Chet from Valve (makers of Half-Life/Portal/Dota 2) https://youtu.be/tdwzvdZFxVM?t=3m27s Notice how he makes a point about only hiring people who have made a game themselves. And notice how he says, just start. There's no way around it. Just do it. What ever you need to learn you will learn on the way. Also, read my other answer to lambdaburrito's reply. About organizing data. 
Only the STL features that have so far been accepted into the C++17 standard. It's far from being C++17 complete (the standard itself isn't even complete).
Heyyy congrats!! Well done, /u/STL :)
Thanks for the explanation, why it is implemented the way it is. But for a reflection library only you don't have to honor this circumstances. Personally, I would find it rather strange when it would be not possible. 
With our current development build (running locally), I observe that f()'s definition is accepted, which is almost certainly because C1XX still doesn't really try to parse template definitions (it's a little more than brace-matching, but not much). Any attempt to instantiate f() emits a compiler error as expected. Fold-expressions are on the list of C++17 things to implement, but they are definitely lower priority than finishing C++11/14 (as much as I'd love to have fold-expressions in the STL). Not sure why the webcompiler is timing out.
Thanks! We all worked hard on this (me, Billy, and Steve in the libraries, plus the compiler devs who implemented/fixed stuff for us).
Well, I will admit that my project is not so big (40kloc), but we include (and so index) several enormous libraries (including Boost). I don't have any real trouble. It used to be awful, though. Which was the last version of CLion you tried?
https://imgur.com/JNGLjE8
I'm using 1.2.2. Our project uses quite a bit of macro metaprogramming and it confuses the hell out of it. Most of the files in the project are marked as containing errors, despite them actually compiling just fine. It also can't keep track of usages anymore and the possibility of generating function bodies from headers is just gone. Sometimes it gives up completely and stops linting source code (or just crashes, which has only happened once before). It's already gotten better and it's very nice for moderately-sized projects, though.
Well I think this means I will soon stop using Mingw on windows altogether. I think aside C++14 constexpr MSVC now does everything I need for my code and I can work around the last problem at least for a while.
&gt; Most of the files in the project are marked as containing errors, despite them actually compiling just fine. This is why I switched *to* CLion. Our codebase is only 1 year old, and was written in C++11 from the beginning. I tried literally every cross-platform IDE on the market, and CLion was the only one that didn't put red squiggles under practically everything I was doing. I ditched QtCreator, despite our project originally using QML, because it spent so much processor time telling me that my code was obviously wrong that it wasn't responsive anymore. That said, CLion actually gotten worse about that, IMO. Sometime between 1.0 and 1.2.2, it's started to think all of my literal arguments to perfectly-forwarded function parameters need to be rvalues.
A reflection library isn't a signal-slot system, right? A signal slot system requires an event loop for cross-thread delivery, a way of marshaling the arguments (a reflection library helps here), and so on.
Yea, I used Eclipse for a while, because we were using Eclipse (Java) at school as well, so I just tried out the C++ version of it. Going to Qt, I remember, I felt there were several things missing that I had gotten used to. Haven't done much C++ing for a while, but I'm giving Clion a go.
What did we need &lt;functional&gt; for here?
Cool! C++14's extended constexpr sure is nice, but we've been able to constexprize 99.9% of the STL (through C++17-so-far) with only C++11 classic constexpr support from the compiler. There are a few headaches (nasty ternary operators), but almost no hard limitations, aside from the looping minmax algorithms. (Of course, your codebase will vary in what it wants to do with constexpr.)
initializer_list doesn't care about variadic templates at all (it's a simple class that the compiler fills with magic). I hoped that fold-expressions would be useful for std::conjunction, although I suspect they are inapplicable due to how std::conjunction was specified (it's got special short-circuiting and inheritance rules). Looks like I can't implement aligned_union's compile-time maximum with them either. Sigh. So I guess I don't need them. But I still want them! :-&gt;
Saying there's no reason not to use Qt Creator is preposterous. Off the bat, eclipse indexes my project better, with more consistent go to definition. It's also more feature rich last I checked with call graphs for instance. It also has better vim emulation. And it also works on multiple languages. C++ and python are a common mix and pydev isn't as good as pycharm, but it's ok. Eclipse is what I'll be using until clion surpasses eclipse cdt, if ever. 
Only use `random_device` as a temporary, make `mt` `thread_local`, and give `dist` automatic storage duration and it's exactly the correct thing to do (except maybe giving `mt` a larger seed).
As you say, Richard's input into the proposed specification isn't just mere "talk.". I've also received valuable technical feedback from Jason Merrill, the principal maintainer of GCC/g++. As of learned lessons, yes, of course the design takes into account several sources of learned lessons including: Clang's, lessons learned from EDG's implementation of "export template" decades ago (the only implementation of that feature, long before we had modules) -- in particular, what to retain, what to exclude, and what to leave for further experimentation. The proposals also acknowkedges the influence of David Vandevorde's early exploration of modules for C++. As you can see, the design benefits from varied C++ compiler and tools implementers' input. Rest assured that a lot is going into the design, far more than is possible to describe in interesting or exciting Internet discussions, or attention grabbing reports :-). It is and remains a community process, like any other C++ proposal. And like most impactful C++ features, its design isn't easy. 
that is bullshit, if you are in the "business segment" with any significance, your machine will be controlled by IT policies, under which the sudden updates will never happen
Actually, `is_enum&lt;T&gt;` is a type and `is_enum&lt;T&gt;()` (or `is_enum&lt;T&gt;{}` if you like that) is an object of that struct type. That object is *implicitly convertible* to `bool`, but is not itself a `bool`, and in certain contexts that matters. You'd need to say `is_enum&lt;T&gt;()()` or `is_enum&lt;T&gt;{}()` to create a struct object and then call its function call operator, to get an actual `bool`. That's kinda weird. Sometimes it's ideal but sometimes not. That's where `is_enum_v&lt;T&gt;` can be nice. It's just a `bool` and you're done.
It is a complicated setup where we reduce a lot of constant information about an embedded device settings into .text memory instead of ram but keep the code fairly simple looking. I wrote a solution in GCC for c++14 and now we want to support it in our various simulators and unit tests on Windows. For now we use mingw for those part but most of our setup is moving or has moved to visual c++ 2015 so we want this last part to follow 
Incidentally, I always write `is_enum&lt;T&gt;{}` because you can't use `is_enum&lt;T&gt;()` as a non-type template argument (e.g., for `enable_if`) - it's parsed as a *type-id* specifying a function type.
CLion is mostly written in Java as well, isn't it?
What's your new algorithm? Do you have any pictures?
What you're doing here is *disagreeing* with the content. The content is relevant to this subreddit and was posted by a user who wanted to hear what people thought here - to create discussion. And he did succeed creating a discussion, and helped people to learn from it. In the context of reddiquette, the content is relevant, interesting enough to spark a discussion, it contributes to the conversation of the subreddit. Whether you personally disagree strongly or agree with the linked content is entirely subjective (opinion-based). For example, there are many people who liked the linked video, and they could be disagreeing with you. If they were here, you would have to hear their opinions and try to understand each other in a civil manner. Thus, *in the context of reddiquette*, you've downvoted content based on your opinion, and you have harmed OP's karma in the process. (Even though what OP wanted was to create discussion and hear people's opinions for the relevant content he posted) Do you consider this fair? Example: If this was a creative writing subreddit, and a user submitted a very poorly written piece (based on the views of the other users in the subreddit), should that content be downvoted because its content is seen as low-quality? No, because it is relevant. The user has contributed. It created discussion. And many people benefited from it by learning from the discussion. This is why it is not fair, and this is why it is against the reddiquette.
Because it's a base header. Incremental builds are basically useless because the whole world depends on it, which means that unity builds can actually improve perf in that scenario.
Setting aside MSVC's choice of `__cplusplus` value which I explained, C++11 and beyond actually require that behavior. N4567 15.4 [except.spec]/17 explains how destructors get implicit exception specifications; in English, destructors are `noexcept` by default, unless there's a `noexcept(false)` destructor in its members or bases. I'm pretty sure that as of 2015 Update 1, this rule has been implemented properly. If you believe otherwise, please provide a self-contained test case and I'll send it to the compiler dev who maintains `noexcept`. Finally, although you probably know this, I should mention it for the record for anyone else: you can't emit exceptions from destructors given to the STL. This has been forbidden in every version of C++ going back to C++98 (in C++17 it's 17.6.4.8 [res.on.functions]/2.4), and our implementation will now reward such treachery with immediate termination. (We actually mark all STL destructors as `noexcept` explicitly.)
Reddiquette asks us to "Moderate based on quality, not opinion." I'm sorry, but I'm not a mind reader and can't know all the reason something was submitted, nor do I think I should base my vote off of those reasons when they are stated. I can however vote based on the quality of a submission. This was a low quality submission as I've already argued. Yes, it did generate a lot of good discussion, but that isn't an excuse for low quality or off topic or any other submissions that aren't appropriate for this subreddit. Addendum: Reddiquette also tells me "If you think it does not contribute to the subreddit it is posted in or is off-topic in a particular community, downvote it." I do not think low-quality rants belong in this community, but if you know of any high quality, fact based rants, submit them and I'll upvote.
Are there plans to support SD-6?
Not at this time, and I have concerns about how useful the library part is as currently specified.
The article states it clearly - "Note that the features described here are not being proposed for C++17, but for the following standard revision."
The library concern I have is that there is no way to query library support without dragging in massive headers. This is a real concern for things like Boost.Config. And yes, I mentioned this to Clark Nelson.
&gt; CLion was the only one that didn't put red squiggles under practically everything I was doing. I have the exact opposite experience :( I have almost no problem in my codebase with QtCreator but CLion can't parse a function for the sake of it
This is common way to implement 3d vector struct: struct Vector3 { union { struct { float x, y, z; }; float f[3]; }; float&amp; operator [](int index) { return (&amp;x)[index]; } //float&amp; operator [](int index) { return f[index]; } //or this way };
From the standard (5.7 p. 4): "If both the pointer operand and the result point to elements of the same array object, or one past the last element of the array object, the evaluation shall not produce an overflow; otherwise, the behavior is undefined." It means that you only can use pointer arithmetic within arrays. Everything else results in non-"safely-derived pointer" and implementation allowed to do UB " even if the unsafely-derived pointer value might compare equal to some safely-derived pointer value" (3.7.4.3 p.4). For example, recently-featured MPX-based bounds checker for msvc will most likely warn on your code, and it's still compliant c++ compiler.
As I said, your subjective perception of quality of content is based solely on your own opinion. To someone else, this could be high-quality content. You're disagreeing with the content itself, which results in your judgment that this content is of low-quality, but this is only your own opinion. Your judgment is relative and subjective, and it is not and cannot be fact based. I also understand that you may think a talk or a "rant" could be better formatted, presented, etc. But this is still related to the content itself. And the judgment of it is still relative and subjective. Important note: Quality of the content is completely different than quality of the *submission* - which is based on its relevancy and conversation contribution factor, among other criteria. And relevancy, conversation contribution factor, etc. are not opinion-based, they are factual and can be measured (albeit measurement is not binary). You definitely don't have to be a mind reader. Fact: The link is a video related to C++, and this is a subreddit for C++. The link is not off-topic. And as you also stated, it generated a lot of good discussion. It helped people see different sides of the ideas presented. This means quality of the submission is not low. Hence, downvoting it is invalid. Thank you for reading and considering this.
I thought so too, however it's legal to copy such a struct with memcpy, which certainly does pointer arithmetic and treats the whole struct as an array of char. I believe the following is legal: struct Foo {float a, b;} f; *static_cast&lt;float*&gt;(static_cast&lt;void*&gt;(static_cast&lt;char*&gt;(static_cast&lt;void*&gt;(&amp;f)) + offsetof(Foo, b))) = 1.0f; Though doesn't fit the definition of safely derived pointer. But if that doesn't then a simple implementation of memcpy isn't defined either. edit: also, it sounds like it would be legal for a 2-Vector since it's not UB according to that to be pointing to one past the end (and the same paragraph specifies that a scalar shall be treated as a 1 element array). 
"safely-derived" is irrelevant. That only matters on implementations with strict pointer safety (i.e., GC'd).
&gt; It's UB, but not for that reason. Do you happen to know off hand which clause? I think it depends if float[3] can be considered as the same common initial sequence as float a,b,c; I'm not 100% sure the wording says it isn't. 
[class.mem p.16]: "The common initial sequence of two standard-layout struct (Clause [class]) types is the longest sequence of non-static data members and bit-fields in declaration order, starting with the first such entity in each of the structs, such that corresponding entities have layout-compatible types". First entity in each of structs are different - float and float[3]. This means that they have empty common initial sequence.
Yes but memcpy() makes no assumptions about internal layout.
I really don't think this is a good idea, even if the standard is silent on this issue. I'm pretty sure structures can be padded even if the types that make them up are not.
you are a hero. do you know where the device firmware would be located in the exe?
9.5 Unions [class.union] 1 In a union, at most one of the non-static data members can be active at any time, that is, the value of at most one of the non-static data members can be stored in a union at any time. **[ Note: One special guarantee is made in order to simplify the use of unions: If a standard-layout union contains several standard-layout structs that share a common initial sequence (9.2), and if an object of this standard-layout union type contains one of the standard-layout structs, it is permitted to inspect the common initial sequence of any of standard-layout struct members; see 9.2. —end note ]** The size of a union is sufficient to contain the largest of its non-static data members. Each non-static data member is allocated as if it were the sole member of a struct. All non-static data members of a union object have the same address.
I've cited definition of common initial sequence in other reply - https://www.reddit.com/r/cpp/comments/42cbd2/i_think_pointer_arithmetic_on_struct_members_is/cz9a8g3 . It seems that float[3] and float x,y,z are not the same thing (I maybe wrong, it's hard to understand standardese). The fact that all compilers do it this way have proves nothing - if it's UB they can do whatever they want, including working this way.
The lz4 library isn't a stream, but it is only about 3 files.
IMHO if this is UB then any usage of union should be UB. SIMD enabled vector libraries use this pattern. Without it it would be not possible to implement them. https://github.com/google/mathfu/blob/master/include/mathfu/vector_4.h Look at **Simd4fUnion**.
3.9 p2: "For any object (other than a base-class subobject) of trivially copyable type T, whether or not the object holds a valid value of type T, the underlying bytes (1.7) making up the object can be copied into an array of char or unsigned char. If the content of the array of char or unsigned char is copied back into the object, the object shall subsequently hold its original value". This is the special case for copying into (unsigned )char *. And 3.9 p3 states: "For any trivially copyable type T, if two pointers to T point to distinct T objects obj1 and obj2, where neither obj1 nor obj2 is a base-class subobject, if the underlying bytes (1.7) making up obj1 are copied into obj2, obj2 shall subsequently hold the same value as obj1." It has nothing to do with pointer arithmetic.
Yes, this is legal, though you don't need to cast to void * (char * is enough to prevent strict aliasing problems). The problem that this is not the same as &amp;f.a + 1 even if pointers are the same. Optimizers may abuse this UB to produce some strange behaviour. You may think about it like strict aliasing - code like `float x = 1; float y = 2; *(int *)&amp;x = *(int *)&amp;y;` may not result in x being 2 even if you check that sizeof (int) == sizeof (float).
Doesn't matter, if your compiler doesn't do the right thing here you should immediately delete it from disk.
Thank you for the subreddit link, and all of the other help.
&gt; It has nothing to do with pointer arithmetic. My point was you need to do pointer arithmetic to copy the bytes.
structs can't just be arbitrarily padded, AFAIK. Each member has its own size and alignment requirements, so padding will occur only in a specific way (of course, padding can be prevented using a compiler directive).
The packing of union members is implementation defined, so every action _based_ on some assumption is undefined behaviour, because you can't be sure.
Provided that all the alignment requirements are met, and except that a standard-layout struct cannot have padding at the beginning, the compiler is allowed to add arbitrary padding however it likes.
You should look into the Windows version of LLVM. It has good VS integration and has a `cl` frontend so it works with existing project files.
I'd be very surprised if 2 or 3 are actually practical. You basically need to traverse the entire call graph to verify them. I also think that making the case for 1 will be really hard, std::variant is looking very good. No doubt language support would make it better, but it would also introduce more complexity.
Only really matters if there's a pointer or reference. If there isn't then it's safe. That should be safe. 
My understanding is that they know two phase name lookup is a priority, but it depends on rewriting fairly core parts of the compiler, and depends on the C1XXAST work described here: http://blogs.msdn.com/b/vcblog/archive/2015/09/25/rejuvenating-the-microsoft-c-c-compiler.aspx . But I'm not a compiler dev so take that with mountains and mountains of salt :)
&gt; The subset mentality hurts C++ programmers equally as much as the Modern C++ mentality hurts it, as far as I'm concerned. I don't think there is much difference between the two. **Banning features** because you think they are problematic effectively subsets the language being used. &amp;nbsp; &gt; **I don't think I said it was about banning anything**, if you actually read what I stated. Are you for real?
Sorry
They can, but only if you build *everything*, **all** the time, which is just... **Nooooo...** I cannot believe that people, you included, speak of "that scenario" so much. It isn't the common case, cater for the common case! I build tens of times during the day, to test a small part I just modified (and make no mistakes, when working on hundreds of MB codebase, a small part is all you ever work at at any given moment).
Google: "difference between a pointer and a reference c++" Top result: http://stackoverflow.com/questions/57483/what-are-the-differences-between-a-pointer-variable-and-a-reference-variable-in
I think you meant `int&amp; r = *p;`.
Thank you.
ian, could you please comment (or PM) on salary range ? thanks.
&gt; This first patch just seeds the RNG via srand by passing it the current time plus some additional random bits from the current pool. Argh.
I think you could avoid traversing the entire call graph to verify 2; you could just say: "any function called by a pure function needs to be qualified as pure". The problem would only arise if you tried to deduce purity, but that wouldn't be very much in C++ spirit anyway.
Is this not just a PATH issue?
I'm not sure if 1 would be a good idea. It sounds nice from the perspective of a newcomer to the language, just being able to use algebraic data types as native language constructs, but I don't think it's very much in C++'s spirit. The biggest problem is the fact that the representation of sum types in memory is non-trivial. Do you use an int to remember the currently held variant? 8 bit? 32 bit? How about using a custom optimized encoding for special circumstances (like -1 to mean 'Nothing')? How about if I have 255 variants and the compiler decides to encode the variant with an 8 bit integer, but I want to be ABI backward compatible for future cases that I might have more variants (I know this example sounds unrealistic :) ). IMHO, std::variant is a satisfactory solution and I can live with a nice library for pattern matching; one that accepts a set of lambdas. Solving a problem with libraries might be less convenient, but it keeps the language simpler and more importantly, it's much better for metaprogramming. Sum types are great in Haskell, but that's because the language is not as obsessed with efficiency. 
Ty, fixed.
I, for one, greatly dislike your idea. If you want both "named" and "indexed" access, surely it is trivial to us an array, create "named" accessors and **not** think about the standard!?
Why do you think that? memcpy is in fact likely to use assembly which has no concept of pointers nor their arithmetics.
Declare variables as late as possible! Always! To be precise: declare them as soon as you can initialize them **properly**. This prevents errors regarding uninitialized variables and automatically allows you to use `auto`.
I cannot imagine any reason to declare all variables on top other than total brain calcification forcing you to code as if you're writing C in the 1980s, when compilers required it because of technical limitations.
I think that your second example would be better illustrated with: int sum = number1 + number2; cout &lt;&lt; "Sum: " &lt;&lt; sum &lt;&lt; endl; int difference = number1 - number2; cout &lt;&lt; "Difference: " &lt;&lt; difference &lt;&lt; endl; int multiple = number1 * number2; cout &lt;&lt; "Multiple: " &lt;&lt; multiple &lt;&lt; endl; int quotient = number1 / number2; cout &lt;&lt; "Quotient: " &lt;&lt; quotient &lt;&lt; endl;
I'll take it to a further extreme: declare variables late, and when writing larger blocks of complex code, use nested scopes to end their existence ASAP. E.g.: void func() { // long funciton { int x = 0; double y = 0.0; // use x and y } } Obviously this is overkill in simple cases, but if you have a longer function, I consider this good practice where it's practical. Ideally each variable is only alive exactly as long as its needed.
I also like this, it applies [_minimize the scope_](https://www.securecoding.cert.org/confluence/display/c/DCL19-C.+Minimize+the+scope+of+variables+and+functions) recommendation on both ends (and we wouldn't really be _minimizing_ otherwise). The rationale matters, so quoting: &gt; Variables and functions should be declared in the minimum scope from which all references to the identifier are still possible. &gt; When a larger scope than necessary is used, code becomes less readable, harder to maintain, and more likely to reference unintended variables (see [DCL01-C. Do not reuse variable names in subscopes](https://www.securecoding.cert.org/confluence/display/c/DCL01-C.+Do+not+reuse+variable+names+in+subscopes)). Source: [DCL19-C. Minimize the scope of variables and functions ](https://www.securecoding.cert.org/confluence/display/c/DCL19-C.+Minimize+the+scope+of+variables+and+functions) Edit: Worth adding that minimizing the scope goes well with `const` correctness, which is also a good rule: https://isocpp.org/wiki/faq/const-correctness To give an example -- noncompliant code: // . . . // code with `number1` and `number2` // . . . int sum; // violates scope minimization: declared prematurely (and uninitialized) sum = number1 + number2; // `const`-incorrect: immutable in this snippet but not marked as `const` Fixed: // . . . // code with `number1` and `number2` // . . . const int sum = number1 + number2; // declared on as-needed basis and `const`-correct 
Even better: `const auto`
FASTBuild is great, we've been using it for 6 months.
&gt; No, it's UB. Your reasoning is correct that you can get the right addresses, but the aliasing rule ([basic.lval] §3.10/10) forbids actually accessing that valid address. If I read that correctly, that's about two different types aliasing. In this case, the types are identical---I'm accessing a float through a float*, so I think that rule doesn't come in to play. As far as I understand it, that section deals with whether the types are similar enough to avoid aliasing, not whether the pointer is valid. &gt; Or better, use Eigen. Why is it better to use Eigen? Personally (and I'm obviously not unbiased) I think TooN is a nicer library to use.
Of course.Standard containers track the standard, just like the rest of the standard library - your own custom containers don't unless you keep doing the work to maintain them. 
And then you name the scopes and pull them out :)
These days it's probably less effort to write a backend for gcc or llvm than deal with obsolete tools, unless you have some special reliability requirements that ask for a "field proven" compiler.
I'm not so sure about that one. Being explicit about the type you expect some variable to have at the point of declaration can be a useful safety check, as well as having a self-documenting effect on the code. Using `auto` is great for avoiding writing out three-line template-based monsters when you just wanted an iterator, but using `auto` everywhere you possibly can loses those other benefits. Even in functional programming languages where type deduction has been routinely used for many years, it's usually idiomatic to put some explicit type declarations at strategic points. Otherwise you can run into the sorts of problems that sometimes hit larger programs written in dynamically typed languages, where you thought you had a lot of code working well and passing its tests, but it turns out that almost everything was using completely different types to what you expected, you were never testing what you thought you were testing, and something goes horribly wrong as soon as you encounter a value that doesn't get converted/coerced in the same way.
There's some truth in it if taken as a general principle and not too literally. Obviously removing as much whitespace as possible is a bad idea, but it is certainly better to have: int x = 5; than int x; x = 5; 
I am not convinced. Three new operators sounds like overkill to me. Moreover I wonder about performance. Switch statements are not always O(1) but sometimes are implemented as binary search. With more complex matching statements such a binary search is not possible AFAICT and the worst case performance would thus degrade to O(n).
It's not that simple. The usual tradeoff is between function length (the one you're advising to avoid) and function maximum indentation level. It's obviously better to have both small, but when that doesn't make it keep at least one. A function that never indents more than the initial block, yet hides the declarations above the screen cut because it ended up long, is still totally ok in my book.
When is this preferable to moving code out to a function? With your example, it looks like that block could be replaced with someObject = GetSomething(x, y). This would even make the code more readable, as it self documents why you need x and y.
Hey Bisqwit, I really enjoy your videos! :) In discussions about this video, you say you should give async more time, both in explaining its powers and its pitfalls. Many consider async to be the best approach to many multithreading situations. Are you likely to create more videos on threading, and if so, would you add more focus on async? Or do you have other ideas in the pipeline?
I declare them when I use them, because then I know where they are used.
Don't post screenshots of code. Post code.
I agree. Variables that are declared and aren't used are wasted cycles, though not so much a big deal anymore on PCs. I also group variables semantically; iterators next to maps, floats all related to calculation A, then variables related to calculation B, etc. it's very handy to store a segment of overall memory use of some function in your brain and analyze the code piecewise
This will be great! Good luck with it. Are you in contact with kitware?
&gt; You are taking the sum of two variables. Obviously you want the type to be the same as those two variables. Well, yes, in this specific case the function prototype is explicit that both variables are `int`s, so presumably we do want an `int` as the result. So why not just write that, instead of being unnecessarily vague? But more generally, following the `auto` everywhere style isn't as clear. For example, if you're multiplying two values, you might have inputs of different types, or you might have multiple plausible result types even for the same input types. &gt; You don't need to know its type, unless it's going to be a different type. You always need to know the type of the data you're dealing with, so you know what you can do with it. The only question is how explicit you want to be about specifying that type in your code. &gt; Being explicit in this case just makes the code harder to read. Sorry, but I just don't see how replacing an ambiguous 4-character keyword with a clean, universally understood 3-character keyword makes anything harder to read. There is much Kool-aid drinking going on here.
Yes, they are aware of this.
This is fantastic. It will increase productivity a lot. I hope that YouCompleteMe will support this.
A '?' Character can be any letter or absence of a letter. If I search (and) it finds the word. If I search a?d it finds the word, but if the pattern is longer than the word it doesn't find it. So (?and) or (and?) can't be found and the program aborts. 
Yes, that would be a good way to get the code completion features into vim and other editors easily. For the rest of the features, I think a new vim plugin would be needed. Fun fact: The cmake daemon is inspired by the design document for YouCompleteMe http://thread.gmane.org/gmane.comp.programming.tools.cmake.devel/12658/focus=13004
Format your code correctly and try to come up with an actual question to ask.
I've encountered a lot of those situations too, and grouping those sets of variables into their own classes if they weren't in the new function's scope always cleaned up the code significantly. For single mathematical equations, I can see how nesting something in a set of brackets can be way cleaner than calling a function with a lot of arguments, but with clean OOP code, that's usually a limited use case. At least in my experience.
Matching any one character (or none at all) means that the remainder of the pattern matches either at the current position or at the next position. It's almost certainly easiest to implement this recursively: int compare(string word, string pattern) { if (pattern[0] == '?') return compare(word, pattern.substr(1)) || compare(word.substr(1), pattern.substr(1)); if (word[0] == pattern[0]) return compare(word.substr(1), pattern.substr(1)); return false; } 
One technique that helps here is "Replace Method With Method Object" refactoring: http://refactoring.com/catalog/replaceMethodWithMethodObject.html This works for free functions as well.
Thank you very much
Some y'all are very rude. I'm just trying to learn something not get put down. You knew very well what the issue at hand was. 
Could you describe a situation where this difference is clear?
Hmm... Sounds like a line drawn in water, an artificial distinction made purely for the sake of being able to talk about different kinds of use cases. I will just go ahead and ignore both terms because it frankly sounds asinine to me. Thank you for the link nonetheless.
Your lack of experience is showing through. Using a thread to do I/O asynchronously? You're doing it wrong. Using one thread per client on a network server? You're doing it wrong. Likewise, using `async` to do parallel computation is flat-out doing it wrong. And the reason it's _objectively 'wrong'_ is because it is using the wrong tool for the job in a way that results in **severe** performance deficiencies.
I find that floating definitions as late as possible usually helps to reveal the structure of the code more clearly. For example, I see a lot of code written in this style: int count1 = 100; int count2 = 1000; int count3 = 12000; int frob1 = frob(count1); int frob2 = frob(count2); int frob3 = frob(count3); fargle(frob1); fargle(frob2); fargle(frob3); (Assuming that `frob` has no side-effects and `fargle` does...) if we float the definitions to their latest possible point we get: int count1 = 100; int frob1 = frob(count1); fargle(frob1); int count2 = 1000; int frob2 = frob(count2); fargle(frob2); int count3 = 12000; int frob3 = frob(count3); fargle(frob3); This instantly reveals the structure of the function you should pull out: void frobargle(int count) { int frobbed = frob(count); fargle(frobbed); } Giving: for (auto count : {100, 1000, 12000}) { frobargle(count); } In a real-world "this looks refactorable" function, there would be other junk in between the `count/frob/fargle` sequence, but floating definitions later will also help separate concerns. Of course, this isn't something you should apply in a battering-ram style, you don't want to move initialization of a string inside a hot loop or something like that :)
Is that a DSP used in music synthesis/digital instruments? I might have a clue what you're talking about. Usually if no architecture documentation is available without signing an NDA, it means it's a piece of crap :( It might cost only about $50k for someone in the know to port LLVM to that chip... It'll probably be a way better compiler from the get go.
Okay, that makes alot of sense now actually. Thanks! 
as late as possible and declare them const if at all possible!!
&gt;I'm accessing a float through a float* By that logic the `S&amp;` and `T&amp;` example in scatters' post, `s` and `t` might alias. Because `s.y = 5;` writes an int as an int, so there is no aliasing violation, etc. To resolve this I think you have to consider that `s.y` implies evaluating `s` which would cause UB if `s` didn't designate an actual entire `S`. 
In C++ the intended use of `union` is for constructs such as a tagged variant. The code you linked to causes undefined behaviour in Standard C++. It relies on compiler extensions. The author of the code may or may not be aware of this. &gt;Without it it would be not possible to implement them. This claim is false, C++ is a very flexible language and typically there are several possible ways to implement any idea. 
One example that comes to mind is that `std::string` requires linking to the static variable `std::string::npos`. 
The boost doc you linked to says "only if copy constructor of T not marked with = delete" which seems to be specifying that it should yield `false`.
&gt; I'm accessing a float through a float* That's not the issue. The array subscript expression implies that there's an array object there. If the compiler can see that a `float` object is not part of a `float[N]` array (because it's part of a class instead), it can conclude that it will not be aliased by an array subscript expression with a nonzero index. So, the problem is about accessing a class as an array, not accessing one sort of `float` as another sort of `float`. Actually, pedantically, the address is invalid. You're not allowed to even perform a pointer addition operation which goes past one-past-the-end of an array, where non-arrays are treated as arrays of extent `[1]`. (Read carefully the preconditions of [expr.add] §5.7/4. I think `char*` addition is supposed to be exempt, but that's the sort of thing the UB SG needs ot hammer out.) &gt; I think TooN is a nicer library to use. Sure, my point is just to avoid rolling your own. There are plenty of 3-vector classes out there.
&gt; Because I don't care about the type of variable. I find that the logic of the code is, 95% of the time, more important than the data types. But the type of data you're working with is part of the logic of the code. You're going to figure it out on some level anyway when you read or work with that code. &gt; I'm just giving you my view and my experience with it. I don't understand why you have to be a dick with this "kool-aid" crap. It wasn't a personal comment. It was intended as an observation that a lot of the C++ community (or at least, the vocal part of it that posts on-line) seems to be assuming that because some type deduction is now available via `auto`, it is somehow inherently better. Many statically typed languages have had type deduction for a lot longer than C++, and dynamically typed languages naturally have a similar style where types aren't specified explicitly. Over time, the culture around those languages tends to move away from maximal inference and towards either a degree of explicit specification or some other strategy for avoiding confusion over types in larger systems. We've even seen this within the C++ community, for example with attempts to be more explicit about what is required of the arguments used to instantiate templates instead of relying on the pure duck typing you get by default. &gt; I've obviously coded without `auto` for years, so when I started using it, I clearly noticed that my code was way more easy to follow. I'm happy that you feel that way. I'm just expressing a different view, and some specific reservations about `auto` that motivate that view.
&gt; The array subscript expression implies that there's an array object there. If the compiler can see that a float object is not part of a float[N] array (because it's part of a class instead), it can conclude that it will not be aliased by an array subscript expression with a nonzero index. I don't think it is accessing it as an array type though: the type has decayed to float*, or was never more than a simple pointer anyway. I don't think having nonzero index alters the type in anyway, so I don't think 3.10/10 applies. 5.7/4 is a different matter though. I agree that it appears to forbid it, though I think but am not sure that there may be enough char related loopholes to allow this variant. &gt; Sure, my point is just to avoid rolling your own. There are plenty of 3-vector classes out there. TooN's older than Eigen as far as I know, and it pre-dates the first recorded commit by quite a few years since it wasn't in VCS for quite a while. Also, TooN is very much more than a 3-vector library. This is all about making a 3-vector with named elements fit into the TooN framework. I could write a long post about the positive and negative aspects of TooN, but I'm not sure this is the place for it :) 
You could use something like boost::string_ref to avoid the unneeded memory allocations from substr.
I started pushing the code to github, but it is not all there yet. I'll push the rest by the end of the week. To set expectations though: This isn't ready for general use. The video is mostly showing what is possible so that I can attract collaborators to make it a reality.
(I'm fine with the downvoting, I was aware my statement was controversial before I made it) They're not mutually exclusive. I agree with that. (the "better to have both small" part should hint). What I don't agree with is some kind of a religious rule I often see brandished around by people who read more computing magazines than actual code, whereby functions has to have such-and-such strict properties of length, indentation and whatnot. Common sense trumps rules! (*) Having tools doesn't make their use compulsory! Anyway, to each his own. Thanks for your answer. (*) In sensible places.
&gt; They're not mutually exclusive. I agree with that. (the "better to have both small" part should hint). Ahh ... my bad :) &gt; Common sense trumps rules! (*) I call this "practicality beats purity" (well, OK, Tim Peters may have called it first, but _we ignore that_). Keep in mind though, that rules that make space for common sense, tend to ignore that common sense is not really common (at least, when it comes to being practical vs. pure, among developers ;) ).
**All** will do this particular thing, but... It is trivial to see that y is always 1 regardless of the const specifier. Compilers even "propagate" this across a call stack.
Yup, that’s correct. However, the question is: copy *of what*? A `T(T&amp;)` constructor cannot construct a copy from a `T const`. In particular, `is_copy_constructible&lt;T&gt;::value` is more or less equivalent to `std::is_constructible&lt;T, const T&amp;&gt;::value`. That said, I admit that all my previous comments were confused. All I wanted to say is that the original test case was insufficient due to the object not being `const`.
What makes you think a new plugin would be needed? To favour modularity or are there features that seem against some of YCM's aims? (Haven't seen the full codebase yet, also not familiar with YCM's source)
I use Rule of Three. https://en.wikipedia.org/wiki/Rule_of_three_(computer_programming). My rationale, if you want to factor out some abstraction, first seeing "potentially reusable code" you usually don't know (you only imagine) future use cases and requirements for this abstraction (be it class/function). On second time, when writing something similar you usually see the pattern but ... one copy and/or rewrite is not such big cost ... still. On third time, doing similar thing you have three contexts and thus much more knowledge about what needs to be abstracted out, so that this new piece of code (class/function) has some meaningfull scope and meaning. Still, that's just heuristics. It obviously doesn't apply to inherently repetive tasks like: int a = readInteger(s); int b = readInteger(s) int c = ... where `readInteger` should be abstracted out from beginning.
This makes sense to me, I'll have to remember it.
&gt; For the rest of the features, I think a new vim plugin would be needed. On what basis are you stating this?
No problem! I was going to put together a simple Hello World repo that could reproduce the issue and email it to the above email address but I didn't get much computer time at the weekend.
Yes. I tried that code sample on g++ 5.2.1. When `y` is declared `const`, the multiplication is not done, but when `y` is not declared `const`, it does the multiplication.
Maybe this will suit your needs: https://github.com/esrlabs/estl-teaser 
I'm not aware of what other features YCM has apart from completion. If it has an interface which could be used to put the keys and values of cmake definitions in front of the user somehow, then that could be used. Does YCM have such an interface? If not, then a new different vim plugin would be needed for that.
Take a look at bundle https://github.com/r-lyeh/bundle It does not compress to a stream, but it can compress containers. You can use a string stream to stream in what you want and then compress the resulting string and send. The thing I like about this library is that it very conveniently packages up a bunch of compression algorithms in a way that is easy to use in code, as well as to build (just compile the amalgamated bundle.cpp file)
&gt; Here's where the problems start, because even though the underlying type of my bit-fields was volatile, GCC decided to optimize away loads and stores on them Possibly related to [this](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=47409)?
I was actually going to suggest this, thanks for stepping up. A function should be no longer than that required to achieve its function.😏😏😏😏😏 I'm not one to support arbitrary standards for function length, but I do object to long functions trying to do many things. 
I'm not sure why you got down voted. There are times when a function will naturally end up long (lines of code) if written clearly. If the routine can't be broken down into smaller functions then you have to accept many lines of code. I think the reason people get all excited about this issue is that there are far too many sloppy programmers out there that simply don't grasp what a function is. They then try to manage these people with arbitrary coding standards which at times can have a negative impact on code. Also the focus on indentation level seem to be a hold over from the days of narrow screens and paper printout. Like length you don't want any more indentation than required. The but here is that often there is personal preference here to deal with. One guy will prefer his braces one way along with code indented differently than another. It gets silly after awhile. 
Declare when needed, adding to all the good reason you can find here, when you have longer functions, finding where a variable is declared is often more annoying because of all the scrolling you have to do.
I'd be happy to fill out your survey, provided you can give us more information on it. Is this something personal for a school project? If not, what company/organization are you affiliated with? What's the end goal for this study?
Chandler Carruth seems to disagree there. He mentioned that there are two cases where const could help in optimising -- none of those with significant effects -- and that clang does not optimise on those yet. https://youtu.be/FnGCDLhaxKU 1:35:24
&gt; Pick at least two options. No. 
It's definitely best practice to declare them as late as possible... I still do it at the top of function. Personally I think it's cleaner and more explicit. Rando declarations mid function just feel sloppy to me. 
Is there a pdf version of it?
What about T* -&gt; char* -&gt; arithmetic -&gt; T*?
It's a bit of an advantage on small memory systems, as it allows you to identify the stack usage of a function up-front. If you bury a 100 element array in the middle of a function it doesn't make it obvious why you're overflowing your stack (especially when you don't have memory protection to tell you).
Part of the confusion is that it is defined differently in C and C++. See http://stackoverflow.com/a/11996970/951890
Well that was exactly my point, mostly because I am used to such kind of codebases : https://github.com/jamoma/JamomaCore/blob/master/Modular/library/source/TTApplicationManager.cpp#L259
It's okay, I giggled a little.
My end goal is to be able to flash tmk_keyboard to it. I'm a noob, I honestly am pretty lost. If you could help me that would be awesome! Loads of people on /r/mechanicalkeyboards would be greatful aswell as those on geekhack. You seem to have messed with this before.
It would if it was odr-used (e.g. its address taken)
&gt; JSF Are there any good generic programming style guidelines for OO languages?
The problem that comes up is input/output; how do you display something on the screen, how do you get input. These can still be done without a library but they get tricky. You can either try to talk to the operating system directly, which is really just accessing a lower level api of sorts. Or you can try to talk to the hardware directly, which most operating systems won't let you do. When you do access the hardware directly you are in essence just using a hardware API of sorts.
Are there any good generic OO program structure guidelines online I can read?
Bug [47409](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=47409) listed several problems throughout, all related to volatile members of non-volatile structs/classes/unions. Bug [33068](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=33068) is similar but focuses on bitfield members, specifically. The point being that GCC treats: struct foo { volatile int bar; }; foo baz; much different than: struct foo { int bar; }; volatile foo baz; In many cases it doesn't seem to recognize the volatility of data members. In your Testbed, "bitfield" is a templatized standard-layout class with one non-static data member, "_raw". In "device", it gets instantiated as a non-volatile object, "tcc", containing a volatile member. This is what was suggested in the code::dive video but GCC doesn't seem to play nice with volatile members of non-volatile classes or structs, particularly with anything above -O0. Sadly, as I understand it, this is not really a bug in the truest sense. From the standard ($7.1.5.1/8): &gt; volatile is a hint to the implementation to avoid aggressive optimization involving the object because the value of the object might be changed by means undetectable by an implementation. It's just a hint. Still, it might be worth filing as a bug.
you should just have to `#include &lt;boost/iostreams/filter/gzip.hpp&gt;` and `-lz`
The Windows 10 version was already written in C++. I tried it a bit and you do seem to get much better performance (render distance, chunk loading, etc.).
But then you'd have to use Rust :/
Microsoft really doesn't know where to put their money. They should try charities instead.
Myea. It's like the wash product people promising over and over again that your white clothes will be really really *really* white, because of the newly included flux capacitors and extra filanges.
I really don't get how they can so easily ignor java obsession with placing every object on the heap when having this performance argument... That alone is a deal breaker and massive flaw with Java. However my point was more so that they had the benefit of being able to rebuild the whole application from scratch knowing exactly how it should function. It would be an embarassment if a rebuilt Java version wasn't faster than the original Java version. Laguage change is an additional factor.
Paragraph 12 of [\[intro.execution\]](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf#section.1.9) specifies that accessing volatile glvalues of objects is a side-effect, much like I/O. I am reasonably sure that `dev.tcc` is an lvalue, since it can be on the left side of an assignment operator, which would make this a straight-up bug.
I really don't know what you're rambling on about. I've recently seen aerospace [ML](http://mlton.org) code, written entirely functionally with imperative (impure) code constrained to a few locations, with formal proofs of correctness. How does that have anything to do with where you define your variables I wouldn't know. ML code is full of variable declarations at the point of use, that's how you're supposed to do it. There's a lot of legacy approaches and practices in the C world that are tightly tied to tools that are for the most part obsolete, or simply to the quirks of C. One reason why FORTRAN is used is that the language places much less demand on the tools to emit good code. Alias resolution is a bitch. Higher level languages like the ML family (F#, Ocaml, MLton) don't have that problem *and* let you write code that's easier to formally prove right, too.
I understand that everyone here is happy that we kick out Java (and hell, nobody is more happy about that than me), but this feels to me more like a move to finally restrict MC to Microsoft approved platforms. As the kid who bought this game while it was still only a shitty Java applet demo to finally have something to play on my Linux system, I'm just disappointed... EDIT: typos
The Java GC can be faster than plain new/delete. It all depends on the usage. Of course you can always write custom allocators in C++ for whatever specific usages, but far from everyone does that. I'm not a Java guy, but honestly comparing the performance of Java and C++ at this point is, generally, pretty moot. C++ does allow for more control though, but I doubt Microsoft is taking it _that_ far, specially since as you said, the main reason Minecraft is slow is due to design choices.
I have not played Minecraft since the early days so I'm a bit confused. How many minecraft version are there ? Why does some tools for educator even justify a separate version ? How many teams work on slightly different versions of the game? The article make it look like every platform uses a complete different code base. Plus "C++" is not quite telling. Will it be portable standard conformant C++ code with opengl/vulkan or something deeply tied to Windows/direct x ?
&gt; Sure, but we're talking specifically about Java here Which one? https://en.wikipedia.org/wiki/List_of_Java_virtual_machines Or do you mean specifically the OpenJDK? Even that one, has lot of GC options to fine tune. Probably as many as any C or C++ compiler have for fine tuning code optimizations. &gt; This isn't something you ever worry about in C++. If you are writing games, you worry about it. Even malloc() as distributed in most compilers stdlib is shitty for AAA game requirements. I remember there used to exist companies making money from selling optimized malloc() implementations for games. &gt; This is unique to STW GC. Sure, but not all Java GC implementations are STW. In any case, lets see how much of this still holds true when Java finally gets proper value types. Please note I am for automatic memory management, in whatever form (RC, GC, RAII or Rust style).
Agreed, Minecraft is virtually the only game I play on my Linux box, and althought Java is generally bad and slow, its portability is a benefit for the Minecraft community, apart from the ease for modders to manipulate the JAR. I'm not surprised by this move by Microsoft, who has an history of restriction of their property, even though in later years they appear to be trying to distance themselves from this evil image and to get closer to the freedom movement. So, who knows, maybe they'll listen to the game's community, and they'll come up with a solution that's just as portable and even easier to modify.
I think your post would have been much more constructive had it omitted your non sequitur conclusion. You raise valid concerns that warrant discussion, but I think the underpinning/assumed fanboyism in your post is not conducive to those discussions. GCC is better for some things, and Clang/LLVM is better for others. I think it's a bit silly to make sweeping statements like "GCC is better" as if we were discussing Star Wars sequels.
I am not fanboying GCC. I used clang in the first place but *had* to switch to GCC because I simply couldn't compile specific code. I edited the post to clarify in what terms gcc might be considered as a major switch from clang.
Their strategy is as follows: Minecraft is a valuable educational resource, but it doesn't run well on the typical school computer (it's slow on a gaming rig), so it needs accelerating.
We will need to wait and see if they are able to provide functionality that comes close to what is already available.
&gt; When you allocate half a gig of memory per frame, I'm not sure you can blame the gc Yep, in my defence I was willing to say a bit of both (dodgy code and GC induced thread stalls) .-)
As I said, it was the exact opposite for me. I ran a simple Quantum Monte Carlo simulation with both `gcc` and `clang`, and the `clang` version was around 6 times slower (can't remember the exact numbers, but ~2s runtime for `gcc` and ~13s for `clang`).
"Despite Warnings From Astronomers, Sun Rises Yet Again This Morning"
It would be cool, but it isn't my call...
This is a good option. Fast and simple, possibly something to work on to have it available with a different interface. The best option to me is a header only library usable like as simple as a std::ostream
It looks like a really useful library. I don't understand why boost geometry is getting such a bad rep.
I'm simply pointing out that type inference isn't a bad thing... There's nothing to overdo here IMHO, it should be the default, with explicit typing being an exception rather than the rule. Languages such as the ML family demonstrate that it's actually leads to less mistakes. Even with C++'s clunkiness, the inference should be treated as a default approach. I even have a couple of sources that start with `#define a auto` after the includes - it makes that specific code less verbose and more readable, way more so than if it used explicit declarations or even unabbreviated `auto`.
All versions of Minecraft other than the initial desktop version are written in C++.
Are there internships available?
A check of my posting history will reveal I am not American. Unless you're saying that you're trolling?
Sorry then. It seemed like a typical post of one of them. I'm not usually wasting my time checking other people's profile, but thanks for warning me.
I'm a *hardcore* free software enthusiast and I think RMS's "don't expose the AST because it may provoke proprietary extensions" was a horrible, horrible decision and set GCC back years... IMO. He did the same exact thing with emacs plugins and it was also a horrible decision that thankfully got overruled and emacs finally got a built-in plugin manager.
I just don't agree you equate Java SE VM with OpenJDK. For example, if I take IBM J9. which is available [here](http://www.ibm.com/developerworks/java/jdk/index.html). I have a very different set of GC algorithms to choose from that what Oracle provides. http://www-01.ibm.com/support/knowledgecenter/SSYKE2_8.0.0/com.ibm.java.win.80.doc/diag/appendixes/cmdline/commands_gc.html?cp=SSYKE2_8.0.0&amp;lang=en Just like C and C++, one should not mix language with implementation, regardless of the selection of free and commercial compilers.
how so ? 
So, Microsoft is still Microsoft ? You had me worried there for a second. Anyway, good on the team for making the code portable :)
I thought all odd numbered gcc releases were development releases.
No I meant that literally, it's just not yet decided! As far as I know we all want to have it multiplatform when it will be time (read: not soon, because Java is not even close to replaceable), but I can't promise things, it's simply not up to me. It's still Big Corp, who knows what happens years down the road.
My personal hope is that they move the codebase to C++ for all platforms. In the process, that will break compatibility with existing mods, but that's a pain worth paying for the benefit in my opinion - there never has really been standard support for modding, and it can be a fracking pain getting mods from sources that don't try to install crapware to allow you to download. Lets keep our fingers crossed that MS keep their promise to continue supporting all platforms. Windows first is understandable, Windows only would be a bit unforgivable.
Im just wondering if when will the 3D Floating stuff be implemented? Also achievements and ender pearls dont show up, anyway the update waas nice :) 
You could check out some of the decompiler tools available for modding the game. Might not be 100% the same as the original source but very close.
&gt; I just don't agree you equate Java SE VM with OpenJDK. &gt; For example, if I take IBM J9. which is available here. You've misunderstood me - I'm not saying everything is the same code base as OpenJDK - I'm saying that all the free as in beer JDK implementations have the same limitation as regards to VM wide thread stalls on a full GC sweep. [I believe the VM you've linked has exactly the same issue as I've been mentioning.](http://www-01.ibm.com/support/knowledgecenter/SSYKE2_8.0.0/com.ibm.java.lnx.80.doc/user/pausetimereduction.html). Notice how they mention _pause time reduction_ not elimination. Edit: has -&gt; have
And coming up next....
I wouldn't think that. The conclusions I've come to have been won by reading the documentation and some source code along with executing various testing programs that attempt to satisfy deadlines. Making assumptions based on "well it's two threads" isn't a great way to work out how a system is interacting.
I think its a very good library, but their C++03 target makes it cumbersome. But mysql has used this library for their GIS functionality.
&gt; Minecraft is a popular tool amongst educators, and has proven useful to keep kids interested and learning. (I mean, wouldn't you love a school where you learned by playing games?) This existed long before Microsoft and is a very cool thing indeed. Microsoft is simply trying to cash on it by releasing another specific version rather than adding a bunch of tool in the vanilla version. Also, I would argue that the java version can or could be tailored to any teacher need through the means of mods. And such mod probably exist as minecraft was used as a teaching tool since it was in beta or so. I would also not be surprised if every version has it's own codebase in separate repo 
Thank you. It compiled on os x but when I try to run it I get the error Clauss-MacBook-Pro-2~%&gt;juci dyld: Library not loaded: @rpath/libclang.dylib Referenced from: /usr/local/bin/juci Reason: image not found Searching google gave hints about homebrev, php, but the solutions seemed to be relative to those app and not juci. otool -L /usr/local/bin/juci /usr/local/bin/juci: @rpath/libclang.dylib (compatibility version 1.0.0, current version 0.0.0) /opt/local/lib/libgtkmm-3.0.1.dylib (...) /opt/local/lib/libatkmm-1.6.1.dylib (...) /opt/local/lib/libgdkmm-3.0.1.dylib (...) /opt/local/lib/libgiomm-2.4.1.dylib (...) /opt/local/lib/libpangomm-1.4.1.dylib (...) /opt/local/lib/libglibmm-2.4.1.dylib (...) /opt/local/lib/libgtk-3.0.dylib (...) /opt/local/lib/libgdk-3.0.dylib (...) /opt/local/lib/libpangocairo-1.0.0.dylib (...) /opt/local/lib/libpango-1.0.0.dylib (...) /opt/local/lib/libatk-1.0.0.dylib (...) /opt/local/lib/libcairo-gobject.2.dylib (...) /opt/local/lib/libgio-2.0.0.dylib (...) /opt/local/lib/libcairomm-1.0.1.dylib (...) /opt/local/lib/libcairo.2.dylib (...) /opt/local/lib/libsigc-2.0.0.dylib (...) /opt/local/lib/libgdk_pixbuf-2.0.0.dylib (...) /opt/local/lib/libgobject-2.0.0.dylib (...) /opt/local/lib/libglib-2.0.0.dylib (...) /opt/local/lib/libintl.8.dylib (...) /opt/local/lib/libgtksourceviewmm-3.0.0.dylib (...) /opt/local/lib/libgtksourceview-3.0.1.dylib (...) /opt/local/lib/libboost_thread-mt.dylib (...) /opt/local/lib/libboost_log-mt.dylib (...) /opt/local/lib/libboost_system-mt.dylib (...) /opt/local/lib/libboost_filesystem-mt.dylib (...) /opt/local/lib/libboost_regex-mt.dylib (...) /opt/local/lib/libaspell.15.dylib (...) /usr/lib/libc++.1.dylib (...) /usr/lib/libSystem.B.dylib (...) 
&gt; The performance cost of the wrapper alone is about 15-25% (versus a native opengl app). &gt; &gt; Also, cache misses. caches misses everywhere Both of these things represent _approximate constant overhead_. One of the things most noticeable to non techies about Minecraft's performance issues are the stutters. Frame generation time / input _jitter_ is what most people are referring to when they consider Minecraft to be a less than fantastic performer. It's easy to get MC to output nearly multi hundred fps - but every now and then that nosedives into the 10s or sometimes worse - due to the VM wide GC pauses. I'm not denying the overhead of the VM boundary and cache locality issues - but that's dwarfed (on a perception level) by the multi-millisecond pauses incurred due to GC thread stalls. 
Well, for one, it doesn't acknowledge the fact that C++, just like C, as languages, make no provision whatsoever for binary compatibility. Then, when they speak of COM, they speak in terms of COM supporting them, whereas it is the exact opposite.
This is especially painful in debug builds. I haven't done any measurements on this, but it feels like the slowdown on Windows using gcc is far worse than on Linux.
Microsoft donates a lot of money to charities.
&gt; Well, for one, it doesn't acknowledge the fact that C++, just like C, as languages, make no provision whatsoever for binary compatibility. It's like saying that it's not a problem if a phone manufacturer decided to make no provision whatsoever for charger compatibility. It's not because a property is acknowledged by its very creators that it's not a problem.
Does tmk_keyboard support the holtek ht1755? I've only ever used it with atmega32u4s, so my experience is very limited.
Part of that would be porting it over. It supported the cortex-m3 processor, which the HT1755 uses. 
As a java dev, 99% of the time, my code is blocked on something. SO yeah, it really is *Just As Fast As C++*™
Yeah I used to mod it, there was a lot of questionable things in the code. Not that I could do any better.
How does Boost.Geometry compare to CGAL in terms of functionality?
The biggest question with the C++ versions is if they'll actually open them up to modding, which is what everyone wants (beyond performance). That's certainly not impossible, even with C++, but they'll need to distribute a header and library to build mods against.
Keep in mind that you're using a compiler version released in the past two months, while most distributions are on a 2 year (or more) release cycle. The most common GCC versions in the wild right now are GCC 4.5.x and GCC 4.8.x...
That comment would still be off topic and annoying in /r/programming, just less so. 
&gt; You shouldn't roll your own code. The standard library was written by gurus and mere mortals won't do better. Even if you do, you'll write bugs, and you'll end up spending more time fixing them than it's worth. Is this conventional wisdom, or a caricature of conventional wisdom? The statement "don't roll your own code" makes no sense on its own, you have to write your own code at some point. It's generally extremely probable that you can't solve a problem better than it's solved in the STL or a high quality library. Their solution probably represents more man hours of time, written by someone with more experience in the problem. The issue with all this is that in many (most) of these cases, the third party library is not solving the same problem as you are. The STL and Boost are generally trying to be very generic and solve a huge swathe of problems with reasonable performance, in a way that's relatively easy to misuse and hard to misuse. Performance is a concern, but correctness and genericism are generally more important. It sounds like you needed very high performance processing of a very simple spec. That's not the problem domain that the STL or Boost solutions define. Rolling your own code sounds like a better solution than those. Finding a third party library specifically hand optimized sounds like an even better one. On the flip side, if you need to parse a CSV file, I can basically guarantee that it will take you ages to get all the bugs out of a hand rolled solution. Whereas with Boost you can put together a working solution in very little time.
Did you run a profiler on any of these? The boost and standard library versions are likely spending most of their time allocating and copying std::strings. An implementation based on boost::string_ref or std::experimental::string_view would probably be pretty competitive.
Yes, I think a much more accurate characterization would be: you shouldn't roll your own code without good reason. And yes, gaining significant optimization in a critical path because your can solve a simpler problem than the library code was designed for, will often qualify as a good reason.
Have you looked at mem usage via the in game diagnostics (F3)? In my anecdotal minecraft experience, the game continuously allocates and deallocates several hundred meg (~300) simply by moving the view around. Perhaps this is standard for game dev and certainly you dont want to waste cycles rendering that which is behind your view or behind walls, but to forget it exists the moment it goes out of view seem somewhat premature to me. I found it quite odd.
&gt; When you allocate half a gig of memory per frame I've been looking around for a citation for that figure on vanilla minecraft - and only found a vague reference to [200 MB memory every second](https://what.thedailywtf.com/t/optifine-modder-rips-the-minecraft-devs-for-the-code-in-the-newest-version/4235). That's rather a different figure to your claimed 60*.5=30 gig of memory a second. Any sources for that?
Of course it's arbitrary. The 100-meter dash is a 100 meters, not 107. If you have a different arbitrary comparison in mind, please do perform it and post your results. The "optimization bug" mentioned is not in Gcc, it is in the physical CPU chips. Rustc misses tickling it purely by luck.
I know that. My point was that sanitizers are being actively worked on in GCC as well. I wouldn't argue that they are more usable in clang right now.
Astrologers, more likely.
&gt; Programming with a GC language means that one needs to learn how to employ data structures and algorithms that are GC friendly. That's true, but you know in a language like C++ one just needs to learn how to employ data structures and algorithms that are RIAA friendly. the question becomes, if that's what you have to do to get decent performance, where exactly is the win? 
They run at the same speed. On a 3.4Ghz Haswell i7 that's about 75 ms, as noted in TOA. On a 2.4GHz Westmere the Rust is a little faster at 154 ms. Of course on other chips and other compilation configurations it will vary, but they will be within a few percent either way. And that's kind of the point.
Pretty sure he wants to see the _C++_ source...
I really like YouCompleteMe. It took me forever to configure, though.
I would like to thank you for fighting this war on GC. I've seen some crazy things done to avoid GC, which could have been solved by just doing a simple JNI level function. And some people consider this avoiding GC techniques, not using Enums and some other crap as good Java programming practices. Android developement is a big culprit. We need people like you to fight this GC war, and educate people that c++ is not all about manually managing memory.
Boost's Spirit library contains Qi, a powerful parser that is much better than Tokenizer. Much like Spirit.Karma is much faster than Boost's format, lexical cast, stringstream, and sprintf- I've benched these myself and found that it's worth taking the time to create Karma generators.
I agree. When Java appeared, you could choose between Eiffel, Oberon (and its variants) and Modula -3. All of them compiling to native code, Eiffel and Oberon also had JITs available, Eiffel and Modula-3 had support for real generics. All of them with value types. Oberon and Modula-3 were GC enabled systems programming languages. Instead we got a VM pushed into the mainstream, but at least it helped to bring many type safe concepts to the mainstream developers in a time where we were writing CORBA and COM servers in C and C++, and a more portable language in the days of K&amp;R C and missing C++ standard.
They are not equivalent. The former reserves space in memory to hold the integers without constructing anything (words.size() == 0), and the latter constructs a vector containing that many integers default-constructed (words.size() == 1&lt;&lt;15).
You're obviously unreasonable so this will be my last response to you. In essence, everything you mentioned happens in GC'd languages as well. multi-threading isn't free, failure to synchronize properly results in corrupt memory, race conditions, performance problems, etc. Also, just an fyi, a 'live reference' in that case is called a memory leak. That crashes your program and causes severe performance problems long term. you don't sweep that under the rug unless you're unduly biased. I could just as easily talk about how getting good memory performance in a GC language requires you to understand the particular GC implementation you're working against fairly well. Then it requires you to build your data structures and your usage against that specific model, just like in C/C++ It's unfortunate, but that's a lot of complexity people want to sweep under the rug because in the case where you don't care, you don't bother with it whereas in C++, you're forced to care. The issue is that we're talking about the case in which you care. Your response basically boiled down to "C++ doesn't scale (despite there being many many projects using C++ that do scale) and if you make mistakes in C++ it results in the wrong thing happening (ignoring the fact that this is just as true in other languages). So like I said, your response screams unduly biased to me.
Is there something wrong with valgrind? Alternatively, when you're on MSVC, you use their debug CRT "sanitizing" features (not really a compiler, right?) There's more than way to skin a cat, you know...
&gt; thus far there’s every reason to expect to see, ten years on, recruiters advertising for warm bodies with ten years’ production experience coding Rust. I think you mean that 5 years on, recruiters will be advertising for warm bodies with 15 years' production experience with Rust.
I use C++ since 1993, with parallel experience in lots of languages with automatic memory management.... I also had the "pleasure" of using C++ and validate code reviews in a couple of projects distributed geographically with 50+ devs of disparate skill levels and gave C++ programming classes to university students. So I do happen to know a few things about C++.
**Not** default-constructed, as that would leave trivial (with special attention to arithmetic) types uninitialized – they are _value-initialized_.
&gt; On the flip side, if you need to parse a CSV file, I can basically guarantee that it will take you ages to get all the bugs out of a hand rolled solution. Whereas with Boost you can put together a working solution in very little time. Too late, the handwritten code is not exception safe (`cout &lt;&lt; `) and leaves a memory leak. It is debatable how likely the exception is, but nontheless, it's there. Edit: typo
And then there's Spirit.X3, which has far less type-erasure than Qi (improving the efficiency of complex grammars) and compiles in about 1/5 of the time. EDIT: Benchmark results [here](https://www.reddit.com/r/cpp/comments/42ua25/a_quick_study_on_tokenizing/czds61v).
Obvious to anyone who looks closer at his response. he tries to wave away memory leaks in GC'd languages while lambasting roughly the same thing in C/C++. This is in addition to the point I made earlier that every single point against C/C++ was a point about the difficulties of concurrent development in general and GC'd languages suffer from them as well. Like it or not, that isn't reasoned, it's unfair and that points to an unreasonable bias.
Given your requirements: In my experience, it's just down to cmake. Lots of critique for cmake exists, but over time it became the de-facto standard (just browse github). When the cmake files are carefully mainainted, building on all platforms just works, and that's something other build systems struggle quite a lot with. And cmake is very well maintainted. For instance, there are currently undertakings to add a server mode, see: https://steveire.wordpress.com/2016/01/24/cmake-daemon-for-user-tools/ This would be a nice addition, since it allows for pretty much perfect tooling in IDEs and advanced text editors. ...unfortunately, cmake is also often not used in the correct way (e.g. lots of self written hard coded paths, instead of using find_packgage() functions, etc...) :-)
"Your own" version is cheating by a significant margin. All the proposed solution accept a separator at *runtime*, (`boost` and `strtok` accept it as an argument, for the iostream it is implicit in the current locale, that can be changed at runtime). On the other hand, the loop in `IsDelim` is likely to be unrolled. I am curious to see how Boost.Spirit performs against your code. 
Interesting idea, is there a downside to compiling with "-std=c++14" when you don't need it?
Define "easy". A cmake file for two modules, three tests, with most "useful" features needed from day to day : cmake_minimum_required(VERSION 3.4) project(MyFabulousProject LANGUAGES CXX) # Will add targets for running tests, valgrind, etc. include(CTest) # Old packages find_package(Blob REQUIRED) # Recent packages find_package(NicePackage REQUIRED COMPONENTS bim bam) # Create our libs add_library(foo src/foo.cpp src/foo_impl.cpp) add_library(bar src/bar.cpp) # Will add -Imy/3rdpary/folder to source files of foo target_include_directories(foo PRIVATE my/3rdparty/folder) # Will add -DBAR_ENABLE_FEATURE or equivalent target_compile_definitions(bar PRIVATE BAR_ENABLE_FEATURE) # Will pass flags to the compiler target_compile_options(bar PRIVATE -funroll-loops) # Will add relevant -l switches target_link_libraries(bar PRIVATE ${Blob_LIBRARIES} NicePackage::bim NicePackage::bam) add_executable(foo_test tests/foo_test.cpp) add_executable(bar_test tests/bar_test.cpp) target_link_libraries(foo_test PRIVATE foo) # Have everything we build use cpp14 set_target_properties( foo bar foo_test bar_test PROPERTIES CXX_STANDARD 14) # Add our tests add_test(foo_test foo_test) add_test(bar_test bar_test) add_test(bar_test2 bar_test --command-line-switch) 
Well, it's not like rust has that much expressiveness in its generic basic implementation and since we are comparing c++ and rust, it doesn't even matter, at all.
He very likely meant "high frequency trading".
I have the same opinion. Cmake is hard when you need to port on several platforms. That's not easy to manage the compiler and the options per compiler 
Last time I've tried to report a bug to gcc they weren't allowing gmail e-mails on their bug tracker (while allowing some 10 minute mails apparently). Luckily bug was fixed pretty fast after I was able to finally report but it seriously pissed me off at that time.
Talking about Rust vs C++ performance is meaningless. For xxhash, I got to the point where my implementation beat gcc but not clang: the difference from the backend was larger than the difference from everything else combined. The actual differences go both ways: - Rust will be slower because it has some overhead like bounds checking and lack of `nothrow`. - Rust will be faster because they default to jemalloc and sized deallocation. - Rust will be slower because they don't have custom allocators. - Rust will be faster because LLVM's link-time optimization is the only compilation mode. What Rust calls LTO is actually whole-program optimization. - Rust will be slower because you can't use gcc where gcc generates better code or pass custom flags to the compiler from cargo, and `-O3` is [not always an optimization](https://github.com/rust-lang/cargo/issues/544#issuecomment-66865734) over `-O2`. - Rust will be faster because of mandatory devirtualization. - Rust will be slower because their hashing scheme and error handling is unoptimizable. 
cmake and premake5 are equally good
The problem might also be related to using an older cmake version: http://www.kitware.com/blog/home/post/510. Try upgrade your system, remove the build directory, and rebuild juCi++ as instructed in the install docs.
People should upvote this and **at least** try it out themselves if they feel this should be downvoted (and post/disprove with results)
Ok - That actually looks a fair bit better than the last time I really used CMake in anger. I'll have to have a go again and see how I feel about it now.
So are you saying people can't distinguish between a code snippet and a real code case?
This was an interesting read, but only as a Rust outsider who was curious to see what is effectively the same program written in both C++ and Rust. What killed the entire article for me, though, was this: &gt; The code may be denser than you are used to, **just to keep it to one printed page**. When I write “much slower”, below, it might mean 1.3x to 2x, not the order of magnitude it might mean outside systems programming. **Huge swaths of both languages are ignored**: C++ templates, destructors, futures, lambdas; Rust channels, threads, traits, cells, lifetimes, borrowing, modules, macros. Surely this completely and utterly defeats the point of the article? The whole idea is to face off how both languages can be used to do the same thing and validate the pros/cons of each. By making arbitrary limitations and actively choosing to ignore major language features, all you've done is made a line-by-line identical tool in two different languages. Effectively swapping a bunch of key words and syntax. That makes it less about the languages and more about the compilers underneath them - hardly a surprise that both ended up near enough the same. I'd be much more interested in a follow-up article that has no such simple limitations but instead uses both languages to their fullest. Compare that, both in terms of brevity and performance and we'll have something interesting to talk about.
Feel free to elaborate. I'm interested.
CAN I HAZ JOB? I KNOW EXCEL AND PAINT
In CMake, you can actually request specific features from the compiler. CMake will automatically add necessary compile flags or produce an error if these features are not supported by the compiler. See https://cmake.org/cmake/help/latest/manual/cmake-compile-features.7.html
CMake, both from software developer and packager's positions.
You can also request specific compiler features instead of requesting a standard: target_compile_features(foo PUBLIC cxx_auto_type cxx_noexcept cxx_nullptr cxx_range_for)
&gt; I have the same opinion. Cmake is hard when you need to port on several platforms. That's not easy to manage the compiler and the options per compiler How so ? with a single cmake script and the relevant toolchains I target windows, linux on x86 and ARM, mac os x, Android, and portable native client. 
I think the answer is CMake. A lot of the old CMake problems are fixed by the 3.x versions. Unfortunately, there is not a lot of information on modern CMake in an easy to use form. The best resource I could find on Modern CMake is http://www.slideshare.net/DanielPfeifer1/cmake-48475415 In addition, while I think there are areas that CMake could do better, CMake is unrivaled in C++ in the aggregate of speed, support for different platforms, and broad use. The sooner we can get all of C++ on CMake, the better it will be in the long term.
Ok. Please give me the simple way that I miss for defining the compiler and for being able to compile easily on different platform. With make I will run something like make port=gcc myprog How can you do that with cmake?
&gt; Rust will be slower because it has some overhead like bounds checking and lack of nothrow Rust doesn't have throws in general so there isn't really any slowness due to exception stack unwinding stuff. Bounds checking is also an overblown problem, the bounds checks can often be optimized away by the compiler and even if they aren't, they will be branch predicted away by the CPU (you would expect that the bounds check would almost always succeed, which is each for CPU branch predictors to handle). &gt; Rust will be slower because they don't have custom allocators. Not true (anymore at least, it may have been true when you last dealt with rust). https://doc.rust-lang.org/book/custom-allocators.html &gt; Rust will be slower because their hashing scheme and error handling is unoptimizable. What do you mean by this? For the error handling, it is pretty fast, rust doesn't throw exceptions, so there isn't really any optimization to be done. There is not stack tracking or stack unwinding which is usually the big costs where errors are concerned.
cmake detects and use by default the standard compiler on your host platform. If you want to cross-compile : http://www.vtk.org/Wiki/CMake_Cross_Compiling#The_toolchain_file Some premade toolchain files : https://github.com/ruslo/polly
This confused me because my first thought was of Rust the game.
Or rather, than the OP could not spot the difference between: - order of magnitude in data size - using `string` as result or as an intermediate computation step 
Address Sanitizer causes a 3x slowdown. Valgrind causes a 30x slowdown.
Yes, it's rather a "dump" of libs - granted many, but lots of them are totally low quality and not good enough to spend any time on it...
Yup. It's like they looked at the weirdness of ML syntax, then looked at the weirdness of C++ syntax, and asked the important question: why not both?
What's the compiler? Specifically, does `std::string` uses Copy On Write (gcc &lt; 5.x) or Small String Optimization? Tokens are generally small (and numerous) so the difference between a solution incurring a memory allocation for each and every token and one which does not will be massive. Ideally, using a slice container (`boost::string_ref` or `std::experimental::string_view`) would be even better since even larger tokens would no longer require an allocation. &gt; The standard library was written by gurus and mere mortals won't do better. Well, the standard library implementations are regularly improved so you can obviously do better... ... however this "advice" forgets a number of drawbacks: 1. Standard facilities are generic, a specialized solution can be simpler and perform better 2. Standard facilities are hampered by backward compatibility (`std::string` dual index/iterator interface, the whole set of streams, ...) 3. Standard facilities are hampered by compromise (`std::unordered_map` is mandated to use bucket-chaining when open-addressing hash tables are much faster in general) Still, Standard facilities are battle-tested in ways a custom implementation will never be, so one does have to think before switching to something else.
&gt; Rust doesn't have throws in general so there isn't really any slowness due to exception stack unwinding stuff. Actually, Rust does unwind the stack on a `panic!`: you cannot catch it (without `unsafe`) but it still behaves a bit like an exception. &gt; Bounds checking is also an overblown problem, the bounds checks can often be optimized away by the compiler and even if they aren't, they will be branch predicted away by the CPU (you would expect that the bounds check would almost always succeed, which is each for CPU branch predictors to handle). I wish, but as [this recent PR](https://github.com/rust-lang/rust/pull/30917) shows there are still gains to be had from removing bounds checks statically. Note that even if the CPU branch predictor is 100% accurate it still means that the code is not as tight for example. &gt; Not true (anymore at least, it may have been true when you last dealt with rust). https://doc.rust-lang.org/book/custom-allocators.html You and /u/Jurily are most likely talking about different concepts: - the link you show is about switching jemalloc - Jurily is most likely talking about switching the allocator on a per-contained basis (for example, to use a stack-based allocator) &gt; What do you mean by this? For the error handling, it is pretty fast, rust doesn't throw exceptions, so there isn't really any optimization to be done. There is not stack tracking or stack unwinding which is usually the big costs where errors are concerned. Regarding the hashing scheme, switching the hashing scheme of `HashMap` is still an unstable feature. Regarding the error handling, you are unfortunately wrong again: 1. Modern exception handling implementation, as used in Clang and rustc, use the Zero-Cost exception checking which is actually cheaper in the case of no error than error code checking 2. As mentioned, Rust does have stack unwinding, on a panic, the stack is unwound before the thread is shut-down, allowing the program (as a whole) to continue running if you took care of loose ends in the destructors 
Regarding bounds checking: it's more a library thing than a language thing, the language itself does not have bounds ;) In the Standard library the implementations of the `Index` and `IndexMut` traits (which are called by the `[]` operator) use bounds checking, but unsafe functions (such as `get_unchecked`) do allow to bypass it for performance reason when the optimizer does not manage to elide the bounds check and it matters. Regarding aliasing: Rust does have more information than C++, however the actual and potential gains are actually hard to measure. It very much relies on LLVM to exploit it. As for the maturity of the front-ends, rustc for now does not perform any optimization (whereas Clang performs some devirtualization for example) however it's in the plans. A current rewrite (introduction of the MIR) is about producing an internal representation that will be more amenable to such work.
Because CPU architectures often have a preference for a certain data size (due to alignment, etc.) and are optimized wrt. that.
Immutability leads to code that is both safer and easier to read. Immutability by default means that you don't have to guess so much. The lack of header files means way less file juggling. You can't simply avoid an error in Rust - well, you can, but you really have to want to. These are off the top of my head.
I hinted elsewhere at this, but the last time I really used CMake it didn't support that, or at least if it did then it was far from obvious. That was on the 2.x version though, and I'm now realising that there's a *lot* of improvements in the 3.x version :)
It's a bit hard to understand exactly what you wish to cover with "elegance" so my answer might be a bit long... I will criticize C++, in the process, but please bear with me. I assure you that I do so because I care about the language, as my StackOverflow profile can tell. I also recognize than Rust has 30 years on C++: it's always easier in hindsight, after all. --- First of all, the trifecta, [out of the horse's mouth](https://www.rust-lang.org/): &gt; Rust is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety. *Rust: Safety* C++ was built on top of C and has, unfortunately, inherited a lot of C's lack of safety. "Undefined Behavior" appears in numerous places in the Standard, and leads compilers to do unspeakable things to the code you write. Safety is not an afterthought in Rust: it's a linchpin of the language. Why? Mozilla estimates that **50%** of the security vulnerabilities reported in Firefox are due to memory safety violations, be it out-of-bounds access, use-after-free, data-races, ... this is why they sponsor the development of Rust. *Rust: Performance* Rust is closer to C, performance-wise, than it is to C++. There is a culture of *explicitness* in Rust: any non-trivial operations (such as a deep-copy) requires an explicit annotation in the code (`.clone()` in this case). A noteworthy exception being destructors. The Rust language is lean, the abstractions provided are lean. It takes the C++ philosophy of "You don't pay for what you don't use" and pushes it to the next level: - Have you heard of people in the game industry deactivating RTTI (and thus exceptions) because it bloats binaries? Rust does not have RTTI (and thus no built-in equivalent to `dynamic_cast`) --- But let's look at the language closer. *Rust: Grammar* The C++ grammar is notoriously complicated to parse: - the use of `&lt;` in templates requires some kind of feedback to disambiguate it from "less than" in a number of situations - the disambiguation rule "if it looks like a declaration..." leads to the Most Vexing Parse And that's after the C preprocessor has done its infamous job (caring little for scopes...). Rust starts from a clean slate: - its macros are syntactic macros: they operate on the AST not on text, so respect scope and hygiene - its grammar is (or at least attempts to be) unambiguous and simple to parse; actually there is a project to formalize the grammar to ensure it is properly LL(1) (or LL(N) for some small N) A well-defined grammar should boost the ecosystem (highlighters, refactoring tools, ...) *Rust: Affine Types* If you have some interest in Rust, you have probably heard already about Ownership/Borrowing. Rust tracks ownership of values and whether they are currently referenced (or not) to enforce memory safety. [Affine types](https://en.wikipedia.org/wiki/Substructural_type_system#Affine_type_systems) are one of the core language primitives which assist in this task: a value of an affine type can only be "consumed" once (though it need not be). Affine Types are all about move semantics, tracked at the type-system level, much safer than C++'s version. However, being a primitive, they can be used for other purposes. My personal pet thing is to encode state transition with them. Imagine a connection: struct ConnectionParameters { ... } struct Connection { ... } impl Connection { // A connection is created from a set of parameters, creation may fail fn new(cp: ConnectionParameters) -&gt; Result&lt;Connection, Error&gt; { ... } fn close(c: Connection) -&gt; Option&lt;Error&gt; { ... } } This is much cleaner than the typical OO approach of having a single `Connection` type which may represent: - a yet to be opened connection - an open connection - a closed connection In a fully-typed design you should aim to avoid "invalid" operations on types: that is, no method should require dynamically checking a precondition before being allowed to call it. Unfortunately, in most languages, and in C++, the "old" variables remain behind: even after calling `connection.close()` you can still inadvertently use the `connection` variable. In Rust, the affine types makes this a moot issue: the compiler will error out if you try to use a consumed value. At the extreme, this allows [encoding session types](https://github.com/Munksgaard/session-types) in Rust. It's [worth a thesis](http://munksgaard.me/papers/munksgaard-laumann-thesis.pdf). *Rust: modern amenities* Rust also features a lot of modern amenities, such as Sum Types and Pattern matching. This extends to library design, and the Rust Iterator design has some significant advantages over the C++ implementations (no risk of accidentally pairing two iterators pointing in different containers for example); it's also more user friendly in that implementing a single method (`next`) is sufficient to get a full-blown iterator, if you've ever implemented C++ iterators, even with the help of Boost, you should get my point! --- And let's not forget the compiler, rustc. It was developed to be very pragmatic and features: - the execution of a pre-build step via `build.rs`: this file is built and executed first, which allows it to generate other files (or portions of them) - the execution of user-provided plugins *Rust: Lints* One usage of plugins is lints! The compiler passes are instrumented by those lints which can be used to emit warnings for dubious code, for example: - [clippy](https://github.com/Manishearth/rust-clippy) is perhaps the best known set of lints in the Rust community, it includes 98 warnings as of today - [herbie](https://github.com/mcarton/rust-herbie-lint) on the other hand is a new experimental lint based on the success of the Herbie tool which proposes to rewrite floating point expressions to increase their accuracy and stability Allowing the community the contribute lints without having to hack on the compiler is a huge productivity boost (in terms of lints creation), it also means that companies or projects can create their own lints, and for example [Servo](https://github.com/servo/servo/tree/master/components/plugins/lints) has some custom lints. --- And of course let's not forget the ecosystem. *Rust: Cargo* You cannot talk about Rust without talking about its package manager. A default standard way of building Rust code makes it much easier to switch from one codebase to another... ... and the best way to illustrate it is to talk about *crater*. If you read the Rust forums, you will sometimes hear about *crater run*: Crater is a tool written by one of the Rust core developers which is used to test new versions of the Rust compiler across a very extensive set of Rust projects (those published on crates.io, the default index) to check for breakage; it may also be enhanced to check for performance regressions. This is only possible because of the uniformity of Rust projects, which itself comes from having a single (blessed) way of building Rust code. --- It's not all roses though. However, the current community is quite incredibly mature on the topic, prompt in recognizing the current shortcomings of the language and has shown its resolve to try and address them. For example, I really like the graph of "performance" vs "safety" showing Rust alone in the quadrant where both meet. It does fail to mention that in order to get there one might have to completely rethink its architecture in a way the Rust language groks (ownership and borrowing) and that a significant syntactic burden might be necessary. Coming from C++, as show-cased here, it's nothing to worry too much about, however coming from GC'ed languages (especially terse ones like Python), it's a cold shower. Another example is that the current `Iterator` design precludes implementing streams. The `Iterator` must produce references into an outside (borrowed) container. It cannot produce references into itself nor can it produce a value. There's also a lack of meta-programming facilities; Rust's generics are closer to C++03 (with mandatory concept-lites on top), and lack: - Higher Kinded Types: cannot write once for both mutable and non-mutable - Genericity over Values: this makes it awkward to deal with fixed-size arrays; in the Standard Library each trait is implemented for the smallest size of the arrays only - Variadicity: macros are variadic, generics are not; in the Standard Library each trait is implemented for the smallest size of the tuples only and C++ `constexpr` are more powerful than Rust's `const fn` for now. Finally, obviously, the lack of maturity implies a general lack of facilities... but then, in C++ it's so painful to integrate other libraries than code sharing is much less developed than it is in other languages and of course there's also the issue of licenses which puts a dent in what technology alone can solve. --- Alright, I hope I wet your appetite ;)
Java and JavaScript were quite slow at their beginning, but a lot of optimization work has made them fast or often fast enough. Some of the current Rust performance problems could be improved. Some bounds checking could be removed from Rust code, as in Java: http://www.ssw.uni-linz.ac.at/Research/Papers/Wuerthinger07/Wuerthinger07.pdf &gt; Modern exception handling implementation, as used in Clang and rustc, use the Zero-Cost exception checking which is actually cheaper in the case of no error than error code checking This interesting article backs some of your assertion: http://joeduffyblog.com/2015/12/19/safe-native-code/ &gt; A nice accident of our model was that we could have compiled it with either return codes or exceptions. Thanks to this, we actually did the experiment, to see what the impact was to our system's size and speed. The exceptions-based system ended up being roughly 7% smaller and 4% faster on some key benchmarks. There are some differences between Rust code and the The low-level C# code compiled by Midori, so it's not a perfect comparison. But if we assume the lesson of the Midori error model is reasonably useful for Rust code, how to improve the Rust situation? If you compile the Rust code with "-C lto" and profile-guided optimization, could the Rust compiler rewrite some passing of error codes of Option/Result with exceptions (where at run-time in all or most cases there's a Some/Ok)?
Regarding the idea of switching between return-code checking and exception, I am afraid it could be a bit difficult given that `Option` and `Result` are today regular types in Rust and not built-in... but maybe I am wrong. --- Since you linked the Midori article, I'd like to also speak about its Optimizations section. From what Joe Duffy says they were able to: - significantly cut down on the number of bounds checks - significantly cut down on the cost of overflow checks both are eminently applicable to Rust (rustc currently disables overflow checks by default in Release because of the overhead). So, yes, there's certainly a lot to be done in terms of optimizations, either in rustc or LLVM. I seem to recall hearing that unfortunately LLVM was not very good at inducing the range of integers today, and thus optimize on it, which affects its ability to remove those checks. 
Mature: cmake. My wishes: meson. At work I am using cmake. For my own projects I am giving meson a try. At work I decided to use cmake (as opposed to meson) because it is battle tested and generates all kind of files: visual studio, makefiles, ninja, xcode... we do need this at our company. I find meson nicer but at this time it is not as mature as cmake.
This is very complex. You can have several compilers installed on your machine without knowing all the details of the installations. BTW the installation can change from machine to machine. And from system to system (eg. fedora or debian). With a classical makefile you just have to call g++ or clang for instance. Cmake is really complex for doing that. Much more than make. I really think they should simplify this part
The comparison is meaningless *only* because it is so close to even. That is the most important point in article. Unlike practically every other language, Rust must be compared to C++ according to criteria other than performance. There's plenty to compare: default safety on one side; expressivity on the other. If/when Rust gets strong enough to express STL, C++ will have less claim to primacy.
&gt; I don't agree at all with you comment about popularizing. Browsing SO, it is very clear that target_include_directories, and generally a 'target oriented' view of the buildsystem instead of 'directory oriented' is strongly taking hold. I agree with /u/jbandela. The worst problem is that when searching cmake docs on google I stumble 3 times / 10 on the old wiki, and 7 times / 10 on 3.0 instead of $current_version where the doc is a bit better. Qt seems to have solved this problem by having a "docs.qt.io" which always refers to the latest version for better googleability (and yet I still stumble on 4.8 pages). For instance, if I type "cmake link library" on google, the first result is : http://stackoverflow.com/questions/8774593/cmake-link-to-external-library There is not a *single* answer which uses the PUBLIC/PRIVATE form (and the top answer IS_IN_SHOUTY_SYNTAX). If I type "cmake include folder", the first answer is cmake 3.0 doc, which does not even have an example for the most basic thing that you would like to do, and the second is : http://stackoverflow.com/questions/13703647/how-to-properly-add-include-directories-with-cmake which again does not even contain a reference to target_include_directories.
Please not into python!
You are 100% right. But if you need that speed, then this is a case I consider "having a good reason to do otherwise" in the above-mentioned rule of thumb.
&gt; within the constraints chosen, including length, clarity and taste Under those constraints you should [pick `` int`` by default unless you have a good reason not to](https://channel9.msdn.com/Events/GoingNative/2013/Interactive-Panel-Ask-Us-Anything).
I agree.
You are right. Pre-made toolchain files don't make sense. Toolchain files are supposed to contains just a few paths local to your system (eg,where is your android cross compiler), and so are local to your filesystem and machine. If your toolchain is not as simple as https://cmake.org/cmake/help/v3.4/manual/cmake-toolchains.7.html#cross-compiling-for-linux then there is probably something missing in cmake to support your use case. The android toolchain file that floats around the internet is not the correct approach. Instead cmake/Modules/Platforms/Android.cmake should contain everything needed so that all you need is set(CMAKE_SYSTEM_NAME Android) If that is not currently enough, then consider contributing patches to cmake.
Actually, now that you talk about this... There is a proposal to add a `?` suffix operator to Rust to replace the `try!` macro; this `?` will require making the very choice that is necessary between returning the value or an error.
I think you mean this: https://github.com/rust-lang/rfcs/pull/243
In both of your examples if you drop the quotes from the search terms google will return the CMake 3.X documentation as the first result. This looks to also be the case for DuckDuckGo and bing for cmake link library, for the include folder search those two prefer the new include docs, not the better target_include docs :(
&gt; And there's still the option of using Boost.Karma for the output instead of stream insertion... I'd like to see this. Karma has always beat the pants off stringstream and has become my go-to when I need to format as well as perform simple single type-to-string conversions.
The article is, as stated, "deliberately about the nitty-gritty of coding.". Nothing that could be done with the other apparatus would make either program faster; those features are there to help organize big programs and libraries, something irrelevant to this exercise. The arbitrary length limit is there to constrain the size of the project. Without, this article would not have happened at all. I would be equally interested to see the article you want, but nobody wrote it.
There is also mxx_ru which is like scons but uses Ruby: https://sourceforge.net/projects/mxxru/files/Mxx_ru%201.6/ It was developed by me long time ago and still in active use but not active developed :( There is a simple example of how project file could look like: require 'mxx_ru/cpp' MxxRu::Cpp::exe_target { required_prj 'so_5/prj.rb' target 'sample.so_5.blinking_led' cpp_source 'main.cpp' } 
This is correct advice. Interestingly, the `scores` array is of shorts because 7 shorts fit into a regular XMM register, a fact that some compilations have taken advantage of. Seven regular ints would fit into an AVX register, but `corei7` doesn't have AVX. Of course this is not something one would normally worry about, but (at at least one stage of the project) the choice did make a difference, and here every difference matters. I will revisit the choice, and report the outcome. Edit: Changing `short` to `int` makes a huge difference. Changed.
I'm talking about actually _allocating_ the heap space.
I haven't tested, but after thinking about it further, I don't think that using Karma will really help any more than just replacing `os &lt;&lt; boost::string_ref(...);` with `os.rdbuf().sputn(...);`. However, this same change could be made to most of the other approaches as well, so I think the best way to keep the benchmark fair is to keep it as-is. I.e., there's an obvious improvement to be made, but it wouldn't be fair to implement it just for the X3 approach and not for the others too.
*sad kitten face*
Thank you for your reply. I already had installed clang via macport so tried to use that to begin with. Altering @rpath in the executable was harder than I though and I felt I was fighting my own shadow. :-) I ended up installing llvm via homebrew and cloned juci again from github to start from clean. Same non-working @rpath as before. I finally managed to change @rpath with install_name_tool -change @rpath//libclang.dylib /usr/local/opt/llvm/lib/libclang.3.6.dylib /usr/local/bin/juci and now I can start the app. When I used clang from macports I did export CC=/opt/local/bin/clang-mp-3.7 export CXX=/opt/local/bin/clang++-mp-3.7 and then cmake .. and changed src/CMakeLists.txt to point to /opt/local/lib. So if I had used the install_name_tool with the -change parameter it would have worked as well.
Thank you again. I have 3.4.1.
 CXX=g++-5 cmake . or CC=gcc-4 cmake . depending on the language you are addressing. You can even CC="ccache gcc" cmake . if I remember correctly.
If your project is speed-sensitive, then going 3x slower s just as bad as 30x slower though :-). Also, you surely don't run retail builds with sanitizers on.
I'm not going to read this article because the implication that Rust code could outperform equivalent c++ code is absurd.
&gt; going 3x slower s just as bad as 30x slower though How can you say this with a straight face? The program is sensitive, not _intolerant_. 3x slower drops 60 FPS to 20 FPS. I can debug that.
I don't know if you know what I'm referring to. It is this: https://github.com/purpleKarrot/CMake/commits/pch Any other approach to PCH in CMake is not the right approach and is likely to be frustrating and not lead anywhere, as you apparently discovered. However, Daniels approach is the correct one, so it is worth spending time on for anyone who wants the feature (and who doesn't think creating their own buildsystem from scratch is a good idea in 2015+).
Again? Rust again on this sub? People religiously advertise it like the second coming of Jesus on this sub. I constantly see how Rust is soooooo much better than C++ and how it fixes literally every problem C++ has. Whereas all I see is constant language advocation, "soon we will be better than C++ in performance" and terrible syntax. I feel that the only thing it has "going" for it is that it's "better" than C++. Reminds me of other language advocation I see, namely for Java and heck, even Javascript. If it wasn't for the syntax, I would still avoid Rust like the plague because of its users. If you're constantly telling me that I should use Rust, because it's so much better than C++ and writing articles that can be summed up to "It's time to drop C++ boiis! Rust is coming for your position!", you'll only make sure I'll keep a nice and long distance from it. Besides, not everybody thinks C++ is literally Satan's personal programming language designed to bring despair down to us mortals. It could be that language if you decide against all the features that make it a great language, but C++ has improved greatly with the recent iterations and I don't see anything taking its place. So yeah, I'm most likely sounding like just another mad kid on the internet, but honestly, I don't care, I'm just speaking my mind in the form of a rant. Also, this rant can also be applied to every other article that is "X vs C++ (performance)" (and sums up to X is God and C++ is the Devil). Anyway, I'm prepared for your down votes.
One of these days I am going to figure out using Spirit, I swear. I have been telling this to myself for about a year, there just never seems to be the right time. :-D
As a Google employee, I love using blaze internally and am holding out hope for [bazel](http://bazel.io/). C++ is one of the better supported languages at the moment, but it's definitely not "cross-platform" (Windows support is still WIP). Given that among its goals are providing repeatable, hermetic builds external dependencies (particularly system dependencies) are awkward.
Either `max(hp,0)` or `hp&gt;0 ? hp : 0`.