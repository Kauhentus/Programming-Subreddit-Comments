C# and Java took a very long time to add generics though (and are they implemented like templates or as abstract base classes?) The key reason this is a problem in C++ is template definitions have to go in the header and get recompiled for every file that uses them.
Literally correct. However this would be a far superior improvement to the include mechanism. Database driven, ODR violation detecting, it could even be faster. Though probably in practice slower, as it would surely be O(N^2) to modules imported (as is the current legacy import mechanism unless you are careful to always import modules in identical order in the preamble to all translation units I.e. you use an `#include "common_modules.hpp"` top of every source file). But still a great leap forward over where we are now, and a great building block for the future.
I've implemented modules using macros and the preprocessor, and it works well. I would be surprised if that technique doesn't become very popular.
if you are looking for that level of performance increase are you sure virtuals are the correct design haha? There are a number of differences though, especially dynamic casts (which you shouldn't do anyway) they vary SO much across compilers. I'd recommend getting googles benchmark library and testing it out yourself. There is an online version quick-bench I believe. That probably wasn't the answer you were looking for sorry haha
&gt; Modules are not *modules* What do you mean by *modules*?
This is really cool and promising. It's basically CMake export config files, but in json, not in CMake-language. CMake exported targets are really great and I think many people like them and they're great to use. But you have to use CMake - if you don't, they're not useful. Now imagine having the same but in json, so any build system can consume them! (And at the same time most build systems would be able to create them). So now the question is - Last commit May 2017, no Stars on GitHub. Is this project dead? What's happening to it? A couple of CMake people seem to be at least partially behind it so one could have great hopes...
Literally exported templates, as was removed from the C++ 03 standard due to only one compiler implementing it, and its authors writing a scathing report to WG21 recommending its immediate removal.
You can delegate it to your functions: ``` auto operator[](constexpr int index) { (*this)[idx_c&lt;index&gt;]; } ```
So when any normal person reads modules, that is not C++ Modules. It was once about a decade ago, but as they have constantly cut anything controversial we are left with Precompileds with a few toy bits of import export control so basic no non-toy user will ever bother with using them (in my opinion) as the existing proprietary extensions are far more powerful, and moreover are well understood. I converted all my libraries over to Modules some time ago, and came away realising nobody is going to use such simplistic ABI management outside small projects. The precompiled part could be useful if wielded right, though in my case linking was a good bit slower (on an older MSVC though). But by modules I mean the things Python and Rust have. Microsoft COM components count too, as do most PIMPL classes. They have a very formal rigid outer, usually simplified, API in order to control and direct and dampen ripples of change from when you modify code to add features or fix bugs. This lets you modify a module without those changes propagating outside that module. Which is the whole point of modular software design. C++ Modules quite literally *does nothing* on any of that.
right.
This headline is interesting because I have been told through unofficial channels that discussion about module tooling has been declared out of scope for the San Diego meeting. Specifically the EWG wiki (which is not public and which I don't have access to so I can't verify any of this personally) has been edited to contain the phrase "discussions about modules tooling are out of scope for C++20". Googling the twitterverse may lead you to further information about this issue. Unrelated to this an email thread discussing the Fortran paper has been ongoing. For your benefit here is a (unrealistic blue sky thinking) snippet I wrote in the thread about a different approach to laying out modules. It is very much in line with the linked article. ------ As far as I know the current standard definition does not limit the number of modules that can be produced for one shared library (which, I'm told, is not even defined in the current standard, but let's assume that it is). That is, for libfoo.so there can be a.cpp, b.cpp, and c.cpp, each of which produces a module (and which may use each other as needed). This forces a scanning step on all sources and building the individual files in a specific order. This is where all problems discussed above come from. Let's now make the following changes: - for every shared (or static) library X, there can be _at most one_ module - the module declaration and definitions are in a _single standalone_ file that has nothing else in it (and which has its own file name extension, if only by convention) Now almost all of the problems go away. The build system can start processes optimally in parallel without needing to do _any_ source scanning. Everything needed to serialise and execute the compilations can be computed merely from the files and build target definitions. Even generated sources work, because we know all BMI files they could possibly require (which are the same as for every other source in the same build target) before the files are even generated. There may be some work on transitive dependencies but they should be workable. This is, in essence, how most build systems use precompiled headers. We know that the design basis is fairly sound.
Yes, it would require support in the object file format for templated symbols. There's only so far you can go with object formats designed for C. On the other hand, with this support, we could even have templates in shared libraries.
Firstly, just because the assembler looks prettier doesn't mean the code is faster in aggregate. MSVC historically avoids inlining routines it thinks might be called often. The rationale is that the uops cache will get reused more frequently, and thus better to loop the same code than inline copies of it. Also its AVX and especially AVX2 smarts are poor. At least, not a patch on its SSE2 usage. All that said, on recent Intel CPUs MSVC does tend to produce slower code. Microsoft know about this and are in the process of fixing it. But the cause is not failing to choose fat SIMD, it's more lack of powerful alias analysis and code reduction, plus it doesn't reorder as aggressively yet. Big improvements are coming soon.
I have not check that, yet. We use the Grisu2 algorithm to write floating-point numbers and a partly hand-written parser. As we target C++11, we would need to wrap this code into an API that makes it easy to use charconv's function if present. I'll check.
Except the whole compiling your code bit (vs just running the repl) And the whole initialization bit And the whole template errors bit (which you may hit since we're talking about using std::vector) And the whole headers bit And the whole declarations vs definitions bit And the whole references vs pointers vs smart pointers bit And the whole printing things bit (printf is error prone, cout is strange, and fmtlib isn't standard yet)
Sorry, just because I don't know, can you enlighten me what does "Intermediate C++ professor" means?
Nothing about Java or C#'s module systems ignores the hardware, and there are plenty of examples of languages in C++'s niche that have also solved this problem.
Those are not part of the module system nor do they need to be. Just use the same (or compatible) compiler for the whole system the way *you already have to*.
&gt; Nothing about Java or C#'s module systems ignores the hardware, Except the literal language themselves, Java and C# are both platform independent (well, C# for the most part is, there are raw pointers you can use, etc. but people rarely use them).
Interesting post, thanks; it had passed me by that explicit instantiation syntax is allowed to name private members. Your code requires the user to create a variable of the right type for the explicit instantiation to set. Reducing it to the essentials yields something like the code below, using a variable template `mps` to store a tuple of member-pointers and a `set_mps` template to set it as a side effect of explicit instantiation: [https://godbolt.org/z/\_OUBO0](https://godbolt.org/z/_OUBO0) #include &lt;tuple&gt; template &lt;class S&gt; inline auto mps = std::tuple{}; template &lt;class S, auto... mp&gt; inline bool set_mps = (mps&lt;S&gt; = std::tuple(mp...), true); class Prive { bool b; char c; }; template&lt;&gt; inline auto mps&lt;Prive&gt; = std::tuple&lt;bool Prive::*, char Prive::*&gt;{}; template bool set_mps&lt;Prive, &amp;Prive::b, &amp;Prive::c&gt;; Prive p{}; char&amp; c = p.*std::get&lt;1&gt;(mps&lt;Prive&gt;); // indirect access The two-phase initialisation disallows constexpr, or even const, so there's a run-time cost for the indirect access. Ideally it could be done in one, with the type auto deduced by the registration. Here's constexpr friendly code with a single 'registration' of the member pointers enabling `tie` access to private members: [https://godbolt.org/z/FrGNjh](https://godbolt.org/z/FrGNjh) usage: class Prive { bool b; char c; }; template struct reg&lt;Prive, &amp;Prive::b, &amp;Prive::c&gt;; int main() { Prive m{}; tie(m) = std::tuple{true,'c'}; auto [b,c] = tie(m); return b; }
 clock_t start = clock(); edit-&gt;setPlainText(stream.readAll()); clock_t end = clock(); This makes me a little suspicious. I'd suggest doing a readAll() into a variable, and then setPlainText from the variable, and report the times separately. Some subset of what you are measuring is the overhead of just reading the file and QString's overhead doing codec conversion, but I have no idea if that's significant or not.
&gt; ISO is not an acronym Heh, TIL.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9tepju/can_anyone_help_pls_i_cant_figure_out_why_every/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
re 1: /u/fp_weenie made a better response than I ever could. re 2: How does that work when what you literally ask for - is a very long and detailed typename, which makes it just as bad on tiny screens? re 3: Your example features`auto` as part of a *block scope* variable declaration. In *other* scopes, this data might appear to have a different name, and will be initialized differently, so I'm free to make naming choices for the local block of code, which is where this variable is defined. If row major order is the norm across the codebase, then specifying it is superfluous. If it is a surprise, then I expect it to appear in the function name, e.g. `auto jacobian = get_row_order_jacobian();`. &gt;substitute any similar type definition by auto and then try to understand what is happening... this is literally the first code I found: http://docs.pointclouds.org/trunk/ndt__2d_8hpp_source.html is this any harder than the original? void estimateParams (const PointCloud&amp; cloud, double min_covar_eigvalue_mult = 0.001) { auto v = Eigen::Vector2d::Zero (); auto m = Eigen::Matrix2d::Zero (); for (const auto pt : pt_indices_) { auto p = Eigen::Vector2d(cloud[pt].x, cloud[pt].y); v += p; m += p * p.transpose (); } n_ = pt_indices_.size (); if (n_ &gt;= min_n_) { mean_ = v / static_cast&lt;double&gt; (n_); // Using maximum likelihood estimation as in the original paper auto covar = (m - 2 * (v * mean_.transpose ())) / static_cast&lt;double&gt; (n_) + mean_ * mean_.transpose (); auto solver = Eigen::SelfAdjointEigenSolver&lt;Eigen::Matrix2d&gt;(covar); if (solver.eigenvalues()[0] &lt; min_covar_eigvalue_mult * solver.eigenvalues()[1]) { PCL_DEBUG ("[pcl::NormalDist::estimateParams] NDT normal fit: adjusting eigenvalue %f\n", solver.eigenvalues ()[0]); auto D = solver.eigenvalues ().asDiagonal (); auto Q = solver.eigenvectors (); // set minimum smallest eigenvalue: D (0,0) = D (1,1) * min_covar_eigvalue_mult; covar = Q * D * Q.transpose (); } covar_inv_ = covar.inverse (); } pt_indices_.clear (); }
Thanks for looking into it, and let me know if you find any issues. (The feature-test macro is coarse-grained, so it won't be defined until the feature is complete; you'll need to test `_MSVC_STL_UPDATE` in order to detect our partial implementation.) Grisu2 (unlike Grisu3) is apparently mathematically inexact, see [my analysis](https://www.reddit.com/r/cpp/comments/9fiko6/fmt_version_52_released_with_up_to_5x_speedups/e5xmve6/). I measured to_chars as being 70% to 90% faster than Grisu2. Our from_chars is 40% faster than our strtod/strtof, although I don't know how other CRTs/STLs will compare. The non-null-terminated nature may be especially convenient for JSON, although I'm not sure about the lack of whitespace reading.
We have to be a bit skeptical about modules. These things need to be logical and feature complete. What is the point to have a module if it’s yet another header file!
I mean, it depends on what the focus and context of the class is. If it's programming 101, which happens to be using C++, then of course you should not be restricted from using STL. On the other hand, if you're learning C/C++ as part of a systems programming/data structures+algorithms/operating systems class within a CS course, to complement programming 101 (which in all likelihood will be through Python or Java), then restricting the use of STL, at least initially, is perfectly reasonable.
I mean, it depends on what the focus and context of the class is. If it's programming 101, which happens to be using C++, then of course you should not be restricted from using STL. On the other hand, if you're learning C/C++ as part of a systems programming/data structures+algorithms/operating systems class within a CS course, to complement programming 101 (which in all likelihood will be through Python or Java), then restricting the use of STL, at least initially, is perfectly reasonable.
I like what sqlite does. It provides an amalgamation of it's sources so all you do is compile the 1 c file. I just want that really for all libraries .
Interesting, you by accident picked the best counter example. For example the auto covar = ... is most definitely not the type you would expect. It is actually a lazily evaluated proxy object and eigen explicitly warns against using auto this way.
&gt; Yeah I know but you have to actually run cmake, and the result only tells you if the build description is valid for the current configuration. To be fair, that's orthogonal from being static typed. There are editors that can give good error information about Python without running it, and editors that can't give you good error information without trying to compile it. The issue there isn't really a matter of static vs. dynamic typing. It's about having a syntax that can be checked. I think you are partially barking up the wrong tree, but maybe static types aren't a bad idea for a build system. But the thing is that you don't necessarily need a very complicated or expressive type system in a build script language because the domain is intentionally quite narrow. Designing a build scripting language that more elegantly expresses all build configurations, and makes it easy to see what they are doing, and has a well defined syntax that is easy to validate is all probably a good thing. Have you played with QBS at all? It recently got sort of deprecated because nobody was using it, but in some ways it does what you want. It's got javascript embedded in it, so it's still dynamically typed. But the scopes themselves are types. It's based on QML, so it's a little weird if you haven't seen it before: http://doc.qt.io/qbs/howtos.html#how-do-i-apply-c-c-preprocessor-macros-to-only-a-subset-of-the-files-in-my-product The things like "Product," "Depends," and "Group" are all effectively statically typed scopes that are straightforward to validate.
Maybe exaggerated for the drama, but tooling varies a lot and in open source projects / unpaid work I don't bother hunting bugs the CI can't find because someone thought alignment or storage is an "Implementation Detail".
"How does typing out a very long and detailed type name (which makes it just as bad on tiny screens) solve anything?" It documents expected type and is checked for violations by the compiler. If after every auto = ... there is a static_assert(std::is_same(...)) I'm perfectly fine with that :)
Do you mean that you have some macros that transparently capital-M-Modularize your libraries, or that you have some other scheme that achieves the same effect as "mergeable precompileds", or something else?
 #define arg(X) std::get&lt;X&gt;(std::forward_as_tuple(decltype(args)(args)...)) #define RETURNS(...) \ noexcept(noexcept(__VA_ARGS__)) \ -&gt;decltype(__VA_ARGS__) \ { return __VA_ARGS__; } #define TL(...) (auto&amp;&amp;...args) RETURNS(__VA_ARGS__) then [] TL( arg(0) + arg(1) ) is noexcept, SFINAE friendly and has zero dependencies. 
So you propose modules as a means to add indirection and kill performance (main reason why *many* if not *most* users choose C++)?.
Just google "tayrona giveaway" and thank me later.
[GitHub repo](https://github.com/Quincunx271/TerseLambda)
True, but I don't like the `arg` macro. It'd really have to be something like `tl_arg`, which makes it more verbose and ugly: `[] TL(tl_arg(0) + tl_arg(1))`.
[GitHub repo](https://github.com/Quincunx271/TerseLambda). I did not remove the dependency on Boost.PP because other macros depend on it.
Unless I'm mistaken, the link seems to be discussing Symbolic Differentiation, rather than Automatic Differentiation, both of which are very different techniques.
&gt; the module declaration and definitions are in a single standalone file that has nothing else in it This reminded me of linker scripts and Windows DLL module definition files. Nice.
&gt; this is what Rust is moving to Could you elaborate on this or point to some further reading?
Yes, that makes sense (and is pretty much how `build2` does it for C++ modules). Thanks for digging this up.
Today, Rust actually already specifies dependencies in two places: in `Cargo.toml` (an easily-parsed external list that is converted to compiler command-line arguments by the build system), and via `extern crate` statements in the source (like C++ `import`s). In the 2018 edition, the `extern crate` statements are no longer used, because the dependencies' names are injected into the root namespace. This is part of a collection of tweaks to that namespace hierarchy, which is mostly unrelated to this discussion, but here's the documentation: https://rust-lang-nursery.github.io/edition-guide/rust-2018/module-system/path-clarity.html
 it's coz ie you cant do proper align after this stuff. stack deployment goes straight to .obj/.o file.
I'm saying that right now, by far the easiest way of implementing Modules is using preprocessor macros and the preprocessor to do so. It does leave much of the supposed point of Modules on the table, but I don't think most end users will care. They just want build performance improvements, and that mechanism gets them that.
&gt; On the other hand, if you're learning C/C++ as part of a systems programming/data structures+algorithms/operating systems class within a CS course, to complement programming 101 (which in all likelihood will be through Python or Java), then restricting the use of STL, at least initially, is perfectly reasonable. Then you are not "learning c++" you are using c (maybe with classes) to demonstrate how certain things work. Nothing wrong with that. However, the original post was about "My Intermediate C++ professor". That doesn't sound like an OS class. Also, even in an algorithm and data structure class you should not restrict the use if the standard library more than absolutely necessary. E.g. if the task is to implement a linked list you wouldn't allow a std::list, but beyond that I don't see any reason to restrict the toolkit. What is even more: If the task is to implement an algorithm and the student sees that it can do this in terms of a different one from the stl toolkit (as long as it is as efficient as possible), I'd be very happy about that.
"Thank you for helping the compiler help you help us all."
`pkg-config`'s `.pc` files have some limitations for some workflows, that are discussed in the [What’s wrong with pkg-config?](https://mwoehlke.github.io/cps/history.html#what-s-wrong-with-pkg-config) section of the specification.
Thanks for the interesting link. I wonder if the authors of the two proposals are aware of each other's work. 
&gt;So now the question is - Last commit May 2017, no Stars on GitHub. Is this project dead? What's happening to it? A couple of CMake people seem to be at least partially behind it so one could have great hopes... &gt; &gt;Someone behind CPS should probably start by allowing CMake to generate and consume cps files? A paper on this was submitted this October ( [http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1313r0.html](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1313r0.html) ) and explicitly mentions cps : &gt;That being said, following a discussion at the 2016 Jacksonville meeting, work began on a Common Package Specification with the aim of providing a satisfactory alternative to existing mechanisms. The Common Package Specification was carefully developed based on lessons learned by CMake and has met with some positive reception already. We feel that CPS may be a viable solution, but it needs wider exposure and a functional implementation. In particular, it would benefit greatly from sponsorship willing to contribute to its further development.
C++ has been perl for a long time now.
&gt; I would love the industry to drop all meta build systems on the floor and move on. that won't happen, ever. Most of the people I've worked with always had a hard requirement on "I want to be able to use IDE x/y/z".
I don't think you understand how those languages work if you think platform independence is a bad thing. Being able to use pointers in the language is in no way related to hardware either.
&gt; However, there are solutions for that. Are you familiar with the language server protocol? Imagine the same thing for build systems. these solutions don't exist today. In practice, as of november 2018, if you want to be able to use : - Visual Studio proper - Xcode - QtC on a single C++ project, without writing three build systems, what are your choices ? 
learn windows programming , not linux. I can say linux is far away from it.Also yeah learn cashe friendly stuff (ie how to make structure alignment so its members'll be hooked up by cpu cashe line). Also very good stuff almost no-one use(only known github project i've seen is opencv) is SSE/AVX intrinsics .
That sounds great in principle. A paper is a good start. But as it rightly notes (and you quote)... &gt; We feel that CPS may be a viable solution, but it needs wider exposure and a functional implementation. In particular, it would benefit greatly from sponsorship willing to contribute to its further development. It's a shame that KitWare themselves haven't pushed it further. If they had implemented it in CMake in 2017, it could've been widely available already today and probably people would try it and there would already be practical experience with it. I really do hope someone sponsors this, I'm sure as soon as it gets into CMake, others like meson and build2 would follow, as well as probably package managers like conan. It would be awesome!
You talk as if ABI-stability was a goal when in fact the paper from Gabriel Dos Reis mentioned specifically about the fact that modules in C++ should *not* be an indirection layer of any kind. ABI-stability can be accomplished in C++ today and can be improved, but I do not think modules should be that by default. It would be a violation of paying extra overhead when you did not ask for it, hence violating C++ you do not pay for what you do not use. People would choose something else over modules to keep performance, one of the reasons, if not the number one in the list, why people use C++ today.
Looks great, but you know there is nanoui right?
However, it is slightly amusing that MSVC generates three very different sequences of instructions for each of the examples, where Clang and GCC both generate the same code in each of the three cases. I think it's fair to ask why this is the case, and which of the three options might be the most efficient one. While the rationale to avoid inlining is likely valid in some cases, I'd wonder if the call-sequence to memcpy doesn't result in similar amounts of µops as the fixed-size sequence for zeroing out memory that we also see in this example.
&gt;Integrates into every build system I've ever used "Integrates into every build system I've ever used" To me that's just a sign of a fucked up design. Cause package management and build systems are the two completely orthogonal concepts.
I thought it was something like that, thanks for clarifying.
Please do. Cause all presently available package managers (incl. Conan, vcpkg, etc) ~~suck~~ have serious design issues. Cget looks like properly thought out, but is not developed to its full potential and lacks some important features. Maybe yours will be more lucky.
There no letters in my alphabet after C.
c++ community has been discussing this for decades. It's very hard for people to come to an agreement for a language that is used in so many different ways.
I'm not saying any specific compiler does that. All I did was ask if such behaviour was technically legal, as per C99 or C11 standards.
What about imgui?
`arg` is a macro which risks collisions, `_1` is scoped to the body of the lambda. 
I can suggest then Mesa, Mesa/Cedar, Object Pascal, Delphi, Oberon and its variants, Modula-3, Ada, D, Swift, .... As languages with module systems, that traditionally compile to native code and do care about the hardware below them.
At least vector-of-bool is aware. And I'm certain everyone will be aware by this time next week. Since we will be discussing CPS and libman in the WG21 meeting next week.
The way I see it, as someone that moved into other stacks but still follows C++ with deep interest, those multinationals will then keep using C++ while everyone else will slowly adopt other languages that are good enough for their use case. 
 I was required to read this book for my introductory programming course as a Computer Engineering major. I found it challenging to thoroughly read its \~1050+ pages within the span of a semester, but in the end very rewarding. As far as it covers basic principles for newbies in programming, it can’t be outdated. It doesn’t refer to any time. It's just one of the “must read” books for any C++ developer. It's like a C++ Bible. 
Will take a look, thanks for the link!
Let's start with SIMD first, most intrinsics cannot be used inside `constexpr`. . .
I thought I had answered that. It shouldn't be legal for a compiler to do it. You see, there can be cases when you need to declare from 20 to 30 variables and have them in the stack. In that case the compiler shouldn't interfere and change the vla to heap allocated array.
I for one have no problem with COBOL 2.0.
**Company:** [Optiver Europe](https://www.optiver.com/) **Type:** Full time, Summer Internships **Description:** At Optiver, a leading global electronic market maker, we trade and provide the most up-to-date and competitive prices on over 50 exchanges globally. We operate our business on in-house built technology. Our infrastructure is a combination of vastly distributed systems, with high-performance computing and low-latency trading algorithms on one hand and high-throughput dataflows, huge storage and data analysis on the other. To be successful, we constantly need the most advanced solutions – we evolve our systems on a daily basis. Working in tech at Optiver is: * Solving challenging business problems * Close collaboration across the teams * Daily releases and immediate results * Ownership of the full stack of applications * Working with simple, reliable and well-architected systems * Having a system-wide understanding * Taking a pragmatic approach * Writing clean code \****Jobs @ Optiver***\* We have opportunities at any level in your career! From graduate to years of experience. We are looking for exceptional engineers, who favour simple solutions for complex problems and have a passion for clean code and good architecture. Knowledge of financial systems is not required. * [Software Developer](https://www.optiver.com/eu/en/job-opportunities/eu-1206128?gh_jid=1206128&amp;gh_src=d0gtnc1) * [Application Engineer](https://www.optiver.com/eu/en/job-opportunities/eu-1207954) * [Graduate Software Developer](https://www.optiver.com/eu/en/job-opportunities/eu-510831?gh_jid=510831&amp;gh_src=6c0pe11) * [And more](https://www.optiver.com/eu/en/job-opportunities/all/Technology/Amsterdam/) **Location:** Amsterdam, Netherlands **Visa Sponsorship:** Yes **Remote:** No **Technologies:** C++14 on Linux, next to that C#, Python and Lua and FPGAs also form part of our technology stack. Want to learn more? Watch [this video](https://www.youtube.com/watch?v=z5AAA3_iBTU&amp;t=169s) on Low-latency Linux during the DevOps Amsterdam Meetup 2018. Although optimization is important, it's not the only thing to do and certainly not a must! Are you a student and would you like to learn how to write the fastest and best performing code possible? Join our [low-latency Masterclass](https://www.optiver.com/eu/en/events/low-latency-masterclass-2018) in Amsterdam on 6 and 7 December 2018 ! **Contact:** Please e-mail Jinre van der Veen or Patrycja Ostrowska at [recruitment@optiver.com](mailto:recruitment@optiver.com) for any questions.
You have this same problem with large but known size arrays at compile time too.
How is this different from putting a large but known sized array on the stack?
It's more than just efficiency. One of the really powerful things about automatic differentiation is that it works with not only standard math functions, but also control flow such as loops and branches. For example the function double f(double x) { double result = x; while(abs(result) &gt; .1) result = sin(result*4); return result; } has no reasonable symbolic derivative as the number of iterations is not known ahead of time, but AD calculates the derivative with only constant factor overhead.
why not `2^16 - 1`?
I watched this a few weeks ago. It's pretty good. He told about how he struggles as a parent. I have a similar problem today with my cat.
Because OP just did not understand that "it works for me" != "allowed in C++"
I see, thanks for clarifying!
I guess you also need to know exactly the maximum number of items you'll be inserting in the container, so you can allocate the correct size buffer in advance.
i usually start my metaprogramming with a "first, rest..." approach to get the idea into a working implementation and then i change what i can to be constexpr computations and pattern matching to reduce recursion. The book Modern C++ Design by Andrei Alexandrescu got me started and gave me a fundamental undertanding of metaprogramming.
If being really pedantic, you're right about the naming, but it is a familiar convention and that's more important than being 100% specific. I agree about value types, and in those cases I tend to just use structs unless there is some processing required. For example if there needs to be type conversion performed in a specific way, then getters and setters are useful. A specific case I often use is in embedded work where I am doing most of my calculations as floats, but data storage is in uint16's. Then for convenience a value type may have a SetXFromFloat() function that would handle the conversion math.
Hearing this just makes me think modules should be dropped for 20 and go to 23. 
I get what you're saying, but IMO tradition is not a very good reason for continuing to do something incorrectly. Note: I'm not making a judgement call right here on whether getters and setters should be used. Rather, I think it's a good idea to revisit assumptions with from time to time and see if there is new information that leads to a different conclusion. And what's more important than naming anyway? ;)
Isn't the best solution (but one that you, as the build tool developer, one that you cannot make happen) for the compiler itself to have a special "give me the imports of this file" mode? There is no more definitive way to preprocess and lex than that. That way your build tool can call the compiler in that special mode to get the module information, and again in normal mode later. I can see three problems with this idea: * Compiler vendors have to cooperate and produce said compilation mode. * Well, someone's got to do it. * This means that every file has to be parsed twice. * This seems like a fundamental problem with the modules proposal as it stands. * It seems almost impossible to implement such a mode, where a file is parsed before its modules are available. * For example, what if a file does `import foo; export [function using bits of foo]; import bar;`. How can the parser get through the bits depending on foo when it's not available? I guess counting brackets and braces might be enough, but this would be a massive change from the regular parsing situation. * Again, this seems like a fundamental problem of modules, and a rather more serious one. 
I didn't know. Thanks for sharing info!
Thanks for the response! To understand better: does the fmt library contain the same or a similar to_chars method like &lt;charconv&gt;?
first, rest... is murder on compilation times for complex situations.
There's not much to review so I'm not too sure what the expectation is but the little you do have available contains errors. For example you have the following example in your min,max section: auto pairInt= std::minmax(2011, 2014); ... cout &lt;&lt; pairInt.first &lt;&lt; ", " &lt;&lt; pairInt.second &lt;&lt; "\n"; This is undefined behavior. `std::minmax` returns an `std::pair&lt;const T&amp;, const T&amp;&gt;`, basically it returns a pair of references. Those references are the parameters you supply to the function. Unfortunately in almost all your examples you are passing in rvalues to these functions meaning that your return value contains dangling references. This is a very unfortunately consequence of C++'s poor and error-prone API, and I would actually suggest that since you yourself made this mistake, that perhaps you should devote a section in your course on how to avoid these problems.
You're going to make us sign up to look at the previews? For real? I don't think it's fair to ask users to agree to your terms of service just to help you out with their opinion. You should post a sample video on youtube or something. The unique pointers video would be best.
I think a fixed size array also works: struct Point { int x, y; } struct Simplex_Storage(int N) { // N: 1 =&gt; 2P = 2P // N: 2 =&gt; 2P + 3P = 5P // N: 3 =&gt; 2P + 3P + 4P = 9P // N: 4 =&gt; 2P + 3P + 4P + 5P = 14P // N: 5 =&gt; 2P + 3P + 4P + 5P + 6P = 20P // ... // N: X =&gt; X*(X+3)/2 Point[N*(N+3)/2] points; // 'Point[]' is a slice / span of 'Point's, say 'struct Slice(T) { T* ptr; int len; }' // Point[] get_simplex(int simplex_index) { int n = simplex_index; assert(0 &lt;= n &amp;&amp; n &lt; N); int start = n*(n + 3)/2; int end = (n+1)*((n+1)+3)/2; return points[start .. end]; } } void main() { Simplex_Storage!(5) ss; for (s32 n = 0; n &lt; 5; n += 1) { Point[] s = ss.get_simplex(n); printf("simplex[%d] has %d points\n", n, s.length); } // output: // simplex[0] has 2 points // simplex[1] has 3 points // simplex[2] has 4 points // simplex[3] has 5 points // simplex[4] has 6 points } 
According to my understanding (I haven't performed head-to-head benchmarks yet), fmt is considerably faster than my fairly naive implementation of to_chars for integers (improving this is on my todo list), but for floating-point fmt is currently significantly slower than Ulf Adams' Ryu algorithm which powers to_chars in MSVC. If you're asking about interface, I haven't looked at fmt's documentation, but I'm virtually certain that they can be adapted to a single interface (to_chars just writes into a [first, last) buffer and returns info about what it did).
Not so sure about that. Obviously, "It depends" is always a correct and very often useless answer that everybody can agree on. However, a) this thread and my rant was about a c++ course and in that context I don't see any valid reason to "save standard library types for later". And b) as I said, even in a algorithms or data structure course I wouldn't restrict the use of library types beyond what is absolutely necessary. I would understand it in an OS or embedded systems course, but in that case new usually isn't the right choice either. 
Steve is one of my favourite speakers - always loads of humour and entertainment, yet informative at the same time.
... In Tel-Aviv. Bummer. :-|
I made it 2 seconds into your animation...care to tell us more, with words?
Sorry, I meant in the more general sense and not the specific case of vector. Basically, do automatically generated operators that use the the spaceship operator have a performance impact? If so, what is it?
2 days, 2 tracks. One pre-conf training day. One half-day post-conf activities: TBA. Call for Speakers is already open. Ticket purchase: soon. Call for Sponsors: very soon. Content: Most Things C++. What else would you like to know?
Different geographical area. Yes. In TLV. Otherwise striving for the same higher quality content and great speakers as CppCon and other international C++ conferences. 
Will there be a theme?
CFront? 
Oh, nice!
Jan. 15. 
I think "stack space is small" is the main concern here. [Windows sets the stack for threads is 1MB](https://docs.microsoft.com/en-us/windows/desktop/procthread/thread-stack-size). My Linux box "ulimit -s" outputs a 8MB stack size by default.
The Precompileds part of the proposal is ready for 20 no doubt.
MSVC is a really weird compiler in terms of architecture. Historically it basically parses tokens and spits out opcodes, and there are various front-to-back optimisation stages which do transforms to make that more optimal. It's more a bunch of hand coded heuristics than anything methodological. However of late MSVC has gained at least a partial AST, and a more formal and conventional back end. So expect it to become much more like clang or GCC in the near future.
Where I want to get to is that you can specify your components with very hard ABI boundaries, and you get all those benefits in terms of very large code base scale management, and that the optimiser can *see through* all that to generate you an optimal binary with no overhead. That's not what we are doing. That is what we should be doing, in my opinion. I think Modules as currently presented has some value, but it's solving the wrong problem. It'll be a net benefit, but it could have been better focused.
It's complicated, personal, and 100% unrelated to C++, but... I've got issues with Israel foreign policy, and won't support activities in Israel (commercial or otherwise) in any shape or form. I'll just leave it at that.
Very excited to see this announced, and proud to be involved. This is going to be a great conference!
Ahh. I think our politics don't align, at least in that I support Israel. But most of all, I support your right to your own beliefs and opinions. Good on your for sticking to your convictions! 
Ah, good point. We can fix that by sacrificing noexcept/sfinae. #define TL(...) \ (auto&amp;&amp;...args) -&gt; decltype(auto) { \ auto arg=[&amp;](auto i)-&gt;decltype(auto){ \ return std::get&lt;decltype(i)::value&gt;( \ std::forward_as_tuple( decltype(args)(args)... \ ); \ return __VA_ARGS__; \ } template&lt;auto x&gt; std::integral_constant&lt;std::decay_t&lt;decltype(x)&gt;, x&gt; c{}; now we can do: [&amp;] TL( arg(c&lt;0&gt;) + arg(c&lt;1&gt;) ) Haven't quite worked out how to do it with sfinae.
Submitted a talk! Hopefully they can fund my travel :)
we built an in-house interface/wrapper around rapidjson that is very similiar to your library to make it easier for developers to use. For us the scalability of rapidjson across devs hasn't worked well and since it is so C like mistakes used to happen a lot. At some point we might switch over to your lib so we don't have to maintain it, but that will take some time. We do have some critical paths that use raw rapidjson still where it needs to be _really_ fast but most use cases an cleaner/easier to use API I think is the way to go considering its still quite fast
Was thinking the same thing. It's natural for beginners to C++ to assume that if the compiler can compile it - especially by default - then it must be valid C++. I remember the days of discovering what I thought might be valid C++ by trying to see if it compiled and ran.
Did you ever go through Israeli Airport Security and Customs? If you had you, would not like to do that, ever, again.
The spaceship operator hasn't been implemented yet, so there's no data on it specifically. Of course, it behaves like any other function, so one could manually write out a 3-way comparison function and measure then. In fact, if you consider what the automatically generated spaceship operator's code will look like, you can get a pretty good idea of the performance impact. For comparisons which have to traverse the entire collection anyway, there should be no measurable performance impact. There could perhaps be a couple more instructions executed, but those instructions would be fast instructions and negligible when compared to the rest.
Why not reject it and ask the author to repost it as a link?
He started this talk off with way too many qualifiers. Wish he just started talking instead of telling us it was going to be bad.
 #include &lt;random&gt; #include &lt;mercy&gt;
For the grammar considered in the example they are very similar. Anyway yes, I should have written symbolic differentiation.
Your scrollbar handles are very small, indicating that you can scroll many pages, which is not the cast. To some extent, the handle size should reflect the true proportions.
What you are describing ressemble much the Copy-on-write pattern; you can find plenty of implementations.
&gt; we often need both unique and shared ownership of an object. To achieve this, is both inefficient and awkward - shared_ptr of a std::string and unique_ptr of a QImage for example. I don't see anything awkward about those "wrapper" classes: the whole point is that `string`, `QImage` and other classes do not need to care how unique/shared ownership mechanics are implemented. As for inefficient, I am unsure what you mean. For instance, what are those deep copies you talk about? Where do they happen? It would be nice to see the original code you are trying to improve, to understand what you are trying to do. &gt; What if we separate the object in two parts - one fixed and one varying. The fixed is trivial and acts as a view to the object, the varying part deals exclusively with lifetime management and is never used without the trivial part. But isn't that precisely `unique_ptr` and `shared_ptr`? If you want to wrap them into your own class, that is fine and is common, to create a movable value handler class, for instance.
Try this: .highlighter-rouge { overflow-x: auto; } This will make the code blocks horizontally scrollable, but only if the code is wider than the block. Works on chrome.
i do not understand 'view' concept you're talkin about. if current std::string is in working condition &amp;str[0] would work too.
&gt; While C++ is rooted in C, it is not a pure extension thereof, and C++ does not "rebase" itself onto newer C standards. Actually, it *does*. Check [intro.refs] of the several C++ standards. That does not mean everything from C is imported, of course. 
I hate that I cannot std::stoi a string_view. 
you can use more efficient std::from_chars
I don't believe it is up yet.
&gt; What is awkward about those "wrapper" classes? Personally, I find the double indirection awkward. Rather than `std::shared_ptr&lt;std::string&gt;`, I'd prefer either: - a `std::shared_ptr&lt;vstring&gt;` where `struct vstring { size_t size; size_t capacity; char[] data; };`. - or a `std::string&lt;shared&gt;` where ownership is parametric. In order to avoid bouncing all over memory. Unfortunately, both are also relatively awkward, so... *shrug*
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9tu32n/hi_can_anyone_help_me_code_a_c_to_display_a/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
string view is gross. I understand why we have it but it's still a sorry state of affairs. like yes maybe it does good... but we went from two kinds of strings to three
CoW entangles what the object is semantically with how is lifetime managed - it is intrusive. It also does not let us reason about lifetime when reading code - when the object will be freed is obscured. 
?????????????? why would you make a struct with the same stuff as string? you want to reimplement string? also you have indirection anyway. every time you pass a string but reference or pointer for example
 Great, will the videos be published?
Yes. That is certainly the intent. 
Follow up: I created an issue to track experiments: https://github.com/nlohmann/json/issues/1334
&gt; Personally, I find the double indirection awkward. Which double indirection? OP's solution also has a double indirection (the pointer to the actual memory, and the pointer to the object containing that pointer). If you are referring to your flexible array member solution, that is orthogonal to using `shared_ptr` or not.
Well, if we had had `string_view` since the beginning, yes; you could have made `string` have a member returning a `string_view` to access the data. Still, it would be painful to always call that member function. In general, I don't mind providing more interfaces in library code if that makes them more ergonomic to use.
I think that having string be a subclass of string_view might have been a viable option. No need to always call a member function then.
From a messaging/serialization point of view, I like string\_view. If a string is part of a message, you can access it with a string\_view. Doing that with char\* required embedding a null into the stream and threw away the length info. [https://github.com/Ebenezer-group/onwards](https://github.com/Ebenezer-group/onwards/graphs/traffic)
The website already has numbers about attendees and speakers. Where do those come from if they conference was only just announced and the submission deadline is not over yet?
I'm fairly certain that the C++ standard document references the latest versions of the C document because of ISO rules. The C++ standard must always reference latest C standard at time of publication, even if absolutely nothing else about the standard has changed as pertaining to C. :) C++ does of course import bits of C here and there, but only in minimal ways and generally only were its deemed especially important to inter-operability (e.g., stuff you'd find in C library headers). C11 and C++17 are far more different from each other than C++03 and C89 ever were, despite some of the C99 stuff that was imported into C++, and that gap is only going to get bigger with time. C++ has and will continue to diverge in feature set or at least in the specifics of syntax/grammar. Examples include `void*` implicit casts, `restrict`, VLAs, fully-featured designated initializers, C99 generic selection, a variety of headers, new `_BuiltIn` types, etc. C++ might get some of those, but possibly with tweaked syntax or different features (e.g. incoming C++ designated initializer syntax is a subset of that from C99, and we are sticking to new `std` types and appropriate headers in place of things like C11's `_Atomic` specifier and associated headers).
Great thanks.
&gt; Which double indirection? OP's solution also has a double indirection (the pointer to the actual memory, and the pointer to the object containing that pointer). Yes, and that is awkward, from a memory access point of view. Of course, as soon as possible you should dereference the owning pointer, ending up passing the "view" only, which cuts down to a single indirection.
Will there be something like this -- [https://cppcon.org/tooltime/](https://cppcon.org/tooltime/) ? If things go well with my on-line code generation efforts, I would like to have a data center in Israel in part because it's on the opposite side of the world from my location in the US. &amp;#x200B;
The point is not the differences between C and C++ (which are obviously different languages), but the fact that C++ picks features from newer C standards and references the relevant standard in order to do so. Also note that there is a set of features that converge: someone reading your comment may think C and C++ are meant to diverge and be totally unrelated languages, which isn't really true. Both C and C++ go quite hand in hand with each other.
I haven't been able to find a group in WI (Madison), so you might be the closest. When were you thinking of starting?
You could use std::transform, an inserter and a lambda but out of interest what's wrong with a good old for loop? struct Item { int id; int value; }; int main() { std::vector&lt;Item&gt; itemList { {1,2},{2,4},{3,6} }; std::unordered_map&lt;int,Item&gt; myMap; std::transform( begin(itemList), end(itemList), std::inserter(myMap,end(myMap)), [](const Item&amp; i) { return std::make_pair(i.id, i); } ); for( auto &amp;i : myMap ) std::cout &lt;&lt; i.first &lt;&lt; ", " &lt;&lt; i.second.value &lt;&lt; std::endl; return 0; }
You may wanna read about the motivation behind gsl::span / std::string\_view and upcoming std::span in c++20
Yeah, GCC/libstdc++ and Clang/libc++ don't have floating-point to_chars yet. Upstream Ryu differs in formatting style (charconv/printf use lowercase 'e', always '+', and at least two exponent digits) but if you can live with that and don't need bounds-checking then you can use it directly.
Yeah, GCC/libstdc++ and Clang/libc++ don't have floating-point to_chars yet. Upstream Ryu differs in formatting style (charconv/printf use lowercase 'e', always '+', and at least two exponent digits) but if you can live with that and don't need bounds-checking then you can use it directly.
You could also use a bit more unknown feature, called transparent comparator. Then you could use an unordered_set instead of map and didn't have to store the key/ID separately. You could simply initialize the set by calling the set constructor which takes a begin/end iterator.
Are you a member of our meetup at https://www.meetup.com/TwinCities-C-Meetup/ ? We were meeting once a month for a while, but we haven't gotten our act together lately, no thanks to me. We've typically attracted around 8-10 people but we didn't advertise seriously outside of Meetup. Note that the current broad-encompassing name was in an attempt to attract more interest/material; I think all but two of our presentations have been about C++.
Cow is to be used with **Value Types**, in which case the time when the object is freed, has no importance. I don't understand what you mean with "entangles what the object is semantically"
Your string class is wrong. Any object with its size unknown at compile time must contain a pointer to a part of memory on heap, otherwise you are risking overflowing your stack, so you will always have double indirections, at least before the compiler do any optimization. (The compiler should be able to optimize away some small mallocs.)
you don't actually need to use a map for this, you can just use a set because the object itself is the key (or part of it is). Just write your comparator so that it only compares IDs and you're done.
I need a hash table to search for a key at runtime
I want sure if the for lip is the fastest way to add items to my map. Was really hoping for a compile-time solution since all data is constant
unordered set is a hash table and you can perform key lookup with find. It just doesn't have the overloaded operator[]
It seems to me that making the filename consistent with the module name is a no-brainer considering all the build and readability advantages and the experience from other languages. Why wasn't it done in the first place?
[removed]
The previous organizer was good about organizing sessions and getting people to present, but he moved to California. That might be why. None of the rest of us really wanted to take charge and keep things going. If you want to organize something, I think there would be interest.
&gt;you don't actually need to use a map for this, you can just use a set because the object itself is the key (or part of it is). How have I never realized this before. I have some code to refactor now. 
This sounds good. I'm fairly new to C++, coming from C. There's so many options in the standard library it's hard to know where to start. Thank you.
Delete this and pay attention in class next time
You could decompose the item in the map: struct PartialItem { int value; // id isn't there }; std::unordered_map&lt;int, PartialItem&gt; items; The key of the map is the id in your struct. The map stores pairs containing both the value and the key together in one struct, making it somewhat equivalent to a standalone `Item` struct. 
Thanks, will play around with getline
Somebody else used their time and energy to be useful, you can delete this comment now. 
Delete this and pay attention in class next time
No one would have to use their time and energy if you could read your text book and learn literally the first lesson of a cs101 course without having to ask world class domain experts to hold your hand.
I was thinking more of the extraction operator, since you know the format your data will appear in.
A better place for this would have been /r/cpp_quetions. That link is good if you want to use the standard library and streams. As with anything in C++ there are multiple ways to do anything, On win32 for example you can use ReadFile() to read the contents of the file into memory that you have allocated and just work with the file contents in memory directly. 
This video was of surprisingly high quality.
std::string / std::stringstream is enough. for out-of-scope in multithread - weak_ptr shared_ptr
&gt; My final, and hardest to write part, is the new memory and object model for C++ to tie the whole thing together. Why do you need a new memory model for that? 
Also, as noted in another comment, the right place for this would be r/cpp_questions. r/cpp is "Discussions, articles, and news about the C++ programming language or programming in C++".
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9u0sm0/how_to_read_in_data_from_a_txt_file/e90plqa/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
louis dionne was a turning point for me: https://youtu.be/X_p9X5RzBJE
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
You won't be able to mutate items in the set though, since sets enforce constness. Only erase and reinsert.
Variable sized arrays as members of structs, a GCC extetention. Allows for variably sized classes. there is also the method of allocating a large char array, and then using placement new on it to create your class. Anything after sizeof(class) would be your variable length storage. Stack allocations can technically be done with alloca, though that has the problems of possibly overrunning the stack, as you point out.
Unfortunately `std::unordered_set` does not support heterogeneous lookup, which means you must create an `Item` object to perform lookup. ([P0919](https://wg21.link/p0919) aims to address that.)
Yes CoW can model value types, but hides lifetime. Sometimes is not important, but sometimes it is when the resources are big or important like a foreign handle - you need to know what is keeping the object alive. It is miles easer with unique ownership, yet often shared is needed. It is best to be able to do both easily and with no overhead. As for entanglement - the object is no longer single responsibility - it has to do its business logic (semantics, be an image or a string) *and* do "system logic" to manage memory. 
Source code?
This doesn't really belong here. Try r/proceduralgeneration instead.
It's not finished yet. I must optimize it, make the algorithm better.
I enjoyed this video, cool !
In a good implementation such as: https://github.com/stlab/libraries/blob/develop/stlab/copy_on_write.hpp there is no entanglement as you say, because memory management is independent from the value type (it is embedded in the smart pointer) Hence SRP is preserved. 
I think you are abstracting at the wrong spot. Look at function_view, function, moveonly_function and shared_function, theoretical (yet obvious) set of variations of std function. This splitting of functionality from value category is not isolated to 'buffers of data'. On top of that, your buffer of data abstraction makes one pay for things they aren't using; the pointer-to-data in base gets replicated in most derived. These types need not be related in a class heirachy; C++ is not an OO language. Instead they just need to be efficiently convertible between: unique converts to shared, everything to view.
There is no free lunch - note that you can't use the object directly. That aside, this will not help you eliminate inefficiencies - it is much closer to shared_ptr&lt;std::string&gt; then to, for example QString. QString allocates only once, for the buffer, this, much like shared_pointer, must allocate twice once for the control block ('model' here) and once for the buffer (inside std::string). When you talked about CoW, I assumed the QString model because this is the only model that is efficient, does not have a pointer interface, at the price ref counting being deeply embedded.
You might be able to piece something together using `constexpr`. 
I think my favorite one is: `std::array&lt;int,10&gt;` as it is similar to `int[10]` but provides a few more features. &amp;#x200B;
I think you did not look closely enough to the class I pointed out (from Adobe, btw). Look at "struct model": it embeds **both** the value-type and the reference counter. This means, from the memory handling, this is exactly like QString: a pointer to a block that contains both the reference counter and the "useful" data. This is not like shared_ptr, that has a separate control block by default. stlab::copy_on_write is a well designed and elegant smart pointer class imo. 
Is there an advantage to those living in Boston area
I doesn't, he just provided an example of the many strengths of C++.
No, man, you will *always* have two allocations, if you use this to implement a class of variable size. * First allocation is for the model itself (look the constructors) * Second allocation is for the data itself, because it is varying it can't be placed inside some T of fixed size - it will have to be in yet another wrapper (like std::string). This is not the case with QString as it allocates a varying buffer and has the ref part of the class. The model, presented in the post has the advantage that not only never does extra allocations, it also can have different lifetime schemes - owning, shared, but why not non-allocating - a subclass that has a big-enough internal buffer for some number of chars. 
You amazing human, thank you!
If it's all constexpr, check out [frozen](https://github.com/serge-sans-paille/frozen)
Since `operator -&gt;*` is overloadable as a free function, you can define this without any customization to `std::tuple`: tup-&gt;*2_i
At that point I'd rather be using `std::get&lt;&gt;()`; `operator-&gt;*` is just too much of an oddball IMO. It's unfortunate that `operator[]` and `operator()` are restricted to member-function-only overloads.
From the sidebar: &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. 
To access tuple elements, structured bindings are the best IMO. For variant, I used to add member functions `is` and `as` in my implementation: if(myVar.is&lt;int&gt;()) { int i = myVar.as&lt;int&gt;(); } &amp;#x200B;
Structured bindings are great, but they force you to introduce a name into the current scope for each element of the tuple. If all I want to do is use the Ith element of a tuple, structured bindings aren't quite the right tool: auto&amp; [a, b, c, d] = tup; // silence compiler warnings about unused variables. (void)a; (void)d; f(b, c); Currently, std::get is probably best: f(std::get&lt;1u&gt;(tup), std::get&lt;2u&gt;(tup)); But I still find this to be more readable: f(tup[at_i&lt;1u&gt;], tup[at_i&lt;2u&gt;]); or this, when appropriate: f(tup[1_i], tup[2_i]); All tuple/variant really needs to do is provide the overloads for `std::integral_constant`. The `at_i` or literal or whatever convenience function could just could be provided by the user.
I am confused by the first example - in which situation would the following code return 1 and in which 0? int main (void) { printf ("%d\n", (INT_MAX+1) &lt; 0); return 0; } 
is swap correct? None of the iterators in the std containers have them.
Please forgive my ignorance, but I thought adding symbols to the `std` namespace is considered to not be good practice just for this exactly reason. Why is it necessary to do that in the examples given in the post?
I had success with gtk on windows with mingw via msys2 (https://www.msys2.org/) and calling pacman to install mingw and gtk. It should work just as well for wxwidgets I would imagine. 
What exactly do you find unclear in the official [build instructions for MinGW](https://docs.wxwidgets.org/trunk/plat_msw_install.html#msw_build_cygwin)?
It works fine here, follow https://wiki.wxwidgets.org/Compiling_wxWidgets_with_MinGW properly and you should have it working in no time.
&gt;...Visual Studio IDE and I refuse to use it since I want to keep the same codebase for diferent OSs. What? Using Visual Studio in no way changes the code. As long as you write portable code, the code is portable. Doesn't matter what IDE you use - it matters what code you write. Using Visual Studio, I regularly write and debug tools that only ever get used on Linux.
What about the Boost iterator library? It is meant to simplify the iterator implementation.
That’s why I love Reader View 
No reason you can't use Visual Studio to write cross-platform code. Just use it as an editor and compile manually with MinGW on the command line. 
If you follow the typical rules about how code is executed (line-by-line, returning back for loop statements, skipping if/else blocks as needed), then this code does, in fact, return zero. However, the whole point of undefined behavior (UB) is that the second you do it, **all** the rules are broken, including the rules about how code is executed. You could say that "it doesn't matter what the print statement prints, because the program *has to execute the next statement*, which returns zero." This is wrong (specifically, the part in italics is wrong), because the program doesn't have to execute the next statement now that you've invoked UB. It could search your computer for a copy of DOOM and run that instead, and this would be perfectly allowed.
The example shows what happens when your standard library implements `hash_value` as proposed in P0549. Just imagine the part in the `std` namespace is actually implemented in a standard library header. 
You can do this: auto&amp; [_, b, c, _] = tup; f(b, c);
Do I really need to compile the library? Aren't windows binaries enough?
it creates strange structures for no reason at all. I code mostly on linux machines but when it comes to windows, I prefer doing the same style of coding and editor. I hate IDE's in general.
 Depends on your MinGW version. The precompiled dlls worked fine with TDM-GCC 5.2, but I had to rebuild wxWidgets when I switched to MinGW-w64 7.2 as the dlls were not compatible anymore. Building it is very easy though.
Could you elaborate a bit please? I find myself with: - Header files - Development files - Release DLLs What do I do with those? I feel lost af. The wiki provided only tells you how to compile, and I'm new to using libraries with C++. 
If you use the precompiled binaries, you don't need to compile, of course. You do need to use one of the 2 supported MinGW versions, which, for the [latest release](https://github.com/wxWidgets/wxWidgets/releases/tag/v3.1.1) are: &gt; MinGW-TDM versions 5.1 and 7.2 (with the default SJLJ exceptions propagation method, using C++11). If you do use one of these compilers, then you just need to uncompress the binaries and, again, read [the instructions](https://docs.wxwidgets.org/trunk/plat_msw_install.html#msw_build_apps) for setting up your application to use wxWidgets. These instructions also apply if you build wxWidgets yourself, of course.
&gt; MinGW-TDM I'll give it a shot, thanks! Also, I can only seem to be able to find the 5.1 version: http://tdm-gcc.tdragon.net/download I'll us 5.1 for the test tho, I'll be back soon if I can :), again tahnks a LOT
I saw his talk at CppCon last year. It was fantastic. 
Black on white sets everything right.
Amazing! Wish I had had this a few weeks ago.
no, it's not
\&gt; You could say that "it doesn't matter what the print statement prints, because the program *has to execute the next &gt;statement*, which returns zero." \&gt;This is wrong (specifically, the part in italics is wrong), because the program doesn't have to execute the next statement now that you've invoked UB. Even worse, because the compiler assumes that undefined behavior cannot happen, the program does not even have to arrive to an execution point that invokes undefined behavior. A smart compiler would just say "that execution path invokes undefined behavior, therefore it is unreachable and can be deleted". 
Things would be so much easier/nicer if we had constexpr parameters/constexpr overloading. Then, nothing would stop you from just writing operator `tup[n]` that'd work just like `get&lt;n&gt;(tup)`. Not sure why this hasn't been proposed/added yet. It probably was discussed and maybe there are some bad corner cases (or people were just reluctant to include it).
Inconsistencies with N4659 (C++17 draft): InputIterator: `(void)i++` does not return something convertible to `value_type`. This should probably be in the cell to the right of `*i++`. ForwardIterator: `i++` should return a type convertible to `const forward_iterator&amp;`
Alright seems to compile, I used .a but it seems it still require the dll... It works tho if I provide it. This is my full compile command: ``` g++ -std=c++17 -Wall -Wextra -Iinclude -Ilib/mswud -Llib src/main.cpp -o bin/main.exe -lwxmsw31ud_core -lwxbase31ud -lwxtiffd -lwxjpegd -lwxpngd -lwxzlibd -lwxregexud -lwxexpatd ``` Is there a way in wx to spawn a window without using the wxIMPLEMENT_APP(MyApp); ? I Mean, I have a working APP that just needs to display something at the end in a window.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9u8nlf/two_beginner_questions_about_raii/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Lowercase c in cout
No, actually, that's fine. At least, I've seen, and done, indenting spaces after the hash to mark nesting levels of # ifdef, # else etc. 
I don't know whether the mods allow these questions, but there's a whole sub for them: [https://www.reddit.com/r/learncpp](https://www.reddit.com/r/learncpp)
thanks man i accidentally posted in r/c and they told me to post here ill repost else where
I tried the space to see if that was the issue it wasn't there previously
I'll fix that 
Although you have other errors, that particular one is that your compiler can't find your include files. That's very odd, it should have its paths set up when you installed it. You might want to go digging around on your hard drive and see if you can find where iostream and all the other include files live. It'll likely be in a directory named "include". Then go poking around in your compiler settings and make sure it's looking there for include files. I'd say it might actually be easier for you to just reinstall your compiler, but not so much if you do whatever it was you did to make it lose its include path in the first place. Also, if you compile that as a console program and then try to run it from the IDE it'll probably just pop up a console window, output the text and then close the console window less than a second later. Unless they finally fixed that problem. 
This is way more in-depth than I expected it to be. Now I'm worried that all my code is full of errors that I haven't considered
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9u8pds/im_new_to_coding_and_i_cant_figure_out_why_my/e92jzni/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Hope that helps. The rabbit hole you're poking your nose in is pretty deep and very complex, but I find the rush you get from watching something you build work for the first time is plenty rewarding. There are always bumps along the way. Don't be discouraged by them.
The compiler knows that both `INT_MAX` and 1 are positive numbers. There are no well defined situations where adding two positive numbers could result in a negative number. Therefore the compiler can implement that expression as a constant 1, and therefore the output would be 0. The fact that signed integer overflow is undefined allows this optimisation. On the other hand, the compiler could simply produce instructions that adds greatest positive number and one together. The behaviour of that depends on the CPU. On some architectures, the result will be a negative number, and there might be an overflow flag in a status register which would be set. If the representation of negative numbers is either one's or two's complement (latter being by far the most common representation these days), the overflown value will be the most negative representable value, and output would be 1. Those two outputs are not the only possibilities however. The C++ standard gives no limits to undefined behaviour of a program. None whatsoever. On some CPU's the overflow could result in a trap representation. If it is, then behaviour will be whatever the system decides. It could for example set a red warning LED and notify an operator to assess the situation.
I don't know of the situation back then, but these days at least the compilers do provide instrumentation that attempts to detect UB and terminate the program with a diagnostic message when it is detected. They are not able to detect everything, but are better than nothing. You also must write tests for your program that actually execute the code that would have UB, or else they remain unnoticed.
Only for signed integers. Unsigned overflow is well defined.
&gt; the fact that C++ picks features from newer C standards and references them in order to do so. My main point is that while C++ started out as ANSI C + extensions (... but not really), it will _never_ be C99 + extensions, as C++ has already intentionally deviated from that path. It will only ever be _at best_ ANSI C + some bits of C99 + some bits of C11 + some bits of C2x ... + extensions, and that's assuming C++ doesn't ever start deprecating or changing anything from C (except they *did* do that already, e.g. `auto` and `register`). :) &gt; someone reading your comment may think C and C++ are meant to diverge and be totally unrelated languages Obviously not unrelated, but they are getting more distant as time goes on. :) They *are* getting less compatible, and they were never 100% fully compatible to begin with. C++ has diverged from C and will continue to do so, so long as both languages are still evolving. New features were added to both C99 and C11 which are not and never will be uplifted verbatim into C++. Even the ABIs might diverge! 
Old but gold.
Is there a recording available?
https://youtu.be/anzzNp8HlVQ
Once UB is invoked, all the rules are broken, and the compiler can do anything - even *backwards in time, if it wants!* Unfortunately I have some bad news to report: on august 25, 2031, at 9:25 in the morning, a colleague of mine will invoke UB. That invokation will cause the compiler(\*) to travel back in time and cause all programs in the world to start failing in subtle and hard to detect ways. There is really no need for any of you to try to avoid UB: it has already happened (or rather, will happen) on that faithful morning, and all rules are broken forever as a result. Ahh, UB - isn't there nothing it cannot do? ;-) (\*) The compiler was an advanced copy of acc, a compiler that was always known for its excellent error messages. In this case it only printed "Integer overflow on line 16 (expression \`INT\_MAX+1\`) invokes UB. Got you now suckers!" &amp;#x200B;
The LLVM suite offers [the UBSan tool](https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html), but I have no idea how good it is. I'm not aware of any equivalents for other compilers.
No it doesn't. It doesn't create anything you don't explicitly tell it to. Hell, it even follows your .clang-format and .editorconfig as best it can. Maybe you're making the mistake of creating the project with the IDE? Shouldn't do that on any platform. VS will happily open and work with a portable CMake project.
That's the terrifying part of UB in C/C++: your program is a union of all the possible UB errors it might contain - a single UB can trash the entire contraption. Imagine that the programmer(s) working on your project have a success rate of 99.999% per line wrt. UB. A 100K LOC project then only has a 63 % probability of not containing any UB (1 - (0.99999 ^ 100000)).
Can you elaborate a bit more? It was just an idea, a more detailed analysis is always welcome. 
I have a question, are behaviours either defined or undefined in C++? So law of excluded middle and law of explosion seems to apply...
I think you have actually calculated the probability that the project does contain UB...
From my small experience in DNN (3 months of internship some years ago), I'd say that a normal gaming hardware and even a top gaming hardware can not run the training phase of a DNN at 60 FPS. Although once your DNN is trained it should run smoothly and requires no data at all for training, you just have to pass your data to test. You may even try to readjust your DNN with some training phase and small data. But there is no way to guess the duration the training and test phases will take, DNN are big black boxes, I suggest you to give it a try and measure the time it takes.
So wait, if I implement `hash_value` (or anything else) in the global namespace, who cares? We’re not C anymore, everything is namespaced. And therefore the implemented function will be called `std::hash_value`, no?
It's on the CppCon YouTube channel
I understand why it will take time with training but i am more concerned with amount of data it will store and will use in game because it shouldn't be way too much to even make it practically usable.
&gt; header-only libraries Maybe that's the problem right there?
Once your DNN is trained you can export it to a simple file (with Keras for example https://machinelearningmastery.com/save-load-keras-deep-learning-models/). You don't need training data, however for test data it depends of your use cases. It could be a simple int to a bunch of very complex data structures (the same type of data used for the training phase).
Of course that's the problem, but what are you suggesting, not using header-only libraries? 
IMHO the problem here does not lie in modules, but in header only libraries. I totally see, 10years from now, header-only to be considered an anti pattern. 
`range-v3` is heavily templatised, how would you implement it as `.cpp` files?
As mentioned in my parent comment, this problem is not intrinsic to header only libraries.
They can be defined, implementation defined, unspecified, or undefined. "Implementation defined" means the compiler can make a choice but it must be fixed and documented, eg sizeof int. Unspecified means the compiler can vary its choice, eg order of evaluation of function arguments. 
&gt; how would you implement it as .cpp files? Using modules? This article shows how to export templates from `.cpp` modules. 
&gt; it will never be C99 + extensions, as C++ has already intentionally deviated from that path. I think you are talking about syntax/grammar/features; which, as I already said, is obvious they are different (and meant to be, otherwise there would be no point). However, that is not the point of C++ referencing the C standard and/or keeping compatibility where possible. &gt; They are getting less compatible, and they were never 100% fully compatible to begin with. (...) New features were added to both C99 and C11 which are not and never will be uplifted verbatim into C++. If you are talking about blindly copy-pasting C code into C++, sure. But nobody cares about that. :) &gt; Even the ABIs might diverge! The standards don't define an ABI, so they can't diverge nor converge. Having said that, in practice, for major vendors, that won't happen, ever :)
Hey, I have a question about Ryu (again) I noticed the other day that you have your own fork, so I cloned that nd I've been digging into the code (and removing eerything that I don't care about, like float (I only care about doubles rn) and removing all of the #ifdef macros, like 128 bit ints) and honestly it's still confusing as hell as to what is actually happening. the variable and function names certainly don't help anything. so I guess my question is, why is it doing what it's doing in the first place? why do powers of 5 matter for example? the mantissa doubles just like regular ints, the highest mantissa bit is .5, the second .25, etc. what does a power of 5 have to do with anything? also, I was looking through Visual Studio 15.9 Preview for the source for charconv, but couldn't find it, but I'm not even sure if I installed the right package there tbh. I'm not even sure what my point is, sorry for rambling.
i must be missing something, can anyone explain me how AoS can cause cache misses? imagine a 3D engine: `struct Entity {` `float x;` `float y;` `float width;` `float height;` `};` `std::vector&lt;Entity&gt; entities;` `void update() {` `for(Entity&amp; e : entities) {` `e.x += timeDelta;` `e.y -= timeDelta;` `// etc etc` `}` `}` i just updated all the entities, using a AoS data structure, where i didn't have to update all the X's first, followed by the Y's, etc etc and since they're all continues inside the structure, and the vector itself is also continuous, how will it cause cache misses when i iterate over it? 
Thanks, edited! Shouldn't do math before morning coffee...
You didn't use width or height. Now imagine that Entity has a lot more attributes like that ;)
&gt; two different compilation models for templates having the same issues is suspicious at the very least. why is this suspicious ? you can just run clang or gcc with ftime-report: contrarily to what everyone seems to think, it's not parsing thousands of headers that take times, but instantiating templates. As long as the C++ compilation model doesn't change to something like the one [zapcc](https://github.com/yrnkrn/zapcc) provides, everything will be slow.
&gt; I can also compile hello independently because again, hello.cpp is a translation unit, not a header: &gt; g++ -fmodule-ts -c hello.cpp -o hello.o I don't understand what the author is trying to prove here. You can compile headers in C++. $ echo "#pragma once #include &lt;cstdio&gt; void foo() { printf("hello"); } " &gt; foo.hpp $ g++ foo.hpp guess what, this compiles the header in a PCH
Now imagine you just want to update x value (say shift all entities right). Let's say vector has 1000000 items. You are going to load 16 bytes for each entity but use only 4. This means 75% of cache is wasted for data never used. Each cache line is 64 bytes so can hold 4 entities. Every 5th load is cache miss in AoS. In SoA cache miss is every 16th element. Now multiply cache line fill by million and you will see a difference. What helps AoS is hardware prefetcher that can preload in advance. 
Well, if you’re going to touch/read all of the data in the Entity structure, all of the time, every time, then you’re right, there won’t be any benefit to an SoA transformation with regards to having to load data into the caches. However, in your example as it is, without elaborating on what “etc” is, then you’re not reading or writing the Entity width and height. In this case, it may be beneficial to transform the data layout so that the width and height data is not stored in the same structure as the rest of the data. This is because as you are iterating over the entities, you’re going to load memory in, one 64 byte cache line at a time. Currently, you’ll load in 4 entities per cache line (they’re each 16B in size). If you reworked the data so you had one list of entity positions (x/y) and one list of dimensions (width/height) then the update loop you have would only have to iterate over the list of entity positions, and would load in 8 entity positions per cache line! In this case, you would have improved the data packing and gotten more utilization per cache line loaded in, and ultimately load half as many cache lines as were needed, saving power and time. Also there are other arguments to be made around SIMD processing which are worth looking into. SIMD kernels love chewing through structures-or-arrays and that can represent another (up to) 3-4x speedup of processing.
Niall: do *not* read this, it will be very bad for your blood pressure. PD: don't take it wrongly ;)
GCC has ubsan too. See https://gcc.gnu.org/onlinedocs/gcc/Instrumentation-Options.html It probably does not have the same set of checks as Clang's one, but it sexists.
That is like being surprised that a 100K LOC project has a bug. Sure. Quite few more, in reality. C/C++ is perfectly fine in that regard. The problem of UB is only critical on security-related tools.
We already have `_1`, `_2`, why not to reuse them? `at_i&lt;2u&gt;` looks even less convenient than `get&lt;2&gt;`.
 int top = std::min(popcount.size(), (size_t)20); nth_element(popcount.begin(), popcount.begin() + top, popcount.end(), cmp); sort(popcount.begin(), popcount.begin() + top, cmp); There's partial_sort instead of nth_element and then sort. https://en.cppreference.com/w/cpp/algorithm/partial_sort
Regular bugs and UB are in different categories, though. A bug might do something wrong, but typically will not unlock complete havoc within the running program.
Is C++ jumping the gun? Really, how sure are we that networking computers isn't just a fad? 
I already can see an engineer being dispatched to do a feasibility study for mature codebases, and them coming back and saying "for our code base, I found zero net benefit over our existing build system". And that'll be the end of deploying Modules there. Even for brand new code bases, for years yet nobody will be targeting C++ 20 exclusively, and so you'll need to remain on pre-Module designs. In that use case, the only support for Modules anybody will bother with is a preprocessor macro based design that eliminates the problems with cmake et al because dumping widely understood build systems is too big an ask right now. And, to be honest, the only currently sane way of deploying Modules as currently proposed for anything apart from small projects is via the preprocessor. So we'll actually end up with *more* preprocessor macros, not less, in the current Modules proposal. By the time people *are* targeting C++ 20 exclusively, we'll have moved vastly onwards from v1 Modules hopefully. Even if everybody were on C++ 20 exclusively right now, there are lots of very problematic parts of the Modules design which makes it very hard to scale build to 100k+ Modules in a way not massively slower than current build designs. The only way to scale these is to use a constant query time graph database. Compiler vendors can either build their own individually, or we can standardise the API for one for everybody so tooling, build systems etc can all interoperate. Guess which option I think makes the most sense. And that's exactly what my WiP paper P1027 *Low level object store* literally proposes (expected before Cologne). I'm hoping that this would solve the cmake support problem for Modules. cmake would talk to the central object store the same way as the dynamic program loader and the compiler linker would. Or indeed any other tooling. Bye bye JSON compilation databases, thank god.
You're right that Google have no interest. They wouldn't hire someone like me in any case. They have a full team of LLVM folk they spend hundred of millions of dollars to retain, they don't need outside consultants, they just assign work to their in house team. No the most likely sponsors are hardware multinationals. They don't have the in house talent in this area, but do want to ship lots more hardware. Direct support for their hardware in the C++ standard is a very compelling value proposition for them. As I mentioned, they are warm to the idea, but want to see more focused direction from WG21 first.
Hey, sorry for that kind of targeted title ;) I think I understand your point now. Even if modules are merged, we're not going to see implementation or even adoption for a long time. Refactoring to modular code is hard, and without any proven or tangible benefits a refactoring of that scale is hard to justify. If you see modules finally merged and expect Qt and Boost to be modularized the next day, you'll be horribly deceived. There could be other models than the proposed module and it's true, you got me interested with "database driven" model but I cannot find any details about it.
*Sorry for thread necro This isn't true. Parser combinators can be implemented in terms of the [GLL](https://pdfs.semanticscholar.org/dc97/9e2f94bf5c33a831f41de811e011838edefa.pdf) algorithm, which does accommodate left recursion and ambiguity.
&gt; The `build2` build system actually parses source files with a simple regex to extract every string of character following import. This is incorrect: `build2` extracts the module dependency information using a real PP-token lexer and a shallow parser that conforms to the language grammar. Here is the source: [`parser.cxx`](https://github.com/build2/build2/blob/master/build2/cc/parser.cxx).
&gt; 1.2-1.4x speed-up in compile-times With which compiler is that? I am personally not aware of any TS or merged proposal implementations that at this stage would be able to compile something like this.
Is only a penalty if the cache gets fill with data that is not going to be used. So if all that data is going to get used then both ways is the same.
&gt; I think I understand your point now. Even beyond the practical considerations, I strongly believe that the ability to export and import symbols at the C++ link level is the wrong level of abstraction for Modules. You can't make modular code at that low level of detail without heroic self discipline, something not commonly found in large codebases with long lifespans. Something far simpler like Microsoft COM's ability to represent C++ via another, separate, layer of abstraction above the C++ link level **is** well and widely understood. I'm not saying we should go *that* simple, but I am saying that it's much safer to start simple and add complexity later, whereas it's virtually impossible to remove features and support from the C++ standard later. But none of these arguments have found favour at WG21, and I'd much rather C++ Modules proceed in an unuseful form than nothing at all. So I keep fairly quiet. &gt; you got me interested with "database driven" model but I cannot find any details about it. I did a lot of R&amp;D work on this during my time at BlackBerry. After they decided to abandon C++, I wrote up the most I could - given NDAs - into https://arxiv.org/pdf/1405.3323.pdf. That paper was very widely reviewed by compiler vendors and WG21 leadership at the time, and we have informally discussed the potential of some approach like that many times since. 
A very good overview of the state of C++ Module post the Bellevue ad hoc meeting. The talk proper is only ~30min and is definitely worth it.
No. That is something repeated over and over everywhere, but it is false. Any logic bug can wreak havoc in unexpected ways. Simple miscalculations and even trivial typos have been known to take down planes, bring down stock markets, delete months worth of irrecoverable data, bankrupt companies, make crypto insecure or kill patients. That means that if you are designing a system that requires *actual* safety, then you better have in place proper processes to avoid *any* kind of bug. Getting rid of UB as a bug class is worth it in some non-safety-critical domains to reduce engineering costs; but that does not make your code magically trustable.
The actual cost here being code clarity and compilation times...
Team leads and maintainers can use clang-tidy to teach newcomers DOs and DONTs.
well, yeah that's what I'm using but it's a "meta build system" which OP does not want
I have a bit of experience with this, since the company that employs me definitely fits in this category (enormous C with classes codebase, several decision-makers who actively resist modernization). Things changed because the a few top developers made a case to the (former developer) CEO. They demonstrated benefits, did a few pilot projects, etc. Eventually the CEO was sold on it and enabled change by scheduling modern C++ training for the entire C++ developer team. Once everybody had at least an understanding of modern style/features, individual developers were able to start making bolder changes. Certain resistant team leads softened their stance, or even flipped sides altogether. From there, it has still been a long road. One cannot erase/replace decades of legacy overnight. Still, the change has been slow and steady in old projects, and new projects are now written in a modern style more often than not. Summary: get a high-level person to drink the Kool-Aid
Ugh this year there have been a lot of talks by people who are emulating some strange form of tech talk performance with halting almost captain kirk like style. One of the things I liked about the previous two years videos was that I either didnt notice, or people were using the conversational model of exploring an idea with you rather than trying to sell me something. I find it the worst in android and javascript video's I've attempted to watch. It's one of the primary reasons I liked the c++ community because it seemed devoid of the bluster and bullshit of the other tech communities. Unfortunately I prefer to read than to listen to these people proselytize.
The differente is that I can test for logic errors offline and online (e.g. put sanity checks on the output of a function). I can't reliably test for UB (at least not from inside the language), because UB infects the whole program, including the very checks that are supposed to protect me from unexpected bugs.
&gt; you can just run clang or gcc with ftime-report to convince you of it: contrarily to what everyone seems to think, it's not parsing thousands of headers that takes time, but instantiating templates. I picked a random template-heavy TU from my codebase and ran it through `-ftime-report` with no optimizations. 63% of the time spent in parsing (16% just in preprocessing). 20% of the time in template instantiation. 12% spent in name lookup. 13% spent in overload resolution. (These are wall clock times). Total compilation duration was 2.47 seconds. Maybe templates will dominate if every source file is instantiating a massive Boost.Spirit program, but I doubt that's the average C++ use case.
I'm one of those project leaders holding things back. Upgrading from C++14 means getting a new compiler. Which means getting a new OS distribution. Which means re-validating and testing our entire universe. Which is its own damn project, and I don't have time for that with the two major module rewrites due in 2019.
So will every new proposal end up in the incubators? Or are there proposals that will go straight to (L)EWG?
I think we need some kind of GUI now explicitly designed to create, visualize, emulate, examine, like, dislike, comment... C++ proposals.
I consider them an anti-pattern already today.
Looking through the list there seems to be a lot of low effort papers that should get dismissed fairly quickly.
Even if you are using all the fields, SIMD is far easier to implement efficiently with SoA than AoS. It's entirely feasible to see speedups from layout changes allowing either auto-vectorization or simple unlocking the ability to write manual efficient vectorized code. This might be by breaking the update into multiple loops (one over the vectorizable fields, one over the other fields) or even with interleaved updates that are just able to use more direct SIMD instructions on appropriate fields without having to move data into and out of SIMD registers inefficiently (which for simpler cases can make SIMD slower than SISD).
&gt; With which compiler is that? clang
And Rust, Swift and .NET Native.
From my experience, I didn't see a noticeable difference in compilation time, in large codes and replacing classes with a lot of members. For the clarity I totally agree, but the complexity can be isolated in a library. From the perspective of the user of the data structure nothing changes.
&gt; I didn't see a noticeable difference in compilation time That's interesting. What compiler were you using?
Regarding Herb's graph of rising paper and attendee count, note that Rust compiled itself first in 2011 and went stable in 2015. Some would say that WG21 has raised its work rate to compete with the upstarts. Others would say there has been a huge increase of interest in systems languages in general.
some version of calng. I have to say that the compilation time was already quite high, so maybe that's why it wasn't "noticeable"
I work on an embedded platform that only supports g++ 4.8. Even C++14 wasn't well-supported until g++ 4.9. Things move slowly with C++ sometimes.
FROM c++14? You are way ahead of the game, I suspect. I can’t justify upgrading until cross platform support is guaranteed. For example Apple still doesn’t have std::variant. So I won’t touch 17 for at least two more years. 
It should be the CEOs and CTOs pushing for the adoption of newer language features out of a deep conviction that these save money in the long run. Short term goals preserve the status quo.
Well *that* won't change. 
You could do greater and better things with your time than fight an uphill battle with industry "veterans". Find another company and another team.
This was the approach taken by Lucid C++ and Visual Age for C++ v4, sadly they were ahead of their time for hardware resources and ended up folding.
Yeah, my team builds with gcc 7 on Centos 6. Building and shipping with a new compiler on old systems is pretty easy.
So given that COM has been getting more central role in Windows thanks to its revamped version (UWP), how you see Microsoft strong focus on modules then? Specially given that Microsoft is the only consumer OS vendor that still cares about supporting C++ as an apps language.
1 - Open n4713.pdf (ISO C++17) 2 - Ctrl+F *#pragma once* 3 - Nope, 0 results found 
Nobody likes COM. Absolutely nobody. It's a travesty of design and implementation, and a wealth of misfortune and pain. But *it works*. And its ugliness and compromises are very widely understood. You may not be aware that Microsoft's Modules implementation can spit out DLLs which have bound the IFSC representation with the binary code. When I mentioned to GDR how very similar those looked to COM components v2, he said he had no idea what I was talking about. So there you go!
Wasn't it added in Xcode 10?
Cool, TIL. Thanks! My usual work systems are managed by a central group and don't have clang installed, so I'm sure this'll be helpful at some point.
Ha, looks like it. 2 days ago. Still cant touch it, corporate policy doesn't have us on Mojave yet (Just got High Sierra in September) &amp;#x200B; &amp;#x200B;
CEOs and CTOs making proclamations about what individual developers are doing feels like pretty bad micromanagement. As above, changing standards requires buy-in from them, but should be driven from the bottom.
I have to say that although networking as a standard library is sorely needed, this seems over complex and seems to stray wayyy too far from the fundamental principles it is trying to cover. Why not have the basics of networking as one library and the asynchronous executors stuff separate? 
We will make that with std.graphics module
We vote our best, forward thinking C++ minds into office to pass legislation requiring the newest standards, and hope to god they don’t go absolutely mad and drunk with power. (They will, though.)
As .NET/Java developer on the Windows world, and former C++ dev, I am quite used to the whole DevTools vs WinDev issues, so I took it seriously actually. But the way you put it I guess you are right, yes.
&gt; Producing a strong proposal that solves more than one problem. I don't like this, because I remember that the uniform initialization proposal aimed to solve two problems: - lack of a way to initialize a container from a list of elements - lack of a uniform way to initialize different types of objects ... and in the end it becomes probably the worst feature of C++11. 
Modern Microsoft is far less dysfunctional than previous Microsoft. There is some actual joined up thinking going on over there nowadays. Very refreshing.
Why do you need a new OS distribution just to get a new compiler?
Part of it is the environment. For example, I can't use C++-17 because we depend on CUDA which depends on it, and also has hard upper limit on the GCC version. Other companies might have target systems for which you need a specific (usually older) compiler version. On top of that, the inertia of a large group of people can be crippling. You could convince one dude to learn the new C++ standards, but convincing a whole group of people is much, much harder. I was stuck at C++98 and managed to convince people to move on to C++14 with a combination of complaining, a great deal of ironing out problems on both the development and target systems, figuring out ways to make compilers compatible, and most importantly just "doing it" and then demonstrating it, pretending that it "just works". That only worked because we were a small team and I already ran into resistance from co-workers and customers. I can't even imagine what it means to convince a big company to do it
You don't make sense. That is not micro-management and I was not talking about proclamations (did you mean slogans?!). The leadership should set the tone and encourage a technological progress within the company. Said leadership should not be just technologically illiterate bean counters. Moreover, they should not be convinced or persuaded to adopt technologies that benefit the company as a whole and they should absolutely not be an obstacle to that progress.
At the risk of tooting my own horn, this is very similar to what [tuple_vector in EASTL](https://www.reddit.com/r/cpp/comments/9ih7ze/eastltuple_vector_an_stlcompatible_data_container/) sets out to accomplish. So much so, that this code actually uses two constructs that I used myself at various points in time in t_v's development, which may be worth consideration: 1) The use of individual vectors for each data type can and will scale poorly as you increase the # of elements, e.g. you're going to invoke a malloc or realloc for each element when the container itself needs to be resized, which can be costly just for the mallocs in and of themselves, but it can further exacerbate the impact that reallocs have on memory fragmentation. It definitely adds a lot more complication, esp. since you can't just forward the vector part of the interface to constituent vectors, but rather have to reimplement it yourself, but given how performance-centric such a construct like this is, it's good to have. 2) Having the iterator reference the container it was sourced from was something I did for tuple_vector's iterator as one attempt, but I found that this actually caused a lot of subtle performance issues whenever the compiler could not determine the container in question was invariant each time the iterator was being dereferenced. The generated code would have to repeatedly reload the container and the pointers to the data in the container, and in some cases could not identify that a pair of iterators were sourced from the same container, whereas just [storing the pointers to the data in question](https://github.com/electronicarts/EASTL/pull/197/commits/86b0a990d23ae07bc410f747264445f205b44215) consistently gave comparable results against a manually-managed series of raw arrays. Besides "remove_copy_if" as an example there, I forget what other levels of complexity were required for the compiler to lose sight of the source container, but in general it was most non-trivial STL algorithms, especially ones that perform swap's at some point. The trick of throwing in a full "Item" as part of the container template definition in order to provide some child to abstract the member accesses, and not rely on tuple-gets everywhere, is interesting, though. As I mentioned in the readme, the problem of get's being so fragile is still not something I'm stoked about, and tuple_vector isn't able to *exclusively* return tuples that clearly abstract the numeric gets behind a symbol like what you demonstrate.
I wrote the original "rant" about it and I can't say I really understand the rationale. Java swing (a similar counterpart) was an abomination that truly did only have applications for teaching but could have (and should have been) relegated to a library. Embedding it in the standard has so many ramifications. Do we really want to link to this when when we ship, say, an Android application (when shipping for Android, you generally statically link libstd++ yourself). I may codify that rant a bit more cleanly in blog-form, just for discoverability.
&gt; "Clang is the best in the world!" According to Google Translate.
Assuming that there is some kind of package for the discord API, it is incredible simple, a discord bot is nothing more than a really long list of if statments, each for every command, of course if you want some complex commands it will be harder, but for a bot that says a couple of things (like a list of the people on the server, or repeat what you type) is fairly easy
&gt; If you are talking about blindly copy-pasting C code into C++, sure. But nobody cares about that. :) Except that's exactly what a header file is doing. &gt; The standards don't define an ABI, so they can't diverge nor converge. They don't define the ABI, but they do define the requirements upon the ABI. It has already been the case that C++ has forced vendors to break their own ABI multiple times, even with standards like the Itanium ABI in place. While it's exceedingly unlikely that any platform's C ABI would retroactively break (well, except that's already happened on several platforms...), it is entirely possible that new C features might mandate that new functions using those features use a different calling convention than the platform's ABI uses by default. And if those features are things that C++ doens't work or wants but in a radically different form, we'll have ABI divergence. And there's proposals in flight right now that _could_ bring that about (though it's admittedly extremely unlikely). Point still stands: C++ is not C and its compatibility is a matter of convenience, not a guarantee&gt; And my original point: C++ is not "rebased" onto newer versions of C.
The word of warning here is that (IMO), C++ is not the best tool for the job in this situation, which is fine if its just to learn more C++. It's completely do-able only requires some basic understanding of how to interact with Discord's API. However, other ecosystems have been designed around the idea of needing to make requests and perform operations asynchronously (such as NodeJS). 
So like, for example, me and a group of friends watch movies every time we hang out and give them individual ratings. Right now, people just say the movie name and their rating in one channel, and then I go and edit the ratings list. Would this be conceivably doable? Also, do you know where I could find said 'package' for the discord API? Or where I could start looking? Thanks for responding!
Ok gotcha. The class is exclusively c++, so as long as it *works,* I'll be alright with it. Thank you!
conceivably and very simple, just make a command, something like !rate "&lt;movie title&gt;" &lt;rating&gt;, the bot parses it (easy as the movie name is between quotes and the rating is (I suppose) a number, then you store those and send it to your server or your databases or wherever you store the data
From what I remember, DiscordPP is still pretty popular. https://github.com/DiscordPP/discordpp Of course, the issue is you have to manage these dependencies yourself, which means installing OpenSSL and others (which could be a pain if you're on Windows).
These talks are really making us less prepared to face the Cylons.
Rust do have compile time issue thou.
&gt; a standardised event loop in Modules Like a WM pump so you can dispatch messages to modules at runtime, or something that exists during compilation?
&gt; Last week in one of the code reviews, my lead who is basically a C guy and a veteran in the industry who doesn't understand c++ well reviews my code that has enable_ifs and few constexprs and lambdas loses his shit and asks me to drop these fancy things to maintain consistency. I am not going to argue for or against but I would just like to point out that just as your 'lead' has biases against new standard features. You yourself also (likely) have biases towards creating an implementation where you can use the 'shinny new toys' in the standard. As with everything there is a balance to me made. You have to accept that specially with very large codebases, every new LOC added is an incremental risk in the codebase. Write for correctness first, readibility second and (if necessary) performance third. When writing code you are not doing it in isolation, so ask yourself, is the code that you are writing realistically maintainable by anyone in your team? If you cannot confidently answer yes, then we are forced to accept that your addition to the codebase is (without training up your colleagues) a maintainability/readibility risk. For everything that you want to use you need to 'prove upwards' to management that it brings 'value' with some measurable metric: Less bugs per LOC due to readability improvements or compile time checks. Reduced binary size by x%. Improved performance by some unit of time. Otherwise at the end of the day it is quite literally your opinion against the opinion of people like your Lead.
Here's an example : #include &lt;unordered_map&gt; #include &lt;vector&gt; #include &lt;string&gt; #include &lt;variant&gt; template&lt;typename T&gt; T copy(T t); int main() { std::unordered_map&lt;std::string, std::vector&lt;std::string&gt;&gt; s; auto s2 = copy(copy(s)); s2.find("hello world"); s2.insert({"blob", {"hello"}}); std::variant&lt;std::string, const char*&gt; var; var = copy(var); auto res = std::visit([&amp;] (auto&amp; x) { return s2.insert({x, {x}}); }, var); return res.second ? s.size() : 0U; } for me, with GCC 8, it's 34% of time spent in template instantiation and 2% of time spent preprocessing.
I absolutely do not care. It's a compiler extension supported by all the compilers relevant to me. Most of the languages I use don't even have an ISO standard anyways and they work just fine.
You can install Xcode 10 on High Sierra.
For all C++ codebases I'm in charge the first rule in the coding standard is "We write modern C++ code, not C.". So using C strings/arrays, malloc, SESE, raw pointers, etc are highly discouraged and you need a pretty good justification (actual performance, interaction with a C library, etc) to use it. We convinced most developers simply by the fact that abandoning this stuff reduced many bugs drastically, e.g. out of bounds errors. I think you convince most people with stuff which makes their lives easier (RAII, smart pointers, ranges, auto), fancy/clever stuff is hard to swallow for many. 
There's a pretty wide gap between being technologically literate and having opinions about every new feature of some language that employees six steps down the management chain are using.
!removehelp
Why would I ever want to write something like this std::vector&lt;int&gt; v {1, 2, 3}; std::for_each(v.begin(), v.end(), [](int &amp;i) { std::printf("%d\n", i); }); instead of this std::vector&lt;int&gt; v {1, 2, 3}; for (const auto &amp;i : v) { std::printf("%d\n", i); } Second example is much more simpler and elegant in my opinion. I also like avoiding the auto in the range-for to make things more explicit (unless the type is really obvious like here or it would be too long). I really hate it when people introduce feature complexity just to show of their modern C++ skills or to show how "expressive" and fancy their code is.
I hate to be that guy but... It's Kanban. 
Your poor team.
And Nim
A while ago I wrote a compiler pass (in LLVM) that does that and beyond (not open source unfortunately). All I had to do is attach a [[derivate(f, x)]] attribute to an extern function declared in the same unit as the f function is defined. Not a single template/custom litteral needed (it even supported derivation on a loop!). [I can't tell more.] All I'm saying is that there is a lot to be gained by working on compilers directly, and some stuff are better as compiler passes than libraries (like logging, debugging or memoization). I think this is one of them.
I can think of a few reasons. - You want to perform that operation on a subset of the entire container, and the iterators being or end or both were computed elsewhere already - You want to write generic code that accepts a callable as a template parameter (in which case `std::for_each(v.begin(), v.end(), vistor)` is more elegant) - You want to annotate that the loop performs no additional side effects, and indeed, an empty capture body for the lambda does exactly that - Your iteration is order-dependent and you want to loop in reverse, in which case you can use `rbegin` and `rend` without too much effort I think how "expressive" something is really depends on the interpretation by the reader. It's true though, that abstractions need to have some commonly accepted semantic meaning for readers of code to get anything out of it. In your case, you see the two styles as completely equivalent, and so of course, it feels like a useless feature. Depending on the requirements of your codebase and the maturity of the authors reading it (as well as the maturity of established conventions), the semantic intent may or may not be significant.
There seems to be a lot of national body support for it. The direction group also seems to strongly want graphics. There may be enough votes to get graphics through, even if 2-3 NBs vote against it.
That's a good question and networking is not my area of expertise. That being said, it seems that there are network devices, the adapter protocols, the networking protocols (IPX, IP etc). On top of that sockets seem to be consistent for TCP/UDP - But I think fundamentally having a threading model not be intrinsically linked with network IO is the most important part. 
Is it bad that the most unrealistic part of your comment may end up being the 'module' part?
Hey, I'm just some guy who is vaguely familiar with the syntax and always wanted to properly learn c++. What *are* the big features that would make it worth it upgrading like that? I'm not even sure I've really seen language features that really make it worth upgrading like that, in any language. Biggest pull would always be a library that requires the newer version.
Isn't your first point just a variation on the second though?
You could say the same thing about... graphics. 
One thing that keeps me from using C++ everywhere is the additional complexity with distributing binaries. I recently went through great pains to get generated (ANTLR4) binaries to work on multiple Linux distros, which required statically linking the C++ runtime (amongst others). This ballooned library size: 48MB on Linux (static link) vs 4MB on MacOS (dynamic link). While this problem is not exclusive to C++, it is much more manageable with C.
I'm with you on this one... These days and threads like this feel like dogmatism, using new stuff just for the sake of it, and turning simple function declarations into unreadable monsters. My philosophy is and will remain: use what you need, that's all. Who cares if that bit of code looks like C with classes? It works, it's fast, it's easy to read and a rookie can maintain it, what else do you want? I'll use the complex stuff when I have a need for it.
For window creation, bare basic guis, pixel buffers and graphics contexts I agree. For vector drawing, sprites, and lots of other things I don't think it is so obvious.
Ok, these seem to be valid points. &gt; Your iteration is order-dependent and you want to loop in reverse, in which case you can use rbegin and rend without too much effort To be honest, I'd still prefer something like for (auto i = v.rbegin(); i != v.rend(); ++i) { std::printf("%d\n", *i); } over the std::for_each variant though (as long as it's not too painful - which can be the case for other examples). That's all a matter of taste, but I generally like to keep things as simple (language complexity wise) as possible. I generally dislike learning about language details (and I would have to in order to understand how std::for_each internally works) and just focus on the problem at hand instead of having to remember all the time how the language semantics work in more elaborate cases. It's partly why I have a sweet spot for C or at least C++ with cherry-picking some modern features where the C alternative would definitely be too painful, insecure and unmaintainable. It's enough for most software development tasks. Advanced C++ features are fine if they are really necessary.
Just gotta write the paper.
You can use absl::variant which is compliant with the 17 spec but written in 11. When you later upgrade to 17, absl::variant simply becomes a typedef for std::variant so you never have more than one implementation in the codebase at the same time.
Which is mostly caused by too many passes at LLVM level instead of MIR and cargo still doesn't handle binary dependencies well. They are actively working on it, do not forget that Rust 1.0 is only about 3 years old.
You seem to imply that using new standards features would reduce correctness or readability. Sure, you can abuse any new feature, but usually I want to use a new feature, because it makes the code more readable. Constexpr is much more readable than doing the same in TMP. Range based for loops are more readable than normal for loops using iterators. constexpr if is more readable than tag dispatch etc. Also sometimes, using standard library features allows me to remove (large) parts of my code, which means less LOCs.
KDE branding is everywhere! :P
Yes, they do. Upgrading the OS just to use a newer compiler is absolutely backwards. 
Even there a “pixel buffer” as you called it (more commonly referred to as a “surface” which integrates with the OS window manager) can be contentious. Precision values for individual color channels may vary or not be present at all. Then there’s the presence of absence of a depth buffer, whether you want fifo buffering, immediate mode presentation, or a mailbox mode. GUIs are even less fundamental because there are many styles of ui programming that need to do very different things. In fact there are whole companies that do nothing but build Ui toolkits. Mobile and console are again entirely different. As for window creation, do you want a natively styled menu bar? Resizable options? Do you want to hide the title bar or style it differently? At some point will the standard library need to break OS compatibility when Mac does a move like deprecate carbon for cocoa or Windows moves to the Vista aero model again? 
Revalue ref was killer in c++11. Adding unified threading was nice. Lambda are nice. Stringview looks to be killer with c++17. Filesystem might be nice. I strongly advocate avoiding inheritance whenever possible and not code like its 1999.
&gt; Which means getting a new OS distribution ... why would it ?
&gt;I see that there is some sort of .... s his shit and asks me to drop these fancy things to maintain consistency. I can relate to that. Until recently we even had to use subversion ! Nothing can be done. There are always those veterans (more like comfort seeking organisms) who are unwilling to learn anything new. &amp;#x200B;
&gt; This ballooned library size: 48MB on Linux (static link) vs 4MB on MacOS (dynamic link). however on macOS it means that you restrict yourself to only some recent versions. e.g. if you want to use &lt;any&gt; or &lt;variant&gt; your code will only run on 10.14. I have users still on 10.6. 
&gt; You want to perform that operation on a subset of the entire container I frankly never ever had to do this outside of coding challenges or some unusual scientific algorithm implementation
Check my edit, but long story short, I ship a framework. Things are easy now because we define the platform and the compiler that our developers target as well as our users use. If I spec'd a new compiler, especially one we built ourselves, I'd have a mountain of documentation to complete. So making that kind of a change is a project in and of itself, and doesn't happen just because of a shiny feature.
Sure any global state will always be mutable :) As for operating on a subset, I won’t say I do that frequently but it comes up often enough when you want to write crypto code, which operates on byte ranges. Alternatively, you might implement a http fetcher that needs to write bytes into a larger buffer as data streams in. More recently, I was toying with a custom memory allocator that again, needs to operate with subsets of data at a time for defragmentation purposes. Thinking more broadly, if you have a large amount of data and want to parallelize it, this functionality might be useful. 
This article seems uninspired. There seems to be very little exploration into what causes the exact limits or how to modify your code based on what you find to maximize performance.
&gt;I enforce a policy of sticking to '98 unless there is a **very** compelling reason not to. How do you maintain your team morale high enough to care about your database? Also, how do you manage to convince new hired programmers to strictly use something from 20 years ago? These are serious questions, I'm seeing that in my team get discouraged by not being able to evolve to a more modern tools. 
Yes, I didn't want to diminish your work. This is great (and outside my competences). Also, doing special compiler passes is horrible to integrate in practice. Your library on the other hand is portable (which wins in the long run). I wish for sufficient reflexivity to one day have the best of both worlds... But I don't see that coming anytime soon.
This all sounds like you are throwing nonsense at the wall because of some pretty existing hangup. Barely anything you said is relevant in this context.
Binding your program to an OS version (unless is embedded) sounds backwards for me as well. I understand the price of upgrading an old version to a new one. But when you don't do it it's only creating technical debt. 
It does, and it's what we're using. However it's not future proof and a hell to maintain. I bet that VS2019 won't be so kind :) 
Ha. It's a good thing I hit that, or else we'd be talking past each other. It took me a while to get what you mean, reading the `Matrix&lt;&gt;::operator*()` documentation, and discovering that it was returning a lazy evaluated `Product&lt;lhs,rhs&gt;` type. In this case, the act of construction of `Matrix2d` from `Product` performs the computation. In this case, the type specification does not serve the superfluous purpose it normally does. There's hidden foo there (that goes against the principle of least astonishment IMO but we could argue about target audiences, and whether a builder pattern or some kind of a verbose `ComputationBuilder` class would be superfluous when 99% of the code is meant to be lazy evaluated). Unless I'm wildly off base, I think this expression can only eventually evaluate into a `Matrix2d`, so stylistically I would probably wrap it in something like auto covar = Evaluate(sxx - 2 * (sx * mean_.transpose ())) / static_cast&lt;double&gt; (n_) + mean_ * mean_.transpose ()); But it's a personal choice (and probably, more of a Java style). I hope that you can agree that changing all the other lines to `auto` would be harmless, and would probably alert an ignorant reader like me, that since there was a conscious choice made to leave the type name on that one line, here's something special going on there. 
I get the feeling that C++ can only be mastered and appreciated after wallowing in the shallow depths of obsessing about bytes and mucking around with raw pointers for a long, long time. shared_ptr is a crazy construct, for example, not to mention outright syntax corner cases like SFINAE that have suddenly been codified as programming “techniques”. 
It doesn't help they picked a bad library for it in the first place.
Wuzzat
You, 3.x here. Compiler supports "most" features of C++98
How is that? There are large swaths of very useful code that could not be be easily expressed without them. Also, C++ does not have the ability to do what languages like Java/C# do with sharing binaries as simple changes make binaries not work together any longer Header only libraries get around the binary issues very well.
You still need a newer libstdc++ though right? How do you get that?
&gt; SESE SESE?
I use new language / standard library features because they make it *easier* to avoid bugs. I'm going to be doing whatever it is i'm doing regardless of the new language features. I suspect my management would rather I use std::the_thing than special::sauce::the_thing.
&gt;SESE Single entry, single exit
Honestly I wouldn't write std::for\_each much, it should be the last algorithm you consider. I believe it also comes from a time when we didn't have ranged base for loops, and it wasn't super useful then either because we didn't have lambdas (iirc BOOST\_FOREACH macro was more popular)
constexpr is pretty neat imo.. offers clearer semantics and provides way to optimize initialization
Migrating a large codebase to a new C++ version is hard. When you’ve spent your life building a product that can get a business off the ground, you become risk averse. Try to adopt the perspective of the business, and make small incremental changes which cumulatively make the codebase better. If you do this during downtimes, you’ll eventually be able to present a clean C++20 compile to your boss, then sell him on the switch with compile time improvements from the module system.
My favorite "missing" feature from Python is the easy list comprehensions and functionality built on them. Python map &gt; C++ map, for sure. Killer when combined with Zip, Repeat, etc. Can be replicated, of course, but I haven't found a library the does it nicely and cleanly yet. Could make it myself, but C++ is a hobby for me.
From a previous entry in the series: &gt; Based on these templates, C++ offers an array of powerful containers to store data in. Each of these containers comes with an API but also with a performance (scaling) guarantee. This in turn makes sure that implementors have to use state of the art algorithms - and they do. That's pretty misleading. Some of those guarantees aren't very useful and have huge performance implications. Like unordered_map having to expose buckets - who thought that was a good idea?
See https://github.com/ulfjack/ryu/issues/27#issuecomment-432052693 for the specific code that I shipped, where I already removed the ifdefs etc. Watch the presentation and then read the paper to understand the algorithm - unfortunately I only have a partial understanding (enough to not mess it up, and adapt it for fixed notation, and perform minor optimizations) so I can’t explain it from scratch. Powers of 5 matter because powers of 10 are powers of 2 multiplied by powers of 5. The latest 15.9 Preview should have charconv - look for the directory where vector is, and there should be three files: charconv (most MS specific code), xcharconv.h (central declarations of chars_format and to_chars_result), and xcharconv_ryu.h (Boost licensed, derived from Ryu). I wish I had a few more weeks to sit down and really work through the paper to understand the algorithm, but I need to keep working on completing charconv (finishing precision hexfloats now).
Ah. Thanks.
&gt; Can be replicated, of course, but I haven't found a library the does it nicely and cleanly yet. [range-v3](https://github.com/ericniebler/range-v3) has been around for years. ;-]
This sorely needed to be said. Still it makes me sad that it even to be said.
Something I think goes unmentioned is the convenience of this: export int foo(int bar, int x, int y) { return bar+x+y; } vs this Header: int foo(int bar, int x, int y); Cpp int foo(int bar, int x, int y) { return bar+x+y; } This makes creating new functions, as well as modifying old ones, easier and less prone to "Damn, forgot to change the header file, fix it and recompile". That human element alone saves compilation time and removes distractions
How is it covered?
What do you mean by that. Taking on a dep? As in a compilation time concern?
Totally agreed, in my case we use shared Citrix servers, so any updates with respect to new softwares must go through IT. Developers are in a restricted environment where all the necessary tools are provided to them by the IT and one cannot compile the latest version at will. Also, if you want newer versions you have to raise a ticket and justify your reason for the same to people up the chain before they approve your request. Also, as with most companies even we have multiple release cycles which can keep you preoccupied all year round, so no downtime as someone mentioned. But these are problems and I am asking for a solution. Unless we collectively think about solution, c++ will always be just an upgrade over c 
One of Bjarne's refrains is that it often takes a language 10 or more years before it's taken seriously in industry. And he's said he expects the same for the modern flavor of C++. Luckily, it's already been 7 years since 2011, so it makes sense that those techniques will begin working their way in in the coming years.
That's odd, honestly. We can also share the reports directly via Compiler Explorer. [Here's your snippet fed through](https://godbolt.org/z/hEj8hn), with wildly different results. I don't know if disk I/O itself is counted in the perf metrics or if the profile only starts once the files have been loaded into memory. (I'd guess Compiler Explorer doesn't have lightning fast disk access). My metrics came from a very fast SSD striped RAID, but (again) I don't know if I/O is included there.
Looks like not very actively maintained 
Most of the code is very C-like. The C++11 features we use are threads in the form of a threadpool, which necessitates lambdas. There are no explicit move semantics, smart pointers, auto, nor range-for.
I don't think you're in the right sub
Which one? Cairo? What if a different library had been used?
&gt; Single entry, single exit Wait, what? When did that become a bad thing?
Single entry isn't really relevant to C++, but I'd say enforcing single exit makes up for some ugly code (horrid if / else tree, which tends to hide your actual logic). It used to be done in C as you'd have to cleanup all resources before exiting, but this is unnecessary in C++ if you're properly utilizing RAII. I strongly prefer early returns when some conditions aren't satisfied, in pretty much any language.
I figured it was a fair question to ask. Not sure where else to ask it 🤷🏻‍♂️
These style guides are good if you are working on some personal project and just want some light lint checking. Otherwise I would recommend using something like a clang-tidy. Most of these style guides do not generalize well. Anyway if you want good resource on writing safe and good code, refer this instead. https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md 
Things that my lead calls as fancy or what you call as shiny new toys are in fact the constructs that would make the code more readable and maintanable. I am talking about lambdas and constexprs.
Things that my lead calls as fancy or what you call as shiny new toys are in fact the constructs that would make the code more readable and maintanable. I am talking about lambdas and constexprs.
This may have been asked a million times, but what is bad about using c++ as C W/ Classes ? 
There are also perfectly fine libraries that advertise themselves as header-only without a reason (e.g. Fmt) Sharing binaries is only a matter of agree on a common ABI (very problematic) or some sort of common intermediate language (less problematic), that I think is already in the works. 
Migrating an old codebase to a new dialect risks introducing bugs for no real reason. "If it ain't broke don't fix it" is a very strong maxim in commercial development. By all means, use modern C++ for a new project though, **if all the developers on the team know it**.
While the author makes good points, how would adding a standard graphic library bloat executables? The binary would only have to include graphics and window-related code if the c++ code used that portion of the standard library. Threads are an example of something C++ has that's a heavyweight feature, but doesn't add bloat. All the code for threads only gets linked into the program if I enable multithreading. If I want to use threads, then I compile with `-pthread`. If I don't want to use threads, then I don't compile with `-pthread`. There's no reason a graphics library would be any different. Need to use standard library graphics? Compile with `-pgraphics`. I'd only pay for what I used. Aside from that, C++ is better equipped than perhaps any other language to have a graphics library that works well on lots of different hardware so long as it's written at a high level. Much of the graphics library can be templated or can rely on static reflection, so that it's compiled as efficiently as possible for as many systems as possible. 
Something with a custom ISA that hasnt bothered to update the compiler and GCC stopped supporting it ? Or just some vendor SDK that doesn't compile with anything beyond 4.8 ? Because i've ran into those and just worked around them
Was that comment really directed at me?
Thanks for the reply. I may be out of my depth, but the way that you described how linkage of standard functionality works isn't congruent with my understanding. Are you referring to the posix thread library? I believe the `std::thread` wrapping facilities would be linked regardless. The easiest thing to consider is the situation of dynamic linking. By definition, the linker can't know what functionality in the standard library you wish to use, so without additional switches, it must export all the symbols. As for templatizing and static reflection, the point I was trying to make was that the branching must happen at runtime. Just because you can compile code for a particular instruction set, doesn't mean that when it runs on the client device, the hardware capabilities will be uniform. If you compile for ARM for example and expect the GPU capabilities to be the same across the ecosystem, you're in for a rough surprise. Production graphics code needs to be able to detect the myriad situations that come up and deal with that situation as it happens. This is analogous to checking for SIMD support at runtime and switching to a SIMD code path.
Cairo is not very C++ like in its interface, it feels like C.
https://stackoverflow.com/questions/45455345/performance-of-stdpartial-sort-versus-stdsort-when-sorting-the-whole-ran You're right ... didn't know that they use different algorithms. Thanks
No. A fundamental principal of C++ is that you only pay for what you use. If you use static linking (and I hazard a guess most people do), only the parts of the standard library you use will be linked and copied into your binary. If you use dynamic linking, *none* of the standard library will be copied into your binary. It will all be in the dynamic library. That’s the whole point. The standard library will be “bloated”, your code won’t be. And that bloat only happens once, leading to smaller total size when amortized over multiple binaries. (Note, templates muddy the issue somewhat, but I don’t think any of std::thread is templated?)
I agree with this post 100%. Standard libraries should be for operations that are expected to stay the same for a long time. Data structures, hierarchical file systems, BSD sockets, mutex, thread, time/date, linear algebra, parsing JSON, printing floating point numbers, and so on. C++ has done a good job at focusing on this kind of task in the library. It's clear that gfx is nowhere near stable enough for the C++ standard library.
&gt; This ballooned library size: 48MB on Linux And that is a problem why?
- move semantics (c++11) allow you to get rid of a lot of u necessary copying - Lambdas (c++11) are *more efficient* than function pointers because they almost always get inlined. In addition, Lambdas can capture local values by reference, so if you need to get a lot of different tiny pieces of data, they're useful. (just don't wrap it in a std::function object, which uses function pointers under the hood. Pass to a templated function) - std::string (c++11) is really goddamn efficient, works really well, and resizes automatically. - C++17 introduced both explicit and implicit template type deduction for classes, so in lots of cases you don't have to specify template types - c++17 adds guaranteed copy elison for objects constructed at the return statement, making factory patterns more efficient, and enabling functions that return immovable objects (by value) - c++11 standardizes a few different kinds of smart pointers, so new delete are rarely seen in modern code - threads were added to the standard library in c++11, and they're really easy to use. 
You wouldn't. Did anyone say you should?
This code is not valid C++ , it has many syntax and semantic errors 
SFINAE is a godawful monstrosity, but it's allowed me to write library code that's so easy and simple to use it feels like magic b/c it "just works" on a huge range of arbitrary types. (The library code is an Eldritch abomination under the hood, but it's an Eldritch abomination that looks and acts like a unicorn, and thanks to static_assert it prints out short error messages) Once C++20 is released, we can finally dump SFINAE in the trash and templated code will become 10x more elegant. 
Use of VLAs goes against the rules agreed upon by the United Nations. Do you really want to violate a standard agreed upon by some ~170 separate Nation-states, just because you couldn't be bothered to use std::vector?
Did you know it's possible to implement the lambda idea in c++11 using slightly different syntax? It relies on a piece of deep magic called expression templates, but it works. Boost even provides a working version of it. 
Thanks, I'll be the first to admit I'm not an expert in how the linker works. Suppose I compile a library that I want to load dynamically at runtime (say with `dlopen` or `LoadLibrary`). This library exposes some C interface that I can lookup symbols for and internally uses `std::thread` functionality. How is the link dependency to `std::thread` resolved in this case if not provided by the executable doing the loading?
It's not like I don't use auto :). All I wanted to say is that its convenience to the writer might be an inconvenience to the reader...
Again, it depends on the actual data you're dealing with, but here's one data point that could be interesting. https://github.com/Valloric/ycmd/pull/825
You definitely shouldn't link individual shared libraries with the standard library statically, I thought you were talking about an executable (I.e. linking everything statistically). Regarding the security aspect: If your code is important for the security of your system (e.g. processing untrusted input/accessible from the outside), you always need a way to patch your code anyway. Lots, if not most of the standard library code resides in header files. Just replacing the dll/so doesn't help with problems in that part of the code (not to mention your own bugs). Anyway. If you have indeed established, that the overhead has significant impact at the point of use (instead of just saying "oh, 42 MB sounds like a lot and is 13 times the original size"), then there is no arguing with that.
&gt; with wildly different results. how so ? from your snippet: &gt; preprocessing : 0.06 ( 6%) 0.21 ( 35%) 0.78 ( 36%) 1254 kB ( 1%) &gt; template instantiation : 0.18 ( 28%) 0.08 ( 18%) 0.27 ( 17%) 27081 kB ( 29%)
Depends on exactly how you’ve built the application, but if you are using dynamic linking then std::thread will be provided by the system’s dynamic library version of the standard library.
Also variadic templates were a huge improvement over c++98.
Btw. I just made a test on my ubuntu system and I ended up with a 2MB executable (vs 500k with dynamic linking). 43 MB seems like a lot. 
If you're using GCC, can't you set it to output a specific ABI version to ensure compatibility for the few breaking changes they do make? As far as I'm aware they're generally pretty good on the ABI thing
Possibly, but doing that would require you to know the settings used by your distro when building the packages for that release. Not ideal. If you're building a monolithic executable that does no dynamic loading of libraries you're quite likely to be ok. If not then you're quite likely to have a bad time.
A runtime event loop. I had proposed ASIO's `io_service` at the time, but in hindsight it would need to be more generic and less specific to i/o. In my opinion, these are utterly unavoidable. COM initially tried to not have them, then somebody hacked in a solution which turned out to be badly thought through, and much of COM's gotchas resulted in the following mess. Ultimately it's a debate about whether Modules ought to provide services via a formal rigid and discoverable interface, or whether they are never more than shared libraries. I would argue that the service model can quack like a shared library much easier than a shared library can quack like a service, and we inevitably always land back at the services model when sharing and reusing code. Have done now for four decades. So, in my opinion, stop fighting it, embrace reality.
Rough overview: The linker writes into the program header "This library needs this other library" and when loading a library (either through `dlopen` or executing a program, the routine is basically the same) the loader resolves those dependencies transitively. If it didn't do that you couldn't load any library without knowing all its dependencies. On Linux try `readelf -d $someliborexecutable | grep NEEDED`. Just imagine if it didn't do that. Would you be able to load something that uses libicu or any other libraries you are not aware of?
Absolutely nothing. Apparently some guys have come from the fashion industry and use things like modern, old-fashioned, etc.
C++98 FTW, more compilers, widespread support. Also, bigger number, therefore better.
&gt; If you use static linking (and I hazard a guess most people do) I am not sure about that. Take into account that many projects have to deal with 1) legal issues with OSS licenses, 2) security concerns and update-ability, 3) some third-parties only providing a dynamic library, 4) requirements of not mixing statically-linked CRT and dynamically-linked CRT (e.g. in MSVC)... In the end, many projects can statically link only a few of their dependencies.
The above proposal would get you that via `using myint128_t = wint128_t;`. I agree that ints up to the CPU cache line (often 512 bits) are by far the most common use case. WG14 have asked for the maximum guaranteed size to be reduced to the maximum supported alignment for that compiler and architecture, which seems reasonable.
How is it not a standard operation to have a graphical interface? Economical and Meteorological prediction software alike run the most complicated computations out there but at the end of the day, they have to still display their results graphically for us mere humans to understand it. Everyone runs their main computations in C, C++, or Fortran, but very few use these languages as the way to present their final product (e.g., finished data analysis).
I wonder can modules do something with problems like this: ```cpp // Root.h #include "Node.h" class Root{ public: auto views(){ using namespace ranges; return m_views| view::indirect; } private: std::vector&lt;std::unique_ptr&lt;Node&gt;&gt; m_nodes; std::vector&lt;std::unique_ptr&lt;View&gt;&gt; m_views; }; ``` ```cpp // Node.h class Node{ public: // return views that linked with this node auto views(){ // can't just move function implementation to .cpp, because of return type // need to include Root.h, but this will cause circular dependency m_root-&gt;views() | ranges::filter(...); } private: Root* m_root; } ``` ---------------------------- Currently, I solve this kind of problems by separating types from definition: ```cpp // RootTypes.h // forward declaration only class View; struct RootTypes{ using m_views_t = std::vector&lt;std::unique_ptr&lt;View&gt;&gt;; using views_t = indirect_view_t&lt;m_views_t&gt;; }; ``` ```cpp // Root.h class Root : public RootTypes{ public: views_t views(){ using namespace ranges; return m_views| view::indirect; } private: std::vector&lt;std::unique_ptr&lt;Node&gt;&gt; m_nodes; m_views_t m_views; }; ``` ```cpp // NodeTypes.h #include "RootTypes.h" class Node; struct NodeTypes{ // Fn implementation can be moved to NodeTypes.cpp, if needed. struct Fn{ Node&amp; node; bool operator()(Node&amp; other) const { return &amp;node == &amp;other; } } using views_t = ranges::filter_t&lt;RootTypes::views_t, Fn&gt;; } ``` ```cpp // Node.h class Node : NodeTypes{ public: // return views that linked with this node views_t views(); // in .cpp: return m_root-&gt;views() | ranges::filter(Fn{*this}); private: Root* m_root; } ``` Which is quite tedious...
It seems that adopting UB in C/C++ was a somewhat hasty decision. This is an only conclusion I come to every time I read about UB. &amp;#x200B;
What the article doesn't mention is that we might simply have the option to move/swap the whole set (altough that's probably not the normal use case, where both sets contain something) std::swap(source, destination); or destination = std::move(source); &amp;#x200B; What I can also recommend is using a flat\_set, where you won't have this problem, due to std::vector being the underlying storage (which was actually the advice I gave a coworker some time ago who ran into an similar issue - flat\_set even ended up being faster for the specific use case). &amp;#x200B; And if your feeling pragmatic there is still the option for const\_cast (which I don't recommend)... for (const auto&amp; pointer : source) destination.insert(const_cast&lt;std::decay_t&lt;decltype(pointer)&gt;&amp;&amp;&gt;(pointer)); source.clear(); &amp;#x200B; &amp;#x200B;
1. Learn C++ 2. Look for a C++ job Doesn't even have to be in that order. Same as any job basically. Or what kind of black magic answer were you looking for? 
For start you can check out Stroustrup's "A Tour Of C++" 2nd Edition. It's an overview of C++ for people with previous programming experience, updated to recent standard C++17.
As a user, I sympathize with your frustration. GUIs have been around for a long time certainly, but the guts of the implementations today are nothing like the GUIs of yesterday. I suspect this is why *most* language runtimes do not support GUIs as part of the standard. Even node.js, who I would argue is likely more spiritually aligned with adding GUI support to the runtime, offers no such support. The same is true of Swift, Kotlin, Ruby, Python etc. All of the above have *library* support for GUIs or graphical programming (to varying degrees), for which the "bar" for inclusion need not be as high, and the availability may not be ubiquitous (depending on how esoteric the target platform is).
&gt; Except that's exactly what a header file is doing. Except writing C++-compatible C header files is not blindly copy-pasting code. You are proving my point, by the way: being able to write such headers *is what matters*; not the ability to use arbitrary C code into C++. &gt; They don't (...) I am not sure how all you wrote is relevant to the discussion. Nobody has said ABIs have never been broken, nor that new ABIs are supposed to remain compatible between C and C++, nor that "C++ is C", nor that anybody is formally guaranteeing compatibility between X and Y, etc. It seems to me you are trying to disprove points that nobody has made. Please do not take this the wrong way. What I said, however, is that major vendors aren't going to be breaking the general ability to call old C source and binary interfaces from C++, for obvious reasons. They may introduce new features in either C or C++, they may introduce new ABIs for either C or C++, they may even change defaults; but any sane vendor will always provide the means to use old code and call old ABIs.
I blame the managers and whoever has the ability to perform high-level decisions. Managers do what they think is good, not what people want. Same mechanism as recent Blizzcon dissapointment on Diablo. ___ In one project there was C++11 compiler (at least I was told so). I can't blame codebase because it was probably written some time earlier. But library politics, what the fuck was happening there. They were rejecting adding absolutely any dependency to the repository. Asking for filesystem lib eventually ended as "Ok, we will provide it". `git pull` some time later and I saw this "filesystem API": int copy(std::string src, std::string dest) { system(("cp -r " + src + dest).c_str()); } What a surprise was it when it turned out that C++11 regex library is not supported. Project changed company few weeks later but seriously, good luck to anyone trying to parse shit *without* any regex library. I wouldn't be surprised if they also gaved an "API" for it in the form of calling `grep`/`awk` with regex argument and piping the result.
&gt; As for graphics, some parts are already quite stable (windowing and events) I agree on this point. In my original post, I contemplated something like a standardized way of querying for a surface and handling events. That said, this isn't actually 100% cut and dry either (although I think it is workable). Problems that would need to be addressed: - Not every OS supports every type of window presentation mode (in terms of how the window composites with anything else and its vertical sync, high-DPI, etc - Different OS's have different mechanisms for handling events, and sometimes there are multiple styles depending on the event - For example: many events might need to operate specifically on the main thread, while others need to happen on the event-sending thread - The events available from one OS to another may be wildly different (joystick support, haptic feedback, touch events, mouse/cursor) - If you plan on handling only a common subset of events, you have to think about how the user will be able to extend that subset as necessary. This would be a big proposal (albeit not as big as a graphics related one, which fully encompasses this one to a certain degree). I personally am not well-versed enough in the subject matter to even attempt it, as I'm just a consumer of the APIs mentioned above, but if I squint hard enough I can see a *there* there.
Check out my just-completed series for more details: https://blogs.msdn.microsoft.com/vcblog/2018/11/06/exploring-clang-tooling-part-3-rewriting-code-with-clang-tidy/ I'll be presenting tomorrow at code::dive about solving the problem high learning curve with AST Matchers and replacement locations!
I was just about to post that here... How you got it in before me I have no idea!
I read the first two parts of that series already and will have a look at the third when I find the time - thanks for sharing! &amp;#x200B; Make sure you post the video here when it's available :-)
And that, honestly, is a reason why your code has bugs. Variant does a bunch of things. The least of which is that it eliminates a metric tonne of bugs in limited polymorphic code. Now, really, you probably don't have that much limited polymorphic code. That is the second thing variant does. It turns that code into a bug filled minefield into something easy. So now code that isn't limited polymorphic style *can be*. Before maybe you used a pure virtual interface and heap allocation etc in order to solve a problem better suited to variant, because doing it manually is a pain. I mean, I get it. `std::filesystem` is a marginal improvement when your file io code is already written. But things like optional, function, span, variant and any are not just new types; they are a new vocabulary that enables new kinds of code sentences, paragraphs and essays. Before expressing "variant" was possible with void pointers, unions, enums, etc. But it was a "paragraph" of code to describe each instance. Now it is a single word. When you have a new word that expresses a key concept, the cognitive load of reasoning about it plummets, and entire new forms of expression result. But no, you can emulate it with a void pointer and an enum. So not worth it. 
haha thanks. was looking for opinions like "don't bother coming to cpp" or "you can use book x, course y", etc
thanks I am having a look
The history lesson of graphics was already told in 1968: [http://www.cap-lore.com/Hardware/Wheel.html](http://www.cap-lore.com/Hardware/Wheel.html) I agree. The functionality is too fluid to standardize. We don't have an agreed model of graphics hardware to program against, as opposed to the Von Neumann computer that every programming language targets.
Nowhitespaceplease:IthinkitistimetomakeC++benefitfromsomeofthefeaturesthathavemadePythonsopopularandversatile.IthinkC++11,14,17,…havedoneanexcellentjobtowardthatgoal,thegoalbeingtomodernizeC++.C++willneverbeexactlylikePython,andthatisagoodthing.Weneeddifferenttoolsfordifferentjobs.Youdon’twanttobanishscrewdriversbecauseyouhaveaplier. Moralofthestory:learnasmanylanguagesasyoucan. ? ThisisanexampleofsomethingyoucandoinmodernC++thatwouldhavebeenalmostimpossible(orverydifficult)todoinoldC++: Ihaveimplementedaheterogenousvector(muchlikePythonlists)usingstd::vectorunderneath.Itisnotthecommonvectorofvoidpointersapproach,oroneofitsmanyvariations(theyreallydefeatsthepurpose). OntopofthatIhaveimplementedaPandas-likedataframe.YoucoulddoalmosteverythingyoucoulddowithPandaswithintheC++syntaxandtypecheckingframework.Youcanadd/deleteanycolumntype,slice,runsummarizationfunctors,transpose,etc.likePandas.ButIalsoaddedsomethingthatPandasdoesn’thave;views.Youcanslicethedataframeandinsteadofgettinganotherdataframeyoucanopttogetaview.Aviewisadataframethatisareferencetoasliceoftheoriginaldataframe.Soifyouchangethedataintheviewthecorrespondingdataintheoriginaldataframewillalsobechanged.Nono, go,nopython.
I have no idea why someone would want to dynamically load the standard library. That seems both risky and foolish.
Ugh, please format it correctly. There's an edit button. But yes you have multiple solutions for that in modules. The first is the most simple: do the same thing. Your current solution will work with modules, but will also make `NodeType` and `RootType` invisible to users, and you can put the for classes in one file. Another solution that also currently work today is to split the declaration and definition of only the functions that causes problem. In your case, I would include `view.h` inside of `root.h`, and I would define `Node::views` after de declaration of `Root`. Then with modules, you can do something similar, importing view in root. You can also put it in one file and define problematic function after the classes, but you can already do they today too. My favorite solution of all is to use nested classes, which will make `Root` and `View` complete types.
For real? 😮 IIRC, doesn't `system` fork a new shell everytime it is called? There seems to be some serious issue here. I mean this has little to do with not using and everything to do with not knowing. I think Diablo is just a start, with such talents blizzard is in for some real fun. 
I don't care much about security issues as it was used only internally. But I wonder how much inputs would crash or have some problems due to mindless string concatenation. Their list directory function was literally piping the output of ls and splitting on blanks.
Excellent article. As someone who used to work in the field of computer graphics a long time ago, I am amazed at how much the field has changed since then. The new low overhead APIs, such as Vulkan, give a tremendous amount of control over the GPU to the developer. They are very powerful but far from beginner friendly. The new GPUs have hardware support for ray-tracing, which I never expected to see. The field is still in a state of flux. I love C++ but, I think we all agree, it has lots of glaring flaws. Whether the language has a bright feature or not will depend on features such as modules, contracts, reflection, deterministic exceptions... Even more important, in my opinion, will be investments into a better compile/link model, package management, and continuously finding ways to deprecate/remove old obsolete features. Please, let's get these right before expending limited resources into graphics libraries. I acknowledge there is value in having an 2D/3D library geared to students or people just getting into programming. But, if we had better package managers and build tools, it could be a much more pleasant experience for a beginner C++ programmer to download a graphics library from a remote repo and include it in their build. Trying to standardize a toy graphics library instead seems to me like an expensive waste of committee's time.
&gt; I enforce a policy of sticking to '98 unless there is a very compelling reason not to. I'm sorry, that's just stupid. No move semantics, no lambdas, none of the things that make modern C++ programming bearable. More, you're limiting your pool of programmers. Only a third-rate C++ programmer would want to work on a C++98 codebase that will never move to newer versions. &gt; Stuff like constexpr and enable_if is completely useless in my opinion "Completely useless". My theory is that you simply don't understand these features if you say that. If you said, "I see no reason to use these in our codebase," then fine, but there are really strong usecases for both of these.
And don't forget `auto`!
There is no need for any of these stuff. There are better "C++ way" of accomplishing these. What limits and at the same time impowers C++ compared with Python is its strict compile time type checking. Algorithm-wise C++ is miles ahead of Python. &amp;#x200B;
&gt; I think fundamentally having a threading model not be intrinsically linked with network IO is the most important part The Networking TS doesn't intrinsically link its threading model with network I/O: That's the point of having executor customization. The talk covers this starting [here](https://www.youtube.com/watch?v=hdRpCo94_C4#t=29m22s) and going through until ~40:00.
True, it is not just security issue, imagine the overhead of forking a shell everytime someone makes a call to their copy function or any other function that such fuckery.
My code has bugs because I’m not using a feature that has only been available for 2 days? 
Your “sent an email” link is damaged (missing dot). This is an excellent summary of the domain’s complexity!
This article talks about graphics as something which always targets the screen directly. There are plenty of uses where that is not the case. A simple 2D API allows you tackle those directly. You shouldn't need to learn about openGL shaders to draw a circle in a PNG file. Low level functions like drawing a line or a circle have their place just like you don't omit a sqrt() function because mathematica or matlab exists. IMHO the bigger issue is the cognitive load of having the ISO committee deal with another enormous area on top of the core language. It is a much better argument that something like a filesystem API is critical but something like a graphics API is not.
Right, so why not the standard library instead of an external library? I am not up to date here on the proposal itself. To me, it seems rather straightforward as an idea, albeit complicated in the details. I must be missing something. My graphics card outputs data over a cable to a screen. I can feed data into the GPU via my CPU because I see these letters appear as I type them, and I see the keyboard under lsusb regardless of whether my GPU is there or not. The latter being a very recent annoyance of mine... Anyways, there thus exists channels in the OS to send data from CPU to GPU to screen. Thus any C++ standard implementation needs to be able to represent a state of the screen and a way to send that state to the GPU via these existing channels. In addition, there needs to be a way to update the existing state of the screen. So far so good? How these states and updates are channeled to the screen seems to me beyond the standard library implementation. Just as how the basic operator+() works is up to compilers to figure out via OS libraries or whatnot, it is up to the compilers to create said channels to the screen as well. Perhaps such a standard graphics library's "ogstream&amp; operation&lt;&lt;(ogstream&amp; s, const ScreenData&amp; sd)", i.e., the screen output operation, will need the user to define the type of printer, be it the screen, a file, or something else, so the compiler can warn when the operation is not possible. (The igstream&amp; operation is perhaps more difficult.) This was quite a rant. But is the proposal far from what I describe? Because more than this seems like a bad idea, but this seems like the level where you want to be at. The screen as just another output...
I have never had to do that. Not that old I guess, name-pun intended. I can delay getting my information slightly by simply running the C/Fortran/C++ code via python these days, and Matlab a few years ago.
I agree with you. It's not about painting graphics on the screen, it's about having common classes like: brush, rgba color, 2D vector, etc. that are used in every single graphics library standardized.
My issue with the graphics proposal is it wasn't the best way to solve the identified points. IIRC The basic selling points for it was computers haven't been console based in a while. There should be a way to make a non-console application that can do the same things. So where does a 2D graphics api fit into that? That solves maybe 0.01% of problems, and even then it's just toy programs that want to display a bitmap that aren't so complicated they need an actual GUI. That would be much better handled via some toy header only lib that did just this. If anything we need a way to just replace console arguments in a graphical manner. Maybe a standardized option parsing lib where all options can be queried via json/xml. Then you could provide those arguments via command line or a graphical wrapper.
Mtly gaming runtime lib tries to handle much of this. However, I only meaningfully have to support NT, Linux, BSD, and Darwin...
SDL2 (the part about window and events) is a good starting point : it has been used by many projects on many platforms for a while, it is quite stable, and it offers a wide range of features related to window and events (e.g. game controllers support is excellent). 
I use SDL2 a lot myself and wrote some of the documentation for its vulkan loading functionality so that library always gets a plus one from me.
 &gt; Ugh, please format it correctly. It looks ok'ish to me... Try open with direct link https://www.reddit.com/r/cpp/comments/9uc0oa/modules_are_not_precompiled_headers/e95jgcm/ . I think it looks broken only in reddit notifications. &gt; Another solution that also currently work today is to split the declaration and definition of only the functions that causes problem. The problem is - to split definition and declaration I need to know function return type. It is hard to predict return type of ranges::view (sometimes close to impossible [see https://ericniebler.github.io/range-v3/index.html#range-views]). I would like to just return auto and call it a day. I'm asking - does it possible to do this with modules? Maybe modules will allow to separate implementation and definition of auto deducted functions? Or somehow forward module... If ranges with views will be adopted by stl2 ...someday somehow..., there should be some way to deal with situations like this. &gt; My favorite solution of all is to use nested classes, which will make Root and View complete types. Could you show, please?
I have to disagree with this paper. Your P0539 comparison is very misleading. P0539 does not use compiler intrinsics. [Here](https://godbolt.org/z/vtNy8Z) is a quick and dirty version using intrinsics, compiled using VC++. The code looks pretty optimal to me - look at the `test` function. I compared it against the same function written using __int128 with clang. The clang version is 15 instructions, VC++ is 20 instructions, a few extra `mov`s. So I do not really see a need for int128_t in the language. My primary objection is having int128_t does not really help me implement int256_t or int512_t. It is much better to standardize the building blocks - `_addcarry_u64` and `_mulx_u64` or `_umul128`. Standardizing these intrinsics will allow me to extend my code to any integer size I need. I want to do much more with the carry or the overflow flags. I want to terminate a loop is a `adc` carry is zero. I want to jump to a error handler if overflow flag is set. We need to expose these 30 year old processor features to the language, and then build general faculties on top.
&gt; The problem is - to split definition and declaration I need to know function return type. If you declare your functions to have return type deduction and define the function as inline in the header, it should work. struct Foo { auto bar(); }; inline auto Foo::bar() { struct hidden {} h; return h; // deduces the type } The other solution I was talking about is only applicable in some cases: struct Root { struct Node { void foo() { // Both Root and Node are complete } }; };
If you change a structure in the libraries you have to recompile everything that depends on them. I wasn't even getting into the compile flags and stuff. fmtlib has constexpr parts too but yeah it was kind of scary to see the asm come out of that because of the common parts pulled in. That is the cost they chose to pay for a library that one can just pull and include. Here is hoping that those parts, when it its standardized, are not in the header portion any longer but in the std lib binaries.
No, I am not asking to write to the screen without playing nice. Most OSs won't give any executable file the default right to write directly to graphics card, just as most OS does not give the default right to write to the file system, or even to the RAM for that manner. This is sensible. What I described is simply what happens: my keyboard is allowed to act as a mean to change the graphical output on my screen. I do not understand how you can disagree with me on this. I am going to assume you simply misunderstood something crucial and make my point clearer below. What I am asking above, is for a way to write graphical information, "ScreenData&amp;", to an open output graphical stream, "ogstream&amp;". The target handling of said stream is implementation specific, the handling of "ScreenData&amp;" is the only thing supposed new in the C++ standard. The only problem is in the formatting of said screen to the output stream, and linking to the available output streams. By formatting, I mean exactly the same way that you use "std::cout &lt;&lt; std::setprecision(4) &lt;&lt; 6.54321;" to remove some output. Of course, "std::scout &lt;&lt; ext::lib::format() &lt;&lt; ScreenData();" will require the ext::lib::format() from an external library to know how to deal with the data. Simply put: If "ogstream&amp;" is a file, then write to the file. If "ogstream&amp;" is a graphics card driver, then write to the graphics card driver. If "ogstream&amp;" is an OS window, then write to the OS window. Your version seems absurdly complicated --- there are reasons to make an apple pie from scratch, but apples, sugar, and wheat are available in most stores so those reasons are not very productive. But perhaps that is the proposal for the graphics library you are against? If so, I agree.
But fmt doesn't have to. It has a cpp file and can produce a linkable libraries. However it advertise as header only and people use it that way. Binary linking is a preprocessor define away. 
&gt; I have to disagree with this paper. Your P0539 comparison is very misleading. P0539 does not use compiler intrinsics. The whole point of the paper is that pure-library solutions don't optimise well. None of mppp, Boost.Multiprecision nor the reference implementation for P0539 do well. I don't think I was unfair to P0539 here. Everybody sucks on this, and it's very hard to reliably not suck badly without leaving standard C++. &gt; Here is a quick and dirty version using intrinsics, compiled using VC++. Nobody is claiming that one cannot use intrinsics to tell the compiler what you really meant. What I am claiming is that any sane implementation of P0539 is going to **have** to use compiler hooks or intrinsics to get out reasonable quality codegen. My second order claim is that if that is the case -- and I think both you and I agree on this -- then why not just push this facility into the language? Why go with library + intrinsics if simply extending the language is the right thing to do on this? If you re-read the paper, I see this proposal as exactly the right mechanism for P0539 to tell the compiler what it wants at the semantic rather than implementation level. Then the compiler can help you. &gt; We need to expose these 30 year old processor features to the language, and then build general faculties on top. We agree. But you'll never get carry recognition into C++. Too many CPUs don't implement carry arithmetic. And besides, carry recognition is the wrong approach. Tell the compiler what you want, not how to do it. Let it decide how best to implement what you want. Besides, the C language committee are not opposed in principle to adding this to C, let alone to C++. I would choose to look at that as an amazing opportunity to transform the support for bigint arithmetic. We just need to get the proposal into a form they can live with. I would love your help and support with that, if you are willing. 
&gt; Google provides this advice because they like to be inefficient? That's implausible on its face. Google has 85 thousand employees, according to a google.com search. 5,653 of them in the U.S. It only takes one person doing something above their skill set incorrectly in order to hose a production system. Checks and balances, static analysis, unit tests everywhere, nothing's perfect and things can still slip through the cracks. Given various other data I've acquired over the years, including conversations with folks who, at the time, worked at Google. I'll say that Google really doesn't care all that much about CPU efficiency, or man-hour efficiency. They care about having their programmers not write super tricky code even if that means the code isn't perfect. So Google's advice here, since they provide no evidence to demonstrate why their advice should be followed, is lazy. You can disagree with me, and maybe you have evidence to the contrary, but I can only draw conclusions from the information I have available. The information I have leads me to this conclusion *shrug*. &gt; I agree that template meta-programming is a way to solve a set of problems. I think it's usually a fairly small set of problems. I also think it's not necessarily the best code generation solution for some of the problems it's used for. But I agree it has uses. Template metaprogramming is the *only* way to solve some types of problems. There's no other way to detect at compile time whether a given class type has a function with a given signature, is there? I'd love to know. Take a look at the Boost.Hana user manual, which goes into more detail about this: https://www.boost.org/doc/libs/1_61_0/libs/hana/doc/html/index.html For me, and the work that I do, template metaprogramming gets used daily, in a fairly wide number of scenarios. We have a different set of experiences on it, apparently. &gt; I think asking for a concrete example in a style guide is asking too much of a style guide, especially when one goal of such a thing is to keep it brief. But anybody who's tried to read any STL implementation doesn't really need an example of where the danger is. (I do consider the STL to be a good domain for the technique, but I'm also very glad I don't have to modify it.) They say all sorts of things can be problematic in the style guide (https://google.github.io/styleguide/cppguide.html#Template_metaprogramming), and then don't show how. I don't know what more to say. I disagree with them on almost every point they've made aside from the compile time error messages (which are waaaaaaaaaaay less problematic with static asserts). Unless they provide me with something more than "don't use it because we say these things are problematic", I'm not inclined to agree with them, and since I don't work for them I can.
Modern processors can execute more than 1 memory operations per CPU clock cycle. For example, Intel Skylake has two memory read ports and one write port, so theoretically it can do two independent reads and one write per clock cycle. However, I don't think you can see that effect in the OP's code. His code accesses memory at random addresses, so cache misses causing pipeline stalls must dominate the performance.
Python does provide GUI support as part of the standard, but it is bad and nobody uses it.
It looks similar, but it isn't really the same thing. There is no way to implement `[][foo(&amp;1)]` using regular Boost.Lambda without a lot of boilerplate.
I've been looking at the wall-clock times (third column)
On a scale of "one" to "very bad", how bad is this idea?
Thanks! It does look decidedly non-rantish/well-thought-out to me, for what it's worth. ;-)
Thanks for the correction. I was worried I'd stumble over the terminology as this isn't my usual knowledge domain. I try to learn something new every day.
Yes, the reason is that string view is meant to be a "view". The constness is a large part of the point here. Of course mutable array sections and that are still useful, you can find that in the gsl::span class (and of course I think pretty much every major project has a span class lying around somewhere).
&gt; If you use static linking (and I hazard a guess most people do), only the parts of the standard library you use will be linked and copied into your binary. Note that it is often surprising to realize how much you pull in. It is deceptively easy to accidentally have the one function you need "conditionally" depend on a whole bunch of things that are pulled in because the linker does not know (or realize) that you will never take the condition, even if it could be known at compile-time.
Why stop tbere? Use code that your receptionist can understand.
Yeah I would think you want to run through memory sequentially to test real read and write bandwidth. Reading and writing randomly might be using the cache as well as reading and writing whole cache lines.
When building a dynamic library, you only mark certain symbols as exported. Any non-exported, non-referenced code can be removed by the linker. This is enforced on Windows - you have to explicitly export symbols (__delcspec(dllexport) in MSVC). I'm not an expert, but I believe that Clang and GCC export everything by default when targeting Linux, although this can be changed.
Downvote if you wish, but please tell me where I am incorrect so that I can issue corrections or delete my misinformation. I don't want to leave misleading information on my website.
Interesting article.
This sort of interface is useless for just about any modern purpose. Graphics APIs are complicated because rendering graphics is complicated. Sure, you can make a library that works like this (do it, and see what you can do with it!), but it will not be usable for anything but slow toy problems. Including it in the standard just adds clutter that doesn't help anyone.
JPEG has been around longer than JSON and will probably remain popular further into the future. I'm not sure jumping straight to putting in a game loop library makes sense but something that could read, write, display and provide a standard interface to interoperate with images would be really handy. 
If by "this stuff" you mean the things in your OP, then I agree; if by "this stuff" you mean range-v3, then.. lol?
I think the missing solution here that I’d wager is used by most is to just use `boost::variant`
&gt; Anyways, there thus exists channels in the OS to send data from CPU to GPU to screen. Thus any C++ standard implementation needs to be able to represent a state of the screen and a way to send that state to the GPU via these existing channels. Well, except for the systems that don't have gpus or screens. 
Thanks for the comment! The abstract interface for Actions makes no pairing assumption. So if you had, say, a picture editing program with a Reflect action that is it's own inverse then the MakeUndoAction will simply return an independent copy of itself.
clang-tidy is a linter which implements some of the cpp core guidelines. Some of those probably overlap with the Google ones.
I benchmarked Mersenne twister at 11ns/call on my 2.7GHz laptop. I found \`ranlux\` and \`knuth\_b\` to take roughly 7ns/call, but they were not nearly good enough even for my (weak) requirements for a RNG in numerical analysis.
Point remains. For every action, you have to find an opposite action, and then find an opposite for that which may not be the first action.
The fundamental problem is that there is very little common ground between UI systems - too little to be of any use. Perhaps what would be more useful is to establish some generic concepts for bidirectional reactive data bindings, so that you can write your own program with hooks, listeners, event handlers etc and you can add the "other side" in the any way you want, with QML, Electron etc.
Textbook reductio ad absurdum. But I feel you missed my point. I am not advocating against elegant and expressive code. I am advocating that it is also my duty to make sure that the code I leave behind is understood and if not then, I should evangelise and "raise" the level of the team that I work with.
interesting, but I found the beginning about the random allocator detracted from your point, because the random allocator seems to be flippant, so I had to mentally switch gears to start taking the remainder of the article seriously. IMHO.
If there are so many computers that have no graphic capabilities, why can we print to the command line? Maybe we should just have file logs. Also why have threads when there are so many computers with only one core? This makes no sense. These days your phone, your kids' tablets, your mom's phone, the $35 raspberry pi, the $30 kindle and your coffee machine have graphical displays. To say that there isn't enough availability as an argument is completely ridiculous. 
Really? It covers close to 100% of my personal usecase of 2D computer graphics. I cannot imagine anything in 2D computer graphics it does not cover. It also covers how I make my own interfaces... oh well, I am probably not using my computers and phone like a normal person then. I mostly spend my spare time when in front of a computer browsing the web, looking at pictures and videos, so what I described above would work. Anyways, I still cannot help but notice that no one is actually answering my question, so clearly this forum is not the correct place for getting answers.
Maybe. I forgot to test in debug mode.
 `auto under = size % Alignment;` My (educated) guess is that division and mod operators are \*slow\*, I suggest you use bit-masking to align pointers. e.g. auto under = size &amp; (Alignment-1); // constraint being Alignment is power-of-2 &amp;#x200B;
This is a good catch. I tested it in Compiler Explorer and it seems that the compiler is smart enough to do the rewrite itself since `Alignment` is a constant expression.
I think sean parent explains a quite similar mechanism very well https://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil The tldr is to store the history so that it behaves like its value based.
First, nobody should be restricted by the abilities of the most incompetent/junior person on a team, which is what you advocated. Second, pretty much the best way of learning is by doing. If, instead, you insist on teaching before doing, you'll end up with an order of magnitude slower learning. A `for(:)` loop, to someone used to `for(;;)` loops, looks strange. But a half-competent programmer, *without* being taught, can see what is going on. They won't know how it works, but they should know what it *intends to do*. It is only when it goes wrong that they need to know how it actually works. If your colleagues don't know lambdas, they can see something going on and google enough to get the basic idea. Actually, at this point, if someone is programming in C++ and doesn't recognize lambdas you should consider your hiring and retention practices; they are a 7 year old construct. Colleagues that need to be taught every single tiny thing about a language are akin to the receptionist. There is value in code so simple that a receptionist can understand it, but the cost of only writing code at the level that the least fluent in C++ person at your company can fully understand at a glance is constant and continuous. There is a fundamental difference between for(std::vector&lt;some_type&gt;&gt;::const_iterator it == myLongVectorName.begin(); it != myLongVectorName.end(); ++it) { } and for (auto&amp;&amp; x:myLongVectorName) { } that transcends "does the person know any C++11". The same is true of struct testForEven { bool operator()(int x) { return (x%2); }; }; // 500 lines later vec.erase( vec.end(), std::remove_if( vec.begin(), vec.end(), testForEven{} ) ); and remove_erase_if( vec, [](auto&amp;&amp; x){return (x%2)==0;} ); yes, a C programmer with rusty C++ might see the new constructs and not fully understand them, but a competent one can go and *learn* the new constructs without having their hand held. The simply massive change in the fundamental readability of the code overwealms the "but some developer doesn't know the new feature". 
&gt; You wouldn't run a webserver using this Depends. You _could_ use a `mapped_area`-per-request. Then the area will be unmapped once the request finishes. Not for long-lived allocations, obviously.
malloc has to return a pointer sufficiently aligned for any possible type.
Yeah, it started from a flippant comment. I think that might be the reason for the cold reception.
Oof. I was unaware of this. I'm not one to usually take "undefined behavior" lightly, but I seem to have underestimated it once again.
If it's a toy then it shouldn't be in the standard library.
Good advice. (Although in my defense, I have written a memory allocator, and I have in the past observed quantifiable speedups by using bit-masking rather than divsion, at least with MSVC).
cool. My experience may be out-of-date in this case.
I think this is the correct default: That way we have vocabulary type that can be created from a string litteral, a `const char*` and a `const string&amp;`, which are in my experience much more common than the need for a modifiable character sequence. One could imagine an additional `mutable_string_view` class, but in that case I'd rather use a `std::span&lt;char&gt;` anyway.
The only real problem here is that, with a no-op `deallocate`, you'll have to swap that out. You can fix this for whole pages by using `MADV_DONTNEED`, but partial pages still suck. Unless you somehow prevent other threads from running and zero the bits and check, but I'm not sure if that is actually possible.
Well yes, that would've been better, but breaks backwards compatibility now. Story of the life of C++, for almost everything where there's a choice C++ defaults to the worse option mostly for backwards compatibility.
Right, so by the OP logic, we should make stdout always write to a file on disk since some embedded computers don't have graphical displays. 
Why would marking all functions nodiscard implicitly break backward compatibility? This would just generate more warnings, right? Old code would still compile.
Maybe after modules something can be done. Otherwise, header files means it would be difficult to incrementally adopt; as long as any part of your project isn't using the flag, the declarations in headers will still need to still have the annotations.
Yeah, it'd have to be per-file (but what about header includes?)
A good start might be not insisting on having to move to using only the latest and shiniest new techniques. People who care more about getting things done in real world projects with real world priorities and constraints get turned away by all the insistence on _only_ using "approved" ways to do things.
`[[nodiscard]]` is amazing. We added over 3000 occurrences to MSVC's STL and it has caught amazing bugs in major codebases. The classic mistake is calling `v.empty()` instead of `v.clear()`. We've also seen: * `is_sorted()` dropped on the floor (instead of asserted). * `remove()` and `remove_if()` called without the erase-remove idiom. * `for (It i1 = c1.begin(), i2 = c2.begin(); i1 != c1.end(), i2 != c2.end(); ++i1, ++i2)` was the most amazing, with multiple occurrences.
Unfortunately, Clang/LLVM poorly optimizes code that contains both division and modulo by a constant (e.g. both `/ 100` and `% 100`). There are multiple bugs tracking this.
std::string was C++98. Class Template Argument Deduction is implicit - I am not sure what it would mean for it to be explicit. Can you clarify?
The command–query separation principle does effectively say that all non-void returning functions should be `[[nodiscard]]`: if it makes sense to call a function and ignore its return value, you must be calling that function for its side effects. In practice if a warning complains about me not checking `printf`'s return value I'm just going to turn that warning off. In newly written code `[[nodiscard]]` will hopefully be much more common than a hypothetical `[[safediscard]]` would be, but I think a default-nodiscard policy would be too noisy to be useful.
Ah, nodiscard on comparison operators. I hadn't even considered that.
You can easily implement your own any with "classic" type erasure: class any_base { // virtual dtor and clone function }; template&lt;class T&gt; class any_impl: public any_base { T Data; // clone implementation } class any { std::unique_ptr&lt;any_base&gt; Data; // templated ctor etc. } It won't have small buffer optimisation, but if you create two visualisers: * any\_impl&lt;\*&gt; =&gt; show its Data * any =&gt; show its Data.\_Mypair.\_Myval2 (i.e. same as unique\_ptr) \- VS will show its value flawlessly.
Do you mind explaining the last example more?
Honestly I think tackling OS event handling and window creation would be a far more useful things to do, but then again we already have libraries like SDL so I'm not sure what would be gained from all that.
Comma operator discards the result of of the left subexpression. This means result of `i1 != c1.end()` is just ignored.
DAAT allocator do'
Presumably the comma should be a `&amp;&amp;`? 
&gt; Perhaps a standard compiler flag can be developed, e.g. 'flag=modern' if set would make a different assumption about non-annotated parts. The problem with this kind of solution, as always, is that the compiler is bad at distinguishing _my code_ from code that was included in a header I have no control over. The issue is that the flag would need to be applied to something that's parsing C++ and building a syntax tree, while the distinction between my own code and the header code is something that's completely gone once the pre-processor is done with the file. So sure, you can have the flag, but only if every last library you use still works when you turn it on. 
That'd explain a very sad and upsetting glibc `malloc` "leak" bug that haunted me for several weeks a few years back.
Could you explain the threading issue? free requires that other threads have stopped accessing the memory, so from libc standpoint you can assume that. Sounds like the only real reason is intern fragmentation. Kernel tracks memory usage with 1 bit per page (4K or more), libc typically 1 bit per 16 bytes approximately.
You can fit more than 8-byte allocation on a page. You can zero it out when it is freed, but you can't atomically look at all the other bytes on the same page to check if they are zeroed - maybe it just happened to be zero, but it's still live and could have a non-zero value written which would be lost by the MADV. ... well, I suppose you could store an extra bit somewhere to say "this is live" ... but at that point, you're well on your way to making a *real* memory allocator.
Ideally they would store them into a reclaimable list (in user space) that the Kernel could go and grab if needed and that mmap would grab from in priority (saving some Kernel calls). That's what the vdso is supposed to do, but I don't know if they went to the trouble of doing that yet.
I kinda enjoyed being misled and the change-in-gear. 
Paging is what allows you to have virtual memory that doesn't always have to be backed by physical memory. Since the memory is virtual, it can also have a different memory address than where it is physically mapped to. This could also allow for multiple processes to have memory areas that map to the same (virtual) address but are still physically separate. This requires hardware support, the hardware that manages translating virtual addresses to physical addresses works at a page granularity. So the operating system has to page in or out entire pages of memory at a time if it has to move data in physical memory around (for whatever reason). One usual reason to do this is to ensure that a virtual address is valid, as operating systems can actually allow physical memory to be paged to swap (or even discarded!) when it's not actively in use. So far this is all independent of 'overcommit' and memory accounting. Most operating systems won't let you allocate more virtual memory than could be made available physically (if necessary, but swapping and flushing discardable caches and buffers) if necessary. The Linux devs, however, figured that a lot of virtual memory space allocation might actually never be *physically* used. So just like airlines allow more passengers to reserve spots on a plane than the plane can physically fit (banking on some people to not show), Linux allows processes to request memory even beyond what could fit in physical memory before it starts failing requests. In fact I'm not sure if Linux ever requests a request for more virtual address space allocation. Unlike airlines, the Linux kernel can't offer vouchers for memory allocations to go away if too many allocations for physical memory get claimed to support. Instead there's an "OOM killer" that starts killing processes until the outstanding allocations on physical memory drop below what physical memory can support again. Other OSes don't need an OOM killer because they don't over-allocate memory in the way Linux does by default.
I understand this is a random shot -- but how do you solve the same problem for Ubuntu which doesn't have devtoolset?
You one of those people that still integrate using a custom made circuit? Otherwise, each of those are solved, so they are not important. It's not like you are going to ask for the standard library to invent a new branch of mathematics before it can be included...
Nice troll! Someone claiming on an html webpage that text, pictures, and videos are unimportant for graphics did make me laugh! Thanks.
Just a question, why is section 3.1 necessary? Why not simply jump directly to section 3.10, and define the new typedefs for the large integers? The implementation of those typedefs will need some compiler magic, perhaps similar to what was described in section 3.1, but unless there is a reason for users to use that syntax directly, it should be an implementation detail.
&gt;The Networking TS doesn't intrinsically link a threading model with network I/O Yes, it does. The threading model is the number of threads you have calling io_context::run.
Several of the types for which string_view wants to be a wrapper are immutable. For example, string literals, HSTRING, BSTR, etc.
Thank you!
&gt; Except writing C++-compatible C header files is not blindly copy-pasting code. See, now we're getting into the semantics of "a subset of C which is compatible with C++." :p Which is back to my point. When we update C, C++ is not rebased onto that new version. I think perhaps you're getting hung up on my use of "rebase" here? I'm using it in the git sense, as in all your changes are moved from being a fork of an old version to being applied onto the new version. C++ _does not do that_. Period. Cherry-picking is very much _not the same thing_ as a rebase. :) &gt; but any sane vendor will always provide the means to use old code and call old ABIs. Probably, yeah. But the result may not be C++, just like GCC allowing VLAs in "gnu++" mode is not actually C++, which is the point of this whole thread. :) I mean this probably won't be a real issue anytime in the near term, but if we're still using C++ 50 years from now... who knows? Yes, that's an academic distinction, but the OP is asking an academic question, so these distinctions are relevant to understanding his professor's standpoint. :) C++ isn't what the vendor allows you to compile; C++ is what the standard says it is. "It compiles" is true of a lot of code that isn't legal C++, and hence the OP's professor is entirely correct and justified in taking points off the OP's assignment for writing hybrid C++/C99 code in a C++ class.
That is arguably a 3rd solution. Simply keep track of all versions of the document. Have a tree/graph of revisions; undo/redo simply moves which one is current. Undo/redo history is kept separate from said state tree. Actions start a new "forward" branch. At any time you can view the full state tree and pick a node to jump to. This can be implemented as an immutable document. Possibly stored as a git database. 
Please provide an example app demonstrating how to use the proposed 2D graphics API to render text onto the screen.
I mean that there's ways of telling the compiler what types to deduce. Suppose you have a simple wrapper class: template&lt;class T&gt; struct Wrapper { T value; //Maybe it's convertible; I dunno operator T&amp;() { return value; } }; In this case, it's useful to *not* define a constructor, because it allows instances of `Wrapper` to be constructed without copying or moving. Unfortunately, the compiler won't be able to deduce the type of `Wrapper`: //Valid, because std::mutex is specified //And copy/move is elided Wrapper&lt;std::mutex&gt; a = std::mutex{}; //Compiler can't deduce T Wrapper b { std::mutex{} }; //Lmao wut //I would *have* to define //the lambda somewhere else Wrapper c { [](){ return 12; } }; However, we can explicitly specify how the compiler should deduce the type of `Wrapper`: This is how you handle the general case: template&lt;class T&gt; Wrapper(T) -&gt; Wrapper&lt;T&gt;; And this is how to handle a specific case, like if we wanted string literals to be wrapped as though they were strings: Wrapper(char const*) -&gt; Wrapper&lt;std::string&gt;; Now I can write: Wrapper a { 12 }; //Deduces int Wrapper b { "Hello!" }; //Deduces std::string //Deduces lambda type: Wrapper c { []() { return 10; } }; 
Is `std::set` and `std::unordered_set` good enough?
Does any compiler properly optimize around those operations? Last time I checked, none was able to reduce a `/` and a `%` to a single `div` (or equivalent series of cheaper instructions), but it's been a while; I'd love for the situation to have changed.
Your blog post was pretty good. I'm going to check out the rest of your website. Keep making content. 
People who do `-Werror` are signing up for that breakage. 
Which only goes further to make the point here, I think. A GUI is perfectly serviceable as a library outside the language proper, and that's how it should be handled.
Then I would maybe suggest [Tessil](https://github.com/Tessil) which has good implementation of containers. Here are [some benchmark](https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html) But I would suggest to measure. Most of the time, the standard one are really good enough.
[This is an ancient report of a one-way memory allocator.](https://groups.google.com/forum/message/raw?msg=comp.lang.ada/E9bNCvDQ12k/1tezW24ZxdAJ) I can't believe no one has mentioned it yet.
Because I teach both Data Structures and Advanced Data Structures courses at an University. &amp;#x200B; More over, the underlying data structure used in the implementation may lead to interesting discussions with my students.
The Go team explored using a Request Oriented Collector at one point in time, as can be seen [if you ctrl-f on this page.](https://blog.golang.org/ismmkeynote) it's a fun concept.
Thank you. This looks very promising! =D
I may have not phrased my point well, I’m saying that none of those things have a programatic interface that is similar to writing bytes + format handlers to a stream.
/r/cpp_questions
http://cpp.sh/4yivi
Right so there’s nothing in the link or comments that explains [[nodiscard]]. Anyone?
Are you really sure about JSON? I doubt JSON survive the next couple of decades.
Thanks for posting those links! Very well written explanations. 
Let's hope for the best!
Upvoted for "sensibly configured" 😀😀😀😀😀
MSVC reuses the computation for div by constant.
Correct me if I'm wrong, but I thought this was a freeze for *new papers*. Has that changed, or is the modules statement simply because its scope is large enough that there wouldn't be enough time after this meeting regardless?
Modules is a TS so it is a quickly evolving individual standard. Don’t forget modules is still quite polemic and could cause delays on the standard if we try to force into national bodies. It’s not as critical to fit modules in this standard as we are currently moving really quickly by delivering a new version consistently every three years.
As far as I understood it, modules has been around in paper form for quite a while, including as a TS, so it would be eligible for a deferred adoption in Kona, as would any other papers in the mailing right now. However, even after EWG adopts it, it needs to go through CWG and the workload involved to get it reviewed and merged is enormous, so it would still take up quite a bit of time in the finalization of the working draft.
Yes. Presumably the `operator!=` for iterator was made nodiscard
Use module imports instead?
Because two assumptions are made [implicitly]. 1. You know about cppreference.com and use it. 2. You are able to type 'nodiscard' in a search box. Like [so](https://en.cppreference.com/mwiki/index.php?title=Special%3ASearch&amp;search=nodiscard) 3. You follow the top reslt by clicking on it and reading the presented information. 
Ij I remember correctly, at San Diego they freeze features. Then there will be a phase of rewording for accepted features. 
Ah, that was Kona to my knowledge.
The `&lt;random&gt;` abstraction of separating numerical distribution from the prng engine itself seems analogous to the possible interface design her. To that effect, I think I can imagine a "tween" to be something like `tween&lt;T, easing_function_t&gt;` where `T` just needs to support the arithmetic operators. This way, you can tween, say, a packed simd group of four floats just as easily as you could tween a float, given the right operators. Arranging the tweens contiguously in memory and invoking `ease` on each of them with a timestep for each could be the responsibility of the caller (or a separate abstraction). Organizing all the things that ease in the same way and have similar lifetimes is probably important (consider a game object with a volume and several animations playing during a sequence). So it may be too much work for the implementation to try to figure that out. tl;dr definitely templatize the type. Being able to animate not just floats, but simd arrays, dual quaternions, ???, etc is super useful. Consider moving the "loop" outside of the library.
&gt;If you declare your functions to have return type deduction and define the function as inline in the header, it should work. I didn't know it is possible. Though this not solves problem completely, because it is still necessary to include Root.h in header: class Root; class Node{ public: // return views that linked with this node auto views(); private: Root* m_root; } #include "Root.h" inline auto Node::views(){ m_root-&gt;views() | ranges::filter(...); }
Yep, there should be an easy graphic library that you can use. But it should not be in the standard or at least in the standard should just be a small interface (like garbage collector?)
It doesn't help to have "vector of bool" as name either.
What I can definitely recommend is forward declaring the templated classes with the default template parameters and afterwards declare a using to be able to use the templated classes with default parameters without having to write angle brackets &lt;&gt; all the time. nlohmann\_json is a great example for this: [https://github.com/nlohmann/json/blob/develop/single\_include/nlohmann/json.hpp](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp) &amp;#x200B; template &lt; typename Duration = float, typename Id = int, typename Float = float, template&lt; typename Signature &gt; class Function = std::function &gt; struct config_base; using config = config_base&lt;&gt;; &amp;#x200B;
I think the problem is that it is relatively easy to identify functions whose result absolutely must not be discarded (e.g. empty) but it is much harder to decide (without knowing the context) if the return value of a function that has a side effect can safely be discarded. What I'd like to have is an annotation that subsumed multiple other ones (like nodiscard, const, constexpr, no except, an implied no-virtual and side-effect free)
While I would love to have a *good* module system for C++, I feel like the current proposals are just not there. It is relying on heroic efforts by build systems to actually work. In his CPP Con talk the GCC module implementer referred to it as an oracle and a "magic box", which does not inspire confidence. The only thing worse than not having a module system is having a bad module system in the standard. Once it becomes a standard it will be around for a long, long time. We don't want another auto_ptr or exported templates.
&gt; Apparently ISO has some rules because of which members cannot tweet before Saturday's vote. It's more than that: we do not self-publish what we or others may or may not have said at committee. The only written record of debate held at committee meetings is the official minutes taken by the minute keeper Nina. There are a long list of very good reasons for this rule. The Federal Reserve has the same rule, as does every serious standards setting body which physically meets and debates. Even after the plenary vote, you should avoid anything in any tweet or public statement about committee business which is not 100% factual. i.e. no displays of emotion, no opinion, no emojis. I would also add that very, very rarely, a plenary vote can be reversed after the fact. So don't say "WG21 voted for X". Say instead "WG21's plenary session on Sunday voted for X", which is factually true whereas the former is not. 
How about: std::find\_in(v.begin(), v.end()).whether(\[\](int a){return a &gt; 5;}); ?
This is simply untrue for the libc allocators on Linux, Windows, FreeBSD and Mac OS. I think you are confusing fragmentation with "recycling mmapped pages". If a 4Kb page^(1) is completely unused, all the major libc allocators **will** munmap it back to the system the next time free space coalescing is performed. 1: ptmalloc2, the glibc allocator, allocates 1Mb blocks per arena. This makes Linux particularly prone to fragmentation preventing release of memory back to the system. That in turn causes most Linux distros to default to over-commit. A more sane strategy, used by every other OS, is to have your memory allocator more aggressively release memory back to the system, then you don't need to use unstable kernel hacks.
What type is x?
Sorry, but this is misleading so I am removing it. [You can find the schedule here](http://wg21.link/p1000). Modules does not have to ship at this meeting.
Exactly. And I have a real experience with nodiscard policy by default which was enforced by PCLint rule. What a pain. People who think that is a good idea usually don't imagine how many valid cases exist. Examples are printf or std::set::insert. In my case it was made even worse by a secret whitelist maintained by the architect. So for example printf was whitelisted but insert wasn't. So that added a great deal of confusion on top. There is really no need to go that far!
&gt; Even after the plenary vote, you should avoid anything in any tweet or public statement about committee business which is not 100% factual. i.e. no displays of emotion, no opinion, no emojis. I would also add that very, very rarely, a plenary vote can be reversed after the fact. So don't say "WG21 voted for X". Say instead "WG21's plenary session on Sunday voted for X", which is factually true whereas the former is not. This is not committee policy.
So in the example of the blog post, it'd catch the lack of assignment of .begin() and throw a warning?
`initializer_list&lt;int&gt; const`
Honestly whether you store the previous versions of the document (or just deltas) or store the actual _actions_ depends on how expensive those actions are to re-apply vs how much memory it takes to store the history - a classic space/time trade-off.
If the implementation of the set is not relevant to the assignment, I would just use a standard one - 2.9MB of data is not a lot, you shouldn't have performance issues.
&gt; Java swing (a similar counterpart) was an abomination that truly did only have applications for teaching but could have (and should have been) relegated to a library. interestingly they did this with JavaFX : it was originally part of java proper and they finally moved it to an external library, **as it should have been since the very beginning**
&gt; some kind of preprocessor language with c++ attributes instead of macros...which is also not so cool. why ? it's a method used with great success in a lot of other programming languages.
You got it.
gcc and clang [also clang-cl on Windows native] already implement `int128_t`, while [google::abseil](https://github.com/abseil/abseil-cpp/tree/master/absl/numeric) proposes a library solution.
I like this. This is almost what I did when writing [my tweening wrapper](https://github.com/chunkyguy/hideous-engine/blob/master/HideousGameEngine/include/he/Animation/Tweener.h) on top of [AHEasing](https://github.com/warrenm/AHEasing) typedef AHFloat (*EasingFunction)(AHFloat); // Any class that provides following operations is tweenable: // 1. Addition: operator + () // 2. Subtraction: operator - () // 3. Multiplication with floating type: operator * (const float) // 4. Copyable (for returning) copy constructor | operator = () class Tweener{ public: Tweener(EasingFunction func, T start, T end) : function_(func), start_(start), end_(end) {} T operator()(float time){ return start_ + function_(time) * (end_ - start_); } private: T start_; T end_; EasingFunction function_; };
Are you sure? GCC disagrees.
Thanks for the feedback, really appreciated. The case of tweening any type `T` that supports operations `T + T` and `float * T` is supported by [the update callback](https://github.com/j-jorge/tweenerspp/blob/draft/include/tweeners/detail/builder.tpp#L44). The part I am more dubious about is [the template parameters in `tweeners::system`](https://github.com/j-jorge/tweenerspp/blob/draft/include/tweeners/system.hpp#L28). For them I do not see for example any use case where `id_type` should not be `std::size_t`, `float_type` not be `float` (it is used to represent the ratio in the update), and `duration_type` not be `float` too (at the end [durations are casted to float](https://github.com/j-jorge/tweenerspp/blob/draft/include/tweeners/detail/system.tpp#L472) to get the ratio of the elapsed time over the total time). Does anyone actually need to represent a floating point value with anything other than `float` in this case? 
It is clearly more readable, thanks.
To the extent to which you use `std::net::io_context` you're correct. However you can very well use the asynchronous model of the Networking TS (i.e. all the support machinery of the Networking TS) to build Networking TS-compatible components that don't use `std::net::io_context` at all. Then there's [this paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1322r0.html).
GCC, Clang and ICC all compile a pair of / and % by a variable to a sibgle `div` instruction. See https://www.godbolt.org/z/Z_qQ0C
Ah, I see. Thanks!
Which version, targeting which C++ standard? Veedrac is correct but the rules changed from C++14 to C++17.
&gt; I like this. This is almost what I did when writing my tweening wrapper on top of AHEasing note that you should look into FMA linear interpolation if you have recent CPUs : https://fgiesen.wordpress.com/2012/08/15/linear-interpolation-past-present-and-future/ ; if you do it a lot very repetitively it can be quite the gain
Really nice, I've looked for a tool like that for a long time.
So, in the example I saw the API used like this: int x; setup(..., x); interpolate(...); // Now x contains the interpolated value While, an immutable approach would be something like this: setup(...) const auto x = interpolate(...); 
Wow, took me a bit to get the last one.
One case is where you have intrinsic refcounting, such as with Qt. In At, you might create a `unique_ptr&lt;QWidget&gt;`, then `.release()` it when you insert it into the ownership tree.
Thank you for that, recently I started to use remove_if(), and if I had not been notified, I would've kept it like it this. [[nodiscard]] is a blessing!
No. But maybe you'll agree with me that I can only measure anything when I have *something* to measure. This is why I'm asking for options specialized for strings.
It hurts me when people use the word "tween". 
I’m so glad I understand like half of this. 
Hello, I am the author of mp++. I feel flattered by the fact that mp++ has been mentioned in a standard proposal :) &amp;#x200B; I just wanted to point out that in the mp++ benchmarks that you link to in the proposal, the benchmarked mp++ class is a general-purpose arbitrary-precision integer class, not a 128bit integer class. The performance penalty that the benchmarks show wrt `(u)__int128_t` is due to the fact that there will be additional overflow checks and branching in order to enlarge the storage to accommodate values that do not fit in 128 bits. &amp;#x200B; (mp++ does use internally `(u)__int128_t` (if available) to efficiently implement optimised codepaths for 1/2-limbs integers) &amp;#x200B;
I'm pretty sure the Fibonacci function should be: tie(a, b) = tuple{b, a + b};
Also: &gt;This means the optimizer was able to compute 60 Fibonacci numbers and sum the last 50 at compile-time! &gt; &gt; static long N = 50; &gt; &gt; auto items = fibonacci() &gt; &gt;&gt; drop(n - 10) &gt; &gt;&gt; take(n); That drops _40_ and then takes 50, so computes 90 numbers, not 60.
Why would this be undefined behavior? 
because malloc does not create objects, `operator new` does
My compiler complains that the code will initialize the members in a different order than you appear to be expecting.
You don't need to create an instance of int, only allocate memory for it. In this case it's not UB.
I tried compiling my project with clang and -Wall yesterday for the first time and got so many warnings about this exact issue. No bugs luckily, but it's always a bit disheartening to see a compiler enumerate all the many, many different reasons why your code is bad...
The value of `foo.i` doesn't need to be 2. It is actually undefined. GCC and Clang issue a warning when this mistake is made.
As tweening is done over a duration, why not use the chrono library? That way I know that the interface takes milliseconds (for example) and I can pass any compatible duration type I want.
Buckaroo looks interesting.
So what have we learnt class? C++ today isn't what people might think it is and that maths is still hard.
Why would you need that for an int?
Wohooo!! Finally :-) I know what I'll try out tonight.
see the paper linked in my other answer : http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0593r2.html
Sorry for my terrible English, but I don't understand what you are trying to say :(
No. You should ask BrangdonJ@ :) I thought about it when I made my previous comment, and couldn't come up with a reasonable example.
I must be missing something here. The entire point I have been making the entire time is to leave the rendering to renderers and the API to the standard library. Yet my suggestion does not work because it does not perform the rendering fast enough? Even though it is not supposed to do any rendering...
Exactly. It's incredibly straightforward undefined behavior! You rely on uninitialized value. And this is a relatively "light" case. `j` can be an arbitrarily sophisticated object, which might cause incredibly weird "mandelbugs"
I actually watched this a long time ago and made a gist on Github to record my thoughts. I'm linking it here in case someone finds it useful: [https://gist.github.com/quantumelixir/b25cfb5f29c63b33fd4ed407bdcfb40d](https://gist.github.com/quantumelixir/b25cfb5f29c63b33fd4ed407bdcfb40d) The idea of using templates to create an inheritance hierarchy internally based on client-side usage is really cool. I hadn't seen it before that talk. That said, I don't think these ideas readily apply in my use case. Concretely (using the notation from the gist) if I add new pair of ModelType classes (derived from ConceptType) representing actions that are supposed to be inverses of each other, then the relevant logic, which would end up referencing these two types, still needs to appear outside of the ObjectType class instead of hiding it away internally.
Would it be defined if you did `int j = 0;` as well as the initialiser list or would it still initialise them in the 'wrong' order?
How many bugs can a compiler have while still being standards compliant?
My problem is that to do that I have to will myself to ignore the hundreds of int to size_t conversion warnings
For example, replacing a vector object with a rasterised version of it. When the command is created, the object it is going to be applied to may not be known. The command might be part of a macro, for example, that can be applied to different objects at different times. Do() rasterises the object, which is a relatively slow process that only needs to happen once. Threading is also an issue. The command would be created by a UI thread, and then handed off to be executed by a background thread. This avoids locking up the UI while the rasterisation happens.
Yeah as a Windows user, using 3rd party libraries is a nightmare, especially when trying to configure it with CMake so it works for other computers/operating systems. Anyone have opinions on which package managers are the best rn?
It's as complicated as you would expect :) ``` #include &lt;iostream&gt; class Foo { public: int i; int j = 0; Foo() : j(100), i(j + 2) {} }; int main() { Foo foo; std::cout &lt;&lt; foo.i &lt;&lt; " " &lt;&lt; foo.j &lt;&lt; std::endl; } ``` All the errors will be flagged and the output is again (!) i.e. your `0` initialization is ignored: ``` 2 100 ``` ``` #include &lt;iostream&gt; class Foo { public: int i; int j = 0; Foo() : j(100) {} }; int main() { Foo foo; std::cout &lt;&lt; foo.i &lt;&lt; " " &lt;&lt; foo.j &lt;&lt; std::endl; } ``` Gives no error (for `j`) and yields: ``` 0 100 ``` The reason is explained here: https://stackoverflow.com/a/13662599
In practice when I used your approach I ended up writing actions whose only purpose was to be paired with another action. It wasn't used directly by anything else. When that happens, having the Do and Undo logic split over two classes is a hindrance. Have you actually written a large, complex app with your approach?
I’m just saying it’s a very technical topic and I’m happy I have some kind of idea what you mean. Your English is fine, it’s mostly the technical terms that make it complicated =)
Infinitely many, as long as none of them affect behaviour defined in the standard.
Yes I (perhaps incorrectly) excluded pure file drawing because it seemed not useful or “significant “ enough to be worth including in any way (especially since things like libpng exist). For the purposes of picking up the language and going in an educational setting, say, having something be interactive feels like a full stop requirement. That said perhaps the majority feels otherwise, as this is just my opinion. 
Hell yes!
And since this is not a warning but a downright error, we should all use `-Werror`
&gt; The classic mistake is calling v.empty() instead of v.clear(). We've also seen: classic STL naming consistency. What stopped them from using a clear (no pun-intended) name like `is_empty`... Qt does it right.
Your mentioning `empty` and `clear` brought an earlier argument back to my mind. I've wanted properties in C++ for some time. I know that MSVC supports them, but GCC nor Clang do. To me, that's a good instance of where properties make sense. `empty` isn't performing a task - it should be a property. You are accessing a property of the container - querying whether it is empty or not. It doesn't necessarily have an explicit state variable associated with it, but it is a plain property. `clear` performs a task, and ergo is a function. I don't think we will ever have standard properties, though.
You can use Hunter from within CMake itself. No extra software required and it works perfect. Though a bit of a learning curve...
nope, see `6.7.1 Fundamental types [basic.fundamental]`. class / structs instances are "objects of class type" in standardese
Or you could just explain it in two sentences. 
Eventually you will end up knowing quite a few of them. Many of them are not as tricky or unusual as they might first seem. As one becomes more senior, they encounter one after the other.
"ints are objects. malloc does not create objects. accessing not-created objects is UB."
Ya, I want to write up "virtual considered harmful". I suspect post-metaclasses the default C++ object model will be superceded. 
A document that is "copy of document with blur run on it" is a document. It could even have a cache for "what you get after", but that opens you up to one of the two hard problems in computer science (caching). (The two hard problems in computer science are naming things, cache invalidation, and off-by-one errors.)
Fair points. These are not issues I have to worry a great deal about - I’m a scientist whose code is all open-source. In my little corner of the world, static linking rules the roost due to its simplicity.
Yes. The gist is that the graphics world is tied so heavily to performance, and the underlying technology changes so rapidly that there is no way to make a renderer-agnostic API that is useful for anything except toy problems.
Okay, that makes sense. I would still argue setting a malloc'd 32 bit block of memory to 3 is *not* UB. Would int x; x = 3; Be UB? If not then int* x = (int*)malloc(sizeof(int)); *x = 3; Is not UB either; &amp;#x200B; The only difference here is memory being on the stack/heap. &amp;#x200B; Accessing uninitialized data is UB, for example int x; std::cout &lt;&lt; x &lt;&lt; '\n'; and int* x = (int*)malloc(sizeof(int)); std::cout &lt;&lt; *x &lt;&lt; '\n'; But that is not what OP is doing.
javascript has `hypot` function too. I will write js version as, let points = [ { x: 1, y: 2 }, x: 3, y: 4 }, { x: 6, y: 2 }, ]; let total = points .map(p =&gt; Math.hypot(p.x, p.y)) .reduce((a, b) =&gt; a + b, 0) console.log(total); 
What is undefined about assigning an int here? What could happen other than what people expect? 
Oh, I’d much rather use dynamic linking if I could. My main project is a suite of command-line tools for medical image processing and the binary size for each runs to several megs with static linking. Dynamic linking would reduce the total size of the suite by something like 80% but sadly one of the libraries uses static global variables in a way that is incompatible with dynamic linking ☹️
Don't you have situations in factorio where you explicitly want to use a smaller type rather than a size_t to save memory/bandwidth? Do you just keep those situations to a minimum and static_cast them as necessary? I've just got a lot of situations in my engine where I'm storing 32-bit numbers (e.g. for triangle indices) and also using them as indices into STL containers and casting them in every single situation would result in a lot of more verbose code
Honestly, a pretty poor blog post as it doesn't really take any stand, show any examples, or even making really concrete points. I think the reality is that it depends entirely on the case. int x = 5; int y = ++x + x++; // what does it do? Is it UB, unspecified? Who cares, rewrite it. struct Foo { int m_x; double m_y; Foo(double y, int x) : m_y(y), m_x(x) {} // all developers must know that m_x is initialized before m_y, and why it works that way };
why is this man explaining the obvious?
None. A compiler can't be compliant to both [\[class.mem\]](http://eel.is/c++draft/class.mem#1.sentence-1) and [\[temp.mem.enum\]](http://eel.is/c++draft/temp.mem.enum). (The former says you can't declare an enumerator outside of a class definition since it is a class member; the latter says you can.)
If you're passing the return value into Qt's `insert` call then you're not discarding it. ;-]
I’ve tried Conan for a couple of hobby projects and it worked well this far.
this doesn't answer your question, but can you not just loop a youtube video like [Relaxing wind chimes [10 hours]](https://www.youtube.com/watch?v=6FCZ8azY_wU)?
Yes we do but we just write the cast to smaller size of up-convert before using a smaller size as an index.
&gt; What I'd like to have is an annotation that subsumed multiple other ones (like nodiscard, const, constexpr, no except, an implied no-virtual and side-effect free) Sounds to me like you want a [[pure]] attribute similar to the one gcc has, as described here: https://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#Common-Function-Attributes
No because the sound needs to be created based on the data in the input file. That data will be taken from collision detection sensors on some real wind chimes. The program is creating the sounds based on the actual movements.
Yes. Even with Qt a discarded `.release()` probably won't be common. However, it is still possible to run into situations where it's correct, such as if you just called `setParent(...)`
Does the link supposed ask for a login or is there a problem?
&gt; Okay, that makes sense. I would still argue setting a malloc'd 32 bit block of memory to 3 is not UB. I agree with you that this is the only sane interpretation, but the standardese would not agree with you. This is not UB because `x` is an object created with automatic storage duration (which implicitly makes it exist) and is "default initialized" with an indeterminate value, and then assigned-to: int x; x = 3; This is *technically* UB (even though I'm sure we both agree that optimizing based on that is insane and dangerous), because `malloc` is not blessed with the semantic ability to make objects exist in the way that `operator new` is: int* x = (int*)malloc(sizeof(int)); *x = 3; From the C++ standard's viewpoint with object creation, that `malloc()` call may as well be: void * malloc(size_t s) { return (void *)rand(); // yolo } However C *does* give malloc that blessing. Casting and usage also signifies a valid object in more circumstances in C than in C++, and a lot of times you're just playing a game as to whether or not the compiler can prove that an object was definitely not what you are casting it to. /u/quicknir's CppCon talk from this year has a really good example of this with reinterpret_cast. For your other point: &gt; Accessing uninitialized data is UB, for example &gt; &gt; int x; &gt; std::cout &lt;&lt; x &lt;&lt; '\n'; I don't actually remember if this is UB or not. I think it might be "UB with uninteresting consequences". This is UB though: int* x = (int*)malloc(sizeof(int)); std::cout &lt;&lt; *x &lt;&lt; '\n'; As for what the original commenter was doing, allocating an array, that's also UB by the same logic. UB all the things! :P I'm probably getting details wrong with the language rules, but this is the rough layman's explanation I got a few years ago from somebody who used to be more involved in the committee.
[This](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#1485) is the public link.
I think this is a prominent feature of JavaScript testing frameworks such as Jest https://jestjs.io
Everything.
You can do both, what do you mean?
`int x` creates an object/instance/whatever of type `int`, named x. Obviously there is no constructor call associated with it since `x` is trivially default constructible, but it's still starting the lifetime of the object. On the other hand, `int* x = ...` doesn't begin the lifetime of any `int`s, it just allocates memory for them. When it comes to object lifetimes, primitive types in C++ as it stands don't get any special treatment. Your example is UB the exact same way that `vector&lt;int&gt; x` is defined, but `vector&lt;int&gt;* x = (vector&lt;int&gt;*)malloc(sizeof(vector&lt;int&gt;))` is UB. In practice people do the former all the time and the latter almost never, but both are UB, and actually both are quite likely to succeed with the assignment statement I would guess.
That’s a great question, I’d like to see the attribute propagated.
Such code hands ownership of `.get()` to another object, then `.release()` can be called and dropped on the floor.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9v2oxd/need_to_create_a_program_that_plays_wind_chime/e993zw7/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Can you give an example? 
I can’t agree to either of those points. Not a single bug so far. The only bug I had was that CLion didn’t support nested ternary operators, but that’s long fixed.
I’m currently forced to write C code for university and it’s astounding how many developers just declare EVERYTHING at the top of the main() and then define it whenever. It’s the most confusing thing.
Compilers can assume that the code path that invokes UB can never be reached and optimise accordingly. If a compiler can prove that the code inside an if block will surely cause undefined behavior, it can choose to not evaluate the if expression at all and just go straight to the else block.
Wouldn't that either imply that malloc can never be used without placement new ? If so what does placement new do that this assignment does not? Also wouldn't this imply that valid, defined behavior in C becomes undefined behavior in C++?
Allocate memory only if you have a reason.
I think the original c-specification required that and unfortunately many university teachers tend to teach c the way they learned it from their teachers and so on.
The Fibonacci example is nice demonstration of how easy it is to accidentally cast integers and get nonsense result. This particular conversion is implementation defined and I'm not sure where the value in the article comes from, it doesn't seem to be result of mod 32 of the correct result. &gt; Strong type system and compile-time type checking No, language that automatically inserts type conversions everywhere to fix type errors doesn't have strong type system.
Pretty much - just that it should not be an attribute but a real keword. Also, I still hope that once we have modules, we might get the ability to change some defaults on a per translation unit base but no Idea if that will ever fly. 
I'd be fine with a "pure" decorator as either a keyword or an attribute. But it'd sure be nice to have something like it.
&gt; a good reas Yeah - those Java people...
&gt; Wouldn't that either imply that malloc can never be used without placement new ? yes &gt; If so what does placement new do that this assignment does not? it "creates an object". malloc only provides storage in which objects can be created. &gt; Also wouldn't this imply that valid, defined behavior in C becomes undefined behavior in C++? yes, that would not be the first time that C and C++ differs. 
`if(i - 10 &gt; 5) { ... }` -&gt; boom
depends on the code base (and size of the code base). Sometimes it just aint worth if you're using old tried and true code. But in general use it where possible. 
ignoring things is dangerous, either make specific exceptions, fix the problem, or don't use pedantic. 
[temp.mem.enum] doesn’t say anything about declaring the member enumerator. It explicitly says “define”.
No need for me to rant again - you can read all about it here: https://discourse.itk.org/t/mix-shared-and-static-libraries-to-reduce-bloat/795 (So I misremembered - it was actually that I was trying to be over-clever and mix static and dynamic linking. If I did it all with dynamic linking it probably would have been fine)
It's UB because the standard says so. As to \*why\* the standard says so... Well, maybe someone who is on the committee knows this, but they will probably want to keep quiet about it (on account of it most likely involving late hours and copious quantities of alcohol). So let me wager a guess: creating a complex object (with a v-pointer, a constructor that needs to run, etc.) is something that needs to be triggered specifically, and malloc does not do that. Most likely the standards people had a long day and just wanted to go home, so they demanded proper construction through some form of new and made everything else UB, since that's always the easy way out in C++. What the linked paper (up above) does is restore the status quo where trivial objects can be accessed without the benefit of proper construction. It's basically fixing the bug whereby the standard accidentally invalidated every C++ program ever written, and made it impossible to interface C++ with just about any non-C++ library. Just to be clear: there is nothing special or magical or even necessary for proper construction of an int, and the fact that the standard demanded this on pain of UB is a straightforward bug.
Great work. A stable range-v3 api is the next step! 
&gt; creates an object But what does that mean? How can it be implemented without itself being undefined behavior unless it is implemented in assembly language? Do implementations of calloc use placement new? If not, how do they zero out the allocations without 'undefined behavior'?
&gt; But what does that mean? How can it be implemented without itself being undefined behavior unless it is implemented in assembly language? UB doesn't exist for the implementation (in a general sense). It doesn't matter how it's implemented under the hood. It matters for the user.
&gt;No, language that automatically inserts type conversions everywhere to fix type errors doesn't have strong type system. Exactly.
Using the fibonacci code as an example thatt you don't need to write low level code to be fast is incorrect. It proves that constant folding in your compiler is pretty good, but that doesn't mean that the function performs better than a low level implementation in cases where it can't be constant folded.
Yes, I get you. I will usually get rid of `-pedantic`. I just turn it on occasionally and have a good look on the types of errors it gives to see if I spot anything unusual.
&gt; How can it be implemented without itself being undefined behavior unless it is implemented in assembly language? the standard does not care about the implementation. Maybe operator new tags its output in some way in its AST. &gt; Do implementations of calloc use placement new? If not, how do they zero out the allocations without 'undefined behavior'? At least on windows from what I see in calloc_base.cpp they use "magical means", i.e. they ask for already zero-ed out memory from the OS with HeapAlloc - and since you cannot link your software with HeapAlloc's implementation, the compiler cannot "see" the UB which protects you from its effects - when you cast the void* that malloc returns, you tell it "please believe me" but you still break the promise. Other implementations are written in C so by the time calloc is compiled the problem is less visible - but wait until compilers get intelligent enough to perform link-time optimizations with binary code :p 
Give it a treat
Well, the general rule is "don't use anything in STL except for vector and array", so it seems a relatively reasonable assumption that std::set/unordered_set aren't ideal.
On my machine it took 90 seconds and 9GB of memory to compile (/O2) the [calendar](https://github.com/ericniebler/range-v3/blob/master/example/calendar.cpp) example. Do you guys have other numbers?
I solved it. If you're curious: My local Jekyll version generated slightly different HTML than the GitHub one, so the selectors I had been using to style the code snippets weren't actually being applied on the GitHub hosted version.
I actually use JS pretty actively on my site. My site is actually an SPA (but only when JS is enabled!). If you click on any inter-site links it will swap out the page content without actually doing any browser navigation and pre-fetch page content when you mouseover a link. I'm thinking about doing a post on how I did this since it's a useful trick to reduce UX latency and give a smooth feel.
[fixed that for you](https://i.imgur.com/9259lvc.png)
what kind o performance numbers do you get?
More analysis pages are up. [https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/Analysis](https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/Analysis)
DAE think the JavaScript is a bit of a straw man? How about Haskell: len (x, y) = sqrt (x*x+y*y) main = putStrLn $ show total where total = sum [ len p | p &lt;- points ] points = [(1.0, 2.0), (3.0, 4.0), (6.0, 2.0)] Or define a `Point` type, if you like: data Point = Pt Double Double len (Pt x y) = sqrt (x*x+y*y) main = putStrLn $ show total where total = sum [ len p | p &lt;- points ] points = [Pt 1.0 2.0, Pt 3.0 4.0, Pt 6.0 2.0] For both this and the post's C++, I get: real 0m0.004s user 0m0.004s sys 0m0.000s And *both* have: * Strong type system and compile-time type checking * No run-time dependency like Node.js * Fraction of the (JavaScript) execution time It's easy to win if you race against a lousy opponent.
I think we are talking past each other here... Close to 100% of my time using a computer, I spend the time in front of a barely changing screen. Just as I am now. Looking at a static reddit-screen while a few letter are changed upon it. If this type of rendering has changed as much as our misunderstanding indicates, then the people in charge should be jailed... environmental criminals they would be... reddit/facebook/google/windows/Gnome/unity does not look different enough from their past selves to warrant such a change... 2D graphics is after all is said and done, just a translation of the hand-drawn to pixel art.
You could build a catalog of movies with actors, and use set intersection to get all common actors between two movies. Or something like that.
If one thread is accessing `this-&gt;name` while another one is writing to it, it's a straight up data race whether you "check-then-act" or not.
I have used many different IDEs for C++ across my career. Recently, I have started using VS Code as my complete IDE solution for C++ projects, and I really love it. You absolutely can debug with it, and there are all sorts of useful extensions. I use: - Intellisense syntax highlighting extension - Cmake extension - Googletest extension I’ve had success with it in Windows (using MSVC compiler) and on Mac (using clang tool chain).
Right, something non-mathy. I tend to think of math-related applications first, I guess. Of course, one nice thing about math applications is that generating a large input dataset is easy. That gets harder when my dataset is in the code -- and I'd like to avoid reading files, to keep my example simple. Thanks for the input.
Take some time to play around Vim or Emacs, install the needed plugins, and you are done finding to best editing tools.
Switched to vim a few months ago and LOVE it. 
I've been dabbling with C++ support in VS Code. It looks to me like there's no support for switching between source/assembly or showing the state of the registers. Those are important tools in C++ debugging. Did I miss them?
So many people in this comment thread are utterly convinced that they understand the C++ object model. This is fascinating to watch.
yes I use the "C/C++ intellisense" and "Easy c++ projects", its a neat all in one extension. you just have to set up a new project it makes your make files (whatever that is, haven't learned it yet lol). I'm guessing you use the "googletest" extension to debug? can you do things like variable watch and looking at call stacks? (also don't really know about these but the guide makes it seem super useful tools).
Bazel's caching behavior will make this happen for you, but you need to keep your libraries granular for it to work well. 
hmm i've heard about it I'm on a mac, are they good options for me? I'll think about it after hearing more
well did you miss them? don't leave me hanging
Then you are lucky, both are well supported on Mac. You may consider heading to the vim/emacs subreddits for more information. (Now I sound like a salesman... Which I am really not...)
Check out Bazel - it has a similar feature (although not based on code coverage).
^ Yeah. For some applications you need to store a lot of historical data anyway in order to make the undo system useful. For example, the Undo for deleting an object in a scene editor is not just creating an object in the scene editor. It's creating that object, restoring all of its properties, and possibly reconnecting any references other scene objects had to that object that were removed when it was destroyed previously.
I have several questions about the module: - Is the nms format suitable for the proprietary software vendors to hide their templatized implementation code? i.e. They don’t have to ship the template source header code in their release any more? Just the nms files. - If so, which I doubt, how could their users get the api documentation that they used to get from the header files. 
Sorry libgit2
 error C2220: warning treated as error - no 'object' file generated warning C4018: '&gt;=': signed/unsigned mismatch
Intersecting a set is a very typical database operation, but while there are mathematical applications, they are not as common. One thing you could do would be something like checking if points are inside a volume, then do the intersection with the sets of points in another volume. You can easily generate the data for that (do it 2D for easy visualization if you want). You get to use `copy_if` as well.
... and then you scroll, and all of a sudden the browser is re-computing and pushing a 30Mb image at 60hz. 
What is this thing? I'm asking as a programmer...
I can’t defend the code - but some people write it this way.
It's a common misconception.
Go for VSCode, learning a new language and a new IDE at the same time will cost you time and energy. I've been using VSCode professionally for C++, it's top notch if your project is using CMake, easy to set up and reliable. You'll loose nothing as far as debugging go (it's very good at debugging actually), but you'll loose some profiling tools which are built in other IDEs, that's pretty much it. 
Could you comment on the burden of floating-point NaN and +-Inf? 
The assembly view goes a fair bit beyond debugging IMO.. depending on whether you debug with gdb or lldb I think that you can get it, but I've never needed that for debugging in, like, forever. (I'm not talking about performance, that's something else of course)
These nonsense titles have to stop. If what you are presenting isn't interesting enough, don't present. Don't go looking for some nonsense 'clever' title that makes zero sense. 
So now "msvc would support ranges before CLion" is not a joke... By the way, does intellisense work correctly with ranges now too?
Does the standard allow you to subclass std::string and declare your derived class non-cooyable?
See [my comment](https://www.reddit.com/r/cpp/comments/9uc0oa/modules_are_not_precompiled_headers/e93wgt8) here
Honestly, I just use a default IDE like Notepad++ or Gedit in Linux if the code is one small simple file. VSCode is pretttty good though.
Thanks, you're right. I was doing -O0
Yes, it's a race in any case. That code is terrible. And it looks so innocent, doesn't it? How many times you've seen such code around?
This code is hard to make exception-safe (hence the need for unique ptr and release, and different code ). Consider: QSomeWidget(QWidget *parent) : QWidget(parent) { ThisInitialuzationCanThrow(); } If the ctor body throws, parent will have a dangling pointer to the widget. Very, **very** bad design choice in Qt. Legacy of the 90's that never went away. Qt had, for a long time, the "policy" that it doesn't use exceptions, but that policy was a lie because operator new throws. I think that didn't change, but not sure.
In Pascal, a method without parameters (so, same form as a property getter) does not need brackets. I always thought that's neat. Why write brackets? They do nothing! 😀😀😀
I suppose you could always ask the compiler to emit assembly and then open that file.
BSTR is immutable? Why? I mean, it's not const, so...?
Depends on context of who owns the BSTR to my limited understanding. If you're passed a BSTR from someone else you have to assume it is shared.
Yes, but I can in-place modify it, and I always thought that would be harmless. Whoever gave it to me, if they gave a non-const one, don't see what's wring with that. Hmmmm... I don't think our code is manipulating BSTRs in such a way, but... 😀
absolutely, but you can still create a `std::string` from it
I've been able to get ranges to work on CLion before this recent commit? What operating system and compiler are you using?
I think your issue is trying to link a dynamic library into a static library, and then that into your actual program. Why not just link the dynamic library into your main app, then statically link whatever you need into there? Also, have you thought about using LTO? You're using Clang since you develop on a Mac, which has really good support for LTO. also, use ThinLTO, instead of Monolithic LTO. 
I use `-Werror` and then disable particular warnings that I don't care about.
&gt; You're using Clang since you develop on a Mac, which has really good support for LTO. also, use ThinLTO, instead of Monolithic LTO. +1, also on Windows. 
I'm developing for a living for more than ten years... and never used an IDE; now using vsCode.
Another one, one I've actually used: https://github.com/Tessil/hat-trie
I happen to like it - at least for the initial programs students have to write - but that is another discussion ;)
Well, what I described has to subsum actual key words like const and no except, so an Attribute is not enough. This is not primarily about optimization, but about making common function declarations more concise. 
Sure, i wasn't saying I don't like your idea, just saying that I'd be fine with it working either way :-)
In my experience about 3% of developers are fantastically productive with vim, and the rest just don't get it. (I'm not one of the ones who gets it.) I totally respect people that use vim, it looks super impressive when you're flipping back and forth between modes and writing complex commands with just a few keystrokes, but it's just not for everyone. 
Depends on what earnings are enabled. 
If you want a smaller type you still can use an unsigned int. 
There is no way to interpolate for a single value with my current implementation. `interpolate()` would be `tweeners::system::update()` but since `tweeners::system` stores a bunch of tweeners it would return have to return maybe all updated values? There is another function more like `setup(..., update_callback)` which is more representative of the way `tweeners::system` works: at each update all updated tweeners trigger a notification via `update_callback`. The x-mutating API is more of a convenience to update the variable in-place. So the reason to not returning the interpolated value is actually that the values are interpolated in batch.
I will, thanks.
The idea of allowing to configure `duration_type` via the templates was to allow using `std::chrono` but in practice it fails as soon as I need to compute the ratio of the elapsed time over the total time because there must be a cast to `float` somewhere for the easing functions. Also it feels a bit weird to ask for a `std::chrono::milliseconds` when the implementation does not care about the actual unit. It can be seconds or it can be frames/ticks, it does not matter as long as the caller is consistent with its unit.
According to some, it's faster to use (unsigned) int's, as the compiler has an easier time reasoning about such an index, due to the fact that overflow is an error, while the unsigned int simply wraps [i.e. is not undefined].
It's undefined behavior.
Once thing I'd like to point out: When the language said something is UB, the implementation is totally allowed to give it defined behavior anyway and I'm pretty sure that's what happens in this particular case (I haven't checked the docs though to verify that)
I had a similar need, storing up to 3.5 Mb of text and a need for efficient lookup. I my case the text was a list of words of up to 9 letters. Since the words were short I managed to encode them to unique `std::uint64_t` values by coding the letters on a few bits. [I did a benchmark of several structures](https://github.com/j-jorge/string-lookup]: - a sorted `std::vector&lt; std::string &gt;` or `std::vector&lt; std::uint64_t &gt;` for storage and `std::binary_search` for look-up, - three homemade implementations of a radix tree (labeled as _trie_ in the benchmarks), - an `std::unordered_set&lt; std::string &gt;` and an `std::unordered_set&lt; std::uint64_t &gt;`, - and [marisa-trie](https://github.com/s-yata/marisa-trie). The `std::unordered_set&lt; std::uint64_t &gt;` perform very well in all cases while marisa-trie is not very good here. Other implementations' efficiency vary if the searched word is in the dictionary or not. I think that one needs quite long strings before a radix tree becomes interesting.
Use a package manager.
I'm not sure, what code you actually had in mind, but the code you are presenting here doesn't show the tertiary operator as an anti pattern at all. At least not without knowing what `this-&gt;name` is.
Appreciate your comment, and I totally get it. Actually, the most compelling reason for me to use them is it's easy to work remotely with the same experience. It's curious that command line is still the most efficient remote environment after all these years.
Cheers mate
Imho your example isn't meaning full. Without having the context I could point at almost any line of c++ code and say: " This is broken in a multithreaded context". Youjust can't write reasonable c++ code if you have to assume that any non-function-local variable could be accessed by another thread at any time. In this particular case: Unless I explicitly design my class to be threadsafe, it is perfectly normal to assume that it isn't accessed concurrently - that's exactly what almost every single type in the standard library assumes. 
Sorry, didn't have my coffee yet
 template &lt;typename T&gt; [[nodiscard]] T func(); What in the case of `func&lt;void&gt;()`?
CLion is not a compiler. This is about compiler support for a library. 
Something something database something table inner joins
&gt; if we had better package managers and build tools, it could be a much more pleasant experience for a beginner C++ programmer to download a graphics library from a remote repo and include it in their build. Trying to standardize a toy graphics library instead seems to me like an expensive waste of committee's time. Strongly agree. Adding graphics library is a workaround. The true problem is build system and package management.
`Java.awt.Point`: member integer x and integer y (8 bytes). And of course an 8-byte vtable pointer! And then you can not even store them sequentially in memory... just an array of `Point` pointers.
Windows, gcc 8.1 from MinGW-w64, last EAP. I mean, for particular definition of "get to work" - sure. But almost all types are resolved wrong, so even simple extract/inline refactorings don't work, autocomplete doesn't work... And this is before you open some actual headers. Not to mention how slow it is.
I personally had a hard time getting through the article, it's a bit too verbose for my taste and lacks some structure, it reads more like a train-of-thought prose piece than an article about programming. E.g. you mention at the start that there are two types of undo systems, it's not easy to actually find where you describe the second. As for verbose, see e.g. this: &gt; Now come the second flavor of undo buffers. I am not entirely sure the description I present fits any actual implementation but the behavior does. And this description is the simplest I could manage to explain it. We will treat the undo action as somewhat less privileged [1] than in the first flavor where, effectively, performing this action puts it into an “undo mode”. By the time you start the actual description I have to admit I've stopped reading. And I also have a hard time digesting the actual explanation, it would really help to have a short (1 or 2 lines) summary of what the system is before digging into the details. My 2 cts!
We simply avoid division by zero and or division in general and it's mostly a non-issue.
Please for the love of God! I beg you! Put some minimal amd reasonable modules support!
At least on MSVC which is where our majority custom base runs I've not seen a difference code generated when using unsigned 32 bit indexes, unsigned memory-sized indexes, or signed indexes. Additionally unsigned math with overflow vs signed math without overflow makes no real difference in our kind of calculations we need the game to perform since we're virtually always waiting on memory latency instead of CPU calculations. So while that might be true on other compiles (and might still be true on MSVC) due to the nature of our program it doesn't really matter.
Exactly - you would think not having to generate machine code would make the task of parsing source code easier.
The standard will make something UB when they want to leave a placeholder for either future refinement, or for compiler implementers to choose their own poison, or simply somebody didn't think it needed to be defined. In the case of `malloc`'s effects on memory, I can assure you that is an example of "we're not going there right now, let each compiler vendor do its own thing". And as somebody else mentioned, that ambiguity has become a problem for optimisation recently, so SG12 via P0593 et al is going to define the previously undefined. Even after that, we still cannot implement `malloc` without resorting to UB, however. Or, to be precise, we cannot implement a `malloc` which can reuse addresses or memory not present at the beginning of the process launch without resorting to UB. That's future work yet to be decided, but efforts are underway.
In fairness, it has changed with every C++ standard, plus in every C standard, and moreover compilers each vary individually. And moreover, it's *hard*. I've sat in SG12 meetings with the most expert people in the world on the C++ object model all sitting around the table, and many hours of discussion emerging about disagreements between those world experts about their different understandings of the C++ object model. If *they* don't share a common understanding, it's absolutely fair that neither can anybody else. Resolving those ambiguities in understanding is precisely why SG12 was founded, and many more years of work remain before it. With a bit of luck, we can coordinate some of this with WG14, over there there is an increasingly bitter debate about how compilers rewrite people's C code. Most of that bitterness stems from their more permissive object model. And much of Peter Sewell et al's research work on formally verifying C code would become moot (in a good way) if C significantly tightened its memory model to more closely match C++'s, though, in fairness, we could do with tightening ours in a direction more compatible with C's use case and direction as well. 
If you are getting a lot out of the book and it uses an IDE then there's no harm getting that IDE: you can apply the knowledge to other tools once you are comfortable with the concepts.
Ha. It is very easy to disproof myths which you just made up by yourself. 
But why? What’s so hard about saying “some functions and classes are grouped, and the group is called `std`. So to access it, you write the group name, two colons, and then the function/class name, like this: `std::vector`.
 auto total = ranges::accumulate(points, 0.0, ranges::plus{}, [](auto const&amp; p) { return std::hypot(p.x, p.y);}); Really not convinced that this is more readable than a for-loop.
&gt; Except you use gitlib as your backing store and fragment your document into pieces, so edits modify only slightly more than their delta. And with a bit more work you support live collaberation with disconnected sessions That sounds so interesting, do you have a few pointers on that?
No, you wouldn't think that, because the two are entirely unrelated. The parsing work is the same in either case.
It made me discover patterns that could easily be replaced by the stl-algorithm equivalent and a lot of other things. Saves me a lot of time, thanks for this!
Clion makes you c++ dev experience so much better.
For sure, the language is just a spec after all, and what matters most is what your compiler actually does in each case. You just run the risk of them changing that behavior in order to enable some optimization (again the reinterpret_cast segment from quicknir's talk is relevant).
Nothing is hard about that, I just like short names for commonly used things.
Also allocating on the heap helps avoid stack overflow. [Here's](https://social.msdn.microsoft.com/Forums/en-US/2a5b32b6-683b-4729-92d3-45ed7a89ef3f/stack-overflow-and-how-to-increase-the-stack-size?forum=Vsexpressvc) a small discussion on that. The default stack size in MSVC is 1 megabyte, which is usually plenty, but you should avoid putting large objects on the stack.
Nothing is hard about that, I just like short names for commonly used things.
For one thing, JetBrains themselves said that they couldn't just use clang, because parsing in IDE is not the same as parsing in compiler. But anyway - even if the work is similar, it's sad that MS did it when JetBrains didn't.
Emacs + rtags is absolutely amazing. One of the real benefit of Emacs is that it can become a fully-functional IDE for every language you write in.
Wasn't this posted a couple days ago?
Hi, I have another terse macro, which I never dared to use in production. It deas with IIL (Immediatey Invoked Lambdas) This is inspired by an article from Herb Sutter: [http://herbsutter.com/2013/04/05/complex-initialization-for-a-const-variable/](http://herbsutter.com/2013/04/05/complex-initialization-for-a-const-variable/) The example below shows the idiomatic C++14 of initializating a complex const variable through a lambda. //construct and initialize vec of type const std::vector&lt;int&gt; const auto vec = [&amp;]() { //define a lambda that initializes the vector std::vector&lt;int&gt; _vec; for (unsigned i = 0; i &lt; 10; i++) _vec.push_back(i); return _vec; }(); //run the lambda immediately const\_initialize is an attempt to make this code shorter and easier to read. With this macro, the previous code can be rewritten as: const_initialize( std::vector&lt;int&gt;, vec, // here, we define the type and name of the const variable. for (unsigned i = 0; i &lt; 10; i++) //initialization code vec.push_back(i); ); And const\_initialize is defined as: #define const_initialize(type, name, initialization_code) \ const auto name = [ &amp; ]() \ { \ type name; \ initialization_code; \ return name; \ }();
Be the change you want to see. Go make some better videos. You have obviously found a gap.
&gt; The lack of sandboxing is the root problem. Make has a dependency graph, but it does not actually enforce it. I've used a number of build systems and I've never seen one that enforce a strict dependency graph with "sandboxing". Another drawback not mentioned is the lack of support for rules with multiple outputs.
Books aren't much better, unfortunately. As a C++ teacher, I struggle to find a good book, and yes I've seen the stack overflow post.
On the one hand, I hear you, but you have to remember a lot of people make these videos because students are covering it in Uni - and worth noting as well, is that the overwhelming majority of these people make next to nothing from it, they're pretty much just helping out first-years.
I want to get into C++ as a beginner programmer, will the C++ primer book do me any good? &amp;#x200B; or any other suggestions?
&gt; It is copied from old tutorials verbatim, year, after year, after year for the last 20. So nobody really knows C?
I have C++ course this semester and I've been hugely surprised that C++ is absolutely different language than I thought because of the people who "teach" C++ as C.
There is a strange, persisting belief that arrays and manual memory management are for beginners, and that vectors are more advanced; utterly false. Vectors are for everyone from beginners to advanced users, arrays and manual memory management are not for beginners and are only for situations with no better choice. I think there are still a great many books, tutorials and even places of education teaching C++ like it's C, with a couiple of extra features bolted on that you should only worry about once you've learned C.
I would consider paying for something like this, honestly. With so many python and web dev related tutorials out there. A legit, modern, beginner to advanced C++ set of videos/tutorials/walkthroughs/courses would be a benefit to a LOT of people. 
One issue is that it flushes the stream, which is fine if you want to print a single line that is immediately visible. Less so if you just want to write a whole bunch of line with maximum throughput.
std::endl flushes the stream, which has a higher performance/time cost than just outputting a newline character.
To name a few: Buck, Bazel and Pants all enforce strict sandboxing. \&gt; Another drawback not mentioned is the lack of support for rules with multiple outputs. make supports that [https://www.gnu.org/software/make/manual/html\_node/Multiple-Targets.html](https://www.gnu.org/software/make/manual/html_node/Multiple-Targets.html)
You're a FOSS salesman, you only spent your time.
My experience with C++ Primer is it's not beginner friendly and very dry. I still like it. I heard good things about Bjarne's Programming -- Practices and Principles using C++.
Because “the” dynamic library is not a single file that was pleasant to distribute. ITK is divided into modules. A lot of modules. A lot a lot of modules. I doubt LTO would have helped much because the code is genuinely that large - it was to do with handling different image formats, again a lot of image formats. The biggest saving in size came when I cut down the number of supported formats to the 2 most common.
If you're writing a hello world, or are a beginner, chances are you're going writing paragraphs. I don't see anything wrong with endl, despite the speed hit.
I'll take a look, thanks!
Also, tutorials should be teaching std::array instead of C arrays anyway
I think an important thing to do is to ask plenty of questions (here or on stackoverflow probably), so people can redirect you away from the obvious pitfalls. You may get some people being a bit dismissive if you've made mistakes but it'll still help you understand 'real' C++ practices
I think a lot of the problem is that C++ has lots of little features here and there that are useful for making fast, high performance, stable, easy to maintain programs that are not particularly useful for a new programmer. &amp;#x200B; Here are a few examples: * I am uncertain how I would go about explaining `shared_ptr` to a new programmer and why it is necessary/good. * Having gone through the experience of using `malloc/free` I can point out the one benefit: No (or fewer) memory leaks. I don't think novice programmers need to worry about memory leaks. * In general, to explain this to novice programmers, you first need to teach them destructors; only then will they understand how a smart pointer works. * As for `auto`, I am not certain that teaching auto to new programmers is actually a good idea. I have begun to see many uses of auto that obfuscate the program because I can't tell what type something is (and from that: what functions I can use on that type). * Namespaces are useful and great for large multi-file programs. I don't think they are useful for 1 file programs that are just a `main` and a few functions. * `std::endl` has 1 problem: throughput. Novice programmers don't need to worry about that. * `if constexpr` I wish I could use this at work, but teaching compile time programming to new programmers is likely a waste of time. * Almost anything involving templates: great stuff, useful,... But new programmers should probably be limited in their exposure. Remember: novice programmers need to get somewhere useful fast or they will move onto something else.
The problem is when people don't realize it does flushing and nobody explains it. I had to fix some serious performance bugs because `endl` is just writing end of line, right? Imo endl should always be replaced with explicit newline and flush if needed.
Seconded
As a teacher, what's your point against Stroustroup's book and C++ Primer (never touched the second one but heard a lot of positive reviews. First one is quite neat in my opinion)? Probably in couple of weeks I would start "teaching" a couple of friends and I was going to recommend both of them. 
Same, if I'm using cout the odds are I want the flush too, I want to see the message displayed in case the program fails for some reason. I don't see how the performance hit really matters unless you're writing to some other kind of stream which interacts with another program. If it's that fast I won't be able to read it or it'll disappear beyond my scrollback. I usually use '\r' if I'm doing a continuous update or something.
Precisely. 
I've implemented this a couple times with kludges in existing build systems like CMake, so I know it's doable. And you have the right approach in mind - it should be based on coverage/profiling data of some sort. It can be tricky, and I know some people complain about the proliferation of targets (instead of a target called run\_test you know have a target for every test suite source file, or at least that's how I did it). Perhaps the biggest problem is the platform-dependence of it all (there's no cross-platform or even cross-compiler profiling info that I'm aware of). So I'm very supportive of the idea that something like this should be more standardized and cleaned up rather than a bunch of ugly hand-rolled stuff like what I did.
Why does it depend on library granularity?
Does Mac OS support UTF-8 in their console? Because then it's hard to justify uses of UTF-16. On windows however, you don't always get the choice.
Yes and no, I'm not going out of my way to write bad code, but unless I'm actually working on a problem were speed is a central component, it doesn't matter. If I'm sorting a list and my shitty java or python program takes 0.1 seconds and c++ takes 0.01 or any other smaller amount, I don't care.
&gt; I don't use it because it seems to be a pain to write and use in general That is objectively true for the most part, yes. &gt; My general impression is that there are efficiencies that I could hunt down like Ahab, which nobody cares about today because the general development of hardware makes efficiency considerations almost obsolete. Your general impressions are wrong. Performance is just as critical as it's ever been; If anything, it's _more_ of an issue nowadays as expectations about responsiveness have gone up. Memory usage is less of an issue nowadays compared to the past, but even that has its limits. &gt; For this to be a legitimate concern, you would have to show that people not using c++11 makes using c++ signifiantly harder and/or less useful than using it. Yes, you'd have to show that as a motivating example to people unfamiliar with it, but it's so bleedingly obvious to anyone who's actually working with C++ that it doesn't need to be stated in a C++ oriented forum. &gt; and not because I don't know one keyword and what it does or how some standard library stuff has changed. Nobody is trying to get you to use C++. We're trying to make people who try _learn_ C++ because they decided they need or want to (or someone else has decided for them) learn _good_ C++ as opposed to _bad_ C++, because the language carries tons of cruft around that's only around because we can't just incinerate it for backwards compatibility reasons. 
Isn't flushing synchronous? As in your code is delayed longer if you're flushing.
Alright, you have very solid points. But I'm curious, what can you do in c++ that you can't do in other languages?
I'm teaching C++ to non-CompSci/non-Software Engineering students. &amp;#x200B; I'm not a fan of the std\_lib\_facilities.h -- it's fallen out of date and doesn't work in all cases anymore. The chapters about building a grammar tend to confuse the students, throwing that in in Weeks 3/4/5 tends to derail any momentum that has been built. The chapters about writing and finishing the calculator dip into concepts that aren't even really taught until later (user defined types, etc.) If you want to do any of the object-oriented material, you need to install FLTK -- getting these things installed in university labs is a major pain. &amp;#x200B; I like the content that the book covers, and I like the pacing overall, but the above make it almost impossible to teach out of. &amp;#x200B;
The precise expression is was looking for. thanks.
I don't really see the point of std::array. Usually if I don't want a vector I am looking for super high tolerance performance, C compatibility or some kind of unusual behavior, all of which are better implemented with C style arrays. Why use a std::array?
A definition is a declaration, by definition, as declared in [\[basic.def\]/2](http://eel.is/c++draft/basic.def#2.sentence-2).
1. Shared pointer: I teach pointers at the end of a one-semester course. Rank beginners don't need them. And for "low intermediate" users I only teach shared pointers as the default. They can learn about unique and move later. Too complicated for beginners. 2. Endl and inefficiency: I completely agree. That's a subtlety for later. 3. Vector: disagree. I teach classes before vector, so they are already familiar with the notion of something that stores data and that has methods defined on it. The template parameter they seem to take in stride, and you don't need to teach the general templating mechanism.
std::array has identical performance to C style arrays. Most C code that I have seen also operates on pointers, so having literal C arrays is unimportant. std::array is basically just a C array with added convenience and less strange pitfalls (no more sizeof bugs, among other things.)
I called it “not so cool” to make clear it is reflecting my opinion, rather than a fact. &amp;#x200B; In general it I'd say that it is preferable to do something inside the language instead of outside of it. This project tries what is possible in regards to derivation and integration while staying close to zero overhead. (I am not even 100% sure that I reached zero overhead). &amp;#x200B; I think that libraries that force me to integrate extra passes in my build system or even force a build system onto me, are super annoying. You can only support a limited amount of these libraries in your project. Sometimes it seems like it is not possible to do it in any other way (like QT before c++11), but is also very hurting. I can't run any of my clang-tools over my code without also integrating QT passes into it. &amp;#x200B; Also I don't know which other languages use macros. I know there are a lot of transpilers in the javascript, html and css world. But they also have there own up- and downside. &amp;#x200B;
I think it is often missed in the discussion of teaching templates that you can teach how to use templates without teaching how to write templates. Using std::vector is far easier than writing std::vector, and writing templates can easily be left until much later in the course.
Yeah but if I'm printing output for humans to read then I'll happily let the code take a small performance hit to be sure of the message being printed. I think the communication with the operator is more important than the performance most of the time, until it becomes an issue someone actually shouts about. If it's a performance critical bit of code I won't be using cout anyway, or I'll only update every n iterations of a loop.
C++ is missing reflection and metaprogramming compared to higher level languages. Other than that it does just about everything other languages do, and often in similar ways.
On linux the standalone profiling frontends are generally better than what is built in to IDEs anyway. Hotspot and kcachegrind are both really good.
sure it does, consider following makefile: ``` ab.txt: a.txt b.txt cat a.txt b.txt &gt; ab.txt a.txt b.txt: echo 1 &gt;&gt; a.txt echo 2 &gt;&gt; b.txt ``` this will generate `ab.txt` containing `1 2`, proving that the rules for `a.txt` and `b.txt` were invoked only once
The big thing for me is that, with `std::array`, the size stays with the container. No more ptr + int functions.
Obligatory Kate Gregory: [CppCon 2015: Kate Gregory “Stop Teaching C"](https://m.youtube.com/watch?v=YnWhqhNdYyk)
You won't be able to step through assembly that way.
With `std::begin()`, `end()` and `size()`, the only advantages of `array&lt;&gt;` are: - it cannot decay to a pointer - it can be returned by value from a function Alas, AFAIK, `array` requires us to duplicate the size that I don't want to bother to know. IOW, most of the times I'm perfectly happy with const/*expr*/ T v [] = { a, b, c, d }; static_assert(std::size(v) == someexpression);
Ty for the feedback, I genuinely appreciate it. Would you recommend Stroustrup's Programming: Principles and Practice Using C++ (2nd Ed) for learning cpp? I was actually planning on expanding my cpp knowledge on my spare time and I ended up purchasing this particular textbook ( found it in the stackoverflow list linked in the sub).
You typically only want to flush the end of stream. cout &lt;&lt; "this is a string" &lt;&lt; endl &lt;&lt; "this is another string &lt;&lt; endl &lt;&lt; " and more" &lt;&lt;endl; when what you probably want is cout &lt;&lt; "this is a string\n" &lt;&lt; "this is another stirng\n" &lt;&lt; "and a final string\n" &lt;&lt; endl; https://en.cppreference.com/w/cpp/io/manip/endl 
&gt; it can be returned by value from a function I see that as a pretty major benefit. How else would you return a fixed number of objects besides making a whole new class to hold them? Plus being able to range-based for loop over it is very nice
Your second example will insert two newlines at the end. You probably meant to conclude with "...\n" &lt;&lt; flush or "..." &lt;&lt; endl?
You can use a range-based for loop over a standard array (assuming it hasn't decayed to a pointer yet). Range based for loops call std::begin(thing), not thing.begin() directly. 
Oh right, I was wrong there, sorry
I've been doing C++ since 1993, but am not a really great template meta-programmer. Feel free to ask me any questions. What languages do you already know or are you a complete beginner? 
Well I wouldn't say it's Python++, there are still some gapes. But I get your point. I was pleasantly surprised from the standard library. What I like the most about new C++ are smart pointers.
An automatic refactoring would be nice too, maybe with a clang-tidy fix. Or aren't there libclang python bindings to write some quick refactoring rules?
Why better with c arrays? You've gotta support that claim.
I recently bought the book, Beginning C++17 because I became aware of this exact issue. (I have only ever done Hello World in C/C++ in the past and my background is VBScript &gt; VB.Net &gt; Python.) Specifically, I was warned about the Lazyfoo SDL tutorial, with SDL being the crux of what I want to do and why I'm learning C++. I'm interested if anyone else has experience /advice/ good tutorials for SDL. 
TurboVision? 
Yes, UTF8 is fine on Mac console. I've inherited some code that I do not fully understand, and do not care to investigate too much now, that utilizes: `std::wbuffer_convert&lt;std::codecvt_utf8&lt;wchar_t&gt;&gt; conv_out(std::cout.rdbuf());` `std::wostream out(&amp;conv_out);` I could not get it to play well with Ncurses (but Ncursesw worked) or termbox. I'm not remotely an expert on any of this though, so take my experience with a grain of salt.
You are right that disruptor is the way to go with any high performance messaging. However, I believe with the ways that C++ abstracts things, there isn’t much usability the user needs to sacrifice for the performance.
It depends on the size of the code base for me. If it is a small project I don't prefix. But when working in a massive code base I prefer the security prefixes offer.
Simply explain that you are a beginner and learning a topic. I did a number of articles about my experiences with Google Web Toolkit - I was writing about my whole experience, all the troubles I encountered, and things I'd learned. I find a lot of articles basically give steps, but never say anything about the errors they encountered learning about things, and that causes issues when versions change and evolve and errors show up - not knowing what could be issues in environment setup, etc. I tried to do the opposite, show the success, but show all the errors and roadblocks I ran into as well. I think you can do something as a beginner, just admit you are a beginner. 
It's even worst than Python++. If you go to Microsoft land you will figure out that there is another ``new C++'' that uses ^ (hats), I think that's the genius of Herb Sutter. So at this point I don't know what's worst: C-styled C++, bastardized C++, standard C++. I don't know what to pick, I mean if you are embedded you don't even have a choice, it's mostly Better C. I think the committee needs firstly to educate the corporations, and afterwards the teachers, it's a huge problem and everybody seems to do whatever thinks it's right, like the wild west.
Rather depending on the size of classes and methods. You start having difficulties distinguishing between local variables and class data members when either class has many data members or methods are too large to see local method variables. When classes and methods are within reasonable size limit, there is no need to have a special prefix for class data members.
I certainly agree that potential errors and such should be a consideration for anyone writing an article directed at beginners (intermediate and above I expect to be able to deal with such things themselves). However, putting "I'm a beginner" on top of a page doesn't help if half the information in an article is wrong.
Just a hobbyist programmer, I prefer to use this-&gt;, I dont mind the verbosity, and it usually gets highlighted a different color in my editors as well.
Yeah, I think that, as usual, it's context-dependent. Want to ensure that your message is written no matter what? Flush it. Is the performance of your application more important than ensuring that some particular message gets written? Maybe don't flush it.
&gt; C++ is missing reflection Even Oracle (Java) is doing things to constrict reflection. It's dangerous to allow at runtime. It is powerful and useful to be sure. But it is very dangerous. But yes,C++ is very tightly coupled module-wise, in ways other languages aren't. I feel this is an issue. I'm also wondering if symbol managling and calling sequences is something that should finally be standardized - this could address some of the module/linkage issues between compilers. 
I like and use it, for two reasons. First, for large classes or large functions, I think it's more clear to read. Second, consistently using the prefix means you no longer have the "OK I have a function called `size` what do I call the variable" problem, because the latter has a clear answer -- `m_size
&gt; I prefer to use this-&gt; If I did some hobby stuff for myself I'd actually give that a shot; I've thought about this before because of Python, where I've actually come to quite like it. I actually already do this sometimes for functions that are binary operations on the same type. For a silly example of my little convention: struct wrapped_integer { int x; wrapped_integer operator+ (wrapped_integer const &amp; that) const { return { this-&gt;x + that.x }; } }; But I have a feeling it would make my coworkers wonder what the heck I'm doing, and in the context of C++ signals that there could be something weird going on, and there wouldn't be in this case. (For example, you very occasionally *need* to say `this-&gt;member` if `member` is inherited from a base class that depends on a template parameter.)
one guy is hacking it slowly but surely &amp;#x200B; [http://tvision.sourceforge.net/](http://tvision.sourceforge.net/)
Wait, what if you use “using namespace std;” so you can omit “std::” ? Sorry if it is a dumb question. I’m new with c++
The performance hit is not so much a problem with std::cout &lt;&lt; .. &lt;&lt; std::endl, but with file streams I actually observed some pretty severe performance degradation when using std::endl.
class Heretic { public: ... private: struct Self { int datum; ... } self; }; class Pimpler { public: ... private: struct Self; struct Self* self { nullptr }; }; 
I’m in university learning c++ and we are not allowed to use c++11 features. When we turn in programs, each use of c++11 takes a good chunk of points off our final assignment grade. They don’t teach it. I haven’t looked too much into it but I figured it was just because c++11 is unused in the career world or it is ineffective compared to c++98.
Actually that's the whole point of "using namespace std;". But usually you should omit the "using namespace std;" instead.
I love this post, thanks for teaching me the evolution of graphics hardware from the software point of view. I did not know this, and it really helps support the theory that graphics does not belong in the stdlib.
Same function, same behavior, whether you call it with explicit namespace or not.
on most IDE, you get a different colour for local and members variables.
That's the point of it but the problem with teaching it to beginners is that they then add it everywhere. So you end up with `using` statements in global scope of header files which causes things to pollute your global namespace. If you are going to be adding `using` statements, it should only be in function or class scope, and should normally name a single class instead of importing a full namespace.
std::array is much better than a c-array, because it behaves like a proper container with value semantics. That being said, I agree that in a c++ tutorial std::vector should be good enough.
&gt; Alas, AFAIK, array requires us to duplicate the size that I don't want to bother to know. That is indeed annoying. In c++17, you can omit all template parameters, but that means you also can't specify the type. Not in c++17
Disagree. Red is much better and clearly faster. Almost everyone I asked agreed with me.
Have you actually looked for paied tutorials? I haven't, but such things usually do exist (I forgot the name of one popular website offering such courses)
Don't teach shared pointers to beginners. 
You might not even need an account. I use stackoverflow all the time, usually from search results. Almost any beginner question will already be answered on there. Just be sure to search first when you have a problem.
And don't get me started on multidimensional arrays. `std::array&lt;std::array&lt;std::array&lt;int,5&gt;,3&gt;,7&gt; array;` is a nightmare to look at and understand compared to `int array[7][3][5];`.
Ah u/vector-of-bool is at it again with making my life easier. He’s got a patron up and y’all should give him some support, esp if you use his wonderful vscode extension 
Nah, that's /u/bstroustrup.
Actually I just spoke with my c++ professor and he said in that syntax the variables are defined from right to left starting from the curly braces.
The casing format I tend to use for members avoids potential confusion: `snake_case` for local variables and parameters, `pascalCase` for private members, `CamelCase` for public. the `m_` prefix is unnecessary, and if I have a case where a private member would have the same name as a parameter (e.g member `data` and parameter `data`) I prefix the parameter or local variable with an `_` `m_` to me just reminds me of the legacy code I've seen at work, and that's upsetting lol. makes me uncomfortable and doesn't feel "right", so I prefer my format.
There is a section in the endl link that indicates implementations are free to flush buffered streams on a newline if they so choose, no matter what. &gt; In many implementations, standard output is line-buffered, and writing '\n' causes a flush anyway, unless std::ios::sync_with_stdio(false) was executed. In those situations, unnecessary endl only degrades the performance of file output, not standard output. 
True, but it indicates that it's not necessarily the wisdom of an expert. Someone with discernment skills should be able to adjust in that case. 
Personally, I don't use the `m_` prefix. If I need to distinguish a local variable from an instance variable of the same name, then I'd just use `this-&gt;` for the latter.
F
Seems interesting.. When i was young I was. Impressed by (pascal) turbovision... But now i need something more stable
There is no problem with "using namespace ..." if you use it correctly... if you have a function that you need to use lots of std::X functions just put the using namespace in the scope, just don't put it somewhere stupid like a header
I think the reason is that “old” C++ is rather basic and gives you a foundation so you can expand your knowledge. I don’t think most people watching beginner tutorials are going to write production code any time soon. I mean, I don’t think you have to start from the absolute lowest level concepts first, but many concepts in C++ do kind of rely on you understanding some of the more lower level concepts. Not trying to defend those tutorials (I haven’t seen them), but sometimes it can make sense. 
&gt;I am uncertain how I would go about explaining shared\_ptr to a new programmer Why would you? Shared ownership by multiple threads is unlikely to be encountered by a new programmer. &gt; I can't tell what type something is New programmers should probably use IDEs rather than plain text editors. &gt;std::vector By using this one, you are implicitly teaching templates. When taught long before alternatives like arrays (as done in every sensible textbook and course), they do "get somewhere useful fast". &amp;#x200B;
It's only faster if it has badass flames on it. 
because of naming collision. It nicely partitions all the functions in that namespace. By saying `std::string` you are explicitly saying use the string class from the std namespace. You might work somewhere (heaven forbid) where they have written their own `company::string` class class. If you bring into scope the std namespace via the `using namespace std` statement then you would run into collisions. Also, it helps the code readability
I've used pluralsight for C# and Python and both we really good. Way better than free offerings I could find. I haven't looked for c++ there but it wouldn't surprise me
Although not a tutorial, i found [C++ Core Guidelines](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines) quite eye-opening. It's written by multiple experienced authors, including Bjarne.
Go figure. Seems like using the newline character when you don't want to flush is perhaps the best you can do?
In that case `using std::endl` ect should be prefered.
I wish I could make the compiler complain if I access a member without using this-&gt;
Why would I use "Beast" over Go's websocket implementations?
The trick to writing a comment like this is to add sufficiently helpful and clarifying info at the end, and then realize you don't need most of the first half since it kinda makes you look like a jerk.
I'm not a c++ developer but I feel that everything in std should be special. It's the others that should prefix their classes if they collide with std
If you have coarse granularity, Bazel will be forced to execute more tests than necessary after a small change. [This Reddit comment I wrote a while back contrasts a fine- and a coarse-grained build configuration to explain this point](https://www.reddit.com/r/SoftwareEngineering/comments/90gj40/regression_test_selection_why_isnt_it_more_popular/e2rxkld)
The scope of an identifier, stack, class, global, is a very important information to clarify code. Note using a notation, whatever it is, is rejected by a code review here. I don't like the suffix _ which smells like "something is missing after the _"
Yes, Pluralsight was the site I had in mind. Thanks.
Interesting. The last time I played with it, it took much longer for some reason. I'll have to try again.
I have my QtCreator set up that way. I don't know it if twas the default, I changed the colors of tons of stuff, some of which wasn't really distinguished in the default settings.
No no no no. Flames signal danger and scare people away. Then once nobody uses the bikeshed, what are we gonna do? Instead what we need is a sky blue bikeshed with green and yellow polka dots.
That is not qutie what I had in mind. C++ toolchains do actually guarantee certain behaviors beyond what the standard does. That doesn't mean, they will support it forever, but your code will not suddenly stop working because you upgraded your compiler without lots of advanced warning. E.g. gcc guaranteed wrap around behavior on signed integer overflow for a long time and even now you can still request this behavior (`-fwrap`). I'd guess (but again, I haven't checked) that current compilers actually guarantee that this works: int* i = (int*)malloc(100); i[0]=5; 
I don't think this is so bad/weird. I work in C++ every day but don't use stl or boost, nor auto.
Because browsers don't generally rasterize the whole web page all at once, given that many web pages are huge. You seem to know what you're doing, so go ahead and implement your api. ¯\_(ツ)_/¯
Thanks, I use QtCreator from time to time, but I don't think this is the default.
If this comes up often enough, consider an [alias template](https://gcc.godbolt.org/z/r0Mm_B): static_assert(std::is_same_v&lt;mdarray&lt;int, 7, 3, 5&gt;, std::array&lt;std::array&lt;std::array&lt;int, 5&gt;, 3&gt;, 7&gt;&gt;);
Why would you use Go if you're using C++ and Beast is available?
I happen do disagree. Far too much noise for too little benefit. While we have to be carefull to not teach beginners antipatterns there is still a difference between proper guidelines for production code at a company like google and guidelines for people that just start to learn c++. In my opinion, things like not using `using namespace` or when to use `std::endl` are optimizations that should be thought when they become relevant (i.e. when they start to work on large projects), not when you are just about to learn how to write a loop. When teaching a language KISS is of paramount importance. I find it ridiculous how much time people spend bikeshedding on the "perfect" hello world program. There are so many/much more important issues than this. 
There's a bunch of existing discussion about this in https://stackoverflow.com/questions/1452721/why-is-using-namespace-std-considered-bad-practice.
&gt; Why use a std::array? Cleaner syntax when using `&lt;algorithm&gt;`
I am a complete beginner.
What is a "good" habit also depends on the context. Putting an `std::` prefix everywhere is almost trivial and can easily be done incrementally. If my project grows from "small teaching example" to a size where I really have to worry about name collisions or generally to which library something belongs I, there is usually much bigger refactoring necessary. That being said: Just like you, I'm used to not use `using namespace ` so I don't do it in my own projects. I just think for a beginner tutorial, people are far too worried about such minor details.
I don't think it's any less readable or less difficult to understand though. You are teaching bad habits for no good reason. If someone gets confused about having to type `std::` all the time that's a _good_ thing as you can explain why it is necessary and creates more learning opportunities. Throwing in `using namespace std;` just to prettify the code is silly, and if it's just about making the code look better then there are good practice workarounds like I pointed out. I'm all for making things easier for a student to understand, but I don't thing `using namespace` even accomplishes that. It may even lead to more confusion.
Nobody should be able to use the word ``C++'' if it isn't Standard conforming C++, period. The committee needs to take immediate action and they have to start from the HEAD (Corporations). Here's a few suggestions: * Microsoft's C++ should be renamed Herb++^. * Qt's C++ should be renamed QMOCplusplus. * Embedded C++ should be renamed NECHITACHIFUJITSUTOSHIBA++. * Google's C++ Style should be renamed Googles's TiTuS++ Style. Why all those organizations get away with false advertisement and abuse of the language? We should stop blaming the teachers for not doing a good job, most people in general will follow a good example, but it's non-existent, that's the main problem. Why MS skipped C++11 conformance, why they shipped a half-assed compiler with VC11 while Sutter was ``selling'' C++11 it's here. All those things are unacceptable and unprofessional for serious businesses. So if you want to be taken seriously better __demonstrate__ some professionalism, no we don't need another paper, we have enough. 
By any means, do you have some source somewhere? And how do you handle things that can't be seen by a coverage/profiling tool, like the value of a global variable without initializer (like a const int, or a const enum), or adding a new overload function, a new virtual function, … I thought that maybe I could use something like clang AST as a source of diff, but I fear it would be complicated to maintains, and long to compute.
They should, but people are stupid.
Like this very much but without simple middleware (like js) for mainstream, c++ will not reach a lot of people i guess
F. C++11 and beyond is a mess.
I usually drop the `m` from `m_` and just keep the underscore prefix.
I'd be suprised if something like that did not exist tbf. However I did find some weird things that are probably difficult to process automatically. Like one of the things I found was similar to: for(auto &amp;i:items){ if(i.first==key){ return i.second; } } Which was looping over a vector of pairs to find a specific one. Cppcheck rightfully suggested a change to `std::find_if` . While maybe a better refactor would have been to consider replacing the vector of pairs with map/unordered map if its going to be used for key/value lookups. &amp;#x200B;
&gt; I don't think it's any less readable I think it is mainly a question of what you are used to. However, it is a fact that shorter text *that contains the same information* is easier to read - to what degree is a different questions. Also, for people new to c++, all the special punctuation does make things more difficult to read - it takes a while to get used to it. &gt; You are teaching bad habits for no good reason. I don't think it is a bad habbit. What people tend to forget over and over again is that "proper" guidelines often depend on the context. An embedded systems project needs to follow different guidelines than google engineers when they write a performance critical piece of code for their server infrastructure and their guidelines will differ from guidelines in microsoft projects and those are different from the ones in many open source projects focusing on linux. `using namespace std;` makes sense in some contexts and doesn't make sense in others. Preventing people from relying on `using namespace std;` is trivially easy. Just have a linter rule (clang-tidy has one). Kate Gregory gave a nice talk about teaching in which she also mentioned why most teaching examples favor simplicity over following all established best practices (again, think about input validation). It is because - for now - we want to focus on a different aspect (I don't remember if she mentioned the `using namespace std` case explicitly or what "side" she was on). &gt; If someone gets confused about having to type std:: all the time that's a good thing No one is getting confused about that. Those people are not stupid &gt; Throwing in using namespace std; just to prettify the code is silly, It is not about pretty. It is about improving the signal to noise ratio of the code and thus improving readability (c++ is already pretty bad in that regard). When you start programming and use only the standard library, `std::` is a completely redundant - it doesn't convey any interesting information. Later it becomes more important (both to avoid (future) collisions and tell people where the type comes from), so it makes sense to explicitly write `std::` then, but you might still not want to write a prefix like `winrt::Windows::Web::Syndication` everywhere - it is a tradeoff. &gt; and if it's just about making the code look better then there are good practice workarounds like I pointed out And I pointed out why I think it isn't a good workaround. You are adding redundancy (similar to includes that become stale over time), you are again adding quite a lot of noise (consider how many different types from the standard library you have even in a short "modern" cpp source file) and all that just to save the `std::` is imho not worth it.
I would probably just do a wrapper around `string` that isn't move constructible, and is constructible from `std::string&amp;&amp;`.
The reality is that 99% of the c++ code in the wild is still that outdated stuff and almost no one uses modern c++
So did anyone actually learn anything useful about benchmarking from this?
Curious, how widespread the use of the "microsoft/new c++"?
Which someone learning C++ for the first time should not care about. 
The entire `std::` namespace is reserved for future use. If you say `using namespace std;` there are no names left, or your code is not forward compatible. Imagine if I have a name in my code called 'span'. Well now maybe I have to prefix it, because in the C++ 20 standard, `std::span` is introduced. Also, maybe you are another developer in my company and you didn't read [P0122R5](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0122r5.pdf) when it came out. If you see the word "span", do you know what that is? Maybe it's something in our code base. If you see `std::span`, you know it's from std.
&gt; ems. This sort of thing needs to be standardized: My brain hurts trying to understand this templated code. I'm not too familiar with the concepts being used here. Care to explain what's going in the templated structs?