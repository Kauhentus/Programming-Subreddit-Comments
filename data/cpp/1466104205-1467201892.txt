Why C++? Do you have an interest in gaming or some other realm where C++ is the most popular for development? The language itself is not the easiest to learn, nor the friendliest to develop in due to its complex nature and room for you to shoot yourself in the foot. I would think about what programming domains you're interested in, and consider what languages are most popular there.
Good question, I was surprised that its so widely popular, while Concepts is the only candidate, which could have made it, its last: https://twitter.com/meetingcpp/status/740910551920959489 To answer your question: I think that module feature is currently over hyped, people seem to think it cures cancer too... ... but its going to bring faster build times to C++, which is really a big improvement. Also, module as a feature does not bring something new to the language, except that it will change how we bundle files, and #include will not be needed as much anymore. As theres a lot of experience with modules in clang, and Gabi Dos Reis leads the efforts of C++ standardization and implementation for MSVC, I think C++20 will bring modules. They will be usable as part of a TS probably much sooner, MSVC and clang already offer them, where MSVC is closer to the standard then clang currently, but I expect that clang changes its implementation soon (if not already happened).
If you are intent on learning C++, Programming: Principles and Practice using C++(2nd Ediiton) is a wonderful book. It's aimed at beginners and focuses on recent standards of C++ (which actually make C++ easier to learn). Maybe the mixed reviews you had are concerning the first edition of the book or people are possibly confusing the book with other Stroustrup books. I am curious why you're choosing C++ though. While it is a wonderful language and I have many reasons why I prefer to program in it professionally, it's not for the faint-hearted. I don't want to steer you away from C++, I just don't want you to give up programming if you find C++ too challenging. On the positive side, if you understand C++, you will be able to pick up most other imperative languages rather quickly. The negative is that C++ has a steeper learning curve than most languages, though it has become a lot less steep with the recent standards.
As others have said, there is nothing quite like doing it yourself. Reading books will only get you so far. The most important skill in programming is not so much knowing any particular language syntax, it's knowing how to put a program together -- which is a slow learning process no matter what language you're using. Project Euler (https://projecteuler.net/) is a great way to sharpen your coding abilities while learning a broad range of (sometimes obscure) math concepts. The problems are small giving you experience in both learning the language itself and also developing algorithms that not only work but are efficient. The problems also tend to build on each other so you find yourself collecting algorithmic "tools" that you can reuse to solve later problems which is also a common pattern in professional development. Once you feel like you've learned what you can from that, then it is time to find a real project -- either one you've invented for yourself or latch onto an open source project that interests you.
 set(CMAKE_AUTOMOC ON) set(CMAKE_AUTOUIC ON) set(CMAKE_AUTORCC ON) set(CMAKE_INCLUDE_CURRENT_DIR ON) find_package(Qt5 REQUIRED COMPONENTS Core Widgets [...]) target_link_libraries(MyApp Qt5::Core Qt5::Widgets) If you don't need uic / rcc you can skip the relevant lines and it goes down to 4.
&gt; eventually it may even solve the underscore hell in STL Unlikely; the "underscore hell" is also used to guard vendor-specific compiler extensions (`__declspec` / `__attribute(())__` / `__cdecl` / etc.)
My (extremely limited) understanding is that the last remaining "hurdle" is that the clang folks want to be able to export macros, and we (the msvc++ folks) want to not be able to export macros.
Why would they want to export macros? Are they insane?
Thanks a lot for the tip(?)! on getting IT experience. I am definitely interested in programming as a career. /r/dailyprogrammer subreddit looks promising. What do you think of C++ Primer or C++ Primer Plus? for someone like me.
tell me more about what format you would find pleasing. blog post? series of blog posts? by presentation do you mean a powerpoint deck that would standalone instead of a demo heavy presentation?
see my question above please.
default was in C#.
They're both great books. I generally would not suggest C++ as a first language, but it's not a *bad* choice by any stretch. Many schools are teaching Python first, these days. If you want to flex your programming prowess in an IT job, Python (or Perl) would be a better choice than C++. Nothing wrong with C++, though.
It's kind of ironic, considering how Microsoft fills their headers with a bazillion macros. It would be really nice to be able to use Windows's API without polluting the global namespace with macros.
You think this, but then you meet Haskell and Lisp folks... /s
All good thanks. I already like that course even though i'm only on lecture 4. There's also a lot of confusion between C++ Primer Plus and C++ Primer. They both get the best and worst recommendations. Weird. I will continue going through reviews on books though! 
I honestly don't care so much about build times. I care about not having code be duplicated across cpp and headers, making the mental effort of coding much harder than it has to be. When you've programmed in something like C#, you realize just how much of an impact that can have on your productivity. Concepts are nice, but I think a large portion of C++ programmers don't use templates (partially due to the problems that concept is supposed to solve).
I would say Unity and C# are for Indie or small games, or any game where performance doesn't matter. AAA games use C++. The games made by Valve for example, are coded in C++. Also the games made by Blizzard. Of course there's the outlier Minecraft, done in Java. But it is clearly an outlier.
I'm deeply disturbed by your excess of ñ letters. In Spanish it is just n for that word. They sound different. Ñ is the sound in words like gnocci (ñoqui) or champagne (champaña).
I'm a novice but I like this movement? There's no downside to standards besides what @immutablestate said. *Nice idea, don't think it will happen because it boils down to OUR PROPOSAL Renowned C++ experts do work for free*
haha! Nope. AFAIK modules don't end the .h/.cpp reign in C++, its just a different way to package your code for the compiler. Its not like you get to just write your class in one file like java/c#.
Write a post (or a series if you think the topic is worth it). Videos make sense for talks (I.e. I had no time nor money to attend) but written content is much more valuable: You can take a brief look, search for keywords, etc; and could also be considered reference by the community if the post is good enough.
Yes, people also want to have their macros supported. There is the fault line, how much legacy do you want to support. And many say, its only worth it, if its like 100% legacy compatible. People only want to change from #include to import, but not the code itself. Also clang version of modules AFAIK always supported macros, but clang never intended standardization, so thats why this conflict existed, but AFAIK this has been resolved.
It was my understanding that it would greatly lessen the need for headers in most cases. It's a bit confusing though, so I dunno. I'd have to try it out. Here's to hoping you're wrong and it does... or the proposal changes. The .h/.cpp reign in C++ is one of my most hated things about C++, despite loving the language.
I think modern C++ is a fantastic programming language and it is much better than the C++ I learned back in 1998. Almost all criticism I can find against C++ applies to the 1998 version but not to the modern one. The thing about C++ is that it enables you to think in very different programming paradigms and mix them at will. The mix them at will is the tricky part. Some people are used to procedural programming like C, and you can do that in C++. Some people are used to Java-like OOP, and you can do that in C++. Some people are used to generic programming via templates, and you can do that in C++. Some people use extensively RAII in C++ and you can't precisely do that in many other languages. There are some equivalent features in other languages, but they are not as clean as RAII. Yes, I expect you to google that. Some languages let you work in a funcional paradigm. The latest C++ standard has some features of this paradigm, but C++ is not a functional language. And then you decide how to mix them all. Here be dragons. And all this while having very good performance compared to most languages. Also, makefiles. Other languages have nice and standard build systems. C++ does not. Most platforms have many compilers, each with its own way to do things. It makes many people reject the language just for this reason (and I do think it is understandable). For that particular problem I recommend [cmake and this particular repository of tutorials](https://github.com/Akagi201/learning-cmake). It will enable you to make your code portable between platforms, with some extra work.
&gt; C++ Primer or C++ Primer Plus Neither of those are really aimed at teaching programming. They're for teaching the details of C++ to someone who either already has experience programming in another language, or someone who is also receiving supplemental instruction such as in a college course. _Programming: Principles and Practice Using C++_ really is focused primarily on teaching programming, and secondarily on teaching C++ as the medium. For someone with little or no previous programming experience this is definitely the better place to start.
For me it is "just" build times. There is a huge difference in productivity when you build in one minute instead of 15. Concepts would not change much for me, modules would. It is my most wanted feature. For other things there are (imperfect) libraries, for modules there is no replacement. No, pch don't cut it. That is something I am envious of Java and Go. Their fast build times. Of course modules make tooling also easier.
Because the inability to export macros results in not being able to use many libraries with the module system. Just ends up being a judgement call.
As a maintainer of std::min and std::max I feel your pain :)
&gt; clang never intended standardization Really? That's a shame.
Not at all. `auto` isn't dynamic typing. That's the beauty of it: static typing without the boilerplate.
What books for complete beginners do you recommend? I was considering C++ Primer or c++ primer plus. But it's still up for debate. Currently looking at * Starting out with C++ from control Structures through Objects (8th Edition) by Tony Gaddis * Programming: Principles and Practice using C++(2nd Ediiton) by Bjarne Stroustrup.
Public macros belong in include files, not modules. You're fighting the good fight.
Do you mean not being able to export macros at all? Many libraries like Google Mock or logging have to export a few macros for good reasons. I think module should be able to specify which macros to export but by default nothing should be exported.
The magic of imported targets!
At least by the time Modules come around, there's one fewer use case for macros (caller source location information) via `std::source_location`.
Out of curiosity, is there are reason to expect modules to be able to deliver faster build times than are available when using precompiled headers, which have been around for many years? For example, the [Clang documentation on PCH](http://clang.llvm.org/docs/PCHInternals.html) specifically says: &gt; Modules, as implemented in Clang, use the same mechanisms as precompiled headers 
 // hello_world.cpp #include &lt;iostream&gt; int main() { std::cout &lt;&lt; "Hello, World!\n"; } `g++ -E hello_world.cpp` -&gt; Tens of thousands of lines of code.
To use a /u/spongo2 -ism, I think the STL is not going to have to worry about being `_Ugly` sometime after heat death of the universe :)
20 years is a long time, let's be bolder :) Basics * Modules &amp; concepts will be in the standard in some form. These are all taken for granted and have annoyances that are now known after having been in use for 18+ years. Standard library improvements * Ranges in some form. * We will get a `std::text` that understands Unicode properly. This will have an associated 'character+trailers' type called `std::rune` or `std::grapheme` or something. * Libraries for networking, filesystems, etc * `await` &amp; `yield` will be in the standard so we'll have `std::task` and all the combinators for it. * A replacement for `iostreams` and locales will exist. * Types for numeric computation (`std::matrix`, `std::actual_vector`) will be added. Core language * Variance will be added to template parameters, so `std::unique_ptr&lt;T&gt;` can work more like `T*`. * All literal types will be able to be used as template parameters. * To reduce boilerplate, there'll be some way to automatically implement equality, comparison, etc. This will be user-extensible to other traits. * More specifiers like `constexpr` will appear, probably `pure` for functions without side-effects, `safe` for code that doesn't do unsafe memory operations (this will also be able to be applied to classes, or even at the module level), maybe `noalloc`. * From functional languages we'll get some form of pattern matching, discriminated unions, etc. * Perhaps: Some form of typeclasses. C++ will get more features from managed languages * JITted runtimes/environments will appear so that vectorization and so on will be customized to the current processor. * Garbage-collected references will be built in. (Something like C++/CLI's `^`, but it will work on standard C++ types.) * Online/daemonic compilers (like HHVM) will become the norm. Build-the-world throws away work! * The C++ compilation phases will be relaxed/removed so ordering of declarations doesn't matter (like Java/C#). ODR becomes irrelevant. Headers are no longer needed, so CPP/macros are removed from the standard. * Reflection will appear in some form or another. * Perhaps: The JITter will be able to migrate particular code onto a GPU (this will support the `std::matrix` type)... or other forms of heterogeneity that are invented. * Wishful (some shades of dependent types): Due to JITted code, runtime template instantiation becomes possible. You'll be able to `std::matrix&lt;m, n&gt;` where `m`/`n` are variables whose value is only known at runtime. Ecosystem * There will be an industry-standard package manager. * Due to JITting, binaries are shipped as bytecode. This is likely to be related to the [IPR](https://github.com/GabrielDosReis/ipr) module format. You won't need to build `libfoo_{32,64,128}{release,debug}{ltcg,}{etc,}`.
Can't we just agree that all programmers are terrible people?
&gt; From memory, what I had found: data locality can be a huge factor for performance (as well as many other things), yet Big O doesn't seem to use it. Because, like I said, Big O only measures complexity, not performance. The really useful thing about complexity is that you can estimate what a particular algorithm's relative performance will be based on the input size. Comparing two different algorithms by their complexity is useless without performance data.
Stack Overflow maintains a "definitive" list of C++ books that aspiring C++ programmers might want to read. Here's the [link](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list)
So, both have multiple editions. Get the most recent editions for both because they'll cover C++11 which will make things easier for you (and make you more valuable in the workplace too). I have not read either books, but I've heard they are both good. The reviews I've read indicate that *Primer Plus* is better for beginners while *Primer* is better for intermediate programmers. &gt; I've gone through too much to be demoralized by anything. Good on ya! :)
`#include` isn't going away...if you want to make public marcos, just put it in a file to be `#include`'d. It makes sense to me...preprocessor crap needs to be brought in with more preprocessor crap, and import can be used to bring in everything else properly
C doesn't have a standard ABI.
And if you want to make a single app for both Android *and* iOS? **C++** is one popular way to achieve that. And there are many fields that are exclusively or near-exclusively C++: high-frequency trading, defense industry, aerospace (shared with Ada), automotive and other embedded projects (shared with C), medical devices, audio and video codecs, CUDA / GPU accelerated computation, high-performance science work (like at CERN), and the list goes on. Don't take me as a C++ elitist. There are a lot of areas where other languages are better ... and most of those languages are easier to pick up than C++. But it's OK for people to want to be C++ developers. They just have to understand (a) the challenges of learning the language and (b) the job landscape out there. Maybe you were just trying to broaden his horizon. Your comment just sounded very much anti-C++ to me.
Hi Steve, by presentation I indeed meant powerpoint, but your idea with demo heavy one is amazing. I think - blog + demos (small videos or something like this) - would be epic.
Hopefully, it'll bring ABI standardization so that I'll be able to take a module produced by one compiler conforming to the spec and use it w/o any fuss in a project using another compiler conforming to the spec. If this mode of use is not among the topics of the standardization effort, then modules are pretty much worthless to me.
Blog, technical article, anything that I can read through quickly in order to find the actual information. If I can spend 3 minutes and learn something new it's 15 times better than spending 45 minutes.
For C++, 20 years is a long time, I think another language safer, simpler to learn and faster to compile will replace it probably before 2036... 
Huh, I never tried to copy or move that type before; TIL. It also prevents code like: std::random_device make_random() { return std::random_device(); } ... std::random_device rng = make_random(); Could be annoying, though I haven't personally had a need to use random_device for more than generating the seed for some other PRNG. It strikes me as a bit weird that it isn't at least movable... which leads me to wonder what this has to do with move-only types and `auto`... :) Though it is weird that `auto rd = std::random_device{};` doesn't call the default constructor like (my completely uninformed opinion thinks) it should.
You know there are tools that make it easier? Visual assist lets you change function signatures, parameter names, etc. It's go to implementation is smart-ish too; it goes to the implementation in the cpp file, and if you use alt+g on the implementation it jumps to the definition. Not that I'm defending it; it's still madness!
Yes, I use VAX. Alt+O is a huge time saver (although I think VS implemented it recently as well). For going to definitions, I just do Ctrl + Click. Never used Alt+G. Also, hail the almighty Alt + Shift + R, but I guess that's kind of unrelated.
Vs had Ctrl + k, Ctrl + o, (in theory same as alt +o) but I'm not sure how long it's had it. It's not as good as vassist's though. Our code base uses ink files for inline implementations and visual assist takes them in its stride. Visual studio gets a little confused though. 
 &gt; It strikes me as a bit weird that it isn't at least movable... I assume that they didn't want an `rd` in an empty/weird state. &gt; Though it is weird that auto rd = std::random_device{}; doesn't call the default constructor like (my completely uninformed opinion thinks) it should. It does call the default-ctor followed by the deleted move-ctor. The compiler might normally be able to remove the later, but it is not allowed to, if it doesn't exist.
The problem I see here is that 'using' has different meaning under different circumstances. I would actually want to see some kind of unification.
The CSS isn't loading for me for some reason. But yeah, all this is why I completely avoid using `typedef` at all in my code, and always use `using newalias = type;`
Probably best to ping /u/blelbach/ BTW, also the [ACCU 2016](http://www.accu.org/index.php/articles/2234) conference hasn't fully released all slides. It seems that after the initial wave, there is not that much follow-up from organizers to complete the available content.
and `typename` 
Only the starter edition so not that exciting, but hey it's a £200 save :)
That's what he said at the beginning.
Getting new keywords past the committee is hard.
RSS is great. I'm starting to think your generational gap comment may be pretty spot on.
Help me.. when does 'static' mean something different? edit: Thanks all!
My theory is it will be just like Javascript.. :-) 
Ah, I think GitHub rolled out an opt-in feature to fully enable HTTPS properly and it's just not been enabled by this user.
Well, it's the Starter. You get going with basic development; if you want Win64, iOS, Android, etc you upgrade.
Why would anybody still use this stuff now? I thought they'd gone long since obsolete - I haven't tried using their compiler since 2004 or so, when I was forced to.
Let's see, the three that I'm aware of are: 1. Static storage i.e. global variables. (As well as function-specific storage) 2. Non-member functions declared in classes. In other languages, these are simply called functions, or "static methods", where member functions are called methods. 3. The old *exclude this from the linker* meaning. Basically, when using static on a normal, non-nested function, you're saying it's an internal routine that should not be used by another compilation unit. To other programmers, it basically means you can't declare it somewhere else, meaning users can't call it / expect it as a part of the API. With all of that in mind, I actually think having context-sensitive keywords is better than having to look up a long list of keywords that mean similar things.
http://c2.com/cgi/wiki?CppStaticRiddle Related (C99, not C++, but interesting): https://hamberg.no/erlend/posts/2013-02-18-static-array-indices.html
&gt; Here is the syntax for the typedef declaration according to cppreference: &gt; &gt; typedef type_declaration; cppreference no longer contains that section because that was incorrect. Declarations such as `double long typedef x;` or `long typedef long x;` are also valid. [This reddit thread](https://www.reddit.com/r/cpp/comments/4m4pep/fun_c_syntax) mentions this syntax. 
With VS I can develop apps using a number of languages, targetting multiple platforms. Much of the library source code is available, even in the free edition. DB apps are easy with .Net, the price (Enterprise) includes access to a whole raft of development licenses to database servers, operating systems, etc. The tools are state of the art, and its still cheaper. Even the Community Edition supports most of the toolset, while I'd have to spend over £1000 to even start learning to use the database tools with Embarcadero. That just means I'm very unlikely to try it. For a company who has lost a lot of marketshare, they will have to try harder to attract developers to even give it a go.
I'm embarrassed that I didn't think of typedefs in this way before.
First, it is a whole lot easier to reuse an existing keyword than to create a new one. Every new keyword is a tiny backwards compatibility break. Not to mention how difficult it is in the first place to come up with keywords that are terse, self-descriptive, easy to remember, not likely to be confused with other keywords at a glance, *and* that users aren't going to already be using as an identifier! Second, the `using` keyword was already being used for type aliases in C#, so there was some precedent for it.
There is a good reason why introducing new keywords is hard to get through the standards committee. They are working hard at keeping breaking changes as minimal as possible. Such a new keyword could have been in use in big codebases already, or apis of some libraries, which would require large refactoring and maybe changing the api. By just reusing something that is already a reserved keyword you avoid this possibility of big breaks.
They're letting people use the compiler for free already. I don't think there's that much of a danger they'd see competitors use the compiler technology. The plus side is they'd possibly get people spotting bugs in the compiler and/or submitting patches. I mean, their value is in (a) getting people to develop for Windows and (b) getting corporations to pay for IDE licenses. The compiler isn't where their value lies today.
&gt; For a company who has lost a lot of marketshare, they will have to try harder to attract developers to even give it a go. Sure. What would you suggest? I'm not quite convinced of everything you say (but open to being convinced, please reply and persuade me :)) For example, the Pro edition - the $1200 price point - includes the entire source code to all libraries. As far as VC targeting multiple platforms goes, it seems a weak solution. CB targets more platforms, and has UI tools as well - VS requires you to leave VS in order to do anything other than code, and who wants to rewrite layers of your app for every single platform in external tools to boot if you can avoid it?
**NOTE:** I know this post is long with a lot of suggestions and requests. But you did ask what would be pleasing. I really do think the changes below would make the information more accessible and interesting for developers. Videos are not bad. There's value in being able to see how someone walks through something. However, 45 minutes is too long. (A lot of people have short attention spans.) The video should be broken up for each feature or mini-feature and should aim to be about 3 minutes in length each -- maybe 5 minutes max. There should be a blog post or series of blog posts about the features. Each blog post can have one or a couple of the short videos embedded with it. A couple screenshots are good too for those unable or unwilling to watch videos. The videos should also be available directly on channel 9 and/or YouTube and should have links in the description back to the blog posts. In the case that longer videos are made, the description should contain links that jump to specific times in the video. (YouTube is great with this. You really need to talk to whoever develops or maintains Channel 9 about time-specific links. If those already exist, then it needs to be easier to access. With YouTube, you just right-click on the video and a menu comes up with an item saying "copy video URL at current time"). **EDIT:** I just found out that you can specify the time for Channel 9 videos. It still needs a YouTube-like interface for quickly obtaining a URL though. In the end, I'm a bit conflicted. I like being able to "meet" the people who work on Visual Studio, but the walking through all the new features does feel like a poor way to accomplish this. As others have said, I think long videos makes more sense when a talk is done from a conference. A better way to "meet the team" while bringing attention to the topics would be to do something like a video version of what CppCast does: Invite someone from the team to talk about the features from a high level, and maybe include at the beginning or end some interesting things about the development and/or something from their personal lives -- that they are willing to share of course. (Ex: How is Stephan's game engine going? What challenges does he face in producing his MingW distro? Something about standards meetings. Volunteer work he's done. Books he's reading. Recent vacation trips.) The video description can then include links to the blog posts that include the videos or, if a blog doesn't exist, direct links to the shorter, more focused videos.
Then what's the point?
Interesting ...have been looking a for a fast performing and easy to use library to integrate into my app for client side requests. Wired this up this morning and testing it out. Easy and fast so far.
I see! Thanks I'm still going through reviews on my spare time and slowly narrowing down what books to start with and what online courses to take. thanks a lot for the feedback and support! means a lot to me.
Links to individual tips: * 1:25 - [Configuring launch options from project properties (command line arguments and setting environment variables)](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=01m25s) * 2:34 - [Seeing function return values](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=02m34s) * 3:16 - [Set next statement](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=03m16s) * 4:07 - [Step into specific](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=04m07s) * 5:05 - [Run to cursor](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=05m05s) * 6:57 - [Edit and Continue (including x64 support)](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=06m57s) * 8:31 - [Exception Settings](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=08m31s) * 13:44 - [Conditional, Hit Count, and Filter Breakpoints](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=13m44s) * 19:17 - [Pinning DataTips](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=19m17s) * 19:42 - [Parallel Stacks window](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=19m42s) * 20:30 - [Show External Code](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=20m30s) * 22:00 - [Parallel Watch window](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=22m00s) * 23:13 - [Freeze and Thaw threads](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=23m13s) * 24:18 - [Flag Threads and Run Flagged Threads to Cursor](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=24m18s) * 26:13 - [Show Threads in source](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=26m13s) * 28:09 - [Debug Location toolbar](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=28m09s) * 29:43 - [Debugging Heap Corruption with Page Heap](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=29m43s) * 33:32 - [PerfTips](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=33m32s) * 35:53 - [Integrated CPU profiling](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=35m53s) * 38:01 - [Integrated Memory Profiling](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=38m01s) * 41:03 - [Natvis](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=41m03s) * 42:43 - [Showing what source code causes an Access Violation](https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/C-Plus-Plus-Debugging-Tips-and-Tricks/player?w=1280&amp;h=720#time=42m43s) 
Yes, in this context, my opinion is anti c++
thanks for your detailed feedback. i'm going to pass all this on to the PMs. For the meet the team stuff, in a lot of ways that is what I'm trying to accomplish with GoingNative shows (which I host and direct). Have you seen those? I think some people do prefer these demos in videos, but my main takeaway from this thread is that for the most important / valuable content, "make it both ways" is probably the right answer.
thanks. feedback passed along.
got it!
No problem! :)
I am trying to stuff the icon into a Linux ELF. Why is this not possible? Is there a work around? 
I have wanted that so bad. A linux executable with a nice icon that the user can just click on and use. There is no such thing. 
Because ELF is strictly a format for packaging executable code; it doesn't have any provision for embedded icons like a Windows executable does. In Linux desktop environments, icons and the like are handled using the [Desktop Entry Specification](https://www.freedesktop.org/wiki/Specifications/desktop-entry-spec/) provided by freedesktop.org (formerly XDG). 
&gt; 20 years is a long time, let's be bolder :) After deprecation of the STL, the Standard Intelligent Library enables new template syntax in the form #import &lt;all_necessary&gt; container&lt;Umm, I just need this to be fast with simultaneous multithreaded access and use the API for dicts in python because I already know that API. Do you have a container like that?, int&gt; foo; You said to be bolder... 
Modules are going to be somewhat similar to python's `import`. Currently used `#include` in C++ literally means "paste the content of that file right here". This has several unpleasant consequences: 1. Templates must be defined in headers, so "modern" headers tend to be large and contain the whole implementation of a library. 2. Compiler has to parse large amounts of code over and over again (if some header is included into several cpp files (translation units), it has to be parsed every time). This makes compilation if C++ code extremely slow. 3. Because of 1. we have violation of encapsulation: all the implementation details get exposed to the user. 4. Preprocessor macro definitions in header files become global in your cpp file. 5. (Update) And currently you have to duplicate declarations of your functions between header and cpp files. Which is unnecessary work and potential source of error. 6. (Update 2) Headers must be manually protected from multiple inclusion using "include guards" or `#pragma once`. 7. (Update 3) Headers can be sensitive to the order of inclusion. (Especially if not well-designed; and especially due to 4.) Modules are supposed to be stored "pre-parsed" form, so no need for compiler to parse them over and over (thus compilation speedup), they can specify a list of exported entities (thus better encapsulation), and macros do not propagate through the module boundaries (as currently proposed; thus better encapsulation and less chances of incompatibility).
I see, so `import` is different from `#include`? I thought they were the same. `import` is not like copying the whole library before the code?
My attitude toward wrapping API's has evolved a lot over the years. When I first started, I saw engineers wrapping API's and I was attracted to it... Mostly because it seemed easy! That was definitely a job I could handle... Then at some point I started to think that wrapping was stupid. It started to look like a good way to create a whole bunch of extra work for yourself. Then about 5 years ago, I was working with a code base that linked a number of different libraries and seemed to use them very inconsistently. The same functionality was provided by multitple API's and each was used... I did some digging and realized that when the libraries were added it was for very specific good reason... But once available, they spread like viruses through the code base. I then arrived at my current opinion on wrapping an API: It useful because it allows you to hide things you don't want widely used and only expose the parts you do.
Well... then it wouldn't really be 'global'... :P Although the concept is essentially the same, and I reckon it is actually the same as a global static variable, except scoped to the function.
How are those two vector examples different?
Love the feedback for Channel 9 content in general. I will make sure to incorporate your ideas into our videos. Thanks again for being so thorough in your commentary!
Ah great point!
The talk mentioned that they looked into the downsides of open sourcing the compiler, but didn't go into what those downsides are. I'm curious about what they are.
Oh yes, I understand completely. Just wishful thinking. In a 'perfect' world, there would be no backward compatibility issues etc.
genuine question, why wouldn't you want reflection?
So the two vector examples aren't different. Got it.
I guess I'm going to go ahead and be "that guy". # Don't aim to work with a specific language. I feel you should reframe your goal to be a "problem solver" that knows how to pick and use various tools to solve a problem. C++ may be one of those tools. Maybe C. Maybe Python. Maybe Java. You want to develop your skill set to be flexible enough to adopt the right tool for a job. Now, that's not to say you can't be a language expert. Language experts are very valuable and becoming one is a perfectly reasonable goal. That said, I think you'll find that you have many more opportunities when you remain flexible. With that out of the way, I would say good next steps for continued C++ mastery are to read and understand Scott Meyers' excellent books: - [Effective C++](https://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876) - [More Effective C++](https://www.amazon.com/More-Effective-Improve-Programs-Designs/dp/020163371X) - [Effective STL](https://www.amazon.com/Effective-STL-Specific-Standard-Template/dp/0201749629) - [Effective Modern C++](https://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996) Also go through the [CppCoreGuidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md). Beyond the language, make sure you know your standard data structures and algorithms.
[removed]
Excellent summary, I agree with each word, particularly the recommendation of the Meyers books. You might consider Python for your next language - because in many ways it's the opposite pole from C++, being a minimal, untyped, but still very sophisticated language. EDIT: Everyone was too polite to point out that Python isn't really "untyped" but simply has much weaker typing. :-) The recommendation still holds though. 
Actually that is exactly what is being discussed. see [P0273](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0273r0.pdf) for details. IIRC the paper favours library devs deciding which macros get exported, instead of library users deciding what gets imported. 
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Because of name mangling you'll get linker errors, as long as don't have the source to your library and recompile it
ELI5?
Thanks for the tip, i am going to check it now
Sadly find a job with C++ is harder than C# or Java so try to learn the basics of both and when you have a job and some experience try to switch back to C++ doing jobs interviews, it will be easier
C++ vacancies are not in the same numbers as C# or Java, we all know this, but there are much less programmers in C++ in comparison. IMHO we'd need to know the jobs/programmers ratios for each language. Anyway probably the entry bar is higher for a C++ coder than a C#/Java one which could be perceived as a barrier.
[boost::operators](http://www.boost.org/doc/libs/1_61_0/libs/utility/operators.htm) is a good library to use for automatically generating these types of operator interdependencies. It's very useful for avoiding having to type a lot of boilerplate code and subtle bugs.
Yes. But boost::operators covers a much wider range of operators such as logical, arithmetic, rings, fields etc. Even within the scope of std::rel_ops it gives finer grained control, such as defining equivalence in terms of less than. 
Can someone `tl;dr` for me as to why this happening, please? Why can't these courses be moved?
http://www.antlr.org/ Great tool now supports a new great language!
I understand they *can* be made to be different, but 95% of the time, this is just fine. It would save a lot of boilerplate if == could define != as !==, &lt; could define &gt;= as !&lt;, and yes, even if it's quite inefficient, &lt; and == could form &gt; as !&lt;&amp;&amp;!== (plus the other three comparison types. So six functions from two.) Or to reduce boilerplate even further and produce optimally efficient code, a generalized compare() -&gt; int operator, where 0 means equal, !0 means not equal, &lt;0 means less than &gt;0 means greater than, and of course, &lt;=0 and &gt;=0 would apply. With one function, containers holding your classes would become sortable, work with trees, hash sets, etc. And if compare() -&gt; bool were define, it would only imply == and !=, and rule out &lt;, &lt;=, &gt;, &gt;= operators as being inapplicable. And then when someone wants the added flexibility, they could declare the other operators. Or if they just don't want them, use = delete syntax on the unwanted operators. Of course, it's too late to make this change to C++. But I'd hope people designing languages in the future would consider that less is often more.
[OT] Do you hate your co-workers, but underhanded preprocessor magic like `#define if(...) if(!(__VA_ARGS__))` doesn't cut it? MSVC might just offer what you are looking for: `/d1nonUDToperators` Ever thought `++int` should add 2? Just do it: `int&amp; operator++(int&amp; v) { return v += 2; }` ( ͡° ͜ʖ ͡°) --- Special offer: human-level performance^1 equality operators *for free!* bool operator==(int a, int b) { using u = unsigned; static u rng = 0xCAF3'B48Eu; rng = (rng &gt;&gt; 1) ^ ((0u - (rng &amp; 1)) &amp; 0xD3AD'F10Bu); return !(u(a) - u(b)) ^ !((rng &amp; 0xFFu) - 0xFFu); } ^1) ^accuracy ^at ^least ^99.6%
 Better/proper language support for programming SIMD &amp; SIMT style code.
To be honest, C++ has also gotten a lot better.
Deducing function specifiers is nice, but sometimes developers make mistakes and intent something to be `constexpr` when its really not. I like these specifiers because it checks my code.
Well I want the entire language to be `constexpr`, so there would be no need for such a function specifier.
But what about `volatile`?
And also `virtual` and `const`
just use boost::operators (see hubhub comment for link), it's very handy. 
I could imagine using it differently if I were writing a symbolic algebra package. In 99% of cases, yes, absolutely. Symbol x("x"); Symbol y("y"); Solve(y == x*x + 3*x, x);
Well, header files with a lot of template code cause a lot of re-parsing of the same code. It would be advantageous if it could be parsed once and dumped in a machine-readable, indexable format. What I'm most doubtful about is whether it would be possible to graft a module system onto the existing header system in a backward-compatible way that doesn't suck. I'm also not looking forward to a module system that does away with the separation of declaration and implementation that we have now.
&gt; Which is unnecessary work and potential source of error. No it's awesome. It lets the header double as documentation. It cleanly describes the interface, the implementation goes elsewhere. If you fuck up the function prototype, you get a linker error, so yeah it's a source of error but none that causes havoc.
Many thanks for the writeup here, I think after reading this, Microsoft should focus on continuing to improve on standards conformance right now rather than delaying since that's one of the things holding back the C++ language in my opinion. 
I didn't realize you could overload operators of primitive types. C++ fuckary will ensue...
You can't without that switch.
&gt; I remember my first ten years of C++. My God, what awful code I wrote. I remember last week and what awful code I wrote! ... And I've been writing C++ since 1991. ;-)
agreed, leave the built in operators alone, define functions for crazy unexpected behaviour.
Most of windows NT was coded in C. You can tell by the win 32 API. some of the newer stuff in 10 is most likely in c++, probably some c# for the higher level stuff. There is probably some assembly language but most in C.
It's more than likely a combination, and probably use Visual C++ for a good amount of it
You actually don't need to compile it on the target platform! My bet is that they have a dedicated machine for it
Bjarne's book had to be split in 3 separate 800-page volumes. The index is available separately as a 100-page booklet. The Modules TS is rumored to be included in C++'40. 
I agree that it could be an extra burden. However, this was meant to be an experiment to see what can go wrong. And the result? Loads. A badly designed C library (that isn't designed in an OOP style) like cnats would have some elements that cannot be ported over, unless you're willing to make your wrapper uglier than the C library itself. Example: the error callbacks are set in `natsOptions` which is passed to `natsConnection` which in turn is used to create `natsSubscription`. But the callback functions are of the form `void(natsConnection*, natsSubscription*, natsStatus)`. There's no way to wrap the error handlers in C++ because I don't have a reference to the `Connection` and `Subscription` that were created. And I certainly don't want them to be destroyed once the error handling function ends. My opinion is that if an API is well designed and your code doesn't use exceptions, then you're generally good to go without making wrappers. However, exceptions significantly complicate matters. It's better to have wrappers than memory leaks.
What are incremental builds? Builds where you only rebuild the files you updated? And why didn't they allow them?
Someone has made a torrent, https://www.reddit.com/r/learnprogramming/comments/4oljp8/calling_out_all_seeders_ive_been_uploading_a_few/.
[removed]
Actually, TCPL includes "A Tour of C++" as "Part I".
Bootloader is written in assembly, or C++/UEFI depending on which version of Windows you are using and what platform you are on.
Accelerated C++ for getting started with the language fast, and directly afterwards "A Tour of C++" for all the C++11/14 goodies. If you already know how to program working through both should cost you 2-3 afternoons (assuming you have experience with another language with deterministic memory management).
Bjarne book is the way to learn all about C++, later you maybe will need a specific book for multithreading or metaprograming, depends of what you want of C++
How often are you making lazy&lt;T&gt; objects that you don't want to evaluate with an == or != test? In the rare cases where that comes up, maybe 0.1% of the time, you could just define both operator== and operator!= youself, right? The bigger challenge is I don't know if C++ can make this change without breaking any existing code. It most likely could, but you'd want to have a large discussion around it. And given how they flipped out over the harmless UFCS change, I'd say this one's not very likely to pass the current panel.
[Scott Meyers Effective C++](https://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876) 
The type of API has little relation to the language it's written in. C-APIs are very easily written in C++. Many of the WinRT APIs are written in C++ although they are usable in C# and JavaScript as well.
&gt; Other windows teams were more locked in to visual Studio. Locked isn't really the right word but there is definite tooling designed to improve the experience of building using Visual Studio. I had tried to use Visual Studio before such tooling existed but gave up because it offered little over a good text editor with syntax highlighting since intellisense didn't work and project files didn't exist. By the time the tooling was created I already had a good thing going outside of Visual Studio and so never switched back. I knew others with similar experiences.
I have developed drivers for the storage subsystem of the Windows kernel. All C. In fact, our software had a common core that was identical between Windows and Linux.
I write "C++" code as if it's C with additional object-oriented language features, with naked pointers, malloc, and free statements.
Annoy /r/cpp in one sentence
Modern C++ is memory unsafe.
The C/C++ langage.
C/C++
I made similar arguments with the UFCS case. By definition, allowing x.f(y) =&gt; f(x,y) if the former didn't exist should not break any existing valid code. Because said code doesn't compile today. But breakage was the main point raised against it, followed second by longer compilation times (which is as simple as template metaprogramming ... pay for what you use, or don't use it.) The feature was ultimately canned, with a near-useless f(x,y) =&gt; x.f(y) proposal put in its place. I believe both UFCS and the comparison operator generation to be safe, but then I'm not a language lawyer. Just a person who has used the language daily for nearly two decades. I understand there's a world of difference between the two.
I think that talk you are looking for is this one: https://youtu.be/TRgWJuQhkQo?t=353 ?
You guys are all incompetent hacks and should instead do what Casey Muratori says and do plain C because it is obviously superior in every way.
MS developers use Unix tools to develop? C is older than C++ but it's not any lower, compared to ASM. The kernel team? Do they compile GBs of code on a specialized CPU for the retail version? Compared to Linux, Windows is modular. I used to code for the early versions of Windows ...Win95 and Win98. Windows used several systems GDI for grahics, Sys32 for kernel functions and so on. When did MS decide to make it a kernel based OS? &gt;They had an awesome debugger called kd that could freeze the target computer and seamlessly jump between kernel mode and system mode code. They also had an internal repo with tons of useful windows tools that I wish they'd release. Where on MSDN can we find more info?
Java is a much better language specially because you don't need pointer.
See Linus Torvalds's rant about C++ in the kernel to see why C++ is simply useless.
&gt; "Top 5 reasons why I avoid C++ in new projects" list This is a strange comment since the kind of projects you would consider C++ for is usually also the kind that you would could not afford to consider any other language for. Usually it's - There is no other option other than C++ for this project or C++ would be the worst option for this project. So I really can't image when this list would be useful. 
huh, cool - I didn't know that, thanks for sharing.
Clean and consistent syntax.
Not at all. I'll typically grab C, unless I think there's a very good reason to do otherwise, in which case I'll drop down to assembly, or up/over to Java, Python, AWK, or shell. C++ is in the second group, but has seldom made the cut. I keep meaning to give C++ a shot, going all in on the "modern" style. I've been keeping up with the additions, but there are only so many hours in the day and it just hasn't seemed worth the trouble.
It's hard to believe that they would still use C, one of the original languages!
For small and simple projects they are sometimes useless
C++ is computer programming language. What you would really want to ask yourself is how well you can solve real world math and engineering problems. 
This is how I started C++, and I'd recommend it to anyone else wanting a brisk overview of the language. It's only about 130 pages, then you have the rest of that giant book to refererence for more intricate details.
+1 for Accelerated C++ ... It's a small book that gives you the essentials very quickly. Great book.
Annoyed me so much that I want to downvote it. Upvoted with justice.
I've got at least one active bug and todo about overhauling our enable_shared_from_this machinery, which doesn't expect to see multiple inheritance, or anything other than the most derived type. The Standardese here is also being overhauled, which helps clarify things (it was pretty underspecified before).
I can't even imagine the mental burden of trying to to keep up with the mental state of a 1000 file project of C code. I'd wager that's not something many people who's first name doesn't rhyme with Linux can do. Abstractions are there to make coding easier to reason about. If you're writing more than 1 file or even 1 function at a time of assembly, you're doing something wrong. And if you can write something in Java, Python or AWK it would be foolish not to do so, that was my point. (except shell, I'll take any convoluted C++ mess if it would save me from writing another line of bash)
Windows is not really developed as a whole with Visual Studio... Especially not for builds.
Pretty much the inverse I think: I doubt Visual Studio has anything to do with full Windows builds, but the compiler IS MSVC. 
The alternate proposal is not useless at all. The number one problem designed to be solved by UFCS was to allow a painless way to find either a member or free function in certain situations; e.g. begin methods on containers. What was accepted solves the problem while adding less complexity to the language. The secondary problem was the "syntactic sugar for chaining" problem, wherein chained free function calls look ugly, so we'd like to allow member syntax. This is annoying, but I don't think most people find themselves chaining 3+ function calls all that often, and trading off syntactic sugar for real language complexity isn't an easy case to make. Especially when custom libraries that do encourage heavy chaining can actually solve this problem (e.g. the way ranges does with |).
This seems to be a Clang Vs GCC thing, instead of a STL issue. The test passes with both libc++ and libstdc++ so long as you use Clang. If you use GCC it fails with both.
OK so this is a compiler defect, not a standard library one. And I would guess Clang is wrong. Here is a minimal reproducer: #include &lt;iostream&gt; template &lt;int N&gt; struct Base { }; struct Der : Base&lt;1&gt;, Base&lt;2&gt; { Der() { choose_base(this); } // Clang prints "In Base&lt;2&gt;", GCC prints "No Base Selected". template &lt;int N&gt; void choose_base(const Base&lt;N&gt;*) { std::cout &lt;&lt; "In Base&lt;" &lt;&lt; N &lt;&lt; "&gt;\n"; } void choose_base(const volatile void*) { std::cout &lt;&lt; "No Base Selected\n"; } }; int main() { Der dr; } It seems really weird clang would choose the conversion to 'Base&lt;2&gt;'. since the conversion to base 'Base&lt;1&gt;' seems equally as valid, and that should probably make it ambiguous. I suspect your code is ill-formed. [util.smartptr.shared.const]/1 states: &gt; In the constructor definitions below, enables shared_from_this with p , for a pointer p of type Y*, means that if Y has an unambiguous and accessible base class that is a specialization of enable_shared_from_- this (20.10.2.5), AFAIK 'Derived' does not provides an *unambiguous* base class that is a specialization of enable_shared_from_this. EDIT: I filed a clang bug (https://llvm.org/bugs/show_bug.cgi?id=28195) 
Because every system I've ever touched using reflection was a maintenance nightmare, because it exposes implementation details of a given component to end users. For example, using automated serialization tools to write some program state to disk as a save file, only to find that now almost nothing in the program can be changed ever again because that would break the file format. The only two legitimate things I've ever seen done with it are implementing garbage collection (reflection is necessary to tell which parts of an object can point to others) or implementing automatic unit test registration (which C++ doesn't need because you can just declare a global with a constructor to do it for you). Every other case has been a crutch around designing one's program correctly.
What is `std::actual_vector` supposed to be?
Oops, yeah, my bad.
Headers are simple, but they're horribly inefficient. Try running a translation unity in a decent sized project through only the preprocessor and have a look, the result is usually many mb of text that needs to be parsed by the compiler. While some could be solved with carefully managing headers it's often not possible because most libraries doesn't supply forward declaration headers, so unless you want to pimpl everything it avalanches quickly. This is the whole reason for why unity builds are such a huge win for many projects ( although I hate them for various reasons ).
I'm confused by this remark. Can you clarify?
Derek Banas has great videos for those who already know how to program where he shows the most important features of a language in about an hour. https://www.youtube.com/watch?v=Rub-JsjMhWY
A [mathematical vector](https://en.wikipedia.org/wiki/Vector_space), so it would have all the usual operations defined.
There's nothing about *want* in the above :) That said, off the top of my head: * There are reasonably common situations where GC will be better than reference counting in terms of overall throughput (especially the thread-safe kind that `shared_ptr` gives us). * No need to worry about reference cycles (helps with implementing node-based graphs, finite automata, etc, where there are no obvious roots). * C++ has always been about choices :)
Amen
It's how you do protocols in c++. Though with protocols it should use virtual methods (for obvious reasons) 
Eh, it's because C# isn't a low level programming language, it's very high level with a lot abstracted away.
compared to C++, it's "high level" 
The compiler would intelligently select the right optimization(s) for the CPU, video card, and BIOS of the system, generating smaller executables.
TIL, after 15 years of C++, I'm no better than an apprentice (on a good day).
Not just smaller, but also objectively faster. The compiler - knowing the specific CPU in use - can select specialized instructions (e.g. AVX2) or apply knowledge about architecture peculiarities (e.g. LEA being more effective than MOV for constants) or even apply changes to instruction ordering based on knowledge of instruction execution costs and architecture pipelining behavior. An OS like Windows could take advantage of this, but not necessarily to the same degree. It depends on how abstract the code it. More assembler, more intrinsics, more fancy optimizations, and so on will obscure details from the compiler and not allow it to apply optimizations for newer/different CPU architectures.
&gt; The expression inside that statement refers to three distinct objects by name: Functions and function templates are not objects. You could also mention the unqualified lookup for the name `std` and qualified lookup for `cout` and `endl`. &gt; 3) The function `std::endl` of type `std::ostream&amp;(std::ostream&amp;)` `std::endl` is a function template. &gt; std::ostream&amp; std::operator&lt;&lt; (std::ostream&amp; out, char const*) Might as well mention that this function returns its first argument.
&gt;An OS like Windows could take advantage of this, but not necessarily to the same degree. Exactly! MS would never allow customers to send in PCs so W10 can be custom compiled like Gentoo
What an absurd answer. Very helpful.
C isn't even close to an early or original language.
You'd be surprised how much legacy code is in Windows!
You can compile Windows on a normal machine, it just takes awhile. Further, it's not necessary to have the entire set of source code in most circumstances, instead you typically have the source for only the components you work on and when you build you probably only build the few binaries you're working on rather than everything. There are machines dedicated to building the entire OS but they aren't super special. Mostly they have a good hard drive and a good amount of RAM.
C and C++ were designed when Unix was popular but that doesn't mean they were designed for Unix. They are both general purpose languages. C# is difficult to use in an operating system because it requires the .Net framework. Until version 4 the framework did not support loading multiple versions of itself into the same process but a lot of code from Windows is loaded into every running program (think about the code to create graphics, for example). Further Explorer will often load other applications' code into your process to handle various tasks like special context menus or special folders. In this world it is impossible to know or control what is in the process you're entering and so this is not an environment for .Net.
Windows is an NMake shop which certainly supports incremental builds. If that was broken it was a particularity of their specific scripts on top of it.
In practice such optimizations are in "the noise" for most software. Most compilers are pretty bad at generating SIMD instructions as proving that such an optimization is safe is nontrivial.
Could you point me at an example of how this paradigm is used for protocols in the wild?
I work in Windows Core. We use a variety of languages and tools. And, as others pointed out - there's a lot of different bits that make up what most of us think of as "Windows". So, disclaimer, not everything I'm saying will be 100% true across the board, but I'll mention some representative cases for what I've encountered when working with various teams. If I'm being vague in a section, it's because I'm trying to only mention things that are already publicly known. Kernel proper - This is mostly written in C. Things like the memory manager, object manager, etc. are mostly written in C. The boot loaders are written in ASM, but set up a C environment rather quickly. Drivers - that said, a lot of newer kernel mode drivers are actually written in C++ (however, its style is more akin to "C with classes". Lower level code has been much slower to adopting anything past C++98) User land - Mostly C++ with varying levels of quality and version compliance. If it's a pre-Windows 8.0 component, it was written against mostly C++98. More recent features are C++14 and better. There's actually a real push happening internally to start adopting modern C++ practices, and actually using the STL. (In core, at least, there's still a distrust of the STL and exceptions due to poor implementations years ago. Unfortunately beliefs like this are hard to shake.) [Again, not 100% representative, only what I've encountered] We also use some internal libraries that follow modern C++ programming practice and provide nice RAII wrappers for a lot of the Win32 data structures and allocation patterns. Shell code (newer code like Cortana, the new start menu, and the WinRT APIs) are ahead of the curve in terms of implementation practices and C++14/17 usage. (I, for example, have recently investigated how co_await could simplify my product's code). The inbox universal apps are written in C++ and C# and target the actual public WinRT API surface (to the best of my knowledge). We really do try to eat our own dogfood, and that goes for writing apps against public APIs too. We do use a variant of the Visual C++ compiler (I say variant, but it might actually be the public version - perhaps just a slightly different version/build). It's usually one release behind the shipped Visual Studio version, just due to release cycles not aligning and to minimize the disruption of changing compiler versions mid-release. Compiling Windows is no small feat. We used to be able to compile a Windows image on our dev machine years ago, but in the last few years it's just not that feasible. We have some pretty beefy build servers. I don't have specs, but we're talking like 32 core, 512 gb ram, striped SSDs, etc. And yes, the build machines run Windows :-) Comparing build requirements to say, Linux kernel, isn't a fair comparison since "Windows" includes drivers, usermode, shells, and components used by any of the flavors of Windows (desktop, server, phone, xbox, etc.). It'd be more like doing a low-level, fully optimized build of a Gentoo image that includes an X Server, KDE/Gnome, dev tools, in-box apps, etc. etc. Hope that helps your understanding :-)
Here is a simple example to see how it works // There is sometimes something like this with just the destructer class ProtocolBase { virtual ~VirtualBase(){}; }; class OpenProtocol : public virtual ProtocolBase { public: // in this case we must open virtual void open()=0; }; class UpdateProtocol : public virtual ProtocolBase { public: // in this case the update might do nothing so we give default // implementation to do nothing. virtual void updateViaNetwork(){}; virtual void updateViaCache(){}; }; class MyWidget : public WidgetBase, public OpenProtocol, public UpdateProtocol { // classy stuff and etc. ... public: // implements it or something void open() override; }; // somewhere in network code startThread([&amp;] { showLoader(); std::shared_ptr&lt;UpdateProtocol&gt; update = dynamic_pointer_cast&lt;UpdateProtocol&gt;(widget); // dynamic cast may return nullptr which means the widget doesn't support // this protocol. Ideally you would have filtered it out before starting // this thread if(update){ update-&gt;updateViaNetwork(); } hideLoader(); }); // somewhere when widget gets double clicked. e.g. it could be something that // looks like a file and user double clicked it. std::shared_ptr&lt;OpenProtocol&gt; fileWidget = dynamic_pointer_cast&lt;OpenProtocol&gt;(widget); if(fileWidget){ fileWidget-&gt;open(); } else { // maybe give popup or something I don't know. } This is the equivalent to Javas `interface` or Objective-C's `@protocol` use-cases. You can search interface/protocol c++ for examples.
Cool, I'm enlightened!
Every time I think about the deep technology stacks we build, I'm amazed our computers, gadgets and servers are working at all.
... or just a novice.
BTW, A while ago I was teaching some high school kids assembly and ended up writing a small graphic library for their use. might interest you - https://github.com/shooshx/libDRD
If you're looking for a tour of C++11/14 features, you might want to take a look at "Discovering Modern C++" book. This book doesn't go quite deep into details but it does provide a good coverage of important modern C++ language and library features.
&gt; But I sometimes get really sad when I step back from my code and I seed how complex are the zero-cost abstraction I just wrote Can you give some examples? &gt; writing efficient C++ is still hard science I think it's more of a craft than a science, but that's not very important I guess. &gt; Is complexity justified ? Does fast-running codes has to be complex ? Or is this complexity just a heritage of old standards and backward compatibility ? No. This complexity is neither required, nor justified, _in all cases_. In most applications, you do not need super-fast efficient code, you just need code that is "reasonably fast". If you need to sort a list of up to ten file names (for example), you will not need super fast code and zero cost abstractions. If on the other hand you _need_ super-fast, then the language allows you to implement it. &gt; Is complexity justified ? For some projects, it is (in domains like scripting engines, graphics, high-throughput data processing ...). &gt; Does fast-running codes has to be complex ? No. If it _always_ ends up being so, you have a design problem. That said, there are sometimes design compromises made for speed. &gt; Or is this complexity just a heritage of old standards and backward compatibility ? I guess it's a bit of both. There have been newer languages that attempted to hide the complexity of C++ while offering similar speed, but with few exceptions, making things simpler requires moving the complexity somewhere else, or solving the problems that appear, through efficiency compromises. &gt; Does it exist already ? Are people/companies working on something similar ? I've heard such claims about Go and Rust (but haven't used either for long enough to figure out if it's true or not).
I think you are searching for something like D (dlang). It has all features modern c++ features bring but in a cleaner form. The compiler is also way faster and it can interface well with C. One feature i really like is the definition of unit test as first class language feature.
Some historical, some not. It's always a balancing act &amp; some of this is a natural consequence of design-by-committe. Every member drags it in every direction &amp; rather than setting out a vision and executing on it. Several languages are attempting to be the next C++: rust &amp; swift are examples of trying to start from scratch (swift was started by a lot of C++/ex-C++ people). D markets itself as such, but it's unclear that it's really seeing the same adoption/popularity as other languages. Meta-programming in C++ is particularly painful &amp; this is a known issue. Static-if, or whatever form it takes, should help reduce this. Conversely, concepts are likely to make it more complex, at least in the short term. In other words, simpler constructs for common problems are being designed while at the same time new complex constructs are being designed.
:)
I'm pretty sure Bjarne was quite explicit about maintaining backwards compatibility and not breaking things in future versions of C++. What I'm hoping to see is more aggressive deprecations in the language. Keep the old cruft there, deprecate it, and make the compiler bitch and moan about old code until you do something about it. 
&gt; "Windows" includes drivers Linux also includes drivers.
I'm just going to touch on just one point, as it's difficult to have a discussion about so many questions. The C++ standards committee works very, very hard to make sure that they minimize any adverse effect new standards have on old, standard-compliant code. They even try to protect a lot of non-standard-compliant code. This is essential to the adoption and use of new standards. C++ is one of the most popular languages in the world. There are an insane amount of highly complex, very large codebases written in C++, some of which are mission critical for people's lives, companies staying in business, and such. Many billions of dollars are at stake here. Do you really think all these codebases would move to a new standard if it broke over 30 years of existing code? No. Absolutely not. It would grind C++ language progress to a halt, fracture the language, and cause chaos. If you want a language that's *like* C++, but doesn't have 30 years of backwards compatibility plus C compatibility anchored to it, why not just use a different language? There are plenty of choices, including, but not limited to: * D - Trying to be just the modern parts of C++ * Go - A new systems programming language from Google * Rust - A language which lives in the same realm as C, but attempts to provide more safety without incurring a runtime cost Or maybe you just want a more modern language, like: * Java * C# * Swift I hope I've made my point. If you're going to use C++, well you get the 30 years of baggage that C++ has, and that's not going to change. However, this can also be an advantage, in that you know that code you write now will still work 30 years from now in C++46. There's also an incredibly rich set of libraries, documentation, example code, best practices, and books for all skill levels. Finally, it's a very common language for programmers to know, making it easier to find other collaborators for your projects.
_entity_. [§3\[basic\]/4](http://www.eel.is/c++draft/basic#4): A _name_ is [...] that denotes an entity or label (6.6.4, 6.1).
I think this works, but negates the effects of the namespace. This means that you can call a function inside the c_api without having to specify the namespace.
The problem is that it is no other ways in C++... 
I have a stupid self-centered way of judging reflection proposals Can I serialize an enum value to a string representation of its name ? I think it's a fundamental feature that is sadly not considered very often. 
Isn't this the same? But who has time for philosophy...
+1 for _Stroustrup's "The C++ Programming Language"_. It not only provides a good foundation into language constructs, but also (many times) the design and criteria that were behind that.
https://xkcd.com/676/
[Image](http://imgs.xkcd.com/comics/abstraction.png) [Mobile](https://m.xkcd.com/676/) **Title:** Abstraction **Title-text:** If I'm such a god, why isn't Maru \*my\* cat? [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/676#Explanation) **Stats:** This comic has been referenced 94 times, representing 0.0815% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d4gjwr2)
Well, if Bjarne Stroustrup rates himself as 7/10, you seem to be well ahead of the curve. :)
Not enough detailed for me, missing the explanation of what happens at logic gate level in a x86 or x86_64(or both) processor. Next one please.
If you want something better than C++ templates, then I think Go is not the language to use. It doesn't even have generic collections, AFAIK.
If you removed the undefined behavior and some of the more weird legacy stuff would you basically end up with D?
What's wrong with it? There is a reason behind every single character in those two lines.
Well, C++ programming jobs tend to pay so much more than other prgramming jobs that banks are moving to Java to save on personnel costs. I would say that's a good indicator of the difference in the jobs/programmers ratio of C++ and Java.
&gt; these three classes So you've never heard of `std::ostream_iterator` or `std::ostreambuf_iterator`? 
Your findings seem to mirror what I have researched on this subject. I believe, at the core of your issue, `iterator_type::value_type` serves to show what type would be ***read*** from such an iterator. You probably want 3 *very small* functions that forward to a common insertion function.
The STL is able to implement all of its algorithms without caring where an output iterator's output is sent to. Why does your code care?
At the device driver level, it bears a rather stronger resemblance to VMS than to UNIX.
I don't care where the output is sent to. I do care what the type of the output is.
Using `std::endl` in hello world only shows that you don't understand why this is a case of premature pessimization.
OutputIterators are kind of weird compared to the other iterators. For example, you cannot compare them to another iterator. They are really just a wrapper for output wrapped up in iterator syntax. With regards to value_type, value_type is more of a reference to the type you can get from an iterator and thus since you can't get any type from an OutputIterator, value_type being void makes sense. From a practical matter, most of the algorithms I have come across that work with output iterators are able to deduce the types needed from the input iterators. When you are not able to do that, it might be because you are mixing transformation with output and you would be better served separating those 2 concerns.
&gt; it might be because you are mixing transformation with output Hmm, that sounds exactly like what I am doing. I actually expect the input and output iterators to refer to different types. What would you suggest instead?
I would think about using something like a transform iterator. See the boost implementation here. http://www.boost.org/doc/libs/1_61_0/libs/iterator/doc/transform_iterator.html Then the transform iterator does the transformation, and you just have to std::copy the transform iterator to the output iterator. 
Except for garbage collection (yes, you can turn it off but at the expense of not using the standard library and any other library that you may find) - that's where D screwed up.
I'm a bit confused - my problem is that I am designing a generic algorithm to convert from one data type to another with iterators. You're telling me I have to tell users not to use standard library output iterators? Or how would I wrap the output iterators they give me and how would it solve my problem with knowing the value type?
For now, if I understood the videos from their recent conference the D folks hope to have the Garbage collector out or optional for the language soon. But that soon is a very uncertain soon. :)
No, compile-time code doesn't have to be complex. Thankfully, in C++14, you can have pretty fancy constexpr functions - this takes care of quite a few things that had to be previously done with template metaprogramming. If course it still allows no I/O, and we've had that in LISP macros since the day LISP macros became available. A LISP macro can do issue HTTP requests if you so desire.
With `std::transform` there is a one-to-one mapping from input to output, but in my transformation one input value could correlate to any number of output values. I'm getting the impression that standard library iterators aren't really designed for this kind of transformation.
Both of those things must be the same. If they differed, it would corrupt the data.
It's easier to write correctly in Rust than in C++ or Go, because the Rust compiler will tell you where you err. Correctness is usually undervalued, and people usually treat the compiler as an obstacle instead of a tool, resulting in frustration that "the damn compiler refuses to take my code" (although, to their defense, error messages can be quite subtle sometimes). Rust offers both low-level access (if you want to do everything by yourself) and higher-level ones. For example, if multiple threads need not access the *same* pixels, but can each work on part of the buffer, then Rust's slice type has the `split_at_mut` function to split the slice in two independent slices, allowing two threads to access a part each without synchronization.
[There's this famous XKCD comic](https://xkcd.com/927/) I think the best solution is to rig things like Lint to be like Microsoft's Clippy: "I see you are using ________. ________ has been created and you can use it!"
Indeed. There's a huge wealth of old software out there. If you ever been in the Enterprise, "if it ain't broke, don't fix it!" gets taken to the levels of "don't reinvent the wheel" in Node
Why isn't it possible (or desirable?) to build an automatic translator between the latest version of C++ and a new, non-backward compatible language, derived from C++? This language could basically be C++, but purged of all of its mistakes. Such a language could build upon C++'s legacy and philosophy. It would also need to be at least as expressive as existing C++. It would effectively be backward compatible because old code could be automatically translated to the new language. I seem to remember Bjarne Stroustrup mentioning the possibility of using clang's tools to do automatic code rewrites in the future to assist deprecation; although I don't know if he had this kind of thing in mind.
Most of the complexity of templates is due to their *accidental* properties. Basically, the templates in C++ are somewhat dynamically typed: you get an error somewhere deep in the instantiation stack when something goes wrong. The answer should be the *Concepts* proposal, but we are not there yet. You can look at Rust for what it's like to state constraints on generic type *upfront*. It makes declarations more verbose, but: - avoids the need for SFINAE - makes error messages simpler which is quite interesting for the user, I would say. As for fast-running code having to be complex... the problem is that C++ is not made to be that fast: - defaulting to copies (not moves) - no tracking of aliases really hamper the compiler's ability to efficiently transform the code, and require the programmer to step in and either nudge the compiler in the right direction (`restrict`?) or just take over completely and write the optimized (and low-level) code. Luckily, though, normally only small portions of the program are bottlenecks.
That would make sense (considering Dave Cutler) but I never used / studied VMS so cannot comment on that. I just meant that it is far more Unix-like than the Win32 API would suggest. (e.g. Ob is pretty "everything is a file"-like, but this isn't exposed at the Win32 level)
Don't know if I'm not understanding what you want to do but I can't see how you would be able to corrupt data from mismatched types while using an output iterator. If your operation and the output_iterator stored type are incompatible your program won't compile, and if they are compatible that's because the person who designed them desired so.
W10 was not developed from scratch. It's just a further iteration of the NT core.
Out would be great, optional means fragmentation of D libraries (nobody is going to rewrite their library twice - one for and one without garbage collection).
As someone else mentioned, a transformation from UTF-32 to UTF-8 is a good example. It wouldn't make sense to store the output in anything larger than a `std::int8_t`, because although a widening conversion doesn't change the value, it changes the meaning.
Huh? I'm talking about my own function, not any standard library function. If I say my function requires them to be the same and not just convertible, then that's how it is.
Yeah, I wonder about backwards compatibility, because one of the ways I've seen it proposed done is to make the use of Allocators mandatory and enforced by the Dlang runtime. I am not knowledgeable what the proposal entails because I only saw it as a statement in a speech.
Duh.. many things that you wrote seem to be taken directly from a O'Reilly 'best design patterns' book. E.g. &gt; If it always ends up being so, you have a design problem Have you ever worked on a large project? 
I'm talking about how the output iterators are used.
I misunderstood and thought you were asking about my specific case.
I feel like Go is a language for people who don't want to invest time improving in programming. Go has very few concepts. Go will never add some concept that makes the language harder to learn even if this new concept improves security, performance, maintainability... http://tmikov.blogspot.com.br/2015/02/you-dont-like-googles-go-because-you.html Rust template/metaprogramming abilities aren't close to what C++ provide. About syntax, C is worse. Go goes on the opposite direction (the same as Rust): https://blog.golang.org/gos-declaration-syntax
Thanks! Unfortunately from the discussion here it seems controversial as to whether iterators should even be used in my case at all, so I'll probably just end up not using iterators at all to save the trouble :(
perhaps you want to iterate over an input range contain arguments from which you want to construct into an output range. E.g. a hypothetical `template&lt;class InputIt, class OutputIt&gt; emplace(InputIt first, InputIt last, OutputIt dst)` algorithm that calls `*dst++ = T(*first++);` in its main loop. Would be nice if one could then write `using T = typename std::iterator_traits&lt;OutputIt&gt;::value_type` in case `OutputIt` was a `back_insert_iterator` e.g.
Yes, clearly the only possible explanation why I would use `std::endl` is that I have no idea what it does. Thanks for enlightening me! 
&gt; In the docs, it seems that sharing a buffer between threads in not simple in RUST I would say sharing things *correctly* between threads tends to be simpler in Rust than in C++. It's hard to screw this up unless you write your own unsafe code. Keep in mind that write access always requires a form of exclusivity or atomicity (even in single-threaded Rust). But that doesn't mean only one thread can write into a buffer. It's possible to divide it into smaller non-overlapping pieces and have each thread work on its own piece exclusively. In case you decide to try Rust for this, you will be eventually looking for a "scoped thread" implementation such as [this one](https://crates.io/crates/scoped_threadpool). And a [library](https://crates.io/crates/ndarray) that supports 2-dimensional arrays and/or 2-dimensional [subviews](https://bluss.github.io/rust-ndarray/master/ndarray/type.ArrayViewMut.html) of such arrays might come in handy as well for partitioning the image into non-overlapping mutable views. You could also write your own unsafe code if the `split_at_mut` method on slices doesn't cut it for you and you don't like this `ndarray` library. If you go ahead and write unsafe code, please try to isolate it behind a safe interface and ask for some help
Now I see it, if you want to select the algorithm by the output_iterator::value_type than I agree, it's an unfortunate trade off made while designing iterators, but I still think that part of the problem is not on iterators but on poor choice of types to represent the values. Built-in types are too generic and don't enforce the semantics you want. If you cannot change the type of the inputs, I would suggest something like [this snippet](https://ideone.com/sFVaU6) to at least narrow down which conversions are allowed on the result of your operation. In this example I completely disabled conversions but you could use enable_if and SFINAE to better select which ones are allowed on your case.
If any compiler adds in warnings telling me to use that "smart pointer" *shit* I'll turn them off straight away and never look back.
To be fair, Python is a very dynamic language. Automated conversion (2to3) is likely made difficult because of that. C++ is statically-typed and has that going for it. But it also has macros. So, I'm not really sure whether C++ is better suited for automated modernization tools. At least we have [clang-tidy -fix](http://clang.llvm.org/extra/clang-tidy/index.html).
X-Post referenced from /r/node by /u/freezer333 [C++ and Node Integration - ebook](https://www.reddit.com/r/node/comments/4oypfq/c_and_node_integration_ebook/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
that's a slight overreaction, but I agree, *if* they do it and enable it by default. they won't though, a lot of c code doesn't and can't use the standard library.
Care to give any reasons why you don't like them? I'm of the opinion that in C++14, the word "new" should not appear in your code. In C++11, it should appear exactly once, when providing a definition of `make_unique`.
So you're suggesting that, compile- and run-time efficiency not concerns, there is _never_ a valid reason to use `std::bind`?
Jesus christ, mixing c++ and JS (node no less) is like mixing pizza and ketchup.
Like `std::valarray`?
Maybe [D language](https://dlang.org/) is what you are looking for. Its design goal was to allow similar power and efficiency as C and C++, but with improved syntax due to not having to offer backwards compatibility with those languages. 
Conclusion: Don't go to wikipedia or cplusplus.com for your C++ information. The latter site obviously puts a lot of resource into boosting itself to #1 on any google search result. If only they put that much resource into their content. 
Still useful to understand `typedef` though, in case you read someone else's code, or do some C programming. 
They can be a bit clunky though , I find `static` simpler for the occasional internal-linkage function. It's more obvious when reading the code seeing it right there in the definition, as opposed to being in an unnamed namespace that might start and end "offscreen" from where you are in the editor. I guess others feel the same way, as this use of `static` was deprecated in C++11, but is un-deprecated for C++14. 
&gt; Well, the storage is global ITYM the storage has static duration. This sub-thread shows more about problems with multiple meanings for "global" ! 
As I said, rapidjson supports in-situ (destructive) parsing: http://rapidjson.org/classrapidjson_1_1_generic_document.html#a7ba626bf84eb45a9bca0b7723bf47f3f If there are allocations (which I have not tested myself since I use nlohmann/json) then only a few.
It's 2016 and you're using this macro all over the place for manual memory management of raw, owning pointers. This is inexcusable.
Here is what I saw * Android: C++-&gt;JNI-&gt;Java-&gt;WebView * iOS: C++-&gt;Objective-C++-&gt;Objective-C?-&gt;WebView * Windows: C++-&gt;WebView
Neither of those were a reason not to use smart pointers.
Thanks for the explanation. I definitely have to give a try at Rust then, at least to see if a simple image filter runs as fast as in C++. 
Not disputing you - just genuinely curious, but doesn't a shared pointer have the extra overhead of 1 CAS to keep track of the number of pointers? So if you were creating some kind of parallel data structure that was being used billions of times a second, couldn't that 1 extra CAS potentially be a not-insignificant overhead compared to knowing exactly when it's safe to delete? Edit: Aaaand, here's a paper on the issues of not being able to do atomic stuff with unique and shared pointers by our good friend Herb Sutter https://isocpp.org/files/papers/N4058.pdf It's really not fair to say that anything should "never" be used - there are certain cases where it's necessary to use a raw atomic pointer instead of a unique_ptr or a shared_ptr. I don't think we're going to be seeing any warnings for raw "new"s while these still exist
\#define exforward(x) std::forward&lt;decltype(x)&gt;(x)
You can only use auto as a parameter type in a C++14 generic lambda. I don't see how this will even compile, aside from the fact that it's not forwarding properly. To write the function properly you need to do it like so: template &lt;typename T&gt; auto foo(T &amp;&amp;x) { return bar(std::forward&lt;T&gt;(x)); } `T &amp;&amp;` is special when T is a template type parameter. It's a universal reference, as dubbed by Scott Meyers. It will bind to any type, not just an rvalue reference. `auto &amp;&amp;x` does not do that, so it can't be used for perfect forwarding.
Well, I'm going to use this (or even #define forward(x)), although I'd love to get rid of C preprocessor. 
I studied it a bit and it seems it does not allocate, however it changes the input string. 
GCC enables some extensions by default, e.g. zero-sized array, variable length array, function with parameter type 'auto'. It won't warn you unless you compile with -pedantic.
It seems that to forward `x`, both `decltype(x)` and plain `x` are required, so I guess the shortest form without macro that does the job (in this case) is `(decltype(x))x`. 
&gt; because it exposes implementation details of a given component to end users. And drivers can run over people, should we ban cars? &gt; For example, using automated serialization tools to write some program state to disk as a save file, only to find that now almost nothing in the program can be changed ever again because that would break the file format. Fun thing is I haven seen this hand rolled. Not using reflection certainly did not stop things from breaking when a field was forgotten and added later. It just made the code a lot uglier. &gt; The only two legitimate things ... Or you know a simple script interface, meta data similar to Java annotations, also access to implementation details is nice if you want to print information for debugging. &gt; Every other case has been a crutch around designing one's program correctly. The perfect programmer may throw the first stone. 
A `shared_ptr` does need the extra space for the reference count, yes. A `unique_ptr` does not, since it can only ever have a single owner. I was hoping to convince /u/xGeovanni that there isn't an inherent difference in speed when using a smart pointer, and `unique_ptr` is the simplest case of that. Thank you for the PDF. I had been unaware that atomic smart pointers could not currently exist, and I hope that the proposal goes through so that they can.
[`Task::run`](https://github.com/mhogomchungu/tasks/blob/155f885f59979595c820f8ae2287d6f1142a5d1e/task.h#L280) only accepts function objects of type `std::function&lt;...&gt;`. It's natural that this does not work well with other kind of function objects. `std::bind` on its own does not have this issue.
&gt; I really like the C++ language [...]. :-]]] &gt; I'm curious as to what else I need to learn before I could get a job as Software Developer that works primarily with C++. I see two questions here: what you need to understand/master to get a job as a SD and how to specilize in C++. For being a SD, here's a list based on the authority of what goes through my head: - understand and study algorithms (should be covered by CS courses you already take) - get some concepts/inclining of project management: choose some personal projects, define your goals, set some personal deadlines, then try to respect them (it is unlikely you will meet whatever deadlines you set, but it will help you understand the problems coming with estimations and trying to get things done). - get some Tool-Fu: install/work with an issue tracking system, git and/or mercurial, and CMake / makefiles. Although you may be able to do everything though Visual Studio (if that is what you use), learning what the build process does behind the curtains is very useful. - learn to debug and write unit tests; you will probably need both. For being a C++ developer: - write code, then ask people to review it (in practice, code review is by far the best way to limit errors in design and implementation; there are other methods, like working with a checklist, but they don't come close); once reviewed, write some more code and repeat. - consider learning and writing some code in a higher level language, for short periods; this will help you understand where C++ is, compared to other languages and it will improve your overall coding Fu; I became a much better C++ designer after writing Python for a while. - when you start looking for jobs, don't "be married" to C++, simply apply to more offers for C++ than you do otherwise; in time, as you accumulate experience, your CV will become more and more attractive for C++ positions. &gt; Also, if you feel extra helpful, perhaps you could guide me to where I can go to learn those things (but that is optional). For implementation details while coding, Scott Meyers' books are good. So is "The C++ Language" by Stroustroup. For design, check out the lectures of Alexander Stepanov (available on youtube). For project management read about waterfall, agile and TDD.
Antlr is the tool which made Jetbrains famous. They use it to develop various programming languages IDEs (IntelliJ, Clion and so on). Oracle also uses it for their NetBeans IDE.
std::function&lt;....&gt; accepts any [callable object](http://en.cppreference.com/w/cpp/concept/Callable) and hence Task::run also accepts any callable object. I think the problem is with "auto" keyword creating an object of a wrong type and this confuses std::bind(). For example,what is the type of foo: &gt;&gt; auto foo = []( int r ){ return r + 1 ; } ; If you were to specify the type,you would say: &gt;&gt; std::function&lt;int(int)&gt; But with auto,gcc atleast autosets the type to: &gt;&gt; example::run()::&lt;lambda(int)&gt; The return type is missing and std::bind get confused and returns an object of a different type resulting in the following error: &gt;&gt; In file included from ../../projects/tasks/example.cpp:31:0: ../../projects/tasks/task.h:322:4: note: template&lt;class T, class ... Args&gt; T Task::await(std::function&lt;_Res(_ArgTypes ...)&gt;, Args ...) T await( std::function&lt; T( Args ... ) &gt; function,Args ... args ) &gt;&gt; ../../projects/tasks/task.h:322:4: note: template argument deduction/substitution failed: ../../projects/tasks/example.cpp:90:24: note: ‘example::run()::&lt;lambda(int)&gt;’ is not derived from ‘std::function&lt;int(_ArgTypes ...)&gt;’ Task::await&lt;int&gt;( foo ) ; Task::run() expects std::function&lt;int(blablabla)&gt; but it gets std::function&lt;_Res(blablabla)&gt; returned by std::bind() and type deduction fail because it cant match "_Res" with "int". Without knowing anything,this is the explanation i have come up with.
I am talking about the return type of the callable object and saying that "auto" keyword produces a "a unique, unnamed non-union class type" that has no return type information or has it in a way that causes std::bind() to return a callable object with a return type that does not match what Task::run() expects. I will be very grateful if you can improve the library to make it accept callable objects that takes arguments without casting because i have tried and tried and failed each and every time. The library works just fine with any callable object that does not take arguments because std::bind() is not involved and this leads me to think the problem is with std::bind(). I added support for callable objects that takes arguments because somebody asked for them. 
If I don't know the value type I cannot generate the output. I don't even have any input iterators to work with, only an input value and an output iterator. As I said it wouldn't make sense for there to be separate template parameters for the output type and output iterator.
Looking at his website and linkedin he seems to be an experienced C++ developer. Personally my first language is C++, but I also really like Node. So I'd say you are right, you might be getting old :)
&gt; Would it be possible for you to explicitly state what exactly are you trying / want to do or reduce it to a small example that has all the key ingredients? Someone gave a good example: conversion from UTF-32 to UTF-8. I am doing something similar: conversion between larger and smaller types that preserve the encoded value. However I'm doing it in a generic sense and working with anything that is an integral and, for the case of the larger type, anything which implements the correct operators. By definition the input and output types have to differ, otherwise it's a no-op. I have to know what both types are for the conversion to even be possible. &gt; but it doesn't work for std::vector&lt;bool&gt;::iterator, zip iterators, and any other proxy iterator either. I don't need to work with booleans, and why can't proxy iterators tell me what type they want? It doesn't make sense to have all iterators bend to the will of a few special cases. &gt; You seem to be assuming that OutputIterators are readable, but they are not. No, I never made any such assumption. The assumption I made was that there was no need to lie about the value type when the answer was known. Just because _some_ output iterators can't define a single value type does not mean all have to suffer. &gt; or make OutputIterator return something with a templated operator= that can handle all those types The issue is that one input value does not always correspond to exactly one output value. A single input could result in anywhere from 1 to 100+ output values.
&gt; *OutputIterator = *Iterator It can be valid, but not suitable. For example a copy algorithm from range of floats into range of ints will just truncate values. Or algorithm to generate some sound samples, it calculates samples as floats: template&lt;typename t_out&gt; void generate_sound( t_out out ) { for( ... ) *out++ = some_math_with_floats; } But what if a user need sound samples as normalized 16-bit ints? So generate_sound author may decide to make specializations to make it easier to use (otherwise a user will need to pass a transform_iterator and perform this float to int16_norm conversion by himself). But such specializations can only work if we can extract destination type from t_out iterator.
Not practically free, absolutely free. The only thing cheaper than unique_ptr is leaking the resources and not doing the cleanup. (Though that becomes expensive over time.)
&gt; Not practically free, absolutely free. Yes, assuming function/operator calls to `unique_ptr` is "free". Any self respecting compiler would inline them, but that is not mandated by the library implementation. Anyway, these kind of pedantic overheads (if any) are not even worth worrying about.
Wouldn't you need a value type in [my example](https://www.reddit.com/r/cpp/comments/4oyu61/insert_iterator_i_cannot_believe_what_i_am_seeing/d4h3ptg)?
Can I use to build a SVG ? What are you using Boost for ? XML parsing and blas ?
Creating SVG is actually pretty straighforward task. Simple XML writer should be enought. But creating conforming reader is very complex task. Boost.MPL and Boost.Spirit are widely used core dependencies of SVG++, some other Boost libs are used sometimes as utility libraries and for portability.
&gt; It's a universal reference, as dubbed by Scott Meyers. C++17 now formally/officially names these "forwarding references" ([temp.deduct.call]/3). The background and rationale on the chosen nomenclature is [here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4164.pdf).
I believe that would have to be `(decltype(x)&amp;&amp;)x`.
&gt; Do you think the two books are good one, or do you have better recommendations? From the sidebar: "*There is a useful list of books on [Stack Overflow](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list).*"
Thanks. How are the two OReilly's books in 2003 compared to the books in the StackOverflow post? Are they good enough and comparable to be added there?
I have been reading OReilly's books in programming such as xxx in a Nutshell and Programming xxx. Does it mean that I have been misled?
That's what I thought, but the suggestion of using a source code modernizer gave me the impression that bind was considered bad practice.
Which was written in C which was written in B which was written in BCPL which was written in CPL which was written in ALGOL 60 which was written in ALGOL 58 which was written in fortran So it's really all fortran.
It may be better to think of it like this: whatever reasons there may have been to use `std::bind`, they are **no longer** valid due to the introduction of generic lambdas. `std::bind` may have had legitimate use cases before C++14 or even C++11, but a generic lambdas is now capable of accomplishing everything `std::bind` is able to with better performance, readability, and ease of use. Why use flint and steel when you have a lighter on hand?
Because of the annoying repetition in `std::forward&lt;decltype(x)&gt;(x)`.
Yes it's hard.
If compile time and memory consumption is a problem, did you consider switching to Spirit X3? Update: I see, it is already in a to do list.
The biggest issue with those two books is their age. They will have zero information about C++11/14/17. 
Why develop header only if you're going to always require boost?
There are a bunch of books on the topic. Even the older ones could give you a good idea of required features and architecture. Search "Game Engine" on amazon. **However**, everyone agrees it's a very, very bad idea to write a game engine in order to write a game. There are a lot of essays out there on the web about how doing the game engine totally gets in the way of doing the game. I mean, well-funded companies have pulled it off, but that doesn't apply to you. And some of those have failed, too. The best advice out there is to simply choose an existing well-known game engine, and focus on using it for your game.
SVG++ library is SVG "reader", it helps to correctly read SVG information, how you'll handle this information is up to you. SVG++ is not an SVG viewer. For task like yours you'll probably need to cut out SVG handling code from some browser.
Sorry, I missed your point. SVG++ is template-heavy library and at the moment the only option for C++ is to include templates in headers. All used Boost libraries are also header-only. Why not?
It really goes from "somewhat advanced" to "fulltime job for many years", depending on what you need :) If you want to build a full fledged AAA renderer/engine like, I don't know, Unreal, that's just absolutely impossible for a single person. However, if you have a very specific game in mind and it has simple tech requirements, it's absolutely possible to write your own engine as you go. The trick really is to not to give in to the "oh this would be a very cool feature" and keep it very, very basic :) source: I wrote a couple of GL renderers used in released games, and they were maybe 5000 lines of code. A better question would be perhaps if it's a good use of your time, and that depends on you really. If you want to learn how a game works it's a great exercise, if you just want to ship one, not so much... although there are some games that are easier to make with a custom engine.
The phrase "OpenGL game engine" is utterly meaningless. Are you asking a game engine for Tetris? A game engine for Battlefield 4? A game engine for Final Fantasy 5? You mention "pixel perfect" and "tiles" so I'm going to assume you mean 2D, but there's still a very huge range of 2D game techniques. What is the relevance of OpenGL? A _game engine_ is much much larger and more complex than a _graphics engine_. Most of the complexities of a graphics engine also have nothing to do with the API. What are the real features you need? Graphics is your focus, apparently, but what about everything else? What input methods do you need? Which systems are you releasing on? What are your audio needs? What kind of level editor are you going to use? Which tool or language is game logic going to be developed in? Even for graphics, how is that data going to be authored (textures, sprite sheets, animations, etc.) ? What are your AI needs? Do you have an idea of how you want to structure your engine, game objects, module communication, etc.? The actual answer to your question is that - if you were already experienced in making games from scratch - a new team-ready game engine is probably going to take your full-time effort for a few months, and then getting that engine up to production grade and keeping up with the design and art requirements is going to require continued full-time development for likely a year or two. It's a fool's errand. Just use Unity, or GameMaker, or Godot, or Torque2D, or one of the bazillion other ready-made options. The only good reason to build from scratch is if you're (a) trying to learn and don't care about your teammates' productivity or the final product at all, or (b) your game is super weird and special and all the existing engines literally can't even.
Every job has its frustrations. Software frustrations are just special.
UE4, Unity and other engines are product of multiple years of research, patents, shader algorithms, lightning research, etc... If you only need to render some 90s style fixed pipeline scene then it only requires like 300 lines of code. If you need a metal shader, Crysis lighting, etc it suddenly becomes a whole different story. People literally spend all their life researching lighting shaders and metal shaders and such which end up as simple materials you can pick with a mouse click in Unreal Engine 4 or whatever. So yeah - everywhere from 300 lines of code with basic linear algebra or 40 years of beard growing and hair loss.
But **why** are you using boost? It would be awesome if we could have a just C++ version.
If you know what you're doing, you can get .obj files on the screen, shaders, etc without too much struggle, just a lot of tedium. If you're new to it all and you're trying to stumble through it all, have kleenex handy because you're going to burst into tears at least a couple times.
[Here's](https://www.youtube.com/playlist?list=PLRwVmtr-pp04XomGtm-abzb-2M1xszjFx) about 200 videos, each 10-20 minutes long about that exact topic. Enough to get started for sure.
I did not run performance tests on all of them. Some of them disqualified themselves early. The one's that fell over were POCO, Simple Web Server, and RipcordSoftware's libhttpserver. ETR's libhttpserver is the only one that I tested that passed. I would expect Proxygen would succeed if you are willing to put up with giant dependencies.
Although anything than perfect [this](https://www.youtube.com/watch?v=FxCC9Ces1Yg&amp;index=1&amp;list=PLSPw4ASQYyymu3PfG9gxywSPghnSMiOAW) is where I started.
I see that no one has mentioned Haskell here, but I think it's quite relevant. If your starting premises is that you want performance and abstraction, but you want to avoid the resulting complexity, the alternatives offered by others Are: * Rust: Compromise abstraction (-abstraction, -complexity) * D: Compromise performance (-performance, -complexity) * Go: Forget about abstraction (--abstraction, -complexity) In the other direction: * Haskell: Hard to learn, but the king of abstraction (-performance, ++abstraction, -complexity) In C++, people often complain about the syntactic noise of metaprogramming, but type-level programming in C++ is like a scripting language as well. That's why you get compilation errors from templates only during instantiation, and the error messages are very deep stack traces of that language. The equivalent in Haskell always stays sane, as in compilation errors are local, the signature of a function locally determines whether it's correct. This lets you increase abstraction to levels that would be beyond intractable in most other languages.
&gt;The kernel is the same beast it's been since NT. It's been incrementally improved (so the same language has to be used) over the years, of course, but there is an awful lot of "just write a bunch of new functions on top of existing code" going on. :) I'll believe it when I see it for myself. I studied OOP. They would have to write entirely new functions just for W10. Did you look at the OS architecture (source) to determine how it handles memory management, and graphics, hardware, and security. I bet it's an entirely different Altered Beast that can act like the old 32bit beast. I think it's weird. What can I say. You obviously think it's because of some kind of awful psychological "syndrome." Don't worry! I don't suffer from that particular malady. I'm gearing up for my MCSE and plan on developing for Windows. I want to get to know the nuts and bolts under the hood....
It'll take me a while to decipher all of it. I'll get back to you :-)
I have been spending most of my free time for the past 6 or so years doing one. haven't yet gotten it to do much of anything useful. (and I am a professional c++ coder by trade) So, not hard at all.
Hey thanks .. looks great!
As a student, I wish the conference was held just a little earlier, since it conflicts with my class schedules, but I cannot express how thankful I am that the presentations are uploaded. I've learned so much from them, and I cannot wait to one day be an attendee at the conference itself.
With any luck, I can work on it with Andrew Sutton after he's less busy with Concepts. I was going to propose this and then found out he had something similar already.
Eh... you're being over-dramatic in saying that people "literally spend all their life" on lighting shaders. Especially since the fixed function pipeline was quite active until the mid 2000's...
As someone whom has written one single handedly from scratch. Yes. It is a lot of work. Do not do it unless you absolutely have to. 4+ years and even though it's quite functional and working great for us I still ocassional rewrite large portions. In our case it was necessary because we needed to interface with a simulation running at up to 60 000 cycles per second with up to 1 000 000 individual entities. Game engines just aren't designed for our purpose. We tried a couple first. (www.digitaldiatom.com for anyone interested in what it is used for).
Thanks for attending! Tips: I have not yet made the schedule available, but I already know its full of conflicts for everybody, so choose wisely which talks you want to attend. The two main rooms offer enough space, but in the side rooms popular talks could be crowded, so be there early to get a seat. 
&gt; and I am a professional c++ coder by trade *In what field* are you a professional? "C++" is not a field. I wouldn't expect someone who does financial C++ to have any finesse when it comes to rendering/engine architecture. At the same time, myself and other engineers have dealt with multiple engines, tearing them apart. 6 years on a usable engine at that point seems *way* overkill unless your goals are astronomical.
The hardest/most infeasible part is the toolchain / asset pipeline. It's very difficult for engineers to grasp as there are a *lot* of UX/design elements associated with it. Graphics, sound, networking aren't particularly difficult in isolation (combining them adds a bit of work, but if you're familiar with it it isn't too hard). Pipeline and editor *are*. There's also a reason that a lot of third-party indie engines don't have full pipelines/editors - it's difficult for engineers to write (as it's not entirely an engineering task). They're usually designed around more manual work - manual import of assets, writing scripts/logic by hand instead of with visual editors, *etc*. This also isn't necessarily *worse*, it's just different and less geared towards designers and more towards engineers and true technical artists. I'd never recommend that someone who has never written a renderer or at least worked in the deep elements of an engine write one, though.
`forward` macro having the same name as `forward` function violates the principle of least surprise though.
Sir/Madam, you're obviously attempting to anger me. I didn't really "spout" anything nonsensical. I merely asked questions regarding the latest version of Windows - W10. As an aspiring network admin/developer, its my mission to learn as much as possible about the OS, not just for MCSE certification but for for apps I plan on developing. I want to pick apart the brains of the developers responsible for the OS to gain a better understanding of the internals, even if that means repeatedly asking questions that may seem like "crap." The source code is not freely available. Unlike most people, I don't blindly accept what someone writes on a Reddit message board. Take a look at what someone wrote: &gt;Various parts of the desktop have been rewritten here and there, of course, and yes some of them use newer or more Microsoft-centric technologies. The core stuff that's sensitive to performance or resource usage, however, are still all C and C++ (kernel, drivers, system services, core desktop services and apps, etc.). It was probably in C++. I'm not debating that. I'd like to learn about the compilers used and command line switches passed to the compiler to optimize the OS. I would also like to inspect how different parts of the OS communicate with each other, internally. Windows uses semaphores and mutexes now, just like in Unix. I know Win 98 used a "DDE" mechanisms. There was a time when Win95 was built on top of DOS. It's changed a lot, since I used to develop for it. Anyway,I have lot of research ahead. I found one person that seems capable of answering my questions correctly on Reddit. I've decided to communicate with that one person from now on. I read the material on the MIT Opencourseware website....
Haskell itself is pure but its runtime uses very clever constructions to expose fully imperative features, so it's perfectly possible to program in Haskell exactly as you program in C. Besides, being pure doesn't mean that you copy stuff. It's quite the opposite, since it's pure nothing ever gets mutated (the mechanisms mentioned above is a different story), so you can pass references around. Actually, in Haskell, a reference is completely indistinguishable from a value.
This maybe? https://qt.gitorious.org/qt/qtbase?p=qt:qtbase.git;a=blob_plain;f=LGPL_EXCEPTION.txt;hb=HEAD
"Text files ending in .html" is exactly how I started out, too. I wonder how many programmers can trace their roots back to there?
Your best bet is this [Stack Exchange site](http://codereview.stackexchange.com/questions/tagged/c%2B%2B). If you PM me, I might be able to take a look.
Really looking forward to it.
Qt has commercial license: http://doc.qt.io/qt-5/commerciallicense.html
I started by looking at the code for Facebook, then I took a 1 week course of HTML and CSS. 3 weeks ago I bought the domain for my website and I've basically been reading as I learn new content I need (comment boxes, JavaScript, databases). I learned HTML and CSS 3 weeks ago. Not a great website but the plan is to make it better as my coding matures.
Removed; this has nothing to do with C++.
[CodeReview Stack Exchange](http://codereview.stackexchange.com/questions/132790/c-pretify-json-class) Here it is. Gonna go to sleep, i'll check back tomorrow. Somehow i got a feeling that i'm gonna look really stupid and my code turns out to be utter piece of crap. Attempt #1: only added a link, need to add code as well. mb.
Possible - yes. Though the fact that you're asking here instead of in your legal department makes it "not advisable".
Can't comment there but use `cstdint` types or just `auto` instead of those horrible ones. You use `long` in many places but it's not guaranteed to be 32 or 64 bit. Furthermore, `string::find` returns `size_t` which is unsigned as well as `string::size`. Because of that you have numerous comparisons between signed and unsigned too.
Why? Games don't encrypt resources. The resources are in the game so any half-competent engineer can extract your key and either distribute the key or a tool to decrypt all your resources. Or they just pluck the resources out of memory when the game is being played, which is also surprisingly easy to do. Engines like Unity aren't encrypting anything. What you're likely confusing for encryption is that the games convert easy well-known files like PNGs into custom formats that you are unable to directly open or view in common tools. That is done for _efficiency_, e.g. storing textures on disk in the same format they're used in memory so that loading the texture requires fewer conversions at load time. Read for example the very first paragraph of http://docs.unity3d.com/Manual/protectingcontent.html . The rest of the Unity manual goes over how you can half-ass cram encryption into the assets if you really want to, but it's by no means supported directly by the engine because it's a pointless thing to try to do.
The right answer
All of your 'questions' sound like you're trying to show off how much you know. You didn't ask "Wow, are they really still using plain old C?" Somebody could answer that and say that no, they're not using the original C from 1972, they're probably using one of the more recent revisions like C99 or C11. Or they could say that even ANSI-C(C89)/ISO C99 are used in more modern things than you might think. But you didn't ask a question like that, did you?
A 2 line function, which starts with a magic number, then XORs every byte while incrementing the magic number. Eg: unsigned char magic = 0x42; //ideally use hash of filename for (size_t i=0; i &lt; file_size; i++) *read++ ^= magic++; Do the reverse to encode. Be creative when incrementing the magic number. This keeps honest people out from snooping at your data on disk, but you cannot stop someone with a memory/api debugger. For extra protection, pack all data into a binary blob, with a table of contents at the beginning. 
Super nice! I should just go ahead and buy a ticket already! Looking forward to this!
I'm right there with you. I haven't been at any conference before. Really looking forward to it, though.
You are **forbidden** from macroizing Standard Library names, N4594 17.6.4.3.2 [macro.names]/1. Don't do it. Sincerely, one of your STL maintainers.
I agree. The types seem completely arbitrary and it looks as if perhaps they were randomly tweaked until the compiler stopped emitting warnings. That sort of a process is unlikely to come up with correct answers.
Please listen to the people who warn you not to *inherit* from `std::string`. The STL base classes are *not* safe to use as base classes.
/r/cpp_questions can help you!
To clarify, no class without a virtual destructor is truly safe - but it depends the actual use case. Of seems unlikely that someone would need to construct a JSONPretify on the heap, and even less so that they would store this as a std::string*. With C++11 and a properly constructed smart pointer, the correct destructor will almost certainly be called anyway (unless the user is trying to be clever). That said, it's probably NOT a good idea in this case, as it comes off as the library writer trying to be clever.
Wish I had the time to waffle on like this guy: http://codereview.stackexchange.com/a/107067
IMO its the user's responsibility to ensure that, if they delete an object through a pointer to a base class, that base class has a virtual destructor.
One doesn't need to defend idiomatic code, they must defend _non_-idiomatic code, such as this. Even with your argument, what _advantage_ is there to avoiding best practice so one can type `this-&gt;foo` rather than e.g. `s_.foo`?
The primary function of inheriting a non-polymorphic base class is to add all its members to your interface. The small amount of time I spent looking at this hasn't convinced me this is very compelling here, but note that I was responding to the claim that it was not _safe_, not the claim it should not be done.
Thanks! 
&gt; I can't think of a single standard algorithm that accepts more than one functor. `std::inner_product` and `std::transform_{reduce,exclusive_scan,inclusive_scan}`. Plus the Ranges TS is adding projections everywhere.
&gt; Liskov substitution is a fantasy Okay, so is OOP then. Pick a side already. &gt; On a gentler note, publicly inheriting a non-polymorphic base is only way to share a common interface between specializations of a class template, isn't it? No, for C++, private inheritance + selective `using` declarations share a common interface without surprising those fantasy-lovers. ;-]
But you have to `using` all the members, and then you have the maintenance hazard of ensuring any new members in the base get corresponding `using`s added in the derived classes. I suppose that's what "selective" means? Was I supposed to be on the OOP side?
You don't call destructor for a reference so no problem there.
Yes.
With the right amount of motivation, anything's possible. If this is a serious question, just take a look at most PC video games. There's a metric shit-ton of software that uses DirectX, OpenGL, or custom back-ends which were written in C++. If you're looking for examples of graphics engines, frameworks, or C/C++ libraries, here are a few links: Commercial Game/Graphics Engines written in C/C++ * Quake 3 Engine (Id Tech 3): https://github.com/id-Software/Quake-III-Arena * Doom III Engine (Id Tech 4): https://github.com/id-Software/DOOM-3-BFG * CryEngine 3: https://github.com/CRYTEK-CRYENGINE/CRYENGINE * Torque3D: https://github.com/GarageGames/Torque3D * Source Engine: https://github.com/ValveSoftware/source-sdk-2013 * Half-Life Engine (precursor to Source Engine): https://github.com/ValveSoftware/halflife * 0 a.d.: https://github.com/0ad/0ad Indie Graphics/Game Engines: * Helium Project (Supported by Insomniac Games): http://heliumproject.org/ * PolyCode: https://github.com/ivansafrin/Polycode * Craft: https://github.com/fogleman/Craft * Banshee Engine: https://github.com/BearishSun/BansheeEngine * Urho 3D: https://github.com/urho3d/Urho3D * Xoreos: https://github.com/xoreos/xoreos * NeoAxis: https://github.com/NeoAxis/SDK * HVOX-Engine: https://github.com/sp4cerat/HVOX-Engine Graphics Frameworks to help implement an engine: * Cinder: https://github.com/cinder/Cinder * Verto Studio Engine: https://github.com/mlfarrell/VGLPP * Gameplay 3D: https://github.com/gameplay3d/GamePlay * TinyRenderer: https://github.com/ssloy/tinyrenderer * Allegro 5 (written in C): https://github.com/liballeg/allegro5 * SFML: https://github.com/SFML/SFML * SDL2: https://www.libsdl.org/ 
is it possible to encrypt data in memory/API by writing custom vertex and pixel shader that applies simple transform similar to the XOR example? then contents are "decrypted" in GPU memory but not in RAM
If you can't go back, then you equally can't just store (and later return) the iterator and expect it to remain valid while you search on for other things.
The community accepts that is "okay" to use Qt commercially if you link against the DLLs. A static link is more controversial, although you will some people that also find it agreeable as they in theory agree to offer those portions of the code upon request. If god forbid, this ever happens consider ignoring the email. ¯\\\_(ツ)_/¯ See https://www.gnu.org/licenses/gpl-faq.en.html#LGPLStaticVsDynamic
&gt; On a gentler note, publicly inheriting a non-polymorphic base is only way to share a common interface between specializations of a class template, isn't it? If you have a class which is designed to serve as a non-polymorphic base, isn't it best practise to make the destructor protected?
Just to add to the list, was surprised it was missing: bgfx - a cross platform graphics framework https://github.com/bkaradzic/bgfx
I had this situation, except Library A and B used different versions of my_cool_function.h . Fun times with different struct layouts in both. In this situation it is a feature when the compiler complains. 
But `std::find` requires `InputIterator`, see [here](http://en.cppreference.com/w/cpp/algorithm/find).
Apologies, you're correct there. I was responding to the comment, without paying attention to the context. As u/tcbrindle said though, I can't see a problem just using `std::find_if()`. In Haskell, I'd reach for a fold for this sort of task, so maybe std::fold would do the job, consider using std::accumulate, with the accumulator being the results (initially empty).
You can't, even with that switch, your co-workers will hunt you down, kill you and undo it.
&gt; ... the whole point of OOP is to not write entirely new functions every time you add a new feature or optimize some code. Sean, they wrote a lot of new functions(code) for W10. There may be code inside the OS that was originally written for Win8/Win7. W10 may function a lot of like its predecessor, win8/win7. But it must be different for MS to label it W10 instead of W7.newhelloworld. OOP is a paradigm used to modularize the software development process. It's way to develop software, so upgrades can be easily incorporated, like you pointed out. I haven't read any books about the OS yet. The last Windows book I read was Programming Windows 98 by Charles Petzold, 1998. That's why I started this thread like a noob. I've used just about every version of Windows since then but didn't do any development! &gt;You'll get further along if you listen to people trying to help clarify misconceptions. :) &gt;Windows 10 is an evolution of Windows 8. Which is an evolution of Windows 7. Which is an evolution of Windows Vista. Which is an evolution of Windows XP. Which is an evolution of Windows NT 4. I'll get further along by writing code for the OS and reading the books you pointed out. You're right. Glad you know the history of Windows. They obviously wrote entirely new functions. I'm not a developer, as you can tell. I wouldn't have started this if I worked at Redmond! I started this thread thinking folks would patiently clarify "misconceptions," not to annoy anyone. Further, I don't know why you would assume that I'm familiar "tongue-in-cheek" terms used in your industry. Would you like it if I get a psychiatrist to describe your stern responses using medical terms. Thanks for clarifying misconceptions! I appreciate your effort, and looking forward to asking questions about the OS, as I prepare for my MCSE certification.
&gt;"According to the experts, Gentoo is programmed to run faster on the machine it's compiled on." I think I wrote that to gain a better understanding of how W10 is compiled. Someone responded that it's usually compiled on a powerful server. Just so you know, Gentoo does run faster if it's compiled instead of downloaded in binary format. &gt;"C/C++ are both languages that were designed specifically for Unix." Yes, C/C++ was *originally* implemented on Unix a very long time ago. It's used by OSs like Windows now as well. I wrote that wondering why MS didn't use a new language like C#/F# for its flagship OS, W10 and to get info about the type of compiler. &gt;"W10 was probably developed from scratch. They didn't use the WinXP code base." How could anyone compare XP to W10? There are similarities but the OS is significantly different, internally. They had to put up the specs for MS Windows10 on a drawing board somewhere. MS didn't just erase the number 8 to draw a 10. &gt;"the internal features of the OS, compared to NT (Win 2000)/WinXP are significantly different." Windows NT wasn't released in 2016! I won't explain why I wrote that any further. &gt;And of course, "C, one of the original languages" The C computer programming language has been around for a very long time. There are developers out there that consider it to be one of the original languages. &gt;I don't see any questions here, just you "spouting crap". The last time I checked no one died and made you in "crap" inspector. It's a public forum. I didn't offend anyone with my MS questions. I doubt there's a little girl crying because I asked about compilers..... Do yourself a favor, find another thread. Don't waste your time looking at spouting crap. The smart person that can answer my questions isn't interested "spouting crap." This will be my last response to you. Good luck.
If you gonna pull boost into your project, [Boost.Hana](http://www.boost.org/doc/libs/1_61_0/libs/hana/doc/html/group__group-Struct.html) is also worth a look. struct Cat { BOOST_HANA_DEFINE_STRUCT(Cat, (std::string, name), (int, age), (std::string, furColour) ); }; Cat cat = {"Stimpy", 5, "Red"}; const auto&amp; a = [](const auto&amp; pair) { std::cout &lt;&lt; boost::hana::first(pair) &lt;&lt; ": " &lt;&lt; boost::hana::second(pair) &lt;&lt; "\n"; }; boost::hana::for_each(boost::hana::accessors(cat), a); const auto&amp; b = [](const auto&amp; x) { std::cout &lt;&lt; x &lt;&lt; "\n"; }; boost::hana::for_each(boost::hana::keys(cat), b); boost::hana::for_each(boost::hana::members(cat), b); 
Your claim that all the downsides of inheritance are mitigated seems like an oversell, particularly with regards to inlining. Type erased objects also cannot have their methods inlined. Dynamic polymorphism always implies either branching or some kind of function pointer jump, the former of which requires all possibilities to be known in some sense, and the latter of which is always a barrier to inlining.
I don't honestly understand how you can say this as a blanket statement. Liskov applies when you are using subtype polymorphism, that's not what's happening here. I can show you problems that can be solved most easily and safely using inheritance from a non polymorphic class.
Sorry, I'm afraid I don't entirely follow. You are saying, what about functions that are part of my interface that are not dynamically dispatched, those can be inlined?
Are the virtual function downsides cited in this article still true with modern compiler optimizations (e.g. de-virtualization)?
You could accomplish this work with a single `std::find_if`. The problem is that **(a)** you need to make your lambda mutable which may not be a desirable thing if you don't play your captures correctly, and **(b)** you're stuffing a lot of work into a single lambda (ie. having it return a bool based on all the correctly found criteria). I was specifically thinking about non-trivial containers when thinking about the problem. Containers like `std::forward_list` and `std::set` where iterating can be expensive in multiple passes.
You might by able to support std types by wrapping the method calls in lambda expressions. I mean something similar to this: Result (*erased_method)(void *, Arguments...) = [](void *this_, Arguments ...args) { return static_cast&lt;T *&gt;(this_)-&gt;method(std::forward&lt;Arguments&gt;(args)...); }; 
No, not really, if de-virtualization can take place. Virtual functions are far less of a downside than the intrusiveness of inheritance. Maybe I should just remove some of the downsides about virtual functions and leave the downsides about inheritance.
Thanks for the replies. 
The problem with using the visitor pattern for reflection is that its not feasible to handle visiting two structs together(like for a generic `equal` that uses reflection). Instead, it would be better to just use unpack. For example, you could just specialize [`unpack_sequence`](http://fit.readthedocs.io/en/develop/include/fit/unpack_sequence.html) from the Fit library, like this: namespace fit { template&lt;class T&gt; struct unpack_sequence&lt;T, typename detail::holder&lt; typename T::reflection_unpack_sequence &gt;::type&gt; { template&lt;class F, class P&gt; constexpr static auto apply(F&amp;&amp; f, P&amp;&amp; p) FIT_RETURNS ( T::reflection_unpack_sequence::apply(fit::forward&lt;F&gt;(f), fit::forward&lt;P&gt;(p)) ); }; } Then all you need to do is provide a `reflection_unpack_sequence` struct to make it unpackable: template&lt;class T&gt; constexpr std::pair&lt;const char*, T&amp;&gt; reflect(const char* name, T&amp; var) { return {name, var}; } struct person { std::string name; int age; struct reflection_unpack_sequence { template&lt;class F, class T&gt; constexpr static auto apply(F&amp;&amp; f, T&amp;&amp; x) FIT_RETURNS ( f(reflect("name", x.name), reflect("age", x.age)) ); }; }; Of course, if you want to make it more concise you could create a `REFLECTABLE` macro that could reduce some of the boilerplate: #define ITERATE_SEQ(...) PRIMITIVE_ITERATE_SEQ(__VA_ARGS__) #define PRIMITIVE_ITERATE_SEQ(...) __VA_ARGS__ ## _END #define REFLECTABLE(seq) ITERATE_SEQ(REFLECTABLE_EACH_DECL_1 seq) \ struct reflection_unpack_sequence \ { \ template&lt;class F, class T&gt; \ constexpr static auto apply(F&amp;&amp; f, T&amp;&amp; x) FIT_RETURNS \ ( \ f(ITERATE_SEQ(REFLECTABLE_EACH_UNPACK_1 seq)) \ ); \ }; #define REFLECTABLE_EACH_UNPACK_1(var, ...) reflect(#var, x.var) REFLECTABLE_EACH_UNPACK_2 #define REFLECTABLE_EACH_UNPACK_2(var, ...) , reflect(#var, x.var) REFLECTABLE_EACH_UNPACK_3 #define REFLECTABLE_EACH_UNPACK_3(var, ...) , reflect(#var, x.var) REFLECTABLE_EACH_UNPACK_2 #define REFLECTABLE_EACH_UNPACK_1_END #define REFLECTABLE_EACH_UNPACK_2_END #define REFLECTABLE_EACH_UNPACK_3_END #define REFLECTABLE_EACH_DECL_1(var, ...) __VA_ARGS__ var; REFLECTABLE_EACH_DECL_2 #define REFLECTABLE_EACH_DECL_2(var, ...) ,__VA_ARGS__ var; REFLECTABLE_EACH_DECL_3 #define REFLECTABLE_EACH_DECL_1_END #define REFLECTABLE_EACH_DECL_2_END struct person { REFLECTABLE( (name, std::string) (age, int) ) }; Then to iterator over it just compose [`by`](http://fit.readthedocs.io/en/develop/include/fit/by.html) with [`unpack`](http://fit.readthedocs.io/en/develop/include/fit/unpack.html): FIT_STATIC_FUNCTION(for_each) = fit::compose(fit::unpack, fit::by); auto print_each = for_each(std::cout &lt;&lt; fit::_); person p; print_each(p); 
It can be if the derived class or the specific method is marked final. Which is probably the fair thing to do in comparison to your techniques, as you seem to offer only interface and implementation, not any kind of hierarchy.
long is guaranteed to be at least 32 bits.
&gt; As a thank you we want to hand out a free license key to every contributor of the Clang project. What about us plebs? Nope?. https://rprichard.github.io/sourceweb/
As far as reaction: The presenter acknowledged not knowing about it, and he just continued on, I was in the back with a few other people we started talking about some industry related stuff and then moved on to another talk. You can watch it here: https://www.youtube.com/watch?v=he-XVt1xIE0 Description here: https://isocpp.org/blog/2016/05/cppcon-2015-faster-complex-numbers-andre-bergner 
But it's not guaranteed to be 32 bits (exactly). That's what I said. And it's generally a bad choice.
As someone whose talk didn't make the cut last year (even though /u/JonKalb was enthusiastically in favor), I can vouch that they do take steps to assure quality. I also sat in a couple weak talks that slipped through, but it's not clear how I could have voted them down if I were a reviewer.
A fairly trivial test basically confirmed my suspicions which was that you benefit from this algorithm when iterating non-trivial containers. You get about a 60-70% speedup when using the `find_for_each` The test I used: http://ideone.com/vvMOGQ
I guess the idea with the `fusion` binding headers is, you might start a project and think you only need `visit_struct`, but then later you need something more heavy duty. Or you pull in a component later that depends on `boost` anyways and you decide to go whole hog. With the compat header, you don't need to rewrite all your code right away, and you can take your time and see how it goes. I guess a `boost::hana` compat header would be a good thing also, I have to go catch up on docs though :)
I think you're failing to see that clone is a virtual method of placeholder that is overriden in holder&lt;value_type&gt;. *edit* Removed nagging about missing C++11isms, failed to see the article is from 2000
I've tested the code with g++-6 (version 6.1.1) and clang 3.8. Both give the same error in both assignment operators about `any(rhs)` (binding of temporary `any` from a non-const lvalue reference). After fixing, the code compiles. The member function `placeholder::clone()` (`public` visibility) is accessible from anywhere within `any`. Why would it not be accessible from within its outer class? 
Must have totally missed the line in placeholder. 
happens :)
It's virtually no problem ;-)
Then I'll just analyze your pixel/vertex/compute shader to figure out what you're doing.
[This PDF](http://llvm.org/devmtg/2016-03/Presentations/EuroLLVM%202016-%20New%20LLD%20linker%20for%20ELF.pdf) is also interesting. 
`std::unordered_map&lt;std::string, boost::any&gt;`
I believe the best approach is to have an open and transparent community vote based process. In short all the big names (Parent, Stroustrup et al) get a free pass no need to have a vote, everyone else including **ALL** first time presenters need to provide a 2+ paragraph abstract about there proposed talk. Community votes on the talks and committee members get to choose a few (no more than 5) wild-cards from the failed group to bypass/override the vote. Presenters then need to provide a complete set of slides (or similar) by say 1-2 months before the conference where they are reviewed by committee and determined if they will go to the conference. As part of the continuous improvement process, presentations that were weak, or unprepared or irrelevant will be reviewed and necessary steps taken for such misses not to occur again in future conferences - documentation pertaining to the process will be maintained and updated so that as committee members transition away and new members come along there isn't the situation of institutional memory loss, also any and all documentation should be made openly and freely available to the general public. 
Well I mean in his list Id Tech 3 and from indie there is Craft are both in C as opposed to C++.
How does your library compare to RapidJSON when it comes to parsing speed and performance? https://github.com/miloyip/rapidjson https://github.com/miloyip/nativejson-benchmark 
It may be to your advantage to learn both platforms. If you are currently good enough with Linux, give Windows tools a try. You are likely to need them in your professional career.
Don't mark your structs / classes with final. It will disable some optimisations. EBCO empty base class optimization, boost::compressed_pair. And maybe also some other.
Modules are not going to help at all as long people still keep including unnecessary headers in headers without even knowing there are things like forward declarations. Also people must get aware that the STL is not some pre-compiled library, is literally open source in headers, and that fact allows to do massive optimizations that wouldn't be possible otherwise, the cost to pay for it are longer compilation times. 
I've used Windows my whole life up until ~5 months ago (I wrote powershell scripts and plugins to make development easier). I generally just would prefer to do my development on Linux.
For problem (3) - `#define NOMINMAX`.
Run a windows VM, share a 'drive' with your code directory (on your linux host). Configure your build systems (make and VS) to put the exe/obj's in separate build directories. edit/build/test on Linux, then just use the Windows VM for testing it after you have it working.
I don't want to put too fine a point on it, but it's interesting that your library uses the preprocessor in a way that is arguably ten times dirtier than just using inheritance in a sane way.
The library is listed in the benchmark https://github.com/miloyip/nativejson-benchmark. Parsing performance and memory consumption is ok, but there is room for improvement when values are serialized. As I need in the README: performance was not the number 1 goal, but rather the possibility to use JSON just like any other container type in C++.
Platform is irrelevant when you're a student, take the opportunity to use VS. Actively avoiding stuff "a priori" is a bad idea. **Do not** think that you will be able to write code on Unix and make it magically build on msvc, **especially** if you did not do it before. Source: I need to build and run stuff on two Unix flavors, one pretty different from Linux, and on Windows.
Seconded. Happy with it. Modern C++, easy to use, easy to integrate, header only, liberal license. Thanks /u/nlohmann!
So I guess being nearly 10x (aka 1 order of magnitude) slower these days is 'ok' as long as the interface is C++14Sexy. ;) 
I see, that's pretty clever. So if I understand right, it checks if the argument is POD, then detects the member types by detecting the well-formedness of aggregate initializations, and brute forcing over the possibilities? (But using this "convertible_to_any" object in unevaluated expressions to divide-and-conquer over the space of possibilities) I think I didn't understand why it has to convert the types to integers and back... I think also it might be better to state this part up front on the home page: https://github.com/apolukhin/magic_get/blob/develop/doc/pfr.qbk#L168 But it is a pretty clever thing, I didn't think that was possible at all.
Surely you expected basic technical comments when you posted this?
Well, 10x performance only really matters in performance critical applications. The interface matters every time you use it.
The library does not solve *every* problem, that's true. But there are many situations, where a nice interface trumps performance, e.g. reading a config file. Side note: there was a talk from Andrei at a conference (I believe it was in 2015, sorry have no link), which he talks about performance. He made jokes about stuff like performance optimizations of command line parsing and how ridiculous it is. Performance matters, yes. But not everywhere, everytime. Edit: found the video: [CodeDive-2015: Writing Fast Code](https://www.youtube.com/watch?v=vrfYLlR8X8k), see around 04:00.
Main trick is 'ubiq' structure with template type conversion operator. As far as I can tell it's the only way to have precise type information of the left hand side of assignment/initialization. But you cannot return/fill typelist from this operator. Only value can be remembered/filled. So it fills constexpr array of integer ids of types that later is converted into typelist. And there is one somewhat hacky thing - it assumes that layout of a tuple with the same types as fields of a structure is exactly the same as structure. 
Use `find` instead of `at`?
Sorry, we don't give away free licenses because we have too many of them lying around collecting dust, but because the clang developers have helped us a lot starting Coati and we want to say thank you to them.
Yes, I've drank the kool-aid and use TDD for all my serious work. I'm using catch which is header only making it really easy to get a project up and running. And why do I use TDD? Because it makes me develop faster, with more readable code, and I have confidence that the ruddy thing works. I'm not saying that you have to use TDD to have readable code or any of that crap. Just that I like the code I write when I use TDD more than the code I write when I don't. I did have a pretty big decrease in productivity when I first started learning TDD. But that's to be expected with any new tool. After a few weeks I started seeing the benefit. The first time I made a change which broke a unit test in another part of the code I was hooked. Finding that bug later would have been hell. 
&gt; The first time I made a change which broke a unit test in another part of the code I didn't expect I was hooked. Yeah, that's a great feeling! :-D
Of course. I meant great in the sense of relief. Like dodging a bullet. :-)
Agreed! And now when that happens i feel disappointed that I didn't understand something, but really really happy I had tests to catch me
Oh, so I can stop doing a live transcript of what's going on to some places. Thanks, Bryce! :D
Last I checked, optional references were gutted from the C++14 paper and someone had put it on track to be in C++17. IIRC, it was shot down. Has there been any talk of it since? I currently use it in many of my codebases and it serves a heavily useful purpose in my generic code.
He's responding to Ville's comment that the Core Issue fix makes optional actually work (that has confused him, because he assumed that it's just about references and somehow is related to optional references while it isn't).
Essentially, `optional&lt;T&amp;&gt;` doesn't seem to be part of the current `std::optional`. Was there any talk about adding it back in?
I'm pretty sure the best you're going to get is `std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;`.
ISO rules don't allow live feed.
still no general LiteralType as non-type template parameter? 
I would love this. For starters, being able to do `foo&lt;"abcdef"_sv&gt;` to pass a compile-time string that can be used to make other template arguments, or combine that with Boost.Hana by wrapping it in some `general_constant&lt;auto&gt;`.
I'm not familiar with this one -- does anybody have an (accessible) link to the paper?
Some link to new drafts which haven't officially been published. You can look here for prior versions: www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/ The P number stays the same, the R number increments. The bot should pick up the latest version at the post-Oulu mailing.
It becomes a lot easier to create stubs and mocks when you have OO-style interfaces. In that case, [Boost.DI](https://github.com/boost-experimental/di) can help a ton, too, particularly with its magic to detect a constructor's parameter list. However, while it provides integration with HippoMocks, it doesn't seem to support AAA testing. After looking a bit, I found [FakeIt](https://github.com/eranpeer/FakeIt), which looks pretty good. I don't know if you can get it working well with Boost.DI, but it's debatable whether a DI container is even appropriate for unit tests in the first place. You shouldn't need to stub out anything but what the unit uses directly. However, creating these interfaces and implementations for them can get tedious, particularly in C++. I've been working on something to take ordinary free functions (or any other callable, really) and turn them into implementations of an interface that is based on the signature. Its use is to replace code where there's an interface with only one function. It also provides a convention for functions to take interfaces as dependencies that can be automatically injected. In many cases, an interface can be broken down into multiple useful interfaces with one each (think something to compress and decompress, where each would be a useful interface on its own) and then combined into a third interface instead of including both functions inseparably in the first place.
Our auto-linking site automatically pulls the latest version of the paper if you don't ask for a specific revision. I have to do a bit of searching to get the last *publicly* available version. They should all be accessible links now, please report any that are not working.
This is not publicly available. You can infer some of it from the pre-meeting mailing.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3413.html explains why this is hard.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3599.html would allow that. It was deferred, but not rejected, by EWG back in 2013. GCC and Clang both implement it. Maybe it's time to push for it again...
I guess the same `op==` problems are part of why `float` cannot be a non-type template parameter? 
Do you happen to know why? Lobbyism? Fear of something? Personally I'm not a fan of closed doors, especially regarding standardization.
So, will people still complain C++17 being "minor update"?
Thanks for the answer and... fair enough. Being comfortable and focused is very important, no doubt. Sometimes it would be interesting tough, to listen to the discussions, to hear the pros and cons about stuff. 
As a note - you should take a look at the wording paper for structure bindings to make sure the syntax is the same. I'm not sure how much changed from the design paper to the wording paper.
According to latest public accessible wording of Structured Bindings (http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0217r2.html), the above syntax should be correct.
I believe the syntax is correct. (I was in EWG when this was updated.)
That makes it sound like it was dropped, rather than just not making C++17 due to wording issues.
It will likely be discussed for C++Next. There was also this alternative proposal: http://wg21.link/p0352r0
I hope all C++ standards will be awesome updates. Sometimes in small ways, sometimes in large ways. I'm pretty excited about C++17 already.
What about the extensions mentioned in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0144r2.pdf such as recursive binding and ignore ?
`x`, `y`, and `z` would also [be accessible in else branches](https://ideone.com/JAMcCg), correct?
As mentioned in the paper, these are slated for later and are not in this version.
OK, so no chance it will be in C++17. The earliest it could be officially accepted would be C++Next(20?) ?
According to the proposal, yes. The wording says that the equivalent to this: if ( for-init-statement condition ) statement else statement is: { for-init-statement if ( condition ) statement else statement }
So what's the `iso` namespace will be used for?
Structured bindings weren't scheduled to go in - I'm pretty happy that we were able to ship them this meeting.
Yes. That is correct. However, we will ship it in a Modules TS. That will probably be before C++Next.
I'll do a new revision of P0060 (http://wg21.link/p0060) as well.
Check out the enum changes in c++11
Please just put off the next release for a year and figure out the big features. We don't need another 3 years of c++11++
[This](https://github.com/nlohmann/json/blob/360f0f3791d4c2c36bc0710885c1c88d47103c13/src/json.hpp#L5707) looks strange to me, "parser_callback_t" has a default assignment of "nullptr" suggesting its a pointer type but [it is not](https://github.com/nlohmann/json/blob/360f0f3791d4c2c36bc0710885c1c88d47103c13/src/json.hpp#L918). I just [started using](https://github.com/mhogomchungu/qCheckGMail/blob/86886cb5b05390c0a594c28a45cb8a7f72511a81/src/qcheckgmail.cpp#L786) the library and it has worked fine so far for me,but my use case is as simple as it gets.
&gt; My question is: Is there a workflow (possibly with Vagrant) or tools that would allow me to write C++ on my linux partition, manage it with git, then run the same code in Visual Studio and have it work as expected to pass off my labs? You basically have the workflow down right there. I think the only thing you're really missing is CMake for setting up builds, and for lab assignments like this, you're really probably only looking at ~10 lines in a CMakeLists.txt file. Here's what I'd recommend: * develop on linux first with your preferred tools there * use cmake to define your project structure * build with -Wall flag (all warnings enabled) * manage the source with git &amp; make sure to build &amp; test on windows as well in my experience porting a windows c++14 app to linux (with clang &amp; gcc both on linux) MSVC is way more lenient on using non-standard c++ code. If you're worried about making your assignment code public, you could either use a private github repo, private gitlab repo (among others), or just set up a HDD partition locally that is visible to both windows &amp; linux on your machine. IMO, developing with a cross-platform workflow like this from the start is going to make you a stronger c++ dev than you would have been otherwise, so good job asking this question at the outset of your education.
But why? `iso` looks like a perfect name for an `std` alternative - short, descriptive and means the same thing, `std2` etc look like a some compatibility wart made out of despair. Note that many style guides require all `std` names written in qualified form, like `std::sort` (no `using namespace std`), so 3 vs 4 symbols is a huge difference. 
And I avoid mocking at all cost. So all tests look like a function call and checks on the return value. As a result, the code structure is very LISPy: tuples/pairs (note: tuple destruction order is implementation-dependent), functors, closures (note: shared_ptr in a closure is the shortest pimpl), moving stuff around, not many classes. Latest C++ standards help a lot. I use fctx header-only C-compatible library and launch these things at build time via CMake-CTest.
I would personally go with b) but with less spaces on the second line, like d). Otherwise b). I hate when the parenth is not on the same line and I feel that a) is wasting space. On another point, I personnally hate conventions that still sticks to 80 chars.... were in the era of 4K screen, for god's sake. 
Between guaranteed copy elision and `if (init; condition)`, C++17 solves two of my biggest language pet peeves. Nice.
You don't pay for what you don't use. Having pop* return a value would result in a copy being created (since the original is destroyed). Also, if you want a copy you can just copy from y.front()/y.back().
Returning a value would violate exception guarantees, since copy/move constructors and assignment operators can throw. .pop_front() is guaranteed to be nothrow: http://en.cppreference.com/w/cpp/container/list/pop_front
Perhaps, with enough SFINAE / concepts hackery, a version of pop_front() could be made that is only viable when the value_type is no-throw movable. It could make an interesting C++ standards paper.
&gt; Work in Linux(/OS X) as usual with Git. This stuff is on Dropbox. &gt; In Windows (with Dropbox), create a VS project Wha? Why not just clone from git directly in VS? Why use Dropbox at all? 
A mixture of a) and b) void Class1::Function(Class2* class2, Class3* class3) { ... }
Original STL FAQ said it was [for efficiency](http://www.sgi.com/tech/stl/FAQ.html). If all you want is to shrink your container by one, copy-construction of the value is a waste. To quote, &gt; All of the STL's pop member functions (pop_back in vector, list, and deque; pop_front in list, slist, and deque; pop in stack, queue, and priority_queue) return void, rather than returning the element that was removed. This is for the sake of efficiency. If the pop member functions were to return the element that was removed then they would have to return it by value rather than by reference. (The element is being removed, so there wouldn't be anything for a reference to point to.) Return by value, however, would be inefficient; it would involve at least one unnecessary copy constructor invocation Since then people tried to rationalize it in terms of exception safety (value-returning pop cannot give strong exception guarantee), but it doesn't stop every concurrent queue to have a pop/try_pop returning the dequeued object: [tbb::concurrent_queue::try_pop](https://software.intel.com/en-us/node/506200), [PPL concurrent_queue::try_pop](https://msdn.microsoft.com/en-us/library/ee355368.aspx), [boost::lockfree::queue::pop](http://www.boost.org/doc/libs/1_60_0/doc/html/boost/lockfree/queue.html#idm45506997807696-bb)
(e) void T::fun ( U u , V v )
Neither: void Class1::Function( Class2* class2, Class3* class3) {
That is just such a messed up answer. JSON is, by specification, slow. I would really just use it when serialization performance is irrelevant (and for a lot of use cases it is). If serialization performance matters, switching from JSON to any other serialization format (possibly a custom binary one) is going to have a much larger impact on performance than switching from this library to RapidJSON. Some applications I've written do use JSON for some serialization tasks. Dealing with JSON never showed up in any profile, mainly because serialization performance for those tasks was indeed irrelevant, and if that is the case JSON is a really nice format. Point being, if I were to make dealing with JSON in those applications infinitely faster, they would still have the exact same performance. So given between irrelevant faster performance and a horrible API (RapidJSON), or "good enough performance" and a really nice API (nlohmann::json), I choose nlohmann's library any day. Anything else is just bad engineering. And IMO, if you are using JSON, chances are, performance is irrelevant, so nlohmann's library is probably going to be the best fit as long as it is fast enough for your use case, which probably is.
None of listed above, but close to (b). I prefer to separate all the agruments: void Class1::Function( Class2* class2, Class3* class3) { ... } With the exception of single line: void Class1::Function(Class2* class2) { ... }
modules when? ;_;
I'm failing to see how `variant&lt;&gt;` differs from `union`. Could somebody please explain? They appear to fulfill a similar purpose...?
[FTL](https://github.com/beark/ftl) has a variant type (called `sum_type`) that kind of has pattern matching. To the extent it was possible in C++11, at least. Looks something like this: sum_type&lt;int,std::string&gt; x{constructor&lt;int&gt;(), 5}; x.match( [](int x){ assert(x == 5); }, [](otherwise){ assert(false); } ); It's a bit bit-rotted at the moment, though I've started work on it again in a v2 branch.
2-No, i do a ton of test but i dont like tdd, i prefer to do first the method/function and later do the tests for it rather than do first the test and implement the function to pass the test
&gt; Template argument deduction for class templates Am I correct that this makes `make_tuple` unnecessary but `tie` is still needed to force it to deduce references?
C++17 will another lump of template meta buggery, and nothing of apparently substance.
I'm fond of separators on the left: void Class1::Function( Class2* class2 , Class3* class3 ) {
Instead of undefined behavior, you get execeptions
I haven't followed C++17 closely, but I've been eyeing the Filesystem library and the ASIO library since these are some things that I'd expect to be standardized in any modern language. I think the Filesystem library was accepted, but I don't know what the status is on the ASIO library. Does anybody know?
Yes. Filesystem is in C++17. The ASIO library is going to become the Networking TS. It's still a work in progress. The draft is [here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4588.pdf).
You can use AppVeyor which is a free cloud continuous integration system which supports Windows and native code via Visual Studio. Configure AppVeyor integration with a public GitHub repro and you can have your code tested on a Windows build bot (which is also able to run and test the resulting binaries, as you'd expect of a CI system). That said, I'd recommend just getting over it and installing Windows. Trying to shortchange yourself on the experience of properly learning to use $COMPANY's development tools and environment does nothing except make it a little harder to find a job once you graduate. There's a reason that good schools make you use a variety of these tools and not let you just bunker down in your comfortable little niche. :)
And when they need `std3`?
If I may ask: How are you creating the specification itself? Pen and paper? A Word document? Some special program?
Hmmm... I think that this is actually part of how Hana works. It seems that Hana takes an abstract view of what a struct is, it doesn't care if the members actually "exist" or the values are calculated by member functions. And it assumes that all the members of the struct are "move invariant". So when I visit a struct in Hana, it isn't necessarily giving me references to the exact objects of the original struct, it might be new objects produced by moving the old ones. http://www.boost.org/doc/libs/1_61_0/libs/hana/doc/html/group__group-Struct.html I will have to think about if making a compat header for Hana makes sense, since the semantics are different and the performance characteristics are different also afaict. At the least, your code can break if your visitor does things like take the addresses of values. That would be fine in `visit_struct` or `boost::fusion`, but you'll get dangling pointers if you use `boost::hana`. And it doesn't appear that I can make a compat header that would make that okay.
What about "reflection"? I remember some old papers about it.
`stl` is not one of the candidates?
The current iteration consists of [p0194R1](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0194r1.html) (wording) and [p0385R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0385r0.pdf) (design) It was discussed in Oulu within its study group.. maybe someone who was there will chime in.
Does this mean no Coroutines? 
The one without pointers.
It's good praxis in general tho. 
I agree. Not up to me though.
I do a hybrid of yes and no. TDD or TDD-like helps when you are working on code that's deep into the application. You don't have to dive into 5 screens, especially if there's a backend component 
What's with pointers?! Normally you do not want them there. That said, it does not matter what either you or manager think. Use what is currently used, or used the most, and stick to it. **Consistency is more important than form.** 
To be honest, I have been playing with the formatting style for more than 10 years and I ended up using clang format with the clang style, maybe is not your preferred at the beginning, but you get use to it pretty fast. I have one shortcut in Vim to run clang format automatically so it's really easy to keep your source formatted regardless your location, for example, I have one style file for my job and for my things I just use the default clang style.
I'm completely aware of how dirty this solution is, as is anyone who looks at the code or actually bothers to read the readme. Your original comment is beside the point. I'm saying, "hmm, here's an interesting application of metaprogramming techniques." I'm not saying, "hey, everyone write code like this."
Got it, ill keep that in my mind, thanks. :)
Thanks. :)
Thanks. :)
There is a proposal on that called `overload` that is almost done ([P0051](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0051r1.pdf)), but we couldn't put it into 17. The author does provide a reference implementation. 
Initialization, sure, but not the definition of variables, which is what 'init' in this context allows for.
Ahhh. Understood.
&gt; Don't mark your structs / classes with final. It will disable some optimisations. EBCO empty base class optimization, How does marking a _non-empty_ class with `final` prevent EBO ? Since the class is non-empty, there is nothing to optimize. When allowing EBO you typically check for each element whether its `final` or not, and then decide to inherit or not. Types like `compressed_pair&lt;empty_type, non_empty&gt;` still perform EBO for the `empty_type` independently of whether `non_empty` is `final` or not. So... yeah, marking an _empty type_ as final will disable EBO for that type, but no, marking types in general as `final` actually allows more optimizations to be performed (e.g. devirtualization). There are many reasons not to mark a type as `final`, EBO is just not one of them (and marking an empty type as final is arguably going way out of your way to be able to shoot yourself in the head). 
EWG also discussed a paper ([P0195](http://wg21.link/p0195)) that makes implementing `overload` a lot easier, as well as linear rather than quadratic in compile time. It very nearly made it in to C++17 as well, but just missed.
Could you elaborate why?
I just happened to come across something that led me to discover that you can actually use FakeIt with Boost.DI: https://github.com/modern-cpp-examples/match3/blob/master/test/functional_tests.cpp
&gt; boost.geometry Does it have algorithms for working with polyhedra? (last time I checked it didn't). &gt; CGAL CGAL has a lot of algorithms for working with polyhedra, its awesome.
An update: we don't have a clear path to fix this problem. Presumably, the Ranges TS will solve this problem. 
I would love to try using them right away, even if it's not definite.
I was being facetious, in case it wasn't obvious. I quite like init-capable control flow. Either way, all languages grow to be complex for the sake of many things, usability included, C++ isn't special in that regard.
There's [#CppOulu](https://twitter.com/search?q=%23cppoulu&amp;src=typd) as well
Definitely! Seems very relevant for CAD / CAM as well.
I usually go with option B, but my primary formatting rule is "it depends on the context". On the other hand, I've found that most coders [absolutely hate my formatting style](https://gist.github.com/jrandom/c0de2854a1459a0df0826bd3830ec392), so take with a grain of salt. *Edit: [Here's what that code generates](http://imgur.com/Yj3zKgM) (surface color is calculated in another class)*
`if (int a = b) { ... a is only available in this scope ... }`
Fortunately, the Library isn't as densely interconnected as the Core Language. I need to remember all sorts of things (e.g. ADL defenses, op&amp;() and op,() overloading, weird function types, const rvalues, etc.) but it's generally in the context of "weird things that the user can bring to me", not library components interacting with others. I rely on my excellent memory. With over 9 years of experience maintaining the STL, it's as natural as knowing hiding spots in a Call of Duty map. Hilariously, I have a checklist mantra for exactly one thing: function declarations, so I never forget an `inline` or `explicit` or `const` when I need it.
"STL" refers to me and the C++ Standard Library in its entirety, through metonymy. As an STL maintainer, I declare that I have the sovereign right to call it whatever I want.
And another question, how do you keep track of what is already implemented and what is still pending? Do you track it by paper numbers (like P0123) or by standard clause numbers?
I don't think that "TDD" implies writing tests first anymore. I think it's why people have adopted the term "test first development" to refer to test first methodology.
[removed]
That's so simple!
If the tests don't come first, then how are they driving development? DOES NOT COMPUTE However, "design for test" is definitely a thing that means something different.
I see. How does one become a STL implementer? Is it just experience? I really enjoy reading the blog posts and books by Herb Sutter, Scott Meyers et al. and I am relying on their posts for my daily work but I believe there is still a long way to go before I'd be able to implement the STL somewhat effectively.
Nowadays it's as easy as sending patches to libc++ or libstdc++. In my case, I happened to be in the right place (Microsoft) with the right interests and skills (modern C++ libraries), at the right time (when the VC Libs dev lead was looking for new hires). I had no previous professional library maintenance experience, just my 2.5 years working in Outlook. Our other STL maintainers have come from various backgrounds - security, robotics, range-v3, etc.
Thank you for the insight!
A further C++17 improvement would be to leverage template parameter deduction for constructors: void safe_init() { std::lock_guard lk(mx_); if (v.empty()) { v.push_back(kInitialValue); } } // .... }
I totally agree! I just see more and more people using the term TDD very loosely now days. I think it's because unit tests are becoming more and more of an industry standard.
The last official release was March 2013. Do you have experience with it? How is it, compared to YCM? Edit: typo
The nice part of it is that the proposal's scope remained small and that was likely a large factor in the feature even making it into C++17 in the first place. Given that this is part of the language now, it's a lot easier to propose a simple addition to allow ignoring something, in addition to all of the other desired tweaks like adding an explicit type to one, but not all.
FWIW, they're already supported in Visual Studio. I've had some fun playing around with generators. Given that they're in a TS, I expect GCC and Clang will support them soon as well. 
A primary use-case of `optional` is to distinguish between an either initialized or uninitialized value. For a domain where a null `T*` is equally as valid as a non-null `T*` (and this is not hard to imagine, e.g. any node-based data structure), your `optional` would be useless. This `optional` design has its place, IMO, and is hardly "the worst API ever". Your `compact_optional` sounds useful as well, but I couldn't say it's objectively 'better', muchless a replacement.
I have to admit that I was not aware of the possibility of HKTs in C++. Thank you very much for pointing this out - now I have some catching up to do. Also, I have to admit that most regular use cases should be covered by these 3 language features. The syntax, however, is quite verbose, which can make it a little bit awkward to use and therefore prevent wider adoption. I have no expertise in compiler theory, nor experience in implementing them, but I think with GADTs the compiler should able to perform more advanced static analysis, for example to check if patterns of a type are exhaustively matched. Please don't get me wrong, I really enjoy programming in C++ and I think with C++17 it will get even better. What I really like about C++ is the flexibility to choose the right paradigm for the problem at hand, while still having fined grained control on what is happening. This flexibility is probably the reason why some solutions may seem blown up, regarding the amount of code. In my opinion this tradeoff is worth it and in since each iteration of the standard straightens out some of the rougher edges, I could not be happier.
Actually, you can retrieve references to the members of the struct with Hana as follows: hana::for_each(hana::keys(cat), [&amp;cat](auto key) { // This is a reference, so you can modify the member at will. auto&amp; value = hana::at_key(cat, key); std::cout &lt;&lt; key &lt;&lt; ": " &lt;&lt; value &lt;&lt; "\n"; }); Furthermore, the second element of the pairs returned by `hana::accessors` is expected to be a function allowing the associated member to be retrieved, as a reference or otherwise, depending on the definition of that accessor. When you use Hana's macros to make your user-defined types models of `hana::Struct`, the accessors will return references. 
W-what if I don't have a Twitter account? :(
It feels pretty snappy. I also used vim-clang (https://github.com/justmao945/vim-clang). But, that one is excrutiatingly slow. I have not used YCM.
The only thing i don't like about this is the long and undescriptive namespace.
There are dozens of us! _Dozens!_ (My vote is 'yes to both'.)
But if you need to remove the first line, you have to touch the second. I think the only real benefit is if the function arguments have drastically different lengths. The only time I really ever consider this style is with initializer lists since I think it looks pretty: void Class1::Class1( double variable1, double variable2 ) : variable1_(variable1) , variable2_(variable2) { ... }
My comparison may be unfair because I tried it when ycm just came out. It's quite possible everything I had a problem with is fixed.
Why on earth would flushing when you just need a newline be good practice?
`std::variant` requires constexpr construction. I'm not sure how this can be implemented. The only way I can think of involves use of union (compiler magic not considered).
I have yet to run into memory allocation being a bottleneck, so I've never used a custom allocator. As for exceptions, I sometimes throw or catch them, but usually I am just making sure all my code has exception guarantees. Does ensuring exception guarantees count?
Ah I see, do you have any link to the relevant papers?
Much obliged.
Here's the alternative proposal: http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0352r0.pdf
Ditto for me.
It's kinda a big deal in games to be able to tightly manage the allocator for speed and other such shennanegains. 
It seems you will require a Visa for most candidates afterall..
You'll need a visa for EU anyway :/
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [What the ISO C++ committee added to the C++17 working draft at the Oulu 2016 meeting](https://np.reddit.com/r/programming/comments/4pulp6/what_the_iso_c_committee_added_to_the_c17_working/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
1) It's a bump allocator that frees all memory on scope exit, presumably. :) A bump allocator is a very simple allocator that just does something similar to `void* allocate(int size){ ptr = align(_next); _next = ptr + size; return ptr; }` and has no meaningful deallocate function. In other words, it only allocates from a contiugous single block of memory, and deallocates all memory in a single `reset` operation. It is the absolute fastest allocator you can write, period, though obviously it isn't even remotely suited for general-purpose use.
No Twitter, but I work on code that uses neither. We've found that disabling exception support provides slightly better optimized code, in a realm (supercomputing) where even a few percent counts. 
My code _is_ the library. Therefore I have to assume exceptions _will_ be thrown when I call client code.
I'm not sure what this means. When calling foreign code it's best to always assume exceptions will be thrown and to bulletproof your code.
Allocators yes, although I did have to make my own thread local heap allocator.
Can't figure out any advantages over QtCreator or Visual Studio.
Here is the c++11 **boost** compatible implementation of `util::match (Functors…)`. namespace util { template&lt;typename Ret, typename... Functors&gt; struct functor_visitor; template&lt;typename Ret, typename Head, typename... Tail&gt; struct functor_visitor&lt;Ret, Head, Tail...&gt; : std::remove_reference&lt;Head&gt;::type, functor_visitor&lt;Ret, Tail...&gt; { using std::remove_reference&lt;Head&gt;::type::operator(); using functor_visitor&lt;Ret, Tail...&gt;::operator(); template&lt;typename Head_, typename... Tail_&gt; functor_visitor (Head_&amp;&amp; head, Tail_&amp;&amp;... tail) : std::remove_reference&lt;Head&gt;::type (std::forward&lt;Head_&gt; (head)) , functor_visitor&lt;Ret, Tail...&gt; (std::forward&lt;Tail_&gt; (tail)...) {} }; template&lt;typename Ret, typename Head&gt; struct functor_visitor&lt;Ret, Head&gt; : std::remove_reference&lt;Head&gt;::type , functor_visitor&lt;Ret&gt; { using std::remove_reference&lt;Head&gt;::type::operator(); template&lt;typename Head_&gt; functor_visitor (Head_&amp;&amp; head) : std::remove_reference&lt;Head&gt;::type (std::forward&lt;Head_&gt; (head)) {} }; template&lt;typename Ret&gt; struct functor_visitor&lt;Ret&gt; : boost::static_visitor&lt;Ret&gt; {}; template&lt;typename Ret, typename... Functors&gt; functor_visitor&lt;Ret, Functors...&gt; make_visitor (Functors&amp;&amp;... lambdas) { return {std::forward&lt;Functors&gt; (lambdas)...}; } template&lt;typename Ret, typename Variant, typename... Functors&gt; Ret match (Variant const&amp; variant, Functors&amp;&amp;... lambdas) { return visit&lt;Ret&gt; (variant, make_visitor&lt;Ret&gt; (std::forward&lt;Functors&gt; (lambdas)...)); } }
So roughly `monotonic_buffer_resource`.
c++31?
For me, extensive configurability is a big win. This is the only IDE on which I could get my project built using clang++ and this is because I could specify the exact compiler and linker switches.
I can't think of a single IDE that _doesn't_ let you do that...
Learn something new every day.
You would be surprised how good general purpose allocators are nowadays. When I overhauled MSVC++'s std::to_string in 2015 Update 2 1 divide had bigger impact than std::string's memory allocation.
[removed]
MSFT made a property sheet for the G++-style frontend for Clang/C2; a one-line edit lets you use this for Clang/LLVM as well. Even making your own toolset property sheet is trivial; I made one from scratch for the VC++ daily builds and it took me maybe two hours.
To be pedantic, the null allocator is even faster than a bump allocator (but far less useful).
Yes to allocators, but not a huge variety, just a few general purpose ones like a shmem one and a few styles of memory pools. Generally I avoid exceptions. Might round my use to "no"; if I throw it generally means the application is supposed to terminate, but sometimes I use it to facilitate RAII.
I haven't really been following C++17 that closely... but I can immediately see that syntax for being useful for error result checking: if (HRESULT err = SomeFunc(blah); err != ERR_OK) { ERROR_MSG("SomeFunc returned %d", err); return; } A lot of errors get eaten unnecessarily because you have to litter things with temporaries and multiple lines today.
I'm not really liking the `if (init; condition)` syntax...I understand that it's useful to be able to constrain the scope of these variables, but I think it interrupts the flow of reading `if` statements. I'd prefer a more Haskell-inspired syntax (or inspired by whoever inspired Haskell for this particular feature) using something akin to a `where` clause, allowing you to read the condition in a natural, more spoken-word like flow, and dive into the specifics of what the variable being tested are only if you need to. Something like: if (a != 12) { // do some stuff } where (auto a = getA()) Or, since this could get difficult to parse if the body of the `if` statement is long, or there are some `else` statements, it could be: if (a != 12) where (auto a = getA()) { // do some stuff } Which could then of course be wrapped for long conditionals: if (a != someSuperLongMethodToCompareTo()) where (auto a = getA()) { // do some stuff }
&gt; auto [x, y, z] = f(); Does C++ really support this kind of collection destructuring via pattern match like this? That's awesome! Is there anything like `_` to avoid having to unnecessarily bind values you don't care about?
That would make `where` a new contextual keyword, significantly complicating the grammar vs. looking for a semicolon in the `if` parens, which means it probably wouldn't be accepted for C++17. Personally I'd rather have this for C++17 than something prettier later.
Doesn't this also evaluate to false (and thus not perform the branch) if `b` happens to be 0? Or is this working because the "return value" of assignment always `true`?
I did read much of the original post, but I didn't realize that you were combining multiple features into a single comment, and thought that you were only talking about the `if (init; condition)` addition. 
Probably because in the areas they need that speed they do no allocations. 
Excellent, thanks for the tip.
I use exceptions during unit-testing only. I don't actually compile with `-fno-exceptions` though. I don't use custom allocators, they are just too awkward. I really think they should have been given language-level magic rather than being library-only.
What do you mean by "block"? and you mention concurrency, that really doesn't make sense ... Any *halfway* decent allocator automatically uses thread-specific pools to avoid contention ...
Do you really have less to care about? Returns all have to be checked for error codes and sometimes errno and you need to write all the stuff for prematurely exiting functions on failures. EDIT - wording.
No to both.
I'm still using it, even though the dev removed split windows, and refuses to give it another thought. I don't know... It's not that great, just a lot nicer in some ways than code::blocks, and easier to use than QtC.
I feel like this will make tuples significantly more useful as the syntax is much less clunky
IIRC, `{}` made the grammar ambiguous, or at least overly complicated. I think _everyone_ preferred `{}` aesthetically, switching to `[]` was a practical decision.
&gt; ~~Pretty unlikely~~ Absolutely never going to happen though :) FTFY
... that's a real question? Most developers use exceptions, and few developers use custom allocators. Although rarely used, custom allocators still matter, but they probably don't matter enough that they have to have the very best syntax or whatnot in every scenario.
It's not really ambiguous, case like below int x = 0; new auto{x}; is not allowed, and I don't think there are other cases that you can have `auto{}`, so the compiler is able to treat `auto{}` unambiguously.
In my experience I would say so. CLion on my machine is slow and unresponsive when using a library like Boost, 3 gigs of RAM and 80% of a pretty decent quad core CPU are wasted just so I can see my code in the editor. Plus I find it hard to justify spending money **every month/year** on CLion.
&gt; If your union is just PODs and you don't particularly care which one is engaged [...] The problem with that is that a lot of the time you have to care, because using the wrong one is UB. So unless you know (and checked that the standard actually says what you believe to know) very exactly what you are doing, you should still be using variant. /u/GabrielDosReis did a lot to educate us about the details there, and a lot of us thought we could get away with more than is actually guaranteed by the standard. 
Regarding structured bindings, as far as I understand, all cv-qualifiers behave as they would with ordinary expressions containing auto. Does it mean that writing e.g. `const auto&amp; [x, y] = f()` extends lifetimes of all temporary objects returned by f()? What happens when we have e.g. the following code: std::pair&lt;int, string&gt; foo() { return std::make_pair(1, "abc"s); } const auto&amp; [i, s] = foo(); If we had inheritance involved in my first example, would destructors of `x` and `y` be called without virtual dispatching?
The problem with the comment is that it overstates (by implication more than by intention) the performance penalty. `std::variant` has been very carefully crafted to be as performant as possible without sacrificing generality. It is true that the variant always stores the discriminator, so `sizeof(variant&lt;Tn...&gt;) == sizeof(max(Tn...) + sizeof(&lt;some small int&gt;))`, however it is very difficult to craft a solution with raw unions where you wouldn't need that discriminator anyway (and a lot of the examples you will find that claim they can actually expose UB). If you craft your discriminated types very carefully you might be able to improve over variant, but it is not easy. **tl;dr:** use `std::variant` unless you know (really, recheck what you believe to know) what you are doing **and** have checked that you really improved the performance 
This is one of those areas where the standards guarantees are much weaker than those provided by practical implementations. For example, by the standard's rules the `LARGE_INTEGER` structure is nonsense, but it is used/required in many Windows API calls. libc++'s `basic_string` representation similarly depends on not-strictly-standards-guaranteed-to-work-but-practically-guaranteed-to-work behavior (IIRC, one of the capacity bits is reused as the "am I large string or small string" indicator). Yes, anyone playing these games needs to realize that they are endian-sensitive. I'm not disputing that most uses of union should be made variant instead. I'm just saying that practical use cases for naked unions remain.
I think "cool" is a good way to describe being able to choose between different tuple libraries... that is, it's "cool", not "good".
Never used allocators, and do use exceptions but only for "Kill the thread/process/subsystem" level events, not normal errors.
C'mon, Billy, you know better than to endorse UB because "it happens to work"...
Weird. YCM is very fast for me.
My favourite IDE. Very fast and responsive, I use it on linux and windows for cross-platform programming.
Thanks to /u/zygoloid/, `if constexpr` is [already working on clang-svn](http://melpon.org/wandbox/permlink/isToq4UWOOvYWyia)! Say goodbye to tag dispatching :)
This is cool. Always on the lookout on subjects about how to parallelise certain algorithms. 
Cheers, will look into it.
&gt; When benchmarking PARLE, I made sure that I uploaded all the input data to the device, and made sure to allocate all memory on the device before doing the benchmarking. This ensures that I will only be testing the actual performance of the algorithm on the GPU, and not the transfer performance from the CPU to the GPU, which is uninteresting for us. Doesn't this make any comparison with a CPU version unfair? Data transfer to and from the GPU will always be necessary
The highlights of the new release are also explained in the dlib blog: http://blog.dlib.net/2016/06/a-clean-c11-deep-learning-api.html
Looks nice. Just one question though. It seems like you specify the network via templates. So is there support for a 'polymorphic' network, like caffe where a network's layers/input is essentially serialised via google protobuffers and can be changed at run-time? From what I can tell, the only possible way to do this is to define your own layer classes. Also, just curious, why no support for AMD (OpenCL)? I realise Caffe doesn't support AMD cards, but there's https://github.com/amd/OpenCL-caffe
Putting the declaration after the place where it's used would be awful.
Maybe to decide if they should use them *more*.
I've stopped using exceptions and my code is a lot more predictable since. I also don't use error codes. Most logic works fine with the `NullObject` pattern.
No, you can't change the network architecture at runtime. You can change the parameters though (that's what training does obviously). Since it takes days or even weeks to train a single architecture, the time needed to recompile to change it is insignificant. Moreover, doing it this way significantly simplifies the user API, especially with regards to user implemented layers and loss functions, which do not need to concern themselves with how they are bound and marshalled between some external language like google protocol buffers. There isn't support for OpenCL because no one I know or have heard of uses AMD graphics cards for deep learning for any real task. I know you can find all kinds of crazy stuff on the internet like training DNNs in javascript. But all the researchers and industry users I know of use NVIDIA hardware since it has far and away the best support both in terms of performance per $ and in the breadth of the development environment NVIDIA has created (e.g. cuDNN, cuBLAS, cuRAND, nvcc, etc.). If you use OpenCL for DNN training you are literally wasting your money. :)
The idea is that we can use RLE as part of some larger video codec implemented on the GPU. In Ana's paper she mentions that you often have to transfer the data to the CPU before doing the final compression, because compression is so hard to do on the GPU. But if we can do that on the GPU as well, the entire codec will be GPU accelerated, and should be much faster. So if I were just doing RLE and nothing else, then I think the CPU version is always preferable, because of the transfer times that you mentioned. But if we are doing RLE as part of something larger, like a video codec, then doing RLE on the GPU should give a speedup. Although in reality, most video codecs noways probably use much more complex compression schemes than RLE...
Don't get me wrong, I understand the advantages of limiting the scoping like this. I just find it hard to believe that people who skip error handling because it's too much cluttery code will suddenly start doing it because this 1 line improvement in what it takes to do it.
This is great, but why on earth did you no try to contribute to the original library instead of creating your own docs? By all means, please talk to the maintainer of Boost.Range so you can make this available as part of the main documentation.
Personally, I'd like to see: * Simplified allocators, perhaps based on the composable allocator ideas Andrei Alexandrescu gave some talks on a while back * A better exception-free story, whether that's with `std::error_code` overloads as in the Filesystem TS or with the proposed `std::expected&lt;T, E&gt;` monad, to address current schism between general purpose C++ and the subset used by the game development community * A more modern alternative to iostreams * `vector&lt;bool&gt;` taken out and shot * `std::string`'s interface dramatically scaled down. The various `find()` methods can go, for example. * `std::string` is assumed to be UTF-8, always 
Sucks that you are downvoted, because you are mostly right. The 'mostly right' is that one cost of exception is tables that increase binary used to unwind the stack. They will exist and sometimes increase memory usage if exceptions are enabled, but can be optimized out if the user of his library gets the source and builds his library and the app linking with it with exceptions disabled. I also happen to think that is the right way to build a library. Often library authors have to expend more effort, but that is OK because in the long run library users save more effort because of it.
actually doctest is my reimplementation of Catch - the original Catch author maybe wants to rename Catch but not reimplement it. Why I decided to make a new framework? You can read about that in the main [readme](https://github.com/onqtam/doctest/blob/master/README.md)
I would probably name it `std17`, to start, ~~or `std::17`~~. I'd love to see containers over ranges, and fix issues associated with modifying a container while iterating over it. Or maybe I'm just bad at C++.
Anyone who wants to interop with COM / Windows / Java / JavaScript bits really need (at least) UTF-16 strings.
17 is not a valid identifier. `std::17` would be a misnomer because algorithms and such are often modified through defect reports and otherwise in following standards. For example, `partition` getting to work with foward iterators rather than bidirectional only in C++11.
I avoid exceptions, pretty much without exception. I return an error code, Often of the old school type of 0, null, or -1 where that makes sense. I use a huge number of very modern C++ bits, yet I program technology that is both fluffy (apps) and mission critical (control systems) in both cases, no exceptions to exceptions. I see exceptions as providing very little benefit while providing huge amounts of pain. They are like threads in that they can create race conditions where I just didn't fully think through my code, not because I didn't pay attention, but it is some edge case gotcha. Usually these edge case gotchas are a pain in the ass to unit test for and thus are missed until some real world situation farts in the user's face. Whereas, without exceptions, I can just program so that it either doesn't matter if a function fails and it just returns a zero which is happily handled, or returns a null which is checked for and then handled on the next line. I haven't checked in a while but programming with exceptions turned off seems to make my code faster and smaller. These are good things. Slower, bloatier, and more prone to crashes are not. If I use some library that forces me to use exceptions, that library goes on a list: "Find replacement that doesn't use exceptions." 
Also, string 
I'm not suggesting vector should replace string. String is a super-class. I'd like a better design.
Doing it by hand it is easy to get wrong, but lots of code that does case conversions (usually due to user input in my experience) is done with something like Qt that is encoding aware. I haven't actually seen much of any case conversion that gets it wrong.
Gotcha, I looked over the github page earlier. I'm definitely interested in giving it a shot. I have very few complaints with Catch, but compilation time is one of them. Unless I'm mistaken it looks like switching from Catch to doctest would be dead simple.
`codecvt` never had virtual-call-per-character interface. it's either once per streambuf constructor (always_noconv true) or once per buffer overflow (always_noconv false). The input to do_out/do_in is a string, not a character.
No checking on operator[]. Don't pessimize!
The iostream API is horrible, I'd much prefer a kind of typesafe and extensible printf/scanf. Also, exceptions should be optional everywhere. Some C++11 library additions (e.g. std::regex) throw exceptions even for "non-exceptional" errors.
`bad_alloc` is amazing, no other popular language can deal with limited memory with such ease. `new_handler` could go, though.
I agree. With something that's used as frequently as `std`, the extra character does make a difference. There's precedent for using the ISO name, too: Fortran, another ISO-standardised programming language, uses `ISO_FORTRAN_ENV` and `ISO_C_BINDING` for the names of its two standard library-supplied modules.
`at` does check, though.
Extremely unlikely. The complexity of the language directly affects learning curve, the skill level of new coders, the ability to hire skilled coders, and the ability to build a team of competent programmers where everyone can understand everyone else's code. If the skill level of the team is too unbalanced and it experiences turnover maintainability goes out the window.
what is `std::stoi("foobar")` supposed to do in your opinion? The problem with `std::stoi` and exceptions is definitely that it doesn't throw enough (for instance `std::stoul(-1)` doesn't throw).
`vector&lt;bool&gt;` renamed to `bool_vector` and the partial specialization deprecated and later removed (so `vector&lt;T&gt;` behaves regular again).
Do you mean separating a "byte buffer" and "text manipulation" (maybe unicode-aware)?
yep - just a different namespace, the main() function is a bit different if you are supplying your own, SECTIONs become SUBCASEs and there are no tags for test cases - just names (for now).
Uh, the STL has both `partition()` and `stable_partition()`, and they're totally different algorithms (notably, `stable_partition()` attempts to allocate memory with an OOM fallback). Unsigned integers make bounds checks simpler.
I may be mistaken, but the input is a string because the number of characters input does not match the number of characters output. The semantics of `do_max_length()`, which must return 1 for `codecvt&lt;char, char, mbstate_t&gt;`, seem to indicate character-by-character processing. But I admit most of the iostreams and locales standardese is greek to me.
Because the semantics are totally different, and as a result it is broken with generic code that assumes that `vector&lt;T&gt;` behaves in a uniform way. I don't think that the actual design of `vector&lt;bool&gt;` is bad, it's a fine class. But it's not a `vector&lt;T&gt;` at all, and it just shouldn't be a partial-specialization of `vector`. It should be its own thing.
Having a bit vector type is not a bad thing. Calling it `vector&lt;bool&gt;` is the bad thing. It means you can't do something like: #include &lt;vector&gt; template&lt;typename Arg&gt; using funcptr_t = void (*)(Arg*, Arg*); template&lt;typename T&gt; void do_c_thing(funcptr_t&lt;T&gt; f) { vector&lt;T&gt; x; // populate x f(x.data(), x.data() + x.size()); // whoops, not an array of bools! } making life for generic code authoring "fun". Too bad they didn't leave `vector` alone and just call the compressed thing `bit_vector` or similar.
- Fix `vector&lt;bool&gt;` and introduce `bit_vector` - Change `unordered` specification to allow more efficient implementations - Add missing stuff to `bitset`: iteration over set bits, finding highest and lowest bits. - Change `&lt;iostream&gt;` interface: better separate 'io' and 'formatting', introduce 'format strings'-style output. Make them stateless. - Introduce `text` - a unicode-aware string, make `string` a pure byte-buffer (maybe needs renaming) - Niebler's views and actions in addition to range-algorithms. - Maybe vector/matrix classes with linear algebra operations. (Maybe together with multi-dimensional tensors) But this needs to be very well designed and specified such a way to exploit all the performance of the hardware. See Eigen. Update: - Hashing should be reworked. 
That would just be weird, as it's not possible to have C-arrays check on []. It's consistent the way it is, and it's been this way for ages, it just wouldn't make sense to change it now.
Not blocking `future` creates UB, since `exit`ing the program while any outstanding tasks are executing is UB.
When I create a variable, I expect RAII to clean it up once I am leaving the scope and am not willing do it manually. For threads that means to join them. Yes, it may be slow, but why would I start a thread if I wouldn't want to complete it. It really is sensible to expect it to block. The current situation OTOH forces me to write code for manual ressource-handling, unless I am willing to add something like that to my codebase: class sensible_thread: public std::thread { public: using std::thread::thread; ~sensible_thread(){ if (joinable()) {join();} } }; I really don't see how it is supposed to be surprising that an unfinished thread will block. With regards to deadlocks: I have to avoid them in any case and don't see how a call to `std::terminate` is much better than a program that doesn't make any progress (yes, the later is UB, but that could easily be changed without any problems).
The problem is it's not a `vector` (even not a container in the standard's sense!) and it does not actually contain `bool`s. So the name `vector&lt;bool&gt;` is a double lie. (And moreover, it's iterators are proxy-iterators (meaning their dereference yields a proxy object, not a `value_type`) which is very odd thing to work with)
&gt; don't see how a call to std::terminate is much better than a program that doesn't make any progress End users understand what crashes mean. Deterministic crash is far better than a zombie program. &gt;(yes, the later is UB, but that could easily be changed without any problems) Not sure how that can be changed without any problems. Tearing down the storage for the thread functor and parameters (that is, completing the thread) requires calling into the CRT. `exit` shuts down the CRT / deallocates the TLS slot for `errno` etc.
[Will Guaranteed Copy Elision (P0135) break ABI compatibility?](http://stackoverflow.com/questions/38042497/will-guaranteed-copy-elision-p0135-c1z-potentially-require-abi-breakage) 
I don't mean something like preemption. I am talking about removing the sentence from the standard that makes it UB if no thread progresses from the standard. At the moment getting into the case in real implementation means that the program “hangs”, as it is called in Germany. In my (limited) experience, most people understand that they have to kill it that case and it has the advantage not to dump cores everywhere. 
&gt; Last I checked, libstdc++ still doesn't support Windows threads natively, and I am highly skeptical of wrappers that attempt to adapt Windows threads to the Posix API. Hi! Out of curiosity, have you run across MCF Gthread? https://github.com/lhmouse/mcfgthread I'm wondering, what are your thoughts about it? I've just run across the announcement on the [MinGW-users](http://news.gmane.org/gmane.comp.gnu.mingw.user) mailing list: [Mingw-users] "new thread library aimed at c++11 and later development": http://thread.gmane.org/gmane.comp.gnu.mingw.user/45248 &gt; A new thread library named mcfgthread, which probably will be a replacement for the various windows versions of pthread's we use nowadays is in develoment. &gt; The code was donated to the FCF and might be added to the gcc sources at some point. It's about 10 times faster than winpthreads and uses native windows TLS functions but has not yet been tested on windows XP, so if anyone here still uses it the developer would like to know if it works when bootstrapping gcc. &gt; Sadly it does not support OS older than XP because the native TLS functions are not present in those.
How would you say your DNN to [tiny-cnn](https://github.com/nyanp/tiny-cnn) in terms of API, speed etc.? (they just integrated libDNN and a lot of other awesome stuff in the past days / weeks) And no VS2015 support? Really? That's extremely disappointing - a strong "no-go" in my opinion? Yea it's maybe not 100% C++11 compliant, but come on. :-)
I love the if and switch init (as an app developer), however the condition should come first. We write the init once, but read the condition multiple times. if(auto p = aComplexExpression(); !p.second) could have me scan `auto p = ....` as the condition which is dangerous.
There's also the issue with texture compression. With texture compression, you can actually raise the frame rate on bandwidth-limited systems. It's like playing a video on a Pentium II. The speed of certain devices were slow to where uncompressed can be slower compared to compressed
Negate your predicate and you're done, with equal efficiency. Soon you'll be able to do this with not_fn(). This is like asking for a reverse sort - you just pass greater.
No, got busy with other things. I have a list of issues to write up and this is very low priority.
I have no opinion unless and until it becomes a default part of gcc/mingw-w64. Boost.Thread works for me.
The dlib API is meant to be used with a GPU (or multiple GPUs). So it's much faster. It's not even clear to me why you would want to train a DNN on the CPU. For example, if I had trained the imagenet model that comes with dlib in a tool like tiny-cnn it would have taken an entire year to train, or maybe even more. That's totally unreasonable. It's not my fault VC2015 isn't a C++11 compiler :). The rest of dlib works in VC2015 and many earlier versions of VS, but the DNN part requires C++11 support. I and others tried to work around the bugs in VC2015 and it almost compiles but there are too many bugs in VC2015. Also, the NVIDIA CUDA SDK doesn't support visual studio 2015 yet anyway. I'm sure VS will support C++11 eventually though and get CUDA support as well. But not today.
* allow non-`const` access to `std::set` members. the current `const` protection does not guarantee that users can't mess up the order, and does get in the way of sensible use cases such as storing objects by name and being able to change other fields except the name. * allow converting from `T*` to `std::list&lt;T&gt;::iterator` so items can be removed quickly from a list knowing only their pointers. * allow specifying a size type (via template I guess) other than `std::size_t`. for many use cases `int` is sufficient and having to cast all `int` indices to `std::size_t` can make code ugly.
It would be cool if one could choose the index type for `std::vector` via a template parameter. Unsigned integers do make bounds checks simpler, but make programming in general a bit harder, for example simple things become dangerous: for (T i = n; i &gt;= 0; --i) `std::vector::operator[]` doesn't do bounds checking anyway, only `std::vector::at` gets slower with signed. A lot of code out there uses `int` because it is convenient to have `-1` mean null and frankly `unsigned` and `std::size_t` are longer to type out. Storing a vector of indices to another vector takes twice the memory (usually) using `std::vector&lt;std::size_t&gt;` versus `std::vector&lt;int&gt;`.
It really isn't that hard: 1. unformatted I/O makes no virtual calls until the buffer runs out. 2. bulk I/O is not required to use the buffer The call to codecvt::out from filebuf::overflow is specified in [filebuf.virtuals]p10. It takes the entire buffer as input and produces the string to be written to the file. Implementations (well, libc++ and libstdc++), of course, skip that call for non-convering codecvts.
My personal nice-to-have list: * BigInt container. * Easier to work with Allocator design/interface. All that propagate* is complicated. * Open addressing based hash maps. * Various string algorithms used in day to day basis. I know it exists in boost, but it should really be part of standard library. * Use of realloc for containers holding primitve types. This is something folly::fbvector does I believe.
I didn't say it should be used to hold a node as part of the primary interface, merely that null pointers _are valid_ in such a domain, so `optional&lt;T*&gt;` must treat them as such. Why should e.g. an algorithm for a node-based data structure not be allowed to use `optional` for the full range of valid domain values? I really don't see any rationale behind your opinion, just.. opinion – it seems arbitrary, for no benefit. EDIT: Should `optional&lt;int&gt;`disallow `0` as a valid value? Following your same logic, `0` should be disallowed because "why would you use an optional just to avoid holding zero?" It doesn't make any sense. `optional` represents semantics regarding presence of a value, and it so happens that `nullptr` and `0` are both valid, useful values. &gt; Sincerely, I have no idea. What a great idea to disallow something! ;-]
I like the approach in Qt. QString::toInt() and similar methods return zero on error (which I find a reasonable default) and there's an optional bool out parameter that indicates errors. Or, similar to the new std::optional, they could add a type like Rust's Result, which contains the result or an error value.
Maybe it at-least remove common mistake with assignment instead of equality comparison.
Symmetry with `for` is a primary goal here.
That's understandable but for is *always* written a certain way. This is not. That's my concern when it comes to reading/scanning code.
Fair enough -- happy cake day!
&gt; You were the one that said that `optional&lt;T*&gt;` is useful in practice What is with Reddit's lack of reading comprehension? Where did I say this exactly? I see saying that the values `nullptr` and `0` are independently valid and useful and should not be arbitrarily restricted from use in `optional`. I see me advocating not restricting use of valid values in `optional`, and saying that the fact that your `compact_optional` proposition (pointlessly, as far as I can tell) disallows usage of valid values makes it useless for people who want to represent every value in their domain. I don't see me handwaving or promising you anything, but I see a lot of fallacious, accusatory BS coming from you.. why, exactly? _You_ have yet to explain why arbitrarily disallowing valid values is a good thing, except that you've never needed them. Where's _your_ thesis, Mr. Confrontational? Drop the strawmen or drop the argument already.
All of this, plus ranges replacing iterators, and &lt;algorithm&gt; being on top of ranges. Allocators and exceptions are the major blocker for the use of the STL in the gaming industry. iostreams also are usually disliked. I'm not saying all the reasons for it are good reasons, but I believe they should definitely be reworked. Probably locale could be also made better, I know very little programmers actually using it.
`std::string` : Straightforward way to iterate over codepoints without codecvt'ing it to a u32string.
Edit: added some more detailed examples. You have to be a bit careful as the following example shows template&lt;typename T = int&gt; struct X { X(T); }; X&lt;&gt; x = 5.5; // Legal C++14 with T == int X x2 = 5; // T == double, so default can be overridden... Personally, this doesn't bother me because I think of the constructor as a template function, and those don't have to include angle brackets unless you are specifying some template parameters explicitly (e.g., make_pair), so why should I have to do so in this case? Note that angle brackets are also omitted for injected class names, so it is not new for a declaration to be able to create template objects without angle brackets (not to mention idioms like make_pair combined with auto) Unfortunately, we had to withdraw the part of the proposal that allows partial template argument lists due to technical difficulties like default parameters as above and variadic templates. (E.g how to handle tuple&lt;&gt; already being a perfectly valid type). We still hope to add support for partial argument lists as a future extension. 
Does that mean "custom allocator in general" or an STL Allocator?
So ... ptrdiff_t?
String should be C-compatible, meaning zero-terminated. This complicates things. Additionally, string has small-string-optimization, which vector is not allowed to have.
Anything that tries to order objects (like `std::sort()` or `std::set`) should not be using `operator&lt;` but a `compare()` function that can return -1, 0, or 1. The problem is that if you have objects with a nested `operator&lt;` (i.e. you call `operator&lt;` on your members) then you end up with a LOT of unnecessary computations, see e.g. https://www.reddit.com/r/cpp/comments/we3vh/comparing_objects_in_c/
Polymorphism, put simply, is the ability to write identical code to perform operations that are semantically equivalent but which differ in implementation. For instance, when you *overload* a function to take arguments of varying types, like `float sin(float)` and `double sin(double)`, you are writing ad-hoc polymorphic code -- the expression `sin(x)` can be expected to do the right thing for any argument, selecting the correct implementation based on the type of the data you give it. In C, all functions have to have unique names -- so you have to remember to call e.g. `sinf` or `sind` as necessary, and if your data types change, then all of your call site code has to change, too. Likewise, when you define a template, you are writing parametric-polymorphic code; when parameterized correctly, the instantiated class or function will be able to operate on whatever data you give it; this allows you to write a generic container or algorithm that can operate transparently on many disparate types without sacrificing performance, flexibility, or type-safety. In C, generic algorithms and non-intrusive data structures are only possible using `void*`, an untyped pointer; once again, this requires you to manually keep track of the types of your data and can result in crashes or corruption when you get it wrong. Finally, when people talk about polymorphism in the context of object-oriented programming, they are usually referring to subtype polymorphism, where a derived class can *override* some of its parent class's behavior. Most object-oriented languages provide this functionality for all methods in all classes, but C++, for reasons of legacy, portability, performance, and simplicity of implementation, chose to make classes opt their methods into being dispatched using the `virtual` keyword. Those are the canonical three, but there are other forms of polymorphism as well; pretty much whenever you hear programmers talking about genericity, flexibility, modularity, or extensibility of code, what they're really talking about is some sort of polymorphism.
Indeed, if we've learned anything from that beast, it's "make it a separate type!" ;-]
For me, one issue is that while it would be intuitive to write: for (auto i = 0u, n = v.size (); i != n; ++i) { ... } it actually contains latent bug on x86-64. After getting bitten by this recently, I wrote myself a simple template so that I can write something like: std::vector &lt;int&gt; v = { 7, 8, 9 }; for (auto i : ext::iterate (v)) { std::printf ("v [%d] = %d\n", int (i), v [i]); } which deduces **i** to be of the same type as the **.size()**'s return type (to cover cases of custom containers).
Some properties of floats are actually runtime. See numeric_limits. Some of those functions are not constexpr for a reason. Think of compiling to generic x86 vs a specific chip. I'm actually not sure how much of that type of stuff affects templates, but it's something to consider.
&gt; What happens when the index is out of range of int? I think generally when you write that you safely assume it won't grow any bigger than 2 billion elements... That's generally several orders of magnitudes bigger than 99% of vectors are.
So you had a 4-billion+ elements vector? :D Care to share your implementation of `ext::iterate`? It does sound appealing.
Ah the "*that will never happen*" argument. Our flight computer might accelerate fast enough to overflow a signed 16 bit integer, but [that will never happen](https://en.wikipedia.org/wiki/Cluster_(spacecraft\)#Launch_failure). If you ever find yourself saying "*safely assume*" you should take a step back and seriously consider what you're doing.
Firstly, to be pedantic: JavaScript is not automatically UTF-16, it can be UCS-2. Secondly: can we please never, ever ever base decisions about C++ on Java, COM &amp; JavaScript?
I apologize, I completely missed that thread; now I've gone back and read it. Regarding your first point, which is automatically checking that the output is as expected, I think this is way out of scope. Sure, it would be nice, but as a first step you should just focus on making your examples part of the main documentation. Then, as a next step (and if you're willing to), try to make sure the examples don't break.
What's wrog with vector&lt;bool&gt;?
Semantically a signed index does not make sense. While it's perferctly fine for C-style arrays (being nothing but syntactic sugar for pointer arithmetic), std::vector owns its memory, so there is nothing meaningful to be found at *(theChunkOfMemory_I_Allocated - 42). As for -1 being a special value: see std::string::npos (&lt;- which has to die btw, while we're at it ;) ) As for storing offsets into another vector: if you're storing them signed, the compiler will have to sign-extend the offset on every use if the *width of int* != *register width of the architecture* so you're exchanging space for speed here (we're prematurely optimizing after all ;) ). Plus: why would you want to throw away half of the range just because ONE value of half the range is special? 
*1u* is deduced as *unsigned int*, which is smaller than size_t on x86_64 so you'll have an infinite loop for v.size() &gt;= 2^32
I guess you should also be checking whether it'll overflow a size_t then? Unless you want to be anal about everything (or programming life critical systems, like a space shuttle), programming is always based on a multitude of assumptions. Besides, I was talking about array indices, which is much different than a speed variable. If your container is expecting a few thousand elements, suddenly getting 2 billion elements into it is generally bound to cause other problems and/or crashes. It only takes the elements being a few bytes in size to just be out of memory on most modern PCs. There is a trade-off to be had. While correct code is nice, if the risk is minimal, then performance may be a better choice.
Either that or, in my example above, n looses it's upper bits and the loop iterates only on a fraction of data.
Thanks. I'll try it out. Only critique I can think of with a quick look is that I'd probably put the helper functions inside a `detail` namespace. Have you ever needed to use those in user code?
&gt; I guess you should also be checking whether it'll overflow a size_t then? You don't have to, nor do you have to make assumptions. `std::size_t` has associated **guarantees** about its range. &gt;Besides, I was talking about array indices, which is much different than a speed variable. If your container is expecting a few thousand elements, suddenly getting 2 billion elements into it is generally bound to cause other problems and/or crashes. Sure, you might get problems: A `std::bad_alloc` exception for example. Which is sane. The program stops running and you know there was a problem. If you're just wantonly stuffing `std::size_t` values into `int`s what's going to happen? The conversion will have an implementation-defined outcome and then you'll go get an index which doesn't really make any sense. The program won't stop, you might not know there's been a problem right away, you just get weird behaviour. Correct programming trumps incorrect programming and "*that will never happen*" everytime imo.
How about `iso`? Implies "standard", **3 letters long**, and "ai-so" rolls off the tongue (although it's two syllables). `iso::sort()`. The `iso` library. I've heard there's precedent for using the `iso` namespace in other languages as well. As a bonus, the key presses alternate right-left-right closer to the home keys, unlike `std` which stresses the left hand fingers.
The helper functions? Never. They can be tucked away safely. I'll push that change right away.
That case is pretty rare. Worst case you distinguish with a tag type; the same way adopt_lock_t works, for example. template&lt;typename... Args&gt; void write(Args const&amp;... args); // throws system_error // escape hatch to print error_codes literally but throw exceptions: template&lt;typename... Args&gt; void write(literal_error_code_t; Args const&amp;... args); // also throws template&lt;typename... Args&gt; void write(error_code&amp; ec, Args const&amp;... args) noexcept; template&lt;typename... Args&gt; void parse(Args&amp;... args); // throws system_error // escape hatch to parse error_codes literally but throw exceptions: template&lt;typename... Args&gt; void parse(literal_error_code_t; Args&amp;... args); // also throws template&lt;typename... Args&gt; void parse(error_code&amp; ec, Args&amp;... args) noexcept; or: template&lt;typename... Args&gt; void write(throw_t, Args const&amp;... args); // throws system_error template&lt;typename... Args&gt; void write(error_code&amp; ec, Args const&amp;... args) noexcept; template&lt;typename... Args&gt; void parse(throw_t, Args&amp;... args); // throws system_error template&lt;typename... Args&gt; void parse(error_code&amp; ec, Args&amp;... args) noexcept; or just give them different names: template&lt;typename... Args&gt; void write(Args const&amp;... args); // throws system_error template&lt;typename... Args&gt; void try_write(error_code&amp; ec, Args const&amp;... args) noexcept; template&lt;typename... Args&gt; void parse(Args&amp;... args); // throws system_error template&lt;typename... Args&gt; void try_parse(error_code&amp; ec, Args&amp;... args) noexcept;
You cannot meaningfully ignore a `future`. If you just forget about it then the thread calculating its result continues to run, and then you get crash on `exit` when your main thread tears down global state but one of the background `async` threads is still running. If you don't care about the result of something you need to arrange to handle cancellation before termination.
Well... it's enough for me to head into building stuff like that. I like typing **auto** way more than std::size_t, so it's definitely biased decision (though auto i = 0uLL is subobtimal for 32-bit code).
&gt; And I agree with you, but only if the correctness never suffers any performance degradation If you don't care about correctness then just delete all your code. I promise you it'll run fast and it won't be correct.
Obviously should have been `sti::`
There are C APIs (e.g. the Win32 Shell) that use zero bytes as delimiters and double-zeros as the terminator. C-compatibility necessitates _allowing_ zero bytes. Not all strings in C are C-strings. ;-]
* High Quality **Portable** Code * Doesn't work in VS2015 Hummmm
&gt; (N.B.: saying `std::size_t` doesn't really mean much since size_t comes from the C library) If you're including `cstddef` and not `stddef.h`, it means the difference between being portable and not being portable (assuming no using declaration/directive). ;-]
It's important to note that `size_t` doesn't exist just to specify sizes, it exists to _describe existing_ sizes (e.g. `sizeof`, `alignof`). And existing sizes can never be less than zero.
Portable means coding to the standard, so all compliant compilers interpret the code the same way. VC++ is not a compliant compiler, so it can't necessarily consume portable code. The fault here is not with the library, or its terminology. :-]
1) Unless you are doing something really specific, arcane or esoteric you should not take a hit on most tasks. 2) In fact it should be faster as you usually can express more semantically the intent of the code and some abstractions just melt away; and 3) Premature optimization is the root of all evil™. You think you can guess the profile of an application just by looking at it. You often can't. Profile and optimize your hot codepaths.
**auto** is blue and bold in my editor :) Anyway there is a proposal for that: [P0330R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0330r0.pdf)
Well that's just silly.
You don't need to customize the STL allocators for accounting, and indeed that would be a foolish thing to do. Better to put the tracking in your general purpose allocator and log callstacks and/or scopes for bookkeeping. 
Re: exceptions in games: Why not just embrace them at this point? Surely we're past the point of it being a problem. Of course, you're not going to use them in the depths of the renderer, but why not for file I/O? 
Including `cstddef` is a waste of time. Portable code must assume that the names are still in the global namespace, so the "isolation" benefit that the `&lt;cXxx&gt;` headers offer is essentially nil. And in practice `&lt;cXxx&gt;` is going to include `&lt;xxx.h&gt;` in real implementations.
&gt; Portable code must assume that the names are still in the global namespace Please elaborate...
Fix `std::map`/`std::multimap`/`std::unordered_map`/`std::unordered_multimap`'s `pair&lt;const K, V&gt;`
`&lt;cstddef&gt;` can put `size_t` in the global namespace. Therefore you must assume that it is in the global namespace in portable code, even if on a particular implementation it is not in the global namespace. (i.e. if you try to make your own size_t in the global namespace or similar, you are in nonportable land)
I certainly don't know what their plans are, but if they wanted to do it, could whitespace work? I.e. `[a, , ]` meaning "match a 3-element tuple but bind only the first element to a variable, called `a`". Seems like it'd definitely work as far as parsing (and not clashing with existing symbols in codebases or reserved identifiers), but maybe that's too light to be considered useful syntax.
&gt; avoid exceptions What does this mean exactly? Does this mean you write exception safe code but don't throw exceptions yourself or...?
Significant whitespace is bad, bad news in a language that doesn't care about whitespace literally anywhere else. I have a hard time seeing anyone vote yes on that. Especially since it'll confuse people that didn't expect it since it's so inconsistent with everything else.
 The code is largely exceptions safe I'd guess, but I do not throw or catch exceptions. 
I use clang-format, so it's close to (b) with the only exception that the type is on its own line, like this : void Class1::Function(Class2* class2, Class3* class3) { ... }
Yes iostreams are known to be slow. But it such an artificial case that it's no very useful. Now, be aware of what you are doing, a naive implementation will always be slower than a clever one just think so to not fall into premature pessimisation. Sorry I'm being non specific it's just a broad question. Yes if you don't know your libraries and your algorithms you will waste performance but it is not a cpp specific problem 
std::find with ranges is a pain, moving around items inside a range tends to be much more painful than with iterators, because ranges want to hide away the concept of position... so then how do you specify where to move which part of the range? And some other stuff. Ranges can also be much more efficient for stuff that is modeled via input iterators, so both have their own benefits.
When looking at C++ code you can always deduce the C equivalent code. And C maps directly to the CPU instructions. Then you'll need to take into account memory, caches and synchronization. So, you know what you're getting.
Agree with shooting the current hashing, it seems to be mostly reactionary and better variants are known. I have to disagree on lin algebra classes, I feel these are too specialized and complex to be part of std. lib without placing too much burden upon the implementation. They would end up either too slow compared to specialized solutions (ie Eigen) or they would take years to materialize.
A range of bits conflates two abstractions: a packed vector of bools as wel as a flat set of ints. The former requires random access proxy iterators (over all bits), the latter bidirectional proxy iterators (over all 1-bits). This is why `dynamic_bitset` is IMO not a proper replacement for `vector&lt;bool&gt;`: although they have a large overlap in syntactic interfaces, their semantics are different. Eg, bitwise-and can mean either a data-paralel logical-and or a data-parallel `set_intersection`. I want both abstractions in STL2, as container adaptors of the same underlying raw `bitvector` representation. And the same for a `bitarray`, which should branch into a stack-based bitset and a packed `bool_array`.
&gt; Usually types start with capital letter, so bool, int, float, std::unique_ptr, std::string, std::vector, std::chrono::time_point, boost::circular_buffer
There are more algorithms that could use fixing, i.e. std::copy_n should return its iterators.
 foo * bar Variable declaration or multiplication?
And its really a good idea to split your code this way: so you can understand how it feels to code directly on an Iphone.
`copy_n` does return the destination iterator. The semantics of an input iterator make returning the source iterator not very helpful.
Can you be more specific about what needs "fixed" ?
I wonder why nobody mentioned the botched random_device interface. * random_device having no guaranteed semantics makes it not helpful without platform-specific switches * How the entropy function in random_device is specified makes no sense at all, so people just return 0 all the time 
To my understanding RtlHeap (Windows' default heap) does play thread local games.
I think stringstream has better support for formatting when using floats. Also, if you overload operator&lt;&lt; for a user-defined type, you can easily print it using stringstreams.
Yeah that'd probably be fine.
You're correct on the first point. There are _other_ reasons we replace the STL allocator interface, e.g. over-aligned types support, or just a general simplification (e.g., not needing the allocator to know the type of a container's elements, because that's pants-on-head stupid). To your second point, no, doing what you suggest is ill-advised and unusable in many domains. Your approach requires either deep callstack tracking (and hence adds sizeable bloat and runtime overhead unsuitable to embedded or real-time applications!) or breaks apart in the face of generic code (e.g., all your allocations get tagged as belong to "vector" or somesuch, which is useless). Explicit arena identifiers that also support hierarchical arenas (e.g. being able to track all "GameEntity" allocations and independently track "GameEntity/TriggerRegions" allocations) are more flexible, require far less overhead, etc. Getting the same level of data and reducing the storage overhead of your approach requires an offline postprocessing of raw events, meaning that the active memory overhead cannot be displayed in real-time within the application. This is very useful to allow content creators to immediately see the impacts of their work in a game level (e.g. showing the "GameEntities/Trees" budget being exceeded in red text on the screen when a level designer adds a clump of forest to a level).
And that's why you use a sane coding style, so that you are forced to depend on context as little as possible. If you look around, I think more than 95 % of C++ projects use initial capital letter for user-defined types. At least I know I've never worked on a project (commercial or otherwise) that used another coding style.
Look at find operations. Or range pivot operations. Or range overlap algorithms. Ultimately, there comes a point when you need to identify that an actual element within a range, and to calculate new ranges given an input of ranges and/or points within a range. An index doesn't work because not all ranges are random-access. An operation to find a pivot point and an operation that consumes a pivot point need a way to communicate what that pivot point is that works generically on all range categories. That concept already exists and in C++ it's called an iterator. There's plenty of literature on the topic, but the best source relative to C++ would be to just read the Ranges paper or Eric Niebler's blog.
Update: Digging around I found a use case for it; if the input is something like a forward list iterator. See [LWG 2242](http://cplusplus.github.io/LWG/lwg-active.html#2242)
&gt; Like, the standard library's coding style? STL (Stephan T. Lavavej, Microsoft STL implementer) explicitly says "DON'T look at the C++ standard library code"... Since they use "uglified" identifiers (with variable names such as _Foo). You think you should emulate that style? Plus, it seems that STL himself use initial capital letter for user defined types: https://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Standard-Template-Library-STL-/C9-Lectures-Stephan-T-Lavavej-Standard-Template-Library-STL-4-of-n &gt; Horse. Shit. I welcome you to give me counter examples.
stdEx ;)
If memory is not an issue, why not use UTF-32? Collation would probably be faster still. At the risk of getting further off-topic: like the other examples above, ICU dates back to the 90s and was originally written for Java, so UTF-16 internally makes sense there. Qt is another 90s-era technology that's still with us, still using 16-bit strings. Today, [87% of websites serve UTF-8 exclusively](https://w3techs.com/technologies/overview/character_encoding/all). UTF-8 is the recommended encoding for HTML and XML. All the Unixes use UTF-8 for their system APIs. 21st century languages like Rust and Go just say "all strings are UTF-8" and have done with it. For modern applications, UTF-16 is the worst of all worlds: it's no less complex to process than UTF-8, twice as large for ASCII characters (commonly used as control codes), and you have to deal with endian issues. As soon as it became clear that the BMP was not going to be enough and surrogate pairs were invented, the entire *raison d'être* for a 16-bit character type was lost. While obviously we still need to be able to convert strings to UTF-16 for compatibility reasons, we should not continue to repeat 20 year old mistakes by promoting the use of 16-bit chars in 2016.
&gt; Sizes are never negative, therefore sizes should be unsigned. http://stackoverflow.com/questions/10168079/why-is-size-t-unsigned TL;DR : Stroustrup thinks that having size_t unsigned was a mistake.
&gt; Incrementing the copy invalidates the data the input iterator points to, not the iterator itself. C++14 [input.iterators] table, expression `++r`: &gt; post: any copies of the previous value of `r` are no longer required either to be dereferenceable or to be in the domain of `==`. The guarantees you mention apply to `ForwardIterator`.
Oh boy, how I wish for the same thing to be integrated into Qt's QObject !
Actually returning error code and having int&amp; out parameter might be preferable because then something like this could be done in C++17 if (int val; stoi("123", val) == std::success) { ...
I really like **iso** as someone previously suggested, is there something that doesn't make it a viable candidate?
I was searching for something similiar and I didn't find anything better than fmt. For example spdlog library (which states to be the most performant logger) is using fmt. Another alternative is Boost, but as far as I knew, its performance is bad.
Initializer list constructors shouldn't be overloaded with other constructors with potentially similar parameters, e.g. vector(10, 20) shouldn't have a meaning which is different from vector{10, 20}. If we aren't going to get named parameters in the language to fix this, then let's have some sort of emulation such as vector(with_size(10), 20).
"Dynamic memory allocation for over-aligned data" I've been waiting for almost 10 years for this. Such a pain when working with SSE/AVX.
That is BS. Parts of the Qt API are great. Take the QStringRef integration for example or QString. Interacting with strings is a pain with the standard library but not with Qt. For both the standard library and Qt priorities were set up front that influence design. Qt has no allocators and exception guarantees while the std lib has. Both are valid approaches depending on the use case. I think the dislike/hate of Qt often found here is irrational given that Qt solves problems that the std lib does not and does that an platform independent way. Given the age and size of Qt there is of course a lot of cruft.
It's a bit buggy sometimes but it's still my favorite c++ IDE on linux. If you are used to visual studio and want a free alternative, give it a go.
Heck, even German is tricky with ß.
I really really really love "sl::" as somebody suggested. But "iso::" works too (even though I feel "sl::" conveys the meaning much better). Just please anything but "std2::". It's so... dirty. Plus, C++ is on the verge of being too verbose anyway. Having to type 5 characters before any stl call is a pain in the ass, and having to type 6 would be even more of a pain in the ass. Make the language as painless as possible, please. Also, how do you feel about CamelCase for the new stl? The same way Qt, Java, C# and co. do it, for example. Saves key strokes, saves on screen space, and people are used to it from other languages. sl::HashSet is, could be nicer than std2::unordered_set. While on the point, hell, even "sl::hash_set" beats "std2::unordered_set" by miles.
I have used allocators ... once. I use exceptions in my day to day code (usually std::runtime_error and my own library-level specializations).
Why did I never think of this?
Hope you didn't include *std::endl* in your test.
&gt; The problem is that if you have objects with a nested operator&lt; (i.e. you call operator&lt; on your members) then you end up with a LOT of unnecessary computations Is this any different from nested `compare()`? Anyways, comparer is provided as third template argument to `set` and `map`, just provide something different than `std::less` if you want custom behavior.
WTF is up with your parentheses? `( x )` wtf
For me, writing that line 1 million times to a file with #include &lt;fstream&gt; int main(int, char**) { std::ofstream out{"test.info"}; for (int i = 0; i &lt; 1000000; ++i) { out &lt;&lt; "Hello World.\n"; } } is faster (.075 sec runtime) than the C version (.120 sec) #include &lt;stdio.h&gt; int main(int, char**) { FILE *fp = fopen("test.info", "w"); for (int i = 0; i &lt; 1000000; ++i) { fprintf(fp, "Hello World.\n"); } } Or in other words iostreams are faster than C output ... (Using mingw and compiling with -O2) Output to the console (for 10k) is the same speed, but console output is limited by the console ...
Replace size_t with an unsigned index_t type, I want to enable warnings for implicit signed to conversion unsigned warnings with no extra effort on my part. Introduce short-hand type names for exact integer widths (e.g. i32, u32). Introduce unsigned integer types that are bit-compatible with signed types (like Ada) that can be checked for using static analysis. (e.g. u7, u15, u31, u63). Change trait names so that we dont have to add "::type", "::value", "_v" or "_t". Completely redesigned utf-8 string type / string span references. Generalize ownership, keep the "pointer/reference/id" representation outside of unique_ptr and shared_ptr. Rethink floating point libraries vs IEEE754-2008, IEEE1788-2015 and common SIMD architectures. Redesign STL, get rid of the bloat and tedium... :-P 
I use it, I rely on it, I love it. That said I've had problems with lining up everything using the same format. I switched to json to debug.
C++17 is trying to lessen the use of uninitialized variable (e.g. by replacing `A x; B y; tie(x,y) = f();` with `auto [x,y] = f();`). Out parameter kind of defeats its purpose.
&gt; Your approach requires either deep callstack tracking (and hence adds sizeable bloat and runtime overhead unsuitable to embedded or real-time applications!) or breaks apart in the face of generic code (e.g., all your allocations get tagged as belong to "vector" or somesuch, which is useless). No it doesn't. It works something like this: Memory_PushScope("AI"); // A bunch of code that allocates Memory_PopScope(); You can log callstacks in addition to this if you want. Or not. Anyway, this way you can track where the memory is going without making your programmers mess with allocators for every allocation, which is just madness. 
&gt; That is BS. Parts of the Qt API are great. &gt; Take [...] QString. QString is part of the problem: It uses utf16, at that point you shouldn't have to discuss it further. But okay let's take a look at [it](http://doc.qt.io/qt-5/qstring.html): * Way more methods than `std::string` and people are already complaining there. And while the methods on `std::string` are pretty much all more or less reasonable, Qt really adds everything it could think of: `toHtmlEscaped`, `toULong` (not `toU32` however, as that could have been usefull) * Copy on write, therefore hard to predict performance-requirements and guaranteed problems with multithreading * `int` as index-type. Way too small and can be negative, certainly a good idea… \s * The description of the static `QString::asprintf`-method is pure comedy: “Safely builds a formatted string [...] Warning: We do not recommend using QString::asprintf() [because it is not] type-safe.” * four versions of `operator[]`: mutable/const and int/uint, which prevents (but only on some plattforms) the use of `std::size_t` completely * Only one version of `.at()` however that also doesn't throw (IIRC it returns `'\0'`) and the returntype is a const value (WTF!!) * Their naming conventions are inconsistent with the stdlib, except when they are not: `push_back/push_front` (there is not even `pushBack()`) Do I have to go on?
&gt; The stdio.h application executed in 4 seconds where the iostream executed in 12 seconds. This can depend on many things; In particular, make sure to disable synchronization with stdio. It is also not very useful, as the use case of writing hello world repeatedly is different than the use case in your application. &gt; I have to ad that iostream.h is much easier to use, and I really like it! So do I :) &gt; There has to be a balance somewhere I don't know about or realize so I can continue to get the speed I need am used to. Here's a tautology: Outside of the cases where performance matters, performance doesn't matter. If you fear performance may be slow, take a concrete decision of where you want your performance to be, then measure (for example, "I want 20 reports printed in one second"). Then measure, identify bottlenecks, and work on those. It may be that you will get the performance you need by splitting the output code in two functional parts, and running them in parallel (instead of giving up iostreams).
There are two binary formats: 0. `cereal/archives/binary.hpp` 0. `cereal/archives/portable_binary.hpp` The latter has slightly more overhead but is endianness-agnostic.
Thanks for the links. The results from the second link are interesting. Nitpicking, I know but, the graphs shown at the first link ([https://github.com/thekvs/cpp-serializers](https://github.com/thekvs/cpp-serializers)) do have a arbitrary scales. They show just ranks. Those graphs transport a misleading image of fast they are or how large the data is, compared to each other. Sure they have nice colors, but aside from that, they are useless. 
Isn't that a stack allocator?
I'm going to add an ELI5 version. Say I have a collection of shapes I want to draw. I create a base class called Shape that has a virtual draw() method. Now, I create a Circle class, a Rectangle class, and a Triangle class. Each class inherits from Shape and implements its own draw() method. Now, if I have a collection of Shape pointers, I can just draw() each one, and it will call the appropriate draw() method for the specific shape. e.g. Shape* myShapes[3]; myShapes[0] = new Rectangle(); myShapes[1] = new Circle(); myShapes[2] = new Triangle(); for (int i = 0; i &lt; 3; i++) { // Huzzah! we call the derived draw() method for each shape. myShapes[i]-&gt;draw(); }
It was meant to be in reference to most replies on this discussion as they don't seem to relate to `std::allocator` at all.
I don't remember when i started using this or where i picked it up but I have this used extensively in my codebase, never needed any advanced features and this works perfectly fine. #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;cstdlib&gt; #include &lt;memory&gt; template &lt;typename ... T&gt; std::string StringFormat(std::string fmt, T ... args) { int len = snprintf(nullptr, 0, fmt.c_str(), args ...) + 1; std::unique_ptr&lt;char&gt; buffer(new char[len]); snprintf(buffer.get(), len, fmt.c_str(), args ...); return std::string(buffer.get(), buffer.get() + len -1); } int main() { std::cout &lt;&lt; StringFormat("%s: %d\n", "meaning of life", 42) &lt;&lt; std::endl; return 0; } http://ideone.com/eKSMrc
First of all I was talking about more than 2 billion characters which is not 2GB in QString since it uses uchar as a character. Secondly _you_ implied that 2GB strings is "on the small end" of things in your daily work. Using QString there would be stupid! It obviously was not designed for such use cases as can be seen by the size being an int, which is 32 bit on most platforms. I never told you what to use, neither did I imply anything which you did not wrote _yourself_. So don't act like an idiot!
how about ...stl::. 
Thanks. :)
The problem is not unsigned types, the problem is implicit conversions. Implicitely converting an int to an unsigned int is a mistake. 
We tried and got the same coherency as if we were developing a C++ project from scratch trying to match code to UML class diagrams. Everybody was fired and we went bankrupt.
I prefer Xcode over all other IDEs, but [Netbeans](https://netbeans.org/) is pretty good on Linux. It seems that many Linux guys prefer just using the command line and Makefiles to build their stuff, no IDE.
The cool kids these days apparently use `lldb` which is pretty similar. Also, in some ways, `gdb` is easier than XCode, once you learn how to get a session going - because it's really stripped down and you only have a command line to enter commands. But to answer your question directly! Up until recently, there were _no_ full-featured IDEs on Linux. I personally just use a powerful text editor (emacs), print statements and very occasionally the debugger (but I think the last time I fired up a debugger was over a year ago). If you are willing to start slow and get better, you can get VERY fast with a combo like that. I mean, I've been developing on this Mac laptop for almost two years now, and I have _never_ used any Apple development tools even one time - only tools that I can use identically on Unix. However, today you can also get IDEs. Eclipse has a free IDE as part of its huge suite. Last time I checked it out, it was dreadful but that was quite a few years ago and I hear it's improved a lot. Certainly the price is unbeatable. A new one from JetBrains is called CLion. I tried the demo and it was excellent - quite amazing really. You have to pay but it really isn't very expensive considering what you get. Also, there are student prices I think. If you're serious about this, I'd bite the bullet and get CLion. I'll bet it'll pay for itself in a week with increased productivity, and more, in "undaunting" you and lowering your stress level considerably. :-)
QtCreator is a fine IDE, even if you're not using Qt. It has decent GDB integration, too.
&gt;Up until recently, there were *no* full-featured IDEs on Linux. You've never heard of QtCreator?
Given the number of times I have seen people try that instead of std that is a good idea. 
Yay!
Because UTF-32 doesn't really buy you anything; you still need to deal with the problem that splitting the string blindly is not safe. Sure, you won't cut a code point in half; but in the presence of combining characters you could cut off parts of the character the user is using. Sure, for "most european languages" you can just put things in to Normalization Form C first, but there are cases where NFC doesn't combine everything. Since in Unicode land you never have the assumption that 1 encoding unit == 1 physically displayed character, the additional mess brought on by UTF-8 and UTF-16 aren't that big a deal.
Yes, I have of course - checking it out as it is now, it certainly seems very matured. The last time I saw it, it definitely didn't understand C++ at all, let alone modern C++... can you tell us more about its advantages w.r.t. CLion?
Why would there be any difference?
Yeah, but to improve C error handling we really need: scope_exit CleanupStatement; E.g. for freeing resources on early return from a function.
Sorry, reading it back that comment was a little more flippant than I intended. As to the advantages of QtCreator... well the main one of course is that it's free, and CLion is not. It goes without saying that it has first-class support for Qt, although it's still very useful for general C++ too. It supports multiple build systems via plugins, whereas CLion only supports CMake. I've found it to be more responsive than CLion, particularly with lots of files open. Now having said all that, I actually use CLion day-to-day in OS X. But when I boot up in Linux I use QtCreator, mostly because the Java toolkit that CLion uses doesn't (yet?) support high-dpi screens on Linux, so everything is unusably small on my retina MBP.
In C, one can go from members to containing structs using `offsetof`. However, in C++ `offsetof` only works on [standard layout types](http://en.cppreference.com/w/cpp/types/offsetof), which the standard library's `list_node&lt;T&gt;` class typically isn't, since it usually derives from some `list_node_base` class that holds the `prev`/`next` pointers. So there is a technical language barrier, although in practice it can be overcome.
Yes please ! I'm in dire need of a **fast** algorithm to find the intersection of two tetrahedra. CGAL does claim to have this, but if you come up with something even marginally faster it will be awesome.
Is there a way to make Cereal recognize input file types? Currently, if you deserialize data that is NOT the correct type, then Cereal crashes. If the two types have the same size but have different formats, then it tries to deserialize anyway. Is there a workaround?
Not for writing to a file.
&gt; it was not a bad decision back then. And that includes Qt which is quite old. Btw. I wonder what that has to do with API ... Age is an explanation but it doesn't change that the API is very bad by modern standards. And since I want to write code today (and not twenty years ago) that is the metric by which I will judge. &gt; Number of methods is not an issue rather their usefulness. you seem to listen to different people than me, this is *the* major complaint about `std::string` &gt; String operations on QString are easy to understand and use. Just replacing something in a QString is very easy. Similarly QString::mid or now QString::midRef are very useful. The problem is not a method to replace something, the problem is that there are countless methods that should definitely be free functions! &gt; I hate implementing such basic functions myself with std::string or relying on external libraries like boost for a mundane task like this. You mean using a very speaking `str.substr(3, 4)` instead of an extremely badly named `str.mid(3,4)` &gt; Copy on write, therefore hard to predict performance-requirements and guaranteed problems with multithreading &gt; &gt; In practice this was never a problem for me. I am still waiting for a recent article that actually shows this to be an issue. The article by Herb Sutter is very old and has no relation with Qt. &gt; &gt; int as index-type. Way too small and can be negative, certainly a good idea… \s &gt; &gt; Ridiculous. When you have QStrings with more than 2 billion characters you have another problem. My laptop has 8GB of RAM even though it is several years old. Notebooks with something like 32 or 64GB are available today. It is certainly reasonable to assume that a well-designed string-type should be able to hold 2/4GB in that environment, which should be pretty easy to get with biological sequences. Granted: Because QString uses a horrible encoding it would be a non-starter there much earlier, but that only adds to why it is horrible. &gt; Also IIRC on the panel of CppCon there was a discussion about the signedness of size types and there they said using unsigned was a mistake &gt; Ah found a mention: http://stackoverflow.com/questions/33257436/int-vs-unsigned-int-vs-size-t I am aware of those opinions and I disagree with them. Especially since `-Wconversion -Wsign-conversion` solves most of the issues. &gt; The description of the static QString::asprintf-method is pure comedy: “Safely builds a formatted string [...] Warning: We do not recommend using QString::asprintf() [because it is not] type-safe.” &gt; &gt; So the documentation could be improved and the function replaced with one using variadic templates. Not a big deal imo. Such a method simply should never have been there that they replaced it with other methods shows just more that it, if anything, should have been a free function from the start. &gt; four versions of operator[]: mutable/const and int/uint, which prevents (but only on some plattforms) the use of std::size_t completely &gt; &gt; Why would you use std::size_t there when the Qt API uses int? Because you might be in a codebase that uses sane containers as well and you might want to use the same indeces? &gt; And what are these platforms, is it an actual problem there? Such highly obscure and unrelated ones as x86 (`size_t` works) and x86_64 (`size_t` doesn't work) &gt; Only one version of .at() however that also doesn't throw (IIRC it returns '\0') and the returntype is a const value (WTF!!) &gt; &gt; So what? You remember my post that they do not use exceptions right? Then return an optional, a pointer or something similar. Or don't offer the method at all (which may have been the best thing). Not using exceptions is of course one of the reasons why the QT-API is so full of shit. Of course, even ignoring all those issues, what I refered to with WTF is specifically returning a const object by value. There are exactly zero situations in which this makes any sense, at best it is just pointless (likely the case here). &gt; Their naming conventions are inconsistent with the stdlib, except when they are not: push_back/push_front (there is not even pushBack()) &gt; &gt; Qt is older than the stdlib. These methods were just added to be compatible with std algorithm. Is it? If anything, it might be older than the STL. &gt; &gt; Do I have to go on? &gt; &gt; So far most what I read are minor nitpicks or simply incorrect stuff. Qt solves localisation issues for me where stdlib make life very hard. Are you switching the topic? I thought you wanted to talk about QString. 
1. `vector&lt;bool&gt;`. As soon as you specialize and cause a *behaviour change*, you are in trouble. If I, as a programmer, request a optional of T* by typing "optional&lt;T*&gt;", give me exactly what I asked for. Trust the programmer. If a carpenter wants to hit a screw with a hammer, don't turn the hammer into a screw-driver because the nail is a screw. Trust that the carpenter has a reason to hit the screw with a hammer. One _possible_ use: There are times you want to differentiate between "the value is null" and "there is no here, here". ie an API that looks things up by name: optional&lt;Date *&gt; getDateField(string fieldname); auto odp = getDateField("endDate"); if (odp == nullopt) { // ERROR - "endDate" isn't a field at all (Or not of type Date?) // database corruption? programmer error? log(....); throw ...; } if (*odp == nullptr) { // no end date // assume day-long meeting meeting.setDayLong(true); } else { meeting.setEnd(**odp); } Not saying that is a beautiful API (maybe optional isn't the best way to handle errors), but we need to trust the programmer that they have reasons (or are just stupid, but we aren't going to guess how to fix their designs for them). Maybe a better example is writing something like a Sanitizer that tracks all the pointers in a program. You may need to differentiate between an uninitialized pointer and a null pointer. (You probably have lots of other state you'd want to track, so optional wouldn't be enough, but I'm sure there is an example out there somewhere.)
OK, but even if regex was UTF-8 aware, a regexp '...' could still match one character, or even less than one character, due to combining characters.
Unicode everywhere. Revise from top to bottom how error handling works so it's all standardized. Right now it's a hellish mishmash, and some things neither report an error OR throw an exception. They just segfault. (Looking at you, popping off an empty STL stack.) In an ideal world, I'd be able to specify which error system I want. Redo random_shuffle so that it's not so stupidly absurd you need to Google it every time. This one actually got worse in recent revisions. Just specify a sane default PRNG. From top to bottom think about compiler error messages and what could be done to make them more understandable to new programmers. This is honestly the biggest problem with the STL. You make a minor mistake, and get nine million lines of error messages that mean absolutely nothing to a newbie. I'm actually working on a project right now to make C++ more newbie friendly, but it would be REALLY nice to have actual support from the language itself instead of fighting it. 
Your analysis looks right to me. See N4582 22.4.1.4 [locale.codecvt]/3: &gt;`codecvt&lt;char, char, mbstate_t&gt;` implements a degenerate conversion; it does not convert at all. The specialization `codecvt&lt;char16_t, char, mbstate_t&gt;` converts between the UTF-16 and UTF-8 encoding forms, and the specialization `codecvt &lt;char32_t, char, mbstate_t&gt;` converts between the UTF-32 and UTF-8 encoding forms. `codecvt&lt;wchar_t,char,mbstate_t&gt;` converts between the native character sets for narrow and wide characters.
The scoped allocators are a nice approach for very general allocations. They fall apart when you have a structure that needs to sub-divide its allocations, or when you have things like vector::push_back to an existing allocation (since the C++ allocator interface has no knowledge of resize, which again brings us back to STL allocator shortcomings). I'll partially concede. I do like the scoped allocation zone approach. I just think you're generalizing too much. :)
Yeah, there's a bazillion names for these things.
Looks very very interesting. Nice.
And a nice clang tools/valgrind/calgrind/cmake integration too.
I'll never understand posting a video on youtube that shows someone coding. It's frustratingly slow and inefficient, so here's a tl;dw: #include &lt;functional&gt; void f(int i); struct S { int v = 6; void g(int i); }; int main() { S s; S* p = &amp;s; std::invoke(f, 3); // f(3) std::invoke(&amp;S::g, s, 4); // s.g(4) std::invoke(&amp;S::g, p, 5); // p-&gt;g(5) std::invoke(&amp;S::v, s); // s.v } 
Well 1st is not the right way C++ string are different from C strings, so that shouldn't be done (from what I understand) std::string is string + length not null delimited string. 2 is probably right.
&gt;&gt; it was not a bad decision back then. And that includes Qt which is quite old. Btw. I wonder what that has to do with API ... &gt;Age is an explanation but it doesn't change that the API is very bad by modern standards. And since I want to write code today (and not twenty years ago) that is the metric by which I will judge. I still fail to see what that has to do with the API, which is what we are talking about. &gt;&gt; Number of methods is not an issue rather their usefulness. &gt;you seem to listen to different people than me, this is *the* major complaint about `std::string` And you think you can apply `std::string`'s issues directly to QString? Btw. a source would be nice, just for reference. &gt;&gt; String operations on QString are easy to understand and use. Just replacing something in a QString is very easy. Similarly QString::mid or now QString::midRef are very useful. &gt;The problem is not a method to replace something, the problem is that there are countless methods that should definitely be free functions! Who says what should be a free function or not. Only because some people (e.g. Sean Parent) like free functions does not mean that this is a general rule. Neither does it mean that member functions are bad. I would say it is a matter of taste. &gt;&gt; I hate implementing such basic functions myself with std::string or relying on external libraries like boost for a mundane task like this. &gt;You mean using a very speaking `str.substr(3, 4)` instead of an extremely badly named `str.mid(3,4)` Got me there, comment on replace still holds though. &gt;&gt; Copy on write, therefore hard to predict performance-requirements and guaranteed problems with multithreading &gt; &gt; In practice this was never a problem for me. I am still waiting for a recent article that actually shows this to be an issue. The article by Herb Sutter is very old and has no relation with Qt. &gt; &gt; int as index-type. Way too small and can be negative, certainly a good idea… \s &gt; &gt; Ridiculous. When you have QStrings with more than 2 billion characters you have another problem. &gt;My laptop has 8GB of RAM even though it is several years old. Notebooks with something like 32 or 64GB are available today. It is certainly reasonable to assume that a well-designed string-type should be able to hold 2/4GB in that environment, which should be pretty easy to get with biological sequences. Granted: Because QString uses a horrible encoding it would be a non-starter there much earlier, but that only adds to why it is horrible. Why draw the line at 4 GB? I could use the same argument in favour of int64 as size_t. "Why it is horrible" ... nothing of what you wrote so far shows that it actually is horrible. &gt; &gt; Also IIRC on the panel of CppCon there was a discussion about the signedness of size types and there they said using unsigned was a mistake &gt;&gt; Ah found a mention: http://stackoverflow.com/questions/33257436/int-vs-unsigned-int-vs-size-t &gt;I am aware of those opinions and I disagree with them. Especially since `-Wconversion -Wsign-conversion` solves most of the issues. But you used that as argument against QString, even though people like Bjarne Stroustrup, Herb Sutter, Chandler Carruth etc. actually say that what stdlib does was wrong. But yeah, I suppose Qt is also "horrible" there. &gt;&gt; The description of the static QString::asprintf-method is pure comedy: “Safely builds a formatted string [...] Warning: We do not recommend using QString::asprintf() [because it is not] type-safe.” &gt; &gt; So the documentation could be improved and the function replaced with one using variadic templates. Not a big deal imo. &gt;Such a method simply should never have been there that they replaced it with other methods shows just more that it, if anything, should have been a free function from the start. Free function argument again. If that is is such a big deal it shows that QString is actually pretty good. &gt;&gt; four versions of operator[]: mutable/const and int/uint, which prevents (but only on some plattforms) the use of std::size_t completely &gt; &gt; Why would you use std::size_t there when the Qt API uses int? &gt;Because you might be in a codebase that uses sane containers as well and you might want to use the same indeces? "Sane containers", wow what an argument. Are you trolling? &gt;&gt; And what are these platforms, is it an actual problem there? &gt;Such highly obscure and unrelated ones as x86 (`size_t` works) and x86_64 (`size_t` doesn't work) And is it a problem? I would say no, since compilers catch it. Moreover the API relies on int, so why use size_t in the first place. &gt; &gt; Only one version of .at() however that also doesn't throw (IIRC it returns '\0') and the returntype is a const value (WTF!!) &gt; &gt; So what? You remember my post that they do not use exceptions right? &gt;Then return an optional, a pointer or something similar. Or don't offer the method at all (which may have been the best thing). Not using exceptions is of course one of the reasons why the QT-API is so full of shit. Or maybe RTFM? "full of shit" another great argument. Btw. using operator [] can lead to undefined behaviour for both std::string and QString. Are both now "full of shit" for not using exceptions there too. Or maybe is RFTM suddenly ok there? &gt;Of course, even ignoring all those issues, what I refered to with WTF is specifically returning a const object by value. There are exactly zero situations in which this makes any sense, at best it is just pointless (likely the case here). That is not true. Even Scott Meyers mentioned that in some cases returning a const value makes sense. Tip 3 in 3ed edition of Effective C++. Yes that was before moving, which makes no difference here, since it is a primitive type. You can't act as if there was no use case for that: `my_str.at(3) = ch;` fails because a const value is returned. You see, I use sources instead of just name calling APIs. You might have heard of that concept. &gt;&gt; Their naming conventions are inconsistent with the stdlib, except when they are not: push_back/push_front (there is not even pushBack()) &gt; &gt; Qt is older than the stdlib. These methods were just added to be compatible with std algorithm. &gt;Is it? If anything, it might be older than the STL. Qt developement started in 1991 (wikipedia). I have no experience pre Qt3 and don't want to dig into that any deeper. Clear is that Qt has a very long history. &gt;&gt; &gt; Do I have to go on? &gt; &gt; So far most what I read are minor nitpicks or simply incorrect stuff. Qt solves localisation issues for me where stdlib make life very hard. &gt;Are you switching the topic? I thought you wanted to talk about QString. QString and QStringRef, the latter was completely ignored by you. Not switching, but QString's UTF-16 support makes localisation related tasks easy. Just take toUpper and toLower.
Make an effort to learn at least some GDB. You never know when you'll be trying to fix a problem remotely, on some embedded device, or some other situation where you don't have access to a UI, only a terminal. GDB is pretty much the only answer then. Learn to set some breakpoints, step through code, print out variables and memory locations, etc. That'll go a long ways in your career.
The answer is no, because that would break every program using any part of the standard library. That or they would have to create new language features like overriding or undefining namespace aliases (if they were to go the route of a default `namespace std = std1` that you would have to change).
There is active work on this by several parties, it just wasn't ready in time for C++17. It will catch the next train in all likelihood, which will probably be a library TS.
I personally find that using :make from inside vim is much more productive than executing it in a separate shell. :make will automatically put your cursor where the error is.
In essence, yes. With structured bindings you get *one* variable defined the way you write the "auto" bit. So if you write "const auto &amp;" you get one variable that is lifetime extended. The names are then bound to the pieces of that variable, but the variable continues to exist as a thing. All this does is provide a way to name pieces of the variable rather than the variable as a whole because it turns out we really commonly want to do exactly that.
I'm a big fan of Clion from JetBrains. It is my daily IDE for linux. It is commercial, through free for a year for students with a .edu address. The only downside is it exclusively supports CMake as a build system. That puts some people off. 
U+0000 is a valid Unicode code point though.
Learn Vim. I've used IDEs for 5 years, emacs for 5 years and Vim since 5 years and it's worth it. If you like the pre-configured axiom, try yavide: https://github.com/JBakamovic/yavide Use a tiling windows manager, like notion, i3, xmonad or whatever. Use a fast terminal, like urxvt, and configure it so that a click on an error jumps to it il Vim (fearly easy with urxvt). Color the compiler output with colout: http://nojhan.github.io/colout/ You can easily leverage the power of the command line for profit. Want to be notified if a build takes too long? A piece of cake, plus it works for any command (tests, anyone?). gdb is worth the try, too. I've been sticked to some of its GUI for years and I d eply regret it now that I've taken some time to learn it. Make your own cmake script, it's easier and more powerful than having to find options in Eclipse. Use build scripts in shell, for funky automatizations.
If you're a student, you can likely get clion for free.
OMG SO EXCITED! No I'm not.
Regarding the 1st suggestion, it would have been undefined behavior in C++98, but in C++11 `std::string` is guaranteed to be contiguous, so it's perfectly fine.
I got the constant console windows, but other than that it was fine. Though maybe that's because I'm on an SSD. Still took around half an hour.
That's coming in two weeks, building up to it.
A minute into the update, I decided to cancel it and update later. Who knows how long later, it's still updating while "Stopping current session", it makes me just want to kill the process in the task manager.
The question is whether optional&lt;T&amp;&gt;'s assignment should "rebind" the reference, or assign "through" the reference. Consider this case: Foo foo; optional&lt;Foo&amp;&gt; orf = bar.getOptionalFooRef(); Maybe orf now refers to some Foo inside bar, say bar.someFoo. Or maybe orf is nullopt. Now do this: orf = foo; // ** Does orf now refer/point to foo (rebind), or does it still refer to bar.someFoo, and we just assigned "through" the reference, effectively `bar.someFoo = foo` ? Does it matter whether orf was nullopt before this line? Or does it always rebind? Now consider this RefLike class template: template &lt;typename T&gt; class RefLike { T * ref; public: RefLike(T &amp; r) : ref(&amp;r) { } RefLike &amp; operator=(T const &amp; val) { *ref = val; } }; The above is how a reference works (give or take). On construction, it binds to the incoming reference. On assignment it assigns _through_ the reference. Now consider an optional&lt;RefLike&lt;T&gt;&gt;. Since RefLike&lt;T&gt; is like T &amp;, optional&lt;T&amp;&gt; should work like optional&lt;RefLike&lt;T&gt;&gt;. In particular: Foo foo; optional&lt;RefLike&lt;Foo&gt;&gt; orf = getOptionalRefLikeFoo(); orf = foo; Now it should be clear that orf binds to foo if orf was nullopt, but we get bar.someFoo = foo if orf was previously bound. Is that surprising? Did you want it to always rebind? ie Would you prefer optional&lt;reference_wrapper&lt;T&gt;&gt; behaviour? - (reference_wrapper always rebinds, thus reference_wrapper is not like T &amp;, which is kinda the point of reference_wrapper) If you find optional&lt;RefLike&lt;T&gt;&gt; to be surprising, and you instead want always-rebind optional&lt;reference_wrapper&lt;T&gt;&gt;, your logic is essentially &gt; "T &amp; does _not_ work like reference\_wrapper, so optional&lt;T&amp;&gt; _should_ work like optional&lt;reference_wrapper&gt;" I find that logic to be not. Basically optional only works "sanely" with Regular types. T &amp; is not Regular, so you shouldn't be surprised when optional&lt;T&amp;&gt; is not Regular. We shouldn't specialize the _behaviour_ of optional&lt;T&amp;&gt;. It should work "as expected" when you logically combine the behaviour of optional with the behaviour of T&amp;. We could specialize the storage (the boolean could be replaced by pointer == nullptr in this case as references can't be null), but we shouldn't specialize behaviour. vector&lt;bool&gt;. If the behaviour of optional&lt;T&amp;&gt; is surprising, don't type it. Type the behaviour you want. Like optional&lt;reference_wrapper&lt;T&gt;&gt; or whatever it is. Mean what you say, say what you mean. 
Nice job trawling through my GitHub repositories until you found some bad code. You chose a really poor example though: that's actually pretty good in C++ terms, all thing considered. Here's a much better example: #ifndef AA_ADAPTIVE for (int k = 0; k &lt; AALEVEL; k++) { xaa = x1 + (2*k + 1)*halfPixelSize/AALEVEL; for (int l = 0; l &lt; AALEVEL; l++) { yaa = y1 + (2*l + 1)*halfPixelSize/AALEVEL; #else xaa = xc; yaa = yc; #endif Vector dir(xaa, yaa, -EDIST); //direction of the primary ray dir.normalise(); //Normalise this direction #ifdef AA_ADAPTIVE col.combineColor(trace (eye, dir, 1), 1.0f); //Trace the primary ray and get the colour value #else col.combineColor(trace (eye, dir, 1), 1.0f/(AALEVEL*AALEVEL)); //Trace the primary ray and get the colour value } } #endif Or perhaps: for (int i = 0; i &lt; widthInPixels-1; i++) { for (int j = 0; j &lt; heightInPixels-1; j++) { int counter = 0; float diff00r01 = abs(colours[i][j].r - colours[i][j+1].r); float diff00r10 = abs(colours[i][j].r - colours[i+1][j].r); float diff00r11 = abs(colours[i][j].r - colours[i+1][j+1].r); float diff01r10 = abs(colours[i][j+1].r - colours[i+1][j].r); float diff01r11 = abs(colours[i][j+1].r - colours[i+1][j+1].r); float diff10r11 = abs(colours[i+1][j].r - colours[i+1][j+1].r); diff00r01 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff00r10 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff00r11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff01r10 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff01r11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff10r11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; float diff00g01 = abs(colours[i][j].g - colours[i][j+1].g); float diff00g10 = abs(colours[i][j].g - colours[i+1][j].g); float diff00g11 = abs(colours[i][j].g - colours[i+1][j+1].g); float diff01g10 = abs(colours[i][j+1].g - colours[i+1][j].g); float diff01g11 = abs(colours[i][j+1].g - colours[i+1][j+1].g); float diff10g11 = abs(colours[i+1][j].g - colours[i+1][j+1].g); diff00g01 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff00g10 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff00g11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff01g10 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff01g11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff10g11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; float diff00b01 = abs(colours[i][j].b - colours[i][j+1].b); float diff00b10 = abs(colours[i][j].b - colours[i+1][j].b); float diff00b11 = abs(colours[i][j].b - colours[i+1][j+1].b); float diff01b10 = abs(colours[i][j+1].b - colours[i+1][j].b); float diff01b11 = abs(colours[i][j+1].b - colours[i+1][j+1].b); float diff10b11 = abs(colours[i+1][j].b - colours[i+1][j+1].b); diff00b01 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff00b10 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff00b11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff01b10 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff01b11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; diff10b11 &gt; ADAPTIVE_THRESHOLD ? counter++ : counter; if (counter &gt; ADAPTIVE_COUNTER_THRESHOLD) adaptiveAA.push_back(std::pair&lt;int,int&gt;(i,j)); } } Of course, all the code we're talking about was written for a university project, the last two parts were from me implementing adaptive antialiasing from scratch in approximately the last 15 minutes before the due date, all of which was over 2 years ago. Mind your own damn business.
Does your optional treat optional&lt;T&amp;&gt; like optional&lt;reference_wrapper&lt;T&gt;&gt;, or does it work "correctly"? ie does it always rebind on assignment, or only when the optional was already empty? If the optional is already bound, does it assign through the reference?
&gt; Mind your own damn business. Then don't stomp around reddit snidely quipping "you're wrong". Seriously. What did you think was going to happen? (And nice cherry-picking code that happens to have names all similar lengths so they all almost line up nicely.) Have fun minding your own business! :)
I hadn't seen this paper; I like this much better than `operator.()`, to be honest. It feels less like a hack, and it doesn't fill me with the same faint uneasiness.
I saw they had something with Visual Studio "15" that improved the installer. It feels like they just really let go with the current one. 
Exceptions for failed memory allocations don't make any sense. Being out of memory isn't an exceptional situation. This is how I would do it: template &lt;typename F, typename=std::enable_if_t&lt;std::is_callable_v&lt;F&gt; &amp;&amp; !std::is_nothrow_callable_v&lt;F&gt;&gt;&gt; void *allocate(F&amp;&amp; f) { ... if (it_worked) return p; else return std::invoke(f); } template &lt;typename F, typename=std::enable_if_t&lt;std::is_nothrow_callable_v&lt;F&gt;&gt;&gt; void *allocate(F&amp;&amp; f) noexcept { ... if (it_worked) return p; else return std::invoke(f); } void *allocate() { return allocate([] { throw std::bad_alloc("Bad allocation"); }); } void *allocate(std::nothrow_t) noexcept { return allocate([] noexcept { return std::nullptr; }); } void *allocate(log_and_abort_t) noexcept { return allocate([] noexcept { std::clog &lt;&lt; "Failed to allocate." &lt;&lt; std::endl; std::terminate(); }); } void *allocate(std::error_code&amp; ec) noexcept return allocate([] noexcept { ec = std::make_error_code(std::errc::not_enough_memory); return std::nullptr; }); }
You can blame ECMAScript and `std::locale` for that one.
Yeah, I see a lot of people swear by it as their IDE of choice. I'll give it another shot eventually. Now I'm just waiting for JuCi++.
Oh didn't know that, hold my my beer I have lots of code to patch.
Almost. You can use :make -C .. You can find some tips here: http://stackoverflow.com/q/729249/951890
The top answer there is a good one. It may take care of my particular use cases. Thanks!
The suggested resolution to LWG2471 is fundamentally wrong. It solves a general problem - the fact that many `_n` algorithms do not return the input iterator - only for `istream_iterator`. The proper solution is to correctly increment the iterator `n` times and return the final iterator value.
I take it you don't do any form of embedded programming then.
This is exactly the reason why I suggested "stl" in LEWG. Yes, it's wrong, but why keep fighting?
Visual Studio updates have always been a nightmare to install.
This is particularly daft as further down the it mentions that &gt;Go language takes an approach of favouring value types ... when the value types are used a null pointer exception is not possible and yet fails to mention that C++ takes the approach of favouring value types, too...
The RC repeatedly broke the VS on both my laptop and office workstation. Let's see how the official bits fare.
Clion is good but one thousand times qtcreator over netbeans
Visual Studio really is rubbish software. I really cannot understand why anyone would want to use it. Terrible C++ compiler (nice two-phase lookup, oh wait still not there after 18 years), terrible C compiler (doesn't even support C99 yet, let alone C11) and more toolbars than an early 2000s shared primary school classroom copy of Internet Explorer. It takes forever to install, it takes forever to update, it takes ages to start. I still don't know why people consider it to have a good debugger: the other debuggers out there must be pretty crap if Visual Studio's debugger is the best. Yet I'll get super heavily downvoted for saying this, because Windows developers are *so* butthurt whenever someone criticises Windows or anything that comes out of Microsoft. They even defend .NET Core's spyware with "oh you can turn it off!", these people.
Give VS Code a shot with the C++ extension.
They probably have lots of unrealistic text that is just loads of east asian characters without a ton of html tags.
You can absolutely meaningfully test doubles for equality, and anyone that tells you that you can't completely misunderstands floating point.
I've done embedded programming. I get what you are saying, that exceptions aren't always supported. But in embedded programming you are also less likely to use an allocator. You would instead have a designated memory range. The important thing about OOM throwing is you almost certainly cannot recover from an OOM. Killing the process is almost certainly your best option. You cannot continue. And what would you even gracefully handle??
Took about 40mins for me to install ,wasn't really all that bad. After installing, rebooting, updating extensions, manually running ngen, it probably took a little over an hour all together. Version 3 is amazing. It use to take me 20 seconds to launch visual Studio and now it takes only 5. Everything about it is much faster . ------------------------------- EDIT: It's pretty good because Update 2 took like 3-4hrs and VS2015 is slow as hell. It has practically cut my productivity in half coming from 2013. But Update 3 is a major improvement and I can actually get things done and it seems to be able to keep up with my typing inside 6000+ line files. Copy and pasting into one of these files no longer takes several seconds anymore. And I can launch it in a decent amount of time. Before this opening a solution with 19 projects, from launch to usable, took between 2-5 minutes with Resharper enabled and roughly 30-40 seconds without Resharper. There has been a major improvement. That's on an i5 Laptop (2c4t, 2ish to to 3Ghz turbo) with a Samsung 950 nvme SSD. My desktop launches it in about half the time on a 4.4Ghz i7 with a Samsung 850 512GB for OS, Samsung 840 256GB for Repos/Documents, Crucial m4 256GB for Temp/PageFile/Hiberfile/etc. 
I only undertake doped C++ libraries of the 14'th persuasion.
There are cases where we are told to allocate memory for bytes to comes (over a network, or whatever). If the data is corrupted, we can be asked to allocate -1 bytes. Memory allocation will fail. While detecting -1 is easy, having a precise threshold for what is valid or not may not be that easy. The fact that `new` throws, instead of crashing the application, offers some kind of defensive programming: we have the possibility to notify something to the user, and sometimes to continue in these situations.
SQLite is an example of software that is written to handle OOM.
&gt; If the data is corrupted, we can be asked to allocate -1 bytes. Memory allocation will fail. ... if you don't check what you have been asked to allocate. "Corrupted data" here really means "I didn't check the input validity". Also, if the input is "unstable", then the use of mitigation techniques is on order (e.g. checksums).
&gt; Yet I'll get super heavily downvoted for saying this, because Windows developers are *so* butthurt whenever someone criticises Windows or anything that comes out of Microsoft. I'm downvoting you because you spout opinion as though it was fact. I criticize MSFT all the time, and _especially_ VS and VC++ (hence my no longer being a VC++ MVP), but I don't say statements of "fact" like "*Visual Studio really is rubbish software.*" _You_ get downvoted because you're incendiary, mostly wrong, and trollish.
&gt; stdint.h, declaration in the middle of the block, struct initializers with labels. Seeing that the post was made in **2011**, I decided to test the stuff that were mentioned: http://rextester.com/ONEKPV51564
Nicely documented, one thing that I like is when such libraries have an implementation of the git CLI to showcase the usage.
&gt; Why not provide an allocator that makes the decision? You are right, this is possible. But it makes generic code hard: template &lt;class Alloc&gt; void do_sth(Alloc &amp;alloc) { auto mem = alloc.allocate_node(...); // eh, do I have to check mem now? }
While I still advocate for learning your GDB, keep in mind you can always debug remotely from whatever fancy IDE strikes a chord for you.
Compiling seems to fail on OS X when I run cmake as is. It seems DOCTEST_BREAK_INTO_DEBUGGER is undefined when compiling the tests. For now, just modifying the cmake options file to disable building them lets it go through. Make install doesn't work either, so I just copied what seemed important. I never use cmake so perhaps I'm just being dumb with it. Anyways, I'd be interested to try this out with some simulation code I work on to ease some runtime mix-and-matches.
A valid checksum doesn't mean a valid input unfortunately -- I had the case once of a bugged peer that send (CCSDS) packets of officially too many bytes (like -1 converted back to a unsigned value) after the header, and they had a valid CRC. But of course, I agree that checking the input validity is what must be done. But then, was is a valid threshold? And can we always be sure that valid thresholds (regarding the domain) are always under the limit of what the system can offer us. In other words, sometimes we don't take the time to properly analyse whether we can load everything in memory or process subsets of the complete data.
Suppose r,x,y, and z are all bigints. Given that there is a mpz_class class, you'd think you could just do something like this: r = x ^ y % z, and it would work (hopefully with the compiler doing a powm instead of a pow followed by a modulus), but worst case scenario you should just be able to pass them to a powm function. But you can't. Because it's not really a C++ library. It's a C library with some C++ window dressing that then has to get stripped away if you want to use it for anything. So your code ends up looking like this barrel of diarrhea: mpz_powm(r.get_mpz_t(), x.get_mpz_t(), y.get_mpz_t(), z.get_mpz_t()); (I'm not ranting at you, just ranting because gmpxx annoys me a hell of a lot.)
Fair enough. Still, you can do this http://cpp.sh/8y7l .
You are right the CUDA 8.0 RC supports VS 2015 Update 1. In case one has already installed Update 2 (or 3) it is possible to uninstall it and use VS 2015 and CUDA without problems. But you are both correct, CUDA support is a bit behind. 
These telemetry calls is just silly hype.
yup, valgrind complains with the original code about using the wrong deleter but weirdly shows that all heap blocks were freed.
oh cool. thanks!
I don't think you know how most developers feel.
Could you show example of it ?
What do you dislike about program_options? Just that it's not header only?
I'd fought with that idea, and decided that it made sense to have both (after all, if they want to do it with a normal args::Flag, they can without trouble). I decided that the user asking for help is something I consider an "exception condition" in program execution because it just prints the help and then kills itself, and also helps to prevent from parsing additional command options by throwing. It also lets the user wrap as much as they want in the `try` block and handle the help condition at the end if they wish. The most important thing is that I consider an "exception" to be something that should bypass or interrupt normal program flow, and requesting help fits that.
I like that idea. I'll have to implement that as an expressive example.
GDB. Get started with small steps. You can do an awful lot with it with very few commands. Here's a simple walk-through finding that perennial favourite, a segFault. It's simple and contrived, but three gdb commands only are used to find and confirm the segFault. http://www.cplusplus.com/articles/iwTbqMoL/
That's a good start I guess.
The trouble with Boost is only that it's huge. Yes, for the header-only parts, they give you a tool to extract a subset. I've tried this a few times; even in those cases, I found that the extracted subset was far bigger all the other parts in the project put together. Now, _if_ you are writing a large program, there's nothing wrong with having a huge dependency like Boost! I've used it with great pleasure in the past (though there are some areas that were, I felt, less ready for prime-time than others...) But we're in a different era these days. We're integrating a lot of stuff. We're cross-platform. People want small, light things with very few dependences. In a recent project, I moved from Google Test to Catch simply because I could replace the whole test substructure with a single, platform-independent header file. Out of nowhere, someone decided to port it to Windows - most of his time was getting a modern C++11 compiler working on a trivial file, once he got past that it was easy. Boy, was I happy I'd made that decision earlier and gotten rid of the whole "build the Google Test .o files" step. So for most projects I'm doing these days, Boost is out, because it's huge. Sometimes I miss it, but so far there's always been some other good choice.
QtCreator ships with a c++ compiler (mingw.)
Thanks man. Code looks really cool. I'm kinda in the stage where I think I need a lot of code in order to improve my own. I'm looking through yours. Looks nice! Well done! Do you work with C++ in your daily work or is it just on a hobby basis? 
I had horrible experience with the RC as well, it hung during the initial installation, couldn't be cancelled and when killed forcefully resulted in a total mess of installation which didn't work at all and couldn't be reinstalled (because setup thought it already was installed) nor repaired (because this didn't fix anything, even after running it several times), nor even uninstalled (even with `vs_entreprise /force /uninstall`!). I lost 2 full days manually removing all traces of it from the system before finally being able to reinstall and have the IDE working again (but `v140_xp` toolset is still broken).
What problems exactly did you have with it? I had [horrible experience](https://www.reddit.com/r/cpp/comments/4q5a5a/visual_studio_update_3_has_been_released/d4re4v8) with the update 3 RC, did the same thing happen with the final update or was it "just" very slow?
`char` is trivially destructible, so nothing bad will actually happen if the wrong delete is called. Think of it like in C where `free()` doesn't care whether you `calloc()`-ed or `malloc()`-ed. The reason the type matters is when the destructors need to be run as part of the destruction of the object - then it needs to know whether to run it just once (`delete`), or once per element in the array (`delete []`). But you should still fix it :). Technically, it isn't required to work, but I believe it does on most implementations.
Hobby basis, though it was my first programming language. At work I mostly use Python, but I try to talk my way into C++ projects wherever I can.
This ticks all the right boxes, but the API seems a bit too verbose compared with something like [Clara](https://github.com/philsquared/Clara) (by the same author as CATCH). Also, does anybody really care about the performance of command line parsing? I would never put this as the very first section in your README, if you really want to speak about it, do it at the very end but IMNSHO it just doesn't matter at all.
Until there's a NaN.
Because it's not part of the standard orthography.
The name "vector" is incredibly overloaded in mathematics. I believe (but am not certain) that the name in C++ comes from linear algebra: https://en.wikipedia.org/wiki/Row_and_column_vectors It's certainly better than... "some other languages" which use the word "list" to mean something that is not a linked list.
As far as I am aware, popular belief was never that you *couldn't* so much as that you *shouldn't*.
Has there ever been talk of a std::reseat()/std::reassign() for updating where a reference "points"?
I've been tracking this proposal because I had to come up with my own poor man's implementation of it for my [signals](https://github.com/thierryseegers/event_channel/blob/master/include/event_channel.h) library. Here's a extract. Incidentally, my `invoke` would be C++17's `apply` (which would be implemented in terms of C++17's `invoke`). I realize it may make little sense without context. Short explanation is this function is used to register a signal handler. What we do is save the handler, remember it by it's parameter signature and craft a lambda whereby we invoke the handler with the parameters that will show up in the event. //! Suscribe a function as an event handler. template&lt;typename R, typename... Args&gt; void subscribe(R (*f)(Args...)) { std::lock_guard&lt;std::mutex&gt; lg(dispatcher_pending_m_); dispatcher_pending_[tuple_type_index&lt;Args...&gt;()][make_tag(f)] = [f](const void* params) { invoke(f, *static_cast&lt;const tuple_type_t&lt;Args...&gt;*&gt;(params), std::index_sequence_for&lt;Args...&gt;{}); }; } 
dunno, maybe on some hard-to-understand code it could be way of screwing with GPL?
Why?
And for that I am truly grateful. Thank you =) Why didn't you take that road sooner tho? I don't need everything Visual Studio can offer me when I just want Visual C++.
I'm more interested in stripping dead code or at least code not executed from a particular run. Is that possible?
Static linking can be fun with MinGW...
What other arguments would you have to parse?
You misunderstoof leftofzen, badly. C doesn't map directly to assembly-level code, either. Modern compilers produce generated code that can look almost nothing like the straightforward logic of the input provided. Thinking that you can model the instruction sequence that some piece of C or C++ code will generate is foolishness.
I think maybe I wasn't clear enough. I understand that you can catch what new throws and try to handle it. That isn't what I'm talking about. What I'm talking about it the part you completely glossed over "and sometimes to continue in these situations." How would you continue? Do you know the rest of the code which is about to be called will not allocate? Will you actually be able to do anything useful for the user? I'm talking about the recovery strategy. If you wanted to inform the user an error occurred you need to make sure showing the error window isn't allocating. Or that cout isn't allocating. Both of those are hard to know. Even if you create the error message window in advance but don't show it, maybe showing it allocates via GDI on Windows for example. It would take a lot of effort to deal with this fragile situation. And the best you could do is tell some subsystem which has aggressively allocated to release some stuff. But why was it aggressively allocating in the first place? Shouldn't you first ask that subsystem to purge a bit before allocation, aiming at the hard limit given by the embedded system? Recovering from an exception isn't that hard. Recovering from out of memory is likely to be a larger system design problem and the fix should happen at the system design level, not in a recovery code path. That's code that will become untested and bitrotted.
IWYU recommends adding headers for everything that's used in the file but assumes that the header is already in the "include tree", so it doesn't support the same sort of use case as include-fixer.
Because unless you specifically enable ETW on the machine, the events emitted do nothing and log nothing
It's nitpicking. There is no way of managing all that flow. What's important is to able to imagine what pattern of memory and synchronization commands will be generated.
That is an important remark. I don't use Windows, so I don't know fully how it handles things. Looks like for Windows, you parse your windows `GetCommandLine` (or `wGetCommandLine`) into a valid utf-8 iterable container and pass that into ParseArgs, or you use `wmain`, and also convert into a valid utf-8 iterable container to pass into ParseArgs. I don't intend to put any real unicode handling into the header, or to assume that any of the data it handles is anything but valid utf-8. How you get that utf-8 to the program is up to you, assuming that Windows doesn't expect stupid things, like for the called program to handle shell constructs like quoting manually or anything like that. So if being utf-16 aware is necessary for Windows support, then Windows support is off the table. OSX handles argc and argv correctly. That's necessary for its POSIX support.
Just be aware that using exceptions means your project is DoA for a number of common C++ users - including games, embedded, and real-time - that often compile with exceptions outright disabled. There are even development environments/platforms that don't support exceptions (out of the box, or at all). e.g., I'd _love_ to have a nice C++ option library for game engine uses, but this is completely useless to me as-is.
That's a very valid concern. I might have to update it to allow it to work without exceptions (You'd just have to check the boolean status of the parser to know if validation succeeded, you could also use a regular boolean flag for help checking). I'm not sure how I'd handle exceptional situations like failed parsing or invalid types, though. I'll think on it. If I can enable an optional exception-free mode with a simple preprocessor option without sacrificing functionality, I'll be glad to. **edit:** I could actually just create a property on the parser like `Error()` which returns an error enum (or bitfield) to make this work. Exceptions out of the control of the program (like custom type parsers and the like) will still kill the program with an exception, but that's out of the control of the library. I'll put this in the books for the next major release.
While a perfectly reasonable idea, this could easily be done as an extension in the existing namespace. The point of using an `std2` would be to allow changes that could break existing code.
&gt; Eclipse has a free IDE as part of its huge suite. Last time I checked it out, it was dreadful but that was quite a few years ago and I hear it's improved a lot. I suppose your view on this would depend on exactly *why* you thought it was dreadful years ago. If you thought it was dreadful because it was too small, too fast, and not nearly confusing enough, then yes, you should probably try it again--you might like it a lot better now. If, however, you're at least partially sane...
Looks nice, I have used boost::program_options before and that library is so strange. It's so easy to just include that single header also :)
NaN doesn't change anything.
Linux does not kill processes in OOM situations unless you want it to. 
&gt; Secondly you implied that 2GB strings is "on the small end" of things in your daily work. Using QString there would be stupid! Right, because it's poorly designed, even more so than the oft-maligned `std::basic_string&lt;&gt;`. I can use `std::basic_string&lt;wchar_t&gt;` with a custom allocator that wraps a memory-mapped file and treat it as a large, performant string. I can't do that with `QString`, but the _reason_ I can't do it is arbitrary and _purely_ a limitation. Why _shouldn't_ I be able to? `std::vector&lt;&gt;` can do it – what makes strings special? Telling me I shouldn't have a need to do this is naive-bordering-ignorant and, again, arbitrary. _You_ just don't have a need to do this. &gt; So don't act like an idiot! ♪♫ I-rony..! ♫♪
Presently I work with GIS data ingestion. GIS data is _huge_. I can handle GBs of data trivially with fundamental standard library types because of custom allocators. If any competing library _can't_ let me do this, then that library is inferior. When one of the reasons that library can't let me do this is because they won't change a simple typedef to match the C++ standard library, that library is just poorly-bordering-stupidly designed.
Something like this _might_ do it (some of it, anyway). It's just running it through the preprocessor.
The example would, but not the entire library required to run it. Boost.Hana does exactly this.
Not to use as your code, unless you're an idiot, but practically you might want to preprocess your source to checksum the actual code or something. Like for a checksum-instead-of-timestamp-based build system, you'd want to do this to ignore changes in comments or #ifdef'ed out blocks.
&gt; Therefore adding the additional copy into `::std::` buys you nothing, because you must assume the global namespace has already been polluted. Yes, you must assume it has been polluted, but you cannot _rely on_ it being polluted, which makes it necessary _[for portable code](https://www.reddit.com/r/cpp/comments/4pxmgs/dlib_19_released/d4pc74s)_ to use `std::size_t` when `cstdint` is included. Yes, I agree, `cstdint` is a useless header and it's more practical to include `stdint.h`; but that's not what I've been talking about, at all.
&gt; you could break the data structure's invariants if you were allowed to mutate the keys So say as a precondition: don't do that. Presently, since one can't change _anything_ (even when it doesn't mutate the "key(s)"), you have to remove the element, modify it, and reinsert it. I don't want the handholding that prevents me from doing it in place as long as I do it correctly. What language is this, after all? ;-] `std::vector` has both `operator[]` and `at()` – I want the associative collections to give me the same level of trust.
I'm normally not a fan of video tutorials for programming, because, you're right, they make no sense. But these, I find very watchable. I guess because he explains what he's doing and you can watch him make mistakes within a code example that actually fits in the screen. EDIT: Edits.
Because ETW already logs every process start and terminate event in system without help of C runtime. So having more ETW startup/stop events in C doesn't give away more information than it already does now.
And resizeable dialogs are so hard to make in 2016, wtf?? https://i.imgur.com/ckoZB7c.png And this is with default font size on Windows. It's not that hard of situation to test!
&gt; I don't like that it doesn't serialize raw pointers, it should just assume it's an owning pointer that doesn't alias. There's a lot of code bases out there which are pre unique_ptr. How does the serializer know how to allocate that pointer? What if the pointer is not null, does it free it first. What if that pointer isn't actually a heap allocated object? I kind of feel like serializing pointers shouldn't be automatic at all so that such problems are handled with specific logic. 
The `[]` are because of parsing difficulties. See the new CPPCast
It can be, and it also can be not. Either way, they add the same amount of bloat to your binary (or for shared libraries, they effectively do if your binary is the only one that uses them). Header-only is the only option for most template libraries though. Header-only increases compilation time, but gives a lot of extra flexibility. It's less about small and big libraries, and more about what you intend the library to do. Any libraries I write that don't use templates (or can use templates with predeclared template parameters), I'll use a static or shared library model to ease compiler work. Normally, even if your library is header-only, it will span multiple files. This one is only one because I want it to be easy to drop wherever you may want it.
There is lots of good stuff here. What I am missing: - Tweak interface requirements for associative containers so that they would allow more effective implementation than current rb-trees. For example b-tree containers, google's dense hash which appears to be successfully picked up by SG14 etc. All of these seem to be faster and/or more memory compact in general case. - Use std::less&lt;&gt; instead of std::less&lt;Key&gt; because it can be faster when searching for key of not the same type which would otherwise require conversion e.g. set&lt;string&gt;::find(const char*). This scenario is already partially supported but changing the default to less&lt;&gt; is the last missing piece - hopefully we don't end up with both string_view and string_span in the std library. That would just fragment the code and confuse all novice developers
&gt;and MS doesn't have the greatest reputation at the moment apart from the topic - I thought they have, with all the open source and stuff.
The difference is that `operator[]` cannot be checked statically, while `const` keys can. If you're doing squirrelly things then there's `const_cast` and `mutable` for you.
Years of experience.
Not to your average Joe it doesn't, see http://i0.kym-cdn.com/photos/images/original/001/121/721/f14.png http://knowyourmeme.com/photos/1121721-windows-10-automatic-update
Developers are more pissed off about the forced upgrades than the norm. Open sourcing .Net and making it cross platform was great and will only get better, but that's a small drop in the bucket of shit that MS needs to clean.
The more poignant question to ask is whether or not anyone other than the people who wrote it have been able to use it successfully. AFAICT, the few places it has been deployed has had at least one or more people that were directly related to its development consistently engaged and on hand. 
Last time I gave it a try, it was a nightmare just to get CDT installed and working. After that I had to cope with insanes hierarchical menus/windows/tabs, in which finding a feature is close to impossible. Then, it was impossible to rapidely choose what I want to build at a given time. Finally, any automatization of a task that was not foreseen by the devs involves having to program "in Eclipse". Is it better nowadays?
HPX offers many advantageous concepts that'll eventually become part of C++. Some time ago I wrote an article on HPX: http://blog.brakmic.com/high-performance-computing-with-hpx/
Political, for example :-)
You may also want to have a look at [easylambda](https://haptork.github.io/easyLambda/docs/welcome/). It works well with iterative algorithms. It is a header only library which uses MPI for parallelization. It is a data-stream processing library that provides map, filter, reduce, scan, zip functional list operations. The data-stream can be from file(s), container, range etc. The library has some default parallelism choices for each unit in the data-flow, which can be overridden. Since, all the types are standard types, you can easily iter-operate with other libraries inside the flows or outside after getting the results in the vector. I have benchmarked it against Hadoop on aws cluster and it outperforms it by huge. It also works well on single core or multiple cores on a single system. I'm currently trying to bring more algorithms, functional list operations and add documentation. Let me know if you want to try it out on aws, I can share an ubuntu image with gcc 6.1 and boost. Using starcluster you can load the whole thing very easily.
I agree. Our project is mostly autoconf based, with a few custom makefiles. Its a hassle to fudge a CMakefile.txt just to edit the code, but I do it anyway. For the most part, I just setup the source and include files/dirs and then build outside clion.
I use clion on a 4k x 2k display. I needed to setup a large font configuration, but thats easy to do. I switch back and forth to the default if I happen to be on a smaller display.
Yeah, I release on a few different platforms, so header only libs, or ones with only a couple cpp files are much easier for me.