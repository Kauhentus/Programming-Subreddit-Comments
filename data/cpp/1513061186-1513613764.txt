There is a paper proposing why namespaces should not be nested too much anymore: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0816r0.pdf That said. This is the style I would like to adopt for future C++ (with modules). 1. Qualification should not be too long. 2. Maybe should not use nested namespaces heavily. 3. Qualification should be optionally explicit. With the #include mess it is easier to mix namespaces with the same name. But with modules there will be more isolation. My advice is that you do not nest namespaces. Get one that is unique. When modules are ready, it will not be a problem. And without modules in, I think you will still survive :) So I would propose something like this: //Your implementation namespace std_myname { //... } //Your .cpp client file #include ... //in the future import ...; using namespace std_myname; For this to work well, try to get names that will not collide with others. This has been especially bad for me when mixing boost with std library due to ADL. 
Fair fair... sorry, I'm a tad jumpy on this n_n' And tend to forget that not everyone is as anti-UX as I've encountered. The "but you *can* get fast and have total control" point comes up too frequently, usually accompanied by, "we don't need anything else." Or my favorite: "It's easy, you just have to..."^(proceeds to make a 20-point bulleted list full of technical jargon) Misproportioning entirely on me, here
Well, I can understand, that they didn't want to change the iterator category of e.g. `std::vector::iterator`, but I'd still have use for a separate category in my own types. Alternatively there could be a is_continuous property in iterator_traits.
Note that when talking about a "large object" you need to distinguish between objects with large "sizeof" and objects that allocate a lot of dynamic memory (e.g. vector). For the latter it's not a problem as destructor is being called when last shared_pointer dies.
Why not `namespace my_name { namespace std {}}`?
Out of all the suggestions, i would say Eclipse Che is the most fully featured. I would like to give another recommendation though: https://slx.cloud is specially tailored for C and C++ software development and based on Eclipse Che. We are currently working on integrating a C/C++ language server to provide autocompletion (https://github.com/eclipse/che/pull/7516) Disclaimer: I work for the company behind SLX.cloud, but our product is free for non-commercial use and we are actively contributing to Eclipse Che.
I second this - that's what we use at work (e.g. that's the namespace we use for stuff like optional / any/ variant / etc. that we ported to C++11/14).
I have a few questions about that solution. * Why the private key struct rather than just a private ctor? * It looks as if Immortal takes arguments to construct T, yet it is given the private key struct. What is the idea there? * What is the benefit of this solution, particularly the allocation scheme versus that of the Scott Meyers version? 
The Industry disagrees.
Everybody: *keeps out of std because compilers might put random stuff in there* Microsoft: *lol let's put our random stuff somewhere else so that people have to avoid two namespaces*
I can understand that. They got sued for using the standard namespace of Java as their companies landfill several years ago. Of course using something obvious like a microsoft namespace was also not an option. Can't make it easy for a user to identify non portable code. 
My main issue with cmake is as a 'user' (someone trying to configure and build a third-party cmake project, as opposed to someone developing a project using cmake). Unless the developer has made the effort to document them, I find it very difficult to discover exactly what project-specific flags can be set to configure which features get built. When building an autotools project for the first time, I can run `./configure --help`and get a list of `--enable-foo` options, each with a brief description. I haven't managed to find anything similar for cmake, apart from `cmake -L`, but that can hide options if e.g. it doesn't find the required dependencies. Hopefully, the functionality is there somewhere, I just haven't managed to find it from reading the man page and docs. Based on things like the above, my overall impression is that cmake is technically capable, but not very user-friendly.
And let's not forget about the address sanitizer configurations too. It's not just about targeting a different platform, it's about using modern instrumentation too to find real bugs (I wished more would do that). That's why I really appreciate the monorepo approach and building everything from source. It's easy to port then and you don't run into a huge configuration mess to deal with all the various flavors of binaries.
I would also recommend the C++ Core Guidelines:[c++ core guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) , compiled and frequently updated by Stroustrup and Herb Sutter.
First learn the basics which are actually kind of static(C++14 should be good) and then later learn C++17 with all functionalities and changes... 
The team I work on is considering switching away from SCons to another build system, and every day it's looking more and more like it's going to be CMake - the language isn't great, but the ecosystem is by far the more important factor. If using Meson allowed us to be in the CMake ecosystem (ie. to produce libraries that can easily be included in CMake builds, to have compatibility with IDEs that understand CMake files or are supported as backends), we'd likely choose Meson.
Which industry? Embedded? Automotive? Aerospace? AAA games? It's C + classes and little else.
Not directly related to your question, but what extensions of the STL are you implementing?
I had a quick look at it and what I really like is that everything (or at least most things) work without macros! If I'm in need of DI in the future I'll give kangaru a try.
I wonder what he's doing now. I hope it's studying Rust .. solely for the schadenfreude :P
&gt; I have no idea why this persist to this day. Naming is hard. This is not the first in IT time when the chosen name of something leads to pointless discussions :).
I think it is D. Languages with a crippling dependency on GC are all the rage. 
Not OP, but I use Meson and can answer that: The main meson file mentions SDL as a subproject, if you go to the subprojects folder you'll find a file called [sdl2.wrap](https://github.com/jpakkane/monocoque/blob/master/subprojects/sdl2.wrap) which contains the necessary info for downloading.
Lets say you have database logic (I have that) It is namespaced with namespace database {} In this area i have special logic for different databases like this namespace database { namespace odbc { } namespace mssql { } namespace sqlite { } namespace postgresql { } } This also matches the folder structure where logic is placed Is it better to do it like this? namespace database { } namespace database_odbc { } namespace database_mssql { } namespace database_sqlite { } namespace database_postgresql { } 
While you're at it might as well add in requirements around linting, code formatting, sanitizers, warn-as-errors. Where you're really going to have problems is dependencies.
Also sidenote, why can I just std:: accumulate(somevec), where somevec is something that contains .start and .end. 
Not to mention compiler flags... Anyway, I doubt this will work: there is just too much to disagree on :-( For example, I don't want warn-as-errors. Not because my own code has warnings, but because I also compile libraries by other people and I'm certainly not going to do any more work on those than I need to... Anyway, if anything like a fixed structure ever gets imposed, I feel it should be part of the move to modules. It might even be used to fix some of the difficulties in the modules proposal (how to match a module to its constituent files, basically). 
You could do `std::reverse(vec.begin()+3, vec.end()-10)`
(Certain) iterators can be in- or decremented; std::reverse(vec.begin() + 3, vec.begin() + 10) would reverse the vector between the 3rd and 10th element, although it doesn't ensure that you stay within the vector's bounds.
I don't the reason, but I would assume it's more generic to ask for begin and end iterators so C arrays can be passed. But with `std::begin() / std::end()`, why not do it know. Do people are against? or simply nobody bother to write a proposal?
unsure of the point of this article
Oh, it's worse than that: https://stackoverflow.com/questions/39948997/use-of-boost-log-and-boost-asio-causes-a-crash/39958285#39958285
I agree dependencies is the worst part, but there is already a .cmake and pkg-config interface for a decent amount of packages that makes our lives at least bettter than before. The aim is not to be perfect, or to get down to all the detail that you can. The goal is to have a basic thing that works. You can always go deeper if you enter expert level.
Mmhhh, actually, the point here is to see what can be agreed upon and leave the rest to the user's choice. If I can get something compiling in half a minute because I only fire my editor, write some code and invoke a standard command, without doing anything else, just because I put it in a src/myLib directory that would already be a win for me.
Thanks! :) If you have C++17, you won't need any macros, since you can use template&lt;auto&gt;.
Mostly freefunctions to simplify string logic
Most variable settings are canonical. If you want shared you can use `BUILD_SHARED_LIBS`, if you want to build tests you can use `BUILD_TESTING`, if you want to disable an optional dependency you use `CMAKE_DISABLE_FIND_PACKAGE_Foo`. The only issue is when a library decides to create its own custom variables, and ignore the canonical ones. In addition, cmake is the only build system so far that lets you tell where its dependencies are with `CMAKE_PREFIX_PATH`. Such a thing doesn't exists with other build tools like autotools, meson, or bjam. Of course, for projects that have additional option, the easiest way is to inspect the cache afterwards with `ccmake` or `cmake-gui`. Each cached variable requires a help text, so there is a nice description for the user. This is a little different than autotools where you can run `--help` without configuring, however, with cmake there is no way to know of these custom options without running it first. So instead you run `cmake` first and then run `ccmake` or `cmake-gui` to see the options and then change then and reconfigure and build.
Tbh im tempted to propose that. Never did anything like that though
Huh didn't think I could. Thanks
Oh thanks. I didn't think you could do that 
Addressing the points in reverse order: 3) This approach is unlike the traditional Meyers' Singleton in that it implements the "Leaky Singleton" idiom as in the OP: the singleton object is created on-demand, and never destroyed. It avoids destruction order issues by virtue of being immortal. 2) Yes, `Immortal&lt;T&gt;` is a wrapper utility that constructs a `T` within its storage from arguments passed to the `Immortal` constructor. The contained `T` is then leaked - it is not destroyed when the `Immortal` instance is destroyed. `Immortal` avoids dynamic allocation so that its leakiness doesn't interfere with memory leak detection (and because, as C++ programmers, we despise dynamic allocation). `Instance` passes a `key` to `Immortal` from which to construct `Singleton` because that will invoke the only viable `Singleton` constructor. 1) The private `key` type as parameter to a public constructor is an idiom to forbid a type to be constructed generally, yet still allow it to be created via an independent factory function. Since `key`'s default constructor is `explicit`, the only way to create an instance is by naming the type. Since the name of the type is private to `Singleton`, only authorized code in `Singleton` or its friends may create a `key`. So despite that the `explicit Singleton(key)` constructor is public, it can only be invoked directly or indirectly from authorized code. In this instance, the "authorized code" is `Singleton::Instance` which creates a `key` and hands it to the `Immortal` factory with which to create a `Singleton`. The same general idea works with other factory functions like `std::make_unique` and `std::make_shared` which you cannot easily befriend since the identity of the final caller of your constructor is an implementation detail. 
I think thats part of the ranges proprosal for C++.
Oh thanks. I'll check it out. Would you happen to have a copy of the PDF you can link me? I can never find updated links
It only works for iterators which satisfy the RandomAccessIterator concept like the iterators for std::vector. When using a std::list you can only increment your iterators (not add a constant). For more info you can checkout [iterator library](http://en.cppreference.com/w/cpp/iterator)
&gt;- How should the directory layout look? - src/ for sources and includes. src/ is included in the build by default If the project is a library of some sort, it would probably be better to split out the "main" includes (those that a user of the library would actually `#include`). I think this helps discoverability and makes getting started a little easier for first-time users of a library. I'm not a fan myself of completely splitting a project into`include/` and `src/`, but having interface includes at the top level would be ok with me: - `MyProject/` - `MyProjectInterfaceA.h` - `MyProjectInterfaceB.h` - `src/` - ... 
For the directory layout: * `doc/` Documentation. * `test/` Tests * `include/` The **public** headers. I like to have the headers that are part of the public interface seperated from all other files. For one I have an irrational aversion to have .cpp files in directories that are part of the include path, more important those are the source files I might have to look at to figure out the interface. I am a bit undetermined how to organize the rest because it depends in my mind on the exact type and size of your project and whether your support a build system or not. If it is a small library, I would just add a `lib/`directory. It contains the files I need to compile and either link to my stuff or create a static/dynamic library and link that. If the project is a little bit bigger I tend to use a `src/` directory that contains directories for private includes, binaries, and libraries. For larger projects that contain several module but are bundled as one I would go a different route. In short: For very simple libraries I do not see a real problem. Adding an include path and some files to compile and link should not be a problem. (Which is why I do not understand why everything *has* to be header only. For everything create a proper structure and **document** it. Also support at least one build system with a *simple* build file. If you cannot do easily go and rethink your structure. Keep the settings in your build script to the minimum, do only what is absolutely necessary to compile your project. Document possible flags. Explain what is needed and why, document any necessary dependencies (internal and external). If you can do that it should be relatively easy for others to integrate your library into their project. (And the complexity of the setup should grow at most linearly with the usefulness of your library.) If you cannot, rethink if it is really necessary and try to simplify. If not your library should be worth the pain. The real problems start once you start to have a lot of flags depending on the system and other factors. Or in a larger project dependency hell might break lose. But then the directory layout is the least of your problem and no real help anyway. And advertise that you are always accepting patches for other build systems.
&gt; For everything create a proper structure and document it I see that more of a problem than it might be: having a "free" layout is exactly at the step we are now. I would not like to remove configurability, but to have a standard, expected way of finding things. Same for targets across build systems. This aids in several ways: 1. I can create just a "standard" directory layout without creating any build files myself. 2. I know where to expect the namespace/files naming. 3. I can just invoke the tool. I think there is no faster way to do this than with a proper standard layout. It is difficult to agree one and we will never have a standard layout for all projects that already exist. But I really think we need a start point if we want to reach an ease of use that is similar to what Go provides. I did not try Rust + Cargo myself but my guess is that this might be a similar experience.
Nay-saying improvements is a C++ tradition.
Ah, I think I misunderstood you. So you want to be able to just to create the directories and put the files into them and then everything works automagically?
This is great, good luck! I think no matter what you choose, anything is better than the void that exists now.
Yes, but with the existing backends (Meson and CMake is what I can think of). If a standard is defined and supported by different build tools, working with any environment should be a much more uniform and less fragmented experience than now, besides being faster. You cannot unify all build systems in C++ at this point anymore. It is a solution that I think it could work reasonably well. 
Thanks. For now this is just a discussion but thanks for encouraging!
Regarding nested namespaces, I find it really peculiar that P0816 doesn't even *mention* namespace aliases. This omission seems to me to undermine pretty much the entire argument that the paper is trying to make. By simply putting `namespace fs = std::filesystem` at the top of a source file, one can easily fully-qualify every call (to avoid unintended ADL) with a minimum of typing. That seems pretty simple to me. (Okay, so this probably shouldn't be done in headers, but people experienced enough to write template-heavy header-only libraries are presumably going to know what they're doing. And modules, if we ever get them, would make this moot anyway.) 
&gt; which makes taking the n-th iterator a bit more complicated. [`std::next`](http://en.cppreference.com/w/cpp/iterator/next) So not that much more complicated.
You don't have to pass the begin and end iterators for a container: You can pass any other pair of iterators. Accordingly `std::accumulate(iter, iter)` provides a strict superset of the functionality that `std::accumulate(container)` would.
Uhm the warn as errors things is handled automatically if you retrieve a header file from a path that was specified with -isystem instead of -I. In fact, that is basically the only point of having both -isystem and -I. I've never seen a good reason not to have warn-as-errors other than having an old crappy codebase with tons of warnings (though at that point, there's little point having the warnings).
[`std::search`](https://en.cppreference.com/w/cpp/algorithm/search) with [`std::boyer_moore_horspool_searcher`](https://en.cppreference.com/w/cpp/utility/functional/boyer_moore_horspool_searcher).
It could be robot-generated even :/
I intended to refer to the end()-10 part which is not covered by std::next, nevertheless std::next is rather helpful in that context.
Ah, so this standard build system is only meant to be used with GCC as opposed to MSVC or other compilers.
Forcing every user to type full qualification is, in my experience, if more readable, tedious to some extent. This is one of the things where D just changes the default: when you import you can use unqualified. &gt; And modules, if we ever get them, would make this moot anyway. The likelihood of mixing with modules is much lower, that is true. But the point for accessing ::testing from your acme::testing namespace still holds I think. 
I use `namespace nonstd` for this typically
&gt; I intended to refer to the end()-10 part which is not covered by std::next `std::next(end(), -10)` or [`std::prev(end(), 10)`](http://en.cppreference.com/w/cpp/iterator/prev).
CMake is Open Source, and the Authors accept pull requests and value contributions. Sign up here: https://gitlab.kitware.com/, dig into the Code and make it better.
I expected negativity to some extent. I embrace your position: if we want quick and fast access, we need some kind of standarization looking at the reality of C++. We can still do much better IMHO.
Great explanation, thank you for taking the time to add the code sample and the write-up. &gt; `Immortal` avoids dynamic allocation so that its leakiness doesn't interfere with memory leak detection As I understand it, this is the biggest advantage to your solution over an `Instance()` function like this: static Singleton&amp; Instance() { static Singleton* instance = new Singleton(key{}); return *instance; } Is that correct?
I agree with your reasoning behind the nested namespaces thing, but I don’t think it really needs to be a rule. How does it affect the layout of the directory structure and the build system? It seems like an independent problem. 
Well, it works exactly the same way on clang. So out of the major compilers, it's actually MSVC out on its own, not GCC. But sure, let me answer snark with snark: yeah all of us *nix devs are clearly going to abandon incredibly valuable warnings-as-errors so that we can cater to the fact that MSVC is (apparently) missing a rather obvious and incredibly useful feature. Sounds good.
I have also thought about this, although not as a standard, but just as a build system based around compiling all C++ in a folder to be a static lib, dynamic lib, or executable. A directory structure like this: src/ stlib/ shlib/ program/ plugins/ The goal is you should be able to just start throwing code in folders and start coding and it would take care of the rest for you. e.g. to make a new executable named 'helloworld' you would put code in the src/program/helloworld/ folder. This would compile to build/Win64/Release/program/helloworld.exe. There could be an optional list of dependencies in those folders, maybe a text list in dependencies.txt that lists what directories are included/linked with the folder, which could be useful to enforce interfaces. I think the entire code for the build system should be put into a single .c/.cpp file and if you wanted to customize it (add new build targets) you should be able to define rules and put them into the plugins folder. Plugins should be in .c/.cpp form and also be compiled with the build system the same way (and plugins can have no other plugin dependencies). This is so you can use these for generated code or package management etc. You might want to add a meta/ folder for example that generates code from .xml files. Build outputs should be placed in a separate directory structure like build/Win32/Release. I really think an opportunity exists to make a build system based around a simple start and go philosophy. I do not think things like namespace rules or generated docs or anything else should be imposed because that just introduces more learning required and would prevent existing projects from being able to be built with it. It has to start incredibly simple, able to build via one command line without any config steps required. It should provide for more advanced usage as long as it still only takes a single command line to compile it. 
&gt; A directory structure like this: &gt; src/ &gt; stlib/ &gt; shlib/ &gt; program/ &gt; plugins/ stlib and shlib would hardcode the decision. It is common practice to decide afterwards what you want to get from there. I understand your point but things are not so easy unfortunately. I think it would be simpler and would get more adoption to use the existing tools as a backend rather than starting a build system from scratch. 
Well, maybe you are right. And maybe we should not force users to take this decision about *not* using nested namespaces. But what I am sure would be a very encouraged practice should be at least directory/namespace mapping.
What are you even trying to do? There sure is a better solution.
The 600 series had rubber skin. We spotted them easy, but these are new. They look human...
Rust and Cargo have an interesting solution to the warn-as-errors problem. You can set your own project to whatever behavior you like, and all dependencies are compiled with warnings off, so you only ever see them for the project you're currently building.
The most basic string search has the complexity of O(n*m), not n^2, with m is the length of the substring (in this case, only 3, so its basically O(3n) or O(n)). When we write complexity notion, we omit the constant part. Usually, the algorithms with lower complexity has bigger hidden constants than the simpler but with higher complexity ones. That's why you should consider the size of the data your working on before choosing an algorithm.
I agree, I htink that src and include should be completely different directories. 
they could have add `std::accumulate(container)` that would forward to `std::accumulate(std::begin(container), std::end(container))` since for some algorithms it might be the most used version. (and people in need probably did add them to their STL.)
Having standards is a good thing; however, it's challenging to create simple standards that work for ALL software. For example, how does one differentiate directories when there are 2 or more executables to build? Add in shared libraries/dlls, how should that work? I wonder if the biggest bang for the buck getting new engineers creating is a set of scripts that a) ensure the build environment is installed and working; and b) sets up simple CMake projects based on flags (i.e. --with-qt --with-boost). One could even wrap a simple GUI around it... (Let me add: as frustrating as CMake's scripting it, CMake is mature and it works.)
Wow. Didn't know this was added to the C++17!
You are right, what I wanted to show is, when dealing with a ForwardIterator it is complicated, for every other type it is almost trivial (`it += n` and `std::next(it, n)`).
Modules don't solve this problem.
Why can't the build system do this where possible and simply not do it where it isn't?
I prefer a top-level `interface` directory. Making it more explicit makes it more obvious to use.
&gt; Having standards is a good thing; however, it's challenging to create simple standards that work for ALL software. For example, how does one differentiate directories when there are 2 or more executables to build? I should study in more depth how other systems do it. A standard layout could go a long way to the goal. Remember that the goal is not backwards compatibility or so. Maybe something like: src/ myprog-exe/ myprog2-exe/ mylib-lib/ mylib/ would be enough to do detection of how many artifacts there are. 
That's a good way of looking at it. And to be fair to the above poster, I think they were being relatively positive with their concerns. I'm sure you'll face much worse, as I've seen time and time again if you dare to suggest that something about C++ could be improved for its most common use cases without hindering the other use cases.
Something that is put on top of a build system to just ease common use cases without getting on the way can never worsen things. Today you have to create your specific build-system thing. Why not generate a standard layout plus appropiate support for just starting coding, no matter the build system? And this is an important part: no matter the build system, because different people are using different build systems. But it is true that I can start coding a project in go much faster than I have ever been with C++. This is because of these standard conventions. So we should start to think of how to fix the problem. 
At the absolute worst, the build system could auto-generate proxy headers that surround the actual headers with `#pragma warning(push, 0)` and `#pragma warning(pop)`. Or MSVC could get the feature if something like this works out.
The disagreement and slow uptake of this sort of thing is what is going to see C++ eventually fizzle and die as more modern languages with these niceties and all of the same use cases as C++ become more popular.
The point isn't to suggest you abandon a feature that works well for you, and you're taking this comment far more aggressively than it was intended. The point is to reinforce how hard it is to make a uniform build system for C++ since compilers don't agree on how to handle a great variety of build parameters and as you point out, even experienced developers don't fully understand the implications or consequences of certain build parameters. It's a noble goal to want to create a build system for C++, but I think it's premature as the problems are fundamental to the language itself. Perhaps when C++ supports modules we will have a much better way of structuring our code base and managing dependencies, but until then (and perhaps even then), I think it's largely wasted effort.
/u/AndrewPardoe is there an easy way to go back to a version &lt; 15.5? (i.e can you point me to a download). Seeing a really weird exception being thrown on my app exit (in _execute_onexit_table) that has only started happening after installing 15.5.0/15.5.1 and haven't got time to debug it to produce a bug report at the moment. Thanks!
I don't see how this would work but I'd be curious to know your idea. In my source file `main.cpp` I include a third party file: #include &lt;boost.hpp&gt; The build system would generate a proxy header, say `proxy_boost.hpp` whose contents are: #pragma warning(push, 0) #include &lt;boost.hpp&gt; #pragma warning(pop) How would this proxy file get included into `main.cpp`?
Since this is an active thread, I'll ask the question and maybe those who have read one (or both) can answer. Is it worth buying both Effective C++ and Effective Modern C++ Books? Is the content the "same" (so to speak) for both, with Modern being the latest Best Practices? Or does each book tackle different concepts?
Because the standard library bases its sequence operations off of ranges, represented as pairs of iterators, rather than containers. That lets it work with C arrays (by using pointers as iterators) and with parts of containers instead of the entire thing at once.
I would prefer it if they could be combined somehow as well, that is just the simplest way I have to solve it. If you had to do other things, like learn a config script to define your lib compilation, already you've violated the start and go philosophy. If they could default to static libs and then you can add things to make them dynamic, that is fine with me. You could always just move the code from shlib -&gt; stlib if you wanted to change it with this current setup. This standardized directory structure could also be implemented with other tools, e.g. if you could write a make file that could compile this structure that is fine too. If I was to write a build system I would start with an open sourced one like fastbuild and use the back end for that with a hard coded front end like this. Currently I use fastbuild with a build script that basically works to this 'standard' anyway.
I was imagining messing with include paths, since that build system likely controls those anyway. Replace the one that contains `boost.hpp` with a proxy directory, and then use the full path in the proxy header file. Something like this: `proxy_headers/boost.hpp`: #pragma warning(push, 0) #include &lt;full/path/to/the/real/boost.hpp&gt; #pragma warning(pop)
Well what I'm saying is that I don't think that, except for includes that are designed to be included from outside of the project. I'm happy with project-internal headers living next to cpp files.
I disagree - it is not uncommon to have a more fine grained directory structure than namespace structure (especially if you go for flat namespace hierarchies).
If there are going to be a bunch of other subdirectories, though, putting them in another one might make it less obvious, at least it seems like it might to me. If they're just in the top-level directory of the project, it should be a no-brainer (plus, setting include paths to point at them might look nicer).
Oh yeah that actually seems workable.
About targets: what about NDEBUG/\_DEBUG builds? What about 32/64 bit builds? What about static vs. shared libs? We're also building an unoptimized retail build of stuff, for easier crash dump debugging.
&gt; If you had to do other things, like learn a config script to define your lib compilation, already you've violated the start and go philosophy. If they could default to static libs and then you can add things to make them dynamic, that is fine with me. You can simply have something like: src/ some-lib/ The prefix would identify as a lib. Let us say it would build as static to use with your exe (for simplicity). And you can switch to shared. Without violating the start and go principle.
This is a proposal meant for simple use cases as a primary goal (for now). If you want a full config, probably you are already into full project kind of thing for which the simplicity is not so important anymore. This is well supported by both CMake and Meson. Could add some handy magic thing like RELEASE or DEBUG but with simple defaults. For advanced cases, go down to the full power of the tool I guess...
at which point the simplicity goes away and you'd better tell the build system what you want to map where, as you do today with build systems. The proposal primary goal is to have something simple that works to get you up and running fast. This does not preclude future extension. But if you want a super customized layout, probably you should roll your own. This is exactly how it is in Go: you have something and for keeping it simple, they take decisions for you. This works great for starting fast.
is lib/name/ really any different from name-lib/? It seems exactly the same just a different naming scheme.
I don't see, why you need a standardized layout for projects that have only a couple of files. At most you need dedicated `src` and `libs/deps` folders.
I did not give to this a deep thought yet. I tend to prefer more flat structures. Namely, I prefer: src/ project-lib/ project2-lib/ project3-exe/ to: src/ exe/ project3 lib/ project1 project2 
&gt; I don't see, why you need a standardized layout for projects that have only a couple of files. At most you need dedicated src and libs/deps folders. Because the point of this is that no matter the build tool you use and the build system you use: it should be as uniform as possible without you studying the new layout or the new commands that someone thought were a good idea. Those are good as an extension, but for the basics I really believe (and see from other languages) that this is what will make things more simple from the start. 
Only works for random access iterators. Usually not a problem. std::next(begin(vec), 3) is the more genetic solution.
Ahh ok. Couldn't they keep the current implementation and also add it to accept containers?
Yes, that is I believe the *only* advantage.
Again: for a simple project, there shouldn't be any difficult to understand directory structure in the first place. For bigger projects, however, that do have a more complex structure, requiring a mapping between namespaces and directories is not something that works well with flat namespaces, because you end up with one mega directory with dozens of files that are only loosely related. Also, I don't know what new commands have to do with a directory layout - that sounds more like a build system issue.
As a semi-relevant note, the performance of `std::next` and kin on non-random-access iterators is only guaranteed to be O(N) rather than O(1). Of course, if one _needs_ to do things like "end - 10," one should _not_ being using `std::list` or the like: use a `vector` or go home. :)
Some of these problems from the consumer side have already been addressed long ago by things like autoconf/automake: you have some standard commands to build (`configure &amp;&amp; make &amp;&amp; make install`), and there are guidelines for common target names (https://www.gnu.org/prep/standards/html_node/Standard-Targets.html#Standard-Targets). For the producer side, there are tons of tools (automake, cmake, tmake, etc.) that try to make your life easier. That these tools have been around for 10+ years and none achieved world domination looks like a good indication that each has its valid niche that the others do not fill. In particular, that one man's "easy, no configuration needed" is another man's "this sucks, I need to configure this but can't".
I also agree, what is the point of separate include folders anyway? It seems like it may make it easier to copy just a public interface if you are distributing binary versions of a lib, but that is a complete nightmare for other reasons that I would prefer to avoid. However I think it should support both versions: src/ libs/ MyProject1/ include/ MyProject1Interface.h src/ MyProject1.cpp MyProject2/ MyProject2Interface.h MyProject2.cpp Then it should automatically add src/libs/MyProject1/include and src/libs/MyProject2/ to the include paths.
Sure, I agree with you that this is largely wasted effort. I think you took my original comment as more related to the original subject post than I intended :-). I was just trying to honestly help my parent, in retrospect I should have qualified with "if you're not on MSVC" but in any case it is useful information that should help some fraction of the people who may have read that comment and are in the same situation.
I know most of these systems pretty well: I started with autotools, tried SCons, waf, cmake, tup and meson. Let me tell you a fact: no matter which one I choose, when I see a project I do not know where and how targets and sources are arranged. So now I am in a position where just starting a project makes me wonder the layout I want and take a lot of decisions. "That is great! You do not lose control." you might say. But those decisions take some investment in time and thought. What I am proposing *here* is to just remove all of that overhead at the expense of some pre-made decisions to make starting a project something much more accessible from what it is now. That is the main goal. I do not care noone could agree a standard layout before. I do not even care wether everyone will like or not the layout I could propose. What I care is that I can start a project, add some docs, targets and things, invoke the tool and have something that is executable, without having to write a build definition file in any of CMake, Meson, Tup, Waf, Scons or whatever. This is a genuine need right now. Just look at the number of likes of the blog post "All I want to do is program...".
I don't see why you have to enforce flat namespaces (or even that subdirectories match namespaces). For simple projects, your build will probably consist of minor variations on the theme "build all translation units, and link them together", and the directory structure beyond the first level is irrelevant. In all other cases, something automatic is bound to fail anyway and you're going to need a proper build system. Since my usual approach is to build a library and then maybe some applications using it, I find that a directory structure along these lines usually works fine (and most of this is pretty much a defacto standard already, modulo exact directory names): * deps/ (git submodules, most of the time) * docs/ * include/ (public interface of library; only headers) * src/ (implementation of library; sources and internal headers) * src-bin/ (one source file per executable) * src-test/ (usually one source file per test suite, details depend on testing framework) Obviously src/ is optional (header-only libraries), as is src-bin/ (no applications).
Many of those do not work under windows. gnu make also has issues under windows as it's case sensitive to / vs \ in paths, meaning you can't write a make file that works across both platforms. cmake is also a terrible build system, but people tolerate it because it has no real competition. I've yet to meet anybody who enjoys it. It also commits some cardinal sins in my book, like generating header files inside the build system, which is just overly clever and completely fucks over anybody already using a different build system.
How do we signal myprog2 links to mylib1, myprog3 links to mylib1 and mylib2, but myprog1 needs neither? How would we link to an external so/dll? (I'm specifically thinking about boost and Qt.) And what happens when we have more than one version of a library? (e.g. Qt 4.x and 5.x because legacy code is a thing.) What about linking to vendor supplied libraries? Currently I add a Find&lt;vendor library&gt;.cmake to a common CMakeModules file to make this "easy". And don't forget about packaging! At the moment, we use Wix for Windows releases and simple tgz files in the rare case of a Linux release. I've considered changing to .debs on Linux but I'm not convinced it's worth the struggle. To complicate this, we build around 30 targets divided near evenly between so/dll, executable, and test. Depending on customer, we package 4 to 5 of those. But we build all targets for every change, to ensure the change won't break a build for another customer. You shouldn't let my experience deter you. Keep at it. Just be aware the strength of C++ is it's flexibility and rich set of libraries. Some of us will (ab)use this more than others...
These are all valid points but unfortunately we don't have the manpower to create a CMake backend. It would take a lot of effort that is better spent improving the system itself.
Out of scope. I want to create an exe fast. That is first step. I even want a C++ shebang and skip compilation! But if what I want is a full project with a lot of complexity, this is something I can already do well in CMake, Meson and others. We are well covered there already.
std::next(begin(), size() - 10) ?
To create just an executable with CMake you literally need only 3 lines of scripting. cmake_minimum_required(...) project(...) add_executable(trg source.cpp) The simple use case is already the simplest. 
This is usually done as install target. 
&gt; I'm happy with project-internal headers living next to cpp files. You dont feel dirty inside when you see that stuff?
&gt; To create just an executable with CMake you literally need only 3 lines of scripting. Which are not the same you need with Meson, waf or others. You will have to learn whatever build system and get tied to one of them. Only this already takes some learning compared to: 1. create file. 2. fire console. 3. type "buildtool make" All without creating anything else. But there is more to it: coverage, docs, install and others for simple cases could be default targets if you stick to a standard layout no matter the build system backend. Maybe some library linking for external dependencies, though linking is something that already needs some user help almost for sure. I must still shape how simple is simple. But maybe internal libs should link to executables or a maximum of one exe and n libs should be allowed for this kind of projects. Not sure yet, but for keeping it super simple some decisions must be made ahead of time, as other tools do. 
I do not get why the downvote.
We enabled installation of [minor version toolsets](https://blogs.msdn.microsoft.com/vcblog/2017/11/15/side-by-side-minor-version-msvc-toolsets-in-visual-studio-2017/). You can add the 15.4 toolset in by rerunning the installer. Please send me mail with your bug so that we can understand it and fix it. &lt;firstname.lastname&gt;@microsoft.com.
As has been mentioned before, there is no O(n2) complexity here - even the simple and straightforward solution is already O(n). I also suspect your algorithm does a poor job on this input set, which consists of only two symbols and has a very short search text. If it's the one I'm thinking of, it relies on advancing the input multiple positions if and when a match fails. However, I don't think that ever happens under these circumstances, leaving you with basically the simple and straightforward solution, plus additional housekeeping that isn't helping much. Personally I'd go for something like: for (int x=0; input [x]; x++) if (input [x] == (input [x+1] ^ 1) &amp;&amp; input [x] == input [x+2]) return true; return false; as the checker. In other words, I would hardcode the search text and take advantage of its structure. Yes, it's cheating ;-) 
What would you do if your non-technical customers used 64 bit PCs with 32 bit windows? Tell them to reinstall their OS? It's a very new development for end-users to actually have 64 bit CPUs with 64 bit OSs.
This would work, albeit you have to use `std::distance(begin(), end())` because `forward_list` does not provide `size()`. But then you traverse the list two times, which is unneccessary. A better approach is to keep a second iterator which is "lagging" behind another iterator like so: template&lt;class It&gt; It from_behind(It begin, It end, int n) { It result = begin, cursor = begin; std::advance(cursor, n); while(cursor != end) { ++result; ++cursor; } return result; } Which is *a bit* more complicated than the other solutions.
I don't know. You're assuming that standard == simple which is not generally true. Also this: https://xkcd.com/927/ 
I just repost my post from a month ago as I think it fits here: A standart layout is very much apreciated. There shouldn’t be any need to write build files at all (except maybe a global library configuration). There exists only a very limited amount of useful project structures. And with modules this narrows down even more. If you follow a given default structure the build system should be able to build your project out of the box. I assume 95%+ of projects could use this approach without any loss. --- Each proposed rule has the following structure: - Shortcut: MBd.x-A.Name (MBd for module build in development. Also MB is not used in the core guidelines yet, to prevent name collisions of rules. x is running number. Use –A.Name to propose alternative design for discussion - Rule: Short description - Required: (to support default build without build files = ‘mandatory’ or ‘strongly suggested’. If the rule is not needed in terms of automated build support, build speed, or build simplification, there is no need to have the rule. Less rules are better) - Reason: Explanation of Reason (required!) - Example: (optional) - Hint: (optional) - Build system support features: (optional) - Exceptions: (optional) - Open Questions: (optional) --- MBd.0) No interference with other build systems - Rule: Proposed default build may not break or interfere with other build systems/approaches - Required: Mandatory (!) - Explanation: Following the default suggestions should simplify build but not prevent or hinder non default approaches - Open Questions: This approach targets zero build files. Still we need a place to put some configuration and that should be invisible to other systems (e.g. no cmake files). (See also MBd.8) MBd.1) Map modules to directory structure - Rule: Each module has its own directory. The directory structure is flat with 1 level (for small project) up to 3 level (for extremely large projects). Only the deepest level (module level) can contain code (files). - Required: Mandatory - Explanation: Futuer Modules form an acyclic graph by design (current TS doesn’t allow cycles). A graph cannot be mapped to filesystem tree. Thus a flat directory structure is the best alternative. Three directory levels to group code into modules, libraries and larger sub-systems should be enough even for very large systems - Example: See MBd.5 for structure example, see MBd.2 for module naming - Build system support features: The build system needs to visualize the module dependency graph (flat structure -&gt; graph) - Exceptions: Modularization on class level can live in the same directory of the parent module (Also see MBd.4) MBd.2) Map module naming to directory structure - Rule: Directory is named after modulename. Each module has a module interface file named modulename.mxx in its directory. (Additional interface files per module are allowed see MBd.4) - Required: Mandatory (? As current proposal only supports one interface file per module) - Explanation: This eliminates one level of indirection and therefore unnecessary complexity for the programmer. There are no useful applications to have separate names. - Open Questions: Any complains? / Upper Lower case problems? - Build system support features: If no modulename.mxx is handwritten it get auto generated by including all other .mxx files in the module directory. It also gets marked with [[modulebuild::autogenerated-module-interface]] to allow regeneration MBd.3) Modularize physical structure of your code - Rule: Each module directory is self-contained (coupling with other modules only over imports, not over the directory structure) - Required: strongly suggested - Explanation: True modularization at ‘source level’ and ‘physical structure’. - Hint: Imports get automatically resolved by the build system. No need to couple module directories by hard links. (See MBd.5) - Open Questions: Only possible for header less modules? (See MBd.8) / Resources? (see MBd.9) MBd.4) Keep interfaces and implementation together - Rule: If interface and implementation is split, keep mxx and cpp files together in the module directory. Also use the same name for both files (1-to-1 mapping) - Required: strongly suggested - Explanation: There are three strong indications that code and interface belong together. o 1) The current proposal doesn’t require an separate implementation file o 2) Interface is carried in the generated binary module interface (?) and headers don’t need to be distributed (?) o 3) Code with headers files and cpp files having already a 1-to-1 mapping is easier to modularize, thus seems to be the correct design - Hint: Use MB.2 to auto generated interface if you want to split your code on class level into separate files. - Open Questions: I guess this point will be controversial. MBd.5) Help the build system to locate your source code - Rule: All module directories are located under directories named ‘source’. (There can be multiple source directories, see example) - Required: strongly suggested - Explanation: Helps the build system to locate source and automate build. - Build system support features: Given a list of root directories, all modules are located automatically and build. Generation of (static or dynamic) library borders can be chosen on modules, libraries or sub-systems levels (see MB.1) - Open Questions: Subdirectories of ‘source’ may only contain modules? / Directories without source are not allowed to be called ‘source’? - Example: (2 root directories; Organization=SubSystem level) o ExternalLibraries\LibraryA\source\ModuleA (Uses 1Level) (&lt;- Bad?) o ExternalLibraries\OrganizationA\source\LibraryB\ModuleB (2Levels) o ExternalLibraries\source\OrganizationB\LibraryC\ModuleC (3Levels) o MyProject\source\Subproject1\ModuleD (2Levels) - Hint: Only the part after source directories belongs to the module name and have a standardized directory design. (e.g OrganizationB.LibraryC.ModuleC). Also see possible problems with name clashes by using only 1 level. MBd.6) Keep generated content local - Rule: Generated content will get generated either inside the source tree in a ‘generated’ subdirectory per module or generated out of the source tree in a ‘generated’ directory that replicates the source tree structure. - Required: strongly suggested (?) - Explanation: Keep generated content local to module helps build system to simplify keeping track of dependency changes. - Hint: Also see MBd.7 MBd.7) Use common pattern for build customizations - Rule: Code itself should specify its need for special preprocessing. If a library needs code to be processed by a custom build step this should be handled by a default build system extension plugin - Required: strongly suggested - Explanation: Any of the many different special build customizations (e.g. Qt Moc) can be generalized into the following 4 actions (?): o (1) Run a custom tool at a certain position in the build sequence (2) on a specific file to modify it or generate new source files (3) and optionally include these new files into the build process. (4) Optionally also include original source into the build process. - Build system support features: o Offer an extension Api o Automatically execute custom build steps (See open questions) o Possibility of automatic installation of build system extension after library build - Open Questions: Non brittle integration without interfering with other build systems (MBd.0). By default file name extension? By including [[attributes]] into the source code? Scan source files for tokens? MBd.8 Use policy based design for (build) options. (Controversial with MBd.0) - Rule: The build system should provide a common structured (!) set of build options that get passed into the modules. Libraries can register their own structured (private and public) options. (If possible do not rely on the preprocessor in a post c++17/20 build system!) (See open questions for discussion) - Required: mandatory (?) and controversial (= bad) - Explanation: Global variables/defines as in CMake are awful brittle, as they are not structured and not standardized. Defining a common set of default options is a better design (on a 90% common denominator that can grow over time). Libraries can still use their custom set of options and migrate to standard ones once available. - Hint: This will also greatly simplify setup as libraries only needs to define their special options. Most of these will settled around optional enabling of modules, that can be further solved by automatically handling optional [[modulebuild::requires-module-...]] and [[modulebuild::optional-module]] attributes in the interface file. - Build system support features: Offer an ‘build options’ Api - Open Questions: This is complicated. I will start with a first idea how to solve it. o Each module can optional #include &lt;ModuleBuild&gt; and/or import Module.Build o If using an alternative build system these files/imports just resolve to empty dummy file/modules. o However using default build these files get passed in by the build system. #include &lt;ModuleBuild&gt; offers preprocessor token for conditional compilation. import Module.Build offers a clean api that can get used with if constexpr to trigger conditional compilation. o As long as libraries do not follow default options names, it is still possible to define a mapping before the builds system passes the files. MBd.9 Resources (tbd) =&gt; Also see MBd.7
Thanks for this! Worth a deeper look whem I have some time!
It's worth pointing out that example will have undefined behavior when you run into an element that isn't followed by a copy of itself, because there's no check that it != std::end(myvector) You could look into std::next(), and you could avoid that if your outer loop was iterator-based rather than index based, but like emdeka87 said, there must be a better way to do whatever it is you're getting at.
Or you type `clang++ source.cpp`
I do not think it targets the sane use case as CMake. If you have to do more than write your .cpp plus invoke you are failing already: not everyone is familiar with CMake or build systems in C++ and the context here is to be able to do it without even those things. Just start and go: time limit -&gt; 1 minute. To do so in CMake, if you do not know how to use it, and I think non-experts should be one of the targets here, will take you at least find a project, copy/paste, invoke cmake for configuration, build and see result. Compare to fire editor and create your project with one file in a standard layout, write, invoke something of the style of "go build" in Go. There is no contest IMHO. I tell you this from the perspective of a person that also can handle several build systems already. But these things take time also, especially for non-familiarized people.
You project sets `CMAKE_CXX_EXTENSIONS` while it is something that should be up for the toolchain/"cmake invocation" to decide. You use `add_subdirectory` on a third-party (fmtlib), I consider this bad practice. You have options to enable things like -Werror, I personally believe this should not clutter the CMakeLists.txt, and instead should be specified on the command line in CI for example, using `CXXFLAGS='...' cmake` or `cmake -DCMAKE_CXX_FLAGS='...'`. You main CMakeLists.txt is simple because some other files contains the clutter, the cctz CMakeLists.txt is not more complicated than yours. Maybe there is a necessary clutter for the C++ standard, because it cannot use CMake 3.9 like you do. Still this is self-contained and relatively short. Concatenate all the files under https://github.com/thelostt/cci/tree/master/cmake and you have more CMake code than cctz does. If you feel like it's easier to understand when it's split into a bazillion files ok, but in the end I believe there are less things to understand for cctz (not that the projects are equally comparable, but since you made it sound like cctz or slog were too complex, I will allow myself this shortcut). Personnally, I avoid creating wrappers around CMake functions like you do with `add_cci_library`, `add_cci_executable`, `add_cci_unittest`, here: - https://github.com/thelostt/cci/blob/master/cmake/modules/AddCCI.cmake#L54-L126 The reason I avoid this is to not create a mini-DSL per project, than one has to learn. Maybe it's more verbose to do: ``` add_library(CCIParser parser.cpp) target_include_directories(CCIParser PUBLIC ${CMAKE_SOURCE_DIR}/include PUBLIC ${CMAKE_SOURCE_DIR}/deps) # why do this BTW? target_link_libraries(CCIParser PRIVATE CCIBasic CCILex) target_compile_features(CCIParser PUBLIC cxx_std_17) # ... ok your target definition is somewhat complex, # I feel like all this Clang stuff should go in a toolchain ``` Than: ``` add_cci_library(CCIParser SOURCES parser.cpp DEPENDS CCIBasic CCILex) ``` But with the first method there are no surprise, just lookup the CMake documentation. Anyway, I like you CMake code overall but I think you misjudged the cctz CMakeLists.txt. It's easier to understand, the project is less complex than yours, and it does not deal with all the Clang-specifics you have in your CMakeLists.txt.
No, I think modules is not a cure. The point why I use CMake is that my projects are multilingua. The most of them are wrapped with python or may be some code generation is needed or there are some build targets or etc. If you want build project from scratch just use plain make. This is the best solution, in my opinion. By the way, my typical CMakeList.txt is about 100 and at least two targets.
&gt; should we follow the standard library naming conventions? Yes, of course. Always be consistent with existing patterns.
Yeah sorry, I didn't intend to negatively criticize cctz's CMakeLists.txt, even though that's actually what it sounds like. Thank you for taking your time to go over my setup and review it, I appreciate it.
I write python myself but I don't share your vision. First of all Python nor go are system languages. Then with python the standard way to handle dependencies is requirement.txt and the de facto standard environment is virtualenv and for building and installing you need a setup.py... The documentation is quite good but that is not simple at all. 
This wouldn't work since allocators generally prefix the returned memory with a header containing information about the allocated block (e.g. the size of the block). There isn't really a way to make both allocated blocks contiguous in memory while also making then independently free-able without dramatically reworking how the allocator works.
I had some issues but they sort of worked on 15.5 Preview 5 (the issues where when you had multiple parameter packs).
It should work, I've played around with them when the update came out. Just double check that you have either "/std:c++17" or "/std:c++latest" defined as additional command line arguments.
Yes I do
Rust has solved this really well - you can have warnings be errors by default on your own "crate" (executable/library), but for all dependencies, that doesn't happen.
Nah, my IDE separates them, but even if it didn't I'm not sure it would matter that much to me. I prefer it to another include path for `../include/` or seeing `#include "../include/blah.h"`in .cpp files.
Very strange. That should be all that you have to do. Only other thing I can think of is a clean install but obviously that's not ideal.
&gt; I write python myself but I don't share your vision. First of all Python nor go are system languages. Then with python the standard way to handle dependencies is requirement.txt and the de facto standard environment is virtualenv and for building and installing you need a setup.py... Yet I still can open a console, write a script and run in less than it takes even to start setting up the simplest CMake project. I think you are missing my point: I use python sometimes because it is dead easy to see something running. Not because I can do a full deployment. And this very case is the one that could be much better supported in C++. Sure that dependencies complicate things. But having a project with two internal libs + one exe where you assume the libs are to be used in the project (without user intervention in the build system) could be something that can be done with defaults much better than currently.
Project assembly issues fade out with comparison with documentation generation. The standard approach is Doxygen but it is soooo ugly and terrible. I envy python and go developers. They have sphinx and godoc. The last one is my best dream.
I gave the Vc a trial and came to a conclusion that it's Apples and Oranges kind of thing going on here. The basic premise seems to be that the scalar type is substituted with a vector type with appropriate overloads. For example: float_v a = ...; float_v b = ...; float_v result = a * b; Would select the intrinsic type based on the compiler SIMD compilation target. SSE2 would choose __mm128 (float x 4), AVX would choose __mm256 (float x 8) and so on. This is the same idea I use here in the particle benchmark / example at https://github.com/t0rakka/mango-examples/blob/master/particle_benchmark/particle.cpp struct PackedVector3 { float32x4 x; float32x4 y; float32x4 z; }; This is a hybrid approach between SoA and AoS where we have array of Short Vector's instead. The idea is that instead of going full 100% SoA have increase locality by storing short vectors in the array instead of scalars. Full SoA has discrete array for x, y, z and other components that we might have. Writing code for such layout is very clumsy if we don't want to process data in multiple passes which consumes more memory throughput. Using PackedVector approach we can select the Short Vector type at compilation time the same way the Vc does and have the convenience of the code looking just like scalar code. We already do have overloads for vector types in mango so this is perfectly legal and compiles: PackedVector a, b; PackedVector result = a * b; Notice the similarity to the Vc code example above? The programmer is responsible for naming the type so if PackedVector doesn't float your boat use something nicer. :) I did a little benchmark of GLM vs. MANGO but didn't include the Vc in it because it is not API compatible with these two libraries and uses slightly different paradigm (see the Apples-Oranges reference earlier). http://www.liimatta.org/misc/mango_glm.txt Yeah; took me a while to get back to you but I did more than look at the code. I wrote tests and checked compiler output, it's OK but as said making direct comparison with the benchmark I wrote earlier is not practical. Should have somekind of process-huge-arrays-of-stuff kind of benchmark. My uses cases are so different from CERNs apparently that I don't see any point shifting my API into that direction. I mostly do setup for GPU data and now and then transform MCUs and that sort of stuff. The data is heavily interleaved and demuxing to Big Array format would be more hassle than it's worth (eg. preparing data for more efficient transformation would cost more than just transforming it). It's a completely different story if the data will be transformed thousands of times with different parameters. Cheers. 
I don't think a standard layout adds much, to be honest. What we need is a standard API. Which activity takes the most time when setting up a new project (apart from 'writing the source', of course)? It's certainly not the build system. What takes time is the libraries that you want to include: downloading, unpacking, configuring, compiling, and finally making available to your project. That's an area where you could easily make some big strides. Why isn't there a command like lib_builder https://www.openssl.org/openssl/latest c:\downloaded_libs\openssl followed by lib_linker add c:\downloaded_libs\openssl c:\projects\my_project The first grabs the library and builds it locally. It doesn't impose any structure, and it lets you install as many versions in as many directories as you wish. The second adds the library to your own project - again, completely project-specific, but after this command you can simply #include &lt;openssl.h&gt; and have it work. Moreover, it should add openssl.lib (and friends) to your link stage. Again, there is no overarching structure, nor any need for one, so it works for all projects, you can select precisely which version you want on a per-project basis, and all the tedium usually associated with this process is taken out of your hands. "This is a job for a package manager" Respectfully, no. There is no need for a centralized, curated package manager; that's just a crutch. There is however EVERY need for a general mechanism that all library builders adhere to and that works like the internet itself: decentralized. Oh, and considering that we use huge numbers of C libraries, to be succesful such a mechanism must be shared between C and C++. 
given source.cpp, you can type make source
&gt; I prefer it to another include path for ../include/ Another include path? You only need one project-specific one, "include". 
Didn't know about that. Can you also pass compiler flags this way?
Can you provide a self-contained repro?
Hopefully we can stop worrying about includes when we get modules standardized.
The one directory per output approach seems grody if I need to make a bunch of executables with overlapping source files. The only way to do it would be to make a big library of the shared stuff? That wouldn't cover the fairly common case of one main executable, and a bunch of small test executables that each want to test the contents a different specific implementation file. Only being able to link to the giant library would potentially expose the small unit tests to strange static initialization order kinds of bugs so that the test_socket_connection test might fail because of a bug in some_gui_button.cpp, and tweaking the socket_connection.cpp would require rebuilding the whole big library just to run one test case. This is one thing I sort of despise about QMake's "subdirs" project type which works in this way.
I don't even want to think about how long it will take us to make that transition at work (large codebase), but yeah, that would be ideal.
The majority of people here know what a DI container is.
There's no need to support them, because either A they're tech-savy enough to understand what it means and can switch, or B it's a shitty prebuilt that's over 4 years old and it can't run the game anyway.
What problem is this trying to solve? In my professional and personal software projects, like this says, no 2 are alike. And it's never been a problem, for me at least. 
I have one: $ type Test.cpp template &lt;typename T, T V&gt; struct Integral { static constexpr T value = V; }; template &lt;bool B&gt; using Bool = Integral&lt;bool, B&gt;; template &lt;typename... Ts&gt; struct And : Bool&lt;(Ts::value &amp;&amp; ...)&gt; { }; $ cl Test.cpp -c -std:c++17 Microsoft (R) C/C++ Optimizing Compiler Version 19.12.25913 for x86 Copyright (C) Microsoft Corporation. All rights reserved. Test.cpp Test.cpp(10): warning C4346: ‘Ts::value’: dependent name is not a type Test.cpp(10): note: prefix with ‘typename’ to indicate a type Test.cpp(11): note: see reference to class template instantiation ‘And’ being compiled Test.cpp(10): error C2059: syntax error: ‘…’ Test.cpp(10): error C2976: ‘Bool’: too few template arguments Test.cpp(7): note: see declaration of ‘Bool’ Test.cpp(10): error C3770: ‘unknown-type’: is not a valid base class
Interesting how *everyone* has his own string free functions (I also have mine).
xkcd 974, but with 200 standards instead of 14. Seriously, there has been dozens and dozens of people trying to do "standard layouts" ... [github is a graveyard of those](https://www.google.fr/search?q=github+c%2B%2B+project+layout). The reason why I use C++ and not Go / Python / ... / is exactly because of this. The project I work on builds &gt; 50 DLLs and at least 5/6 "main" executables for various platforms (mac, win, linux, android, ios, and even pnacl at some point) from a single codebase with files in various programming languages according to the platforms (c, m, mm, java...), not counting platform-adaptations for other host environments: C#, puredata, max/msp, etc. Just putting everything in an "src" dir doesn't cut it *at all*. 
For your information, the autoconf/automake target for testing has always been 'check' and not 'test'. 
the std::string and std::wstring are important and I think a lot of developers need to extend their functionality. Before C++ 11 almost all created their own string classes. It was just too slow before the move constructor. Now I think there are a lot of projects that sit with legacy code that they get grey hairs over because they would like to rewrite it but doesn't have the time
you can pass compiler flags to it with environment variables. like so `CXXFLAGS="-Wall -O3" CC=clang++ make foo` see [implicit rules](https://www.gnu.org/software/make/manual/html_node/Implicit-Rules.html)
It's offered by Avast. Does that mean it also vomits weekly popups for the even-more-premium retargetable machine-code decompiler family 5-pack? Will it periodically announce that it wants to rm -Rf /tmp/* to "make your machine faster?"
Yeah, I see more and more projects doing it. For example, there are some PR on cctz to make it easier to use cctz that way: - https://github.com/google/cctz/pull/61 steveire had an explanation on why CMake support for this is non-existant, and provides directions to superior alternatives: - https://www.reddit.com/r/cpp/comments/65iyxv/embracing_modern_cmake/dgjamhk/ IMHO, with CMake, the correct model is to depend on the install output (the "distribution") of your dependencies.
maybe, but its still proper practice to spell out an acronym before using it
Warn as errors is annoying for local development. For example if you are debugging and add a return at the top of the function and suddenly your compile fails due to unreachable code so you have to go back and comment it out. That being said I don't think any commits should contain warnings and I have no problem gating on that. 
Thank you very much for the work. I'll try your code, those looks like Vc is a given for us
i feel even dirtier when they're in include/
Thanks! Repros with our current dev build and doesn't seem to be a duplicate, so I've filed it in our internal database as VSO#537705.
There are multiple "existing patterns". std lib is just one of them. And not even the first one.
That's what Python is written for. It is literally built for fast scripting. C++ has many more complexities in terms of build options. You're trying to simplify something that's already been simplified.
OK, so I bought a copy of the standard as a PDF from Standards New Zealand, https://shop.standards.govt.nz/catalog/14882%3A2017%28ISO%7CIEC%29/view (C068564e.pdf). What I have found after a couple of seconds use is that the internal links don't work. This was discussed with a supervisor at SNZ who stated they sell only what ISO supplies to them. Has anyone else had a problem with the links in their PDF? In the meantime I am contacting ISO via their customerservice e-mail to discuss this issue.
 template&lt;class... Ts&gt; auto f(Ts... ts) { return ( 1 &lt;&lt; ... &lt;&lt; ts ); } int main() { f(1, 2, 3); } Compiles fine with just `/std:c++latest`, but with `/std:c++latest /permissive-` yields: ggg.cpp(1): error C3546: '...': there are no parameter packs available to expand ggg.cpp(5): note: see reference to function template instantiation 'auto f&lt;int,int,int&gt;(int,int,int)' being compiled ggg.cpp(1): error C3520: 'ts': parameter pack must be expanded in this context Compiler Version 19.12.25830.2 for x86.
Duh, if an object can't exist without another you need a composition relationship. 
The problem with this is when your code causes warning somewhere deep in the dependency code (like with templates).
Thanks! I haven't reported it before because i don't use the IDE, and you know, it is not possible to report bugs directly through this [page](https://developercommunity.visualstudio.com).
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7jbtid/using_stdfind_to_start_from_a_certain_value/dr5yb7c/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Fair point, especially for C++. A really good solution would probably involve a combination of concepts and more compiler support for control over warnings. (Rust has this much easier because generics have their parameters annotated so that they can be checked separately from their uses.)
headerfiles and sourcefiles are separated for a reason. You dont get intimate with your siblings, right?
When generating a package, though, do you include all headers in said directory? It's often the case that I want to share internal details that aren't in the public interface between classes in my library. Where should those headers go?
Sorry, what do you mean by this? Are you referring to two interdependent Singletons?
no, you could do include/private and include/public for example.. or just /include/private, and then not include that one
Ah, okay. When you said: &gt; one project-specific one, "include" I took that to mean just a single directory, not something uses sub-dirs.
Fails to compile with 15.6 internal preview 2, but successfully compiles with our current development build, so this must have been fixed very recently. Thanks for the report. (I don't know whether this fix will ship in 15.6 for production.)
well its only separate dirs from the package generator
My directory structure look like this: src/ &lt;-- every target has src as include directory vendor_a/ module_a/ src1.cpp include/ &lt;-- additional include directory for consumers concept_a/ src2.cpp module_b/ ... vendor_b/ ... app/ appname_a/ appname_a.cpp In `src`, `vendor_a` and `vendor_b` is shipping libraries like `module_a` and `module_b` to be compiled as static library, then linked to applications. `vendor_a` and `vendor_b` are not really external libraries, but really a group of static libraries. `module_a` and `module_b` are static library targets. The `app` directory contains the executables, and `appname_a` is one executable that can link to many modules. Then, everything is exported with CMake, so other projects like that can link with the modules of another. This is pretty much it for us. It may not be perfect for everyone, but good enough for our needs.
&gt; When I tested this your implementation beats our std::to_string by approximately 2x; You should be careful when benchmarking: a) this code(borrowed from [Alexandrescu](https://www.slideshare.net/andreialexandrescu1/three-optimization-tips-for-c) without accreditation) clumsily handles INT_MIN, and surprise surprise test integers are always positive. b) this code uses more data(LUT) so it slows down other code and you can not notice that in microbenchmark. c) most of the code uses std::string as result, not buffer so I do not consider this a fair benchmark( I mean printing to string and then using .c_str to fill output buffer... you may as well keep result string in unique_ptr ;) ). 
Are you asking if both symbiotic objects qualify as singletons..? ;-]
There are many issues with this article: You make your function thread unsafe without any mention of this You do not provide your benchmark code and from your github code I assume this benchmark may also be useless since you are not using Google Benchmark API correctly. For example your code: ` for(auto i = 0; i &lt; count; i++)` ` {` ` state.PauseTiming();` ` auto d = static_cast&lt;double&gt;(i);` ` state.ResumeTiming();` ` str += boost::lexical_cast&lt;double&gt;(d);` `}` Google Benchmark comments: // NOTE: PauseTiming()/ResumeTiming() are relatively // heavyweight, and so their use should generally be avoided // within each benchmark iteration, if possible. 
It seems that the VC++ Team claims that they implemented some C++ 17 feature, but the implementation is always buggy... Recently I tried the inline var in 15.5, a single `inline static auto x = 1;` leads to ICE. Did they do tests?
I agree, the example provided here does not seem particularly tricky... 
I like the structure describe by Hilton Lipschitz in is [blog](https://hiltmon.com/blog/2013/07/03/a-simple-c-plus-plus-project-structure/), he also describ in the contente of each directory bin/ build/ doc/ include/ lib/ src/ test/
[this](https://cstheory.stackexchange.com/questions/2373/complexity-of-the-simplex-algorithm) will blow your mind. :P
Literally will take someone proof-of-concepting it and selling the benefits to management for money. A week on the first part. Two years for the second if you have a good salesman.
&gt; c) I think this was Veedrac's point though; that super-well-optimized things will do their own buffering and write directly into said buffer; in which case the intermediate std::string is harmful. The point was not that std::to_string is poorly optimized, in fact that implementation being poorly optimized detracts from that point rather than helping it. I think I debunked the absolute values for the differences here being caused by std::string, but he's correct that it has nonzero costs.
What about all the people that come to C++ and just want to make a program, fast, without any complications, that have no build tools experience? Look at the post "All I want to do is program...". It does not look like a use case for you? For me it does.
The fact that it's impossible to report a problem without using VS is being fixed, I believe. But let me page /u/spongo2 anyway. He's management, he can fix anything! 
Yep, /u/Z01dbrg reported this one already. It's fixed in 15.6 Preview 1--I even launched VS to make sure I'm not testing on an internal build. With regards to users as "zero cost QA", there is a balance between giving developers early access to our bits and shipping bugs. It's a bigger problem with more recent features. And trust me, while we really appreciate all the feedback--bugs, criticism, even a few compliments!--people have sent us, nothing is zero cost in the end. I hope we've been clear enough with people that we're still working on all these features. We do extensive testing before shipping anything, including a rolling builds of a bunch of popular OSS libraries. But we do still have bugs, and we know we have bugs, and we hope that developers recognize that we have bugs. And while we try to fix them as soon as possible there's still a significant latency between a bug being reported, fixed, and the new bits shipped. Anyway, this snippet compiles now. `inline static auto x = 1;`. You can download the 15.6 preview and see for yourself if you like. But be warned: you're likely to run into some other bugs somewhere :) 
I implemented this thing so let me know if you like it.
While I implemented this thing so I'm predisposed to tell people it's the best thing since ice cream, I don't think it's a great fit here: 1. The alphabet is tiny. 2. The search text is tiny. 3. There are multiple search texts. ... all of which are really bad for boyer-moore.
If it will turn my fortran DLLs into C, it can do whatever it wants... I'm finding the setup very difficult on Windows (7) though, I give it about a 50% chance that when I'm done I'll have something that executes at all.
Given that the input is a binary string doesn't sound like cheating to me. Building a DFA could do it in n compares instead of 3n compares but would probably lose in practice.
Fortunately and unfortunately, where I work managers are all technical, but customers generally only pay for features. Because we have a lot of closed-source not-publicly-available 3rd party dependencies and a lingering few Fortran libraries, even upgrading C++ compilers happens at a glacial pace. So we'll have to do that, then we'll have to find some excuse/time to make that kind of major change to a huge codebase. I know we will probably do it, and everybody (including management) will _want_ to do it as soon as it's technically possible, but it will take us a stupidly long time.
I agree but then you should compare sprintf instead of to_string. Regarding not using to_string for performance sensitive code I agree. BTW since I saw you mention iota as potential problem for other implementations: to_string is by the standard specified to use sprintf(I learned this from STL and checked it now). Obviously per asif rule you can implement it using any way you want, but I hope they didn't. P.S. Here is another cool trick related to this problem: [godbolt link](https://gcc.godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(j:1,source:'static+unsigned+const+PowersOf10%5B%5D+%3D%0A++%7B1,+10,+100,+1000,+10000,+100000,%0A++++1000000,+10000000,+100000000,+1000000000%7D%3B%0A%0Aunsigned+numDigits(unsigned+v)+%7B%0A++auto+log2+%3D+31+-+__builtin_clz(v)%3B%0A++auto+log10Approx+%3D+(log2+%2B+1)+*+1233+%3E%3E+12%3B%0A++auto+log10+%3D+log10Approx+-+(v+%3C+PowersOf10%5Blog10Approx%5D)%3B%0A++return+log10+%2B+1%3B%0A%7D'),l:'5',n:'0',o:'C%2B%2B+source+%231',t:'0')),k:50,l:'4',m:34.38967136150235,n:'0',o:'',s:0,t:'0'),(g:!((g:!((h:compiler,i:(compiler:clang_trunk,filters:(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',trim:'0'),libs:!(),options:'-O3+-std%3Dc%2B%2B1z+-march%3Dhaswell',source:1),l:'5',n:'0',o:'x86-64+clang+(trunk)+(Editor+%231,+Compiler+%231)',t:'0')),header:(),k:50,l:'4',m:62.441314553990615,n:'0',o:'',s:0,t:'0'),(g:!((h:compiler,i:(compiler:gsnapshot,filters:(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',trim:'0'),libs:!(),options:'-O3+-std%3Dc%2B%2B1z+-march%3Dhaswell',source:1),l:'5',n:'0',o:'x86-64+gcc+(trunk)+(Editor+%231,+Compiler+%232)',t:'0')),header:(),k:50,l:'4',n:'0',o:'',s:0,t:'0')),l:'2',m:65.61032863849765,n:'0',o:'',t:'0')),k:100,l:'3',n:'0',o:'',t:'0')),version:4) from [this](https://blog.jetbrains.com/clion/2017/10/godbolting-your-cpp-code/) article 
&gt; The reason why I use C++ and not Go / Python / ... / is exactly because of this. I fail to see how my proposal disables your current use of build systems. This is a simple solution for a simple use case. 1. fire, write and run directly. No more things at all. No minimal CMake or whatever file. So you can skip learning some of the build system if you are no expert. This thing looks silly to you, because you are familiar with some tool already. Not for people who just want to go and try something. 2. You can expect to find things at a certain place. I do not say everyone *must* follow the layout. I just say that when I enter a Go project I already know the layout before hand. This saves cognitive overhead at no cost. If we want more C++ adoption we should make it as easy as possible and not start enumerating "I would have used C#/Python/Java" or whatever. What we need is to maximize its first use experience.
You don't need to read any book. You'd better learn it yourself, trust me. I've never read a book remotely related to computers, and I'm pretty much fluent in many languages. Plus, C++20 is beginning to be implemented already. (If you don't know how to learn it yourself, you aren't qualified to be a programmer!)
Thanks, was wondering how that magic happens. 
&gt; Obviously per asif rule you can implement it using any way you want, but I hope they didn't. Oh, but they did. (And we did too until someone complained and I made it less crap in 2015U2) &gt;P.S. Here is another cool trick related to this problem: &gt;you can precompute the number of digits. &gt;More in this article I have the book version of that article and don't see anything about counting digits. (There are lots of counting bits set, counting leading and trailing zeroes, etc; but they all operate in binary space and this thing needs to operate in decimal space)
&gt; and I made it less crap I think it is pretty good now, I benchmarked it against Abseil StrCat and it was only 20% slower. &gt; and don't see anything about counting digits https://godbolt.org/g/gACdiR It is from this part of the text: "Recently I needed to find the number of base ten digits in a number quickly and I ended up with a bit of code like this, which combines neat branchless bit trickery with some cool processor instructions."
One question I have about modern cmake is about ExternalProject_Add. Functionally its a great feature since it allows one to build dependencies very cleanly. One part where I struggle with is that if you have a single dependency with an expensive configure step your iteration times go through the roof. Building an executable A with dependencies B, C, D will run the configure step of B,C, D every time you build A. As a specific example if you add boost as an external dependency using ExternalProject_Add then every build will try to configure boost. Is there any way of just building only A (effectively saying I know for sure that B,C, D dont need to be rebuilt).
Personally, I like the fast releases. It's a welcome change from the past where it might take years for a new major release to come out with new language features, followed by a wait of several more months for the first service pack. Being able to install Preview side-by-side helps too. That having been said, I was a bit surprised when the very first if constexpr statement I tried ICEd the 15.3 preview compiler -- that was a bit more raw of a feature than I was expecting. One other big worry with the current fast-and-furious release setup is the inability to download older releases. I encountered a fairly bad codegen bug in 15.3.x Preview that thankfully wasn't hard to work around, but it was pretty disturbing when 15.4.0 was then released as stable with that bug and 15.2.x was no longer available for download. That means that if there is a blocking issue that is not discovered or fixed in time I may be stuck with not being able to recreate my last stable configuration on a new machine, which is frankly unnerving. And this is on a relatively small project that builds entirely from scratch, to say nothing of the dependency nightmares I have seen on bigger projects like compiler version dependent vendor-supplied libs or version-sensitive IDE plugins. 
We just started supporting [side-by-side minor version toolsets](https://blogs.msdn.microsoft.com/vcblog/2017/11/15/side-by-side-minor-version-msvc-toolsets-in-visual-studio-2017/).
I used to mostly feel that way.. but I would not say this about C++11 (and beyond). You can keep treating it like older C++ and continue to get things done, but there are certain things that are entirely unintuitive, and there are a lot of people out there making the most of it.. and it won't entirely make sense if you haven't been exposed to what they are doing. You can either read about them in a book or across legions of crappy blogposts. I find books that consolidate a lot of the information relevant to a subject to be a more efficient use of time. Of course it's necessary to develop/practice as well.
Which other ones are there?
&gt; including a rolling builds of a bunch of popular OSS libraries Note that while this is beneficial regression test this has limited use for testing features that are new. What you could do is (if it is ok legally, IDK) if Clang implemented some feature 3 months before VC++ it is probable that somebody was bored/curious enough to write code exercising that feature and commit it to github. Now obviously detecting interesting code is not that easy in general although I assume sometimes regex is enough :), also Clang is opensource so in theory you could patch it to know if code triggered something related to some new language feature. P.S. please do not answer if this is legally gray area, I know the corporate legal advice about everything is not to comment on anything. :)
There's a tab at developer community for c++: https://developercommunity.visualstudio.com/
I think you're overthinking this :) Most of what we're doing right now is implementing features that other compilers have had. There are a lot of libraries out there already using C++17 features. They make beautiful test cases for us! Now when we're actually implementing C++20 features along with our friends in Clang and GCC we won't be able to rely on OSS libraries. But we license professional test suites for those.
 #include &lt;type_traits&gt; #include &lt;iostream&gt; template&lt;typename... T&gt; auto fold_sum_1(T... s){ return (... + s); } template&lt;typename... T&gt; auto fold_sum_2(T... s){ return (1 + ... + s); } template&lt;bool... B&gt; struct fold_and : std::integral_constant&lt;bool, (B &amp;&amp; ...)&gt; {}; int main () { [[maybe_unused]]auto w = fold_and&lt;true, false, true&gt;::value; [[maybe_unused]]auto a = fold_sum_1(1, 2, 3, 4, 5, 6); [[maybe_unused]]auto b = fold_sum_2(1, 2, 3, 4, 5, 6); return 0; } these are the most basic cases that i could think of and they don't compile at all, someone needs to reevaluate what "implemented" or "done" means I even tried to compile it with the latest daily build of the compiler that is offered on nuget, no dice
To expand a bit on this, the side-by-side minor version toolsets are there to provide a way to use the previous update's toolset if you upgrade and discover an issue. If you do have to use the side-by-side minor version toolsets, please shoot us a message to let us know so we can fix the bug you're hitting! There are a couple of other options, both of which require advanced planning. One is to cache an installation of VS locally. I think I discussed it in the blog post Stephan linked to. It's not a cheap option in terms of disk space, but if your company is ready to ship a product on 15.x, it might make sense to cache an installation image of 15.x. The other option is to install the VS update side-by-side and try it out. Not just the toolset, the whole VS. You can't do this from the installer UI, unfortunately, but you can launch the installer from the command line with an `--installPath` argument. This will direct the VS installer to install the new copy in this other folder. Because VS install no longer mucks with the machine's global state, this enables you to have multiple updates of VS side by side. 
Clean install did nothing to help
Can you specify what exactly you consider a "simple" project, that should be buildably by default by a build system. As I said before: I you only want to compile a single main.cop or maybe a handful of files, you can already do this very simply by directly invoking the compiler.
Can you specify what exactly you consider a "simple" project, that should be buildable by default by a build system. As I said before: If you only want to compile a single main.cop or maybe a handful of files, you can already do this very easily by directly invoking the compiler (or calling make).
Can you specify what exactly you consider a "simple" project, that should be buildable by default by a build system. As I said before: If you only want to compile a single main.cop or maybe a handful of files, you can already do this very easily by directly invoking the compiler (or calling make).
If I want to just "go and try something" I do ctrl-N in my IDE, select "new project", type some code, and do ctrl-R to run it. I don't think project structure has any bearing on the simplicity of the act of coding - especially when there is so much tooling allowing you to browse your code by sorting it semantically (namespace, classes, etc) instead of relying on the file system.
&gt; Supported architectures (32b only): Hard pass.
&gt; Can you specify what exactly you consider a "simple" project, that should be buildably by default by a build system. Thanks for the question. This makes me think deeper. Simple means (I have been thinking a bit more about this) that from start to having the first program compiled it should be seconds. You know how to compile? Not everyone knows the details. You can use and list files? Great. Want to separate in libraries? Ok, create your files, dirs and so on, with your easy build files (because it is just add_library or add_executable). At the time you are doing that you are already *wasting* time IMHO. Alternatives: detect directory layouts and give you all this for free. Example 1. Simple script --- mkdir myproject cd myproject emacs somefile.cpp #edit... &lt;simple-project&gt; run #detect compiler, generate build and run That would compile and run the project. Compare to: mkdir myproject cd myproject mkdir src #MMmmhhh, maybe src is ok? cd src emacs CMakeLists.txt #edit, know cmake a bit, create exe, list files. emacs myfile.cpp #edit do mkdir build-dir #create build-dir cd build-dir cmake .. ninja #Error, you are using make, make #now yes That is a simple use case. It is true that you need to add external dependencies handling and will think of this. But this is not about maximum flexibility right now. It is about *maximum simplicity*. I see so many people here saying that it is so easy to invoke the compiler, or to create a CMakeLists.txt and so on. Yes, it is, for you. You have to know: - A minimum of cmake. - Create build directories and not make in-source build by accident. - Create the CMakeLists.txt, list files, know the commands. - In any other case, know how to invoke your compiler. - Oh, where was the output left? Look for it. - Invoke your executable. Compare that to dropping a file and saying &lt;simple-project&gt; run and done. By a person that comes and "all he wants to do is program". There is no contest. And this can be expanded to defaults for embedding libraries and linking internal dependencies from the project automatically. For external dependencies this will require some metadata. I do not plan to do a full-fledged build system. My purpose here is to make it the simplest possible using existing backends and get up and running *the fastest possible*. 
&gt; We do extensive testing before shipping anything, including a rolling builds of a bunch of popular OSS libraries. I report a dozen compiler bugs per month mostly about new language features advertised as supported and 10 of these are real bugs that take from a couple of days to 6 months to get fixed depending on the wishful thinkness times shame tolerance coefficient of the compiler dev and severity of the issue (new language features are typically severe when they break old code). All of the bugs I report could have been caught if the compiler devs actually tried to use the feature to do something useful after implementing it, or, as IMO they should, tried to break their own implementation of the feature. Probably the best way to do so is to take range-v3 or the cmcstl2 and try to replace some workaround around the lack of the feature by the feature. However, most of the tests I see in clang and gcc for new features can be described as "the compiler can parse the feature, and using the feature in hello world to do nothing useful does not break anything". Together with your statement of "rolling builds of a bunch of popular OSS libraries _that do not use the feature_" (how could they? it wasn't implemented before!) gives compiler devs a sense that their implementation is solid enough to write the feature in some compiler-dick-measuring-table as "implemented! btw, we were first!". Sorry, but no. I expect a recently college grad to write unit test for new code. And when that pass, I expect them to try to explicitly break their code, and fix it, and we catch this in code review. One would think that professional compiler developers would have a higher standard than recent college grads. Yet every single time they seem surprised that a new feature that is completely untested broke. 
&gt; I don't think project structure has any bearing on the simplicity of the act of coding - especially when there is so much tooling allowing you to browse your code by sorting it semantically 1. In this case you are relying on the tooling already. With a standard layout you do not need to rely on it. You know where things are. The same way that class com.mycompany.Widget is in directory com/mycompany in Java. There is a mapping and this is one of the points of this. 2. My point with the directory layout is to also, besides having targets for free, know where to find things among projects if people decide to follow it for new projects. This would be a net win. Uniformity and simplicity in most cases beat any other considerations. But if you still need all that complexity, just enter expert mode and go for the build system itself with all its features.
The standard layout maybe does not add too much as you say. The standard layout is not a goal in itself, though it is nice to have it also IMHO. The goal here is that the workflow goes from: 1. create dir for project. 2. now I create a .cpp file or I add a src/ (First decision). 3. I create a src directory. So now, should I create a toplevel CMakeLists.txt or one at the toplevel and a recursive one in src? 4. Go for first solution. 5. Ok, now I create the CMakeLists.txt: let's learn CMake (or Meson or build2 or whatever) and add that build definition file. Cool I am done. 6. Now I need to build, so let us create a build directory. Let us call it... (another decision) 7. Cool, now I enter the dir and invoke cmake .. 8. Now invoke my tool for compiling. 9. Now let us run the executable... where is it? ah here, under src I guess? In the eample above you must be aware of more things than you might think, such as knowing a minimum of CMake, where to put files, create build dirs, invoke cmake, find executable, run executable. It looks simple but it is simple after you do it a few times and you still have all this boilerplate and overhead. Compare to this workflow: mkdir project cd project emacs myfile.cpp simple-builder run Done: project generated, build dir created, executable compiled and located and executable run. Obviously the second workflow is going to take to a person not familiar with C++ a fraction of what it takes in the first workflow. I have no idea of Go and I was astonished at how simple is to do this. This is my inspiration to go ahead with something that looks similar. And not stopping to take all these decisions is something that we need to make things simpler.
Even my life problems?
or maybe you have gcc. Or maybe VStudio compiler and you always use another one so you have to go to the manual. Or maybe you decide to learn CMake or Meson or one of the one million build systems around. Or, wait... no, maybe you can stick to a directory layout and not write a single definition file and do: mkdir myproject cd myproject emacs myfile.cpp simple-builder build (optionally simple-builder run to also run it). 
&gt; Most of what we're doing right now is implementing features that other compilers have had. There are a lot of libraries out there already using C++17 features. They make beautiful test cases for us! In my other comment I did not consider this, but a lot of libraries I work with disable features not supported by MSVC when being compiled by MSVC. Are you forking these libraries and upgrading these checks?
&gt; That's what Python is written for. It is literally built for fast scripting. C++ has many more complexities in terms of build options. You're trying to simplify something that's already been simplified. This is a false dichotomy: you can have something running as fast as in python. Not because you have a systems programming language you have to use all the flags existing in a compiler. You can ignore most things and start simple and have something running pretty quickly.
&gt; In this case you are relying on the tooling already. yes, and I think that not relying on tooling if it is available should not be considered as an use case. Do we see highways accommodate for people who choose to go by horse ? &gt; know where to find things among projects if you know where you want to go, you don't need to know where it is on your hard disk. Again, all IDEs have a "find class" / "find whatever" function accessible from a single shortcut.
Isn't that why we have acronyms? You're basically removing the most important benefits that come with belonging to a community like this, ie, that people will understand you.
&gt; yes, and I think that not relying on tooling if it is available should not be considered as an use case. Do we see highways accommodate for people who choose to go by horse ? There are not highways everywhere. Sometimes you do not have a choice. My goal here is to have a layer that can unify any build system. I do not want another build system, what I want is a simple thing that can be plugged into existing things with powerful backends and definition languages, namely, that means Meson and CMake nowadays. I also want to keep it invocable from a command line. Not everyone uses Qt Creator or CLion. Some of us use emacs + some plugins and invoke the tools directly :) So let me tell you that there is at least one user of this: myself :)
There are not so many alternatives ...
You keep coming back to an example with a single file - you don't need a standardized directory layout just to compile a single file. If you can teach a tool to recognize a directory structure, you can teach it to simply compile and run a single file. I understand that you want to get running a c++ project as fast as possible and use a standardized directory structure as a kind of build specification to achieve this, but for trivial cases, a directory structure isn't required in the first place, so why standardize one? Where a standardized layout becomes imho interesting is for projects that actually need a directory structure (e.g. with multiple artifacts, unittests, 3rd party dependencies etc). So, I think we all agree, that a standardized structure doesn't suffice (but might still be useful) as a build specification for really complex projects and I hope I have convinced you that it is not useful for trivial cases either. Ergo, we should put the focus somewhere in between and once the supported scenarios are agreed upon (at least roughly) we can discuss the desired directory structure.
I'd same the same thing applies to all compilers though? There's plenty of features that are "done" / "implemented" by clang and GCC that simply aren't. You've got compiler bugs, implementation issues, potential mismatches between developer interpretations of the standard, etc. If you dive into the bleeding edge, you're almost certainly going to hit these sorts of problems. The vast majority of my hobbyist code simply doesn't compile. Different compilers will compile different bits (and this is helpful for producing bug reports and learning what the standard actually allows, not what the compiler tells you it does), but nothing can compile it as a whole.
I plan to extend this to multiple exes and libs in a project. The command line will still be “build-tool run exe” or “build-tool build” in case I finally jump to implement something.
There are a lot of customer cases here: https://www.qt.io/built-with-qt/ And on the youtube channel here: https://www.youtube.com/playlist?list=PL661F1B899D92A4E4 
And what you are proposing is to learn yet another build system, because it is so much simpler than all the other ones. Someone already linked the relevant xkcd comic.
&gt; And what you are proposing is to learn yet another build system, because it is so much simpler than all the other ones. Someone already linked the relevant xkcd comic. It is misleading to just say that it is yet another build system. Wrong and superficial analysis. My analysis comes from real problems: 1. you are not going to convince everyone to use CMake, Meson or whatever. We have CMake, Meson, Waf, SCons, MSBuild, premake and probably others. 2. if you are ok with going through cmake manuals or meson (I have done it myself before) and spend hours there, good for you. Some people just want to do: - open file and code. - build-tool run. - see something on screen Some people will not just use C++ if you stick to that mindset of "what we have is ok and cannot be improved". I myself went to go and had something compiling in seconds. It was a single command. There was nothing else: editor, code and "go build" and "go run". The landscape, though, is very different in C++: you are not going to have a standard build system anytime soon. If you think this is yet another build system, well, that is up to you: what I care about is to get up and running the fastest possible and to make it more beginner friendly. There is a long road to go in C++. I really fail to see how this is implementing a full build system. It is just delegating to good tools and make a uniform interface that build systems can adhere too (plus a standard directory layout so that the toplevel tool can figure out lots of things without having to write *a single line of build system*, just a command. The only thing this tool would add is layout analysis + script generation with the hope that the interface is single commands. You can see the cognitive overhead that using C++ had for the person who tried C++ in the post "All I want to do is program...". Even more, you can see the number of upvotes. People are crying for something more simple. This is not another build system. It is just a simplification layer that could work with any backend. We need further simplification and a unified interface. It would be nice if there is a day where no matter the backend you use, you have a considerable amount of targets available without doing extra work and just invoking a tool because the layout is an interface between you and the backend. At this point no matter what you are using. Nowadays every project is just free form, the commands different, the conventions different. I have suffered this myself to the point of becoming quite proficient at autotools, CMake and Meson. If you really want to spend your time reading manuals and becoming an expert, noone will stop you. Many people will just not do it and this hurts adoption: I will take this road, I really think it can improve things.
&gt; And what you are proposing is to learn yet another build system, because it is so much simpler than all the other ones. Someone already linked the relevant xkcd comic. It is misleading to just say that it is yet another build system. Wrong and superficial analysis. My analysis comes from real problems: 1. you are not going to convince everyone to use CMake, Meson or whatever. We have CMake, Meson, Waf, SCons, MSBuild, premake and probably others. 2. if you are ok with going through cmake manuals or meson (I have done it myself before) and spend hours there, good for you. Some people just want to do: - open file and code. - build-tool run. - see something on screen Some people will not just use C++ if you stick to that mindset of "what we have is ok and cannot be improved". I myself went to go and had something compiling in seconds. It was a single command. There was nothing else: editor, code and "go build" and "go run". The landscape, though, is very different in C++: you are not going to have a standard build system anytime soon. If you think this is yet another build system, well, that is up to you: what I care about is to get up and running the fastest possible and to make it more beginner friendly. There is a long road to go in C++. I really fail to see how this is implementing a full build system. It is just delegating to good tools and make a uniform interface that build systems can adhere too (plus a standard directory layout so that the toplevel tool can figure out lots of things without having to write *a single line of build system*, just a command. The only thing this tool would add is layout analysis + script generation with the hope that the interface is single commands. You can see the cognitive overhead that using C++ had for the person who tried C++ in the post "All I want to do is program...". Even more, you can see the number of upvotes. People are crying for something more simple. This is not another build system. It is just a simplification layer that could work with any backend. We need further simplification and a unified interface. It would be nice if there is a day where no matter the backend you use, you have a considerable amount of targets available without doing extra work and just invoking a tool because the layout is an interface between you and the backend. At this point no matter what you are using. Nowadays every project is just free form, the commands different, the conventions different. I have suffered this myself to the point of becoming quite proficient at autotools, CMake and Meson. If you really want to spend your time reading manuals and becoming an expert, noone will stop you. Many people will just not do it and this hurts adoption: I will take this road, I really think it can improve things.
Ok, presented like that it seems like a useful idea, and if you provide an environment that does this I'm sure it will help people. I wouldn't call this a default for C++ though, but an easy way to get beginners up to speed. Once you've been programming for a while none of this stuff matters anymore, though - you'll have systems that work fine and don't particularly need changing. I'd like to point out what Visual Studio already does this: you can set up a new project in a fairly short time with defaults that are generally ok. So maybe this is a solution for Linux as well: just have a tool that lets people set up a default project of a specific type (lib, exe, etc.). 
&gt; There is every reason for me to believe that my algo(not exactly mine ;) ) should work faster in all kinds of inputs. Your understanding of the big-O notation seems to be flawed. The notation doesn't tell you which algorithm is faster - only how speed will vary, and only for a sufficiently-large size of the input data (where sufficiently-large depends on the algorithm, implementation details, compiler, operating system and - possibly - planetary alignment when you ran the code for the first time). In practice, at small input data sizes, the big-O notation is useless. It is also possible to write a more efficient algorithm (better big-O class), but in a much slower way than a worse-efficiency one - for _sufficiently-small_ input data sizes. 
&gt; I'd like to point out what Visual Studio already does this: you can set up a new project in a fairly short time with defaults that are generally ok. So maybe this is a solution for Linux as well: just have a tool that lets people set up a default project of a specific type (lib, exe, etc.). For WIW I am aware of IDEs as well. They are nice. What I would like to have is a solution that is potentially compatible with anything. Why? Because we will never have a unified build tool at this point. We can have an interface on top of it and target it though. Not everyone can afford the luxury of using a single tool. I think it would be a good service also if I find the same interface no matter the backend in Linux, Windows, etc. No matter how expert you are, there are a ton of build tools/languages/interfaces right now. We have to simplify that.
While I agree that it is hard to test, are there that few projects enabling floating point exceptions ? At work we enable those through _controlfp_s (not flags), I'd say those are pretty important in debug for any application doing some serious work using floats... (Physics, Game engines, rendering, ...). I hit some issues recently because VC++ generated a (halfly) SIMD-optimized loop that did a div and the 2 last values were set to 0.f (hence div by 0.f). (We ended up doing the div before the loop and then use multiply to 'fix' it). Not saying it's easy to test those, just wondering if those kind of flags should really be marked as "used by almost nobody"... Unless you guys have telemetry that indicates it's the case ?
I sometimes try [the daily MSVC builds](https://visualcpp.myget.org/feed/dailymsvc/package/nuget/VisualCppTools.Community.Daily.VS2017Layout) to see if the bugs I'm reporting/following are getting fixed (but most of them are unfortunately low-priority). But there are a couple things that make them hard to use: 1. It would be nice to have a script included with the package, that opened up a PowerShell prompt with the appropriate PATHs and environment variables set to make testing the daily build on the command line easier. There's a `cmd` script in the `build` directory, but that doesn't work with PS and doesn't add a entry for the daily MSVC directory to the PATH with a high enough priority that it would get chosen instead of the one you might already have on the PATH (I have the `cl` directory from the latest preview already on the PATH). 2. The download speed for the daily MSVC build packages is really slow. I've got a measly 5MB/s down, but it usually downloads with a speed &lt;300KB/s (that's over 12 times slower than what my not so good connection could handle).
Andrew, Thanks! Will install the last toolset (after freeing up some disk space). Will e-mail you re: this bug I am seeing 
Ah, no, that's not so good. I don't see the advantage of a project having one source subdirectory per executable, because nearly always the code doesn't logically divide that way. Very many of my production C++ projects have had more than one binary target yet would not fit into this format. For example, my last project but one had four binaries: 1. The main program 2. A time-limited demo version 3. A tiny utility we sent to people whose binary wouldn't even start to get us system information so we could troubleshoot 4. Another utility we gave away for free. 1 and 2 were basically the same binary, with different compile-time flags. 3 and 4 were quite different, but had only one or two small source files of their own - all the real functionality came from the same codebase as 1 and 2. 
This kinda makes me want to see a day-in-the-life video showing how compiler devs do things, but their screens would probably be blacked out :P
UB if people write `using namespace my_name;`
I don’t think so. A mess maybe, but definitely not UB. 
Yeah, I corrected that part, after I realized I was probably wrong.
PascalCase/camelCase
&gt; you are not going to convince everyone to use CMake, Meson or whatever. No, but if one of these was really effective out of the box, then we could point to it and say, "To quickstart your C++, download this program and go" and this would actually solve the problem.
Yes, if you are creating an API, then having a separate directory just with .h files which third parties will use. Fine. But most of us aren't doing that most of the time. If I have a class `Foo`, surely I want all the code for that class in the same directory? Why would I want `foo.h` in one directory hierarchy and `foo.cpp` elsewhere? I like to be able to toggle between the .h and the .cpp file with a keystroke. I use emacs, an editor that's good at customization, but you can see in my configuration files the long history of other people's different .h/.cpp directory conventions that I've had to support... I never really understood the appeal of that idea, nor do I know any other language that does that. 
Your argument would be more convincing with some actual reasoning behind it.
@utnapistim I very well understand the big-O notation. I know saying O(n) is faster than O(n^2) is not always true. My point is that the algorithm I used leads to lesser comparisons per iteration and should be faster. i know that there is additional book-keeping but time should be faster.
My doubt is that the algorithm I used leads to lesser comparisons per iteration and therefore should be faster. I know that there is additional book-keeping but shouldn't the time be less?
&gt; Why would I want foo.h in one directory hierarchy and foo.cpp elsewhere? Again, separation of header and source. Even if you dont write a library, it keeps things separated and clean. .cpp files and .hpp files have very different purposes, but I'm sure you already know this. But let me clarify anyway; .cpp files are sourcefiles for _one_ compilation unit each, that will be compiled in to one compiled object file per source file. .hpp files are header declarations, which are used as tools by sourcefiles, to resolve symbols, structures, inline functions, defines etc. The .cpp files are only needed when you want to compile a specific project. The .hpp files may be needed in more scenarios than this, for example if two or more applications share the same code, or if the project you are creating is a library. Separating the .hpp and .cpp generally makes life easier, without any actual negative side effects. For example, it can make packaging a project much easier, as you dont have to extract the .hpp files out of a directory hierarchy, you could just copy the include folder directly. &gt; I like to be able to toggle between the .h and the .cpp file with a keystroke. This is a flaw with your IDE if you dont have this option already. With Visual Studio, it's CTRL+K-O by default, in KDevelop, its Ctrl+Shift+C by default.
Ahh ... sorry for assuming :)
The comparison is almost free, roughly on par with the housekeeping you are doing in terms of CPU time. Bottom line: O-notation is all very nice, but those constant factors actually also count in real life, and for small datasets (like this) it is almost meaningless.
Gosh, I hit compiler bugs almost daily. It's mainly because my code has to build with g++ 4.8.5, but I believe some of the bugs I have to work around are still there in recent versions, or the bug was fixed but introduced a new bug, so the code still doesn't work. Sure, some of my code is really clever, but sometimes I wonder if they even tested the feature at all. Like, in g++ 4.8.5 you can't move a `std::fstream`, so I have to do some stupid acrobatics to be able to return a struct that contains a `std::fstream`.
Thanks for your feedback, I will look into this.
Whoa, I was thinking `std::advance`, then I saw your comment. advance and next look painfully redundant with each other, unless I'm missing something? (seems like next should be preferred).
Ubisoft to the rescue! - https://github.com/ubisoftinc/Sharpmake And there's also GENie (lua script, fork of premake); - https://github.com/bkaradzic/GENie 
`std::advance`is O(1) if the iterator meets is a RandomAccessIterator.
&gt; CMake only makes sense if you're already using it. Or if you use CLion.
Yes! He just clicks his ruby slippers three times and...no wait, /u/spongo2's not the one from Kansas. My mistake. 
I never claimed to be a UI guy! Backstory: Recently you couldn't actually report a problem on the website itself. A group of people on the C++ team met with the folks who own the report-a-problem page and got the functionality changed. Now we have a tab! (And you can actually report a problem from the browser.) Yay!
This may not be technically required by the standard for `std::next` but it doesn't really answer my question; they are exactly equally capable of being O(1) for random access iterators. In fact, the suggested implementation for next is in terms of advance.
/u/Ikkepop, thanks for the report. /u/mechacrash is right: the bleeding edge causes some cuts sometimes. And the bleeding edge for MSVC is a bit behind the bleeding edge for Clang/GCC right now. 
&gt; With regards to users as "zero cost QA", there is a balance between giving developers early access to our bits and shipping bugs. I like the frequent shipping but coupled with the dubious stability of new releases and inability to upgrade to anything but the latest version vs2017 is shaping up to be a nightmare for use in production. :(
https://developercommunity.visualstudio.com/content/problem/96411/impossible-to-ignore-warnings-from-system-librarie.html On this website someone from Microsoft appears to have confirmed they are "working on" functionality similar to -isystem. Can't come soon enough!!!!
If move is broken for fstream do you not just concede and put a pointed to the fstream in your struct?
&gt; Most of the tests I see in clang and gcc (I don't use MSVC) for new features can be described as "the compiler can parse the feature and using the feature in hello world to do nothing useful does not break anything". It wouldn't surprise me if MSVC tests look the same MSVC has a number of different testing strategies, including: 1. Unit tests written by the dev at the time they implement the feature. These are the sorts you describe, though some devs are better than others at writing negative tests. 2. Test suites licensed from professionals such as those from McCluskey, Plumhall, and Perennial. 3. Regression tests from previous bugs fixed 4. Building real-world code ranging from Windows and Office to a bunch of OSS repos. We know that we don't find all of our bugs, but the majority of bugs are found internally. We really appreciate developers getting in touch with us, whether it be a bug report or just feedback about the product. &gt;&gt; We should be holding compiler developers to a higher standard than recent college grads I believe that we do. And the GCC/Clang/LLVM developers I know are generally better developers than the recent college grads I know. (Some recent college grads are pretty amazing, though!) Regardless, we're hiring. If you want to increase the quality of compiler developers, come be one and help raise that bar.
why would you create ANOTHER reserved namespace when you can just put something inside of std where it's already reserved?
Well maybe I sounded bit too harsh, really it's just that the vc++ blog has kept promising fold expressions and they kept not happening to work for me, at all. Felt like someone forgot to checkin the feature into source
We don't maintain forks of these. We generally carry patch files that we re-apply as the library evolves. And we push back changes to the library as we make fixes. For example, we worked with Boost for about a year to get all the MSVC-specific defines removed from Boost's develop branch. 
With regards to PowerShell accessing scripts, I use Lee Holme's [Invoke-CmdScript](https://www.powershellgallery.com/packages/WintellectPowerShell/4.0.0.1/Content/Code%5CInvoke-CmdScript.ps1). 1. There's a script in the NuGet package that sets up environment variables that indicate where components are located. VCVars reads those environment variables. So you can run that NuGet script, then VCVars, and get a compiler environment. 2. We're factoring the packages, which will enable you to only install parts of the product. 3. The ABI incompatible major version will rev the major version. That is the 14 will change to a bigger number. 
The naming convention as been set to snake_case since Denis Ritchie wrote C back in 1972. C and C++ specs have been following snake_case since. That's the existing pattern and it's really not up for debate.
Ah yeah I recall some STL commits and mailing list post doing just that for the Boost repo. Props, that's a lot of hard work, but with real community benefit. AFAIK no other compiler devs do that! 
Thanks! Our entire team does that. You might think that all of Microsoft is doing that: remember the stories about [Microsoft having the most OSS contributors?](https://www.networkworld.com/article/3120774/open-source-tools/microsoft-s-the-top-open-source-contributor-on-github.html) I'm sure the numbers are skewed in some fashion, but this kinda of effort had to go into these stats. 
Read both because in Modert C++ he assumes you're aware of the issues identified in C++. Also, do not pass up the chance to read Effective STL by Meyers. 
There was no `C++` in 1972. And it wasn't set anywhere. Language can't follow some naming pattern (unless it's enforced by the standard). Standard library can, but in C case it's hardly a snake_case. More like snkcase. And C++ std lib came pretty late so there were already many existing projects using different naming conventions. Anyway, that was then. Now there are eve more diverse projects with millions of LOCs so you can find a "pattern" among them for almost any conventions of your choosing.
The amazing /u/caseycarter removed the library from the repro (thus absolving himself of any responsibility): template&lt;class T, T N&gt; struct integral_constant { static constexpr T value = N; }; template&lt;bool... B&gt; struct fold_and : integral_constant&lt;bool, (B &amp;&amp; ...)&gt; {}; static_assert(!fold_and&lt;true, false, true&gt;::value); It is a fold expression bug, and he's entered it into our bug database. Thanks again!
i don't understand why I would care or consider any other projects than the standard.
Clarifying: I removed `fold_sum_1` and `fold_sum_2` from the repro because our current development compiler understands them just fine.
I guess that would work better than my current acrobatics 😛
It's a historical relic, not a modern design.
Thank for you this response, I'll buy all three then. :) I was just trying to make sure that the contents didn't overlap. I appreciate the response.
&gt; I do not care noone could agree a standard layout before. That line sounds like a good introduction to https://xkcd.com/927/ :-) &gt; What I care is that I can start a project, add some docs, generate them easily, targets and things, invoke the tool and have something that is executable, some docs and whatever without having to write a build definition file in any of CMake, Meson, Tup, Waf, Scons or whatever. For simple things, I do `make whatever`, and it automatically infers that it has to compile `whatever.cpp` and link it to the C++ library. For more complex things, I don't see an alternative to writing a build script. Starting with simple things: if you have `a.cpp` and `b.cpp`, do you compile those into one executable or two? If one, how do you call that? But then, project(foo) add_executable(foo a.cpp b.cpp) isn't too hard. Neither is bin_PROGRAMS = foo foo_SOURCES = a.cpp b.cpp 
is it conforming to break stuff in namespaces other than std::?
Here is a link to compiler explorer with simple range example. Note that range library is not in the standard and that compiler explorer only compiles, does not run code. https://godbolt.org/g/fBRL9K
this was a known [limitation](https://herbsutter.com/2011/10/07/why-no-container-based-algorithms/) of C++ nowdays they could fix it, but everybody is just waiting on ranges. If you want it now either use ranges or use google abseil, I write about abseil for a bit [here](https://medium.com/@gaussnoise/why-google-abseil-is-cooler-than-it-looks-and-what-it-can-teach-us-about-c-libraries-in-general-ec9bbda48941).
https://www.reddit.com/r/cpp/comments/7jb405/using_stdreverseor_any_function_accepting_an/dr79eaz/
Riding on the back of this question, any one know when Bjarne's "The C++ Programming Language" is going to have a successor from the current 4th edition? I'd love to buy the print but I'm afraid the minute I buy it, the next edition will be announced.
Ok thank you!
Thanks for the links! I'm not dying for it but it would be convenient
the difference is like a difference between ++i and i + 1
Technically, it is nonconforming for an implementation to expose any `pretty` identifiers to users that aren't in the Standard - only `_Ugly` (and `__ugly` etc.). 
If somebody wants some video introduction to actors in C++ this are videos I saw many years ago and I liked. Notice that it may be quite different from SObjectizer https://channel9.msdn.com/Shows/Checking-In-with-Erik-Meijer/Checking-In-Rick-Molloy-Gone-Native https://channel9.msdn.com/posts/Rick-Molloy-Actor-based-Programming-Control-Flow-versus-Data-Flow
&gt; Why isn't there a command like &gt; lib_builder https://www.openssl.org/openssl/latest c:\downloaded_libs\openssl Cget can already do that with cmake packages(ie `cget install http://zlib.net/zlib-1.2.11.tar.gz` will install zlib in a local directory). &gt; followed by &gt; lib_linker add c:\downloaded_libs\openssl c:\projects\my_project That would be cool. It shouldn't be a major a problem if all packages provided there usage requirements as pkgconfig. I would like to add to cget a `cget info` which gives some guidelines how to use a project in cmake. 
&gt; Why? Because we will never have a unified build tool at this point. We can have an interface on top of it and target it though I think a layout of files doesnt help with that at all. The big problem with different build tools is describing the toolchain across all of them. Most build tools are lacking(for example, cmake is the only build tool that I know of that has a flag to tell it where dependencies are installed). So having a standard toolchain description can go a long way in helping unify build tools, and help with package managers. I discussed some of that [here](http://pfultz2.com/blog/2017/10/27/universal-package-manager/).
Every "actor" framework for C++ mentioned in the starting post looks very different from each other. CAF is very different from QP/C++ and from SObjectizer, QP/C++ differs from CAF and from Just::Thread Pro and so on. There is a slides where I shows how can implementations of Actors look in different frameworks: [Actor Model and C++: what, why and how?](https://www.slideshare.net/YauheniAkhotnikau/actor-model-and-c-what-why-and-how). Strictly speaking SObjectizer is not a pure implementation of Actor Model. It borrows some ideas from Actor Model and sometimes agents interaction in SObjectizer is performed just like in Actor Model (I speaks about cases when agents use only MPSC-mboxes for message passing). But SObjectizer also support some kind of publish-subscribe model (via MPMC-mboxes) and CSP (via [mchains](https://www.slideshare.net/YauheniAkhotnikau/dive-into-sobjectizer-55-ninth-part-message-chains)). But we often use term "Actor Model" in conjunction with SObjectizer because it is much easier to explain what SObjectizer can provide to developers.
So when is it expected to ship ?
My "used by almost nobody" comment is based on Chomium/Windows/Office/a blizzard of other OSS projects/our 30+ years of accumulated tests not catching this. &gt;VC++ generated a (halfly) SIMD-optimized loop I think this is why the vectorizer doesn't engage under /fp:except. At least, I'm assuming it doesn't engage as /fp:fast is usually necessary to vectorize anything floating point related (I haven't actually tried).
I'm curious - how do you achieve it?
Hey, why the downvotes? Care to explain?
Well, I never felt that way, at least.
In my case, I began with assembler and piled on from there.. which sort of makes it necessary to attempt to link everything learned with what's likely happening at a low level. It turned out to be a useful niche for a long while. I suppose that track of learning is a lot less common than it used to be.
It seems to me that there are more things than just fold expressions that were broken by 15.5+. Two days ago our CI-tests for the PEGTL on AppVeyor worked fine. Now, after an update on AppVeyor's side of Visual Studio and with a few commits to our code that did not affect the code involved in the problem, it suddenly fails. Working (MSVC 19.11.25547.0): https://ci.appveyor.com/project/taocpp/pegtl/build/master-459/job/2ght553tq8vh5mhd Failing (MSVC 19.12.25830.): https://ci.appveyor.com/project/taocpp/PEGTL/build/job/f62gw90eove3qaqw The problem seems to be connected to pack expansion in general, so maybe it helps /u/STL and his colleagues to analyze it. It might be the use of an unevaluated context, maybe the double expansion? I'm really at a loss here. Here's an excerpt from the code that previously worked (and still works on Clang and GCC) and that now suddenly fails: ```cpp template&lt; typename... Actions &gt; struct apply_impl&lt; apply_mode::ACTION, Actions... &gt; { template&lt; typename Input, typename... States &gt; static bool match( Input&amp; in, States&amp;&amp;... st ) { using action_t = typename Input::action_t; const action_t i2( in.iterator(), in ); // No data -- range is from begin to begin. #ifdef __cpp_fold_expressions return ( apply_single&lt; Actions, decltype( Actions::apply( i2, st... ) ) &gt;::match( i2, st... ) &amp;&amp; ... ); #else bool result = true; using swallow = bool[]; (void)swallow{ result = result &amp;&amp; apply_single&lt; Actions, decltype( Actions::apply( i2, st... ) ) &gt;::match( i2, st... )... }; return result; #endif } ``` Note we are currently not using/testing C++17 on Visual Studio, so the non-fold-expression work-around is used. 
You keep putting up straw mans. I can do exactly what you showed in your example without any build system without knowing anything that isn't shown at the beginning of every c++ tutorial I know. Even for slightly more complex programs: As long as I don't have to deal with dependencies or special compiler flags I don't need more time to learn how to do that in meson or cmake than it would to take me to learn a standardized directory structure and how to use your script (the time-consuming part is actually to find the respective tutorial in Google). Where using a build system becomes necessary and difficult is if you have dependencies (that might get build with a different build system), if you want to run unit test (with and without sanitizers) compile with lto, use a non-default c++ version, add/suppress warnings, generate headers, use modules and all of that portably across different platforms and compilers. I've never said, nor did I want to imply that the situation could not be improved or that a standard directory structure wouldn't be beneficial. But please, instead of showing how much better your idea works for compiling a single file compared to cmake (which you would never use for that job), please argue on the basis of more realistic examples. Also, I don't want to discourage you, but unless you true to stick very close to existing practice I think it will be a hard fight to standardize any layout in a community that essentially can't agree on anything
Correction: I wasn't trying hard enough. Both `fold_sum_X` functions compile with just `/std:c++17`, but `fold_sum_2` errors with `/std:c++17 /permissive-`. Let's file a separate bug for that, too! I like to keep the compiler guys busy.
The compiler team has been refactoring the pack expansion code, moving away from the extremely brittle token-replay approach and towards a real AST, so regressions are possible. Can you prepare either a minimal repro (ideal!) or a preprocessed repro plus commandline?
We can talk about lots of things, but not unannounced release dates.
The problem is I don't have Visual Studio - because I don't have Windows. I'm using AppVeyor for our CI tests because it's the only way to run MSVC for me, but this is an extremly tedious cycle and not really suitable for creating some minimalistic example. Also, http://webcompiler.cloudapp.net/ is currently giving me "We’ll be back soon!", so I can't even try to create something over there, sorry. You (or someone from your team) could, however, just clone the PEGTL from &lt;https://github.com/taocpp/PEGTL.git&gt;, we have a `CMakeLists.txt` which we are using for AppVeyor. I understand that this is probably asking for too much, but I currently don't see any way how I can create a minimal repo to reproduce the problem.
I find it a bit sad that float exceptions do not get much traction. It might also be the case that the applications you are talking about are not that math heavy or just use control_fp. I would have them enabled for debug builds just like we enable bounds checking. At least it caught many bugs for us (it is impressive how a simple -0.f can cause issues sometimes) 
Because "other projects" in total are used overwhelmingly more than even standard lib? Especially the C++ one.
they are not a native english speaker, it's reasonable that they make mistakes.
Kinda redundant, but `advance` modifies passed iterator (and returns nothing), and `next` takes as a value and returns without changing.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7jngcp/graph_analysis_in_c/dr7qes3/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Consider Boost.Graph.
Because standard library is only a tiny tiny piece out of all the useful code out there.
That really depends on how bad the code inside the namespace is. 
i got excited over nothing. I thought this had something to do with POSIX shared memory.
I guess maybe reflects a change in thinking where output parameters are seen more negatively.
Well as of this fix all the STL's tests run with /fp:except enabled (I added it to 2 of the 16 sets of C1XX switches); hope that makes you happy :)
i agree somewhat, but I would put more emphasis on the fact that compilers became better and copying can be better optimized than 20 years ago. If you support c++11, you're a pretty modern compiler.
Idk... here's my upvote
Looks great, I will finally be able to `-Wall` my code without getting hundreds of warnings from external libraries and having to suppress them.
Its great that msvc has finally implemented this! Now when i make a cross platform lib targetting gcc clang and msvc, i can configure msvc similarly to the others and try to be warning clean wrt all of them, instead of basically ignoring msvc warnings.
None of it is relevant. The only commonality between all C++ users is the C++ language. Whatever the language does is what everybody else should do else you're not following existing patterns set forth by the language. It's as simple as that. It is.
You are saying that a good programmer has to teach himself how to code. You know reading a book is still teaching yourself. You don't have a teacher in front of you. Reading a book is just the better version of using the internet. But /u/NewFolgers explained that very well. Also not trying to offend you but to me you sound like a 13 year old kid being proud of Hello world and saying it is superior. 
&gt; Whatever the language does is what everybody else should do else you're not following existing patterns set forth by the language Point me to where language dictates: "all valid C++ programs should be written in snake_case".
It’s really mature if you stick to the areas that are close to its core comptenties: statically built C++ or Java. Python, Go and shared library C++ do work but have some rough edges. The biggest day to day thing is the local server likes memory, and it should be as fast as ninja since it has an always on process but it’s not (it still is pretty fast though).
Thanks for the info, the configure support is a bit of a bummer but you can get around some of it (after all it’s part code gen and Bazel is *great* at code gen). I was hoping meson had plans for the remote caching/build/test support Bazel has along with its build isolation features. Also I think you miss-read the Bazel community a bit, they really updating things to support non Google use cases, just at a slower rate than smaller community first projects.
You can't move some tupe due a **compiler** bug?!
Very nice. I've been waiting for this feature forever so I can compile my stuff with -Wall. The parameter external:templates- is a nice inclusion so we can get warning that happen in 3rd party library code but are still actionable. Now to wait for gcc and clang to add this flag as well and for CMake to have some variable to activate it.... 
My plan is to add those at some point. I will do some tests to see how it works. :) I am telling you that many people do not know compilers, flags and build systems as we do here. For those people it is not accessible enough the environment nowadays. Even of it has improved a lot. This is my opinion. Yours may differ. 
No? A build layout does not help? How do u propose to guess exes and libs in a project without build files then? Please let me know your idea.
i wish one could just subscribe to books and get an update automatically :)
sthing is not a typo. and it's not in any spell checker. It's not a "mistake". 
I didn't say typo, I said mistake.
That sounds really helpful. Our codebase is currently riddled with pragmas around system headers. ^(Now if only we weren't still using VS2010...)
&gt; src/ for sources and includes. src/ is included in the build by default No. For small projects having all the source dumped somewhere and being indiscriminate about public vs. internal headers is fine. That's not acceptable for large projects though. If I were to recommend something it would have: - top level include/ and src/ directories. - Public headers go somewhere in include/&lt;unique project name&gt;/ - The build system has include/ in the header search path for the project and for anyone that depends on the project, so that public headers are always included using a path including the unique project name. The public headers can either be at the top of that hierarchy, or there can be sub-folders for components within the project. - private headers stay within their modules' src/... directory and are not found via header search paths, so that they can't easily be included by anyone except the source files in that module. Making a strict distinction between private and public headers is perhaps overkill for small projects, but then that's why a 'one size fits all' solution is problematic. &gt; the subdirectories in src should match the namespace. No, there should be no such correlation. If I want my project to use a single namespace across all modules, with no nested namespaces, that's my business. Requiring a bunch of extra namespaces nested under my top-level organization namespace is a terrible idea and I don't want to nest namespaces that way. &gt; should we follow the standard library naming conventions? I prefer to do that with very generic and broadly applicable components. For components that are very domain or application focused I generally use a different style that uses more capitalization. &gt; should namespaces match directory layout under src/? I think that yes. Absolutely not.
Oh, true, I guess that's a bug in the standard library and not in the compiler.
&gt; I am telling you that many people do not know compilers, flags and build systems as we do here. I have the impression we are running in circles. There is no buildsystem or compiler flags here: `g++ foo.cpp` so why do you keep reminding that people don't know buildsystems - I never disagreed on that. But int turn, if your code requires `g++ -std=c++17 -Wall -lopencv foo.cpp` (with opencv being installed on the system or a package manager), how are you going to to specify that information just via the directory structure (ideally in a Cross-Platform manner)?
Finally! My biggest and longest living issue with MS toolchain is fixed. Thanks. Do linters and analyzers also respect this?
Not all use cases can be handled with absolutely no metadata. That for sure and I also agree on that. What I want is to guess most defaults and see how I can handle the rest later with minimal overhead. Can do much better than now.
Interesting. I wonder how a build system can take care of this auto-magically. I suppose for imported libraries we could automatically re-map `-I` to `/external:I`. However, there could be situations where you do want to see warnings for certain imported libraries. For example, if you are developing project `libfoo` and want to see all its warning when used by project `foo`.
No, but they probably support -isystem and #pragman GCC system_header. This was just released a couple of days ago with 15.6 Preview 1 and we haven't had a chance to tell users about it. This blog post is the first announcement
I'd say just don't use /external:* switches in the build of project foo and you'll be getting all the warnings as before. Granted, this will require overriding switches if foo is part of a larger build where you want this feature on, but that probably warrants the exception since you want it to behave differently
&gt; Can do much better than now No argument there. Just a wrapper around any compiler that passes a sane set of default flags might already do some good (e.g. default to c++14 or 17, increase warnings etc.) My suggestion would be to look at a couple of small open source libraries in GitHub and see how many of them you can compile with the same set of defaults if you rearrange their directory structure. That might give you an Idea of what's possible and what not.
Thank you for the suggestion. Could be a good idea indeed.
Project `foo` may import other libraries which I do want to have included as as `/external:I`. And anyone else who builds `foo` should by default "see" it as external. It's just me, as a developer of both `libfoo` and `foo` want to treat this specific import as internal. BTW, another interesting question is how this applies to modules. There is probably more control since the interface is compiled separately but I would imagine warnings in external template instantiations is still an issue.
Is '#pragma system_header' recursive? I use some libraries that produce errors on windows, but an easy way to solve it internally would be for my project to have a master libfoo.h header that served only to include those external headers and this pragma.
You can include libfoo headers inside foo with "" and other headers with &lt;&gt; and then use /external:anglebrackets on foo project. That will give you warnings from libfoo and avoid those from other libraries.
We will do #pragma warning (push, n) as soon as we see #pragma system_header, so everything included after that will still be in the scope of that push/pop.
[removed]
Thanks, I get it.
No Problem. I understood what you were saying. 
Why so? Just out of curiosity. Turing complete means that the user can maybe solve problems the creators of the build-system did not foresee. And I don't have to tell you that build-systems are *really complex*.
Someone tl;dw please.
I didn't know there are no such MSVC's flags equivalent to `isystem` in GCC. Wow!
Is there anyone who actually use `/Wall`on VC++? Why would they? It's hard to believe that mentioned 15% actually build their code with `/Wall /WX`. Not with (IMO misnomer) gcc and clang -W"all but not *actually* all" but with `/Wall` from VC++ which literally enables all warnings. For example this sample program doesn't compile with `/Wall /WX`: struct foo { foo() = default; foo(const foo&amp;) = delete; foo(foo&amp;&amp;) = default; foo&amp; operator =(foo&amp;&amp;) = default; }; class bar { foo f; }; int main() { (void)bar {}; } It produces pretty useless for anyone (besides compiler dev) warnings: error C2220: warning treated as error - no 'object' file generated warning C4626: 'foo': assignment operator was implicitly defined as deleted warning C4625: 'bar': copy constructor was implicitly defined as deleted warning C4626: 'bar': assignment operator was implicitly defined as deleted `/Wall` in VC++ != `-Wall` in gcc. If anyone want to use something like `-Wall` from gcc with VC++ they should build it themselves. One way is to start from /W4 and then add and remove warnings one by one. Another way is to ask for separate option `-Wall_like_in_gcc` or something on user voice.
It's not the layout but the naming that needs (alread is?) to be standard. Then browsing a given repository is easy. * src: *.cpp and private headers * include: public headers * test: unit tests * docs: documentatio, references * deps: third party dependencies * build: Do not name a folder build How you layout your folder or if folders should match namespaces is you at your on disgression. The root folder should contain a readme and license file. No need for a standard. Good C++ coders have order in their repos anyway.
No, I express myself in C++ how I like it best.
True. But slight variations in those comventions is what prevent people from having a build system that does by default a few things with no indications. This is exactly what I am trying to simplify.
That's where you go wrong. "create fast" is not the C++ way.
I am pretty sure that Makefiles, scons, cmake and all the others easily work with any variations.
I am not sure you get what I am trying to do. What I want is that you can start a project by dropping a few files and invoking a command. Nothing else. Zero conf. So how does the underlying build system know what to do? By having standard conventions and layout. For sure you cannot have everything without any metadata. But u can have way more than today without writing a single build file. That is what I am trying to figure out how to do better.
Then click "New Project..." in your favourite IDE what gives you a Hello-World-Project in less than a seconds. You are trying to solve a problem nobody has.
This needs context or explanatory text.
There is more to it than just that. What about when I do not have my fav IDE available? What about all variations and languages we have to deal with currently for writing build files? What about having to learn those separately? What anout the 52 upvotes? 52 upvotes does not seem to me like a problem noone has.
Reading a book is the most basic step in any knowledge based culture. It is essential for EVERYTHING (e.g. religion, science, law, mathematics, philosphy). Discouraging to read a book on any topic is just plain stupid.
I will simply not agree on this. You can have more speed. Why not enable it? I expect rational answers, not slogans.
I wonder if a re-edition would changes some things in those books. I read them many years ago.
People usually have warning files that disable warnings they don’t like which they /FI to everything making /Wall work
No! Since then he published *Effective Modern C++*
We most certainly build with /Wall /Wx and selectively disable warnings we've not yet fixed. Same on Clang where we build with -Weverything -Werror and then set -Wno-foo for warnings we mute and -Wno-error=foo for warnings we want to display but not treat as error. This is for a codebase of 500k lines. The big limitation is that MSVC does not allow you to build with all warnings treated as error and then selectively downgrade some to plain warnings.
I want to have a better integration fo warnings in CMake now. It would be awesome if we could use target properties to leverage this option !
Great news! The big limitation though is that I want to build with /Wall /Wx and selectively treat some warnings as warnings, such as the equivalent of -Wdeprecated which is very useful. With MSVC I can only mute warnings, not downgrade them from errors to warnings. Please can we have that?
Looked at my code now: auto state = other.m_fh.rdstate(); auto pos = other.m_fh.tellg(); other.m_fh.close(); m_fh.open(m_filename); m_fh.setstate(state); m_fh.seekg(pos);
If you could change the way VS presents the lambda's "name" to you, how would you present it? 
Just having the name of the stored callable (type or function) in the value field would be super useful. In particular when you work with work-stealing thread-pools.
Just display the type of lambda instead of its value. The value is not that interesting most of the time. Also, make it jump to source code by double-clicking. Currently it already shows the lambda's type with scope and allows right click to go to source code, it's only too hidden for most developers.
Do you mind explaining how or in which cases non-destruction is better than the destruction of a static object? I'm not well versed on the singleton patter and its problems so I'm having a hard time understanding what is gained with this pattern.
Why arrays? Do you know at compile time how many people will be involved?
We were planning 21. And it’s for a school project. Our teacher didn’t explain how to use strings in arrays and we have a project on it that we’re all struggling on. 
That doesn't really clear it up for me. Even if I knew the full list of names I'd _still_ be more inclined to use a vector so I didn't have to keep track outside the container how many in it were left and I wouldn't have to swap their positions around (cleaner code). But if for some reason y'all decide this is performance-critical (you really need to get that Secret Santa list a few microseconds faster!) I still don't see why arrays... why not just leave it as an initializer list?
&gt; how to use strings in arrays Hold up... what do you mean? It's like an array of any other type. What data type are you using for string? The most common/obvious way to do an array would be: std::array&lt;std::string,21&gt; my_array; Depending on circumstances you might want to use string_view instead, but all that does is change the string type: std::array&lt;std::string_view,21&gt; my_array; 
My class is at a fairly basic level of coding and my teacher wants us to use arrays. Vectors haven’t been introduced and he isn’t willing to show us how to use them. I totally understand what you’re saying, but I’m just simply not familiar with vectors
The reason I asked for help on here originally was because we didn’t know how to randomly select the first person to go. But now, we figured it out. So thank you for your time, but I think we’re okay now
Yeah, we just figured it out. Thank you for your reply 
There's good ways to do randomness in C++ and bad ways to do "randomness". I'd recommend looking at the example usage of std::shuffle presented here: http://en.cppreference.com/w/cpp/algorithm/random_shuffle Depending on the requirements of the assignment, it could be as simple as saying each person gives their gift to the whoever comes immediately after them (post-shuffle) in the list (last person gifts to the first). That wouldn't allow the possibility of independent sub-group cycles, but if you ask me that's preferable. In a gift exchange. Try to avoid calling rand(). It has many pitfalls.
1. We've been discussing about patterns, not diktats. 2. We haven't been discussing about what makes a C++ program valid. Why do you change the subject?
Effective C++ is in the 3rd edition (at least, I have the third, do not know if there's a fourth). i THINK most, if not all, of the modifications are present in the errata that Meyers has released. I'm not aware of any re-editions for More Effective C++, Effective STL or Effective Modern C++.
I was thinking about the build in tools in VS like the Core Guidelines Checker. Not 3rd party tools.
Note that `stdint.h` is a deprecated C-compatibility header - use `cstdint` and friends instead.
Good news! CMake `target_include_directories` already accepts a `SYSTEM` keyword which is equivalent to `/external:I &lt;path&gt;`, but is currently ignored by CMake when using MSVC. All it takes is someone to define that equivalence. In CMake, variable shouldn't be the first thing you think of when you want a first-class API. Waiting for "CMake to have some variable to activate it" isn't the mindset to go for. Look for something target-specific and avoid always variables when you can. See https://steveire.wordpress.com/2017/11/05/embracing-modern-cmake/
We will do awesome stuff with C++.
There are also warnings like "behavior here was different in VC6" turned on under /Wall.
The thing is `libfoo` is not inside `foo`, it is a separate project/package. And for everyone except the developers of the two, import of `libfoo` in `foo` should be treated as external (no warnings). So it looks like there needs to be some way to override *externalness* of imports for certain projects. Also, I wonder if using -isystem for imported libraries is correct. They are not exactly *system*. GCC documentation is quite vague about its semantics.
I believe you are mistaken. Please read my other response to get more context. Yes, my demand was a bit ridiculous but so was my opponent's statement. I'm just trying to expose this.
Have to say that I consider omitting destruction of an object, even a static object, to basically be a hack. It doesn't work for the all time most common application of a singleton (a logger, which almost always has a non-trivial destructor). I know well that there are issues with calling the destructor but the better solution is to solve those issues correctly.
&gt; Classical enum class approach &gt;programmer have to ensure that values are unique Isn't it solvable by macro? 
There unfortunately is no silver bullet to deal with SIOF (at least, if you implicitly consider destruction ordering issues to be part of SIOF, which I do, since destruction and initialization are reverse ordered). I gave a talk on this topic at CppCon: https://www.youtube.com/watch?v=xVT1y0xWgww. A few guidelines, thoughts, that may help out: 1. Be clear on globals vs singletons. Try to avoid singletons. When you say "singleton", you can probably just have a normal class, that also happens to have a global instance. 2. Make sure you know basic, simple techniques for creating safe individual globals. Prior to C++17, you can either use a Meyer Singleton, or you can use a Meyer Singleton initializating a static reference (in a header). These are both totally safe, the former is lazy, the latter isn't. 3. Continuing on the above theme: assuming you aren't worried about lazy initialization being triggered in an awkward spot, lazy initialization trades making initialization headache free, at the cost of losing control over destruction order. It's a good solution for things that don't have interesting destruction logic (interesting means, dependencies on any other global objects). 4. Try to simply minimize globals generally, and inter-dependencies between globals in general, at high level of design. Turning your singletons into normal classes + global can help with this. E.g. if you have another global that wants to log, rather than make it dependent on the global logger, you can alternately give it a private logger instance. Obviously if the logger is a singleton you lose that option. 5. Try to declare globals in *header* files as much as possible. If your class uses a global, include the global's header from that class' header, not cpp. The last point may require some explanation. Header files for a whole program form a DAG, and therefore are topologically ordered. Some header files may initialize in unspecified order relative to each other, but if Foo.h includes Bar.h, the code in Bar.h is *always* run before Foo.h. So if you have globals Foo and Bar, and Foo depends on Bar, and you follow the last guideline, and you are initializing Foo and Bar non-lazily, you'll get this: // Bar.h, included by Foo.h Bar&amp; barMaker() { static Bar b; return b;} static auto&amp; g_bar = barMaker(); // Foo.h Foo &amp; fooMaker() { static Foo f; return f; } static auto&amp; g_foo = fooMaker(); In this kind of setup, Bar is 100% guaranteed to be initialized before Foo, and destroyed after. In sum doing things via headers helps establish ordering which is very good where globals are involved. Note that the class methods can still be defined in .cpp files, we just need to ensure that the globals are initialized in the header, not the .cpp. The Meyer Singleton ensures that it only gets initialized once (even though it's in a header file), and the trick with initializing the static reference makes it non-lazy. Anyhow my talk is only 30 minutes, if you're interested in this stuff you may want to watch it.
There are no required macros at all. `CLI11_PARSE` is the only user facing macro, and is completely optional and only was added in version 1.2 or so to make make it easier to use. Internally, the only macros used are the error definitions, to reduce code bloat (in 1.3). All files are guarded with `#pragma once`.
P.S. This was actually meant as a reply to the post below on whether anyone actually use /Wall on VC++. Not sure why it appeared here
They will eventually once the feature gets out of experimental. I know our /analyze team is actively working to adopt the same logic with their static analysis.
Sometimes the "issue with calling the destructor" is simply that you want the destructor not to be called. Leaking is an appropriate solution to this need whether it be for the very rare leaky singleton or the much less rare memory pool allocator.
When you want to statically guarantee that the singleton is alive during the execution of dynamic destructors, or when you simply want to avoid the cost of a dynamic destructor registration for the singleton itself, the leaky singleton idiom is appropriate. These situations are extremely rare in practice. For example: I recently implemented `&lt;memory_resource&gt;`. The functions [`std::pmr::null_memory_resource`]()http://en.cppreference.com/w/cpp/memory/null_memory_resource and [`std::pmr::new_delete_resource`](http://en.cppreference.com/w/cpp/memory/new_delete_resource) are specified to return pointers to singletons of types that derive from [an interface with a virtual destructor](http://en.cppreference.com/w/cpp/memory/memory_resource). (Yes, this means a user can inadvertently destroy the singleton - the C++ Standard makes mistakes, too.) I don't want the runtime to register dynamic destructors for these singletons for both of the reasons listed above: they need to be available in dynamic destructors for other objects, and there's no reason to waste a bit of memory to call a do-nothing destructor.
Maybe people who want these functions in the standard think the process of including them in it takes too much time and energy. I wouldn't blame them if that was the case. 
Can't open the article, here is the google cached version: https://www.google.com/search?q=cache:http://dreamdota.com/a-debug-helper-for-lambdas-in-ide/
1. I will write concrete signatures and native implementations this weekend or so. The only one that looks problematic is split. 2. Sadly I currently don't have the money for this
Yup, looks like C++
As if I wasn't already confused by the latest death stranding trailer? TLDR: Should I just stick with stdint.h?
I assumed the case where developer doesn't care about performance. In most cases, caller has no idea how much the size of buffer will be. In most cases of conversion, size can't be predicted or estimation of size is over engineering and code becomes less readable. I also dislike data being passed as a reference. 
Boost has some of that functionality (trimming): http://www.boost.org/doc/libs/1_54_0/doc/html/string_algo/reference.html#header.boost.algorithm.string.trim_hpp
I still consider The Art of Unix Programming as a must read for everyone who wants to learn good engineering practices. Despite the title the book is pretty general and uses *nix apps only as samples of particular software design decision. So I would highly recommend the book to anyone who wants to become an engineer, not just "a programmer".
Exceptional C++ is the book I perhaps got most out of, but that was after quite a while spent with the language. You might try reading the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) first.
Remove_prefix/suffix remove a number of characters. With trim I refer to the removal of leading/trailing whitespace (or user specified characters). With replace_first/last I mean a function that replaces the first/last occurrence of a substring with something else. Sure it is easy to implement pad, but I don't think this is something I should need to do this. I neither think that this is an argument against the inclusion of this functions into the STD, especially if you consider that we already have many trivial functions like std::max there
Anyone willing to explain this? Still pretty new to cpp &lt; 1-year experience. Its like its an include directive but instead of defining a separate file the content is just pasted here? #ifdef _MSC_VER #include &lt;intrin.h&gt; #define FORCEINLINE __forceinline FORCEINLINE uint32_t bsr(uint32_t x) { unsigned long res; _BitScanReverse(&amp;res, x); return res; } #else #define FORCEINLINE __attribute__((always_inline)) inline FORCEINLINE uint32_t bsr(uint32_t x) { return 31 - __builtin_clz(x); } #endif 
&gt; So it looks like there needs to be some way to override externalness of imports for certain projects. Yes, it's a default, and yes it's overridable inside the foo buildsystem if you want to be a special client of the external libfoo. &gt; Also, I wonder if using -isystem for imported libraries is correct. They are not exactly system. GCC documentation is quite vague about its semantics. Yes, the semantic is more similar to what is described on the blog (where they are described in the blog as 'external' for exactly the reason you state).
The ones boost provides seem reasonable.
Good idea - I never thought of using structured bindings for that. using Animals = flag&lt;0, 1, 3&gt;; namespace Animal { auto [Cat, Dog, Wolf] = Animals::values; } The names are quite separated from the values. You will have to count the ordering to know, which bit corresponds to a name. Namespaces are never closed. You can always add new definitions to a namespace. Therefore I would prefer to use a struct in this context. Even though we use just like a namespace.
'Discovering Modern C++: An Intensive Course for Scientists, Engineers, and Programmers' by Peter Gottschling is the textbook I wish existed when I was learning. Prioritizes modern practices and practical performance.
The best analysis I've ever seen on the topic has been by Paul Khuong and Pat Morin. See their paper on the topic, [Array Layouts for Comparison-Based Searching](https://arxiv.org/abs/1509.05053), as well as some supplemental blog posts, [Binary Search \*eliminates\* Branch Mispredictions](https://pvk.ca/Blog/2012/07/03/binary-search-star-eliminates-star-branch-mispredictions/) and [Binary Search Is a Pathological Case for Caches](https://pvk.ca/Blog/2012/07/30/binary-search-is-a-pathological-case-for-caches/) for information relevant to your measurements. I suspect that if [their code](https://github.com/patmorin/arraylayout) is not faster, you're unlikely to find any that is.
I have Introduction to Programming with C++ by Y. Daniel Liang because my class requires it. Does this books cover more than any beginner/basic C++ book? or go more in depth? 
IO is going to take almost all of the time taken. There are lots of ways to make this particular search extremely fast, but it's pointless if that's not the part that needs to be sped up.
Sweet Jesus, this is infinitely better than doxygen. I am so excited to use this for my own projects! 
I'd rather have a method to get a character by index or actual string length in characters and not bytes first `:^)` Unless I've missed something in C++11/14/20
I would very much appreciate that. It looks so much better than doxygen, and even though you have to create it by hand (using the mediaWiki page editor I think?), I would still instantly switch away from doxygen. I assume one would need to setup a local webserver serving a media wiki instance, create the pages and then export it to HTML? Is this how you did it? 
That's also fine. It's just that hissing at people who use the other form is not productive.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7jv5t2/any_personal_suggestions_for_c_books_for_further/dr9oyhy/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Looks very nice on first look (had not time to study it in detail yet). We have an internal library (https://github.com/gromacs/gromacs/tree/master/src/gromacs/simd, http://manual.gromacs.org/documentation/2018-beta2/doxygen/html-lib/page_simd.xhtml) we are considering to make available as a separate library. There seem to be quite a few similarities.
Thats a bit complicated and obscure for something taht *should* be a simple operation.
So [AAlib](https://en.wikipedia.org/wiki/AAlib)?
I found [this](https://github.com/CaptainCrowbar/unicorn-lib) utf8 string library that has grapheme iterators. Don't think it uses string_view, though.
You just saved me lots of work , moving from python to C++
[I have a proposal for your library!](https://github.com/Wunkolo/qreverse)
IBM has contributed Altivec implementations of various SSE2 intrinsics for gcc 8. For example: https://github.com/gcc-mirror/gcc/blob/master/gcc/config/rs6000/xmmintrin.h 
&gt; Most of this functions are provided by boost or can be trivially implemented.
Because nobody bothered to add them... and also C++ has this "genius" building block philosophy where they rarely bother to add anything that somebody else can do, Titus even said they had problem getting bla_with in C++ 20 because somebody complained you can implement it yourself. 
If I was reviewing code and saw someone using that in multiple places, I would reject it until they removed the code duplication, which would mean they would have to write a trim function and stuff it in some utility library full of all sorts of other things that should be in the standard library but aren't.
How does substr factor into this?
I spent 13+ years gamedev mainly in C/C++, then moved to work to another place with Java (I didn't know what language I'll be using). And it was then that I was introduced to DI (through "juice" - https://github.com/google/guice). At first, I was puzzled - why do we need all that. Week later, I'm realizing I am at a place where testing is taken to the next level - unit tests, integration tests, functional tests. People are writing the code in a way where it could be tested - e.g. any call to "new SomeClass" makes the code less easier to test, as a concrete implementation is used in-place (SomeClass). Instead people had set it up, where you deal with interfaces, and you simply ask - I need an interface of this, or that - I depend on it, I consume it. Whether you gonna me give me the same instance, or the same per-thread instance, or new instance everytime is up to you in your staging, or production configuration. Now when comes to testing, this SomeClass may aswell be the real implementation (if unit-tested), or empty (fake/stub), mock (one who can be instructed by a test what to return, if asked back), or just a spy (a hook over the real implementations, with tweaks - a bit like monkey patching). And that's not all, and I'm still not there yet, but here I'm back in the original company doing C++ and I stumbled on a wonderful system for a level editor (game studio), where "modules/plugins" are loaded, have dependencies on each other, and everything is isolated through interfaces - and the more I look at it, the more I realize - it's a bit like dependency injection - one plugin if needs functionality from another does no refer to it directly, but through interface - and given time, we can return a different implementation so that it could be unit tested. Surely we are digging some other tunnel with it, but I'm realizing that it's very similar... So my take is that what java/ruby/python/etc. programmers established as well known and used there practice, the C++ are just starting on it, since it wasn't easy to express these things without new features in the language. It's great to see someone making strides here where I can have a construct() with all interfaces that I need injected. Surely it'll take some time to get accepted, and may not be the perfect interface yet - but unless your application is real-time, or soft real-time (say video game) I think it'll have pretty good use. Since I'm on the tool side, and real-time performance is not highest priority, I'm all open to try it out, and have marked certain other libraries too, like: https://github.com/kulseran/SQUID/tree/master/CORE/DEP (written by a coworker from the previous company where I learned Java) https://github.com/google/fruit (from Google) https://github.com/boost-experimental/di https://github.com/arthurlm/qt-dependency-injection (for Qt specifically, and we are heavily vested into the framework) https://github.com/vogel/injeqt and possibly many others! 
Reading about the preprocessor would be a good start.
Looking forward to it!
slug_case i'll accept, camelCase i'll tolerate, PascalCase i'll love, but this, this i won't stand for.
What do you think about Rusts stdsimd library? 
"yeah! why use std::vector, you can implement it yourself." &gt;__&gt;
Indeed, `startswith` is wrong for any convention.
This looks like a C library with a C interface to me.
Is there any difference between `std::less&lt;&gt;{}` and `std::less&lt;&gt;()` in this example?
The library looks great from the capabilities point-of-view, but are there any examples or tutorials of using it online?
Did the cat die or something?
In this case, no. The braces variant uses the new (since C++11) "direct-list-initialization"; the other one uses "direct initialization".
`static` is usually regarded as the worst offender.
The lion eats you and throws an exception as it burps.
Not that I know of unfortunately. Hopefully this will be improved with the next release of libsimdpp.
I would really like to see it being easy to use as Doxygen. Generated pages have much better layout and use monospaced font.
Not sure I follow. Will this treat C5038 as a warning (show, not mute) in my code while at the same time treat all other warnings (in my code) as errors?
Not really. They are pre-C++11 and usability is not that good. Verbose to declare iterators outside and create vectors. In my opinion algorithms like split should be function objects that keep an internal vector of string views so that the vector can be reused between calls.
If you terminate the loop when you find a suitable key you might get a small speed up.
Most of the time handling projections is a matter of projecting parameters just before comparing elements in algorithms that accept comparison operations, which is a rather automatic change.
guy doesn't seem to know how std::reverse works though
Why not copy the signatures from some other language. Why does every language have to reinvent the wheel?
this has been a pain to me lately. After we got lambdas I was happy I could do it that way, but then the boilerplate got old very quickly.
Pretty sure that belief is a requirement to teach a beginning C++ class.
Better tooling than doxygen is coming. https://ned14.github.io/outcome/reference/ was produced from the header files by the Standardese tool (https://github.com/foonathan/standardese). And Outcome is no shrinking violet of a library, Outcome pushes C++ 14 to the max and is really a C++ 17 library. Doxygen just falls over with complex template input, and even if it works, the output is hard to grok by humans.
They are completely different libraries. `stdsimd` is basically the intrinsics headers of a compiler + run-time detection support (it looks like `stdsimd` has better run-time detection support than `libsimdpp` though). A Rust library that attacks the same domain as `libsimdpp` (a portable simd wrapper) would be the `faster` crate, and feature-wise it looks like `faster` lags waaay behind `libsimdpp`, but I guess that's reasonable given that `faster` is one month old. 
This one is pure C.
&gt; map | sort This would do something very different though. 
what type deduction? A string splitter will have to provide both a string_view and std::string version, depending on how the user wants to use it (i.e. Is the source string a temporary? -&gt; use the std::string version) Preallocation is an issue with both. As for the rest... meh
If you are talking about Folly, then it's not a replacement for standard library. It's an extension. It even depends on boost. 
That's a very good point: If you don't provide comfortable special-purpose APIs, people will use the whatever is the next comfortable thing. Leaving out “slow” functions therefore makes the real-world code even slower, resulting in the opposite of what was intended.
This just demonstrates that C++ has become too complex.
There is no such thing as "character" in Unicode. Do you mean code points, graphemes, grapheme clusters, or something else?
 std::sort(a, std::less&lt;&gt;(), &amp;employee::last); This reminds me of pre-C++11 days when we didn't have lambda functions and the only option was to pass templates like std::less for customizing STL algorithms. I personally find this more readable: std::sort(a, [](const employee&amp; x, const employee&amp; y) { return x.last &lt; y.last; }); Is there any advantage in the first case? 
No other language has the C++ type system and, therefore, C++ function signatures?
&gt; it just hates taking new keywords when it can use the same ones over and over. Why exactly is that tho ? Learning a good dozen of keywords seems rather easier compared to have a same word with different meaning. static and inline are the worst in my opinion.
&gt; libsimdpp seems to rely on __builtin_cpu_supports intrinsics This is incorrect. There are multiple backends to fetch architecture info - you can use whichever is best for the platform. On x86, for example, it's possible to parse CPUID directly.
Again, if you think Boost or any other equivalent is better, you should just use it. More options on the table is always better, that is not really debatable.
Fair enough, if you add a significant amount of memory per string and per character, you can get it down, but people won't use it either way.
I have read he's really hard to work with.
starts_with, ends_with are already added to the draft of the standard: [Here](https://www.reddit.com/r/cpp/comments/7ca2sh/2017_albuquerque_iso_c_committee_reddit_trip/).
I have so much respect for all compiler developers
You mean you haven't memorised the ODR? Get back to the quiche
Thanks for giving my library a shot. I eagerly waiting for your feedback! If you have problems or questions, leave me an issue or chat with me on [gitter](https://gitter.im/gracicot/kangaru). Do you plan to make a blog post about this comparison on all the DI framework you tried? An extensive comparison between idioms they each enable, performance with equivalent code and other stuff. That would be really great, and certainly make people aware of dependency injection and what it can do. --- To continue on your "why are we needing this?" text, I think injection of interface are one aspect of dependency injection. Yes indeed, your code isn't tied to a concrete instance anymore, and it could be greatest thing in your case! However, if what you want is only to automate this kind of code: Class1 c1; Class2 c2{c1}; Class3 c3{c2}; c3.set_c1(c1); Class4 c4{c2, c3, c1}; c4.init(); Class5 c5{c4}; I think a DI container should be able to help you, and you should be able to use `container.service&lt;Class5Service&gt;()`, and the result should execute something very close as if I wrote this by hand. The goal of my library is to enable both classic dependency injection with interfaces, and enable dependency injection with static types that don't have virtual functions. Also, another type of injection is automatic injection in function parameters. We have those container that can inject in constructor, but why not any functions? Javascript got fancy injection like that, and I think there is no reason why C++ should have that too. Simply adding parameters to a function and compile, without refactoring the call site is a bliss!
&gt; Feature-wise it looks like faster lags waaay behind libsimdpp Also, like much of rust, it has a big problem with making it's name kitschy and confusing. 
I find my homebrew projection (especially for sort) to be extremely useful std::sort( a, order_by(&amp;employee::last) ) where `order_by` does template&lt;class P, class O=std::less&lt;&gt;&gt; auto order_by( P&amp;&amp; p, O&amp;&amp; o={} ) { return [p=std::forward&lt;P&gt;(p), o=std::forward&lt;O&gt;(o)] (auto&amp;&amp;...args) RETURNS( o( p( decltype(args)(args) )... ) ); } and #define RETURNS(...) \ noexcept(noexcept(__VA_ARGS__)) \ -&gt; decltype(__VA_ARGS__) \ { return __VA_ARGS__; } is for a more-perfect lambda. Maybe the Rangesv3 solution is cleaner. 
So only clang is right in that case? Is this really a compiler bug to not allow this?
many classes in standard library are not designed to be extended, so I think Folly is some combination of extension and replacement. For example, it has folly::fbstring which is clearly defined and used as replacement for std::string (https://news.ycombinator.com/item?id=8704684)
Creating new keywords causes hackwards compatibility problems, because prevopusly legal vnames become illegal.
You say: any sane programmer would assume that `erase` and `remove` mean the same thing. In response, I ask: what kind of programmer would expect that two functions with different names do the same thing?
C++ as a language isn't built for lazy evaluation. Nothing else returns proxy objects if it can return real objects. I think it would be bad design to introduce it into the standard library at this point.
It says it contains Visual Studio 2017 15.4, which is the version that works just fine anyways.
&gt; I wonder how often he needs to debug leaks and segfaults Oh, look, C++ developers spousing language snobbery in the same way that rust developers do.
Do you mean [hippomocks](https://github.com/dascandy/hippomocks) or [trompeloeil](https://github.com/rollbear/trompeloeil)?
It's just a warning. Same as an unused variable warning, so I don't know if I would call it a bug. 
No I meant, the fact that GCC and MSVC forces you to capture reference even when they bound to global variables. Should we report bugs to them?
some C stdlib implementations are implemented in C++ but I don't see anyone calling them C/C++ libraries.
Moral of the story is there should be either `erase()` or `remove()`, not both. And it should be a *member* function because, as much as I like having a general algorithms that apply to many things, the very idea of a global function algorithm in 2017 is itself a design smell. Literally zero discoverability. Oh and while we're on the subject, let me also say that implementing collection operations on the basis of duck typing (the presence of `begin()/end()`) is also crazy. Just build an interface type called `iterable/enumerable` and define iteration on that interface.
I'm guessing it's replicating some Python APIs, which is fine for Python programmers, but function names such as `mul` make this pretty much unusable in my book.
ok, i'll bite: what would be a better alternative? and if I hear error codes I'll slap you through the monitor.
There is also [FakeIt](https://github.com/eranpeer/FakeIt)
I for one am prepared to sacrifice correct operation with, ugh, emoji, just so we can avoid the cluster~ck that is Swift, because that's exactly what they do -- force you to just through hoops just for simple character-by-character iteration. One reason I like C++ is I can continue to work in ASCII. One byte, one character. Also maps neatly onto SIMD, GPUs and FPGAs if you need to hardware-accelerate string processing algos.
I wonder if adding both `noexcept` and an `is_noexcept` (or something similar) keyword would have been any less backwards compatible than just adding the `noexcept` keyword.
Is your library usable on Windows with VC++?
I've made my own `replace` that takes anything that can be regarded as a pattern, i.e. a character, a string, or a predicate, and replaces all sequences or characters that matches that pattern. I no longer have a billion overloads with 6 arguments each. I only need one: ` void replace(Pattern&amp;&amp; pattern, string_view with)`
Yes
I was going to point you to /r/cpp_questions but it looks like you already posted the same question there and in other places. You're probably getting voted down because this isn't a question that can be answered without asking you a lot more questions in order to suss out what your question actually relates to. For example: * It lacks context about where you're trying to accomplish this. Are you trying to render? Create input for an existing rendering engine? If the latter, which render engine? If the former, what platform? * It doesn't give any indication of where you're hung up. How far did you get, or what references didn't work out for you? What part confused you? You will get a lot of mileage out of [this](http://www.catb.org/esr/faqs/smart-questions.html#intro) if you have the patience for some reading.
&gt; the fact that GCC and MSVC forces you to capture reference even when they bound to global variables. Erm... I just tried it and got nearly the exact opposite result. GCC seems to allow capturing or not a global; both work, neither issue a warning. Whereas in Clang and MSVC, capturing a global issues a warning/error. #include &lt;iostream&gt; int x {42}; auto f = [&amp;x] () { std::cout &lt;&lt; x; }; &gt; MSVC error C3480: 'x': a lambda capture variable must be from an enclosing function scope &gt; Clang error: 'x' cannot be captured because it does not have automatic storage duration As far as I know, capturing a global by reference doesn't do any harm, but it's pointless. A global will be allocated and accessible from any scope for the life of the program.
I think that was the one! 
Yep, that would have been my preference too.
Why do you need those types of lambda expressions? Isn't a global accessible with or without a capture?
This is not the scenario that's described in the bug report.
&gt; One is the library the others are language features. There are library parts to these too. Concepts without standard-defined concepts for the standard lib are pretty useless. &gt; It's like saying that nobody is gaining anything from having different compilers/implementations of C++ language. so do you also reimplement your algorithms twice or thrice at your day job ? Besides, I don't know what we are gaining, but one thing is sure: single-compiler languages such as Rust, Haskell, Swift have zero problems thriving.
GCC [warns by default](https://wandbox.org/permlink/lCrS5J5WjzWJkwlD) and [emits an error in -pedantic-errors mode](https://wandbox.org/permlink/el1TBkT72GZ1w2Q3).
How so? auto&amp; sm (scope_map::instance); auto make_global_scope = [&amp;sm] () -&gt; scope&amp; &gt; Both sm and vp are references to global variables. &gt; warning: lambda capture 'sm' is not required to be captured for this use
I think you misunderstood. I meant this code in particular: int x; int main() { int&amp; y = x; []{ (void)y; }(); } This is what clang wants you to write according to the warning, but in the two other compiler, it doesn't compile: [GCC example](http://coliru.stacked-crooked.com/a/6434ea522642d2cd) (fails) [Glang example](http://coliru.stacked-crooked.com/a/e75fa8f3ee80fb39) (works) [MSVC example](http://rextester.com/OWV43046) (fails) What I said is that if it's actually required by the standard to allow this code to compile, we should report bug to MSVC and GCC.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7k11gd/create_a_sphere_in_c/drat0c8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; The problem is that even the most basic non-ascii-characters like “ä” are not necessarily a single codepoint or have a single representation as codepoints. How is that a problem, and how does it make code point iterators any less useful? It is (should be) common knowledge that there is no 1:1 correspondence between code points and graphemes and no 1:1 correspondence between graphemes and rendered glyphs. Work with text is a lot more than rendering and selection for copy-pase. &gt; you are supposed to have them all compare to equal Under some conditions, some operations may treat U+00C5 as equivalent to U+0041 U+030A. I can't imagine a condition where U+212B can be considered equivalent to U+00C5, perhaps in some specific font's glyph table?
It would be a gem if that did work. I put `static` before the `constexpr` to work around that.
Ah! This is because your function is not constexpr. If a constant expression yield a reference to a global, you'll end up with the same behavior: int x; constexpr int&amp; f() { return x; } int main() { int&amp; y = f(); []{ (void)y; }(); // works with clang }
I must be missing something. What’s surprising about this? Why wouldn’t a captured reference to a global variable be redundant? How could an unshadowed lexical reference vary its referrent based on whether the was a capture or not?
If you mean a Linux kernel, I agree. But entire git is in C.
A range or iterator returned can be constexpr too.
actually, Git is also a bunch of shell scripts mashed together (not that that's any consolation)
`std::string` is already broken for anything but ASCII. If all you're doing is ASCII, then these are trivial to implement/find. If you're using Unicode, then even iterators just return a fragment of a fragment of a grapheme, and these higher-level functions can't ever properly operate anyway.
I doubt he expressed his opinion in context of "using C++ for Git".
Can't we introduce more contextual keywords instead like `final` or `override`.
So for anyone who feels that spending an hour to listen to someone slowly, laboriously explain what he did is just too much: it's about a tool that records the entire program state while running, and lets you seek backward and forward through that state in order to pinpoint the root cause of a bug. It's not actually about a tool for putting bugs in, as one might reasonably expect from the title. If you're looking for one of those, I can recommend using a text editor of some kind. Works wonders for me... 
`array&lt;T, 0&gt;` is mandated to work by the Standard. Stateful comparators in associative containers need to be copied, to avoid damaging the source container; this is a deficiency in the Standard's specification.
But that's exactly what happened, someone asked why git is not in C++ and he responded.
&gt; the very idea of a global function algorithm in 2017 is itself a design smell. Could you do us all a favour and stay with Java? &gt; Just build an interface type called iterable/enumerable and define iteration on that interface. for that sweet bit of virtual dispatch on each step. 
`noexcept(expr)` can be used outside of `noexcept(predicate)`.
If you're willing to spend $10-20 there's a website called Udemy with a lot of full online courses made by experts. I've found it very helpful in learning java. If not then there's a youtube channel called thenewboston with a lot of good videos too. If you're in school you might have free access to Lynda.com which also has videos that you might find helpful.
Yes, op* makes perfect sense for replicating a string. 
&gt; Its very hard to find non cpp-con or other major talks videos of known experts. I suppose people interested in C++ doing the kinds of jobs which require C++ programming aren't that interested in making youtube videos about C++. It generally doesn't have that "cool" aura around it. And, also, for the kinds of systems people use C++, the actual C++ language isn't that important. Their major problems will lie on some areas of knowledge. I mean, their major problems will be networking problems, AI problems, algorithms and data structures problems, computational geometry problems, etc. Look at the games industry. Sure they use tons of C++, but if you look at a game programming book (even the ones which exemplify things in C++), the major difficulty is somewhere else: that is, not in C++. (You see some game programming books which talk about C++ solely, and sure enough, you learn almost nothing about game programming in them.) So, these people will make videos (when they do) about other topics, which are their actual topics of interest. That may be compression, AI, networking, concurrency, etc. And these talks, with very little change can be made language agnostic (which can then attract more people). In my opinion, talks and videos around a programming language don't really seem interesting. Generally, the interest is in another subject, and then C or C++ appears as a consequence. For example, the OS course @ berkeley uses C (not C++, but you can adapt what is in there if you're interested). &gt; without ever coming accross books like the evolution of C++ to know why things are the way they are. Don't get me wrong, but knowing why things are the way they are is interesting, but it doesn't change the fact that things are the way they are. Many people find C++ to be a terrible language and have no good reason to use it (my guess, from anecdodal experience, is that this makes sense to most people). For these people, knowing "why it sucks" doesn't really change that "it sucks". Many people don't have to use C++. The moment they conclude (right or wrong) that C++ sucks, they can just move on to another language and it *will* generally work out for them (again, from my anecdotal experience). That is why (as far as I know from programming "history") people migrated away from C and from C++ in the late 90's and early 2000's. It's also hard to find videos on C programming. I personally wish there were more of those. In my opinion, this all has to do with the fact that there aren't many reasons to use C++ (or C) anymore as there were in the past. So people just don't; for them, there are other languages they perceive as better. Generally speaking though, you can look at the interesting techniques people are using in other languages and them apply them to C++. First you'll end up "writing language X in C++", but then you can evolve the idea to fit better with C++. 
I filmed a bunch of videos on Channel 9 about C++, although it's been several years since my last one. My problem is that being a C++ expert means being constantly busy, and features don't implement themselves :-/
`value`
Ahh indeed ::&gt;_&gt;
This has been already exposed at https://www.reddit.com/r/cpp/comments/7fl6zl/compilers_cant_agree_on_capture_type/
Just in case we're trying to be as concise as possible: `std::sort(a, [](auto&amp;&amp; x){ return x.last; });`
ODR? Pff. Try to memorize ADL.
Different operating systems grew up with different conventions. You can use `-` if you want. MSVC accepts it. 
You don't memorize ADL. You simply put the base case in the global namespace, and special cases in the namespace of the types of variant ADL that are required, then invoke a function in an ADL-enabled way to find the correct rule. 
I'm sure you can upgrade VS in the vm, no?
Does the Bucky Boston dude do them? I used to watch his Python ones back in the day. C++ is pretty lame to learn about, I'd definitely prefer a Ctrl-F'able doc to read. On top of that, there's so much ground to cover you'd never be able to make an engaging video on it, I don't think.
Huh, indeed... Hilarious, lol. I still see his point, though... C++ is so rich with various crap that it really gets in a way of solving the problem, unless you are very proficient with it. 
Couldn't it be possible to add future-keywords? So like in C++20 there's new warnings for a dozen new keywords, then in like C++24 or 28 they're finally used. I feel like 4 or 8 years is a long enough time to update libraries like that, I dunno. I'm new though, but does that mean that people run new compilers on old code and it should still run 100% of the time?
I like Cherno’s. 
Thanks for mentioning this. When I implemented deduction guides in MSVC's STL, I didn't test this. Now I've written tests for `less()`, `less{}`, and `less op{}`. (I already had tests for `tuple{}` but that's an empty pack, not a default arg.) They're unsurprisingly passing with Clang/LLVM with no action required from the STL, but it's good to have coverage for this compiler corner case.
Even though there was a proposal dedicated to this specific case (which was later retracted because edits to the core feature were enough to cover the case)? Now I'm surprised considering you were the one to propose diamond function objects in the first place :p
Those people put their energy and content out there mostly for free. Feel free to not watch it and be quite about it. Or even better - start your C++ course today and make the world a better place. Stop complaining and be the change you want to see happen.
Channel 9 STL C++ series was what made me abandon C with classes and learn the std library better.
lol, nice mental image
Even though we probably share sentiments towards Microsoft, I believe we should be kinder towards each other.
I don't think there's any context, this is clearly a homework, and OP doesn't know enough about the subject to even clarify the question.
The series by Kate Gregory and James James McNellis is IMO a good example of good modern beginner c++. [https://mva.microsoft.com/en-us/training-courses/c-a-general-purpose-language-and-library-jump-start-8251?l=fVmOhQKy_5104984382](https://mva.microsoft.com/en-us/training-courses/c-a-general-purpose-language-and-library-jump-start-8251?l=fVmOhQKy_5104984382) and then STL's channel9 vids are for when you are ready for more advanced stuff.
it's the preprocessor directive. It literally includes/doesn't include the source code based upon whether or not it's defined. #ifdef _MSC_VER bool is_ms_compiler() { return true; } #else bool is_ms_compiler() { return false; } #endif note: this is a horrible use of the preprocessor, but it's simpler and gives you a more clear understanding of what it does. This is also how "include guards" are done. #ifndef MY_PROJECT_MY_HEADERFILE_H #define MY_PROJECT_MY_HEADERFILE_H class MyHeaderFile { }; #endif The compiler will **literally* just not include anything in between the #ifndef and #endif the second time it encounters it because it's already defined. Most modern compilers can replace all of this with a simple #pragma line, but both approaches have their pros and cons.
... because they are (almost) free?
I like his gaming series...
&gt; Does anybody know why requires requires was not removed? Shouldn't that be &gt; Does anybody know why requires requires was not removed removed? As a committee member, I'm having trouble understanding your syntax, or to what you are referring referring. 
&gt;There are library parts to these too. Concepts without standard-defined concepts for the standard lib are pretty useless. True. But it still depends on the language features. It's not like the concepts are held back because library developers are stuck "reimplementing boyer-moore search, ...". If the C++ development just "stopped" until "innovative features such as concepts, metaclasses &amp; coroutines" were fully implemented, we'd still be waiting for C++0x (now C++xx). &gt;so following that logic, do you also reimplement your algorithms twice or thrice at your day job ? No, usually I don't. But i'm sure that most of the things I write are "reimplemented" by many people on their jobs every day anyway. Having some well-tested often-needed stuff in std lib means that I don't need to rewrite that stuff myself every time. That it'll be available on most conforming implementations and that it will work in unified way. You don't reimplement `std::sort` every time you need to sort a vector, do you? &gt; single-compiler languages such as Rust, Haskell, Swift have zero problems thriving with their single implementation. Wouldn't call them "thriving" at this point (though there is definitely a potential in some of them). If anything, lack of alternative compilers (though Rust already has some in development and Haskell already has some) is the sign of a niche language (even if it's a very big niche). Anyway, that's not the point. Maybe the current situation is not ideal but there are reasons for it. It's not just because of some mindless "stubbornness". You can just go and look up all the different std lib implementation and see their rationale to understand what in each case you (or them) "gain". It may turn in even more "philosophical" question of "why do forks/alternatives exist" for any entity.
Just like *many many* people, I ended up [implementing my own](https://github.com/rodrigocfd/winlamb/blob/master/str.h). Not to save the world, but just to suit my needs. And my life got a lot better since then. Actually my desire is to write a whole wrapper to the string class, but doing so would be too much disruptive.
 i really wished there was a simple function to split strings into a vector&lt;string&gt; kind of like java's string split method (i'm sure other languages have something similar).
Scary if so... kind of late in the semester for that!
Have a look at [pystring](https://github.com/imageworks/pystring)!
I tried listening to the audio during my commute as I was learning C++11 when it popped up on my podcast player. It was hard to just listen, still I was sort of able to follow because you still read it out :)
Sphinx supports documenting C++ too, afaik.
CppCon videos are great
Maybe. I wouldn't know. Plus it's quite some overhead to learn using all this stuff when you are an Emacs + Bash guy :) I might give it a try anyways when I find some time. Thanks for pointing me to the site! 
So like [UndoDB](https://undo.io/products/undodb/) or [rr](http://rr-project.org)? It seems like CppCast already did one on that last year, no? But yes I was expecting either a talk on how to successfully create bugs, or how to hide/obfuscate the bugs you create. I'm already an expert on those topics though so I didn't listen.
C++, the trillion dollar mistake.
Surely that code shouldn't be allowed. Otherwise, what if you did something like this? int x; int main() { int foo; int&amp; y = (rand()%2 ? foo : x); []{ (void)y; }(); } Should that randomly sometimes compile and sometimes not? (Clearly it should not be allowed to work!)
I found this to be a pretty bad reason to be honest. Plus the chances that it impacts that much people is questionable. Most people's coding style requires the underscore in most identifier names, with a few exceptions. And it's just a simple name, the refactoring is very easy and don't introduce actual logic changes.
Ok, just because you asked nicely. But #noflame, also my previous comment have been downvoted to oblivion and the previous one deleted so you will probably will be the only one that will read this. But this says a lot of how mature is the topic. Anyways, well for example error cod... &gt; if I hear error codes I'll slap you through the monitor. Oh... Ok, let's think about something else. Let's see for example what would be the best nice syntax that make everyone happy? I would like to write code like this: std::future&lt;int&gt; ma_function(std::string const&amp; obj_name) { Foo bar(get_obj(obj_name)); bar.use_obj(); } But let's say that use_obj, create a thread and return a future passing the object or something silly that I really don't want to manage every single failure case and that obj name may represent a resource in a web server, or in a file that it may or not may exist depending on a status that I have no control over it at compile time. Also, I expect that once I get an object I always use it (otherwise a server will hold a resource until it time out one year later, a fairy die of starvation or other nasty things). I really would like to write code like this, because is readable it goes straight to the point and people that are familiar with the class Foo know exactly what this code is doing. Cool. The only problem that this code is wrong. It may works in the nice case (it works on my machine^tm) but what the code above does to express all the thing that I said above? Someone that change that code, add more stuff in the middle is aware of all the trap that those two lines actually doing? Is this any better? std::future&lt;int&gt; ma_function(std::string const&amp; obj_name) { std::future&lt;int&gt; future; // not RAII MyObject* gotcha = get_obj(obj_name); if (gotcha == nullptr) { // TODO: signal error in some way return future; } Foo bar(gotcha); if (!bar.is_initialized_properly()) { printf("Fail!!"); // FIXME: this is an important error add more exclamation marks. gotcha-&gt;release(); return future; } future = bar.use_obj(); if (!future.is_valid()) { // FIXME: failed to create the thread, now a fairy will die, but the server is safe at least // Fail silently for extra amusement. gotcha-&gt;release(); } return future; } Is this any better? Is this even C++? This is ten times worse. * Is not composable, if I want to use two objects I have... 8 if. Is that what you want in your everyday life? Eh? * Release is called twice if I add another case I have to remember to add it again. If I add another object, how many release I have to add? DRY yourself! After you have two or three objects in a function you will end up adding a goto just to clean up all the mess. * The caller is not informed of what happened. The the thread failed, should I use more explicit error code? Then the main will receive e_MA_BAR_ERROR_THREAD_UNABLE_TO_CREATE_THREAD = 0x800435C2, then what? * I can ignore completely the return code, nobody will notice is until production time. Seriously error code is so 1995, they are ok if you feel nostalgic or you are a huge hipster, one of those that go to Starbucks for the whole day with a MacBook. I have no idea what they do, but they probably do a long chain of if. But error code doesn't solve our original problem. And you are right to bitch slap anyone that says otherwise, all tell you more, [when you have explicit control flow it's a problem.](https://vimeo.com/97329153) Exception then. Let's try: std::future&lt;int&gt; Foo::bar() { std::future&lt;int&gt; the_future_is_here; bool failure = false; do { try { the_future_is_here = std::async(std::launch::async, [this]{ this-&gt;m_obj.count_stars_in_the_universe(); }); } catch(std::system_error&amp; e) { if (e.code() == std::errc::resource_unavailable_try_again) { // ehm... now what? failure = true; } } } while(failure); return the_future_is_here; } std::future&lt;int&gt; ma_function(std::string const&amp; obj_name) { // Ah... smart pointers, why I didn't think about it before. std::unique_ptr&lt;MyObject, Releaser&lt;MyObject&gt;&gt; my_obj; try{ my_obj = get_obj(obj_name); } catch(ObjNotFoundExcetption&amp; e) // catch to manage code flow, yeah, why not? { my_obj = get_obj("default_object"); } try{ Foo bar(my_obj); return bar.use_obj(); } catch (std::bad_alloc&amp; e) { // some function (maybe std::async or the constructor) wasn't able to allocate something, now what? } // FIX ME: There are probably more exception that are thrown and are not catch... but hey... stack unwinding it's someone else (future me) problem. Feature done and it's 5PM. return std::future&lt;int&gt;(); // Return an invalid future } Ok, what else. Declarative error handling? The smart pointer is part of it like we need Alexandrescu to discover it (Ehi Alex! nobody use fopen anymore). But what about the failure in the constructor of Foo, Foo will probably allocate memory. Ok, let's say it... should I check in every place where I allocate memory that I wasn't able to do it? And then what? Should I call a garbage collector? There is no garbage collector. Ask to install another memory bank? Delete some random object and try again? If there even a sane way (not `malloc(-1)`) to finish the memory on a system with virtual memory? Same thing with system object handler. Because at the end this is what the 90% of the code that I see around looks like. std::future&lt;int&gt; Foo::bar() { return std::async(std::launch::async, [this]{ this-&gt;m_obj.count_stars_in_the_universe(); }); } std::future&lt;int&gt; ma_function(std::string const&amp; obj_name) { std::unique_ptr&lt;MyObject, Releaser&lt;MyObject&gt;&gt; my_obj = get_obj(obj_name) | get_obj("default_object"); Foo bar(my_obj); return bar.use_obj(); } Optional? They [workish in rust](https://doc.rust-lang.org/book/first-edition/error-handling.html)... void ma_function(std::string const&amp; obj_name) { // Can't I just make the object nullable and use |? std::unique_ptr&lt;MyObject, Releaser&lt;MyObject&gt;&gt; my_obj = get_obj(obj_name).value_or(get_obj("default_object")); Foo bar(my_obj); // FIXME: Let's hope everything goes well. auto ret = bar.use_obj(); if (ret.has_value()) { return ret.value(); } return ah... this is exactly as checking for return values. But at least I can't ignore the error, well... I can, in that case... it will throw an exception!! } Multiple return value? Do I return the value AND the error code? It solves some problems, but I still have a chain of if and it's not composable. Do the C++17 initialize condition in the if make things better? Maybe, I didn't to many experiments. Ok, what else... I don't know! **Just write code that doesn't crash**!!!11!^eleven!1!!auto!^!!needs_more_exclamation_points!^!11!! Note: I work in graphics programming. Most of game/graphics programmer don't really use C++... is more a "C with classes but sometimes I want to make something to look cool and I use C++ style but try to use inheritance and I'll review your ass out of the door". Something that are rarely used in game industry are exceptions (and [they always laugh at us at any C++ conference](https://youtu.be/mFUXNMfaciE?t=1h28m8s) &lt;-- that's not me). And when I say rarely I mean that PS4 libraries are compiled with exception disabled with a secondary version with exception enabled with a high recommendation to not to use them. What do I do? I use error code in initialization phases and prove that the other code can't run into a problem. There is a problem during the rendering cycle? Cool, please crash, that's why we have tests and testers. I prefer my code to crash than and spend 0.1% of the runtime in error checking. Can we just please take in account that exceptions are not the solution that fits well in any cases? Why they design the whole language around it? Also, most of the time people that evangelize exception don't even know how to use them. Anyway, I'm perfectly aware that this is not the only field where C++ is used and in some other field you have to check every single malloc because you know... is better than a nuclear reactor fusion. But from being useful in some cases to "let's make the whole language based on exceptions" is something different. And I'm perfectly aware of this -&gt; https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#S-errors Are the people that downvoted me aware of this? http://seanmiddleditch.com/keep-disabling-exceptions/ 
The `rand` function is not constexpr. Therefore `y` needs to be captured to be ODR used.
&gt; apologise for the collision of ideas, but writing a string two characters at a time is not a new idea. I did cross-check against fmt::FormatInt when writing it Code you linked actually mentions in comment this: // Integer division is slow so do it for a group of four digits instead // of for every digit. The idea comes from the talk by Alexandrescu // "Three Optimization Tips for C++". See speed-test for a comparison. Also your godbolt linke that uses code from Godbolt interview is related this if you want to give proper accreditation: http://graphics.stanford.edu/~seander/bithacks.html#IntegerLog1 &gt;&gt;Not sure why you expect that matters. Because I do not expect it to not matter. In other words when I see branch taken 100% of time IDK if it being taken *randomly* 50% of the time will cause a difference or not. So I make sure I test it. &gt;200 bytes Yes, but it is not only that... if it is not in L1 when real code uses this function it may be a big performance problem. And in benchmark you can not see this since it is always hot. Unfortunately IDK how to test this beside to say that if improvement is only 5% do not use LUT, if it 50% use it since it is unlikely that it will be slower. But I have no idea how to test this. 
&gt; In C++20, requires-expression is just a primary expression like lambda-expression or fold-expression. It makes sense to allow a requires-expression to appear wherever a fold-expression is allowed to appear. (One should prefer named concept over ad hoc requires-expression, but that shouldn't be enforced by the language.) I disagree. So although I do not doubt you are technically correct I do not want to learn this abomination of a syntax. Having a real C++ job means that "if you do not like it do no use it" does not save you from reading crappy code... And that means no way for me to escape requires requires.
&gt; it just hates taking new keywords when it can use the same ones over and over. Being good at doing something bad does not make you good(still less negations than in answer when does your function add does not throw ;) ) . And this is not just me being irritated with ISO prioritizing people with shitty codebases that are too lazy to run rename on their code... Go has a bunch of smart people working on it but I hate their language goals so there is no way I will ever like Go. Same with: decltype auto and decltype having diff result based on extra () ... Also you forgot to mention love of C++ committee for choosing new keywords not based on them being good but based on them not being likely to show up in existing code(same with unordered_ BS)... **no**except was added in C++11 because I doubt anybody actually thought 10+ years after Code Complete appeared that giving bools negative names is a good idea... 
Hear, hear
&gt; Explain someone it for me, I don't get why would we need double requires Paper I linked says we do not need it. If you are worried it is too technical I honestly think it is quite accessible.
This would be a good talk to see from you if you plan to do one next year. "When to use static_assert/SFINAE/constexpr if" Trivia: std::sort(my_list.begin(), my_list.end()); is used as posterboy for concepts and I think it may be better to solve with static_assert. This is ignoring compile time, IDK which one is faster. 
Thanks for following up the accreditation. &gt; Because I do not expect it to not matter. In other words when I see branch taken 100% of time IDK if it being taken randomly 50% of the time will cause a difference or not. Ah, I wasn't aware you thought there was a branch. In that first version the negatives are actually handled by a simple `bool negative = value &lt; 0; digit_ptr -= negative;`. Getting the absolute value also resolves branchlessly. &gt; Yes, but it is not only that... if it is not in L1 when real code uses this function it may be a big performance problem. If the table isn't in cache, the code isn't likely to be in cache either, at which point the data miss isn't important.
No, this will just allow you to see C5038 in external headers. Looking back at your comment I think your request is a separate feature that is orthogonal to the whole external/user header idea. IIUC, you would like to still treat some warnings as warnings when using /WX regardless of whether that warning is emitted in external or user header.
 &gt;&gt;Ah, I wasn't aware you thought there was a branch. confused it with INT_MIN check. :) Although I guess it can still matter due to speculative execution... &gt;&gt;If the table isn't in cache, the code isn't likely to be in cache either, IDK how you **know** ( I am guessing same as you) that, for example code could be prefetched if inlined... &gt;only three cache lines long are you sure it is not 4?
My old professor put up a lot of C++ videos and game engine programming videos and he has lots of personality. You can check him out here: https://www.youtube.com/user/1kingja
My favorites are by Bo Qian: https://www.youtube.com/user/BoQianTheProgrammer/playlists
My suspicion is that programmers typically prefer written instructions to video. Also, you're so right about the videos out there. They are incredibly cringe-worthy. I want to scream at the monitor Everytime I see someone ignore good formatting.
Both boil down to value-initialization here, so in this case, yes, actually. ;-]
Because videos as a form of tutorial are awful and the people not aware of that are likely unable to create decent content 
I do not use GUnit but I saw this guy's talks on YT and I was impressed. BTW as a mild offtopic SML is very cool, I am kind of in a hammer looking for a nail more mode wrt it since I want to use it so badly in code because it is so cool. :)
Nice, but what I do not like is the "manuality" of this. I mean do you really need me to tell you that boost is 3rd party code? Protobuff? range-v3? I feel a lot more could be achieved by using information from vcpkg or at least a list of common 3rd party libraries, than asking user to list them. But problem here is that this is cross team effort for MSFT unlike current solution that is limited to people working on compiler... 
Blame DOS? DOS always uses `/`.
If you want an April1st joke material: Implement a warning for this: https://stackoverflow.com/questions/4075276/variable-scope-in-c 
Because $. Do you really think you can make money of making videos that get 20k views? And beside money experts find teaching people about for loops boring... This is one of my problems with C++ committee - they have been programming in C++ so long that they do not give enough thought how this abomination of a new feature that makes sense to them will be hard to learn for junior developers. If you want to pay money Lynda has C++ courses... https://www.lynda.com/C-training-tutorials/1250-0.html 
Since we only used the textbook for topics we cover in class, I don't think it covers those topics you mentioned but I'll take a closer look into it!
Ah yes, because it makes so much sense to hate an entire language because he thinks a few people who just so happen to use it are mean. Perfect sense.
That's a bit disingenious. Catch requires you to have one TU where it's main is defined. I also don't want to spend time on recompiling the test library for each and every test TU if that weren't the case. With a package manager (like vcpkg) adding gtest is super simple.
Can't agree more with this.
PM me if you want friendly guidance. It can be hard to get started but it's surprisingly easy after you've done it once.
I love his videos. He teaches really well, and has such a great voice!
you know there is actual business to fake your github project with lots of watch and forks, so you can later put it in your resume. This youtube thing is similar.
As a presenter at multiple CppCon and C++Now conferences with several videos on youtube I can say that it requires a lot of work to create a decent video (or even a crappy one for that matter). Maybe some people are "naturals" but for most of us it's really a lot or work. The CppCon/C++Now sessions are 1 hour long. I'm starting to thing that this is too long for a video. Jason Turners videos - 12 min on a specific subject - I think are the most useful. For more extensive treatment I think an blog/ article / book is better. I need to go back and forth, random access, mess with the code, etc. But blogs articles and books are also very time consuming to produce. And programmers/companies are paying for this material these days. So we're in a good/bad state. Good - lots of material - some of it very good. Bad - haphazardly organized and surprisingly hard to find what one is looking for. I would like to see some model where the best authors/coders can get compensated by those who benefit from their work. I don't have any specific ideas though.
Part of the problem is that C++ has evolved into a huge batch of disjoint features. It is very powerful, there are many ways to do the same thing. But this also makes it very, very hard to learn. One has to learn a ton to be able to select the most suitable way to do something. The problem is made a lot worse by the tendency for bloggers/video presenters/etc. to choose the most clever way to do something. But this often happens to be the most opaque way to do it.
Offering crap for free doesn't somehow magically elevate it above being crap, and if most tutorials are of low quality than we as a community have a problem: we kinda need those beginning C++ programmers, because without them we will eventually run out of experts as well. Also, someone asking for tutorials is not likely to be in a position where they can provide those tutorials, now is he? 
Very tough to present coherently on though because it's so opinion based. Suitable for C++ Now, otherwise I wouldn't risk it. Besides 2018 talk topics are already known, ACCU is on Outcome V2, CppCon is on clang libtooling.
Ah, so it's treated like a straight alias instead? Is this a bug? Is this case covered explicitly in the standard?
Well it's also possible to write nonsense like `requires (!!~-+x)`. But even if it does need to be prohibited by the language, _how_ should this be done? Should we just add a sentence to the standard saying that "anything that looks ugly is ill-formed"? :)
And `\` for both paths and escapes
It's not redundant if the reference is captured by copy. (I don't know whether that's specified by the standard, but compilers seem to agree.) Yet clang still issues the warning in this case. int var = 0; int main() { int&amp; varRef = var; [varRef]() mutable {varRef = 1;}(); return var; // 0 }
"The algorithm then becomes simpler, becoming copy instead of transform." You can replace copy with std::for_each but that does not make it better, it makes it worse. Similarly here when I see copy I think 5 will be copied somewhere, I do not think 5 will be copied as 55 somewhere. Since transform is for that. 
TheChernoProject has good tutorials on youtube: https://www.youtube.com/user/TheChernoProject. He works as a C++ programmer at EA I believe, so he is a professional.
Paper I linked explains the changes needed.
Right. To clarify, I understand why what I posted is different, and why it cannot work; but from my point the core elements are similar enough to the original example that I feel it would be dubious design for the original example to be acceptable.
Read a book boi 
 std::sort(a, [](const employee&amp; x, const employee&amp; y) { return x.last &lt; y.last; }); Is that an array of callback functions? I've seen it before, but don't really know exactly what it's and what I should use it for. `[]()`
On reddit mobile there are these eyes staring at me under the title: "you WILL use my websockets...".
Indeed. I wish he did more videos.
Seeing as the proposal [String literals as non-type template parameters](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0424r2.pdf) was added to C++20 I tried to make it work with GCC to test it out. Enjoy. 
All you people talking about zero overhead all the time without the beginning of a proof even for what already exist are crazy. Have you ever taken a look at the shit that is emitted by modern C++ being compiled? It could be worse, of course, but if you don't find overhead in there in the compilation result of a non trivial code, please tell me where to look. Now I'm not saying that it would not be useful in some particular cases to have lazy algorithms. But run them on trivial dataset (where split will probably be called *most of the time*) and you actually risk to generate far more overhead than if you used a trivial eager implementation. This is more or less the classical constant factor vs. algorithmic complexity, and unless you have a working prototype that permit you to watch a real result, you just don't know where is your crossing point.
&gt; it just hates taking new keywords when it can use the same ones over and over. I would interpret this as they hate me a little bit anyway... :p
Also, it was in the pre-C++11 era. Not that I'm sure that Linus would find C++ &gt;= 11 better, he might as well think its even more crazy (which kind of is for several reasons, e.g. the size of the standard...)
I downloaded the VM (which took more than 7 hours!?!?), turns out it does have 15.5 - despite saying on the website it's 15.4. I was able to reproduce the problem and to find a work-around, so our library is fixed now. I will try to come up with a minimal example for the Visual Studio team somewhere in the afternoon and I'll post it as a reply to an earlier message in this thread. 
Code-as-images breaks my heart. Do not do this. &gt; // Dear Santa please make this &gt; // ranges::copy(va, vb) &gt; // equivalent to this &gt; ranges::copy(va, ranges::back_inserter) Please, don't. Perfomance of `back_inserter` is often horrible. It should be equivalent to `vb.insert(vb.end(), va)` or `s.insert(va)` (assuming all two-iterator functions are overloaded to work with ranges too) for eligible types.
Since C++11, an expression beginning with a single left bracket is a *lambda function*, that is, a function with no name. The code you quoted is more or less equivalent to declaring a function `compare` as follows: bool compare(const employee&amp; x, const employee&amp; y) { return x.last &lt; y.last; } and then doing: std::sort(a, compare);
Yep, four cache lines, though that last one is only used every seven calls or so, even with uniformly sampled, maximally sized integers. Given that's not always a valid assumption, since you'll frequently be using smaller numbers and natural numbers normally follow [Bedford's law](https://en.wikipedia.org/wiki/Benford%27s_law), that is pessimistic. Even if you missed top level cache on *every* reference to that last cache line you're talking worse-case 1 cycle latency extra on average. It is possible to hypothesize cases where only D1 is flushed or where I1 is flushed but gets prefetched, which doesn't require inlining. I don't see it happening a lot, though, and if it does it's not likely to be performance critical. Skylake's D1 is 512 cache lines and 8-way associative, so if you're calling this function frequently enough to matter you'd have to be pretty unlucky for your data to get flushed. Even if it does get flushed, [L2 latency is only 12 cycles (v. 4/5 for D1)](http://www.7-cpu.com/cpu/Skylake.html). Since all of the misses can be done in parallel, we're talking going from 29 to 37 cycles per call. Whilst a tradeoff that takes, say, 33 cycles with no LUT might win in this case, to do so means you have to be missing D1 more than half the time. Given this code is most likely to be a bottleneck during serialization, which generally doesn't thrash the caches, I'm not concerned.
Can we predict what would be nessesary in the future? WOuld you be able to tell 5 years ago that `requires` would be keyword? DId `co_yield` felt nessesaty to reserve in 2011?
Agreed. (And I don't know how, either.)
I find it useful in if constexpr expressions for example.
&gt; I wonder how often he needs to debug leaks and segfaults I must point that GCC supports cleanup functions in C as extention. It executes function with given variable as argument as soon as that variable lifetime ends. Does it looks familiar?
https://www.youtube.com/user/BoQianTheProgrammer Go to his playlists. He is the best regarding your concern IMO.
Doesn't this sort of go against the way STL algorithms are designed (container-agnostic using iterators)?
And it should be named `insert`, not `copy`. Because `copy` in standard library has always been *replacing* contents of the destination, not inserting.
With some help from /u/TemplateRex, I was able to install a Visual Studio VM and this is a minimal example to reproduce the problem, no includes required: struct X { static bool match() { return true; } }; template&lt; typename T, typename &gt; struct A { static bool match() { return T::match(); } }; template&lt; typename... Ts &gt; struct B { static void match() { using swallow = bool[]; (void)swallow { A&lt; Ts, decltype( Ts::match() ) &gt;::match()... }; // works: (void)swallow { A&lt; Ts, bool &gt;::match()... }; } }; int main() { B&lt; X &gt;::match(); } 
Most of these algorithms could be done on generic iterators. And that's the only way I could see it get into the standard library. But then it's even harder to make it not copy too much.
&gt; Please, don't. Perfomance of back_inserter is often horrible. I know. My wishlist for this Christmas was regarding the meaning of code, not about implementation... I know inserters are slow, I mean I knew about it 5 years ago, I did not do any benchmarks recently...
Yes, but that is kind of the point. And AFAIK STL was designed in that ugly way because at the time they could not solve overloading properly... and if you wanted to sort c array or half of a vector you could not do it with a container overload so they picked the 2 iterator one. This is my understanding of the situation based on some stuff Bjarne said. 
Yeah integrating google test isn't the hardest thing, but it definitely breaks convention, so it's a bit of a pain to always have to be explaining it to people. I feel like abseil is going to be the same way.
Wow, thanks so much! I was looking for something like this and it's amazing!
Yeah, I have seen many non-standard C features which are part of core language in C++. GCC also offers lambda expressions in C.
Can you come off a bit less passive aggressive when you post something?
Quick look through the code it seems to be standard snake_case?
Okay. No generated code is not always beautiful, especially where there's a lot of inlining. What I'm suggesting here is to make things as efficient as they are, because I'm concerned about generated code. I don't want it to be worse. So you know how a lazy split even work? Let me enlighten you. basically, the state of the range will be very simple: a beginning and the end. Each time the next value is called, we save the beginning into a local, then we call `std::find` to find the splitting character. We assign the result of find + 1 into the beginning, return the local beginning, and the result of find. Voilà! It's basically looping over the range, and taking a small break to return a view of the range that would be a split. This is indeed zero overhead, and of don't waste time allocating useless memory. Do you know the greatest thing about that? If you adding the result of the lazy split into a vector of string, you basically have the exact same thing as if the split returned a vector of strings. In that case were you do an assignment into a container, the algorithm will run until the end, making it as if it was not lazy. You really get best of both world, without any overhead over the choice of how the user want to use `split`. std::vector&lt;std::string&gt; vec = string.split(','); // works for (auto&amp;&amp; str : string.split(',')) {} // works + no overhead I agree, generating all the result beforehand may be faster, and I couldn't be more agree with you. In my code, when I'm concerned about performance, I benchmark and profile. If creating a vector with the whole result of split before doing anything else is faster, yeah, screw the lazy, give me the vector. But at least with the lazy algorithm I have the choice to either be lazy or not. I hope the motivation behind having lazy algorithms are clearer now. We want to choose where something is lazy or not, and we want the smallest overhead possible, because it's how we roll. 
Yes, it become an alias. Great thing references have no specified storage. I don't know if it's covered by the standard or not. I think so because I really doubt clang folks would create a warning they encourages you to not follow the standard.
&gt; And it should be named insert I am fine with that, but problem is that there are other algorithms I want to see work with containers, so you would need transform_insert transform_insert_if(transform_if is proposed IIRC) move_insert generate_insert ... So I still feel overloading is the best solution. But not too strongly since I have little experience with using code that operates on containers.
Shouldn't that algorithm just be called `append`?
Are you fine with inconsistency that depending on the type of `b`, `copy(a, b)` would either replace contents of `b` (for `array`) or append to `b` (for `vector`)? I find it totally unacceptable. We don't need another `vector&lt;bool&gt;` type of thing.
&gt; Greg is the co-founder and CEO of Undo. ...
Something I would recommend is to refactor the names of your source files, and just putting them in a parent directory.
&gt; My suspicion is that programmers typically prefer written instructions to video. I certainly do. I like to skim, go back to a certain part, etc... it's easy with books (especially digitized, but an index will do). Videos are not the format for it.
I meant to comment on this yesterday, but this looks great! Also, awesome docs and I'm definitely going to have to use that package on my projects from now. Much more useful and succinct than doxygen, especially for smaller projects where the architecture and graphviz diagrams doxygen can make aren't as useful. Question though - how did you pick up using SIMD stuff like this? I'm trying to understand how to better use SIMD stuff, because I'm doing astrodynamics stuff at work and that requires more than just a few arithmetic operations. I want to understand how to use streaming loads, shuffles, scatters, etc, along with understanding approximations of things like `exp()` for AVX2. Just can't find a ton of resources on it
Yeah, examples and library files are mixed. I need to look in the Makefile to tell them apart.
Yeah, moving around a video to find what you need is miserable without linked annotations. 
Hey, that's a great point. Didn't think about it this way. Do you think that the intent would be clearer by using a free function called "push_back" instead, like the range-v3 library does?
If that's what you've got from my point, you're clearly just trolling.
I agree, it certainly got crazier, but on the bright side benefits you get off new craziness are significantly higher now.
&gt;Yes, but that is kind of the point. A change in the STL algorithm design would probably fit better in a hypothetical std2 rather than the ranges TS. That said, a post generalizing this change and explaining why it could be a good idea for std2 might make for some interesting reading. &gt;they could not solve overloading properly Could you expand more on this? Genuine question; it's the first time I've heard this claim.
Either that, or add some lines to your /etc/sources.list.d/llvm: deb http://apt.llvm.org/unstable/ llvm-toolchain main deb http://apt.llvm.org/unstable/ llvm-toolchain-5.0 main deb-src http://apt.llvm.org/unstable/ llvm-toolchain-5.0 main Let the package manager do it's job, minimal overhead, well-resolved dependencies.
`std::sort(xs, (a) =&gt; a.last);`
It's really weird to me why the author chose development as the example for the use of containerizing clang. There are legitimate uses, like managing a consistant CI infrastructure. But they're really misrepresenting the idea here.
This successfully compiles for me in 15.5.2 with `cl /EHsc /nologo /W4 /std:c++latest meow.cpp` (version 19.12.25831). I also checked our internal build of 15.6 Preview 2 (current version 19.13.26009) and our current development build in git, and they also succeeded.
https://www.youtube.com/user/lefticus1/videos
I've reorganized things a bit. Mainly removed all the unnecessary files from the older prototype. A side aim of the library is to avoid frameworkitis, so keeping it all at the top level is like an ongoing "design test" to test that it doesn't blow out in complexity.
Get C++ Primer. (Not Primer Plus, different book) C++ is like a different language now, you're doing yourself no favours using an outdated book.
But that was exactly your point. It's in plain English right there. "Look, some i think some C++ developers are being snobby or something, no wonder Linus hates the language!" I don't know what other way to interpret "Linus has stood by his anti C++ position because he thinks some C++ devs are snobby" if not as, well, that. It does not make sense to be anti C++ because of something stupid like "I don't like some developers who just so happen to use C++"
The VM has 19.12.25830.2, so I assume the bug is fixed now? Thanks! :) (Plus I found a non-ugly work-around for our library) 
I can’t be certain without verifying that our command lines are identical (e.g. that this is not specific to `/permissive-`).
It seems to be connected to /std:c++latest. Here's the output I see: &gt; C:\Users\User\source&gt;cl /EHsc /nologo /W4 /std:c++latest Source1.cpp &gt; Source1.cpp &gt; &gt; C:\Users\User\source&gt;cl /EHsc /nologo /W4 Source1.cpp &gt; Source1.cpp &gt; Source1.cpp(26): error C2976: 'A': too few template arguments &gt; Source1.cpp(11): note: see declaration of 'A' &gt; Source1.cpp(22): note: while compiling class template member function 'void B&lt;X&gt;::match(void)' &gt; Source1.cpp(33): note: see reference to function template instantiation 'void B&lt;X&gt;::match(void)' being compiled &gt; Source1.cpp(33): note: see reference to class template instantiation 'B&lt;X&gt;' being compiled &gt; Source1.cpp(25): error C2955: 'A': use of class template requires template argument list &gt; Source1.cpp(11): note: see declaration of 'A' &gt; &gt; C:\Users\User\source&gt;
The problem is that different people have differing intuitions. `ranges::copy(range, container)` could legitimately be equivalent to: * `ranges::copy(range, back_inserter(container))` * `ranges::copy(ranges, inserter(container, begin(container)))` (for ordered containers) * `ranges::copy(range, begin(container))` * `container.assign(begin(range), end(range))` all of which are useful in different contexts. range-v3 avoids this confusion by providing different meaningful syntaxes for each: * `ranges::action::push_back(range, container)` * `ranges::action::insert(container, range)` * `range::copy(range, begin(container))` * `container = range` [**DEMO**](https://wandbox.org/permlink/A4svdpo4CGFPZKuF)
&gt; Please, don't. Perfomance of `back_inserter` is often horrible. `ranges::push_back(rng, container)` is [actually implemented by `ranges::insert(container, end(container), rng)`](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/action/push_back.hpp#L45) which is [implemented by `container.insert(end(container), begin(rng), end(rng))`](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/action/insert.hpp#L132) except that [it's smart enough to grow `vector`s exponentially when they run out of capacity](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/action/insert.hpp#L86).
&gt; I am fine with that, but problem is that there are other algorithms I want to see work with containers, so you would need &gt; &gt; transform_insert &gt; &gt; transform_insert_if(transform_if is proposed IIRC) &gt; &gt; move_insert &gt; &gt; generate_insert view::transform(rng, function) | action::push_back(container) view::filter(rng, predicate) | view::transform(rng) | action::push_back(container) view::move(rng) | action::push_back(container) view::generate(function) | action::push_back(container) 
Search using SIMD? https://blog.demofox.org/2017/06/20/simd-gpu-friendly-branchless-binary-search/
Your mom is ill-formed! (with no diagnostic required)
I just build it from source?
How would the idea of constexpr bit fields work with the rest of the language? We can at least get constexpr optional&lt;bool&gt; of size 1 with constexpr bit fields. Then again, I don't see that much point in an optimized optional&lt;bool&gt;. Surely it's better to use a tribool type or a dedicated of some kind. Then you can have you multiple states and constexpr. But constexpr bit fields would still be interesting...
This doesn't sell me on the utility of smart output iterators. I would solve the problem in the post with ([**DEMO**](https://wandbox.org/permlink/LXzPc4ukKTTjUaND)): auto results = numbers | ranges::view::filter(isEven) | ranges::view::transform(ranges::convert_to&lt;BigInt&gt;{}) | ranges::to_vector; I *do* think you were on to something when you mentioned algorithms with multiple outputs like `partition_copy`, however. The "single data flow" nature of range-v3's range adaptor compositions cannot really copy with multiple-output algorithms. There's definitely a use case there for smart output iterators / ranges that someone needs to investigate.
I'm not sure constexpr bit fields would get us efficient `optional&lt;bool&gt;`. A bit field cannot produce `bool&amp;` to individual bits (see [vector&lt;bool&gt;::reference](http://en.cppreference.com/w/cpp/container/vector_bool/reference)), so we still have the problem of converting to `bool&amp;`.
 &gt; Then again, I don't see that much point in an optimized optional&lt;bool&gt;. - Ideally everything in the stdlib would be optimized to the greatest extent that it can be. Otherwise the types in the stdlib don't get used in practice, and people have to replace them with types that are optimized for their use case. The standard types should be the best option for as many use-cases as possible. A lot of companies do end up basically discarding stdlib and implementing their own, but that shouldn't be the case and ideally at least "vocabulary" types like optional and variant would be used by everyone and be fully optimal. - If there's going to be generic code that uses `optional&lt;T&gt;` you don't want to have to special case it for `optional&lt;bool&gt;` to avoid `optional&lt;bool&gt;` if `optional&lt;bool&gt;` has bad performance, because making exceptions like that is a PITA.
I don't think using 2 is very useful, the most efficient when it comes to generated assembly is to use a signed byte, because you can just use the zero, positive and negative conditional jumps or instructions. I'd put the optional part on 0, the other 2 values can be any positive and any negative number.
I hope it's something the standard can clarify soon. I doubt it would be the source of many bugs, but there is no reason to leave this unclear (it's not like there are optimizations depending on it).
Isn't optional&lt;T&amp;&gt; just T*? If we assume we always use smart pointers for memory management, I know that I'm nos supposed to delete raw pointers. I don't see why I'd use optional&lt;T&amp;&gt;. 
It doesn't get us the reference requirement, but it would get us the size == 1 and the constexpr requirement. Two out of three.
I don't think the stdlib should be maximally optimized. You can't have generalized libraries that are optimized for every use case. Companies should use their own libraries if the standard ones aren't sufficient. And I highly doubt there would be any measurable difference in cases like optional&lt;bool&gt;. Out of all the options, the only one making any sense to "optimize" is constexpr, because constexpr is hard. The standards committee would be wasting their time with anything more than that.
Because you wouldn't have to check for null. With an optional&lt;T*&gt; you have to check that it exists, then you'd have to check that it's not null. If you can cut out that extra check when it's not needed, why wouldn't you?
I was just watching a cppcon video with some guy talking about working on llvm... Is that what all the cool kids are using these days?
We can already do that without a constexpr bitset. The article shows a constexpr example with `bool` instead of `bool&amp;`, but a constexpr `optional&lt;bool&gt;::reference` type should also be possible.
Use static_assert, when there are/should-be no other options available to the user. "Use this function/overload correctly or else" Use constexpr if if you want compile time branching. Use SFINAE if you don't have constepxr if (ie pre C++17 compiler), or you really need to remove a function from the overload resolution. :)
I'm asking about optional&lt;T&amp;&gt; being equivalent to T* because the article mentions that it should be a thing. I didn't say anything about optional&lt;T*&gt;.
Which is what I said. My point is that constexpr bit fields would get us most of the way there. Those are the most useful optimizations. If the reference specialization isn't as optimized, no big deal, since reference wrappers are just pointers internally and you literally cannot get constexpr or size == 1 for that. It's a fools errand to want all three at once.
We are already most of the way there (2 out of 3). constexpr bitsets add nothing to `optional&lt;bool&gt;`.
You can't optimized for every use case when there are tradeoffs. The standard should be generally optimized. A byte sized type is better than a 2-byte type in every case. If the standard can implement a byte sized constexpr `optional&lt;bool&gt;`, it should. `optional&lt;bool&gt;` currently has a tradeoff, so `std::optional&lt;bool&gt;` cannot be optimized for size. If the restrictions on constexpr unions are relaxed, `std::optional&lt;bool&gt;` should be 1 byte.
Sorry, I misread. std::optional gives you the value_or function, which you can't get with a T*. Sometimes you just want to have a default value if it doesn't exist.
Thanks, this is why it's always important to provide command lines with repros. Reproduced with our current dev build (Clang 5 accepts in both 14/17 modes) and filed as VSO#541040.
À `optional&lt;T&amp;&gt;` is basically a `T*` indeed, but it express something more. It clearly express the intent of the programmer about what semantics are expected. That and `value_or`. Also, an `optional&lt;T&amp;&gt;` would be constructible from a `T` lvalue, and would also be default constructible.
I see. The example I meant to express what the one of [set_segregate](https://www.fluentcpp.com/2017/02/09/set-aggregate-set-seggregate-higher-level-algorithms-on-sets/), where I think smart output iterators could be useful to add a transformation on only one of the 3 outputs, for example. I'm in the process of investigating more the use cases for smart output iterators. I'll submit to conferences when this is ready so that we can discuss it more. Thanks for your comment! :)
Under oath I can say I am. :) Like Casey said in his answer people have different intuitions and obviously I think mine is correct one(copy means to me copy from source to the container using insert member fn that dest container has). 
&gt; Shouldn't that algorithm just be called append? Problem is that you end up with a lot of duplication... transform_append move_append ... You can see Casey's comment for the best syntax. You can trust him, he is official Ranges person. 
clang uses LLVM for its IR and codegen phases I believe, some other projects also target LLVM because you basically get a high-quality compiler backend for free 
I actually wrote a short article about what I find missing in range-v3 based on reading your article. :) tl;dr is that I would want ranges-v3 to work with container outputs(so need to use back_inserter/inserter). People here [commented](https://www.reddit.com/r/cpp/comments/7k6g2b/what_is_missing_from_ranges_ts/drcpvgt/?context=3) it is confusing(because people would not know what to expect) so if I had to pick one true algorithm I would implement my_range::c_transform(src|is_even, dest, make_big), where dest is container and c_transform is container based version of transform, same as google Abseil has c_sort, c_find_if... But honestly my biggest problem with this code that IDK how to fix is this RandomAccess of operations. first thing that happens is that input if filtered(that is in the middle of the line of code), then it is copied (beginning of the line) to src(end of line). So mixing of | and function call makes code less readable than I would like... So currently the best way of writing this would be: `auto even_nums = src | is_even;` `my_range::c_transform(eve_nums, dest, make_big);` 
&gt; Could you expand more on this? https://herbsutter.com/2011/10/07/why-no-container-based-algorithms/
I found the same problem... However if you are looking for an example and explanation of a specific concept... There is tons of easily findable resources... The way I learned was I found a site with exercises... I used code abbey... And as I worked my way down the exercises, I needed to figure specific problems out... And 99% of the time... Any concept you have a problem with, somebody had it first... So you're searches will turn up results... Just looking for a CPP tutorial video playlist isn't very helpful. 
*sigh* There are some problems pulling that quote out of context. That section of the paper is really discussing a fairly vexing technical issue related to name mangling. And, as a critique of that paper, that particular statement is also made without any explanation or support for why the syntax is confusing or embarrassing. Take unsupported claims with a grain of salt. That said... story time. Not so long ago requires-expressions (the phrase introduced by the second `requires`) was not allowed in constraint-expressions (the phrase introduced by the first `requires`). It could only appear in concept definitions. In fact, this is *exactly* what is proposed in the section of that paper where that claim appears. However, in 2016, there was a [proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0266r2.pdf) to relax that restriction. Note the strikethrough of paragraph 4 in section 4 of the paper. And thus was born `requires requires`. To tell the truth, I had never actually implemented that restriction in GCC, so it had always been possible. I think that Walter may have discovered that and found it useful, leading to that paper. Lest anybody think that I wasn't sensitive to writing `requires` twice, I did spend some time trying to determine if that could be simplified. Short answer: no. The problem is that there are two grammatical constructs that need to introduced after a template parameter list: very commonly a constraint expression (like `P &amp;&amp; Q`) and occasionally syntactic requirements (like `requires (T a) { ... }`). That's called a requires-expression. The first `requires` introduces the constraint. The second `requires` introduces the requires-expression. That's just the way the grammar composes. I don't find it confusing at all. I tried, at one point, to collapse these to a single `requires`. Unfortunately, that leads to some seriously difficult parsing problems. You can't easily tell, for example if a `(` after the `requires` denotes a nested subexpression or a parameter-list. I don't believe that there is a perfect disambiguation of those syntaxes (see the rationale for uniform initialization syntax; this problem is there too). So you make a choice: make `requires` introduce an expression (as it does now) or make it introduce a parameterized list of requirements. I chose the current approach because most of the time (as in nearly 100% of the time), I want something other than a requires-expression. And in the exceedingly rare case I did want a requires-expression for ad hoc constraints, I really don't mind writing the word twice. It's a an obvious indicator that I haven't developed a sufficiently sound abstraction for the template. (Because if I had, it would have a name.) I could have chosen to make the `requires` introduce a requires-expression. That's actually worse, because practically all of your constraints would start to look like this: template&lt;typename T&gt; requires { requires Eq&lt;T&gt;; } void f(T a, T b); Here, the 2nd requires is called a nested-requirement; it evaluates its expression (other code in the block of the requires-expression is not evaluated). I think this is way worse than the status quo. Now, you get to write `requires` twice everywhere. I could also have used more keywords. This is a problem in its own right---and it's not just bike shedding. There might be a way to "redistribute" keywords to avoid the duplication, but I haven't given that serious thought. But that doesn't really change the essence of the problem. TL;DR. True understanding is not gained from headlines, pull quotes, or tl;drs. Read the fucking post.
Casey thank you for your comment and thank you for your work on dragging VS to support ranges. :) But I hope it is obvious this code still contains boilerplate. Like article mentions most containers have one insertion point, so push_back is just noise unless you are dealing with deque. So this would probably be nicer: `view::transform(rng, function) | action::insert(container)` Problem may be that overloading insert action may give super confusing error messages for other use cases of insert. 
llvm and clang have got two big things going for them: 1. They have been written in a very modern style, so jumping in the code base and integrating it is a lot more straightforward and palatable than GCC 2. They are licensed under the BSD license, so it's a lot more comfortable to be used in a commercial environment. Also of help is that Apple has thrown their weight behind the projects.
Thanks for the in depth reply... So how trailing is visual studio? Because I've already run into issues with some features of c++17 not making it into the 2017 edition
&gt; byte sized type is better than a 2-byte type in every case My friend `std::vector&lt;bool&gt;` would like to have a word with you
http://en.cppreference.com/w/cpp/compiler_support
MSVC is getting better with each version. The latest one (15.5) is actually pretty close to being full featured C++17-wise. Just make sure you've updated your installation and are using the proper compilation flags. One of the issues I've found personally, is that despite increasingly great langauge support, cl.exe is not quite clever enough to handle the full brunt of modern C++. It works, but the resulting assembly ends up being not nearly as tight as what you get out of gcc, clang or ICC. My projects are set up so that I use visual studio for development (for the amazing debugger), but my windows release builds are generated using mingw. CMake makes this easy. Microsoft has also been working on integrating a clang frontend on top their codegen (Clang/C2), but it's not production-ready yet. I don't know how good the resulting code is.
First of all thank you for the reply. And that is pretty much end of good news. :P Bad news are: Concepts are your baby. Even if they were the ugliest and dumbest baby in the town you would still think they are beautiful and smart. So if you ask me there is no need for UX study or poll or Sankel [video](https://www.youtube.com/watch?v=H8HplZtVGT0#t=36s) on why "requires requires" is confusing and embarrassing. If you do not believe me do the Herb style UX study(without leading the witness :P ) on 5 junior developers and see for yourself. Just do not run it against some members of C++ committee - they are not "normal" C++ developers, plus they will try to be nice and polite since they have personal relationship with you and Bjarne and Gabriel. So it is not shocking that you do not find requires requires confusing when you implemented and designed the feature... But that is not really a good criteria if a feature is intuitive and easy to understand. And this is nothing against you personally, there is a reason why companies do UX studies instead of just trusting people who designed the feature to say if it is good or not. People get attached to their work, there is nothing strange about that. That is why code reviews can be so much "fun". :P So in the end I will learn to live with requires requires like with a billion mini [disasters](http://ericniebler.com/2013/08/07/universal-references-and-the-copy-constructo/) in C++ but I mean for a language feature in 2020 it is quite clumsy. I won't go into the keyword phobia and rant how this is not year 2000 where people do refactoring manually or with sed since co_bla showed how much committee cares about this. P.S. I have one use case/feature I would like to see in language wrt "meta" you are working on now, if you are interested ping me your e-mail over pm. 
&gt; Microsoft has also been working on integrating a clang frontend on top their codegen (Clang/C2), but it's not production-ready yet. I don't know how good the resulting code is. That's been abandoned for quite a while, and will be stuck on Clang 3.8 for the remainder of its short life.
Huh, I completely missed that. Thanks for the info!
Thank you for the suggestion! Vcpkg is part of Visual C++, we communicate with them regularly and are always on the lookout for ways of improving the overall experience with Visual C++. A solution like yours would require many questions answered, before it can even be considered: - How should a compiler validate whether a given library is really one of the famous ones? Should we look for environment variables, known locations, file content? - Should the list be hardcoded or should we connect and load definitions from vcpkg? - Why limit to vcpkg, why not try to pick up some information from other package manager, build systems etc.? - What performance degradation for these checks are you willing to tolerate? Few might agree such automatic detection is useful, but everyone will be throttled down - How surprising will such feature be to users? Will they see warnings on one computer and not see on another or something like that? We are all for making the experience smoother, but this would probably be a better functionality for IDE than compiler.
They picked the wrong tradeoff.
I was wondering about [similar](https://www.reddit.com/r/cpp/comments/6oefcz/should_sizeof_stdoptionalt_sizeof_t/) problem before... In this case I think best solution is to have 2 byte optional&lt;bool&gt;. I know this may be controversial, but it is what I would pick. Additionally what I would like is for compilers to start using deadspace inside optional(padding) for storing other variables (in release build).
&gt; no diagnostic required Great, now I will have nightmares for the rest of the week. ;)
In the mean time, if the library marks its own headers with #pragma system_header you will be implicitly getting what you want. Besides, if you include all external headers via &lt;&gt; and all yours via "", you can use /external:anglebrackets and you won't need to specify locations of your standard libraries.
Sure. To be fair, they picked a trade-off that turned out to not be so good in 2017 as it was whenever they made the decision. But, there's at least one case where a two byte type is better than a one byte type. Also, sometimes you want your data spread across multiple cachelines so that e.g. your atomic operations don't invalidate data that it doesn't need to. I realize that's not the case you have in mind -- just playing devil's advocate.
&gt; but this would probably be a better functionality for IDE than compiler "it doesn't matter if a cat is black or white so long as it catches mice" So although I know nothing about technical difficulties of implementing this here is a brief "user story for this feature": 1) When user is creating project there could be an unchecked option to specify that "library" code is analyzed at lower level than user code. And user could here specify what code he considers library with some reasonable defaults provided by the IDE. 2) When user compiles and VS displays the error/warnings list there could be a gentle message about how it is possible to change warning levels for library code. This should not slowdown the IDE/compiler too much since you have the warning information(file, warning kind). Obviously there are many corner cases, like for example sometimes users need to specialize something in namespace std and you want full warnings on that code... 
It's definitely a valid tradeoff for some use cases. The main problem is they compromised the standard vector interface, so `vector&lt;T&gt;` cannot be used in generic code when `T = bool`. `vector&lt;bool&gt;` should be a vector of bools. What they made should be called `dynamic_bitset`. &gt; Also, sometimes you want your data spread across multiple cachelines Good point. The user can add `alignas(std::hardware_destructive_interference_size)`, we shouldn't artificially inflate a standard type for everybody.
That benchmark is specifically tailored towards horizontal scaling. Depending on the amount of work performed per connection, these benchmarks will change dramatically. If it's just a matter of being able to handle many connections, C++ will not given you anything here that won't be obtained by simply throwing more Node servers at the problem. Adding a whole new programming language to your stack is going to cost you a LOT in the long run, so it's not a decision to take lightly, your cost-benefit analysis is very tricky here.
run!
C++ is efficient, at the price of difficulty. If you want to learn it, buy and read books. There are several reasons C++ isn't used by most webdevs. The most obvious is that, well, you can hire a lot of junior webdevs to write a lot of code in another language for the price of a competent C++ dev. The web servers are cheap enough that typically makes economic sense.
Ah yeah totally get that. Connections isn't the issue. Right now, I am only relaying messages so that is easily doable. Client side handles the data transmission, but I don't want to rely on client side data connections. Memory usage is what I am considering. Delivering GL data by way of single threaded JS could limit me to a handful of connections per server, if that. Obviously I am not on the Desktop app team but we do have a C++ team of 4, one guy sitting on 20 years of experience. I could have them write this for me....but I like having objectives to take me to new places. This isn't even a requirement in the near future, just something I want to write that has a purpose and can benchmark against current operations.
Yeah...that's what the syntax was telling me too lol.
Thanks for the suggestion! I’ll definitely put it on my wishlist! 
You can do this stuff in C++ and, if you have expertise -- it will be awesome. Question is -- do you have expertise? :) You should do it anyway as a pet project. You will learn a great deal which will help you even if your primary skill is JavaScript.
There is a new library called [Beast](http://www.boost.org/doc/libs/develop/libs/beast/doc/html/beast/introduction.html) for websockets. IDK if that would make your development easier than emulating the code from your link.
Thanks. For the record: GCC 4.8+ and Clang 3.4+ are fine with it even in C++11-mode.
You don't necessarily need to write c++ yourself in order to taste its efficiency - https://github.com/uNetworking/uWebSockets. It is by far most performant web sockets library I've used and I think it'll suffice your use case. And don't think that people here are trying to discourage you from using c++, you just need to understand c++ provides efficiency as a tradeoff for productivity and knowledge when compared to usual webdev languages which are specifically geared towards churning out applications as fast as possible. c++ is still a good language :)
I'm going to ignore the particular needs of game programming, they have reasons to avoid exceptions outside of the scope of your argument. &gt; Cool, please crash, that's why we have tests and testers. Honestly, your argument builds very similarly to the way I would argue for exceptions. Let's keep going. How would I write the exception version of the code you wrote? std::future&lt;int&gt; ma_function(std::string const&amp; obj_name) { Foo bar(get_obj(obj_name)); bar.use_obj(); } The beauty is that the happy case just works, and the sad case is deferred to the caller who will have better context about how to handle it. Moreover, it reads very cleanly, and if we messed up our error handling, it crashes just like we want! Loud failures are great. Exceptions provide the right default when ignored, unlike most other forms of error handling. &gt; Can we just please take in account that exceptions are not the solution that fits well in any cases? Exceptions are the only thing I know of that allow me to write code that looks like your desired implementation. Granted, they are not for every project or for every error case, but they work amazingly well when used correctly. BTW, your exception example wouldn't pass code review and it doesn't reflect a realistic usage of proper exception handling. You only catch what you are able to handle, and you wouldn't catch and ignore an exception except in very rare cases. You are treating them like error codes and not as exceptions. 
Why would you use a std::future and not a std::atomic_flag (or std::atomic_bool if you need full load/store operations, but you probably don't)? Why would you encapsulate the object so the thread is outside the class, not inside? If it's inside you can make the join() call part of the stop() behaviour, for example. You should probably delete the copy constructor and make the destructor protected (or, alternately, virtual public).
Usually creating threads manually is consider a bad idea(for most use cases). You can use libraries that have thread pools, or use std::par overload of algorithms when they get implemented in major compilers.
I haven't followed this all this much, but I hope you are keeping in mind that less typing is generally better than more typing. Or, in other words, do we really need that 'action::' there? I get it that it is an action, but surely the phrases 'push_back' and 'insert' already sound like actions anyway? The thing that bothered me most about early STL was that it made me type things like std::map&lt;int,std::string&gt;::const_reverse_iterator. Let's not go back to that. 
 Doing C++ with Qt makes C++ so much simpler, in Qt, you can [easily terminate](http://doc.qt.io/qt-5/qthread.html#terminate) a thread. 
Interruption points of boost threads are nice I think if you really want to do this. From your link: "Warning: This function is dangerous and its use is discouraged." Doesn't seem nice.
My understanding is that clang's frontend itself is getting so good at compiling windows code that there will shortly be no need for the hybrid version. The choice would be msvc or clang. Presumably VS will allow projects to choose one or the other.
But since we can't overload on constexpr, it sometimes mean that having a function be constexpr means that it will end up being *less* optimized in a runtime case. Example: std::string::size. If it is constexpr, it has to be a for-loop of some kind. But if it isn't, it can call to strlen that will generally have optimized versions for sse, avx, etc (which isn't possible in the constexpr version since strlen isn't constexpr)
The thread can be terminated at any point in its code path. Threads can be terminated while modifying data. There is no chance for the thread to clean up after itself, unlock any held mutexes, etc. In short, use this function only if absolutely necessary.
&gt; Why would you use a std::future and not a std::atomic_flag (or std::atomic_bool if you need full load/store operations, but you probably don't)? Scott Meyers has ~10 pages on this in Effective Modern C++ (Item 39: Consider `void` futures for one-shot event communication). I hear it's popular, it might be worth a read. ;-]
I though vector.insert(pos, beg, end) did only 1 capacity check?
Actions have different semantics than algorithms, and most action names are also algorithm names. We don't really need that `action::` there, but we need _something_ there; how is different names(spaces) for different semantics a problem exactly?
That is the case only for random-access iterators.
Well, maybe creating threads by hand is discouraged. But one needs to learn how to use threads properly before using the higher level constructs like thread pools and such. Part of understanding how to work with threads is indeed how to start and stop them cleanly ;).
His reasoning for not using an atomic is the polling behaviour; but if the flag is just controlling whether some infinitely-looping task should exit then polling isn't a problem. The code in the linked blog post actually polls the future.
For every complex problem, there's a simple, but wrong, solution (or something to that effect).
Can't wait for an atomic flag, and waiting for a "thread was asked to finish" event is a very common need.
Really? Waiting for a thread to finish, yes, but I don't think I've ever seen "wait for a thread to be asked to finish".
That's ok. I wasn't aware of the algorithm names, and I don't like seeing additional syntax that doesn't actually have any meaning. I mean, you could design a new container library that has containers named something like std::containers::ordered::associative::contiguous::container - but let's be thankful that we don't...
Holy shit, you're crazy.
&gt; For every complex problem, there's a simple, but wrong, solution (or something to that effect). I like this quote from Scott Meyers: threads are: easy to start hard to synchronize impossible to stop :P 
That's an great repo. Good documentation, tagged and timely resolved issues, useful changelog and a CI system. The code is probably good too. This could easily be an example repo on how to successfully run an open source project
I may have misinterpreted, but a common example of this is when your main thread creates a bunch of "child" threads, then waits for the 'stop' event (signal handler or whatever). 
Exactly what my project needed. Thanks for the work!
No return, infinite loops... what the hell did I wrote, LOL. Kids, don't drink and code. :D The point I was trying to make is that because of exceptions, looks like that the error handling problem in C++ has been solved and we are not developing any other solution. I don't follow the C++ committee mailing list or read every C++ paper, so I don't know if they propose something else, but every news that I have about C++ error handling is "we are trying to mitigate this problem that exception is causing". /u/duheee is right, there aren't many alternatives. Even relative new languages (Rust, Go, Swift) that don't have all the legacy of the C++ don't propose anything really innovative. What do we learn from these languages? * Rust : If you want error code you have to force the user to check them or crash early when the error appear. Here I would like to add another no check flags, where if the code has been tested and never have caused any problem all the error checking should be optimized out. This is why I pest my code with assert of any kind. At least assert make pre/post conditions of the code clear and are disabled in release. * Swift: You declare the function that throw the exceptions, not the one that don't throw. I know C++ has templates that makes everything more complex. * D: Has exception with finally. And scope guard (see the video I linked before). Natan Blow is writing [Jai](https://github.com/BSVino/JaiPrimer/blob/master/JaiPrimer.md). &gt; Abstractions like RAII, constructors and destructors, polymorphism, and exceptions were invented with the intention of solving problems that game programmers don’t have, and with the result of interfering with the solutions to problems that game programmers do have. The problem that I see here is the opposite. Sometime I really would like to think with object instead of data flow. I like to write code where if you forget do to something the destructor will kindly do it for you. Why can't we have both? Anyway, maybe is my fault, not disabling exception for many years probably changed the way I program and writing correct exception require a different mindset. A mindset that I never developed because I don't use them very often. Don't blame me, I'm not lazy (only a bit), I'm forced to not use them. So at the end every time I write code with exceptions I'm always nervous. I would be happy to use exception if I could disable them in some part of the code, losing even 10% of CPU at loading time when the whole process is bounded by disk access is not a problem. nothrow all the thing? Or maybe disable some exceptions (at compile time), I don't care about memory allocation but I care about missing resources. It would be nice if it was something compile unit based. 
I love this project too. Currently spending time to convince the next manager so we can actually use it.
Are you casually supporting MsgPack from now on? That sounds huge! 
Good docs, good API, couldn't ask for more. Well done!
Smart pointers are only about ownership. You often want to pass around the value of that smart pointer without giving away ownership. I think that not understanding this is where a lot of the abuse of `shared_ptr` comes from. Anyway, assuming you just want to pass optionally pass a reference, why not just pass `T*`? Because accessing an optional without a value results in an exception, while accessing a `nullptr` results in undefined behaviour. It expresses the intent that the value is optional AND it enforces it without killing your program. It's similar to why we use `new` (now inside of `unique_ptr&lt;T[]&gt;`) instead of `malloc` even when allocating a byte array. `malloc` returns a `nullptr` when the allocation fails, while `new` throws an exception when an allocation fails. One crashes your program instantly when you forget to check, the other one throws an exception that can be handled.
I am deeply sorry for bringing this up and I am not trying to undermine the incredible work you have done... But wtf did you call the namespace after your name?!
Because it's likely to be unique?
How does its speed compare to rapidjson?
Used that library for a University project, worked flawlessly. Amazing project, and it keeps getting better!
The author of rapidjson also created a great benchmark to compare several libraries, including Nils' library. See https://github.com/miloyip/nativejson-benchmark
Don't do that, man. Set a good namespace for your library.
And if you don't like it you can write namespaces xyz = nlohmann
https://github.com/dascandy/view/blob/master/split.h Sounds good to me. Somebody should write a paper on strings and string views, and then propose these kinds of things as a set of functions applyable on anything string-like.
check out Google absl, I think it is a bit more user friendly that STL, but it is quite small so it is not STL replacement... 
If uniqueness was an issue then nothing is better than generating a random SHA256. e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
&gt; Concepts are your baby. Even if they were the ugliest and dumbest baby in the town you would still think they are beautiful and smart. I'm a scientist, professor, and engineer. If you seriously think I'm not capable of critically evaluating my own output, you may not understand the concept of professionalism. This is an insult to anybody who takes their work seriously. It effectively reads as "You're not good enough to know that your work is bad." Is that really what you meant to say? &gt; So if you ask me there is no need for UX study or poll or Sankel video on why "requires requires" is confusing and embarrassing. If you do not believe me do the Herb style UX study(without leading the witness :P ) on 5 junior developers and see for yourself. Why would I need 5 junior developers? I teach 50-80 students a semester. I know where C++ is hard to teach and hard to learn, and I assure you this ain't it. Teaching full time at a university will give you a *very* different perspective on what's important in a language, and---most importantly---the importance of exposing complexity incrementally. It seems that there's an assumption that because one can write `requires requires`, that it will be used frequently and for common cases. False. I've been teaching generic programming with concepts to undergrads for 5 years, and it's only come up once or twice. Why so infrequently? It's not essential. Why did it come up? Clever students. All of these "mini-disasters" you refer to are artifacts of adding new features to an increasingly complex language. There are corner cases in the composition of those features that can be surprising or look weird (`noexcept(noexcept(...))`, `requires requires`, copy constructors with forwarding references, etc.). That those warts tend to manifest in advanced library code written by (at least) journeyman developers, is not an accident. I think that's a sign that the committee has done a good job balancing the language's evolution with its complexity. My email address is published widely.
How is a "random SHA256" better than some random bits? ;)
It's not random bits, it's the name of the author ... I see that you are the author/a member of the taocpp ... why didn't you called your json library dfrey::json?
QThread::shoot_yourself_in_the_foot()
&gt; I'm a scientist, professor, and engineer. If you seriously think I'm not capable of critically evaluating my own output, you may not understand the concept of professionalism. LOL, IDK why I wasted time discussing anything with you.
I see, "random". Have my upvote! ;) And yes, not using my name was, in fact, the reason to create a project on GitHub in the first place, even if I'm not super-happy with the project's name "tao" as a top-level namespace seemed to be free and is sufficiently short and easy to type.
Let me take your functions apart: split() trim_left() trim_right() trim() These are effectively string_views on parts of the string. The first is a view-range over the original string, the latter three are a constrained view over the original string. begins_with() ends_with() only_whitespace() These are harder than they look. String equality is defined currently on code unit level, but should be on loose grapheme cluster equality. Doing so makes it language dependent though, making these functions much harder to use correctly. Whitespace is sort of doable but that still requires additional knowledge about encoding to do so. pad_left() pad_right() replace_first() replace_last() These four are methods to create a new string. that are effectively a combination (sequence) of parts of the original one, with some other things appended. While a pad_left function is nice for simplicity, it's the same as a view over a number of space characters, followed by a view on the original string.
It started as a side project and nobody cared. Then there were some discussions and nobody had a better proposal...
MessagePack and CBOR are supported for a year now, see https://github.com/nlohmann/json/releases/tag/v2.0.9. :-)
In case you cannot use it, please tell me the reasons for that.
Several reasons: * It falls out of generic code. Sometimes you want an optional whose type is deduced from something else. This'll become especially important if functions like `map()` get added. If `optional&lt;T&amp;&gt;` doesn't work, you need manual massaging in lots of places... it's not great. * `optional&lt;T const&amp;&gt; = {}` is a fantastic way to express a conditional function! * While we can say that `T*` is a non-owning pointer in modern C++, that's simply an idiom choice that we collectively decide to make. `optional&lt;T&amp;&gt;` expresses "non-owning" clearer. 
Love your work, thank you for bringing the world a reasonably fast, and overwhelmingly convenient JSON C++ library. There might be faster libraries out there, but nothing beats the ease of use of this one!
ugh, futures...
Perhaps you misspelled "hug." Would you like one? 🤗 --- I'm a bot, and I like to give hugs. [source](https://github.com/as-com/reddit-hug-bot) | [contact](https://www.reddit.com/message/compose/?to=as-com)
A common pattern in the "permanent worker thread" code is: "nothing to do? Wait for the signal that I need to stop ". Even more often seen is simply ""wait for either the next work item or a signal tat I need to stop". Not aware it can be done in standard C++, but `select` or `WaitDorMultipleObjects` are the platform-specific tickets to do it.
Then there is also the question of the design behind this if you really want to do it. 
It's as good as any unrelated names people usually come up with!
&gt; array&lt;T, 0&gt; is mandated to work by the Standard well, sure, but the more different implementations you have and the more chance you have to get small behavioral bugs like this. At the end of the day, the only thing that matters is that the code builds and runs the same way no matter the platform.
Would constexpr bit_cast solve this? I'm thinking a union of bool with char; to determine whether the optional is engaged you bit_cast the union (as a whole) to char and test whether the value is 0, 1 or 2. To engage the optional you store true or false to the bool member of the union; to disengage it you store 2 to the char member. I'm pretty sure the latest bit_cast paper is constexpr and should work on unions. Am I missing anything here? 
It's a great project, but I just hope those who use it as example won't latch on the use of emojis in commit messages instead of all the good things you mention just because it's the most visible one (and also the one that requires the least effort and, at least IMHO, also the least useful).
Whats wrong with Gitmojis (https://gitmoji.carloscuesta.me)?
I've always found C++ enums lacking due to (1) the lack of introspection and (2) the absence of support for string conversion (back and fro). As a result, I tend to define my own enums via X macros which in addition to the enum will add: - a `values` function which returns an array of all the enumerators, - serialization to/from string (and via streams) support. Building on the latter, it's easy enough to create an `EnumSet&lt;E&gt;` class on top of a `BitSet&lt;N&gt;` (not the `std` one, it's not `constexpr` enough unfortunately).
Eggplants. Eggplants everywhere.
Some of us are old farts who see people using emojis the way people used to view people who overused ASCII smilies: immature and probably a bit dumb. Also the fact that they are coloured means that they draw attention in a really annoying way if you get to read more of them in a row.
TBH if the API is sane and there are less edges, who cares about "fast", just distribute the load.
I’ve used it in two companies already, and it’s a fantastic library. In fact, even the JS devs were amazed at how east it is to use, given their thoughts on cpp verbosity. Also, if you ever get a 2FA sms, especially in Europe, there’s a very high likelyhood your lib was used at some point :)
lots of people care about being fast. it's the whole point of the language
No need to be so rude. And I don't use Java (surprise!)
(◔_◔) No it's the whole point of other languages maybe, but C++ adds more abstractions and it's rarely ever a blanket "faster than all other libs". https://chadaustin.me/2017/05/writing-a-really-really-fast-json-parser/ mentions in the first fold that it's fast https://github.com/chadaustin/sajson (not an endorsement) CPP is not the fastest language. Maybe from your perspective it is the fastest you know, and that's fine to hold as a personal view, but you need to know that weird unreadable garbage aside (because that's not meant for CPP); there are many other languages and technologies that have raw-speed advantages over CPP. Where those other languages fall down is in allowing simple expression of higher-order components and complex integrated systems (which it turns out CPP is only a certain way towards for some problem spaces). There is no one-size fits all language and speed is a specific focus for a library that only apex projects need. You want the most speed you certainly don't go for JSON or any text-expressed envelope. This is not a debate. Don't mistake it for one.
What are you on about?
XML MASTER RACE!
Depending on how you use a library, speed does matter. And it is not necessarily a contradiction with a modern API. We use our library for the logging system in our company, each log-message is a JSON value and is then either written to a log-file or send to an ELK-Stack. Or both. Efficiency is what allows us to get away with it. :)
And once you can't you'll have decisions to make. Perhaps you'll start by having machines log to intermediate forwarders so that you don't overload the machine. I doubt you'll change the implementation of JSON parsing you use, but hey as long as I don't have to pay for it.
So you're fine requiring all generic functions that use `copy` to be specialized for arrays vs. other containers just to ensure the function is actually doing what it says it does? It's completely unintuitive to me to have the same function do completely different things for two models of the same concept.
You are missing the point. Of course we scale horizontally if needed, but the efficiency is important for the *latency*. If you have to reply within given constraints to a request, you have to be fast.
I love your project, I introduced it and used it extensively at a previous job. It seriously is well coded, documented, and you're even trying to standardize it! But emoji everywhere looks unprofessional; a commit message "fixed that 2 gb memleak :lol:" feels to me like getting an email that goes "no raises this year :lol:". It's like applying for a job with the email you created when you were 13: "please reply to milf_stud@gmail.com" Also, :emojis: don't render at all in console: tig, git tree. It bruises my eyes. Just my 2 :cents:. NB: The git tree recently looks like a highway... ouch. 
Could you tell me a language that is generally faster then C++ . (Excluding ASM) ?
That paper is still going through revisions and it's as yet unclear if `bit_cast` will be `constexpr` at all. And if it is, it seems very unlikely that it would support either unions or pointers - which is what you'd need in this case. 
You are right about all this, but it is my side project and I try to be professional in the code and everywhere, but just let me add a picture to every commit I do in my spare time :-)
YAML is the best of both worlds You get optional types, it looks cleaner and is easier to write, and it's JSON compatible (As in, any valid JSON is valid YAML, the reverse is not true, obviously).
&gt; So you're fine requiring all generic functions that use copy to be specialized for arrays vs. other containers just to ensure the function is actually doing what it says it does? It's completely unintuitive to me to have the same function do completely different things for two models of the same concept. Containers and arrays are not same thing. Arrays are memory of certain capacity, that can contain junk values if not initialized and have no notion of size. Containers are containers. :) Containers do not have junk values and know their size :) 
SQL?
There is not a single header-only YAML parser in modern C++ though... That unfortunately kills YAML for many projects.
Where is the `cpuid` backend? I only see a `/proc/cpuinfo` backend. 
Except I can't for the life of me remember the correct spelling. 😀
[`vector`'s range constructor is specified to perform no reallocations when the iterators are forward or better.](http://eel.is/c++draft/vector#cons-10) [`vector::insert` doesn't have a similar requirement](http://eel.is/c++draft/vector.modifiers), although I know at least the Microsoft implementation and libc++ guarantee at most one reallocation when the iterators are forward or better. I assume the optimization is common (and not specifying it was likely an oversight). The example I give above for the non-performant case is out-of-date: range-v3 currently passes Ranges-TS-conforming-but-not-quite-standard-conforming iterators to the range-accepting functions of standard library containers (constructors, `insert`, `assign`) and hopes they don't notice the difference. A hyper-paranoid concept-checking `vector` implementation will detect the non-conformance, but otherwise it's extremely likely to work out fine. 
`ranges::action::insert` seems redundant, but `std::insert` seems too non-specific of a name for a range action. `std::action::insert` would be just about right. My current inclination for standardizing components from range-v3 is that `ranges::foo` and `ranges::bar::baz` will become `std::foo` and `std::bar::baz`. 
I don't know that I agree with the assertion that "most containers have one insertion point". Sure, associative containers don't care about sequencing / handle it for you, but I don't think that most containers are associative containers - either in the Standard or in the larger C++ codesphere. Also, `push_back` is 3 more keys than `insert`; it's not exactly a huge cost.
&gt; it has to be a for-loop of some kind `std::string`s normally store their size, the implementation of `std::string::size()` is generally something like `{ return _M_string_length; }`. Perhaps you meant `strlen`. But it doesn't have to abide by the laws of the language. It may just be a compiler built-in, and Do The Right Thing&amp;trade; every time.
yeah, `size` was a bad example, I was thinking of the constructor that takes a `const char*`. &gt; It may just be a compiler built-in, For strlen, sure, it's certainly a builtin. But for your own code, you are left between writing code that will be fast using constexpr and potentially slow at runtime, or not constexpr and potentially fast at runtime. 
If a two byte size type requires a 300 LOC header and a byte size equivalent requires 30 KLOC maze of headers, all different, then the question of which one is better suddenly becomes not so clear-cut. Compilation times matter a lot, library simplicity and maintainability and freedom from bugs matter a lot. So perhaps we don't want a 30 KLOC `&lt;optional&gt;`. 3 KLOC? Probably yes. It's a compromise, like everything else.
&gt; And I highly doubt there would be any measurable difference in cases like optional&lt;bool&gt;. So, I agree that wasting one byte in your program, or in the stack frame of some function, it is not going to be measurable at all. But, if you have like a large `std::vector&lt;std::optional&lt;bool&gt;&gt;`, and you iterate through it, if it's twice as large, it's basically going to take twice as long because you get twice as many cache misses. If taking 2x memory wasn't ever an issue then a lot of things would be different: - `vector` would probably always use power of 2 capacity on all platforms -- on some platforms, stdlib mantainers decided to use a 1.5x scaling factor to cap the maximum wasted memory ratio. - `variant` would probably be strongly exception-safe. There is an "easy" implementation of `std::variant` which uses 2x memory and makes sure that when a type-changing assignment occurs, the new value is not clobbering the old value, so the old value an always be safely destroyed after the new value has been constructed (and did not throw). If 2x memory was no big deal then that's clearly the best implementation from the point of view of `constexpr` and strong exception safety. In C++17 the "Kona Compromise" shows that the committee cares more about 2x memory savings than they do about strong exception-safety, for better or worse.
That's because we don't have `is_constexpr` (yet). When and if it is added (back) to C++, you should be able to do is_constexpr(arg) ? slow_but_constexpr(arg) : fast_but_not_constexpr(arg);
xtensor may be the closest match: https://github.com/QuantStack/xtensor, https://xtensor.readthedocs.io/en/latest/ Some examples: - basic usage: https://xtensor.readthedocs.io/en/latest/basic_usage.html - reducers: https://xtensor.readthedocs.io/en/latest/operator.html#reducers - accumulators: https://xtensor.readthedocs.io/en/latest/operator.html#accumulators - filters: https://xtensor.readthedocs.io/en/latest/view.html#filter-views - broadcast: https://xtensor.readthedocs.io/en/latest/view.html#broadcasting-views
C, Fortran, Depends upon the compiler (obviously) and the problem you're trying to solve. What I'm saying is there is no blanket "faster" language for every case without getting weird (at which point you're often sacrificing the benefits of the language). It depends on the problem what tool you pick. Screw it for some text processing ActiveState is claiming their Python beats C++ for Regex using standard boost https://www.activestate.com/blog/2017/11/python-vs-c-text-processing As for ASM, again it depends on who's assembler you use, your own proficiency. You cannot in-fact do C++ higher order tasks in ASM because it's a low-level language. You can implement higher-order methods This isn't about forming autistic rules for or against tech, it's saying that there are a host of considerations
Unfortunately, it has not been updated in a while.
It seems like you want SQL. Either use some full SQL server or you can use SQLite that is written in C and well known.
Don't listen. Because of the JSON project I have started using emojis in my commit messages at work. 🙋🏻
This is off-topic, I'm afraid.
You're comparing apples to oranges. Or rather, specialization to templates. You can't compare design decisions relating to `optional&lt;bool&gt;` and those of `vector` or `variant` templates. You have to argue from the point of view of `vector&lt;bool&gt;` and `variant&lt;bool, ...&gt;` . And when you do, you start to realize how ridiculous it is to chase perfect optimization in all cases. What is the size of `variant&lt;bool&gt;`? Is anyone complaining about that? I am highly skeptical anyone would use large `vector&lt;optional&lt;bool&gt;&gt;` to the point where it actually matters. Until we see an actual use case for it in the wild, it's a waste of time to consider. There are plenty of other optimization opportunities.
I feel like you're missing the point. For a start you're logging to a text-format, so you'd immediately get a benefit logging to something less generic, where you could cut-out some of the overhead. Being more specific with what is logged could also lead to lower `latency`. Re-inventing JSON parsing isn't the only way to speed up your use-case, assuming it's even the use-case that's not part of the problem. I feel like you know that, but are just arguing for the sake of it. In any large enough system we could both be right. I'd be horrified to find JSON encoding of logs as a large hit to latency, but it's hard to imagine a system with no other areas to improve upon.
True. Maybe if we send Milo some pull requests for our libraries and ask nicely, he'll update it again? Sadly, it seems to be a manual process for him to update the results and not something that is generated automatically after a pull request is merged. :-/
Though then the cast to reference wouldn't work.
This looks like a nice project to contribute to, need any help?
I _think_ this is a similar question to https://www.reddit.com/r/cpp/comments/64hzmd/is_there_a_dataframe_library_in_clike_pandas_in/
This feels like letting the perfect be the enemy of the good. I mean, zero overhead is neat, but a simple vector API that doesn't do lazy splitting would still be fantastically useful to a lot of people, even if it isn't perfectly optimal in all use cases.
Well, in addition to the issues list (https://github.com/nlohmann/json/issues), there is so much to do: polishing documentation, testing with more compilers, supporting allocators... Or from a non-technical perspective: the project has neither a cool project website nor a logo. Any help is greatly appreciated!
I'm not even parsing JSON in my use-case, I'm generating JSON output from a log-line in the code that looks something like this: LOG( INFO, "unknown user", { p } ); where `p` might be some Radius packet which will be fully expanded into a JSON structure. The key is logging *structured* data. And the ELK-Stack expects a JSON-structure. I'm not going to write down all the details here, but I did a talk about it in the C++ User Group in Aachen, the slides are available [here](http://www.wilkening-online.de/programmieren/c++-user-treffen-aachen/2016_11_10/taocpp-json_DanielFrey.pdf). So no, I'm not just arguing for the sake of it. And the library developed further, the slides are a bit outdated.
A less-than-ideal API defined in the standard still has to be carried 'forever' (modulo deprecation and removal), even though we know up front that better is possible.
Would be great to see how a recent version holds up.
At this point, I've just started to accept that written English has suddenly become partly ideographic. The use in this json project at least seems to be pretty consistent. Documentation gets one glyph, bug fixes get another, etc.
No we're not most of the way there with a char bitset. In fact, that takes us a step back. Because now you've doomed the `value()` function to always have to do this: `return m_value &amp; 0x1`. For the most common case, of non-constepxr read, you've slowed it down. Since we're talking micro-optimizations here, maybe that's okay. But so is a two-byte bool in that case. But with a bitfield, at least now the compiler knows what we are trying to do. With two bit-members of type bool, a compiler has a better understanding of what it's used for and stands a better chance of optimization, if micro-optimizations are your concern.
`m_value &amp; 0x1` is slow? It's a single `and` instruction. Can't get much faster than 1 instruction. And it's constexpr, so the compiler knows exactly what you are trying to do and can optimize however it wants.
Interesting read. Looking at it I'm not sure how it applies to this as the lib mentioned didn't have the highest throughput or lowest latency, but thanks for linking.
Thank you so much. This library is a dream. `json::parse_error` will clean up my error handling code! I used to wrap JSON parsing, catching `std::logic_error` to throw my own parse error.
The main reasons for management would be "we have some other lib already" and general unwillingness to change. Not much to reason about or change. Thanks for your offer though!
Oops. I totally missed that.
We did not design for execution speed, and there was also a lot of discussion about the number roundtrip checks. But yes!
Yeah. `0` and `1` need to be `false` and `true` for valid `bool&amp;`. Using `-1` or `-128` for `nullopt` might be better than `2`.
Yes. It could be useful, yet the lazy algorithm would be as simple to use as the vector API, and would be zero overhead. Performance != hard to use. See my other comments, you'll see that the lazy algorithm is as easy to use. Also, when the range library will be in the standard, you'll only want ranges, and the vector API will become hard to use with the rest of your code using ranges. Hard and easy to use is subjective.
;) The data is not already in a sql database. Do any sql implementations work on arbitrary schemas? The actual schema is not determined until runtime.
To complement your chapter "Generating the duck", Zach Laine has done an application called "emtypen" that generates type erasure code: https://github.com/tzlaine/type_erasure 
GSL has some types for vectors and similar. It's popular AFAIK. I'm not sure what are its capabilities, I'm curious myself.
Right, on x86 you could save a byte by using test to check the high bit instead of cmp against a sentinel.
&gt; wait for either the next work item or a signal that I need to stop You can usually accomplish this with a single `condition_variable`, even with multiple workers. `notify_one()` after adding work, and `notify_all()` after requesting stop.
I missed that part, I guess you can switch the values around then. What matters is that you can use a free test and not require computing a subtraction.
Yeah, please tell me more. I can already say I won't be able to arrive at any committee meeting. Looking at your flair I can't think of many other people that would be so much inside as you.
What the duck?
Luckily you can create and populate tables at run time.
ROOT root.cern.ch
no it's not.. this is just an add leading straight to 'buy' page what a scum! if you want just buy an add from Google you cheap bastard
I worry the overhead of creating a table, writing the data into the table, doing the manipulation, and then reading the data out would be quite high. What do you think?
I said in the most common case: *non*-constexpr read. It's not one instruction. It's one *extra* instruction. One *extra* instruction *every* time you *read* *non*-constexpr. Unless you want to argue that the most common case for `optional&lt;bool&gt;` is constexpr read, I don't see how you can argue against it. You're slowing down the *non*-constexpr case for the rare constexpr case. And like I said, if you're not worried about one extra instruction, then you shouldn't be worried about one extra byte.
Reading the value (with `optional&lt;bool&gt;::operator*`) is 0 instructions. You only need to check a specific bit in `value()` to check if the optional contains a value or not.
&gt; if you're not worried about one extra instruction, then you shouldn't be worried about one extra byte. Not true, an extra byte is usually much worse than an extra instruction. Your CPU will waste hundreds of cycles waiting for new cache lines.
And how do you check the specific bit, other than `m_value &amp; 0x1`? Which is one extra instruction...
Only if you have, as another commenter argued, large arrays of `optional&lt;bool&gt;`. I'm skeptical that will ever come up, so no. It's a highly theoretical concern that is a waste of time.
What are you on about? Nico is one of the most respected names in the C++ community. His books **C++ Templates: The Complete Guide** and **The C++ standard library** have for a long time been primary sources for understanding aspects of C++ for me. The book in the link may not be complete *now*, but it is getting there and given his track record I highly doubt it wont be as advertised. 
The takeaway from that article seems to be that somebody who's more fluent in python than C++ writes better python than C++.
Use -1 for invalid, and check the sign (single instruction) instead of checking for zero (single instruction). In [this test](https://godbolt.org/g/75DJmW), the assembly for one-char is one instruction shorter than for two-bools.
My bullshit, spam and shady sensors are of the charts.
I have approved this post as non-spam for the following reasons: * The submitter isn't Josuttis (to my knowledge) and the link is an official, non-affiliate link * Josuttis (who I have met personally at Committee meetings) is indeed respected, and I am confident that this book contains original content instead of copy-pasted garbage * Resources about the leading edge of C++ are of interest to the community (if this were about C++98 or C++11, I would consider it far less relevant, as we generally assume subreddit members are at least intermediate level) Thank you to those who reported this link as spam; we must be vigilant against spam, and I believe that "buy this thing for money" links should be subject to a higher bar than usual.
Yep. Removed.
Yea. I was going to suggest pandas... Maybe ROOT is the only thing in C++ that's somewhat similar. Really something the (modern) C++ domain is lacking!
It definitely will come up. C++ is a widely used language. It is applicable in more situations than a large array of `optional&lt;bool&gt;`: struct Foo { double a; int32_t b; int16_t c; int8_t d; optional&lt;bool&gt; e; }; With `sizeof(optional&lt;bool&gt;)` 1 or 2, `sizeof(Foo)` will be 16 or 24 respectively. That's the difference between 4 `Foo`s fitting in a cacheline, or only 2.
Hey this is really cool! You can choose how much to pay! That's an awesome idea. And looks like it could be a great book. (Note: It says the book is 70% complete so it's not really a "Complete Guide" yet :P)
Question: this looks similar to Dropbox's json11...what would be the main differences?
Even in this example, the better solution would be to choose a better layout if that really matters.
I tried your test to use bitfields for the two bools. Try it out with the different compilers. Different compilers give different results. Different architectures give different results. Which is why these micro-optimizations are of dubious value.
This kind of attitude does not really belong here. 
SQLite can do in-memory database.
Absolutely adore this project. I saw in the release notes that CMake and CTest are now used. Any chance that a Config.cmake file will be included in the packages for this project? It would be awesome not to have to have a custom Find*.cmake file.
The signal-to-noise ratio around here would improve immensely if you stopped attempting to "discuss" anything here.
You could use `= default` for all the copy and move operators and destructor. What is the type T supposed to be? The result of the work?
C++, where even the books can be declared before being defined.
I PMed you.
Instead of defaulting the copy/move ops and dtor, just don't mention them. The rule of the Big Five doesn't demand that you always mention them - just that you mention all or none.
I agree that it is better to write nothing at all.
alright, I updated the code. For some reason I was under the impression that you had to define them if you define any of the constructors but I guess that was wrong :) Do you have an opinion on whether or not such an approach is reasonable or better done in another way?
SML? As in, [Standard ML](https://en.m.wikipedia.org/wiki/Standard_ML)? Or am I misunderstanding you?
I tried to understand how, but I don't see how the waiting side (in the worker thread) is written? I want (pseudocode) switch (wait(stop_condition, work_condition)) { case STOP: return case WORK: do_work() } Help? What am I missing?
One option, if you have a mutex `mut`, thread-safe queue `taskQueue`, condition variable `condition`, and bool `running`: Task task unique_lock lock { mut } while(running) lock.unlock() while(taskQueue.try_dequeue(task)) process(task) lock.lock() if(running) condition.wait(lock)
https://stackoverflow.com/questions/38835747/type-erasing-type-erasure-any-questions -- replace boilerplate with something like: auto do_quack = any_method&lt;void()&gt;([](auto&amp;&amp;duck){ quack(duck); }); auto do_walk = any_method&lt;void()&gt;([](auto&amp;&amp;duck){ walk(duck); }); using duck_t=super_any&lt;&amp;do_quack, &amp;do_walk&gt;; then duck_t duck; (duck-&gt;*do_quack)(); quacks the contents of `duck`. Augmenting this to handle views, variants, move-only, SBO, fixed buffer, etc is all relatively simple. 
I used few weeks back and was surprised to see `std::pair` and `std::tuple` was not supported out of the box. Good to see it is supported in this release. Keep the good work!
Other adults who use Reddit Enhancement Suite may wish to take advantage of the Ignore User feature. For example to ignore a user that thinks it is acceptable to call someone 'scum' and 'cheap bastard' simply for posting a link to a respected author's relevant book. 
Disagree. Labeling them default tells future maintainers that you considered these and knew they should be default. Not mentioning them is ambiguous.
Check out Dyno by Luis Idionne https://github.com/ldionne/dyno/blob/master/README.md Is still experimental but he gave a talk in cppcon 2017 and looked very promising. 
Well, I know *that*, obviously, but I kinda don't want it because it's more complicated than necessary[1] and still polling (on the `running`). [1] there's other platforms where simpler things are possible 😀. 
And this (you and your parent) is why there should be a style guide. Either option is *fine* and either works well when everybody adheres to it, not when they do not adhere 😀.
Yeah, the standard tends to target the lowest-common-denominator. You might be able to use `native_handle()` on Windows. Can POSIX wait on multiple condition variables? I thought `select()` is only for async file I/O. `pthread_cond_wait()` only accepts one condition.
You are right, `select` needs a "fake" IO for the "stop" signal. Windows does this (waiting for different kinds of "waitables") the best. Then again, it's the most recent API design.
You still need to do some calculation (subtraction, cmp, and, test, whatever) to set the flags (zf, sf, cf), just loading the value into a register isn't enough
Could you please open an issue (https://github.com/nlohmann/json/issues) and describe this in detail?
Thanks for approving this. I hadn't been aware of this new book in progress before this post. But I do have a copy of Nicolai's templates book on my shelf at work and he's earned my trust as an author on C++. I understand the need for vigilance but at least for me, this is something of both relevance and interest.
I have not used json11 myself, but just by looking at the README gives me the impression that json11 needs hints like `object(...)` or `array(...)`. I'm also not sure if they support JSON Pointer, JSON Patch, CBOR, or MessagePack.
 auto&amp; vp (variable_pool::instance); Is this a reference initialization? 1st time seeing done it this way
Undefined reference to that 'statement'
lol , just lol
I don't mean to hijack discussion about Nicolai's book, but has anyone read the new "cookbooks" from [Arthur O'Dwyer](https://www.amazon.com/Mastering-17-STL-standard-components/dp/178712682X/ref=sr_1_4?s=books&amp;ie=UTF8&amp;qid=1513581155&amp;sr=1-4&amp;keywords=c%2B%2B17), [Marius Bancila](https://www.amazon.com/Modern-Programming-Cookbook-multithreading-networking/dp/1786465183/ref=sr_1_1_sspa?s=books&amp;ie=UTF8&amp;qid=1513581155&amp;sr=1-1-spons&amp;keywords=c%2B%2B17&amp;psc=1), or [Jacek Galowicz](https://www.amazon.com/STL-Cookbook-enhancements-programming-expressions/dp/178712049X/ref=sr_1_2_sspa?s=books&amp;ie=UTF8&amp;qid=1513581155&amp;sr=1-2-spons&amp;keywords=c%2B%2B17&amp;psc=1)? I've not read them, and I only recognize Arthur in the list.
When can we expect *the* STL book? :)
I've read and reviewed two of them: Those are really good and solid books about the newest standard. http://www.bfilipek.com/2017/08/cpp17stl-review.html and http://www.bfilipek.com/2017/06/modern-c-programming-cookbook-review.html 
nope, google boost sml, but not it is not in boost.
&gt; The signal-to-noise ratio around here would improve immensely if you stopped attempting to "discuss" anything here. Actually what I wrote is based on science. It is scientifically understood that people are not rational about things close to them. trivia: even Bjarne said he was wrong being pissed about Concepts not making it in C++0x because "he was too close to it".
Probably not any time soon - working on the STL leaves me with little free time these days.
I see the discussion has gone offtopic, but here is something ontopic: What you seem to be looking for is something like std::expected&lt;std::optional&lt;CsvLine&gt;, some_error&gt; https://github.com/viboes/std-make/blob/master/doc/proposal/expected/p0323r3.pdf Where optional is unset after you processed the entire file.
I had considered that approach, but the library I was using was actually setting the values via the parameter list so it wasn't convenient to take that approach. plus the syntax is still a bit awkward and unwieldy. However, I've since decided to roll my own CSV parser as I was finding problems that I didn't feel like working around with the other library so I'll probaby end up going with something closer to this. I do have a question though, is there an implementation of std::expected anywhere? I tried to track one down and couldn't seem to find anything. I'm hoping my googlefu is just bad.
I had considered that approach, but the library I was using was actually setting the values via the parameter list so it wasn't convenient to take that approach. plus the syntax is still a bit awkward and unwieldy. However, I've since decided to roll my own CSV parser as I was finding problems that I didn't feel like working around with the other library so I'll probaby end up going with something closer to this. I do have a question though, is there an implementation of std::expected anywhere? I tried to track one down and couldn't seem to find anything. I'm hoping my googlefu is just bad.
True but if it's a returned value the registers set the flags accordingly right? Unary instructions are also cheaper to encode and decode.
**Company:** [www.zividlabs.com](http://www.zividlabs.com) -- 3D computer vision, startup, well founded **Type:** Full time **Description:** Zivid creates a 3D video camera for use with robots in industrial automation. We are looking for generalist C++ developers, C++ QA developers, and C++ machine vision and robotics developers, or any combinations of those skill sets. The detailed job listings can be viewed at [www.zividlabs.com/jobs](http://www.zividlabs.com/jobs). As a developer, you will mainly work with C++, everything from hardware programming and library development to UI programming. You are also expected to tackle most other aspects of software engineering: scripting, testing, automation, packaging, cloud services, docker, CI, bindings for other languages, documentation and working with multiple platforms like Linux and Windows. Or in other words, we are looking for all-round developers and quick learners with strong C++ skills. **Location:** Oslo, Norway **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++17 (whatever passes VS2017, latest Clang, GCC, clang-tidy, ...). C++/CLI, GPGPU, Python, Bitbucket pipelines/Appveyor/Jenkins, libclang, boost, Qt, CMake. **Contact:** [e-mail](mailto://jobs@zividlabs.com)
I think `boost::outcome` is what you are looking for!
Accessing an empty `std::optional` through `operator*` does NOT throw an exception! It's UB. Using `.value()` does throw, though, but I rarely see people use that. This is IMO a huge design flaw.
Has somebody already read it (the part that's there)? And would that someone be willing to maybe write a short review? Thanks :-)
aha, so I wasn't off my rocker with the idea, I just didn't have a well thought out api for it. That's good to know :) I'll take a closer look at that, thanks for mentioning it.
No, only arithmetic. You're right that checking the sign bit is cheaper to encode though, so you could use a negative number for the sentinel.
&gt; "unless maybe we use macros heavily, but who would want that? :)" I wrote such a tool, works surprisingly well, but I will admit that it was horrible to write and I doubt anyone would enjoy reading it. Here is an example of a hierarchical scene graph item. TYPE_ERASE((PropTE)(), ((CONST_TE)(void))(gatherInfo)((InformationTree&amp;) info), ((CONST_RETURN_TE)(FrameState))(getChildFrameState)((const FrameState&amp;) parentFrameState, (int) child), ((CONST_RETURN_TE)(const Identifier&amp;))(getIdentifier)(), ((CONST_RETURN_TE)(const Transformation&amp;))(getTransformation)(), ((CONST_RETURN_TE)(const std::vector&lt;PropTE&gt;&amp;))(getChildren)(), ((CONST_RETURN_TE)(const CameraSettings&amp;))(getCameraSettings)(), // Mutators (()(void))(render)((const FrameState&amp;) frame), (()(void))(hide)((bool) hide), ((RETURN_TE)(PropTE&amp;))(add)((PropTE&amp;&amp;) child), ((RETURN_TE)(Transformation&amp;))(getTransformationMut)(), (()(void))(erase)((const Identifier&amp;) id), (()(void))(clearChildren)(), (()(void))(addReaction)((const std::shared_ptr&lt;ReactionDestinationTE&gt; &amp;) destination) )
That'd be polling the stop signal, though, unless you never need to do work again after clearing the queue (and in that situation you'd just let the thread exit)
Wouldn't you just join() all the child threads and have them respond to the stop signal?
You monster.
https://github.com/WebKit/webkit/blob/master/Source/WTF/wtf/Expected.h
&gt; Or, in other words, do we really need that 'action::' there? - 1. Actions are eager, views are lazy. There is a huge difference between `action::sort` and `view::sorted` (which isn't implemented yet). So yes, differentiating eager algorithms from lazy ones is important. - 2. `action::` is a namespace, you can just import it, import it with a different name, ... but because of point 1., that's probably not something you want to do.
&gt; Like article mentions most containers have one insertion point No they don't. You provide the following quiz: &gt; insert, push, push_front, push_back: Which STL container has not 1 but 2 of the above listed member functions? And you say the answer is `deque` as if there is only one, but `deque` actually has three, vector has two, list has three... 
&gt; Labeling them default tells future maintainers that you considered these and knew they should be default. I disagree with this: when you define a class you should always look into at least these considerations: - copiability/movability - how it's going to be used (a base class requires different considerations than a final class) - how it should not be used (what should be hard or impossible to accomplish with it) - API effects, side effects, pre-conditions, post-conditions, invariants Relying on _constructors being specified_ sounds like a flimsy criteria to decide if these considerations have been taken into account, especially when you may consider the constructors and _decide it's better to rely on defaults_.
In the context of copying into container without specification of insertion point they do. If you want to copy in the middle or begin of the container then you would not write copy(src, dest), but something more complicated like copy(src, prepend(dest)) copy(src, append(dest)) copy(src, inserter(dest, dest.begin()). Like seen in other comments people do not agree with me what the natural meaning of copy(a,b) is but that is just that. No way to prove they are wrong or that I am wrong. 
I've been following this closely for a while. I must say that this is really promising. There's already some demos like this one: https://msorvig.github.io/qt-webassembly-examples/widgets_wiggly/widgets_wiggly.html That look very impressive. I'm already thinking that in the future it could allow us to create windows / mac / linux and web Qt programs very easily sharing a large portion of the code. I would trade any day a Qt app for a backoffice than a website in angular or other js framerwork. I'm not sure if this is being worked on by Qt company itself or just by freelancers but I guess that maybe the company should allocate some employers to work full time on this port. What do you guys generally think about this Qt port?
It's my first contact with gitmojis, and I love the idea, it's just that they are...ugly. Neither clear, nor pretty. Fire, what am I supposed to know what happy, colorful "fire" means? Critical bug, or hot, new feature? What do "stars" mean?
&gt; Keep it up, and maybe be more humble next time: if things aren't they way you wished them to be, consider that a lot of people have given the problem a lot of thought, and that there might be something that you are missing. No need for me to be humble. Article is correct (beside missing std::list) in a sense that I think that copy(a,b) should behave in a certain way. Like mentioned before you it is just the way I think ranges should work, not a claim about alg complexity of insert. So I do not care if 100% or 10% 0r 0% of people agree with me. For me push_back is just noise.
&gt; I don't know that I agree with the assertion that "most containers have one insertion point". tl;dr is that in my code I have never(IIRC) have written vec.insert(vec.begin()). So if you and me are talking about code and you tell me ok, just copy the data to vec I would think of vec.push/emlace_back(). Similarly for set. I would assume copy means do inserts, not clear and then inserts. So this is based on my usage patterns of STL, you and others may disagree. &gt;&gt;Also, push_back is 3 more keys than insert; it's not exactly a huge cost. Again it is more about What Code instead of How Code. Although here unfortunately insert could mean what(insert into dest) and member function(call .insert()).
Ah, the union-forbidding code was added in r2 (that is, `bit_cast` on a union is non-`constexpr`). That's annoying.
&gt; For me push_back is just noise. Copying does not require allocating any memory, `inserting` does (where it's `push_back`,`back_inserter`, `inserter`, ...). This is an irrelevant distinction to a lot of people, but it is a very relevant distinction in the STL design and very relevant for a lot of C++ programmers that think that allocating memory behind the scenes should not happen silently. That is why copying from one array to the other just works, why copying from one vector to another fails to compile. So yeah,
I have literally like last week discussed the insert and allocation with STL materialized. So I know that containers allocate. I just do not think it is serious enough to show in the user code. Like I said in the article action::push_back is nice for learning ranges... "aha, let's see this example, ah it has action::push_back, ah ok I get it it will use push_back to insert into destination, ok I get it" ... but ranges is not some fringe library that is rarely used so it should be short and push_back is just noise. Same as {ptr,ip,is_tcp} variable names are acceptable while per for person is not. Because ptr ip and tcp are widely known to mean pointer, ...
&gt; So I know that containers allocate. I just do not think it is serious enough to show in the user code. But this is wrong. Containers don't allocate: std::vector src = {1,2,3}; std::vector dest = {3, 4, 5}; ranges::copy(src, begin(dest)); // does not allocate
&gt; which is why the STL takes the distinction seriously (and why memory allocations are explicit) FYI: inplace_merge allocates. Unless you consider that explicit since in the documentation it says it allocates. 
No, `inplace_merge` _tries_ to allocate, but it also works if it can't allocate. Also if you want a good example of an algorithm that tries to allocate, `stable_sort` is probably the most used one.
&gt; ranges::copy(src, begin(dest)); // does not allocate Yes, you can use vector as an array. I would not recommend that(this code is "unsafe" style C++ code). Before you call me an idiot I know this code works fine, I am saying that you are manually controlling dest size and that is "dangerous". For the rest of your comments it just basically you say that the Holy Spirit of C++ is something and that I am heretic, and I say that I know the True Holy Spirit of C++ and that you are heretic. One new point I just thought of now: ranges TS/STL already has some defaults: input range even when bidi iterators is traversed from first to last. Why not make it explicit? Because 99% of iteration in production code is first to last. Now my question is not about allocation or no allocation. My question is how much of production code does v.insert(v.begin()...); // note that v.insert(v.end())... is push_back In *my* experience I have almost never seen this. If you care about your data being ordered you are not using a vector.
Oh I did not realize that. I pretty much always use `.value` since `-&gt;` is useless with primitive types and `*` is usually awkward in longer expressions. I would have preferred it to always check, and have an explicit `unchecked_value()` or something similar for those rare cases where it is needed.
&gt; I would not recommend that(this code is "unsafe" style C++ code). All C++ code is `unsafe`. Some code is more safer than other, but there is no such thing as `safe` C++ (and assuming there is is a recipe for disaster). &gt; Yes, you can use vector as an array. A vector is an array, a dynamically-resizable one, but still an array. Sometimes I want to copy from one vector to another, sometimes I want to append at the back, the front, or somewhere else, but saying that the idiomatic way to copy from one vector to another is to append at the end reallocating when needed is a very long shot, in particular because `ranges::copy` is a wrapper over `std::memcpy`, and that's just not what `memcpy` does. 
For me it was a surprise to find out how slow the unordered containers are compared to other things in the stdlib. For example below are two implementations of duplicate removal when we don't care about the order of the output. The first function has O(n) complexity and the second one is O(n log n), but for any inputs fitting in typical RAM the latter one is many times faster (provided that comparison is fast). template&lt;class T&gt; vector&lt;T&gt; remove_dups_set(const vector&lt;T&gt;&amp; v) { unordered_set&lt;T&gt; s(v.begin(), v.end()); return {s.begin(), s.end()}; } template&lt;class T&gt; vector&lt;T&gt; remove_dups_sort(vector&lt;T&gt; v) { sort(v.begin(), v.end()); v.erase(unique(v.begin(), v.end()), v.end()); return v; } 
That sucks you've found it clunky, the recent version or two have been good to me. On a side note, it uses ninja directly to build your code instead of NMake (which the cmake integration used before) and was very painful. 
Yeah, it's baffling to me that they chose the shortest and least visible name for the most dangerous operation. I personally have `.unwrap()` for checked unwrapping, and `.unwrap_unchecked()` for unchecked unwrapping.
Cheaper in space can be cheaper in time because of the reduction in instruction size, resulting in less cache misses. The instruction might take more time to decode but I haven't followed the recent instruction decoder improvements. Also, while apparently `ret` doesn't set the flags, if your function is inlined, the return instruction can be replaced by a set flag instruction. I think compilers would be able to do this optimization.
More "STL the movie" then. Those video series from a few years back got me started! 
Doesn't using Qt create binaries with dozens of megabytes of overhead? Does this create fat web pages that just end up running fast?
&gt; For me it was a surprise to find out how slow the unordered containers are compared to other things in the stdlib I think that unordered containers are usually better than map/set one but for your example they are quite bad. And to make things even more sad boost::container::flat_set does not have constructor taking ordered_range_t, just the one with ordered_unique_range_t.
std::map is faster than std::unordered_map for n small enough -- same goes for other unordered containers, because the lower complexity comes at the cost of larger constant factors
&gt; but saying that the idiomatic way to copy from one vector to another is to append at the end reallocating when needed is a very long shot I agree that you may think that. And you may actually often use vector in a way I do not. &gt;&gt; So IMO, this code is just as dangerous as any other line of code in every C++ program out there. I do not agree with this. vector like unique_ptr if used in certain way is safer than if used in some other way. For example keeping vector iterators for a long time risks their invalidation, copy to v.data() risks buffer overrun, using .release on unique_ptr is risky... But it all depends on what you consider acceptable risk.
I spoke too soon, looks like you have these lines in there include(CMakePackageConfigHelpers) write_basic_package_version_file( ${NLOHMANN_JSON_CMAKE_VERSION_CONFIG_FILE} COMPATIBILITY SameMajorVersion ) configure_package_config_file( ${NLOHMANN_JSON_CMAKE_CONFIG_TEMPLATE} ${NLOHMANN_JSON_CMAKE_PROJECT_CONFIG_FILE} INSTALL_DESTINATION ${NLOHMANN_JSON_CONFIG_INSTALL_DIR} ) install( DIRECTORY ${NLOHMANN_JSON_SOURCE_DIR} DESTINATION ${NLOHMANN_JSON_HEADER_INSTALL_DIR} ) install( FILES ${NLOHMANN_JSON_CMAKE_PROJECT_CONFIG_FILE} ${NLOHMANN_JSON_CMAKE_VERSION_CONFIG_FILE} DESTINATION ${NLOHMANN_JSON_CONFIG_INSTALL_DIR} ) which is what I was looking for. Thanks again for the great project!
Well I for one want to see the std::is_permutation_alloc :) 
I agree but unsorted array is faster for 5 elements... I am talking in general when you do not know the range of your container sizes precisely. So in general std::unordered_bla is much faster than std::bla
Step 1: [Don't](https://geometrian.com/programming/tutorials/write-games-not-engines/) &amp;nbsp; &amp;nbsp; Some further reading: - [Your 1st, 2nd, 3rd, and Nth Game Engines](https://www.youtube.com/watch?v=GK7ntA7a2vk) - [Write Games, Not Engines](http://scientificninja.com/blog/write-games-not-engines)
BTW although I do not reccoment people to use boost flat_set often this my be the proper use case(I know the sort and erase should be faster but flat_set code looks nicer). Code is [here](http://coliru.stacked-crooked.com/a/420f0b8b9cbba683). Could be buggy, I am in a rush. Also coliru timing ratios differ from my machine a lot. 
The difference between exceptions and asserts is that you **don't have to** crash when an exception is thrown. There are cases where you can recover and happily chug along. I coulnd't open that file? Meh, that's fine, I'll just give myself default values. Does it happen often? No. Usually a catch is "log the thing and move on", or at best " log the thing and throw". But that's a programmer problem not a tool problem.
We've had some pretty iffy experiences with Boost.Serialistion and its error handling capabilities. Sometimes an exception would be thrown, others a crash, when trying to deserialise a message that had a break in it. It made rolling out code changes very painful.
Yes, for something like this, something like capn proto is much more preferable.
Sorry if I'm kind of late to the party. I was wondering why you chose to create a new language instead of just having your build files be pure Python? It seems to me that this would be much more flexible.
The New York Times website is 7 MB for me today, and [https://www.nytimes.com/](it's a god damn newspaper). If I have to wait an extra 2 seconds to load another 10 MB to get a full application, it's a good tradeoff! (Plus how many JS web apps put up those obnoxious full page spinners while they're loading?)
Also: Qt has this "Qt Lite" project where they've made it easy to drastically lower the compiled size of the library. See: http://blog.qt.io/blog/2017/05/31/qt-lite-qt-5-9-lts/ http://blog.qt.io/blog/2016/08/18/introducing-the-qt-lite-project-qt-for-any-platform-any-thing-any-size/
I agree with you in the sense that I'm primarily making a game, and the engine emerges as a side effect. I think this jives with my suggestion to take an iterative approach. I'm a bit loathe to call it an engine as it's more of a suite of libraries, but an "engine" is more interesting to talk about.
The 15.5 release is much better. For the most part it works. I've had ninja throw 'path too long errors' due to the nature of how it works, but that's ninja. Don't get me wrong. I love visual studio and am thankful for CMake integration. It's relatively new and am sure will get better. 
Thanks! This is helpful to me! I actually needed a MOCK_METHOD12. It brought up a discussion of whether tests should affect how the code is written (assuming non-TDD). Anyhoo I did some of what you were doing and then found myself still needing to write MatcherTuple with 11 arguments and with 12 arguments (plus more). I'll just take yours!
Thank you for the support! 
How does CBOR and MessagePack parsing compare to parsing JSON? Should be much faster right?
Ha - the guy in the YouTube video you linked even referenced the same Joel Spolsky article as I did 😂
Yea, I'd love to see more movies from you STL on channel9 - even if it was just like one every few months! :-)
&gt; I do not agree with this. vector like unique_ptr if used in certain way is safer than if used in some other way. &gt; &gt; For example keeping vector iterators for a long time risks their invalidation, This isn't what I meant. What i meant is that `ranges::copy(src, begin(dst))` is not more dangerous that calling `.front()` on an empty vector, calling `.data()` and dereferencing the result, calling `vec[idx]` with an `idx` out-of-bounds, ... There are pre-conditions on whether you can do any of these things, and violating any of these preconditions introduces undefined behavior. So my point was that there is no usable subset of C++ without preconditions, and the pre-conditions that one must uphold for `ranges::copy(src, begin(dst))` are not any more complicated than those required to properly use most of the `std::vector` functionality. 
The MessagePack support has been awesome! We are passing large JSON objects around using shared pointers and streaming a fairly large amount of data out to a websocket using MessagePack - it's been awesome! It worked right out of the box with a javascript MessagePack implementation too. Thank you for your work!
The algorithms won't be renamed, but they will probably get a new overload taking a state argument (e.g. a temporary buffer).
Cereal is a great library for serialization, I've been impressed. 
But it's fun.
If we're being semantic, wouldn't you just call it a to say framework? Maybe a rule set.
Very silly article, for two reasons: 1. If you are a beginner with little experience, you should not really focus on making a "game engine", because it is a more or less generic piece of software and you are not aware of all use cases you might want to cover at that point. 2. If you have enough experience to know what you would want from a game engine, chances are that you don't need a "how to" article to tell you what to do.
Somebody has to do it.
Just assume libraries are sane (Warnings show up during compilation and not just during usage) Then I would suggest to start with two options 1) Suppress warnings from ALL vcpkg libraries for library users. (e.g handle the vcpkg include directory during 'integrate' command) Because at the time building a vcpkg library you either accept existing warnings (and don’t want to have them shown downstream again) or you need to fix them right away 2) During vcpkg library build. Only show warnings from the current library in compilation. (Same rule as with point 1. Warnings in dependent libraries already have been accepted) 
You're repeating advice that is more appropriate for game ~designers~ (/r/gamedev crowd), as the people that want to specialize in that are the ones that are disadvantaged by creating engines. This is not appropriate advice for people that are studying engines, low-level apis, the graphics pipeline, etc. Also - there's a perception that an engine is a full blown SDK Unity competitor that has unlimited features for every game type. Engines can be small and single purpose, and they can also bring in libs where necessary. Also, when your game ends up requiring special functionality not possibly in Unity - good luck trying to understand and implement it when you've avoided practicing the fundamentals your whole career because you only thought you needed to know EZGameMaker5000.