Isn't that just overloading though? Chrono uses numeric literals whereas string uses string literals. I did a quick test and I could use both `s` literals in the same scope.
What if the compiler didn't have a choice in this case and had to always do in-place construction?
**Company:** [MXX Music](https://www.mxxmusic.com) **Type:** Full time, setting up interviews now to take place from August 7th (due to holidays). **Description:** MXX Music develops smart music editing technology. We are currently developing our Audition Pro desktop application, which allows a recorded stereo music track to be automatically re-edited to fit the narrative of a video. We are looking for a mid-level or senior Qt/QML C++ person to help bring our prototype to market. **Location:** London, Knightsbridge. **Remote:** We prefer on-site, but if you feel your skills are a good fit, and you’re very interested, then please do contact us. **Visa Sponsorship:** No **Technologies:** Code base is new, so mostly modern C++14. Qt/QML, Mac/Windows/Linux, Boost, FFMPEG. Experience with backend technologies and Google Cloud would be a plus. **Contact:** [join@mxxmusic.com](mailto:join@mxxmusic.com). When we last posted a job advert here, somebody rightly mentioned that we had been unresponsive. We apologise to those that applied, but we did not get back to. I (CTO) have personally taken charge of the application process, and this will not happen again. 
Honestly, the choice of "abc"s for creating an std::string is horrid - that's a "literal" that contains dynamic allocation for what should be a constant!
Having literals like that is good for the always-auto people. For constant data, you can use `"abc"sv`.
Honestly, I'd rather have an explicit cast for anything that allocates: auto mystring = std::string("abc"); Thankfully I'm not forced to use the ""s literal suffix so I can do this :)
As a side problem, is there a standard way to convert a tuple to a struct without have to create a dedicated (generic) function?
How can I add this to my code?
(the cpp reference is more concise and accurate imho)[https://en.cppreference.com/w/cpp/utility/move]
Should point out that contracts aren't just about security. They are useful for performance, and help prevent you making mistakes that slow down development.
Isn't that a risk for literally every user-defined type? Does chrono dynamically allocate? I'd wager not, but do we really know? Does the std::string dynamically allocate? Maybe, maybe not. In this case, quite possibly not, thanks to small string optimization. Personally, I like the literal syntax simply because it lets me avoid tedious repetitious boilerplate. And regardless if I write it out the long way or the short way, I still have no guarantee whether a type will dynamically allocate or not.
It's a shame that the equivalent lifetime checker for libtooling/clang-tidy remains stuck in the LLVM review queue. https://reviews.llvm.org/D15032. If somebody keen is reading this, finishing that into clang-tidy 7 would be a definite thumbs up from a lot of us.
How does it fare against the clang-tidy review mentioned by /u/14ned? 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8zm4mu/help_cant_include_header_files/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It would be a lot to ask for him to check out D15032 and rebase it onto trunk LLVM. I mean, if he did that, basically D15032 is ready for merge into LLVM i.e. the work to finish it is done. Don't get me wrong, that would be great, but it's a big ask.
How would that work? Under the current rules this is impossible.
OP has invested so much into this, having an open source checker should keep him up at nights! :)
It's allowed to not allocate at all.
In C++17 it's _guaranteed_; read up on the prvalue changes regarding object materialization.
Not so sure about that. Bjarne has stated that C++ came to be due to his experience having to port Simula to BCPL, which he didn't want to repeat. C++ came to be, because after that decision he joined AT&amp;T and truthful to it, started designing the pre-processor that would free him to deal with plain C, while keeping it compatible with UNIX toolchain. So I would call that more an historical accident, which by the way modern C++ keeps trying to fix.
&gt;Does chrono dynamically allocate? I'd wager not, but do we really know? A lot of the chrono stuff is `constexpr`, so it definitely can't dynamically allocate (for now anyway).
Great overview! My humble experience has taught me the following mantra: stay away from Autotools at all costs.
It's not so much that `T&amp;&amp;` *is* or *is not* a forwarding reference. It's just an rvalue reference. Forwarding references aren't really a thing *per se*, they're just an (intentional) artifact of the type deduction and reference collapse rules. So `T&amp;&amp;` can act as a forwarding reference in the context of CTAD but not in the context of a normal constructor call, because type deduction is happening in one place but not the other.
/u/berium is going to feel slighted...
I suppose he refers to the case where a company has a strict "don't use any code from outside" policy and someone doesn't comply and uses this under the pretense that it is under namespace std, and then the author gets sued because he put the code to disposition without a no warranty binding (and even those aren't recognized everywhere - in some european countried AFAIK you can't surrender some warranty rights). Also, great example of why tabs suck : https://github.com/cpp-io2d/P0267_RefImpl/blob/master/P0267_RefImpl/P0267_RefImpl/xgraphicsmathfloat.h
&gt; Guys, if you want to see C++ explode (again) in popularity, please, get Modules working with a well-thought out design I fail to see how modules will solve anything. Imagine that you have a magic `cpp_package_manager install graphics2D`. You run it in your source dir. At some point, some precompiled stuff is downloaded from an outside computer to yours. Does this precompiled stuff work with MSVC ? Clang ? GCC / MinGW with the old or the new C++ ABI ? Imagine that you want to use boost, as modules. cpp_package_manager install boost now, say, that you use boost.multiindex. How do modules handle you wanting to define BOOST_MULTIINDEX_DEBUG in debug mode and not in release mode ? How do modules handle debug (with #define NDEBUG), release, profile, -O1, -O2, -flto, etc ? 
Nö, they can't conflict (overload resolution) and they are imported into the same namespace anyway (std::literals)
I have been dealing with porting binutils and such. I now have a loathing hatred of autotools.
I don't think he cares.
C/C++ - how do you use RAII in C?
My mistake. You are correct.
Won't it make sense to fix ranges ? Or it's that too difficult cause of some design choices (if it's a design choice could you please elaborate ?)
You kind of just glossed over FASTBuild without acknowledging that it's a free alterbative to Incredibuild. It's fundamentally different from everything else in the list. Also instead of switching to CMake, try using [GENie](https://github com/bkaradzic/GENie). It's a fork of Premake4 with a more complete story for toolchains, and less aimless project management. Also debugging either Premake or GENie is easier, much easier than CMake. Jist add print statements, or attach a Lua debugger like ZeroBrane.
Forgive my ignorance if this is a silly idea, but would it be possible to specify optionally-supported attributes that could provide a hint to the compiler as to whether an embedded thing is read-only vs. writable?
 &gt; Ha! I know that my earlier hyperbolic comments may have made it seem that I think so, so I'm going to respectfully walk that back a tad. There are hundreds (thousands?) of talented, dedicated people who are all working on various bits of the language, the library, etc, and they all deserve a pat on the back (and our help when we can!). That being said, I think that a bit of prioritization is in order. Granted, we are seeing some of this already: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf Thank you! As someone interested in graphics, and perhaps some amount of further standardization on graphics-related concepts, this is appreciated. &gt; This is a fascinating read, but it touches a nerve when it gets to this paragraph: &gt; "C++ teaching is mostly stuck in a pre-graphics, pre-web world. This is a serious weakness, potentially fatal over the longer term." &gt; I think we would all agree with that... But where that sentence leads next is (IMHO) the problem that I stated earlier: &gt; "Teaching C++ to modern students will not be really effective until we can offer &gt;&gt; Simple standard graphics and simple use of browsers (or GUI). &gt;&gt; Simple mechanisms for packaging, distribution, and installation for libraries and programs" &gt; Oops. In my opinion, if you solve the SECOND one, you will get the FIRST one (easily). And much more. I tend to agree that a good packaging system would help many C++ developers, however, I don't buy that graphics is unimportant, or that, as many *seemed* to have put it (and I'm about to paraphrase here), 'Not now. Not ever'. &gt; The focus on adding graphics to the Standard is well-intentioned but dodges the larger issue, which is packaging. Heck, even in this paper they admit this: Maybe so, however I tend to be somewhat skeptical of any concerted effort to *only* focus on one, large, perhaps "hot button" issue at a time. &gt;&gt; "Students cannot be expected to download and install libraries on day #1." &gt; Yikes! But, how true. Can you imagine if that were true of Python or Rust? Then we perhaps never would have heard of those languages. One thing I miss, nowadays, when doing C++ development, is something like NodeJS' package manager (npm). It's been relatively easy for me to get something usable done with it, in good time. I'm not sure if this, exactly, is the right solution for C++, but it has been handy when doing JavaScript development. &gt; To further drive this point home (and likely beat it to death -- apologies), go to your console and type "pip search &lt;x&gt;", where &lt;x&gt; is almost anything you want (music, graphics, machine learning, networking, blah blah blah). The list that shows up will likely contain some amazing things! I'm more of a fan of [HomeBrew](https://brew.sh), and [npm](https://www.npmjs.com/) myself, but I'll take a look at pip. 😊 &gt; Now imagine that these are C++ Modules. &gt; Let that sink in. Already there! 😊 (I think, maybe?) &gt; This is why Modules are so important, and yes why I think that the C++ committee should pause on certain things in order to get Modules right; because doing so will likely ACCELERATE all of the other stuff that they are working on. I think even Bjarne himself is starting to see the Insanity of things: http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0977r0.pdf No doubt from my end, here. &gt; The people working on these items are certainly awesome and to be commended! But I wonder what would happen if we JUST got Modules working? I am suspicious of any concerted effort to get a major feature done in record time. Mind you, I don't want to see it languish either, but I don't want to see graphics, or any one of several things, languish, either. &gt; And as perhaps the most glaring example of why we need Modules (and should really not focus on adding this-or-that to the Standard Library), consider Python's own standard library (which DOES have graphics APIs in it): &gt; https://docs.python.org/3/library/ &gt; Check out items 25 and 26. Amazing; I'll bet that many people that use Python daily perhaps didn't know that it has Turtle graphics and Tk widgets as part of the standard library. But I'll bet that EVERY Pythonista out there knows how to install any graphics API they want (pip). I was unaware that these were in the standard distribution of Python. Thanks for the tip! &gt; Sorry to be so long-winded and thanks for reading! Thanks for replying in an (arguably) long-winded, and well thought out, IMHO, manner! 
This seems to me like an issue worth resolving, preferably in a way that is compatible with the wide and complex-seeming network of international law. I am not a lawyer myself, but I imagine that pull requests, especially from qualified, legal professionals, would, at least, be considered. (I hope so, at least!) 😉
You bring up a number of good points here. I'm not a huge fan of the point and matrix classes, as written, either. 😉 I am also a big fan of [https://libsdl.org](https://libsdl.org), and wrote an arguably-large-ish chunk of their UWP/WinRT code (which could use some improvement, FWIW!) One thing to note, the paper was developed, to my understanding (which may be wrong!), with the intention of having a basis for which to consider graphics as a larger whole. Thanks again for your feedback.
Great feedback, tcanens. Thanks!
Not that I know, but the function can be relatively simple: template&lt;typename T, typename Tuple, typename...Args, std::size_t... I&gt; T to_struct(Tuple arg, std::index_sequence&lt;I...&gt;) { return {std::get&lt;I&gt;(std::forward&lt;Tuple&gt;(arg))...}; } template&lt;typename T, typename...Args&gt; T to_struct(std::tuple&lt;Args...&gt; arg) { return to_struct&lt;T&gt;(std::move(arg), std::make_index_sequence&lt;sizeof...(Args)&gt;{}); } 
I seem to remember it being a design decision where range views are pure views, never owning, but I can't find a reference for it. Possibly it's in one of the videos.
One of the issues with many build-tools is that they take a way to agnostic approach about the language they build or how the project is structured. I'm for example unaware of any tool that enables warnings by default or provides a way to control them short of directly passing them to the compiler. Be opinionated dammit! The defaults most compilers pick SUCK hard and if I have to pick all flags manually, I might as well use makefiles. Also: Forcing me to write a list of all files that I want to build is not really better than forcing me to write out the dependencies by hand. As the author states, the performance difference between build-systems is so tiny, it really wouldn't matter if you checked for changed directories. Since I use GLOBs, I ALWAYS rerun Cmake, and those 0.1 seconds have NEVER been an issue.
Yours is an excellent example. It's not an easy problem to solve; it requires careful thought by seasoned experts. And those people (thank goodness we have them on the C++ committees!) will need to know the entire stack, from libraries to language to linker. Again, it's a tough problem. Let's imagine that something like this exists. To your point, perhaps this would work: From bash prompt: BOOST\_MULTIINDEX\_DEBUG=1 cpp\_package\_manager install boost **as boostdbg** (This installs and pre-compiles to something higher than LLVM-IR but lower than source... I suppose almost like a PCH) Now in your C++ code: import boostdbg; int main() {} Now when "building", we can specify -O1 or whatever and it gets applied to EVERYTHING, including the PCH stuff. My answer certainly has some flaws.... heheheh. But this is why there's all the smart people in the C++ committee to figure this stuff out. 
I'm surprised to see QBS left of the list, especially in light of all the things included that nobody uses.
&gt; One thing to note, the paper was developed, to my understanding (which may be wrong!), with the intention of having a basis for which to consider graphics as a larger whole. A larger whole? Well, SG13 started with much bigger expectations, but it never had any roadmap and io2d in particular has never been explained as a part of something else. Anyway, good luck for anything you can do in this field, I will be watching. 
QBS passes -Wall -Wextra, along with taking some other opinionated positions by default, such as disallowing in source builds.
No love for Boost.build/jam? Just advocating for the guy with happens and sulphurous aftershave. I've pretty much resigned myself to CMake, just as I have to git, and Jira, and all of the other "it's terrible, but at least it's a clear and consistent winner" elements of the modern professional development ecosystem.
Do compilers normally optimize the original variable (one which is sent as function parameter) out, if the value that's being sent as a function parameter goes out of scope without being used further after the function is being called at the call site?
I do likewise and then automate it and turn it into an on-line service.
Regarding Meson: "Why not, but what I am actually looking for is a tool that can build my project for iOS, Android, OSX and Linux. Something that just works; speed is a secondary concern." Then why not try Meson? Supposedly it works just fine for cross-compilation and it's just so much nicer than CMake! Soooo much nicer!
Make dependency generation has been pretty "straightforward" [for some time](http://make.mad-scientist.net/papers/advanced-auto-dependency-generation/). You don't even necessarily need all of the lines in the link, usually it's a case of collecting the dependency makefiles into a variable, passing `-MMD` to the compiler, and then including the resulting makefile fragments. It's not as simple as other non-make solutions but it gets the job done.
D:
Yes, `operator co_await` is allowed to be a coroutine. See [https://godbolt.org/g/LK4UrY](https://godbolt.org/g/LK4UrY) for an example. The caveat is that the return-type of that coroutine must itself be an `Awaiter`. ie. contain the `await_xxx` methods directly on the object. If the return type of the `operator co_await` coroutine has an `operator co_await` itself then currently this will not be called. We would need some extra wording to make the behaviour of `operator co_await` mirror that of `operator-&gt;` so that it keeps calling `operator co_await` on the returned objects until we reach something that either doesn't have an `operator co_await`, or that implements the `await_xxx` methods. Adding this capability, however, would make it more involved to write awaitable types that directly wrap/adapt other awaitable types since it would need to emulate this call-chaining behaviour.
&gt; such as disallowing in source builds. I think you might have out a word?
\&gt; But if you want to write a generic task accepting thing, how do you know what T is? It's possible to write a traits class that emulates the internal mechanics of what `operator co_await` does and uses decltype to deduce what type you will get when you `co_await` something. See [cppcoro::awaitable\_traits&lt;T&gt;::await\_result\_t](https://github.com/lewissbaker/cppcoro/blob/4022c11543f3911dc6783239219cbf3d8e77e2bb/include/cppcoro/awaitable_traits.hpp#L23) for an example implementation.
https://softwareengineering.stackexchange.com/questions/365460/in-source-build-vs-out-of-source-build
Interesting... I knew that by "in/out-of tree" rather than source. I might have even recognized "out of source", but as-is I think my brain latched onto you trying to say "such as disallowing *something* in source builds" and didn't pick it up. Thanks for the clarification!
Geez, am I the only person who *likes* autotools?
Does the lifetime checker in VS detect cases like this? (I'd check myself, but I don't have VS.) std::string make() { return "-----string-----"s; } std::string_view observe(std::string_view s) { return s; } int main() { auto s = observe(make()); // original string destroyed, but string_view remains } 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8zmtfw/has_anyone_had_any_luck_linking_using_the_mingw/e2k6jbo/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8znprp/i_am_willing_to_do_for_you_the_stuff_you_are_sick/e2k6koj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
More people need to take a look at [Shake](https://shakebuild.com/). I'd like to see its performance evaluated, and I think the author will be pleased with its correctness.
Thank you for this! Someone had to say it... And you formulated it quite aptly
I see, you are right. Please delete the post.
The distributed build aspect of FASTBuild makes it radically different from the others but I wonder at which project size it becomes interesting. If I remember well, in his 2014 conference at CppCon /u/NicolasFleury claims that a non-distributed full rebuild of Assassin's Creed takes only five minutes. It's seems to be a quite large project to me so if they don't need it why should we? I've never heard of GENie before but I am not yet ready to leave CMake unless it has a large and active community. Being stuck with the problems of Premake for four years was painful.
&gt; can't think of a practical example where users rely on it being compile-time If you have a public constexpr API and users use it in an constexpr function.
The 3rd link is my favourite, I have to completely agree with every single thing written there
Well, speaking of things nobody uses… I had never heard of QBS before :)
It's the newer build system from Qt that is supposed to replace QMake in Qt 6. It is actually really nice.
 In current project we use FastBuild and it’s shit. Ok, it allows distribute compilation, and can generate VS projects on the fly, but it is everything that it can do, its tooling lacks most of quality of life features, and if your project is multilanguage you are also out of luck. Bazel (which is left out of comparison) can do everything that FastBuild can but much better. 
I don't really have an opinion on Boost.build, it's the best tool to build… Boost. Joke aside, Boost.build is almost 20 years old. In these ancient times there was no CMake yet and no credible alternative so it made sense to use it. I guess that they are somewhat stuck with it nowadays even if there is an effort to offer [a CMake based build](https://github.com/boost-cmake) now. 
More definitively, the chrono stuff doesn't have a *Throws:* paragraph so it's nothrow per [res.on.exception.handling]. Since allocators can throw, nothrow implies non-allocating.
I just use github and conan
*Cries in qmake*
Why not use cget?
What makes you feel that Meson is nicer than CMake? Its main argument is that it's faster than CMake but I don't actually see any difference in my use cases. It may certainly be more efficient on larger projects but right now CMake is older, more experienced, still active and reacts positively to criticism. I don't think we are at the moment when CMake is so over-bloated that we should drop it.
I'm with you on explicit allocation, but now you're calling the more expensive constructor. I don't know how measurable this is for strings - but I noticed it with string view. 
Thanks, I'd not seen this before.
I looked into FASTBuild a while back. It has a very promising back end and terrible front-end. You can't use it to generate code because you can't declare the dependencies correctly. There is a custom script language with bizzare syntax that requires a full rebuild of your project on any change to the source files. And you can't use it to build non-code steps because you can't declare multiple outputs. It can't deal with VS wanting to output debug data separately from the obj, instead requiring you to use z7 (or whatever the flag is) so it can deal with a single output. I would be really surprised if they used it in production at ubisoft or I would have expected some of these improvements to have been made, he likely just got it working as a side project.
Didn’t read yet but I noticed Bazel wasn’t mentioned at all (which I have a personal interest in) nor Conan.io. Any chance to include them in the review?
More expensive how? I'm going to guess it doesn't have an overload for a known-size char array...
Your only argument for CMake is that it's older and more used?
I, too, work on cross-platform games and apps, and I, too, found CMake to be the best solution despite all its problems. Now I try to force CMake wherever I go, and even submitted a few pull requests to libraries that were not built quite correctly using CMake (including Curl on iOS). It works especially well for end-user projects, where you don't need to worry about someone reporting an exotic edge case. People who maintain widely used libraries are much less fond of it, because things sometimes break in an unexpected manner. But... It's not like this doesn't happen with "some other build system". I know people who swear by premake, but I wonder if they are enamoured with it just because they hadn't yet had a chance to maintain a build script written for this system for 10+ years, adding new platforms and architectures along the way, changing C++ standards used etc... A colleague of mine used to say he prefers custom-built project generators which create projects in the way your company needs them. This might be a fine solution, but it only works as long as you're content to build dependencies by hand every time, and preferably, store all artefacts somewhere. But unless you're willing to set up a system for serving these artefacts, it becomes a versioning hell, when one projects needs libfoobar 1.2.6, and another 1.2.9, which introduces some breaking changes, and the third projects needs libfoobar with custom patches because it needs to work on a new platform... I find that building necessary dependencies from source for each project is a much cleaner solution - and one that works very well with CMake's add_subdirectory command and Git sumbodules. That approach, however, might be made obsolete to a large degree by Hunter package manager, which takes care of managing versions on developer's machine.
Fortunately, I think you are
I had an extremely difficult time reading the post. You might want to rephrase your post so it's more clear as to what the project is and how it differentiates itself from what exists. From what I can gather, your project looks like it's aimed at just being something that downloads dependencies from GitHub (or whatever plugins you have) and generates output for them. However, how does it actually help you include these packages in a build? One of the reasons that build systems and build system generators for C++ are so complex is that the number of ways packages are provided in the wild are immense, each built a different way, and you need to link against them. Does Architect provide any facilities to make this easier? If it doesn't, then you are missing the core of what makes tools like Conan and Vcpkg relevant -- they abstract the building and linking of external libraries so you don't have to hardcode scripts.
[This will surely be very useful](https://imgs.xkcd.com/comics/standards.png). More seriously, conan is basically what you want. If your only argument against it is relatively sparse official repos, your time would better be spent packaging and publishing the libs you want yourself. Keep in mind that you would have to do that anyway for your new package manager, in addition to implementing it.
&gt; It can't deal with VS wanting to output debug data separately from the obj, instead requiring you to use z7 (or whatever the flag is) so it can deal with a single output. It's also worth pointing out that Clang and GCC both support `-gsplit-dwarf` which does something similar (with a `.dwo` extension). I've only played around with this a little bit, but using that flag *substantially* speeds up large C++ links, and I kind of want to do some enhancements to *our* build system to use that flag on Linux.
Or "how to just emulate Rust's semantics"
That's not how it works. If it's not marked `noexcept` and has no _Throws:_ paragraph, then it can throw anything.
&gt;Also: Forcing me to write a list of all files that I want to build is not really better than forcing me to write out the dependencies by hand. Do you mean that you would like something like "*include all *.cpp files from this dir into built*"? 
yes
Indeed. Bincrafters have a HUGE library of packages and a pretty fantastic set of Boost packages: [https://bintray.com/bincrafters/public-conan](https://bintray.com/bincrafters/public-conan) Just click the "Set Me Up!" button, add the repo to your conan config and away you go.
Hello, thank you for your time reading my post and I am sorry if it is unclear in any way. I will absolutely write a proper documentation once the project is in more advanced stage of development. As for your concerns about Architect's building and packaging capabilities, these are currently being worked on. Architect is absolutely not just another way to download your git repositories and execute their build scripts. While working on my projects with npm, I was used to fetching, building, bundling and deploying them using one single command with very little need of configuring anything, therefore I am kind of spoiled from npm world in this way and I don't want to give up my comfort (which might sound kind of hilarious from a guy who is trying to write a package manager all by himself...). Of course I am fully aware that there are thousands of configuration scripts and data files that need to be properly taken care of in an actual C/C++ project and that the linking and compiling phases are a separate chapters on its own. And that's exactly why I am trying to build - a system that's dissectible to its very core and still pretty useful with as less configuration as possible. My problem with the solutions you have provided is that they do the linking, compiling and packaging very well, but that's it. But as far as I know, they do not provide any way of fetching my dependencies from a remote repositories, they do not support local installation of my desired libraries so that I don't have to worry about some wild version of the same library already being installed somewhere on my system, they don't provide a simple way for me to hook into their internals and just script my special needs without having to rewrite what has already been written. So yeah, I am fully invested in writing Architect plugins capable of resolving dependency graphs, bundling your projects and executing targets and their respective test suites. And surely, it will be an immensely complex task. But I still prefer this to the headaches and code friction that would arise from repetitive writing of the exact same shell script that I have already written for managing my other quintillion C/C++ projects but I still have to write it again just to compensate for the one non-standard dependency.
The last message is asking the author to rebase. But the author probably has lost interest (2 years have passed!) and I doubt the future of this patch.
Hey, thanks for allocating your time to read my post! xkcd is surely pretty accurate, except there's not really a standard way to do this. And I am really not trying to build a new standard. Well, I am in a way... but, I am trying to reuse as much standards as I can to support as much projects as possible. And also, I am not going to build a new public dependency central. I think that fetching projects from GitHub and other popular git services is more than fine. Sure, then you have to deal with their compilation but I am more than willing to support this in order to allow for local and reproducible builds.
FYI: [just released Cmake 3.12](https://blog.kitware.com/cmake-3-12-0-available-for-download/) learned the trick with `CONFIGURE_DEPENDS` option to `file(GLOB ...)` command. 
As Meson uses Python, it's syntax is clearer and there's no need to learn a scripting language with the sole purpose of building C++ If CMake would replace it's crazy language with Python (and a few small improvements like sane globbing) I would find it OK. Readability matters not only in actual code... I actually don't find CMake bloated, but it's neither been modernised nor is it easy for newcomers to learn and that's why I would recommend Meson over CMake.
Very clear and concise criticisms! I am happy that these issues are voiced - a 2D graphics library without windowing or interaction... I find it stunning that this didn't get shut down much earlier!
Meson uses a custom build description language just like CMake. That it's written in Python is kind of irrelevant.
!build_pass:message("There there. Heey, things might not be so bad - it still might work. It just hasn't yet.")
Next video has arrived. This time we are going to use [RTTR](https://www.rttr.org) library to bind a C++ class to Lua. This will allow us (in Lua) to construct an object of any class that we bind. In future videos, we will set up the destructors, methods and properties as well. [Embedding Lua in C++ #26 - Creating Native Objects Using Run Time Type Information](https://youtu.be/zpUszqZThTg)
Ninja was originally created for chromium where a single line change would take an unnecessarily long time to compile. Its speed advantage over make is in incremental compilations and not in full builds
I still user jam. Is a single executable c compiled executable. Along with fossil for an it makes for a light build environment. 
Thanks for the clarification. I wanted to address some of the concerns you brought up and further the discussion: &gt; As far as I know, they do not provide any way of fetching my dependencies from a remote repositories, Conan and Vcpkg both download files and dependencies from their repos, respectively, unless I'm misunderstanding what you mean. Conan allows users to upload things in a way closer to NPM, while Vcpkg is more fenced-off. It forces packages to be in the correct format, which is similar to what NPM requires. If you just need a package of GitHub then you would end up cloning it locally. &gt; they do not support local installation of my desired libraries so that I don't have to worry about some wild version of the same library already being installed somewhere on my system, They actually do support this, as far as I am aware. I believe they even let you choose how you'd like the libraries linked, statically or dynamically. Since they both link into CMake, you probably can't even accidentally use system libraries unless you explicitly use those packages in the CMakeLists file. &gt; they don't provide a simple way for me to hook into their internals and just script my special needs without having to rewrite what has already been written. Conanfiles are actually also Python scripts, so you should be able to script whatever kind of behaviour you need. If you mean linking libraries, you would do this likely through CMake instead. All said, I think you might misunderstand what the existing tools do and what they are for. For the longest time I refused to learn CMake because I thought the language was arcane. It still is, to some extent, but actually understanding CMake now makes me appreciate it much more for actually how simple it is to use in basic cases and how easy it is to link in libraries. With either Conan or Vcpkg (or any other package manager), they typically provide a hook into your build system or generator, frequently CMake, which allows you to easily make use of third-party headers without having to write any of your own includes or build scripts for the third-party libraries. If you wanted to perform the same kind of functionality you'd end up having to write CMake scripts anyway, so it might be worth taking a deep dive there first.
I really like some of the approaches you're taking! For example, I found conan to be very (unnecessarily!) cumbersome, but you seem to have a much cleaner CLI with some sane defaults. It's not quite clear to me what this tool is supposed to be able to do, it would be great if you would try to formulate, as concisely as possible, not only the philosophy (it should be just as easy to do packages in C++ as in other languages), but also what exactly the tool should do and where other tools should take over. I only skimmed your stuff so far, but it's not immediately clear to me e.g. who should then execute CMake or Make. A repo with example projects would be quite nice btw. I am myself trying to simplify C++ build processes by writing a new build system (for simplicity it is specific to clang): [https://github.com/Trick-17/clang-build](https://github.com/Trick-17/clang-build) The goal is similar: it should not require much more than a few lines of configuration file to define the build requirements etc. for a simple project (and through nesting of projects it actually works fine for quite complicated projects). clang-build has some simple dependency fetching, where a git repo can be specified from which to pull the sources for a target or project (a project is simply a collection of targets). Lastly, if you didn't already, I believe you should also take inspiration from homebrew and Meson (the latter is sort of a better CMake). 
I can't remember the last time I did a full local rebuild at work, it would probably take at least 15-20 minutes. I'd be really surprised if a full local rebuild for AC's codebase took only five minutes. Maybe they prebuild a lot of components, or he was talking about unity builds? If it's really only 5 minutes, can we convince Nicolas to give a talk on how they keep build times so low on such a large game? :P If you've already moved your premake projects to CMake then no point in trying GENie, for sure. If you have some premake stuff lying around though, maybe give it a go. Won't have the CMake mindshare, but there are big projects with complex build configurations that use it, like MAME.
Doesn't he imply right in the bit that he needs platform specific IDE project generation? I'm interested in Meson but life is a lot easier when I can generate Xcode and VS projects.
Autotools + gnumake is great
Also if you'd really care about the cost of dynamic allocations you would just implement a custom allocator...right?
Indubitably. 
What do you mean by "more expensive constructor"? Neither the constructor of std::string nor operator""s deduce the length of the string literal at compile-time (i.e. const char[Size]). They probably use something similar to strlen internally, which some compilers can optimize and evaluate at compile-time ( e.g. `_builtin_strlen()` in GCC)
I don't think this is one of those circumstances where unmaterialized value passing wouldn't apply though. The make factories return the same unqualified value type as the specified type in the template.
And has the advantage of being accurate. Compilers and build systems often disagree on how -I -isystem and quoted vs angle brackets work. One of them is correct. 
And this is how we end up with yet another build tool, because people don't think it's actually hard. Autotools is painful mostly because it supports ancient systems. Well, and M4 never took off. But if cmake language is ok, that can't be an objection. The biggest reason autotools withered is Windows, where the basic model is too different. 
There are two kinds of tools, the ones you hate, and the ones you don't really use. 
In my unscientific testing, it looses a lot of its advantages if you disable gmake built-in rules. Stat-ing for ,v files in case you need to co from rcs takes a while.
Meson's biggest advantage IMO is its DSL, which is *far* nicer to work with than CMake's macro language. The build files are also incredibly simple and readable, and the configuration has pretty colors. 
Boost.Build definitely isn't perfect, but IMO it works really well for C++ code and trying to tame different sets of compiler flags. 
Isn't Conan basically a CMake wrapper?
Shake is awesome, but Haskell is a pretty big dependency IME...
I think that's because the autotools are optimized for the UX of the installer and sysadmin instead of the UX of the developer. Any time I'm installing some third-party code from source and I see the autotools I breathe a sigh of relief.
You make it sound like that is not a big advantage.
TBH. I went down the same path (and I have &gt;15yrs commercial C++ experience). I actually got a working system that I integrated into a couple of my projects. I got it working well for Windows; but never found the time to migrate it to Linux. Happily, I'll tell you some things you need to consider, then I'll tell you what I did to overcome them. Things you need to consider: * Built libraries are dependent on compiler version (major and minor typically matter) * Built libraries are dependent on operating system (linux, BSD, windows, OSX) * Most libraries have many many different build configuration (debug, release, test, optimised, threaded (how?)) * That most professional projects have many developers and a dedicated build system. Getting and building libraries isn't really the problem. Distribution configurations for libraries and the project to other developers and the build system can be quite time consuming. *Note: I get where you are coming from as a single developer; but I feel this is more an exception than the general rule. That being said, I think the solution I came up with works for both worlds regardless* Now, The approach I took: * I built a system that allows you to commit pre-built C++ libraries that are bound to Operating System and compiler version (major and minor). You could make these libraries either privately or publicly available. * The project had two configuration files that came with it * Configuration file 1 was a global project file that was checked into the source control system. This included the list of libraries, their versions, where to put the files (headers and libs), compiler or linking flags etc * Configuration file 1 (global) was version controlled * Configuration file 2 is a local one, this one contains overrides to the global as well as staging changes (e.g. developer is testing a newer version of a library). This file is not checked into source control. My theory was that a new developer a project would most likely use the same compiler as the dedicated build system, or other developers. If so, they could run a single command to pull down all pre-built libraries for their project. Then if they wanted to update a library they did so locally, then commit the staged changes to the build configuration. This allows a single developer on any project to handle compiler updates for all developers. Once the commit has been done all other developers can "update" and receive the latest copies of all libraries. (FWIW, when I used this in my project. Pushing a new full build of boost to the other developers took ~1 minute each). If the developer uses a different or newer compiler, then they would either have to source the libraries they want from publicly available ones; or build and commit their own. 
[i was expecting this one](https://xkcd.com/1654/) 
I don't think it's that hard to implement. Just make a constructor taking T&amp;&amp; and have a member of type T. Then give the (one line) deduction guide. The template metaprogramming part is there to add const to the ref... Which you might not need. Maybe it's not trivial to read, true. But maybe it should become a common pattern :) 
`operator""s` is passed a size so no strlen call is needed.
You're right. I've overlooked that part.
Apparently it does not. In fact it does not even catch something like: std::string_view sv(std::string("hello")); std::cout &lt;&lt; sv; But you're not this [first](https://github.com/isocpp/CppCoreGuidelines/issues/1038) one to complain about it :)
Nobody said cmake is ok. It just tends to work better. I'm still having difficulty with autotools on projects where it should simply work.
:( no discussion about build2 or, my favorite, tup.
It's not, that's another dependency you get.
That is a good question. There are some instructions [here](https://blogs.msdn.microsoft.com/vcblog/2017/08/11/c-core-guidelines-checker-in-visual-studio-2017). (I don't know if there are better ones elsewhere.) Btw, those instructions refer to an "Extensions" section that is no longer present or needed. Also, I found that selecting the "C++ Core Check Rules" did not enable the lifetime checks. (I assume this is a bug?) I needed to explicitly select the "C++ Core Check Lifetime Rules" (or "Microsoft All Rules") in order to enable the lifetime checks.
You don't have to use a template, you can use a boolean to say if you own a pointer or not. It is quite useful if you want some type erasure so you don't need to make everything a template. For example, you can make a view of a part of an image that will expose the same type, but internally marks its pointer as non-owning (and it better since in many cases the base address isn't even stored).
I wish all these people making new build systems would just recreate Shake in their pet language.
No
Does anyone else find this kind of an incongruous situation? I mean, apparently the cyber security market is on the order of $100 billion. The U.S. federal government alone spends like $20 billion a year on cyber security. One could argue a working C++ lifetime checker would be more effective, and far more cost-effective, than pretty much any cyber security product or policy out there. Yet somehow, in our little world, "a definite thumbs up from a lot of us" seems like a reasonably competitive compensation package. :) Somebody, somewhere, somehow needs get some of those misspent resources redirected to this task. I'm just sayin' ...
Your example probably doesn't allocate at all. It depends on the implementation and none of the widely used ones will. Also, why should allocation be disallowed? If you don't want it then don't do it, but I don't see why 'literals' should be prohibited for types that allocate. What's the value in outlawing things like `std::list{1,2,3,4}`?
Ninja's speed is mostly useful for incremental builds. If you're running a clean build, the majority of time will be spent on compiling and linking, so even if the build tool was infinitely fast you'd barely notice a difference. A faster build system is most noticeable when you're repeatedly compiling small changes. I've seen cases where make takes a second or two to start compiling while ninja is instant. YMMV. I like using Ninja because all it requires is passing \`-G Ninja\` to CMake. It's not even a net increase in flags because you don't need to pass \`-j N\` to ninja. It's parallel by default.
To avoid possible collision with user-defined literals.
This is way too clever, IMO. Especially since all of the extra complexity doesn't even get you something that works reliably - like the last section notes, it's really easy to come up with scenarios where this results in dangling references. Something like this is much simpler to accomplish the same effect (but with the same problems): `struct TextDisplayer` `{` `TextDisplayer(const std::string &amp;str) : strRef(str) {}` `TextDisplayer(std::string &amp;&amp;str) : strVal(std::move(str)), strRef(strVal) {}` `std::string strVal;` `const std::string &amp;strRef;` `};` 
It is required – they are reserved.
I've never heard of JWT, but on-line code generation is another approach to safeguard investors. I'm working on that for C++ for a number of years. My code generator is proprietary, but using it is free. 
#[CMake 3.12 Release Notes](https://cmake.org/cmake/help/v3.12/release/3.12.html) Changes made since CMake 3.11 include the following. ##New Features ###Generators - The [Visual Studio Generators](https://cmake.org/cmake/help/v3.12/manual/cmake-generators.7.html#visual-studio-generators) for VS 2017 learned to support a `version=14.##` option in the [`CMAKE_GENERATOR_TOOLSET`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_GENERATOR_TOOLSET.html#variable:CMAKE_GENERATOR_TOOLSET) value (e.g. via the [`cmake(1)`](https://cmake.org/cmake/help/v3.12/manual/cmake.1.html#manual:cmake\(1\)) `-T` option) to specify a toolset version number. ###Command-Line - The [`cmake(1)`](https://cmake.org/cmake/help/v3.12/manual/cmake.1.html#manual:cmake\(1\)) [Build Tool Mode](https://cmake.org/cmake/help/v3.12/manual/cmake.1.html#build-tool-mode) (`cmake --build`) gained `--parallel [&lt;jobs&gt;]` and `-j [&lt;jobs&gt;]` options to specify a parallel build level. They map to corresponding options of the native build tool. ###Commands - The [`add_compile_definitions()`](https://cmake.org/cmake/help/v3.12/command/add_compile_definitions.html#command:add_compile_definitions) command was added to set preprocessor definitions at directory level. This supersedes [`add_definitions()`](https://cmake.org/cmake/help/v3.12/command/add_definitions.html#command:add_definitions). - The [`cmake_minimum_required()`](https://cmake.org/cmake/help/v3.12/command/cmake_minimum_required.html#command:cmake_minimum_required) and [`cmake_policy(VERSION)`](https://cmake.org/cmake/help/v3.12/command/cmake_policy.html#command:cmake_policy) commands now accept a version range using the form `&lt;min&gt;[...&lt;max&gt;]`. The `&lt;min&gt;` version is required but policies are set based on the older of the running CMake version and the version specified by `&lt;max&gt;`. This allows projects to specify a range of versions for which they have been updated and avoid explicit policy settings. - The [`file(GLOB)`](https://cmake.org/cmake/help/v3.12/command/file.html#command:file) and [`file(GLOB_RECURSE)`](https://cmake.org/cmake/help/v3.12/command/file.html#command:file) commands learned a new flag `CONFIGURE_DEPENDS` which enables expression of build system dependency on globbed directory’s contents. - The [`file(TOUCH)`](https://cmake.org/cmake/help/v3.12/command/file.html#command:file) and [`file(TOUCH_NOCREATE)`](https://cmake.org/cmake/help/v3.12/command/file.html#command:file) commands were added to expose `TOUCH` functionality without having to use CMake’s command-line tool mode with [`execute_process()`](https://cmake.org/cmake/help/v3.12/command/execute_process.html#command:execute_process). - The [`find_package()`](https://cmake.org/cmake/help/v3.12/command/find_package.html#command:find_package) command now searches a prefix specified by a `PackageName_ROOT` CMake or environment variable. Package roots are maintained as a stack so nested calls to all `find_*` commands inside find modules also search the roots as prefixes. See policy [`CMP0074`](https://cmake.org/cmake/help/v3.12/policy/CMP0074.html#policy:CMP0074). - The [`install()`](https://cmake.org/cmake/help/v3.12/command/install.html#command:install) command learned an optional `NAMELINK_COMPONENT` parameter, which allows you to change the component for a shared library’s namelink. If none is specified, the value of `COMPONENT` is used by default. - The [`list()`](https://cmake.org/cmake/help/v3.12/command/list.html#command:list) command learned a `JOIN` sub-command to concatenate list’s elements separated by a glue string. - The [`list()`](https://cmake.org/cmake/help/v3.12/command/list.html#command:list) command learned a `SUBLIST` sub-command to get a sublist of the list. - The [`list()`](https://cmake.org/cmake/help/v3.12/command/list.html#command:list) command learned a `TRANSFORM` sub-command to apply various string transformation to list’s elements. - The [`project()`](https://cmake.org/cmake/help/v3.12/command/project.html#command:project) command learned an optional `HOMEPAGE_URL` parameter which has the effect of setting variables like [`PROJECT_HOMEPAGE_URL`](https://cmake.org/cmake/help/v3.12/variable/PROJECT_HOMEPAGE_URL.html#variable:PROJECT_HOMEPAGE_URL), [`&lt;PROJECT-NAME&gt;_HOMEPAGE_URL`](https://cmake.org/cmake/help/v3.12/variable/PROJECT-NAME_HOMEPAGE_URL.html#variable:&amp;lt;PROJECT-NAME&amp;gt;_HOMEPAGE_URL) and [`CMAKE_PROJECT_HOMEPAGE_URL`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_HOMEPAGE_URL.html#variable:CMAKE_PROJECT_HOMEPAGE_URL). - The [`string()`](https://cmake.org/cmake/help/v3.12/command/string.html#command:string) command learned a `JOIN` sub-command to concatenate input strings separated by a glue string. - [`target_compile_options()`](https://cmake.org/cmake/help/v3.12/command/target_compile_options.html#command:target_compile_options) and [`add_compile_options()`](https://cmake.org/cmake/help/v3.12/command/add_compile_options.html#command:add_compile_options) commands gained a `SHELL:` prefix to specify a group of related options using shell-like quoting. - The [`target_link_libraries()`](https://cmake.org/cmake/help/v3.12/command/target_link_libraries.html#command:target_link_libraries) command now supports [Object Libraries](https://cmake.org/cmake/help/v3.12/manual/cmake-buildsystem.7.html#object-libraries). Linking to an object library uses its object files in direct dependents and also propagates usage requirements. ###Variables - The [`CMAKE_FOLDER`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_FOLDER.html#variable:CMAKE_FOLDER) variable was added to initialize the [`FOLDER`](https://cmake.org/cmake/help/v3.12/prop_tgt/FOLDER.html#prop_tgt:FOLDER) property on all targets. - The [`CMAKE_DOTNET_TARGET_FRAMEWORK_VERSION`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_DOTNET_TARGET_FRAMEWORK_VERSION.html#variable:CMAKE_DOTNET_TARGET_FRAMEWORK_VERSION) variable was defined to initialize all [`DOTNET_TARGET_FRAMEWORK_VERSION`](https://cmake.org/cmake/help/v3.12/prop_tgt/DOTNET_TARGET_FRAMEWORK_VERSION.html#prop_tgt:DOTNET_TARGET_FRAMEWORK_VERSION) target properties. - `CMAKE_PROJECT_VERSION*` variables have been introduced: - [`CMAKE_PROJECT_VERSION`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION.html#variable:CMAKE_PROJECT_VERSION) - [`CMAKE_PROJECT_VERSION_MAJOR`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION_MAJOR.html#variable:CMAKE_PROJECT_VERSION_MAJOR) - [`CMAKE_PROJECT_VERSION_MINOR`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION_MINOR.html#variable:CMAKE_PROJECT_VERSION_MINOR) - [`CMAKE_PROJECT_VERSION_PATCH`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION_PATCH.html#variable:CMAKE_PROJECT_VERSION_PATCH) - [`CMAKE_PROJECT_VERSION_TWEAK`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION_TWEAK.html#variable:CMAKE_PROJECT_VERSION_TWEAK) - The [`CMAKE_SUPPRESS_REGENERATION`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_SUPPRESS_REGENERATION.html#variable:CMAKE_SUPPRESS_REGENERATION) variable was extended to support the [`Ninja`](https://cmake.org/cmake/help/v3.12/generator/Ninja.html#generator:Ninja) and [Makefile Generators](https://cmake.org/cmake/help/v3.12/manual/cmake-generators.7.html#makefile-generators). It is also now documented. - `CMAKE_VS_SDK_*_DIRECTORIES` variables were defined to tell [Visual Studio Generators](https://cmake.org/cmake/help/v3.12/manual/cmake-generators.7.html#visual-studio-generators) for VS 2010 and above how to populate fields in `.vcxproj` files that specify SDK directories. The variables are: - [`CMAKE_VS_SDK_EXCLUDE_DIRECTORIES`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_VS_SDK_EXCLUDE_DIRECTORIES.html#variable:CMAKE_VS_SDK_EXCLUDE_DIRECTORIES) - [`CMAKE_VS_SDK_EXECUTABLE_DIRECTORIES`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_VS_SDK_EXECUTABLE_DIRECTORIES.html#variable:CMAKE_VS_SDK_EXECUTABLE_DIRECTORIES) - [`CMAKE_VS_SDK_INCLUDE_DIRECTORIES`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_VS_SDK_INCLUDE_DIRECTORIES.html#variable:CMAKE_VS_SDK_INCLUDE_DIRECTORIES) - [`CMAKE_VS_SDK_LIBRARY_DIRECTORIES`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_VS_SDK_LIBRARY_DIRECTORIES.html#variable:CMAKE_VS_SDK_LIBRARY_DIRECTORIES) - [`CMAKE_VS_SDK_LIBRARY_WINRT_DIRECTORIES`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_VS_SDK_LIBRARY_WINRT_DIRECTORIES.html#variable:CMAKE_VS_SDK_LIBRARY_WINRT_DIRECTORIES) - [`CMAKE_VS_SDK_REFERENCE_DIRECTORIES`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_VS_SDK_REFERENCE_DIRECTORIES.html#variable:CMAKE_VS_SDK_REFERENCE_DIRECTORIES) - [`CMAKE_VS_SDK_SOURCE_DIRECTORIES`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_VS_SDK_SOURCE_DIRECTORIES.html#variable:CMAKE_VS_SDK_SOURCE_DIRECTORIES) - A [`MSVC_TOOLSET_VERSION`](https://cmake.org/cmake/help/v3.12/variable/MSVC_TOOLSET_VERSION.html#variable:MSVC_TOOLSET_VERSION) variable was added to provide the MSVC toolset version associated with the current MSVC compiler version in [`MSVC_VERSION`](https://cmake.org/cmake/help/v3.12/variable/MSVC_VERSION.html#variable:MSVC_VERSION). ...
##New Features (Continued) ###Properties - The [`COMMON_LANGUAGE_RUNTIME`](https://cmake.org/cmake/help/v3.12/prop_tgt/COMMON_LANGUAGE_RUNTIME.html#prop_tgt:COMMON_LANGUAGE_RUNTIME) target property was introduced to configure the use of managed C++ for [Visual Studio Generators](https://cmake.org/cmake/help/v3.12/manual/cmake-generators.7.html#visual-studio-generators) for VS 2010 and above. A corresponding [`IMPORTED_COMMON_LANGUAGE_RUNTIME`](https://cmake.org/cmake/help/v3.12/prop_tgt/IMPORTED_COMMON_LANGUAGE_RUNTIME.html#prop_tgt:IMPORTED_COMMON_LANGUAGE_RUNTIME) target property was added to support `C++/CLI` for imported targets. - The [`DOTNET_TARGET_FRAMEWORK_VERSION`](https://cmake.org/cmake/help/v3.12/prop_tgt/DOTNET_TARGET_FRAMEWORK_VERSION.html#prop_tgt:DOTNET_TARGET_FRAMEWORK_VERSION) target property was introduced as replacement for [`VS_DOTNET_TARGET_FRAMEWORK_VERSION`](https://cmake.org/cmake/help/v3.12/prop_tgt/VS_DOTNET_TARGET_FRAMEWORK_VERSION.html#prop_tgt:VS_DOTNET_TARGET_FRAMEWORK_VERSION), which is considered deprecated now. - An [`EXPORT_PROPERTIES`](https://cmake.org/cmake/help/v3.12/prop_tgt/EXPORT_PROPERTIES.html#prop_tgt:EXPORT_PROPERTIES) target property was added to specify a custom list of target properties to include in targets exported by the [`install(EXPORT)`](https://cmake.org/cmake/help/v3.12/command/install.html#command:install) and [`export()`](https://cmake.org/cmake/help/v3.12/command/export.html#command:export) commands. - The [`PDB_OUTPUT_DIRECTORY`](https://cmake.org/cmake/help/v3.12/prop_tgt/PDB_OUTPUT_DIRECTORY.html#prop_tgt:PDB_OUTPUT_DIRECTORY) property learned to support [`generator expressions`](https://cmake.org/cmake/help/v3.12/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions\(7\)). - A [`TESTS`](https://cmake.org/cmake/help/v3.12/prop_dir/TESTS.html#prop_dir:TESTS) directory property was added to hold the list of tests defined by the [`add_test()`](https://cmake.org/cmake/help/v3.12/command/add_test.html#command:add_test) command. - A [`VS_DEBUGGER_COMMAND`](https://cmake.org/cmake/help/v3.12/prop_tgt/VS_DEBUGGER_COMMAND.html#prop_tgt:VS_DEBUGGER_COMMAND) target property was created to set the debugging command line with [Visual Studio Generators](https://cmake.org/cmake/help/v3.12/manual/cmake-generators.7.html#visual-studio-generators) for VS 2010 and above. - HLSL source file properties [`VS_SHADER_DISABLE_OPTIMIZATIONS`](https://cmake.org/cmake/help/v3.12/prop_sf/VS_SHADER_DISABLE_OPTIMIZATIONS.html#prop_sf:VS_SHADER_DISABLE_OPTIMIZATIONS) and [`VS_SHADER_ENABLE_DEBUG`](https://cmake.org/cmake/help/v3.12/prop_sf/VS_SHADER_ENABLE_DEBUG.html#prop_sf:VS_SHADER_ENABLE_DEBUG) gained support for generator expressions. - HLSL source file property [`VS_SHADER_OBJECT_FILE_NAME`](https://cmake.org/cmake/help/v3.12/prop_sf/VS_SHADER_OBJECT_FILE_NAME.html#prop_sf:VS_SHADER_OBJECT_FILE_NAME) has been added to the [Visual Studio Generators](https://cmake.org/cmake/help/v3.12/manual/cmake-generators.7.html#visual-studio-generators) for VS 2010 and above. The property specifies the file name of the compiled shader object. ###Modules - The [`FindALSA`](https://cmake.org/cmake/help/v3.12/module/FindALSA.html#module:FindALSA) module now provides imported targets. - The [`FindCURL`](https://cmake.org/cmake/help/v3.12/module/FindCURL.html#module:FindCURL) module now provides imported targets. - The [`FindJPEG`](https://cmake.org/cmake/help/v3.12/module/FindJPEG.html#module:FindJPEG) module now provides imported targets. - The [`FindLibXml2`](https://cmake.org/cmake/help/v3.12/module/FindLibXml2.html#module:FindLibXml2) module now provides imported targets. - The [`FindMatlab`](https://cmake.org/cmake/help/v3.12/module/FindMatlab.html#module:FindMatlab) module now supports the Matlab Runtime Compiler (MCR) for compiling and linking matlab extensions. - A [`FindODBC`](https://cmake.org/cmake/help/v3.12/module/FindODBC.html#module:FindODBC) module was added to find an Open Database Connectivity (ODBC) library. - The [`FindPkgConfig`](https://cmake.org/cmake/help/v3.12/module/FindPkgConfig.html#module:FindPkgConfig) module has learned to export the found libraries with full path for direct consumption with the [`target_link_libraries()`](https://cmake.org/cmake/help/v3.12/command/target_link_libraries.html#command:target_link_libraries) command. - New [`FindPython3`](https://cmake.org/cmake/help/v3.12/module/FindPython3.html#module:FindPython3) and [`FindPython2`](https://cmake.org/cmake/help/v3.12/module/FindPython2.html#module:FindPython2) modules, as well as a new [`FindPython`](https://cmake.org/cmake/help/v3.12/module/FindPython.html#module:FindPython) module, have been added to provide a new way to locate python environments. - The [`UseSWIG`](https://cmake.org/cmake/help/v3.12/module/UseSWIG.html#module:UseSWIG) module gained a whole refresh and is now more consistent with standard CMake commands to generate libraries and is fully configurable through properties. - The [`UseSWIG`](https://cmake.org/cmake/help/v3.12/module/UseSWIG.html#module:UseSWIG) module learned to manage multiple behaviors through `UseSWIG_MODULE_VERSION` variable to ensure legacy support as well as more robust handling of `SWIG` advanced features (like `%template`). - The [`UseSWIG`](https://cmake.org/cmake/help/v3.12/module/UseSWIG.html#module:UseSWIG) module learned to support CSHARP variant wrapper files. - The [`WriteCompilerDetectionHeader`](https://cmake.org/cmake/help/v3.12/module/WriteCompilerDetectionHeader.html#module:WriteCompilerDetectionHeader) module gained a `BARE_FEATURES` option to add a compatibility define for the exact keyword of a new language feature. ###Generator Expressions - A new `$&lt;GENEX_EVAL:...&gt;` and `$&lt;TARGET_GENEX_EVAL:target,...&gt;` [`generator expression`](https://cmake.org/cmake/help/v3.12/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions\(7\)) has been added to enable consumption of generator expressions whose evaluation results itself in generator expressions. - A new `$&lt;IN_LIST:...&gt;` [`generator expression`](https://cmake.org/cmake/help/v3.12/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions\(7\)) has been added. - A new `$&lt;TARGET_EXISTS:...&gt;` [`generator expression`](https://cmake.org/cmake/help/v3.12/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions\(7\)) has been added. - A new `$&lt;TARGET_NAME_IF_EXISTS:...&gt;` [`generator expression`](https://cmake.org/cmake/help/v3.12/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions\(7\)) has been added. ###CTest - The [`ctest_start()`](https://cmake.org/cmake/help/v3.12/command/ctest_start.html#command:ctest_start) command has been reworked so that you can simply call `ctest_start(APPEND)` and it will read all the needed information from the TAG file. The argument parsing has also been relaxed so that the order of the arguments is less significant. - A [`PROCESSOR_AFFINITY`](https://cmake.org/cmake/help/v3.12/prop_test/PROCESSOR_AFFINITY.html#prop_test:PROCESSOR_AFFINITY) test property was added to request that CTest run a test with CPU affinity for a set of processors disjoint from other concurrently running tests with the property set. ###CPack - The [`CPack`](https://cmake.org/cmake/help/v3.12/module/CPack.html#module:CPack) module now uses variables [`CMAKE_PROJECT_VERSION_MAJOR`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION_MAJOR.html#variable:CMAKE_PROJECT_VERSION_MAJOR), [`CMAKE_PROJECT_VERSION_MINOR`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION_MINOR.html#variable:CMAKE_PROJECT_VERSION_MINOR) and [`CMAKE_PROJECT_VERSION_PATCH`](https://cmake.org/cmake/help/v3.12/variable/CMAKE_PROJECT_VERSION_PATCH.html#variable:CMAKE_PROJECT_VERSION_PATCH) to initialize corresponding CPack variables. - [`cpack(1)`](https://cmake.org/cmake/help/v3.12/manual/cpack.1.html#manual:cpack\(1\)) gained basic support for [NuGet](https://docs.microsoft.com/en-us/nuget/what-is-nuget). See the [`CPackNuGet`](https://cmake.org/cmake/help/v3.12/module/CPackNuGet.html#module:CPackNuGet) module. ###Other - The [`Compile Features`](https://cmake.org/cmake/help/v3.12/manual/cmake-compile-features.7.html#manual:cmake-compile-features\(7\)) functionality is now aware of C++ 20. No specific features are yet enumerated besides the `cxx_std_20` meta-feature. - The [`Compile Features`](https://cmake.org/cmake/help/v3.12/manual/cmake-compile-features.7.html#manual:cmake-compile-features\(7\)) functionality is now aware of the availability of C features in MSVC since VS 2010. - The [`Compile Features`](https://cmake.org/cmake/help/v3.12/manual/cmake-compile-features.7.html#manual:cmake-compile-features\(7\)) functionality is now aware of C language standards supported by Texas Instruments C compilers. ... 
##Deprecated and Removed Features - The [`Visual Studio 8 2005`](https://cmake.org/cmake/help/v3.12/generator/Visual Studio 8 2005.html#generator:Visual Studio 8 2005) generator has been removed. - CMake no longer produces `&lt;tgt&gt;_LIB_DEPENDS` cache entries for library targets. See policy [`CMP0073`](https://cmake.org/cmake/help/v3.12/policy/CMP0073.html#policy:CMP0073). ##Other Changes - Include flags for directories marked as `SYSTEM` are now moved after non-system directories. The `-isystem` flag does this automatically, so moving them explicitly to the end makes the behavior consistent on compilers that do not have any `-isystem` flag. - Fortran dependency scanning now supports dependencies implied by [Fortran Submodules](http://fortranwiki.org/fortran/show/Submodules). - The existence and functionality of the file `${CMAKE_BINARY_DIR}/cmake_install.cmake` has now been documented in the [`install()`](https://cmake.org/cmake/help/v3.12/command/install.html#command:install) documentation so that external packaging software can take advantage of CPack-style component installs. - The [`CheckIncludeFile`](https://cmake.org/cmake/help/v3.12/module/CheckIncludeFile.html#module:CheckIncludeFile) module `check_include_file` macro learned to honor the `CMAKE_REQUIRED_LIBRARIES` variable. See policy [`CMP0075`](https://cmake.org/cmake/help/v3.12/policy/CMP0075.html#policy:CMP0075). - The [`CheckIncludeFileCXX`](https://cmake.org/cmake/help/v3.12/module/CheckIncludeFileCXX.html#module:CheckIncludeFileCXX) module `check_include_file_cxx` macro learned to honor the `CMAKE_REQUIRED_LIBRARIES` variable. See policy [`CMP0075`](https://cmake.org/cmake/help/v3.12/policy/CMP0075.html#policy:CMP0075). - The [`CheckIncludeFiles`](https://cmake.org/cmake/help/v3.12/module/CheckIncludeFiles.html#module:CheckIncludeFiles) module `check_include_files` macro learned to honor the `CMAKE_REQUIRED_LIBRARIES` variable. See policy [`CMP0075`](https://cmake.org/cmake/help/v3.12/policy/CMP0075.html#policy:CMP0075). - The [`cmake(1)`](https://cmake.org/cmake/help/v3.12/manual/cmake.1.html#manual:cmake\(1\)) `-E copy_directory` tool now fails when the source directory does not exist. Previously it succeeded by creating an empty destination directory. - The [`UseSWIG`](https://cmake.org/cmake/help/v3.12/module/UseSWIG.html#module:UseSWIG) module [`swig_add_library()`](https://cmake.org/cmake/help/v3.12/module/UseSWIG.html#command:swig_add_library) command (and legacy `swig_add_module` command) now set the prefix of Java modules to `""` for MINGW, MSYS, and CYGWIN environments.
More expensive in terms of runtime. The constructor needs to check the length by finding the \0 terminator. 
Meson can generate Xcode and VS projects. The project type is determined by the --backend argument which is from this list: ninja,vs,vs2010,vs2015,vs2017,xcode.
Because it isn't. Meson gets more popular by the day, so now you're left with it's old. Give me a technical advantage.
Sorry I was wrong. "All ud-suffixes introduced by a program must begin with the underscore character _. The standard library ud-suffixes do not begin with underscores." From https://en.cppreference.com/w/cpp/language/user_literal
I think it is a terrible idea: it makes impossible to search file name with tools like grep (for example if compilation flags for this particular file should be checked). Name of a source file is a kind of information which must be provided manually and explicitly, but of course only ones (in a good built system). 
When I compare with the headache that cmake starts to be, autotools is awesome, too bad the documentation is scarce and a real update might be useful.
I'm not referring to construction from an initializers list, rather the new custom suffixes stuff.
As others have said, don't. There are already solutions like this out there, do not contribute to the 15th competing standard. Looks like Conan and/or vcpkg are almost what you want, and those two have been \*already\* gaining reasonable traction. (Sorry, other package managers.)
I haven't worked with JWT for licensing but I've used it for web authentication. JWT is (I'm simplifying) an encoded string representing a JSON payload with a signature of the issuer, so I would say that your library could work both by 'pasting it' and by pointing the library to the correct file. I suppose it depends on the library itself, is there an initialization function that you can call? Maybe you have to pass the JWT there. Also, if you could share the library name and documentation I think I could help you more. 
Well, Conan isn't exactly a build system. It can be used to get stuff done, but it still needs some "underlying" builder like CMake to generate files / call `build` command.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8zt3ch/how_and_what_is_the_most_successful_ways_to_learn/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
From what I've heard, fetching projects from GitHub is _not_ fine. I believe Go / Cargo / Conan guys can tell you more about it.
But a single one of my dependencies can be built with meson
You say old, I say more experienced :) Experience is a clear advantage, it means basically that it will just work and if you encounter a problem with CMake you will certainly have a solution. Sometimes newcomers are better than older solutions, see for example Chrome/Firefox or Git/any VCS, but I do not think we are in a similar situation with Meson/CMake. Actually I wish one could give a technical advantage of Meson over CMake. Once you use the Ninja generator there's not so much difference. If you use another generator CMake is certainly better. Even the [pro/cons on Meson's website](http://mesonbuild.com/Comparisons.html) is not convincing. Then there's the language, and for this I think there is no satisfying solution. Use Python and people will complain that it's a dependency or that it's slow or that it's not their favorite language, etc. Use anything else and people will complain in similar ways. In my humble opinion as developers we will encounter a lot of languages (I'm a C++ developer and I still have to deal with at least Bash, Python, JavaScript, Java, Ruby, Groovy and CMake's DSL on a regular basis), so we may as well accept it and move forward.
I can't list all build systems, there's just too many! :)
Cargo supports that OOTB...
Yep, and I am pretty sure I have heard several times they are not happy with this approach - but I might heard this about Go or some other new language, so I am not sure.
Have you tried vcpkg instead of Conan?
It would have been a great idea some years ago. However today we have Vcpkg, Conan, etc. and the committee is working on a module system in C++, therefore I don't think it's worth to spend time on it. You said that the current tools are "rusty" or "over-complicated", but with Vcpkg it's 2 lines to setup the package manager, then 1 line to install each library. If you need to add a library or update one, follow [the documentation](https://vcpkg.readthedocs.io/en/latest/examples/packaging-zlib/), I don't see anything over-complicated :). (However doing a gui over a package manager would be great)
&gt; Maybe they prebuild a lot of components, or he was talking about unity builds? If it's really only 5 minutes, can we convince Nicolas to give a talk on how they keep build times so low on such a large game? :P There is more detail in [his talk](https://www.youtube.com/watch?v=qYN6eduU06s) (great talk by the way). Actually it's 3 to 5 minutes on Rainbow Six Siege on the developers' workstations, respectively with and without distribution. They use unity builds but it seems that there is no prebuilt components.
The fact that you list build systems that nobody no longer uses (like scons) or cares about (like maven) in the context of C++ and don't list any of the bleeding edge stuff (like `build2`) doesn't reflect positively on the quality of your article. Also, you haven't even mentioned support for C++ modules which is probably the most important aspect one should consider when choosing a build system for a new project.
That makes one of us. Autotools is camel diarrhea. In my experience it works about 50% of the time. Using a gargantuan shell script to query the version of every tool on your system using grep matching is about the worst idea I've ever heard. Of course it breaks when your tool goes from version 1.9 up to version 1.10.
For such types and situations copy-on-write idiom can be used.
&gt; I mean, apparently the cyber security market is on the order of $100 billion. that's what security experts want you to believe. If it was really the case people would rush to fix low-hanging CVEs
&gt; If CMake would replace it's crazy language with Python then a lot of people would look for another build system without crazy dependencies like Python 
&gt; Also, you haven't even mentioned support for C++ modules which is probably the most important aspect one should consider when choosing a build system for a new project. modules aren't going to be there for at least 5-6 years. Unless you work in a big industry, most of your projects will be much more short-lived - a year or two would already be uncommon for the average project.
don't do this please, it always ends in pain
Not even remotely. It's a package manager that can be used with any build system. It has special support for most major build systems out of the box, CMake being one of them, but any build system will work. You use Conan to manage your dependencies, whether they're libraries or build tools. Your dependencies are listed in a `conanfile.txt` or `conanfile.py` file. = https://conan.io/
In your defense, the correct spelling is "in-source builds".
It's not *at all* a build system. It's a package manager.
But in that case you have to heap allocate the object, this doesn't.
My best guess is consistentcy. Everything else in the standard library is in the std namespace, so they probably threw literals in there too. Maybe to avoid confusion for people who would assume something in the library is in namespace std, which I definitely would
No, the lack of attention makes sense. For those writing brand new code bases idomatically in C++ 14, use after free is so rare as to not be worried about. I don't believe I have seen a single case of use after free in any code I've personally written in the past five years. I *have* seen dangling ownership problems in code I've written, so specifically where a `span&lt;T&gt;` referred to memory which no longer exists [1]. They're frighteningly common, in fact. And they're also not detectable most of the time with a static checker, the exact same problem can occur in Rust. For those big multinationals with legacy code bases e.g. my current contract, most have just about heard of clang as being a "new compiler" potentially worth investigating "at some point". They certainly have never heard of clang-tidy, or any of the libtooling or sanitisers stuff at all, and when you explain these fancy new tools to them they are genuinely interested in using them "some day" i.e. at least a decade out from now when they are no longer on a low GCC 4.x series due to the GPL v3. So ultimately those who have heard of a borrow checker don't need it, and those who really need a borrow checker haven't heard of it. Thus borrow checkers for C++ end up stuck in a no man's land in between, which is unfortunate. What I think would gain far more attention from the big multinationals is a runtime checker for `string_view` and `span&lt;T&gt;` orphaning. That's a serious problem, and is going to become far worse with time, and due to its criticality they may just throw developers at the problem until it's done. [1]: I hang my head in shame with this which I wrote into the P1031 *Low level file i/o* reference implementation, and which has been in production use for several years now. Horribly, it usually "just works", and never caused a single problem with memory corruption. It was detected when I was writing the Technical Specification wording, and I realised that the below is flat out wrong as in stack corrupting **wrong**: [[llfio::make_free_function]] io_result&lt;buffers_type&gt; read(extent_type offset, std::initializer_list&lt;buffer_type&gt; lst, deadline d = deadline()) noexcept { buffer_type *_reqs = reinterpret_cast&lt;buffer_type *&gt;(alloca(sizeof(buffer_type) * lst.size())); memcpy(_reqs, lst.begin(), sizeof(buffer_type) * lst.size()); io_request&lt;buffers_type&gt; reqs(buffers_type(_reqs, lst.size()), offset); return read(reqs, d); } 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
thanks
&gt; a year or two would already be uncommon for the average project We are talking about C++, not python. Yout assumptions are wrong.
Yeah it's really neat. Once you add to CXXFLAGS -MMD (emit dependencies for non system header files) -MP (emit dummy rules for headers so you can delete a header without pain), it will write out a .d file, with the same basename as the .o file it's written. All you need then is to include(wildcard *.d) (or something like that). So, basically it's 2 lines of Make to have precise rebuilds: CXXFLAGS+=-MMD -MP include($(shell find . -type f -name \*.o)) I don't believe gnu make sup[ports recursive wildcards, hence the find in there. 
The giantic script is compiled code, you're not meant to read it. And it doesn't require (or make use of) having autoconf installed, so a version change won't break it. 
If you need grep to search for the filename in your build-system, your problem lies very much elsewhere. A build-configuration has exactly no business to be longer than what fits on a screen and should be so declarative that it is very easy to read then.
Never has for me. Having to write out the build-files manually IS pain however.
Yeah, but it isn't even available in arch-linux yet, and I use a script for building that always runs it anyways. The option should also really be active by default.
Meson enables several warnings by default.
I once looked into autotools and decided that plain makefiles were a much superior solution. I ended up writing my own makefile-generator that worked really nice, before I switched to cmake. (Which I still don't like and which does several things worse than my own tool, but is somewhat usable once you make sure to always use `file(GLOB...)`.
You don't have to point to the heap with a pointer.
Yeah, but it REALLY hates wildcards. If the maintainer would add proper support for them, I would probably switch right away. Instead he claims that it would be bad for performance, which is quite a BS-argument, because either Meson is super-slow to begin with (in that case: fix that first) or reruning it every time only for those users who use wildcards would be a very simple solution to the problem.
You discard SCons because it's slow: &gt; I have compiled some projects using SCons like fifteen years ago and I think that I have never seen a tool so slow, ever. &gt; This behavior can be modified but even when using the classical timestamp comparison of the files and applying all available tricks to make the build faster, it’s still extremely slow. But later you're downplaying Meson's focus on speed: &gt; Why not, but what I am actually looking for is a tool that can build my project for iOS, Android, OSX and Linux. Something that just works; speed is a secondary concern.
Looks like I'll have to give it a go then, thanks for letting me know!
True, but in this case it's wanting to take ownership of an rvalue object - it has to store it somewhere. If you don't have a template predicated on whether it owns it or not, your only choices are to always have the storage present in your view, or heap allocate the storage.
Note that the XCode backend is a bit crap ATM (speaking as the person who wrote it). Mostly because XCode's project file format is mind-numbingly horrible.
I get what you mean, but if anything it's inconsistent with the other literals; `100u` doesn't need a namespace import but `100s` does. I know that the former is a core language literal whereas the latter is a library literal, but that isn't really something that a user should have to think about.
I think you need to concentrate on a subset of the packaging problem, and a subset of the versioning problem if you're going to get real market share quickly. In a way which adds considerable value above Conan and all the other more traditional solutions, all of which involve non-trivial work to add them into your build process, work which most people couldn't be bothered doing, and so do not. Specifically, if you made your solution a simple pypi.org clone but for header-only C++ libraries only, one where a person can request "I want ASIO vX,Y and all its dependencies in a single drop-in download file" via RESTful query, then I think you'd see very rapid uptake. You could have a web interface with tick boxes which lets you build a `curl` query, and people could copy and paste that command into their project and bang!, we're done. Because all your dependencies nicely wrapped up into a unity single file download which works with any build system is where we need to get to. It just makes so much hassle just *go away*. And no existing C++ packaging system remotely comes close to the hassle free experience which is `cargo` for Rust or `pip` for Python, which is where we need to get to. C++ is unique in having a multitude of common build systems. That will remain true for a long time to come, and it's a big obstacle for packaging. Until now packaging systems have thus become complex and sprawling to accommodate all the variety, and correspondingly nobody wants to bother with that learning curve. Single unity file dependencies. That's my recommendation to you, or to anybody else wanting to make packaging on C++ hassle free.
Honestly, *even if* `"…"s` allocated (which it shouldn’t) I’d still prefer having a native string literal type over having to invoke a conversion constructor. Virtually every other modern language has dynamically allocating string literals. Your objection seems to be based on a perceived equivalence between “literal” and “non-allocating” but this isn’t given, required or natural at all. The fact that this (more coincidentally than by design) used to be the case in C++ pre C++11 is a fairly weak argument, in my view.
Well, there's slow and "oh my god will it finish in my life time" slow :) My point is that modern build tools (like Premake, CMake or Meson) are already quite fast and there's no gain to claim to be faster. A tool that could automatically handle the iOS build (i.e. building, signing and the providing the provisioning profiles required to build the IPA) would be more of a life changer. Bonus points if it can also handle the build of the Android application.
There's a number of different language-agnostic things to consider here: * "only pull from GitHub HEAD" is the Go model (until soon, with the new "modules" system, formally called "vgo", you don't pull from HEAD, but still GitHub or some other git source) It works, but it has a lot of mutability; HEAD changes quite often. * Central registry, this is Cargo, and many others. The nice thing about this is immutability: you can insure that when I grab version 1.2.3, and you grab version 1.2.3, you get the exact same thing. * Decentralized registry, this is Conan, Cargo in the future, and others. You can pull multiple packages from multiple registries. Additionally, not every single system is purely one of these. For example, while Cargo defaults to the central registry, you can pull straight from git if you want to, and you can spin up a copy of the registry and use it instead if you prefer. On top of that, how you implement the central registry can be different. You may be thinking of [this situation with CocoaPods](https://github.com/CocoaPods/CocoaPods/issues/4989#issuecomment-193772935) from a few years back. Cargo has the index on GitHub, but the actual contents of packages on S3. Etc etc etc. There's a *lot* of variation in this space.
For being open for the future. In future the committee can decide that \`std::string\_view\_literals\` or similar defines \`""s\` to be a \`std::sting\_view\` or maybe a \`std::new\_string\`. If they block this in the global scope this is more or less for forever.
&gt; And they're also not detectable most of the time with a static checker, the exact same problem can occur in Rust. If you have the time, I'd be interested in some more info about this; if you can find a dangling reference in safe Rust, that'd be a huge deal.
&gt; Because it isn't. Meson gets more popular by the day, so now you're left with it's old. Give me a technical advantage. I disagree. Build systems are messy. Dealing with weird, non standard, stupidly implemented libraries on oddball platforms is a huge pain. The only way build systems get robust to that is to bump into enough of the weirdnesses that they end up not having assumptions that are too strict. I'm not a CMake fan: 10 years ago it was terrible. These days, it's working decently well by virtue of having bumped into enough weird crap that it now has the required flexibility without having to resort to too many nasty hacks.
&gt; I've seen cases where make takes a second or two to start compiling while ninja is instant. YMMV. With CMake generated makefiles, sure. With decently written makefiles, I don't think I've ever seen a noticeable delay. I love make, but I use CMake and ninja because the ninja backend is far, far better than the Make one.
You're right, I did not know about build2, and my article is not academic, not even rigorous on a technical viewpoint. See it as a humble opinion piece, I tried to talk about the stuff I have used or at least seriously considered. I could have stopped at Sharpmake to stay focused on the C++ world but I thought it would be interesting to cite tools from other domains to emphasize on the fact that the problem is more global. Also, when one develops for Android and iOS like I do he is not only a C++ developer but also has to handle Java and Objective-C stuff. The dependency management part of build2 seems quite interesting though. Can you give me more detail? Is it some kind of a Conan-like system integrated with the build tool?
Are you quite sure this is a new operator?
&lt;= is already the less-or-equal operator
A shorter move operator would be nice but the coice of glyphs isn't perfect (see other comments) ;)
The problem with that is that the specific namespaces (e.g. `string_view_literals`) are all inline; every standard literal ends up getting imported into `std::literals`. So they can't make changes like that without breaking lots of existing code.
It's entirely possible that Rust is better now. Last time I was writing in it was more than three years ago. But I do remember running into an interesting corner case, it was definitely in safe Rust, and I remember the dev team feeling it was probably a compiler bug and/or a not implemented yet part of the language. This was long before Rust 1.0, long time ago. All that said, Rust does depend on the programmer not lying to it when traversing from unsafe to safe code. Not dissimilarly to when in C++ we take a `span&lt;T&gt;` on something, the programmer is telling the compiler that it points to valid memory, and no doubt we need to come up with a contract specification so the compiler can check that for us both at compile and run time, making use of Richard Smith's fixes to the UB in the C++ object lifetime model currently wending its way through WG21. The long term hope is that in combination with deterministic exceptions, we can point formal verification solvers at C++ and have them complete in a reasonable time. We can then declare portions of C++ to be formally proven to be correct, which would be a big gain for reliable and embedded systems use cases. 
&gt; That said, now you know my reasons for building my own package manager capable of fetching, building and executing native C/C++ dependencies and producing local and reproducible project environments. [I've kinda already done this?](https://github.com/Dekken/maiken/) hooks into git for remote retrieval and can use conan/custom modules
I asked [exactly this question](https://stackoverflow.com/questions/26590165/why-arent-c14-standard-defined-literals-in-the-global-namespace-by-default) on Stack Overflow a couple of years ago. The best answer was that it would potentially allow the committee to define a different `s` suffix in a different namespace later, for example to construct a mythical `std2::string`. 
I think [he does](https://www.reddit.com/r/cpp/comments/8zm66h/an_overview_of_build_systems_mostly_for_c_projects/e2lbks2/] :) But please don't feel slighted, there's no intent to offend anyone. Just sharing thoughts. 
`#define mv(t) std::move(t)`?
&lt;-
&gt; we are moving away from the const&amp; paradigm Are we? Can I have some references to where this is discussed? I was not aware of this
As far as I know there's no implementation of ""s out there that won't allocate for large literals (&gt;16 characters -ish depending on which). I've heard people argue that you should use ""sv if you don't want to risk an allocation, but honestly that makes ""s nearly useless...
&lt;—0
Ah, that makes more sense then, yeah. Shouldn’t be a thing today :) Agree 100% on the “not lying” thing. That verification work sounds very awesome! We’ve been going a pretty traditional route, with all the ups and downs that entails.
Just as long as it's not `:=`. I don't want to lose Bjarne over this. ;-)
It's the same on macOS. The debug information stays in the object files, when you link your application, you just have references to those object files. Later on, you can use a tool dsymutil to collect them into a .dSym file for archiving and debugging.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8zup91/what_to_install_in_visual_studio/e2ljgcm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I guess I have been *using*, and maintaining b2, for a long time now to build much of what I work on (excluding Boost). I find it a bit sad that it's taken so long for other build systems to adopt some of the design elements of b2 though.
Not sure you realize who you replied to. ;-]
Again, I don't know if recent Rust has improved on this, but one of my least favourite parts of Rust was the static borrow checking :). It makes writing Rust tedious, modifying Rust even more tedious, and in general it's for me my number one reason why I don't think Rust can scale out to truly large and old codebases, plus I also don't think it's a good use of programmer productivity to be enforcing things better enforced by automated testing. But as I've mentioned on /r/rust, I would be happy to see me proven wrong.
People hate macros!
These are some pretty deep questions. :-). Thank you for asking them! I don’t feel that I can speak all that well on behalf of the other io2d devs, with regards to your questions/ponderings, and certainly not on behalf of the BSI, but I could note that I’ve worked, or attempted to work, with a bunch of graphics-ish APIs, often in a professional (arguably! 😜 ) setting, often with a fair amount of proverbial hair-pulling, and often wondering why I, or perhaps anyone, wants or needs yet another API for {matrices, vectors, windowing, geometry, drawing} (just to name a few). I realize (maybe), there is a certain irony in this, and do feel it necessary to link to the following web comic: https://xkcd.com/927/ For answers to your other questions, I am willing to bet that if you offered one or more io2d developers, or perhaps just BSI-affiliated persons, a beer (or coffee, etc.), they might be willing to try answering some of these. 😉
C++ modules have nothing to do with packaging end products. Although the committee is working on the package and dependency management problem.
a &lt;- b is equal to a &lt; (- b)
What you refer to seem to explain why he wouldn't care. But then, of course, who knows what's on his mind...
`std2`
Ever since C++11 was released there have been countless articles about passing "sink arguments" by value+`std::move`. Just google for "sink argument passing c++"
That's only if you need a copy anyway; for observation, `const&amp;` isn't going anywhere.
That's what I thought, it seemed a bit strange to not pass const refs if that's all I need anyway
https://www.codesynthesis.com/~boris/blog/2012/06/19/efficient-argument-passing-cxx11-part1/
as I see, all the advancements in c++11 and above are to remove macros as much as possible.
I have the same question with you. thanks!
You are supposed to use glob to get the source list with FASTBuild, then you don't need a rebuild to add a new file since you don't need to modify the configure files. The reason it wants you to use z7 is for the distributed compilation and the cache parts : so that it can get back the obj file and the debug symbols in a single easy to use package that can be put in the cache. The terrible frontend is solved by SharpMake if I'm not wrong. You can practically consider that FASTBuild is a Ninja equivalent tool : syntax suxs to write, it's more focused on running quickly. So you use a generator to write those files instead.
&gt; The [file(GLOB)](https://cmake.org/cmake/help/v3.12/command/file.html#command:file) and [file(GLOB\_RECURSE)](https://cmake.org/cmake/help/v3.12/command/file.html#command:file) commands learned a new flag CONFIGURE\_DEPENDS which enables expression of build system dependency on globbed directory’s contents. This addresses the main drawback of file(GLOB)'ing, right?
https://xkcd.com/1987/
Gotcha. See my edit.
The full rebuilds are at their worst when trying to solve linker errors on a large project. You generally need to tweak the config file to solve them, and if it takes 15 minutes to build your project, what would be an hour task in another build system will take all day with FASTBuild.
That's my definition of "sink" argument, something you're going to retain
I thought that too, until I read this note on the [docs](https://cmake.org/cmake/help/v3.12/command/file.html): &gt;Note We do not recommend using GLOB to collect a list of source files from your source tree. If no CMakeLists.txt file changes when a source is added or removed then the generated build system cannot know when to ask CMake to regenerate. The CONFIGURE\_DEPENDS flag may not work reliably on all generators, or if a new generator is added in the future that cannot support it, projects using it will be stuck. Even if CONFIGURE\_DEPENDS works reliably, there is still a cost to perform the check on every rebuild.
As an experienced C++ developer, I recognise that macros have some uses that simply can't be done in C++ itself. But a lot of C's use of macros is gratuitous in C++, which has language-level features for dealing with the same issues (inline functions, function overloading, etc).
&gt; The target_link_libraries() command now supports Object Libraries. Linking to an object library uses its object files in direct dependents and also propagates usage requirements. This is personally a long-awaited feature. Thank you to everyone who made this happen. This makes using "Modern CMake" possible when I have object libraries.
I understand that; my point is that that limited context is hardly "moving away from the const&amp; paradigm".
How is an object library different from a static or shared library? Is it just all the .o files? 
I'm not sure if manually specifying `std::move()` is as necessary in C++ 17 as it was in the past thanks to the new prvalues, guaranteed copy elision and new/delete elision. In short, for new code, just pass arguments by value and if and only if benchmarking of optimised code says that's a problem, then you might insert some `std::move()`'s. There are further improvements for the optimiser auto-selecting moves tabled for C++ 23, so I suspect WG21 will see no need for a custom operator to do moves. Or, put another way, some of the relocatable proposals define a new relocation operator where it could be argued it really makes sense, and those proposals have to date not fared well at WG21.
Yeah those are a pain indeed. The integrated cache does help a lot for that though because linker errors tend to be fixed by changing the linker flags, not the rest of the build. But really this mostly happens at the initial write/setup phase for your project. Once it's done, linker errors are source code mistakes and you don't need to change the project to fix them.
Lol, he's putting out there Ninja, while Ninja is not meant to be used for describing source rules, but something else better (re-)generate them - like CMake, GN, etc. Also no mention of GN itself, Bazel (blaze), buck, pants, etc. These are clearly the "new" kids on the block with modern declarative syntax (almost compatible between themselves). 
Bah, `target_link_options()` appears to have been cut from the 3.12 release :( https://cmake.org/cmake/help/latest/search.html?q=target_link_options says it isn't there. https://cmake.org/cmake/help/git-master/search.html?q=target_link_options suggests it will be coming in cmake 3.13 instead. Unfortunate.
Yeah, the only use case I've seen is doing self-registration at static initialization time, which sometimes can be a little wonky with static libraries. I'm sure there are other uses.
Is there a reason I should choose this over the C++ Slack or the [#include Discord](http://www.includecpp.org/)
We have members all around the globe, and it's nice to meet people
&gt; I'm not sure It seems there's a lot of uncertainty here. People on StackOverflow would argue that I always need an explicit move. &gt; if benchmarking of optimised code says that's a problem Should I benchmark every place where I expect a move operation?
Off topic, but I was surprised to see a call to `alloca`. The legend lore around the function seems to be that it's not portable and/or is often buggy. Have you encountered any problems using it? 
Or [this one](https://discord.gg/J5hBe8F), where I host a Discord version of geordi, a C++ eval bot. 
I've been part of your community at some point, and I didn't have the best experience.
Nah. The include crowd is very authoritative and bans people who disagree with them or even if they don't like your name. Don't even think of joining if you're not an outspoken 3rd wave feminist and support socialism. The slack is good and has lots of experienced people in it. 
Its use is very common in fixed latency programming for obvious reasons. If you're careful to never allow stack smashing, it's safe and works well across all the major platforms. Well, if you never leak it to outside code like I did above anyway.
Sounds like explicit moves will often be a pessimization then, since it will disable any chance of copy elision. Or is that issue also taken care of now or in a proposal? I haven't been following that area closely.
I see. I think Apple and Google wouldn't like it if such a tool existed, as they want to lock you into their own developer tools.
&gt; It seems there's a lot of uncertainty here. People on StackOverflow would argue that I always need an explicit move. For C++ 11 and 14 compilers I would agree. &gt; Should I benchmark every place where I expect a move operation? Benchmark your finished C++ 17 code under optimisation. If your hot path involves code doing a lots of copies where they could do moves, then explicitly move. And report such an example here to /r/cpp, because such examples are very valuable for WG21 papers targeting C++ 23. 
\&gt; A move operator would make code simpler and elegant. It does not make code simpler nor elegant. It just makes it a few characters shorter, and it doesn't even work in all cases, like passing \`std::move(x)\` as an argument. Utterly useless.
Thanks, it's also what I did (but in only 1 function, your solution is better). I was just wondering if something was in std.
This is equal to `&lt;0`
&gt; For those writing brand new code bases idomatically in C++ 14, use after free is so rare as to &gt; not be worried about. I don't believe I have seen a single case of use after free in any code &gt; I've personally written in the past five years. &gt; I have seen dangling ownership problems in code I've written, so specifically where a span&lt;T&gt; &gt; referred to memory which no longer exists [1]. They're frighteningly common, in fact. For me "use after free" means that somebody dereferenced a dangling pointer, regardless of where it pointed into (heap or stack). And C++14 doesn't really protect you from that. You still have to worry about aliasing and life-time issues as soon as non-owning pointer/reference-like things (including iterators, spans, string_views etc) are involved. To some extend this is a matter of application domain. In my domain, I hardly run into these types of problems. They pop up from time to time. But in other domains it might be more difficult to avoid them. &gt; And they're also not detectable most of the time with a static checker, &gt; the exact same problem can occur in Rust. Uhm, no. This type of problem can never occur in (safe) Rust. In Rust, references are generic over two things: (1) the type of the pointee, (2) the lifetime parameter. The lifetime parameter is always deduced and kind of invisible, but it's there and part of the type system. Dangling references are impossible to create because its lifetime parameter upper-bounds the lifetime of the reference itself and lower-bounds the lifetime of possible pointees whose address you want to store in such a reference. This way, references never outlive their pointees. &gt; So ultimately those who have heard of a borrow checker don't need it, and those who really need a &gt; borrow checker haven't heard of it. Strongly disagree. But maybe your idea of what a borrow checker does doesn't match mine. &gt; What I think would gain far more attention from the big multinationals is a runtime checker for &gt; string_view and span&lt;T&gt; orphaning. That's a serious problem, and is going to become far worse &gt; with time, and due to its criticality they may just throw developers at the problem until it's &gt; done. That falls under "use-after-free", too, IMHO. I think it's very difficult to retrofit complete lifetime safety into C++. I think the key that makes it work in Rust is that it's part of the type system. And Sutter et all want to get away with function "annotations". I don't see how this could work for generic types, possibly wrapping some pointer-like type, for example, the lifetome of a std::vector&lt;std::string_view&gt; object has to be limited to the shortest lifetime of all the strings. How do you make the compiler be aware of this, if lifetimes are *not* part of the type system? I have no clue...
https://godbolt.org/g/dFVyLr suggests that in C++ 20 I should continue to follow my rule: 1. Extern functions should take reference parameters. 2. Inline functions should take value parameters. 3. Value returns should be returned by value. Those rules are good for all C++ 11 onwards. I look forward to the day that I can change them.
Seems to have been cut, [because it's a big feature and they wanted more testing](https://gitlab.kitware.com/cmake/cmake/merge_requests/2033#note_414497).
Yeah that’s totally fair! I see it quite differently, but that’s why we don’t have only one programming language, and why I’m excited to see C++ stepping it up in the safety department. I care about the outcome, better software for everyone, than I do specific languages.
But because it's a library literal you can choose whether to include it or not. The choice is good. Maybe you just don't want to use them, and then they won't pollute the namespace and/or auto-completes.
Same for me. When I just need to cross compile any strange tool, I'm much more happy when I see that it uses autotools instead of cmake.
&gt; I'm not sure if manually specifying std::move() is as necessary in C++ 17 as it was in the past thanks to the new prvalues, guaranteed copy elision and new/delete elision. None of those replaced uses of `move()` in any way. &gt; In short, for new code, just pass arguments by value and if and only if benchmarking of optimised code says that's a problem, then you might insert some std::move()'s. This seems like bad advice. Just always use `move()` when it's what you need to do. Why prematurely pessimize? &gt; There are further improvements for the optimiser auto-selecting moves tabled for C++ 23 [...] What?
`-&lt;`
I think that Rust, more than others, can be thanked for the increased effort to improve memory safety in both C and C++. As I've often said, Rust is a superb motivator.
&lt;3
`-&lt;`. Or maybe `&lt;=`. Alternatively, make moves implicit where the compiler can determine that "It's The Right Thing" ™.
What I would really like is a keyword to move objects, that would remove the variable name from the scope after its use. std::string str = ... std::string str2 = super_move(str); str.size(); //Error, str not found, or something like that
We will just make the move-assign operator `bjarne`.
I still feel that something like `std::move` should not be a stdlib function but rather a language-level feature. The MCU toolchain I use supports C++17, but provides basically no headers. I have to use `(T &amp;&amp;)` there. Maybe a unary operator that implicitly casts to a move reference?
I wasn’t serious and that’s not a single dash. 
&gt; That falls under "use-after-free", too, A better, more generalised, term would be the general class of referring to C++ objects where the reference is used after the destination has ceased to exist. &gt; IMHO. I think it's very difficult to retrofit complete lifetime safety into C++. It's not *that* bad. It's mostly a herding cats problem. &gt; I think the key that makes it work in Rust is that it's part of the type system. And Sutter et all want to get away with function "annotations". I don't see how this could work for generic types, possibly wrapping some pointer-like type. For example, the lifetime of a std::vector&lt;std::string_view&gt; object has to be limited to the shortest lifetime of all the strings. How do you make the checker be aware of this, if lifetimes are not part of the type system? I don't know. I can't speak for others, but I would take the view that the type system is the wrong place to specify or enforce lifetime. It's the biggest failing, in my opinion, with Rust. Where WG21 is roughly heading is firstly to make it possible to be conclusive about C++ object lifetime. Some coordination with WG14 will be needed for this, as much of the ambiguity stems from C and the same issues apply there. WG14 have expressed warmth towards this coordination to date. Once it is possible to be conclusive about object lifetimes, then a runtime sanitiser is the next obvious step. So a lifetime checker of the same mould as the thread sanitiser. I'd assume those sponsoring LLVM will be the likely implementers, but maybe Microsoft may surprise us again as MSVC's internals are very considerably more modern than they were. 
I'd rather see a unary operator that effectively casts to a move reference. `m_name = ^name;` or something. Where it would be defined roughly as: `template &lt;typename T&gt; T&amp;&amp; operator ^ (T &amp;val) { return (T&amp;&amp;)val; }`
If C++ were to get fully-functional user-defined attributes and annotations, we could eliminate almost all uses of macros. Give me a built-in that can call an external program and insert the stdout. Be useful for gamedev and embedded.
&gt; None of those replaced uses of move() in any way. The optimiser, when inlining code, can elide copies going into a function and thus eliminate the call of the move constructor. &gt; This seems like bad advice. Just always use move() when it's what you need to do. Why prematurely pessimize? For inlined code, value semantics, always, unless benchmarking says otherwise. The compiler vendors have repeatedly given this advice for multiple years now.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8zwe7x/help_with_understanding_a_problem/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Pre-C++11 the recommendation for arguments that are going to be retained (i.e. sink arguments) is "take by `const&amp;`". That's what I assume the "`const&amp;` paradigm" is referring to. That is not the case anymore post-C++11.
This is a particularly silly use of a macro as you can achieve the exact same thing with a function: template &lt;typename Target, typename X&gt; void mv(Target&amp; target, X&amp;&amp; x) { target = std::move(x); }
&gt; I'm not sure if manually specifying `std::move()` is as necessary in C++ 17 as it was in the past thanks to the new prvalues, guaranteed copy elision and new/delete elision. Guaranteed copy elision doesn't have anything to do with turning an *lvalue* into an *rvalue*, which is what `std::move` allows you to do. --- &gt; In short, for new code, just pass arguments by value and if and only if benchmarking of optimised code says that's a problem, then you might insert some `std::move()`'s Terrible advice. If you have an *lvalue* and you want to turn it into an *rvalue*, the compiler will not help you. You need `std::move`. 
&gt; The optimiser, when inlining code, can elide copies going into a function and thus eliminate the call of the move constructor. Yeah, but you're not calling the move constructor if the thing on the right hand side is not an *rvalue*. The only way to call the move constructor is by passing an *rvalue*. If you have an *lvalue*, you can turn it into an *rvalue* with `std::move`. --- &gt; For inlined code, value semantics, always We agree on this. Using `std::move` is not against value semantics in any way. 
Your own example is proving you wrong, as it's calling the copy constructor of `Foo`. Change it to: func2(static_cast&lt;Foo&amp;&amp;&gt;(v)); And you'll see that the move constructor will be called instead. https://godbolt.org/g/gbS9vQ
Can you show me an example of code where removing a correct explicit `std::move` invocation results in better codegen in C++17 and in worse codegen in C++14? 
No, it's correct. I was checking to see how much reordering and copy elision occurs in C++ 20 when the compiler cannot see side effects of external function calls.
I honestly would just like WG21 to accept the fact that moving and fowarding are very common operations and provide shorthand notations. Just create some unique backwards-compatible keywords (e.g. `@move` and `@fwd`) and allow usage as follows: a = @move b; a = @fwd b; 
I don't get it. The generated assembly shows a call to `Foo(const Foo&amp;)`, which is suboptimal as `v` could be moved. Moving `v` results in a call to `Foo(Foo&amp;&amp;)` instead.
User-defined unary operators.
You're missing the point. The point is that *don't use `std::move()` for calls to inlined code*. It may inhibit optimisation e.g. if you move into a function which is inlined, the compiler may have to terminate lifetime when the inlined function ends instead of using the original in the caller, which gets used again later on. None of this is my advice. Watch any conference talk by Chandler on value semantics. Feel free to disagree with *him* if you like.
The issue I have with that is the lack of explicitness. Also would not work for forwarding
Oh sorry! I hope your dash accept my apologies. Then I guess that you have a variable named `—0` in your code, witch is totally valid ;) And I wasn't serious either. The whole thread made me laugh.
&gt; Terrible advice. If you have an lvalue and you want to turn it into an rvalue, the compiler will not help you. You need std::move. No, you're missing the whole point of why value semantics to inlined code is the best default choice. When you type `std::move()` you *constrain* the compiler into interpreting and behaving in a certain way. Not typing `std::move()` when calling inlined code gives the compiler more freedom to optimise and reorder to give you the best code. Now don't get me wrong. If a function takes a rvalue ref, then you must move into it. But for calling inline functions which consume values, always pass values, unless benchmarking for your particular compiler version says otherwise.
I remember attending a few talks by Chandler and I honestly do not recall this. I would really like to see an example of this in action. It doesn't make sense to me intuitively, because... &gt; if you move into a function which is inlined, the compiler may have to terminate lifetime when the inlined function ends instead of using the original in the caller, which gets used again later on ...moving an object does not affect its lifetime. The destructor of a moved-from object will be called. Moving a `Foo` instance into a function taking `Foo` by value merely changes whether `Foo::Foo(const Foo&amp;)` or `Foo::Foo(Foo&amp;&amp;)` will be invoked. What does that have to do with lifetime?
A move is inferior to doing nothing at all. Not telling the compiler to move lets it choose with more freedom. In the godbolt example above, because of the calls to functions without unknown side effects, you are correct that you need to move to get better efficiency. But for inlined code, things could be very different. Best to trust the compiler's optimiser until you have benchmarked that you should not.
This is what I am talking about: https://godbolt.org/g/WsKgU5 Your posts make it sound like you are suggesting that line 18 is now bad practice, and that line 13 should be preferred. I'm confident that's not good advice, but I am happy to be convinced otherwise.
&gt; None of this is my advice. Watch any conference talk by Chandler on value semantics. Feel free to disagree with him if you like. Can you show me where he said this?
does it worth with visual studio, ninja, and make? For most people I think those are probably the only ones that matter
You already make that choice by `#include &lt;string&gt;`. If you've included the string header, I'd argue that an auto-complete result for constructing a string literal is quite relevant.
There could be an unary operator as well, like foo(&lt;==x)
You will never get this in C++. ``` std::string str = ... std::string str2; if (something) { str2 = super_move(str); } str.size(); //What should happen here? ``` The Rust language works similar to what you want 
Looks like you're right and I am wrong: https://godbolt.org/g/EAggKH Flip the `USEMOVE` macro and see value semantic optimisation not occur at all.
Looks like I was wrong, see below for godbolt example showing moves substantially beating value semantics.
&gt;I have seen dangling ownership problems Just to clarify, in my use of the term, "dangling reference" bugs are "use-after-free" bugs, and, when completed, the lifetime checker should catch them. Regarding your example, I'm not sure what the Core Guidelines' position on the use of `alloca()` is, but in general, returning a `span&lt;&gt;` (or any type that is or contains a pointer/reference) that references a (stack allocated) local variable or array should be caught by the lifetime checker. You know, when it's eventually completed.
How about x &amp;&amp;= y instead of x = std::move(y)?
&gt; Writing code that is resilient upon errors has always been a pain point in all languages. Exceptions are the politically correct means to signal errors in C++, but many applications still resort to error codes for reasons related to ease of understanding, ease of handling errors locally, and efficiency of generated code. &gt; This talk shows how a variety of theoretical and practical artifacts can be combined together to address error codes and exceptions in one wholesome, simple package. The generic type Expected T can be used for both local (error-code-style) and centralized (exception-style) manners, drawing from the strengths of each.
Static libraries for pure organizational users can be inefficient. You have the tool chain copying all your object files into a library then reading that. Hurts build times on slower or congested drives, and wastes space. The later was a big problem for my previous job, where any one branch's build tree could take 150+ GB, about a third of which was library files that just duplicated object files. It was difficult to have multiple branches checked out at a time, and in-place branch switching rebuilds were just to show to be tolerable. There's also some things with Windows DLLs built from collections of static libraries that can be a pain.
Or you can implement `std::move` yourself and use that.
And instantiate that template a million times.
Because it's so much harder to install Python than to install CMake? Please...
That would still require `(T &amp;&amp;)`.
In the implementation, yes. So?
So, it doesn't eliminate `(T &amp;&amp;)`. I'd also rather not reimplement all of the stdlib headers, and there is effectively very little gained by using `std::move` over `(T &amp;&amp;)` in this context.
Good old Xcode 😓 Thank you for your effort on it, regardless!
&gt; I have seen dangling ownership problems in code I've written, so specifically where a span&lt;T&gt; referred to memory which no longer exists [1]. How is that fundamentally different from use after free? In both case the problem *is* referring to memory/object which does not exist anymore.
I didn't say c++ is complete, I said it's better to have a feature implemented with the language. If the current std::variant is not enough (the others have nothing to do with sum types), then it should be in the language. &gt; I was mocking you logic, which is illogical. It's not illogical at all. Given the amount of objects managed via pointer in a c++ program, the changes that a null ptr creates havoc is very small. I have been programming with c/c++ for over 20 years and with Java for at least 15 years, and guess which language has the null pointer problem: yeap, it's Java, where something that is should not be null appears to be null comes up a lot more than in c++.
=8^)-
Frankly I don't understand at all why there should be an undefined reference in the first place. Is it because a variable of a dllimported class is itself considered dllimported or what?
But `X` can be deduced to be a const lvalue ref, and `X&amp;&amp;` in turn collapsed into a const lvalue ref, making `x` immovable.
&gt; I can't speak for others, but I would take the view that the type system is the wrong place to specify or enforce lifetime. It's the biggest failing, in my opinion, with Rust. That is an interesting point of view because I have the feeling most people consider it one of the most crucial value proposition of Rust; and with the evolution to non-lexical lifetimes it even has proven that the model is able to evolve to more convenience (by allowing more constructs where there is no risk of lifetime issue) without sacrificing any bit of safety. The C++ approach *has* to come from the opposite place, going from a free-for-all but dangerous way to availability and maybe even one day enforcing of more structured constructs. But I have very low hope for the enforcing part, because for now the end result is brittle, and remains full of risky stuff even when using only state of the art brand new features (you can have and deref dangling refs by merely using string_view "incorrectly", where incorrectly in question might even be buried 13 templates away and all of them are seemingly sensible when taken individually), and mainstream compilers are not really going to help you with that, probably even on the contrary (if they detect that you did some shit, they will half of the time conclude that this is an "impossible" code path and "optimize" accordingly by pretending the conditions that can lead to it are always false -- hilarity then ensues) So obviously, there is a kind of radicality in enforcing lifetime safety in the compiler, but maybe even only if the reference is C/C++? And so I welcome it, because they do not have a particularly good track record of avoiding those issues, and merely making the hypothesis that developer are not going to write bugs has not really resulted in those disappearing, particularly nasty ones having a potential security impact. So back to the "place to enforce lifetime" opinion: what would be the alternative?
Unless implementations enforce that rule, it'll be ignored just like the double underscore or underscore-capital rule is routinely ignored in many code bases. :(
You referred to "literals" and so my example is of a "list literal": a value written literally in source rather than computed or read from input. Why should strings be able to be constexpr but lists shouldn't, so that a string `"abc"s` is "horrid" but `list{1,2,3}` isn't? It seems like you're asking the user to distinguish between literal syntaxes based merely on whether they happen to be in section 2.14 [lex.literal] or not. I think that's unnecessary and quite undesirable. One of the 'design ideals' of C++ is to enable user defined types to match the functionality of built-in types. You seem to want to do the opposite and maintain this distinction where user defined types aren't allowed to do certain things. Frankly, I would go the other direction, along the lines of P0784 so that you can put constant `std::string`s, `std::list`s, `std::map`s, etc. in programs' data sections. In the meantime there's nothing horrid about the fact that user defined types are able to use various literal syntaxes. If you don't want allocation in certain places then don't do it. If that means you avoid the new syntax added just for user defined literals, that's a far better alternative than not having user defined literals.
That's basically impossible to prove without very advanced analysis. This is why move return of lvalues only works with the explicit `return foo`. And that final return is the only place that's safe. The reason is that you can make aliases of a value, with someone as simple as: auto&amp; alias = value; auto moved = std::move(value); cout &lt;&lt; alias; // uh oh! Even a "simple" use analysis pay can be trivially defeated by aliasing into external modules or the like. Basically, it's only safe to automatically move from values that the compiler is 100% sure can never be used again, which is only true for xvalues and `return foo`, more or less.
and no tup
As someone who wishes to transfer their 1000 file project to cmake this is very dishartening. Guess I got to build a python script to produce the cmake for me. No way am I going to sit there and enter all those files manually. Having to do so is biggest gripe I have with cmake. Entering the files manually is a huge waste of time. I would much rather have it function like git with an ignore file.
Shouldn't the `-name` glob be `\*.d`? You're supposed to be including dependency files that contain dummy rules, not object files themselves.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8zy0yu/transcriber_ag_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; It just makes it a few characters shorter How would you like that instead of int *ptr = &amp;x; you would have to write int *ptr = std::address_of(x); 
Just use glob. It's not a big deal to rerun cmake manually when new files are added.
This would not compile? But yeah, at this point, it is more reasonable to use Rust than to attempt to transform C++ into it... 
should we make std::move obsolete then?
That wouldn't be a dealbreaker. You can always write a wrapper with a shorter name yourself if like. Adding a language feature for the sake of saving a few characters is always a dumb idea.
Reported as a bug to both GCC and clang: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=86573 https://bugs.llvm.org/show_bug.cgi?id=38213 
Good question. I just tested the 3 most common compilers (Clang, GCC, MSVC) and they all warn when declaring a literal that doesn't start with an underscore.
Not at all. Sometimes you really must move e.g. a function which only accepts an rvalue ref.
Topic begins at 34:20
In the last line of your code, the lambda `[](int e) -&gt; bool { return (e % 2 == 0); }`'s type is some type unique to this specific lambda. Although it is implicitly convertible to `std::function&lt;bool(int)&gt;`, its type is not `std::function&lt;bool(int)&gt;`. So during overload resolution, it finds that your first function template, `template&lt;typename T&gt; void print_content(T func)`, is a better match than your second function: `T` can be replaced with the lambda's type. So you're actually calling the first function, not the second. What you could do is change the first function template to `void print_content(std::function&lt;void(int)&gt; func)`. This way, your second call to print_content will find that your second function is a better match for the lambda than your first function.
Thank you for the explanation. I would expect some warning from the compiler in these situations. Looks like programmer must take care of these problems by himself.
I've never used Bazel nor Conan, so there's not so much I can tell about them. Also, as others have already pointed, Conan is a package manager, not a build system. I hear mixed reviews about it, which make me a bit reluctant to use it. I would love to have feedback about its usage for Android or iOS projects though, especially on how to include Boost with it since it is a pain to compile for these targets.
You seem to end up with a class that is conditionally owning. This is a recipe for disaster. First, reference member variables are already scary because you can so easily have dangles. You should try to avoid them on the first place. Second, making the ownership conditional makes it even harder to reason about what's going on. Feeling like you need to do this at all is almost certainly just an XY problem. Redesign ownership/reference structure so this simply isn't necessary. It's ironic because the author is described as looking "clean" code but there's nothing clean about this technique at all.
I don't think that the existence of a toolchain that lacks standard headers is a good argument for putting things in the language.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
That would ruin SFINAE.
Okay, once again, thank you all for your opinions. I will certainly look into the suggested solutions in detail. From what I can tell, Vcpkg, which I previosly didn't know about, looks very promising but its way of interacting with other projects (based mainly on CMake) still feels very unclean and clumsy. Somehow I still feel that things could be much smoother and it bothers me greatly. Also, I am very glad that /u/ZaitaNZ, /u/GPMueller and /u/Dekken_ has shared their efforts that happen to somehow intersect with my project. I am absolutely going to go through the source files (if available) to see how you had gone about solving the problem. I am very interested in different approaches. Oh and thank you /u/14ned for sharing valuable insights and /u/WHEEEEEEEEEW for trying to convince me no to go down this road, after all, that has been the whole point of my post. I might actually still try to implement this, just for the sake of seeing how it turns out. And please, don't take this the wrong way, I am not saying that all of the other tools are bad and the way I intend to go about it is better than the others. I just... don't really feel that comfortable with the provided solutions... they feel really unpleasant. Maybe the complexity of the current utilities is only the logical consequence of the unspeakable complexity of the projects themselves but still... can't we do better? I wish we could. Also, I might just be too *green* in this area to understand why such complexity is needed and should probably learn much more about it before complaining. But trust me, I have done quite a big research on all of the existing build tools and tried to consider all of them but they just feel really off putting. I don't want configuration files written in Python. I don't want to write a separate CMake file for each of my non-standard dependency... Well, see you in my next rant post on C/C++ build tools :)
Hey, I am saving your post for reference and will surely use what you have shared, thanks for the insights.
&gt;You referred to "literals" "Literals" as in std::literals, as in what the post (that we are in the comments of) was _about_. &gt;Frankly, I would go the other direction, along the lines of P0784 so that you can put constant std::strings, std::lists, std::maps, etc. in programs' data sections. I would love it if the ""s literals resulted in an entire std::string being in the data section, with no runtime allocation, but they don't - they result in the raw data being the the data segment, and then _copied_ into the std string object that the udl returns (whether into the short string buffer or a heap allocation) at _runtime_. I think hiding such a potentially expensive operation behind a single character is a design mistake. Most of the std literals are fine - the chrono ones don't allocate, the ""sv one doesn't allocate... It's just ""s I object to. It's not as "literal" as the others - it has a hidden cost which is very against the spirit of C++.
No problem. Happy to elaborate more if you have any questions, PM me any time. I’ve been working in several ecosystems on this kind of thing, so I’ve seen a lot of stuff...
How about not having to type `std::move(...)` every time you perform a relatively-common operation?
&gt;You referred to "literals" "Literals" as in std::literals, as in what the post (that we are in the comments of) was about. &gt;Frankly, I would go the other direction, along the lines of P0784 so that you can put constant std::strings, std::lists, std::maps, etc. in programs' data sections. I would love it if the ""s literals resulted in an entire std::string being in the data section, with no runtime allocation, but they don't - they result in the raw data being in the data segment, and then _copied_ into the std string object that the udl returns (whether into the short string buffer or a heap allocation) _at runtime_. I think hiding such a potentially expensive operation behind a single character is a design mistake. Most of the std literals are fine - the chrono ones don't allocate, the ""sv one doesn't allocate... It's just ""s I object to. It's not as "literal" as the others - it has a hidden cost which is very against the spirit of C++ IMO.
What about: Object::Object(Other bar) : _bar(bar) {} or Object::Object(Other bar) { _bar = bar; }
Sorry, I did not know it.
&gt; Also, probably add a few more macro features so macros can do things like "do this ten times". Guys, /u/Ameisen has never seen [Boost.Preprocessor](https://www.boost.org/doc/libs/1_67_0/libs/preprocessor/doc/index.html)! ... should we tell him?
I guess it is time for ISO to define a new keyboard, at least for developers. Current keyboard is a huge obstacles for programming. Suppose we have more keys in the keyboard, the programming language has more choice.
I did that exactly for my project (well it was C# not python but close enough). Worked well enough for me and once it was done, adding any additional files was not much of a hassle. Def my recommendation over using glob, but then again, I am really not a fan of using glob so I am biased.
it finally supports range-based for-loop ! 
&gt; "Literals" as in std::literals, as in what the post (that we are in the comments of) was about. But in that case you're talking about user defined literals which have _never_ been been guaranteed to be constant. They're a new feature which from the very beginning has allowed allocation. So why would you say they "should be a constant?" &gt; it has a hidden cost which is very against the spirit of C++ IMO. Do you also object to the "hidden cost" of copying arguments into parameters? Or all the hidden costs in constructing many user defined types? Like I've heard C developers complain how C++ container types all 'hide' allocations from you instead of putting a `malloc()` in plain sight like decent code should. `""s` is just like everything else: it's cost is 'hidden' because it's new, but eventually it's not new and it's cost becomes known so it's no longer hidden. Which is to say it was never really hidden in the first place, and it's certainly not in opposition to the spirit of C++, IMO.
It's an interesting talk, but around the 33 minute mark he says you don't want to have raw pointers in class definitions and to use shared\_ptr or unique\_ptr instead. This post by Howard Hinnant: [https://stackoverflow.com/questions/38780596/how-to-handle-constructors-that-must-acquire-multiple-resources-in-an-exception#38780597](https://stackoverflow.com/questions/38780596/how-to-handle-constructors-that-must-acquire-multiple-resources-in-an-exception#38780597) gives an alternative approach that I'm using i[n my code](https://github.com/Ebenezer-group/onwards/blob/master/Buffer.hh) around line 509. 
you could split the sourcefilenames into a separate file, and include that. Allows you to rerun the script, and still have fast builds
I wasn't aware that Boost was part of C++.
My day has been made. Just as long as somehow they haven't weaseled .begin() .end() into the syntax. 
something
Doh! I was looking forward to that one.
Imho going worked well enough already before 3.12. And even if you go brute Force and re-run cmake Everytime it tends to be negligible compared to the actual build times.
You should take a look at waf, if you like python for build scripts but dislike the slowness of scons.
How is compiler support on the previous version across MSVC, gcc and clang, and any roadmap for compiler support for 5.0? :)
Yes, I really want good support for wild cards. One of my projects has a directory containing optional 'drivers' for particular circumstances. Users can augment this set with their own or remove some of the default ones if they don't like them. When a build tool lacks support for wild cards, then an extra step is required: running a script to generate the build description so that it incorporates each of the drivers. That script is more difficult to maintain than a wild card in a build script and requires more skills from maintainers who have to understand both the scripting language and the build tool language. The language of the script is an additional dependency.
I can't wait for http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf to be a thing
boost is c++'s director's cut
In my example I used grep to find project file at first, not only to navigate inside it.
I'm still wondering wether or not this is a joke following the 2d meeting or if this is actually a serious proposal.
How do you know when new files have been added? Do you just wait for link errors, assume somebody has added files and rerun `cmake`?
This paper not even touches the surface of what would be required for anything close to that to happen. I had to check my calendar again to be sure it wasn't April 1st. Upvoting for effort trolling.
What if I `#include &lt;foo/bar.h&gt;` which includes another header which includes `&lt;string&gt;`? Did I opt into that? ;-] Without modules it simply doesn't work that way.
I wonder how it would work to implement a unified memory allocator, like one can do with cudaMallocManaged, because I really love this unified memory model, where you don't need to manually copy things between host and device anymore. Or will one still have to do mappings etc in OpenMP around areas where computations should be offloaded?
Such as?
In my opinion it would be better that projects which are too weird are simply not supported, forcing them to improve their deficiencies if they want people to use it. Sometimes the weird is a necessity, but I'm sure that's a very rare thing.
I think complaining about a dependency on Python is crazy - it's widely present on systems already by default, but also there's certainly no benefit of having to install CMake over having to install Python.
No no, you want [PO4116R0](https://isocpp.org/files/papers/PO4116_emoticons.html).
Didn't you write that you also never used Meson?...
The second they started injecting JavaScript into their example I nope'd out of there
https://youtu.be/xnqTKD8uD64?t=1h3m43s
Should have implemented a subset of C++. C++Script.
I disagree with your last statement. Syntactic sugar is important. One of the things I love about C++ is that I don't have to type `.equals()` or `.clone()` everywhere to get value semantics. Value semantics is deeply baked into the language, so the language supports convenient syntax for using it. I think it's very unfortunate that since C++11 we have to fill our code with noisy function calls just to move or forward things (or heap-allocate stuff, for that matter). Move operations are just as fundamental as copy operations, and they deserve some syntactic sugar IMO, though I don't know what I'd want that syntax to look like.
Isn't there a C++ to JavaScript compiler already?
MSVC is still at OpenMP 2.0.
Not awful, but looks too much like it should mean logical-AND-assignment, and it wouldn't help when moving into a function argument.
\-&gt; emscripten
[Emscripten](https://github.com/kripken/emscripten)
So? You'd have to copy in that case anyway.
Yeah, but Java gets their own unrelated scripting language. Now it's our turn.
You really hate whitespace.
lol I assume that's the reaction they were going for?
wat
When wouldn't you know when new files are added? It seems odd that the programmer wouldn't know that. 
Ah. Presumably you’re working on solo projects. I guess globbing would work in such a scenario. On even a small team, colleagues are going to be creating, moving, renaming and deleting files pretty regularly. I guess one could just adopt a policy of manually running `cmake` after each pull. Personally, that still seems like more work than maintaining a `CMakeLists.txt`, but to each their own
Ah personally i regenerate my cmake cache after every pull out of habit anyway. I like knowing it's up to date at all times. I thought you were talking about solo projects.
I think this kind of makes sense... it's not like standardizing anything more complex that doesn't just throw the problem over the wall is ever going to happen.
Yes, it's all the .o files. The target will not result in a file, but rather its just a logical unit that represents a grouping of object files that can be linked to something else.
I also like fast builds. In this case I don't have to include &lt;memory&gt;
I'm shaken
lld supports a similar thing with "thin libraries" that store the path of the object file rather than the object file itself, and they give a noticeable speed improvement to the edit-&gt;compile-&gt;link-&gt;run cycle even on a project that's minuscule in comparison to that. Getting similar benefits on all platforms just from updating to a newer cmake is pretty exciting.
i guess it's supposed to be funny, but i feel violated. 
Why not standardize networking so you can make a local server with it and fire up a real browser to see it?
It sould be based on Smalltalk.
With a touch of INTERCAL.
Just 5 more years! ...I hope.
He said "unrelated to C++"
`std::move` is a nice name for a language-level feature (cast to rvalue reference type)
&gt; None of this is my advice. Watch any conference talk by Chandler on value semantics. Feel free to disagree with him if you like. "*I'm the authority! But if I'm wrong, he's the authority! Either way, just listen to authority!*" More Fallacies from Niall™ coming soon; proper citations sold separately.
I don't see how `@move b` is any better than `move(b)`
So? Template instantiation is part of the language. If you are trying to imply a performance penalty then I doubt that claim.
This puts my config to shame. I need to organize my config like yours.
KDevelop is also great. I don't use it anymore, but has nothing to do with it not working well.
I would normally expect it to be a unary operator or keyword that does so given how core the concept is.
I think we shouöd go farther. Std::unix is where we should be now!
There are a lot obvious problems with this and some subtle ones too (for example, stdlib implementations historically have not updated as frequently as is needed for a web platform to be secure). The C++ standard would be much better served by approaching these desires by focusing on a solution to package management (yes, even if this seems hard). Then any code that wants to use a webview can bring it in from a library. Ditto for 2d graphics. This is just clearly the wrong direction to be headed in. 
What I worry about is that the standardization process allows vendors to work together to share. Outside of the standardization process anti collusion laws can keep them from effectively working together so we can’t get the same level of support except through the standardization body. So I think leaving it as an optional TS can get the best of both worlds.
What I worry about is that the standardization process allows vendors to work together to share. Outside of the standardization process anti collusion laws can keep them from effectively working together so we can’t get the same level of support except through the standardization body. So I think leaving it as an optional TS can get the best of both worlds.
pls no
frankly, if it's a joke, it's not a very funny one because people in the std committee will still have to spend time to review it
What's wrong with that code? That's also roughly how I lay my code out. Are you using too small fonts perchance?
So the intention is provide web contents from C++ program and interact with it. If that's the case, I think it is easier and useful to provide embedded HTTP / WebSocket server as standard. nodejs community has many sophisticated frameworks to make that happen. Also process handling facility (like boost::process) would be useful to kick start Web browser and other myriad of usecases. If we want to interact with Web technology, I think we should do it through a network rather than embedding web browser. I think that is more straight forward, scalable and useful.
Please type `UriSchemeHandler` instead of `URISchemeHandler`. Please use `std::string_view` instead of `std::string`. This proposal shows us that we just need package manager.
Lack of time or willingness to prove is not the same as inability to prove. Though, as mentioned below, in this case I was simply wrong.
Implementation is so minimal and uses wxWidgets. Definitely must be a joke.
You should try to keep in mind that lack of willingness and inability are indistinguishable to everyone else.
I don't think that the case for more than a minority. People aren't stupid. If they think me wrong, they challenge me. It may then turn out I was wrong, I found a godbolt proving I was wrong, so then we all gain from the discussion. I personally think that a good thing. I don't care about appearing infallible through silence like some do. I think you should fail productively instead. And we would not have reached that godbolt proving I was wrong if I had not made the off the cuff statement. It's all good.
on Windows I just \&gt; dir /b \*.cpp Copy, Paste, ???, Profit!
He'll be giving this talk at CppCon.
Sorry, I worded this wrongly, I'm sure they all could be built with meson, and many libraries are header only, so the lib itself doesn't need to be built (I still prefer to track them via cmake's dependency management) Anyway, here is a handful of libraries from the top of my head that I am using or have used in the past. - catch2 - ASIO - cxx-opts - date -zlib - ranges-v3 - boost - a couple of internal libraries More importantly: Can meson use packages from vcpkg? (Honest question, I haven't checked)
There is an initial idea to make this idiom more friendly to use. Regarding the standard types, you should be able to call them like this `std::optional&lt;std::string&gt; opt(in_place: 3, 'A');` `std::any(in_place&lt;std::string&gt;: 3, 'A' );` Note that `in_place` does not have to qualified. Also note the colon (`:`), which, in away, indicates a sub-list of arguments. The idea is to also be trivial to create constructors like this, which can be alternative of static functions, used as "named constructors". `rect(center: point, size);` `rect(bottomLeft: point, size);` Read more here [https://groups.google.com/a/isocpp.org/d/msg/std-proposals/tPtdQE2GXb0/4OjT5Z4pBQAJ](https://groups.google.com/a/isocpp.org/d/msg/std-proposals/tPtdQE2GXb0/4OjT5Z4pBQAJ)
I've seen cases where it took over 10 minutes to start compiling with make. Ninja? 1s. I didn't discover ninja because I read about it in a blog post; I actively went looking for a make alternative because it was so ridiculously slow (at the time, 8s for no-op build).
The issue with automated testing, is as you refer in another comment, typical enterprise developers just ignore those tools. One doesn't get to ignore the type system. Which is the main reason why I never liked C and always favored C++, even when coding on MS-DOS back in the day.
It would be nice to see the best of both worlds. Something that lets you choose how the expected is handled. eg `int|throw() foo math(...)` Which lets the throw or return type continue down the stack till it is caught, like normal exception handling. vs int|error() foo math(...) if(foo.error()) { return(0); } Or something like that, so you can choose if exceptions are local or not. This would make the code more explicit removing run time surprises. This would also open the doors bringing modern C++ to the embedded world. The std library can now be supported. win,win,win,win
That's a good trick, but if you're only deleting things in your destructor and not anything more complicated, unique pointers are superior, no?
If enterprise developers ignore the tooling, that's on the enterprise. I have worked for clients where not only can't you commit anything to trunk which isn't all green, there is also a peer review to ensure that the committer hasn't cheated to make the tests go green instead of solving the fault. There is also weekly, or even nightly, Monte Carlo soak testing of the code under the sanitisers and via clang tidy of a unity build, so the static analyser can see side effects. Anybody who did a commit the previous day/week and the tests fail are dealt with first as the highest priority item in the morning standup. No other sprint work is done until the tooling goes green again. Equally I've worked for clients where the unit tests haven't passed in a decade, and in some cases *haven't even been executed* in some years, despite shipping a mission critical product. Ultimately it comes down to how much the enterprise cares about quality vs turnaround. &gt; One doesn't get to ignore the type system. Of course one does. It's called C casting. Happens all the time, and everywhere. Even I write C casts into my own code, relying on clang-tidy -fixes to rewrite them for me into the correct static/reinterpret/const casting. I know I shouldn't be so lazy, but C casting is much faster to type and not have to think about. I'm hoping one day that clang-format will auto-expand C casts into appropriate casting via an option. 
The current hope is that C will have facilities mapping directly onto C++ deterministic exceptions, so in your C++ code you will be able to mark a function as `throws(E)` to indicate you wish propagation-if-unhandled, or you can choose C22 `_Fails(E)` to indicate you wish a compile-time-error-if-unhandled. Both languages would have a `catch(expr)`/`_Catch(expr)` operator which converts a throwing/failing expression into a C22 `_Result(T, E)`, from which a `std::expected&lt;T, E&gt;` or `boost::outcome::result&lt;T, E&gt;` could implicitly construct. Before anyone asks, that paper isn't public yet, though an earlier draft can be found on std-proposals. WG14 have asked for the `_Fails(E)` syntax instead, I have promised it to them by the start of August. 
Hal Finkel is a highly respected senior member of WG21 with a CV longer than several of us put together. It's no joke.
That's... worrying.
You are aware of [Networking TS](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4734.pdf), right?
Look great! I like the direction this train is headed in. It addresses one of the few complaints I have about C++.
Is this talk related to that proposal?
This should not compile. If a variable is "super moved" (need to find a better term) it can't be read later in the same scope or any outer scope. But I think it should be completely fine to read it in a parallel scope, link if there was an "else" statement to that "if". It could be interesting to be able to "reboot" a variable after this operation by assigning it a new value afterwards, but this may complicate things too much.
Given the 1% answer to Herb Sutter's question at CppCon to the audience regarding who uses such tooling, it is pretty clear where the "quality vs turnaround" pendulum swings to. As for C casting, it is yet another language feature to ease copy-paste from C with the expected consequences.
Effectively, `move` is a keyword that is scoped in namespace `std`.
I’m on mobile, list of comments may grow as I read the article... 1) c++ volatile != java volatile You already use a mutex, so you’re good to go (circular queue)
I think some background has to be given. It's easy to think this is a ludicrous idea. However, there has been a strong push for a "simple 2d graphics" library in the standard. There is nothing simple about graphics. And it would take years (a few decades really) to get to some place where that library would be of any actual use, beyond "hey, look, this is cool, I have drawn a square". Especially, because of text, fonts rendering, even loops, image formats, inputs etc... then people will want 3d, audio and piles of piles of cool stuff that the committee has neither the time, will or expertise to write wording for - let's not speak about the burden for the 20 guys that actually write most of the standard libraries. And if we were to do all of that, we would end up to something rather close to a web stack, but worse because people spend decades bringing browsers to the maturity level they have today. So what this proposal offers is to offload some standardization effort to existing, battle-tested standard and implementation ( aka web techs ) instead of reinventing the wheel. `std::web_view` would serve the "educational toy library" goal, while actually performing better as a renderer (because web browsers rely on GPU which is something the 2d graphics proposal fails to acknowledge). It's about saying "These guys over there did the work, they know more than us, maybe we can use that". And then the c++ standard can just refer to the w3c/ECMA standards and call it a day. It would also be less of a burden for the implementors since the libraries already exist to do that on most platforms (either WebKit (Linux, apple), edge(Microsoft), chrome(android))).
O..o This is getting worst every year.
`std::plan&lt;N&gt;` with an instantiation for 9 provided 
[https://wrapdb.mesonbuild.com/](https://wrapdb.mesonbuild.com/) Contains catch, hinnant-date (date?), zlib, range-v3 and a few others. Not a super long list I suppose, but it's a start. I haven't seen anything about vcpkg support, but from a quick glance at vcpkg it's just a matter of using meson's find\_library and include\_directories with the correct vcpkg paths.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I've recently experimented with Meson after using CMake for several years. I have kind of gotten accustomed to the muddy, bitter taste of CMake DSL, but after using something sane for only a few days, the CMake code looks absolutely horrible. For one, having no return values from functions. No methods on objects. Actually, no objects at all besides strings. And all the weirdness such as VARIABLE\_NAME being interpreted as a variable in some context, as a string in some, and in yet another context it is interpreted as a variable if that variable exists and otherwise literally. And optional string quoting, the fact that lists have to be written differently depending on whether they are quoted or not. The list goes on. Sure, every general or domain specific language can be complained about, but CMake DSL is literally and objectively bad. There might not be a satisfying solution, but any solution is \*more\* satisfying than that. And after many, many years of CMake, I still haven't figured out how to get dependencies right for custom targets. It's basically trial and error. With Meson it's simple and elegant.
You might want to look up Serialization. 
You may want [`std::is_trivially_copyable`](https://en.cppreference.com/w/cpp/types/is_trivially_copyable) and you definitely want /r/cpp_questions.
It sounds like you want to "serialize" data (and then, at the other end, "deserialize" it). You're effectively writing that code yourself. Alternatively, there are any number of existing formats, and libraries for each, that already exist: https://en.wikipedia.org/wiki/Comparison_of_data_serialization_formats
It's ugly to read. There's too much mental effort involved in parsing tokens not separated by whitespace.
Removing whitespace will probably save you several clock cycles per build. All that will be dwarfed by linking and file i/o.
Please don't.
Obviously everyone is entitled to write their own coffee however they want. But personally I find a line like val|=(uint64_t)buf.GiveOne()&lt;&lt;40; takes extra effort to read. Just personal though, different strokes for different folks.
[At 0:39:30](https://youtu.be/nVzgkepAg5Y?t=2305) Andrei's slide says: &gt; Just use `*result`, that is an `int`, or throws `err` if not. This diverges from [P0323R7](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0323r7.html) and seems to indicate a double check in the &gt; Idiom: `if (result) use(*result)` right above it on the slide. What gives?
It's not _idiomatic_ to throw just because an `expected` contains an error.
So your understanding is that `*unexpected` is UB, and that the slide is in error?
I assume Andrei knows what he's talking about, i.e. that the slide is correct, but it's not _idiomatic_.
Re your second paragraph, that is exactly why I feel discomfort about a standard graphics library. C++ doesn't feel right when it takes an arbitrary tiny piece of a large field and declares that standard. Sure, it'd be cool to just invoke std::draw_window_and_all_buttons() and get a nice user interface, but there's no standard around, and not because nobody knows how to do graphics, but because too many do. While I agree with the author that the committee should, if they have to do graphics, move as much of the work implementing it to someone else who's already solved it and is in high use, it still feels wrong. Is it "standard" to use HTML for graphics? Should 2D graphics just become an Electron clone, where every window needs it's own instance of Chrome?
Right, yes I agree not having space after commas or around operators is excessive and luckily not very common.
While I still feel this is ludicrous, I appreciate the explanation. It sounds like the crux of this is &gt; there has been a strong push for a "simple 2d graphics" library in the standard. Why is there this strong push? Have there been lines drawn for what compromises we are willing or not willing to accept to meet that goal?
&gt; MSVC is still at OpenMP 2.0 Any reason for them being so slow on that front? Looks like 2.0 is from 2002, so it seems like there's zero interest from Microsoft in this?
&gt; p0323r7 says its UB to dereference if `!*this` so maybe Andrei's presentation is based on an older revision? The few previous revisions I checked (r0, r1, r3, r5) all say the same thing.
nah ... just define it yourself, using macros that call other macros ... (I'll see myself out)
They care more about C++ than C; OpenMP is far more useful for the latter (at least until 5.0), meanwhile MS has the PPL and ConcRT for C++.
Very cool. How hard was it to patch the compiler?
Great work! But I'm worried the words "relocatable" and "relocate" already hava a very definite meaning in computing, and it conveys the idea of changing data or code to adapt to a new location. Just the opposite of what (I think) is your intent. See [https://en.wikipedia.org/wiki/Relocation\_(computing)](https://en.wikipedia.org/wiki/Relocation_(computing))
I'm a bit confused by the definition here: &gt; *trivially relocatable* -- the operation of “moving an R and then immediately destroying the original” is equivalent to `memcpy`. Then goes on to this example: // This happens to be true, thanks to my patch. static_assert(std::is_trivially_relocatable_v&lt;std::unique_ptr&lt;int&gt;&gt;); I'm not sure how `std::unique_ptr&lt;int&gt;` fits the definition of "trivially relocatable." The moved-to destination will be perfectly happy with the result of `std::memcpy`, but how do the moved-from instances know that they are no longer responsible for calling the deleter?
lmao this guy and his pumpkins
&gt; but how do the moved-from instances know that they are no longer responsible for calling the deleter? They don't, you simply don't call the destructor. The prime use case is the reallocation of std::vector: It has to allocate new memory, move elements over, destroy old elements, deallocate old memory. But with relocate it just needs to allocate new memory, `std::memcpy` elements over, deallocate old memory (no destructors!)
Ah, gotcha -- I was thinking in terms of a language user, not a library author :-)
I'll start by saying that I do noy bear any ill will towards anybody, but it is not because someone as a huge CV that he knows better than other people. now, here is what I think about the proposal : The Good: - delegating work to other standards (w3c for instance) sounds like a good idea in such cases - using the web technology is a decent choice for UI The Bad: - the interface kind of looks ugly to me - The code sample (who ever wants to see this kind of code serve as basis for production code, really ?) - It skips over many things like windowing and such. The Ugly: - This will be a maintenance pain unless it uses the OS browser - it hides the real problem : the need for a standard build layout and dependency description + management I think that if we needed such feature (and we wouldnt with a package manager), it should be some kind of server implementation + a function to open a given page through OS features, that would then redirect to the user's preferred browser. as others pointed out, there are also issues from a technical point of view (windows must be handled through the main thread on some OS for example) with the proposed api (which again, looks kind of unfriendly )
No, there isn't.
Bingo. Package management in my mind is the #1 issue I fight in my cross-platform work. Cmake based efforts like hunter.sh and vcpkg are helping, but it's still a PITA. Java and every other language have figured this shit out already. I like how Hunter at least supports regular make and autobuild, so non-cmake projects at least have a chance at getting packagified. 
why do you need a Queue interface in C++ if you are always using the derived class as a template?
Probably from academics looking to teach C++ classes again, and be relevant next to JavaFX. Honestly, I may hate the complexities of using Qt/Wx, but I at least have choice. You get nothing if you put something in the standard, except the worst of all worlds. 
Especially ones that aren't common to [nearly] all platforms and project types? 
&gt; Probably from academics looking to teach C++ classes again, and be relevant next to JavaFX. I suspect this is the case as well. Personally, adding a toy to the language to fit such a niche need feels terrible.
It provides a bit more syntax checking, and (in my opinion) a bit more clarity for a human reader. It does not affect the code in any way. 
You write `std::move` just as much as documentation for the reader as you do for the compiler.
That's almost exactly what you do if you want to make sure you get the actual address, and not something else because the author of the type T decided to overload `operator&amp;`.
It kinda does affect the code, it adds an 8byte vtable pointer to the queue and the methods are still virtual, not guaranteed to be de-virtuallized by the compiler. 
If you can static\_assert an attribute's presence, then it's not exactly ignorable.
&gt;OpenMP is far more useful for the latter How do you figure? IMO OpenMP is the only reasonable way of doing parallelism in C++ across platforms. Now that Clang works quite nicely on Windows, it's actually finally fully available there as well.
&gt; it'll be ignored just like the double underscore or underscore-capital rule is routinely ignored in many code bases. :( So annoying. I've run across real errors caused by that multiple times. Clang has a warning for when macro names are reserved, but unfortunately none for normal identifiers.
Actually clang does more than that: user defined literal suffixes that don't start with an underscore, other than those specified in the standard, won't work at all. The warning it gives is: &gt; warning: user-defined literal suffixes not starting with '_' are reserved; no literal will invoke this operator [-Wuser-defined-literals] And it carries out that threat; Trying to use the suffix will produce an error: &gt; error: invalid suffix 'hey' on integer constant So the rule on reserved suffixes is pretty effectively enforce in clang at least.
I am surprised that the solution proposed to for the false-sharing of elements is to use a dual-queue straight from the get go given the complexity of the solution. I would favor measuring the benefits of a simple approach first: simple cache-aligning each element. It's a bit silly for `int`, but most queues should exchange more sizeable elements. Secondly, I have successfully in the past implemented *stripes* for this use case. Stripes are relatively simple: // Take a big queue of... 16 elements: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16] // And instead, change the mapping index -&gt; elements to have multiple stripes: [0, 4, 8, 12, 1, 5, 9, 13, 2, 6, 10, 14, 3, 7, 11, 15] // Which flattened again gives use: [0, 4, 8, 12, 1, 5, 9, 13, 2, 6, 10, 14, 3, 7, 11, 15] This very simple idea achieves the same goal as cache-ligne aligning elements (ie, no two adjacent elements share the same cache line) while at the same time avoiding any waste of space. The number of stripes can be adjusted based on the size of the object... or one can just use 128 (so that even pre-fetching does not accidentally lead to false-sharing).
Thanks for posting your criticisms here and in the mailing list! The points you make are obviously valid and I cannot comprehend why no-one of the authors is listening (especially since a lot of this has been voiced before, such as [here](https://groups.google.com/a/isocpp.org/forum/#!msg/sg13/9MweFe7hCDo/ZNELiRp6h6gJ) and [here](https://groups.google.com/a/isocpp.org/forum/#!msg/sg13/8qPJ5Nc7YcE/nhw5ISwu3pQJ))... But already the first response "None of the above is a proposal. Where are the papers?" says a lot about the mentality. I really really hope the 2D graphics proposal doesn't get through in any form like this (especially based on cairo - wtf??).
&gt; Unfortunately, this committee has neither the time nor the expertise to address this problem by directly creating some sufficiently-comprehensive API. Specifically, this is the problem addressed by web standards (i.e., HTML, CSS, SVG, and so on), those are in-turn built on many efforts in graphics (and many other areas), and clearly we cannot foster a comparable effort in this space in this committee. The only feasible way forward is to reach out to the large and vibrant community tackling this issue, creating portable standards in this space, and make direct use of their efforts. So... We can't be bothered to do it right, therefore we'll just incorporate the security, interoperability, performance, and syntactical nightmare that is a web-browser and all of it's related functionality and apis. This is just... what? Can't we just.... not try to include everything into the standard? I'm opposed to standardizing a package manager because a programming language has no bloody business involving itself in things outside the language, but holy shit I would rather have a package manager (horribly, poorly, buggily) standardized than anything to do with a web browser. Why can't we remove things? Do we always have to add things? Lets do Meta Classes : https://herbsutter.com/2017/07/26/metaclasses-thoughts-on-generative-c/ Lets do constexpr all the things Lets do reflection http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0578r1.html (or alternative, i'm not up to date). Lets even do a package manager (blech) But a web browser, or anything involving standards coming out of the W3C? We've clearly lost our minds. 
Yeah, and if we had a standardized operator or keyword instead, it would be just as much documentation as std::move is, without the bloat.
Wait... `class` is a keyword? I don't see it in my codebase.
This is a really helpful attribute of Rust's moves: all of them can be memcpys. It's good to know that we can at least get that optimization in C++ now if we write the code for it.
I use `enum struct` because I use `struct` everywhere else where `class` can be used, except in template parameters.
&gt; why would you be using expected if you just want to throw any errors..? Who says I had any say in the decision to use `expected`? In any case, introducing a totally avoidable UB just because somebody decided the use case isn't idiomatic (never mind `value()` _does_ throw on `!*this`) is the sort of reasoning that drives people away from C++. 
What's wrong with `class`?
Well what does it add in addition to 'struct'? It's not like I've ever seen the default private visibility used
Why would I use a keyword I don't need? Every keyword `class` replace are clearer in their context in my opinion.
I'm replying not really to you, specifically, but just to the general concept of std::web_view. Please don't feel that I'm personally attacking you, or even trying to be hostile. I'm trying to keep a happy demeanor, but with a complicated topic like this it's sometimes difficult to use text to convey the appropriate tone of "voice". &gt; I think some background has to be given. It's easy to think this is a ludicrous idea. It's still a ludicrous idea, and any notion of delegating functionality of the C++ language to a joke like the W3C will always be, but I appreciate you taking the time to educate us on the topic. &gt; However, there has been a strong push for a "simple 2d graphics" library in the standard. Well, it's always easy to say "they're wrong". But I'll say it anyway. The people pushing for any kind of graphics (2d, simple, webview, whatever) into the c++ standard are simply wrong. They'll continue to be wrong until the vast and potentially infinite problem space of the actual language (meaning the syntax and grammar) have been resolved, and they'll continue to be wrong until the vast and but definitely not infinite problem space of things that deserve to be in the standard library have been resolved completely. Personally I don't think that the c++ language should have things like graphics, package managers, or anything of the like that's "very external" or overwhelmingly platform dependent included in it. I have a medium objection to the filesystem stuff, and a small objection to the networking stuff, but I suppose I'm more happy than upset that those were included, in no small part because despite my medium objection to the filesystem stuff it's incredibly tiny and straight-forward, so overall it's a win, and the networking stuff is going to be used nearly ubiquitously, is incredibly hard to get right, and is promising to be very well integrated into the other standard library facilities, so overall i suppose it's a net win. Graphics, however, doesn't need to be in the language standard. It doesn't need to be solved by a new library. It doesn't even need to be solved, because so very few people would even consider using "simple 2d graphics" for anything beyond 2 minute toys that the very notion is a joke. "simple 2d graphics" is an oxymoron, as you point out in your very next sentence, but more to the point this problem has been "solved" by a large array of platform dependent, and platform independent frameworks, libraries, engines, and solutions, with modern, and not so modern, APIs, performance, and feature sets. The very existence of graphical window frameworks like Qt defeats the argument that the C++ standard needs to solve any problems in this space to begin with, but the twice yearly (or faster) release cadence of the Qt framework, with a substantial list of bug fixes, feature additions, and performance enhancements CLEARLY demonstrates that the c++ standard is no place for anything resembling a graphics library. At least not any time in the next ten years. The standards document shouldn't have anything in it that's going to change every 2 months, and "Displaying visual information" is a problem space that isn't even CLOSE to slowing down. The hardware is evolving under the hood wildly. The low level intermediate representation / serialization / command sequence stuff (directx, opengl, vulkan, mantle, opencl, cuda, whatever gets announced next week (probably? who knows, i stopped keeping track)) changes so rapidly, and the expectations of users encompasses such a wide and varied landscape that itself changes rapidly, that there's no meaningful justification for even investigating this space. The standard should be for "if you don't have it, you're fucked" stuff. Like allocating memory, or things that would otherwise need incredibly tricky platform-dependent assembly code or compiler intrinsics like std::atomic. We don't even need standard containers, because those are so simple to write yourself (for the most part, obviously they've become very nuanced, and therefore complex, over time), but it's precisely because they're so simple (relatively speaking, of course) that it makes sense to have a standardized version so no one *has* to write their own. &gt; There is nothing simple about graphics. And it would take years (a few decades really) to get to some place where that library would be of any actual use, beyond "hey, look, this is cool, I have drawn a square". Especially, because of text, fonts rendering, even loops, image formats, inputs etc... then people will want 3d, audio and piles of piles of cool stuff that the committee has neither the time, will or expertise to write wording for - let's not speak about the burden for the 20 guys that actually write most of the standard libraries. Right, exactly. The problem space is overwhelming. So why bloat the C++ language standard document with it? The problem is solved by existing solutions that take mere minutes to install and get started, with license terms that run the full gamut to full commercial, to public domain. &gt; And if we were to do all of that, we would end up to something rather close to a web stack, but worse because people spend decades bringing browsers to the maturity level they have today. I disagree. Graphics engines for 3d games do not look anything like a web stack under the hood, unless you're meaning something rather different than what I think you do??. Even so, if somehow a proper "bottom up" solution, where the standard standardizes the bare-minimum of fundamental functionality, like executors, networking, threads, atomics, so on and so forth, ends up looking like a web stack, well I guess everyone wins then? The web browsers out there can replace huge swathes of themselves with the *extremely* fine-tuned but also highly flexible implementation coming from the c++ standard. Everyone wins! Browser implementors do less work, get better perf. But the solution isn't to just say "Well, it's too hard. Lets just standardize firefox into c++" (yes, that's a drastic simplification, but it's still illustrative). &gt; So what this proposal offers is to offload some standardization effort to existing, battle-tested standard and implementation ( aka web techs ) instead of reinventing the wheel. std::web_view would serve the "educational toy library" goal, while actually performing better as a renderer (because web browsers rely on GPU which is something the 2d graphics proposal fails to acknowledge). &gt; It's about saying "These guys over there did the work, they know more than us, maybe we can use that". And then the c++ standard can just refer to the w3c/ECMA standards and call it a day. That's a complete cop-out. Ignoring that the various standards documents revolving around web browsers are....... horse shit. I mean, have you ever tried to implement any parts of their "living standards"? Ugh. I've been implementing large chunks of the WebRTC "standards" for the better part of 5 years now (in c++, with various javascript things thrown in when building the client side of things, or testing apps), and I tell you it's fucking pathetic. Under specified, over complicated, and they change the way things happen every 6 months. Not to mention that half the browsers out there just *completely* ignore what the standard says to do, and do it their own way, and so the various javascript libraries out there just build shims to cludge both ways of doing things into working together. And lets not forget that the browsers point their finger to IETF standards, which themselves are in sore need of professional editorial review, saying "do it this way!", and then don't actually do it that way 25% of the time. So you can either build a standards conforming RFCWXYZ implementation, or you can build one that works properly with web browsers. So, again, ignoring all the above there: What business does the c++ programming language standard have with pointing at literally anything that exists outside of itself, and physical computer hardware? For sake of implementing things like "new", std::tread, filesystem, and networking, I'll grant very small concessions to talking to the host operating system for very small sets of delegated functionality. C++, the language syntax / grammar, and the supporting standardized library, should have absolutely no notion that something like a web browser even exists. &gt; It would also be less of a burden for the implementors since the libraries already exist to do that on most platforms (either WebKit (Linux, apple), edge(Microsoft), chrome(android))). Now, my rant above this last quote being said, if the Implementer of a particular std namespace API wants to implement something using a web browser under the hood, well that's fine. Don't care, because the stdlib on the other 3 platforms I target will do it differently, and as long as they all work it makes no difference to me. My objection is that we're talking about standardizing something into the language that explicitly relies on standards not controlled by the c++ standard. I don't care how a particular platform chooses to implement whatever they implement. The very real danger that I'm afraid of is that when a standard includes everything anyone ever says "Hey, it'd be great!" over a beer, the standard quickly becomes a useless mess, progress grinds (or maybe screeches) to a halt, and the standard is abandoned in favor of something else that doesn't do literally everything. If people want simple 2d graphics so badly, they can go and make their OWN standard. They don't need to inject it into the document that I use to make a living.
Would a compiler be able to take advantage of this trivially relocatable trait to elide destruction of values if it can prove that they're moved out of before the end of the scope?
Isn't the ConcRT also not developed anymore? I remember hearing or reading a post/announcement about 1-2 years ago. I would also agree with /u/GPMueller that (at least before C++17) OpenMP is one of the most practical way to do cross-platform parallelism in C++.
Could you clarify? Are you saying the other problems that we could fix are not common to nearly all platforms and project types? Or are you saying that graphics are common to all platforms and project types? I think what you meant was "Graphics is not going to be commonly used, whereas *insert proposal here* is going to have an effect on almost all projects out there, so why aren't we working on those things?", but I had some difficulty parsing your sentence.
You are right about vtable pointer; however, this pointer on its own does not cause any harm. Besides, this is a research code, which is naturally simplified; production code might already have some virtual methods for other needs. By the way, won't the compiler allocate this vtable anyway for RTTI (the code uses typeid)? As for the second point (a virtual call) I disagree. The compiler must be really stupid to issue a virtual call for a method from statically known class, and using this type of compiler defeats the idea of any performance measurement.
You might consider looking at Portage, from the Gentoo linux distribution. * Fully agnostic to the host operating system, (works on Linux, obviously, with support for (on paper, anyway, but not a huge amount of users on) windows, bsd, mac, so on.) * Fully language agnostic * Fully build system agnostic * Supports arbitrary installation directories (a prefix, so to speak) * Supports dependencies based on both the version of the the other package, but also on the configuration option of the other package * Supports arbitrary patches at compile time * Supports source packages to compile on the fly, or binary pre-built packages * Supports installing multiple versions of the same package within a given installation directory 
I choose not to use class keyword so enum struct is a commpn occurence.
I agree with you on `typename`, it's much clearer in templates. But `struct` and `class` have widely accepted meanings in OOP, and using `struct` just because `class` is technically redudandant really only adds more confusion.
\&gt; A Java-esque Stream library would resolve this, but I see no candidates for inclusion in the standard library. I'll bite. Implement a Java Iterator with performance characteristics that you like, and I'll implement an equivalent View with range-v3.
Wouldn't that already work with a move or swap? It would still have overhead, however it should not involve an additional allocation. 
It wouldn't do an additional allocation for unique_ptr, yes, just unnecessary reset of the pointer. But IIRC MSVCs node based containers allocate in the move constructor.
Is this thread full of joke replies or is there some sort of anti-class keyword movement that I wasn't previously aware of? As for OP's question: I use enum class arbitrarily because it comes first alphabetically.
those people don't have any... class!
The author here. Prevention of false sharing between elements was not the only reason for chosing dual-array; in fact, it wasn't even the main one. Cache eviction by circular access worried me much more. The article contains a section with tests where element size is 64 bytes, where no false sharing is possible; still, the tests show some advantage of the dual-arrays. The striping idea is interesting and easy to test; all I need is to do some bit-shuffling or read_ptr and write_ptr before using them as indices. I'll definitely try it when I get back to it (I'm now on leave), but I have some doubts about it. The false sharing is only a problem when the current queue size is so small that it entirely fits into one cache line. This is where we lose on tightly packed elements. When the queue is longer, we rather win on them, for both reading and writing speeds up (15 out of 16 operations are performed on cached data). Moreover, tight packing works as a negative feedback: the operation of the queue becomes faster when the queue grows, and it is always good to have such a stabilising factor. Nevertheless, I'm going to test the striping. On the other hand, the dual-array solution never suffers from tight packing and always benefits from it. As for complexity, it is a matter of taste. The dual-array doesn't seem too complex for me, and I like it that it only needs one shared variable; it helps when connecting to Java.
I was taught that: when you have something that only contains data (and maybe some basic operators), use a struct; when you have something that contains both data and logic, use a class. I guess this isn't as widely accepted as I thought?
I disagree on the "educational toy library" goal. Such a proposal leads to teaching "put together the samples to create a web view and then do everything in JavaScript" -- then I'd rather teach Chrome/Firefox dev tools and JavaScruot directly.
Value semantics means using values instead of using references. It does not mean exclusively trafficking in copies. There is no conflict between value semantics and using \`std::move()\`. It doesn't make sense to say that moving beats value semantics. 
Intel TBB works fine too as cross platform multi-threading library, moreover it doesn't rely on fancy preprocessor such as `#pragma omp`.
This powers the Small String Optimization, Small Functor Optimization, and `variant`.
Not sure if trolling, but if not: &gt; Public inheritance by default is much clearer in my opinion. Specifying the access specifier rather than relying on the default is much clearer in my opinion.
Oh yea, the `class`ic `template &lt;struct T&gt;`
...pumpkins?
Enhanced memory debugging*
Wait'll you see Emscripten's inline assembly. Here is the code for an Emscripten-legal, Hello World program: ``` #include &lt;emscripten.h&gt; int main() { EM_ASM(console.log("Hello World!")); } ``` 
Was OP juggling it? That's fucking gangsta lol.
As someone who's been starting some amount of io2d work, and wondering if part(s) of it might ever get adopted into the ISO C++ 'std' namespace, I suspect that if `std::draw_window_and_all_buttons` were in the spec, we've gone way off the deep end (moreso than usual?). 😉
I don't get that angle. Surely, nothing in academia is stopping you from grabbing a simple graphics library on the side? It's not like it will somehow violate C++ principles more than a std 2D library would. And unlike companies, there is literally nobody around to tell you not to use a 3rd party lib because it's GPL2, not L-GPL, or perhaps not supported in a year.
This might be already implemented, but can there be some compiler warning if a struct can be trivially relocatable but you haven't annotated it? For example, in Rust I can do: #![deny(missing_copy_implementation)] struct Widget { } ... which will fail to compile with `struct Widget could implement Copy` (i.e. the Rust equivalent of `[[trivially_relocatable]]`). If you said that the compiler could deduce the trivially-relocatability of a type, couldn't it warn about a missing `[[trivially_relocatable]]`? Or is this annotating process already done by the compiler automatically for all trivially-relocatable types (which then begs the question why we need to annotate it)?
&gt; The standard should be for "if you don't have it, you're fucked" stuff. Like allocating memory, or things that would otherwise need incredibly tricky platform-dependent assembly code or compiler intrinsics like std::atomic. I'm not entirely on board with that wording, though I generally agree with your post. I could live without linked lists, because they are easily implemented. I'm still happy to use a standard one if it's there. I'd rather say it should also be for often-needed stuff that has an obviously good solution. If I know I need a map, I can use std::map and be sure in the knowledge that it's a pretty darn good implementation for most use cases. And then I can use algorithms on the map that give me certain guarantees. If I know I need 2D graphics, there's no way that I can just grab "a graphics" to make it do what I want. As you say, the field is just way too large.
SFML library has an Event class with a enum for the type of the event, and a union of many different types for the actually event body. So when consuming an event you check the type first and then just access the member variables that match that type. It was really cool to me cause it made me realize you could do a messaging / pub sub solution using unions instead of templates
vector structs that can be indexed with [] and .x .y .z and .r. .g .b are useful. 
https://www.reddit.com/r/cpp/comments/7eq2tm/c_scalar_accessor_for_simd_vector_class/ While technically being undefined behavior, it's still a pretty neat way to implement simd "accessor" i.e. proxy types that use assignment operator and implicit cast operator to provide scalar access to the components of the encapsulated simd type.
Dude, I use unions all the time. They are more practical in C than in C++, because C++ supports polymorphism whereas C does not. So if you want enumerable types in C a union is the best way to go about it. Unions are also great if you want to avoid using a bit mask which makes it easy to access specific bits of a value. Here is an example of a 32 bit color type. typedef struct __color32 { uint32_t m_color; struct { uint8_t r; uint8_t g; uint8_t b; uint8_t a; } } color32; Now you can access and modify any base color and the transparency or the entire 32 bit value via the dot operator.
Isn't that technically UB, at least how it's for example [implemented in glm](https://github.com/g-truc/glm/blob/master/glm/detail/type_vec3.hpp#L27)? Not sure about the details but I thought I read something like that a while back.
Numpy arrays take data and format it like you'd expect from serialization. It allows you to store complex numbers and use byte offsets to extract real and complex parts
The problem with that is that the line between these definition between what a class or a struct should be is blurry. What is the meaning of a "class with no logic"? When you only have public members and no member functions? But what if you have a string as a member or a complex class as a member, is it a class then? What if you only have simple public members but you privately inherit another type? What if that other type is a struct and you just want to compose your struct? There is so much grey area that I'm not convinced about the message it conveys to the user of the code. I believe making a separation between the two brings much more conclusion because the rule is not clearly defined, and in fact won't change a thing when it come to use the class, apart from screwing with forward declaration. This is why I picked one and forgot the other. \`struct\` gave me sane default so I used it. If classes had public inheritance and public access by default, I would have picked class.
I'm not an *expert* C++ programmer, but why add a whole new extra syntax feature for this? As opposed to just a new keyword, like this: ```` Widget(Widget&amp;&amp;) = trivial; ````
New syntax feature? All it's doing is defining a new standard attribute, a syntax thats been supported since C++11 https://en.cppreference.com/w/cpp/language/attributes
TBH, I just use them for simple aliases.. e.g. using pixel24_t = struct { union { struct { uint8_t R, G, B; } RGB; struct { uint8_t B, G, R; } BGR; uint8_t Raw[3]; }; };
I use `typename` there.
AST node for a compiler written in C. The unions (many of them) were for the various AST node types
Sometimes you want to defer the start of an object's lifetime. std::optional can be inefficient in certain cases due to the storage of an "is_initialized" indicator. With unions you can union deferred { deferred() {} ~deferred() {} void init() { new(&amp;d) data; } data d; }
https://stackoverflow.com/a/25672839/1806760
Isn't double underscores `__` anywhere in an identifier reserved by the standard?
If you think marking up raw loops is "practical" then your C++ code surely looks very different than mine.
Not as far as I know. Underscore can be used anywhere in a name and you can even lead with them(unlike numbers). The compiler treats them just like any other object name. However I lead with underscores only in C so I do not know if C++ has this kind of restrictions. The reason I do this, is to type define the structure and avoid having to type "struct" before every instance of the object. And because I exclusivly used the type define the actual name of the structure is irrelevant so I lead with doble underscores to avoid any possible name collisions. I've coded in most C standards even c99 and it had never caused an issue.
"Each name that contains a double underscore (`__`) or begins with an underscore followed by an uppercase letter is reserved to the implementation" So yeah, they are Another one that's good to know: "Each name that begins with an underscore is reserved to the implementation for use as a name in the global namespace."
&gt; Who says I had any say in the decision to use `expected`? What does it matter? Are we really that hung up on the idea that just throwing the error inside an `expected` isn't _idiomatic_? I've emphasized that word enough times for it to be clear that's my only point here... &gt;_&gt; &gt; In any case, introducing a totally avoidable UB ... drives people away from C++. And sufficient numbers towards it, apparently. Am I on /r/rust here? I'm not interested in discussing the API design or the \[de\]merits of UB by default; the only reason I ever responded in the first place is to say that throwing from an `expected` is not an "idiom".
http://www.gnu.org/software/libc/manual/html_node/Reserved-Names.html &gt; In addition to the names documented in this manual, reserved names include all external identifiers (global functions and variables) that begin with an underscore (‘_’) and all identifiers regardless of use that begin with either two underscores or an underscore followed by a capital letter are reserved names. This is so that the library and header files can define functions, variables, and macros for internal purposes without risk of conflict with names in user programs.
that's a perfect place for `typename`
&gt;**Author:**[Hal Finkel](mailto:hfinkel@anl.gov) (Argonne National Laboratory) Probably not. 
When working with hardware (FPGA usually, in my case), you don't have the benefit of serialized messaging. Instead, you might have a map of 32 bit words. Some float, some double (2 words), some integers of various lengths, some just single bits. You can make a struct if you're careful and don't mind that it won't be very portable. You can then union all your message types together if you want. The clever part is also putting `uint8_t` and `uint32_t` in the union so you can easily look at bytes or words by number. 
How does that work? With anonymous unions? struct vec3f { union { float x; float r; }; union { float y; float g; }; union { float z; float b; }; }; It's too bad anonymous structs are not allowed, or else you could do this. I mean, you can do this, but I think it'll only work on GCC and clang. #include &lt;iostream&gt; struct vec3f { union { struct { float x; float y; float z; }; struct { float r; float g; float b; }; }; }; int main() { vec3f v; v.x = 10; std::cout &lt;&lt; v.r &lt;&lt; std::endl; return 0; }
Why isn't it called trivially_movable instead?
what if you want to write your own move constructor?
Did you mean “typedef union __color32”?
You need to be able to know from the type that it's trivial, not from the implementation.
is there a list for these very serious and useful proposals?
If you're going to specify the access regardless of `class` vs. `struct` then there's still no argument in favor of class here – so what about this even _hints_ of trolling? Redundant keyword is redundant.
&gt; std::move is a nice name for a language-level feature std::&lt;anything&gt; is not a nice name for a language-level feature.
I'd strongly argue that using `class` for non-polymorphic types is more "confusing". Disagree? Not surprising, since it's entirely subjective. &gt; But `struct` and `class` have widely accepted meanings in OOP Don't overgeneralize here; they have meanings in C#, but "OOP" predates and surely doesn't care about the two. And of course, this is C++, not C#, and we're not forced to drink the OOP kool-aid; i.e., even if your statement here was correct, it doesn't apply.
It is. It's optional to provide an identifier after the `struct` keyword, by the way.
Also, everything you can do with a lambda you can do with a functor. But having lambdas makes people more likely to program better because it's more convenient.
Yes I did. 
&gt; it wouldn't help when moving into a function argument. unary &amp;&amp; maybe?
Looks like you speak from experience.
But the name is scoped, so it should not mess up anything right? Unless it's a macro...
Basically a poor guy's variant.
You twist my words (not sure if intentionally?) The language-level feature is `static_cast&lt;std::remove_reference_t&lt;T&gt;&amp;&amp;&gt;` or something like that, and `std::move` is a short form with the same effect. I would say that `std::move` is nicer than the static cast expression, YMMV I guess. 
If it happens to conflict with something in your libc implementation, it's possible that including a libc header could break things. The rules might protect you, but technically a leading double underscore is reserved for standard library implementors.
Note that this would lead to undefined behaviour in C++ (where only the last-set member of a union can be read). 
You didn't mean "nice", you meant a "more convenient form". I didn't understand. Now I do. I wish C++ would differentiate much more between "core language" and "stuff we provide because it's convenient but you could do it yourself if you wanted to". 
In a language full of complexities, having two keywords accomplish the same thing and making artificial/subjective distinctions between them only adds to that complexity; and what's the value-add? If "anti-class" is a thing, I personally wonder who's "pro-class", and whether they aren't just projecting their desire to be writing in C# instead. ;-]
Only a macro can mess up something here. This is why we need modules .
That's already legal for types with an overloaded `operator&amp;` that produces an lvalue.
Yes, by the standard double undersores are "reserved" but only by convention. The compiler doesn't understand a difference between a name with two underscores. The convention is designed to avoid collisions which is the same reason I use it for. The identifier is not always optional. Every so often I have to type define an incomplete class because it's not defined in the current scope. Or there are two structures dependent on one another. For instance. typedef union __color32 color32;
You mean that they're not powered by some internal `meow` of some kind?
My MIPS emulator can run in a browser, compiled by Emscripten. The output JS is... interesting, to say the least. Also, the JIT doesn't work (obviously). I don't think there's a sane way to make the JIT work. Would it emit native Javascript?
Please don't use reserved identifiers. This sort of thing makes implementers' lives unnecessarily hard, when we could be working on actual features. Use any of the identifiers that you're permitted to, and leave the implementers alone with their `__ugly` and `_Ugly` identifiers.
Wouldn't be the first place where a space is required, right?
Looks interesting! Can you summarize your design? Readme file is short on details. 
Fair enough guess I'll be using 3 underscores from now on. 
I appreciate both the offer and the likelihood of following through on this offer, _but_... When I find range-v3 to be a bottleneck, rare as it is, rewriting with Atria proves to be faster basically every time. I only use the library in personal projects since Ableton doesn't like contributions or updating, but I have to agree with the OP that the approach is inherently more efficient.
At what warning level?
The problem there is that you have to have _very_ simple cases. How would the standard reliably differentiate between your example and `Object::Object(Other bar) : _bar(bar), _foo(bar) {}` ? Or `Object::Object(Other bar) : _bar(bar) { something(bar); }` ? Or even cases like `_bar(bar.a), _bar(bar.b)` ? Would we have to specify that automatic move only works for object initializers with empty/defaulted bodies whose initializer expressions are only non-reference lvalues? If so, does that actually accomplish the goal? The C++ specification is written in terms of some rather specific translation phases. It's not a case of C++ compilers being unable to implement these features' semantics; it's a case of the standard document being unable to express those semantics.
Never really thought to try nontrivial types in unions... Wouldn't that kind of usage mean the destructor isn't called (without adding additional logic)?
The *very* simple cases are also very *common* cases. Also, in this case: &gt; _bar(bar.a), _bar(bar.b) If `bar` is a local object and thus not aliased, it can be presumed to be discarded. Ergo, so long as `bar.a` and `bar.b` do not alias one another, they should be moved.
Identifiers with 3 consecutive underscores contain 2 consecutive underscores and are therefore reserved.
Reading values from a big endian file in a little endian environment. They felt natural for that task. I would read them byte by byte and then access them as a whole let's say integer and voila, no rotation of bytes needed. I took this idea from a stack overflow answer a long time ago before anyone thinks it's mine.
Midi messages have lots of different configurations based on the first byte.
You're asking for an operator to perform a cast? 
ITT: Undefined Behavior
I'm asking for an operator that indicates that I wish to move the object. That does necessitate a cast, but semantically it's 'moving'.
Polymorphism support via enums in SDL
Let me preface this to clarify: I'm not saying that you're wrong for thinking that the feature could be easily implemented (I'd wager that it certainly could be!), but I _am_ saying that it would be incredibly difficult if not impossible to add to the C++ standard document. &gt; If bar is a local object and thus not aliased, it can be presumed to be discarded. Ergo, so long as bar.a and bar.b do not alias one another, they should be moved. And again, _how do you specify that_ ? In the kind of words that you find in the C++ standard document, not in words meant for mortals like us. :) The C++ specification can't just say what's so painfully obvious to us meat-bags. The standard isn't a thinking person. The standard isn't a compiler. The standard isn't even a _description_ of a compiler! It's a weird collection of technical clauses that talk about phases of translation and entities and value categories and grammatical constructions and a bunch of other gunk, but critically does _not_ talk about any form of value/usage analysis! This is why the `return foo;` case works: because the standard can literally reference the grammatical form `keyword_return identifier semicolon`, though it uses significantly more words to say precisely that. :) &gt; In the _bar(bar), _foo(bar) situation, it would appear that the first instantiation would need to copy whereas the second could move. Appears to _us_, yes, _obviously_. That's now how it "appears" to the standard, because the standard doesn't know what first or second means here. That's not how the C++ specification is written. It doesn't have the technical framework to express things like "first or second use." &gt; If the compiler can determine that something does not mutate bar The standard doesn't care in the slightest what the compiler _can_ determine. The standard only cares about what the compiler _must_ determine and _how_ that determination can be made. Therein is the problem: if the feature requires the standard to specify in standardese complex value usage analysis passes, we have a problem. Note that this is one half of why the OP's proposed feature works in relation to a `[[trivially_relocatable]]` annotation: those are allowed to be ignored which means that a conforming C++ implementation needs no need analysis passes. The _other_ half of the equation is that the proposed feature works perfectly even when it is ignored; it semantically replaces a sequence of (should be) trivial constructor and (should be) trivial destructor with another different trivial operation. The only difference is that it allows a nice way to hint to the compiler that the sequence of operations are trivial despite not meeting the existing rules. The second reason that the OP's proposal works - and turning copies into moves doesn't - is that turning copies into moves will one type of non-trivial operation into another type of non-trivial operation. This _changes semantics_. In particular, it would mean that different compilers would produce different results for non-copyable types, or that it wouldn't work with types that aren't both copyable and moveable (meaning no `unique_ptr` support, among a great many other things).
&gt; And again, how do you specify that ? In the kind of words that you find in the C++ standard document, not in words meant for mortals like us. :) Any movable, non-aliased object which is to be discarded (its lifetime will end) after a copy operation without any subsequent operations mutating the object, or any subsequent operations referencing it, will be moved instead of being copied. That should also cover member fields of such an object, as well. I should point out that on some compilers, I get different compiler behavior from LTO than without it (on GCC in particular) - for instance, templates which shouldn't be resolvable suddenly are. So, I already get different results for different compilers.
my favorite was/is this union float32_rep { uint32_t i; float f; struct ieee { signed sign:1; unsigned exp:8; unsigned mantissa:23; }; }; float_rep r; r.f=-4.2f; cout &lt;&lt; r.sign &lt;&lt; "," &lt;&lt; r.mantissa;
There are some excellent usage examples in the STL itself. Check the implementation of std::optional or std::variant.
Me too. What I meant was I do not use `struct` there (because I can't).
Thanks for your reply! I updated Readme, and hope it can make clear. Thanks!
ADL can, too, in a pathological case.
But why do you need the underscore at all? This should just works: ``` typedef union color32 { ... } color32; // or even better typedef union { ... } color32; ```
C++ standard libraries are largely built within the language because it is flexible enough.
Maybe it makes a difference in some errors when the actual union isn't anonymous.
&gt;Yes, by the standard double undersores are "reserved" but only by convention. The compiler doesn't understand a difference between a name with two underscores. The convention is designed to avoid collisions which is the same reason I use it for. &gt; There is no need to avoid collisions, you can give both the same name and differentiate by using `union foo` and `foo`. (Or just use C++) 
Yeh how does init() work when it relies on the constructor?
The blogging platform died. I'll post a valid link to updated version when get to my computer. 
I'm just saying same that Bjarne Stroustrup state for a few years now. And this is a very good example of how stuff goes wrong with the working group IMHO.
This is exactly what I was thinking on this context :) great example.
I agree with being undefined behavior in C++ but not with your explanation because there is a case where you can read another member. §12.2.23 (n4659) states In a standard-layout union with an active member (12.3) of struct type T1, it is permitted to read a non-static data member m of another union member of struct type T2 provided m is part of the common initial sequence of T1 and T2; the behavior is as if the corresponding member of T1 were nominated. But even in C there is no guarantee that this will yield the desired results, because `m_color` and the anonymous struct are not compatible types (§6.5.2.3.6). Therefore note 95 applies If the member used to read the contents of a union object is not the same as the member last used to store a value in the object, the appropriate part of the object representation of the value is reinterpreted as an object representation in the new type as described in 6.2.6 (a process sometimes called ‘‘type punning’’). This might be a trap representation. Since no guarantee can be made about alignment no guarantee can be made about the result.
SDL (1 and 2) do the same. I also like it, and yes it is a kind of C variant (SDL and SFML beeing C interfaces after all)
&gt; When in doubt, don’t overload the comparison operators. Just manually use predicates when required by containers or algorithms. Is this considered best practice? Maybe I'm just too lazy, but I'd rather not have to look up/write a named comparator and pass it every time I declare a container of some type just because that type doesn't have an obvious natural ordering. It strikes me as unnecessary purism. I would rather the type hand me an arbitrary total ordering, if one exists.
Yes, you need to call the destructor explicitly in this example.
&gt; It's too bad anonymous structs are not allowed, or else you could do this. I mean, you can do this, but I think it'll only work on GCC and clang. Microsoft supports anonymous structures too https://docs.microsoft.com/en-us/cpp/cpp/anonymous-class-types
The blogging platform for the original article died so moved the blog and revised it a bit. Quoting from the latest version: "We have union just like at the beginning but there is a subtle difference: it is union of identical types (the standard would call this common initial sequence, 9.5.1)." This just moves the goalposts a little bit since now it is a question if the x86 intrinsic types like __m128 and others qualify for common initial sequence. (other architectures intrinsics included) Here's the link to latest version: https://t0rakka.silvrback.com/simd-scalar-accessor Now that I read it through after a while, probably should not jump so quickly to the SIMD variant. It's like two ends of two different articles were forced together at the middle. :_( 
Nice, but you have to take care of the endianness of your float. ```cpp struct ieee_little { unsigned mantissa:23; unsigned exp:8; signed sign:1; }; struct ieee_big { signed sign:1; unsigned exp:8; unsigned mantissa:23; }; using ieee = typename std::conditional&lt;std::endian::native == std::endian::little, ieee_little, ieee_big&gt;::type; union float32_rep { uint32_t i; float f; ieee internal; }; ``` 
Seems the name comes from [Relocator: Efficiently moving objects ](http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0023r0.pdf) Beats me why this paper is not credited at all.
There is still not guarantee this will work everywhere
No. What you are trying to take care of is part of the ABI of your compiler. It is not influenced by the endianness of your CPU.
Highly UB, but will afaik work on most platforms
I'm currently working on a gameboy emulator as a hobby project, and one of my worst abuses of unions is this: union { uint16_t AF; struct { union { uint8_t F; struct { uint8_t : 4; uint8_t F_Carry : 1; uint8_t F_HalfCarry : 1; uint8_t F_Subtract : 1; uint8_t F_Zero : 1; }; }; uint8_t A; }; }; Essentially, there are two 8-bit registers, `A` (the accumulator used as an implicit destination/argument in a lot of instructions) and `F` (flags set by arithmetic operations). A few instructions can save/load A and F together as a single 16-bit value referred to as `AF`, so those are in a union to make that easy. But F itself is a flags register, and I need to be able to set/query individual flags - so it is also a union between the uint8 for the entire register and a struct of bitfields for the individual flags. So I end up with a union in a union!
Why track size of allocations in a separate hash table? Allocate one sizeof(size_t) larger than requested. Store the size in the first size of(size_t) bytes, return the address directly following the end of your size data. Then when memory is returned, you just subtract sizeof(size_t) from the returned address to determine the size. Significantly faster than doing anything with a hashmap. Probably less memory overhead as well. If you wanted to get crafty, you could. Instead of having a hashmap for each size of memory region. Only ever allocate specific known sizes for anything under, say, 1024. Like powers of 2. Then you'd have specific known sizes that you could store. And could reasonably store them as a fixed sized array of pointers. So if you're requested to allocate 100 bytes, allocate 128+sizeof(size_t). Then when that's returned, any subsequent allocation that would be rounded up to 128 can use that block. Go further, and make sure that for any block you do allocate you allocate enough space to store a size tracker for each "sub block" that you can break it up into. So if you want your smallest possible size to be 64, and you allocate a block of 128, instead allocate 128+2*sizeof(size_t). By default you hand it out as 128 bytes, but if someone asks for a 64 and you only have a 128, you can split it into two to avoid having to do an allocation For any particular power of 2 you'd reserve N/smallest*sizeof(size_t) extra bytes to support size tracking. Now on top of the above, when you get a request to allocate, that's most likely going to be followed by another request soon after. So if you actually have to call the OS to get memory, allocate a whole bunch. Memory is cheap-ish. CPU time is expensive. So if you're asked for 1024b, just grab 10240, and split it into 10 1024 chunks. Heck, you could just always grab memory by 10x your largest chunk size, unless given a template / compiler options indicating otherwise. If there's actually a reason to use a memory pool, then there's going to be decent memory allocations happening to make it worth it. And finally we can do away with the use of hash maps entirely by storing each chunk in a linked list of the appropriate size. (Not an std list, btw. More like a stack data structure that has items added and removed usinf atomic operstions) When you're storing the memory in the free list, just use your size storage as a pointer (union, static cast. Whatever) to the next node in the free list. Using an atomic compare and swap for any operations on the free list (careful about the ABA problem), you can get rid of the mutex entirely. Mutexes are... Horrible, for performance in multi-threaded code. They block the other threads. Super slow. Atomic operations aren't necessarily ideal, but they're no biggy by comparison. You could go another step on top of all that and work out a way to re-combine chunks that you split apart. Possibly by adding more storage to track the next chunk part even when not in the list? The trick would be that you can never afford to do a full scan of all the chunks in your reserve..that would be far too expensive..but it could potentially be worth it to, e.g. check the first, second. Maybe third, item(s) that's already in the list to see if they're a match. If they are, check out those chunks (remember, atomic compare swap means someone might check the chunk out while you're looking so if you get back a different chunk than you thought, abort)_ and then put the combined chunk back on the one larger free list. 
It is also acceptable to use a structure when you have logic associated with it. The idea I use (taken from A. Stepanov) is this: if you have invariants on your data, hide it behind an interface and impose the invariants. If you have no invariants at all, use a structure.
There is still no guarantee this will work everywhere
I you set the value by \`AF\` and read from the structure you have no guarantee it works everywhere.
No, it relies on little endianness unfortunately.
Well, I wrote out a lot of comments about your code, and submitted the comment, then noticed a typo and went to edit and apparently reddit decided I wanted to delete it all. So that's a bunch of crap. I'll rr-write it all tomorrow. Summary : * Don't use a hashmap to store sizes. Allocate 1 size_t worth of memory extra, and store the size in the first sizeof(size_t) bytes, and return the address of the byte following that. * consider limiting the sizes you allocate by rounding up to a power of two. Let's you split allocations in half later if you need a small chunk. * mutexes bad!!! Use atomic operations. Make a free list where each chunk holds a pointer to the next chunk, and use atomic compare and swap to add/remove from the list. One list per chunk size. Maybe 32b, 64b, 128b, 256b, 512b, 1024b. Then anything larger can use more complex machinerry., like your hashmap and mutex.
Probably the same people who write `auto main() -&gt; int`.
Did you mean [`MeowIterator`](https://en.cppreference.com/w/cpp/named_req/ConstexprIterator)?
&gt; Would a compiler be able to take advantage of this trivially relocatable trait to elide destruction of values if it can prove that they're moved out of before the end of the scope? that would be a real game-changer
Technically it is UB but compilers have no problems with it.
That's pretty much the road to disaster though...
Hey cool, that's awesome! Thank you very much for posting the link, and your posts are awesome! :-) Do you have the software rasterizer code online somewhere too? I couldn't find it as part of the mango library.
Could you elaborate? I recently tried to do something similar but was discouraged because i didnt know how to properly deal with endianness. Do you have any resources on this topic?
The following is not the case (§6.5.2.3.6) \`\`\` One special guarantee is made in order to simplify the use of unions: if a union contains several structures that share a common initial sequence (see below), and if the union object currently contains one of these structures, it is permitted to inspect the common initial part of any of them anywhere that a declaration of the completed type of the union is visible. Tw o structures share a common initial sequence if corresponding members have compatible types (and, for bit-fields, the same widths) for a sequence of one or more initial members. \`\`\` So note 95 applies \`\`\` If the member used to read the contents of a union object is not the same as the member last used to store a value in the object, the appropriate part of the object representation of the value is reinterpreted as an object representation in the new type as described in 6.2.6 (a process sometimes called ‘‘type punning’’). This might be a trap representation. \`\`\` Since your compiler can add padding bytes to the structure there can be \*\*no\*\* guarantee
 std::unix::cat("~/files/logs/log.txt") | std::unix::grep("error") | std::unix::less()
Why should they? They can "do what they want" - if there is a problem you will have it for sure
I might OSS it eventually but for now I am doing other stuff. It's pretty useless w/o usable API. I am generating the vertex buffers "in app", which is actually as simple as it can get but not very.. loss at words.. sorry. ;)
Words found: it's a fun toy to play around with but not practical one. 
&gt; Surveying the current implementations has convinced me that this kind of interface is appropriate for standardization, at least in the sense that, while broadly useful, using these services from a C++ application today requires difficult-to-get-right platform-specific code. Moving that burden to C++ library implementers, as a result, makes sense. In addition, it should be possible to create production applications using this facility that meet modern user expectations across many different kinds of devices and platforms. # &gt; I don’t believe that we can require all C++ implementations, not even all non-freestanding C++ implementations, to provide a web-content interface. As a result, it must be legal for an implementation to stub out the implementation of web_view where it cannot be reasonably supported. Nevertheless, given currently-shipping web-browser implementations, we can provide a succinct API that ties C++ into the most-vibrant standards-driven ecosystem in this space. wat I stopped to be funny when I saw examples that embed JS code in strings.
There's no argument in favour of struct either. Class is much more widespread, so using `struct` over it just feels like going against the flow for no (or little) reason.
Not just C#. Also D and Swift. It's definitely a thing.
If you're consistent in your codebase you're not going against the flow, and the reasons for `struct` are already spelled out (namely default accessibility). Doing things out of dogma or "because everyone else does (for no good reason)" is not how I live my life or write my code. ;-]
no include required
None of those predate C++; none of those _are_ C++. Applying other languages idioms is misguided.
In this thread: UB.
And you're free to do so. I was mostly unsure of whether it was trolling because they originally said they didn't know `class` was a keyword. If not trolling, then I already made my argument. With all that said; who really gives a fuck? The only problem you may encounter is an easily-fixable compile error. There are more important things to worry about.
&gt; With all that said; who really gives a fuck? ... There are more important things to worry about. I agree, but that's an argument against the conversation. I hope you downvoted this thread duly. ;-] 
I didn't downvote anything. I was clarifying that it's mostly style and people can use either because of preference. You saying "there's no argument in favor of class" also reinforces my point. Because some people always specify access, they won't have any preference other than what they're used to.
I'm pretty sure it can't add padding bytes because it should be standard-layout? C++'s layout requirements are quite strict if you fit the definition of standard-layout.
&gt; with support for (on paper, anyway, but not a huge amount of users on) windows It looks like this requires using cygwin, which is a dealbreaker for many. Even though this increases complexity substantially, a good solution to package management in C++ will have to work with compilers that don't act like GCC, and systems that don't comply with POSIX (well, practically this is just required in so far as windows doesn't, at least -- and WSL doesn't work even close to seamlessly (or, often at all) for cases where GUIs are involved yet, so that's not a solution either). In practice this tends to be a little harder than just making the package manager run on different platforms (although that's a bare minimum, obviously), since you have to answer questions like how to handle dependencies that only exist on one platform.
Copy and trivially_relocateable aren't semantically the same. Every rust type is trivially_relocatable (ignoring Pin, which is not stable yet), since move is always memcpy -- since rust has no way to implement a custom move constructor. Copy is in rust is semantically equivalent to the is_trivially_copyable trait and related TriviallyCopyable concept. I don't have an answer to whether or not there's a warning (I suspect not), but the compiler has no way of knowing if a type is trivially relocatable or not without you telling it (you can store pointers to interior fields, and even write those into what look like normal `uintptr_t` fields if you want), so it can't infer these things for you.
Hes; C++ distinguishes identity from bytes. The abstract machine cares about both what bytes are there, and the identity (type) of the object. Almost every single "fav use of union" here ignores the identity part and tries tomuse the unions to bit-bash between types. And C++ only supports that with common initial sequences. So..., UB, UB and more UB here. 
&gt;*largely* What Standard library features aren't built within the language do you know?
I can be mistaken but in §12.2.24 (n4659) the standard further claims &gt;If a standard-layout class object has any non-static data members, its address is the same as the address of its first non-static data member. Otherwise, its address is the same as the address of its first base class subobject (if any). \[ **Note: There might therefore be unnamed padding within a standard-layout struct object, but not at its beginning, as necessary to achieve appropriate alignment. — end note** \] \[ Note: The object and its first subobject are pointer-interconvertible (6.9.2, 8.2.9). — end note \]
A lot of [stuff in `&lt;type_traits&gt;`](https://stackoverflow.com/questions/20181702/which-type-traits-cannot-be-implemented-without-compiler-hooks) requires compiler support. I know clang also has intrinsics [__make_integer_seq](https://reviews.llvm.org/D13786) which makes for a faster sequence generation. They're possible to implement in C++, but they're slower.
I think I've used anonymous structs and never had a problem with them.
Thanks, interesting links!
To be fair he said cleverest, not best.
**Company:** Cisco Systems **Type:** Full time **Description:** Our team in Galway is looking for a Senior Software Engineer to help create Cisco’s next generation of software and services for communications, incorporating business messaging, meetings calling and collaboration tools. Global teams, mobile workforces, social networking, pervasive video, and information overload: this is the new normal. To address these business complexities, Cisco Collaboration products connect people, information, and teams, helping to enable comprehensive and effective collaboration. We deliver a high-quality, highly secure experience across any workspace. **Location:** Galway, Ireland **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++14, C++17 (and beyond). We do cross platform development on Windows &amp; OSX, but we also work on iOS, Android and Linux. Knowledge of Qt a big advantage. Other languages used are Swift, Objective C &amp; Python. **Contact:** [email](mailto:adrwhite@cisco.com) or [apply online](https://jobs.cisco.com/jobs/ProjectDetail/Senior-Software-Engineer-Collaboration-Group/1237334)
One of the things included in "doing what they want" is defining the behavior Some compilers, such as GCC, do define implementation support for type punning.
unless your compiler defines the behavior, which GCC does.
They all warn by default; I didn't set any compiler flags other than the language version (C++14).
Im not sure how to elaborate on this. The order in which individual bits are assigned to bitfields is implementation defined. Your compiler needs to tell you how they are allocated. Endianness doesnt factor into this until you want to serialize data in a binary format or transmit data over a network. Even then endianness only tells you about how bytes are ordered (least-significant to most-significant byte, or vice-versa) and says nothing about individual bits. I personally dont really worry about endianness because x86 and ARM are little-endian (POWER is one notable big-endian architecture IIRC), so basically every CPU youre likely to meet uses the same endianness.
That is correct. But at some point one might want to support other compilers and platforms as well. Therefore I would recommend writing according to the language and not compiler specification.
But you could also use std::aligned_storage for that. 
Should be well-defined in C though.
\&gt; mutexes bad!!! Use atomic operations. Make a free list where each chunk holds a pointer to the next chunk, and use atomic compare and swap to add/remove from the list. One list per chunk size. Maybe 32b, 64b, 128b, 256b, 512b, 1024b. Then anything larger can use more complex machinerry., like your hashmap and mutex. The implementation you suggest suffers from the ABA problem! Lock-free programming is much more than 'throw-in-a-cas', especially with more complicated datatructures like hashtables
As I understand it: no. In C you are able to use a union with a type T and an array of char to inspect T, but that's an exception to the general rule that you're not permitted to read from a different union member than the "active" one. I may be mistaken though, since I'm not a C expert.
That's really awesome ;)
Type punning via unions is well-defined behavior in C but UB in C++. AFAIK C has no notion of the active field of an union. https://stackoverflow.com/a/25672839
Left-to-right just makes sense when you come from Haskell. Once C++11 dropped, I started writing all of my functions, even main, with the arrow syntax. Life's been good.
Thanks for the link, I didn't know C allowed all forms of type punning through unions. It's been a long time since I've worked with it.
That's referring to padding required for alignment of members - I'm fairly sure there's a clause that a standard layout struct should be packed with no other padding added other than what is required for alignment.
It wouldn't work out. The direction of this proposal is being too specific.
&gt; The number of keys of hash tables will affect their look-up performance, so if hash tables have too many keys, the performance may be downgraded. Isn't the main point of hash tables the constant lookup performance?
One of our libraries contains a solution for your problem: &lt;[https://github.com/taocpp/PEGTL/blob/master/include/tao/pegtl/internal/pegtl\_string.hpp](https://github.com/taocpp/PEGTL/blob/master/include/tao/pegtl/internal/pegtl_string.hpp)\&gt;, it's quite portable, works with up to 512 bytes long string (you can adapt and extend that easily) and it works with embedded null bytes.
I think so, but I'm not well versed in the C standard
I imagine that adding an extra JIT layer would make optimization a lot trickier, and am hoping this gets better over time, if it's not sufficiently. I like some of the cross-platform prospects that WebAssembly or Emscripten seem to have. I can see a JIT-to-JavaScript, or (perhaps) better, JIT-to-WebAssembly, yielding interesting results, although perhaps only for benchmarking purposes. I do suspect that JIT-to-WebAssembly would be easier to write while keeping output reasonably-performant, but I am very much unsure of that. 
In C++20, this will be so easy. Check out [P0732](https://wg21.link/p0732), which has an example in it that addresses your use case.
I'd like to put forward that 'std' package management, and 'std' graphics, could and eventually-should co-exist. I'd also like to put forward that progress on both could be made simultaneously. I am, admittedly, very biased, having started some amount of work on io2d (an offshoot-ish project from the recent, big, ISO C++ 2D Graphics proposal). Having means to help keep stdlib implementation(s) up to date would also be nice, in my book.
Is that a proposal or upcoming feature? template &lt;std::basic_fixed_string str&gt; auto operator"" _udl(); [it's actually possible](https://godbolt.org/g/D3PZP7)
Trailing return type is not bad, but I dream of normal order of C declaration syntax (eg `const int[N]&amp; arr`)
Moving: destructor of moved-from object is (eventually) run. "Relocating": destructor of relocated-from object isn't run.
I have used it for some small proof of concept apps that test using third party libraries in isolation and a few small utilities for my applications, but basically anything of medium or large size I do uses Qt.
Hello r/cpp! I have been developing a FOSS 3D rendering library for C++. The library also includes basic physics integration, sound and text rendering. The dependency library list is very small and the library is very easy to integrate into a project because the library is header-only. The C++ build target is currently set at C++14 but I am looking to add C++17 features down the road. The code compiles without errors or warnings and I have been working to remove all UB from the code. If anyone is interested in stress testing the library it would be appreciated. If anyone is interested in this library I would appreciate any C++ feedback and areas where I can improve the library. I currently use OpenGL as a backend and am aware I am leaking some OpenGL details through the abstraction but I believe I can clean this up sometime in the future, when I add a Vulkan backend. Please feel free to post any questions, comments or details! Thanks! 
I think your are mixing several mistakes here. 1. std::cin is used to read some data from stdin (aka the standard input) 2. the return value is the code that will be returned to the system it has nothing to do with what you print in the terminal (e.g using `std::cout`) 3. the return code is only used to indicate an error or success. For example, if your main return 1, the following shell script will write an error: ```bash $ myapp || echo "oops, my app failed!" ```
From now on, I will use `purr` instead of `class` or `typename`.
(On UNIX) Your shell runs your program by forking a new process and running your executable with (some variant of) [exec](https://linux.die.net/man/3/exec). It then [waits](http://man7.org/linux/man-pages/man2/waitpid.2.html) for your program to return unless you specified to run it in the background. If you're using bash, the return value from the exec (which is the return value from main) is stored in $?. You can echo $? immediately after your program returns to see the integer return value. Once you run another command (including echo $? IIRC) $? will contain the new return value of the program you just ran, so you have to store it in a variable or otherwise use it immediately if you want to keep it. Sometimes shell scripts check the return value, but for the most part, actually returning anything from main seems pretty pointless. However, if you check the status return from wait, you can find out some nominally more useful things, like whether your program completed execution normally or crashed while it was running. This can be handy if you have a program that needs to be running full time but which is crash-prone, as you can just write a launcher program for your program that monitors the return status and restarts it if it goes down. Init does similar things when starting your system up. For the most part you don't "need to know" unless you're doing systems programming. If you are doing systems programming or you're just curious, read up on fork, exec, [dup2](https://linux.die.net/man/2/dup2) and [setpgid](http://man7.org/linux/man-pages/man2/setpgid.2.html). The latter two are used for controlling the child's stdin, stdout and stderr streams and breaking the parent/child relationship with the original spawning process. You don't need a whole lot more than that to write your own shell.
Ok let's say that i am typing something on my keybaord and is being printed out in terminal. For that i will use std::cin so system is returning string right? 
I appreciate your effort for writing this whole paragraph but i am a windows user not unix/linux. I am just learning C++ right now so 99% of things you said went above my head. I am sorry.
It's similar but not quite exactly the same in Windows. All these systems share a similar heritage and have similar concepts (Processes et al.) It's mostly academic anyway, unless you're planning to write your own operating system, but the more you know about the tools you're using, the more effective you can be at using them. Plus it's kind of cool how everything fits together.
[openFrameworks](https://openframeworks.cc/) uses it, but it was a pain in my experience.
Storing size like that can cause allignment issues.
I never tried it, I actually always thought it was purely commercial - like almost all Intel stuff.
Lock-free programming is also often slower than lock-based. I'd rather, under heavy contention, threads give up back to the scheduler rather than hammer the CPU with interlocked instructions.
I've run into use-after-free, mainly in bizarre legacy game code where everything was strange and arcane, and we were working relatively blindly without really understanding what was going on. Manually-handled virtual destruction coupled with a multiframe deferred allocator, with unclear semantics and comments in a foreign language that decoded to squares.
Even in Qt I don't use it...
Your allocator allocs memory with new and the default allocator (via unordered_map). It would make more sense to rewrite these to use the allocator itself.
cin - to read input, cout - to print the string
No, output has nothing to do with return. Read a C++ book, trial and error will not work.
&gt; trial and error will not work Until you enter the workforce.
&gt;but still... can't we do better? we have to at least try! ;) I believe it's fine to restrict the build process to some common cases - making the build/dependency workflows much nicer - and leave the more complicated cases to more complicated and cumbersome-to-use tools. By the latter I mean for example cross-compilation, which can be a bit tricky, or mixing the build of C++ together with other languages.
I suspect that the confusion here is something as follows. The output to the screen is not the same as the return value of the program. The former is what is produced as a result of the stream to std::cout The latter is an int value returned to the OS to indicate the exit state of your program. If left unspecified this is typically zero. It's as-if main had an invisible "return 0;" at the end of it. See [https://stackoverflow.com/questions/334879/how-do-i-get-the-application-exit-code-from-a-windows-command-line](https://stackoverflow.com/questions/334879/how-do-i-get-the-application-exit-code-from-a-windows-command-line) for the on-Windows recipe. So you could put a `return int-value;` at then end of your main, and %errorLevel% in your shell would have whatever int-value was set to.
This is wayyy more complicated than meets the eye. When we do `std::cin &lt;&lt; variable`, the return is not the value of `variable`. The value is the status of the `std::cin &gt;&gt;` operation. What's happening here is, `variable` is being passed as a *reference* to the function `std::cin::operator&gt;&gt;` (the fancy name for the function you're using). Then that function modifies `variable` so it contains your input, and returns an error code. Another subtle thing to notice is that calling a function without doing something like `variable = function()` throws its return value. So unless you have something like `return std::cin &gt;&gt; variable`, then `main` is not returning the return of `std::cin::operator&gt;&gt;`. If you don't have a `return` anywhere in `main`, I believe it defaults to returning `0` but that's dependent on your compiler.
The best IDE for C++ I've used so far.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; But I'm worried the words "relocatable" and "relocate" already hava a very definite meaning in computing, and it conveys the idea of changing data or code to adapt to a new location. I actually very much think it *is* in-line with that use. Code that is relocatable can be moved around, perhaps needing to apply some fixups. Code that is not relocatable can't be moved. Calling something *trivially* relocatable then naturally means that it can be moved without doing anything... and that's exactly what it means in *this* context.
In addition to the other reply, not that trivial relocatability isn't a property of the move constructor in isolation -- it is a property of the move constructor, the destructor, and the moves/destructs of all subobjects all in combination.
_Average_ constant-time complexity, provided the load factor is set correctly and the hash function isn't garbage.
Not if you want constexpr support.
People used the objecty-thing vs POD value reasoning for choosing struct vs class before C# came around. Presumably that's why C# did it that way. It's a very common style, not a quirky language-specific idiom.
I'm a CMake user, and Qt Creator is the best I've used so far.
Potentially interested - a few comments: &gt; Dependencies: 'mingw32' - for win32 only, 'freetype' - for win32 and linux These seem quite heavy. Why mingw32? What about MSVC? Or what do you actually mean with "win32" - 64-bit (x64) too? In general the dependencies are quite heavy in my opinion for a minimalistic rendering library. Why libvorbis, openal, freetype, if I never want to do anything with sound or text? Are these required or optional dependencies? General comment: It would help me to further decide about the library if the readme.md had a code example (or a few). You've got 10 examples there with pictures - cut that down to the three or five most important ones and add some example code instead that showcase your libary? About your directory layout: It's really a bit weird. I see `.cpp` files in there, so is it really header-only? Or a hybrid, you support both cases? And then I'd say that `min` is not really a too good namespace name - if your library is named `MGL` anyway, why use `min::` as namespace and not `mgl::`? But most importantly, you should provide a "namespaced" include directory. In your case this would be, from the root of your repository, a directory `include/mgl` (or `include/min`, if you really prefer that - it should match your namespace), and this is then the directory that people will add on the compiler command-line (or build system) to add your library - like `-I/home/user/github/mgl/include`, and then you can access all files with `#include "mgl/filename.hpp` from thereon (without having any build-system or unrelated files in there). In this way the #includes are always consistent, both inside your project and for external consumers, and the user has an include directory without any other cruft inside. 
&gt; The implementation you suggest suffers from the ABA problem! Lock-free programming is much more than 'throw-in-a-cas', especially with more complicated datatructures like hashtables Of course it does. My original, and then accidentally deleted comment explicitly addressed that, but you would have no way to know about that *shrug*. The suggestion to use lock free programming was as an alternative to a hashtable/hashmap for sizes in the known-size region. If you're using a complex structure like a hashmap, it'd be better to use a mutex. &gt; Also, if you're allocating common sizes out of dedicated blocks, no reason to put the size inline or at all. Proper block alignment will let you discover the block (and size) by masking the pointer. Could you please elaborate on this? How would this work with blocks that can be split later, if it would at all? 
A fancy idea to store sizes: Bucket your allocations based on rough size; each bucket holds allocations of size 2^n to 2^(n+1). There can be more than one bucket of each size. Each bucket holds a size table. If the bucket has K bytes in it and has a min size of 2^n, then the size table has size K&gt;&gt;n. An address in the bucket can be converted to an index in size table by doing (ptr-bucket_base)&gt;&gt;n. This should result in 0 collisions and use more than 50% of the space. If buckets have standized sizes, the bucket base can be calculated from a ptr. And the size table can be put before the bucket base. The standarized size assumption runs into problems with extremely large allocations. Reserve a huge amoung of address space, call it a "bin", and use standardized size buckets within that bin. Addresses outside that bin can be larger and slower. You can even steal memory from the top of the bin for large allocations, and/or have multiple bins. 
&gt; These seem quite heavy. Why mingw32? What about MSVC? You could use MSVC, but I choose not to use it. I wanted something that would build with GCC. I went the CYGWIN approach for Windows because you can readily get all the packages efficiently. &gt; Or what do you actually mean with "win32" I use the Win32 API on Windows, it builds just fine in x64. &gt; so is it really header-only? &gt; In general the dependencies are quite heavy in my opinion for a minimalistic rendering library Yes it is header only. I knew some people would want sound and text so I expanded those areas. If you use the sound header you need OpenAL. If you need the text header you need freetype2. The linker dependencies are optional. Side note, I would like to remove these in the future, but if you don't need them you do not need to link against them. &gt; About your directory layout: It's really a bit weird. I see .cpp files in there The CPP files are examples that showcase my 10 examples in the README.MD. I also have CPP files to compile a static library, which you don't have to use but I added as an example on how to do it if you need to do it. It also tests my #include are correct. &gt; if your library is named MGL anyway, why use min:: as namespace and not mgl:: This can be easily changed. I don't see this as a big issue. &gt; n your case this would be, from the root of your repository, a directory include/mgl (or include/min, if you really prefer that - it should match your namespace), and this is then the directory that people will add on the compiler command-line (or build system) to add your library - like -I/home/user/github/mgl/include Look at the makefile I do this. The include directory has subdirectories for file, geometry, math, rendering, etc. Although this isn't a hard separation so you need all of the subdirectories for general use case. This could be improved in the future. &gt; And names starting with two underscores are illegal I believe. Really? That seems weird but understandable.
Could you elaborate on the alignment issues please? Are you predicting a data structure with alignof() larger than alignof(size_t) ? While arbitrarily large alignment is possible, I believe that most implementations do 16 byte alignment on x86 systems. So my initial advice was wrong, and the extra space would need to be 2xsizeof(size_t), not sizeof(size_t). https://stackoverflow.com/questions/506518/is-there-any-guarantee-of-alignment-of-address-return-by-cs-new-operation Could you also elaborate on cache friendlyness of heap allocation? How would an arbitrary address returned by malloc be used predictably in a cache friendly way?
Fair enough. Thanks for your insight here. For what I do, having the thread yield to the scheduler would be pretty bad. But there are obviously lots of programming domains out there, and mine is only one of them.
You are correct, we can do more than just rendering. However the smallest usable case can be used for graphics only. If I advertised it as a game engine, people would be disappointed since the design is similar to "here is a bucket of algorithms, go use them as you need to" and not "here use my easy framework which solves all your problems". Your feedback is welcome and I will reflect on it for the next iteration. Thanks!
&gt; Are you predicting a data structure with alignof() larger than alignof(size_t) ? It's not impossible. Some systems have larger alignment requirements for certain kinds of things (think DMA transfers). &gt; Could you also elaborate on cache friendlyness of heap allocation? How would an arbitrary address returned by malloc be used predictably in a cache friendly way? If the data is closely-packed together, it's more likely that different pointer accesses will be accessing data already in-cache.
I would also like to comment on this. &gt; Your library seems much more than a minimalistic rendering library. Yes indeed the usability aspect is far from being minimalistic. The minimalistic nature is the code foot print. I feel like I have created a very small package as far as lines of code go to be called "minimalistic". You can create a game with this code and I have done so [here](https://github.com/Aaron-SP/bds) as a proof on concept.
I will fix the header include guards. Thanks!
Hey all! I'm here to address any questions, comments, complaints, or concerns!
&gt; &gt; And names starting with two underscores are illegal I believe. &gt; &gt;Really? That seems weird but understandable. In fact, names **containing** two consecutive underscore anywhere are illegal. These are reserved for implementation. That is why language extensions use keywords like `__attribute__` for example. There are a few other rules for reserved indentifiers as well. I recommend reading `[reserved.names]` section of the standard.
wtf? then why you guys have question mark flair?
It's surprisingly good. I started learning QT about a week ago and I thought I would not like the IDE as a someone that comes from VS and Intellij Idea. But wow, the IDE is well baked. Moving from the UI to code is swift. QMake seems simple and easy enough for my needs (hobbyist). It's fast and responsive and doesn't seem to have the clunkiness of Eclipse and Netbeans. It's pretty nice. Well done, QT.
So, I've a question. In my mind, a C++ `struct` is something that is purely data while a C++ `class` is data and logic. Because of the fact that they both encapsulate data semantically, they cannot be reordered/restructured by the compiler. What would be a good name for something that only semantically defines logic (it can have data, but the compiler only needs to guarantee that the data is functional for the logic, ordering and such doesn't matter)? Interface?
Thanks, I fixed it.
We don't...?
ah... sorry i misunderstood. i got confused between 2 different subs.
&gt; 'Lockless' just changes the granularity of the lock; it isn't necessarily better. Lock-free programming is a necessary step toward Wait-free programming. 
There really isn't that much grey area. A lot of types either have all data members private, joint invariants, and limited surface area. These are classes. Others are just a list of public data members. These are structs. In the vast majority of cases you shouldn't have any member functions when all data is public; this shakes out of Meyers recommended member vs non member algorithm. It's clear and useful enough that despite being somewhat arbitrary, it's in the core guidelines. If you think a lot of classes are grey, I honestly think there's either some misunderstanding of the guideline, or you're writing many strange classes.
No question, I just wanted to say thank you. Thank you.
&gt; Could you elaborate on the alignment issues please? Are you predicting a data structure with `alignof()` larger than `alignof(size_t)` ? Yes. You should at least align to `alignof(std::max_align_t)`. It likely is 16 bytes, not 8 (see https://godbolt.org/g/RpUDVh). A typical usecase for such alignments is using SIMD (data or operations). 
You're very welcome!
Ah. Thank you for the note about std::max_align_t. My day job involves a custom STL, and I don't think we have that. I'll have to do some reading!
I've heard many times Cisco is open to a remote employment - how one can find such (C++ related) positions?
&gt; It's not impossible. Some systems have larger alignment requirements for certain kinds of things (think DMA transfers). The other commenter noted that std::max_align_t is the ticket here. &gt; If the data is closely-packed together, it's more likely that different pointer accesses will be accessing data already in-cache. I'm having conceptual difficulty with trying to pack data together across multiple allocations coming out of malloc. Malloc allocates pointers from the available address space however it wants, doesn't it? So if I allocate two Foo structs, with "new Foo", I have no guarantees that both Foo structs will be close to each other in memory. Even if we assume that the allocator (e.g. the default stl one, for sake of example) starts allocating from the lowest possible address at program start, and then for each next allocation grabs the lowest possible address still available that matches the requested size, as soon as something frees memory that was previously allocated, subsequent allocations stop being contiguous in memory. Or, to summarize, the location in memory that two arbitrary allocations will live at is unbelievably hard to predict at best, and un-predictable at worst. So how can you pack the data closely together if there's no way to determine where in memory two allocations will live at? Maybe we're talking about two different things? Sorry I'm being dense.
Actually, identifiers that contain 2 consecutive underscores any where are reserved and should not be used, e.g. all of `__foo_bar`, `___foo_bar`, `foo__bar`, `foo_bar__` are reserved.
&gt; It would have been a great idea some years ago. However today we have Vcpkg, Conan, etc. therefore I don't think it's worth to spend time on it. I don't think vcpkg really solves the problem. It does not support specific/multiple versions of a library. Every built library is dumped into the same directory structure. You can't pin any version number. If you need to go back you have to fork the ports and partially revert them. If you care about your dependencies, which you should, you need one or more vcpkg instances _per project_, instead of machine wide. But then you waste potentially a lot of time by compiling libraries multiple times. I also hate the integration into msbuild since stuff is just magically available without ever specifying any dependency. With cmake one can at least use `find_package`. 
It isn't about guaranteeing that they're close, it's about increasing the likelihood of it. Smaller data sets and allocation algorithms which attempt to pack more closely will increase cache locality overall.
Well, Visual Studio 201x is still a bit industry standard. 
I don't see how you can even begin to increase the likelihood of any two allocations being closer together in a meaningful way. The system malloc is already allocating more than the requested size to store it's own meta data. An additional sizeof(max_align_t) is rather meaningless, unless you're allocating individual bytes. If the programmer wants things close together in memory for cache locality, they can allocate an array all at once, and then parcel out individual chunks from that array. That'll be guaranteed to be contiguous.
Hey I recently started working with C++ (comming from Java/Python). I wanted to use something else than Microsoft's compiler and tooling. But I quickly realised that the CMake and tooling world om general for C++ was a massive quite complicated. Is this project something that would help me get up and running with a C++ project without depending on VS and other Microsoft tools? 
\&gt; I don't see how you can even begin to increase the likelihood of any two allocations being closer together in a meaningful way. By not adding an extra 64 bits to each allocation, and by having the allocator internally favor patterns such as \&gt; they can allocate an array all at once, and then parcel out individual chunks from that array. That'll be guaranteed to be contiguous. The allocations don't need to be contiguous for this to matter, although it helps. - imagine an allocator which favors recently used memory and when it can't favors densely allocated blocks within the allocator. What matters is that your effective working set becomes smaller (especially if you do many small allocations), meaning that more relevant data fits in the caches and you get better cache hit rates
Thank you both for trying to explain.
Even without allocation patterns - if every object is smaller, with all other things being the same, the distance between two objects in memory will always be smaller. A smaller dataset reduces the memory required, thus reduces the mean distance between objects, thus improving the overall cache locality. If I put 100 raisins on a table, and 200 raisins on a different table, closely packed, the distance between any two random raisins of either table will on average be shorter on the 100-raisin table.
Depends what you're looking for. VS Code itself is a Microsoft tool, so you'll be using that at least. CMake can be a complex tool, but it's not hard to get up and running for simple projects. The purpose of CMake Tools is just to provide editor integrations for the CMake build system. You won't go wrong learning CMake purely because of its ubiquity in the C++ ecosystem. As for not using Microsoft's compiler: it's not hard to use MinGW or clang-cl with CMake on Windows. Using the MSVC compiler with Ninja is another great option: You won't have to deal with MSBuild and Visual Studio with that setup, but you'll still get the benefits of using the official Windows C++ toolchain.
What’s the difference between this and a tuple?
A tuple doesn't have any logic.
I do this just fine without thanks
Seems to correspond to Qt's Q_MOVABLE_TYPE http://doc.qt.io/qt-5/qtglobal.html#Q_DECLARE_TYPEINFO 
What state is the relocated-from object left in, then?
That's true until you have to resolve collisions. If you want to scale ad infinitum a binary tree scales quite nicely. The usual pitfall of that is to think you need a tree for each hash value; just share one tree for all collisions so now the hash is just small turbo boost in front of the tree.
That's true as long as you don't have any collisions to resolve.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/90k3xe/i_need_pointed_to_a_recommended_starting_point/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; Even without allocation patterns - if every object is smaller, with all other things being the same, the distance between two objects in memory will always be smaller. I disagree. If you have an address space of N bytes, and allocate two chunks of X bytes, the first chunk may be at address offset 0, and the second chunk may be at offset N-X. If, instead, you allocated two chunks of Y bytes, where Y is smaller than X, the first chunk may be at offset 0, and the second at offset N-Y. Now you've increased the distance between the last byte of chunk one and the first byte of chunk two by 2*(X-Y). The distance between the first byte of chunk one and the last byte of chunk two remains the same, however. Perhaps that's what you meant, and I parsed your sentence wrong. &gt; A smaller dataset reduces the memory required, thus reduces the mean distance between objects, thus improving the overall cache locality. Since they are, on average, closer together, this increases the odds of any two objects fitting together in a cache line. Sure, if the underlying allocator from the system is giving you memory chunks that are anywhere close to each other. But I suspect that the system allocator behavior is going to dominate any closeness by a large margarine. I also hope that the system allocator is performing some kind of address layout randomization, to protect against heap spraying attacks and such. So I'm very skeptical that there's any meaningful conversation to be had about the probabilities of two arbitrary allocations fitting in a cacheline together. I really hope the system allocator is at least *trying* to make that hard to predict. But I don't disagree that smaller objects are more likely to be closer together than large ones for an arbitrary allocator, simply because smaller objects can be packed more tightly. That doesn't mean I agree that they *will* be, or that we can make meaningful predictions about it, just that they *can* be. &gt; If I put 100 raisins on a table, and 200 raisins on a different table, closely packed, the distance between any two random raisins of either table will on average be shorter on the 100-raisin table. &gt; std::raisin_allocator Ehh, maybe? You're simultaneously increasing the surface area, which should increase your average distance, but also increasing the number of raisins, which may or may not increase the average distance. I'd need to do some calculations on this before I'm comfortable agreeing that this is the case (which I'm not planning to do, but I suppose I could if you thought it was important). Off the cuff I expect that there'll be a curve involved, where the average distance maybe starts out decreasing and then starts increasing as you add additional raisins, or perhaps the opposite, where it first starts increasing, and then decreases thereafter. Likely the second. I betcha it's some relationship between the radius of a raisin and the radius of the total surface area of raisins (since tightly packed roughly-circular objects will form roughly a circular shape). But, again, I don't think this really makes a big impact. It shouldn't be possible to use the system allocator to get tightly packed memory, because that'll make it much easier for an attacker to inject malicious machine code, versus a system where the heap is randomly allocated from. 
Clang backend went from using 3-4gb of ram to around 350mb. Awesome. Locator is amazing, learning the commands sped up the development but I would like to see a customization of those. Is it already there? Something like VS's "c" for class, "f" for function etc. Using snippets also helped with mundane tasks like deleting copy/move operation. Can't figure out the use case for macros and I havent tried using remote linux yet. What Im missing the most right now is VS's diagnostic tools - memory profiler or whatever it was called. QtCreator's support for writing plugins sucks a little bit as well. Great tool, good shit.
I like that one. It's a lot more precise than my scheme.
So add new keywords to solve a problem modules will already solve?
How is related to modules?
&gt; no include required
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/90kfcs/why_is_this_vector_not_working_in_my_class/e2r2q5o/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I switched to Qt Creator from MS Visual Studio six years ago and never looked back. Best C++ IDE for me.
`type&lt;const int[N]&gt;&amp; x;` is easy to get working.
Hi, r/cpp! I'm reading this thread and I appreciate the feedback. To respond to a few comments, 1. It is not a joke. It is intended to provoke discussion. 2. As has been mentioned, there has been a long-standing desire (by at least some fraction of the standards committee) for standard C++ to include some mechanism for graphical user interaction. If you're interested, I recommend reading sections 4 and 5 of "Directions for ISO C++" (by B. Dawes, H. Hinnant, B. Stroustrup, D. Vandevoorde, M. Wong), [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf) 3. I also recommend reading, "Diet Graphics" (by B. A. Lelbach, O. Giroux, Z. Laine, C. Jabot, V. Romeo), [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1062r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1062r0.html) \- I view my web\_view proposal as taking the underlying approach behind this proposal to its logical conclusion (in the sense that it addresses use cases involving both input and output across many platforms). Moreover, I think that it's important that ***if*** we end up proceeding in this space, we end up with something with which production applications can be written. We might well decide that we can't do anything reasonable in this space at this time. 4. I certainly understand that interacting with HTML, etc. is cumbersome in C++ (especially as presented in the example in the paper). I fully expect that, if we decide to go down this route, additional utilities and abstractions would be added to go along with it. Also, even with only the presented interface, I can certainly imagine constructing a program with mostly-static HTML input combined with some kind of reactive JavaScript library (e.g., Vue.js ([https://vuejs.org/](https://vuejs.org/))) that's reasonably clean (at least in the sense that it does not involve the gratuitous composition of markup text in C++, although it might involve use of JavaScript injection to update values). 5. Many of the concerns here (e.g., quality of the external standards, update frequency, security concerns) have also been raised by members of the standards committee and are important parts of the discussion. I intend to post a revised proposal before the next committee meeting. This will, in part, incorporate feedback from this thread.
You're right, we do work with a lot of people all over the world, many of them teleworkers. That's actually one of the great advantages of the collaboration technology that we work on. I put this posting up earlier today as soon as we got the job opening but before I had a chance to talk to the hiring manager about remoteness, and felt it was better not to make assumptions untill I had. I've since cleared it with them that we would be willing to accept a remote candidate if they're a great fit. I will update the listing now. So, apply to the addresses linked above if you're interested! I'd be happy to answer any questions about the role. Ask here or PM me.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/90jxel/how_many_decimal_places_are_usedcalculated_with/e2r3qog/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
A non-standard state where it's the user's responsibility to ensure that the destructor isn't run, but the memory is freed or reused. See [this comment chain](https://www.reddit.com/r/cpp/comments/906gzo/announcing_trivially_relocatable/e2o6fls/).
I must admit to using a similar idiom myself in the past. Not in any recent or new code, however. One learns!
I'm really not trying to be contrary, but I think you're still missing the core problem here. The C++ standard is not a compiler. &gt; non-aliased object That's not really something that can be expressed in the C++ standard. The standard only works in terms of value categories. There is _no_ concept of aliasing or the like; the only references to such topics are in non-normative notes. C++ is not specified in terms of how a compiler actually works, but rather in terms of some very abstract translation phases and in terms of semantics deriving directly from grammar. There's no standardized use-def translation phase and we can't express "non-aliased object" directly via grammar aside from very specific and restricted cases (e.g. `return identifier;`). &gt; without any subsequent operations mutating the object, or any subsequent operations referencing it You're placing a requirement on use-def analyses, for which the standard does not yet even acknowledge the existence. :) &gt; I get different compiler behavior from LTO than without it (on GCC in particular) - for instance, templates which shouldn't be resolvable suddenly are. So, I already get different results for different compilers. Which either is non-conforming behavior (e.g., a vendor extension, and not within scope of the standard) or reliant on implementation-defined or undefined-behavior (owning to the ancient crusty C linkage model and hence a necessary evil). Linkage is pretty weakly specified in C++. There's absolutely zero mention of dynamic vs static linking, weak vs strong symbols, non-TU-based symbol visibility, etc. All those "common" technologies are either vendor extensions or implementation details, and just _very important_ ones. The C++ standard pretty poorly represents the actual tools and processes of building C++ code, unfortunately.
Microsoft wrote in a msft forum at some point, years ago that they were abandoning support for OpenMP. They have no intension, last I read, to update openmp support. At work we've gone with Intel TBB (now under.. MIT license wasn't it?)
While it's a bummer that CMake is the one gaining massive traction, with all it's flaws, I am still thrilled that the C++ community is finally "standardizing" on some build system. Hopefully with all the attention CMake is getting, it will mean their documentation will get better, especially with cross compiling.
How are you running clang on windows? 'Any experience with OMP in that config?
Technically, std::vector can't be implemented in strictly conformant c++. The implemention requires things that are UB when done outside of the standard library. I think the key() method on c++17 node handles is the same.
Hey, I'm having a weird issue after updating to 1.1.0. I get this in the output when I configure or build: [rollbar] Unable to automatically determine compiler {"lang":"C","fileGroup":{"compileFlags":"/DWIN32 /D_WINDOWS /W3 /MDd /Zi /Ob0 /Od /RTC1 ","isGenerated":false,"language":"C","sources":["main.c"]}} [rollbar] Unable to automatically determine compiler {"lang":"CXX","fileGroup":{"isGenerated":true,"sources":["build/CMakeFiles/f7740a9a59a2cce30d1014dc2172041e/generate.stamp.rule"]}} [rollbar] Unable to automatically determine compiler {"lang":"C","fileGroup":{"compileFlags":"/DWIN32 /D_WINDOWS /W3 /MD /O2 /Ob2 /DNDEBUG ","isGenerated":false,"language":"C","sources":["main.c"]}} [rollbar] Unable to automatically determine compiler {"lang":"CXX","fileGroup":{"isGenerated":true,"sources":["build/CMakeFiles/f7740a9a59a2cce30d1014dc2172041e/generate.stamp.rule"]}} [rollbar] Unable to automatically determine compiler {"lang":"C","fileGroup":{"compileFlags":"/DWIN32 /D_WINDOWS /W3 /MD /O1 /Ob1 /DNDEBUG ","isGenerated":false,"language":"C","sources":["main.c"]}} [rollbar] Unable to automatically determine compiler {"lang":"CXX","fileGroup":{"isGenerated":true,"sources":["build/CMakeFiles/f7740a9a59a2cce30d1014dc2172041e/generate.stamp.rule"]}} [rollbar] Unable to automatically determine compiler {"lang":"C","fileGroup":{"compileFlags":"/DWIN32 /D_WINDOWS /W3 /MD /Zi /O2 /Ob1 /DNDEBUG ","isGenerated":false,"language":"C","sources":["main.c"]}} [rollbar] Unable to automatically determine compiler {"lang":"CXX","fileGroup":{"isGenerated":true,"sources":["build/CMakeFiles/f7740a9a59a2cce30d1014dc2172041e/generate.stamp.rule"]}} &amp;nbsp; A seperate minor issue, the new buttons in the CMake tab (Configure, Build, Clean, Clean Rebuild, Clean Reconfigure) show up in the command pallet, but without the "CMake:" prefix that previous CMake Tools commands had. And the "CMake:" commands still show up in the list alongside the new ones. Imo these should be unified - maybe add the "CMake:" prefix to the new buttons on the CMake tab and remove the old commands?
Just moved from Clion to qt creator - never going back. Love it and its free.
Do you know if there is a demo or example of ninja + msvc somewhere? The last time I tried that combo i couldn't get it to work (though that was a while ago). 
there's a locator tab in one of the options menus that lets you configure prefixes for the global locate, and in the keyboard settings you can a hotkey for certain locator subsets as well
If you mean installation, it's quite trivial. However, I think you need the MSVC stdlib, i.e. you need to install some Visual Studio. I don't know about CMake or other build tools, I'm using my own custom solution: https://github.com/Trick-17/clang-build Basically, you can call clang from any command prompt, where my build tool uses Python for that to automate things. Visual Studio has some integration for clang as a backend, but I wasn't able to get it working myself.
What didn't work? Are you familiar with how to use CMake, in a general sense? If so, literally all it takes is: `cmake &lt;path to project root&gt; -G Ninja` with ninja in your path.
Doesn't clang-cl need to use the msvc standard library? Or has libc++ progressed far enough on windows now?
Ninja is the default if you use CMake within Visual Studio, so it must work nicely with MSVC. According to https://vector-of-bool.github.io/docs/vscode-cmake-tools/kits.html CMakeTools will prefer Ninja, so I guess stick ninja.exe on your PATH and see if it works?
[Portable bitfields](https://blog.codef00.com/2014/12/06/portable-bitfields-using-c11)
Any references for those? I can't find anything with a quick search.
https://www.reddit.com/r/cpp/comments/67xpeg/is_there_an_obstacle_to_implementing_vector_in/
Yes I am familiar with Cmake. I don't remember what didn't, but if it's just that simple then I'll try again. 
For the record (as I've previously mentioned on Reddit), the compiler intrinsic for `std::make_integer_sequence` was my idea, and JonCaves implemented it in C1XX first. I sent the idea as a request to David Majnemer, who proposed a rename (I originally suggested `__make_integer_sequence` but that conflicted with libc++, so we renamed it to `__make_integer_seq`) and then implemented it. I like to claim the credit for this idea not just because I'm a stickler for accuracy, but also because it's the definitive example of my personality as a Standard Library implementer. I was told that libc++ (and possibly libstdc++) went to a significant amount of trouble implementing `std::make_integer_sequence` with clever library-only code, emitting a logarithmic number of instantiations. MSVC had a simple linear scheme, and users were complaining about the comparative expense. So instead of doing difficult, clever work, I decided to take a gloriously lazy path that was also superior for users - get the compiler to do the work (because it can emit the sequence almost instantaneously).
r/cpp_questions
Just tried out the project outline view. Very useful! Any chance that header files could also be listed in that view?
I must have missed it, thanks.
Is anything these days? Even the results of std::sort differ across compilers when you have multiple elements with the same sort order. It's not strictly useful to care about these things. It *is* useful to care about things you need to: for example I don't have to care about my code not working on non-x86 CPUs because it will never run on them.
Yes. MSVC is known for their ABI changes, so is GCC https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html
&gt; You could use MSVC, but I choose not to use it. This, particularly using C++ is extremely limiting mgl's usability on windows. &gt; I wanted something that would build with GCC. If it builds with gcc, it will also build with Clang/LLVM natively, make a simple cmake project (get rid of make) and you're on your way. &gt; I went the CYGWIN approach for Windows because you can readily get all the packages efficiently. Yes, but now everything built will have a dependency on cygwin1.dll (or something like that name). Using vcpkg will get you all the packages efficiently as well (chocolatey and others are other options).
I would write a type renderer for a debugger if struct layout is relatively stable
Really? I thought that only starting with a double-underscore was not allowed :o
&gt; It's not strictly useful to care about these things. For the large majority of software engineering projects, it is very important to care about undefined behavior. It is a total misunderstanding to look at strict aliasing rule and think "this doesn't matter if I only care about x86". See for instance expert opinions here: https://stackoverflow.com/questions/32272603/is-undefined-behavior-only-an-issue-if-you-are-deploying-on-several-platforms
The op explicitly asked for the compiler / language ABI, not if the abi of the standard library changes. In particular gcc is known for it's relatively stable ABI (even the standard library has only one breaking change in recent yearss). Not sure about msvc.
If memory v serves right, this was a great product 10+? years back. What compiler (version) are you using these days? How is support for c++17 and static/dynamic analysis tools like address sanitizer?
Name mangling is somewhat constant with GCC, but definitely not with MSVC. Afaik the standard says nothing about this part. vtables are constant as far as I observed (not sure about the standard). It worked like a breeze to use an ANSI C interface and just share class interface pointers. Just make sure to check the calling conventions and only user primitive types or self defined structs or interfaces as parameters.
You should use interfaces for this purpose. Vtables with VC++ (and Clang targeting Windows) must be compatible with COM calling conventions. Microsoft uses this for their own Windows APIs. Note that your interfaces don't actually have to derive from COM's `IUnknown`, you can use your own (like [foobar2000](https://www.foobar2000.org/SDK)).
If the `std::` part really is that horrifying, do `using std::move;`.
Very clean code thumbs up! Just small suggestions: \- Is there a good reason for using const char\* everywhere as oppose to let's say std::string\_view? \- Use std::make\_unique&lt;TireNode&gt;(); instead unique\_ptr&lt;TireNode&gt;(new TireNode); \- I'm not sure if you have to initialize children\[26\]. unique\_ptr's default constructor should take care of itself.
Good read. &gt; Side note: Using size_t is potentially even better on x86-64, since the function won’t even need to do sign extension. However, this might simply move the sign extension out to the caller. Could you elaborate on that, I think I get it, but want to be sure (possibly add to article as well).
For GCC, the produced ABI depends on the fabi-version switch, see here: http://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Dialect-Options.html Using the same switch will retain compatibility but the default of 0 will change with GCC versions and produce incompatible code. Between GCC and MSVC, there was never any form of compatibility, and there cannot be any, as not even the mangling is the same. Between msvc versions, there is no compatibility either, as long as they use a different runtime library version. VS2015 and 2017 are explicitly compatible though. Using a different runtime library will already break things like new and delete. Interfaces - that is to say pure abstract classes that don't transfer ownership - have to remain compatible on Windows, since that's what COM APIs use, but that's a result specific to MSVC. This assertion holds in practice for GCC as well but there's no official guarantee for it. The Steamworks API uses this method in cross platform applications and it seems to have panned out for them so far. This still won't obtain GCC&lt;-&gt;MSVC compatible code though.
&gt; I can simply use checkprime() and there we have it. I like this one even better, writeprogram().
What's with the .NET 3.5, that version doesn't even come out-of-the-box with Windows-10-1803? I read the answer: "Some apps don't run without it", but we're now on .NET 4.7 (which is included out-of-the-box).
Fairly impressed by the inline hints with fix-its in this version - first it warned me about a loop such as for(auto it = ...; ++it) { // stuff with it } and changed it automatically in a range-based for-loop, and then warned me about a repeated push_back into a vector in this loop without calling `.reserve()` before.
How do you figure that name mangling changes with MSVC? My reasons for believing they don't: 1. There is a Windows API to reverse it (https://docs.microsoft.com/en-us/windows/desktop/api/dbghelp/nf-dbghelp-undecoratesymbolname). It doesn't take a "compiler version" parameter. 2. Though not officially documented, someone pieced the scheme together (http://mearie.org/documents/mscmangle/). In that document there is no indication of change between compiler versions. In fact they don't even mention, which version they are talking about. 3. Unless it is buggy, there is logically little reason to change the scheme.
\&gt; free \&gt; Revenue Restriction: less than $5000 USD or local equivalent \&gt; Restricted to teams and organizations with fewer than 5 developers 
`std::swap()`should not invalidate references, iterators and pointers, svo will not guarantee that.
&gt; I certainly understand that interacting with HTML, etc. is cumbersome in C++ (especially as presented in the example in the paper). I fully expect that, if we decide to go down this route, additional utilities and abstractions would be added to go along with it. Also, even with only the presented interface, I can certainly imagine constructing a program with mostly-static HTML input combined with some kind of reactive JavaScript library (e.g., Vue.js (https://vuejs.org/)) that's reasonably clean (at least in the sense that it does not involve the gratuitous composition of markup text in C++, although it might involve use of JavaScript injection to update values). at this point why not directly standardize Qt ? It is well-integrated in C++, already solves the event loop question which is necessary in any kind of UI work, and provides a true declarative and reactive language for user interfaces (not like the simulated reactivity in the eDSL of vue.js) with well-specified interoperation with C++.
Now automatically detects clang-cl and the env for it. Thanks for the great work!
If it's all public, which in case of an enum is the case, it **should** be an enum struct, as it expresses the intention, for the whole thing to be public. There's also the `typename` vs `class` thing in template parameters, cppreference.com uses `class` consistently. I think it's irritating, it's a `typename` (it is what it says it is).
You might want to read about the standard library and then possible install an IDE like CLion which may have a nice auto completion for methods in a library.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
i have little experience in this area, but i would also worry about alignment in the structs you send across the boundary. i don't think this is all quite standardized. 
Interesting blog!
There's no such setting. Contest mode stays forever or until a mod changes it.
&gt; the compiler intrinsic for `std::make_integer_sequence` was my idea Apologies! I didn't mean to imply that clang had invented it, only that it was the only one I was aware of.
Microsoft declared that vs2015 c++ is binary compatible with vs2017. They did not mention vs2010 so I believe they're not. Also I know from past experience that vs2003 was not compatible with vs2010. 
Doesn’t “implementation defined” provide all the same benefits as “undefined” without sending you into the realm of “all bets are off”? Personally, I’ve worked on enough code bases that have had to migrate to new platforms multiple times in their lifetime, that I’d prefer if everything was defined by default and we could explicitly marks blocks where implementation defined is allowed to let the compiler do extra optimizations. That way we could only ask for such optimizations where we’ve measured &amp; know that we need them. And when moving to a new platform, it would be easier to find those places and reëvaluate them.
&gt; Using a different runtime library will already break things like new and delete. That should only be a problem if object ownership is transfered (i.e. an object that was created on one side of the ABI is deleted on the other side), right? And even if such behavior is needed (which might not be the case), it could still be solved by using a smart pointer that stores a deleter.
The windows API (and many other C APIs) uses structs extensively. So I think alignment should not be an issue.
There are no stability guarantees about name mangling with MSVC. It's mostly the same with new stuff tacked onto it. There are few minor pitfalls though. You can look through [Clang's mangler](https://github.com/llvm-mirror/clang/blob/master/lib/AST/MicrosoftMangle.cpp) (look for `isCompatibleWithMSVC`).
There are 3 special classes of behavior, in order of leeway: Implementation Defined Behavior, Unspecified Behavior and Undefined Behavior. - Implementation Defined Behavior: the toolchain must pick a behavior. For example, gcc on x86 represents signed integers as two's complement (the other possibility being ones' complement). - Unspecified Behavior: the toolchain can pick some behaviors, not necessarily a single one. For example, while gcc chooses to evaluate function arguments from right-to-left, it could introduce an exception like "except that vector arguments are evaluated first" or even a dynamic condition like "except that on threads with an odd ID, they are evaluated left-to-right". - Undefined Behavior: here be dragons. So, yes, in general Implementation Defined Behavior and Unspecified Behavior are much more user-friendly, although since MSVC decided to evaluate arguments left-to-right, they may cause portability issues. However, the programs they produce behave *deterministically* and have a *small* number of possible outputs. Many thing that some of the instances of UB should instead be reclassified as Implementation Defined or Unspecified. For example, one could follow Rust's lead on integer overflow where it's Unspecified Behavior: by default it causes an abort in Debug and simply wraps in Release. However, some UB will remain. Use-after-free and double-free, out-of-bounds access via pointer arithmetics, ... those cannot be statically eliminated at compile-time, and the run-time overhead (memory &amp; CPU) is simply too high for many programs. Still, I do agree that **trimming down** the amount of UB would be a net gain for the C and C++ languages.
I have fond memories of Borland products, that's how I learnt programming in the nineties. Saw this posted elsewhere and decided to post the link here. Then tried installing it in a Windows 10 VM. It required .NET 3.5 which it started installing but failed immediately. Not looking good so far.
In [clang's MicrosoftMangle.cpp](https://github.com/llvm-mirror/clang/blob/12e2fde/lib/AST/MicrosoftMangle.cpp#L1432) it is mentioned that MSVC 2015 mangles empty expanded template packs as `$$V` while older versions mangle as `$$$V`.
I'm just a curious former user of Borland C++, I have no association with Embarcadero, so I've no idea what they use.
I have too, Borland Turbo Prolog 2.0, pretty good, it's now re-licensed back to [pdc](https://www.visual-prolog.com/). But back to the subject, it's not good at all. [To install .NET 3.5 you'll have to use your install media and dism.]( https://winaero.com/blog/offline-install-of-net-framework-3-5-in-windows-10-using-dism/), not that you need it.
That "freeze" time during startup is somewhat reduced. I guess it is better to put some splash screen or loading instead of the screenshot...
It's a pure observation. At work I started with VS 2008 and the same functions had a different representations (in e.g. Dependency Walker). Of course it wasn't possible to use such a library from an other VS version. MS says it's on it's own website, that it changed several times: https://msdn.microsoft.com/en-us/library/56h2zst2.aspx My guess for the API for reverse the mangled name is, that it somehow interact with the VC runtime to identify name. Of course, it makes no sense to change the mangling, except if they never put any effort into making it the same. In first place all those decoration are needed to glue two compiled entities together and to make sure, they're unique. MS basically forced everyone to use the same VS version (or have multiple, at least). However, it is somewhat easy to deal with this: static linking of your library (so the VC runtime is not a dependency any more) and your own ABI via class interfaces. Libs on Windows are just a pain in the ... so I just use DLLs and never had any issues with the customers. This even works with GCC DLLs on Windows.
https://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Dialect-Options.html#index-fabi-version
That should be fairly straightforward to circumvent. Using variadic temolates in an ABI is problematic anyway (how many explicit instantiations would you need to provide in the binary?)
Ownership, exceptions, and potentially other things. As said, an ABI guarantee is not made, so anything beyond interfaces may or may not break (in the future).
Boost beast? https://www.boost.org/doc/libs/1_67_0/libs/beast/doc/html/index.html 
I wouldn't say it fits the description...
Maybe [RESTinio](https://bitbucket.org/sobjectizerteam/restinio-0.4) would fit the bill?
There is [this](http://siliconframework.org/). However, in the spirit of traditional and modern C++ I would use a combination of Boost.Beast and the JSON library by nlohmann.
I think the author is saying that the caller of the function `int sum_sizet(int *vals, size_t i)` may need to do some extra work to convert from an unsigned int to a size_t outside of the function call, negating the performance gained by removing the sign extension inside the function.
You will also have to stay clear of trans-boundaries allocation/free. You might also have to stay clear of other things I can't think about immediately. Probably you should at least disable LTO, otherwise you risk reaching some kind of "virtual" ODR violations (modern compilers will happily exploit properties about what they think can not happen, and different versions might have different ideas about how to do that, leading to incompatibilities because what you think of the layout is now nowhere near the full-story). Disabling LTO might not even be enough if, like often, you put your implementation of all the methods of a single class in a single translation unit. So let's just say it is an audacious project, and if it has anything resembling safety requirements (like it connects to anything using a socket, or you must be confident that the design is sound), just don't do it beyond what compiler vendors claim. MS claim to have C++ binary compat between MSVC 2015 and 2017. That's it. The situation is better for libstdc++ under Linux, but even there except maybe if you learn by heart the Itanium ABI, I would not recommend that approach to target versions too far away (and the compilation chain risk to use modern symbols behind your back, too, so it's not trivial to setup something that will allow you to target different versions, and even less different systems, using the dynamic libraries provided by the distro). [ But if you use a single toolchain, at least you can freely decompose single programs into multiple .so over there, without random restrictions about which feature of the C++ languages you are allowed to use across their boundaries, which is not the case at all with .dll under Windows -- which makes me think that Windows might be constraining the evolution of the Standard, btw ] 
Try Poco libraries.. it has similar design to java libraries
Any insights as to why the Java version is faster than C++?
While good in theory, even that can punish architectures substantially. Even for things as simple as numeric operands, UB protects differeing behavior on alternate architectures. The biggest reason for this in my experience is processor flags! One such example I have is shift-by-greater-than-size. This is UB in C++. The X86 instruction is a 'mask', the processor itself doesn't even check bits outside the range (so a shift by 33 is likely a shift by 1). ARM on the other hand, saturates the register, so the same shift by 33 results in the register being all 1s or all 0s (based on the value of the MSB). OpenCL makes the mistake of specifying the behavior of shift as 'mod' (the x86 behavior), so any ARM core running an OpenCL program is forced to run 2 separate instructions! A mask (which is a mod in powers of 2), followed by the shift itself. This puts ARM at a distinct disadvantage! HOWEVER, you said implementation defined! Why can we not simply specify each of these as valid implementation behaviors? The answer lies in the carry flag. When the shift amount is in range, the carry flag always holds the last bit shifted out. This holds on x86 as well, since it simply does the mask/mod. HOWEVER on ARM, the carry flag is the MSB! The danger here is that further logic in the program might very well depend on the carry flag. Subsequent instructions can often take flags as inputs. We can't make 'a subsequent, seemingly unrelated, conditional having a different result' part of implementation defined behavior. Thus, UB. However, typically when I mention this, someone brings up "well, what about a UB that promises not to time travel?" The difficulty here is that reordering of instructions is typically very useful, so you'd lose the ability to ever do code reordering.
Personally I read “undefined behavior” as “you are not allowed to do that, but we might not always be able to catch you if you do it nonetheless”. Most UB implies bad code near it and I really like banning bad code. 
I've written an experimental one with a similar goal. https://github.com/guan-jing-ren/native-2-web 
Shift in x86 is not always a mask either! If you're shifting r8 or r16, the mod continues to be by 32, and there's no mod at all shifting words of xmm registers with e.g. PSLLQ.
move is a pretty bad name for it, too.
Nx library : https://github.com/ddway2/nx Asynchronous http library based on asio + websocket lib
https://github.com/ipkn/crow/blob/master/README.md 
It's not undefined behavior to continue running the program if an exception occurs. That's what catch blocks are for after all. However, it's certainly not a good idea to use exceptions for everyday control flow since they are fairly slow and can be too easily ignored. Edit: also, this isn't /r/cpp_questions
&gt; Most of the time you actually don’t want overflow to be defined, and instead allow the compiler to assume it just doesn’t happen. Most of the time, I want overflow to be defined and to crash the application. That way, I can quickly and easily figure out if I have a bug and where it is. The minor performance improvement is worth it only in rare cases.
An operator that gets passed something like a parse tree. Standardized. It returns either a result or a "do not rewrite" token type. When you assign or construct a T from an expression: Foo x = a+b*c; first the compiler does `b*c` then adds that to `a`. Then it checks `Foo::operator parse( tree&lt;A&amp;, plus, tree&lt;B&amp;, times, C&amp;&gt;&gt; )` to see what it returns. If it is not found via overload resolution or it returns `do_not_rewrite` nothing happens. If it returns a `Foo` the code written for `a+b*c` is discarded and replaced with a call to `parse`. Maybe there is a way to make the rewrite more transparent; have it return a parse tree itself, so it can compose.
How is that supposed to work? That'll just lead to infinite recursion when his allocator calls into itself to allocate memory, which leads to an insert into the unordered_map, which has to allocate memory from the allocator, which leads to an insert into the unordered_map....
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
That's dangerously close to `Meowtilator`
Does Intel TBB work on non-Intel platforms?
Yea but I don't think there's any good alternative to this... Given how common this type of code is, `static_assert`ing the size to guarantee alignment and working only on one platform is likely to be OK.
&gt; Even the results of std::sort differ across compilers when you have multiple elements with the same sort order. But that's implementation-defined behavior (and you have `std::stable_sort` to solve that problem). Very different from UB. With that said, type-punning is very common so I reckon most popular compilers support it in C++ (since they very likely also compile C). I can't imagine the UB of such behavior would be very helpful for optimizations, and making it UB would be just too dangerous given how much C code is used in C++ projects...
And if you come from expressjs background you would find nice that RESTinio has [express-like router](http://test.stiffstream.com/en/docs/restinio/0.4/expressrouter.html). And on any help with it you can ask me ;)
Sounds like yes; on AMD and ARM processor too. But not tested myself. 
Ah, right. Use-after-free &amp; things of that ilk being undefined seems fine.
How do you figure that exceptions don't work? Of course I have to stay away from std::exception, etc. but with own exception types I don't see any problem. Keep in mind that I don't need guarantees as in 'some standard document says this is safe'. It is enough for me that in practice most things don't change. The only thing that really changes is the implementation of the standard lib, and very few minor details. Think of it this way: before C++11, you could not rely on the memory layout of the data in a vector. Still every important implementation did what C++11 standardized. That is good enough for me.
Check out [Uniform Forward And Move](https://groups.google.com/a/isocpp.org/d/msg/std-proposals/F2kuIycC_4w/iphRuZHWAAAJ) 
Can you share a code example that somehow manages to do something with that carry flag? Because I don't see how you're going to be able to do that from C++. 
Ah, sorry, had read: &gt; What would be a good name for something that only semantically defines **logic** as &gt; What would be a good name for something that only semantically defines **data** It seems like the kind of interface you’re describing is more akin to an abstract class, but why would it have data at all? Can you give an example of what you mean by only “semantically defines logic”?
What are your requirements? Most webservers are written in C/C++.
Really? I thought committe thinks packages management is not in their scope.
Perhaps, it will be a topic for the next article.
we need `&lt;animal_traits&gt;`
Be *extremely* careful with following the make-const suggestions. Resharper C++ only checks if the code would compile with const, but that's rarely what you want, for example if you ever have pointer or reference members without propagate\_const. I've filed an [Resharper C++ issue](https://youtrack.jetbrains.com/issue/RSCPP-16523) for that. I'd like it to be conservative, and *not* suggest adding const if const is sneaked by via pointer and reference members. - propagate\_const is not even in the standard, and it's still possible to mark those methods const by hand.There is a similar open [issue with the core guidelines](https://github.com/isocpp/CppCoreGuidelines/issues/566).
Exceptions use their own unwinding scheme? Every implementation uses their own unwinding handlers and they're part of the standard library. They're in no way standardized, and on for example Linux you have libc++abi, libunwind from GCC, libunwind from LLVM, and there's no guarantee that even within and implementation they remain compatible. They generally do not. Furthermore, exceptions may need to be copy constructed, depending on the type of the catch clause. This means they will require special member functions to be called, and that happens to get broken often with GCC and MSVC (see the fabi-version link). This isn't the kind of "data of a vector may not be contiguous" but rather bound to break sooner or late.
Includeos has chosen to use a design inspired by express, so you may find that quite familiar http://www.includeos.org
Thanks, I installed .NET 3.5 by following the instructions in the article, and then managed to install C++ Builder.
Also OP is mostly likely not the author. /u/vormestrand regularly posts articles in /r/cpp.
You're correct, /u/skeeto would be the author. He would be able to answer OP's question.
Think a class. It can contain state, but how the state is set up internally isn't important. The ordering, data size, etc is completely irrelevant, unlike a class where, like a struct, maintains its ordering. Basically, a stateful interface where you don't care about the details of the state - the compiler is free to optimize members as it pleases.
Nontrivial types in unions are only allowed since C++11, afair. The caveat is, that the standard doesn't give you default move or copy constructors, move or assignment operators, default constructors and destrictors. You have to provide everything yourself, but for the intended use-cases that is ok, imho.
Wasn't includeos a complete unikernel? If so that seems kind of an overkill...
A vertex buffer that implements rendering meshes seems a strange abstraction...
This one's good: https://github.com/eidheim/Simple-Web-Server
&gt;at this point why not directly standardize Qt ? That's a good question, and moreover, we have C++ committee members who are very familiar with Qt. However, the API surface is huge, and I don't see how we could practically create a high-quality standards document for an API that large. From [http://doc.qt.io/qt-5/classes.html](http://doc.qt.io/qt-5/classes.html), there are 1,594 classes in the Qt 5 API. From [http://doc.qt.io/qt-5/functions.html](http://doc.qt.io/qt-5/functions.html), there are 12,984 functions. I don't know exactly how much committee time would be spent on each function, but I think 10 minutes per function, on average, seems optimistic. If we stick to our "regular" schedule at meetings of approximately six 12-hour days, it would take approximately 30 meetings to get through the entire API. We generally have three meetings per year. This seems completely impractical, and moreover, the library working group already has lots to do. In addition, I don't really see the committee taking a hands-off approach to the content of the interface. Even if we could start with the text of Qt's documentation, we'd need to make sure that each class and function were specified in sufficient detail to allow for an independent (clean-room) implementation. I'm sure that suggestions would be made to change aspects of the interface to better expose capabilities of different vendors' underlying implementations, and future systems, and these would be discussed. I'm sure that there are some aspects of Qt's current design that reflect a history of (primarily, I presume) targeting desktop applications, and changes would be desired to make things more natural for mobile platforms. And so on. In short, I think that, even starting with a fairly-holistic preexisting API, such as Qt, what we ended up with would be obsolete before the document could be published. Even if we cut the scope down to only a 10th of the current API, I suspect that the same would be true.
A lot of cases of UB can't be made IB without runtime overhead. E.g. writing out of bounds. What exactly happens as a result depends on the current memory layout when it happens, what optimizations the compiler applied and what code will later read from that location. AFAIK the only way to turn this into IB would be to perform range checks on any potential out-of bounds access.
There's things you can do, but there's corner cases with undefined behaviour: [https://stackoverflow.com/a/49090642/1149664](https://stackoverflow.com/a/49090642/1149664)
The regular `clang++` driver works for either STL, controlled by passing `-f[no-]ms-compatibility`. The `clang-cl` driver is half-assed and I recommend avoiding it regardless of which you're targeting.
Not from the source code directly, but the compiler may be able to take code that reads a bit from the value and then shifts it into code that shifts the value and then uses the carry flag.
The committee formed a study group dedicated to tooling, including package management: SG15. There are a few papers this year already under this subgroup.
Try Crow
So you want to be able to use [Rust's strategy](http://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/). By default it crashes the program with a message if any signed or unsigned integer overflows in debug builds, and is defined to use two's complement in release. This is a bit less convenient for unsigned integers, but the standard library has functions like `wrapping_add` to get C++'s unsigned int behavior back with a little bit of inconvenience/explicitness.
MSVC has one of the oldest name manglings of anywhere. At the very least, VC6 used a subset of the same mangling of VS2017 today, and I would expect it goes even earlier than that again. Calling convention changed markedly between x86 and x64, but that's the case with any architecture change.
There are numerous `safe_int` / `SafeInt` library implementations, you are free to choose one of them, wrap all your integer math in it, pay the performance cost and enjoy fail-fast crashes of your application.
I think that that note is entirely wrong; `size_t` is specified to be a alias to an unsigned integer type, which means its still subject to having to handle wrapping, with the inefficiencies that that entails. Side side note: an unsigned integer type for which overflow is undefined behavior is missing from C/C++ and could occasionally be useful (such as in this case).
Not having hardware support for instructions that trap on overflow sucks, doesn't it...
Author of the article here. This is exactly what I meant. The conversion may just be hidden outside the function.
i'd recommend piggy-backing off apache using SAPI https://stackoverflow.com/questions/6912761/how-to-use-c-for-apache-server
https://renenyffenegger.ch/notes/web/webserver/cpp/simple/index
do you not jump between different branches many times a day?
Not many times a day, but I do regenerate my cmake anytime my repo changes.
As an audio programmer I use it for MIDI data
I have had several requests recently for something like this. I might need to write a blog post. There will be a talk at CppCon 2018 called "The Bits Between the Bits: How We Get to main()" by a popular speaker that I hope covers linker scripts.
You can remove cygwin dependency if you statically link. Also you don't really need the makefile if you use MSVC because you can just import the header files and go about your business. I made a CMake package for the project. I doubt it will make any difference.
Why? A mesh is a list of triangles.
Excellent work on this, thanks for your effort! Is there a way to switch between configurations without deleting the build directories? E.g. if I want to build with both MSVC and MinGW?
You keep forgetting that I don't need guarantees or standards. Conventions are all I need. If this breaks in the future, I can always again create a new binary for the version that makes the breaking change. Also I don't need GCC to do it the same as VS. I don't see any indication that special member functions get broken a lot, the fabi-version link has a very special case, that I can probably easily avoid.
 Why would an arbitrary blob of data have so many responsibilities? How would you handle threaded rendering?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/90uuf5/i_want_to_learn_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Here is mine: https://github.com/dicroce/webbie 
Thank you for clarification :)
I Use mongoose https://github.com/cesanta/mongoose It's very nice and applicable
On MSVC and Clang, you can use `__assume`/`__buitlin_assume`, and on GCC you can use `if (!(c)) __builtin_unreachable` to establish constraints to the compiler. In this case, you could do `__assume((a + b) &gt;= a &amp;&amp; (a + b) &gt;= b)`. This will force the compiler to assume that wrapping will not happen (and thus wrapping will become undefined behavior, as you've told the compiler that it cannot happen).
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/90udjk/looking_for_some_inputs_regarding_audio_plugins/e2tehur/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yeah, missed that bit, would like it explained (better) though.
Two points I have to mention: 1. This is official standalone repo. 2. As a personal option I wish if we are going to have standardized build system. I wish it was gn. Because a) it is extremely fast. b) Its syntax is extremely intuitive. This has been used in chrome for past 2,3 (or 4,5 I don't remember exact date) years. Now Fuchsia team is using this build system too. 
Yet another build system eh?
Are the header files listed as source files on a target? The files in the outline are shown based on what the CMake Server API returns. If a file isn't attached to a target, it won't appear in the outline.
It is not yet (?) another build system. They have been using it for building chromium for past 2, 3 (4?) years. Past versions was tight to chrome itself. When you were building chromium, it would pull a recent version of gn then use that gn. But now they removed all the dependency to chrome libraries and released a standalone version of gn (because Fuchsia team does use gn to build their source tree too). It is extremely fast. And wouldn't be that shocked if in a short timeframe it got so popular and become de facto standard. Just like Ninja, when they (same team) released Ninja it was yet another build system. P.S. I have no affliation with GN team or Google or Chrome or Fuchsia team.
Those messages are definitely bugs, but won't prevent most things from working. It will prevent IntelliSense for those files, though. Would you mind opening up a ticket on GitHub for that one? Regarding the duplicate buttons: I noticed that in-dev, but I'm not sure how to make the outline commands not appear in the command palette. They actually _are_ separate commands because they work slightly differently. As for the context menu on files: I'll probably add more to that menu in the next release to more closely match what's in the file explorer, but I can't completely. VSCode itself doesn't understand them as "files" in the same way as the nodes in the file explorer, so I can't perfectly reproduce the file explorer context menus. I might open up a report on VSCode itself about that one. It's a bit tricky.
You're welcome! Glad to hear that those fixes are working!
Am I then right in saying, iff one uses std::size_t consistently it's better, otherwise it's potentially worse?
At the moment there is not, unfortunately. I do have a GitHub ticket open for that feature.
&gt; There is a Windows API to reverse it That doesn't imply very much by itself. If v1 of an ABI differs from v2 of an ABI in a way that the API can reliably detect and handle, there would be no need for a compiler version parameter or the like.
You can still profile in vs if you used msvc as the compiler. It's a little clunky but the best option I've seen. You have attach to a running process, the option is buried in some profile menus.
Does anyone know if it has open source distributed build and caching support? I was looking at some docs for Chrome and they seem to mention only internal google systems for that.
Some undefined behavior basically just falls into the category of stuff you have to do when writing kernels, drivers, JIT compilers, or other low level code. Like reading or writing a memory address that you didn't get from new/malloc or taking the address of some valid object, or wacky pointer arithmetic based on what you know about the machine. I have no idea how you could nail down defined behavior sufficiently to make something like a JIT compiler work properly in a portable way, but I am confident that it wouldn't be worth it.
&gt; Having means to help keep stdlib implementation(s) up to date would also be nice, in my book. Reducing the surface area of stdlib will help in keeping it up to date. Stuffing things like graphics into it will increase the complexity, the amount of stuff that needs to be tested in a release, etc., which will do the opposite of helping with the problem of keeping up to date.
that readme file is ... lacking.
Great, looking forward to it!
Where does bazel fit? CMake was/is there solving the same problems.
This is awesome! I've been waiting for a standalone GN for ages!! Now I wonder if we'll get a standalone build/ config directory...maybe I'm just dreaming, but it seems odd they'd create an entire googlesource subdomain for just one project, no?
&gt; But that's implementation-defined behavior I wasn't specifically talking about UB vs other behavior types - just that you can't ever really rely on "this will work everywhere". &gt; and you have std::stable_sort to solve that problem std::stable_sort solves a completely different problem. std::sort still produces a deterministic result for a given compiler. The problem comes from it producing different results on different compilers and using std::stable_sort to work around that problem has too much overhead.
I use it for all my projects and the only problem I have is the 'Intellisense' error finder thing. It will sometimes randomly show an error or falsely report a syntax error even though there is none. A quick restart will usually solve the problem though.
My personal understanding is GN is more geared toward lightweight and C++ specific projects. For example, Fuchsia team uses GN to build Zircon which is part of Fuchsia kernel. And since bazel does have Java dependency maybe some team do prefer to stay away from it. But at the end I think the reason why developed gn was the a) bazel was not open sourced at the time and b) they wanted a more lightweight solution. That being said, I have to add they have tried to keep syntax between Bazel and GN as similar as possible. So when you learn one, learning the other one should be trivial. About CMake. I personally use it extensively (Almost in all of my projects). But I think for the most part we can agree it is like torture to work with CMake. But if you wanted a more educated opinion you can read this: [https://gyp.gsrc.io/docs/GypVsCMake.md](https://gyp.gsrc.io/docs/GypVsCMake.md) (GYP is predecessor to GN)
As far as I've heard from the developers, they are trying hard to make gn a complete standalone project. Other than requests from community, one of the most important reason for this is request from Fuchsia team. Fuchsia team chose GN as their build tool for the most part.
Yeah, it does. It looks awesome, but I’m just trying to prototype a small internal website. 
Yes, the headers are listed in the target definition. After looking more closely I see that only of my headers is listed. Slimmed down example: add_library(somelib include/util/raster.h include/util/rasterdiff.h rasterio.h raster.cpp ) Only the rasterio.h is shown, the relative headers with include/util are not listed. Is it caused by the relative file specification?
I’m just knocking up a small internal website for my team. I’d normally use node, but seeing as C++ is my normal language I thought I’d see if I could use that instead. 
Why don't you use a webserver, like lighttpd?
Thank you! I implemented suggestions 2 and 3. I was/am using const char\* to avoid having to copy substrings, or pass an extra index argument. std::string\_view seems like a good alternative - my only question here is whether there is pre-C++17 support for such functionality? If not, is C++17 'stable' enough to jump into as a beginner?
I would normally use node to create a small webpage or a web-based tool. But I mainly write C++. 
You can find quick start guide and faq on this page. https://chromium.googlesource.com/chromium/src/tools/gn/+/48062805e19b4697c5fbd926dc649c78b6aaa138/README.md
Exactly. I know C++ well, so I’m seeing if I can use it to rapidly create a small web-based tool. 
The only thing I can think of is boost::string_view but I understand why someone would want to avoid including this huge dependency for just one small class. 
I've used a fork of mongoose called [civetweb](https://github.com/civetweb/civetweb). I had pretty good luck with that.
Thanks for your kind advice :-) And I recommend checking out http://includecpp.org/ for a friendly reminder that the C++ *can* be welcoming and inclusive. 
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/90p7cm/easy_c_web_server/e2tk2k5/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well, that escalated quickly... 
What he's saying is that there's potentially no benefit to using size_t because the extension you're trying to avoid may end up happening anyway, just not in the function.
What does it do better than cmake? More specifically, what does it so that's so much better than cmake that people who are already using cmake should switch?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/90w0d8/what_way_works_for_you_in_terms_of_studying/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
In addition, C++ allows embedded assembly.
Read the README.md linked above by ttmp3
As I said, mangling is somewhat needed for linking something together. But for plain good C, there's no mangling needed. So I would expect the mangling fun started (at least) 1998 with the standard becoming real. And VC6 was released in 1998, indeed. GCC surly made also this step in adopting the standard somwhere, though there have been different projects at this time. The largest change between x86 and x64 was the change of the standard calling convention, however. Per default, MSVC for x86 uses stdcall, for x64 it uses fastcall, and in some circumstances also vectorcall. 
I should delete this and post it to cpp\_questions correct? i dont this follows the guidelines here 
I don't think that's possible. You can't express anything in C++ that somehow relies on the value shifted out by a `&lt;&lt;` or `&gt;&gt;` operator. If that bit was something you could access in C++ (like the sign of an expression, for example) it would be possible, but it is literally only that: the bit shifted out. It has no meaning you can refer to in an expression. The reason I asked is because the parent makes quite a bit about the need for this operation to be UB because of the carry bit, and while there are differences in behaviour between CPUs for shift lengths greater than or equal to the word length, as well as potential issues when shifting into or out of the top bit, I find it extremely hard to believe that the carry bit is ever an issue. But hey, it's C++, and miracles happen on a regular basis, which is why I was asking... 
&gt;I don't think that's possible. You can't express anything in C++ that somehow relies on the value shifted out by a `&lt;&lt;` or `&gt;&gt;` operator. That's why I said the code would read the bit first, then shift it out. The compiler doesn't need to do it in the same order.
I just saw you updates. COM uses a different calling convention: safecall. This is rarely used at all and COM should be threaded deprecated today (note: not the design, but MVCS COM interface, they're two different things). My tipp: never relay on something that might work if it is not clearly stated so. Assume it broken in this case. For your question: from VS 2010 to 2017 mangling changed, this is also stated on the MSDN website. Clang probably tries to be compliant to VC6. This runtime is the only one shipped with Windows directly. MingGW has the same approach.
Please stop. 
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/90p7cm/easy_c_web_server/e2tl8c4/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; COM uses a different calling convention: safecall. This is a Delphi thing; in C and C++ `__stdcall` is used. &gt; Clang probably tries to be compliant to VC6. No; it only works with VS2015+'s stdlib, so that would be rather pointless. ;-]
For what it’s worth, I’ve got a few decades of experience in the industry, and I’ve got a thick skin. But this kind of response puts people off asking questions and sharing knowledge. And our industry is a creative, knowledge-based industry. We need to share our knowledge and help eachother. That needs empathy and kindness. 
The software I'm working on is solely for linux and I'm on linux as well.
Sometimes I suspect that writing a build system is a rite of passage at Google. That, and writing a messenger app. This being said, it seems to be less oriented to Google's tooling than, say, Bazel, which is a good thing.
Plenty of other people provided useful examples that do pretty much what I want. None of them felt the need to insult me. 
May I ask at what point in this correspondence did he insult you?
Actually the code is doing precisely what you are asking for. If you want the optimized version you must transform `input` to an output range. The range `input` is formed by random access iterator. From the type system alone, it cannot be inferred that the string referenced by the view will not change while you iterate over it. For example in a real code you could compute the size of the word then change the underlying string and then advance the "word" iterator. If you do not plan to use such a possibility, you must express it by forming an output range!
He seems like one of those internet tough guy self-appointed gatekeepers.
Completely agree. UBSAN is a blessing where usable
You're right, I mixed up those relicts... For Clang I do not see the point, however. MinGW just uses the VC6 approach, so no dedicated cpp lib has to be provided. For VS 2015 and probably 2017 apps it would work, any other might need a recompilation, at least. That's the reason I avoid those dependencies at all. So no customer needs to ask: "we're still stick to 2013, could you please provide a fitting library?"... Or maybe for any future VS version...
Probably one of the deleted or automod-removed comments.
MinGW uses its own stdlib and must distribute its own runtime. Same problems, different compiler.
There is no mention of CMake in the README. So how does it compare to GN? 