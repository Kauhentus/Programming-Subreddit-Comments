And I think your posts are why having an honest and mature conversation about this issue is virtually impossible.
Step 1. Announce you're hiring "smart young people". Step 2. Get sued into oblivion for age discrimination, which is illegal in the United States. Step 3. [Your competitors will] profit!
I'm the opposite. I don't have a quantity of non-work related projects because I do programming all day for work so I'd rather do something else when I get home.
STL is a 25-year-old library from SGI so it's good that you don't use it. 
Do they have to be actively looking? They might like the idea of working for you even if they aren't actively looking. 
I think most good programmers can understand where he's coming from. 
We aren't a code factory so the productivity gains are only a distraction. We spend a lot more time trying to figure out how to solve hard problems then we do coding them. So I agree. But yes we realize that to take advantage of some of the new threaded features we'd need to leak in some STL code.
We use GCC 4.9.2 so it supports C++11, assuming we enabled it via command line. Given the large size of the codebase, low language features like these aren't likely to produce appreciable changes to performance. We rarely to never copied by value in the past. Our memory allocator is very low overhead but we could avoid that hit instead.
We pay and we pay well.
On-site in a major metro area. Where are you located?
Boston. Are you interested? Send PM and I'll give you the link.
No C++ meetup in Boston, strange as that sounds. Corporate policy forbids it as well sadly.
Similar domain here. I don't think we'd mind a Java web dev, assuming they had the right mentality and were interested in switching tracks.
Austin is great. You should move here! We have other divisions here that may be hiring. I can forward your resume if interested.
Post the job there. Boston has a large development community so finding people there is a bit easier than in the middle of nowhere Missouri. If your company is willing to pay relocation costs for the right candidate you could try directly reaching out, but that is a pretty large commitment.
I posted several references in another post, but anyhow there are numerous studies that simply contradict the idea that software developers have to work 12 hours a day and have stressful jobs. Honestly, just go to Google and type in "best jobs in the U.S." and data compiled from the Bureau of Labor statistics, or from academic studies, or general surveys, or recruitment info all list Software Engineer as being at or right near the top among a variety of criteria which includes stress, working hours, and even obscure metrics. Do a search for the best companies to work for such as the Fortune 100 Best Companies, it's dominated by software companies including the #1 position going to Google. Seriously you can do this right now and see the results for yourself if you don't want to take my word for it. It's not that you have to be lucky to avoid working 12 hours a day, it's more that you're unlucky if your job requires 12 hour work days. The reason why it may seem like most people on reddit work 12 hours a day is because those are the people most likely to post about their job experience. Simply put, those who are most vocal tend to be those who are in an extreme and unusual position, relaying their experience to others who are in that same position and hence giving the misleading impression that most people share that experience. But the more objective surveys and studies indicate that this job allows for the best work-family balance, least stress, most autonomy, best work environment, even most hours of sleep.
You can detect the callability of function objects without Expression SFINAE. It relies on objects being implicitly convertible to function pointers, so it only works for function objects.
It's not my call but it's not really a choice. When you've got millions of lines of code that didn't use it already written and a group of developers who aren't skilled with it, well that's just the way it is. Either you find people who can/are willing to do it or you don't and you die. I tried pushing for change myself years ago, no luck. Fortunately not only are we still around but we are doing extremely well in spite of it.
You mean the meetup or StackOverflow? I don't think relocation costs are a problem, certainly not in the US. We've relocated a number of people internationally even, for the right talent. But it's a limitation for how many people we're willing to bring in for an interview.
Hey, I have given several presentation here at the Austin meetup. Perhaps I have seen you there. I would be interested in a C++ developer position, however, I don't want to relocate to boston, and a lack of STL sounds awful. Also, if you've seen my blog or presentations perhaps you wouldn't want to hire me anyway(I use a lot of functional and generic programming). 
We almost certainly have then :) You gave the Clang presentation? I don't know about the Apr 1 presentation but I should be at the Apr 20 meeting.
Glad to hear you're doing well. I just wanted to address what I thought was a misconception you had. Maybe I simply misunderstood you :-)
I'm in Connecticut, but I was mostly asking because the way to find C++ developers (or workers in general) really depends on whether they have to be on site. If you allow people who work from home, you have a much bigger pool of people and the search / interview process is completely different. On the down side it's much MUCH harder to work like this if the work itself is very "team based".
Hi, I'm an STL maintainer and Standardization Committee member. I really wish people would stop saying "stop saying STL". Referring to the C++ Standard Library, especially the containerish/iteratorish/algorithmish part, as "the STL", is a perfectly valid and convenient use of [metonymy](https://en.m.wikipedia.org/wiki/Metonymy). It's just like calling the executive branch of the federal government, the "White House". Nobody's confused by the fact that it's literally a mansion/office building.
Non-mobile: [metonymy](https://en.wikipedia.org/wiki/Metonymy) ^That's ^why ^I'm ^here, ^I ^don't ^judge ^you. ^PM ^/u/xl0 ^if ^I'm ^causing ^any ^trouble. [^WUT?](https://github.com/xl0/LittleHelperRobot/wiki/What's-this-all-about%3F)
As a C++ dev at home, this gives me the screaming terrors. 
I just copied it from the comment I was responding too, hence the quotes. I didn't want anyone to confuse it with my opinion so I edited it. It seemed odd at the time but I didn't want to call him out on it, as you've done to me. We certainly would not discriminate and our annual ethics courses make sure we don't forget it. I was just trying to point out that the suggested filter wasn't something easy to gather in an automated fashion.
Let's have an honest and mature conversation. Now. You start.
finally I can listen to someone testing an IDE
Ah, Niebler trickery, I should have guessed.
:-)
You should look at web browser internals. "legacy codebase from the 90s" "very time / memory intensive" "we have our own STL equivalent". These would be perfectly appropriate comments. Yet people tend to think these are cool projects.
Where do these jobs actually get advertised? I just stumbled on a weather related hpc cuda c++ job (not US). And interestingly it was the only one in this domain I found in my region. Its limited for two years (university contract) so I'll have to find something new in a couple of years.
&gt; Just curious, when would somebody's constraints get in the way of whatever it you're trying to do? I'm not sure what op is referring to, but I can imagine a situation where the API requires a parameter to implement the "Lockable" concept (must have `lock()`, `unlock()` and `try_lock()` methods), while it really only needs the `BasicLockable` concept (`lock()` and `unlock()`).
It's the moment we've all been waiting for, with baited breath.
Im a C++ programmer and my work just switched to C++11 and i think youre underestimating how much time saving stuff is in there. I dont think i could go back unless its for embedded stuff
If it's a junior position then you should be looking for people who can write software with probably some basic knowlegde in C++ rather than C++ developers. At our company we hire C++ developers and i wish we didn't. 90% of them can't write one single function properly even if their life depended on it. Result as you expect (even for devs who work &gt; 3 years there) * 3 kLOC classes with 45 member variables, * 4-5 monster methods, * memory leaks everywhere * 0% reusable code * copy/paste code is about 20% of each class 
I like this example because it is close to real world programming. I am happy to have an example that is close to things programmers encounter every day. Thanks for that (Unfortunatly this is really rare today in C++ where people are mostly interested in writing some obscure useless templates)
https://github.com/facebook/fatal https://github.com/facebook/folly
I'm sorry but that's complete nonsense. Not having to work with a legacy code base from the 90s is not wanting to work with bleeding edge. I'm currently working on a legacy code base (K&amp;R C) and even though the code is great (according to the standards from the time) it's still complete crap and a complete nightmare. These legacy code bases are built on outdated assumptions and if you don't approach these code bases extremely aggressively you will have the worst time of your life working on these. These are the worst jobs in the industry.
https://github.com/mnmlstc/core
I'd have two reasons for using the NDK: 1) Not using Java 2) Being able to write code once for android and ios Linderbaum according to the article doesn't support ios, instead it offers me blackberry, which is like offering me zune. If this was a academic training exercise, I apologize, carry on. If not, then I question what slot this is trying to fill on the market.
Quick, you can still get this trick into your STL before shipping VS2015 ;) 
While CUDA 7 lock nice it is useless if you need to support all GPU by all vendors. So my wish is OpenCL 2.1 support as soon as possible!
Except that web browsers are using fairly modern techniques and STL? At least the most obvious one (chrome, chromium, safari) are. Or did you mean compilers? Like LLVM project, that has adopted C++11 quite a long time ago? 
Wow, what an excellent description "An Open Source C++ Library". Nothing on its purpose. 
Or wait for OpenCL C++ kernel language for SPIR-V. Vulcan looks very promising.
Ah. But only if the real talent *knows* they pay well. And his question, of course, is how to get that information out there. 
Impressive as it is, this implementation totally misses the most important feature of `match` in those other languages, namely that it must be exhaustive and it is checked at _compile_ time.
Yeah. It seems like this idea about side projects might have gotten its start with junior developers and people who are trying to prove themselves without having to get a college degree, and then later on that context got stripped away. I've worked at a couple of Fortune 500s known for technical excellence, and none of the senior people I met there ever talked about side projects.
It’d be interesting to see if this feature could be added. Of course this *cannot* work for every type, but it could work for `boost::variant`s: this is what `boost::static_visitor` already provides, but wrapping this inside this library (or a similar library) would improve syntax (and thus usability) vastly.
You just need a switch statement: template&lt;class Number, class F&gt; void match(Number n, F f) { switch(n) { case 0: f(std::integral_constant&lt;Number, 0&gt;()); break; case 1: f(std::integral_constant&lt;Number, 1&gt;()); break; case 2: f(std::integral_constant&lt;Number, 2&gt;()); break; case 3: f(std::integral_constant&lt;Number, 3&gt;()); break; case 4: f(std::integral_constant&lt;Number, 4&gt;()); break; case 5: f(std::integral_constant&lt;Number, 5&gt;()); break; case 6: f(std::integral_constant&lt;Number, 6&gt;()); break; case 7: f(std::integral_constant&lt;Number, 7&gt;()); break; case 8: f(std::integral_constant&lt;Number, 8&gt;()); break; case 9: f(std::integral_constant&lt;Number, 9&gt;()); break; default: throw std::runtime_exception("Number out of range"); } } Of course, you would want to always limit to a certain range. I don't think its feasible to build it for every possible integer value. 
Shameless self-advertising: https://github.com/patrikhuber/superviseddescent It's a little library for optimisation and landmark detection in computer vision. I'm sticking to modern C++11/14 code and to keeping it as simple as possible. 
I’m not sure that qualifies as *compile-time* checking for exhaustiveness. Furthermore, could you give an example of how this would be used? I’m honestly having difficulty seeing how this differs from if (n &gt;= 0 and n &lt;= 9) f(n); else throw std::runtime_exception("Number out of range"); … and that’s not really the same as pattern matching at all.
Yeah I don't know how well it'd work in practice. It would have been nice to try from the start were it possible. Good data locality has always been a challenge for us, especially with NUMA. Not only do you have the traditional cache hierarchy to worry about but now you also have memory split between different processors on the same chip and different chips on the same board and then even multiple motherboard controllers. We're typically buying the largest machines companies like Dell can make and even then, sometimes they're prototypes. A 2TB machine today can perform 50-100% slower than a machine half or a quarter of its size due to these effects. Our largest machine right now has 80 processors (we'd actually want fewer for performance but not an option anymore due to memory hierarchy restrictions in current architectures) and they keep getting larger. Linux doesn't seem to do a good job scheduling for locality so we sometimes have to use numactl to speed things up further or at least get consistent results. Our data structures are nearly random graphs so ensuring that you can sort of stay in the same area is tough. Many of the heuristics are amenable to fork/join type abstractions where you could divide the problem up among multiple machines, each with its own local subproblem, though we've tried a few times over the years to make it happen.
Cap'n Proto: https://github.com/sandstorm-io/capnproto
Can you provide an example of those C custom types?
I wouldn't say compile time check is just a bonus. Without it, the `match` is not much better than the explicit sequence of `if`, `else if`, `else`.
printf is my repl ;)
That's something I'm interested in as well. After years of C++ and then programming for a while in functional languages, I definitely miss having a REPL at hand for quick testing and a more dynamic development style.
Excellent. Thank you!
You didn't mention how much experience you expect candidates to have. I'm a mid-level C++ developer and not really actively searching, but the only "job boards" I ever look at are StackOverflow and Hacker News. Both of them have a low percentage of C++ jobs though, I find. In my experience more senior guys spend less time on the Internet or clicking on job ads, so you have to either find them at meetups or contact them directly (LinkedIn works for that, just search for people with embedded or 3D experience if your standard is smart person who knows math and pointers, trading if you're more into HPC). For entry-level people, looking at my coworkers, I'd probably try to look at graduate students in non-computer science STEM fields with very computational research (even if not your specific domain), and ask for code samples to filter out the ones that can't really code.
How did you achieve this _x result? I mean, what it is?
We have openings at junior and senior levels.
&gt; and even the stack depending on circumstance What is this magic? How do you get faster than a single pointer add (at least that how I remember it from x86 assembly)? Edit: Oh I see I misread the quote. That seems like it could indeed be bad for locality.
Any chance for telecommuting?
No sorry :(
If he really wants speed, shared pointers might be bad due to reference counting overhead. If he wants locality, shared pointers are only good if pointed-to objects are allocated together (granted, that should be his case).
what keeps him from using unique pointers?
Move semantics?
Just use an appropriate STL allocator with your vector. Howard Hinnant has an excellent [example](http://howardhinnant.github.io/stack_alloc.html) of how to do stack allocations with various STL containers.
Declaring a function as a scoped-lambda is wise from the standpoint of making everything as local as possible. However, having multiple definitions of the same thing begs for a class function instead.
I generally find there is no need to use new/delete or smart pointers. You can go a long way by just using standard containers of objects. The memory is managed automatically but in a very predictable and efficient way.
Easier SIMD through Boost.SIMD.
What are you asking? Is the question do I compile from the command line or a gui? Both. They're the same program in many cases. Multiple compilers exist for Windows / Linux / OSX etc. I don't know of any that can't be accessed from the command line. I tend to use make files - which is kind of like scripting your build process. Did this help?
Dev C++ is an ancient program that hasn't been updated in over 10 years. I strongly suggest to update to something that at least supports the majority of C++11 features. Modern C++ is a lot different than what was written 10 years ago. I like Qt creator as an IDE, my colleagues use either vim, visual studio or eclipse. There are many good options.
I used Dev C++ for ages and never ran into the problems people always mention. However, I would recommend C++Visual Studio Express if you're doing more GUI work. It's free. 
It is a very valid question although you might have to describe exactly what you are doing to get a real answer. It's very unlikely that a vector of pointers is going to be the best technique. One thing you can do is create a stack if you don't know the size of what you are allocating ahead of time. If you can simply use a vector of whatever object and use a vector like a stack, that will also work, since the majority of the time it won't be doing heap allocations. If you need to delete arbitrary objects you could look into memory pools (and probably use a predefined library). 
DevC++ was the thing when there wasn't a free version of Visual C++ years ago (I actually bought Visual C++ 6.0... oh god) but Microsoft has been doing a lot to foster Windows development in the last few years (gotta compete with the Googles of the world!), there is no reason not to use Visual Studio if you're using Windows, of course there are some great alternatives (that are usually conform to the standards more, especially when it comes to C (not C++)), Visual Studio is the best IDE I've ever used and it is free. &gt;&gt;
And code in assembly rather than C++. But for the rest of us, there are wrappers.
We learned to use SIMD with the SSE intrinsics. These wrappers can sometimes still have a small overhead. When you are at the pointer of writing SIMD code, you might as go all out optimization and write using intrinsics.
Unless you'll want to create your code once, and compile it for 10 different CPU's. Libraries such as agner's make this a breeze while not really adding any overhead if you know what you're doing in the first place. I would always recommend hand-coding using intrinsics for novices, though. You'll need experience with the real thing in order to use SIMD libraries effectively.
You have a point there. And I gotta admit, my teachers is a complete optimization god, and will do anything to make his code faster.
I think it's better to start with a high level approach.. STL, smart pointers, etc., because it's easier to understand and less error prone. Then cover low level stuff like raw pointers and arrays once the student has a better understanding of the language and programming. Check out some basic question or learning C++ programming subreddits and forums. The sort of things many newbies throw up is... painful. Don't encourage making it worse. 
Isnt compiler doing this automatically if you enable arch::SSE2?
In theory, yes. In practice, no. If not coding with SIMD optimizations in mind, you are almost guaranteed to mess up either the memory layout, access pattern or alignment of your data. Even if you did all that correctly, the compiler might not be able to vectorize the code without -funsafe-math. And did i mention floating point exceptions? My experience with auto vectorizers is that they are still unreliable. If you want it to be vectorized, do it yourself. It's actually easier than toying around with the auto vectorizer or 3 different compilers.
Section 8 of the article covers the authors reasons why this doesn't work as well as writing your own SIMD code.
This is super cool and, as an embedded developer, extremely enticing!
Turbo is still a thing, sadly, and it's much older.
The guy that I was watching is using g++ from MinGW.
Do modern Fortran compilers nail this stuff? Doing this stuff properly seems like an arcane pain in the ass in C++. Might be easier to wrap some Fortran bits if that works...
I tend to think the more important stuff is testing and following the more abstract 'best practices' (Dependency injection, single responsibility, use of interfaces, modularity, etc...). But smart pointers and design patterns are useful too. Have unit tests for everything, generate code coverage and use the sanitizers. Put it all in your build system and make a script that will do everything. Put it all into a simple continuous integration setup and make sure it happens automagically. For my personal projects I'm using local installs of Gogs and Drone.io in Docker containers. Other choices are Gitlab, Jenkins and so on or non-self hosted things (Github, Drone.io, travis-ci, etc...). Once you have a really good skeleton build setup you can use it for all your projects. It's free. Smart pointers will help you prevent memory management errors, testing will help you catch one (although not in all situations). Smart pointers can be used with custom memory management. You can always use factories to produce your objects+pointers, or custom memory allocators to handle low level memory allocation. The fact is smart pointers will be necessary for many projects. If you are working in team or if your writing a library you won't be able to deal with the memory management because you don't control the whole system. People can always forget to free something, use after free and so on. In many situations there's no real reason not to use them. Performance/memory constraints are about it. Similarly design patterns are useful to teams also. People can recognize them and work with them. They can also make your code modular. But that doesn't mean everything has to be a pattern. Also a lot of the crap people make would be simpler and better as a pattern. Having said that, most coding practices are guidelines and have situations where they don't make sense. They are the 'default' setting. New coders should probably learn them as being ghosple since they are not experienced enough to know when to deviate. Experienced programmers do. For example "goto considered harmful". Unless you are programming graphics card driver where every cycle counts, then goto's can provide a speed up as can other things like manually unrolling loops and so on. All things considered 'bad' practices. Although you can probably provide a clang plugin that gives you a custom optimization pass or a preprocessor step that turns a specific loop into an unrolled one with gotos but that might be much more work and locks you into a specific compiler. If good memory management is a high priority then maybe C++ isn't the best choice over languages that are managed. C++ is for performance even then you only need performance in hot code and performance might be boosted more with multi-threading which some languages are better at and allow you to divert more time to that problem rather than the low level stuff.
Documentation is sparse, but the library itself works great.
A big thing to emphasize out of what you said is that getting SIMD code to run fast means being very specific with laying out data and how you use it. I think most people don't realize how limited SIMD is. Even gathers and scatters defeat a lot of the gains you can get unfortunately. I have seen it implied that this won't be as bad with skylake but I'm not sure.
&gt; I hate smart pointers simply because I can't tell when memory is freed. And passing owning-raw-pointers around between different classes is easier to understand? It's perfectly reasonable to criticize, for example, `shared_ptr` for creating uncertainty as to when the objects will be destroyed, but `unique_ptr` is simple and automatically does the thing that you have to do manually with owning raw pointers. If you were to use `unique_ptr` in place of owning raw pointers your code would have the same structure, you could eliminate the code that does `delete`, you could eliminate a bunch of `try`/`catch` code, and many errors that almost certainly exist in your code would be fixed automatically. &gt; I feel that trying new things is essential in the learning process, so why sacrifice this to make code "appear' less complex by wrapping everything into a class and using smart pointers for "every interface possible"? Don't use smart pointers for every interface possible. That's not what advocates of 'modern' c++ styles want. What they advocate is using RAII, and smart pointers is only one instance of RAII. Also, the point is not to make code "appear" less complex, it is to make it actually less complex and easier to get resource management correct, and easier to keep it correct over maintenance. &gt; I just think this fear of complexity may be unhealthy for new programmers. Complexity shouldn't be shunned, it should be embraced. It issue is not 'fear' of complexity, it's an understanding that complexity leads to errors. Code should be no more complex than it absolutely has to be. And of course complexity takes into account program size; a giant program that uses only simple constructs everywhere can be more complex than a very tiny program that solves the same problem using some small but more complex constructs. &gt; new/delete/raw pointers are part of the C++ language, so using them shouldn't be instantly condemned. There are acceptable uses of new and delete, but the point is that the are _very_ hard to use correctly without using RAII, and code that does manage to get it right without using RAII is very easily broken during maintenance.
This is actually cool to listen to. Not only that but CLion has a lot of promise as a serious competitor to visual studio.
You could not be more wrong. People who love to solve problems don't want to solve problems that have already been solved. It sounds like you guys are probably doing quite a bit of that.
I have unfortunate news for you, that you may already be surrounded by C people.
The only one you didn't mention is openGL compute buffers, but I don't know if that works on consoles, it is very new. The bigger picture though is that making a real time ray tracing engine is beyond non-trivial. It is exceptionally difficult and an area of active research. Furthermore, using that in games for anything graphical (millions of rays per frame to arbitrary triangle) is extremely impractical. Memory limitations and performance limitations would mean ray tracing would dominate what your game is able to do. 
That's not good way to promote your repo, how many other obscure solutions you possible use just because you learned them first?
&gt; However, before you try to squeeze the last bit of performance out of a piece of code, make sure it is efficient. Only if you have tested all possibilities in terms of efficiency it can pay off to worry about performance. Not always true. Superior algorithmic complexity often comes at the price of increased code complexity. Careful attention to a few tight loops can give you the freedom to use dead-simple brute force algorithms that are easier to maintain. For example, [a log analysis system with a highly optimized core](http://blog.scalyr.com/2014/05/searching-20-gbsec-systems-engineering-before-algorithms/?updated=true) that does all its queries with brute force linear scans. The developers observed that typical complex search structures are optimized for particular kinds of queries, so the nice cases run fast but the pathological cases run very slowly. Brute force approaches perform more predictably, and the code is simpler. We've seen [Bjarne's test where `std::vector` clobbered `std::list`](https://www.youtube.com/watch?v=YQs6IC-vgmo) even on textbook "linked list" tasks due to cache effects. Or how it's [sometimes worth sorting an array](http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array), even before an O(n) operation, to take advantage of branch prediction. Modern CPUs are highly optimized to execute predictable, repetitive tasks. We should have "mechanical sympathy" and try to write code that plays to the strengths of our hardware. The correlation of fast and hard-to-read is overstated. Writing fast code is usually an act of awareness, not of sacrifice. &gt; There is a saying that 80% of the run time of a program is spent in only 20% of the code. Some say it’s 90/10. The exact numbers are not very important in general. The crucial point is that the program spends a lot of time in a small amount of code... Don’t optimize code that you have not proven to be vital for the overall program performance. A platitude. I wonder how much time its repeaters have spent with a profiler. In my experience with complex CPU- and memory-bound desktop software, any such 80% is usually from a foolish mistake. I've seen a lot more cases of 8 different 10%'s. Death from a thousand cuts of sub-optimal architecture choices and laziness. 80/20 is a pipe dream. Absolutely, live by your profiler, but if someone hands you a piece of complex code and asks you to make it run twice as fast, you will probably need to make many 5-10% optimizations. &gt; Optimizers come in all shapes and colors, and unless you are an expert in the field, you can’t even guess what they will do to a nontrivial piece of code. Optimizers can eliminate temporary objects, they can inline functions, sometimes even at link time, and they can shuffle around and eliminate lots of those instructions. You don't have to be an expert. Optimizers' abilities are exaggerated, and they are predictable. One week studying [SSA form](http://en.wikipedia.org/wiki/Static_single_assignment_form), [common compiler optimizations](https://www.youtube.com/watch?v=BoDw5ihpe3k&amp;index=73&amp;list=PLFB9EC7B8FE963EB8) (lecture series, watch sections 14 and 15), and linkers will give you a good ability to predict which constructs a modern compiler can optimize. Sure, the optimizer is better than you at knowing details of the x86 processor, but that's very micro. At a macro level, it's easy to inadvertently write code that the compiler can't optimize. We should have "mechanical sympathy" with our compilers as well as our hardware. I'm rambling... but the point I really want to make is: *fast code is usually just as readable as slow code*. Even heavy optimization tricks like storing a bit in the end of aligned pointer are easily abstracted in C++ with completely readable results. Fast vs. clean is a false and poisonous dichotomy. The unholy bit-bashed speed-over-readability mess that everyone imagines, is a result of programmer failure. C++11 is a fantastic language for writing clean code that runs fast, and we should put in the effort to do so.
With the speed of modern compilers why would you resort to a sort of standard interpreter? 
&gt; fast code is usually just as readable as slow code If written by an expert perhaps. There is a world full of novice and intermediate programmers out there who will produce more readable and __maintainable__ code if they aren't obsessed with being clever and trying to pull out every optimization they ever heard of. I think what I'm trying to say is, that to write readable fast code you need someone with some expertise and with some maturity, and those people necessarily only make up a fraction of the programming world -- else all code would be perfect. I think everything you said here is true, but only if you are assuming you have a stellar person in the chair doing the coding. I think the OP's advice is far more applicable to the general programming world that actually exists in reality.
I remember something like this from a job interview to a major tech company. They asked a simple question: you have 2 large arrays of integers, you want to find if there is an integer that appears in both of them. Easy, I say! Sort them both, then go one by one on the sorted arrays similar to how you "merge" sorted arrays (increase the index of the array with the smaller), and then you'll find the item that is in both! Very simple, clean, efficient code. "Oh", the interviewer tells me, "what's the complexity of this code? Can you do better?" Well, it's technically O(nlogn), and technically I can do it in O(n) by entering all the items from one list into a hash table (or `std::unordered_set`, if you will), then go over the second list and check if it's in there. But... sorting is a very VERY efficient O(nlogn), where we're talking about 1-2 operations for the constant (so it's really almost nlogn operations). Moreover, all the memory reads and writes are consecutive in memory (merging 2 sorted arrays is reads from 2 different consecutive places, and writing to one place consecutively), so the cache will work great. It will really be 3nlogn cache memory operations. And for all practical purposes, logn is &lt;~40 anyway. Using a hash table is O(n) operations, but each operation is around 2 random access memory reads (most likely not in ANY cache level), with a decision tree that must wait for the read to finish before continuing (there is a branch right after the read: did I hit or miss?), not to mention applying the hash function itself (which in integer might be just the identity, so there's that) Anyway - the question is: is L1 cache more than 20-40 times faster than no-cache memory access? Well, L1 cache is ~1-2 cycles while random access is ~100 cycles. So yea. ----------------------------- Also, when I have code with matrix multiplications, it's much MUCH better to optimize the loops (transpose one of the matrices so that memory access is continuous) and keep the code O(n^3) than go for an O(n^2.4) algorithm. The code will be much cleaner, and unless you really do need huge matrices, will probably run faster as well.
I don't understand what you're saying about having the size baked in - please elaborate?
No-one should be allowed to use C++ for real work, unless they've used C++ for real work at least twice before. *Edit: [it's a joke](http://www.artificialworlds.net/blog/2008/04/07/c-is-an-expert-language/), if that's at all unclear.*
Haven't used Boost.SIMD, but I suspect it's nicely wrapped away as a 'behind-the-scenes' concern only.
Did you have any prior programming knowledge? 
Then reimplement it, write your own portable SIMD solution, the only thing you want to do is: `for x in y: z = x * 2 + w` or "similar"; should be easy. Boost.SIMD unrolls the loop for you, if the loop-count is not a multiple of the vector length, deals with the last elements for you, finds the right simd instruction for your architecture (from the expression you want to compute), it can also compile the code for all architectures and choose the best available instruction at run-time. It also allows you to "view" types such as std::vector as a vector of simd vectors, ... People (a university research group in france and a company that has a matlab to C++ translation tool) have put in 5 years of work on this, IIRC the first BoostCon/C++Now presentations about this are from 2010. You can come up with your own wrappers (probably full of macros as well), but I doubt you can solve this problem half as good as Boost.SIMD does without putting a massive amount of effort into this.
Sorry, it looks like they are now within the NT2 docs (I fixed the comment above): http://nt2.numscale.com/doc/html/boost_simd.html It is better to just generate them from source tho.
I think that to really learn, you need to have both a good book / website AND a good idea of a project that you want to pursue. You might find mid-course that your project idea wasn't that great after all, but what matters is that you understand the problems that are talked about in the books, etc. because you will certainly face them while programming even simple tasks, and you can then better understand the reasoning of the authors.
The book I would recommend for someone learning programming and wanting to do so with C++ is _Programming: Principles and Practice Using C++_. I've heard some good things about _C++ Primer_ and it seems to cover the language thoroughly, but it looks light on some more general information on programming. For example it doesn't seem to discuss testing much, whereas the book _Programming_ has a chapter on it. _Primer_ looks like a book about C++ while _Programming_ is a book teaching the general practice and just happens to use C++. _Programming_ also does a good job of introducing the language (it is written by the original author of the language) but I would guess it doesn't cover as much or in as much detail as _C++ Primer_.
Well done for making the choice then, C++ is a beautiful and powerful language. "C++ Primer" is a great book. Obviously, I'd highly recommend the following classics: "The C++ Programming Language" by Stroustrup; "Thinking in C++: Introduction to Standard C++" by Eckel; "Effective C++" by Meyers; "The Art of Computer Programming" by Knuth. 
Isn't a bloom filter also random-access?
Take /u/youarenotafish 's advice, also, these tutorials taught me: http://www.cplusplus.com/doc/tutorial/
CS50x will help a lot with programming principles. It's taught in C, rather than C++ but the knowledge is transferable. edit: wow downvotes for legitimate learning material. Stick to your C++ syntax books OP (y)
Definitely not C++ primer for a beginner to programming. They state in an early chapter that they assume you've worked in another language before and have previous experience compiling code.
Well, then changing that could give you a huge boost of applicants ;-)
&gt; In my experience with complex CPU- and memory-bound desktop software, any such 80% is usually from a foolish mistake. I've seen a lot more cases of 8 different 10%'s. Death from a thousand cuts of sub-optimal architecture choices and laziness. 80/20 is a pipe dream. I think the exact numbers and distributions of "hot" parts of the code depend much on the nature of the application. I have worked on actuarial software where the performance critical part was about 5% of the mathematical core - which was only a part of the whole application. My point in that section was that people often spend much time optimizing code where the optimizatino does not pay off. &gt; *fast code is usually just as readable as slow code* Let's say you often *can* make fast code as readable as small code. But to do that, you need a certain level of understanding of the language and the "mechanical sympathy" you write about that in my experience a lot of programmers don't have. Either because they lack the experience or because they simply don't care about further studies (aka "don't have the time"). The post is mainly targeted at those programmers who lack that mechanical sympathy and try to brutally beat a tiny bit of performance out of code. 
http://www.cplusplus.com/doc/tutorial/ Was my jumping off point but I had already done some c.
CPP people are known (by me) for their lack of a self-deprecating sense of humor.
I had to check. &gt; anArray is actually a pointer that points to the first element of the array! This is exactly why there are so many people using `sizeof` on pointers and expecting it to work.
All I can say is that the [good books](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) are much better than every online tutorial I've come across. Edit: Definitely meant to say "the that the"...
I am using my customized and extended Cling from time too time. https://root.cern.ch/phpBB3/viewtopic.php?f=21&amp;t=18365
&gt; fast code is usually just as readable as slow code. In my experience, most often where this falls apart is when you have to introduce caching: You have to execute an intractably expensive operation so you want to cache the results in case you need them again later. Cache maintenance means culling of stale results, thread safety, garbage collection, etc. Not only does caching result in more code, it makes correctness much more difficult to prove and therefore should be avoided when at all possible. Unfortunately, it is also often very effective in achieving performance goals. That said, &gt; Fast vs. clean is a false and poisonous dichotomy. is a good observation.
I agree with your point. I am only speaking on your implied definition of "where the optimization does not pay off." Yes, *if* the code has an 80% hotspot, that's the only place where optimization would pay off. But if the code *doesn't* have an 80% hotspot, that doesn't mean you should give up on making it faster. (And if the 80% hotspot is at all complex, it's probably several 20% hotspots lumped together.) I think we are not really disagreeing. Day to day, I write code without worrying about performance very much. I save it for major architectural decisions. I even suffer and complain when maintaining code containing obsolete performance optimizations. (e.g.: reusing the same variable for different purposes. I guess that programmer *really* didn't trust the register allocator.) But "the proof of the pudding is in the eating" and we are surrounded by software with terrible performance even though a basic smartphone is powerful enough to do 95% of what we ask in real time. Clearly most programmers in the world do not care about performance enough. I think our culture's endless refrain of "don't worry about performance too much" is partially responsible, so I feel compelled to make a counterpoint when I see it repeated again.
This tutorial is actually pretty good: http://www.tutorialspoint.com/cplusplus/index.htm
Cool. Note that the &lt;thread&gt; family is still blocked - we may investigate this for the release after 2015.
&gt; Yes, but the article's point was that many real-world queries can't take advantage of B-tree indices, so it's not worth (to them) the programmer effort of implementation and the machine effort of maintaining the index. If that is the case then they should not present the problem as constant factors vs asymptotic complexity as they currently do. &gt; Sure, but then you are changing the problem. AVL trees and B-trees maintain the elements in a specific sorted order. Maybe the search criteria changes all the time and there's no single key that works for all searches. Anyway, my point is not "always use vectors" but "understand how your hardware works so you can make good estimates of the constant factors." Bjarne's example problem can be expressed as a B+Tree with a proper index containing both order + position metadata in a way that will always be &gt;= a vector.
Why would you want to do this? I would say it is disallowed due to being unnecessarily hard to read for no benefit...
I believe it's ultimately a wrapper over COM. You could do it from C, but it's not fun. (You can do DirectX in C for example.)
Personaly, I dont know anything below C. 
It looks good only on paper. In reality, high performance vector code is often executed on CPUs that have not so smart C++ compilers (smart human outperforms even good compilers like recent GCC with little effort). I write ultra fast code for living for various platforms including existing TI DSPs, Intel x86-64 and some new stuff that are still covered under NDA. We tried to have portable intrinsics, but we failed. DSP compiler have uber-crap C++ optimizers and no one seems to care. Too many inlines or template instatiations ? A function call that blows everything away. Problems with memory aliasing even with "restrict" everywhere ? No SPLOOP. In is easy to write portable floating point multiply-add on 3 vectors, in reality kernels are much more complicated. You need vector predication to mask unrelevant stuff ? No way you will find a a common approach between AVX2, AVX512 and some proprietary Israeli DSP. Fixed point arithmetic and 20/40/72 bit accumulators ? Phase estimator when one DSP has vector atan instruction and another DSP/CPU needs approximation ? Reality sucks, and C++ will not solve that issue IMO. Code generators like SPIRAL are more likely to do it. 
I knew it years ago, but now I have forget a lot. But it is still useful to understand output from Interactive compiler - C++ compiler like this one. http://gcc.godbolt.org/
No idea. I haven't heard much of anything about any of them and haven't personally gone through any.
I've done some assembler programming in DOS on a Pentium computer, and while I still remember the basics like how some of the registers work, move instructions and even how the C calling convention works, most of it is now lost on me.
I use it very rarely, almost exclusively when debugging. Ability to read disassembly is needed to debug tricky issues. 
That is neat. Thanks!
Or, you know, `Thing* thing[N][N]`... edit - `*` instead of `&amp;`...
On my Amiga I used 68000 Assembler. More than C actually... Before that, on my Comodore C-16 I used Assembler too. I wrote a whole game in Assembler (a breakout clone). But on the PC... I used Assembler when I still used DOS. I guess it was on a 486 or maybe even 386... Since then I had no need to touch x86 assembler. I can still read and understand most of the code the debugger displays, but I could not write anything in assembler anymore. 
Don't complain about downvotes. It is +16. 
You're my favourite microsoft person. Not because it makes it more reasonable to use VS - I have no interest in running Windows, I'm afraid - but because it means I can use those features in cross-platform code and be sure they'll work!
 std::printf("(%d, %d, %d)\n", x, y, z); -- std::cout &lt;&lt; '(' &lt;&lt; x &lt;&lt; ", " &lt;&lt; y &lt;&lt; ", " &lt;&lt; z &lt;&lt; ')' &lt;&lt; std::endl; Are you really going to claim the second of those is easier to read?
 struct { int i; double d; } anon {10, 3.14}; decltype(anon) my_function();
I haven't migrated to ROOT 6 yet. It (ROOT 6, not Cling) still seems pretty buggy.
http://learncpp.com is okay. It's at least enough to get your feet wet and get a good grip on the syntax and structure without throwing you straight into complex concepts. It'll also let you figure out if you enjoy programming or not without a monetary investment. Take some of it with a grain of salt though; he's changed it now, but when I went through it, he was teaching hungarian notation as a good thing. ^^Spoiler: ^^it's ^^not ^^really.
I think this is only if it is declared outside any function and lives in the data segment. I'm not sure if a 2 dimensional array on the stack ends up being a strided 1 dimensional array underneath. Can someone clarify? I've actually tried and failed to look this up before.
Even RollerCoaster Tycoon, the Windows game programmed in assembly, still used C++ for its DirectX-bits IIRC.
Hang on while I do your homework before everybody else does it. We're all trying to prove to each other we're smart.
mt19937's algorithm is mandated, so it produces consistent results across all implementations. The distributions' algorithms are not mandated, so implementations can vary.
get&lt;MyType&gt;(mytuple) is maybe 75% as good as having names, and certainly a lot nicer than indices.
Ahh okay. Do you know what the rational behind this decision was? It seems like keeping the random engines consistent is nice because it allows great cross platform development. But then not making the numeric distributions standard nips that in the bud. 
Haha. Yeah I will be careful. Thank you for your help on this. Off topic question: Do you work on the standards committee or do you just happen to have the STL user?
I'm not sure what you want but this works for me: auto make_anon(int i) { struct { int val; } ret{ i }; return ret; } ... std::cout &lt;&lt; make_anon(555).val;
I used to write whole (but small in scope) Windows apps in it until 64 bit chips became common. It was actually the most "fun" language I've written code in and I'd love to have an excuse to go back to it. **But**, refactoring code was a nightmare which made large program frustrating. Also code you wrote wasn't really ever optimized for speed, rather it was optimized for size. These days I want speed, static typing **and** generics! What I learned was invaluable in debugging, I genuinely believe every programmer should aim to have a *comprehensive* understanding of it.
I do, asm was the first programming language I learnt when I was a teenager. Back in the days it was the way to go if you wanted to be cool... BUT! it was on the 80386, 16bits (32, but DOS) without MMX, SSE and all those. Today there are crazy instructions out there, and I don't know them at all You'll hate me for this, but I still think that a "real" programmer has to know ASM, or at the very least how the function_calls/return/stack/heap really work (compiling c++ code and using gdb/"g++ -S" is the fastest way to learn it).
take any tutorial and just dive in! you only learn writing code
Ah, that's where I was lacking phantasy. The struct is anonymous but it is known outside of the function. I always thought about returning an anonymous struct which is defined inside a function from that function, which obviously is impossible.
Well of course random will be inconsistent!
First, it's something other languages do, and so it can be surprising for newcomers to the language to have things not be reproducible. It’s not uncommon for people to come to C++ from Java or a scripting language. Java’s `java.util.random` is reproducible (and likewise, on Unix, C programmers using POSIX's `drand48`). For scripting languages, if I run this `perl` one liner: perl -le 'print "Perl $^V on ", `uname -srm`; srand(42); print rand(12345) foreach (1..5)' It produces the same numbers on * Perl v5.18.2 on Linux 3.4.90 armv7l * Perl v5.18.2 on Linux 3.8.13-gentoo x86_64 * Perl v5.18.2 on Darwin 14.1.0 x86_64 * Perl v5.8.8 on Darwin 9.8.0 Power Macintosh * Perl v5.6.1 on Linux 2.4.18-3 i686 (Redhat 7.3 from 2002) Likewise, if we run python -c 'import random, sys; random.seed(42); print [random.randrange(12345) for x in xrange(5)]' it produces the same five numbers with * Python 2.7.6 on Linux 3.4.90 armv7l * Python 2.7.9 on Linux 3.8.13-gentoo x86_64 * Python 2.7.6 on Darwin 14.1.0 x86_64 * Python 2.4.4 on Darwin 9.8.0 Power Macintosh So, first of all, cross-platform cross-version reproducibility is not uncommon. It’s not crazy to expect the program we ran last year to run the same this year. If the standard doesn’t mandate behavior, from release to release of the same compiler and OS, users can get different output from the same program. It’s particularly useful when teaching (including on-line tutorials), where you want to give the code and tell people what output they should expect to see. Lots of other parts of the standard library restrict implementation flexibility. `unordered_set` is pretty much hardwired to not merely be a hash table, but to be a hash table with separate chaining (even though that’s not the fastest technique). In fact, the random number library fails on flexibility elsewhere. It (erroneously) insists that the `SeedSequence`s used by the provided engines exactly match the interface of `std::seed_sequence` even though none of them use all its functionality (in particular, there is no need to be able to go back and ask to get all your seeds a second time), making seeding much more difficult than it needs to be, and technically impossible for anyone to elegantly wrap `std::random_device` so that it can be used as a `SeedSequence`. (BTW, I could go on at length about how broken seeding is in C++11 and C++14. I attempt to repair it a little with `seed_seq_from` in the PCG utilities library, allowing you to say `rng.seed(seed_seq_from&lt;std::random_device&gt;)` — currently almost every example you’ll find on-line uses `rng.seed(std::random_device())`, but that uses just one 32-bit number as the seed and is incredibly bad practice. Boost observed the same problem, and the maintainer of `boost::random` fixed it by making all the boost generators also almost-but-not-quite-`SeedSequence`s in the same way that the `seed_seq_from` adapter does, thus allowing the more concise `rng.seed(boost::random_device)`. Feel free to contact me away from reddit if you’d like to discuss it further.)
Is that using libc++ on both platforms? If not, switching to libc++ on linux might be a workable solution 
Huh. I hadn't tried that one. Neat.
Don't tell STL I said it BUT if the distribution is not consistent you could always just use %.. For a game the lack of perfect distribution may not matter.
&gt; Second I was looking into procedural game development and it would be nice for users to be able to share seeds across platforms. I had a feeling this was the driving reason behind this post. :) If I may offer an observation: The reason why Minecraft can get away with sharing game seeds is that it uses Java, which will have 100% the same behavior everywhere. Like /u/STL has suggested, be careful in picking your implementation for random number generation. I would recommend finding a good-enough single-file library and make it available to the students... provided that's not too advanced for the class. It might prove to be a useful exercise in using a third-party API, as well as ensuring reliable behavior across platforms.
When you say Java is reproducible do you mean Oracle/Sun's Java implementation, or GNU Java (gcj) and Darwin as well? I mean if gcc was the only compiler it would be reproducible too. I don't know much about Java, but it might be just that there is only one implementation.
Yes, learned it initially for reverse engineering work and then to contribute to a JIT compiler
I do up to a point, but that point is probably approaching a couple of decades out of date... Protected mode I can do at a push, 64 bit I wouldn't even know where to start without Google.
&gt; Before that, on my Comodore C-16 I used Assembler too. I wrote a whole game in Assembler (a breakout clone). &gt; amiga memories here too , 68k was really nice. 6502 BBC micro before that.. its basic came with an assembler. Never had a c compiler on the amiga. 
&gt; without pc Probably nothing. Programming on paper is hardly a useful thing. &gt; And I want to know can I develop any software with c++? Just beginner softwares. Yes you can. I believe "beginner software" is more about feature set, than implementation language. Anyway, C++ is general purpose language, so you can write basically anything with it. 
&gt; Java’s java.util.random is reproducible That ones sort of a push though, because it's not really cross platform, is it? It reproduces only on 1 system, the JVM, which whatever OS you are on creates a VM for. Porting the VM from system to system, then saying the VM behaves the same, that's almost a tautology. For the python example, that's true in one case, but that's not what the design docs say: &gt;Most of the random module’s algorithms and seeding functions are subject to change across Python versions, but two aspects are guaranteed not to change: &gt;If a new seeding method is added, then a backward compatible seeder will be offered. The generator’s random() method will continue to produce the same sequence when the compatible seeder is given the same seed. Yes, you are promised to be able to get your old engine back, which C++ previously made no promise for. I could be wrong here, but doesn't C++11 specify certain random engines, like if you use std::mt19937_64, isn't that guaranteed to always be the same for the same seed regardless of (conforming) implementation? I know it's late to the party, but it's still something. The default random engine can change between distributions, but that's true for Python, too.
I meant that as more of a joke, as far as the issue on hand, I think op should look into other methods of generating data, maybe even just a non-stl prng.
What about speaking to the teacher who taught you C++ in school to see if you might be able to use the computer after school for a short period of time each day? If that's not possible, do you live near a college or a library with computers for public use?
Agreed on using operator() vs operator[] [From cppreference.com](http://en.cppreference.com/w/cpp/language/operators) &gt; To provide multidimensional array access semantics, e.g. to implement a 3D array access a[i][j][k] = x;, operator[] has to return a reference to a 2D plane, which has to have its own operator[] which returns a reference to a 1D row, which has to have operator[] which returns a reference to the element. To avoid this complexity, some libraries opt for overloading operator() instead, so that 3D access expressions have the Fortran-like syntax a(i,j,k) = x;
If you have access to a PC and the internet you can write C++ programs without needing to download or install anything. For example, you can use a library computer. You can use sites like http://coliru.stacked-crooked.com or http://ideone.com to compile and run programs. Also https://www.codebox.io might become useful but it looks like they're not taking new users right now. You can also sign up at a place like https://github.com and use https://gist.github.com as a convenient place to save your programs. [hello world](http://coliru.stacked-crooked.com/a/3c36b2451381fe92)
&gt; I know how to write programs but how to code a software What's the difference between writing programs and coding software? To my understanding those are the same thing.
The decision isn't really up to me anymore. My position at the school is just to provide feedback to professors around what is commonly happening during tutoring and to help manage the student tutoring and grading activities. Whichever professor runs the course next semester can make the choice themselves.
What an excellent talk. Reminds me of Computer Security class where the professor would dissect every single bit of code and show us how it can be exploited in some way. Informative and fun too.
YOU'RE KILLING MEEEEEEEE
And that is what he is complaining about. MT is fine and reproducible its the implementations of the uniform distributions that are not the same across compiler vendors because their implementation isn't defined by the standard.
Oh, I gotcha. Thank you for the clarification. 
you should try r/cpp_questions for help with homework, this isn't really the place for this type of thing.
Hey OP, You might want to initialize the variable 'r' to some value. Depending on the compiler, the value of 'r' may be zero and thus it might never enter the while loop. Apart from that, I think you've nearly got it working. Try printing out the values of n1,n2 and r inside the loop to figure things out. Good Luck!
I have a LED TV with HDMI port. Do you think Raspberry bi will good for a beginner? Or should I go with a pc (something cheap). And mate I don't think anyone would be interested in giving his old pc equipments for free (no matter how old it is) . So you think I should study python. Okay mate I will surely try to learn it online. And thanks for your kind reply. I am feeling motivated. 
Well I liked how you explained it. However, I just wanted to say that I know to write a program to make a simple calculator but how I can make a application from that. Like an apk for Android os? Lol! 
I will keep it in my mind. Thanks. 
&gt; but I don't know how to proceed in writing the code. Seeing as you have written a complete program that almost works, I'm assuming what you mean is that you don't know how to _debug_ the program you've written. Here are a couple of tips that should be sufficient for fixing this program: - Turn up compiler warnings. As written your program produces the following warnings with my compiler: main.cpp:5:17: warning: variable 'r' is used uninitialized whenever function 'main' is called [-Wsometimes-uninitialized] int n1, n2, r; ~~~~~~~~~~~~^ main.cpp:8:11: note: uninitialized use occurs here while(r!=0){ ^ main.cpp:5:18: note: initialize the variable 'r' to silence this warning int n1, n2, r; ^ = 0 - Work out by hand the steps and internal states (i.e., the values of key variables) you expect your program to take while running with some particular input. Use a debugger (or print statements, if you want to start out simple) to check the actual steps and internal states the program takes while running with that input. Here's an example of your program with print statements so you can follow along as it runs: #include &lt;iostream&gt; using namespace std; int main() { int n1, n2, r; cin&gt;&gt;n1&gt;&gt;n2; std::cout &lt;&lt; "Begin n1: " &lt;&lt; n1 &lt;&lt; " n2: " &lt;&lt; n2 &lt;&lt; " r: " &lt;&lt; r &lt;&lt; '\n'; while(r!=0){ r=n1%n2; n1=n2; n2=r; std::cout &lt;&lt; "Loop n1: " &lt;&lt; n1 &lt;&lt; " n2: " &lt;&lt; n2 &lt;&lt; " r: " &lt;&lt; r &lt;&lt; '\n'; } std::cout &lt;&lt; "Loop done n1: " &lt;&lt; n1 &lt;&lt; " n2: " &lt;&lt; n2 &lt;&lt; " r: " &lt;&lt; r &lt;&lt; '\n'; cout&lt;&lt;r; return 0; } Keep in mind that learning to use a debugger will save you a lot of effort vs. using print statements, though there's an upfront investment in terms of the time it takes to learn.
I remember some of it and have written some of it two decades ago. Serves me now, but only to read disassembly while debugging something *bad* :-)
you can get a used laptop for less than a raspberry pi. Install linux with a light window manager on it.
So by application you mean graphical ? Because your basic c++ calculator can already run in Android, it just won't show anything on screen.
[Gist](https://gist.github.com/)? [Pastebin](http://pastebin.com/)?
We did some ARM micro-controller assembly in an undergraduate class at uni. Before that, I've taught myself some x86 assembly because I wanted to know how a computer boots up. I read a lot about protected mode, LDT/GDT, interrupts and so on (praise the Intel x86 manual :) ) and wrote a small bootloader that would load a tiny C kernel (it couldn't really do anything). I've forgotten a lot of the details, but I still know enough about it to be able to read very simple code and know what's going on, and I'm not scared if I see assembly.
Those (especially Gist I think) are awesome for actually hosting the snippets. I was just thinking somewhere where there could be discussions and descriptions as well. The more I think about it, I guess a subreddit would be the best. I might start one if there isn't already.
That would be okay for tuples in which the elements have distinct types. But they maybe don't, so IIRC C++ (for example, and as you presumably know, judging from your name!) has a `get` that takes a zero-based constexpr integer. Still it would be a fun exercise in template metaprogramming to define a variant of `get` that did accept a type, and for extra credit produced an intelligible compiler diagnostic if the tuple has more than one element of the requested type. *feels nostalgic for brief dalliance with boost hacking about 10 years ago...*
I actually did that limit on purpose to avoid it getting flooded (wishful thinking) with other languages. But, actually you're probably right. /r/codesnippets already exists though (and is empty) EDIT: Yanked /r/codenuggets though. 
I think the Raspberry PI suggestion is a very good way to go. It will also help you to get familiar with Linux and it comes with a variety of tools and compilers.. Python is a bit easier to learn than C++, but if you are going to program professionally you should learn both. If you are looking to expand your programming skills you might also consider online courses or programming challenges. You might like codinggame.com because it doesn't require that you have a PC to do the challenges and for most of the challenges you can use any language that you like.
Get the new Raspberry Pi 2 model! It's only very slightly more expensive but if you can afford it, it's about 4x the computer.
Exactly. Going back to pre-C++11 is just completely impossible for me. It's indeed almost like a new language, to paraphrase Stroustrup. It's close to impossible for me to understand that there are still people ignoring the massive improvements that have been officially introduced more than three years ago. We've been using C++11/14 at work for several years now (basically as soon as GCC/Clang became conformant enough), and it was the best decision ever.
Done :)
&gt; It seems that people use "random" to generate a large set of numbers. If they want that set to be the same, every time, every where, why are they asking the computer to generate it every time? Because the amount of data they want to generate may be very large (or even unbounded). Think seeds for generation of Minecraft worlds, or for randomised testing which you want to easily reproduce. 
You don't need an expensive PC to program in C++. Just get some ancient piece of shit laptop and install Linux on it. Code in vi or nano or something. Don't even need a GUI and in fact I think they get in the way of learning.
That was a great talk, thanks! Given what you've said, it should certainly be considered for inclusion in the STL. One question: in your talk you mention that it's possible to advance through all the possible permutations in a deck of cards using only the deck of cards as the state. Will that method go through all the permutations without duplicates? And if so, how exactly does it work? You also mention that it's possible to get a random seed with no input. Is it by exploiting data-races with multi-threading? Although I'm not sure if that would be very random.
Isn't that modulo going to result in bias? Not entirely sure of the tricks you're using with it.
That's what the badDistLimit stuff is about. Let's say that your RNG only returns numbers from 0-15 If you want a number from 0-2 then you'd mod 3, and you get: 0-2 3-5 6-8 9-11 12-14 and 15 is left out, which would bias the result. So what this code does is determine the last complete modulo cycle in the engine range and then if the number from the engine is greater than that it just throws it away and requests another number.
The STL has had next_permutation() and prev_permutation() since C++98. You start with a sorted input, and use a do-while loop to advance through all permutations, then stop when you get a sorted input again. (I've mentioned in one of my videos that this is the only good use I've found for a do-while loop; all other scenarios make me uneasy.)
All of the Standard's engines (except random_device, obviously) have fully specified algorithms (unless I'm forgetting some, but I only care about two), and in fact the Standard says what the 10,000th output value should be. It's the distributions that aren't mandated like that.
Well, your Perl example isn't reproducible by default. You had to use `srand`, as Perl's `rand()` documentation clearly states that if you don't call `srand` yourself with a certain seed passed in, that Perl will implicitly call `srand` without a parameter (which is non-deterministic, albeit not cryptographically safe). If you're the kind of person who will read enough `perldoc -f` output to figure out that you need to call `srand` yourself then you should be able to apply those skills to C++ as well by reading the documentation of the standard libraries you're using. So while I see your point, even you have to recognize that your "other language" programs didn't end up being reproducible by default, they had to be designed and programmed to be reproducible.
catching up to mingw-w64's SEH flavour?
I'm aware that it has several issues. As mentioned in the answer, I'm not trying to replace the standard library, nor am I claiming that the code is actually any good. It was merely an (barely tested and unused) illustrative example to answer a question that I had. Please, if you have the time and patience, feel free to write your own answer on the question, and if it teaches me something about random distributions in C++ I will certainly award it an upvote and tick it as accepted.
While I understand your motivation, I don't think you'll find much agreement in the C++ committee or community at large. Input iterators do not own any resources (not sure if this is codified in the standard, but I'm unaware of any input iterator in the standard that would be required to allocate memory, a file/socket handle, etc). Likewise, neither do output iterators own resources. Iterators, by their very nature are "views" on pre-existing data structures. They are adapters to make disparate interfaces seem the same. Seeing as iterators are effectively views on another resource/object, it makes sense that you would not be able to construct an iterator from an r-value. For instance, if you were looking at accepting ownership of an object that required iterator support, how would you differentiate between std::cout or std::vector in constructing the end iterator? std::end(std::cout) likely returns a sentinel value, while std::end(std::vector&lt;blah&gt;...) returns size + 1 from the vector's contents. If you're trying to pass such a construct to a standard algorithm, you need begin &amp; end, but you cannot compute both if the argument is an r-value. Sorry for the rambling, and I'm sure (hope) others will chime in with a more eloquent explanation.
Thank you for your suggestions.
Thanks.
&gt;Input iterators do not own any resources Indeed. That is what I was trying to address when I mentioned that `istream_iterator` is unique. I agree that *in general*, you don't want an input iterator owning any resource at all, ever. However, because `istream_iterator` is only valid as long as the file stream is valid (not just open), then the two lifetimes are much more tightly tied than "normal" input iterators. Not to be obscene, but it would be equivalent to having an algorithm call `vec.clear()` after iterating over your vector. &gt;If you're trying to pass such a construct to a standard algorithm, you need begin &amp; end, but you cannot compute both if the argument is an r-value. This was something else that was bothering me about my idea. It would require effectively re-writing iostream iteators, and I don't think that anyone would be in agreement to that. As /u/Plorkyeran mentioned, it would be better to have a class that encapsulates the iterators. Maybe it would be even better to leave behind the fact that iostream iterators underlie the structure. (see my update to the post).
Thanks for your ideas! (see the updated OP).
Nice!
I think `reproducible_uniform_int_distribution` wouldn’t fly but you’re welcome to try. My guess is that too many people would think it needlessly duplicates existing functionality and it’d get shot down. All you have to do w.r.t. seeding is look at your code (or LLVM’s or GCC's) for all the current engines and ask “what functions do I actually call when given a seed sequence”. In other words, what do we actually _need_. Those should be put into the spec for `SeedSequence` and the rest should not. I’d be happy to write things up more formally if I were convinced that people were receptive to the idea. (It’s not completely clear how the various committees work and how receptive they are to ideas from random outsiders.) 
I believe you'd need to iota between 0 and N!, shuffle, then convert the numbers to [Lehmer codes](https://en.wikipedia.org/wiki/Permutation#Numbering_permutations), then permute the sequence. But N! grows so fast, you'd never be able to traverse all permutations of even 20 elements. If you merely want random permutations, and are content with occasionally getting duplicates, shuffle() on the sequence itself is what you want.
Not just the distributions. No one says how `std::shuffle` should work, merely that it “Permutes the elements in the range [first,last) such that each possible permutation of those elements has equal probability of appearance.” It doesn’t say how many random numbers it uses, only that it requires “(last - first) - 1 swaps”. It’s pretty clear the kind of algorithm that’s envisioned, but it’s not 100% nailed down.
I've seen a couple of people ask for reproducible distributions but not enough for me to write up a proposal (and only the integers would be within my grasp). Interesting thought about reducing the seed sequence requirements. That has been done in the past (with allocators) and it is a fairly non-invasive, easy thing to do, since it doesn't increase requirements on user code. I'll look into specifying it if I have time. Library Evolution is fairly receptive to proposals (much more so than Evolution for the Core Language), although they need to be presented in person (either by the author, or a Committee member willing to donate their time). Occasionally something is controversial (e.g. I was unable to get the distribution preconditions fixed, despite having what I thought was an ironclad argument).
Improvements to the allocator interface: - Reallocation! - The ability to query the actual size of the memory chunk returned by the allocator. - The ability to query whether allocator::construct does any special bookkeeping, so that we can avoid default-constructing elements if they don't need to be initialized. - Ditto for allocator::destroy. - Support for allocation where the address is subject to alignment constraints, e.g. posix_memalloc. Other notes: - initializer_list should have a constexpr operator[]. - Constexpr variadic min, max, minimax functions. - std::is_specialization_of - Is it possible to detect if T supports moving (but not copying) from U? If C++1z does not support concepts, I will rip out my nipples, staple them to a printout of the standard, and use it to kindle a bonfire for a satanic ritual in which I will condemn every member in the committee to an afterlife in the shapeless void of template error messages produced by today's compilers.
This is a problem for ranges to solve.
Ranges, e.g. Niebler's range v3
I would recommend getting a new model raspberry pi as well. It's more than good enough for learning. I'd offer to send you my original model B raspberry pi, but I suspect it would cost the same to just buy the newer, better one
This stuff is not the STL
Ranges, std::optional. Also, what about the long-promised graphics library (based on Cairo IIRC), filesystem library, networking library ?
* std::string_view and std::array_view * an ability to report errors/warnings without throwing exceptions/unwinding the stack * some basic utf8 iteration utilities would be nice * a universal, overloaded, ADL-enabled std::from_string, a complement to std::to_string * memory mapped file handling/support * more free container functions, like aKateDev's std::contains, maybe std::erase, std::find_or_default, etc. EDIT: Right, forgot about &lt;filesystem&gt; !
This litters my code, and it's extremely frustrating. I'd love an addition like this. In a similar vein a version of at() and find() (Find is fine, I'm super dumb.)that give back pointers and produce a nullptr instead of an exception when nothing is found would be great. Though I know that might be against tenants of the STL or something like that. I'm still a relatively new programmer and still a student so I'm not as well read as many of the folks around here. edit: I'm dumb.
Additions - I'd really like to see executors, though I expect the ongoing discussion to prevent standardization for some time. Some libraries from boost would be great as well. In no particular order: filesystem, asio, lockfree, flat_(multi)map/set, lexical_cast, optional, any. On another note, I'd like to see a reasonable replacement for iostreams. IO and string manipulation is just not as good and/or nice as it could be.
A method for getting iterators out of range-based for loops would be nice. This might fall within the scope of *ranges*, as I haven't kept up with all the recent momentum on the subject, so I apologize if this is already covered there, or elsewhere for that matter.
I can't think of a single example of needing to know if something is in a container and then not needing the item. Can you provide an example?
 * A concept-aware, range aware STL. That alone is a massive undertaking ( you have about 2 years, no pressure ) * The STL should come in module form * hopefully std::optional will move out of experimental * a type safe printf or a better way to manipulate streams * boost::variant and boost::any are nice, not sure if they should move into the STL ( speaking of which, the standard should mandate that typeid works across library boundaries ) * I guess it would require a core feature, but, It would be ~~normal~~ nice for scoped enums to support bit manipulation operators 
* ranges * optional * variant
 scoped_function for automatic clean up on scope exit callback list/signal slot style class. Allows adding/removing functions/slots that can all be invoked/signaled at once. Your std::erase and std::erase_if stuff looks good Possibly deprecate std::for_each as range based for is a better alternative
Sorry, I was thinking about Operator[], I was thinking about all three of them while writing and goofed up! Find works fine the way it is, I'm just dumb! 
It is slower. `contains` would stop on the first element found.
std::count could perform worse in some situations where you would only need the first hit to satisfy 'contains'.
That's a good candidate, right. Indeed std::count() wasn't in my mind. It is true that std::count() solves the problem just as well, I'd still argue that the semantics are different: * std::count() tells you the number of occurrences * std::contains() would tell you whether an item exists at least once. From this perspective, std::contains() is (possibly) faster than std::count() and expresses more precisely what the code is doing that std::count(). So bottom line is imho: std::contains() would still be a worthy add-on.
&gt; There's std::set, but that imposes a strict ordering on the elements in the container which might not be desirable. ~~Also std::set is immutable~~ Also the values stored in std::set are immutable &gt; The STL container class set is used for the storage and retrieval of data from a collection in which the values of the elements contained are unique and serve as the key values according to which the data is automatically ordered. The value of an element in a set may not be changed directly. Instead, you must delete old values and insert elements with new values.
Not exactly the STL, but a fix to templates: partially specialised template functions function. Yes function overloads can cover a lot of use cases, but what about template&lt;typename T, int x, int y&gt; T foo() which might very easily need a special implementation for floats or whatever.
There is something really close. bool std::any_of(begin, end, predicate); The only thing is needing to wrap the comparison in a lambda. There is also all_of and none_of algorithms. It would be nice to have overloads that take the iterator value_type or possibly event anything that is equality comparable with the value_type.
Asio? as in boost asio. having core socketing capabilities feels like something that should be part of the language 
-whole heartedly support the asio proposition - saddly graphics libraries are maintained by the hardware companies that implement them in their driver. Afaik, c++ can't just decide to publish a graphics api that wouldn't just be a wrapper over opengl
A good standardized library for networking. BSD Sockets are tiresome to work with and not really a good match for the new modern solutions we got in the C++ STL today. 
Scope guards and error_or (separately from optional)
I meant interruption behavior like we have in boost::thread (interruption points). I'm quite certain this can implemented portably.
I tend to use `std::set` to collect unique items quite often, and check whether it contains a specific item before performing some operation.
ok, it says 2D, it's more credible then.
Newbie here, forgive me if this sounds weird, but why do you want the memory wrapped file support? Doesn't the OS do that for you, so when the file is read it automatically gets put into memory. And if you want to load it into memory before needing to read it, you can use a system call to signal the OS that you want to flag it as read without actually reading it. 
&gt;I don't know how libstdc++ and libc++ implemented shuffle(), but if they didn't do that, they took a needlessly harder path. Are you allowed to take a look at other implementations, or would their licenses prevent you from actually using what you saw? E.g. I once checked the libc++ implementation of the `std::equal` algorithm and they don't use your clever elimination (that you showed at CppCon'14) of an extra overload of the 4-argument version (that relies on partial ordering of function templates). So perhaps they are similarly restricted from looking at the MS sources?
It's not nearly as masochistic as it sounds. Checkout [flat assembler](http://flatassembler.net/) commonly referred to as Fasm. Go through the examples folder and you'll see how easy pure assembly can be with just a few boilerplate macros, all of which can be ignored.
There is no fine grained control for any of that (not portably, anyway). The library gives me no information whether the memory I'm accessing is just mapped, or whether it actually touches significant amounts of RAM. In a 64-bit application specifically, I'd love to be able to map a 3-5 gig file (and, for example, use it as a fast tree, omitting the need to call system functions) without worrying whether any of that puts significant pressure on memory availability. It's just simpler, faster and has the potentiality to be optimized by the system.
+1 on the uninitialized vector allocation.
we _need_ ranges in order to get rid of all the raw loops! Now for my dreams: In terms of Algorithms, [lodash](https://lodash.com/docs) has a few neat features-- I doubt there will be consensus though, because a lot of them will require allocation: I'm thinking especially about algorithms that do things like pluck, zip, zipObject, unzip -- basically operations on KV structures that produce lists and vice-versa. In terms of async stuff, I _really_, _really_ like all of the control flow algorithms that are in [async](https://github.com/caolan/async), notably series, parallel, waterfall, auto, and cargo. I tried implementing async::prallel and async::series with variadic templates but it didn't really work out for me (I'm sure people more talented could pull it off) :). If these made it into C++, it would make writing asynchronous code a lot more idiomatic. A couple of low-hanging fruit: searching for a sequence within a range: something like find(begin,end,seqBegin,seqEnd) kind of [like this](https://github.com/matthewaveryusa/utils/blob/master/util_bytes.hpp#L241) iterating over a larger numeric limit in smaller numeric limit increments [like this](https://github.com/matthewaveryusa/utils/blob/c670060060017c7645f023be0d0b88c9dca29eaf/util_swiss.hpp#L41). This is mostly for supporting legacy code that expresses sizes in int32s, and you need to wrap the interface to support int64s. A usage example is me wrapping openssl with a sane interface [here](https://github.com/matthewaveryusa/utils/blob/c670060060017c7645f023be0d0b88c9dca29eaf/util_crypto.hpp#L125)
&gt; SIMD datatypes Plus one for that. I recently read a blog post by an intel guy claiming people didn't use SIMD compared to multithreading for cultural and code cleanliness reasons. I thought to myself: "Standard multithreading exists. SIMD does not." &gt; filesystem See [n4100](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4100.pdf) &gt; b-trees Basically, `std::set` and `std::map`... but that doesn't help us if we feel we need an unbalanced tree, or one where the nodes aren't ordered in a particular way. &gt; networking [boost::asio is being standardized](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4370.html). Maybe if you don't like it, post your concerns/complaints on the C++ Future Proposals google group and spark some discussion.
Seems messy to use just that. We use tinyformat which is header only https://github.com/c42f/tinyformat
* A simple way of initializing a std::array of objects with non-trivial constructors w/out hitting the default constructor first -- eg. some way of passing in a generator to the std::array constructor. * A simple way of determining if an incoming template parameter supports specific constructors and methods (via name and signature) for use with static asserts * A simple way of determining if an incoming template parameter is derived from any particular base class * The ability to have arrays/vectors of refs and const refs * Fixed-point datatypes (so I could create something like `std::fixedpoint&lt; 64, 64 &gt; myvar` -- this would come in handy for problems where I need both precision *and* range) * SSE/Vectorized math routines for matricies, vecs, and all that linear algebra goodness * Thread pools! * Full UTF-8 support in std::string.
A write once, run anywhere type standard so STL objects could be passed across dll boundaries. But this will never happen.
+1 for &gt; expected&lt;T, E&gt;
&gt; bool std::contains(start_iterator, end_iterator, item). This should be covered by [std::count](http://en.cppreference.com/w/cpp/algorithm/count). The return type is not bool, but it is convertible to bool so it can be used safely in an if statement. &gt; bool std::contains(container, item) If the STL expands to use range-based overloads, then a range-based std::count should cover this use case too.
Use std::count.
This^
&gt; more mathematics, especially std::matrix&lt;Type, X, Y&gt; and std::vec as typedef for matrices where one dimension is 1. I really really really want something like NumPy for C++. 
std::stack::clear()
Thanks for the reply. Yup, "cultural and code cleanliness reasons" are why I'm not allowed to commit SSE code at work. Unless you work at a shop that's obsessed with performance, SIMD scares people. Is there a reason why `std::map` couldn't be implemented with a b-tree? Iterator invalidation, I'm guessing? I'm only a dillettante in networking so I don't feel comfortable starting that discussion. I understand that serious networked applications need async, and OS async APIs are very different so a standard abstraction is valuable. If `asio` is standardized, hopefully they'll add some kind of simplifying wrapper layer so the code for simple tasks is simple.
If you want matrices and vectors look at Eigen. It is a header-only library and very easy to use. 
&gt; I can't think of a single example of needing to know if something is in a container and then not needing the item. I worked on software that would have to do a lot of work for account numbers that hadn't been encountered yet while processing any given incoming dataset. We stored the previously-seen account numbers in a collection and for every incoming record, if the account number was not already in the collection we'd trigger the "do all the setup work for this account" code and then add the account number to the collection when done.
Possible: * Fixed `std::copy_n` return type, added `std::move_n` as a convenience function. Impossible: * Stateless and generally improved iostreams. * Fully constexpr and reference constraints enabled STL.
Third. ADTs are just so nice. And everyone can stop returning null pointers.
&gt; flat associative containers See: `std::unordered_map`, though we don't have any sort of "sorted vector". The closest might be `std::priority_queue`, but that's a heap. Maybe it'd be nice to have something like `std::ordered_sequence&lt;T, Container=vector&lt;T&gt;, Cmp=less&lt;T&gt;&gt;`. (needs a better name)
[Elvis Operator](http://en.wikipedia.org/wiki/Null_coalescing_operator): now: if( ptr ) ptr-&gt;doSth(); 17: ptr?-&gt;doSth(); Ternary ? with default: now: resultPtr = a ? a : b; 17: resultPtr = a ?: b; Closures with containers (samples from Groovy lang): {1,2,3}.each([]( auto it ) { func(it); }); {1,2,3}.eachWithIndex([]( int pos, auto it ) { func(pos,it); }); Semicolons optional?
&gt;graphics library (based on Cairo IIRC), filesystem library, networking library plz
&gt; There's std::set, but that imposes a strict ordering on the elements in the container which might not be desirable. You can use `std::unordered_set`.
It's not just 'possibly' faster. It's exactly N times faster in the best case scenario (the item is at the front), and N/2 times faster in average (I think?).
Well, works for me. Not sure what you mean by the naming conventions as its all seems fairly rational to me. Any examples? As far as I can tell its much easier to use than competing libraries. Armadillo is another nice looking library but I don't have much experience with it. However it does have initializer lists, if thats important to you. 
Here you go: https://gist.github.com/en4bz/f07ef13706c3ae3a4fb2 Uses '%' as the format character and needs '&lt;&lt;' defined on the type. Doesn't currenty support the '%%' escape. 
&gt; Is there a reason why std::map couldn't be implemented with a b-tree? Iterator invalidation, I'm guessing? It is! If you look at gcc's implementation, and probably clang's, too, there's a hidden class implementing a [red-black tree](https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CB4QFjAA&amp;url=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FRed%25E2%2580%2593black_tree&amp;ei=0QscVaXxMIOVNorRg_gC&amp;usg=AFQjCNEEUpDO5JqccaShKg06jOe0E2dzjA&amp;sig2=xnbg80QN0QPHtovGW0HpKw) that `std::set` and `map` are both implemented in terms of in order to ensure worst case `O(log(n))` lookup, insertion, and deletion. (Unbalanced binary tree lookup has linear complexity in the worst case.) So, I think the question is: Why don't `map` and `set` iterators have left and right children publically visible? Why don't we have unbalanced tree access? I think the answer to both has to do with how `&lt;algorithm&gt;`-compatible iterators are implemented. To increment an iterator in a tree, if there's a right-child, go right, then left as far as possible. But when already at a right-most child, one must traverse through the parent nodes until one of greater or equal value is found, meaning traversal using iterators requires ordering. Generic, unordered trees don't really fit with standard C++ style, but that certainly doesn't mean they wouldn't be useful.
You could just wrap it in a templated function that takes container and T while using equal_to&lt;T&gt; as the default predicate.
std::size(), std::empty() and std::data()!
CppFormat to standard library https://github.com/cppformat/cppformat
A simplified string class. The `std::string` interface is an overwhelming mouthful, and it doesn't have to be.
Is it the camel case thing ... ? If thats it, yeah, I kinda get that I suppose. But personally I use camel case for function names in my code so ... :D 
With proper UTF-8 support ! :)
Yeah, multi-dimensional arrays would be great. Or even better, some sort of tensor module. Which I think they have but is experimental at the moment and not fully developed. 
* ranges * flat versions of all containers with more customization support * TBB style task system * SIMD support, possibly using the approach Boost SIMD is using. Must not limit user from performing any optimizations or nobody will use it. * GPU support: something like C++ AMP 
And that could get all the various SSE variants hidden away so we could write portable routines that automatically get us SSE-accelerated code where available.
Bravo! Just... Bravo!
&gt; and N/2 times faster in average (I think?). That would be true if only the container is guaranteed to contain the element (which is silly, because then you just optimize it down to `return true;`). In your use case, you very rarely have the looked for item, it will just approach the same speed as count, whereas on the other end if you almost always have the item in the container it will approach N/2 like you said (assuming a random distribution. If we are looking at pure noise, with a 50% to contain the element, with an equal chance to be at any point in the array, it would be N*(3/4).
You're in luck, they were voted in at the last meeting.
Ranges indeed! I'm sick and tired of writing: some_function(long.text[to].find[container].begin(), long.text[to].find[container].end()); Also I'm sick and tired of auto tmp=my_multimap.equal_range(key); for(auto it=tmp.first, it!=tmp.second;++it) ///... ideally a range would act like an iterator (have an `operator++` and an `operator*` but also have an operator bool that says if we're still in range **edit** To get an idea, a possible implementation could be something like this: template&lt;class ITER&gt; class range{ public: range &amp;operator++(){++b;return *this;} operator bool()const{return _b!=_e;} reference operator*(){return *_b} ITER operator-&gt;(){return _b;} ITER begin(){return _b;} ITER end(){return _e;} private: ITER _b,_e; }; 
Ah, yea, I thought I might've missed something. Point being though, count is always slower, never faster and the wrong tool for the job. If you wanted to use "good enough" algorithms you might as well use C#.
The STL intentionally makes inefficient code harder to write (that's why vector doesn't have push_front(), even though it can be implemented with insert-at-begin). I worry about contains() encouraging quadratic complexity, and also about its interaction with the associative containers. (In erase_if() I was able to argue that equality should always be used.) But the argument that contains() is merely a weaker, faster version of count() is somewhat compelling, and it's clearly popular (and easy to specify). I'll think about it, thanks!
The Filesystem TS was recently finalized. (And implemented in VC 2015.) It's a strong candidate for inclusion into C++17. Study groups are working on the others.
&gt; Also std::set is immutable I think you meant to say that the values contained within std::set are immutable – std::set itself is clearly mutable.
In this particular case, we didn't want the value inserted until *after* all the heavy processing had been done. Inserting the account number right at the start would have Broken Everything. (Granted, it wasn't the best design, but when coding for a living you spend most of your time working on pre-existing codebases where redesigning from scratch isn't an option.)
&gt; I want std::any_of_is, std::all_of_are, … What do you mean? I understand the difference between contains and count, but I don't see how to create a variant of any_of/etc. which already return bool.
long overdue :-)
Some kind of standard circular buffer container would be great. It's nice to have a constant-time, array-based collection container that can be used in resource constrained environments.
This is Core, but there's a not-so-obnoxious workaround. Provide a function template for users, and implement it with a static member function of a class template. You can then partially specialize the class template. Alternatively, if you translate your explicit template args into tags, you can implement it with overloaded helpers, since partial ordering of function templates works like partial specialization of class templates. It is an omission from Core, but even as a professional template metaprogrammer, I've found this comes up rarely enough to be really problematic.
Yeah, this would lead to endless confusion - what about a string that contains only null characters?
You are right, fixed.
I've thought about guards, but I believe they must be done in the Core Language to be truly useful. (The problem is that you really don't want to allocate memory.) for_each() is the world's least useful STL algorithm but it's not really harmful.
You have `auto` for non types http://goo.gl/H1EN5l 
&gt; some basic utf8 iteration utilities would be nice [utf8-cpp](http://utfcpp.sourceforge.net/)
I'm hoping the "Boost.Expected" proposal goes through. There are some things in it I disagree with (do notation), but I like it as a refinement of `std::optional`, and it would certainly make wrapping C APIs a lot easier (as of right now I'm stuck with MNMLSTC Core's `result&lt;T&gt;` and `expected&lt;T&gt;`, which are for `std::error_condition` and exceptions respectively) Also a `std::variant` It's not been proposed but I would love a `std::bytestream` to replace `std::strstream`. Getting rid of `argument_type` stuff would be dandy~ Also, maybe some forms of functions found in `&lt;algorithm&gt;` that would allow early termination while iterating (like a `copy_until`/`copy_while) or conditional forms of some algorithms like `transform_if`. Oh! And now that we have `void_t`, I'd like to see some standard type traits for figuring out if a given operator exists. The `void_t` trick works with *every* operator, I've discovered. This is also sort of related to the operator type traits, but a `std::ignore_t` that is simply `decltype(std::ignore)`. We do it for `nullptr`, why not `std::ignore`? (Just to clarify, I use `ignore_t` to represent 'ignored' types in template overloads. Sort of like Boost's `dont_care`. EDIT: Wrote more than I thought. Whoops! :v
'So how many years of experience of Cucumber would you say you have?'
One can dream
Simply too ridiculous to even entertain for a second.
I know, I was specifically thinking about range-v3 (I think a lot of people are) but the proposal is huge ( in every sense of the term ), how far off are you from approval ? And then there is the matter of the integration with the various existing implementations.
Saving this for next week to scare the junior devs about the language they need to learn for the upcoming project.
If you let `std::contains` return a `std::optional&lt;Iterator&gt;` (or maybe a `std::pair&lt;bool, Iterator&gt;`), you can avoid most traps of quadratic scaling or other double work. E.g. you can write stuff like if (it = std::contains(first, last, value)) // proces *it
My general design direction was approved by non-binding straw polls last meeting. In May I'll present wording for (what I think of as) a minimal useful subset of functionality: basically, the concepts; some small utilities; and range-based, constrained overloads of the algorithms. No views (yet). The quality bar for a TS is lower than for the Std, so expect this to move along quickly, but we're still a long way from realizing the full potential of ranges. I'm going as fast as I can, and after the Lenexa meeting it's likely there will be more hands on deck.
&gt; Dennis Ritchie declined to comment :'(
C++ people always come up with great April Fools jokes. Like Stroustrup's [whitespace overloading](http://www.stroustrup.com/whitespace98.pdf).
Surprised no one has mentioned cryptography yet -- [this python library](https://cryptography.io/en/latest/) proves it's possible to have a high-level API that *doesn't* look like a thin port of OpenSSL, or depend on only a couple popular algorithms. I'm imagining something a little like the improved random number library.
Actually, I meant something like the failed-assumption behavior of the assert() macro, but as a regular, runtime C++ function (with the option to provide some sort of message). Everybody ends up (re)implementing it at one point or another anyway, why not add it to the library?
&gt; iostreams Removing iostreams for the standard and replace it with something superior would be really great :) 
Feels more like a Matlab thing to me. Making the syntax more like an engineer's math, horrifying programmers in the process.
&gt; On Windows in particular, the interop standard is COM, and that gives cross-language ABI, api versioning, process isolation, component monitoring if you use COM+ and more. If you want to do that you can, but clang's 'interop standard' is being ABI compatible. For example on OS X linking clang built object files and gcc 4.2 (the version that used to be the OS X platform compiler) object files is supported. Clang intends to support the same thing with MSVC on Windows. http://clang.llvm.org/docs/MSVCCompatibility.html http://blog.llvm.org/2014/07/clangllvm-on-windows-update.html http://llvm.org/devmtg/2014-04/PDFs/Talks/clang-cl.pdf 
Eric Lippert's [C# joke](http://blogs.msdn.com/b/ericlippert/archive/2010/04/01/somelastminutefeatures.aspx) was pretty good too.
&gt;std::string_view and std::array_view Came here to add this. Glad it was already there! The string facilities in the STL need some loving.
&gt; std::size(), std::empty() and std::data()! What about std::capacity &amp; std::shrink_to_fit?
The C++ streams seem to get a lot of hate, with some arguments more compelling than others. I'm curious about your perspective since you work on the standard library. Why do you say they suck? How would you like a total replacement to look?
I would love to see some more domain specific algorithms. Such as Boyer-Moore string search. std::fill( ) that does not take a value, instead default constructs instead of copy constructing. Less useful but still nice would be to support emplacement fill. containers constructor and resize overloads that default initialize - without messing around with allocators. 
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3951.pdf 
What are some concerns that are unique to interrupt/exception handlers? When would you use volatile and static within a function? Globally? What types of precautions are necessary when working with overlays? What techniques would you use to minimize executable size? And data size? What are some pitfalls of passing by value? What are some operations that allocate non-stack memory as a side-effect? What would you use as alternatives if you assume all memory has to be preallocated? What kind of information would you collect to facilitate debugging? What kind of error recovery is possible and appropriate? What measures would you take to ensure firmware upgrades complete successfully, or to recover in the event of a failure part-way through? How could you identify worst-case performance or memory utilization scenarios before deployment?
COBjective-C#+ just rolls off the tongue, does it not?
The trouble with `boost::optional` is for a common use case, returning an optional `Type&amp;` or `Type const&amp;`, it's internally implemented with a pointer and a boolean. There's no need to have the boolean - you could just use `nullptr` internally to represent the unset state. Let's hope that any `std::optional` implementations don't have this blemish.
No, it kicks ass, and rapes C# and Java.
Nice questions. I'm off to find the answers :o)
`std::optional&lt;T&gt;` would be an example of an "algebraic data type". It optionally encapsulates a value of type `T`. And if it does not, it's "empty". These kinds of types are popular in more functional languages. You can also use them as a function's return type to avoid exceptions. [This](http://doc.rust-lang.org/std/result/index.html) is how error handling is done in Rust, for example.
I'm curious why they put that in there. If that was a sentence by itself, it would be part of the joke. But lumping him in with a living person and giving him an action is just kinda...weird. &gt;Bjarne Stroustrup and Dennis Ritchie declined to comment, but were seen shaking their heads and muttering, “they’re nuts!”
&gt; I was unable to get the distribution preconditions fixed, despite having what I thought was an ironclad argument. What issue were you trying to get fixed? Is there a proposal I can read, or maybe the discussion is covered in some meeting minutes?
Goddammit. Read halfway through before I realized what date it is.
Given how silly that is, could a modern compiler optimize this sort of thing into a non issue?
Particularly, it must do the format string parsing **at compile time**. 
I'd love a total deprecation of basically all the IO in the stdlib with good replacements.
Absolutely agree!
*checks to see what date PHP 1.0 launched on*
`unordered_map` isn't flat, it's required to be bucket-based.
&gt;17: ptr?-&gt;doSth(); Eugh no. If you have a pointer that shouldn't be null then use a god damn reference.
I personally would prefer `reversed(c)`. `reverse(c)` should reverse c. `reversed(c)` should give you a reversed view of C. Same with `shuffled(c)` vs `shuffle(c)` and `sorted(c)` vs `sort(c)`. 
`std::fiber`
Maybe I'm odd, but I'm pretty certain I've never written code like that before, which is why I am surprised that this is called common. Always for me the code is 'do something with all of these things', or, 'get this thing and do something with it'. I think if I came across this code I would question it. 
&gt; For those of you who I fooled -- including at least one tester on the C# QA team, ha ha ha ! He never saw it coming, poor guy.
To expand on this, if you just want a very quick implementation of this, initialize with std::vector&lt;T&gt; array(width*height) then use array[x + width*y] (which is essentially what those includes use).
They are way too complicated, with lots of customization points that nobody ever uses. They are also infected with localization issues, when I/O (talking to devices like files and consoles) should be cleanly separated from localization. I would want a replacement to be massively simpler, and I would be willing to give up a whole bunch of "power" for that.
I'll use this as an excuse for my own, simple C++ library that (among other things) has something similar :) http://www.reddit.com/r/cpp/comments/2xxbi0/a_small_library_of_useful_tools_for_those_of_us/ what's relevant here is an object that turns text into a stream state: cout &lt;&lt; '-'&lt;&lt;sstate("10.4")&lt;&lt;pi&lt;&lt;" "&lt;&lt;100.&lt;&lt;" "&lt;&lt;0.00001&lt;&lt;-71.23456789&lt;&lt;endl; prints - 3.142 100 1e-05 -71.23 (sets `cout` to width 10, precision 4) You can set all of an ostreams states using this class, and it also integrates nicely with some other output tools I have. There's also a python-like "`printf`" (with `%`, you know), but I haven't gotten the time to rewrite it at home (it's a library I have written at work, and I can't send files out so I have to rewrite it)
B-Tree containers. std::set and std::multiset waste a fair bit of memory and a B-tree container would perform better on many workloads. The ability to adjust the sizes of the nodes would be needed as well. This would nicely round out the containers. The addition of specific sorting algorithms rather than just a generic "sort". Different sorts have different properties and at least implementations of the most common sorts would be nice. If these were to be added, I would hope they would be in a separate header, as the algorithm header is already enormous. std::sort should be required to be introsort by the standard. These should all be added to &lt;algorithm&gt;. * find_first_not_of * find_last_of * find_last_not_of * identical The ability to tune the size of the nodes in a deque, at least to power of 2 sizes, would be welcome. I don't care if this is a leaking of the abstraction. Intrusive containers and simple fixed size containers would be nice as well. 
I think he means something like [this](http://stackoverflow.com/a/25846080/1430927).
I like java's implementation of InputStream/OutputStream very simple.
I absolutely concede on the localization issues - those are one of the more compelling arguments against them. I guess I was hoping for some technical arguments about what makes them "way too complicated". I usually hear ones about how verbose or unintuitive they are compared to `printf`, things that can be often be handled with a few helper functions, even if that is less than ideal. I tend to consider such arguments to be more preference than technical. I don't know exactly what I'm looking for, but I was thinking along the lines of design aspects which force inefficiency, or egregious implementation/maintenance burdens.
- concepts - std::hash_combiner! - std::copy_type_qualifiers_t&lt; From, To &gt; - std::initializer_list for forwarding, not just only copying (otherwise braces-list initialization is quite useless for containers with container&lt; Heavyweight &gt;::container(std::initializer_list&lt; Heavyweight &gt; il) c-tor). - std::optional&lt; T &gt;. And maybe std::optional&lt; T &amp; &gt;, but raw pointer is semantic identical. - std::variant&lt; Ts... &gt; (can be implemented at the moment even in constexpr-way, as I know, but it would be better if C++ would have native support for inheritance to/from union-s) and coupled std::apply_visitor for visitation, multivisitation and delayed visitation. - std::size, std::empty... in a way of Stroustrup's proposal (requires a language-native support). - way to output using std::ostream_iterator&lt; T &gt;(cout, ", ") without trailing delimiter. - std::ostream_iterator&lt; T const &amp; &gt;/std::ostreambuf_iterator&lt; T const &amp; &gt; support
Thanks for taking the time to respond, STL; those are the kind of features I was after. I've read parts of the standard, but not in its entirety, and used streams, though not to the point where I did anything significant with them. Now I have few specific things I can go and research. On a half-related note, I am certain I'd like to work with you if I could. Just not sure MS is the place for me :)
Sometimes you have to use C API in C++, e.g. with openssl or [curl](http://curl.haxx.se/libcurl/c/CURLOPT_READFUNCTION.html): size_t read_callback(char *buffer, size_t size, size_t nitems, void *instream); CURLcode curl_easy_setopt(CURL *handle, CURLOPT_READFUNCTION, read_callback); I'm not sure how to use references there. 
Thanks for taking the time! I couldn't sleep anymore, so this is not well thought out: *Description:* * `std::value&lt;T&gt;` and `std::value&lt;void&gt;` * `std::value_equal_to&lt;T&gt;` * ... `std::value` would take a `const auto &amp;v` * `v` is already a value, then `std::value` acts like identity * `v` is a pointer, then `std::value` is called on the dereferenced `v` * `v` is a pair, `std::value` is called on the second element * overloads exist for smart pointers * custom extension points need to be possible, to provide support for custom smart pointers etc. When `std::value` is called with a non-void `T` the recursion will stop as soon the function parameter has type `T`. int a = 10; auto b = std::value&lt;int*&gt;(&amp;&amp;a); // b would be of int* and point to a `std::value_equal_to` would take a `T` and store it by value. Then it would have free comparison operators taking any other type and calling `std::value&lt;T&gt;` on them. *Rationale:* Make generic programming easier. For example, using algorithms is hard when the containers contain pointers of any form, or when associative containers are used. At the moment one has to write lambdas to find an integer value in a container of integer pointers (plain pointers, shared pointers, ...). In combination with associative containers like `std::map` this even gets worse. What I want to do is write `std::find(my_container, std::value_equal_to(10))` and not care whether the container is a `std::list`, a `std::map`, a `std::unique_map`, ... and whether the container stores pointers of some sort to int. I think something like the proposed `std::value` could be very powerful in combination with ranges.
The standard is based on what is existing best practice. The networking, filesystem and threads libraries, for example, are all based on boost. The containers are based on the STL. When the committee come up with things in their own, they naturally produce things that aren't production-ready and general-purpose enough. `iostreams` are theoretically fine, but they have so many flaws and annoyances to use that most people don't. And they have a reputation for inefficiency, but I'm not sure if they are still as inefficient as they used to be. If someone wrote a library for 2D graphics use in the style of the standard library, perhaps as part of boost and perhaps not, it would be a good start. I'd personally like to see a few revisions of something like that along with real world testing to show that it is both portably implementable (with consistent behaviour!) and actually useful. If that library got used enough that people wanted it in the actual standard library, that would IMO be a fine thing to do. But without existing practice to guide the committee, I'm afraid they'll build another monstrosity, or even worse just copy some other non-stdlib-style library like Cairo or something. That would not be a good thing. Look at Niebler's range proposal. It is much stronger because it is guided by the successes and failures of ranges in other languages and libraries (D, for example). EDIT: What would the library do? 'Render 2D' sounds all well and good, but would it render to an array of bytes? Or to the screen? Or what? --- ^(*note: as far as I know, the now-removed `export` is another example of something the committee came up with on its own. `auto_ptr` might have been too? :P*)
Or [utf8rewind](https://bitbucket.org/knight666/utf8rewind/downloads), which has an `utf8seek` that can seek forwards and backwards. 
The interesting thing here is how you actually _want_ to use `random_shuffle` for your explanation, because the “weird” RNG it uses is actually really convenient for expressing the algorithm. That’s not that much of a surprise, Perl’s `rand`, Python’s `randrange` and OS-X (and BSD’s) `arc4random_uniform` (and so on), because it’s just about the most common use case for a RNG. In other words, the designers of `random_shuffle` weren’t idiots, and the behavior it imagines for the RNG class is quite sane. There’s no reason C++11 couldn’t have made it so that the engine classes provide this interface as a bonus—they can easily pass off the task to `uniform_int_distribution` if they want. (FWIW, my PCG generation classes do exactly this. It costs almost nothing to add the convenience and it lets me bypass wicked-slow implementations of `uniform_int_distribution` that have to handle utterly brain-dead RNGs [an issue you mentioned in your video]) It might be less clean, but it’d be much more pragmatic. For many common uses, the random number generation library is both over engineered and cumbersome to use.
I have already granted your wish - my `erase_if()` proposal, [N4273](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4273.htm), was voted into the Library Fundamentals v2 TS. It works in-place, without additional allocations.
Most graphics are destined for the screen, although offscreen rendering is also possible. In today's world of framebuffers, there isn't a big difference. I should clearly work on my engine instead of browsing reddit.
&gt; Interesting thought about reducing the seed sequence requirements. That has been done in the past (with allocators) and it is a fairly non-invasive, easy thing to do, since it doesn't increase requirements on user code. I'll look into specifying it if I have time. One thing that’s not 100% clear to me from that standard is what `test_seedseq` in the code below is _required_ to output for any Seed Sequence—do the two lines it outputs _have_ to be identical. Can a Seed Sequence have a `size()` of zero? (If it can, `std::random_device` can wrapped to be Seed Sequence, otherwise it can’t.) #include &lt;random&gt; #include &lt;vector&gt; #include &lt;iostream&gt; #include &lt;cstdint&gt; #include &lt;type_traits&gt; template &lt;typename SeedSeq&gt; void show_seedseq(SeedSeq&amp;&amp; seeder) { std::vector&lt;uint32_t&gt; sequence(6); std::cout &lt;&lt; "Generated:"; seeder.generate(sequence.begin(),sequence.end()); for (auto x : sequence) { std::cout &lt;&lt; ' ' &lt;&lt; x; } std::cout &lt;&lt; std::endl; } template &lt;typename SeedSeq&gt; void test_seedseq(SeedSeq&amp;&amp; seeder) { typedef typename std::remove_reference&lt;SeedSeq&gt;::type SeedSeqType; std::vector&lt;uint32_t&gt; saved_param(seeder.size()); seeder.param(saved_param.begin()); SeedSeqType copied_seeder(saved_param.begin(), saved_param.end()); show_seedseq(seeder); show_seedseq(copied_seeder); } int main() { std::seed_seq orig_seed{1,2,3,4,5}; test_seedseq(orig_seed); return 0; } Oh, one other thing: when `shuffle` and `random_shuffle` got fixed to take a universal reference to the RNG, they should have likewise fixed the `seed_seq` arguments to the engines. There’s no reason to stop people from passing a temporary, it’s just annoying.
Nice thing about a library is that it can be discarded if it doesn't work out, but yeah, I understand. I am more worried about applying a thin coat of C++ to an existing library (which according to my vague understanding is what the Study Group is doing); I would prefer something designed from scratch.
This is an exceptionally good idea for a beginner project, as it avoids the hard yucky stuff by being almost entirely pure computation (parsing moves in algebraic format is a very simple task), and is a well-defined small problem.
Then upvote. Commenting to say "this" just adds noise.
reference is not in Java. Everything is pointer in Java, so you cannot have contiguous allocation of the data members.
Deterministic memory management!
* Something similar to RAII is in Java, it is called try with resources. * Something similar to copy ctor is in Java, it is called `clone()` method. * std::move is not needed in Java, because everything is a (shared_)pointer. * edit: Something similar to `struct` is Java's value types which comes in some future version of Java (probably Java 10). * edit: Also multiple inheritance is solved by `implements` in Java, which solves the diamond inheritance problem, everyone is inheriting from java.lang.Object.
Yeah, that whole "but were seen shaking their heads and muttering" thing makes it sound like the author is actually unaware of the fact that Ritchie is dead.
A Java reference is more like a badly designed C++ reference. They are automatically dereferenced ('.' rather than '-&gt;'), but assignable like pointers, but do not support pointer arithmetic. Worst of all, nullable.
* Pass by reference * Higher-order functions (via function pointers) * Unsigned primitive types * Access modified inheritance * Ability to put more than one class in a single file * Ability to arbitrarily name that file * EDIT: Default arguments * EDIT: Type aliasing
Well, no more than one public class that is.
A smart move is hard but perhaps a brute force where we find the first piece that can move and the first spot it can move to and just do it would be easier? 
* Faster speed * lower memory usage * predictable performance (no pause the world) * faster startup (no VM to load) * less battery consumption * pointers * access to libraries with similar design goals * not owned by a company (open and standardised).
 * More powerful generics
That's a stupid chess engine :-). You would be better off taking a *random* move - but regardless, you need to have an enumeration of moves to be able to determine how sensible a move is - a move can be very stupid, but if it's the only one you can make it's still a good move.
Aww, I had forgotten about that. Now I'm sad 😔 
Just don't get too caught up on the gui, concentrate on your engine. I'd have it output the game as ascii to start. Later you can confirm to UCI to take advantage of any existing GUI.
I agree with this, but I want to point out something. &gt; parsing moves in algebraic format is a very simple task Except that the algebraic syntax is poorly defined. It's been a while since I looked, but I recall it having some undefined/unspecified "corner cases". A beginner could, for simplicity, legitimately make some initial assumptions about the algebraic input (no implicit piece names or destinations). This would be a good experience for: 1. Encapsulated programming (make the algebraic parser a different file with a well-defined API, then it can be rewritten without impact to the engine). 2. Prototyping (make the algebraic parser "good enough", to focus on the engine) 3. Proper design
I've no doubt there are a bunch of perks working there. I even interviewed a couple years ago. Since then I've become biased against it due to everyone I've worked with who came from MS. Perhaps I'm just being unfair and associating the company too closely to the people. It's the culture I'm concerned about more than anything. Maybe it's like Amazon where the team really matters. Heh, the idea of a standard confetti party amuses me enough that I'm tempted to become an iostream expert just to witness it. We may be far enough off topic now that we should continue outside the thread. Thanks again for the direction to run in with stream complexity.
+1 for this post
&gt; pointers Almost everything is a pointer is Java. What they *dont* have are proper value semantics.
Although that's what OP wanted to ("outputs random legal move"). I think for him it'd probably be useful to leave out any chess AI until he's got the game finished. I haven't really thought about it much but it seems to me a proper chess AI is going to be quite hard to program.
And the compiler would most likely optimize away all differences between the above `s[x][y]` and `s(x,y)`. My guess is there'd be no performance difference in the end.
If done correctly I don't think there would be a difference even without compiler optimization (but including inlining). The first [] would increment the pointer, the second [] would increment the pointer and deference it. Doing this for more than two dimensions would require returning a temporary object that also has operator[] overloaded and I think that case becomes unnecessarily complicated.
auto
- Reified generics. - Template variables 
Please fix the following move iterator issue nobody seems to care about, or at least take a look at it: &gt; https://groups.google.com/a/isocpp.org/d/msg/std-discussion/V-Fu_fnPzXc/h1EXajRWj9QJ What is your opinion on it?
It seems really unnecessary to me when operator() can do the job. When you start creating intermediary temporary objects within templates you get into the territory of vector&lt;float&gt;::const_iterator and things like that. So not only do you have this extra complex implementation which to me doesn't seem like it actually helps syntactically, but when you throw in templates, const, and possibly other things like iterators, it can really become tricky for something that should be simple and straightforward. 
Move iterators are super squirrelly and it was premature to standardize them. There should probably be a Library Issue about this, although I don't know how far it should extend.
A lot of what you put down isn't terrifically beneficial. Operator overloading is a bit gnarly. Friend violates encapsulation and multiple inheritance is not winning any medals on code readability either! 
That's [`std::find_if_not`](http://en.cppreference.com/w/cpp/algorithm/find). Also, there's no need for a `std::pair&lt;bool, Iterator&gt;` or a `std::optional&lt;Iterator&gt;` return type as returning end iterators is just an easier and more efficient way to indicate that no element was found.
One slight inaccuracy: &gt; Simultaneously, it _always_ loads the current value of shared back into expected The spec states that the update of `expected` only occurs when the exchange fails. See [here](http://stackoverflow.com/a/21946549/365496) for details.
Effective Modern c++
I guess I've already did that.
&gt; searching for a sequence within a range: something like find(begin,end,seqBegin,seqEnd) kind of like [this](https://github.com/matthewaveryusa/utils/blob/master/util_bytes.hpp#L241) Unless I'm mistaken, that's [`std::search`](http://en.cppreference.com/w/cpp/algorithm/search).
Don't know about "best", but here are some: CppCon 2014: Leor Zolman " An Overview of C++11/14, Part I" https://www.youtube.com/watch?v=Gycxew-hztI CppCon 2014: Leor Zolman "An Overview of C++11/14, Part II" https://www.youtube.com/watch?v=pBI0tS2yfjw (Slides in the description) C++11 Talk Slides by Alex Sinyakov: https://dl.dropboxusercontent.com/u/13100941/C%2B%2B11.pdf Article by Herb Sutter: http://herbsutter.com/elements-of-modern-c-style/ Most importantly: Stroustrups C++11 FAQ http://www.stroustrup.com/C++11FAQ.html
Thanks for the catch! That was my (unwise) attempt to simplify the explanation as much as possible. I always pass a local variable to `expected`, so I tricked myself into believing it was true. Didn't realize that some people were passing shared variables instead. I'll improve this part of the post.
For me it's going to be http://en.cppreference.com/w/Main_Page
Yes... I wish my school taught more practical programming related stuff
The current design is sophisticated and in many ways elegant, but if you look at code that actually wants random numbers, it’s frequently clumsy. Assuming you mean [N4316](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4316.html) as implemented [here](https://github.com/lichray/randint/blob/master/random.h), it’s really quite far from being free from drawbacks. To better explore that space, I just posted [here](http://www.reddit.com/r/cpp/comments/31857s/random_number_generation_it_might_be_harder_than/).
I agree about the criteria - implementers should be strongly discouraged from choosing low quality. (For all of mt19937's deficiencies, I think that non-MT choices for default_random_engine are terrible.)
also allows threading
What are modules really going to offer us?
From the [documentation](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4047.pdf): &gt; 1. componentization; &gt; 2. isolation from macros; &gt; 3. scalable build; &gt; 4. support for modern semantics-aware developer tools. 3 is vital for me (ever worked on a project that is so big that compiling takes 20 minutes) 4 is nice to have
20 minutes is a small project :p Will have to see how modules provide that improvement. Would be very nice.
There is: std::move(inBegin, inEnd, outBegin) Which you could call as std::move(inBegin, inBegin + n, outBegin) http://en.cppreference.com/w/cpp/algorithm/move
This would be nice to have I have seen code working around it.
no, multiprocessing the reading would not really be faster because you would need to lock the access to the file and IO are likely to be the bottleneck. EDIT: Seeking, except on ssd, are slow. Reading a file is an operation that is still quite fast (sequential reading/writing) event though it has some initial latencies. Also, a seek operation do not work with line, but with offset and except if you have fixed-length line, it is no use. If the reading is actually what takes time compared to the processing, you may improve performances by using the cstdlib and its `FILE`, `fread` (but then you lookup for the `\n` yourself,) as iostream in C++ are quite slow. IIRC, if you reuse the same string (i.e. you don't create new one when you loop), it should not reallocate memory except if the new string is bigger. If the processing is the slow part, just push the string onto a shared queue that is polled by several thread. Finally, if you do are anal: `mmap` and `madvise` are your friends.
&gt; Higher-order functions (via function pointers) With Java 8 you can write HOFs
Sounds like a good starting plan, thank you for your input
Looks like [File Mapping](https://msdn.microsoft.com/en-us/library/windows/desktop/aa366556%28v=vs.85%29.aspx) or [mmap](http://man7.org/linux/man-pages/man2/mmap.2.html) could be used in this case. This library is supposed to be portable [Portable Memory Mapping C++ Class](http://create.stephan-brumme.com/portable-memory-mapping/). And here is also proposal for something like this [Memory Mapped Files And Shared Memory For C++](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2044.html)
Thank you! Yes I'm new to programming but I seem to have the "mind" for it and the proper way of 5 hiking and within the past two months I've continuously thought of codes to make (prime number finder, perfect number finder, polynomial integrator, and my most recent project was tic tac toe. I had the chess idea the whole time I was just afraid it was out of my skill range but all of the help in this thread has made me feel more confident 
I'm a 2000 Elo rated chess player but that has no factor because I just want it to make random "legal" moves. I'm fairly new to coding and just making a program that can make legal moves in response to moves is still chalenging for me
Faster build also implies better tooling / IDE integration (as far as symbols indexation &amp; completion go)
I'm a noob at both languages, so please don't mind me asking: what's the difference between a C++ const and a Java final?
Will you also check if the human player does legal moves?
Error handling in Rust has evolved a bit from an optional return value, as your link shows. Now an algebraic data type (ADT) that has two possible values is used, kind of like a union. The equivalent in C++ syntax is template &lt;typename T, typename E&gt; std::result&lt;T, E&gt; This is useful in Rust as the language lacks exceptions, so E is often used to return errors. Keep in mind you cannot ignore the error implicitly, as you need to unpack the std::result into a variable of either type E or T, and there is syntactic sugar to help with this. What you mentioned, an ADT containing either a value of a given type or nothing, is called std::optional. This is better than using null as you have to explicitly account for the empty case.
Would the optional version be optimized to run like the bool version if the iterator isn't used?
Is it possible for a CAS loop to deadlock? (E.g. if another thread runs a tight loop that continuously modifies the variable).
It'll be slower, but at least it's much clearer, which is something C++ lacks in many places. The point would be that if it's slow, it's your fault and you can always make it faster.
I just watched your [talk](https://www.youtube.com/watch?v=45Oet5qjlms) and it was definitely interesting. A few things: * The website could really do with a short explanation and pseudo-code of the actual algorithms, in order to demonstrate that the core-ideas behind it have been known for a while and are more than just “random internet-person came up with it under the shower/by divine inspiration and claims that the algorithm is better then everything else”. Basically what the video does in the end. * As an academic you certainly understand, that I don't mean to insult you, when I ask for further independent expert-opinions. Do you know of anything in that direction? * Why does your (?) C++-implementation put stuff into the global namespace? :-( * Are there any chances that you will propose them as additions to the standard?
&gt; Better iterators categories: &gt; I) separate access and traversal (a transformed view of a random access range needs to be random access) I don't believe that access and traversal need to be separate in order to achieve this. See the series of block posts starting [here](http://ericniebler.com/2015/01/28/to-be-or-not-to-be-an-iterator/).
How will closed source libraries be distributed with modules? 
[This](http://clang.llvm.org/docs/Modules.html) page from the Clang docs has a lot of concise info about them.
&gt; Actually, there are good reasons. In addition to speed concerns, you have space concerns, and as I mentioned to Stephan, the Mersenne Twister is 2.5 KB, which is massively larger than necessary for a good RNG. As I wrote, size shouldn't be too much of a problem if we are talking about one RNG per thread. At least not on “normal” computers (low-end or embedded devices are of course another story, but in that case using a certain one explicitly is certainly bearable). It is of course better to have a smaller one if it provides at least the same quality, but I don't think that the C++-standard currently provides that (correct me if I'm wrong here). &gt; And since most implementations of uniform_int_distribution are slow anyway, it’s not clear to me that speed is a major concern for the developers of the libraries. I would be very carefull with that assertion. Stephan can *certainly* tell you more about it, but when I look at the implementation in libstdc++ it don't actually see much room for improvement, without changing the API.
This `range` type mixes some stuff up. Iterators can be advanced. Ranges in general can't. But it's possible to offer a `range_facade` helper that turns a type like above into a real range type with iterators. I've got one in [range-v3](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/range_facade.hpp).
Is the point of a non-mutating shuffle or sort view to avoid the cost of copying the container and then swapping elements in place? I don't see a way to do either without at least allocating a vector of iterators and shuffling/sorting them (with an indirect comparator), which doesn't seem like a huge win to me.
&gt; I just watched your [talk](https://www.youtube.com/watch?v=45Oet5qjlms) and it was definitely interesting. Thanks! &gt; The website could really do with a short explanation and pseudo-code of the actual algorithms, in order to demonstrate that the core-ideas behind it have been known for a while and are more than just “random internet-person came up with it under the shower/by divine inspiration and claims that the algorithm is better then everything else”. Basically what the video does in the end. *As an academic you certainly understand, that I don't mean to insult you, when I ask for further independent expert-opinions. Do you know of anything in that direction? Well, there is an a minimal implementation of pcg32 [here](http://www.pcg-random.org/download.html). One problem with showing the code is that some people see it and think anything *that* simple can’t be that good. As for the just “random internet-person came up with it under the shower/by divine inspiration and claims that the algorithm is better than everything else”, there are a few responses. First, there are RNG test suites, the best (IMHO) being [TestU01](http://www.iro.umontreal.ca/~simardr/testu01/tu01.html). In the RNG community (to the extent that such a thing exists), it seems to be seen as the gold standard. But there is also [DieHarder](http://www.phy.duke.edu/~rgb/General/dieharder.php) too if you want a second opinion (Robert G. Brown, DieHarder’s main contributor, says that in comparison to Pierre L’Ecuyer, author of TestU01, “[I'm a ruddy amateur.](https://lists.phy.duke.edu/pipermail/dieharder-devel/2011-May/000037.html)”). PCG does really well in statistical tests (in fact, in the paper I show that we shouldn’t expect anything to do much better than the best PCG generators), and that’s something that’s independently verifiable. If you like other endorsements, I had several of my colleagues read the paper. Geoff Kuenning (author of the venerable `ispell`) who maintained [a very fast implementation of the Mersenne Twister](http://fmg-www.cs.ucla.edu/geoff/mtwist.html) changed the top of his webpage to say “Use PCG instead”. [Nick Pippenger](http://en.wikipedia.org/wiki/Nick_Pippenger) who I revere quite highly read an early draft of the paper and said “I’m very impressed”. And various people have tweeted about it, e.g, game developer [Tom Forsyth](https://twitter.com/tom_forsyth/status/536030079944384513). I probably wouldn’t have been invited to Stanford to give a talk about it (resulting in the video you watched) if someone hand’t thought it was cool/interesting. And lastly, the PCG paper will hopefully eventually appear in a peer-reviewed journal at some point. Alas, the journal process is not a fast one so we’re all still waiting on that. So, basically there are already people that like it and all my claims are entirely testable. &gt; Why does your (?) C++-implementation put stuff into the global namespace? :-( Because it’s a stand-alone library that does one thing. You wouldn’t include it unless you wanted it, and saying `pcg::pcg32` seemed redundant. My apologies if it was a poor choice. Most of the implementation is tucked away in namespaces though, and it wouldn’t be hard to adjust it to avoid namespace pollution (e.g., polluting or non-polluting depending on which `#include` you use). &gt; Are there any chances that you will propose them as additions to the standard? I’d be happy to. I suspect that people wouldn’t want my full implementation, because it sings, dances, and makes the tea. It’s intended to allow people to explore the PCG family and add new members if they want. So, understanding that I’m an academic, I’m actually on sabbatical right now (otherwise I’d never had had time to throw together website, etc.), so I *can* do stuff, and I’m very familiar with C++ (I teach it and am generally interested), but haven’t written a C++ proposal before, how would you recommend I proceed? I’m happy to have collaborators. BTW, my code is currently apache licensed (so people can be sure I won’t patent anything), but it’s about to switch to MIT (because that’s what people seem to prefer), so it should be eminently takable.
Does this mean I don't need to have *private* members out in the open where everyone can see them?
A CAS loop can be used to implement a spinlock, and two spinlocks can deadlock. I'm not sure if that answers your question?
I wish that was "using module std::io" so it matches "using namespace std".
No, modules won't change anything about the C++ ABI. Private members will still be visible.
&gt; the real question/discussion is how awkward this is to simple tasks well in C++14 today I couldn't agree more. I've been using mostly only raw STL for almost a decade, and I've only recently started to create my own library that uses STL behind the scenes. The result is code that is _so_ much simpler and clearer, both to write and read. I think the reality is that STL will probably never be a library that one should use directly, but as the backbones of wrappers/helpers.
&gt; One problem with showing the code is that some people see it and think anything that simple can’t be that good. I certainly see your point. &gt; As for the just “random internet-person came up with it under the shower/by divine inspiration and claims that the algorithm is better than everything else”, there are a few responses. I may have written that in a slightly confusing way: This was just a comment on the presentation on the website, the talk convinced me that it definitely isn't that bad. Concerning the “probably not too insane, but even very clever people can make honest mistakes”-part, the quotes you mentioned, definitely reduced that fear too. &gt; Because it’s a stand-alone library that does one thing. You wouldn’t include it unless you wanted it, and saying pcg::pcg32 seemed redundant. Thanks to C++'s terrible include-system I wouldn't be so sure about it. Furthermore there might be name-clashes if some other library decides for some reason to provide these. (Think of the case where this would become `std::pcg32`: Way to many people use `using namespace std`.) &gt; So, understanding that I’m an academic, I’m actually on sabbatical right now (otherwise I’d never had had time to throw together website, etc.), so I can do stuff, and I’m very familiar with C++ (I teach it and am generally interested), but haven’t written a C++ proposal before, how would you recommend I proceed? I am the wrong person to ask here, I'm just a CS-student who picked following the development of C++ over having a life. However, the committee provides an explanation how to submit something [here](https://isocpp.org/std/submit-a-proposal). 
for the standard library: std::result&lt;Success, Error&gt; ( https://doc.rust-lang.org/std/result/ ) with a method for chaining multiple results together ( http://hackage.haskell.org/package/base-4.8.0.0/docs/Prelude.html#v:fmap ) for the language: enums which are tagged unions ( http://rustbyexample.com/enum.html )
(It’d be great if you emailed me so that I can attribute your feedback if/when appropriate. If I’ve missed papers and terminology from the crypto area, you can certainly help fix that. FWIW, regarding Salmon et al which you explicitly mention, although I missed citing it in the PCG paper when I wrote it last year, I’ve since read it and tested those RNGs too.) About ChaCha20, in the table on the website, I was talking about the OpenBSD implementation, which is the only implementation of ChaCha20 as a PRNG that anyone is likely to have used. In the [main comparison section](http://www.pcg-random.org/other-rngs.html) of the website it’s clearer about making a distinction between the OpenBSD PRNG and the usual ChaCha20 code. As for security claims, I make it fairly clear on the [predictability](http://www.pcg-random.org/predictability.html) page of the website exactly what I’m talking about and not. I am absolutely not recommending it as a stream cipher for cryptography (given how new it is that’d be absurd!), but I am saying that even general purpose RNGs should have an eye to not being predictable. The only way to actually test unpredictability is to have a challenge, ideally with a prize. I’m working on setting that up. When the contest is announced, I hope you’ll give it a try. If it’s as predictable as you seem to think, collecting ought to be easy! If you have advice on that aspect, I’d also be delighted to hear from you—I hardly want anyone claiming I rigged it! As for [my speed claims](http://www.pcg-random.org/rng-performance.html), I’m not sure how you get the notion that there isn’t much difference between the Mersenne Twister and PCG (or other fast RNGs), the graphs make it clear that it’s more than twice as fast. It is true if you want to have 64-bit state, the easiest approach is 64-bit multiplication (although there are other ways of doing things that are fast). The paper briefly mentions 32-bit tests, and PCG does still do well in that domain, although things are certainly closer for the standard PCG generators. I think 64-bit is the future though, which is why I don’t focus much on 32-bit. Even for ARM, 64-bit is either here now or on the horizon. My phone (which is old enough that it’s now out of contract) is 64 bit; if yours isn’t, it will be in a year or two. (Also, in the embedded space, the state-size of the RNG starts to matter too, and the relatively huge size of the Mersenne Twister becomes more of an issue.) FWIW, here are speed results for ChaCha, using a nice parameterized version that Orson Peters wrote as part of a conversation we had about ChaCha 20, where you can choose the number of rounds: ChaCha&lt;8&gt; results (GCC 4.8, Clang 3.4): With SSE - Clang: 9.46 Gb/s, 3.15 ns/32bit (but only 8.94 Gb/s with Clang 3.6) - GCC: 8.13 Gb/s, 3.66 ns/32bit Without SSE: - Clang: 8.70 Gb/s, 3.43 ns/32bit (but only 5.80 Gb/s with Clang 3.6) - GCC: 5.61 Gb/s, 5.31 ns/32bit ChaCha&lt;20&gt; gets 4.62 Gb/s with Clang and SSE and 4.06 Gb/s without, GCC timings are worse (3.37 Gb/s for the non-SSE version, although Clang 3.6 regresses to 2.66 Gb/s). In contrast, arc4_random's result is - Clang: 1.59 Gb/s, 18.79 ns/32bit - GCC: 2.90 Gb/s, 10.29 ns/32bit That’s still dramatically slower than most noncrypographic RNGs (the test setup and machine are the same as the one used for [my other performance results](http://www.pcg-random.org/rng-performance.html)). Also, [Tyche-i](https://eden.dei.uc.pt/~sneves/pubs/2011-snfa2.pdf) performs better than ChaCha, but still isn't as fast as PCG. It clocks in at 26.74 Gb/s with GCC (22.05 Gb/s with Clang). Also, [Random 123](http://www.deshawresearch.com/resources_random123.html)’s `Philox2x64` variant is pretty quick (for a PRNG using cryptographic hashes), easily beating ChaCha/8, but not Tyche. If I were writing a proposal for additional RNGs to add to the standard, I’d almost certainly include ChaCha20. Thanks to someone else who liked ChaCha20, I now have a fairly nice C++11 implementation of it (and I have arc4random too), and some other relatively new/good ones as well, such as [SplitMix](http://dl.acm.org/citation.cfm?id=2660195); which is the fastest statistically good recently published RNG I've found (although it is beaten by some PCG family members), but is trivial to predict. I’d be _delighted_ to see any modern RNG added to the standard, and if PCG were merely seen as a minimum standard to equal/beat, that’s fine. If people want to say they have something better, that’s awesome. Maybe we can argue about relative strengths and weaknesses. But the RNGs we have now in C++11 are all worse. Edit: Add performance for ChaCha, mention Tyche, Philox2x64.
That may be within an optimizer's power, if everything is fully inlined (it would see the equivalent of a pointer being returned and unused, and optimizers are good at dead code elimination).
Makes sense.
What I meant was, MT is the least worst in the Standard. As an implementer, if it's not in the Standard it basically doesn't exist to me :-&gt;
Not sure what you're trying to get at. The whole point is to demonstrate that Java only has value semantics &amp; what reference semantics means (value semantics means foo doesn't alter t whereas reference semantics means that t is altered). Yes it leaks memory, but that's for clarity. Also, you're assuming that setX has no side-effects which might not be true. What if setX also logged to stdout? What if the constructor did things? Then all 3 code snippets technically do something.
What I am saying is in both 1st and 2nd code snippets you take a pointer to SomeClass as an argument and immediately discard that, using that pointer for pointing to a new object you create in your function. You don't change anything on the object your argument points to.
[This company](http://www.azulsystems.com/zing/pgc) seems to claim that their GC makes no pauses. In any case, Java does get used for real-time computing, where predictability is important. I guess what I'm trying to say is that in order to talk about performance it's not enough to analyse the language itself. 
I don't know anything about that particular implementation. Sun/Oracle did/does have some kind of real-time Java implementation, but it's definitely not free - last time our company looked into it, you needed to sign an NDA to even find out how much it costs, which likely indicates it's big bucks. The pauseless implementations likely also have some significant downsides in terms of throughput performance as well.
I’ll take your points about the table on the front page of the website under consideration. I’d like to represent all the RNGs I mention fairly. &gt; I'm not sure I understand the distinction you are making between predictability and trivial predictability. In what situation would I find acceptable to use a generator that is predictable, but simply not trivially? Well, how about you head to crypto.stackexchange.com and contribute an answer to [this question](http://crypto.stackexchange.com/questions/20495/how-brittle-are-lcg-cracking-techniques). It’s about something much simpler than PCG, a mere truncated LCG with a minimal permutation tacked on. If you think there are no degrees of predictability, it either is or isn't, you’ll have no problem predicting the all the generators shown there. &gt; I see no reason to use insecure generators without a very good justification Excellent, I’m glad you agree with me on that. We even agree that *some* PCG family members are “secure enough”, because a counter is a degenerate LCG and cryptographic hashes are permutations, thus ChaCha and Random 123 can actually be seen as (distant) PCG family members. Hopefully, at some point it’ll be clearer just how unpredictable the PCG family members from the paper are. I have my opinions on the matter, but I’m sure someone would love to show me how wrong I am. Again, anyone who wants to do that can start [here](http://crypto.stackexchange.com/questions/20495/how-brittle-are-lcg-cracking-techniques). &gt; Speaking of which, it would probably make more sense to talk about CPU cycles than nanoseconds in benchmarks, at this level (I was actually looking at the paper's Table 1, not the website). Cycle counts are both more informative and easier to verify than nanoseconds, in my view at least. I can measure cycles too, but there are lots of variables and whatever you do, it’s always an incomplete picture. Cycles vary based on compiler and CPU (Broadwell differs from Haswell differs from Sandy Bridge), and ARM is quite different (ARM has single-cycle integer multiply-add which is great for LCGs), and PowerPC is different again. Trying to do the diligent thing (I’ve tested on all these), is a challenge and you end up with volumes of data to tell essentially the same story. I do try to downplay the issue of whether a cycle matters here or there, but in algorithms that make heavy use of RNGs, it really can make a quite noticeable difference. Likewise, code size makes a difference, especially in C++ where inlining is an option. &gt; For what it's worth, I am also not at all a fan of the C++11 random API and algorithm choices. PCG is an improvement over the many crappy generators littering programming languages. Thanks. &gt; EDIT: Those Chacha8 timings seem suboptimal. Chacha8 should be close to 0.5 cycles per byte on Haswell, and should be ~1.5 cycles per byte even without fancy AVX2 instructions. This amortizes to somewhere between 2-8 cycles per 32-bit word, which is pretty OK for a 256-bit cipher. You can go lower than that, say Chacha4, and double the speed at the cost of cryptographic security. Well, [here’s the implementation I used](https://gist.github.com/orlp/32f5d1b631ab092608b1), written by Orson Peters. If there’s something radically wrong with it, do let me know, but its performance also matches the performance I saw with the OpenBSD implementation which is based on the original ChaCha20 source. I suspect that the differing performance numbers may relate to differences between being used as a PRNG and being used to produce large blocks for a stream cipher, but that’s just a guess. FWIW, ChaCha/2 fails TestU01’s statistical tests _really really_ badly. ChaCha/4 seems like it may be okay but even if it’s twice as fast as ChaCha/8, it won’t outperform today’s fast general-purpose RNGs. 
I’d love to see your code (I run Linux and OS X, so don’t have MSVC++), and would be happy to add numbers for it to the above table. Also, are your corner cases documented somewhere? &gt; In my implementation, the distribution is stateless, which is actually a performance sin - it would be better to store unused bits in the distribution so as to invoke the engine less. No, you’re doing the right thing. Good RNGs have large periods and are very very cheap to call, there is absolutely no need to call the engine less — the extra complexity will probably make for _slower_ code. Also, with a simple stateless implementation, it is very straightforward to argue that the implementation doesn’t damage the uniformity of the generator, but a more complex design might require a more complex argument (maybe there’s still and easy argument, but I’d have to think about it). P.S. _Please_ do the exercise that this post invited readers to do (or explain why you won’t). If you won’t have a go, who will?
Actually, as far as I recall, `default_random_engine` is entirely up to the implementation, so you do have latitude there; if you want to implement something else, you can. But obviously a `typedef` is way less work. Also, you may be an implementer, but you’re also involved in the C++17 standard, and you are even one of the contributors to the `randint` proposal, so you have much more control than most people.
You mean livelock? If so, yes, although it will eventually resolve since your OS probably won't perfectly schedule two threads to always align like this.
&gt; I’d love to see your code (I run Linux and OS X, so don’t have MSVC++) Since I wrote it at work, I can't paste it here, even though anyone could install 2013 Community Edition in a VM and look at &lt;random&gt;. &gt; Also, are your corner cases documented somewhere? Only in the E-mail that I sent to Dinkumware when I checked it in. Working from memory: * Signed outputs are obnoxious - for example, the distance between -2^63 + 10 and 2^63 - 10 can't be represented in int64_t. So I translate the user's requested range to unsigned, do all my work in unsigned, then translate back at the very end. * Non-Power-Of-Two engine treachery needs to be dealt with (frustratingly, some Standard engines are NPOT). Anything that isn't a clean number of bits needs to be discarded. * The engine has to be run enough times to accumulate as many bits as we need for the output; more math to figure out how many bits we're getting from the engine and how many we need for the requested range. (No floating point logarithms!) * Once we have enough bits, see if we can generate the output without bias. If it's at the upper (biased) end of the range, discard and try again. More math to calculate exactly where the cutoff is. Even in my maximum paranoia mode, I still managed to mess up - I wrote a full shift (e.g. shifting 32 bits out of a uint32_t) which isn't portable. Worked on x86 but ARM dealt the punishment I deserved. I also worked out the worst-case numbers for discards (assuming a maximally treacherous input range and output range) and it isn't that bad - something like 4x. Most of the time (POT engine, lots of input bits, few output bits) discards never happen. &gt; Good RNGs have large periods and are very very cheap to call, there is absolutely no need to call the engine less — the extra complexity will probably make for slower code. Hmm, that's good to know then. &gt; but a more complex design might require a more complex argument Well, as long as an implementation doesn't try to stash away fractional bits of randomness, the argument carries over. &gt; P.S. Please do the exercise that this post invited readers to do (or explain why you won’t). I write code at work all day! When I get home I just want to waste time on Reddit. :-&gt; What I would do is use a mt19937, uniform_int_distribution, thread_local, seeded with random_device (filling the whole state; I've worked out how to do it before, it is obnoxious, but not as obnoxious as doing anything with iostreams).
I'd suggest to compile your program as 64-bit (free 15% speed boost over 32-bit builds) and use memory mapped IO. I am programming for Windows, so I cannot tell anything about unix api. But on Windows: 0. Use asynchronous i/o or couple of threads - this way, while next chunk of data is coming from the disk, you are processing the previous one 1. File systems work using clusters. If you request operations not aligned on clusters, they need to read 1 or 2 more clusters to satisfy the request. Always read on cluster boundaries. See [here](https://msdn.microsoft.com/en-us/library/aa365256(v=vs.85).aspx) 2. Data is transferred using DMA. Always consume page-aligned memory. On recent Intel processors, you can request large memory pages using VirtualAlloc with MEM_LARGE_PAGES. Always read data aligned on memory page size. 3. Virtual memory manager on Windows is smart, but on desktop editions of Windows is tuned for particular workloads (which makes it smart) and reading large files is outside its tunning. It can remove pages from your working set and you'll need to wait for them to be paged in again. Require elevated privileges in your exe manifest, and use SetProcessWorkingSetSize to guarantee yourself exclusivity over physical RAM. 4. Tell your intent to the file system, the memory system and the i/o manager - when (opening)[https://msdn.microsoft.com/en-us/library/windows/desktop/aa363858(v=vs.85).aspx] the file, use FILE_FLAG_SEQUENTIAL_SCAN. Never use FILE_FLAG_NO_BUFFERING. 5. Pro tip - remove antivirus program - everyone I tried is programmed extremely sloppy and kills the I/O. 6. As I said, 64-bit code is typically ~10-15% faster than 32-bit for i/o bound operations. As for parsing, stop using anything from std and do it manually - this would speed your program order of magnitudes . I do not remember exact numbers, but I think it was 30 **times**. By the way, using mmap-ed i/o would automatically do most of the work for you. Really, just use it - it is both faster and easier to use. Hope this helps! Source: Couple of years ago I was tasked with reading 160 GB of text files fast :) 
That doesn't really work as a generic solution and is an imperfect replacement at best.
Of course. That's exactly the difference between value semantics &amp; reference semantics that I'm illustrating.
great one, I agree, doing board games is incredibly fun jm2c: it depends on your level, but chess is pretty complex in the end (castling, en passant, pinned pieces, promotions). **Go on and try**, but if you feel it's not going well don't spend too much time feeling bad, consider doing http://en.wikipedia.org/wiki/Draughts (and sokoban! sokoban rocks!) before/also
I would like to be able to write: for (auto&amp; word : dictionary) if (contains(dictionary, reversed(word))) print("%\n", word); Which requires: * type-safe formatted printing * `std::contains` * `std::reversed` I mean sure you could write this: for (auto word : dictionary) { reverse(begin(word), end(word)); if (find(begin(dictionary), end(dictionary), word) != end(dictionary)) cout &lt;&lt; word &lt;&lt; endl; } `shuffled` and `sorted` were poor examples. `reversed` seems reasonably easily implementable.
If I use the utility-libs, that I have on my system, the code becomes very close to the python-version: #include &lt;boost/range/irange.hpp&gt; #include &lt;utilities/random.hpp&gt; #include &lt;yoga/yoga.hpp&gt; int main() { for(auto i: boost::irange(2u, 27u)) { yoga::writefln("[0,%s):\t%s", i, util::rand_int(0u, i-1)); } } Otherwise (naked stdlib): #include &lt;iostream&gt; #include &lt;random&gt; int main() { auto gen = std::mt19937{std::random_device{}()}; for(auto i = 2u; i &lt; 27u; ++i) { auto dist = std::uniform_int_distribution&lt;unsigned&gt;{0, i-1}; std::cout &lt;&lt; "[0," &lt;&lt; i &lt;&lt; "):\t" &lt;&lt; dist(gen) &lt;&lt; '\n'; } } The second I needed another uniform int distribution I would however reimplement `rand_int`. 
No-one else has, so I'll give it a go. This is written on potato on a bus with minimal reference to documentation and no testing. #include &lt;random&gt; #include &lt;iostream&gt; int main() { std::random_device rd; std::default_random_engine r{rd()}; std::uniform_int_distribution&lt;&gt; d; for (int i = 2; i != 17; ++i) std::cout &lt;&lt; "[0," &lt;&lt; i &lt;&lt; "):\t" &lt;&lt; d(r, std::uniform_int_distribution&lt;&gt;::param_type{0, i - 1}) &lt;&lt; std::endl; } I think this is the most obvious implementation. Edited to add formatting and make range half-open (I missed that in the specification). Now, what's wrong with it?
dang, even if you just change a .cpp file, not a header? my link phase is slow, but nowhere near 20minutes.
Yeah, that was indeed a bug. In that specific case however the ternary is never needed, since i is always larger than 0.
std::process for creation controlling and communication with child processes
no offense. I like the filler, it help me learn more about c++11
I watched your talk and really enjoyed it. Going to read the paper itself if I find the time. Looks like you put a huge amount into the presentation itself, which is nice considering how many mediocre presentations are around. So I took your challenge. Judging from your and STL's comments I assumed that the most straight forward and also most cited description on how to intialise mt is wrong. Otherwise why should there be a challenge? Ok, maybe I have to check if the post is from April 1st. ;) So this is what I came up with: #include &lt;iostream&gt; #include &lt;random&gt; #include &lt;utility&gt; namespace detail { template&lt;std::size_t... Indices&gt; std::seed_seq generate_seed_impl(std::index_sequence&lt;Indices...&gt;) { std::random_device rd; return std::seed_seq{((void)Indices, rd())...}; } template&lt;std::size_t N, typename Indices = std::make_index_sequence&lt;N&gt;&gt; std::seed_seq generate_seed() { return generate_seed_impl(Indices()); } thread_local std::seed_seq mt19937_seed = generate_seed&lt;std::mt19937::state_size&gt;(); thread_local std::mt19937 rand_gen(mt19937_seed); } template&lt;typename Integer&gt; Integer randint(Integer from, Integer to_inclusive) { return std::uniform_int_distribution&lt;&gt;(from, to_inclusive)(detail::rand_gen); } int main() { for (unsigned i = 2; i &lt;= 16; ++i) std::cout &lt;&lt; "[0," &lt;&lt; i &lt;&lt; "):\t" &lt;&lt; randint(0u, i-1) &lt;&lt; std::endl; } Before this thread I would never have thought of doing it that way, so I really hope that this solution is too complicated.
Yup. On GCC or Clang, build with -ftime-report. It should give you a decent breakdown, including template instantiation time. Also try grabbing the preprocessed source and look at what the big contributors are. It's tricky to account for [1], mostly due to include-once optimizations, but it can be very eye-opening to see how the expensive edges get in. In my experience, there is rarely a single #include edge that dominates. Rather, it's the pattern of #including too much in too many headers. Fixing it is nigh-impossible. I've tried out some of Clang's C++ modular support on one particularly large build, and I've been mightily impressed at what I've seen so far. Edit: [1] You'll probably need to write a script. :-/
Depends. From [Clang](http://clang.llvm.org/docs/Modules.html): &gt; Each module is parsed as a standalone entity, so it has a consistent preprocessor environment. This completely eliminates the need for __underscored names and similarly defensive tricks. But: &gt; Headers (particularly C++ headers) expose the full complexity of the language. Maintaining a stable binary module format across architectures, compiler versions, and compiler vendors is technically infeasible. So yes and no. It depends on what you're "hiding" and why. If you're talking about private class members, then no, nothing changes. If you're talking about the morass of preprocessor tokens and include-order dependencies, then yes, those "private" details get privater.
To be honest, it's kind of hard to teach this kind of thing in just a few weeks, unless it can be assumed the student is doing the coding full time. It can be taught, but it doesn't really "click" until you're really going through the development steps a few times on the same project. Having to revisit and refactor the same code a couple of times teaches you to think ahead a little, code for flexibility, allow for abandoning/reverting an idea, and such. Until you've experienced it, it's merely "academic advice". Still good advice that should be taught, but hard to teach and make real. 
One minor issue is that you’re using `default_random_engine`, which in some systems may be a LCG with a tiny 32-bit state. If so, you’ll have an RNG with a tiny period. That’s why [Stephan recommends](/r/cpp/comments/31857s/random_number_generation_it_might_be_harder_than/cpz7coh) that you explicitly use the Mersenne Twister. Of course, it might be something better, with more state. But what’s really wrong with it is that you use a _single_ 32-bit integer to seed the RNG. If you’re using the Mersenne Twister, you’re using four bytes of state to try to seed 624 bytes. It’ll work, but it’s way worse than what the Python code does; Python uses 624 bytes of actual entropy rather than four bytes. 
- N4165 Unified Call Syntax, N4174 Call syntax: x.f(y) vs. f(x,y) - and support in ranges - Monadic await - with support for optional, expected, etc.
&gt; I assumed that the most straight forward and also most cited description on how to intialise mt is wrong You could give a link to such a description, just to make sure. As for your code, it’s a good effort. Of course, variable templates are a C++14 feature, so people using C++11 are out of luck. Although your code compiles with GCC, unfortunately, GCC isn’t respecting the standard. Clang [refuses to compile it](http://pastebin.com/NSwJB7Nu). The big problem is that you’re invoking the copy constructor for a seed sequence, and that’s forbidden. That happens here (you’re making an explicit temporary which must then be copied): return std::seed_seq{((void)Indices, rd())...}; and here: thread_local std::seed_seq mt19937_seed = generate_seed&lt;std::mt19937::state_size&gt;(); where you try to store the return value, which again requires copying it. Also, on Unix you’ll be opening and closing `/dev/random` 624 times.
Ok, some things I'd like to see: 1. std::iterator_facade. Implementing iterators without it is a PAIN 2. Ranges 3. Chainable algorithms, like ones in Boost.Range - sum(odd(container)) vs container | odd | sum 4. Many types (like optional, error_or, variant) should be range-compatible - for chaining 5. std streams should die and be buried 6. Not a full suggestion, but we possibly need some kind of buffered iostream ranges and transformers, similar to boost iostreams filters, but without their tediousness to implement 7. string_ref, array_ref 8. Some tools to facilitate raw buffers. In particular, capture existing buffers into container-like wrappers. 9. variant. Though I don't like boost version due to heap usage. This can be possibly circumvented by enforcing 'movable' over contained type. Also would be nice to have in-place match, at least over set of contained types. Here come some wishes for core 1. Stackless coroutines (AKA resumables), range-compatible 2. Concepts 3. Modules 4. Way to specify functor argument signature. Don't tell me about std::function, it's for different purpose. 5. UFCS or at least some kind of extension methods Thanks for attention.
dynamic memory allocation *and* another level of indirection? No thanks.
the site is down?
Have you seen otlv4.h file from OTL, one of the best C++ library for working with DBMS? It is more than 30K lines. Or lexical_cast.hpp from Boost -- it is almost 3K lines. So 3200 lines with just 1600 lines of code it is not too much.
Okay, thanks. &gt; For any good RNG, the extra steps performed by seed_seq are pointless make-work, trying to further randomize something that is already random. For my use case it is pointless make work, but in a way I'm abusing `seed_seq`, using it for something it wasn't intended for. It's intended to implement a mapping between an arbitrary amount of seed data and the exact state size of the RNG. So if you expect that seeding with one value is not sufficient then you can seed with two, 10, or any number: std::random_device r; std::seed_seq seed{r(), r(), r(), r(), r()}; std::mt19937 eng{seed}; It's true that initializing mt19937 with just 32 or 64 or 1024 or however many bits of entropy may be wasting a lot of its capability, but I think allowing this is reasonable functionality for the standard library. &gt; Actually, there is a way to find out but you may not actually know until runtime, and again it means more work and more ugliness. I’d invite you to have a go. http://coliru.stacked-crooked.com/a/501fd0ebc38af447 struct random_device_seed_seq { std::random_device random_device; template &lt;typename InputIterator&gt; void generate(InputIterator rb, InputIterator re) { std::generate(rb, re, std::ref(random_device)); } }; int main() { random_device_seed_seq seed; std::mt19937 eng(seed); std::uniform_int_distribution&lt;&gt; dist; using param = std::uniform_int_distribution&lt;&gt;::param_type; for (int i = 2; i &lt; 17; ++i) std::printf("[0,%d):\t%d\n", i, dist(eng, param{0, i - 1})); } I'm cheating a bit by depending on the engine not really needing the full Seed Sequence requirements. I can see what you mean about the trouble with requiring the whole interface when only very little is actually used. Other than that, this honestly doesn't seem too ugly to me. It'd be nicer if C++ engines allowed their state to be initialized simply with a generator function though: std::random_device rd; // random device happens to be a generator std::mt19937 eng{rd}; // more generally std::mt19937 eng{[] { return 10; }}; // initialize state to 624 10s. Not a good idea... 
&gt; count is always slower, never faster Worst case scenario, they both take O(n) time (where the item is either the last in the container or not present at all). It would be more accurate to just say that count is never faster. Also, your post earlier where you mentioned this: &gt; N/2 times faster in average illustrates the issue with "average cases". Unless you are talking about a stochastic algorithm (such as quicksort with a random pivot) where the average time more accurately means the expected time (in a probability sense), average time is a very vague measure depending on real world use, not properties of the algorithm.
user definable value types. explicit control of copying/move behavior on user defined types (copy/move ctor, copy/move assignment) explicit control over what member functions are available on what kinds of instances (const, volatile, lvalue, rvalue) customize-able allocation behavior (replaceable new/delete, member new/delete, placement new) constexpr, constexpr types user defined literals pointers to members tons of template features or features that are only useful in generic code: e.g. template template parameters, decltype type deduction raw string literals 
&gt; So if you expect that seeding with one value is not sufficient then you can seed with two, 10, or any number: &gt; &gt; std::random_device r; &gt; std::seed_seq seed{r(), r(), r(), r(), r()}; &gt; std::mt19937 eng{seed}; Yes, this version is more-or-less acceptable, but it looks really clumsy and it's sad that Python is doing a better job. Your idea for `random_device_seed_seq` is exactly what I provide in generalized form as `seed_seq_from` in the `pcg_extras` part of the PCG library, allowing you to say: pcg32 my_engine{seed_seq_from&lt;std::random_device&gt;}; This is guaranteed to work for PCG, and _happens_ to work in practice with other RNGs wherever I've tried it, but as you observe, using it with, say, the Mersenne Twister means relying on sloppy enforcement of the conditions required by the standard; both yours and mine don't properly conform to the rules for a Seed Sequence. I'm delighted you agree that the rules are silly and should be dropped to allow our code. `boost::random` goes one better, allowing (as I recall): boost::random::mt19937 my_engine{boost::random::random_device}; but not because it works the way you suggest (i.e., allowing us to pass a callable object to RNGs), but because `boost::random::random_device` and all the boost engines provide a `generate` function so that they can pretend to be kinda-sorta Seed Sequences. &gt; Other than that, this honestly doesn't seem too ugly to me. It'd be nicer if C++ engines allowed their state to be initialized simply with a generator function though The problem is, in a lot of situations, including reading from `/dev/random`, it’s nice if you can know _in advance_ just how much seed data you need. So although it’s elegant in its way, it doesn’t obviate the need for a function like `generate`.
Sooo... what could this be used for? I have no idea what a brokered messaging queue is supposed to be.
You might find [my IO benchmark](http://adityaramesh.com/io_benchmark/) useful. It tests this kind of stuff using virtually every IO method available on Linux and OS X. I would also advise against taking advice from people on performance related matters unless (a) they're known for what they're talking about or (b) they have hard numbers to back up their claims. Preferably you want both (a) and (b). Notice that mmap (recommended by many developers, including many commenters here) is **never** the fastest method for reading from or writing to a file. It is possible to use two threads to implement a double-buffering scheme: while one thread waits for chunk n + 1 to get read, the other processes chunk n. This helps, even if you're doing a trivial operation like counting the number of occurrences of a byte. These results aren't tabulated in the article, but you can find the CSV files with the timings for this in the repository I link to. Lastly, I'm working on a [library](https://github.com/adityaramesh/neo) (pending documentation and public release) that allows you to tweak all of the platform-dependent parameters mentioned in the article using a uniform API. I'm in the process of revising the API and integrating it with some other stuff I'm working on. It's intended for people who really need to use the fastest disk IO method available for their platform.
Here is nice tutorial about usage of brokered queues. [RabbitMQ Tutorial](https://www.rabbitmq.com/getstarted.html)
Very interesting. I've never used Kafka but am well aware of it. What are the honest drawbacks of this vice Kafka?
I would probably have time to review a proposal, not sure if I'll have time to commit to more.
I have not seen any significant difference between 32 and 64 bit in terms of io speed. In fact my personal experience involved one that was slower in 64 bit but only due to larger structure sizes in memory. I would be interested to know more if there is a measurable difference. 
* One I haven't seen mentioned is support for heterogeneous associative containers so that we can lookup items by a different type than the key (i.e. the canonical lookup string by const char* example). * a constexpr literal S suffix that creates string_view. * string_view + string_view results in string. * constexpr string_view + constexpr string_view results in a new string view that is the literal concatentation of the two so that: "abc 123"S + "566"S results in "abc 123 566" being stored in the .TEXT section
use a struct and please read up on the basics on C, then C++
You could use a simple struct for this: typedef struct { int x; int y; } point;
It would be simpler to construct `const point origin(0, 0);`. You need `make_pair()` only when you need a temporary pair, and don't have the type right there.
god damn, has no one ever heard of shared libraries?
Heterogeneous Associative Lookup was voted into C++14 and has been implemented in VC 2015. (It's for ordered containers only; nobody has done the work to specify what this would mean for unordered containers, where hashes can be type-sensitive.) It's activated by my transparent operator functors: `map&lt;K, V, less&lt;&gt;&gt;` requests the magic. It had to be opt-in in order to avoid changing the correctness and performance of existing code.
For Nintendo's Wii, it was true in 2006 when I developed for it.
Wait a minute. The zero mq author blogged a long rant about why they shouldn't have used C++. Now you're telling me there's a high performance message queue in C++? I'm shocked, SHOCKED, that this was even possible.
Thanks for pointing that out, I was going off memory... If you have a better view, or I came up with a poor example, just say :) I thought a std::map was internally a linked list of pairs anyway. So how can this be fixed?
Can we have a balanced binary tree container? It would be so much less awkward than repurposing a multimap. Specifically, I'm often interested in finding the first element whose key compares equal to the specified one, or the last element whose key compares less. The `lower_bound`/`upper_bound` interface works but isn't ideal.
Which reminds me. In the other thread where you ask for C++17 requests: Howard's hash proposal please. It's so ingenious &amp; deceptively obvious.
Damn, this comes about 1 month too late. I've already started a similar project that's 2/3rd finished. Edit: Have you ever tested your system with large messages, like 256MB messages? That's what we are sending around.
Oh sweet. Didn't realize that. Shame about the opt-in nature of it - not as discoverable. Yeah - having unordered containers addressed too would be nice. I imagine it would be opt-in too: `unordered_map&lt;K, V, hash&lt;&gt;, equal_to&lt;&gt;&gt;`. For type-sensitivity, what about allowing for a std::hash implementation that would take a tag indicating the type of key in the map? namespace std { template &lt;typename T&gt; struct hash_type {}; template &lt;typename T, typename V&gt; size_t hash(hash_type&lt;T&gt;, const V&amp; value); template &lt;&gt; size_t hash(hash_type&lt;std::string&gt;, const char* value) { //... default implementation of hashing a string_view } template &lt;&gt; size_t hash(hash_type&lt;std::string&gt;, const string_view&amp; value) { //... default implementation of hashing a string_view } } This could also solve the problem of unordered_map&lt;const char*&gt; not working since the hash_type could be a template parameter. Additionally, this could be extended to std::map so that map&lt;const char*&gt; would work correctly too (again taking a template parameter for the equality_type this time around).
equal_range() gives you both lower_bound() and upper_bound(), but more efficiently. Be careful what you wish for, when functionality is already available but you wish it were more convenient - that's how we got basic_string.
Well, "discovering" the feature via broken code would be "fun". I can't think of any high-profile occurrences where the Standard has broken back-compat at runtime (whereas compile-time breaks are common). For unordered, I think we would have to demand that a "transparent hash" care only about the values and not the types of what it's given - e.g. it would have to treat int and unsigned long long, or const char * and string, identically.
I'm just a guy, who likes C++ and cats and wasting time on Reddit.
Please don't use a pair! It's not hard to make your own type, with sensible named accessor's. Looking through code that uses "first" and "second" as coordinate parameters would be a nightmare.
A hash function isn't built in for a pair? That's a strange choice. What about a tuple?
Well, as everything related to performance, only you can tell if something works or not. Measure and take whatever works best in your scenario. For me, simply recompiling in 64 bit gave me that 15% boost, but obviously I was processing the file, not simply reading it. (Ninja edit) You did manually laid out your data structures to avoid alignment gaps, didn't you? I do this out of habit :)
Nope.
We write inspection software, and continuously get lots of high resolution images from several cameras that we need to analyze
&gt; C:\Temp&gt;type meow.cpp What is this magical "type" command ? I only know good ole' edit 
It's like `cat` in Linux, it displays the content of a text file (or binary, but that won't look pretty).
And you have `namespace foo = std;` for namespaces: http://en.cppreference.com/w/cpp/language/namespace_alias 
That's odd, it works for me on a standard cmd (Win 8.1), I didn't change the `PATH` or install it or whatever. What could be is that it comes with Visual Studio - maybe no VS, no `type`?
For the ones who like the book, see also https://github.com/BartVandewoestyne/Effective-Modern-Cpp for sample code. It's work in progress. I hope to finish all items soon. Contributions in the form of pull requests are welcome! Comments and suggestions also highly appreciated!
ah i remember that. the guy who didn't know the difference between intrusive and non-intrusive containers and kept comparing apples and oranges.
I'd be interested to know what you view as filler. I actually worked hard to keep the book under 300 pages.
`type` is a cmd.exe built-in. It isn't part of VS.
I'd be interested to know which footnotes you view as filler. My general policy is to avoid footnotes, and the ones in EMC++ are typically there only because I couldn't figure out how to omit the information or to integrate it into the main text. As for the Item on special member functions, the full set of rules are in the Item only once (pages 114-115 of the printed version). That information is summarized in two bullets in the "Things to Remember" at the end of the Item, but an end-of-Item summary is supposed to include the most important information in the Item. This is the same policy I followed in the third edition of Effective C++. Please don't misunderstand me. If you find that the book contains filler, you find that it contains filler. The reason for my pursuing the discussion is that I honestly spent a lot of time chopping stuff out of the book, because I wanted to limit its length. If there's a nontrivial amount of stuff in the book that doesn't need to be there, I'd like to know about it.
I see your point. I've used custom deleters for two purposes: * to control the thread context the destructor runs in ("active object" pattern) * to have a side-effect at deletion I probably should use the shared_ptr-alias constructor to achieve the second one.
Everyone loves cmake and hates the language.... I know I do...
&gt; C++ proposal before, how would you recommend I proceed? Talk to a member of the comittee with experience in writing proposals. That's what was mentioned at CppCon anyway.
My todo list for VC's STL is lengthy - I need to focus on conformance first.
Thanks for your kind words. On Friday we finished updating the master source for the next printing, and the result should be the best Kindle version ever, both in terms of content and formatting. I expect the new version to get pushed out to people with the digital versions of the book in the next couple of weeks.
The headers are what causes the slow builds. Templates encourage you to put stuff in headers. Thus everyone thinks it is templates which are the issue, when it is really headers. You can test this using boost library with and without precompiled headers and comparing the build speed. Not that templates don't have a cost, its just minor compared to headers.
I used it quite extensively over a decade ago for implementing a video codec that exploited SSE on the Pentium III. Also did a bit of reverse engineering back in the DOS/Win95 days to erm... fix... a game or two. These days? Practically never. If I want performance, I hit the GPU with compute shaders.
FWIW I suggest just that here: https://groups.google.com/a/isocpp.org/forum/#!search/scope_guard/std-proposals/cIZ2T_ivyHU/KuGUEgB-r6AJ The reception was shall I say a bit frosty from those pushing a library solution. Maybe it would be worth stirring up some interest again?
i would love to see some partial measures that gradually reduce the problems of header files - i.e. the ability to prototype elements of classes without the whole class, the same way you can forward declare free functions without seeing the whole description of any structs it uses; the ability to forward declare constructors, conversion operators etc like that too. Also syntactic hints ('this symbol is a template' or 'this symbol a global'.. but we don't say exactly what yet) that would help allowing out of order/incomplete parsing (and leave finding actual the definitions till later in the compilation pipeline)
and end to the madness of having to maintain the description of one thing in two places. seriously , its 2015, we shouldn't have to put up with header files.
Hi STL, big fan here. Basicly ranges and std::optional would be cool. The other thing that I miss much is functor like select_second that would be helpfull for taking all values/keys from map. If not functor like this, then some other solution to do this easly without making stupid lambdas. And also concepts should be cool. 
Unfortunately your question can't fully be answered without a little additional information. Most of the existing answers touch on a few things, but the ultimate answer depends on a number of factors that are not given in your question. Just off the top of my head, many of the existing answers could apply to your situation or might be complete red herrings based on other factors. Ultimately, the real answer is to identify the bottleneck and adapt accordingly. Use options given as guidelines, not absolute truths. This is a good principle to keep in mind for nearly all optimizations. (Fundamentally, your question is about optimizing.) The idea of seeking to various locations in the file and using multiple threads might work, but really depends on where the file exists and how much work is being done as a result of reading the data. Is the file on a network share? Is the file on a local device? This matters because of issues generally beyond the scope of the question. (Seek times, command latency, IO bus contention.) If the file exists on 'spinning media' with limited caching, moving a file pointer could result in exceptionally poor performance. A similar issue is involved with command latency and how a seek would likely cause blocking that can be nearly as painful as physical media. So before you try and improve performance, I would look at the overhead of the work that is performed as a result of reading each line. Measure JUST the work done. Then look into the amount of time it takes to acquire each line. fstreams will have some caching done 'behind the scenes' on your behalf, so you need to focus on averages. If the amount time required to accomplish the work is considerably lower than the amount of time to acquire the data, the general approach you take to partitioning the load (work) can vary greatly and might result in a large amount of effort (programming) to achieve no real gain (lower 'wall clock time'). If everything is IO bound (and I would ~guess~ that this is the case) you are not going to see any direct performance gain. Direct in this case meaning that the overall 'wall clock time' will be shorter. What was 'true' about IO and bottlenecks has radically changed (and continues to evolve) over the years, so try and learn as much about the nature of the problem you are trying to solve first. Many of the suggestions are valid, but are likely to be beyond the real problem you have.
gaiety
"custom interpreter written in cmake" u wot m8?
https://github.com/toeb/cmakepp/blob/master/tests/obj/assing_syntax_test.cmake 
When faced with the same shortcomings I chose to write [my own build system](https://github.com/jpakkane/meson). I even thought about making it write out CMake files as output but then quickly decided against it.
I like the Haskell way, with Show / Read typeclasses. Seems simple enough to implement for a concept enabled C++ (Hopefully C++17). Non intrusive and supports built-in types.
With the libstdc++ implementation on linux `/dev/urandom` is opened on construction of `std::random_device` and closed on its destruction, so its not that bad. `__x86_rdrand` is used when libstdc++ is compiled accordingly, which I would say is at least disputable, due to concerns listed [here](http://en.wikipedia.org/wiki/RdRand#Reception). Well, both [en.cppreference](http://en.cppreference.com/w/cpp/numeric/random/mersenne_twister_engine/seed) and [cplusplus.com](http://www.cplusplus.com/reference/random/mersenne_twister_engine/seed/) are, lets put this friendly, misleading. Some books I checked are also misleading or plain wrong: * [Introduction to the Boost C++ Libraries](http://www.amazon.com/Introduction-Boost-Libraries-Robert-Demming/dp/9491028014/) suggests on page 201 to use `std::time` and casts it to `boost::uint32_t` * [C++11 Der Leitfand für Programmierer zum neuen Standard](http://www.amazon.de/11-Leitfaden-Programmierer-Standard-Programmers/dp/3827330882/) Section 19.3 * [Der C++ Programmierer](www.amazon.de/-Programmierer-lernen-Professionell-anwenden-Loesungen/dp/3446426914/) pages 712 -- 716 * [The Boost C++ Libraries](http://theboostcpplibraries.com/boost.random) Ad the German books: Well, in general I buy English books, but at the release of the C++11 Standard there were none around. When doing my non-conformant implementation above I actually looked at the source of libstdc++ to know what happens, since I found no description for constants like `std::mt19937::state_size` online. Base line: **C++11 random is completely broken.** * The single one engine that is always suggested is most of the times used incorrectly. * Using mt correctly though is a pita, which is prove for me of a bad API. * There is also no platform-independent way to use `std::default_random_engine` correctly. * `std::random_device` is not very efficient, by not providing a way to specify the number of bytes/integers one is interested in. To be honest I think feature wise C++17 should be conservative. Concepts might be nice, but reading Eric Niebler's blog it appears to me that its consequences are not fully understood just yet. Just looking at C++11, many of the initially nice looking features like "uniform initialization" and `auto` are filled with so many exceptions to the rule that "modern C++" is hardly modern at all. Instead it got way more complex, needing to know old shenanigans and now many more. Yes, I am amazed with what is possible now, but there are many hidden costs.
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 2. [**Reception**](https://en.wikipedia.org/wiki/RdRand#Reception) of article [**RdRand**](https://en.wikipedia.org/wiki/RdRand): [](#sfw) --- &gt; &gt;[Theodore Ts'o](https://en.wikipedia.org/wiki/Theodore_Ts%27o) publicly stated about the use of RdRand for /dev/random in the [Linux kernel](https://en.wikipedia.org/wiki/Linux_kernel): &gt;I am so glad I resisted pressure from Intel engineers to let /dev/random rely only on the RDRAND instruction. To quote from the article below: 'By this year, the Sigint Enabling Project had found ways inside some of the encryption chips that scramble information for businesses and governments, either by working with chipmakers to insert back doors....' Relying solely on the hardware random number generator which is using an implementation sealed inside a chip which is impossible to audit is a BAD idea. &gt;[Linus Torvalds](https://en.wikipedia.org/wiki/Linus_Torvalds) dismissed concerns about the use of RdRand in the Linux kernel, and pointed out that it is not used as the only source of entropy for /dev/random, but rather used to improve the entropy by combining the values received from RdRand with other sources of randomness. However, Taylor Hornby of Defuse Security demonstrated that the Linux random number generator becomes completely insecure when a backdoor is introduced into the RdRand instruction. This backdoor can be inserted, for example, by means of a microcode update. Taylor's proof-of-concept implementation works on an unmodified Linux kernel. [*[better source needed](https://en.wikipedia.org/wiki/Wikipedia:NOTRS)*] &gt; --- ^Interesting: [^Excavator ^\(microarchitecture)](https://en.wikipedia.org/wiki/Excavator_\(microarchitecture\)) ^| [^Random ^number ^generation](https://en.wikipedia.org/wiki/Random_number_generation) ^| [^List ^of ^random ^number ^generators](https://en.wikipedia.org/wiki/List_of_random_number_generators) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cq2um9p) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cq2um9p)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
My short list of mostly utility stuff: * make_optional_noexpect and make_expected_noexcept - to report errors from constructors without exceptions. * await keyword (assuming it gets into C++17) to work with all monads * template &lt;int n&gt; class integer - supports long integer arithmetic
It means 'or'
That is the logical expression OR! Just like in English, it means that either of these are true. That loop will continue as long as temp1 is not empty or temp2 is not empty. For another example, if(temp == 1 || temp == 2) will evaluate to true is temp is either 1 or 2. If temp is anything else, it will be false.
You might be interested in my new site I just launched - [C++ Samples](http://www.cppsamples.com/). You made this post right as I was finishing it off and I was holding off mentioning it until now! It's not exactly as you were suggesting - less about sharing cool samples, more about demonstrating C++ features - but might be interesting to you.
That's a set of pipes you got there. 
| is bitwise or || logical or.
Plus you would probably break people that wrote crappy code that depends on first generated number being 47. :) like your RAND_MAX being 32767 :D
First one I'm taken to: http://www.cppsamples.com/common-tasks/unique-ownership.html Why isn't auto being used in main? Where and when did the community curate this stuff? I've been out of touch lately I suppose but I never saw anything about this going on. Looks like it's all written by one dude and I would say there's lots of reviewing to do.
Hey, I'm the creator of the site! Currently every sample has been written by me for the sake of launching the site, but the source is all available on GitHub, and I'm hoping that people will correct mistakes, add new samples and such. Apologies if that intro text is misleading at all. **Edit**: I have added a disclaimer to the site to emphasise that the samples are still under review! As for why `auto` isn't being used, there are two reasons: 1. The samples are supposed to be easy to understand and provide references for C++ beginners to start looking up different features of C++. If I had used `auto` in that sample, it may not have been clear to a beginner what the `std::unique_ptr` in the description was referring to. I feel that for the samples to be useful for everybody, the types need to be explicit (when possible). 2. `auto` isn't mature enough to have a general consensus on when it should be used. I personally don't think `auto` should be used in that example.
&gt; With the libstdc++ implementation on linux `/dev/urandom` is opened on construction of `std::random_device` and closed on its destruction, so its not that bad. Yeah, I actually misread your code. It just performs 624 distinct _reads_ from `/dev/srandom`, at least when I run it with OS X. &gt; `__x86_rdrand` is used when libstdc++ is compiled accordingly, which I would say is at least disputable, due to concerns listed [here](http://en.wikipedia.org/wiki/RdRand#Reception). Hmm. I did notice that when I run your code on Ubuntu 14.04, it didn't seem to be using `/dev/random` (sample [`strace` output](http://pastebin.com/2QFta5D6)). (Incidentally, running it on 14.04 requires custom installing GCC 4.9 since GCC 4.8 won't compile the code, even in C++1y mode.) &gt; Base line: **C++11 random is completely broken.** That's why I wrote the post! The idea you that the only real problem with RNGs in C++11 is that it's hard for _novices_ and that you can fix things by introducing `randint` seems like a massive understanding of the current state of affairs. &gt; Just looking at C++11, many of the initially nice looking features like "uniform initialization" and `auto` are filled with so many exceptions to the rule that "modern C++" is hardly modern at all. Instead it got way more complex, needing to know old shenanigans and now many more. I teach C++ (in a relatively late course, after students have seen Java, Python, etc), and while I do think C++11 and C++14 added numerous good things, I also feel like C++11 didn't make my life much easier. You can pretend that you can just brush the annoying ancient-history cruft and too-cool-for-school cleverness under the rug, but the reality is that sooner or later, someone is going to have something odd (an error, a behavior, or a “how do I do this?”) question that requires us to expose all that stuff. &gt; Yes, I am amazed with what is possible now, but there are many hidden costs. Exactly. 
It would be nice if there was a "Run" option like there is on http://en.cppreference.com/w/cpp/container/vector/erase Nice work BTW
Probably. You could get by just fine using something like openframeworks which is much higher level.
foo&amp; operator=(foo other) { std::swap(p, other.p); return *this; } WTF is this?
I figured this would be a fun exercise to write, and finally have something productive to put on my website. Feedback is welcome.
[This is a mirror of the page, before it went down](http://i.imgur.com/nbVnoTY.jpg) If you have any comments or suggestions, please send me a PM. Thank you!
upvoted. It actually implements 4 (copy-constructor, copy-assignment, move-assignment, destructor). And the move-assignment is not a great implementation. The rule of 3 died in 2011. In modern C++ the rules are "rule of 5" or "rule of 0". This class needs a move-constructor, and the article should have some discussion of the pros and cons of this assignment operator (preferably also including an example with the optimal move-assignment). 
&gt; This site is going to be a big jumble if you don't set some coding guidelines. Agreed! I have some reasonably flexible coding guidelines in the [samples repository README](https://github.com/sftrabbit/CppSamples-Samples). The reason they are flexible is because it's often difficult to say whether one particular style is better or more idiomatic than the other. Yes, `auto` is a C++11 feature, which makes it modern. That doesn't necessarily mean that it should be used whenever it can be. I myself don't think that stopping something from "getting difficult to read" is a good enough reason to use `auto` (although I can see the appeal) and I know that there are people out there on both sides of the fence. Considering this and the fact that I want to be explicit about types for the sake of C++ beginners, I think it's reasonable to take the approach I have done. Personal coding preferences mean I can't please everybody!
I had thought about it. However, many of the samples are not really "runnable". That is, they just show a concept and don't really do anything useful. Adding `main` functions to everything that print out some results will make the samples more complex.
Really cool! Here I've been writing those overloads by hand all this time.
Thanks, I'll have to have a think about the best way to present this. I might simplify the rule of three example first (without using copy-and-swap), but I think the biggest issue is that there's no rule of five sample. Also, perhaps the rule of zero shouldn't show the deep copy example (because in that case, the smart pointer shouldn't have been used).
This is a great list. I will also recommend [Rosetta Code](http://rosettacode.org/wiki/Category:C%2B%2B).
I agree with your arguments about `auto`. The example on your site is however one of the prime examples of when to _really_ always use `auto`. The type is repeated identically, it is completely unnecessary and it's very arguable if explicitly stating the type twice makes the code more readable. Beginners should learn to _use_ `auto` in exactly this case.
To expand on this, by using a non-reference parameter it will already allocate and have a copy ready for you, so you just swap your object with the newly constructed temporary object, then the temporary object, now holding your old object, automatically destructs at the end. It's safe because the compiler handles constructing and destructing for you and swap safely handles assigning the newly constructed object's contents to the current object.
Herb Sutter wrote an article saying to always use auto, then after other C++ gurus pointed out how absurd that was he revised his article to almost always use auto. Since C++ is a complicated and fairly advanced language, people tend to listen to what C++ gurus say verbatim without giving it much independent thought, hence your statement that auto shouldn't always be used blindly where ever possible goes against the top C++ guru. As such you can expect to get a lot of flack for your opinion.
for me opengl would be way to low level for such a purpose. I'd use an established gui library like qt to get things done quickly. if something needs tricky custom rendering code (fancy graphs) you can then still make use of opengl, cairo or whatever.
Grab the C++ Std from here: https://isocpp.org/std/the-standard You will need it as you progress.
Agreed. I'm not an expert by any means (started learning a month ago) but knowing the basics and practicing it has helped me immensely.
Not necessarily. What if someone has never seen std::unique_ptr before? They might not have any clue that make_unique is returning a special type of smart pointer. If they just see "auto" as the type, they're left with a blackbox. Believe it or not, for some people, seeing explicit types *improves* readability. In most cases I'd *much* rather be able to glance at the type on the left to know what kind of object I'm looking at, rather than spend time (even if it's just seconds) trying to infer the type from the function on the right. auto is very useful for common loop structures where the type is just blatantly, stupidly obvious (i.e. an element in a container), but I don't find that it improves readability in most other use cases, at least for myself.
&gt; Not necessarily. What if someone has never seen std::unique_ptr before? Then they should **really** read the documentation. `std::unique_ptr` and `std::make_unique` should be the first approach to non-stack-based resource-managment, and it really is imperative to learn that as soon, as possible.
I see your point, and you're certainly not wrong. So it would make sense to show and teach both sides of the story at that point. What about keeping the example like this and putting a footnote that explains that `auto` can (and in most circumstances should) be used there? Or maybe a direct link to an a little bit more complex follow-up example (like one with a more complex type) that then uses `auto`?
weird, is std::arrays preferred over C-ish arrays and vectors now for size-fixed-at-compile-time containers? http://www.cppsamples.com/common-tasks/pass-arrays.html (any particular reason why?)
it's not just herb. scott meyers is pro-auto as well. I know it's great to think for yourself and all, but you'd better think pretty hard before concluding those two are talking out of their ass. btw, auto _is_ explicit about types, at least from the compiler's POV.
If your goal is to learn OpenGL, hell yeah! If your goal is to make your application in the most efficient way, you'll want to use a higher level library that handles 2D drawing for you, because chances are you'll end up doing the same thing to some extent (wrapping OpenGL calls inside your own API).
I disagree, since the examples are about teaching a specific programming feature/algorithm, not about teaching a certain style guide (even if auto would be great, it's not what that example is meant to teach). Teach one thing at a time, which is why this site is great.
Very much so; they're preferred over vectors because: * they can be more performant, since they don't do any heap allocation * if size is fixed at compile time, they're more type-safe and over C arrays because: * they know their own size * they have standard copy semantics, and don't convert into a pointer to their first element at the slightest provocation.
 shared_ptr should be the last, it makes code far harder to understand, since at a glance you have no idea how many owners might exist. unique_ptr is very clear, 1 owner, and most of the time that is all you need. Also, using auto is the better approach here. If you don't know what the type is, any decent IDE can tell you.
I don't think the auto issue is really worth nearly the attention it gets. I certainly wouldn't argue that using auto is some kind of "bad" or evil thing, I just don't think code bases that prefer redundancy and explicitness are evil or bad either. Redundancy is often good for human communication to express intent and emphasis. For example, /u/STL claims with authority as the designer of make_unique that it should be used with auto. Sure, but consider that using auto with make_unique can result in clashes if you want to reassign or mutate a polymorphic object, for example: auto animal = std::make_unique&lt;Cat&gt;(); ... animal = animal-&gt;TransformToDog(); The above would be a compiler error since *animal* is an std::unique_ptr&lt;Cat&gt; and what we really want is for it to be an std::unique_ptr&lt;Animal&gt; so that it can be assigned to any kind of animal. The following is much more clear and expresses intent: std::unique_ptr&lt;Animal&gt; animal = std::make_unique&lt;Cat&gt;(); ... animal = animal-&gt;TransformToDog(); Compiler error is gone. If someone wishes to dogmatically stick to the always use auto, they could do this: auto animal = std::unique_ptr&lt;Animal&gt;{std::make_unique&lt;Cat&gt;()}; I consider this to be an abomination that does nothing more than adhere to dogma. My own personal position I think is fairly sensible. If you write the following: auto animal = expression; Then you're communicating a bottom-up declaration where the type of *animal* is dependent on *expression* and you impose no requirement on what *animal*'s type must be. If you write this: std::unique_ptr&lt;Animal&gt; animal = expression; Then you're communicating a top-down declaration where *expression* must satisfy the type std::unique_ptr&lt;Animal&gt;, you are imposing that as a requirement on *expression*. And finally, none of this is really a big deal period. If you want to use Sutter's advice, go right ahead, if you want to use my advice, by all means... if you want to make your own convention based on the requirements suitable for your own team, then do that.
Even stateless lambdas aren't functions. This matters in at least two ways: stateless lambdas can occupy zero space (via the empty base class optimization), while function pointers always occupy space, and stateless lambdas are good candidates for inlining whereas function pointers are never better and sometimes worse. (Stateless lambdas are convertible to function pointers, but the conversion must be requested by something.) The Standard refers to lambdas as closures fairly often. I dislike the term "closure" and never use it myself. I did many years of Scheme, so I know exactly what "closure" implies, and I don't like it.
As an STL maintainer, I would never say that std::array is "preferred over vector". There are reasons to use std::array but they are uncommon. Most things work with flexible-length data. There are only a few situations in which you need a truly compile-time-fixed bound, which is small. This tends to occur in mathematical situations; for example, a quadrilateral is always represented by 4 points, a Huffman tree always contains 511 nodes. If somebody used a vector when an array would be reasonable, I'd point it out, but I certainly wouldn't hiss at them.
what don't you like about the term closure and what a closure implies? (if there's a good reference/article i'll read up on the issues...)
I was thinking that somewhere in TransformToDog() there would either be a downcast or an instantiation of the specialized type, but it's true that it's not explicitly stated.
Yes, I'm just saying those situations are uncommon.
If you created this page for newbies, you should explain such cases directly on your web page. Not only idiom name, but also it's 'story'. Otherwise users will go back to stackoverflow. You should also say a word about exception safety, nothrow, move constructors, why swap for type 'foo' should be defined, and so on... In short: raw code is not enough. 
&gt; auto animal = std::unique_ptr&lt;Animal&gt;{std::make_unique&lt;Cat&gt;()}; I wrote myself a "two type" version of make_unique to handle cases like this. Simplified version: (this one doesn't handle arrays) namespace util { template&lt;typename T, typename U=T, typename ...Args&gt; auto make_unique (Args&amp;&amp;...args) { return std::unique_ptr&lt;T&gt;( new U(std::forward&lt;Args&gt;(args)...) ); } } - // animal is a std::unique_ptr&lt;animal_t&gt; holding a pointer to a cat_t auto animal = util::make_unique&lt;animal_t,cat_t&gt;(); It works like std::make_unique if you omit the second type // cat is a std::unique_ptr&lt;cat_t&gt; auto cat = util::make_unique&lt;cat_t&gt;(); 
Yes, Rosetta Code is great! Slightly different purpose - it's more about showing how to solve common programming problems, rather than exploring modern C++ features.
It's not, but you can spin off a thread pretty easily.
Nice examples; thanks for the work. The pimpl example is missing a destructor since it cannot be auto generated because unique_ptr requires class impl to be complete at the time of destruction.
So it would replace use of pointers as return values for the Something, Maybe Nothing case?
&gt; I also find myself rewriting/restructuring my code many times over. It's a sign you're doing it well :p The worst would be to be satisfied with something that smells if you have a lot of time in front of you. I think that the best is to work hard, and ask when you've got specific problems. You can also look on codereview.stackexchange and post some code there where people will explain what's wrong and how to make it better. 
Do you think it is worth paying for the hard copy? 
That book should be a must for everyone.
"Refctor mercilessly until its perfect" - Ideally at the design stage of course ;)
That depends on your personal preference I guess but I got the hard copy, and I'd say it's the single most important book on programming I've ever read.
Cairo optionally can [use OpenGL as a backend.](http://cairographics.org/OpenGL/)
Well, I'm certainly in favor of such a change; not that my vote counts for anything. One argument I can see for adding `generate` to `random_device` is that since the engine knows how much entropy is required it can request exactly that amount in a single system call; as well as being possibly more efficient than requesting entropy in 4-byte chunks, this benefits system tracing and in entropy-constrained situations would help ensure that at least one application makes progress. 
I find you can get pretty close on your first pass with the following approach: 1. Design your data to reflect/represent the problem/domain. 2. Create functions to perform the operations you'll need done on the data. 3. Create functions/data to drive the model in your application. I often go back to what it is I'm trying to represent to check whether my design is appropriate. Stay in the problem domain as long as you can, and the solution often falls out of that naturally. It can save you a lot of blind fumbling with patterns trying to get to the way it had to work all along.
Seems like you are falling into a trap ("proper OO code design"). You are trying to plan for the future, and you are thinking about "code" and not "data", seems like you have probably drifted off your core goal. Your task as a developer is to usefully transform data, the further you get from that task, the worse off your are. Watch Mike Acton's "Data-Oriented Design and C++" from CppCon -&gt; https://youtu.be/rX0ItVEVjHc Always remember the [three lies](http://cellperformance.beyond3d.com/articles/2008/03/three-big-lies.html): - Lie #1: Software is a platform. - Lie #2: Code should be designed around a model of the world. - Lie #3: Code is more important than data. I suspect just by changing your perspective a little bit, your code will be wildly improved and simplified. 
Its too much work, too much reinventing the wheel. Use Qt for the widgets, and maybe graphs. When something starts running slow replace those Qt parts with OpenGL.
I expect at first it will be something like `std::experimental::view::reverse` or some such. The delivery mechanism for ranges hasn't been discussed yet, but it'll probably be a TS and get its own namespace. This is a Good Thing. You really don't want to dump things in `std` that are going to change. And I expect the ranges stuff to be in flux for a while.
The big caveat there is "where a struct will do". There are many cases where std::tuple is preferable: 1. Handling varargs, where the number and type of fields isn't fixed. 2. When you'd like some basic reflection facilities on the structure. 2 is really the big one, IMHO, since C++ still doesn't provide much in the way of reflection. A lot of serialization libraries for C++ basically generate C++ structs from an external type definition, or worse, do runtime reflection and thereby impose overhead. The good news is, at the cost of a bit of verbosity, you can basically have the best of both worlds: using foo_tuple = std::tuple&lt;float, int, std::string&gt;; struct foo : public { float bar() const { return std::get&lt;0&gt;(*this); } int baz() const { return std::get&lt;1&gt;(*this); } std::string biz() const { return std::get&lt;1&gt;(*this); } }; 
shared_ptr permits custom deleters for pointers. You should use Boost.ScopeGuard or equivalent tech for non-pointer resources. Manual resource management is leaktrocity in the presence of exceptions and other errors.
Oh I don't want `experimental` things in `std` until they're standardised, absolutely. `std::experimental` for experiments, etc. etc. But there's a lot of talk about the need for basically a new standard library namespace to cover the fact that doing Ranges is going to be hard to do backwards compatibly. And similar talk about Polymorphic Allocators. And similar talk about parallel algorithms. Ranges realistically have a very good chance to be in C++17, right?
I need more vespine gas to read it, :(
Since no one else has, I'll say it. THANK YOU! 
I think a lot of people start with a little text adventure game. Gets you thinking about the flow of your game logic 
I think that it would be quite an easy task for me, I am just asking for an idea, what game to make for my school project..
It wouldn't be overkill. It should be very simple to write a thin abstraction layer over OpenGL (or D3D for that matter) for your visualizer. It will be miles faster than whatever framework you will pick up, and if your program will contain a lot of data, you won't have to be working around GUI framework inefficiencies.
Thanks a ton for taking effort to compile these links. Its very helpful.
what does :zap: mean? It is attached to a lot of the entries - by the looks of it the bigger more well supported ones. 
It's a github list I believe so anyone can push commits.
Cringeworthy language identifier ... I also do C++/Linux.
even there you generally I wouldn't want to be hard coding my filter kernels unless I was only writing a quick-and-dirty prototype.
I personally started with [Connect Four](http://en.wikipedia.org/wiki/Connect_Four); the rules are *extremely* basic, so that you can actually write a relatively simple "AI" to play against.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Connect Four**](https://en.wikipedia.org/wiki/Connect%20Four): [](#sfw) --- &gt;__Connect Four__ (also known as __Captain's Mistress__, __Four Up__, __Plot Four__, __Find Four__, __Fourplay__, __Four in a Row__ and __Four in a Line__) is a two-player [connection game](https://en.wikipedia.org/wiki/Connection_game) in which the players first choose a color and then take turns dropping colored discs from the top into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the next available space within the column. The objective of the game is to connect four of one's own discs of the same color next to each other vertically, horizontally, or diagonally before your opponent. Connect Four is a strongly [solved](https://en.wikipedia.org/wiki/Solved_game) game. The first player can always win by playing the right moves. &gt;==== &gt;[**Image**](https://i.imgur.com/cAb3rCO.gif) [^(i)](https://commons.wikimedia.org/wiki/File:Connect_Four.gif) --- ^Interesting: [^Score ^Four](https://en.wikipedia.org/wiki/Score_Four) ^| [^Battleship/Connect ^Four/Sorry!/Trouble](https://en.wikipedia.org/wiki/Battleship/Connect_Four/Sorry!/Trouble) ^| [^252 ^\(number)](https://en.wikipedia.org/wiki/252_\(number\)) ^| [^Connect ^4x4](https://en.wikipedia.org/wiki/Connect_4x4) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cq5779h) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cq5779h)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I agree it would be better as 2 lists. of course any c++ programmer would use a c library if it was the best option, but c++ libraries are preferable
Every anchor I clicked did absolutely nothing. For example, the anchor that points to #game-engine should actually point to #gameengine.
As long as "Something" is not an abstract type: Yes. You can think of `optional&lt;int&gt;` as a struct with an `int` and a `bool` data member. That's better than a `std::unique_ptr&lt;int&gt;` which is also nullable but would require a heap allocation. So, depending on whether you want/need a layer of indirection, you would pick between `optional` and `unique_ptr` for this use case. 
All the GUI libraries listed there suck...
A very un-focused list. And there is no awesome C -- that simply does not exist. ;)
&gt; By the way, even searching for talks about Boost.Qi is a challenge in itself, because most of Youtube results for “boost qi” are videos of Chinese people doing gymnastics, rubbing feet to strengthen kidney health, etc. This really made me laugh! :-D &gt; I’m still not sure how to properly handle some CMake-related files in the repository, e.g. the CMakeLists.txt contains some absolute paths that you will need to adjust in your clone Look into populating the cache with an initial_cache.cmake file (`cmake -C cache_file.cmake`). &gt; After consulting with Biicode folks, and looking at some examples, I’ve excluded all the unnecessary stuff via the .gitignore file as follows I'd rather do complete out-of-source builds. Then you'll never have the problem of committing something that you shouldn't, or having a huge .gitignore file. Your directory structure will look like: - ProjectName/&lt;All your project files that go into the repo, can be a src/ dir, include/, CMakeLists.txt, configs, etc.&gt; - build/&lt;This is your build dir, run `cmake` from here, all temporary build files will go here, e.g. the cmake-cache, files from your IDE (IDEA or VS or whatever), etc. Nothing of this will be committed.&gt; - install/&lt;in case you're working with an install target, the final product will go here.&gt;&gt; So you'll run cmake like: `cd build/` `cmake -C ../ProjectName/initial_cache.cmake -G "Your generator of choice" ../ProjectName`. Your source directory ("ProjectName") will never be touched by any build-stuff.
&gt; But there's a lot of talk about the need for basically a new standard library namespace to cover the fact that doing Ranges is going to be hard to do backwards compatibly. That's not the problem. It's concepts. Constraining the standard library with concepts -- with or without ranges -- is hard or impossible to do in a backwards compatible way. And once you decide to break back compat, then it opens up a lot of possibilities. &gt; Ranges realistically have a very good chance to be in C++17, right? Ranges have a very good chance of being in their own TS. C++17 looks doubtful, but when I say that, I mean that ranges have a slim chance of being in the official C++17 standard document. There is a very good chance that vendors will be shipping ranges by then in a a separate namespace for the TS.
I wouldn't worry about boost or qt yet. focus on fundamentals. make sure you understand memory: pointers and references, copy and move semantics, stack vs heap, all the flavors of static. OOP and basic templates. linkage: static libraries, DLLs, what can/can't/should/shouldn't go in header files vs. in CPP files. any decent job will give you time to learn their libraries and GUI frameworks, but you'll be lost if you're weak on the fundamentals.
Ask them have they read Effective C++? Of course I'm not saying it should be a deal maker/breaker by itself.
These are all essential. I would add the memory hierarchy all the way from on-chip caches to disk. 
nice check this site out http://www.sorting-algorithms.com/ 
Would it be ideal to put these fundamentals on a resume? 
SFML is kinda yuck though.
Clear thought process, good writing skills. Initiative to learn. Most everything else can be taught if you have a familiarity with the language and CS concepts. Specific things if they are coming from a C++ background. * Pass by value, pointer, reference, and when to use them. * Basic digital logic stuff: draw a truth table for AND, OR, XOR. * Difference between Public, Private. (bonus for Protected, and why to avoid it) * Difference between Struct, Class, and Instance. * Basic inheritance. * Difference between Inheritance and Composition. 
Wow, truth tables. I haven't touched that since Discrete Math I. I should probably look back at that.
Thanks again for all your work on that ChaCha20 implementation, etc.!
In the game industry, you won't go wrong with - a rock solid understanding of what happens in C++ under the hood (for example, how are virtual functions actually implemented?) - an understanding of 3D math (tell me how to determine if a ray has intersected a polygon) Practically all entry level questions will revolve around those (very large) topics.
I think just knowing one is a sign of professionalism. Doesn't really matter if it's git, perforce, subversion, etc. Obviously git is the new shiny thing so that would be cool, but I know that no one in my company (or any company I've worked at) uses git for anything. Which isn't to say that that might not change, even perforce is starting to integrate git into it.
I would advise getting a github account, then putting your side projects up on there. Then on your resume have a Projects section where you describe them. And then finally add you github handle on top of you resume The recruiters will likely see the project section of your resume and ask you to talk about one or two. So be prepared to discuss your projects and use them to demonstrate your programming skills
Thanks.
Not gonna lie, if they get modules working (and make sure they don't suck) C++ will actually be a pretty nice language 
What's wrong with Protected? Honest question.
I just finished an Introductory-level book on C++, but I think there was no mention of "modules". Should I know what they are?
Sounds pretty nice, thanks.
Most dreaded: #3 Wordpress. Heh, heh. 
&gt; Average Salary &gt; Ukraine 21,825 $26,190.48 The fuck? Our currency just became trash this is why big macs so cheap but that doesn't makes us rich. About year ago 1$ = 10 UAH, now 1$ = 25 UAH
&gt; The more things change, the more likely it is those things are written in JavaScript with NotePad++ on a Windows machine (theme: dark) using Git, and tabs instead of spaces. Down to the theme, huh?
`#pragma once`, man... `#pragma once`
&gt;That's not the problem. It's concepts. Constraining the standard library with concepts -- with or without ranges -- is hard or impossible to do in a backwards compatible way. And once you decide to break back compat, then it opens up a lot of possibilities. What would the new namespace be? I really don't want to be writing `std::concepts::` instead of `std::` in new code. :/ You can write `namespace stdc = std::concepts`, but I'd rather not do that everywhere and I really don't want to be writing `using namespace std::concepts` at the beginning of all my `.cpp` files. :( Backwards compatibility is hard. &gt;Ranges have a very good chance of being in their own TS. C++17 looks doubtful, but when I say that, I mean that ranges have a slim chance of being in the official C++17 standard document. There is a very good chance that vendors will be shipping ranges by then in a a separate namespace for the TS. So them being relatively finalised by 2017 is possible, just not in C++17? That's unfortunate but better than them just not existing. C++17 is going to have concepts in the language, and will probably have concepts in the library, right?
Er... why?
1. It has no benefits: there's no advantage to if over header guards. 2. It's not standard. 3. It's fragile on many platforms when you involve build tools that can potentially move things around, etc. What does it *actually mean*? That nothing with exactly the same content should be included again? That nothing that hashes to the same SHA-1 hash should be included again? That nothing at this particular file path should be included again? 
&gt; and being time-effective debuggers Are there resources for this beyond just raw experience? I find myself repeatedly stumped by memory corruption bugs in particular. If it's a segfault I can figure that out because the area of code causing it is usually apparent, or if not you can usually trace back where the problem originated. But when a block of memory has been stomped on in a system running 50 different subsystems in the same process I don't really know how to even approach it.
It isn't possible exactly as you describe, but you can get a similar effect by introducing a new (int,float,int) function which calls the (int,int,int) function. For example, with a lambda: void (*f)(int,float,int) = condition ? f1 : [](int a,float b,int c){f2(a,b,c);}; while (...) { int a = ...; float b = ...; int c = ...; f(a,b,c); } However, if performance is your concern, you may find that this is slower than the original. This is also assuming that the variables in the loop are actually of type int, float, and int. If not, you would need to modify the signatures to match.
I'll admit that I haven't researched this very much, and I am very much curious about reasons to use/not use `#pragma once`. I disagree with you on number one. `#pragma once` is MUCH easier to manage on a file-by-file basis. Ever copied a file, changed the class name and forgotten to change the include guard? Ever accidentally caused a name collision in include guards and get mysterious compiler errors? I know I have, and `#pragma once` prevents that. [Wikipedia also lists possible speed optimizations](https://en.wikipedia.org/wiki/Pragma_once) but [other](https://gcc.gnu.org/onlinedocs/gcc-2.95.3/cpp_1.html#SEC8) [sources](http://tinodidriksen.com/2011/08/31/cpp-include-speed/) show that compilers are able to recognize and optimize include guards. Although `#pragma once` may not be standard, [Wikipedia shows it is very portable](https://en.wikipedia.org/wiki/Pragma_once#Portability). Depending on your project, this may or may not be an issue anyway. The software I write at work is always compiled with a specific compiler. If that compiler supports `#pragma once`, that's good enough. I am seeing your third point listed as [the only downside of `#pragma once`](http://stackoverflow.com/a/1946730/2218034). I'll admit that I have not run into this, but I can understand that this would be an issue if your build system is complex enough. At that point, I would probably argue for simplifying your build system, but that's a different discussion, and I suppose it may not be feasible :)
&gt;I disagree with you on number one. #pragma once is MUCH easier to manage on a file-by-file basis. Ever copied a file, changed the class name and forgotten to change the include guard? Ever accidentally caused a name collision in include guards and get mysterious compiler errors? I know I have, and #pragma once prevents that. Wikipedia also lists possible speed optimizations but other sources show that compilers are able to recognize and optimize include guards. 1. No, why would I copy-paste code? Everyone knows that is bad. 2. Speed issues are a simple quality-of-implementation issue. &gt;Although #pragma once may not be standard, Wikipedia shows it is very portable. Depending on your project, this may or may not be an issue anyway. The software I write at work is always compiled with a specific compiler. If that compiler supports #pragma once, that's good enough. Its lack of standardisation is an issue to those that want to write standards-compliant code, and feeds into the next issue. &gt;I am seeing your third point listed as the only downside of #pragma once. I'll admit that I have not run into this, but I can understand that this would be an issue if your build system is complex enough. At that point, I would probably argue for simplifying your build system, but that's a different discussion, and I suppose it may not be feasible :) "It has completely unspecified semantics" might from your perspective be "the only downside", but it's enough of a downside that that should be enough to stop you using it. A build system moving a file - or rather, copying a file - does not make it complex. Use the well-specified, well-defined, *clear-in-semantics-to-anyone-reading-them* header guards instead and it saves you all the trouble of `#pragma once` with no downsides.
&gt;I was asked about the difference between C++ and C# I hope you know that. &gt;virtual constructors That's not a thing. Do you mean virtual destructors? &gt;size of an empty class, Pointless trivia. &gt;OOP Stupidly broad. &gt;when use public/private in classes When you want something to be public or private. &gt; multithreading Stupidly broad. --- Looks like you dodged a bullet.
The cost of inner "if" is about the same as actual function call, as the function by pointer cannot be obviously inlined. So, the better solution is to use "if" and hope for good inlining of both function variants.
Alright, 26k/yr, some real ukrainian salary. What's the matter?
Nice!
I wish there were a guide for each language, like "If you put X language on your resume, you'd better know this about X".
C++14, anyone ?
imho, you are ready to get a job in the field. You won't know everything you need on day1, but on day30 you probably will... (and it is like that for *any* job, regardless of your experience level) keep on searching, and in the meanwhile study the things you got wrong on that interview
&gt; "one declaration and definition" But I love my header files. I often prefer looking through a .h file to reading docs.
Now if just the Android team also though the same way...
That sounds amazing. I hate header files.
The public interface of a module is still subject to name collisions (so if you create your own std::vector class and then try to import the STL version you'll still have problems), but privately modules only have to worry about collisions against things they're importing, and not against things that are importing them. STL implementations are also written with compilation speed in mind (because they have to be recompiled for every file that includes them) but with modules this won't be an issue, so they can be written for readability instead. 
Maybe you should interview for higher paying jobs.
It's basically the same. - your build-dir is inside the source dir, which is no big deal (you can just `.gitignore` `build/`), it's personal preference I guess but I don't like it, I rather have build and source separate and leave it up to the user - you omit `-G "..."` which is ok, it'll just take the default (Makefile on Linux) - you omit `-C "..."` which is ok as well but the OP specifically asked in his blog how he best adds platform-dependent / absolute library paths to his CMake project, and this is exactly how. (you can also do it with `-DWHATEVER_VAR=/some/path` but it's exactly the same).
And NuGet on Windows.
1 is false. #pragma once is easier to read, maintain, and debug.
Way too complicated. type as few commands as possible that are as short as possible. have working software. That should be my workflow. 
Awesome survey! I'm very surprised about the category `Text editor`. No IDEs in there? Visual Studio? (since the majority is developing on Windows). No XCode, Eclipse, whatever? I guess they limited the question to pure "text editors". But the transition from a text editor to an IDE is fluent (take Sublime with a couple of plugins for example). Also, the follow-up question is called "IDE Theme" which suggests they DID ask for IDEs after all and not "only" text editors. That's all a bit unclear.
I agree with you and I don't see your issue. All I am saying is: "Here are the options in case you need them / because you asked for it". In most of the cases, the default is fine. Sometimes it's not however.
What? GitHub doesn't let just anyone screw with your repo. Why on Earth would they allow that? Also, how does this answer the question?
Can you recommend a better one?
That nothing at this particular file path should be included again.
1. It's a lot easier to read, why should you have to write 3 lines of code, when 1 can do it? 2. While this is correct, it is implemented by all major compilers. Also, how do you think things like this become standard? 3. This is a legitimate point, but I still feel that this argument falls under "premature optimization". I see no reason to start using verbose header guards for all my projects, when a small fraction of them ever leave the comfort of my hard drive. And should a day come when I get an issue filed saying that the pragmas are causing problems for a user, then replacing them would be a simple enough task that I wouldn't trade it for easier development.
they are essential to any C++ job. or C, except the OOP and templates part. nowadays C++ is mostly used for: - heavy computation: games, data analysis, CAD - platforms: web browsers, VMs - embedded systems: GPS device, programmable thermostat, engine controller You'll notice that most of these require some other domain knowledge compared to a typical web programming job. but often the work is divided between experts writing the heavy duty stuff and junior devs hooking up GUIs, saving/loading files, etc. I'm lucky because my current job has allowed me to expand from GUIs towards the heavy duty stuff after I demonstrated ability. that is not always the case. even if your boss believes you're capable, they still need N warm bodies doing junior stuff. so I would suggest you try to acquire the domain knowledge ahead of time if possible.
C++ is already moving in an "easier to write and maintain, use tools to grok" direction with `auto`. I think having all the functions defined in line is just another step in this direction. Most IDEs can maximize/minimize code blocks for readability purposes, and even vim has tagbar for skipping between symbols.
Then go and write a tool that extracts those informations and writes them into a text file named *.h 😈 I really hate managing **two** files for the same purpose! This is just redundant and violates the DRY principle!
&gt; :( Backwards compatibility is hard. True words. &gt; C++17 is going to have concepts in the language, and will probably have concepts in the library, right? I don't know the answer to that.
Having been interviewed and done some interviewing for this, I'd recommend looking at Scott Meyers's Effective C++ and Effective Modern C++. They're very well-written, to-the-point, and I'm of the opinion that if you're comfortable with their content, you'll be adequately equipped for the sorts of language questions that I've seen in interviews (as well as better equipped to write good C++).
A programming language is a tool used to realize complex solutions for certain kinds of problems. That is how I treat it. Don't treat jobs as C++ jobs, Java jobs and so on, but consider what kinds of problems the job requires you to solve. Only after you are certain that you can solve such problems, the question of the tool required to do so becomes relevant for you. And learning how to effectively use tools is not that hard, but rather 'trivial'. If you need to know C++ then learn how to use it. If you need to know Java then learn java. In reality a programmer has to adapt to new languages all the time! But that is really not that difficult. The key here is to learn some common languages really really well and you will realize that every other language is very similar and that you will be able to adept quickly. Such common languages could be C++, Regex, Java, Javascript, Python, C#, XML, SQL, HTML and most importantly ~~Brainfuck~~. But don't worry, learning languages doesn't take forever, after the first one you will be picking up new ones much faster. Also become familiar with basic standards like posix, winapi, TCP, UDP, GUI-APIs, SQL-APIs, Regex-libraries and so on. Not in great depth, but you should be able to say that you have used such tools/libs at least once (for more than just hello world). &gt; Or should I mention on my resume that I'm not that experienced with C++? **ONLY** mention what you **can** do (and a little more ;P) - no exceptions!
From almost everywhere I read and hear people recommend putting every language you have some experience in and just include your level of proficiency with that language in parentheses.
When people say 11 or 14, they are similar enough that you can consider people to be talking about the same thing, at least for the most part.
I would argue that the encapsulation is improved if the alternative is providing a public method to access private members. Instead you can provide a protected method to access private members.
No need to hardcode anything: template&lt;typename T, std::size_t N = 512&gt; auto kernel(std::array&lt;T, N&gt;...) { ... }
Sounds to me like you may want to take some software engineering courses or read books on the subject.
&gt;What motivated you to leave academia to join Morgan Stanley? &gt;I wanted to get back to solving real-world problems. This was very important to me. I had gotten too far away from my roots and I wanted more realistic problems than I was dealing with in academia. I am getting those challenges here at the firm. I find myself motivated by the important and varied technical challenges that are presented, and by working with a technical community that is among the best skilled in the world. That and money.
&gt; C++ is already moving in an "easier to write and maintain, use tools to grok" direction Both very true and very unfortunate. The code bases I've been working in the last seven years or so are just too big for the IDEs to handle and this direction is terrifying me.
It's going to be like every other new feature in C++. It will have terrible syntax, won't be fully implemented (it will be finished in the subsequent standard), and will come with a long list of caveats and corner cases where the feature does not work like you would expect. At some point in time the committee needs to say to hell with backward compatibility and create that "smaller, cleaner language" that Bjarne talked about.
No, they've all gone bankrupt. Back when they *did* publish C++ magazines, or even Dr. Dobb, those mags had long, in depth articles that were very relevant. As opposed to a whole article on whitespace preferences from some guy.
Weird, I tried it an everything seems great. Including stdafx.h. Few warnings I did not like I could disable globally. Overall I love it. Much more than VAX.
Another solution you haven't thought of apparently is to refactor the loop into a function. Make it templated on the function parameter. On phone and it no have braces so can't show code. The compiler should inline the call to the while function and actually eliminate the use of function pointer, which is going to have similar effects as the if. To be honest though it sounds like your situation is such that the cpu branch predictor will catch on and your code will run as if there were no if in it. You should profile before worrying.
How is #3 legitimate? From some quick googling the very complaints seem to be about trying to use #pragma once with files that expect to be #included multiple times - which just doesn't make any sense anyway. The other complaints about #pragma once of headers by different paths seems like an implementation problem in the compiler (if the file resolves to the same real path) or just a plain stupid issue of making copies of a header.
Code Complete is a good place to start.
A "friend" of mine emphasized C++ on his resume after skimming a "learn C++ in 24 hours" type of thing. He literally couldn't write hello world without google. Apparently had a ridiculously easy interview with no code test, got a job as a C++ developer. As it became clear he had no idea what he was doing, there was some animosity at work...
`#pragma once` is objectively not well-defined, and it objectively is not supported everywhere. It's not more readable either. 
At least one compiler reads it as "nothing with exactly the same content".
Well they're asking stupid questions, which usually means they're stupid. :)
I suggest you read http://en.wikipedia.org/wiki/Pragma_once.
Thanks!
It's for a third-party library that is used extensively throughout my code base. So I include that library's header files in stdafx.h, just as I would/do include &lt;iostream&gt;, &lt;vector&gt; and other libraries that are not part of my project. Are you suggesting I should #include those headers again in the cpp files that use that library, even though they are already present in stdafx.h? Edit: Answering my own question: Yes, even when precompiled headers are used, every source file should #include the headers that it needs to compile, even if those headers have already been included in the pre-compiled header. The extra headers will not be re-compiled if they have already been pre-compiled, but this will still allow the same source code to compile in environments that don't support pre-compiled headers. I've been writing C++ code since 1990. I still keep learning new things. Thank you for bringing this to my attention, /u/femngi.
&gt;It's a lot easier to read, why should you have to write 3 lines of code, when 1 can do it? Writing less code is unimportant if that code has completely undefined semantics and is wildly inconsistently implemented across platforms. &gt;While this is correct, it is implemented by all major compilers. Also, how do you think things like this become standard? Not by being rejected by the committee for being unimplementable - hard links, soft links, NTFS subst, etc. all make it virtually impossible to have any sort of sensible "it's the same if they're at the same path" semantics, and different line endings make it impossible to have any sort of sensible "it's the same if they hash the same" semantics. &gt;This is a legitimate point, but I still feel that this argument falls under "premature optimization". I see no reason to start using verbose header guards for all my projects, when a small fraction of them ever leave the comfort of my hard drive. And should a day come when I get an issue filed saying that the pragmas are causing problems for a user, then replacing them would be a simple enough task that I wouldn't trade it for easier development. It's not premature optimisation to say "I'm not using this feature that was rejected by the committee for not being sanely implementable, because it isn't sanely implementable." That's not optimisation at all. It's optimisation for correctness, but that is never premature.
&gt;`#pragma once` is a de facto standard. It is so well established across all compilers with consistent behavior that it's omission from the standard is a formality (in terms of cross-portability). No its omission from the standard is a recognition of the fact it has wildly varying semantics. &gt;Perhaps you're unaware, but compilers apply a speed-optimization to include guards already so that #includes can get skipped. #pragma once applies this same speed-optimization except without needing to explicitly specify #include guards. #include guards are also a de facto standard by the way - the standard makes no mention or recommendations about them. `#include` guards don't need to be 'explicitly mentioned in the standard' because their semantics are defined in the standard. The standard doesn't specify what `1 + 1 + 1 + 1 + 1` does, but you can work it out by applying the rules of C++. Similarly you can work out what `#include` guards do by reading the standard. Not so for `#pragma once`. `#pragma once` has literally no benefits. &gt;Also, most real world code I've ever seen has had to rely on compiler-specific options anyway All of those things sound very 1995. &gt; I don't see this, which is far more portable with consistent semantics, as any more deserving of avoidance. It's not portable, and the semantics aren't even remotely consistent. Have you never heard of a soft link? A hard link? Multiple filesystems? Network filesystems? Different line endings on different platforms? Files being moved by build systems? These things all exist and happen and they are the reason that it was rejected for standardisation as unimplementable.
That doesn't make any sense. At all. You are calling this `create` function on what, exactly?
`std::vector&lt;_Tp&gt;` etc. 
&gt;C++ is already moving in an "easier to write and maintain, use tools to grok" direction with auto. Are you drunk, bro? `auto` has nothing to do with tools. 
What would you prefer? Fucking GC? 
NP. Your question basically boils down to "how do I write good code", and there's no easy answer. It takes experience, coupled with learning from those with experience. Code Complete is a pretty good book on the matter, and there are many others. I'm also in scientific software; you might want to check out "Scientific Software Engineering: The Object-Oriented Way".
If you're going to attack a popular library, at least make the effort to explain *why* you dislike it.
&gt; You can't understand it by reading the standard. I was referring to the code, but I'll concede its a minor difference &gt; You don't need to maintain header guards. Until they conflict, and you start concatenating long "random" characters to the end, and then you end up with the point above. I can't rebut your last point as I havn't used more than one compiler for c++ in years.
Auto makes the code more difficult to grok at first sight by hiding the actual type of the variable from the reader. It makes the code easier to write and maintain by forcing you to program against interfaces instead of types. You can overcome the increased difficulty of analyzing auto'd variables by using an IDE or another tool that can tell you the actual type of a variable (or the return value of the function that spawned it).
&gt; It's red highlighting lots of identifiers that come from include files included in my project-wide stdafx.h file. I hope that is intended behavior. I think all cpp files should be compilable even if the precompiled header include is removed. I view precompiled headers solely as a build optimization, and I wish they (somehow) didn't actually include their symbols into the cpp file. They shouldn't change the normal C++ practice of always including all necessary headers and not relying on the implementation details of one header to accidentally pull in another you happen to need as well. This way the contents of the precompiled header can change without breaking the rest of the code. That said, I've seen enough projects that use precompiled headers as a default include dumping ground to also want an option to disable the warning.
&gt;Auto makes the code more difficult to grok at first sight by hiding the actual type of the variable from the reader. Which of these is easier to understand? auto i = v.begin(); -- std::vector&lt;int&gt;::const_iterator i = v.begin(); You don't need to know the type of something to be able to understand what code is doing.
&gt;A recent example: I worked on a routing problem where several vehicles visit a set of nodes. At the end I wanted to look at fill rates (sum of workload assigned to vehicle, divided by capacity). To do this from the main, I had to go through Optimizer-&gt;Algorithm-&gt;Solution-&gt;Route-&gt;NodeList and loop over its elements. It makes sense to give the Route class a GetFillrate() function and the Optimizer a GatherReportData() function, but that still leaves 3 levels of nesting to tunnel through. 1. Pedantry warning: Your names are nonstandard. The standard naming convention in C++ is `lowercase_with_underscores` for everything except template parameter names. 2. This sounds like a lot of indirection, and `NodeList` sounds like a linked list. bleurgh. 3. What is an Optimiser? It sounds like it's a class, why does that have to be a class? 4. Why is an Algorithm stored in an Optimiser? Algorithms usually work on data. They aren't really nouns, they aren't stored in things. They're functions, usually. 5. What is a Solution and why is it stored in an Algorithm? Sounds like you want to write: auto routes = routing_algorithm(input_data); for (const auto&amp; route : routes) { // calculate the fill-rate for that route } where calculating the fill-rate for the route probably involves `std::accumulate` with a lambda to sum (v.workload / v.capacity for each v in route.vehicle).
&gt;Until they conflict, and you start concatenating long "random" characters to the end, and then you end up with the point above. How would they conflict? something that is part of the XYZ project at the directory path include/abc/def/ghi.hpp should look like: #ifndef XYZ_ABC_DEF_GHI_HPP_INCLUDED #define XYZ_ABC_DEF_GHI_HPP_INCLUDED // etc. #endif
Have you met Bjarne? I have. I was in the same lab for grad school. He's certainly not going to complain about the money, but that's not the real reason. He has grandchildren in the area. They aren't in College Station, where Texas A&amp;M is located. He wanted to be closer to family. You seem like you have an axe to grind. Not everyone at the top is as greedy as you seem to think.
&gt;You are right, it should, but what happens is some library you include ends up using the same silly #ifndef TREE_NODE_GUARD ... or some such. Not really sure how that's worse than a library dumping something into a global namespace or something.
Is it a factory? `auto car = myAbstractCarFactory-&gt;buildCar()`? where `myAbstractCarFactory` is a pure virtual/abstract...
A managing director (which he is) at an investment bank makes about half a mill BEFORE bonuses. Which are regularly more than a couple of million bucks. He was being underpaid at Texas A&amp;M for what he brings to the table. 
Yeah and at Morgan Stanley. Flash trading algorithms. Machine learning. Virtually unlimited resources. (Need a whole building in New York with a fat pipe to the stock market? Done!) World-class programmers. A pile of money. Nice work if you can get it. Come to think of it, AI is probably gonna come from the stock market.
Personally, I like to sit down with clean white sheets of paper and I do basic UML class diagrams. BUT, I do them fast... I purposefully make them messy, and when I encounter a problem or a better way I grab a new sheet, quickly copy the old stuff onto it and keep going.. in this way, I imagine I have saved myself countless hours of typing in code...
It's not, you can make more interesting/interactive UI with it. I wrote cross platform rendering library and noticed a lot of interest for developing GUIs with it (something I haven't anticipated at all when I released it): https://github.com/bkaradzic/bgfx#bgfx---cross-platform-rendering-library 
I would answer true. The `length` and `size` member functions of `basic_string&lt;CharT&gt;` are defined to return 'the number of `CharT` elements in the string'. Clearly in the context of C++ std::basic_string, 'length' means 'the number of `CharT` elements' i.e. for std::string, 'length' means 'the number of bytes'. Given that he said "I guess the question is a little bit ambiguous" and "the question can be understood as asking..." rather than "the question clearly asks..." you should probably get *at least* partial marks. 
Your instructor is wrong. `std::basic_string&lt;CharT&gt;::size()` returns the length, in `CharT`, of a string. In ASCII, this is the number of bytes; in UTF-32, this is the number of 32-bit multichars. Try it for yourself: #include &lt;string&gt; #include &lt;iostream&gt; std::string char_str = "Hello, world!"; std::wstring wchar_str = L"Hello, world!"; std::u16string char16_str = u"Hello, world!"; std::u32string char32_str = U"Hello, world!"; int main() { std::cout &lt;&lt; char_str.size() &lt;&lt; ' '; std::cout &lt;&lt; wchar_str.size() &lt;&lt; ' '; std::cout &lt;&lt; char16_str.size() &lt;&lt; ' '; std::cout &lt;&lt; char32_str.size() &lt;&lt; ' '; return 0; } The output is `13 13 13 13`.
Why would someone write this: char* buffer = (char*)malloc(BUF_SIZE * sizeof(char)); when they could write this: std::vector&lt;char&gt; buffer(BUF_SIZE);
The question is ambiguous: does he mean the logical length (what we see, the intended length), or the physical length (what the computer sees, the implementation length)?
Because C++11 is a *new language** * but please wait until C++17 for us to work out all the kinks we introduced
I still need to double-check this, but I think I can remove those CMake files from my repo completely. They seem to be regenerated by bii, when I run "bii configure". If that is the case, there won't be any absolute/plaform-specific paths in the repo...
I would.
Yeeeeeaaaah. I don't think you can get much better backup than STL himself, OP. Maybe Bjarne. 
That is why we love you STL, I have done a few interviews in the past and in some of them I even lost the temper and told directly the interviewer "don't you realize that question is really bullshit?". Awwww god ... btw I didn't get that job xD.
Why don't you just include the PCH directly? I'm confused. If the files are inside it, then they'll be included as well, whether PCHs are supported or not.
\*sigh* They're going the VAX route of being super expensive.
A quick google tells me that 3NF is about database normalization. I don't think that's exactly what I'm looking for. Could you provide an example where 3NF is applied to "internal data" of a program only?
From the C++ standard: &gt; Returns: A count of the number of char-like objects currently in the string. So I guess, both of you are wrong about size().
I would have responded with "yes, of course" Then &gt; Instructor: "It is not correct. The reason being that the size function returns the size in terms of bytes. The function is blind to the underline encoding. Therefore, the value (number of bytes) may not match with the actual number of character that were encoded. " Then I would reply with, "Do you intentionally word questions ambiguously because belittling people makes you feel intelligent or are you poor at communicating in general?" Because, I become a smug asshole when dealing with smug assholes. I probably would not last long with petty teachers.
I see what you did there.
I hate these kind of questions. They aim at a specific facts that can easily be misinterpreted, overseen and often you can't be sure which of the 495 alternatives you can interpret them is meant this time.
Imho the question reveals the shortcomings of the ``std::string`` API... imho a good string API *must* provide functionalities to get the number of code points - the *size* in Bytes however is not very interesting for the domain of a string. The problem is indead, that C++ lacks a clear separation of string and bytes, whereas other languages emphasize this. The simple wrapping of ``char *`` is a mess nowadays...
Compliant compilers do.
&gt;You are calling it on derived instances, held through a base pointer or reference, in order to construct a new instance of the same class you call create on (as you do not know it's concrete type). How often are you doing all that `virtual`/runtime polymorphism/base-reference-to-derived shit anyway?
I know. As I said, I never used this pattern (and the one time when I needed to use cloning, I did so through a [non-intrusive implementation](http://codereview.stackexchange.com/questions/54371/polymorphic-owned-reference-wrapper-for-class-hierarchies)). I just mentioned it because it is apparently a documented pattern.
That's funny, I expected length() to give the number of characters and size() to be the size in bytes. ... I'd have gotten this question right according to the instructor, but wrong according to C++. That makes this a very bad test question indeed.
The instructor is right. Consider the UTF-8 case for example. Edit: I realise the disagreement here comes only for the ambiguity of the question.
True, but I had to learn that on Reddit for some reason.
Haha, yes.
I did the same mini-project recently, but played it through pulseaudio instead.
Old habits die hard. I'd also probably use std array here over vector if I did it again.
He's wrong both ways for being ambiguous. The only correct answer is an ambiguous one. &gt; "If you want to know the length of the string that is stored in a string object, you can call the object's size member function." Maybe. 
Ask again later.
It does strike me odd why python uses True and False. Python was my first language, so when I started learning Java it made so much more sense to use true/false rather than the capital letters. I just don't get why they would do that. 
I don't know the names of every compilers that ever has been, is, or will be written that was, currently is, or will be at some point in the future standard-compliant. Writing correct code isn't just about it being compilable today. 
None (hehe see what I did there?) of python's built-in types are capitalised. `str`, `int`, `bool`, `list`, `dict`, `set` are all lowercase. But all of Python's built-in singleton values are capitalised: `None`, `True`, `False`, etc. 
No, 20 minutes is not a small project. I work on a BIG c++ project, but it doesn't take anywhere near 20 minutes to compile. Your project is structured awfully. Fix it.
Yeah, thats my bad, I re-read it and I immediately edited that to say constants.
Thank god. 
&gt;On the other hand, Python is this very friendly, easy to understand interface for beginners, but at the same time you can overload __eq__() - you can still easily shoot yourself in the foot[2] , but hey, you can potentially use it if you know what you're doing. I disagree that that is shooting yourself in the foot. The language has clear and obvious reasons for not defining `__hash__` if you define `__eq__`. 
Sorry but C++99, C++03, C++11, and C++14 are all versions of the same language: ISO C++. It is not a new language. 
but its messed up that they should be in the header. you should be able to prototype member functions without seeing the full definition of the class, just as you can prototype free-functions. That should extend to conversions &amp; constructors inlining can be done further downstream in the build process actually what am I saying. you shouldn't have to prototype things at all. But as we are at the minute, where prototypes are needed, you should be able to partially prototype data &amp; functions to choose what you do and don't expose , and limit dependancies for recompiling, and to make it easier to decouple dependancies between files generally.. benefits for project organization and code re-use
&gt;but its messed up that they should be in the header. No it isn't, they're part of the interface. &gt;you should be able to prototype member functions without seeing the full definition of the class, just as you can prototype free-functions. Member functions are shitty anyway. Classes in general are shitty.
&gt;I'm also in scientific software; you might want to check out "Scientific Software Engineering: The Object-Oriented Way". God that sounds awful. 
What do you think a database is, if not a way of organising data? I don't think /u/kkrev is actually saying "put it in a DB", but DBs are organised as they are because it's usually the most efficient and most sensible way of organising data - in a 'tabular' fashion. 
Oh right `BUF_SIZE` is static const. It should be `buf_size`, btw, it's not a macro. And yeah, `std::array`. 
&gt; it's a string of ``char`` Imho there is **no** reason for a "low"- or "high"-level string interface, because nobody would expect that. A string is just a string and the meaning is very clear in common: A sequence of Characters (aka Codepoints, Glyph or whatever synonyme!) - but clearly **not** a sequence of a 8-Bit data type ``char``. What you describe would rather be a ``std::vector&lt;char&gt;`` - so why call such a construct ``string``? 😉 (We have more basic slogans for that than string, e.g. vector, list, sequence...) Btw. other languages have often a clear distinction between a string (by its common meaning) and a sequence of bytes for **encoded** "text" data. So ``std::string`` is definitly (of course for historic reasons) a confusing and often missunderstood type. And yes, therefore I believe, that this is a poor design nowadays, as C++ is quite isolated by its meaning of "string". And forcing polyglot developers to do **mental mapping** is never a good thing...
All the GUI libraries in the universe suck.
Haha... that sounds pretty awful.
This comes from my own personal little C++ toolkit. I'm posting it here because it's turned out to be all sorts of useful and thought others might be able to make use of it.
Nice! Granted, my local version of SmartObject has extra stuff in it I pulled out for the public version because otherwise I'd have to post the entire toolkit which is extremely incomplete. I guess this stripped-down version isn't *quite* as useful as I thought. Still, makes for a nice reference for those who want to write their own and get the memory fence semantics correct. (I had to make updates after watching a Herb Sutter video on the subject and found I had got a few things wrong. :) )
rumor says his Morgan package is $800k+
Yeah, quite obviously not gonna hire someone who doesn't work well within the contraints of the situation :) 
For a license for an individual developer, a VAX license is actually the same price as a ReSharper C++ license. Plus, JetBrains actually makes its software available for free for students; Whole Tomato gives a 50% discount for VAX for students. JB also gives its software away if it's going to be used to contribute to open-source projects, and startups get 50% off. Honestly, for a tool at the level of VAX or R#/R#C++, $100 for a perpetual license (with a year subscription to updates including major versions in the case of R#C++) is really not that bad.
That's what I was doing in the first place. My current project is a moderate-sized project with ~10K lines of code. My PCH file currently includes 35 headers from the standard library and other third-party libraries. If the platform didn't have pre-compiled header support, it would be wasteful of compiler time to include all 35 header files in every source file, when most source files need a small subset of them. But honestly, this isn't a cross-platform project. This project will always be compiled with Visual C++. So I don't think I was committing *that* big of a sin with my previous practice. The only real downside, and what started all of this, was that ReSharper C++ couldn't follow the PCH file include to find my dependencies.
*woosh*
"Variable templates" and "Relaxing requirements on constexpr function" are sure on the list. [C++14 features supported](https://software.intel.com/en-us/articles/intel-c-compiler-160-for-windows-release-notes#cpp14) I will need to check how well they really work. 
Be careful - if your mental model is "`length()` is the number of bytes", you'll misuse `wstring::length()`, `u16string::length()`, etc. My mental model is: for `basic_string`, `length()` is a silly synonym for `size()` (I always use `size()`), `size()` returns the number of elements like it does for real STL containers, and `basic_string` is the honey badger of types: `basic_string` don't care what your elements are, they could be UTF-8 or UTF-16 where code units differ from code points.
Hmm, we could tighten this up to be binding. I'll add this to my list of Library Issues to write up.
the most "complete" that I found is http://cpprocks.com/c1114-compiler-and-library-shootout/ but already 1 year old.
C++17 is where it's at. Bring on the modules!
My main concern is that I'd basically have to pay that yearly, which now ends up being more than what I pay for Visual Studio, since it's free. IMO Microsoft should've bought VAX long ago, and implemented it as basic IDE usage.
&gt; A sequence of Characters (aka Codepoints, Glyph or whatever synonyme!) Except these aren't synonyms at all. Multiple code points can map to one glyph (e.g., combining characters), or a code point can map to zero glyphs (e.g., zero-width joiner), or a glyph can map to two characters (e.g., ligatures). The meaning of the length of a string changes depending on what you're doing. It's not like other languages don't have problems either. If you get the length of a string containing a surrogate pair in C# you'll get 2 instead of 1. Is it wrong? It depends. C++ simply makes no attempt to deal with the issue and doesn't make any claims to. If your use case requires proper Unicode handling then you need to use something up to the task like ICU.
Wow! So much time in, dare I to say, low priority feature while modules for example are still not so sure for C++17?
Yea that's unfortunately much too old!
That would be ambiguous and really hard to parse. 
In what situation though? I can't think of an example where it would be ambiguous.
Underscores stand out better and don't have the issues of spaces IMO. 1_000_000 or 1'000'000? 
&gt; Ahhh... the downside of being so nice and approachable. Right. The trick is to know a bunch of stuff and be a raging asshole nobody wants to talk to. Then you only get asked questions when it's really important ;)~
As posted by [/user/pnKYe4IIA](http://www.reddit.com/user/pnKYe4IIA), in [this paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3499.html#Approaches) you can see some approaches they looked at and why they were dropped, including [undescores](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3499.html#Underscore).
The students are bearing with the idiocy, and also trying to get the professor to maybe stop doing that a little bit someday. He is a new professor, so there's a little bit of hope, but not terribly much.
Every one had drawbacks. I think the underscore was still the best choice.
Don't worry, I didn't take your response as snarky.
In my last small project, thanks to boost::string_ref, I found std::string to be the most convenient container for storing the bytes of a compressed image^^pleasedon'thurtme .
One group of people working on one feature does not slow down an entirely separate group of people working on an unrelated feature.
They use the stdlib from the system.
I'd go as far as saying it is the most important and biggest C++ conference. It emerged from the [Going Native](https://channel9.msdn.com/Events/GoingNative/2013) conference, just have a look at the speaker list and you'll see. I can't answer how big it is as I haven't been there, but from what you see in the videos, I'd say around 500 people?
And I think the bike shed should have been green, but I think it's ok when it's blue too.
I tried out the pre-release version about a month ago. Not too surprising it was rather buggy, very slow and frequently choked on our large source base. However, it does have a lot of promise if they get it stable and optimized. I'm looking forward to a lot of these features.
If you are on Windows then you use STL shipped with Visual Studio. If you are on OS X then you use [libc++](http://libcxx.llvm.org/) or [GNU's libstdc++](https://gcc.gnu.org/libstdc++/).
You must be very hard to please if intellij sucks balls :(
:-) indeed, in one way or another.
I tried in the BETA last month, back then it really didn't compete with Visual Assist because; * Theres no C++/CLI support * It doesn't play well with Visual Assist (macros break, multiple intellisense engines running etc.) * it had plenty of bugs and threw loads of exceptions (though i'd assume most of this has been fixed by now) 1. It's missing some features that VA has. However, Resharper is completely free for students which is a huge bonus considering you have to pay for VA no matter who you are.
As Alf said in answer, C++ `std::string` does not use reference counting. All "fast" parsers use something akin to `std::experimental::string_view`, the only requirement being that the moment pointed to remains alive of course.
Hmm, been using Resharper for a while now in C#, I might give this a try
No C++/CLI support: true. We'll think about this later on. Pre-release builds throw loads of exceptions so that you are able to report them. In release builds if there are any, they're simply happening behind the scenes. What are the missing features though? I'm aware of some but which are important to you?
What happened to CLion then? 
Ok, what is ReSharper?
&gt; You can't understand it by reading the standard. If you are learning C++ by reading the standard, you are doing something fundamentally wrong. Also, if your definition of "easy to read" is the C++ standard, get your head checked. If you are looking for compiler pragmas in the C++ standard, you will find: &gt; 16.6 Pragma directive [cpp.pragma] &gt; 1 A preprocessing directive of the form &gt; § 16.6 435 &gt; c ISO/IEC N4296 &gt; # pragma pp-tokensopt new-line &gt; causes the implementation to behave in an implementation-defined manner. The behavior might cause &gt; translation to fail or cause the translator or the resulting program to behave in a non-conforming manner. &gt; Any pragma that is not recognized by the implementation is ignored. So, you are looking for compiler specific info from the standard, instead of, say, the compilers own manual? How smart of you.
Am I just missing something? Where is the code for split7 on the SO post? Also, it would be nice if there were basic unit tests to make sure that something so fast is actually producing correct results. *edit: why the downvote? I was sincere about that question.
Sure but the sizes are still specified somewhere in your code when you instantiate.
&gt; VAX https://www.google.nl/search?q=VAX&amp;oq=VAX&amp;aqs=chrome..69i57j0l5.381j0j7&amp;sourceid=chrome&amp;es_sm=91&amp;ie=UTF-8 Which one?
I made another version that I believe is way faster. https://github.com/Andersbakken/string-splitting/commit/c9faf2b4fa3d0cbe1f3904fc1da5309a1ef95d96
Just to complement [/user/Elador](http://www.reddit.com/user/Elador)'s answer, if you wanna know more about the conference you can have a look at their [youtube channel](https://www.youtube.com/user/CppCon/), where you can find videos of most of last year's talks.
They seem to take all the feedback seriously, and I don't know yet of any comparable alternative that'd "just work" for that example I described in the blog post with downloading Boost and configuring CMake... I think there is some discussion inside Boost community to create a similar kind of tool... I think it's one of the big gaps in C++ toolset...
It is not, size() returns the amount of the underlying type it uses. So even though it's 14 bytes (on windows), it actually has 7 wchar_t's in there.
In Microsoft STL implementation one can find this definition: #define _ATOMIC_MAXBYTES_LOCK_FREE 8 On my machine it is in the: "C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\include\xatomic0.h" I remember seeing similar definition in earlier MSVC STL implementations too, but not 100% sure they were in the same header file. As far as I understand, MSVC STL atomic&lt;T&gt; simply compares sizeof(T) with this threshold for being lock-free. GCC STL implementation also seems to make the decision based purely on sizeof(T), though I coudln't find the definition of the threshold... 
Oh hey, I never even thought of that. You'd have to kind of work at it to get that scenario to arise, but C++ is good at making the improbable likely.
Can't. It's 2000 lines and owned by a publisher. ;)
Not code that I am the most proud of, but a func bit of code for a member function callback that can detect if the object is still alive without keeping the object alive constantly. template&lt;typename... Args&gt; class CallbackBase{ public: virtual void Call(std::tuple&lt;Args...&gt; arg_tuple) = 0; virtual bool On() = 0; virtual void Off() = 0; }; template&lt;typename ClassName, typename... Args&gt; class CallbackDerived : public CallbackBase&lt;Args...&gt;{ private: std::function&lt;void(ClassName*, std::tuple&lt;Args...&gt;)&gt; func_; std::weak_ptr&lt;ClassName&gt; w_ptr_; std::shared_ptr&lt;ClassName&gt; s_ptr_; bool on_; public: CallbackDerived( void(ClassName::*func)(std::tuple&lt;Args...&gt;), std::shared_ptr&lt;ClassName&gt; s_ptr ) : w_ptr_{ s_ptr }, on_{ false } { func_ = [=](ClassName* raw_ptr, std::tuple&lt;Args&amp;&amp;...&gt; arg_tuple) { (raw_ptr-&gt;*func)(arg_tuple); }; } // virtual funcs void Call(std::tuple&lt;Args...&gt; arg_tuple){ if (!on_){ On(); } func_(s_ptr_.get(), arg_tuple); }; bool On(){ on_ = true; // try cast to bool return (s_ptr_ = w_ptr_.lock()) ? true : false; } void Off(){ on_ = false; s_ptr_.reset(); } };
If you ever actually dereference `blah`, that's UB...
A bit silly, and a very very simple, but it's the sort of simplicity that strikes you as "why didn't I think of this sooner?": #define OUTPUT(x) #x&lt;&lt;"= "&lt;&lt;(x)&lt;&lt;std::endl allows me to do the following: cout &lt;&lt;OUTPUT(theta) &lt;&lt;OUTPUT(t) &lt;&lt;OUTPUT(cos(theta*t)) ; and get the output theta=0.1 t=1.2 cos(theta*t)=0.9928086358538663 I actually have more advanced versions that accept multiple parameters at once, but that code is way too long to be here. 
You do know that that whole thing is totally unnecessary, right? template&lt;typename T, typename F, typename... Args&gt; std::function&lt;void(Args...)&gt; callIfAlive(std::weak_ptr&lt;T&gt; weak, F f) { return [=](Args... args) { if (auto sptr = weak.lock()) f(sptr, args...); }; } Now you can call any function object based on any other object being alive, it's far neater, etc.
It absolutely was.
and somewhere else? :)
Come for smart code, stay for the rude internet jocks. ;)
Some functional stuff to simulate parameters with only a member variable : static void parsePathChanged(Map&amp; map, const std::string&amp; message) { json_map obj{message}; std::string path = JSONParser::valToString(obj.get("path_changed")); json_assert(map.has(path)); auto getter = [] (auto&amp;&amp; member) { return [&amp;] (auto&amp;&amp; p) -&gt; auto&amp; { return p.*member; }; }; auto mapper = [&amp;] (const std::string&amp; name, auto&amp;&amp; getter, auto&amp;&amp; method) { if(obj.find(name) != obj.end()) map.update(path, [&amp;] (Parameter&amp; p) { getter(p) = method(obj.get(name)); }); }; mapper("description", getter(&amp;Parameter::description), &amp;JSONParser::valToString); mapper("tags", getter(&amp;Parameter::tags), &amp;JSONParser::jsonToTags); mapper("access", getter(&amp;Parameter::accessmode), &amp;JSONParser::jsonToAccessMode); mapper("value", getter(&amp;Parameter::values), &amp;JSONParser::jsonToVariantArray); mapper("range", getter(&amp;Parameter::ranges), &amp;JSONParser::jsonToRangeArray); mapper("clipmode", getter(&amp;Parameter::clipmodes), &amp;JSONParser::jsonToClipModeArray); }
I came here to realize that my cpp skills need improvement, lots of it.
Really just convenience, but //This part isn't mine, but I got it on stackoverflow and it's really handy #define AUTO_FUNCTION_BODY(x) -&gt; decltype(x) { x; } //This is mine template&lt; class Args... &gt; auto zipWith( Args &amp;&amp; ...items ) AUTO_FUNCTION_BODY( boost::make_iterator_range( boost::make_zip_iterator(boost::make_tuple(std::forward&lt;Args&gt;(items).begin()...)) , boost::make_zip_iterator(boost::make_tuple(std::forward&lt;Args&gt;(items).end()...)))) Basically it's a shortcut so you don't have to write all of that garbage and can just write for(auto &amp; itemPair : zipWith(container1, container2)) { //do something }
It's stuff like this what makes me appreciate Python so much.
This object doesn't force you to dynamically allocate it. With the class: class MyObject : public Core::SmartObject { ... Direct stack allocation in an array: std::array&lt; MyObject, some_constant &gt; array_on_stack; Dynamic heap allocation: Core::SmartPtr&lt; MyObject &gt; heap_alloc_object = new MyObject(); I often need both approaches with the same class so I made sure this worked. :) *Edit: I've updated the README.md file in the repository to demonstrate this.*
Not most proud of but kind of handy. It's just a helper function that reads a series of arguments from an input stream and calls a function with those arguments. I use it for a command line in a game. template&lt; typename FuncT, typename... BoundArgs &gt; struct CallFromStream_ { template&lt; void * v &gt; static std::string call( std::istream &amp; stream, FuncT func, BoundArgs... boundargs ) { return func( boundargs... ); } template&lt; void * v, typename T, typename... Args &gt; static std::string call( std::istream &amp; stream, FuncT func, BoundArgs... boundargs ) { T t; stream &gt;&gt; t; if( stream ) { return CallFromStream_&lt; FuncT, BoundArgs..., T &gt;::template call&lt; static_cast&lt; void * &gt;( nullptr ), Args... &gt;( stream, func, boundargs. .., t ); } else { return "Invalid input"; } } }; template&lt; typename... Args, typename FuncT &gt; std::function&lt; std::string( std::istream &amp; ) &gt; CallFromStream( FuncT func ) { return [func]( std::istream &amp; stream ) -&gt; std::string { return CallFromStream_&lt; FuncT &gt;::template call&lt; static_cast&lt; void * &gt;( nullptr ), Args... &gt;( stream, func ); }; } You can then create a map of functions, e.g., consolefuncs.insert( { { "set-global", CallFromStream&lt; std::string, float &gt;( std::bind( setGlobal, std::ref( game ), std::ref( globalVariables ), _1, _2 ) ) }, { "get-global", CallFromStream&lt; std::string &gt;( std::bind( getGlobal, std::ref( globalVariables ), _1 ) ) }, { "quit", CallFromStream( exitButtonFunc ) }, { "exit", CallFromStream( exitButtonFunc ) } } ); and have a function that reads the command name and calls the appropriate function: std::string inputstr = consoleinput-&gt;GetText( ), cmdname; std::istringstream stream( inputstr ); stream &gt;&gt; cmdname; if( consolefuncs.find( cmdname ) != consolefuncs.end( ) ) { std::string output = consolefuncs[ cmdname ]( stream ); if( !output.empty( ) ) { consoleoutput-&gt;AddText( output ); } } else { consoleoutput-&gt;AddText( "unrecognized command" ); } 
This.
Plus, there isn't going to be any technique that could possibly be more optimal than an if/else, since at some point the code *has* to branch and decide whether it's going to push a float or an int onto the stack.
Is a function that takes JSON Arrays and transforms them into SQL Tables bool Controller::insertTableFromJSON(const QString &amp;name, const QJsonArray &amp;data) { QSqlQuery query(QSqlDatabase::database()); const int ncols = data.size(); const int nrows = data.at(0).toObject().value("values").toArray().size(); QStringList col_names; QStringList createVals; for(int i = 0; i &lt; ncols; ++i){ QString col_name = data.at(i).toObject().value("name").toString(); col_names &lt;&lt; col_name; createVals &lt;&lt; QString("\"%1\" TEXT").arg(col_name); } QString create = QString("CREATE TABLE %1 (%2)") .arg(name) .arg(createVals.join(",")); if(!query.exec(create)){ qDebug() &lt;&lt; query.lastError().text(); return false; } QStringList values; QString query_string = QString("INSERT INTO %1 (%2) VALUES ").arg(name).arg(col_names.join(",")); for(int row = 0; row &lt; nrows; ++row){ QString vals; for(int i = 0; i &lt; ncols; i++){ QJsonArray values = data.at(i).toObject().value("values").toArray(); QString value = values.at(row).toString("NULL"); if(value.replace(" ","").isEmpty()){ value = "NULL"; } vals += QString("\"%1\",").arg(value); } vals.remove(vals.lastIndexOf(','),1); values &lt;&lt; "(" + vals + ")"; if(row % 400 == 0 &amp;&amp; row &gt; 0){//SQLITE Limitation QString query_string_temp = query_string; query_string_temp += values.join(","); values.clear(); //qDebug() &lt;&lt; row; if(!query.exec(query_string_temp)){ qDebug() &lt;&lt; "E_" + query.lastError().text(); errorMessage("Error al insertar tablas"); return false; } } } if(values.size()){ query_string += values.join(","); //qDebug() &lt;&lt; "f_row"; if(!query.exec(query_string)){ qDebug() &lt;&lt; "E_" + query.lastError().text(); errorMessage("Error al insertar tablas"); return false; } } return true; } 
A FizzBuzz solution that can scale to more number/word combinations! https://gist.github.com/TheBuzzSaw/5acda39a77343ce45fb3
Btw., use std::endl only if you really intend to flush the stream. Otherwise, use '\n' or '\r\n'. Although the underlying implementation might still flush if it's line based. (Source: http://en.cppreference.com/w/cpp/io/manip/endl)
Hey I saw the genetic algorithm in the ga.cpp and Im just wondering what exactly is it for? Generating a random board?
if you need to wrap a function that expresses sizes in ints instead of size_t and you're worried about sizes &gt; sizeof(int), then I wrote this little function: template&lt;class SIZE, class UPDATE&gt; bool numeric_limit_split(UPDATE &amp;&amp;update, size_t size){ while(size &gt; std::numeric_limits&lt;SIZE&gt;::max()) { if(!update(std::numeric_limits&lt;SIZE&gt;::max())) { return false; } size -= std::numeric_limits&lt;SIZE&gt;::max(); } return update(static_cast&lt;SIZE&gt;(size)); } Here's an example of me using it to wrap openssl: https://github.com/matthewaveryusa/utils/blob/c670060060017c7645f023be0d0b88c9dca29eaf/util_hash.hpp#L53
My favourite super-simple ones for debugging: #ifndef NDEBUG # define DEBUG(x) std::cerr &lt;&lt; x &lt;&lt; std::endl # define DEBUG_BLOCK(x) if (true) #else # define DEBUG(x) # define DEBUG_BLOCK(x) if (false) #endif Means I can write code like: DEBUG("The value of 'x' is " &lt;&lt; x); or, more verbosely DEBUG_BLOCK("Label") { int x = 1; DEBUG("Does x == 1? " &lt;&lt; x == 1); } Something more substantial: a macro that generates a 'does this class have a type called `T`'? (Note that I use `boost::` versions here just because I live in a word where I still cannot use C++11): #define GENERATE_HAS_TYPE_TRAIT(__NAME__) \ template &lt;typename T&gt; struct has_##__NAME__##_impl \ { \ template &lt;typename U, typename V&gt; struct SFINAE \ { \ }; \ \ template &lt;typename U&gt; \ static char test(SFINAE&lt;U, typename U::__NAME__&gt;*); \ template &lt;typename U&gt; static int test(...); \ \ static const bool value = sizeof(test&lt;T&gt;(0)) == sizeof(char); \ }; \ \ template &lt;typename T&gt; \ struct has_##__NAME__ \ : public boost::integral_constant&lt;bool, \ has_##__NAME__##_impl&lt;T&gt;::value&gt; \ { \ } Means I can write e.g. GENERATE_HAS_TYPE_TRAIT(key_type); and then do things like template &lt;typename T&gt; boost::enable_if_c&lt;has_key_type&lt;T&gt;::type, bool&gt;::type foo(...) {} I'd like to have a version of this for 'has function with some name', or 'has function with some signature', but to be able to do that entirely within a self-contained macro I (think) I need C++11 + `decltype()`.
No for generating moves to solve the game. Each child is a game played and we generate new children by mixing two games together. It's not an optimal solution at all, just a fun way of playing and a showcase of how you can use the library.
Oh so that's why you have the speed.cpp there? That's pretty cool though!
Where to find more information on that library? That page seems a bit broken to me without login...
Huh, I've done something similar :P #define PEXPR(expr) #expr , "=", expr It is for my logger, which uses variadic templates. Usage is like this logger.warn("Something is wrong, ", PEXPR(variable)); Assuming variable is int with value 42, it would print 'Something is wrong, variable=42'
Generic static observers with scope-based lifetime. http://pastebin.com/KTnVvQcF Also, support for result aggregation, though I haven't found a valid use case for that yet.
Thanks :)
Several things, but nothing big to brag about. The things that have the largest amount of functionality are also so poorly written that I dare not to share them. But anyway: * [double_integer&lt;T&gt; template](http://tringi.trimcore.cz/int128) to make myself 128-bit, 256-bit and even larger integers with *native* little-endian P.O.D. memory layout * [ad absurdum templated hierarchical parser/serializer](http://tringi.trimcore.cz/Brace_Cpp_Library) for my configurations and human-editable data files * [templated linear interpolation](http://emphasize.cz/trunk/ext/interpolation) optimized (precomputed) for floating point conversions * not much C++ but [abstracting and extending some Windows API](http://emphasize.cz/) with better parameters, usually dynamically using better function on later OS version, falling back to older API on older OS
Its still needed if you want to constrain the function as well.
Boost already has [`BOOST_MPL_HAS_XXX_TRAIT_DEF`](http://www.boost.org/doc/libs/1_57_0/libs/mpl/doc/refmanual/has-xxx-trait-def.html) which does the same thing. &gt; I'd like to have a version of this for 'has function with some name', or 'has function with some signature', but to be able to do that entirely within a self-contained macro I (think) I need C++11 + decltype(). What you need is Expression SFINAE, which is compatible with C++03, but is now required for C++11. So newer compilers such as gcc and clang will support Expression SFINAE in C++03 mode, you will just need to use `sizeof` instead `decltype`.
...hey good to know. Thanks!
I'm not proud of this because it's good coding or anything, but for a class I've manage to figure out how to make a BigInt class store numbers in base 10000 and do carry conversions without fully understanding exactly what base conversion was until after I got it to work with base 100. (I was just trying to break numbers up into chunks of two digits to make it faster to work with, and then scaled it up from there) It also works with base 2 (binary) if the original digit lengths are under 8. (If anyone has tips on how to make it look/function better, i'm all ears) BigInt::BigInt (string x) { int space = x.find_first_not_of ("\x20"); int sign = x.find_first_of ("+-", space); int begin = x.find_first_of ("012345679"); int end = x.find_first_not_of ("0123456789", begin); if (end == string::npos) end = x.size(); else end -= 1; if (space == sign &amp;&amp; (space + 1) != begin) exit (1); else if (space == sign &amp;&amp; space + 1 == begin &amp;&amp; x[sign] == '-') isNegative = true; string pun = x.substr (begin, end); //the part of the string containing digits unsigned long push; if (pun.size() &lt; 9) { // unsigned long = 10 digit long value, 9 is used push = stoull (pun); //so it doesn't go over; carry() takes care of the rest. data.insert (data.begin(), push); } else { int y = 0; if (pun.size() % split != 0) { //if it can't be evenly split, take out enough digits y++; //until it splits evenly. (max = split - 1) if ((pun.size() - 1) % split != 0) { y++; if ((pun.size() - 2) % split != 0) y++; } } if (y != 0) { //only used if it can't be split evenly push = stoull (pun.substr (0, y)); // and let carry() take care of the rest. data.insert (data.begin(), push); pun.erase (0, y); } while (pun.size() &gt; 0) { //continues to split the number evenly and delete the substr push = stoull (pun.substr (0, split)); pun.erase (0, split); data.insert (data.begin(), push); } } this-&gt;carry(); } And note: bass = base/10 and under is base-1 void BigInt::carry() { for (int i = 0; i &lt; data.size(); i++) { int g = data[i]; if (i == data.size() - 1 &amp;&amp; g &gt; under) { data[i] = g % base; data.push_back (((g / base) - ((g % bass) / bass))); } else if (g &gt; under) { data[i] = g % base; data[i + 1] += ((g / base) - ((g % bass) / bass)); } } }
if it's for debugging I'd want to flush.
Swaps if your values are ints... In C++11, you can just: ``` std::tie(b, a) = std::make_tuple(a, b); ``` or, shuffle a bunch of variables if you want :) ``` std::tie(b, c, e, a, d) = std::make_tuple(a, b, c, d, e); ```
Also a function pointer is an indirect branch that can flush the pipeline anyway.
I actually created a subreddit the other day for these kinds of things: /r/codenuggets It's somewhat overlapping with /r/codereview although the intent is a bit different. Either way it'll probably wither and die. :) 
Lightweight actor model. https://github.com/dicroce/cppkit/blob/master/include/cppkit/ck_actor.h Here is a link to a test that shows how to use it by implementing a simple actor class that simply adds the arguments its passed. https://github.com/dicroce/cppkit/blob/master/ut/source/ck_actor_test.cpp
UFCS is the worst piece of code obfuscation I've seen from the idiotic people submitting proposals to the standard yet. &gt;yes classes are shitty, because we don't have extention methods, being able to prototype methods outside a class would achieve that. UFCS would also be a solution, but we still have conversions /constructors. we should get extention methods for constructors too even if they can't access private Classes are not shitty because we don't have extension methods. Classes are shitty because `a.b()` is idiotic syntax. `b(a)` already exists and is superior. &gt;we DO want this : a.foo(b) - because it makes autocomplete work a dream: on the fly documentation search, or a "type-based search" -also method chaining a.foo(b).bar(c) is clearer than bar(foo(a,b),c)- and it lets you explore an object graph as you type (before anyone says "read the docs", the purpose of computers is to save us chores, and that should extend to the tools we use to program.). No, it doesn't. This is all just rubbish spouted by Java/C# developers that can't get away from their obnoxious, slow, terrible tools and their similarly awful syntax. &gt;we still want to decide which is the most important argument,we get the ability to change code to &amp; from vtable-dispatch, but we don't want to limit where functions that use that are declared, we still want to be able to separate dependancies out freely. There is no 'most important argument'. All arguments should be treated equally. &gt;We currently have an annoying conflicting draw to 2 syntaxes . your API is way more user-friendly if it uses member-functions , because of AutoComplete, but then you're stuck with the shittyness of classes you observe. Completely false. Your API should be intuitive. Being auto-completeable is completely and utterly irrelevant. &gt;stop pretending this situation is ok. You should get both benefits simultaneously. the language is BROKEN, lets get it fixed, FFS, its' not a difficult fix IMO. UFCS, and/or additions to how functions can be prototyped, thats' all it would take. The current situation is 100% okay. It is not "broken" just because incompetent developers create overly broad APIs that require autocomplete and IDEs to use. Stop trying to use C++ as fucking Java. holy shit. 
Sure, and there are plenty of things in every language that you can not know about. Maybe people should learn to read. This 'I shouldn't have to read documentation' attitude is fucking toxic. 
&gt;Eh. Why? For the target audience of people often used to Fortran77, it's a useful intro. Because OOP is a fucking nightmare of shittiness. It's the worst so-called paradigm ever to come out of the software development industry. It is occasionally useful and nearly always overused. &gt;Well, there's a lot of unique problems when trying to teach good software development to people in scientific computing. Typically I'm working with PhD students in hard sciences/engineering, and the book is good for those people who need to write code, but have no formal training at all. They should almost certainly just use Python and NumPy, honestly.
&gt;It is a GoF pattern, so it has to be good, right? Who would possibly think that everything "Getting around the pitfalls of trying to apply OOP to every problem, the book" would contain only good things? Code that rigorously applies the 'patterns' in that book is nearly always unreadable in my experience. &gt;When you can’t avoid global state, use a singleton. No. Do not use a singleton ever. If you need a global variable just use a global variable god damn it.
&gt; Because OOP is a fucking nightmare of shittiness. It's the worst so-called paradigm ever to come out of the software development industry. It is occasionally useful and nearly always overused. Edgy. &gt;They should almost certainly just use Python and NumPy, honestly. They and I work on 1,000+ cores on DOE clusters. We almost certainly should not just use Python and NumPy.
&gt;Edgy. I don't see what is edgy about that. It's heavily overused, especially in languages that force its use like Java and C#. C++ isn't one of those languages, so don't encourage its use too much. It's useful in a small set of circumstances and not useful outside those circumstances. &gt;They and I work on 1,000+ cores on DOE clusters. We almost certainly should not just use Python and NumPy. They should have formal computer science education then.
&gt; Who would possibly think that everything "Getting around the pitfalls of trying to apply OOP to every problem, the book" would contain only good things? A fair number of "enterprise" developers, especially in the Java community. I've even seen GoF patterns described with a kind of reverence on StackOverflow questions tagged [java] and [c#]. Hence "FactoryFactoryFactory" joke Factories.
I really dislike macro coding in C++. It just looks so inelegant. 
I wouldn't use the word *proud*, but this C-style macro is what I had to do to get around C++'s limitation of not being able to pass in floating-point constants as template parameters: [Mutatable_Value.h](https://gist.github.com/jrandom/62d6741e5d1eb65a8060) (I need the min/max values available so that a new randomly-set instance can be generated just by passing in a random number generator to the constructor, but didn't want to have to carry around the min/max values inside of each instance as that would waste a lot of memory.) You can [see them in action here](https://gist.github.com/jrandom/211810d2bcd0927f3c30).
* http://gameprogrammingpatterns.com/singleton.html &gt; Despite noble intentions, the Singleton pattern described by the Gang of Four usually does more harm than good. They stress that the pattern should be used sparingly, but that message was often lost in translation to the game industry. &gt; Like any pattern, using Singleton where it doesn’t belong is about as helpful as treating a bullet wound with a splint. * http://jalf.dk/blog/2010/03/singletons-solving-problems-you-didnt-know-you-never-had-since-1995/ &gt; A sin­gle­ton com­bines two neg­a­tive qual­i­ties. It takes the “you can never cre­ate a sec­ond instance of this class” con­straint, which hardly ever makes sense, and even when it does, does not typ­i­cally need to be enforced by the com­piler, and com­bines it with a global object, giv­ing us all the down­sides of both! &gt; Two wrongs don’t make a right. Not even if they were described as a good idea by some guys 15 years ago. &gt; . . . &gt; Most of the time, your classes should have neither of these attributes. Sometimes, rarely, they may need one of them. But the singleton pattern imbues the class with both properties, and that is just a plain bad idea. * http://www.object-oriented-security.org/lets-argue/singletons &gt; Singletons are just globals &gt; Singletons make code hard to follow &gt; Singletons make code hard to test &gt; Singletons make code hard to maintain &gt; Singletons make code hard to secure 
&gt; I don't see what is edgy about that. It's heavily overused, especially in languages that force its use like Java and C#. I was going to say, you sound like a bitter Java/C# person ;) &gt;They should have formal computer science education then. ... that's kind of the point - trying to give them a more modern look at software and at least think about how to write "good" software. It's generally not realistic to teach CS people how to solve the mathematical/physical problems these scientists are approaching, and it's not realistic to give practicing scientists a full CS curriculum. That's the niche where I recommend that book.
Well yeah morons will be morons I suppose.
You'd want to flush at the end of your output, not every time. So like: `cout &lt;&lt; "theta: " &lt;&lt; theta &lt;&lt; "\nt" &lt;&lt; t &lt;&lt; endl;` However, it's still likely to be irrelevant really, specially for debugging purposes.
Why not just have variadic templates with a logger class, then you could just write Log.Vars(theta, t, cos(theta*t));
You have an issue if an observer is destroyed with pending notifications...
I think it's because DeadMG basically assumed the code was useless and his version perfect when it may not be the case (and actually ends up it isn't). A better way to approach would be to ask why the simpler solution wasn't used, rather than state "that's useless, use this instead."
What exactly is the use of having that as the return type, vs just doing: template&lt;typename T, typename... Args, typename = std::enable_if&lt;is_string&lt;T&gt;::value, std::string&gt;::type&gt; void Recursive(T first, const Args&amp;amp;... rest) { m_line.append(first); Recursive(rest...); return m_line; }
If you're gonna just reinterpret_cast, there's no difference.
 template&lt;class Return&gt; class ArgErasedNode{ public: virtual ~Node(){} virtual Return eval() = 0; }; template&lt;class Return, class... Args&gt; class Node : public ArgErasedNode&lt;Return&gt;{ std::function&lt;Return(Args...)&gt; f; std::tuple&lt;ArgErasedNode&lt;Args&gt;*...&gt; args; template&lt;size_t... n&gt; Return call(std::index_sequence&lt;n...&gt;){ return f(std::get&lt;n&gt;(args)-&gt;eval()...); } public: template&lt;class F&gt; Node(F&amp;&amp; f, ArgNodes&lt;Args&gt;&amp;&amp;... args) : f(std::forward&lt;F&gt;(f)) , args(std::make_tuple(std::forward&lt;Args&gt;(args)...)){} Return eval(){ return call(std::make_index_sequence&lt;sizeof...(Args)&gt;{}); } }; template&lt;class Return&gt; class Node&lt;Return&gt; : public ArgErasedNode&lt;Return&gt;{ std::function&lt;Return()&gt; f; public: template&lt;class F&gt; Node(F&amp;&amp; f) : f(std::forward&lt;F&gt;(f)){} Return eval(){ return f(); } }; This is the gist of an abstract syntax tree. The nonterminal nodes have a tuple that holds all the children, and pretty nicely forward them for function evaluation. The terminal nodes just hold a nullary function, which is usually constructed as a lambda capture: ArgErasedNode&lt;int&gt;* numConstantNode(int a){ return new Node&lt;int&gt;( [a](){ return a; } ); }
I'm unsure about the debug block thing. VS dims out code in which the preprocessor variables don't match. So if you're in release and have code like: #ifdef NDEBUG DoSomething(); #endif Then that will be dimmed, which can be much easier to read than your version. There are already tools in VS and VAX to quickly add these preprocessor blocks.
And here I thought his blog posts were confusing. At the first glance, this is 170 pages of diff vs the current standard + some other documents! That said, I started reading and found this: &gt; An iterator or sentinel j is called reachable from an iterator i if and only if there is a finite sequence of applications of the expression ++i that makes i == j. and &gt; Range [i,j) is valid if and only if j is reachable from i. Does this mean that D's [cycle](http://dlang.org/phobos/std_range.html#.cycle) won't be implementable? edit: &gt; If i is incrementable, then (&amp;++i == &amp;i) != false. To the best of my current knowledge, the evaluation order above is unspecified under C++14. edit2: There's more of that. I guess this is supposed to be pseudo-code.
If it's for debugging, why not use cerr (which is unbuffered in any case)?
I didn't design the interfaces I was using. One output it in signed format and the other required it in unsigned. When I joined onto the project it was in desperate need of TLC after I saw the code base and the way libraries were being linked together. The data was just being used for file I/O so it didn't matter. The cast was obviously written more as a joke and something that worked in only a few cases, since, you know, UB.
I do too, but I don't see an obvious workaround that doesn't involve manually specifying the variable name.
I'm not used to seeing many naked pointers in modern C++ code as much as I'm seeing there. Doesn't look very RAII-ish but given it's jules I'll assume he knows what he's doing.
I agree. I especially dislike how macros don't have namespeces. So I always say you should only use macros where you can't do the same thing without macros. However, macros are the only things that have access to the actual code text, which is what I need here. There is no way at all to make this work without macros unfortunately :( I really think C++ should have this feature in "non-macro" things.
See `C.7 Infinite Ranges`. Also technically it's entirely possible to create an invalid range, the draft just doesn't guarantee what will happen if you pass it to an algorithm. Also check out `C.5 Range Views and Actions` -- views are a huge part of range-v3, I doubt they'll be left out forever. (Cycle would be [ranges::view::repeat](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/repeat.hpp))
Oh, true. I thought he was talking about the separators since he put different ones =/ I think it's still possible to do a variadic macro though.
Nah i was referring to the ${value}= part.
There's proposal like [N4286](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4286.pdf) for that. Or you can see how it is emulated in C++14 and used in this [tree traversing example](https://github.com/jamboree/co2/blob/master/example/same_fringe.cpp#L87)
I'm quite pleased with my [variant](https://github.com/mnmlstc/core/blob/master/include/core/variant.hpp) class, especially the 'matching' via lambdas. It was really difficult to get right at the time.
Fitting username 
Didn't look at multithreading much when I wrote this bit. I believe it's built for a single thread.
What does using pointers have to do with RAII?
I'm no template expert but I can' get that to work. I'm glad you made me to look at the code again because the meaning has changed but code hasn't. I dont need to return the string anymore. But I cant get the overloading to work. *template parameter 'unnamed-parameter' cannot be used because it follows a template parameter pack and cannot be deduced from the function parameters of 'Logger::Recursive'* template &lt;typename T, typename... Args, typename std::enable_if&lt;std::is_same&lt;T, bool&gt;::value, T&gt;::type&gt; void Recursive(T first, const Args&amp;... rest) { m_line.append(first ? "true" : "false"); Recursive(rest...); } template&lt;typename T, typename... Args, typename std::enable_if&lt;is_string&lt;T&gt;::value, T&gt;::type&gt; void Recursive(T first, const Args&amp;... rest) { m_line.append(first); Recursive(rest...); } // edit: I think I missed a '=' sign there. typename **=** std::enable_if..... Live and learn. Thanks 
&gt;&gt; I can tell you aren't a C++ developer because you say 'method' which is something that doesn't exist in C++. LMAO you pedantic idiot. You can tell what I mean. if I write 'member function' all I did was use 2 words instead of one. &gt; It doesn't multiply anyone's productivity, it just makes things more difficult to use by obfuscating the code It doesn't obfuscate. It makes the flow of values clearer. Thats why they use it in functional languages. It approximates infix notation. it puts operands closer to operations. And as I keep trying to explain, it has great synergy with the autocomplete feature. you interactively walk the object graph as you type, its' like following documentation links. Its' so fast. &gt; (ugly unreadable syntax) Never had any problem reading this syntax. &gt;&gt; How do you disambiguate? In my ideal world there would be no member-functions, just free-functions. But we are where we are, with a mix. In time projects could refactor away from member functions toward free functions, whilst keeping the superior a.foo(b) calling syntax.
There are several existing C++ HTML template libraries, but most are either old, unmaintained, too complex to build, or use an unfriendly license. I found the Mustache template system but even the C++ implementation was incomplete and had external dependencies. Another C library I found didn't function properly and didn't have tests. So I spent the weekend writing my own library. It's C++11, header-only, Boost license, zero dependencies. I plan to test on MSVC 2013 soon, but I expect it to function with minimal (if any) changes. Any feedback would be great!
Motivation for a `Windows.hpp`
"Never terminate" is a bit too strong, some counter examples for the algorithms you mention: - `all_of(view::repeat(false), true);` (are all elements in the sequence `[false, false, ...]` true?) - `any_of(bools_from_network, true);` (terminates on the first true bool received from the network) - `for_each(infinite_range, lambda_that_throws)` (terminates when the lambda throws) - `for(auto&amp;&amp; i : infinite_range) { if (cond(i)) break; }` (terminates on condition) In a nutshell, infinite ranges allow you to reuse algorithms and views to easily write code with e.g. "input-dependent" termination patterns (network/user input) such as e.g. event loops.
There is a Concepts Technical Specification that is currently work in progress, should be voted into an "official/finished" technical specification this year. The Ranges TS is basically a part of the STL 2.0 with concepts built in from the start, so it kind of makes sense to reconsider algorithms, containers, allocators, iterators, ranges... from scratch, and find concepts that are widely applicable for all of these.
Lol... perhaps you are to *C++ish* to understand the concern‽ As I tryed to explain a "string" has a common meaning in programming languages. The ``std::string`` interface just behaves diametrically - and that **is** a stumbling block! So nobody complains about that - I just pointed it out! So don't take it personally that I dislike certain aspects of your favored (?) language! But perhaps you can explain to me, **what** purpose ``std::string`` serves and **why** it is a good thing to have? Especially as other languages provide a more sophisticated string modell at a first glance...
&gt; &gt; If i is incrementable, then (&amp;++i == &amp;i) != false. &gt; To the best of my current knowledge, the evaluation order above is unspecified under C++14. There's something very odd about that statement. Why would incrementing an object ever change its address? And why write `!= false`?
&gt;&gt; If you want pipelines, then do this: v | sort | unique abuse of overloading an operator that's used for bitwise-OR in C++, with god knows how much template malarkey behind it to make it work.. bloating compile times... yeah thats so much better! NOT. How much boilerplate to make this technique useable, and what does it look like when you want to pass additional parameters. 
How about auto foo = bar(); ? Now you have to look up the return type of bar(), or your IDE has to figure it out.
That too! For example, I have a `#define` that adds comparison operators to a class given the `operator&lt;` and `operator==`. I know you can do it with some weird inheritance, but it just looks / feels so wrong to do the inheritance thing, while this define is so simple... #define ADD_COMPARITORS(T) \ bool operator&gt;(const T other)const{return other&lt;*this;} \ bool operator&lt;=(const T other)const{return !(other&lt;*this);} \ bool operator&gt;=(const T other)const{return !(*this&lt;other);} \ bool operator!=(const T other)const{return !(other==*this);} I feel bad using it (because it's a macro) but it's so much more... "nice on my brain" than the inheritance method. Meh 
I simply prefer this style.
Agree that range and filesystem will be good things but they are already on good tracks. For me some of the missing parts are. - Serialisation it's always difficult to explain to new devs why there isn't a standard one and why it need work to implement it compared to java/c#... - Compression If we have serialisation we should have a compatible compression API to plug standard and personal algorithms. - Database Access Most of database access lib always cherry pick 2 or 3 popular open source projects. We need something like ODBC/JDBC which can handle both the best opensource solutions and all the proprietary one like Oracle, SQLServer, Sybase, DB2... - A color text console support Nice to have standard text output but the tricks to have color in console start to become annoying. - Maybe some internationalisation or localisation helpers We always have to rewrote abstraction layer for messages or resources loading.
But why would I want anything like that? introduce a whole engine VM for what? stitching html? why not simply have objects which are metaobject of data+layout and they simply spit the final output from a virtual render() or templated render() ???
The autor of CppCheck QtCreator plugin has more cool plugins on his [github page](https://github.com/OneMoreGres?tab=repositories) * [Google Test](https://github.com/OneMoreGres/qtc-gtest) Qt Creator plugin * [Markup viewer](https://github.com/OneMoreGres/qtc-markview) Qt Creator plugin 
But names don't look like `foo` and `bar` in real life, so that's a bad example. auto name = getName(); It's pretty clear that's going to be a string. 
I assume the `!= false` is to be extra-clear (though it only serves to confuse me more). As to the second point, `operator++()` isn't required by the standard to return `*this` as `T&amp;`, so it's a valid requirement for a concept if it depends on it. I am more uncomfortable with code like `(a++, a) == (b++, b) != false`.
&gt;Lol... perhaps you are to C++ish to understand the concern‽ Perhaps you aren't experienced enough with C++ to understand my answer. &gt;As I tryed to explain a "string" has a common meaning in programming languages. A 'reference' is widely 'known' amongst C# and Java programmers to mean what is actually known as a pointer. Does that mean that C++ should rename its references to aliases and its pointers to references? Of course not. Terminology means different things in different languages. C++ has existed quite a bit longer than Unicode. &gt;The std::string interface just behaves diametrically - and that is a stumbling block! That's because it's not designed to represent what users of other languages might think strings are. &gt;So nobody complains about that - I just pointed it out! So don't take it personally that I dislike certain aspects of your favored (?) language! I'm not taking it personally, I'm just pointing out that coming to the C++ subreddit and talking nonsense about C++ is silly. &gt;But perhaps you can explain to me, what purpose std::string serves and why it is a good thing to have? Especially as other languages provide a more sophisticated string modell at a first glance... Because it holds a bunch of bytes (or 16-bit `char16_t`s, or 32-bit `char32_t`s). C++'s strings are low level. If you want a higher-level Unicode interface use a Unicode library. I personally don't think Unicode should be supported by the standard library: it's just another encoding, like PNG or H.264. Standard libraries should be concerned with low-level building blocks, not individual encodings. 
It's bad unnecessary code. Why would that make you appreciate Python?
smart pointers
My day just became better 
&gt; [...] If so, why aren't concepts like `DefaultConstructible`, `MoveConstructible` and others already defined? They don't seem to be specific to ranges feature... As far as I know, this has to do with [Palo Alto TR](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3351.pdf) which tried to specify the smallest set of concepts required by the standard library and so avoided proposing concepts that just checked for single isolated properties of types in favor of combining then into bigger concepts. [/u/eric_nibler](http://www.reddit.com/user/eric_niebler) actually talked a little bit about this on Range SG's mailing list: &gt; [...] `Semiregugular` got decomposed into the host of concepts that the standard already defines: `DefaultConstructibe`, `MoveConstructible`, `CopyConstructible`, etc. This was more an oversight on my part than a conscious decision -- a too-literal mapping of the current standard. I can roll this back if we decide we don't need the zoo of fundamental concepts the standard currently defines. [...]
&gt; It has to scan the header file at least once. Well color me surprised, I haven't yet seen a compiler that can compile without scanning a header once.
There are three words in "the English language" (blah blah something about -gry) what's the third?
Well their programs aren't remotely portable.
... well no shit, that's what I just said. Of course they have to scan the header files.
&gt;It's used in F#, its used in Clojure.For some reason haskellers prefer to do it backwards with $, but thats' culture. I would abuse the culture and do it forwards. "F# does it" is about as sensible as "C# does it". Haskell, ML, Lisp, these languages it's not done. Clojure and F# are designed for users of Java and C# respectively. &gt;I think the F# and clojure people have the right idea. When I dabbled with lisps, I found clojure generally had many good ideas keeping lisp fresh, and I believe the criticism that common lisp is 'mouldly'. Of course I wouldn't use clojure because I'm no fan of the JVM. I think the F# and Clojure people have the right idea for their use case, which is building functional languages that are attractive and accessible to people that already use the CLR/JVM respectively. &gt;your time isn't worth a faster computer? seriously ?? Autocomplete is faster than manually switching windows to consult documentation. The computer is doing its' job, helping you. why not??? I have an extremely fast computer. It still takes forever for Visual Studio to do anything remotely complicated (like start up, or search). I have two monitors, and I usually don't need to consult documentation because I make a point of using libraries with interfaces I can fit in my head. I don't like autocomplete. I've used it before and I don't think it helps me do what I want. Just today I was working on some C# code and I wanted to write `e.X` and when I typed `e.` the program decided I meant `else`. I tried again, `else` again. I had to type `e.[ESCAPE]X`. &gt;We could use some initiative here! menus can be sorted!! menus can have sub menus!!! we can put all the most specific functions first, and generic stuff under a submenu. 21st centuary software and UI technology has come such a long way !!!! WOW!!!!! You need to calm down. Feel free to keep using autocomplete and having menus sorted by some arbitrary quality measured by the IDE that changes as time goes on. I don't want to be looking through bloody menus to write code. I want to *just write code like a normal person*. Autocomplete doesn't help you understand what something *actually does* or how it *actually works*, *why* you should use it. All it does is tell you the interface to using it. You save time on reading documentation by using autocomplete and spend that time manually typing out huge slogs of code, while I save time by using vim and achieving in a few keystrokes what takes other developers tens of minutes, and spend that time saved reading documentation so I can actually understand how something works and not just how to use its surface API. &gt;I've never used Java. Why do you call member functions methods then? &gt;But many C++ systems are comprised of graphs of objects. Now, saying a want a.foo(b) DOES NOT MEAN I THINK EVERY FUNCTION SHOULD BE DEFINED INSIDE THE BLOODY CLASS. I WANT UFCS BECAUSE I SPECIFICALLY DESPISE THIS SIDE OF OOP. I WANT TO ADD FUNCTIONS THAT CAN BE CALLED LIKE METHODS , ANYWHERE, ALLOWING DECOUPLING OF DEPENANCIES BETWEEN MODULES You can already call things easily. You even get the right namespace lookup: you don't have to write `{ ns::bar b; ns::foo(b); }`, you can just write `{ ns::bar b; foo(b); }` because of ADL. C++ is designed to be used this way, this isn't an accident. UFCS doesn't 'allow decoupling of dependences between modules', it's just a syntax aberration to make things look nicer to shitty developers that can't handle syntax they're not used to. Face it: `a.b` will always mean that `b` is a member of `a`. :) &gt;STOP INSULTING ME BY CALLING ME A JAVA DEVELOPPER. Wow you're getting quite upset about this aren't you. &gt;JUST BECAUSE I WANT a.foo(b) DOESN'T MEAN I WANT TO ORGANISE CODE AROUND CLASSES What's so special about the first argument? Why should `foo(a, b)` be sugared into `a.foo(b)`? Why not `b.foo(a)`? &gt;Nothing amicable here: You are a stain on this earth, holding back the language I have no real choice to avoid. That's pretty rude, dude. &gt;we could write a |&gt; foo(b) |&gt; bar(c) instead, but its' just using an extra character. Not sure how you could write that in C++, given we thankfully don't have arbitrary operator overloading. &gt;Rust standard libraries look great, they're functional inspired, with iterator chaining Rust doesn't have proper iterators. Its "iterators" are really just bad ranges. &gt;but looking familiar to C++ Syntactic similarity is so fucking unimportant, dude. &gt;but with types extendable by implementing traits (not closed, inherited classes). C++ doesn't need you to implement pre-defined traits to do something useful. Just implement `T::begin()` and `T::end()` (or ADL-findable `begin(T)` and `end(T)`, or whatever floats your boat) and suddenly `T` is iterable. &gt;D is out there with UFCS. And it makes the language worse. &gt;the correct models exist, lets keep C++ fresh Change for the sake of change, just to "keep C++ fresh" i.e. waste the committee's time that could be spent on useful things like Ranges, Concepts, Transactional Memory, Concurrency, Parallelism, Networking, Filesystems, etc. just so the C++17 announcement can have something that makes Java weenies like you happy, is a fucking terrible idea. 
It's spelt Moustache, by the way. 
The [official](http://mustache.github.io) project isn't. According to [Wikipedia](http://en.wikipedia.org/wiki/Moustache) this spelling is American English.
Or even better, use a [native Lua](https://github.com/Olivine-Labs/lustache) implementation.
I take it you don't subscribe to /r/MURICA ;)
No, I compile this with clang 3.5: $ clang++-3.5 -std=c++14 auto_param.cpp auto_param.cpp:4:12: error: 'auto' not allowed in function prototype auto print(auto&amp;&amp; x) { ^~~~ That most likely compiled at ideone because its using gcc 4.9, which supports it as an extension(see [here](https://gcc.gnu.org/gcc-4.9/changes.html)): &gt; G++ supports unconstrained generic functions as specified by §4.1.2 and §5.1.1 of N3889: Concepts Lite Specification. Briefly, auto may be used as a type-specifier in a parameter declaration of any function declarator in order to introduce an implicit function template parameter, akin to generic lambdas. 
Well, because achieving the exact same result in Python would require no additional libraries and way less verbose code.
&gt; No. Do not use a singleton ever. If you need a global variable just use a global variable god damn it. Except when you need to get around the fact that [the order of static initialization is undefined](http://isocpp.org/wiki/faq/ctors#static-init-order). Using a lazily constructed singleton gets around this to some degree (though you have to be careful to avoid chicken and egg problems). I will concede that you generally shouldn't need things like this (or if you do you might want to reconsider your design).
&gt; That's the stupidest idea I've ever heard. Well, its' very popular with a lot of smart people I've met who do a lot of 3d maths. 'dot-product' is a very common operation on vectors so it does arguably deserve an operator, it makes 3d maths formulas both read &amp; write better, closer to how you'd write them on paper. &gt; Because we have more than enough operators and | is a very standard one literally called pipe. yeah but in maths there are similar looking operators used for products. its' highly ambiguous. To further complicate matters - it actually made sense to bit-wise OR vector data together aswell. I have personally been ambiguous on it, but have definitely wanted it myself sometimes. And i'd certainly MUCH rather have a|b for a dot b in vector maths formulas rather than piping, WHEN WE'VE ALREADY GOT THE BLOODY `a.do_something(b).do_something_else(c)` SYNTAX . of course having a method , oh sorry you pedantic asshole, MEMBER BLOODY FUNCTION for 'dot product', you can use those to make your formulas look more pleasant, like the infix notation you're used to using when you write it on paper.
&gt; UFCS doesn't 'allow decoupling of dependences between modules', for the umpteenth time this is the problem. you want to be able to use 'member-functions' for autocomplete, it makes your code more discoverable by others, and for clearer expressions, chaining operations. BUT currently in C++ this imposes that you add your functions TO THE CLASS. this is bad, because it draws dependancies into the class, contributing to the "gorilla banana problem" of OOP. we are tortured bouncing between the two. you can't plan everything upfront, code evolves. you want to be able to seperate out and group functions on an individual basis, based on their own dependancies... thereby *decoupling*.. just like with free-functions. The benefits of a.foo(b) should be available for free-functions. The superior decoupling of free-functions should be available for superior a.foo(b) syntax. &gt; have something that makes Java weenies like you happy, I DONT USE JAVA java people would be raving about how classes are the way to work. 
Shouldn't `Call()` look something closer to: if (on_ || On()) { func_(s_ptr_.get(), arg_tuple); } else { // Handle the case where we couldn't acquire a strong pointer (object already destroyed) return ThrowOrReturnApproprateError(); } It doesn't seem like it is actually ok to go though with the call with nullptr, since you are always invoking a member function. Also, couldn't you omit `on_` and just use `s_ptr_`'s `operator bool`? Edit: actually, I'd strongly advise after looking more closely at `On()`, which currently unconditionally sets `on_` to true, but may still fail, leading to undefined behavior in `Call()`.
&gt; I'm surprised the first example compiles since normally functions can't be overloaded by return type. Its not overloading based on type of the return type. &gt; So this is essentially a form of SFINAE, correct? Yes, its SFINAE. 
Since you're using C++11 you should delete copy and assign instead of the old make-them-private idiom.
Agree. This is yet another hot air post, as so many these days in programming subreddits...
That `i` must be incrementable to `j` is undefined in a general sense yeah but nearly every class and function in the stl that uses iterators specifies something like this. &gt; N4296 § 24.4.4 &gt; template&lt;class InputIterator&gt; &gt; typename iterator_traits&lt;InputIterator&gt;::difference_type &gt; distance(InputIterator first, InputIterator last); &gt; 4 &gt; Effects: If InputIterator meets the requirements of random access iterator, returns (last - first); &gt; otherwise, returns the number of increments needed to get from first to last. &gt; 5 &gt; Requires: If InputIterator meets the requirements of random access iterator, last shall be reachable &gt; from first or first shall be reachable from last; otherwise, last shall be reachable from first. &gt; N4296 § 23.2.4 &gt; 10 &gt; The fundamental property of iterators of associative containers is that they iterate through the containers in the non-descending order of keys where non-descending is defined by the comparison that was used to construct them. For any two dereferenceable iterators i and j such that distance from i to j is positive, value_comp(*j, *i) == false I'd consider the statement that the distance from `i` to `j` being positive means `j` must be reachable from `i` no?
Dunno... that's how Britts spell it. And perhaps Ozzies and Kiwis. Cannucks are kinda 50-50 so you seem to be outnumbered... :)
Reminded me of ["Are there more nearby spiders than the sun is big?"](http://what-if.xkcd.com/136/).
Shit, main memory access is up to 230 cycles now? D: I honestly think that the main reason that CPUs don't look like they're advancing as fast as they are is because code is bottlenecked on memory much more than on cores. 
230 cycles at 4 GHz is 57.5 ns. The only thing that prevents this from being totally punishing is the elaborate cache hierarchy, which C++ takes advantage of by having locality-friendly data structures like `vector`, `vector`, `vector`, and occasionally `array`.
[And you would be absolutely right.](http://1.bp.blogspot.com/_0sB_kfTI7ig/TOPt-HhRfwI/AAAAAAAAB_0/FB8E-yXGzMY/s1600/ScreenShot132.png) Writing cache friendly code is incredibly important. It's often surprising how large your N has to be before big O notation becomes more important than writing something cache friendly.
Remember back when C++ was considered "high level" because it was structured...
&gt;for the umpteenth time this is the problem. you want to be able to use 'member-functions' for autocomplete, it makes your code more discoverable by others. If by 'others' you mean 'people that intuitively understand an API from autocomplete information but without reading any actual documentation and who can't keep your API in their head'. You can write free dunctions without the shitty, shitty, shitty syntax you want.
i have some problems to understand. why does scott say its better to use promise -&gt; future instead of conditional variable and or conditional variable + flag. when promise and future still use conditional variables, mutexes &amp; boilerplate code in their implementation. (at least for msvs). the void type seems to be a bit better but still uses a mutex. still he says "unlike condvar -&gt; no need for gratuitous mutex" what am im missing?
It's absolutely relevant. I have found that people nearly always choose examples like that because they cannot think of actual examples where their suggestion would be actually useful. 
Please stop **making** random *words* bold and italics, it's very **distracting**. &gt;Of course - but if you have differences in core language concepts that might be ok, as everybody has to learn the main concepts. But the term string is quite well defined. `string` means different things in different languages. Some treat a string as a sequence of bytes. Others treat it as an alias to `vector&lt;char&gt;`. Some treat it as Unicode. etc. In some they're mutable, in others they're not. 'String' is a heavily overloaded term: coming to a language and expecting things to work identically to how they worked in the last language you worked with is stupid. &gt; And of course that is nowadays a bad thing, if the name missleads people. The name misleads people if they assume that 'string' means the same in every language. No other term means the same thing in every language, why would strings work the same in every language? &gt;We are just talking about this, because of the drawbacks of this old interface, you remember? `std::basic_string` only has drawbacks if you try to pretend it's something that it's not. &gt;It's a shame that so many people are often not really polyglott. If they were, they would better care about the concern of bucking the trend. Imho no language can just ignore trends and justify shortcomings with the age of the language. Yes, C++ is old and of course older than unicode - but if it wants to stay alive it must react to new technology; what it clearly does. But std::string is simply a shame! I have programmed in many languages. I am not ignorant. C++'s string handling is low level, which is FINE. The locale handling? The facets? Oh god those are an awful awful awful attempt at supporting Unicode, they should be deprecated and quickly removed from the language, and replaced with something sane. High-level Unicode string support, ability to iterate over the code units or the code points, etc. *That* would be helpful. But the low level string functionality - `std::basic_string` - is absolutely fine for what it does, which is store strings. It stores strings perfectly. It presents the contents as an array of code points - if you use `std::u16string` or `std::u32string`. `std::u8string` would be a fine addition. &gt;And that's a stumbling block! 😈 Every language has stumbling blocks. If you come to C++ and expect `std::string` to be a high-level interface then you're going to be sorely surprised. &gt;Then you have not really understood that unicode is primarely a concept and of course not a technical encoding! The library / language designer has to choose an internal representation, that's right, but the overall goal is to provide a universal type to use for all internal string handling. And that is far more than just an encoding! C++ doesn't aim to have a standard library that encompasses all possible functionality. That's a bad way to build a standard library. The better way is what C++ does, which is provide a core of useful building blocks. If people insist on having Unicode support in the standard library, much like they insist on having IEEE754 floating point support, then we should have it and it should be good. But that should be implemented in a way that is compatible with a smaller core of the library that is platform- and encoding-agnostic. &gt;To be honest, the std::string resembles what other languages call "byte-string" or encoded string. But where is the counterpart? Hm... not in the core library - Ooops... that is quite bad, as other libs cannot rely on such a missing type! `std::basic_string` does everything it was intended to do and more: it provides a container for storing strings. If you want full unicode support then that should be done with a higher-level interface. &gt;And I do not believe that good string handling could be ignored by the core of a language nowadays. We're not living in the 80s and 90s anymore! We're living in the 21st century, where it's still perfectly appropriate for a highly portable and platform-agnostic language to provide low level tools that let library developers create whatever sort of Unicode magic they like. &gt;And you still have not explained, what the purpose of such a lean interface is? What is the added value compared to a std::vector of some byte type? `std::u16string` works *completely* different from `std::vector&lt;char16_t&gt;`. &gt;Imho the lack of a good string handling in the core of C++ is responsible for some horrible and inflexible pieces of code we still see today. (Use german "Umlaute"? Forget it in many applications... for me that's a no go!) Incompetent developers are responsible for bad code, not C++. There are lots of programs out there written in C++ with great support for Unicode. &gt;And yes, probably you are much more experienced with C++ - and I also admit that I do not really like the language to be polite - but I have do deal with it and therefore I am interested in the development of the language. And so I think I have the right to post here in this subreddit! And I do also think that it is good, if C++ folks get more in contact with polyglott developers - or do you prefer to live on gilligands island, completly separated in an artifical IT world? Don't act all high and mighty as if you're the only person around here that's used languages other than C++.
First of all there is no such thing as good and/or bad pattern and no such thing as anti-patterns is BS. Every pattern can be abused and one should stop treating them as a panacea pills to start with. All patterns, publish-subscribe, events etc. can be terrible abused and it is not easier or harder to do so for the case of singletons. Seconds thing you should realise is there is no single implementation for singletons. For instance I can demonstrate you a singleton which is none of the below: " Singletons are just globals Singletons make code hard to follow Singletons make code hard to test Singletons make code hard to maintain Singletons make code hard to secure " indeed you can achieve all those with particular implementations. bottom-line it is not better or worse than all the rest of patterns out there! 
&gt; Like any pattern, using Singleton where it doesn’t belong is about as helpful as treating a bullet wound with a splint. Exactly! Every pattern can be abused and every pattern including Singleton can be used! “you can never cre­ate a sec­ond instance of this class” this indeed I found better not to enforce! you end up introducing unnecessary non-essential complexity in your code-base 
STFU
stop preaching! it is like, never use mutable state! cmn gime a break! 
Best of both worlds: linked list of fixed-size arrays (about the size of a cache line or multiples thereof). Easy dynamic growth without shuffling memory around, but still good-enough memory locality for most use cases.
&gt; Kenny Kerr: I’m hoping to release v1 later this year. So the library is not available for now!
I cannot compile your lib on Mac OS X. Do you know, what I might be doing wrong? I get [this](http://pastebin.com/VukQyiyD) error.
I remember when developers would disdain Pascal and C compilers because they only generated bloated slow code. To suggest to those devs to use C++ was a major offence. 
I'm sad that you're being downvoted when those slides are incredibly relevant. It's a real world demonstration of how making small adjustments can result in enormous payoffs when you design with the cache in mind.
Certain optimization techniques used to make a difference. Others were probably feel-good measures. This was back when clock speed and capacity were measured in values prefixed with 'kilo', so it's all irrelevant to modern systems. To be honest, most of the reason I fall into coding this way now is that it makes me feel smart because I'm producing code that's a little cryptic. It's dumb, but there it is.
Except that article makes much more sense! I know what you mean though:) Thanks, by the way. Hadn't seen that one. That was a much more worthwhile use of my time; not to mention the interesting reference material. Good stuff.
&gt; To be honest, most of the reason I fall into coding this way now is that it makes me feel smart because I'm producing code that's a little cryptic. It's dumb, but there it is. That's more evil than dumb!
When I'm the only one who ever has to maintain it, it's just dumb.
Product page here: https://www.jetbrains.com/clion/ Download link here: https://www.jetbrains.com/clion/download/
Nice to hear! Don't forget that students get CLion and other JetBrains products for free: https://www.jetbrains.com/student/
Think it will give VS a run for its money on Windows? I've used CLion and its really good! Congrats to the Jetbrains team!
Proper C/C++ IDE, I recommend. Enjoying it since early private builds. (good replacement to ~~QtBuilder~~QtCreator for Qt development - it has good CMake support).
CLion still has a long journey ahead of it, but it's already the best Linux C++ IDE in my opinion. I don't like some under-the-hood design decisions they made, but it works, and that's what really matters.
This is a perfect example of the ["clean break fallacy"](http://www.joelonsoftware.com/articles/fog0000000069.html). Yes, you can always design something better the second time, but the time to reach feature parity of the original is non-trivial and unless there's an order of magnitude improvement to the user, they won't want to ditch they're old code and start all over as well. Just look at the headache that the Python 2/3 transition is wrestling with and that's less dramatic of a change than what is proposed here. Also, to at least some degree, isn't this what D was aiming for?
Removed __iterator_category. Can you try it now? Also added some documentations (cleaning and documenting the code is my next big priority) Cheers!
what kind of decisions did they make that you don't like? Cmake?
Oh definitely. Its interesting to see some of the changes that magic foresight could have made possible. Still, having a compatible (if only in separate files) version of this kind of cpp syntax would be interesting. I know it's unrealistic, but having this syntax act as a thin layer over generated cop would be cool. I think D's problem is the gc. 
Better than Qt Creator?
I'm underwhelmed. I suppose it's a net improvement, but I was not left wishing that I could use this today.
I think CMake was the best choice given no really good options. There's no build system I've found that I really like. Mainly, I don't like that they implemented their own parser instead of integrating with the compiler's one. 
Yeah cmake was probably the best choice given they needed cross-os compatibility. I was under the impression that gcc's parser is notoriously hard to integrate with. The other option would be to go with clang's. But then they would be interoping with two toolchains.
I tried it, seems like glob.h does not contain GLOB_TILDE_CHECK on Mac. [pastebin](http://pastebin.com/hxzyF4TL)
Why is it better than other free alternatives? (i.e. Kdevelop?). To justify its price it has to be incredibly better.
It's interesting to see a joint paper on [Unified Call Syntax](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4474.pdf) by both Bjarne and Herb following on from their independent suggestions at the last meeting. Perhaps it shows encouraging development in this area.
`pacman`, `apt` and `brew` are all I need, sorry!
Could you expand ? I tried it about a month ago and was not convinced (much slower than QtCreator...). Downloading the trial right now.
As long as it isn't ~~not~~ free software, I wont use it. It is that simple. That is even aside from all the problems those systems bring, when pacman works just fine. Edit: And I also won't trust anyone with this kind of task, who is to incompetent to produce a working website: If static content doesn't display nicely without JS, you are obviously to stupid to be in any way trusted with code that runs natively on my system. If all I get is a white page, you have failed at every level imaginable.
Is it better than qt creator? 
Well, still not convinced : the trial lags like hell in comparison to QtCreator (MacBook Pro mid-2014), Retina ain't working, and the memory consumption is insane. My build failed but the CPU consumption is still stuck at 100% ?? Here are some `htop` numbers VIRT RES SHR CPU clion 7730M 1108M 455536 ~10% when idle qtcreator 4201M 271M 116M ~1% when idle on the same project (https://github.com/OSSIA/i-score). The cmake autocompletion is ok... variables don't seem to be autocompleted in `message(${A_VAR})` for instance. When adding files to a project (which is nice in comparison to QtCreator where you have to `touch` the file and add it by hand to the CMakeLists) it adds them at the end of the `add_smth` command and not in a variable outside (this would be almost impossible to detect so I don't blame them). Completion seems to be faster than qtcreator with the clang code model. However Qt-specific stuff (which is quite common when doing cross platform C++ development) like signals &amp; stuff is not completed. Can't blame them either... There is a spell checker, and it sucks ? Yes, "Menubar" is not a valid english word but I guess everybody in the context would understand it.. I'd rather disable it than have some lines in my code under every word which isn't common usage...
I said "you probably shouldn't have global state", not "you should never have global state".
&gt; I need to make sure the developer has a c++11 compiler Not using C++11 in this day and age seems a little silly.
I just got started on qt creator too. I'm using qmake though and everybody seems to be using cmake. So I guess qmake is kinda abandoned?
This is something I've wanted to do as a beginner, but I wanted to ask whether you had to use objective-c++ in order to mix cocoa and c++ in the same project?
It does OK. The problems start when you want to add some Obj-C UI glue code though :)
This is really quite a weird 'proposal'. If we all ignore for a minute that they'd never allow anything like this, most of these changes are simply gratuitous. How is this: type Vector : class { [public] obj x, y: int; obj z : int; } superior to this: using vector = struct { int x, y, z; }; Why would anyone want to change from the MUCH better `template &lt;...&gt; class X` syntax to `class X&lt;...&gt;` syntax? The former makes it MUCH more clear that a class template is NOT a class.
The GC is heavily tied into the standard library, though.