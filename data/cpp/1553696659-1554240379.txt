Sorry, I overlooked that this was about use cases, that are not possible in rust. I don't know rust, so I can't make a statement about that.
God I can't up vote you hard enough! I've built a career out of doing exactly what you outline, combined with a healthy dose of "It's easier to get forgiveness than permission"
I don't recall Rust ever being mentioned as an influence in any papers...
You do not understand at all, because in order to understand facts, you need to know history. C++ inherited an ambiguous grammar from C, its error-prone memory management, lower level data structures that point to memory (arrays and such, now replaced by std::vector in modern C++). Rust did not have any of that. It would have been very difficult to design a language from scratch that could be "worse" than C++. Please read. http://www.stroustrup.com/blast.html Once you - as many - have seen a few dozen large industrial C++ projects completed on time, as budgeted and going through maintenance as hoped for, clever arguments based on the necessity of individual language features - invariably features absent in C++ - lose their credibility. Such arguments remain interesting sources for ideas for improvements of C++, but their central sales/propaganda message is fundamentally discredited. Over the years C++ has been deemed useless because it lacked (among other things) type checking, metaclasses, multiple inheritance, garbage collection, generics, concurrency support, exceptions, co- and contra-variance, dynamic linking, typecase switches. Simultaneously, if was - often by the same people - deemed useless because it was too complicated and had too many features. At the same time, a steady and increasing stream of projects were successfully completed in C++. My firm conclusion is that no single feature is truly necessary. Much more successful software has been written in languages proclaimed BAD, than has been written in languages acclaimed as saviors of suffering programmers; much more. https://www.youtube.com/watch?v=fX2W3nNjJIo http://www.stroustrup.com/new_learning.pdf
You have to keep in mind that these libraries are meant to support many other use-cases than your own. A similar templated design can also be found in Boost.Beast. This [video](https://www.youtube.com/watch?v=WsUnnYEKPnI) explains the design decisions pretty well. TDLR; for some use-cases `std::string` is not best option and the authors do not want to force `std::string` onto its users.
&gt; no one has wanted to introduce the interface keyword Introducing a new keyword doesn't solve the problem. People have been working hard to come up with a design. The previous attempt before the *current* concepts design was ambitious. It supported actual modular type checking and so called "concept maps" with which it was possible to make type X from library A conform to concept Y from library B without A and B having to know eachother. For a brief moment this design was part of the draft for C++11. But it got scrapped because it was super complicated and little understood. And I'm actually glad that it happened because I consider the approach it took to define concept requirements in terms of function signatures (as opposed to "usage patterns") deeply flawed in the context of C++ where we have overload resolution which is sensitive to value categories. The concepts design we have now is actually the "lite" version which dropped modular type checking, concept maps and replaced function signatures with usage patterns for constraints. The hope is that it will be amenable to future extensions to allow pre-instantiation type checking of templates. My point is: It's a complex problem to solve. Where have you been slacking off instead of helping to solve it? ;)
What does any of that to do with what I said? I'm not sure what hidden motives you read into my short post that spurred such a heavy response. No worries, I'm no rust programmer and I'm certainly not here to convince anyone that one language is better than the other. I only really know c++ (only for about two decades now, but I'm certainly not ignorant of it's history), and am for the most part happy with it. That doesn't blind me to the fact that rust can solve some things better, exactly because it doesn't have to stay backwards compatible to code written decades ago in a different language under completely different circumstances. I also hope that anyone who is actively participating in the design and development of a programming language has a decent amount of experience with other languages and looks out for features and techniques that could be beneficial in this language too.
Please read my post again. I clarified my initial statement a bit - maybe what seems to offend you was just a misunderstanding. 
You're right, I meant to type smart_ptr, not its predecessor.
&gt; and the compiler will tell me nothing Yes. In 99% of cases, the compiler can't know if the index is out of bound. &gt; Has it always been like this? Yes. &gt; I swear I used to get error messages for this kind of thing Some compilers will warn you for static arrays (`std::array` and `T foo[]`). ********************************** Please note that `std::vector`'s `operator[]` doesn't do runtime bound checking. `at` does.
Nesting doesn't give you any particular coupling other than the name, though? 
The point is that the compilation can be aggressively optimized if there is no bounds checking. Check out Compiler Explorer and some sample code (along with -o2 or -o3) to understand.
I believe with the requirements on `std::basic_string::c_str()` that is the case. Using `basic_string` as a vector actually has some nice advantages, you get small vector optimisation, and you can easily concatenate 2 vectors with the `+` operator. Down side is the null terminator needs to be added, also because of `c_str()`
Some Implementations contain assert(i &lt; size()). But this is not required and will be ignored if debugging is disabled.
Probably this, always running in debug mode when developing
If it's not in the papers it of course can't possibly have had any influence;)
Write a quick sort algorithm and you will know vector has no bonds checking.
I believe that both operator[] and at() have (or used to have) bounds checking in Visual C++ in debug mode.
This Rust-&gt;C++ explanation is super useful. If only there was a book or blog series that just did this for the whole language. :) 
kk, bye
libstdc++ and libc++ both support this too, though you have to explicitly enable it. (MSVC has somewhat standardized what "debug mode" and "release mode" mean, while that's even looser on Linux. The checked STL isn't what I would consider part of a "normal" debug build on Linux.)
It is the same with all the standard containers. If you want bound checking one must use the member functions performing it, such as the [at](https://en.cppreference.com/w/cpp/container/vector/at) one. As usual in C++, you can choose to pay extra or not for some checks.
Maybe you could get away with making multiple promises, but it doesn't make sense to use the same promise over and over.
There is no competition, it is not a contest. If it was a contest, C++ projects were successfully deployed in millions. &amp;#x200B; Rust could not even start such a contest, regarding legacy and "success" (horrible term) of a language. &amp;#x200B; I also do not care at all about your decade-experience in the field. You are a random stranger on the Web, so I am. You could boast 50 years of experience, for that matter, I would not care less. We have equal right to express an opinion. And please note that I met "engineers" with decades of experience that still write Java version 1.5 in 2019 (they never got past Java 5). They claim to be technical experts. So, yeah. YMMV. &amp;#x200B; tldr; it is not a contest; and if such a contest could exist, there would be no contest at all between C++ and Rust. See audience questions at the end of this video. [https://www.youtube.com/watch?v=aPvbxuOBQ70](https://www.youtube.com/watch?v=aPvbxuOBQ70) &amp;#x200B; &amp;#x200B;
Thanks. Sadly, i don't know of such a blog series. It would be tremendously useful for C++ people trying to learn Rust and vice versa. I'm not really into blogging, but maybe someone will take the effort (who is more qualified than me).
You can't check if the memory can be allocated if malloc always says yes and the system just kills you without warning if the answer is no.
Needing to provide a char traits for your T isn't fun.
operator[] doesn't have bound-checking. However .at() has and you should be using that instead
Well, you're pretty much forced to statically link any libraries you create since C++ doesn't believe in shared libraries. But if you go down the shared library route, you'll need to pay attention to your ABI. If you're free to break it at any time then it's no real bid deal. If you're not then you'll have to design your classes carefully and use PIMPL quite a lot.
 Interesting point, I would say that, *for* development I would always use shared libraries. When I'll have to release the final binary, statically linking would be ok. When I said that everything should go in library. I don't mean that the interfaces have to be perfect at the beginning. At the beginning of the development they will change a lot and often. My point is that it's better to start writing code with the modular approach in mind.
When I had this opportunity, I chose to build a single, large omnibus library with everything in it--including static copies of most of our dependencies. I started out with a sea of small libraries, but we wound up with such deep dependency chains that meant we were pulling in most of the libraries every time anyway. Things were even worse when each library lived in its own repository, since keeping everything up-to-date became a chore. At this point UI, UX, and workflow logic goes in the application itself, while core capabilities go into the main library. The separation is usually easy to find, since the framework is our main product and the applications are just usages of the framework. The result is that starting a new application using our framework doesn't require a lot of dependency analysis. Start a new project, link in our framework library, and you have everything you need. And the linker will strip away anything you didn't use.
&gt;Things were even worse when each library lived in its own repository, since keeping everything up-to-date became a chore This is something I'm investigating. It seems a bit scary, but logically it makes sense. What if you want to create your software product, where most of the logic is shared between other modules? what if you need to write different applications that have a lot of common logic? &amp;#x200B;
You address a lot of known pain points :) - Speed: Which aspect in particular? Parsing? Serialization? Value access? - Allocations: Yes, that is a TODO... - Errors: I do not understand what you mean. Could you give an example? Which library did you switch to?
Of course you can use shared libs with C++
Personally, I think your ideas are exactly correct. It's about building something complex through incrementally higher levels of abstraction. a) This permits you to develop and test each level incrementally thereby converting a large complex task into a series of simpler tasks. b) it promotes narrow interfaces which are more easily understood. c) it's easy to document your system as you proceed. d) it's much easier to chang something by dropping one component and substituting a new one. e) it's easy to include type checking at each level to make your program more provably/demonstrably correct and diminish reliance on testing which gives an over optimistic assessment of code quality. f) it requires that you actually design your app rather than just provide a miscellaneous grab bag of features. e) it makes your complex project understandable in an incremental way. This us permits those of use with smaller brains to make more meaningful contributions. f) it permits one to deploy your code as either a static library - which means that components which become unused don't take up any space in the application or as dynamic libraries which permit updates after the application is deployed. This is not part of the design - it's just a deployment strategy. g) in C++ it requires some thought regarding which code should be explicitly instantiated which is not a bad thing as you actually come to understand how complex your application is. Alternatively, one can build everything header only which doesn't mean you actually have to think about which code is actually being used, but results in non scalable compilation times which can start to be measured in hours. I prefer the former. Robert Ramey
So a simple example of CRTP, would be to inject all 6 comparison operators for a class that provides a single `cmp` function (returning -1/0/1). It's opt-in injection of public API implemented in terms of existing API of the class. Policy based design is inheriting from multiple CRTP classes, each of which is responsible for a different part of the API. So it's not as simple as "more template parameters to increase genericity". Each policy template can directly control what API is available. What you are describing in Rust (default trait methods) is indeed one thing you can do with CRTP but CRTP can go much further. Also, it seems to be like with default trait methods, wouldn't the person defining the trait have to define those defaults? In C++ you're not coupled in that way. &gt; For now, we do this by exploiting "SFINAE" which is kind of a hack but "works" in a lot of cases albeit looking rather cryptic. It's somewhat cryptic I guess until you learn it, which doesn't take very long. I've almost never had to use sfinae for operator overloading though so I'm not really sure what they mean still.
Yes, you can. I didn't say you couldn't. However, find one place in the C++ standard where shared libraries are mentioned.
Seriously with due respect, is this a troll question? 3 years in c++ and you weren't aware of the fact that vector doesn't do bound checking with operator\[\], considering the fact that there are tons of posts, questions and articles about it in internet and its one of the most popular argument some people make against the usage of c++ ( no bounds checking )
In the same place it mentions libraries in general :) Many things we use daily aren't part of the standard, they are left for the implementation and the environment to define
Oh come on you can pass a variable to the index operator. How the blazes do you expect the *compiler* of all things to check bounds in the general case. 
Though as with other out-of-bounds accesses, this can be detected by AddressSanitizer.
&gt; It seems a bit scary, but logically it makes sense. Logically, it makes sense to split up libraries into different repositories. In practice, this only works when the modules are not coupled at all, when you can both technically and politically treat them as completely separate deliverables or products. For instance, we had a `render` module and a `metadata` module. `render` is responsible for drawing images to a buffer, and `metadata` is responsible for reading our file format that describes the stuff to be rendered. These seem like orthogonal concerns, so separating them made sense. Except that some parts of `render` are intended to consume the output of `metadata`. Solving this either requires directly depending `render` on `metadata`, or splitting out a new module with definitions of all the shared types. Since you can use either module without the other for lots of purposes, making the dependency sucks; and having a types library for every pair of loosely-coupled modules also sucks. So we basically wound up with a generic `types` module that contained *all* types used by two or more modules and was included in every application. So when everything is in different repos, an application making use of functionality from several different modules winds up with a *lot* of git submodules to fulfill all dependencies. It was very inconvenient, and required QA steps to ensure everything was always built using the latest versions of the modules. It became a huge pain in the ass to update a module, even if the change was 100% compatible with current usage. Things might have been different if it were okay to ship tools built with different versions of the framework, but our operational requirements demand that only one version of the framework be deployed in an environment at any time. So if there was any change to the framework, that needed to be propagated to all client applications. &gt; what if you need to write different applications that have a lot of common logic? Aside from the kind of core functionality that defines our framework, I have never found this to be the case in practice. If I have a complicated UI app with a bunch of workflow business logic encapsulated, and I need another feature, I'm going to extend that tool, not make a clone of it with an extra button. I don't want to maintain a second app, and my users sure as fuck don't want to learn or juggle another application. If it were up to them, literally our entire toolsuite would be shipped in one GUI application. For perspective, we seem to have about 100,000 lines of code in our framework library. Our largest application linked to that library has about 30,000 lines of code. Of that 30kloc application, basically none of it makes sense to re-use in any other application (aside from embedding the *entire* application in a client frame). And while I'm sure a lot of it could technically be pushed into a library, I cannot imagine that working with library-bound UI code would be pleasant at all. My basic rule on libraries is this: the first time you need a thing, just write it into the most convenient place to put it. The first time you need the same thing somewhere that it's inconvenient to get from the first place, put it in a library.
Oddly specific requirements... purely academic I assume...
Yes.
We did exactly that at my company. We have various libraries where all the plumbing goes - including a `lib/app` where library code specifically to help create a (generic) application goes - and then our actual apps all use these libraries and have very little code themselves other than their specific business logic. Generally the model has been ok, but after 5 years and ~50 developers, some results have been suboptimal: - The dependency graph has become quite messy _between_ the supposedly-separate libs. Also, most executable targets end up depending on everything anyway. (not all, but most) - Build times are longer because of link times. We have ~500 targets (90% are tests), so touching some popular lib means linking a _lot_. - It's very, very hard to keep the dependency graph clean and _lean_. By "lean" I mean _not_ including dependencies your target doesn't truly need. Code review won't find unnecessary dependencies, for example. At my company I think we're actually going to have an intern write a tool to go clean them up, because we can't find any existing tool out there that does it. (which is rather shocking, tbh) But on another topic, if you're starting from scratch and have grandiose plans, a few things I'd absolutely recommend you do on day 1: - Build with all compiler warnings turned on and set to error, so they fail compilation if hit. And I don't mean just `-Wall` (since it is most definitely _not_ **all**), I mean **ALL** warnings you can find in the compiler's docs. clang has a nice `-Weverything` that means what it says. Then disable what you don't care about by adding `-Wno-` arguments. (i.e., use the whitelist model instead of blacklist for warnings) It is very difficult to be more restrictive after you've got a lot of code. - If possible, have your CI build with both gcc and clang. (unless you're a pure Windows shop) You don't have to run the tests for both compilers' output, but compiling both will not only assure you can switch compilers later, but also they each detect slightly different warnings. - Build with ASAN. Trying to get it to work later is painful. Also, make sure your CI runs `valgrind`, and either `helgrind` or TSAN. Again, getting these things to work _after_ you've got a lot of code, is quite painful. - Use `clang-format` to format your code. Choose the format you want it to use, and put that format settings file in your git tree. Every editor/IDE I know of can be setup to use `clang-format` automatically on file-save, so you don't have to worry about it once it's setup. You can also add a git pre-commit hook that runs it and verifies the code is ok, just to be sure. - Pick a unit testing framework _carefully_. Don't just go with what seems easiest to compile in an hour. Changing it out later is not trivial. Reddit seems to favor `catch`, but at my company we started with `googletest` and I'm really happy we did. ymmv. There are ton more of such things-to-do when starting fresh, but a lot depends on what you're building and your target OS/environment, etc. Someone could write a big article about it... actually, maybe someone has? I dunno, my google-fu isn't good enough. 
How? &amp;#x200B; I have the CMakeLists.txt files for my project which work well in linux but not in windows! I followed there instructions(or whatever they are) and used the shlwapi library, still getting linker error. where did you get the documentation or do you know of an example?
Yes. 
 How? I have the CMakeLists.txt files for my project which work well in linux but not in windows! I followed there instructions(or whatever they are) and used the shlwapi library, still getting linker error. where did you get the documentation or do you know of an example?
I did this on VS2017. I followed the instructions and built a Lib. What issues do You have? 
I am using VS2017 too but I need to be able to build it in the cmd, using CMake. the library gets build in the src directory! not in the Release directories! &amp;#x200B; having some trouble linking the library. would need an example, where it is NOT INSTALLED but used. getting linker error
I have that Modern C++ Design book in my shelf but I didn't remember policy-based design as an implementation technuique that uses CRTP a lot. I'll take a look again. &gt; wouldn't the person defining the trait have to define those defaults? Yeah. I think so ... unless you accept the help of a macros. Right now, I don't see a way of easily providing those implementations for a large group of types because that attempt I can think of leads to code like this trait MyHelperTrait { fn cmp(&amp;self, other: &amp;Self) -&gt; Ordering; } impl&lt;T: MyHelperTrait&gt; PartialOrd for T { fn lt(&amp;self, other: &amp;Self) -&gt; bool { self.cmp == Ordering::Less } fn gt(&amp;self, other: &amp;Self) -&gt; bool { self.cmp == Ordering::Greater } fn le(&amp;self, other: &amp;Self) -&gt; bool { self.cmp != Ordering::Greater } fn ge(&amp;self, other: &amp;Self) -&gt; bool { self.cmp != Ordering::Less } } which I believe is not allowed outside the "translation unit" where `PartialOrd` is defined. The trouble here is that `T` could be anything and potentially lead to conflicting implementations of `PartialOrd`. The compiler is very strict about this. These generic implementations tend only to work within the same "translation unit" of the trait. I don't know the exact rules and maybe I'm wrong.
1) what’s the state that’s updated each loop iteration? 2) make a function with that state as the inputs 3) ??? 4) profit
Yes. I had that too. I modified some output settings in the configuration files. Can't check it now. I'll answer when I find it. 
you modified their config files? &amp;#x200B; guess thats the only way thanks 
sometimes amputating a limb is the only way to stop disease ;)
yes, I built and installed it via [vcpkg](https://github.com/Microsoft/vcpkg) without any problems recently.
no installation only using. installation is easy, i cant make people install stuff just to checkout my library
There definitely are some cases where CRTP can go further than Rust traits, partially because of C++'s post-instantiation type checking and partially because of Rust impl coherence rules, but traits are already *really* close to CRTP and will only get closer with impl specialization. For example, with impl specialization, you might decouple the comparison methods from `cmp` like this: trait Ord { /* 6 comparison declarations */ } trait Cmp { fn cmp(&amp;self, other: &amp;Self) -&gt; Ordering; } impl&lt;T&gt; Ord for T where T: Cmp { /* 6 comparison implementations, in terms of `cmp` */ } (Disclaimer: specialization is not totally nailed down yet and also I could be missing something about coherence rules, but hopefully you get the idea.) Overall, though, this is basically the modules-vs-typeclasses question, which has been pretty well-studied.
Vcpkg's purpose is for installing a library to "use" it. 
i understand but i have to use it without installing, like link to the local built library
That's cat vcpkg does : https://github.com/Microsoft/vcpkg/blob/master/docs/examples/installing-and-using-packages.md
no it creates a globally accessible version of the library which i am trying to avoid
&gt; I've been using C++ for about 3 years now Out of curiosity, what other programming languages did you know before starting C++?
Cool, I hadn't heard of this feature. However, AFAICS, this is not opt in? Doesn't this mean that all T that implement Cmp will now automatically implement Ord in the manner describe? Can they then override it? In this particular example this probably isn't important because Cmp serves little other purpose. However once you start doing policy based design, then I think this (and the late checking you mentioned) probably become critical. It's good to see that Rust is adding these things.
Have I insulted you somehow? Where did I devalue your opinion on the matter? Where did I claim to be an expert? I felt the need to mentioned my background (Those two decades include my first computer course in school btw., so really not all that impressive imho), because I felt that you painted my opinion as that of an uninformed, inexperienced newcomer to the language or maybe a rust evangelist. ("You do not understand at all ...", "once you have seen...") without knowing anything about me. Maybe I am informed but have simply drawn other conclusions?
You can write the `impl&lt;T&gt; Ord for T` block in such a way that it can be overridden on more specific `T`. You could also condition this `impl` block on an additional trait to make it even more opt-in, if `Cmp` also existed for some other purpose. In general the typeclasses side of this divide has more tag-like entities in programs, like the extra `Cmp` trait here, or newtypes used to get around the coherence rules, or whatever else.
Yes. And easily as well! The Google benchmark lib has uses cmake. It suffices to add it as a subdir to your project (via git submodules) and it will build and link automatically on windows. 
Solid article, thanks for sharing. You might speak a bit more about the setup of your agent. Any reason vcpkg setup is not a part of the jenkinsfile?
The agent we use at work is a simple Windows Server. No actually there is no real reason, except that we only need to intall all necessary dependencies once with vcpkg. So there is no invocation needed at every build. If we would use a docker based build system your right, then we would need to resolve all dependencies every time we build.
Because it's not necessary? It just hurts performance.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b68jo8/very_urgent_id_really_appreciate_it_if_u_guys/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The installation argument needs the CMake installation path which is provided by the variable InSearchPat. That’s basically the same you get with $path under windows
Perhaps a diagram of the folder structure on the agent would make it clearer. I read ```installation: 'InSearchPath'``` as meaning something slightly different, but I think I have it now.
I used Bamboo and currently I'm using TeamCity which I really like I've never used Jenkins though. Do you have any experience with its two competitors?
No sorry, I used circleCI which is also pretty nice 
I know the CMake plugin syntax is confusing. It’s really the path where Jenkins find the CMake installation. In this case there is no build directory defined which then is the workspace as default
Depends on how you define "library" are you just talking about e.g. individual cmake targets or full fledged separate library projects with their own repository, ci-pipeline, versions, documentation a.s.o? The latter becomes pretty difficult to manage while the whole system is under active development. In particular interface changes now require you to coordinate commits/versions between different libraries and finding all consumers of an interface becomes even more difficult. In my experience, a separate project is only warranted when a significant amount of implementation complexity is hidden behind a (relatively) stable interface and is itself used by multiple different projects. But the way this usually develops is that some functionality is developed as part of an application and at some point it is either stable and/or complex enough that we say: Ok, we are putting this into a separate project and fixing+generalizing the API. Now having your code inside an application separated into individual modules, where each module might be it's own build target/library is certainly best practice. Especially, because it simplifies unit testing.
How about Herb Sutter's "Zero-overhead deterministic exceptions: Throwing values"? http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf Other places where Rust is an inspiration for future editions of C++ are improved lifetime tracking, pattern matching and language variants.
ABI is defined by OS, not by a language
This looks like a very interesting blog. I'll have to add it to my bookmarks. Thanks! 
Thanks, no need for bookmarks, just sign up for following and your always up to date
I use top of tree as a submodule in my projects and it builds without any issues on Windows.
It should not be your responsibility to fetch or compile your dependencies. Leave that to the user. If the user just wants to quickly check out your library, he can use things like conan or vcpkg for that. If he wants to seriously use it as part of his app, there is nothing more annoying than when each library tries to implement it's own package management system and I end up with 5 versions of the same lib, because everyone of my direct depencies decided to pull it in in their own unique way.
Strongly disagree. vector::at() should never be used - exceptions are for recovery, but recovering from logic errors is questionable. If you aren’t absolutely certain that your indexes are valid, you need to restructure your code.
You can install it in a prefix in a subfolder in your project. This is the easiest way to a dependency local to a project.
Lot of good work put into C++ gradle project. You should check it out! Gradle streamlines most manual work you have to do on cmake. Only issue is you cannot use or create visual studio build files.
&gt; In particular interface changes now require you to coordinate commits/versions between different libraries and finding all consumers of an interface becomes even more difficult. This usually devolves into asking the resident greybeard, then pushing the changes and seeing what starts breaking on the build server.
I did. 
Yes I used gradle for java, but never with C++. I will definitely give it a try
That does cover a lot of things. I am finding more and more things area trivial these days. But yeah, if you can bit_cast, it is a blessed way of type punning for things that could be done in C too. 
Thanks for the article!! I've been unsuccessful in the past using the pipeline CMake plugin. In my case, I don't get any regular nor error output from the CMake step, so I can't see what went wrong when the job fails, but rather a simplistic "cmake failed with error 2". My alternative was basically manually calling cmake via 'sh' steps. Does this problem sound familiar?
Thank you! I like that you say "It's easier to get forgiveness than permission" because very often, that's exactly what having good initiative is all about!
That's a very good point. Crap I remember now. I used to be able to identify out-of-bounds because the program would always segfault at runtime when I tried to access an out of range index. But last night was the first time the program just kept running without segfaulting.
Ah, I see. So I was probably misremembering an implementation-dependent runtime catch, I edited my OP.
Lol no troll. I don't use it as professionally, so you don't have to worry about planes falling out of the sky. I think I was conflating out-of-bounds checking with runtime segfaulting. I edited my OP about that.
Python. Maybe that explains my compile-time/run-time conflation as explained in my edit to the OP.
Totally agree
Thanks thats a good description.
&gt; giving too many choices can be counterproductive, especially if those choices usually don’t matter in the big picture. An important principle that's imho far too rarely considered in c++.
The APIs in other languages most likely are just wrappers around the REST API, maybe with some nice wrapping. You could certainly read the source of those libraries to see what they actually do.
they mentioned the best way was to make cmake download and build googletest, i was planning on doing the same with benchmark
Largely I imagine because teachers don't know C++. When I was at school twenty years ago it was still an obsession with basic. 
Nothing wrong with learning pure C. It has its uses and it's an elegant language in its own way. 
Any of this get activated with c++ parallel algorithms?
I've never touched VB so I can't compare it to anything. But did you take a class called C and then VB was taught instead? 
I've never touched VB so I can't compare it to anything. But did you take a class called C and then VB was taught instead? 
C is taught because it allows you to express data structures very effectively and precisely. It also makes you appreciate all the garbage collected languages. The main goal is not to learn the language, but the concepts. btw modern c++ has std::array for static raw arrays
Most places I've seen and worked use "modern" c++ in a pretty scattered way. Some of this, some of that, some none at all, some all in. Teaching the base in C I think is correct for unis. The higher level stuff is pretty easy to pick up if you are strong enough in the fundamentals, and at least in my experience its pretty likely that X stl feature won't be really allowed.
I don't think there is anything wrong with learning pure C. C is a very powerful language in it's own right. But that's the point I'm driving at, why do we call it C++ then? Although C++ is an extension of C, they are still very different languages and I feel C++ gets crapped on a lot because "it isn't modern enough." Or "behind the times." Which isn't true.
Basic is not the same as VB. Think older :)
Take a look at r/Fortran. Seriously. Students are being forced to program in Fortran 77. Yes, that's right, in 2019 students are being taught to use a language *standardized* in 1977. I had a professor that was giving introductory C classes in my Computer Science course that couldn't write a single line of C before writing in in Pascal. With rare exceptions professors don't care about updating themselves.
I guess it should be made more clear. "In C you have to do this. But in C++ we have std::array to take care of the back end of that stuff." I listed vector because I didn't learn about vectors until my 3rd year in school. 
This is very exciting news to me. I’ve been waiting too long for MSVC to support more recent features of OpenMP and I now have hope that they’ll actually focus on implementing OpenMP 3.0 and 4.0. Plus, I can use this to convince my group to upgrade to VS2019.
Kate Gregory has a [CppCon talk](https://www.youtube.com/watch?v=YnWhqhNdYyk) on this and I largely agree with her. I think teaching the basics of C++, with vectors, strings, and smart pointers first and then later on teaching pointers, printf, etc if it's necessary is the optimal way to go. The main reasons are that there's just way too much going on with C style coding, which is valuable in the eyes of a more experienced programmer, but not in the eyes of a beginner in my opinion. The vector is great, and it has the [] operator to access arrays, do for loops with and such. No need to touch iterators. Working with a string class makes sense, where as working with char* will be a heck of a lot of explaining. I think a lot of professors are just busy with their research, and are not necessarily software engineers. I kind of wish students would be forced to read a tour of C++ by bjarne when learning C++, it says so much and it's actually readable unlike the massive C/C++ textbooks you read in universities. 
I'm in a Modern C++ course and my professor briefly explained that Modern isn't often emphasized in higher education because a) job interviews mainly test basics so just get real good at that, and b) companies may not have caught up with the times and it would be difficult to just overhaul all that code. IDK, all I know is that I'm really lucky to be learning this at the Community College level.
Make that premake and I'm in!
Great to see Microsoft working on this! Amazing :-) Two questions: 1) &gt;/openmp is not compatible with /permissive- or /Zc:twoPhase Is this true? The latter I could live with for now but unfortunately not the former. 2) Will/is Eigen able to profit from that? Presumably it might need code changes in the form of updated `#ifdef` directives, or something like that? Anyone from Microsoft working/communicating with the Eigen team? This would be the ideal test case for you guys.
That is a big OOF from me. I wonder if going from Fortran to any other language would be easy.
Are you asking "why are they still teaching C in school" OR "why are they teaching a called 'Programming in C++' and excluding almost every useful feature of the language." &amp;#x200B; To #1: C is still useful as a systems programming language good for teaching memory management and low level operations. As long as the UNIX kernel is written in C and every embedded manufacturer provides a C compiler in their IDEs/SDKs, C will never die. &amp;#x200B; As to #2: because profs don't work in the field so haven't worked on massive coding projects to know what's useful or isn't. Also CS education has shifted to Python and Java so no one was motivated to update their textbooks beyond C++98 standards. Most profs never advanced their understanding beyond "C with classes." I learned C++ in 2000 (1st semester CS) and 2003 (2nd semester CS). We used std::string, the prof's library had his own implementation of std::vector as well as matrices, stacks, and queues. We didn't have smart pointers, but mostly passed by reference anyway. Maybe it wasn't in the language back then, but we never covered the iterators common to all STL containers. We also used cin and cout. Unfortunately, we were also taught to type "using namespace std." &amp;#x200B;
&gt;(unless you're a pure Windows shop) Even then you should really use CI with at least one of gcc or clang :)
I was lucky enough to have an adjunct, professor who is in the industry, teach me modern C++ in the most phenomenal way. I just wished it was taught early in my academic career.
C is usually taught when the goal is to force students in to become familiar with a more limited language. I.e. learn fundamental data structures and algorithms, system programming concepts like memory allocation. You COULD do this with C++, but why bother with the eventual questions about ABI incompatibilities and the STL. 
\&gt; Why is there a lack of modern C++ developers coming out of the education system? I think you're asking two different questions. &amp;#x200B; At an introductory level, C is much better because it is a closer model of how things actually work short of learning assembly language. This is better when you \*start out\*. &amp;#x200B; Classes like \`std::vector&lt;T&gt;\` and \`std::string\` provide high level abstractions which are critical for writing \*safer\* code, which is necessary for writing industrial scale programs. You should absolutely learn C++ in \*upper division\* classes, so that when you come out of the education system, you will be trained in industrial techniques.
#2, #1 I totally understand and respect.
I think I did ask two different questions. I guess I meant to ask, "Why is a class that is called C++ is taught C with standard out?" For the fundamentals I completely understand that it is taught in C.
I don’t.
A nested class can access all members of it's outer class, including privates. Basically it has member access, as the nested class is, itself, a member. 
That sounds like a badly named class or a badly taught class.
You missed a big one. Do you support overrides? F&lt;Sigs...&gt; instead of F&lt;Sig&gt; you cannot efficiently implement `F&lt;Sigs....&gt;` on top of `F&lt;Sig&gt;` for *any* case you listed, but vice versa is trivial. For example, function ref needs `sizeof...(Sigs)+1` pointers one way, and `2*sizeof...(Sigs)` the other. And I find overloaded function refs to be awesome for callbacks. 
You can enable bounds checking for the [] operator [in libstdc++](https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_macros.html) using `-D_GLIBCXX_ASSERTIONS`. Fedora added it to the default distro build flags a little while ago, and it turned up all kinds of interesting errors.
&gt; Also, I keep hearing about "modern" C++. Is there a guide or book on how to code in "modern" C++? The resources I have found so far only go over features, but not style. Obviously there is no authoritative definition of the term, but I think [Peter Gottschling's Discovering Modern C++](https://www.amazon.com/Discovering-Modern-Scientists-Programmers-Depth/dp/0134383583) is a pretty good resource for getting started
Vb is about thirty years younger than Basic. I'm in Britain so basic was pretty much it. Cememted by the BBC Micro with actual prime time evening TV programmes on basic programming - and nobody owning atari or Nintendo in the 80's and zx Spectrums, Amstrad, commodore, Dragon 32 and Acorn owning the market for home games - all using basic. 
I believe FORTRAN has uses still in scientific computing. Being faster than C in its target use cases
Interesting article. I’m personally quite frustrated by the actual `std::function`’s design choices. In particular, the lack of a move-only option has caused me to have to do my own type erasure for a few different use-cases. One thing that isn’t mentioned in the article is whether the function should be invocable when const. This is one way that the const-semantics of a `std::function`differ from an ordinary lambda, and I have always found it odd.
Might want to listen to [this](https://overcast.fm/+EN2Y7BfFI) episode of CPP cast where they interview Titus Winters on maintaining large codebases. Many of the problems they discuss are only applicable to giant companies, but you also get some good insight into why Google (who Titus works for) uses a monolithic codebase. Not saying it’s the only or right way. Other companies do different ways. But worth a listen regardless. 
Consider monorepo, and build system that would work for you - [https://www.youtube.com/watch?v=W71BTkUbdqE](https://www.youtube.com/watch?v=W71BTkUbdqE) &amp;#x200B; For example, MSBuild simply does not scale (well), when the number of your projects (\*.vcxproj, etc.) grows, or just the number of indepenently compiled units (e.g. certain \*.cpp files compiled one way, others another). CMake, PreMake, etc. anything that generates .vcxproj is not going to work. &amp;#x200B; So choose something that would work (if you want lots of small pieces reused) - like Ninja (CMake, PreMake and others can target it), or something completely else (Buck, Pants, Bazel, [Please.build](https://Please.build)). &amp;#x200B; Some of these actually support multiple-repos. &amp;#x200B;
Thanks for clarifying. I still stand behind my remarks. I did a quick review of my old text from back then. In fact it's freely available [online](https://www2.cs.duke.edu/csed/tapestry/) under a CC license since rights reverted to my prof when it went out of print. &amp;#x200B; From the intro: &gt;In particular, this is a book designed to teach programming using C++, not a book designed &gt; &gt;to teach C++. Nevertheless, I expect students who use this book will become &gt; &gt;reasonably adept C++ programmers. Object-oriented programming is not a programmer’s &gt; &gt;panacea, although it can make some jobs much easier. To mix metaphors, learning &gt; &gt;to program is a hard task, no matter how you slice it—it takes time to master, just as &gt; &gt;bread takes time to rise. &gt; &gt;\[...\] &gt; &gt;Although this book uses C++ as a tool to be used rather than studied, students coming &gt; &gt;out of a first course must be well prepared for subsequent courses in computer science &gt; &gt;and other disciplines. Therefore, the essential features of C++ must be used, studied, &gt; &gt;and mastered. The syntactic and semantic features of C++ sufficient for an introductory &gt; &gt;course are thoroughly covered. At Duke, we teach our first courses using C++, and then &gt; &gt;we move to Java. We have had great success with this approach. **This book uses C++,** &gt; &gt;**not C. In particular, there is no coverage of I/O using printf and scanf, there is no** &gt; &gt;**coverage of C-style (char \*) strings, and the coverage of C-style arrays is minimal and** &gt; &gt;**included only because initializing an array with several values shortens code. Instead,** &gt; &gt;**we use streams for I/O, the standard C++ class string, and a modification of the STL** &gt; &gt;**vector class called tvector that performs range-checking on all vector accesses.** &amp;#x200B; I think my former prof (I only had him for second semester) agrees with you. Some authors, did not have that goal in mind. Some authors (and publishers who are always encouraging new editions to eliminate the used book market) are looking for a quick buck and dusted off their C texts and made a "C with classes" text. I imagine a lot of the early C++ for scientists and engineers texts were similar. Numerical code doesn't really need OO concepts although operator overloading on vectors and matrices is nice. So when C++ was the language of the day, and they needed to put out a text in C++, lots of old C code got reused.
So no unique_function in C++20?
Irrespective of the implementation, you need to use the rest client apis. It's very easy, usually your have an endpoint, a resource and the http verb. endpoint: http://www.testresults.io resource: /proj1 verb: get A slight google search about any rest client implementation will give you the overview. 
plus there still aren't any documentation for that too
What if the indices come from some sort of input and are rarely expected to be invalid? Is vector::at() still significantly worse than other solutions, eg manually sanitizing the input? If so, why?
I had to use a shared_function so that it could be registered and unregistered. The shared_ptr was used to find the function within a map. 
Because school learn how to think not how to master a language.
Where is the data?
The problem is not using Fortran, the problem is using Fortran 77. There are more recent Fortran standards and most compilers support it. Also, Fortran being faster than C is a myth, particularly after the introduction of `restrict` in C99.
Yuck! I skimmed over that. I can believe restrict makes C just as fast, particularly in vectorizing code.
Well going from *modern* Fortran (i.e. Fortran 90 onwards) to other languages is not very hard. Fortran 90 is actually nice if you're not doing anything fancy like I/O, or working with pointers. But going from Fortran 77 to anything else is.
Build the benchmarks and run them to generate data for your system. I will be posting some results on the wiki analysis page when I get a chance.
You probably want to use intrinsics with Eigen rather than automatic loop vectorization. It's hard to beat carefully crafted optimizations.
Same! It's great that the VS team got around to improving OpenMP features.
In high school (around 1999), I was taught a horrendous mishmash of C and C++. In college (around 2006), I was taught *somewhat* more modern C++, but it was still a mess. In 2009-ish, my workplace paid for some training using material produced by Scott Meyers. *That* was pretty cool because we went pretty deep into templated types and features provided through TR1 (the precursor to C++11). But I had a decade of using unnecessary C-isms in my C++ code. I blame the earlier exposure on the school not having the funds to buy C++98-compliant software and retraining the instructors in its use. I blame my exposure in college to being taught by academics with little connection to industry best-practice.
You should not package benchmarks along with your application.
Most people would rather use Matlab instead because it is much nicer for making interfaces. For big matrices computations, it will work the same, it calls some BLAS library with handwritten assembler.
It would seem programmers have a hard time naming \_classes\_ , I wonder why...
This is always a challenge since people who go to school in software want to go out in the industry and make a boat load of money. No one goes to be a professor and so we have this bad match of professors only spending their academic career doing research, and adjunct professors who are in industry but do not necessarily have the best teaching skills. 
I think the biggest mistake developers make is forgetting YAGNI principle. You will not lose anything much by making a monolith, but you will add overhead with a micro library approach. Until you're servicing other developers in your company, a monolith is fine.
&gt; Suppose you're going to build your own company and that you can decide everything about your future codebase. I'm am entrepreneur. You're welcome to check out my flair code. &amp;#x200B; &gt; Last but not least, in contrast to cpp core guidelines ( if I recall correctly), I prefer separate classes in different small headers, instead of putting everything into a single one. I went from that approach to a single header. Someone suggested going in that direction to me and at first I wasn't very convinced, but now I'm happy with it. For one thing my build times are cut by half.
why? I can add an option. to be honest I have to use it first which is turning out to be impossible
There are ways to bind to code written in other languages, of course. https://www.boost.org/doc/libs/1_69_0/libs/python/doc/html/index.html But if those private libraries are _not_ just using the network, how on Earth are they working? Are they running on Instagram servers? If they are using the network, it's probably easier to just use that.
&gt;I do know the rest apis from Instagram but it seems to me that both of them do not contain useful features. &gt; &gt;[https://www.instagram.com/developer/endpoints/](https://www.instagram.com/developer/endpoints/) \- almost no endpoints &gt; &gt;[https://developers.facebook.com/docs/instagram-api/?locale=en](https://developers.facebook.com/docs/instagram-api/?locale=en) \- only usable for business accounts Didn't i mention them or what do you mean? &amp;#x200B;
This is such a good post. My previous company had a setup similar to what you describe with the small libraries, and using `lib/app`. We ran into the same issue where the dependency graph got out of hand. Although, many of the worst offenses could have been caught with better code reviews in our case. I also recommend googletest. It works very well. Never tried catch. I've never thought of `-Weverything` and making a whitelist, but for the next project I start I'm doing that. 
It's telling that one of gcc's main bugs on this has been open for more than ten years: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=2316 IMO, Visual C++'s method of handling this is more sane than the standard: different calling conventions are handled by the `__cdecl` and `__stdcall` modifiers, which unlike linkage can be applied to templates and static class member functions. Captureless lambdas are extended to have an overloaded conversion operator that automatically supplies a function pointer with the appropriate type. It just works. 
I have never heard of this being done before. I’m having trouble of thinking how I would take it vantage of it probably because I’m not used to having it available. Can you expand on the kind of things you tend to do with this?
&gt; Down side is the null terminator needs to be added ... From what I read on the theory on SSO, the null terminator comes for free [if you implement it correctly, or should I say well], but does reduce the effective length by one, of course.
As far as I know, ABI is defined by the compiler vendor, and there is no standard C++ ABI, that's the main reason we often use C ABI which is still not standardized, but very stable. 
Because most people who do that teaching learned everything they know about the language before most of the new stuff or even before C++ became a relevant language besides C.
COuld you... elaborate please?
I think using e.g. ISPC for efficient SIMD is a far superior approach. I think that extending the language with pragmas is not a good direction, in general.
I read not so long ago that the type `unique_function` has been proposed for move only functor types.
Even id got stray within the capacity of the vector?
Oh that's moment when you turned 31 years [https://i.dailymail.co.uk/i/pix/2014/05/21/article-2634986-0077020000000258-859\_306x516.jpg](https://i.dailymail.co.uk/i/pix/2014/05/21/article-2634986-0077020000000258-859_306x516.jpg)
Just had a look on the memcpy test and basically it's (as expected) just some loop code (so at least you didn't test the std/library implementations). However I do not see where there is the comparison against the library provided memcpy - which is afaik somewhat more optimized than any implementation in the test? However you didn't specify which compiler you've tested, nor any flags for the respective compiler. Of course I'll get very bad results in -O0 compared to -O3 (both, in runtime and the generated assembler). Same for a huge bunch of vector optimizations. Can you provide a explanation on what you tested and what your expected results are, i.e. what you lead to your conclusion for huge possible improvements?
Almost my preferred way, except for the idea of a library as a linkable target (neither dynamic, nor static). I totally prefer to have a "library" as a tagged release as code I compile into a larger application. For this approach we're using include-cake files, so dependency management is a breeze. The benefit is one (rather large) binary and absolutely no hassle with customers who do exchange some dynamic libraries on their own. And the second benefit was a slight performance increase in the executed code, compared to static libraries, as the whole codepath is optimized. Drawback is of course a longer compile time for a release, but that doesn't really matter.
Yea, sometimes it is. &amp;#x200B; In this case it is not.
They still do, both in debug and release mode. Use `_ITERATOR_DEBUG_LEVEL` macro to control it.
The code looks equivalent to what I responded with. I havn't tested it, but I think this only works if `trait Ord {...}` and `impl&lt;T&gt; Ord for T` are placed in the *same* crate due to coherence concerns. Right? Your example also doesn't seem to be related to "impl specialization" unless // 6 comparison implementations in terms of `cmp` expands a use of the default keyword like this: default fn lt(&amp;self, other: &amp;Self) -&gt; bool { self.cmp(other) == Ordering::Less } default fn ... which then would allow other overlapping implementations for `Ord`.
The null terminator isn't a problem with SBO, but it will still be there when it transitions to a large buffer.
&gt; Can they then override it? *This* is what "impl specialization" is about: Overlapping trait implementations. But instead of a possibly complicated resolution algorithm to pick the right implementation of a function, the current experimental design simplifies this by requiring the less "specialized" (and therefore less preferable) function implementation to be defined using the "default" keyword. See my [other answer](https://www.reddit.com/r/cpp/comments/b5wkw7/writing_c_from_a_rust_developers_perspective/ejk5hx6?utm_source=share&amp;utm_medium=web2x).
\*you\* do not anything about me either. Let us stop here. Bye. I do not care about reddit karma at all. People do not like unpopular straightforward opinions. I am downvoted often only for speaking my mind and I am happy about this. A nice day to you.
Been proposed a few times in fact! Question: Is it difficult to find and read these proposals?
https://github.com/potswa/cxx_function/
Does this work even if you happen to end up accessing memory of another valid object outside the vector?
Thanks for sharing! Interesting additional topics should: 1. test code coverage 2. warnings report 3. run tests with sanitizers 4. clang-tidy integration 5. [cppcheck](https://blog.kitware.com/static-checks-with-cmake-cdash-iwyu-clang-tidy-lwyu-cpplint-and-cppcheck/) could run by using the `compilation_commands.json` or the `CMAKE_CXX_CPPCHECK` 
Sure, Rust owes a lot to C++. But A influencing B and B influencing A are not mutually exclusive. Specifically, Rust added "borrowing" to "C++ ownership" which kind of makes its way back to C++ with Herb Sutter's efforts to allow static checking of lifetime safety. I even see C++ programmers using Rust lingo: Describing a set of types as ["**borrow** types"](https://quuxplusone.github.io/blog/2018/03/27/string-view-is-a-borrow-type/).
YMMV. 
Thanks, that’s a good point 
In addition, using `std::move` where it isn't necessary, could actually hurt performance. Just saying.
Are you using `-march`?
Don't hold your breath. They only added this subset because it's used a lot in ML libraries. All the feature requests for actual modern OpenMP support each with lots of votes on them have always been declined.
No, I didn't state results - because different compilers and OSes will have different results. What I have tested is a pretty large cross section of common and embedded OSes and compilers - but those results are too much to share. Some OSes are shipping with unoptimized versions of memcpy and memmove, some with semi-optimized versions, and a few with well optimized versions. I'll go over that in my analysis, when I have time to sort out all the spreadsheets and write a proper summary. &amp;#x200B; Also, you should try running the test and reading more closely (starting with main()) - as it does obviously test the library functions.
I use std::any as a type-transparent attribute type for tokens in a translation framework. To this day, I still think using a std::string instead would ultimately work just as well and faster.
I was doing multimedia and was the almost only choice to work with video. Now I use OpenGL frameworks in C++ whenever I can. 
MS's NIH syndrome with respect to commandline options at work again. gcc/clang have nicely separated this as -fopenmp-simd cause it requires no runtime. But no let's use the puzzling 'experimental' suffix again even though it's 'production ready' and let's also couple it with the runtime.
You can read them, it's not hard. Maybe try this to learn how to find them: https://wg21.link Also most of these proposals have implementations available on GitHub. I use one in production and I believe I'm not the only one.
No. In particular things like /fp:fast are not safe to engage. We do not believe OpenMP's parallelism model is appropriate for the standard library because we want to be good citizens of the system, we want system wide knowledge to drive thread creation policy rather than blindly creating number of cores threads. See https://channel9.msdn.com/Shows/Going+Deep/Inside-Windows-8-Pedro-Teixeira-Thread-pool for more details.
From my experience, the more complex the problems are, the less complex the architecture is. Human brain can only take so much complexity, so when this capability is spent on things like computational geometry, physics simulation, or inherently murky optimization (in the mathematical sense) tasks, the code itself grows simple. I'm now working on 3D printing company's SDK and all the mathy parts are basically all about one pattern. Previously I've been working on really boring SCADA system that just moved some bits around, and it was 90% architecture for the sake of architecture. I've witnessed this effect in game dev and back-end too. The harder the problems - the simpler the code. This both shows that writing simple code actually doesn't take too much brainpower; and that it's for some reason impossible for bored engineers. So I'd say the best way to handle accidental complexity is to keep ones head busy with essentially complex problems. 
c++ is a tool. Universities tend not to focus on teaching tools but principles. Modern c++ is too high level to be useful when teaching fundamentals of how computers work. On the other hand, all the low level complexity and gotchas make c++ not necessarily the ideal language to teach high level architectural concepts or completely new paradigms (e.g. functional programming or distributed architectures). That being said. I hope ever course using c++ is also using `std::vector` where appropriate, but if that already counts as "modern" we are in big trouble.
Also, I would strongly disagree with function length principle. A function should be unifunctional, yes, but the length is irrelevant. It's just if a function grows multifunctional then it should be split. But if it's doing one job, then it doesn't really matter how many lines does it take. It's usually less then more, but if for a good reason it takes more, just let it be. For instance, it might be a dispatcher for some elaborate protocol: a huge switch-case with really simple branches. If there is no good reason to split it into smaller chunks, say inherently isolated parts of the protocol, then splitting just to meet some arbitrary length criteria will only add complexity not reduce it.
did you check recently?
How about going full YAGNI and moving code to a library only after it is actually needed in two places. Like others here I've seen build and link times increase after a project has grown to 10s of devs, and everything ends up depending on everything. Whereas old me would've put utility functions I create as 'low' as possible, now I create them exactly where I need them and move them down later on when I actually need them in another place.
I am pretty sure it is cheaper to validate your input than to recover from an exception.
Because it forces users to install the benchmarking libs in order to run your application
i can give a option like it will downloaded only when debug or you have to pass an argument. &amp;#x200B; i just dont want people to have trouble setting up the benchmarking tool to benchmark my libs
\+1 for "Unfortunately, we were also taught to type "using namespace std."". 
&gt;its pretty likely that X stl feature won't be really allowed. Yeah, by programmers who never learned C++ features properly, most likely because they weren't taught it in university and are the kind of people who are too scared to try and learn anything on their own.
Cheaper is a non-issue for exceptional cases. Using indices from input is unlikely to be in a hot loop anyway. My question is about readability and correctness, not performance.
This is really sweet, nice work bro. Too bad no compilers can even nearly live up to the awesomeness of your test, I cant wait for the day loops containing things like x[i] = min(x[i], y[i]) automatically become excellently organized avx512. Can't wait to checkout your other code.
Every time you post an update I spend 10 minutes on mobile to find a link to that page. Maybe next time you can post a direct link to the wiki?
There's a whole subgroup that does surveys out in the industry to make sure there's not too much friction picking keywords that clash with existing identifiers.
The purpose of 'identifiers with special meaning' is to avoid breaking old programs that use these identifiers, and in the case of `delete`, there's no valid program that uses it as an identifier. Plus, allowing `delete` as an identifier would produce ambiguous, or at least very confusing cases: template&lt;class T, class... Args&gt; void f(T t, Args... args) { t.operator delete(args...); // does `operator delete` name the deallocation function, or some type conversion function? }
Great post Robert, we'll totally in tune.
Interesting real-case scenario. I still think that the approach I'm suggesting is the one I should keep. The "only" downsides I see are the lack of tools to manage the dependencies (this can be fixed if some good soul finds the time to write them) and the incresead link time (not sure about this). Totally agree on your awesome list of tips .
Seems like it was discussed on Kona and still has a chance to be included: https://github.com/jensmaurer/papers/issues/98
Can you be more precise about "dependency graph got out of hand." please?
You can try Gitlab-CI. Pretty simple but really powerful (i do like TeamCity tho, but it is another style)
Adding new keywords that are reserved everywhere could break a lot of existing code. Therefore the choice is often between making it only have special meaning in certain contexts, or spelling it in an *unusual* way that is unlikely to be used in a lot of code bases. Words that are already keywords are valued highly because they can be reused for different purposes so it's unlikely that the committee is going to allow the `delete` keyword to be used as a normal identifier.
Looks nice and shiny. If the company I work for used git it would be an option. Thanks!
I think they mean that you don’t need to build with gcc and clang if you’re pure windows, not that you shouldn’t use CI. Although in most cases you can use clang to compile on windows now so perhaps they’re just not aware. 
&gt;individual cmake targets or full fledged separate library projects with their own repository, ci-pipeline, versions, documentation a.s.o? I'm speaking about the first at the beginning of the development stage, but with the second as goal. I'm still investigating the 1-library = 1-repository option / N related libraries in 1 repository / All libraries in the same repo. As I've already said, the first option seems the most logical one, but the problem is the lack of good tools. I would probably use submodules , but also in this respect, git-submodules need to improve..
You could have that today with ISPC
Would be pretty hard to allow `delete` as a type name given that delete p; Is already valid and means something quite different from declaring a new object named `p` of type `delete`.
Hi Noah, how much are you paying per hour?
Also as a variable: delete ([] { return new int; }); But honestly, who would write something like that :)
Identifiers with special meaning are used because they can only appear in very restricted places unambiguously. Take `final` for example, it can only appear after `struct Foo` where it can't have another meaning, or after a function `void f() final` where it also can't have another meaning.
A really simple case is a variant_ref. A `variant&lt;A,B,C&gt;` has a few fundamental operations; `visit&lt;A,B,C&gt;`, `store&lt;A,B,C&gt;` and `destroy` (not all code blocks are actual C++ code, some are pseudo-code). Everything else can be viewed as composition of those operations (copy/move is a visit in one variant followed by a store in another). Both visit and store are (compile-time) polymorphic; they can take an `A` a `B` or a `C`. And they can be separated from the variant. `variant_ref&lt;A,B,C&gt;` is basically `function_ref&lt; void(A&amp;), void(B&amp;), void(C&amp;) &gt;` -- there is nothing you can do to a `variant_ref` other than visit its contents. So if you want to expose some data of one of multiple possible types *without* exposing the memory layout of the storage or making a copy, a `variant_ref&lt;A,B,C&gt;` aka `function_ref&lt; void(A&amp;), void(B&amp;), void(C&amp;) &gt;` can be used. --- For more concrete variant on this: template&lt;class...Ts&gt; using visit = function_ref&lt; void(Ts)... &gt;; know those annoying visitor interfaces you sometimes write for double-dispatch? struct A; struct B; struct C; struct D; struct IVisitor { virtual void did_visit( A* ) = 0; virtual void did_visit( B* ) = 0; virtual void did_visit( C* ) = 0; virtual void did_visit( D* ) = 0; }; struct IVisitable { virtual void do_visit( IVisitor* ) = 0; }; template&lt;class D&gt; struct ImplVisitor : IVisitable { virtual void do_visit( IVisitor* v ) final override { v-&gt;did_visit( static_cast&lt;D*&gt;(this); ); } }; well: using visitor = visit&lt;A*, B*, C*, D*&gt;; struct IVisitable { virtual void do_visit( visitor ) = 0; }; template&lt;class D&gt; struct ImplVisitor : IVisitable { virtual void do_visit( visitor v ) final override { v( static_cast&lt;D*&gt;(this); ); } }; and now visitors can just be lambdas: void consume_visitable( IVisitor* v ) { v-&gt;do_visit( [&amp;](auto* v) { // code that has the concrete type of `v` in it at compile-time } ); } or even: void consume_visitable( IVisitor* v ) { v-&gt;do_visit( override{ [&amp;](A* v) { }, [&amp;](C* v) { }, [&amp;](auto* v) { // default case } } ); } and now we have in-place override-based pattern matching. It doesn't stop there, but I think that is enough. 
Thank you, this "Identifiers with special meaning are used when they can only appear in very restricted places unambiguously. " sounds really good. However the word 'very' can have tons of levels :) For example private/protected/public can be only appear in two places (as I know): inside classes/structs before a ':' token and at inheritance list for a class/struct after ':' and before '{'. So in your view do it satisfy the unambiguity restriction? try/catch may be also good example.
Really good point. Ambiguity is the most important concern. In case of `delete` I agree it is a dealbreaker. Thank you
&gt; After moving from an object **of a type defined in the C++ standard library**, it is left in a valid but unspecified state fixed that for you
True enough, still, that's also the semantics that i would expect from a user defined type too.
Well, I don't think this is about YAGNI. I don't think that linking to bulky 1 GB library just to use a basic functionality has no overhead...
I think you missed the point of a monolith :)
I know about Google, but didn't watched this video. Thank you for sharing. &amp;#x200B;
Interesting, thanks for sharing.
Not at all
I'll look into it, thanks. I'm into Unix / Linux, so no MSBuild issues.
Thanks, I'll look into it. So, you're happy about the build time only or for other reasons too?
Interesting theory hehe
Its a good start buddy! If you want to find some freelance work fast, focus on web dev, learn a stack (MEAN stack is a good start) and you should be able to start developing webapps right away. You could also try learning Wordpress and PHP since there are a lot of freelance/maintance jobs regarding those. 
If you're a CS student, try getting a part-time mini job at your university, at another research facility or at any company. People love employing students at minimum wage. If you aren't a student, just write job applications and practice job interviews. Freelancing as a beginner isn't a good idea, focus on getting a stable job instead.
Thanks for the clarification. As I said, I don't think the second version is automatically a desirable state - even with better tooling. Not every set of classes should be treated as a "project" . Separation on a project level makes sense when the components you are separating are only weakly coupled and you are willing to commit to a (somewhat) stable interface (otherwise differnt projects will not be able to depend on it anyway) a.k.a. those components can and are developed independently of each other. If that is not the case, I simply don't see, what benefit it would bring to do this. 
We have different views for sure. The bigger the function the harder it is to maintain, debug and so on. It is especially more difficult to understand. The bigger the function is the more comments you have to add, while the opposite is true if you use meaningful names. There are of course exceptions but, as I said, in my opinion of course, they are exceptions. In the case of the big dispatcher switches for instance, I tend to use kind of enum based compile time function dispatchers.
Please, please leave existing keywords alone! There is already far too much ambiguitey and context dependence in the language, which makes it hard to parse for humans as well as tools. Don't add to it.
Another real-case scenario. Very interesting. &gt; I cannot imagine that working with library-bound UI code would be pleasant at all Well, I know for sure how bad it is code duplication, so I prefer the former. The proportion 100k and 30k application is not bad, I think it's very good. My goal would be to reduce this ration as much as possible
&gt; In high school (around 1999), I was taught a horrendous mishmash of C and C++. In fairness, no one had anything approaching a compliant compiler in 1999. And the compilers were so variable that it was serious work to actually write portable code. &gt; I blame the earlier exposure on the school not having the funds to buy C++98-compliant software and retraining the instructors in its use. Don't. That simply wasn't available. And back then a lot of commercial compilers were VERY expensive, and often required special hardware to run on (i.e. a particular brand of unix workstation). GCC mostly hit C++98 conformance (except export) in 3.4, in 2004.
This is another viable option. In general however I don't think everything has to depends on everything. I would create a library in any case, a test of that library and then I would take parts of this library and put in the more generic ones I've already written. 
Good point
&gt; So in your view do it satisfy the unambiguity restriction? Yes it would. :) try/catch not so much. For try you would have to look at the next token to see if it's a { and then also check if you have a statement or a braced-init-list. catch could be a call expression.
Yep, I probably have. Are you just speaking about repositories? I was speaking about a unique BIG library instead of different ones, regardless of repositories. Logically, as I said, I would see many repositories instead of a big one. This is however something I'd like to investigate very very well..... &amp;#x200B;
Interesting point. I think however it depends on the kind of coupling. If lib B, C, D depends on A, and B,C,D do totally different things, why should everything be a unique lib? 
&gt; Well, I know for sure how bad it is code duplication, so I prefer the former. If you already know *for sure* that you will have multiple applications that re-use the exact same UI, then this makes sense. But I've never found that to be the case. If the exact same UI works in both places, just ship the same application in both places with tweaked configuration. But what I find is that you might need *similar* UI in multiple places, but with key differences to support the different workflows. It can really make sense in these situations to put custom widgets and components into the library. But I have never seen anyplace that it makes sense to put UI layout or logic into the library. When it's attempted, you wind up with these ridiculous functions like `tuple&lt;EDialogResponse, string&gt; showDialog(Window *parent, string message, EDialogButton visibleButtons, optional&lt;string&gt; subMessage = none, optional&lt;icon&gt; icon = none, bool showSpinner = false, bool isModal = true, optional&lt;string&gt; timeoutMessage = none, optional&lt;Component&gt; customComponent)`. Nobody *designed* that function, it started off as `bool showDialog(Window *parent, string message)`. But successive engineers have gone in and adapted the library function to also support the needs of some new kind of dialog. None of the new support is needed at any of the old callsites, and the old support doesn't cover the needs of new callsites. And the actual implementation of `showDialog` becomes a huge fucking mess full of conditional branches. For me, a proper design here would be `void showModalDialog(Window *parent, Component *dialogContents)`, with the `dialogContents` specific to each client callsite. This provides some generic utility in terms of setting up the dialog frame and handling modality, while still ensuring that each application is not obliged to carry the sins of all other applications.
Okay, and Eigen is probably already doing that?
Yes, specialization is what allows those pieces to be in different crates.
&gt; However, it is a price to pay when heap-allocation is not acceptable or in high-performance code. No it's not, it's a design choice that could have gone another way. The earlier full Concepts design would have provided C# style template parameter constraints with C++ style code generation and performance. This is how Rust works, for example- you always know exactly what you're allowed to do with template parameters, but at the same time there's no type erasure or class hierarchy to add runtime overhead.
This type of question is more appropriate for r/cpp_questions &amp;#x200B; Regardless, this is a quirk of complex C++ initialization rules. \``atomic_int val = 1`\` is copy initialization. What it's underneath the hood is akin to: atomic_int tmp{1}; atomic_int val(tmp); Which is copy construction, which is deleted afaik for `atomic_int`. &amp;#x200B; Your code is actually valid for C++17: [https://en.cppreference.com/w/cpp/language/copy\_initialization](https://en.cppreference.com/w/cpp/language/copy_initialization) &gt;First, if T is a class type and the initializer is a prvalue expression whose cv-unqualified type is the same class as T, the initializer expression itself, rather than a temporary materialized from it, is used to initialize the destination object: see copy elision &amp;#x200B; So with C++17 it's just like calling the constructor with a `1`, instead of doing copy construction. &amp;#x200B; As to how people accumulate this knowledge, it's just experience, like the experience you're having now :). Everyone goes through it, some people may get more anxiety about it than others, though.
We do communicate with the Eigen team on occasion as that project is part of our internal testing for the compiler. If they have plans to start removing/changing `#ifdef` guards, we'll be the first to know if it will be breaking for an upcoming release and address it accordingly.
Currently do work in scientific computing and i had to create a fortran interface for our library and had to do a few things with strings, and man it was a pain. Passing data back and forth with C and working with strings of char pointers in fortran is much more challenging than with C. 
Unfortunately omp simd is only partially supported for now. Also it does now work with two phase name lookup. Overall it would be great to get full omp simd support or even better usable OpenMP 4.0 support! 
C++ requires some attention in details. If you open [https://en.cppreference.com/w/cpp/atomic/atomic/atomic](https://en.cppreference.com/w/cpp/atomic/atomic/atomic) , you can see next: 3) Atomic variables are not [*CopyConstructible*](https://en.cppreference.com/w/cpp/named_req/CopyConstructible). So now you *must* follow reference to understand what is Copy Constructible. The thing is you really have to understand what are you doing. It's not only to C++, languages like Python will allow you to do some stuff without understanding, but result can be surprising (look youtube for "wat js", "wat python")
Honestly? Depends where. I know it's popular nowadays to chastise "teaching C as a pre-requisite to C++", but as someone who used to be very involved in training new programmers, my experience has been that *if you have the time* (ie you control more than the content of a single course's syllabus) you can very effectively use C as a C++ gateway. If you teach a person decent C, and don't do all that collage Intro to CS 101 stuff of ignoring that pointers and memory management exist, but **actually** teach C as a tool to manipulate memory, you can use that knowledge to much more easily explain what modern C++ abstracts, while giving the student a good basis to understand the underlying principles behind other languages. Chances are if you are teaching someone C++ it's because you want them to be able to function in the domain where C++ is used, not to be able to do things in C++ they could accomplish in other languages. I'd rather have someone be capable of implementing std::string than someone who can use it. If anything I'd rather a C++ programmer be taught about compile time programming, duck typing, cache optimisation,
Nah, just in game studios. We write plenty of higher level "modern" code in other languages. We also write assembly when we need to he as performent as possible. Just so much of modern c++ is kind of a nightmare, whether it be for performance on platforms we need to ship on, or in terms of ease of use compared to other options, or in terms of bloating compile times. Stl has a lot of historical problems, some of which are legacy, some of which are definitely still there today. Anyways, I'm not trying to say anything is right wrong or indifferent here, im mainly just saying that learning fundamentals at uni can better prepare you for the reality of many places you might work. Need no to bring in the integrity or intelligence or education of places I've been.
I didn't explain myself well, sorry. In general, UI is the most difficult to put into library form and, in some cases, I agree, it's even useless. &gt; This provides some generic utility in terms of setting up the dialog frame and handling modality, while still ensuring that each application is not obliged to carry the sins of all other applications. I agree with you in this. Another approach however could be also the following: creating almost everything as library and then use a kind of declarative meta-language to express logic / layout.
Honestly? Depends where. I know it's popular nowadays to chastise "teaching C as a pre-requisite to C++", but as someone who used to be very involved in training new programmers, my experience has been that *if you have the time* (ie you control more than the content of a single course's syllabus) you can very effectively use C as a C++ gateway. If you teach a person decent C, and don't do all that collage Intro to CS 101 stuff of ignoring that pointers and memory management exist, but **actually** teach C as a tool to manipulate memory, you can use that knowledge to much more easily explain what modern C++ abstracts, while giving the student a good basis to understand the underlying principles behind other languages. Chances are if you are teaching someone C++ it's because you want them to be able to function in the domain where C++ is used, not to be able to do things in C++ they could accomplish in other languages. I'd rather have someone be capable of implementing std::string than someone who can use it. Modern C++ is driven by several idioms and philosophies that are pretty far removed from beginner classes, I see plenty of value in separating students from those features until they can be introduced and taught in an appropriate manner.
thanks for mentioning /r/cpp_questions it's a legitimate questions, and i like your answer, but this is not the right place. 
How did I do it? I started in 1999 and used it ever since
When can you consider yourself an expert? In all likelihood probably never; there are only a handful of people who really deserve that designation. I've used C++ for around 15 years now and still don't consider myself anywhere close to expert level. This is due not only to its complexity but also to the fact that it's actually been changing significantly in the past decade. The good news is that you don't need to be an expert to write high-quality code, you just need to understand the relevant paradigms for your project. In real life it's usually best to avoid getting too fancy.
I'm confused because these tables say we haven't implemented stuff we really have implemented, like string_view. It should be noted we change this stuff all the time.
I recommend a bullet list of your skills and how proficient you are in it. Recruiters and companies do not spend long on a portfolio website so you want to show them right away what skills you got. Take a look at my portfolio website(it's not perfect) javid.nl
No, that's a wrong approach in many cases. In complex interactive systems that do many independent things it is totally acceptable to throw an exception if something is not working in one part of the system and allow the user to continue working. &gt;exceptions are for recovery that's exactly what at() gives you a chance to do in such systems. as opposed to [] which might silently corrupt your program. &gt;If you aren’t absolutely certain that your indexes are valid, you need to restructure your code. ugh-ugh, i'd like to see a programmer who is absolutely certain of everything (or anything) in their programs.
Oh well, sorry about that, I failed to find the string_view header file when looking into the VS installation directory and then forgot to verify it again before publishing. Will check properly and update the table. Thanks for the heads-up! :)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt;If you aren’t absolutely certain that your indexes are valid, you need to restructure your code. Totally disagree. No one is perfect enough for that, I'd encourage to use .at() in development since it will save you hours of debugging unspected crashes or undefined behaviour.
starting to approach QtCreator's features level :) 
F
F
F
F
F
F
But does it take all the CPU on our dev servers? Yes.
We ship an engine on 6 different compilers - correct me if I'm wrong but basically anything thats not defined inside https://en.cppreference.com/w/cpp/header/iosfwd is basically relying on compiler specific behavior right? 
Common words that are not used in existing code bases are very, very hard to come up with. This is way we have co\_await instead of await. Because of that, the committee is unlikely to give up any reserved words because they may be useful in the future. &amp;#x200B; Take for example \`export\`. It was in C++98, but removed as a feature in C++11. However, the identifier was kept reserved. In C++20, it is nicely repurposed for Modules. &amp;#x200B; Another example is \`auto\`. It was obsolete even in C89, though still part of the language. The keyword was repurposed in C++11 to do type deduction. &amp;#x200B; One example that is reserved but unused now is \`register\`. It was deprecated in C++11, and removed in C++17. It is entirely possible that register will get re-used for something else. &amp;#x200B; Take your example of \`delete\`. Because it was a reserved word, it was easy to use it in the \` = delete\` syntax in C++11. &amp;#x200B; As these examples illustrate, having a common word that the committee knows for sure is only ever used in a specified way is very, very valuable for extending the language without breaking backwards compatibility. &amp;#x200B; &amp;#x200B;
What’s the issue with using ‘using namespace std’, i’m currently going through the ‘beginning c++ through game programming’ book and it shows 3 different ways to use this prefix but this is the preferred method which i did agree with due to the lesser amount of trying required, seems neater. PS i’m on day 3 of learning so i know FA at the minute 
\++Ditto; //s
&gt; Also, Fortran being faster than C is a myth, particularly after the introduction of restrict in C99. This is not the only feature that C lacks. And it's a lot about ergonomics. Matrix/vector/slices operations are way more natural in Fortran and compilers are usually geared towards such fields. So while it's possible to write C code just as fast as in Fortran, it often still more convenient to use F (especially if dev familiarity comes into play).
Still, some development in this area is always good. At some point OpenMP 3/4 will be the next "straightforward thing to add".
Article updated (and sorry again) — turns out MSVC's `&lt;xstring&gt;` contains also a forward declaration for `std::string_view`, sut since it's in the same header as the full definition it doesn't help much.
The incompatibility with /permissive- /Zc:twoPhase is a known issue and the VS team are working on a fix. It is due to the recent upgrade of their front-end parser. 
Yes, that's exactly what the article says (only that it's STL-implementation-specific, not compiler-specific). You need to detect what the STL implementation is and then include corresponding internal header having the forward declaration. Works as long as the header is hermetic.
Of course, ergonomics matter a lot, particularly for non CS people. It's much more likely that someone codes a slow C loop than a Fortran loop, and probably that's where the myth comes from.
Good they added ClangFormat. But why they didn't fix generated code (getters, setters, etc.) so that ClangFormat won't complain about it? 
Please vote in the original blog, or via email (visualcpp@microsoft.com), or via the VS Developer Community (https://developercommunity.visualstudio.com/spaces/62/index.html).
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b6i5ze/wavebricks_turning_sounds_into_shapes_and_shapes/ejlehtf/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Once I have been trying to check whether it would be feasible to implement some heavy high order functional programming in C++ using lambdas and std::function (e.g. Church numerals). This would generate std::functions containing lambdas which capture std::functions containing lambdas which capture std::functions etc. and copying that would make the program run much less efficient than if we wrote it in an actual functional programming language. I believe shared\_function would be appropriate for this situation. Several times I had a bug where, during an execution of a lambda contained in std::function, I have assigned something else to it. Obviously this causes the captured variables to suddenly become gibberish, but if you do not undestand what is going on, it is somewhat hard to debug. I think one possible knob would be to try to prevent that. (Should be easy to do in shared\_function. Just mentioning another knob, probably not worth it.)
Right, IIRC the forward declaration there is only to make string\_view::iterator implementable.
Most standard library functions and types are wrapped in the namespace "std." By typing a blanket "using namespace std" all of these functions are imported into your current namespace. Without it I have to type std::cout instead of cout. However, let's say I want to define a custom function with a similar name to a standard library function. Which function gets called? Is it clear to the user? What if I want my own vectors instead of std::vector? What if I want boost::numeric::ublas::vector? The blanket include statement can be dangerous. It's better to import selectively. &amp;#x200B; Nothing wrong with using std::cout, std::cin; etc. to save a few keystrokes.
Yeah, i see what you’re saying, it’s better to be safe and use it as and when it’s needed, i’m not on vectors yet so that’s all French to me but i’m sure it will pop up soon Thanks
Sigh, I thought GitLab had fixed their mobile layout. OK, I'll make a note to include the wiki link in the future.
CLion has better support for CMake, especially when using toolchain files. 
&amp;#x200B; * Use lots of interface classes, classes with only virtual methods and no data, such as IXmlTree, IRootSolver ... and make clients codes and implementations depend on the interface as it allows parallel development and swap implementations at runtime. * Make all functions and client code depend only on interfaces. * Create some reflection mechanism for interface discovery at runtime. * When add third party libraries make them fit the interfaces in order to be able to change them if needed and not depend on a single library. &amp;#x200B; &gt;All the classes, functions and function members should be as small as possible. I agree, many people including Scott Meyes recommended minimal class member functions to fulfill the client code requests and and any other additional feature to be added as free functions or friend free functions. It minimizes the possible changes in the implementation and client code extending the implementation without making any changing in the class code (open-close principle). I also would consider making the classes depend on interfaces. &amp;#x200B; &amp;#x200B; &amp;#x200B;
+1 i gotta get into it!
It would be good if Clion supported other building system generators such as Ninja build that much faster than any Makefile, GNU Make, BSD Make and Windows NMake. On Linux or any other Nix, CLion can only use Makefiles that are hard to debug and slow to compile as GNU Make does not support parallel compilation. 
Well, if you aren't fixing compiler issues or don't care about how well (or poorly) your compiler generates code - then these benchmarks may not be for you. But sometimes it helps to know which min/max idiom works best with your compiler. And sometimes the tests illustrate that the libraries or compilers are generating code as well as they could be (big hint: they're not). Plus, in the long term, it helps to take problems seen in real world code, clean and abstract that code, and turn it into benchmarks so that the various compiler and OS vendors can improve their results (without breaking NDAs, or focusing too much on irrelevant code). As for my other code: you probably already use Photoshop. And you indirectly benefit from hundreds of compiler issues already resolved, plus better hardware thanks to benchmarks provided directly to CPU and board design companies.
That's pretty good example how to make CI process for C++ project, thank you. It covers all necessary stuff to begin with. Would be even better if article would be more C++ specific. Kida: * Incremental builds * Absolutely tricky part for me: distributed builds with IncrediBuild or something similar * Caching (AFAIK CI systems can overwrite build cache, \*.obj files). It could be critical for codebase with depedencies like boost, QT, etc * Integration with package management tools (vcpkg, [conan.io](https://conan.io)) &amp;#x200B;
It may be due to network effect and due to lots of scientific code examples and legacy code in Fortran. It is not coincidence that it was the first programming language ever to exist as computers were initially created for number crunching and every machine capable of number crunch including sliding rule were called computers. Fortran has also other features that makes it compelling for non-professional programmers and scientific users such as one-based arrays and matrices instead of zero-based arrays, vectorized functions, some interoperability with C and obviously high performance and loop optimization. 
I think you accidentally posted a comment instead of replying to the person you were talking to. 
Yes, you’re right 😂 i haven’t been on Reddit long, still learning the ropes, although still pretty stupid, cheers
Well in that case thank you very much. Have you applied your prowess to something like a 3D game ? I'm sure if you wrote a game engine it would be lovely to read (and probably very performant).
Concerning the dependencies, check out https://github.com/tomtom-international/cpp-dependencies 
Can you elaborate?
&gt; It shouldn't compile Although that's not a strictly conforming construct, I suspect this is still conforming and I also suspect that all implementations rather support it or reliably don't compile (otherwise I think it would be a defect of the implementation) So I will certainly use it; because I also strongly suspect that MSVC, Gcc and Clang support it, and for 99.9% of people that's what matters; that for platforms where this concept exist this is ABI, so this won't go away overnight; and because the failure case when it's not supported is very probably not UB but just (proper) refusal to compile.
While I have done some contract work to improve specific game and game engine performance, I have not worked full time on a game or game engine. (which also means I have several drawers filled with NDAs ;-) )
&gt;Basic block placement &gt; &gt;You can make a hint to compiler using `__builtin_expect` construct I like to use this (even in non-optimised code) to make expected code paths more clear to the reader (as well as the compiler). Usually wrapped in a nice macro as follows: `#define iflikely(x) if(__builtin_expect((long long)(x),1))` `#define ifunlikely(x) if(__builtin_expect((long long)(x),0))` So the code would become : `ifunlikely(foo &gt; 2) return 1;` As a reader of the code, I know that I should probably follow the "false" branch of this code because the programmer expects it to happen rarely. 
&gt; If you aren’t absolutely certain that your indexes are valid, you need to restructure your code. That non-practical advice. It can be reduced to "if you aren't absolutely certain that your program has no UB, you need to restructure your code". This brought the industry to decades of exploits and data corruption instead of (for the overwhelming most parts) mere DOS or fixable reliable crashes. Now reserving .at() for recovery, I can also kind of understand the reasoning (*although* one could also argue that you 99.9% of the case should not try to recover from a logic_error), but then C++ is missing something...
Thanks mate,
I'd consider naming the macro to unlikely_if(foo &gt; 2) return 1; because ifunlikely() to me reads "if this condition is unlikely".
The problem becomes when you will be asked to implement something like `max(T,T);` Where `T` is a type like `int, double, float.` Look at the following program: #include &lt;iostream&gt; using namespace std; int max(int a, int b) { cout &lt;&lt; "Hello" &lt;&lt; endl; if(a &gt; b) return a; else return b; } int main() { int a = 4; int b = 6; double c = 2.0; double d = 3.2; int maxNum = max(a,b); int test = max(c,d); cout &lt;&lt; maxNum &lt;&lt; ", " &lt;&lt; test &lt;&lt; endl; } This will print out: Hello 6, 3 Why? Shouldn't it have printed out Hello twice? Well...no. Because our custom `max(T,T)`, currently only takes two integers. Although our compiler is smart enough to deduce it on itself and truncate our doubles into an integer, it decides "Oh, I have something in the `namespace standard` called `max(T,T)` as well! The user means for me to use that one!" Which maybe you didn't want to use `std::max(T,T)`, maybe you have your own reason to create your own max function. Maybe you want all numbers that go into max to return to you as an integer and not a double. So in reality when you use, `using namespace std;` your code actually looks like this: #include &lt;iostream&gt; int max(int a, int b) { std::cout &lt;&lt; "Hello" &lt;&lt; std::endl; if(a &gt; b) return a; else return b; } int main() { int a = 4; int b = 6; double c = 2.0; double d = 3.2; int maxNum = max(a,b); int test = std::max(c,d); std::cout &lt;&lt; maxNum &lt;&lt; ", " &lt;&lt; test &lt;&lt; std::endl; } So how do you know you are guaranteed that YOUR `max(T,T);` will always be used instead of the standard template libraries' `std::max(T,T);`? This is why we discourage people from putting `using namespace std;` at the top. Sure you use 5 more characters to type `std::`, but at least you know you are using standard out from the namespace of the standard template library. 
I like the macro implementation on [StackOverflow](https://stackoverflow.com/questions/10962290/find-position-of-element-in-c11-range-based-for-loop): #define fori(i, ...) if(size_t i = -1) for(__VA_ARGS__) if(i++, true)
Hi Thanks for this, it’s greatly appreciated, as i noted, i’m only on day 3 of learning and have just grasped variables, naming the variable, giving it a value and sending it to the console so a lot of the above is a bit over my head but i certainly get the gist of what you’ve said and why it’s important 
Fair enough, though not really the point... 
Not with my machine...?
MEMORY VIEW? Holy shit this is HUGE for me!
I did C++ for like 5 years before I had even heard of vectors. Stupid C with Classes style teachers and books had me overusing the fuck out of malloc and static arrays :(
Save this comment and come back once you have gone over functions. Then it will make a lot more sense :)
You can use this as a workaround: https://github.com/pthom/clion-ninja Instead of using CMake in Clion directly, you give it a wrapper that silently changes the generator. Works great.
who not both?
👍🤘😎
What do you mean by that? Generated code is reformatted by ClangFormat when it's enabled.
Thanks, but they should seriously add that feature to support other building systems. There many CLion customer asking for that. Makefiles for big projects or libraries are really slow because they compile the files one by one. Visual Studio IDE supports way more building systems such as Ninja.
Just because someone made a Youtube video doesn't mean they know what they are talking about. The compiler is correct, \`setLocation("");\` cannot be compiled for the reason stated in the error message.
Please post specific syntax and language related questions to r/cpp_questions. This subreddit is geared towards cpp discussion instead of answering specific questions. 
is it easy to get CLion working with Arduino ? 
If you're making an argument about readability then naming is 100% part of the point
[Here you go!](https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/home)
We have dev servers at work with clion users. Frequently the machine becomes laggy, it's very often clion using 6 cpus at 100%.
In C++20 \`\[\[likely\]\]\` and \`\[\[unlikely\]\]\` will be a portable way to do this [https://en.cppreference.com/w/cpp/language/attributes/likely](https://en.cppreference.com/w/cpp/language/attributes/likely)
Sounds like you're over subscribed. Don't do that.
Sorry, I meant that ClangTidy (integrated in Clion) complains about the generated code, not ClangFormat. For example, when you generate setter for class X { int a; } it will look like this: void setA(int a) { X::a = a; }; and ClangTidy will complain about shadowing the variable name. &amp;#x200B; When generating single argument constructor ClangTidy complains about missing explicit. &amp;#x200B; &amp;#x200B;
Same :D
This is very true. Tool chain files in qt creator are just, well, a total pain in the ass to work with. I do embedded and going back and forth for building and coding is a royal pain.
Wait what? Your developers are working on thin clients connected to a server? The heck? Why? 
Compile DB(compile_commands.json) is supported. I use bear ( https://github.com/rizsotto/Bear ) to generate Compile DB for the Linux kernel and other legqcy projects owned by me.
Thanks for making it better and better every day it passes, I am a happy customer that gets joy when a new version it is released because it means an improvement in the IDE, like a kid with new toys Keep the hard work, it is worth it, the product is awesome, i havent regret much having to adopt CMake back then when it was only a beta version, it was the rigth one even the pain in the ass that cmake is
The macros are an example. The main point is to include the "likeliness" of a branch as part of the code to improve understanding. Preferences about the exact words used to implement the idea are a matter of taste. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b6ore0/argument_of_type_const_char_is_incompatible_with/ejmbb94/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Not sure actually, but there are many BLAS libraries that exist for heavy matrices operations. And when it's Intel who makes them, you can usually get the best performance possible on an Intel CPU.
If, for example, you had a common library that most other libraries depended on. Then one team decides to add a dependency on the common library to their library. Now everyone using the common library also depends on their library. That, but over and over again. If we had a better code review process it's likely that these types of changes would get rejected. However, when deadlines get tight, and hours get long, code reviews tend to suffer. Also, sometimes these dependencies are subtle. Like A -&gt; B -&gt; C -&gt; D. Then D adds a dependency on E. Now A also depends on E, even though A doesn't care about E at all. If you architect your software well you can avoid this issue. But not every team understands OOP well enough to so. Especially if your team is cross discipline. The last company I worked for had many people contributing code who would not consider themselves software engineers, but were vital to the success of the project.
Clion is unacceptably slow on a sizeable codebase for me on a very beefy workstation. It's really unfortunate because I love it as an IDE, but it's outright unusable. I wish they'd take some release cycles to halt feature development and just focus on performance. 
Rewrite some code from Java to C++ ;)
It seems to be geared towards STMCube right now, so only STM32 would get the full features. Of course, if you setup your own canoe file for arduino it will work.
No matter what they do it’s going to be too slow for some people. Presumably they have metrics on that and are developing for the 80% or so. 
I mean, you just did. Be the change you don't want to see in the world.
You can actually target multiple versions for backward compatibility. I'm not sure of the caveats involved in this course of action, though.
You might also want to read [https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/memcpyAnalysis](https://gitlab.com/chriscox/CppPerformanceBenchmarks/wikis/memcpyAnalysis)
no idea what a canoe file is I use a basic make file: https://github.com/sudar/Arduino-Makefile
Lol a canoe file is what my autocorrect calls a CMake file. Not sure if there are any good setups for a CMake arduino build. If you want a nice development environment for arduino though, check out platformio 
Also, you should try reading the makefile to see the default compiler switches (-O3). Honestly, it looks like you just wanted to complain/troll without bothering to read any of the code (much less compiling and running it).
Yeah finally 😇
No, the project is big but not huge. This is one user. 6 cpus at 100% until bouncing.
This is hardly rare in many large companies
Maybe I am nuts, but other than spaces vs tabs, and basic sanity like indenting blocks, reasonable line lengths, I honestly find most "code formatting" requirements to be a big bag of garbage. How code is formatted can communicate. Almost any machine formatter is going to block that communication and replace it with information redundant on the code text itself. I mean, I've been programming for a long time, and never seen the point of more than a handful of rules. 
I like the idea of providing comments on whether an if branch is an expected code path, but I think it's a bad idea to tell the compiler about it. Patrice Roy talks about this around 32m here: https://www.youtube.com/watch?v=pnSvUbE1HHk The default behavior around handling branches is usually a good one, and the likely / unlikely attributes should be maintained and checked regularly whether they have the intended effect. That's a maintenance cost.
I've voted on plenty of feature requests over time just to see them ignored. The latest one is https://developercommunity.visualstudio.com/idea/351554/please-support-newer-version-of-openmp.html Lifting restrictions on loop variables (e.g. simple support for size_t!) is the most basic OpenMP 3 feature and would have simplified our lives a lot with minimal investment from your side. But there's an easy solution to that and other problems, just switch to clang-cl.
Great, I've had to switch back to cmdline with gdb -tui and/or eclipse with any tricky embedded issue for a long time. Excited to kick the tires on this
&gt; spaces vs tabs, and basic sanity like indenting blocks, reasonable line lengths That's cool, then just set `clang-format` to fix those and nothing else. Ours does more, for things like the style of [indent/braces](https://en.wikipedia.org/wiki/Indentation_style), and to put a space between control statements and parens like `if (...)` and that sort of stuff. I wasn't thrilled with the idea originally, because in some code areas you have turn it off; but I think it's helped a lot overall. For example some people used to comment in code reviews when the submitter messed some silly format thing up due to fat-fingering; now we don't need to point out that stuff because it never happens. The funny thing is you get really used to having this tool reformat your code for you when you save - so much so that you actually type without even thinking about the spaces, line lengths, or indentation; you just save the file and it's done for you. It's changed how I type code.
Yes, and then you get lovely abominations where people write code in the form of * setjmp * malloc * register crash handler * touch all allocated memory * longjmp on crash And then the question here is if you're going to get a crash that's possible to handle at all, if you're getting OOM killed there's nothing you can do. I've read something about overcommit being a thing because of fork and exec, namely them being a copy on write operation, but I still think overcommit is a net negative for software stability. Afaik BSD has an "I'm going to kill you if don't clean up memory real soon" signal for when the system is low on memory, which is a much cleaner solution than outright OOM killing in my opinion.
There are two issues here. First, the problem is in complexity not size. Length correlates with complexity, true, but one should not be substitute metric for another. Moreover, the complexity wouldn't just go away if you split a function into two. You're still solving the same problem with the same code it's just now you had to add more entities into equation by creating another accidental thing (named scope) you don't essentially need. And that's the second issue. Meaningful names. Somehow they are viewed as panacea, while in reality they are much more a form of placebo. "Meaningful names" is the most underestimated problem in programming. It's just not what we're good at. There are much less successful writers than practicing programmers. And what's worse, it's not validateable. Compilers wouldn't tell you: "that's meaningless". Static analyzers wouldn't tell you. Testing wouldn't tell you. You'd think code reviewers would? Maybe. But maybe they are too busy with their own scope to really grasp the problem you're trying to solve to appreciate the meaning of every aspect of the solution. So 96% (arbitrary number) of all meaningful names are only meaningful for whoever wrote them. In ideal world they would be solution, but in reality they are not meaningful, they are just names, so they aren't. They only create some false sense of understanding leading to more and more problems. I'd stay with unifunctionality as a criteria for separation. If your function essentially does two things, then even splitting int into intentionally meaningless names like two_thing_function_step_1 and two_thing_function_step_2 will still make sense. They you could think really hard and come up with better names. But if you have to think really hard just to come up with a name for something that is not even a complete thing, then you'd better not tear it from where it belongs.
Thanks for your previous suggestions. Regarding the runtime-free switch issue, the current -openmp:experimental switch does cause the linker to link against VCOMP.lib even if SIMD is the only OpenMP usage in a program. However, since there is no actual dependency to the OpenMP runtime from the program, the input VCOMP.lib file will be simply ignored by the linker. We'll consider not passing the lib file to the linker in this case. The size_t type is now allowed in OpenMP SIMD loops, but still disallowed in regular OpenMP For loops. We'll fix it. Is there other specific OpenMP 3.0+ features you are interested in exploring? 
I started from the other end: I first considered how the SW will be deployed, THEN that dictated the organization into modules (DLLs packaging COM components). Working with COM, I've become fond of component technologies. Yes, COM is "clunky" in C++ (ATL helps; haven't had the time to look into WRL yet), but it's rock-solid under the hood and just by organizing the code around COM principles the application grew rather nicely just organically. Some of the components run in the same process as the controlling application, some in another process and they can talk with each other without a glitch (RPC). Had to do some small very isolated hacks to pass C++ objects to COM components but they work robustly. E.g., how to pass `shared_ptr` to an inproc server component? Declare the method in the IDL to take `int64` and pass a *pointer* to `shared_ptr` to the method. I also have a couple of small libraries wrapping platform functionality into higher-level classes commonly used by all components. So I ended up with ~80% of the code packaged as COM components, the rest are controlling applications (which themselves are COM components). As a bonus, I can drive and test components individually from PowerShell (or any other scripting language supporting COM) without any extra plumbing.
Not just odd, it violates const correctness. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4348.html
Interesting alternative for Windows side. I'm more into Linux / Unix, but good to know :)
I think it should be `(*(myGameMap-&gt;tileMap[y][x]))-&gt;hideTile();`
/r/cpp_questions is the right place to ask such questions. I think that code looks horrible and you should organize things differently. The most simple fix would be to write functions that modify the tile map instead of doing the pointer wrangling everywhere. That being said, I guess this could fix your issue=? auto\* myTileMap = myGameMap-&gt;tileMap; (\*myTileMap\[x\]\[y\])-&gt;hideTile();
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
`(*myGameMap-&gt;tileMap[y][x])-&gt;hideTile();` should also work. 
You should probably wrap that in a `GetTile(x,y)` method.
I hate macros that have control flow keywords in them.
I understand your view. Your main point I think can be translated into: "there's no way to create a tool that checks if a name is meaningful, so it's useless give meaningful names. Meaningful names are subjective". I agree about the first thing, and only in part on the second. Even if it's true that there aren't tools to automatically check if a name is meaningful, I have to say that we write code not only for the compiler, but to be read by other people and ourselves. It's not just placebo. It makes all the code easier to understand because people are not able to deal with many things. Why you have to comment everything when those comments can be substituted by function names? Regarding complexity and size. Well, they are two different things indeed, but they are often connected. A 1000000 SLOC project is almost always more complex compared to a 100 SLOC one. 
Thanks for the feedback. I agree, even if I would suggest to use static interfaces. The same Stroustrup suggests to write small functions / classes in his books.
I totally understand your point. Yes, that's a problem to solve. Ideally it can be solved by using some tool to automate dependency checks and by frequent code reviews. It's not easy though, I have to admit it.
looks very very promising, many thanks!
Ah, I see, thanks for explaining. We'll consider that
if we really push the boat out we might be able to get support for canoe files in ;-)
You're right. I got confused with all the pointers involved.
CLion uses all available CPUs for initial indexing to finish it as quickly as possible. However, you can control this in registry by *cidr.indexer.thread.count*. Be careful still - changes might reduce the initial indexing speed. Also, CMake might take several cores to parallelize the CMake reload, it's controlled by Build option in the CMake Profile (-j 4, by default).
Between the compilation db support we added previously, and support for custom builds and run targets this time, you can get almost any build system working now, reasonably easily. In the What's New video, this time, I show it integrating with build2, for example. But more integrated support for more build systems is coming.
Let me try to cover all the comments in this thread. First of all, performance is a top priority for now and most of the things we do are in this direction. Like for example, moving all possible parts of language engine to Clangd, introducing some lightweight AST/PSI trees and so on. As for Java. While it's a common thought that CLion is slow because of Java, it's not of course. The issue is in the complexity of the language (C++), when you need to resolve the code to be able to parse it correctly, and partially in the platform architecture, that is historically tuned more for Java, Python, JS and other languages. We do some major refactorings in this area to make it work with C++ in an optimal way. As for the metrics, we are of course aware of user's issues with performance, we have dozens of CPU snapshots and see some common issues in them, which we do our best to address. The process is incremental and we hope we improve the product with every release.
I think performance was one of the main focuses of this year's releases.
You can get [Platform.io](https://Platform.io) and generate a CMake/CLion project for Arduino. I guess that's the way many our users work with it.
I would love to use CLion! Especially now for the memory view but the last three times I've tried it, the performance was sadly just unbearable..
Lol “Boo STL”
Some things are slow because I ask it to do something more complex (like find all usages of something) and that I don't mind so much. The one performance issue that *kills* me is the hotkey for switching between header and implementation (Ctrl alt home is the default I think). This should be a trivial instantaneous operation but it hangs every time, like 5-20 seconds. 
&gt; That's a maintenance cost. And, for some people, it is worth it.
If I may... I think the most glaring issue is not so much the performance of CLion, or even its resource usage, but its responsiveness. The most egregious example is doing a `git pull --rebase`, which leads CLion to freeze as it reindexes the project. I understand it will take time to reindex the project after 100s of files changed under its feet: it's C++, it's slow to compile. However it's annoying to have to give-up on working with CLion for a couple minutes as it reindexes everything. As far as I am concerned, focusing purely on responsiveness, even if it slowed initial indexing by 20%, etc... would be a huge gain. I can deal with no code-completion for a few more seconds, but I can't do anything if the GUI is completely unresponsive.
Thanks!
There's XPCOM ;) https://developer.mozilla.org/en-US/docs/Mozilla/Tech/XPCOM
Link should probably direct to platformio.org?
Nothing wrong with that, as long as it stays inside .cpp files :)
No-no, giving meaningful names is important indeed. It does make code easier to understand comparing to with, um, meaningless names. It's just most of the time they are not as meaningful as it seems, so they only contribute to complexity. You can't split a 1000000 SLOC project into 10000 100 SLOC projects and claim that it's now simpler because of the 1000 meaningful names. This might have worked in the ideal world, but not in this one. Naming is important, hard, and when done wrong (which is often because it's hard) very misleading.
thanks !
You can avoid std::function by using templates and type deduction. The compiler output will not be pretty though.
&gt;It's just most of the time they are not as meaningful as it seems,, so they only contribute to complexity. Well, that depends. Usually if the name is not good enough, it means you either don't understand well that part of code or you haven't spent enough time to think for a good name. In either cases it means that that part of code needs a refactoring. Software development for me should be an on-going process with the goal to make it always better. &gt;You can't split a 1000000 SLOC project into 10000 100 SLOC projects and claim that it's now simpler because of the 1000 meaningful names. In general, in my opinion, when you split it in smaller projects is almost always better also in the real world ;)
&gt; When I am inheriting data and implementations, however, I pretty much have to crack open the parent class's implementation It's very rare that I encounter this situation. &gt; or use composition In case there is a problem, composition will not save you from crack-opening an implementation even if that implementation is a member object instead of a base object. &gt; You have a limited selection of magic names that are baked into the class rather than having the class implement a set of interfaces. This also makes it impossible to constrain type parameters C++ will have concepts. In practice though, the only real problem is error messages. Otherwise, you can constrain type parameters in C++ as much as you like, using templates. &gt; Visibility is fine up until you get to friendship, protected, and just dealing with inheritance. What is the problem with visibility? you don't mention any problem. &gt; how can I write my C++ code around these issues, What issues? I see no issues presented, only things you don't like or don't know how to use. 
&gt; Inheritance is not a very good method to prevent code duplication (the reason is tight coupling). Not true because with composition you have the exact same tight coupling. 
&gt; Unfortunately a lot of inheritance in code is for reuse, where composition should have been the preferred way; and a lot of programming courses incorrectly teach reuse as a reason for inheritance. Not true. It's mind-boggling that so many people get this right. Both inheritance and composition can be used for reuse, but it is only inheritance that can be used for combining reuse and subtyping. Reuse+subtyping is a very real need and it comes up often in OOP design. It really makes things a lot easier because you get a piece of code that you reuse with minimal effort. 
The reason why no one uses these libraries is that you should always use the Buckingham Pi theorem to non-dimensionalize your problem before you do anything else. This is done traditional in atomic units and in CFD.
That would be weird setup though? Use Platform IDE to generate Cmake for Clion ? Can Clion compile/upload/debug Arduino? 
In the cpp subs, nothing is ever good enough. Hang tough, buddy.
&gt;at I don't mind so much. &gt; &gt;The one performance issue that kills me is the hotkey for switching between header and implementation (Ctrl alt home is the default I think). This should be a trivial instantaneous operation but it hangs every time, like 5-20 seconds. No, not really. When your GUI is blocked, you are not only slow but you are also slow in a very wrong way. Slow-indexing is manageable, blocked GUI is not. I want to keep reading/thinking about code while intellisense is offline.
This again...the message is way too extreme: there's no problem using \`std::endl\` outside of performance-critical code (which, in my personal experience, is 99.9% of std::endl usage). \_Definitely\_ use \`std::endl\` if a newline+flush is what you want. &amp;#x200B; If for some reason you need your std:: printing to go faster, definitely avoid flushing at every newline.
Yeah I think the emphasis should be on not using std::endl for file streams. I observed some pretty bad performance regression in that case, but not so much for cout.
Agree. I'd even add "don't write to cout in performance critical code". (Note: you probably want to switch to markdown for formatting ;) )
You can start with a union as the outside and put structs on the inside. You can then make one for x, y, z one for float[3], one for r,g,b etc. 
I'm fine with it, I sometimes forget to flush in C and most of the time it's exactly what I want
And you want to write x,y,z into your Vector3 and then read the values as v[i]? Isn't that UB?
It is, but it shouldn't be. It's kinda the point of their post I guess. It's just another thing which is very, very useful in game programming but only "okay" because there are extensions for it.
Books are one thing, but I think I learned most by reading and playing with code on github while wondering what the hell they were doing
I forgot where I read it and someone correct me if I am wrong, but I think the standard defines it as UB but major compilers like GCC implement it as defined and allowed behavior since it is so useful / widely used.
In some case, it is not. The standard says: "[Note: One special guarantee is made in order to simplify the use of unions: If a standard-layout union contains several standard-layout structs that share a common initial sequence (12.2), and if a non-static data member of an object of this standard-layout union type is active and is one of the standard-layout structs, it is permitted to inspect the common initial sequence of any of the standard-layout struct members; see 12.2. — end note ]" This condition may be relaxed if we consider that `float v[3]` has the same layout than a struct with three floats. In that case, the code would not be UB. 
If you mean: ``` union Vector3 { struct { float x; float y; float z; }; struct { float r; float g; float b; }; float v[3]; }; ``` then you have the same warnings. The only solution (but you loose the array): ``` struct Vector3 { union { float x; float r; }; union { float y; float g; }; union { float z; float b; }; }; ``` 
I actually wanted to know this in detail once... while this is allowed by the C-standard, it is actually still UB for the C++ standard. float v\[3\] and float,float,float do not share a common initial sequence (by the wording of the c++ standard). While every compiler will just do the right thing, it is currently still not covered by the standard.
The problem is that `std::endl` is premature pessimization in the **vast** majority of cases, making it impossible to see whether the flush is intentional. `&lt;&lt; '\n' &lt;&lt; std::flush` completely avoids that problem and should thus always be preferred.
You can always add an assert that the structure as a whole is 12 bytes. It is enormously useful and seems to work with all major compilers.
I don't know what your warnings say and I don't know what compiler you are using.
Let me guess without reading: because std::endl flushes the stream? Well, that is a feature, not a bug.
For example, with `-pedantic` Clang says: "warning: anonymous types declared in an anonymous union are an extension [-Wnested-anon-types]" 
So turn off that specific warning. 
That's the conclusion I came to last time I looked into it. The standard doesn't define the behavior, but most compilers do. I use type-punning fairly often while doing game and emulator development.
&gt; float v[3] and float,float,float do not share a common initial sequence What does this exactly mean?
I filled out your survey, but to elaborate a bit in case it's useful: Where I work, Boost.Units isn't especially useful because of the design that the units of interest are known and fixed at compile-time. (Similarly for the duration types in &lt;chrono&gt;.) In our product line, our users may very well have one file (or one attribute of a multi-attribute file) whose units are "kg/m^3", another whose units are "g/cc" and a third whose units are "degrees Celsius". We therefore need to be able to operate on units (parse, convert, multiply or divide, and check for dimensional consistency) at runtime, not compile-time. All our code for doing so was written in-house, much of it long ago. Using compile-time unit libraries such as Boost.Units systemically would require us to templatize every bit of our code base that touches units, which is entirely a non-starter. Using a UoM library that handles units at runtime would theoretically be a possibility, but there is nevertheless no way we are going back through an existing millions-of-LoC code base to do so.
&gt; Again, a warning. What compiler warned about the latter program? Unnamed (but indeed not anonymous) structs are standard conformant as far as I know, so the warning seem uncalled for. &gt; Why does it compile? Because, C11 introduced anonymous struct. Some compilers did support anonymous structs as an extension before C11 standardised them. I would certainly like to see anonymous classes added to C++.
&gt; What compiler warned about the latter program? Clang says: "warning: anonymous types declared in an anonymous union are an extension [-Wnested-anon-types]" &gt; Unnamed (but indeed not anonymous) structs are standard conformant as far as I know, so the warning seems uncalled for. Per what I cited in the post, I think it is considered a nested type and is thus forbidden. 
And end up with a non-standard program that's not guaranteed to work with other compilers? No thanks.
"The [common initial sequence](http://eel.is/c++draft/class.mem#22) of two standard-layout struct types is the longest sequence of non-static data members and bit-fields in declaration order," So it deals with structs only and not with arrays. 
There also is the issue with output from multiple threads. Mixing up parts of things you intended to output as a single string.
&gt;Per what I cited in the post, I think it is considered a nested type and is thus forbidden. At least the warning message is misleading in that case. You're citing a *note*. Notes shall not contain requirements and are not normative. The wording of the note does seem to strongly imply that this is the case, but I would like to see the rule that actually says so.
What's wrong with a class that defines x, y, z methods and operator[] and stores an array internally? I work on CAD software and that's literally what we do. Force it to be inline if the function calls are too slow.
Take a look at simdb - https://github.com/LiveAsynchronousVisualizedArchitecture/simdb It is a simple lock free key value db that uses shared memory and should make interprocess communication trivial.
My opinion is that it is not a big deal. Most programs that use std::endl are toy ones where the output performance isn't a big deal. It it does turn out the the flushing is a major bottleneck, then that is a teachable moment, to go over various options such as using "\\n", switching to a binary format that may be more compact, or not using iostreams. In addition, when teaching beginners, std::endl flushing may prevent them from being surprised by output that seems to occur later than when they did it. Basically, std::endl won't matter for beginners and learners, and if it does matter there are bigger issues to consider than flushing vs non-flushing.
My solution to this was to create a data structure that held all its data in a single span of memory so that there is *never a difference between a serialized and deserialized version. The advantages have been huge in terms of simplicity and flexibility. It can be written out to a file, memory mapped from a file or passed to other processes trivially. I made the struct contain a pointer to the actual data of the structure as well as three function pointers for three allocation functions (such as malloc, realloc and free). If it isn't supposed to own the data, the allocation function pointer will be null. If it owns the data but shouldn't be able to expand it, the malloc and realloc pointers will be null but free won't be. To save creating lots of data structures like this, I made one that is a array/hash map/tree hybrid called tbl (for table). The array and hash map contain only intrinsic types and other tbls. This covers a huge amount of uses which simplifies a lot of scenarios. Something like an image file format can be made using the array for the pixels and the hash map for the width, height and number of channels for example. Because it is already serialized it can be written to disk directly and used from disk directly, etc (not to mention sent over a network or to other processes). https://github.com/LiveAsynchronousVisualizedArchitecture/lava/blob/master/Libraries.md#tblhpp
What compiler does this not work on?
It's also for crashing when you do an out of bounds read, instead of hoping for a segfault.
I think this is a good idea, but I also think that it doesn't really matter in most cases so I hope this will not be another of those things that we are going to tell beginners to stop doing out of the blue when they ask for help on a totally unrelated problem.
&gt; This condition may be relaxed if we consider that `float v[3]` has the same layout than a struct with three floats. In that case, the code would not be UB. I don't think that having same layout gives any guarantee about union punning. Common initial sequence has a specific meaning in the standard, and that meaning doesn't cover arrays.
I've been reading about Clions remote development features but I'm still confused about one thing. Does it have a remote explorer like Eclipse, with you can write code directly on a remote machine? Our workflow really depends on this feature but I'm sick of eclipse and would like to return to Clion.
Wow very nice. I was originally going to either use a custom (linux-only) implementation or pull in Boost but that lib seems to do exactly what I need plus adds some extra helpers to make it clean. Thanks!
I agree with you, I meant the standard must be changed to guarantee this behavior.
Just wondering:Are you talking only about things like feet vs meter or also time vs distance, because I think all your motivational examples are about the former, whereas the latter is afaik a much more common application for unit libraries.
&gt; The reason why no one uses these libraries is that you should always use the Buckingham Pi theorem Somehow I don't think that's actually the reason no one uses these libraries :-P
Hej! Both in fact. A UoM library would ideally be able to ease the conversion of different units of the same dimension and also allow for operations such as multiplication, division, exponentiation of different different dimensions. + addition/subtraction of quantities of the same dimension (like metres + feet).
C++ has still an enormous weakness for teaching: error message reporting. When you teach programming you expect to have helpful error message that students can read and understand. But, while there's been a lot of effort put into having clean error reporting from c++ compilers, debugging templates is still a nightmare. And templates are the very basis of the STL.
&gt; Strongly disagree. vector::at() should never be used It's an easy way to force an abort in code that must be resistant to buffer overflow attacks. &gt; If you aren’t absolutely certain that your indexes are valid We're always certain that they are valid, until the next bug report comes in :)
That's a google doc link, so I can't touch it. I had the opposite experience of kmccarty. Where I was working when I suggested such a use it was the opposite case, where dimensionality was the only thing of any interest (and that was static for any given variable), since they had already very much standardized across applications which units are to be used within any given dimension (IIRC cm, s, rad were the only ones of any real interest, I don't recall any mass quantities). I eventually got them to allow me to parse out a unit suffixes in config files for time units at least, since sometimes it's easier in a crunch (when config files are written) to think in terms of minutes or milliseconds or whatever for a given field. But boost::posix_time was a more convenient backend for that (especially since it was already widely used within the code).
https://github.com/google/mathfu/blob/master/include/mathfu/internal/vector_3.h#L184
See my comment above for why that is wrong.
The stack based array goes out of scope and all you've done is assign a pointer to it. Your pointer points into the stack, which becomes something else entirely when your constructor ends. You need to copy the array into a heap allocated array.
&gt; heap allocated array. Thanks for help. I have never heard heap allocated array. could you show me an example?
\*\*Company:\*\*[Shield AI](https://www.shield.ai/) \*\*Type:\*\* Full time \*\*Description:\*\* We are an autonomous robotics company building products for the national security sector and first responders. Our mission is to protect service members and civilians with artificially intelligent systems. We are actively shipping product and are backed by Andreessen Horowitz. We are seeking experienced C++ engineers to work with our autonomy team and robot operating software team. Ideally looking for at least a few years of experience in C++ in a production environment or graduate academic setting, with a preference for individuals with robotics or embedded experience. Hiring at all levels, including lead/manager. \*\*Location:\*\* San Diego and Pittsburgh \*\*Remote:\*\* prefer individuals open to relocation (relocation assistance available), however, we are open to considering remote workers in San Francisco. \*\*Visa Sponsorship:\*\* US Citizenship required \*\*Technologies:\*\* Ideally looking for strong mastery of C++11 and newer, we are a Linux environment, additional languages we use include Python, Matlab, and Julia, but are not required. \*\*Contact:\*\* If you’re interested in applying, please do so [here](https://jobs.lever.co/shieldai). If you want to learn more about the opportunity before applying, please reach out via DM.
&gt;…There is one or two cases in C++ where inheritance is necessary for reuse, and that would be to take advantage of the empty base optimization. … &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Recall that C++20 offers the `[[no_unique_address]]` attribute added when [P0840](http://wg21.link/p0840) was merged, thus allowing similar space savings under reuse via composition. 
You should probably read up about stack versus heap and dynamic memory.
No problem, let me know if you encounter any problems or have any suggestions.
And he answers: "Usually, but no, not always." More specifically for the non-empty case: &gt; David Rodríguez reports that GCC 4.8.1 calls v.clear() in this case, leaving v empty. libc++ does not, leaving v not empty. Both implementations are conforming. But in any case I would stay away from such complex reasoning. If it is in practice emptied with your impl. and specific use case, then 
Thank You sir. I will read the stack versus heap and dynamic memory for c++. Have a nice day. 
Why not? It's an option in my company. Sometimes it's just more convenient to connect to a 48+ core 256+ GB RAM server to run a big test-suite or do a quick change/build/test iteration. Not to mention when you need hundreds of gigabytes of artifacts. Most big projects in C++ world can be unwieldy even on the most powerful local workstation (especially if it's a laptop).
https://godbolt.org/z/dwAKW8 I believe there is a common initial sequence for all of the members; the Storage&lt;&gt; base class. :) WARNING: This technique requires care with the operator overloads!!!
Non owning raw pointers.
C
Anything inherited from C that has a better replacement.
Never heard of those and already i fear them, i’m new to programming :-/
Eventually fmtlib will be standardized and we'll forget all about this nonsense.
Added indexing and some template stuff as extra bonus. Kept the type fixed to float but easy to see what's happening. https://godbolt.org/z/h25fjf 
I know the feels. I used vim + YouCompleteMe for years before trying CLion out. And CLion is unbelievably slow in comparison. UI constantly freezes, autocompletion pop-up window sometimes needs half a minute to populate, while in vim it's just lightning fast. On a 4-years old laptop I could have 4 or 5 projects open in multiple windows in vim+tmux and work without any performance issues. CLion can barely handle a single project and it eats the CPU constantly, sucking the whole battery in a hour (4 hours in vim in comparison). God, I miss my vim, especially UltiSnips. Live templates are just garbage in comparison. Sorry for the rant. It is a nice release, you did a good job folks =)
So this library is basically UB? And even silences the warnings? And isn't the same true for glm, which is quite widely used?
So your code is not UB according to the standard, do I understand that correctly?
The standard calls this a common initial sequence and is defined in 9.5.1. I think we covered this before on other thread a while ago.. :D
If the snippets in the post were valid, you would not need such a construct (with all the limits that we talked about previously).
As someone who’s been learning C++ for a year, grasping this concept early will be a huge help. Start with the notion of scope and lifetime of the variables you make - how long do they last, and what parts of your program can see them? You’ll soon learn about for loops, and if you creat a variable inside a for loop, it vanishes when you exit the loop - i.e. strictly local scope. Namespace scope is, as far as I can tell, about allowing the programmer some additional controls over scope and lifetime (but I’m still a beginner). Once you get into functions you’ll learn about passing variables to functions by value or reference, about static variables (scope vs lifetime), global scope, etc. . .but namespaces are one step beyond that, I think. I’m still a bit confused by the topic, to be honest, for example, you can nest one namespace inside another. Seems tricky. Regardless, if you’re always thinking about scope and lifetime it will greatly help your C++ programming and you will avoid many baffling situations (which I learned the hard way). Good luck! Current project: code parser which restructures all my old C++ code written with ‘using namespace’ into std:: format... Think I’m going to write it in Python tho. 
It would be fantastic if they were, would simplify life a lot. 
Well structured, straight to the point post. But I don't think I'll ever need one
Part of the problem is that they are very, very complicated. Boost.Units has an insane amount of templated magic going on. And if you need to make proper use of the library, you need to dig deeply into it. Also, they can have bugs. For example, here's an issue I encountered and tried to fix: https://github.com/boostorg/units/pull/18 Still open, because I don't understand boost.build and the unit testing enough. And it's not got enough maintainer support to handle simple stuff like this. I encountered this precision loss when writing unit tests for conversion (https://gitlab.com/codelibre/ome-common-cpp/tree/master/test/ome-unit-types). One of the major reasons for using units is to improve code correctness by making invalid unit conversions impossible. However, you also have to account for bugs introduced by the extra complexity of the unit support. Boost.Units is ridiculously overcomplicated. And many of its conversions are inaccurate and lossy. After spending the time converting a whole codebase to using it, I think for the next project needing it I'd roll my own and do runtime conversions. None of this is to say that static unit types for compile-time checking are bad. I think this is generally a great idea. However, Boost.Units suffers from the same problem that quite a few other Boost libraries do. It's not friendly to use, has undocumented limitations when you try to exercise its functionality which aren't apparent because it's all a rats nest of templates, and the cost may outweigh the advantages it provides. https://gitlab.com/codelibre/ome-common-cpp/blob/master/lib/ome/unit-types/length.h https://gitlab.com/codelibre/ome-common-cpp/blob/master/lib/ome/unit-types/pressure.h (and the rest of the headers there) Why is none of that basic stuff built in? Boost.Units provides all the building blocks, but why the hell doesn't it provide the actual concrete unit types you'll actually *need* in a typical program or library? I'm not going to want to expose the horrible guts of Boost.Units to my fellow developers and end users; they'll find it unreasonably difficult and confusing. Would you be able to export this mess of templates across a DLL boundary on Windows? Just to pass a length or pressure value? Doubtful I'd want to try. But a plain `struct { T value, enum Unit }` would do the job with a great deal more simplicity.
I don't think advocating avoiding ADL is sensible. If you want to use the globally defined space type out ::max
Cool thanks. Once I write something up I'll let you know how it goes! Just looked into the source for simdb.hpp and it's a very nice design. I'm learning a lot like what the [FNV-1 hash](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function) is (I don't come from a Comp sci background, maybe this is an obvious hash haha) 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
That's something I picked because it was small and I could copy and paste it in without dependencies. I wanted to make sure it could be used by dropping the file into into any project. I forgot about it until now actually. I didn't focus too much on the hash function, and worried much more about the concurrency. It should be very fast, although there are still ways it could be sped up. 
I don't think you understood the concept of this post. The point is by advocated the use of `using namespace std;` has unintended consequences that I have seen in industry. This is a very safe example of what happens. However, I have seen much worse. It is better to just type `std::` when you need to use something from the standard library. 
Actually you don't even need to do find_package for other libs. Build tensorflow with bazel, it has two .so targets and lots of generated include files. Copy them to appropriate locations (usr/local/lib and usr/local/include or a folder of your choice). Then add to your own projects CMakelists.txt using target_include_directories and target_link_libraries. Done!
I work in a place where a million people had the idea of "I'm more comfortable writing my own X" and therefore we have to hire people to maintain a two-decade subset of a standard library implementation.
I guess the scale of things matters. In a large enough organization cost-effectiveness is probably king. 
The real question here is: Is VS 64-bit yet?
The sentence immediately before that note is the following: "Each member-declaration in the member-specification of an anonymous union shall either define a non-static data member or be a static_assert-declaration." Basically, the standard gives a whitelist of stuff you *can* define, and the note specifies what you *can not* define.
An unnamed struct definition does define a non-static data member though, so the wording seems ambiguous to me. Perhaps that's why the compilers fail to agree as well.
It defines two things: A non-static data member of an unnamed struct, and an unnamed struct.
I’m sure my grandkids will tell me all about it in the nursing home. (I love C++ but timely integration is not something they value.)
I didn't say it can't be used for reuse. I'm saying in most cases, it shouldn't be. You can reuse things by reusing them. They don't have to form an inheritance relationship. If you can reuse something without inheriting from it, then don't inherit from it. If something is so generally useful, then it should be its own thing that can be reused without being inherited from. Convenience is a poor excuse for poor design. It's mind-boggling that so many people think this is acceptable. You shouldn't put something into a design just because it makes something easier. Subtyping is not for convenience.
MSVC does warn, "warning C4201: nonstandard extension used: nameless struct/union". https://godbolt.org/z/zGocsd 
That's not equivalent to the second example from OP. You've used an anonymous struct, which is definitely non-standard in C++. What we're discussing in this thread is whether an unnamed struct within an anonymous union is standard or not. MSVC does not warn: https://godbolt.org/z/4FkA8c
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b76awb/hey_im_learning_c_i_wrote_this_dog_years_program/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; GCovHTML collects code coverage using the gcov tool, and then generates reports on the data. There is a simple text report that calculates the line coverage and function coverage for all of the source files (example). For more detailed information, there is an HTML report (example). The HTML report includes line coverage, function coverage, and possibly branch coverage. Annotated source files are also created (example). What does this mean?
What do you mean "impossible"?! If the author of the code knows what endl does, then it us, otherwise it isn't - *simple!*
What are the differences compared to lcov or gcovr?
Hi, thanks for this i’ll definitely bare it in mind, interesting that a variable inside a loop vanishes once the loop ends (i did not know this but i guess it makes sense really), regarding namespace, from what i understand (at the minute) there’s only one and that’s the standard namespace where the standard library is stored (pre written code to be used at our disposal?), i could be totally wrong though?, and this is where things like iostream and cout are already written and stored 
Found a neat header only/low overhead library that looks/feels modern that I'll be using in my next side project: [nuklear](https://github.com/vurtun/nuklear)
I have to spend some time on the homepage this looks pretty cool. Some nitpicks from glancing over the code/readme: - What compilers are supported? - I believe most static casts are unnecessary - You should replace `shared_ptr&lt;foo&gt;(new ...)` with `make_shared&lt;foo&gt;` - I would prefer a non-header only library, but others may disagree 
Hi, thanks for this i’ll definitely bare it in mind, interesting that a variable inside a loop vanishes once the loop ends (i did not know this but i guess it makes sense really), regarding namespace, this is where i’ve been struggling the most, i understand that to have more than one variable with the same name in the same scope there has to be a namespace but i can’t with any certainty settle on what a namespace actually is, this gets more confusing for me when i think about the standard namespace and the standard library, is the standard library contained within the standard namespace or are they two different things entirely and my confusion simply stems from the fact they both use the word ‘standard’ Ps. There is no need to give me the answers to these questions, i’m sure it’ll all click at some point, i’m just thinking out loud really 😂 No one said learning a new language was gunna be easy so i’ll just keep on trucking
On cout that will happen regardless, because the cout stream object doesn't buffer by default.
Interesting, did not know that. But makes sense. Every single &lt;&lt; is a function call.
&gt; In practice calling `.clear()` on a moved-from vector isn't needed, but it's necessary to be correct according to the standard. What do you mean it is necessary to be correct? i.e. correct for what purpose? For re-using the vector? Or something else? (The paragraphs reads as if `std::vector::clear` was required to be called after all and any `std::vector` moves).
Why we don't use unit libraries in our applications: 1. The majority of units is user-defined, and thus cannot be checked statically at compile time. 2. For the few units that are built-in, there is virtually no gain to having the unit checked. This is because the value passes through numerous generic components that don't care about units: database interfaces, message passing interfaces, user interface components, IO interfaces, etc. Should we implement all those things in unit-specific versions, at considerable cost, just to have a tiny extra amount of safety? It's just not worth it.
In practice you can assume that moving any vector will leave the moved-from vector empty, because that's what all standard library implementations will do. But that's implementation-defined behaviour so you shouldn't rely on it. So a call to `std::vector::clear` is one way to put the object in a well-defined state (even if in practice it's a no-op). 
How?
I was asking because it seemed like you were saying that in some cases, a moved-from vector could be non-empty, and I wondered if that *maybe* required for whatever reason a `clear` to ensure the vector is destroyed properly along with its elements etc. It would be disastrous, of course, and does not make sense, because the standard library objects will be in valid states, so will be properly destroyed, but still, the original paragraph read a bit weirdly :)
I have a similar problem. [anastasiak2512](https://www.reddit.com/user/anastasiak2512) could you please tell us if it is possible to write code directly on a remote machine without holding code base on local machine?
* What compilers are supported? It is tested with gcc 5.4 and has been tested a while ago with VC 2012 (CTP). It use cmake as cross-platform building system : It should be supported by any compiler supporting at least C++11 features * I believe most static casts are unnecessary Thank you, I will make a tour to clean-up. (There is a lot of missing places where the use of 'auto' will also clarify the code) * You should replace shared\_ptr&lt;foo&gt;(new ...) with make\_shared&lt;foo&gt; Thank, indeed. I will make a clean. * I would prefer a non-header only library, but others may disagree Being also for student and so, I think it makes it more accessible.
cout buffers until newline by default; _cerr_ is unbuffered by default.
I tried working with Boost.Units multiple times. But usually I failed. And the reason in all these cases was that simply setting up the whole system took more time than I had to invest. I could use the same time to write tests and that would really find and prevent errors and at the same time not introduce a crazy complicated library every other developer in my team would have to deal with. Additionally we have a lot of interfaces (our own and more so to external software/storage) that are not typed at all (at best: stringly typed). So there is no actual gain when using a unit library as opposed to simply setting up tests for our own code. But luckily no rockets blow up when we get our units wrong. On the other hand simple systems like std/boost::chrono are used extensively in our code base. Mainly because they make our code simpler to reason about when dealing with multiple different clocks. These times are converted to usually floating point seconds and then used to compute our results as plain numbers. Again, this is the part we fully control and check via tests. So to sum it up: there are no typed interfaces/no typed storage in our case. Adding unit types internally does not help much in our case so we most of the time resort to testing our own code and making educated guesses about input/output ranges. But basically it's garbage in/garbage out.
Yes, I switched from clion to VScode a few weeks ago due to this. VScode's indexing isn't as good as clion, but its GUI doesn't freeze!
Asan pads allocations with dead bytes so it’s not possible to accidentally within segment of a nearby object. 
Why is it not possible? The padding can't be infinite so it should be possible for large enough index to access a nearby object, isn't that so?
C++ won't make it faster if the wrong algorithms are being used.
It happens in Java projects as well. One of the reasons that I still prefer Eclipse for Java and only touch IntelJ for Android related stuff.
Yes, however even with massive Java projects (millions LOCs), it still only take a few seconds. Even with a medium-sized C++ project the stall takes at least half a minute :/
I'm happy I don't use `unamed` structs, sounds terrible.
&gt; VC 2012 (CTP) Don't ever mention this again - tell you, or your colleague that used it, to upgrade *now*. *Now* *now*. Don't use 7 year old compilers, for everyone's sake.
If you use it in a context where it isn't necessary it might prevent a "copy elision" optimization. Then you have an unnecessary move compared to no move at all.
Hey, so this looks really cool. But I'm a bit confused. I went to https://hurna.io/index.html and it says it's a web-based visualization platform. Yet I am unable to find any visualizations online. For example I go here: https://hurna.io/academy/algorithms/sort/bubble.html but still can't find any interactive visualization. Is it not web-based? Edit: Oh... after some more searching, I now found the Hurna Explorer https://demo.hurna.io/#path=sort/bubble_sort where there's indeed interactive visualizations! It's really cool, wow! May I just perhaps suggest that the website layout could be improved quite a bit, so it's easier to find those web-based interactive visualizations, linked to the courses? Very nice work!
Another thing! It would be really amazing if there was a window showing the code running right next to the visualizion, with a line highlighting the current step that's being executed. That would be amazing.
formatting tools are not that useful in practice anyway, as simply needs to concat string and numbers. It is actually better to flush [in my opinion], as normal people expect to see something in their terminal when using `std::cout`
vec.x() seems less pretty than vec.x, especially in vec.x() = 123 example.
The vast majority of people do not know however and it is very hard to know if the author knows (or knew when they wrote the code). That is the opposite of simple. 
I even Saw this in a game dev Book and a guide for SIMD/SSE programming. I've been looking into it this last week and just am confused. What's the usecase of union if it's undefined behaviour? Or is it just because it's an inherited feature of c and should be skipped in c++?
I didn't get what spurred this comment... &gt;and has been tested a while ago with VC 2012 (CTP). 
You are mixing stream buffering on the OS level (it maybe c level) and buffering in the c++ upstream objects.
In engineering, applied mathematics, and physics, the **Buckingham** **π** **theorem** is a key [theorem](https://en.wikipedia.org/wiki/Theorem) in [dimensional analysis](https://en.wikipedia.org/wiki/Dimensional_analysis). It is a formalization of [Rayleigh's method of dimensional analysis](https://en.wikipedia.org/wiki/Rayleigh%27s_method_of_dimensional_analysis). Loosely, the theorem states that if there is a physically meaningful equation involving a certain number *n* of physical variables, then the original equation can be rewritten in terms of a set of *p* = *n* − *k* dimensionless parameters π1, π2, ..., πp constructed from the original variables. (Here *k* is the number of physical dimensions involved; it is obtained as the [rank](https://en.wikipedia.org/wiki/Rank_(matrix_theory)) of a particular [matrix](https://en.wikipedia.org/wiki/Matrix_(mathematics)).) The theorem provides a method for computing sets of dimensionless parameters from the given variables, or [nondimensionalization](https://en.wikipedia.org/wiki/Nondimensionalization), even if the form of the equation is still unknown. [https://en.wikipedia.org/wiki/Buckingham\_%CF%80\_theorem](https://en.wikipedia.org/wiki/Buckingham_%CF%80_theorem)
&gt;I was a bit disappointed that modules doesn't force you to use namespaces by default and I have not really seen a good reason not to do this. So if I want to make each file its own module, and put each class in its own file, all my classes should essentially have their name duplicated? import Point; import Vector; Point::Point x(1, 2); Point::Point y(5, 6); Vector::Vector myVector(x, y);
Not using it anymore, just saying i tested a while ago when I had the occasion and this is the oldest one I remember was compiling the project. I'm under gcc 5.4 with QT Creator \^\^
Thank you very much for your advice : indeed I will try to make it more visible from the courses to ease the visualisation access. Concerning the code running panel, It would be very nice and exists when using Blocks for programming. It could be quite easily implemented running JS code. From the C++ and the JSON logs generation it is much more difficult to implement because the log is not related to a specific line of code (wrappers) and then if I had to deal with this extra information, it would make the JSON file heavier.
**Feature request:** OpenMP 3.0 allows to use `unsigned` types in parallel for loops. But MSVC does not support this feature yet. This was the most annoying issue I encountered in one of my C++/OpenMP projects. Hence it would be nice if MSVC would add support for `unsigned` types in OpenMP.
Sure. I think [[likely]] is sometimes appropriate. I don't think using [[likely]] is good default. Just use // likely
&gt;Generally the model has been ok, but ... OK - compared to what? The alternative is to not try to keep things separate and just let everyone "just code". The "but..." part of the post recounts those aspects where someone has broken your own rules. It's really a confirmation of the OP thesis. I think practical help would be to run some dependency checker one a regular basis and spend some effort diminishing or eliminating circular dependencies via regular code refactoring. It "seems" like extra effort, and it is, but I think it will be rewarded with less problems and better code. \&gt;Build times are longer because of link time ... Again, compared to what? All that link time is (or should be) replacing compilation time which has been saved. So link times are not a good reason to eschew this kind of practical modularization. One thing that might be helpful is to investigate the hiding of internal symbols in object modules. This comes under the heading of "visibility" in gcc/clang and "symbol export/import". The way it's been defined by vendors makes this a pain to use. But it has two big benefits: First. it can diminish link time by a lot. Second, it prevents library users from reaching into implementation just to solve an immediate issue. This shows up as a compilation or linkage failure. At this point the issue of whether or the public interface should or should not be expanded or the app is doing something it's not supposed to do becomes a public one which requires that the players - the library developer and app writer, have to explicitly come to agreement and address together. This is contrary to the usual scenario whereby the the app writer just hacks a working result (because he's under time pressure, and dealing with other programmers is a pain in the rear anyway) and adds one more little land mind for the next developer to work on the project.
I have been a big promotor of Boost.Units. The responses here are very interesting to me and I'd like to comment on a few here: One issue it that it seems that in some cases the distinction between dimensions and units is not made clear. Actually the whole topic sort of reflects this. \&gt; Boost.Units isn't especially useful because of the design that the units of interest are known and fixed at compile-time I'm of the belief that if you need runtime units checking you're doing something wrong. Dimensions can't be a runtime concept as they are intimately related the types of variables used. Units could be runtime but I don't think this should be a feature of the "units" library but rather the the application which might permit selection of units input from user input at runtime. So I believe that code should be written with fixed dimensions and canonical units selected at compile time. Note that compile time units checking library such as boost units permit translation of quantities between units of the same quantity at runtime. \&gt;Part of the problem is that they are very, very complicated. Boost.Units has an insane amount of templated magic going on. And if you need to make proper use of the library, you need to dig deeply into it. This is unfortunately very true. I've even given a [talk](https://www.youtube.com/watch?v=qphj8ZuZlPA&amp;t=3285s) at CppCon on the subject in attempt to address this. My belief is that the Boost.Units is (fatally?) flawed by the lack of good tutorial documentation. The implantation is very complex - I'm sure if written today it would be a lot simpler - this makes it almost impossible to figure out how to use by inspecting the code. I have invested the effort to understand enough of it to use and it IS very useful. But this criticism is very valid. Other responses echo this complaint. I found the links to **Buckingham** **π** **theorem** very interesting, though I have to confess I didn't understand them. Robert Ramey &amp;#x200B; &amp;#x200B;
&gt; OK - compared to what? [regarding many little libraries] Compared to having a very few libraries; maybe even just two or three. But I didn't mean we regretted it - we don't. As you said, it requires investing time in keeping the library dependencies clean. I'm ok with that, we just didn't appreciate how much effort that would be when we started. &gt; Again, compared to what? [regarding link times] That's a good question. Indeed, perhaps it is the best case scenario. &gt; hiding of internal symbols in object modules I knew about the visibility flag/attribute, but I was not aware it would help diminish link time significantly. Thanks for the tip! I've also been meaning to try out LLVM's `lld` linker, to see if its reported speed gains over old and Gold will help us. 
This tutorial helped me and is exactly what I need which is calling a function from python. &amp;#x200B; [https://www.coveros.com/calling-python-code-from-c/](https://www.coveros.com/calling-python-code-from-c/) 
I have pushed for UoM types at two companies with limited success (autonomous vehicles). It is easy to sell developers on UoM types in APIs. The adoption of std::chrono in C++11 makes the sales pitch easy from a coding perspective. No one argues against the benefits with respect to code robustness. However, is hard to get developers to use UoM in their internal application logic. It's not their fault: All UoM libraries fail miserably at supporting anything but simple computations. I know of no linear algebra library (e.g., Eigen) that allows UoM types to be preserved across computations---this is a near showstopper for widespread UoM adoption. This makes it _very_ hard to use UoM types for any computations that require rotation and translation (i.e., practically all robotic applications). Optimization/least-squares problems, also common in robotics, are even harder to solve, since the dimensions of your problem are much greater than the what's necessary for solving rotation and translation. Even if you had a linear algebra library that supported UoM, I fear that compile-times could grow non-linearly with the number of dimensions in your problem (O(n^2)? O(n^3)? I haven't thought too deeply on this.), since the compiler would have to derive a UoM type for every temporary variable (how many temporary variables are there in matrix-multiply?). Sure, you can `reinterpret_cast` your way to success (provided your UoM library merely wraps arithmetic types) to adapt to a linear algebra library's API, but that boilerplate code is ugly, tedious, and it defeats the whole purpose of UoM types. I've worked with Boost.Units and the Units library (https://github.com/nholthaus/units). I enjoy using Units more, since (1) it's developed in modern C++ and supports constexpr, and (2) its API is far easier to use than Boost.Units. However, I dislike that Units that it defaults to `double` types, and the library does not let you pick the units of the backing store (e.g., lengths are always stored in meters). This leads to loss of precision when you try to use something other than doubles. I think some of these issues will be resolved in Units v3.0. If a UoM library is going to gain wide-spread adoption, I believe it will need the following characteristics: 1) Its API needs to be at least as easy to use as std::chrono (and std::chrono leaves a lot to be desired). Boost.Units does not meet this bar, in my opinion. 2) Its API needs to let the user define the arithmetic type is the backing store of the their UoM type. Just as we pick int, float, double, etc., according to need, a good UoM library needs to let developers do the same. 3) Support mixing the use of UoM types with different underlying backing stores. Just as I can multiply a double and float, I should be able to multiply two UoM types with different backing stores, and expect the result to follow C/C++ type promotion rules. 4) The UoM library needs to let us define the scale of the underlying storage (e.g., store data in meters, millimeters, etc.) 5) Make it easy to adapt to other libraries. One that provided pre-canned adapter layers for common libraries (Eigen, protobufs, etc.) would be wonderful. 6) It's 2019. It needs to support `constexpr`. All of these items can be summarized as: UoM types need to be as easy to use as arithmetic types, or at least close as possible.
The fmt library has support for this, though I know that isn't really helping you. It might be simplest to create a custom function that pads with whitespace. ie Pad(msg, padding) will put msg to output, then if the msg's length is less than the padding, add padding - msg's length whitespace characters. 
Destination could be shortened to "Dest" :), "Takes of" could be "Departure Time", "Lands" could be "Arrival Time". That will help get some of the fields to more closely match.
Let's say your heading are H0, H1, H2, ... characters long, and your values V0, V1, V2, ... characters long, then I would say you should start both the heading and the values at : 0, max(H0, V0) + 2, max(H0, V0) + max(H1, V1) + 4, max (H0, V0) + max(H1, V1) + max(H2, V2) + 6, ...
`m*65534` and `(m&lt;&lt;16)-(m&lt;&lt;1)-m`) are not equivalent.
This is exactly the sort of thing I was looking for. Pretty sure this'll work. Thanks!!
We would make and sell together freelance, 1/n number of people working on the project
Can you please rewrite your comment in Rust?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b7gbka/help_a_normie_compile/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I would just write a 2-pass function that takes a 2d array of strings (iterator-ize as needed) and prints them table-formatted. It should be very easy as long as you don't need maximum possible performance.
**An explanation of my issue:** I've been using your software for some time to program music for my [musical Tesla coil](https://www.youtube.com/watch?v=lcm9c_UDiGk&amp;t=0s&amp;list=PLuf7-ivwVQAYqM9AMxgYC2Nq3yDnRdYYp&amp;index=2) and have encountered a software challenge that I'm hoping you can help me with. Currently, when quantizing,MidiEditor makes notes as long as they possibly can, extending into the timing of other notes. For example, 4 quantized quarter notes currently land on the following ticks: 0-192 192-384 384-576 576-768 Notice how the **off** tick of each note is the same as the **on** tick of the next. In typical applications, this isn't an issue. However, the Tesla coil is programmed to only play 2 notes at a time, so when harmonies, or just several notes come on in quick succession, the software I use to translate Midi to Tesla coil cuts notes, which isn't ideal for the listening experience. The change I've made changes quantization so notes now land on these ticks: 0-19**1** 192-38**3** 384-57**5** 576-76**7** &amp;#x200B; **The Solution:** Sources/src/gui/MainWindow.cpp line 2884 off-&gt;setMidiTime(quantize(off-&gt;midiTime(), ticks)-1); //This -1 stops the quanitze function from extending into later notes. Added by Mario Avila previously the line read off-&gt;setMidiTime(quantize(off-&gt;midiTime(), ticks));
I'd do it something like this: using Size = size_t; auto constexpr separator {' '}; auto const &amp;table = load_table(); // formatting pre-pass Size format[cols] {0U}; for ( Size col = 0; col &lt; table.cols; ++col ) for ( Size row = 0; row &lt; table.rows; ++row ) if ( table[row][col].length() &gt; format[col] ) format[col] = table[row][col].length(); // printing pass for ( Size row = 0; row &lt; table.rows; ++row ) { for ( Size col = 0; col &lt; table.cols; ++col ) { std::cout.width( format[col] + padding ); std::cout &lt;&lt; table[row][col] &lt;&lt; separator; } std::cout &lt;&lt; "\n"; } Ideally I'd be using {fmt} instead of the abomination that is std::cout, though.
Formatting is something you don't want to re-invent the wheel on! Use the `{fmt}`[https://github.com/fmtlib/fmt] library. It'll handle all your problems, and more, once you've learned it you'll never have to deal with these problems again.
They were not intended to be. The point is that the compiler will do the clever thing when it sees fit, even if you don't bother doing it manually (65534); or it will do the simple thing when it sees fit, even if you go out of your way to do things clever manually (65533).
As soon as the output device uses proportional font, all solutions based on character lenght will fail, eventually. For example, both “iiii” and “wwww” are 4 chars but the latter obviously takes more space when using non monospaced font.
&gt; The size_t type is now allowed in OpenMP SIMD loops, but still disallowed in regular OpenMP For loops. We'll fix it. Thanks for the suggestion. Unsigned types are now allowed in OpenMP SIMD loops, but still disallowed in regular OpenMP For loops. We'll fix it.
Why is it very hard? I can ask him, can I?
Why wouldn't the compiler recognize this situation? 
Interesting! Compare to the cases where they were using HTML for "hacking" government, this is progress. *Checks the username* Are you Iranian/Iranian descendant?
Range based for and std::unique_ptr. At least it’s “modern” C++. 😀
CMake plugin had issues in the past, maybe upgrading the plugin would help. Recently I had no issues with this plugin anymore.
Thanks for the article, in my last company we had a similar setup, but with traditional Jenkins configuration, not with pipeline. We never updated to pipelines, but nice to see that it would have been pretty easy.
You can easily rename the confusing variable InSearchPath to something more meaningful in the plugin configuration.
Thanks I hadn’t thought about that 
oh and the use of reasonable comments to boot!
Additional suggestion: IIRC the cppcheck plugin provides also a pipeline step, so you don't have to use the generic sh step. And the warnings-ng plugin provides recording/publishing options for almost all sources of warnings/errors.
Please don't. It may be that it makes your code a little more elegant right now, but future maintainers of your code and tools (syntax highlighters, static analyzers, ...) will have a hard time understanding your code.
copy elisions are not "as-if" optimizations. They affect behaviour in an observable way which requires explicit rules about when such optimization is allowed and when not. The use of move changes the former situation into the latter where copy elision is not legally applicable anymore.
ETD = expected time of departure ETA = expected time of arrival ATD = actual time of departure ATA = actual time of arrival are the acronyms used in the real world.
To not get UB, this code provides the same interface at the cost of extra overhead: struct Vector3 { Vector3() : data(), x(data[0]), y(data[1]), z(data[2]) {} float&amp; operator[](std::size_t i) { return data[i]; } const float&amp; operator[](std::size_t i) const { return data[i]; } float data[3]; float&amp; x; float&amp; y; float&amp; z; }; enum class ShapeType { Circle, Rectangle }; struct Shape { Shape() : data(), radius(data[0]), width(data[0]), height(data[1]) {} ShapeType type; float data[2]; float&amp; radius; float&amp; width; float&amp; height; }; &amp;#x200B;
That will likely still be there in 25 years.
Can the rules be enhanced to cover the common situations where this is the case? Do any of the major compilers offer diagnostics / warnings when this event happens?
Nice write up. Thanks
According to the original thread, the show is set before C++11 was a thing 🤷‍♂️
I meant the SIMD stuff
The /fp:fast effects are SIMD stuff
Don't use a proportional font, then. No one uses proportional fonts to do accounting with, for exactly that reason.
The point is that there are a lot of libraries that do this and every compiler that I know support this.
Task constructs and custom reductions are on my wishlist. Also support for twophase lookup with OpenMP enabled would be nice.
It's not clear why some consider running vcpkg commands from cmake a bad idea. It's not. vcpkg is cross-platform. In a team setting, where reproducible builds are important and not everyone is a package-manger ninja, taking a dependency on a package manager of your liking (vcpkg, Hunter, conan) does not sound that bad. Second, with enough cmake abstractions such as [ExternalProject\_Add](https://cmake.org/cmake/help/latest/module/ExternalProject.html), the experience could be much smoother. See some examples below. pmm and [google-cloud-cpp/super](https://github.com/coryan/google-cloud-cpp/tree/auto-vcpkg-prototype/super). Hunter, for instance, easily manages downloading and building dependencies before cmake project generation phase. It's seamless. Gradle in java world downloads the jars from maven repository before compiling your code. I never used \`vcpkg integrate install\` in my setup. I don't know why it's needed at all. I know what it does. I did not find any reason to use it. Multiple versions of the same library in different vcpkg instances is not far fetched at all. Hunter effectively does the same thing under \`${HOME}/.hunter\`. Working on different versions of the same project ends up using different dependency versions. I updated the blog to allow passing CMAKE\_TOOLCHAIN\_FILE from command line. Also, target-based cmake commands.
The book is from 2001, although both the book and the current series seem to be aiming for "modern day". Flat panel TVs and modern smartphones are also shown in the show.
You keep making my points for me: If you have to ask whether this was intentional you have long left the realms of readable and self-explaining code. Also: Not every other author sits next to you in an office that both of you work in every day. Maybe you are looking at a sporadically maintained FLOSS-project or the author is on vacation, making this into a potentially multi-week-endeavor until you get your answer.
All kidding aside, lot of really good Iranian emigre scientists and coders (especially women) that the US ended up massively profiting from after '79. Iran's doing pretty well in the science department nowadays itself (RIP Mirzakhani). But they've had to rebuild everything from scratch, and the local physics prodigy mothers often want their sons out of the country and working at Caltech instead, so they don't get conscripted into the bomb project and risk getting knocked off by Mossad. Given how the Shah wanted an atom bomb no less ardently than the mullahs, it's not implausible they'd already have one if the mullahs didn't decide to pull an Islamic version of the Cultural Revolution in the 1980s. Makes for interesting what-if history. 
It’s a while since I read the book, and I haven’t watched the show. But from what you’ve said, I now agree it’s probably legit.
Aren't most tools line buffered so shouldn't '\n' be equivalent to endl?
Niah.. You're inventing "your point" as you go. You said first that's "impossible to know". Now you're saying it's not readable. And dig this: if **you** know what this does (I did) code is readable and it explained itself. So... good luck with this, you have won (it's what you care about anyhow, so you can have it, I am not interested).
It's common on Linux (and IIRC different on for example Windows) but even here `std::cout &lt;&lt; "foo\n"` is measurably faster than `std::cout &lt;&lt; "foo" &lt;&lt; std::endl` because you still safe write-operations by combining them.
&gt; If your project is using inheritance as a means it prevent code duplication then they are doing it wrong What if i have a function that needs to execute different code for different platforms wouldn't it be good idea to use an abstract class and put the platform independent code in the abstract class?
Ive been going through this book [https://7chan.org/pr/src/OReilly\_\_Practical\_C\_\_\_Programming\_-\_Steve\_Ouallin.pdf](https://7chan.org/pr/src/OReilly__Practical_C___Programming_-_Steve_Ouallin.pdf) . I know ya'll might say its terrible but its a gentle intro which i needed. different strokes for different folks. find what works for you
why, so we can program special effects for the new marvel movie :P /s
&gt;According to the original thread, the show is set before C++11 was a thing 🤷‍♂️ And it's still more advanced than most C++ code I see these days
AFAICS you just implemented interpreter pattern for a rather poor sequential-only XML-based language.
I guess it would indeed be simpler to export primitives bindings to Python or some other scripting language, but there are platforms with very limited computational resources (embedded and stuff) with no ability to run the interpreter.
Thanks for the link to the talk. I would have to agree with all the positive and negative points you raised there. Regarding the point about "if you need runtime units checking you're doing something wrong", this really depends upon the use case. For the examples you mentioned, static compile-time unit conversion makes a lot of sense. However, some other cases involve processing user input, for example from a GUI or a file format. These require run-time conversions. I currently do this with some really nasty Boost.Preprocessor usage to allow run-time use of the static Boost.Units types (e.g. https://gitlab.com/codelibre/ome-model/blob/master/ome-xml/src/main/cpp/ome/xml/model/enums/UnitsLengthConvert.h) but there is a need for proper run-time support which could be done ancillary to the static compile-time support.
Coincidentally, I just ran into a Boost.Units error testing with the new Ubuntu beta release with Boost 1.67. Yet again, it's an MPL issue. MPL really needs to disappear, it's totally unnecessary with variadic templates since C++11. I run into so many terrible problems because of it. The lack of coherent support for C++11 language and library features across the board in Boost is another separate problem which really needs addressing. If I'm using C++11/14/17, I really don't want to use the obsolescent Boost libraries which predated that standard version, but they remain pervasive and without any consensus for improving Boost across the board. [ 13%] Building CXX object ome-model/ome-xml/src/test/cpp/CMakeFiles/model.dir/model.cpp.o In file included from /usr/include/boost/mpl/aux_/include_preprocessed.hpp:37, from /usr/include/boost/mpl/bind.hpp:50, from /usr/include/boost/mpl/lambda.hpp:18, from /usr/include/boost/mpl/iter_fold.hpp:20, from /usr/include/boost/mpl/distance.hpp:18, from /usr/include/boost/mpl/aux_/size_impl.hpp:19, from /usr/include/boost/mpl/size.hpp:19, from /usr/include/boost/units/detail/dimension_impl.hpp:19, from /usr/include/boost/units/dimension.hpp:22, from /usr/include/boost/units/unit.hpp:20, from /home/rleigh/scratch/ome-files/ome-common/lib/ome/unit-types/types.h:48, from /home/rleigh/scratch/ome-files/ome-common/lib/ome/unit-types/angle.h:50, from /home/rleigh/scratch/ome-files/b/ome-model/ome-xml/src/main/cpp/ome/xml/model/AffineTransform.h:58, from /home/rleigh/scratch/ome-files/b/ome-model/ome-xml/src/main/cpp/ome/xml/meta/MetadataRetrieve.h:53, from /home/rleigh/scratch/ome-files/ome-model/ome-xml/src/main/cpp/ome/xml/meta/Metadata.h:41, from /home/rleigh/scratch/ome-files/b/ome-model/ome-xml/src/main/cpp/ome/xml/meta/OMEXMLMetadata.h:49, from /home/rleigh/scratch/ome-files/ome-model/ome-xml/src/test/cpp/model.cpp:53: /usr/include/boost/mpl/aux_/preprocessed/gcc/bind.hpp:466:67: error: template parameter ‘template&lt;class T1, class T2, class T3&gt; class F’ template&lt; template&lt; typename T1, typename T2, typename T3 &gt; class F, typename Tag &gt; ^ In file included from /usr/include/boost/mpl/aux_/include_preprocessed.hpp:37, from /usr/include/boost/mpl/quote.hpp:45, from /usr/include/boost/mpl/aux_/full_lambda.hpp:25, from /usr/include/boost/mpl/lambda.hpp:22, from /usr/include/boost/mpl/iter_fold.hpp:20, from /usr/include/boost/mpl/distance.hpp:18, from /usr/include/boost/mpl/aux_/size_impl.hpp:19, from /usr/include/boost/mpl/size.hpp:19, from /usr/include/boost/units/detail/dimension_impl.hpp:19, from /usr/include/boost/units/dimension.hpp:22, from /usr/include/boost/units/unit.hpp:20, from /home/rleigh/scratch/ome-files/ome-common/lib/ome/unit-types/types.h:48, from /home/rleigh/scratch/ome-files/ome-common/lib/ome/unit-types/angle.h:50, from /home/rleigh/scratch/ome-files/b/ome-model/ome-xml/src/main/cpp/ome/xml/model/AffineTransform.h:58, from /home/rleigh/scratch/ome-files/b/ome-model/ome-xml/src/main/cpp/ome/xml/meta/MetadataRetrieve.h:53, from /home/rleigh/scratch/ome-files/ome-model/ome-xml/src/main/cpp/ome/xml/meta/Metadata.h:41, from /home/rleigh/scratch/ome-files/b/ome-model/ome-xml/src/main/cpp/ome/xml/meta/OMEXMLMetadata.h:49, from /home/rleigh/scratch/ome-files/ome-model/ome-xml/src/test/cpp/model.cpp:53: /usr/include/boost/mpl/aux_/preprocessed/gcc/quote.hpp:64:8: error: redeclared here as ‘template&lt;class P1, class P2, class P3&gt; class F’ struct quote3 ^~~~~~ make[2]: *** [ome-model/ome-xml/src/test/cpp/CMakeFiles/model.dir/build.make:63: ome-model/ome-xml/src/test/cpp/CMakeFiles/model.dir/model.cpp.o] Error 1 
Replace XML with protocol buffers, add millions of dollars and thousands of hours of engineering with hardware support and you have TensorFlow.
This code is shown during a flashback, and written with an old monochrome CRT (on a text only os), probably somewhere during the 80s or the 90s. 
Nice work, but I think what's rubbing some people the wrong way is the implication that you invented some sort of new technique. The idea of coupling different polymorphic function objects based on runtime data has been around forever in all kinds of different contexts.
Or it's just some programmer sitting in a Starbucks.
Thanks! I'll revise some of the wording to make it less agressive
https://imgur.com/a/6UKNXSE
You just reinvented domain specific languages
So in finance people have been doing this forever, except the xml file specifies not a simple call chain but an entire computational graph, with config specified node types, parameters, and edges. Complete with runtime verification of matching types at edges, and a lot more fancy stuff. 
You should add my new parallel hashmap: https://github.com/greg7mdp/parallel-hashmap
Beginner here, how would the fmt library know the width of the strings and their columns it is supposed to limit it to?.
Looks great! &gt;A single phmap hash table is thread safe for reading from multiple threads. For example, given a hash table A, it is safe to read A from thread 1 and from thread 2 simultaneously. &gt;If a single hash table is being written to by one thread, then all reads and writes to that hash table on the same or other threads must be protected. For example, given a hash table A, if thread 1 is writing to A, then thread 2 must be prevented from reading from or writing to A. With a map I would lock a mutex for both reads and writes. Is there a more efficient access pattern that would satisfy both of these constraints?
&gt; Is there a more efficient access pattern that would satisfy both of these constraints? not with the regular hash map (like phmap::flat_hash_map). However you can use the phmap::parallel_flat_hash_map and provide std::mutex as the last template parameter. The table lock internally (both read and write), but only lock the submap which is used, so it is multithread friendly.
Can't you do the same thing without the overhead like so: struct Vector3 { float x, y, z; constexpr auto operator[](std::ptrdiff_t i) noexcept -&gt; float&amp; { switch(i) { case 0: return x; case 1: return y; case 2: return z; } std::terminate(); } constexpr auto operator[](std::ptrdiff_t i) const noexcept -&gt; float const&amp; { switch(i) { case 0: return x; case 1: return y; case 2: return z; } std::terminate(); } }; Also, `operator[]` really should take a `ptrdiff_t`, since that's what it takes on actual arrays.
Asking the author is not a viable solution. They might not remember, they might not work where you are anymore or you might have not gotten the code from someone in person to begin with. Information that is not in the code or in the documentation is almost guaranteed to be lost eventually.
&gt; In addition, when teaching beginners, std::endl flushing may prevent them from being surprised by output that seems to occur later than when they did it. That's an even more valuable lesson, though. Debugging through std::cout is common for whatever reason and it is inherently broken.
/u/martinus, thanks for sharing the technique, looks great, I will use it :-)
Using SSE to [check 16 slots at once](https://github.com/greg7mdp/parallel-hashmap/blob/master/parallel_hashmap/phmap.h#L461) is really smart :D
Or you could use my new hashmap family implementation, https://github.com/greg7mdp/parallel-hashmap, for which all hash maps can be forward declared using a small, 117 line [header](https://github.com/greg7mdp/parallel-hashmap/blob/master/parallel_hashmap/phmap_fwd_decl.h). There is also a small [header](https://github.com/greg7mdp/parallel-hashmap/blob/master/parallel_hashmap/phmap_utils.h) allowing to overload std::hash&lt;&gt; in headers without including any large header (except for MacOs which requires &lt;optional&gt;)
What is that giving you that free functions don't?
Yes, I agree. It allows for a very high load factor (87.5%) while still maintaining excellent performance. Super fast *and* memory friendly, what's not to like?
Going to phuleptr in C++3000
What extension(s) one has to install to get the experience (well, beyond MS cpptools) ? Could you provide a list?
Forgot to mention it uses exactly n * sizeof(T) amounts of memory during runtime.
You're a few hours early in my timezone, so it took me a few paragraphs to catch on. Nice!
why wait start now ``` struct fullptr_t { template&lt;typename T&gt; operator T*() const {return (T*)~0;} }; constexpr fullptr_t fullptr; ``` 
What a pleasant surprise!! I used to follow your answers on Quora and back in 2013 I PM'ed your for C++ advice and you advised me to read C++ Primer :) , Do you still write Haskell? 
I like the cut of your jib 
Fantastic! I’ll start implementing now. 
Shit at least put some effort into it.
Kinda disappointed that `halfptr` was not suggested for 16-bit memory address ranges, typically seen in small embedded environments. 
The main difference from lcov is that is uses the intermediate format introduced by gcov in version 7. For most users, this probably isn't a big deal. However, I've found lcov to be fragile, often breaking because of changes in the internal format. I'm expecting that GCovHTML will be more robust, but time will tell. I have some other plans, such as performance and support for clang. However, the tool is usable now, so I was hoping to get some feedback.
Thanks for remembering me! I don't write in Haskell, because my work is in C++ and Haskell is tough to keep up with if you are just using it occasionally, like I do. I still would love to do more of it! What about you, Haskell or C++?
C++ :) Writing C++14 in a data backup team. I have dabbled in Haskell and have an interest in OCaml as well but like you said it’s tough to keep up. 
1-st April foul, nothing more.
Code coverage tools measure how much of your code is being exercised by your tests, and the reports help identify which section are tested or untested.
Inheritance gives you access to protected members, composition doesn't. More importantly, inheritance means you're stuck with the parent class. If the parent is doing something the child doesn't want, and it's a non-virtual function, you have to modify the parent class and then deal with a cascade of changes to the other child classes. Composition, on the other hand, allows you to easily create new components when you need different behavior. No cascading effects to other classes.
Yes, people say C++ is difficult, but next to Haskell I find it quite straightforward (at least to be competent in :-).
Are you looking for std::basic_fractional_pointer_t&lt;1,2&gt; to get a half pointer?
I’m wondering, does the standard actually specify that nullptr is 0? I know it says 0 is nullptr but not the other way around.
I ate the onion for a bit there. Side note: I have actually thought about getting rid of \`nullptr\` and \`nullptr\_t\`, and making every address "fully addressable". However, instead of using a \`fullptr\_t\`/\`fullptr\`, I would use a default-constructed \`std::optional&lt;T \*&gt;\` instead, and make all pointers require valid initializations. (The \`std::optional\` class could be overloaded to keep ABI compatibility)
God damn, I fell for it and typed up a whole response. It's too early for this in the US.
The problem with this proposal is that the byte after any valid pointer also has to be addressable. Unfortunately, `(char*)fullptr + 1` wraps around. 
Have you looked at [wise enums](https://github.com/quicknir/wise_enum)? There are others too, of course, but that one looks very good to me. BTW, your `StrToEnum()` is taking the `std::string` by _value_, which you probably didn't intend.(?) And `EnumToStr()` should probably do bounds checking. 
So let me get this straight... * there is a performance problem (because if there wasn't, the point is moot) * one can't check whether changing to '\n' fixes it (because there's no tests? Because there's no performance targets?) * there's no documentation about this in a comment or whatever * there's nothing to see from code history (e.g. whether this part was written by an intern thereby making the probability of them nor knowing what endl does) * there's nobody to ask for all the reasons you evoke above. Yeah, that is surely what OP called "impossible". 
CMake &amp; CMake Tools are the only essentials for C++. One of the parentheses colorisers will be helpful, I think the one I have is called Rainbow Parens. Git Lens can be handy but to be honest I find it a bit clunky (also the first thing I do with it is turn *off* most of the options. That’s it. You don’t need much.
With C++17, it'd be better to use `std::string_view`, to spare the allocation and copy of the string literals. Pre-C++17, `const std::string&amp;` should be used to get/return those strings, instead of copying them in/out each time
&gt;nullptr is defined as a pointer value with all its bits set to zeroes I know this is an April Fool's joke, but come on. It's already wrong.
&gt; nullptr is an invalid unused address at address zero and any memory access to this particular address cause a running process to die from a segmentation fault. No, it's UB. If it segfaults it's because your implementation does.
You got me for a moment. C++ is exactly that language which would do this kind of thing unfortunately.
the "parallel" part is kinda misleading. &gt;&gt; The parallel tables can be made fully thread-safe, by providing a synchronization type (for example std::mutex) as the last template argument. Because locking is performed at the submap level, a high level of concurrency can still be achieved. what do you mean by a high level of concurrency? Providing a synchronization type isn't enough?
I'd really like to see an article about it or the code. Is there anything available?
I really wish C++ had a builtin way of getting the names of enum class members. There are a bunch of solutions to this problem, some more elaborate but they all pretty much do what you are suggesting. Here is something similar that I did last year with slightly different design goals (no macros): [Converting enum classes to strings and back in C++](https://sheep.horse/2018/5/converting_enum_classes_to_strings_and_back_in_c%2B%2B.html) [github repo](https://github.com/andrewstephens75/EnumMapping) 
No it does not - and it is in fact -1 in GPU programming (among other architectures) with 0 being a valid address. Of course, actually creating a "0" pointer is hard when casts of a literal 0 (and in C, and expression that can be evaluated to 0 at compile time) to a pointer type gives a null pointer (with the value of -1) not a pointer to zero...
Damn it.
ikr! As much as I love/hate C++, advanced C++ syntax can get pretty ridiculous. Can we all just go back to C89? 😛
&gt; Inheritance gives you access to protected members, composition doesn't. If the base class has protected members, and that's only if you design it in such a way. &gt; More importantly, inheritance means you're stuck with the parent class. If the parent is doing something the child doesn't want, and it's a non-virtual function, you have to modify the parent class and then deal with a cascade of changes to the other child classes. Same thing with composition: if the instance doesn't do exactly what you want, you have to modify it. &gt; Composition, on the other hand, allows you to easily create new components when you need different behavior. No cascading effects to other classes. Inheritance too allows you to create new components when you need different behavior. It's no different, because inheritance is actually composition (composition is not inheritance though). 
&gt; I didn't say it can't be used for reuse. I'm saying in most cases, it shouldn't be. You can reuse things by reusing them. They don't have to form an inheritance relationship. If you can reuse something without inheriting from it, then don't inherit from it. If something is so generally useful, then it should be its own thing that can be reused without being inherited from. Exactly what I said: use inheritance if you need subtyping (i.e. use inheritance only when you need it). &gt; Convenience is a poor excuse for poor design. It's mind-boggling that so many people think this is acceptable. You shouldn't put something into a design just because it makes something easier. Subtyping is not for convenience. Poor design is when you have to write a lot of boilerplate code because of composition, whereas if inheritance was used no such need would exist. 
Trop gros, passera pas. 
aprilptr
Honest credit to others. Kudos. :) Maybe I will try this at some point.
Shouldn’t we cast 0 as a size_t before taking the complement?
This is exactly how i fee. Sometimes syntax is just so full of magic. It should be simple. We read code more than we write it and this mental tax adds up. Now someone will come up saying that once you learn it - its fine. No it is not. It took me a good while to grok SFINAE. Now i can read it and write it. This fact does not make it suck any less. Cant wait for `if constexpr` to become a thing once c++17 becomes lowest common denominator.
Sorry that this took so long to get out. I've been busy with life and stuff, and also had to carefully comb through the spec to try and get everything right. There is a lot more subtlety to the subjects of this post than the prior. Hopefully the third part will be ready much more quickly! If anyone has any questions, comments, concerns, or corrections, please drop them in a response to this comment for visibility and so that I can address them ASAP! Thanks!
1) Can ADL find a non-visible (non-exported) function? 2) I'm not sure if I like this concept of reachability that lets me use types that haven't been exported. It sounds as if this is a case where c++ tries to be too helpful and in the course threatens to undermine the primary advantage of modules, namely isolation.
https://cppx.godbolt.org/z/nEj80c
No, because 0 is signed, ~ makes it negative and negatives are expanded with 1s.
I suppose std::uintptr_t would be more appropriate, wouldn‘t it?
Just woke up, first aprils fools joke of the day. This is funny as fuck
Didn't we actually have long and short pointers (near/far?) back in 16-bit x86? I vaguely recall something like that...
Unfortunately `default_order` didn't make it due to concerns about ABI breakage. :-(
0 is signed but it is also only 32 bits. ~0 is therefore only 32 consecutive 1 bits with the rest still 0 (and yes as an int represents -1) ~(size_t)0 guarantees all bits in an address sized value are flipped.
Agree. Its a missed feature, and especially in these "exchange data in json" times. At work I've introduced [better-enums](https://github.com/aantron/better-enums) for a green-field project. We do a lot of ingress json (with [StaticJSON](https://github.com/netheril96/StaticJSON)) and so far its has worked really well for us. Especially its case-insensitive conversion and comparison and no-throw options have been suiting our small embedded target.
Again, if we extend negative 32 bit number to any 64 bit number, it is extended by adding 1s (ones) as each extended bit because this is the rule for extending negative integers.
have looked at https://github.com/jpbarrette/curlpp? Agreed it hasn't been updated in a while.
I use clion but I do wish it had better performance. &amp;#x200B; Sometimes when i'm typing really fast it doesn't pick up my inputs ( like home/end for start/end of line ) &amp;#x200B; Also I wish it worked without cmakelists.txt, but I get why it doesn't.
&gt;Exactly what I said: use inheritance if you need subtyping That's a bit different from: &gt;but it is only inheritance that can be used for combining reuse and subtyping. &gt; &gt;Reuse+subtyping is a very real need and it comes up often in OOP design. Or this sentiment, for that matter: &gt;Poor design is when you have to write a lot of boilerplate code because of composition If you use inheritance to get rid of boilerplate code, that is poor design. It really is you who are doing it wrong. Nowhere does Liskov's substitution principle talks about reduction of boilerplate. You can reduce boilerplate with composition. If you can't do that, that is a problem literally only for your poor design sense.
I hadn't but that looks like a much more complete solution. It is harder to use than my simple wrapper but might be a better fit if you need it.
Lovely, any idea if it could be added to VCPKG? 
Was just about to exec an aneurysm when I realized it's April Fool's Day. Well played.
[https://github.com/preshing/junction](https://github.com/preshing/junction)
That's the most C++ thing I've ever seen.
Look at the order of operations here. You’re extending from 32 bits to 64 bits after taking the complement.
Addresses are not signed
Cast to unsigned is applied after the extension. Please read something on casts, signed extension, and how it all works.
Standard section 4.7. Paragraph 2 says: If the destination type is unsigned, the resulting value is the least unsigned integer congruent to the source integer (modulo 2n where n is the number of bits used to represent the unsigned type). You are correct.
No need. Its a pointer, and like pointers of any type it will be the correct width for the architecture.
&gt; Cast to unsigned is applied after the extension. Citation needed. AFAICT, all the standard says is that this is implementation-defined.
Random iterator support in for loops and thus the foundation for range-based for loop support (which was clarified in OMP5). Custom reductions. Offloading.
7.8 Integral conversions ^(2) If the destination type is unsigned, the resulting value is the least unsigned integer congruent to the **source integer (modulo 2****^(n)** **where** ***n*** **is the number of bits used to represent the unsigned type**). I have highlited in bold where it states that the extension happens prior to cast.
I'm aware of that, but nothing in the code involves unsigned values, so where does the standard say that integral values cast to pointers are first made unsigned?
Well if it is not cast to unsigned, things are even esier, aren't they? You just sign extend a negative value to the desired width. What are you trying to prove?
There is actually a way to **convert string&lt;-&gt;enum** without needing a macro to define your enums: [https://github.com/Neargye/magic\_enum](https://github.com/Neargye/magic_enum) This will also work for 3rd party enums that are not under your control. It works by constexpr iterating over the enum (which I think is quite smart). To not needlessly hurt compiles times you can define the max search depth. So I think that it's best suited for enums that don't define arbitrary values, but rather have all values &lt; 128 (that's the default search depth of the library). &amp;#x200B;
I use "\n" because "hi\n" is a lot more comfortable to type than "hi" &lt;&lt; std::endl I usually don't think that typing is a strong argument but I'm this case the technicalities simply don't matter for 99.9% of the cases. I call bike shedding
I'm not trying to prove anything; you're the one making strong assertions about how things work here, and I'm just trying to make sense of it with the hope of learning something. The only thing I see in the standard that's relevant is &gt; A value of integral type or enumeration type can be explicitly converted to a pointer. A pointer converted to an integer of sufficient size (if any such exists on the implementation) and back to the same pointer type will have its original value; mappings between pointers and integers are otherwise implementation-defined. You told someone to "please read something" as though you know something we don't; so, what should I be reading..?
r/woooosh
you are welcome :) The hash is basically taken from absl, so it's mostly to their credit. I've removed their randomization and use + instead of xor.
I'll see if I can add it, but I've already results from 4 1/2 days of benchmarking that I'd like to publish
April Fool's Day is getting more tiresome by the year. Could be correlated with growing older perhaps.
I think this is a bad name. I expected `fullptr` to be a pointer that points at everything simultaneously.
Well, names are kinda hard. Regarding the high level of concurrency, I did a full writeup [here](https://greg7mdp.github.io/parallel-hashmap/) which explains it in detail.
I guess, a high level here means "a lot of parallelism" because concurrent accesses rarely block
Not with that attitude...
I disagree! It's funny to point out errors in April Fools jokes! I think he got the point but nevertheless wanted to strike back
sure, will look into it asap.
Please stop giving them ideas!
Where’s the section on NVMs
Yep. And I don't know details (just [this bit from a talk by Andrei Alexandrescu](https://youtu.be/LIb3L4vKZ7U?t=848)), but supposedly dealing with new/far pointers is what `std::allocator` was originally introduced for, which is why it's design for allocation was... weird.
https://isocpp.org/std/submit-a-proposal
Just submitted the PR: https://github.com/Microsoft/vcpkg/pull/5893
My issues with that in no particular order: 1. This seems quite formal. I don't want to submit a half baked idea without presenting it to the general community in a less formal setting first. 2. The forums linked seem inactive, and will be completely migrated soon?. I couldn't actually join (tried a month or so back).
My combine times want my C with classes back.
I love wise_enum, I just wish MSVC could compile it. Would be wonderful if MSVC was actually standards-conformant, [Announcing: MSVC Conforms to the C++ Standard](https://devblogs.microsoft.com/cppblog/announcing-msvc-conforms-to-the-c-standard/) is just a lie because of these [Compiler Limits](https://docs.microsoft.com/en-us/cpp/cpp/compiler-limits?view=vs-2017)
&gt; If you use inheritance to get rid of boilerplate code, that is poor design. It really is you who are doing it wrong. Nowhere does Liskov's substitution principle talks about reduction of boilerplate. You can reduce boilerplate with composition. If you can't do that, that is a problem literally only for your poor design sense. Indeed, Liskov's substitution principle has nothing to do with boilerplate. My "poor" design sense says that the more boilerplate the users of my library have to write, the worse experience they will have. So no, boilerplate is out, and composition in C++ sometimes forces you to have boilerplate code, so no composition for me. You have failed to give a sufficient reason why composition is preferable to inheritance. 
I didn't realize until I started reading the testimonials at the end. 
I have to at least ask - if it is all done at compile time, why not use arrays and enums for keys?
&gt; export import :some_partition; Is that a stray colon, or a real thing? Or maybe it should be `::`? (I legitimately have no idea which of these is right.)
&gt; export import :some_partition; Is that a stray colon, or a real thing? Or maybe it should be `::`? (I legitimately have no idea which of these is right.)
A lot of the casting behavior goes back to the past and performance considerations (and a certain kind of simplicity). If it's not making sense, check if it would do nothing in the simplest cases (I.e. same number of bits) - and then maybe it will.
The forums are active, but yeah, a lot of people's emails seem to be blocked by the spam filter (mine included). But std-proposals is still the best avenue to get feedback from others (and some committee members are quite active there).
For a library: Develop it, put it on Github, try to bring it into Boost and if many people start to use it, then you can look for a champion at the committee. For other things you might want to start on the ISO cpp mailing list for future proposals and maybe you find someone else there that is interested and helps you to get your idea into a proper paper.
Because of counterintuitive error messages and restrictions Google has put on that forum people are unable to post messages, therefore they want to use a mailinglist based discussion again. It seems that top message was edited 2 months ago (one month before Kona meeting) so it is a bit odd that I can't find a mailinglist or any updates about the forums fate. The forum also isn't completely inactive because you can see new topics started in late March. One option could be to [get in touch with the 'owner' of the Google group](https://groups.google.com/a/isocpp.org/forum/?fromgroups#!aboutgroup/std-proposals). Politely ask them if there have been made any decisions to how std-proposals forum will go forward since you can't find any up to date public information?
You may try to discuss you proposal on some of the channels of [https://cpplang.slack.com](https://cpplang.slack.com/). I've seen people from the committee participating in the discussions there. 
The casting behavior makes sense to me; the GP's insistence that the rules are anything other than implementation-defined does not make sense to me. ;-]
Great job.
1) Yes, in certain cases involving dependent names: when a template in a module is instantiated, any functions/function templates that are visible to the definition of the template are also visible to any templates that it in turn instantiates (with one exception, see http://eel.is/c++draft/basic.lookup.argdep#4.5 for details). So if code in module A instantiates a template in module B, which instantiates a template in module C, the template in C can see non-exported declarations from B.
Just so I get this right: You are talking about a situation, where module A imports B, which imports C. Correct?
Thanks! It should not be too hard, considering it is header-only and fully standard compliant. 
&gt; use + instead of xor any rationale for this?
This had me going until I got to the part where Herb Sutter is putting metaclasses on hold for this
Yeah, but it wraps around to 0, which is addressable, just not dereferenceable (on most platforms).
You'll have to wait for C++25, implementations will be required to provide exactly one of `fullptr8_t` `fullptr16_t` `fullptr32_t` and `fullptr64_t`. Which of these is provided is implementation defined and mentioning a non-provided `fullptrXX_t` in a translation unit is UB. Good luck.
I have some tests where I am counting the number of operations like moves, copies, hash calculations etc. with high load factors. In my tests I got better (lower number of operations) with + instead of xor. But I don't have any rational explanation, it just seemed to work better in my tests
So i got r/woooosh-ed?
Yup 😂 happened to me too
5% of programmers actually know this much about memory.
Ah, empirical evidence! I can't see any reason why + would be any worse than xor - or better - so why not?
I know this is a c++ sub, so it makes sense here, but ‘every programmer’ seems a bit hyperbolic when you consider the amount of programmers who know only java/ python/ etc or a combination of these kinds of languages with automatic memory management. 
I'm sorry but I still do not understand what you are trying to ask here. Where is the ambiguity? What could different implementations do differently? You seem to understand what you're talking about.
Not true, and Java dev who's dealing high-performance stuff like low-latency trading will need to know and apply this to things they do. Some will even deliberately break out of the rules-of-Java: [https://stackoverflow.com/questions/16819234/where-is-sun-misc-unsafe-documented](https://stackoverflow.com/questions/16819234/where-is-sun-misc-unsafe-documented)
Union isn't "undefined behaviour" in general. The purpose of union is to use a single area of memory for a (member) variable whose type is chosen at runtime, but the choice is limited to a set of types. A typical use case is for example parsing a JSON object: You cannot know at compile time whether the next element you read is going to be a string, integer , array ... so when you parse the input into a data structure, you can specify a type that can hold any one of those without allocating space for all possible types spearately. For this use case, there is little use for union since C++17 added `std::variant`, which provides you with safer, easier to use interface for the same thing. Having `union` in C++ is still important for compatibility with C of course. Trying to union for type-punning or array indexing is undefined in standard C++. The C language - unlike C++ - has been changed to allow these uses of union in C99 standard version. These may also be supported by some C++ compilers as a language extension.
The point of having an array is not so that you get `operator[]`. The need for the array is usually so that you can have a pointer to x, and increment it to get y (without relying on UB).
At least one person out of those 5% thinks that 100% should know it.
I am still at c++11 and you guys are at c++23, I need to step up my game.
Once again providing that the tech industry is humorless
Also see [Take 2: Bootstrapping a vcpkg-based cmake project in Linux and Windows](http://cpptruths.blogspot.com/2019/03/bootstrapping-vcpkg-based-cmake-project_31.html)
I read it and now I know words such as "TLB" or "cache associativity" so that I can make an impression of a smart person
Write a blog post, share it on reddit? Write a description on reddit ? Ask on slack, discord, twitter ? We are _everywhere_ 
Beautiful project and documentation!
The overwhelming majority of shops doing low latency trading will be using C++ over Java (there are some notable exceptions, but it sounds like they end up fighting Java at every step).
I don't care if you write visual basic. If you program for a living you should know how the things you are using work under the covers. Hell I'm all for knowing every part of the chain from semiconductor physics through memory management. Surely the amount of benefit you get scales depending on what you do but there's nobody who doesn't benefit from learning more. 
I've just tried to add it, but get lots and lots of multiple defined symbols. Here are just a few: /usr/bin/ld.gold: error: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/benchmarks/CtorDtor.cpp.o: multiple definition of 'phmap::container_internal::UnsampleSlow(phmap::container_internal::HashtablezInfo*)' /usr/bin/ld.gold: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/app/main.cpp.o: previous definition here /usr/bin/ld.gold: error: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/benchmarks/CtorDtor.cpp.o: multiple definition of 'phmap::container_internal::SetHashtablezEnabled(bool)' /usr/bin/ld.gold: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/app/main.cpp.o: previous definition here /usr/bin/ld.gold: error: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/benchmarks/CtorDtor.cpp.o: multiple definition of 'phmap::container_internal::SetHashtablezSampleParameter(int)' /usr/bin/ld.gold: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/app/main.cpp.o: previous definition here /usr/bin/ld.gold: error: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/benchmarks/CtorDtor.cpp.o: multiple definition of 'phmap::container_internal::SetHashtablezMaxSamples(int)' /usr/bin/ld.gold: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/app/main.cpp.o: previous definition here /usr/bin/ld.gold: error: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/benchmarks/CtorDtor.cpp.o: multiple definition of 'phmap::container_internal::ShouldInsertBackwards(unsigned long, signed char*)' /usr/bin/ld.gold: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/app/main.cpp.o: previous definition here /usr/bin/ld.gold: error: CMakeFiles/bench_greg7mdp_phmap_flat_hash_map__FNV1a.dir/src/benchmarks/CtorDtor.cpp.o: multiple definition of 'phmap::container_internal::GroupSse2Impl::kWidth' I've added `inline` to all the `Throw...` functions but that was not enough.
Thanks man, you made my day :-)
OMG, thanks a lot, I'll look into that today.
Oh I 100% agree, but too often I see people who fall under the realm of “its not relevant to what I’m doing, so I don’t need to understand/ know it.” Which oftentimes is actually relevant, as you said, but not quite as much as for, say, c++ programmer. 
Just pushed the fix
Just gonna read this 114 page document on my lunch break, no problem guys.
1) Can `export module &lt;module&gt;:&lt;partition&gt;` ("exported partition declaration"? "exported module declaration"? "export module declaration"?) appear in multiple files for the same partition, or are partitions under the same restriction as non-partitions: there must be exactly one `export module` declaration for each module or partition? 2) Can there be multiple anonymous implementation units for the same module? If not, perhaps "primary implementation unit" would be a good name alongside "primary interface unit". 3) Can there be multiple implementation units for the same partition?
1) Can `export module &lt;module&gt;:&lt;partition&gt;` ("exported partition declaration"? "exported module declaration"? "export module declaration"?) appear in multiple files for the same partition, or are partitions under the same restriction as non-partitions: there must be exactly one `export module` declaration for each module or partition? 2) Can there be multiple anonymous implementation units for the same module? If not, perhaps "primary implementation unit" would be a good name alongside "primary interface unit". 3) Can there be multiple implementation units for the same partition?
Not really, unfortunately. Finance being finance it tends to all be rather proprietary. But from the little I understand, it's not going to be radically different from any graph based computation system like tensor flow.
1. "Exported module partition declaration" is probably the most accurate term. As far as I am aware, module partitions must have a unique name between files. When a partition is imported (`import :part`) in another file, that `import` must resolve to exactly one module unit. 2. Yes, there can be an arbitrary number of implementation units. 3. See #1. An implementation partition need not _define_ its contents: It might declare them only and then define them in another implementation unit.
I think that vector of bool's package manager manager does the same thing just better xD https://github.com/vector-of-bool/pmm
So a module can split its interface and implementation units, but a partition can have only of them?
Thx. Will look into it.
I'm not sure that this argument accounts for scarcity of time. If I exclusively write visual basic and wanted to improve my effectiveness as a programmer, semiconductor physics is probably not the first thing I'd invest in learning. But I agree, knowing everything would be amazing!
&gt; Write a blog post, share it on reddit? That's what [I did](https://www.reddit.com/r/cpp/comments/b6xtfu/anonymous_and_unamed_struct/) a few days ago, with a relative success (or rather a relative failure). The other solution is that nobody cares about this. 
Oh. Yeah, that makes sense. They really need to standardize on the way C11 handles this. That's one of the few things that C got right that C++ didn't.
Using `std::hash` may be concerning. Have you done any benchmarks regarding this?
&gt; **must read for c/c++ folks** I found 'C++' two times in the 100+ page article. One of the two times is this: "The C and C++ language in gcc allow variables to be defined as per-thread using the \_\_thread keyword." This looks to me like another attempt to use C to smear C++. 
Derived from immediately available evidence?
&gt;This looks to me like another attempt to use C to smear C++. Could you explain this?
In my tests using an int64_t key there is virtually no difference. Even though phmap uses std::hash by default, it adds some "mixing" of the computed hash for the cases where the std::hash implementation is not very good. Also, the user of phmap is free to use any hashing framework he or she wants, even absl :-).
/u/convery, PR was merged to master, parallel-hashmap is in VCPKG!
Yes! This! Computer science is a perfect example where modularization and abstraction made it all possible. The downside is that it becomes way too easy to ignore and neglect basic knowledge because, well I don't have to... Why do I care how my compiler works as long as it does its job? Why is it important to learn how quicksort wors, I just have to call std::sort and my problem is solved. Stay curious kids.
thanks, I've updated and my benchmarks are now running with phmap::flat_hash_map and phmap::node_hash_map
Cool... let me know when I can see the results somewhere!
&gt; I'm not sure that this argument accounts for scarcity of time. If I exclusively write visual basic and wanted to improve my effectiveness as a programmer, semiconductor physics is probably not the first thing I'd invest in learning. &gt; Surely the amount of benefit you get scales depending on what you do but there's nobody who doesn't benefit from learning more. 
sure!
No, "every programmer" does not need to know how memory works on an electrical level. That's absurd. I'd say that most programmers don't even need to know exactly how page tables work; knowing that they exist and are how the CPU/MMU maps virtual address space to physical memory is more than enough for at least 99.9% of software development. Knowing how to develop cache-friendly data structures and algorithms can be helpful when you really need absolute maximum performance, but in world where the vast majority of programming is done in "managed" and interpreted environments, that's clearly not an everyday thing either.
Yeah, definitely not enough templates and ranges-v3 in this one. 
No software project I've worked on has required this much attention to memory optimization. If someone asks for a Camry, I'm not going to engineer a Ferrari.
for software engineer's own good as well thus could fathom what's behind the language syntax, e.g enjoy more while reading 'C++ Concurrency in Action' ;-D
C really should catch up now!
not true
Nod to (late) Robert Asprin
If you only work at a high level you don't need to know the low level. One of the benefits of abstraction. People writing business type applications could probably go their entire career without knowing what a register is. Every person who uses a light switch needs to know how the circuit works. /s
There is plenty of material online that talks about why composition is preferable to inheritance.
I get that this is a document explaining all the intricacies and corner cases of C++ modules, and that real life usage will probably be boiled down to a bunch of conventions after hands on usage, but it still makes C++ modules seem very complicated and over engineered. I am having a hard time seeing what modules brings to the table other than the fact that it isn't headers, and maybe the potential for some multi-threaded compile time improvements. 1. **If code is in a module interface file, why isn't it exported by default?** Seems like a lot of these rules/corner cases regarding visibility and reachability could have been avoided if we just enforced the fact that if code is in a module interface it will be exported, and code that you don't want exported as part of the module should just not be in the file in the first place. Why do we do it the other way around, and then have to pepper our code with a whole bunch of export keywords. Just seems like it makes it extremely verbose and harder to use. 2. **Why are we bothering with module implementation units?** I thought one of the benefits of modules in general is that you no longer really need to have a interface/implementation split like we do with `.h` and `.cpp`. However, this combined with point 1 above just makes it seem like they're encouraging users to split up interface and implementation again. 3. **Partitions are a syntactically ugly way to enable splitting a module definition into multiple files.** Why not get rid of the whole concept of primary interface file and allow multiple files to call `export module &lt;module_name&gt;`? Any declaration exported from a file with that line included will be exported as part of that module. Why do we have to instead manually define module partitions and then manually include them into the primary interface file using something as confusingly named as `export import :partition`. Maybe the whole thing was designed this way because of all the baggage that C++ brings with it and it would take too much work for existing compilers to adopt a more flexible module system, but the way modules is designed right now kinda makes me disappointed. I am probably being naive here, but what I really want is: 1. `export module &lt;module_name&gt;;` This will export everything declared in the current file. No need to type `export` in front of everything in there. 2. `module &lt;module_name&gt;;` This will make everything declared in that file visible to code that belongs to that module. No need to `import :&lt;partition_name&gt;` in other files to use the code defined here.
Wondered if that was a Willard reference.
Yea a 5-pages TLDR would be nice... and then this can be the in-depth version.
I've been a C++ dev in low latency trading before and whilst I definitely needed to know about page tables and how they work, I certainly never needed to know how memory works on an electrical level. I agreed that the title of this post/pdf is absurd to the point of just being clickbait.
Well embedded programmers are arguably more than 0.01% of programmers and usually find knowing how memory works useful. Not as in-depth as this.
&gt; If someone asks for a Camry, I'm not going to engineer a Ferrari. That's just bad engineering period. Delivering based on the known and unknown needs of the client is priority #1.
A lot of the overhead in LeetCode questions comes from slow IO from synchronization and stuff. Just add this at the top of your file: static auto fast_io = [](){ ios::sync_with_stdio(false); cin.tie(nullptr); cout.tie(nullptr); return nullptr; }();
Maybe try a non-recursive solution, something like TreeNode* stack[tree_size]; int index = 0; stack[index++] = n; // push root int sum = 0; while (next) { TreeNode* current = stack[--index]; // pop sum += current-&gt;val; if (current -&gt;left != nullptr) stack[index++] = current -&gt;left; // push if (current -&gt;right != nullptr) stack[index++] = current -&gt;right; // push } return sum; Untested, just a concept. But you should get the idea... :)
Hey, maintainer here! Sorry about that, I've been trying to carve some time for a while. Afaik msvc only fails because by default I have the max enumerator limit too high. If you run the included python script to lower it, then it should compile fine. I'm planning to do this myself and commit the change.
Now simply add the terms "cache oblivious" and "cache coherence" to your repertoire and you'll be forever known as a genius.
SFINAE was accidental syntax, not designed. Concepts and if constexpr are the designed replacements.
&gt;Robert Asprin It's all just a Myth
Gotcha. Sorry for posting to the wrong area. 
Important for game programming too. That code has to be real fast.
lovely hack :) 
Wow. Can you point me to a good article on why the `static auto fast_io` sped up the solution to the top 98 percentile?
The title is hyperbolic and pretentious, either for the purpose of clickbait or due to overinflated ego of the author. Even deep in the bowels of the kernel, RAM implementation on an electrical level is largely not a factor. The rest of the information has at best very limited utility for C and C++ developers, and hardly any when it comes to more high level technologies.
Email address required? Ain't nobody got time for that.
Jane Street Capital writes almost all it's non low latency code in OCaml, recently it seems they are either getting into HFT as well or the have, tried doing it with OCaml but failed since they are now looking for C, C++ devs for their low latency positions. 
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b81p19/what_every_programmer_should_know_about_memory/ejwxo7i/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&amp;#x200B; &gt;due to overinflated ego of the author The author is Ulirch Drepper, in glibc dev circles he's known to be quite the colossal a\*\*\*\*le. Here's some fun links talking about his "fantastic" reputation - [https://urchin.earth.li/\~twic/Ulrich\_Drepper\_Is\_A\_.html](https://urchin.earth.li/~twic/Ulrich_Drepper_Is_A_.html) [https://news.ycombinator.com/item?id=2378013](https://news.ycombinator.com/item?id=2378013)
I'm sure your clients are delighted to never receive their otherwise-perfect software.
Yes, correct.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b8azct/how_can_i_make_this_range_sum_of_bst_faster/ejwz1v2/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Wordpress scheduler is to blame for this!
I guess that's the wagers of sin...
This was originally posted to LWN.net as a series of articles. If you'd rather approach the topic in manageable chunks on an HTML interface, give it a try. [Part 1:Introduction](https://lwn.net/Articles/250967/) [Part 2: Caches](https://lwn.net/Articles/252125/) [Part 3: Virtual Memory](https://lwn.net/Articles/253361/) [Part 4: NUMA](https://lwn.net/Articles/254445/) [Part 5: What Programmers Can Do](https://lwn.net/Articles/255364/) [Part 6: More things programmers can do](https://lwn.net/Articles/256433/) [Part 7: Memory performance tools](https://lwn.net/Articles/257209/)
&lt;3
If you didn't like the CMake feature list this might not do it for you either, but here are a list of things that SCons gives me that I now consider basic features of a build system: * Not have to write a bunch of boilerplate to handle include files * And not have one of the common versions of the boilerplate that I don't write vomit `.d` files all over * More accurate builds * For example, I can modify the makefile-analogue and it will rebuild exactly those things that are affected by the change I made * Content-based rebuilding decisions is more robust to 'weird' things going on with timestamps and can actually cut *down* on work done if the source code changes in a way that doesn't affect the resulting object file (or similar) * At least *some* degree (they could do a lot better) of built-in support for building with different toolchains In terms of stuff you can actually *do*, we can define things like "hey if you need to use libdo_a_thing then add these to CFLAGS and these to LDFLAGS" automatically. Very nice for medium projects.
Quite enlightening.
Lots are starting to use Julia as well.
TLB just speeds up virtual memory lookups for your computer. Modern systems all give processes a virtual memory space so it looks contiguous to the process but the memory is actually laid out randomly in real system memory. There's a maping so that when you try to access something at memory adress 15 it knows that's actual real address 26 for instance. Cache associativity is the result of trying to fit a vast memory address space into a tiny little cache. Imagine the cache is composed of lines and each line is associated to a bucket. For each memory fetch you do you will go and place that memory in a cache bucket. Which bucket you chose will be based on the cache associativity bucket - the naive case is round robin, which just goves from line 0 to line n-1 and then rotates back. Or it could hash the memory address to select a bucket. And so on. These are 100% things you will never see unless you're on the cutting edge and trying to push process performance to the limits (e.g. in high performance computing and in gaming). For the rest of the people this is not especially important information - with some caveats. But those are not important here.
I do low latency work and while I agree that broadly this is the case the level of detail given here is completely pointless to all but the most performance sensitive developers. And the information that is here could be condensed into something much more digestible without much loss.
The build system at my work has a package manager with thousands of packages. Adding a dependency on a package is less than five minutes of work in the typical case. It's easy enough that we have "left pad" problems, where we pull in dependencies for trivial reasons. The same command line interface works for building code targeting Windows, Linux, Mac, and a bunch of RTOSes and firmware environments. When I say the same command line interface, I mean the \_same command line interface\_. I don't need to pass a bunch of obscure flags telling it where my sysroots are, or what target triples I'm targeting, or even tell it that I'm cross compiling at all. I can go to someone else's package and build it without needing to talk to them at all. I just run the same commands I run everywhere else. No hunting down dependencies or configuring my environment in weird ways. I can build multiple variants of the same target with one invocation (e.g. win32Udebug, win32Urelease, win64Udebug, win64Urelease). I don't need to make different build directories and invoke the build system in each. I can use .cpp and .h files that are generated during the build. I can build code authored in C++, C#, Python, and LabVIEW, all from the same build system.
This is the wrong sub for this sort of post. I recommend /r/tutor instead.
Wait, so how do you actually make a pointer to 0 on GPUs then?
Uff... Be aware that i am not a C++ guru so dont take my text as law but the macros is just too bad, not because the macro itself in the sense it is really bad you use &lt;html&gt; as main function header and &lt;/html&gt; as return and close the function, the real problem for me is that you can only use as many elements as you has defined and now is more or less ok but when you start adding all the tags HTML has it will be a mess and an endless source of bugs and/or problems I think you should reconsider how you want to face it, since after all you still has to compile it there has to be another approaches to the problem
&gt;If you program for a living you should know how the things you are using work under the covers. like, every single piece of microcode and every undocumented or obscure feature in every Intel processor on which you program might run? and the same for all your computer subsystems, like HDD which is a computer on its own? wow, you must be a 1000x programmer!
No. I didn’t say any of those things. You did and then acted like it was me. 
Let me explain what I think he means there, even though I don't think this article is that case at all. &amp;#x200B; He must be referring to this tendency that people have where they say that "C++ is bad because you can do malloc", whereas that is just a nuclear option in a language that otherwise offers enough features that you hardly ever have to call malloc/free/new/delete directly at all. These people confuse the capability to drop down to C with the compulsion to do so. It doesn't help that it takes a semi-competent developer - a rare commodity indeed - to realize that C++ is not just C with classes.
Is that an in house system?
Is the joke that it uses puts and printf?
Hint: look at the timestamp of the commits and most of the issues there. Also, the comment on the pull request. :)
It's a joke in general, but using `puts` isn't necessarily a joke. See https://youtube.com/watch?v=VZTVmKOXLVU C++ Weekly - Ep 88 - Don't Forget About puts 
And that material is almost totally wrong.
Yeah, The title does not match the document. Few if an programmers *need* to know capacitor charge/discharge curves. It's well written, has a good flow, but "What Every Programmer Could Learn About Memory" would be more true to content and intent. 
Yet for a long time this accident was treated like a solution.
Those Boyer-Moore and Boyer-Moore-Horspool searchers are in the standard library since C++17 though.
i wrote mission critical and high performance in-memory database software for a dozen years. it's *really* interesting what you pick up, what you can optimize and how, and exactly how little of this applies to most development.
Hey Yehezkelshb, can I ask you a question about c++ on private?
This was acknowledged in part 1: &gt; The algorithms in Boost fall into two categories: the algorithms that don’t exist in the STL, and the algorithms that are added in the STL in some version of C++ (for instance, if you don’t have C++17 but have a recent version of Boost, you’ll get in it the algorithms that are added in C++17, such as `exclusive_scan` for example).
Duh, I scanned the whole article to find a note but didn't think about checking part 1 (which only mentioned Boost-specific algorithms if I remember correctly).
&gt; I don't need to pass a bunch of obscure flags telling it where my sysroots are, so... uh... is it scanning your whole hard drive for stuff named `([a-z0-9+]-gcc)` or something like that ?
CMake being more-or-less a general purpose language, you can use it for fairly horrible stuff. I personnally use it to parse some macros in my code and generate code from it since C++ does not have reflection yet. I also quite like CMake's ability to generate targets for individual preprocessed sources (`make foo.cpp.i`), as well as assembled files (`make foo.cpp.s`)
The title is borrowed from similarly titled pieces that have gotten wide acclaim, e.g. Goldberg's "What every computer scientist should know about floating-point arithmetic" (although that is an actually great resource). 
Dissapointed of no more-type-safe `nullptrptr` and `nullptrptrptr` for nested pointers.
I trust people with experience (and my own, after implementing their advice) on the matter. In my own experience, I cut down a lot more boilerplate by composition than with inheritance. It sounds like you haven't even tried.
My comment was a joke...
It would have been so nice if we had a [standardized C++ IO 2D interface](https://github.com/cpp-io2d), and this would have been a Blend2D would have been an implementation. 
or a while loop if your feeling especially bold.
[http://c-faq.com/null/accessloc0.html](http://c-faq.com/null/accessloc0.html) gives a few ways. But generally, you don't need to \_manually\_ construct such a pointer, it would be given to you as an argument.
How ADL works with overloaded but not exported functions? Can you export only certain overloads?
It does seem rather pointless, though, given that Jonathan very much so promotes the use of Modern C++(17) in ~~all~~ most of his blog-posts. 
Oh
Seems quite C-like - everything prefixed by "BL", instead of using namespaces. Is the library itself developed in C, and just has a C++ API?
Honestly: nothing. I don't think build systems are there to impress people, i think they are here to do the thing that they were designed to do in the most obvious way possible. That being said, using CMake I've constructed a nice build system that is pretty configurable, can do static/shared builds, does RPATH trickeries to find the libs at runtime, install itself into a portable prefix and do incremental rebuilds.
The library itself is implemented in C++, but all public functions use C interface for interoperability with C and other programming languages (no bindings yet, but that's a matter of time). The C++ API is just a thin layer over the C API that makes it nicer to use from C++ and simplifies memory management. The alpha version of Blend2D offered only C++ API and used a 'b2d' namespace, but after having a lot of feedback it was decided to go with C API instead and to offer a C++ API on top of it.
No.
 BLResult r; ... r = img.create(256, 256, BL_FORMAT_PRGB32); Why? This is terrible practice for C++ code, yet you feature it on the front page of your site as an example for the C++ API. Don't advertise libraries as C++ when they're just C with classes.
Sure, for the quant work maybe, i doubt the market access code will be in Julia.
c++ source -&gt; c api -&gt; c++ wrapper. c++: am I a joke to you?
I love this, thanks.
You should check the source, it's wrapped only once, but the wrapper is universal and is used both internally and provided for C++ users.
&gt;k build systems are there to impress people, i think they are here to do Can we get the name of the package manager?
The example is pretty clearly intended to be viewed side by side with the C example on the left (with each line matching up between the two examples). Why shouldn't they advertise their C++ library as C++ even if it was just C with classes?
I still can’t ever read this as anything other than “boo stl”
But if `ptr` is a valid pointer then `ptr + 1 &gt; ptr` must hold. The one-past-the-end pointer compares greater than pointers it's the one-past-the-end of. 
The very next paragraph after that says: &gt;Here we’re going to focus on the algorithms that are not in any version of the STL (at least as of this writing). So it's a bit strange.
I am very interested about what was the feedback you got about namespaces? Also, can't you simply provide different headers that wraps your api in a namespace (or inline the content of the namespace in the global one)? That way people can chose their thing and you don't have much work to do to make it work.
Do you know any similar papers?
"Here" meaning part 1. This is part 2. ;-]
The question is similar to asking "What can I do with a cool programming language that I can't with assembler": There isn't a lot / anything, but it lets you do the same things with less complexity and fewer commands. I'd say, where manually written make files usually break down compared to something more modern/high level is if you want to easily build your software on/for different platforms, with different toolchains, in different configurations.
How does it compare to gRPC?
I don't see anything "terrible" with that.
The compilers are also packages (mostly, it's weird). In my build scripts, I say I want to build with gcc-7.3 targeting Linux x64, and the package, compiler, and respective paths are all made available.
It's an internal package manager, not based on any third party package managers.
The feedback wasn't about namespaces, but about having the possibility to use Blend2D from other programming languages that can use C API natively, but have problems with C++ API (or don't support it at all). Such languages include D, Rust should be covered as well, and maybe other runtimes like LuaJIT would work too, but we are not that far yet and what you see now is an initial design of the API that may change (that's why the BETA). So it was about offering such API directly instead of forcing others to create their own C wrappers of C++API of various quality. When the design of C API started it was pretty clear to not duplicate constants, structures, etc... So instead of having a common namespace a common prefix (BL) was added to structs, classes, and enumerations, which made it possible to share these between C and C++ and to only focus on C++ in terms of wrapping things that require memory management. I don't think the API is perfect (the world is not perfect after all), but I consider it as the best possible compromise between C and C++ worlds. At the moment only Blend2D and Cairo offer C API, most other libraries only offer C++ API and leave the burden of implementing C API wrappers on third parties.
/r/ihadastroke
That is the proper way of doing it, actually.
After seeing the code, it's even more surprising. So you are directly mixing c++ member functions into c structures using #ifdef __cplusplus? This is neither c nor c++.
but where does the gcc-7.3 comes from ? e.g. let's say that I have a custom-built toolchain for an embedded board in `/opt/my_toolchain/.../bin/armblah-noneabi-my-cc-8.2`, how do I tell the build system to use it (along with its ar, ld, sysroot, etc) 
Oh I see. What about my suggestion to allow users to still use namespace if they want? I've implemented that in several libraries in the past.
It was considered initially (I really wanted to keep the 'b2d' namespace when I started designing the C API), but since the whole API would have to be wrapped in that namespace (and Blend2D has a lot of constants and structs) it was decided against it. All public enums and POD structs in Blend2D are shared between C and C++ APIs and are documented only once. C++ API has only some extra classes and additional templates that make certain operations easier. BTW I know only one widely used 2D library that uses namespaces, which is AGG (and maybe cairomm wrapper). Others such as Qt and SKIA don't use namespaces and it seems just fine.
Says who? Given that the implementation is written in C++ there’s no reason not to expose a C++ API based on that, instead of going via a C layer. The C API can then be added as an additional thin layer. Nothing wrong with that.
What’s bad about this is that \`r\` is being declared without being explicitly initialised, and is subsequently assigned to. In idiomatic C++, the assignment would be replaced by direct initialisation or copy initialisation.
&gt;The example is pretty clearly intended to be viewed side by side with the C example on the left That doesn’t explain/justify writing inferior C++ code. `r` should be initialised at declaration, not assigned to. The example code is odd anyway since `r` is subsequently overwritten without having been used.
I don't see where it's overwritten before use, can you point it out?
Never mind, I misread the code. I’ve edited my answer.
What I found super convenient in my last works build system was that it was purely declarative and you basically only had to list your dependencies, the rest was taken care for you. Another awesome feature was that you could annotate your classes/functions with a macro (pretty much similar to \_\_declspec(dllexport)) and it would automatically create wrappers for either C# or JavaScript (you only needed to provide marshalers for custom types yourself). You could chose the frontend (C#/WPF or JavaScript/HTML) and the C++ code would be the same. 
It’s still pretty bad code. The `foo.create` methods should be constructors, and declaring the object should fully initialise it. In fact, using a `create` method instead of a constructor is an established anti-pattern.
The pre-beta version of the website had an additional text before the C and C++ API samples stating "Please note that the samples were written to be comparable line by line and to be as narrow as possible". I removed it because I thought that the intent is obvious.
I love the `$` operator so much. I don't know why a lot don't like it. With that I can send `$type` to functions, deduce `type`, and forget that pointy braket existed for function call!
Yet it was also computer code. Yet it was written using ASCII characters. Yet it wasn't written by a Yeti. Yet I think yet isn't an appropriate response. Of course it was a solution. If it wasn't solving problems people wouldn't be using it. It was a solution to a bunch of problems; and it worked. It just wasn't *designed* to solve the problems it was used for. So it was awkward syntax and convoluted to reason about. The problem it solved - Turing complete template specialization dispatch - has one sub solution in production and almost standardized. 
Sounds similar to Yocto.
I don't think you can say it's right or wrong, it depends. You can call create() or begin() on fully initialized object to reinitialize it and you can also use constructors in C++ mode, but such example doesn't use constructors because it intends to be line-by-line comparable.
&gt;I don't think you can say it's right or wrong, it depends. “It depends” can be valid, but it may equally be a cop-out. Partially initialised objects are generally an anti-pattern. Using them despite the disadvantages (= makes state less clear, and harder to reason about) requires a justification. I’m not saying that it makes the API unusable but it definitely makes it improvable.
There is nothing like partially initialized in Blend2D. All C++ classes have constructors and destructors and they are always properly initialized.
What does “properly initialised” mean for an empty, dimensionless image? What *is* an empty image even? Is it ever useful? A fully initialised object is an object that’s in a useful state and doesn’t need further initialisation.
Congratulations, the git versioning looks really sweet!
I means its size is zero, but it's still a valid object from C++ point of view and can be passed everywhere where Image can be passed. It's the same as default initialized std::string or std::vector - these also won't allocate memory until you use them, call `reserve()` or do something else.
Again, what does “valid” mean? I’m not talking from a C++ point of view but semantically, in the context of your API: How is an empty image useful? Your reply completely side-stepped this question.
Technically not a build system, but a compiler: https://blog.thecybershadow.net/2018/11/18/d-compilation-is-too-slow-and-i-am-forking-the-compiler/
That's the proper way to do it, if your main focus is to be usable from as many languages as possible with minimized evelopment overhead. But you are also restricting the semantics of your interface to what is possible in c and just provide a bit syntactic sugar for c++ users.
I also see no one mentioned ccache yet.
I still don't see the point here, it's the same as empty string or std::vector. Empty means it has no content, but you still have a valid container that can hold that information safely and that can be passed to API functions that can consume it.
Can I ask why you used cpp-rest-sdk and not Asio?
It sounds like you want valid to mean not default or empty, which is not the case. I'm having far more difficulty understanding what you mean by valid than what the reply is describing as valid, and I totally agree with their definition of valid. 
The difference is that an empty string or vector have *specific* purposes. You still haven’t shown what the specific purpose of a dimensionless image (in contrast to e.g. an empty canvas of defined size) is. And it doesn’t really help that you (in this discussion and elsewhere) continue to cite precedence in other graphics libraries, all of which are widely recognised to have *atrocious* APIs.
In very rough and hand-wavey way, you make a package for your toolchain, and you put all the information on how to get to ld there. The thing that wants to use your compiler depends on your toolchain package.
&gt;It sounds like you want valid to mean not default or empty, which is not the case. No (see vectors and strings). I want it to mean *useful*. As in: I can perform operations (other than initialisation) on it. What can I do with a dimensionless image? I can initialise it — and pretty much *nothing else*. This isn’t useful, and, *in the context of an API*, it’s not a valid image.
That's thing i like to see in standard, same ABI on all compilers
This was pretty confusing until I figured out that 'dynamic library' meant shared library / dll
I’m pretty sure that the default-initialized instances do use memory – just not from an additional allocation. A null `QString` is still a `void*` in size. Or two (I forget now). 
True, Blend2D instances are typically sizeof(void*) in storage size. So maybe a more precise statement would be "default initialized instances don't use dynamically allocated memory".
The same think is possible using cmake and Conan. We have an llvm toolchain Conan package that is used to build the project.
If you want a unified ABI, you need C++ to be compatible with one and only one architecture. For example, a library compiled for 32bit may have a different calling convension, and a different set of register used.
I have no idea why people would be complaining about the API.. looks fine to me.. 
This pattern is not entirely uncommon. C guarantees stable ABI across the board, whereas maintaining a stable C++ ABI for *a single version of a single compiler on a single platform* is a PITA.
I mean same on same architecture, not same at all available architectures.
What else could it mean
No. Those objects may have a completely valid default constructor for all we know that setup the object correctly. You raise an exception when your constructor fails to achieve the invariants that your class holds. If your class has a valid empty state, for instance, it is perfectly fine. Also, there are other good reasons to use named constructors and also circumstances where fetching a resource is expected and not a hard error.
&gt;If your class has a valid empty state, for instance, it is perfectly fine. Agreed. Which is why I have repeatedly asked OP to explain why allowing empty, dimensionless images is a desirable feature. For all I know they are very sensible but I have to admit that I can’t imagine a use-case. The fact that OP has repeatedly failed to provide such a use-case makes me think that, rather than being a conscious design decision, the default constructors simply represent lack of thought. &gt;there are other good reasons to use named constructors Absolutely, but we’re not talking about named constructors here (those take the form of non-member functions or static member functions). &gt;circumstances where fetching a resource is expected and not a hard error. That’s fair but — in the context of object construction — this is still best modelled as either an exception or using an option type (e.g. `std::optional`) in C++.
Automatically collect the set of objects to link for each project, based on include relationships. :) (See [https://upcoder.com/19/automatic-object-linkage-with-include-graphs](https://upcoder.com/19/automatic-object-linkage-with-include-graphs))
Says most libraries intended to be widely used by all sorts of clients, and not just C++ ones. The only libraries that typically expose C++ APIs/ABIs are those that are intended to be used exclusively with C++ anyway, like Qt. As soon as you have to provide a C API, there is no actual benefit on providing a C++ one. It is way better to give the user a proper C++ wrapper on top of the stable C ABI. And let's not even start to talk about the mess of using C++ shared libraries and passing types across boundaries...
"those things" I listed belong to your vague "things you are using" even though you didn't spell them out &gt; you should know how the things you are using work under the covers.
For almost all libraries, that is what you want; and in this case it is clear, because the library provides the C API. I am not sure what you mean by providing "syntactic sugar". You can provide a proper C++ wrapper to your library, with all the bells and whistles that you want. If you are doing it properly, your client has no clue whether it is going through the C layer or not.
Indeed. Most people have no clue about how complex this turns out to be, for no real gain.
Meh. I want same ABI across languages. COM is pretty neat. And horrifying.
&gt; why allowing empty, dimensionless images is a desirable feature I commented exclusively on the snippet one parent comment posted, and you asserted that this is bad in general and non-idiomatic C++, which is simply false. &gt; I can’t imagine a use-case Well, I am pretty confident you have created empty `std::string`s all the time! &gt; Absolutely, but we’re not talking about named constructors here (those take the form of non-member functions or static member functions). We are, though. It is quite common to see context objects creating resources tied to that context; and in effect, they are the named constructor pattern. I have no clue if OP is using them as such or not; but the snippet above looks very much like it. &gt; That’s fair but — in the context of object construction — this is still best modelled as either an exception or using an option type (e.g. std::optional) in C++. It depends. If you are allocating memory, yes in almost all cases. If you are opening a file, depends. If you are creating a network connection, no in almost all cases. By the way, in real-time software/graphics, a lot of projects do not even have exceptions enabled. As for optional: you really don't want your users having to carry around `optional`s of your `T` everywhere if the empty state is a common scenario. Would you like having to use `std::optional&lt;std::string&gt;` just to have an empty string?
See here for some other CS resources, more than a few with similar titles: https://github.com/mtdvio/every-programmer-should-know Note that this isn't just CS, there's tons of books and articles and etc out there titled "What every ____ should know about ____." I don't know the origins, though.
&gt;In the context of libraries, even the STL gives you "empty" objects everywhere And some of these are widely considered to be a mistake in hindsight. &gt;Well, I am pretty confident you have created empty `std::string`s all the time! As explained elsewhere, an empty string fulfils a specific purpose, it’s not just a placeholder. A dimensionless image is fundamentally different. You’re attacking a straw man here: Nobody is objecting to default constructors. I (along with others) am objecting to default constructors on classes where they make no sense. Scott Meyers explains this in great detail in *Effective C++*. &gt;We are \[talking about named constructors\], though No. As explained, a [named constructor](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Named_Constructor) is something related but crucially different. A non-static member function is *not* a named constructor. This isn’t “orthogonal”. &gt;in real-time software/graphics, a lot of projects do not even have exceptions enabled. That’s fine, they can use an option type. You say that using them is cumbersome but the counter is that it’s *much* easier to write correct code with them. Part of me can’t even believe we’re having this conversation: This isn’t something esoteric, it’s an extremely well established principle in software engineering. You could argue that existing projects are often also not using option types, and in low-level code there are reasons for that. In high-level APIs, however, the reason is simply: bad design. Since most of these projects are old this is entirely excusable (until recently C++ had no builtin option type). For new projects, it’s much less excusable. Either way, it’s a valid criticism.
In C++ you can never ever have an object of `sizeof(T) &lt; 1`. So when someone says an object "uses memory", it always means some extra memory.
Who cares if it works and is fast? :D Does it compile with a C compiler - it is C, does it compile with a C++ compiler - it is C++ :-) Chill.
&gt; But modern C++ provides ample ways of working with objects of classes that don’t default-initialise to an empty state. Not really. Everyday I still write: std::string s; // ... You are talking about move semantics and non-copyable objects, but that does not mean empty objects and default constructors are bad now.
&gt;that does not mean empty objects and default constructors are bad now. Again, this is a straw man. Literally nobody is saying that default constructors are bad. They are bad *when they don’t make sense*.
DLL stands for dynamic-link library...
No. An image is as useful as an empty string. You *can* perform operations on an empty image. If only, to attach/append new image data. And all plethora of configuring that may need to be done *before* the image data is uploaded, for instance. You are mixing up real non-copyable objects like threads with objects that may very well have value semantics.
So many toy-programmers here. @Asm2D You have created really cool library/app on top an interesting project (asmjit). I am not sure I am going to have use for it, but it certainly is an achievement what you have done (two persons if I am understanding correct from your project page). I doubt that any of those toy-academics here who know everything about C++ and probably have never written a library for a paying customer, would even be able to put together a simple triangle on the screen with asmjit less alone make entire graphic compositing library on par with similar well-known libraries.
so... instead of "passing a bunch of obscure flags telling it where my sysroots are", you have to "set a bunch of obscure variables in a package file telling it where my sysroots are" ? 
Seriusly, if you were knowledgable, you wouldn't even need to ask such question with very obvious asnwer (just look at source). It is very common to expose C API outside but to use C++ under the hood, nothing strange with that, nothing "improper" or "bad practice", just a standard solution to a practical problem. That is quite common practice for middlewares that are supposed to be used by 3rd party software.
Anywhere registered in the PYTHONPATH environment variable I would say. Note that you can easily modify this variable by importing the "sys" package and appending new directories to the attribute "path" of "sys". &amp;#x200B; Note that Pybind11 has a gitter channel where you can usually have very quick answers to such questions [https://gitter.im/pybind/Lobby](https://gitter.im/pybind/Lobby) 
I think that PYTHONPATH does not exist anymore. It was removed for Windows 10. for my system this is only set: * D:\\Programme\\Python\\ * D:\\Programme\\Python\\Scripts\\ &amp;#x200B; What does the PYTHONPATH do? How exactly can i set this? Like this? &amp;#x200B; `import sys` `sys.path(...)`
&gt; And some of these (e.g. the file streams) are widely considered to be a mistake in hindsight. I am not talking about file streams or other non-copyable objects. I am talking about STL containers, which are actually the equivalent here to the image concept of OP's and have value semantics. Please stop mixing things up. &gt; As explained elsewhere, an empty string fulfils a specific purpose, it’s not just a placeholder. A dimensionless image is fundamentally different. You’re attacking a straw man here: Nobody is objecting to default constructors. I (along with others) am objecting to default constructors on classes where they make no sense. Scott Meyers explains this in great detail in Effective C++. You keep appealing to authority in several places, but maybe you don't realize many people here have read Meyers decades ago. It is not really a compelling argument in /r/cpp with the amount of experts around :) To recap: you claimed originally that the snippet shown was "bad" and "non-idiomatic C++", etc. Then, you tried to argue that *this* particular case is bad, because of the imageless semantics "do not make sense" (to you; I am pretty sure we are not domain experts here to know the answer to that, and I for sure haven't even looked at this library to know). Finally, now you are quoting Meyers to try to to teach us all basic class design and avoidance of superfluous states. Alright... &gt; No. As explained, a named constructor is something related but crucially different. A non-static member function is not a named constructor. This isn’t “orthogonal”, it’s part of the definition. Named constructors refer to a way to overcome the problem of distinguishing constructors due to C++ design choices. You are confusing the forest for the trees. First, Wikibooks is not an authority. But even if it was, you are failing to understand what is explained there (which is true): "In C++, constructors are distinguished from each other only based on the type, the order and the number of parameters. Of course when a class has multiple constructors, each constructor has a different purpose. However, in C++ it is hard to capture that "semantic" difference in the interface of the class because all the constructors have the same name and only parameters can distinguish between them. Reading code with lots of constructor calls only differing in the type/order/number of parameters is quite unintuitive except for the original developer of the class. Named constructor idiom addresses the problem." &gt; You say that using them is cumbersome but the counter is that it’s much easier to write correct code with them. Citation needed. I would actually claim the opposite, depending on the use case. &gt; Part of me can’t even believe we’re having this conversation: This isn’t something esoteric, it’s an extremely well established principle in software engineering (see again the existing literature, e.g. Effective C++). There is no "well established principle in software engineering" here that we are discussing, and you keep moving goal posts, trying now to mix things up even further, You are going away from the core issue. &gt; You could argue that existing projects are often also not using option types, and in low-level code there are reasons for that. In high-level APIs, however, the reason is simply: bad design. Since most of these projects are old this is entirely excusable (until recently C++ had no builtin option type). For new projects, it’s much less excusable. Either way, it’s a valid criticism. Right. People not using option types nowadays are making bad designs... And now you are mixing up option types with low-/high-level code (???). Sorry, but I won't play yet-another-game.
Dynamically linked library means something, a 'dynamic library' could mean physics Dynamics, dynamic instruction generation, etc.
With each release there's some very cool features being added. Hope more and more projects start using Conan!
I've using it long ago, one thing i've never do again :)
&gt;Finally, now you are quoting Meyers to try to to teach us all basic class design and avoidance of superfluous states. What’s the problem with that? If you indeed read Meyers decades ago you must either have forgotten what he said, or you’re otherwise ignoring it. Either way this is a lost battle.
PYTHONPATH is an environment variable that instructs the python interpreter where to look for scripts. When embedding the interpreter it probably makes sense to set it relative to your executable before executing anything. https://docs.python.org/3/using/cmdline.html#environment-variables
&gt;You *can* perform operations on an empty image. If only, to attach/append new image data. How do you append data to a dimensionless image? I’d understand if the image was default-constructed as an image with dimensions (0,0) (although I’d still argue that this is a pretty useless default), but then what does `img.create` do? It overwrites the existing zero-dimension image with a new one — in other words, the `create` function doesn’t use the current instance’s state at all. And that’s still bad design, it’s *literally* what constructors are there for. &gt;You are mixing up real non-copyable objects No. This is completely orthogonal to copyability. In fact, you could easily imagine a `thread` class with a `create` member function (which would likewise be a questionable design).
Just to pop in here, not sure how you can compare an empty image to an empty vector or map... Can you just take an empty image object and add a pixel?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b8ljll/where_to_put_py_in_the_c_project_so_that_i_have/ejyp6mz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You could probably do something like &amp;#x200B; \`\`\`cpp py::module::import("sys").attr("path").attr("append")(PATH\_TO\_YOUR\_MODULE); \`\`\` I am not 100% sure of the syntax as I've never really used this part of pybind
True, I think you must be fairly new to native languages though because dynamic libraries are an extremely heavily used term so most of us would assume that in the absence of a physics context. They contrast with static libraries which are just chunks of object code which can be hard linked directly into an executable.
”B-b-but muh zero cost abstractions...” Seriously, though, it seems to me that there are two main reasons to build a C++ library with public headers: - For use as a building block in applications whose sources are *mostly or entirely written in C++*. - To provide an efficient implementation of a computationally expensive task for applications written in languages *including but not limited to C++*. OP’s project seems to fall into the latter category, and it’s surprising that more commenters aren’t cognizant of this distinction.
This is the top-level comment for **meta** discussion. Reply here if you have questions or concerns about this post.
This is the top-level comment for **individuals looking for work**. Reply here if you want employers to contact you. You don't need to follow a strict template, but I suggest inverting the relevant parts of the employer template. For example, mention whether you're looking for full-time or freelancing etc. work, briefly describe your experience (not a full resume; send that after you've been contacted), mention whether you care about location/remote/visa, and list the technologies you're skilled with. Feel free to disregard all of these suggestions, except that you obviously need to provide contact details.
basically yes. And you do that once and check it into source control, as opposed to every time you do a clean build. Now, I can go and build your firmware without needing to find your toolchain, build it, install it, then pass the path into the build on the command line. I just go and build your firmware, and all the configuration is in source control.
24 yo. Finish college in Bucharest romania. I do not have any preferences i will see afterwords. I am available for both relocation or remote. 2+ years experience: 3m java internship, 3m c++ full time(mostly support on banking software). 1y1m optimisation team mostly with c and Python on linux. Working on pypy interpreter and one benchmark for ai using docker and vms. 9m c++ on embedded software. Worked with c++11. Experience with linux as operating system(some deep knowledge from three courses, one of them on the kernel side).
That was because of the 20bit address space. By combining a 16bit segment register value shifted 4 bits left with a 16bit offset.
&gt;I doubt that any of those toy-academics here who know everything about C++ and probably have never written a library for a paying customer Well, I can only speak for this “toy-academics” but I can tell you that you are categorically wrong. And guess what? Some of the code I’ve written was really quite bad. Some of the API design was questionable. And it still shipped and it works. But that doesn’t invalidate criticism of said API and code. But apart from that I agree with you that it’s a shame that this criticism of the API has completely overtaken this thread. Despite minor criticism this is an amazing, very impressive project. I’m playing with the code as we speak.
I see it as valid if you can use it like any other initialized data, though. an empty image which behaves like an image is still an image if you want to treat it as such. It's likely not what you wanted, I'll give you that, but if the API is designed to handle empty data then it is still effectively valid. If it won't crash the program or produce bogus results then by the libraries own definition it's valid. Counter point, and probably what you're getting at, you likely don't want that empty a data and considering it valid can hid bugs. I'd also argue that using an empty image Iinstead of failing to load one from disk, for example, can be a good solution if the issue is well exposed to the code. In that case a notion of empty but valid can be very useful. I'm not an experienced C++ developer and I haven't read what you linked, currently busy and typing in my snuck time from work, but I'm all for similar designs to what is being offered here if it provides use. useless uninitialized data should be avoided, but give it purpose and it can be okay. 
Also it's important to keep in mind that just because people are criticizing the API doesn't mean they aren't interested in the project. It just seems more useful to offer criticism of the project than have a bunch of worthless "very cool" comments.
I've never seen that. Also it is strange for someone to have a tutorial on 'writing' something that comes down to linking.
Well, would you “write a program” or would you “write the source code which is compiled into a program”? The whole thing is full of metaphor when you think about it because there was no “writing” at any point. Like it or not, our entire field is full of shorthand and metaphors and a DLL is both a thing which is linked as well a deliverable which could be said to have been “written” at the point you install it on a customers machine.
Another visual studio? I just got done figuring out what to turn off and tweak to make the past version fast enough to not lag. 
Looking for: Summer 2019 internship (Full-Time) Location: Bremen, Germany Willing to relocate: Yes Travel to nearby cities: Yes Status: MSc Student in Data Science Visa status: Work permit (Germany only) Research Interests: Computer Vision Tech : C++11, OpenCV, Cmake, Python Total of 2 years experience in software dev + undergrad in CS. Current courses: Machine Learning, Statistical Modelling, GIS Lab. My master project I: Drone based vegetation mapping and analysis. (DM for more details). I’m in my second semester and am trying my best to get into Computer Vision. I’ve worked a bit with OpenCV, and have programming experience in C++11. I’m looking for a full-time internship. I am ok with traveling to nearby cities such as Hamburg. Or even work abroad (but I’ll need a visa outside of Germany). 
Im still using 2017. I’ll probably install it on one machine. Can you please share how you optimized it. It’s lagging for me too? Thanks
I’ll check it. I was using insider build but still didn’t update to a stable version 
 **Company:** [Stellar Science](http://stellarscience.com/index.html) **Type:** Full Time regular W-2 employment with phenomenal benefits. **Description: We hire smart software developers** who love to create and maintain high quality, extensible, scientific code: OOP in C++14/17. **Support software development in the following domains:** computer vision and image processing, image simulation, high power microwave systems modeling and simulation, laser source generation and effects modeling, computational electromagnetics (CEM), space situational awareness (SSA), high performance computing (HPC), and computer aided design (CAD) tools, among others. **Location(s):** Albuquerque, NM or Vienna, VA **Remote:** Remote work is not immediately available. **Visa Sponsorship: NO -** US Citizenship is required + willingness to undergo background investigation. **Technologies:** C++14, C++17 - Cross-platform software development on Linux, Windows, Mac **Experience in any of the following is a plus:** · 3D graphics using Open Scene Graph and/or OpenGL · User interface development with Qt, Java Swing, GWT · Supercomputing, OpenMP, threads, MPI, GPUs · Google closure or similar tools for large-scale javascript development · OSGi, Orekit, or Apache Commons Math **Contact: Apply for the specific jobs** Vienna, VA - [https://stellarscience.applytojob.com/apply/CDgjTQyqGs/ObjectOriented-Software-Developer-NoVA?source=reddit-cpp](https://stellarscience.applytojob.com/apply/CDgjTQyqGs/ObjectOriented-Software-Developer-NoVA?source=reddit-cpp) Albuquerque, NM - [https://stellarscience.applytojob.com/apply/fMVkEOvL7Q/ObjectOriented-Software-Developer-ABQ?source=reddit-cpp](https://stellarscience.applytojob.com/apply/fMVkEOvL7Q/ObjectOriented-Software-Developer-ABQ?source=reddit-cpp) POC - John Jones - Technical Recruiter - jjones@stellarscience.com
Given that there is VS for Mac (backed by Clang I presume?), is there a chance that we'll ever see VS for Linux?
I had to search quite a bit and do it incrementally, I can't remember off the top of my head.
Given Microsoft's recent interest in Unix systems (probably because that's where a lot of ML and scientific computing is done, and they want to attract business to their Azure services), there's a decent chance they might try for a Linux port.
VS for Mac is not the same as VS on Windows. VS for Mac is basically a rebranded Xamarin Studio.
I'd also be interested if you have a summary!
Jesus finally! I've been waiting for this one for sooo long...
There's a big difference between having knowledge of the tools you directly use and having knowledge of tools being used ten abstraction levels deep.
I only ever used older versions, and it’s been a while, but IIRC arguably the biggest bang for the buck (given insisting on an IDE...) is from turning Intelisense off. Intelisense is a massive performance hit on typing, in the occasional rescan, and on project load times. If your project (solution) is anything but a trivial size, it can become ridiculous. I also turn off version control support, because I generally stick to command-line Git. I don’t know how much help this one is—I’m guessing not much—but the general idea of eliminating anything and everything you can live without should be a net good.
The stated purpose of this library is to use native OS stacks as much as possible. On OSX/IOS it uses a client based on NSURL. On Linux/Android it uses a client based on top of CURL. For all other cases it uses cpprestsdk. On Win32 this means a WinHttp client and on UWP this is based on top of WinRT APIs. There is also a fallback client based on Boost ASIO for all other platforms. The thing I don't understand is why they didn't simply add NSURL and CURL clients to cpprestsdk. It's already structured in such a way that adding alternative client impls is part of the design. What they have done just seems to fragment things.
VS for Mac only compiled .NET stuff. No C/C++
&gt; Abseil is an open source collection of C++ libraries drawn from the most fundamental pieces of Google’s internal codebase.
Currently I optimize it by: 1. Updating it (most recent updates removed slow downs, except for some searches fonctions) 2. When it suggests me to deactivate an expensive plugin, I agree with it and it helps massively. Other than that I find it ok on reactivity. In particular since "Ctrl+," was added.
Visual Studio Code is rather nice and available for Linux. C++ support is decent and improving.
Finally? CMake 3.14 came out less than a month ago.
Really? Felt like much longer...
The installer still shows only the preview version for me
I've done another experiment to support compiling modules with a generic makefile and clang 9. It's actually relatively easy. You can read the makefile here: http://retropaganda.info/~bohan/devel/cxx-lang-experiments/modules/Makefile
Freelancer here looking for either more freelance or a full-time position. My specialization is music/audio and the Juce framework. Willing to relocate although a remote position is preferred. Many years of experience working in digital audio, music production, sound editing, etc. Currently working with C++17. I learn new technologies quickly and I am excited to take on new projects.
You need to re-download the installer to install this version. 
I'll have a go at this :)
Nope, they didn't. It is shipped with CMake 3.13.19031502-MSVC\_2. Regretfully support for Visual Studio 2019 as generator is not available in @CMake until 3.14. So there is no way to use the built-in CMake to generate solutions. 
Thanks for the review! Now I don't have to bother to boot into Windows just to try it :-).
All hail Ninja, our savior.
Well, that sucks
Likewise, it looks fine to me as well. I guess people have a problem with the fact that the external API doesn't consist of latest, coolest, bestest features even if it would be a lot less usable in this context.
cpprestsdk started life as a tech demo to demonstrate that you could connect PPL to WinHTTP. We still do any work on it at all primarily because the Azure Storage SDK for C++ depends on it. &amp;#x200B; That is to say, I wouldn't hold your breath to see much in the way of transformative work on that thing unless the business situation changes or someone contributes that kind of change.
Yes, Ninja builds worked for me. Although I got a compiler error the first time I ran it due to a missing include. My guess is that this is most likely due to the order of compilation in VS Solutions vs. Ninja builds.
You e.g. can't forward constexpr through the c Layer. Forwarding exceptions is possible but expensive (you have to catch them and rethrow them) You can't directly pass any c++ types through the c layer (e.g. anything using inheritance) and of course templates are also a no go. 
Disabling IntelliSense entirely and getting VisualAssist is also a great way to make the whole thing faster 
&gt; How do you append data to a dimensionless image? How do you append data to a dimensionless vector? &gt; what does `img.create` do? We have no clue, but surely it does not *construct*. It creates something, which may simply be some image data allocated somewhere, even external hardware. It may be that you do not want to raise exceptions just for that, so you cannot simply do it in a constructor. It may be that this requires several steps and the author decided to go for this kind of design. It may be that there is some special and common usage for the empty state. There are many potential good reasons, and none of them are necessarily "bad" simply because you see a `create` member function. &gt; It overwrites the existing zero-dimension image with a new one — in other words, the create function doesn’t use the current instance’s state at all. And that’s still bad design, it’s literally what constructors are there for. You don't know that from that snippet. You are assuming there is no usage for a empty image. You are assuming you have access to exceptions. You are assuming it is trivial to construct and errors aren't likely/expected/common. You are assuming the author is incompetent. You are assuming this has to be a movable-only object. Etc. &gt; No. This is completely orthogonal to copyability. In fact, you could easily imagine a thread class with a create member function (which would likewise be a questionable design). Not sure what you are trying to say, because I haven't claimed anything like that. I simply said you seem to be fixed on thinking that this image class is all the above, just from 1 line of code which says `create`, and that there are no reasons behind them.
compiler flags can change ABI
The same way you add an element to an empty vector object. You seem to assume people want to "add" pixel (10, 15) with an empty image object. Would you add element [15] in an empty vector object?
it's called the [hourglass pattern](https://www.slideshare.net/StefanusDuToit/cpp-con-2014-hourglass-interfaces-for-c-apis) and works quite well
Hi Billy, thanks for your reply! Sorry to hear that MS aren't currently planning major investment in cpprestsdk. It fullfills a very useful roll. I think you've answered a question I didn't ask though! My question was why Spotify would build a layer on top of cpprestsdk rather than contribute a "native" client to it. IIRK there was even a cpprestsdk PR a few years back that added an NSURL native client, which wasn't ever quite completed.