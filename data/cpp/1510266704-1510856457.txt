&gt; &gt; ... or serializing them. &gt; How this help with serializing? It's impossible with upcoming reflection proposals? Well we don't have reflection right now. Also, serializing polymorphic types is non-trivial even if you have reflection, since you need to serialize which type is being serialized. &gt; &gt; ... but also eventually about functionality. &gt; Please, do investigate the technique itself further. Like type that implementing several concepts, concepts inheritance, concept cast, etc... Even conceptually. I think this is more important. Yes, I'm planning to explore further, but keep in mind that one person can only do so much. IOW; help is welcome. 
On Windows, the highest fidelity signature would use wide character strings to avoid the possibility of data loss through encoding into the current ANSI code page.
&gt; Well, the current language allows specifying an array as a non-type template parameter Ah crap. Did not know about this... So yeah you are stuck with ugly ampersand. :/
Also generally a good read
It's not you, it's Xcode.
Off-topic for the C++ subreddit.
Why offtopic, it's about C++
So what, the important part is that it works without bleeding eyes. If you believe that this is to expensive, you really should support this proposal, because if we don't get a sane interface, this is what every competent programmer should really use.
P.S. did you ever consider constexpr function arguments? something like this: `constexpr void func (constexpr int i) {` ` static_assert(i&gt;0); ` `}` `constexpr void func (constexpr int[sz]){` ` static_assert(sz&gt;0); //sz automagically defined to constexpr ``size_t matching the dimension of int array passed to function` `}` I know that for people like you that wrote a ton of library code template version is readable, but I think for "normal" developers normal function syntax may be nicer. 
If your API is shit, then complain to whoever provided it and use this: void myfun(std::string_view s) { terrible_api_fun(std::string(s).c_str()); } Yes, it performs an allocation, but if the API is that terrible, that it requires zero-terminated strings, there is no way around it. And punishing everyone for those who want to work with extreme-legacy-libs, is very much the opposite of don't-pay-for-what-you-don't-use.
Amazing how much Microsoft has changed in the last years. Great job.
There's also the book "Concurrency with Modern C++" by Rainer Grimm. See https://leanpub.com/concurrencywithmodernc
Completely agreed.
&gt; the ability to ask "does X not compile" we have with SFINAE There's a difference between "this metaprogramming ish thing that is useful in some generic code situations that we can't do anything about breaking" and "OK now we're going to do that to literally every function ever".
&gt; Are there even a guarantee that the constexpr will really be computed are compile time in constexpr contexts? No, there is not. MSVC++ does not. 
&gt; static_assert places a pretty hard requirement on constexpr evaluation that would be hard to delay to runtime The compiler can evaluate as constexpr when you ask static_assert but not evaluate as constexpr elsewhere. MSVC++ does this because we don't yet have high enough confidence that being more aggressive about that wouldn't break things.
argv.pop_front() is often useful.
Isn't that basically obsoleted by https://github.com/isocpp/cppcoreguidelines ?
Saying it doesn’t need a major refresh != not wanting it to change
both can be supported at the same time... Worked ok for the strn* family of functions. 
&gt; This requires familiarity of [...] traditional for-loops! Oh, the horror!
&gt; I am curious to know in which use cases start up time is so crucial to the application that this slight increase may pose a problem. Perhaps it would be an issue for some embedded platforms... I just take issue with the paper bragging about C++'s ability to replace C with zero-cost abstractions and then proposing a set solutions that all either remove current functionality, incur extra work, or include non-trivial library headers. So because C is gross we've suggested replacing it with something that at best performs the same and at worst produces extra copies and incurs additional memory overhead while compiling slower. This is not the mark of a great proposal.
Isn't there also a race if people are changing it in odd places using the traditional C syntax with bare pointers? I mean, it's a pretty unusual use-case to be trying to repeatedly change argv from different threads. It seems like a std::args would be just as subject to abuse, but not particularly moreso.
My vim does that... ;-) With ycm it is very easy.
That's debatable. Either way the OS will have to parse the command line and break the input into separate, 0 terminated, char arrays. Computing the string view size in this step should be trivial enough to not incur any overhead, worst case scenario it gets the size by doing pointer arithmetic, one single extra clock cycle. Unless you're running millions of tests each second and you are very concerned about CPU cycles, you won't see any difference.
Is the msvc issue fixed?
Yes, all the `"foo"`s will refer to the same `inline constexpr` variable. 
Yes, this is something many people think about, but it's incredibly difficult to define what a function with constexpr parameters actually means. For example, what does it mean to take the address of such a function (it would need to have a different address depending on the arguments you pass to it)? On the outset it seems like a nice solution, but there are many hairy problems to solve in order to make this work. Proposals welcome.
&gt; C++ programmers really should be able to understand c strings and arrays There's no reason to introduce pointers, pointer/array ambiguity and string zero termination to beginning or even and intermediate C++ programmer. Worse, we shouldn't suggest beginners that passing a raw pointer and an integer count is a good interface for a function. And yes, while I wouldn't hire a C++ programmer not knowing about raw pointers, the language itself allows us to treat them as "tool to interoperate with low level libraries". Except for a few pesky corners like command line arguments, thrown in the face of every beginner. For me, making C++ easier to teach is sufficent reason for this problem to deserve a solution. 
 void (*lam)() = +[](){};
thank you :)
@3: `void foo(ConceptName auto a, decltype(a) b) is probably the best solution in the general case.` Disqusting, but IDK a better way, I would just introduce a new keyword, but ISO will never do that. So if you want your types to for arguments a and c be the same you would write: `void func (same Sortable a, int b, same Sortable c); ` @4.2: I totally do not agree with your reading of programmer intentions, but that may just be me. I would always consider auto useless in the case where you have `Concept auto = bla();` 
There were some patches for MSVC support issues but if there are still problems then I’d be happy to review patches.
I mean if you're going to go with some arcanary you could just skip to the point and use static_cast&lt;&gt; using lam_ptr = void(*)(); lam_ptr lam = static_cast&lt;lam_ptr&gt;([](){}); but that's besides the point if you use a capturing lambda you can't cast it to a function pointer anymore.
&gt; For example, what does it mean to take the address of such a function (it would need to have a different address depending on the arguments you pass to it Well I am not sure this is a real problem. Addresses are just mechanism for "doing polymorphism"/if/switch and if you do not mix functions like current constexpr one does(in a sense that same function is both runtime and compile time) I am not sure you would actually need for pure compile time functions to even exist as functions. In other words they would be as if you copy/pasted their code in the calling site. Obviously you could do "polymorphism"/switch and call different c/p code fragments based on your compile time input, but I am not sure you need to be able to take "real" address of a function. So long story short is that you should be able to call those functions based on their "address" but I see no reason why constexpr function should have real 0xsomething address. Here I am talking about functions that have all arguments constexpr and can not be called at runtime. 
Is it really appropriate to copy selected parts of a copyrighted work and make a GitHub repo in your own name? Shouldn't the moderators have questioned this?
Doesn't it work the same way in many dynamic languages? I know it's similar in Python and Ruby, at least.
&gt; and even traditional for-loops! Lol what. Counted for loops have many uses in modern C++ and if you're going to teach them as bad design/not-modern-C++ you are are very wrong.
&gt;However, one of of the last vestiges of C left in C++ is also both the most difficult to educate new programmers, and an incredibly error prone one to knowledgable programmers. Oh, the absolute horror. &gt;One thing that you may take from this pessimized and contrived example is the horrible amount of C-isms and otherwise terrible set of functions that the programmer is immediately being exposed to. For a student of Modern C++, one can imagine how terrifying this is for an otherwise simple operation. This requires familiarity of C-Arrays, pointer decay, C-string functions, and even traditional for-loops! Oh my god, a for loop where someone has to increment a counter. This is the end. Next I will be told someone might actually have to write code to avoid running over the end of an array. /sarcasm I am not opposed to getting a more modern interface to an application in C++20+ (nor a more flexible one), but this is a rather minor issue. 
What have you tried so far?
Well, my best suggestion is to buy a book (any book, really) on C++ and fiddle with it whenever you want. If you're interested in making games alone, it would also be extremely handy to learn a video game engine, such as [Godot](https://godotengine.org), which has great documentation and support, as well as tutorials by the dozen. I'm only a GNU Linux developer, so I'm not sure how much the following will help you... [Emacs](https://gnu.org/s/emacs) for writing and editing code. It has **so** many great features and it's extremely stable! [Lisp](https://gnu.org/s/guile) for functional programming. Lisp is considered a great language to help expand the mind and make you a better programmer all around, it is also my #1 favourite language! (The link listed points to Scheme, which is a dialect of Lisp, but very clean) [Blender](https://blender.org) for 3D modeling. It is the best open sourced 3d development tool available, the only other option would be [OpenGL](https://opengl.org), which is *very* low level and, unless you want to work at, say Nintendo, is not very necessary. [GNU Linux](https://gnu.org), okay, okay, this one is bias, but in my defense, Windows and mac have IDEs available for them, but GNU Linux **is** an IDE! My favourite GNU Linux distribution is [Ubuntu](https://ubuntu.com), it's simple but not restrictive. Not sure if this helps, but I hope it does.
Embedded systems often times don't do any dynamic allocation. Forcing a dynamic allocation to run C++ alienates plenty of embedded software engineers.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7bym0m/new_to_c_where_do_i_start/dplw0el/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7by379/how_to_compile_and_running_c_and_c_in_command_line/dplw1rd/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's VS2015 being updated?
15 is 2017
Yup, 88 fuccbois triggered so far :D
Pretty much. I just pointed out rust as C/C++ and Rust fit the same development niche. Where as python and ruby fill a completely different need.
Not on Windows it seems: https://www.reddit.com/r/cpp/comments/67oh29/visual_studio_code_cc_extension_april_2017_update/dgsnhlu/. https://github.com/Microsoft/vscode-cpptools/search?utf8=%E2%9C%93&amp;q=libclang&amp;type= also yields 0 results. 
I'm happy as long as auto is avoided in function signatures
On embedded without process support, you're right. But RTOS-es for embedded allow process-based applications. When starting a process, one passes it arguments. Nothing wrong with that :-). 
That's _every last API for C-based libraries on the planet_ you're talking about. But there is an easy way around it: the native types for strings in C++ is already the zero-terminated array of char, and that decays quite conveniently to the required pointer. As long as you don't stick an awkward and ill-advised string_view in the middle, but rather something that respects this reality on both sides, it's not a problem. 
Possibly. On one hand, it's a small amount of content compared to the book's voluminous size, which... *might?*... qualify it as fair use. On the other hand, it's a particularly useful portion, effectively a tl;dr of the book. On the other other hand, since it's littered with references to the book to read more, I suspect this might boost, not depress, purchases of the book. If the owners ask me to take it down, I will, but I think it could be beneficial for everyone.
Do these embedded, no dynamic allocation systems actually have an OS from which command-line arguments are passed? I'd always imagined these were tiny systems where your executable would be the only thing running on the hardware, and therefore there would be no one to pass command-line arguments to or read return values from it. Not arguing for or against the proposal. Just curious. 
The `initializer_list` stuff is completely mad...
Yeah, I guess you've got me there. Embedded is strange like that, in the end I'm the one calling main, and then when main ends (or someone calls exit) I get the call. You end up writing some of the code that goes in the background behind main.
Does the acceptance of your proposal lower the bar for getting user-defined non-type template parameters as a new (to be proposed) feature?
Do we know what Bjarne thinks about it?
 ¯\_(ツ)_/¯
I am curious... Do you have an example for such a use?
Sometimes we get surprised by a T a user supplies to a template that triggers a warning we think is our fault and not the user's fault. It's rare but it happens; the most recent example I remember fixing was `normal_distribution&lt;float&gt;` triggering "narrowing from double to float" warnings.
Yes, but that doesn't help you in contexts, where you need a compile time constant as per the language rules (e.g. template parameters)
Can't you just hover the variables to see their types ? Most ides have this
&gt; ... and another part that seems almost ready to shed off most of grandpa C's legacy and break backward compatibility. I have been on that side since 1992, even though I was using BIDS (Borland International Data Structures) instead of STL back then. C was already outdated back then, and its copy-paste compatibility was an advantage regarding adoption, but also a big sin in what concerns code security.
&gt; Using Factories. Who needs a factory when you have new? Or God forbid std::make_shared (see above about std::shared_ptr!)? Seriously, some people can't wrap their head around them or their use cases. In our codebase we have factories, but not really. That is to say, we have some static functions that return the baseclass, and the parameter of the function determines which instance is created. This leads to fun things like calling a factory function, dynamic_casting the result to the expected concrete type and then working on that. Great use of factories there. 
You need to buy the book to get the context of each advice, so there is not much utility for these advises without the book. It seems to be more of an advertisement for the books, than a copyright infringement.
Yes you do. There are situations where this doesn't work at all when you mix binaries compiled with different ASan flags. That was 2 years ago and confirmed by LLVM devs not to be a bug, just working as intended. It was not entirely reliable at all as many factors can prevent the problem to show up and using the same pattern and libraries, I had a false positive rate of just 1% in that code base. Everything went away when I rebuilt everything properly with ASan too. &gt; That is a good point, which can be simple to update. Lots of things are "simple" to change. But you shouldn't have to handle all of those yourself, otherwise, you'd just be reimplementing CMake instead of using it. &gt; For a toolchain, usually you define it using CMAKE_CXX_FLAGS instead of using those. You shouldn't have to use CMAKE_CXX_FLAGS, that's an old string variable. And in practice, not everything is a toolchain flag.
Not only that, the MSVC++ version in VS2017 (version 15) is version 14.1, but it has internal version 19.10 (since updated to 19.11).
Hi zerexim, I already answered in another thread, but don't want to leave your questions here unanswered. There are no plans for remote work at think-cell unfortunately, we prefer to work at the same office. Since there is a no-meeting policy, it’s good to have all colleagues nearby during office hours. However, these hours are flexible if the developers need to run an errand, they have to simply notify the others through the calendar. The office is usually open from 9:00 to 19:00 and closed on weekends, which means no overtime and no working on weekends. About your turnover question, the reason we are constantly hiring is because we want to grow the team and we want to find the right talent for it. Because of that, we are in no hurry and we are patient until we find it. This is an ongoing search for us, since we would like to hire as many high level C++ developers as we find. We do not have a high turnover rate, only two people have resigned in 15 years and one of them because of relocation to another country. In general, we take between six months to a year to allow candidates and our team to get to know each other, to explore if they are a good fit in terms of work culture and skillset, and then make a decision. This usually happens within the first six months (sometimes it takes less, just three months for example). Our new recruits share the office with our Technical Director, who personally guides them through the first few months of their employment. Be assured that our Technical Director would not dedicate this kind of time to on board people we intend to replace. Also, from the company's perspective, let me tell you it is much more expensive to let somebody go and keep recruiting than to pay the 120k that we are happy to do and honor somebody's work since we are a stable and profitable company. We are looking for long-term colleagues, people who want to stay with us and strengthen our team. The decision to let go of an employee during his or her probationary period is never an easy one to make, nor should it be. At think-cell, this decision is not made by any single person, however senior they may be, but by our developer team, based on their experience working with the new hire. We know that think-cell is not an easy company to get into. At the same time, those who make it through the first year stay with us for a long time. And those who stay with us get to work in a team of excellent C++ developers, undoubtedly the best in their field. I hope I answered to your questions, but if you have more don't hesitate to write us to hr@think-cell.com, Soledad Pons on behalf of think-cell's HR team.
&gt; Presumably you need to USE it for something Yes. What type it is is irrelevant, what you can DO with it is what matters. It doesn't matter if your function returns `std::vector` or `std::list`, what matter is you can iterate over it and use algorithms. Never mind that you can always jump to the definition and see what the return type there is.
``` unsigned foo() { return 5; } int main() { int x = foo(); } ``` Oops.
&gt; Using pure virtual classes. People don't understand why you'd ever want to use them. Do these people know any other OOP languages??
I doubt it. In D all functions are constexpr by default and it doesn't seem to matter at all.
You should have asked the author before posting. I think that doing it without his permission is immoral.
Templated lambdas? But.. why? At that point, why not write a normal function?
I believe that when you write sqrt(x); GCC and clang are picking up the C function sqrt(), which works on doubles. When you write std::sqrt(x); then the C++ std::sqrt() function is picked, which has different overloads for float, double and long double. If you wanted to perform the computation on a float using the C function, you should write sqrtf(x); So it seems to me that GCC and clang are doing the right thing (or, at least, what I would expect :) ).
&gt; . For example, what does it mean to take the address of such a function (it would need to have a different address depending on the arguments you pass to it)? &gt; &gt; step 1. full-blown non-type template parameters step 2. `int f(int x, constexpr foo y) =&gt; template&lt;foo y&gt; int f(int x)`
Thats why they make their text editors as IDE like as possible by adding in all those features, *but still totally not IDEs*
So are you saying I should file a bug report with MSVC?
&gt; If someone writes for (std::pair&lt;K, V&gt; p : m) they are making unnecessary copies of nodes due to type mismatch. Or they forgot the &amp; and it copies regardless but the fact the &amp; is forgotten is lost because they explicitly wrote the large type info cluttering the view :)
This is missing [this neat trick](http://cpp.sh/5mu5) using auto, which can even used structured bindings in simple cases for maximal efficiency.
I don't know honestly. I had in the past a problem with the math headers on MSVC which looks vaguely similar: https://stackoverflow.com/questions/46360828/msvcs-stdlib-and-fma-function-template My impression at the time was that MSVC might be injecting extra overloads for the math functions that are not present in the standard. But I did not pursue the issue further as I don't use MSVC habitually.
That phrase "GCC and Clang are unaffected" seems to be popular of late.
Print out a comma-separated list of vector&lt;T&gt; using a range-based for loop. The last element can't have a trailing comma. Next, do the same but in reversed order. That's two trivial cases where you need to use the iterators directly when processing the list, and there are other cases as well.
i *still* find auto breaking traditional scope rules a bit off-putting, even if useful in cases like this.
That's a great trick! Easily readable and tightly scoped!
&gt; What's wrong with that when you do need it??? Nothing, but people arguing against pure virtual classes do it 99.99% of the time because of some performances reason. The performance impact of the pimpl is the same if not worse (disclaimer: I've not compared a benchmark) than using virtual. After both are usually not use for the same reason.
C++98 for historical reasons or is it a new library and it was a deliberate design choice? What's up with platform-specific configuration scripts instead of CMake? Why no FreeBSD support?
for (auto &amp;&amp; [i,v] : zip(ints(0), vs)) { if (i) ... } Or as I would do it bool first = true; for (anything) { if (std::exchange(first, false)) {...} } 
&gt; My impression at the time was that MSVC might be injecting extra overloads for the math functions that are not present in the standard. That is my impression as well after consulting MSVC's implementation. To be fair, this is probably a useful optimization and transparent unless you static assert the size of the type returned from sqrt.
I'm not sure I understand your reply. Using static_cast or the unary plus operator is the same thing, both are calling the lambda's conversion operator.
True.
&gt; Using pure virtual classes. &gt; &gt; ugh; that's basic C++, not even modern black magic. that's basic OOP actually
It changes the results because a float can't store as much precision as a double meaning if you do this: my_struct.double_value = sqrt(float(3.64)); vs this: my_struct.double_value = std::sqrt(double(3.64)) You get different results stored in double_value.
That's nice, but `zip` isn't standard functionality yet, is it? Where does your implementation come from?
No, I'm saying it's NOT some stl iterator or something, which is the trivial obvious case. Some external library function returns a class object that you need to use, and it has a bunch of member functions. The type is 100% relevant, otherwise you can't actually use the thing. Like, you have: `auto x = factory.createAwesomeObject();` `x` has like 100 methods you need to use. What is `x`? First, I have to open the header for the factory and get the return type. Then I need to open the header for the object itself to see how to use it, SO I NOW NECESSARILY KNOW THE TYPE OF THE OBJECT. Why not just declare it explicitly to reduce the complexity of the codebase? I guess that this is the "Almost" case of AAA, but this is the majority of the code I work with. I'm not just diddling around with iterators all day, there are a ton of library dependencies and objects I need to use. I use auto where it makes sense, which is in a lot of places, but I worry about it being overused because it is the sexy "new" c++ feature, and 10 years from now people trying to maintain this code are going to be pulling their hair out.
Did you mean to write `std::sqrt(float(3.64))` for that second example? Otherwise, I would expect to get different results anyway.
I don't think it's a bug. &gt;For some of the C standard library headers of the form xxx.h, the C++ standard library both includes an identically-named header and another header of the form cxxx (all meaningful cxxx headers are listed above). &gt;With the exception of complex.h , each xxx.h header included in the C++ standard library places in the global namespace each name that the corresponding cxxx header would have placed in the std namespace. &gt;These headers are allowed to also declare the same names in the std namespace, and the corresponding cxxx headers are allowed to also declare the same names in the global namespace So it's not required for c++'s sqrt to be in the global namespace, but it's also not prohibited.
You are right - I already consider the RangesTS to be standard with respect to standardization discussions/future which is indeed not necessarily correct.
&gt; This is exactly the kind of argument I (a young developer) would have with a more elderly developer and I think any reasonable C++ developer would back me up here in saying that: You should rely on the compiler to optimize for you. (From the "functional guy" picking up C++ to the Bjarne Stroustrup himself) No no no no no. This is a horrible practice if you ever ship portable software. Are you going to throw your hands up in the air when large customer A gives you an old compiler and offers millions of dollars for your software and say "sorry, your compiler didn't optimize the hot path in our code, so we can't sell the software". No you aren't. Instead, you're going to write code which will help the compiler understand what you are doing. &gt; That null terminated string, are simply a bad choice. It's efficient, simple, elegant, and a well-defined standard.. &gt; That array decaying to pointer is retarded (bad for code quality, unexpected, hard to understand, useless... etc). Easy to understand, representative of what the hardware is **actually** doing, and a well-defined standard.. &gt; That not having a comprehensive standard library is poor choice. (Hello people still manually writing lists !) There is an incredibly good reason why most companies roll their own standard library, and actually the C standard library is quite powerful. &gt; That having a type system which is so poorly designed you can't have a memcopy with the (T* src, T* dest) signature or a free(T* res) is, again, a poor choice. I'm confused, do you mean templates? You can just use void* and enjoy not having to argue with a customer about the size of your libraries when they're about to code freeze for production. Because trust me, even if they have more than enough space they'll fight tooth and nail for it. &gt; That the amount of UB the language allows for where it could instead generate compiler errors is a dick move You're talking about C++ right? I shouldn't have to argue this one. &gt; ...etc, I'm not familiar with C, if I were (and if I had the time), this list could go to infinity. You don't need to state it, it's pretty obvious that you don't know much about C or working on long-term software projects with modern C++ features. &gt; But, going back to the original point... I can't see many cases where these legacy constructs within the language would be relevant to a "junior" developer and if they do that means whatever codebase that junior dev is working on is in need of a serious refactoring. Someone at my previous company had this **exact** mentality and moved all the codebase to modern C++. The company ended up having to rewrite everything back to C when they couldn't ship to customers. If you avoid the standard library, there are a lot of good reasons to use C++ but for the love of god avoid 90% of the features. Software is **not** the platform.
I especially appreciate how it's usually actual development staff you see replying on Reddit and blogs instead of the usual social media specialists, marketing folks, or support engineers. "We're working on it," means a hell of a lot more when said by an actual compiler or library developer.
&gt; x has like 100 methods you need to use x. &lt;tab&gt; (see list of completions). Or jump to definition of `createAwesomeObject`. I don't know about you, but I can't keep even 10 member functions in my head (much less 100) even if I knew what the type was anyway. Either way I'm going to have to go look (or tab complete). &gt; Why not just declare it explicitly to reduce the complexity of the codebase? The actual type might change. The interface might not. Maybe it's a `std::function`. Maybe it's a function pointer. Maybe it's a function object. It shouldn't matter. &gt; but this is the majority of the code I work with I guess that's our difference. I've successfully tried to stay away from OOP for a while now. &gt; about it being overused because it is the sexy "new" c++ feature It doesn't only exist in C++. It or its equivalent is usually preferred over explicit types in any language with type inference. The only C++-specific thing about `auto` are the weird deduction rules. 
This is more of a library issue. [\[headers\]/4](http://eel.is/c++draft/headers): &gt; Except as noted in Clause 20 through Clause 33 and Annex D, the contents of each header c*name* is the same as that of the corresponding header *name*.h as specified in the C standard library (Clause 2). In the C++ standard library, however, the declarations (except for names which are defined as macros in C) are within namespace scope (6.3.6) of the namespace `std`. **It is unspecified whether these names (including any overloads added in Clause 21 through Clause 33 and Annex D) are first declared within the global namespace scope and are then injected into namespace `std` by explicit using-declarations (10.3.3).** I think (though I'm not sure) this means both of the following are allowed: - declare both `float sqrt(float);` and `double sqrt(double);` within global scope and then pull them into namespace `std` via using-declaration, i.e. what MSVC STL does - declare `double sqrt(double);` within global scope and then pull it into namespace `std` via using-declaration, and declare `float sqrt(float);` directly in namespace `std`, i.e. what libstdc++ (and libc++) does
&gt; But. List macros can not be fitted in C++, they had to be there from the start. I won't be so sure. I experimented with mutilating C with a pervasive macro system (deeply integrated, interacting with the type system, etc.). A similar design surely can be retrofitted into the existing C++: https://github.com/combinatorylogic/clike (also, see a toy template metaprogramming engine implemented right on top of these macros just for fun). I made few additions to the language that make macros easier: optional node annotations (which are very useful when you do quasiquotation), a statement-expression block and a lexical context lifting block (e.g., if you want to define a new method in the same class as the method containing your macro). &gt; In c++ everything that is not an expression is a statement. Expression are nice, they have a type. statements, not so much. And? Both are just ASTs at the end. &gt; Like what if the thing you want to pass as parameter to the macro depends on a variable defined inside of the macro ? I'd say that hygiene is overrated (Scheme people won't agree, but CL is doing just fine without it). &gt; Functionals languages have it easier in this instance. There is nothing special in the functional languages that makes macros easier. 
Nice find! I think this settles this specific issue. Do you know if stdlib implementations are allowed to declare in the global namespace functions with the same name as those in the standard library but with different signatures? I am asking because apparently MSVC declares an fma() function *template* in the global namespace which ultimately seems to end up breaking ADL for fma() functions defined in other namespaces. E.g., see here: https://ci.appveyor.com/project/bluescarni/mppp/build/557/job/m25u5g59tp49jfl3#L1049 On line 1060 MSVC refers to an fma() function template which renders my own fma() implementation for my user-defined type ambiguous.
You don't even need a direct access to an AST. All you need is a symmetric quasiquotation (working both for construction and pattern-matching). Surely, you have to add a pattern matching to your language first...
Does it actually include a way to define custom string literals that receive the string as a template parameter? That would actually be very useful.
&gt; There are situations where this doesn't work at all when you mix binaries compiled with different ASan flags. That was 2 years ago and confirmed by LLVM devs not to be a bug, just working as intended. Do you have a link to this bug report and discussion? Asan is designed to work without needing to recompile your dependencies. &gt; But you shouldn't have to handle all of those yourself, otherwise, you'd just be reimplementing CMake instead of using it. I am not reimplementing cmake, I am just translating cmake's toolchain to bjam's, which doesn't come close to implementing cmake. Of course, now that I think about, I don't think its a problem. Cget will set the release or debug version of boost. If there are additional flags they can be set with `CMAKE_CXX_FLAGS`. &gt; You shouldn't have to use CMAKE_CXX_FLAGS, that's an old string variable. Its not an "old" string variable. Thats still how you can set the compiler flags today directly from the command line. Furthermore, a toolchain, generally, just set some default cmake variables. It doesn't usually call to `add_definitions`(alhtough that does work in a toolchain file). Also, just setting variables(rather than properties) can help simplify translating the toolchain to other buildsystems. &gt; And in practice, not everything is a toolchain flag. Its not, but if you are talking about needing to compile everything using a certain flag to avoid ABI/ODR problems then its a toolchain flag. Its also pretty easy to set toolchain flags with cget: cget init --cxxflags='-fsanitize=address' cget install -f requirements.txt This will install all the dependencies(including boost) with ASAN enabled.
Hey there, libtins developer over here. I added pcapplusplus to my benchmarks (only locally, still not pushed to the repo) and I compared it to libtins' master branch and I'm surprised to see libtins is actually faster than pcapplusplus in all 3 test cases. I'm genuinely surprised since, as you probably know, libtins copies each layer's payload internally so there's definitely a major performance penalty in there. Still, it somehow manages to beat pcaplusplus. Note that I recently made some optimizations on a few classes so that may be part of it? Still, I wouldn't imagine that would have made things that faster. e.g. on the TCP + options one, I'm getting 0.35 seconds for pcap, 0.41 for libtins and 0.74 for pcapplusplus. I cloned your repo and built the library manually. I see that there's a -O2 in the Makefile somewhere but is this building with optimizations on by default? I'm using Linux btw.
Yes, as the abstract says, this is possible with this paper.
There's already a proposal for this.
&gt; x. &lt;tab&gt; (see list of completions). I don't assume that an IDE is a necessary requirement for using the language. Or, many of our projects use Makefiles, and CLion only uses CMake, and can't auto complete if I'm just using it as an editor. I spend 80% of my time in an IDE, and autocomplete is nice to have, and I use it where I can. &gt; Either way I'm going to have to go look In at least two header files, instead of 1. &gt; The actual type might change. This seems like a good thing to know. I consider it a feature that the compiler tells me this. If the type changes, it will probably break further down execution path. Unless, again, it is truly some totally generic type, in which case it DOES make sense to use auto. &gt; I've successfully tried to stay away from OOP for a while now. I don't know what that means in the context of writing C++. You don't use classes? You don't use libraries that use classes? &gt; It or its equivalent is usually preferred over explicit types in any language with type inference. Preferred by whom? The writer, or the maintainer? I thought the saying was "Code for the maintainer, not the compiler." Auto seems to go against this. I guess I'm approaching this from the point of view of a developer who starts working on an established code base after an old senior dev leaves the company, and I get the nod to take over the library. Which is what I went through this summer. I worked on two libraries, one that was more modern with `auto` everywhere, and an older one that rarely used `auto`. The newer one took significantly more time to understand, whereas it was clear from the code what the older one was doing. I also work with a lot of python, and the lack of a python type system is such a detriment our team tries to avoid large python projects as much as possible. It is nearly impossible to keep a mental map of the system without types, or without working on it for months.
No bug, it was a formal discussion at Cppcon, they told me it's working as intended. You can't mix code from the same library with parts instrumented and parts that aren't with full confidence.
At first I thought this was really nice, and something I'd definitely use. However, the fact that it's still depending on gmp and mpfr is a shame. Your README led me to believe otherwise, which was somewhat disapointing, and calling your library "header-only" is a bit of a stretch. Is the plan to get rid of tmp gmp/mpfr dependencies altogether by the time you hit 1.0, or will they stick around?
I think you're confusing morality with ethics.
Sorry, I could not access it here since Github is blocked. 
The difference is that 'main' controls it, since by standard, argc/argv are the only way to get this info. Therefore, if 'main' itelf causes races by opening threads, that is the programmer's fault. However, if we give access to it as a global variable, then static initializers in a sub-library (or a dynamically loaded library!) can alter it before main has a chance to see it.
Alternatively, no need to give a name to the struct: auto square(int a) { struct { int original; int squared; } output { a, a*a }; return output; } 
The stack... in a VLA or alloca.
Unless you need to support ancient compilers you should: 1. Always `#include &lt;cmath&gt;` (never `&lt;math.h&gt;`). 2. Always call `std::sqrt()` (never `using namespace std;`). That way you should be much better off. 
I agree, but I'm curious to why you, specifically, say that.
&gt;macro Pass.
until we have constexpr function parameters or static_reflection, you're not going to find another way of achieving this as a single expression. Of course, you could always just write all the boilerplate that the macro hides every time and get the same outcome.
Yes; they are both the same thing ones just less confusing to people that haven't seen the decay through unary plus. Aka when doing 'meta hackery' its usually preferable to make intent incredibly clear vs something that requires people to go to stackoverflow or the like. As for debugging things +operator gives "cannot find matching operator" or equiv vs static_cast&lt;&gt; gives "no suitable conversion ..." and static_cast is a hell of a lot more clear what the intent is in that case since you're trying to cast it to a function pointer anyway...
Link is broken?
To *sfinae*, no. To having to wrap your constraints with `std::enable_if_t&lt;C, int&gt; = 0` as a trailing non-type function parameter, in order to be able to have the other function template be able to use `std::enable_if_t&lt;!C, int&gt; = 0`, yes. I don't think many tears will be shed over not having to write that anymore. 
That is a better answer, thanks.
Probably, I'm going to google difference :p
think it's fixed now? godbolt was having some issues earlier with compiling - might have been on that end?
What does any of this has to do with the question about VS2015?
yes... :)
That's... exactly what I linked in the example. math.h isn't included and there's no "using namespace std". /* #include &lt;cmath&gt; */ and you can call /* sqrt(...) */ just fine.
Yeah it's good now
Does anyone know if this library would allow you to detect RTMSP (real time media streaming protocol) traffic from your own computer to potentially extract a video stream from a web page with lots of crap on it and play it elsewhere?
That's easy enough to fix: - `std::args` will rely on having `argc` and `argv` written in some memory location, - this memory location will start at 0, so any invocation *before `main`* will result in an empty iterator (or, alternatively, an exception), - right before `main` is called, the location is initialized. And to avoid data-races, make it a thread-local memory location. If only the main thread is allowed to see those arguments, then there's no data race.
It's not immediately clear to me what aspect of constexpr you are leveraging to try to do this. I've written an is constexpr macro (in an SO answer) that leverages the fact that constant expressions are always no except. It works perfectly in gcc but not in clang.
I'm taking advantage of the fact that a constexpr function's return value is constexpr only if the parameters supplied to it are also constexpr. Combine this with hana::is_valid, and you can take your expression, pump it into the aforementioned function, and see if the return value can be used as a template value parameter (only possible if the expression, and therefore the function's return value, are constexpr). I'd love to see your solution too, don't suppose you have a link?
Link: https://stackoverflow.com/questions/46919582/is-it-possible-to-know-when-is-constexpr-really-a-constexpr/46920091#46920091. Summary of solution inline: template &lt;class T&gt; constexpr void test_helper(T&amp;&amp; t) {} #define IS_CONSTEXPR(...) noexcept(test_helper(__VA_ARGS__)) It's a bit shorter ;-).
Because of the issue where it's unspecified whether `&lt;cmath&gt;` supports unqualified `sqrt` and whether `&lt;math.h&gt;` supports qualified `std::sqrt`, portable use of both qualified and unqualified functions requires including both: #include &lt;cmath&gt; #include &lt;math.h&gt; And this does indeed [work][1] with gcc, clang, libc++, libstdc++, and msvc. Including both headers means you uniformly get the C++ overloads. libstdc++'s behavior: - `&lt;math.h&gt;` alone makes the C++ overloads available in the global namespace as required, and also available in `std::`. - `&lt;cmath&gt;` alone makes the C++ overloads are available in `std::`, and the C version of `sqrt` available in the global namespace. This is weird, though legal, I think. - Including both is the same as `&lt;math.h&gt;` alone. libc++'s behavior: - `&lt;math.h&gt;` makes the C++ overloads available in the global namespace, but not available in `std::`. - `&lt;cmath&gt;` alone makes the C++ overloads available in both the global namespace and in `std::`. - Including both is the same as `&lt;cmath&gt;` alone. msvc's behavior: - `&lt;math.h&gt;` alone makes the C version of `sqrt` available in the global namespace, which is not legal according the the C++ spec. - `&lt;cmath&gt;` alone makes the C++ overloads available in both the global namespace, and in `std::`. This is legal. - Including both is the same as `&lt;cmath&gt;` alone. [1]: https://godbolt.org/g/hQKHPB
haha, I think you've got me beat! A very elegant solution :) Shame about the lack of Clang support, and also the inability to check 'void' expressions, same as me. I'd definitely recommend replacing the template parameter with (...) however. Even more concise!
But won't that report `true` when the expression is `noexcept` but not `constexpr`?
So your argument here is "My customer has bad infrastructure so I must ship software for his bad infrastructure, thus I can't use any modern language features" ? That seems to be the sum of it. If a shitty bootlegged version of gcc 3.0 with some c++ features on an embeded devices is what you are working with (or something even worse, like msvc), I totally get why most of my points don't apply... but that's not coding in c++ in my opinion. It's like talking about javascript running on IE6 or Java running on the 1.2 JVM. I mean, what's the point of arguing around smart pointers, modern tmp, auto and other features if you'r compiler doesn't support them ? I do get that a huge part of the C++ community is stuck having to deliver software for an old ecosystem and I guess that's one of the problem with C++, that some people are currently implementing experimental +2a features whilst others are stuck migrating to +03. Personally I don't think of that part of community a lot since I've had the luck of only working on internal software within reasonable companies. So whenever someone talks about C++ I assume it's the 14+.
if I'm looking at this right - no. Because the test_helper itself isn't 'noexcept', meaning the only way that tag can be implicitly added is if it's constexpr (which is implicitly noexcept and inline).
ASK AND YE SHALL RECEIVE: void bar1() {} constexpr void bar2() {} int main() { std::cerr &lt;&lt; IS_CONSTEXPR((bar1(), 0)); std::cerr &lt;&lt; IS_CONSTEXPR((bar2(), 0)); return 0; } Prints 01 for me on gcc.
yeah, I know about that - but integrating it into the macro isn't possible, because it breaks other expressions :(
Looks fine to me: http://coliru.stacked-crooked.com/a/8f75a6ea951a49d3.
I see.
https://godbolt.org/g/7WfQeN not here - values are ignored because of the default comma behaviour, leaving '0' as the only thing passed into the function (which is guaranteed to be constexpr)
Too much hand-waving in this.
So far I think the best method to mark with `[[nodiscard]]` would be `empty` on containers. People keep calling it with real intention to call `clear`.
I think everyone we have on social media are actual engineering staff (and management, like /u/spongo2, but don't hold that against him!) Our team--and maybe not Microsoft?--doesn't have social media specialists. And thanks!
This library is quite new (2+ years). C++98 is a design choice to make this library usable in as many projects as possible - both ones that use c++11, c++14 or c++17 but also ones who still use c++98. This is the same reason for not using CMake - I encountered many projects that didn't use CMake and it was hard to integrate libraries that enforce using CMake
We’re getting that in C++20 thanks to Josuttis’s paper.
May be something like this ? http://coliru.stacked-crooked.com/a/f1a42b93131447c3
Unfortunately RTMSP isn't supported yet, but you are welcome to add it :)
c'mon mannnn, you can't just use another macro altogether ;)
This is indeed surprising. I ran your benchmarks a few months back and got opposite results. I also used Linux to run them. Perhaps some code changes I made since then caused PcapPlusPlus to run slower, I will revisit the tests and the code. Thank you for letting me know!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7c3sq3/i_have_an_assignment_due_for_c_and_i_dont/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Hmm, VS2217.5 compiler do not like this.
You know a language is fucked up if "advices" take the form of ~790 rules. I mean: you can probably formally define a complete small elegant programing language, with that much sentences. Even maybe with less.
Note that while part of it may be caused by pcapplusplus getting slower, some of it is definitely caused by libtins being faster than before. I worked a bit on optimizing it a while back so that definitely helped.
You are not forced to use "trailing, defaulted non-type function template parameter". You can normally do away with smth like this: template&lt;class T, enable_if_t&lt;is_floating_point_v&lt;T&gt;&gt;...&gt; T sqrt (T x); :)
I have a [non-macro is_constexpr()](https://github.com/coryshrmn/cgs/blob/master/include/cgs/meta/constexpr.hpp), which works on GCC and Clang. There is a limitation: only default value parameters are considered. This is fine in most cases. You can see the strange results in [this test](https://github.com/coryshrmn/cgs/blob/f6575e9b2a1c584f84f81ce3eb05442bc7252b9b/test/meta.cpp#L61-L63).
IDK if you count this under SFINAE because I never used dispatching through something to control something... but here is what STL said about that https://www.reddit.com/r/cpp/comments/64frhb/ctai_compile_time_assembly_interpreter/dg7v5oo/
&gt; this is the best convention for code bases that aim for high type correctness "And yes, as you mention, the point is that there can be unintended consequences. If you always do auto x = X{y}; you've lost the implicit vs explicit distinction." - https://www.reddit.com/r/cpp/comments/6ttabw/with_respect_to_proper_usage_of_auto/dlqamss/?context=3
I think if I knew enough to add it I wouldn't be so eager find a library. 
Got it. I looked again at the benchmark tests and it seems that a large part of it is around how fast each library parses the packets, rather than how fast you can access the data afterwards. So maybe the difference lies in PcapPlusPlus parses packets slower 
Yeah, parsing the packets is the heavy work. Once you've done that, accessing it should be really fast unless there's some really high level wrapper around every field like in libcrafter's case. That's why the benchmark only focuses on parsing them as once you've done that, the rest should take no time.
I'll look into PcapPlusPlus parsing mechanism, I'm sure I'll find places for improvement there
Sorry, by "usual" I didn't mean "as is typical of Microsoft", but rather "as one often comes to expect from large corporations nowadays". 
As long as you keep in mind partial ordering of constraints you will be fine.
It was assumed 15.5 has been confused with 2015 in the question, as this happens frequently.
I've been watching your effort. I very much want to see something like this get into c++20. I disagree that this is useless with an mpfr dependency. job one is to get the API correct. We need to get the resource design correct. my view/hope is that we can eventually separate the math and the storage. have a view that could do mp on either a dynamic or a static array of limbs.
See [`std::rel_ops`](http://en.cppreference.com/w/cpp/utility/rel_ops/operator_cmp). This is practically never used, as it's not easy to use it to generate the operators for the type, and it's awkward to require someone to have `using namespace std::rel_ops` to use your type. It can absolutely be written to work well, though
what becomes of numeric_limits in this mp world? I plan to subject my special functions github/tr29124_test to mp++. 
This is only useful for functions that don't have a separate definition. Some people spend too much time in the "header-only" world.
&gt; attribute People don't want C++ attributes to alter the program behavior. Metaclass might do the job, but it's still in the early stage. Another choice is to use CRTP (e.g. use `boost::totally_ordered` in [&lt;boost/operators.hpp&gt;](http://www.boost.org/doc/libs/release/libs/utility/operators.htm)), but it's intrusive, as one needs to modify the class definition.
I believe you can also do something like this with C++2a's templated lambdas : https://godbolt.org/g/fCKpFZ and C++1z's "using Args::operator()..."; Doesn't work with clang because they haven't implemented templated lambdas yet though. 
`rel_ops` is an abomination, because it doesn’t work properly with argument-dependent lookup. It’s about to be deprecated.
Exactly. Some form of code generation is needed for this case and should be backward compatible.
You are absolutely right: you can build a fully expressive syntax manipulation facility on top of the IPR. Template Haskell did a remarkable job at their syntax library.
Is this actually well-defined under the specification? It seems weird that it works since `template&lt;class T, void...&gt;` is not legal yet that's basically what we're expressing here. I noticed that icc chokes on it, but I'm not sure that means anything since icc seems to have issues with some of its corner cases when it comes to templates.
https://blog.rmf.io/cxx11/almost-static-if
How would you suggest embedded SW developers use C++ after this change? There are cases, where complete standard library is not available due to memory constraints. Would you want to create an enforced dependency to a container type, even when this container is not necessarily needed anywhere else in the code base. All this generates is binary bloat.
Yuck. I'd be interested to find out what library is used to play the notes but there's no way I'm sitting through fifteen minutes of just watching someone type, in an awful DOS font. Looking at the URL given at the beginning leads here: http://bisqwit.iki.fi/source/adlmidi.html
I don’t think this is cool.
Yes you *can* call `sqrt()` (as others have explained, that's part of the standard), but you *shouldn't*. That's an important part of point **2**.
`#include &lt;vector&gt; // for std:: vector` ....
Haha I thought exactly the same thing. I hate redundant comments
That was mostly for completeness’s sake. The other #includes are more descriptive: #include &lt;vector&gt; // For std::vector&lt;&gt; #include &lt;cstring&gt; // For std::strlen() #include &lt;cstdio&gt; // For std::fopen(), std::fwrite(), std::fclose() 
This video was probably my first C++11 video, and I wanted to illustrate a practical use for variadic arguments. Admittedly not my best work. ADLMIDI is a different product alltogether, it is a full-fledged MIDI player that uses OPL3 synthesis. What this video does is generate a MIDI byte stream for a particular hard-coded song at runtime.
Yep, no worries! Just wanted to clarify. 
I don't know. Such comments have a tendency to become out of sync with the code (and at least those 3 are pretty obvious) so I generally don't like them, but if that is the coding style the author is used to - why not.
That being said, I'm sorry for nitpicking on such a minor detail that is completely irrelevant for the quality of the video.
I don’t do that usually myself, but this was a program that was only made for a video. Others are complaining about the lack of narration. Before I started doing narration, I tried to do more with comments.
That's a general truth about video. People can read much faster than they can speak, and written text can be searched to find the correct spot, rather than having to slowly, painfully skip through a video. More and more information on the web seems only to be available in video form, even though its contents is 100% text that could easily and far more conveniently be read. And since I'm at it, might I make a suggestion for when videos from conferences are posted here? Would it be possible if the associated abstract, or a short summary, were posted with each video? The volume has been so great lately that it is hard to keep up, and it's a shame to miss out on interesting talks... 
Ah nice, a Bisqwit video 😊
The God himself
That's a complaint for the tooling doing the PR request then. We're in the 21st century, having everything in one's head and on screen is for 1970.
This can't be upvoted enough. It really is about using a dedicated product versus making a dedicated product oneself (or, rather, using setups thereof other people made). The whole discussion is **seriously** misplaced - it's not "no IDE vs IDE" but merely "my IDE vs. your IDE" (one being vim-based). 😁
Sorry for the delay. [Here is a zip with set of 85 json files that reproduce the 30min run time + crash](http://s000.tinyupload.com/index.php?file_id=00873328128460186600). I took great care of getting the *exact* same structure/string length, etc as in my original files. They still exhibit the original behavior. Let me know if you got the files, or if I should host them elsewhere.
Bisqwit is the man. His 3D series are amazing.
Regarding your pet peeve: With C++17 you'll have access to `std::map::try_emplace` which has a more descriptive name of what it is actually doing. As a bonus, you get a guarantee that temporaries are not moved from if a key already exists. See [N4279](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4279.html) for more details.
I want to point out Python decorator (which you call "attribute") does not correspond to C++ attribute. The syntax of applying Python decorator looks like applying C++ attribute, that's why the confusion. C++ attribute is like a marking of extra information. Like `[[deprecated]]` means the thing is deprecated, `[[fallthrough]]` means I don't write `break` here intentionally. Python decorator is a function, that takes the function that being decorated, then creates a new function out of the original, and then assign the new function to the original name. (Actually, decorator can be either function or class, and it can decorate either function or class. But you get my point.) Also note that Python attribute corresponds to C++ data member. Terminology is confusing.
This is nonsense. You cannot undef an upstream header guard, eg boost, in order to use it yourself. Because, if you use it yourself, then at the time you undef it, you dont know if it was previously defined by boost or by you. Your user may repeatedly include your files or boosts files, and you must not cause multiple definition errors. Undefing a header guard is always a bug and a huge blunder. If you clash with upstream header guard name, you must simply rename yours.
CppCon is good about linking to slides in the YouTube description
Initially I started to built this library solely as a learning experience. But then I needed to deploy Keras models in a specific C++ application and thus added the Keras import. Along the way I learned a lot about the the Keras model format, the details of implementing the different layer types and the computational graph. I would be happy to hear your feedback and to answer questions. :-)
KDevelop, QtCreator are great open-source IDE. My two favorites.
Hmm, not entirely sure, but [Eclipse](https://www.eclipse.org/downloads/packages/eclipse-ide-cc-developers/oxygen1a) should be fine in your situation I believe...
I'm going to be in the minority here, but I use Netbeans. That's partially because it's just what I'm used to, and partially because it's the only IDE I can reliably get to work when I've got local source code, but want to do remote machine compile/run/debug. But it's got full debugging support, tab completion, point and click navigation to jump around to definitions/usages/etc. I'm unaware of any major IDE feature that it does not support. Another free option is Eclipse. I've always found it a bit hard to set up and get used to so I've never gotten past the initial learning curve, but I've also never tried hard to enough to see if it's really that difficult or just not what I'm used to.
Implemented a macro option in https://github.com/fmtlib/fmt/commit/246bdafc74aaff7b207d1baa532aa746294b4b88. Now you can do auto s = fmt::format(FMT_STRING("{}"), 42); and the format string will be checked at compile-time. This should work on any C++14 compiler including recent versions of MSVC. 
This was simply a 'direction' paper to see if the committee is open to change. It leaves a lot unspecified in the paper with the goal of creating discussion in EWG.
This paper in no way proposed the removal of int main(int argc, char**argv). Those platforms are free to still use those. This is a case of "don't pay for what you use", if you are not willing to put up with the library/startup costs, dont! Additionally, discussion during the week (before this paper was presented), came up with a new type that lacked these issues (introducing a new type).
I have to join you on the Netbeans. Maybe not the most fanciest or best IDE, but for the price (non) you get a IDE supporting Java, C/C++, PHP etc. Netbeans is more than just capable of basic things used for debugging etc. Other option I use (but I have it for free as I am still a student) is CLion from JetBrains.
Good code still doesn't need tooling to be readable though.
Out of interest Bisqwit, do you only write impressive walls of code on your own personal projects, or would you write in a similar style in a group project? I've watched a few of your videos and I find myself being absolutely amazed at how you can thrash out code that produces such interesting output. I also feel sorry for anyone picking it up after you though! Do you have any thoughts on working in a team? 
You could use [Visual Studio Code](https://code.visualstudio.com/) with its [C++-Extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode.cpptools). Basically a sublimetext inspired editor, cross-platform, open source, has intellisense &amp; debugging functionality through the extension, very configurable (if that is a word). For me, the "sanest" microsoft product. 
I didnt know but this one is free for commercial use. I may take a look I have tried it for Python and is quite nice. Not the same as Visual Studio mut may do the trick!
In addition to all the excellent suggestions, might I make one more? It's this: if your company provides you with the right tools, you'll be more productive. Even in the fairly short run, that's already going to have a significant net benefit to them. It is not strange to ask for the right tools, and if you believe Visual Studio is part of that, do go ahead and ask for it. In every other job on this planet it is customary to use the right tools, and software development is no exception. I wouldn't go to a garage that doesn't have the right tools. I wouldn't call a plumber without tools. I wouldn't commision something from a woodworker without a machine shop. You see where this is going? We're also not talking about a major investment. A copy of Visual Studio 2017 Pro costs 641 euro where I live, and is plenty good enough to get you going. It is also extremely easy to set up, since it will install the C++ runtime, the compiler, the editor, the debugger, the header files, etc. all in one go, unlike any of the other options given where you'll find yourself installing bits and pieces from all over the internet. Anyway, I'm not saying Visual Studio is better than all the other options named here (for one thing, I haven't used the majority of them, so I wouldn't know), but I can tell you it is a powerful tool that will help you get going quickly. And for the rest... Your toolkit is not finished here. You'll need a web browser (for looking stuff up), communication software, a version control tool, software to write and/or generate documentation, a copy of winamp and some headphones (my nr. #1 productivity booster), some small tools like Depends, Process Explorer, and WinMerge, deployment tools, some visual studio extensions like vscoloroutput and 'text macros', a PC specced to run all that, and local admin rights to run it properly. Because you are a pro, and a pro uses good tools. 
Bisqwit is the best, love his videos!
I second this. I program PHP/javascript using sublime text 3. Recently I wrote a REST-service in C++ and the first few lines in SB3. Having used eclipse before I missed the autocomplete and downloaded it again. I was a bit hesitant since the mac mini I use is not the fastest but the speed using eclipse surprised me positively.
There isn't currently a tool for it, but you can emulate it in code [(here)](https://gist.github.com/foonathan/023ff0fe923c6b0312dfc15e17ebb595), and it is theoretically possible with attributes.
I believe the C++ core guidelines checker is supposed to do something like this, though not in a way that ensures 100% correctness.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7c93pl/free_ide_for_c_and_c_for_commerical_use/dpoackc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I only know about the guidelines. There's a checker?
Most of my coding experience is solitary, but I have also worked in teams. Regarding the coding style, in videos I emphasize everything-in-one-file style coding because of presentation reasons and for brevity. If I only wrote short files that are promptly forgotten soon thereafter and not seen on the screen again, it would become more difficult to follow. Not having to write separate prototypes and definitions also saves time, meaning that more of the video can be spent doing relevant stuff instead of wasting time in boilerplate code satisfying the compiler. The actual time shown on the screen (video) is a minuscule portion of the development budget for that particular project. The bulk of time is spent in first designing the application, and then minimizing the design into a concise enough format that it makes an entertaining video, and this happens off-screen weeks, months or even years before the video is made. Right now I am working on several.
I think the first link (the spaceship operator) is meant to be P0515 rather than P0513.
Thanks, fixed.
Yes, the guidelines are intended to be checked automatically. Specifically, the borrow checker is the rough equivalent of the lifetime safety profile, on which see [this design document](https://www.reddit.com/r/cpp/comments/4csc6z/c_core_guidelines_checkers_preview_of_the/). The checker for MSVC has some support for lifetimes I believe ([blog](https://blogs.msdn.microsoft.com/vcblog/2016/03/31/c-core-guidelines-checkers-preview-of-the-lifetime-safety-checker/)). Unfortunately the checker for clang-tidy AFAIK does not.
It's a video tutorial though. Not a production code. It's supposed to be as descriptive and obvious as possible.
Great video! Why make `main` locals `static` though?
Hh
The important part is that those are static *constants*. If you do `const int table[5] = {1,2,3,4,5};`, you are initializing an immutable table at run-time with compile-time constants. If you do `static const int table[5] = {1,2,3,4,5};`, you are initializing an immutable table at compile-time. When the table is initialized at compile-time, it simply *exists* when the program is loaded. If the table is initialized at run-time, the function must run code that allocates storage for the table (from automatic storage i.e. stack in this case), and then deposits the values into that table one by one, and at the function exit, also disposes of the storage allocated for the table. 
Thank you! I got the files and made an [issue on GitHub](https://github.com/quicktype/quicktype/issues/270)
&gt; class/struct types as non-type template parameters I think the link is broken, and I'm interested by that, do you have a working link ?
The link for "Floating point std::atomics" (https://wg21.link/P0020R6) returns a 404
&gt; you are initializing an immutable table at compile-time. Hm, no. I think this is wrong. It's just so happens in this particular case, because table is of simple type and can be optimized. Not sure why compilers other than clang fail at doing so for non-static table, but it's their problem. AFAIK, `static` local variable only means that it's initialized once. So if the function is never called it might never be init-ed. Or if it's called repeatedly, it's constructor would only run once and it'be shared among different calls. But this incurs additional penalty since it's guaranteed to be thread-safe. But in this case, I guess, static just makes compiler think that the table isn't going on the stack and since it doesn't need to be the same among all function calls (since `const` doesn't really guarantee constness) it can safely init it in compile-time. If you replace int with something that can't be obviously compile-time initialized you'll see that `test2` code is much worse: https://godbolt.org/g/PYpdea Hence why I had this question. Though I haven't really checked the standard, so I might be wrong)
Literal types in fact do get special treatment here; using `static` is necessary to qualify the variable for [constant initialization](http://en.cppreference.com/w/cpp/language/constant_initialization).
For "Interpolation for numbers and pointers" I would prefer "lerp" not "lint". 
I understand what you mean. Still, the library is more than a simplistic GMP/MPFR wrapper. In particular, substantial code and optimisation efforts have gone in the small-object optimisation, in the re-implementation of basic numeric primitives for 1-2 limbs operands, and in the design/implementation of the API for the real class (which ends up being quite a different beast from mpfr_t). So there's a non-trivial amount of header-only code :) In principle, one could adapt the same ideas/optimisations using a different backend from GMP/MPFR (e.g., Boost multiprecision). I wouldn't oppose work by others in this direction, but I am not going to do it myself right now because: a) mp++ is currently a one-man project and I personally have other priorities at the moment b) GMP/MPFR are the golden standards for multiprecision arithmetic, and, for a performance-focused project, they are IMO the most sensible choice. I would rather focus on making sure that mp++ uses them as effectively as possible rather than having to spend time supporting multiple backends purely for licensing reasons (with that said, PRs are always welcome!). (I understand that people have different (strong!) opinions about licensing, and that's fine. However I must say that I disagree with the (frequently repeated) notion that the LGPL license of GMP/MPFR prevents them from being usable in a commercial context. GMP, for instance has been included in Mathematica and a bunch of other commercial CASs for many years now) 
That’s because it’ll be in the post-meeting mailing. To access the latest published version of a paper via wg21.link, omit the revision number - here, omitting R6 will take you to P0020’s last published version R5.
Just for the record, the script I use to generate the HTML table output flipped the test results so the times I provided are actually for the DNS test (third one). It still works faster on the other two but not by that noticeable amount.
Thanks for the kind words! Math and storage are indeed separated in GMP (see the low-level mpn_* integer functions in the GMP documentation). In MPFR there's something similar with what they call the "custom interface", which allows you to init mpfr_t object using externally allocated storage (you can then use the usual functions from the MPFR API on these externally allocated mpfr_t, as, contrary to GMP, MPFR functions usually do not need to do further memory manipulations on initialised mpfr_t objects). It would be interesting to have some primitives in the standard for doing low-level multiprecision computations, it may be a good starting point for a gradual introduction of higher level multiprecision facilities. I took a look at the tr29124_test repo and I must say I would really really really love to hear your feedback about the design of the real class in mp++. One of the design goals I have with the floating-point classes (real128 and real) is to facilitate generic implementations of special functions that can work with arbitrary floating-point types. Indeed, I have dabbled in the implementation of special function myself when I needed Weierstrass elliptic functions for my research: https://github.com/bluescarni/w_elliptic (I plan to get back to this once mp++ has support for complex types) Please let me know if/when you start using mp++, I would be very interested in hearing what you have to say (PM, or just come over to the mppp gitter channel at https://gitter.im/bluescarni/mppp).
It would certainly be possible in theory: there's nothing magical to Rust after all. The borrow checker essentially relies on two properties of the Rust language: - the absence of data-races, - move semantics, tracked at language level, - lifetimes. Lifetimes are certainly the easier; it would suffice to annotate types and functions with a specific attribute which tie the lifetimes together. Similarly for move semantics, an attribute on the type enforcing that its move operations follow certain guidelines. And of course, data-races would have to be addressed in a similar fashion. --- However... it would not be a drop-in. There is an inherent trade-off in type systems: the more constraining they are, the more likely they are to reject perfectly fine programs. Many C++ programs in the wild now cannot be converted as-is to a Rust-like flavor, because they rely on pervasive mutability to work (and they do work!). Converting them would not only require annotating them, it would also require changing their architecture to a degree. And it may not be obvious what to convert to: by virtue of being a relatively young language, Rust's idioms are few and far between. Now, I would not want to sound to pessimistic. Rust has kicked the hornets' nest, and the C++ community has risen to the challenge: the C++ Core Guidelines already define a number of automatable checks that will go far toward making C++ programs more resilient. AFAIK they are limited to intra-procedural checks for now, but it's always better than nothing!
 [&amp;](auto&amp;&amp;... args) noexcept(noexcept(obj.func(std::forward&lt;decltype(args)&gt;(args)...))) -&gt; decltype((obj.func(std::forward&lt;decltype(args)&gt;(args)...))) { return obj.func(std::forward&lt;decltype(args)&gt;(args)...); } Down to: [&amp;](args...) =&gt; obj.func(&gt;&gt;args...) That's what I call a haskell of life improvement.
I wonder why noone has mentioned `int` result as an archaism. The standard defines just `EXIT_SUCCESS = 0` and `EXIT_FAILURE`, everything else is unspecified behaviour. How often do you see `return EXIT_FAILURE`? Pretty much never. In my opinion, the perfect signature of main is: void main(); Call `exit(int)` when you need to exit with non-zero code.
What was the committee's opinion on abbreviated lambdas and forwarding without forward? I think that these papers are essential to reduce the insane boilerplate related to forwarding and code triplication (for noexcept and SFINAE). Please give us good news...
First of all, you can still do the same with `auto`: auto C = MatrixXd(A * B); Secondly, you can do even better without stating the type! auto C = (A * B).eval(); It also works for fixed-size matrices and reflects the meaning correctly.
Good to know! Another `static` thing to keep in mind =) Though it looks like it's still not guaranteed &gt;it `may` be performed at compile time.
Paging /u/je4d, who is the author.
Fixed.
Paging /u/je4d, who is the author
`std::expected` finally happening!
It was a late paper, so not in the pre-meeting mailing. There's a copy at http://je4d.s3.amazonaws.com/D0732R0.pdf. It might not be quite the latest. I'm out at the atomic history museum atm. I'll re-upload when I have my laptop and some wifi again.
Thanks for pointing this out. I consider attribute as some kind of compiler magic. What I was thinking was something like "= default" that let compiler generate some code for me. Not the current function, but the other comparison operators that make use of the current option. I guess attribute may be used for this purpose as well but correct me if I'm wrong.
+1 on metaclass as it does exactly this job, but do we need a not-so-perfect solution right now? Also the fear of attribute is unnecessary. IIRC the "override" keyword was originally an attribute, but changed to the current status for exactly this reason. Though we still depend on attribute for other cases like [[nodisregard]] and [[fallthrough]] anyway.
Great post, thanks for taking the time :) Some exciting stuff!
I wasn't really talking about the guidelines, because I really don't think the lifetime safety stuff is equivalent to a real borrow checker.
This is best I could do until now. https://godbolt.org/g/Z86YZU Using __builtin_constant_p() for Clang. 
Don't quote me on this, but I believe the forwarding one went well and the abbreviated lambdas didn't progress much. Even with the distinction that `=&gt;` implies that a parameter list of `(T)` means that there's unconditionally a parameter `T` and not an unnamed parameter of type `T`, I've already seen concerns about how it's inconsistent with what we have today.
Sent to LWG doesn't mean happening, it means `std::expected` made progress.
He, well fair enough. How the standard works and how to track progress is still all a bit mysterious to me. Any progress is good I guess.
I thought Keras relies on back-ends like Tensorflow. How can you reproduce all that in one header only library? 
Here's the latest: http://je4d.s3.amazonaws.com/D0732R0-wip.pdf It'll likely change again to include more wording before the post-meeting mailing. - Jeff
Most of these give me a big "meh" response. Educate people on when to use, and why. With the exception of using `new`/`delete` at all (and possibly "deep hierarchies") all of these have their time and place. Pimpl, virtuals, shared_ptr, singletons, get grossly overused in practice. People need to learn the downsides and also what would be a good reason to use them
/u/blelbach, can you update the link in the post?
Or if anyone had experience with template expressions. The same pitfalls occur in all of these (any template expression that can contain literals/state)
I like the type deduction, but the syntax is completely different from anything else in C++. A lot of these problems seem applicable to template functions, too. It would be nice to have a fix that works for both. Could we maybe introduce something like noexcept(auto)? I'm also a little unclear why decltype(auto) has to be replaced with decltype(&lt;return statement&gt;). Apparently, there's some cases where the former would fail to compile while the latter would succeed, but can't we just make decltype(auto) friendlier? Improving std::forward might be nice, too. From what I understand, std::forward needs the decltype of the expression explicitly passed as a template parameter because references are stripped before argument type deduction. If there were a reasonable way of opting-out of that, we could make forward easier to use in any context. I see that the "Return type deduction and SFINAE" suggests allowing this new syntax for all functions. That would make things consistent, though I'm still not enthusiastic about having to teach people yet another way of doing the same thing. That said, the defaults for lambdas definitely seem a little wrong for generic functions and a new syntax would allow you to change those without any possibility of breaking anything.
&gt; I'm also a little unclear why decltype(auto) has to be replaced with decltype(&lt;return statement&gt;). The latter SFINAEs. Doing that in `decltype(auto)` is a breaking change in that a hard error now SFINAEs, which isn't necessarily always wanted. It would also leave you with no way to get the old behaviour. 
I'm afraid it will be as intrusive as CRTP. Also I like the ability to tell apart strong, weak, and partial ordering. It allows me to easily tell if a type can be used in an algorithm.
I'm afraid it will be as intrusive as CRTP. Also I like the ability to tell apart strong, weak, and partial ordering. It allows me to easily tell if a type can be used in an algorithm.
&gt; It also has the advantage of being able to preserve non-ascii/current code page command line arguments based on the individual implementation. I would argue this is only an advantage to platform vendors, it's really unfortunate there's no "easy" way to get UTF-8 arguments no matter what. (Unless I'm not aware of this functionality?). I'd love if a future version of the proposal added some way to make that guarantee. 
I fully agree with you, and note that I didn't accuse the library of having no merit or valid reason for existence, and I apologize if my previous comment gave that impression. I just meant that presenting it as a "header-only multiprecision arithmatic library" is misleading as that positions it as a GMP/MPFR alternative, which it isn't.
u/blelbach small correction: default-constructible lambdas were actually voted into the working paper. The proposal went through both EWG and CWG this week.
If by the forwarding one you mean p0664, that kinda failed too. We voted the proposal down, and discussed using a keyword instead - which people mildly liked in principle, but all of the candidates for that keyword got voted down. I'm not sure that an acceptable keyword exists.
Just as you expected!
no.
Done.
Will we see spaceship operator implemented in major compilers soon? It looks reasonably easy to implement.
What's the status of `span`?
Rust doesn't have spaceship operator, too. In Rust, we could just #[derive, then we get what we want. 
Needs to be revised, we will bring it back to Jacksonville.
Could the committee place all proposals in GitHub and open issues for each proposal which track the status of the proposal?
This is theft. You are saying "if someone took my wallet, they don't have to give it back until I ask for it." How does it become the responsibility of the victim? You know this is something you'd be punished for, which is why you're using a throwaway account on Reddit and GitHub.
I wonder what will happen if I use `a &lt;=&gt; b` without including the standard header that declares `std::strong_ordering` et al. Will it be ill-formed? Is a diagnostic required?
The `=&gt;` syntax restricts the body to only one expression. Otherwise we need to debate on whether C++ should allow SFINAE on the whole function body that may contain arbitrarily complex statements (which seems nice, but is apparently very hard to implement).
SFINAE for tuple get... Yes!
I simply reimplemented all the needed operations (e.g. [convolution](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/convolution.hpp)). :-)
I would love a GitHub-centric workflow, but I believe some people are uncomfortable with having to sign up for any kind of account.
Completely agreed. In fact this is the first time I've seen lint used in this context.
Thank you both !
Very disappointing. Is there any chance for abbreviated lambda syntax at all? I have the impression, that Everytime someone purposes a way to make day to day c++code more readable there come forms of naysayers complaining that without all the boilerplate c++ doesn't look like c++. So instead of making the syntax for lambdas in the default
Are there any plans to replace the deprecated `&lt;codecvt&gt;`?
Great stuff! Note that resharper C++ has some support for free functions, but it seems to not support function templates struct C { int a = 0; }; int foo(C val){ return val.a ; } template&lt;typename T&gt; int bar(T val) { return val.a ; } inline example(){ C c; c.foo // completes to foo(c); c.bar // the template is not found, no bar(c); I would like to be able to *type* `container.std::begin` (tab) `.std::nth_elem` (tab), and have that expand to `std::nth_element(std::begin(container)`.
I believe with lamdas in unevaluated contexts you can now already do this: auto foo() -&gt; decltype([](auto const&amp; v) { &lt;complex code here&gt;; }(std::declval&lt;bar&gt;())) { // do smth }
My coffee is really hard to read until I drink some code
is there any progress in the view adaptor proposal?
It's the cost of a short sintax
Thanks for the response; I can confirm that the videos are entertaining in the format the they follow right now. I'll be sure to have a look at your NES emulator. Keep up the great work man.
What is with lamda templates? I would like to write []&lt;typename T&gt;(std::vector&lt;T&gt;){} but it is not standardized.
Is the following snippet valid in C++20? auto expr = decltype([]&lt;class... Ts&gt;() requires requires(Ts f) { f(); }... {}){}; 
Yes, (un)fortunately it does not SFINAE according to P0315R3.
Not the author, but I use this framework (http://ehiti.de/machine_objects/) and I'm quite happy with it. What are the strong point of boost::statechart? 
[You sure you can't do that?](https://godbolt.org/g/1vPLgU) :P
Using -Wpedantic: warning: ISO C++ does not support lambda templates [-Wpedantic] []&lt;typename T&gt;(std::vector&lt;T&gt;){};
What was the problems with these proposals?
Not sure what that's about (maybe it was just preliminary support before standardisation), but lambda templates are definitely in: See [[expr.prim.lambda]](https://timsong-cpp.github.io/cppwp/expr.prim.lambda) and [[expr.prim.lambda]p5](https://timsong-cpp.github.io/cppwp/expr.prim.lambda#5).
So this could be a gcc pedantic bug?
It was accepted in C++20 at the previous committee meeting, but compilers don't implement it yet. Well, g++ has it, but because it was considered a GNU extension; the warning should be gone in GCC8 in -std=c++2a mode.
Is there a paper describing more than just the wording for atomic floating point values? Just as with the new execution policies, users need to understand that the results are usually not deterministic.
Guess so.
clang tidy should have some checks.
I had a look at the documentation and quite like the style. Good minimalistic examples! Is there an ebook file (or pdf) for this?
Ok, but Tensorflow is a huge project, no? And you just reimplemented it in a header only lib? There's gotta be a caveat here. Don't get me wrong; this is still impressive even if some corners had to be cut.
&gt; So why is there no GC++VM (GnuC++VirtualMachine) or something like that? I see two problems: First I am not sure that you can be standard compliant if you don't output machine code. (Since C++ can take pointers to arbitrary function and execute them, you would have to find a way to differentiate between bytecode pointers and actual machine code pointers) Second, I don't think there is a demand. I think most peoples choose C/C++ because they don't want to pay the a VM or want to use some specific hardware feature. 
There is no need. C++ is platform-independent. You write once, compile everywhere. You can use Cling for JIT compilation. And there is no "easy" platform-independence, even with Java, if you do not debug for each different virtual machine you are bound to face problems anyway. (fortunately not for each browser as well anymore) 
I don't understand what exactly you are looking for. Is it LLVM? LLVM is "Low level virtual machine". I doubt it's what you need.
I presume he means a Virtual Machine like the Java bytecode interpreter. LLVM is not really a virtual bytecode in the same way - the details of the target implementation leak up into the intermediate layers if I recall correctly, so it’s not really possible to output 'llvm bytecode' and run it where ever you like on an llvm bytecode interpreter because no such thing exists. (Happy to be corrected on this, but that’s my understanding of where things stand right now.)
I think he only reproduces the Tensorflow ops that Keras needs, not all 1 million LoC.
People generally use C++ because they need high performance applications or libraries, and despite all the optimizations made to JVM runtimes, they still can't beat native compiled code. C++ has a good balance between the high-performance characteristics of C and programmer protecting abstractions. If they were fine with using a virtual machine and sacrificing some performance for ease of deployment, they'd probably just use Java or C#. What you're asking is "Why isn't C++ used more like Java?" I think the simple answer is: Because we already have Java. 
A standard VM only gains you instruction set Independence, which is 1% of the way towards platform independence. Anyway, C++ already has that 1% covered, since you can compile your code multiple times with different compilers. A platform consists of devices, drivers, conventions, user expectations, wildly different ways of gluing things (like displaying your items in a context menu) etc.
LLVM does not stand for "low level virtual machine" anymore.
No corner cutting was needed. :-) As /u/fg-flat already [pointed out](https://www.reddit.com/r/cpp/comments/7c91n0/frugallydeep_a_headeronly_library_for_using_keras/dppefcs/), it was just the stuff needed for Keras. I also do not yet support all layer types (only the common ones) and back propagation was left out completely, since only forward passes are supported. Also there are no optimizations for GPUs, distributed systems, different CPU architectures, no alignment, SIMD, kernel fusion etc. Some of the implemented operations are [convolution](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/convolution.hpp), [matrix multiplication](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/tensor2.hpp#L95) for e.g. [dense layers](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/layers/dense_layer.hpp), [batch normalization](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/layers/batch_normalization_layer.hpp), pooling variants (e.g. [max pooling](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/layers/max_pooling_2d_layer.hpp#L27)) and some activation functions (e.g. [selu](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/layers/selu_layer.hpp)). The most tedious part of it was to get the corner cases not only right, but equivalent to Keras. Frugally deep has the aspiration to not only calculate the results correctly from a theoretical point of view, but to return the exact same values as your model in Keras does. Keras/Tensorflow does some strange things, for example use different paddings in a convolution depending on if it comes from Conv2D or [SeparableConv2d](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/layers/separable_conv2d_layer.hpp#L69), for no obvious reason. Also these things are handled different if run on a CPU or a GPU. So [the conversion code actually checks all these things](https://github.com/Dobiasd/frugally-deep/blob/master/keras_export/convert_model.py#L295) to make sure the automated tests pass. :)
Why do you want a VM? Size of your integers and similar implementation details have very little to do with portability. You want to take care of wildly different APIs provided by different platforms. Threading, networking, graphics, filesystems, this kind of stuff. You want to wrap them all in a common platform-independent interface. And it doesn't matter much if you do it for a VM or for native code. A VM also buys you transportable binaries, but there's little sense in having *unsafe* transportable binaries. Either the VM defines all of the undefined behaviours of C++ (and has unacceptable performance overhead because of that), or you are no better off with the VM than with native code. 
CLIPP is a single header library for building command line interfaces. It also generates usage lines and per-parameter documentation with custom formatting. Simple interfaces with a few options can be set up with a few lines of code and almost no boilerplate. At the same time it allows for building complex interfaces with arbitrary numbers of values per parameter, grouping, multiple nested alternatives, (generalized) joinable flags, repeatable groups, controllable paramter matching order, custom value filters, full control over flag prefixes, optional error checking, ... CLIPP doesn't have any dependencies besides the C++ standard library; the minimum required standard is C++11. The documentation is written in an example-oriented style. The repository does also contain numerous examples and a Doxygen file.
No worries, apologies if I sounded a bit on the defensive side :) I'll try to reword the introductory text for the next version, in order to convey more clearly what the library is.
The abbreviated lambda paper did not have consensus at all. There is a desire for shorter lambdas, but it is really hard to get any kind of agreement on what that shorter syntax should be, and what the syntax should expand to.
Abbreviated lambdas had (at least) a couple of issues. Here are the two I remember right off... 1. The default deduced return type for regular lambdas is a value, but the abbreviated lambda paper switched it to a reference. This wouldn't be a huge hurdle. 2. The noexcept semantics are very difficult to implement with captures.
Any plans for String CaseInsensitive comparetions?
Sorry to disappoint, but the paper was merely discussed. It likely needs another revision, then discussion in LEWG and LWG before getting put in the working draft. Also, that paper is trying to fix (what was perceived as) a very corner case issue. Inheriting from a tuple *and* providing a get overload isn't a super common use case.
Man, this looks really nice. I'm always on the hunt for better C++ argument parsers, and this one looks fantastic.
Its a compile time library and easy to use(Provided one is familiar with CRTP template syntax Scaling the SM is extremely easy Performance wise, its awesome..
To my knowledge, almost everyone wants *something* to fix this, they just don't agree on the details. So yes, I'd say there's a good chance that it will go through eventually (like `variant`).
Sorry for that mess in my comment - completely forgot to check what text the auto completion engine deduced from my swipe gestures.
Thanks for the clarification. 
Not so much a bug as lack of C++20 support. It's simply that no one has gotten around to changing the extension into an actual language feature.
Not yet.. still in construction stage, hopefully will have one in couple f months or so
I had a quick look at building the tests with Visual C++ 15.5 P3. First, `&lt;functional&gt;` is missing. Then, I had to disable the `const char*` overload of `parameter::parameter()` because it made some calls from `option()` ambiguous. There's a whole lot of templated constructors in there that have similar parameters, but I didn't spend time trying to figure it out. Building with /Wall, I'm getting type conversion warnings, such as in `make&lt;float&gt;::from()` and the many `begin() + i`, where `i` is unsigned. I also get a few about conditional expressions, but you're saying it's C++11, so that's fine. Unfortunately, I can't run the tests easily because every file has its own `main()` and you seem to be using a handrolled python script with a hardcoded `g++` in there. Anyways, interesting looking library. I'm not a fan of the operator overloading, like`%` (is it for a description? for values?), but it seems concise and well documented.
Actually there are at least two VMs for C++. .NET has C++/CLI. IBM i has TIMI for all programming languages, including C++.
&gt; Size of your integers and similar implementation details have very little to do with portability. This might just be the answer. Maybe i'm overestimating the effort it takes to target different platforms. I never really used c++ for more than getting introduced to oop before switching to java entirely.
Ok, but isn't there still soom room for a faster "less secure" java that lets gives you more power over your code at greater risk? From my experience java is just a c++ with training wheels left one, except that in most applications the greater freedom gained by removing the training wheels actually isn't worth the increased risk. Tough i have to say that i never used c++ for serious development beyond exercises.
I mean't easy as in "as easy as it gets". There is only so much abstraction a VM can do, before you run into difficulties on the various platforms.
Pretty sure you can't have pack expansion around a requires clause. But you can put it inside and fold over a comma. Relevant snippet: requires (Ts... f) { (f(), ...); } Other than that, yes.
Looks good. I am currently loking for a default go to libray for cli tools. How does it compare to Clara. They look very similar: https://github.com/philsquared/Clara/blob/master/README.md
I'm a game developer by trade. In general, the bulk of the industry uses C++ for game development due to its performance characteristics, as well as the fact that there's a massive C/C++ ecosystem in place (existing code, middleware, compilers, platforms, etc). But it's also not uncommon for high-level game code to be scripted using Lua, C#, Java / Groovy, Typescript, or for me, my own little language [Jinx](http://www.jinx-lang.org/). For tools, it's pretty common for them to be written in C#. Developer typically have fairly beefy machines, so performance isn't an issue. And since the development environment is nearly always Windows, portability really isn't a factor. I use C# instead of Java, but I think they share many strengths, and chief among them is improved programmer productivity. So from my own perspective, at least, I can't really think of a situation where I'd need something halfway between those two. Any time performance isn't a critical factor, people tend to use languages which are a bit more developer friendly or simply quicker to iterate on, since C++ compile times are always terrible due to the complexity of the language.
I'm on mobile so I could be wrong but the run_tests python script seems to accept options for cflags/setting compiler
WebAssembly aims to provide a VM target for languages like C and C++, in addition to other languages. Currently most use it to run C/C++ code in the browser, but it was designed to be used in non-web cases as well. That said, it doesn't map its semantics to C++ directly -- in particular it is designed to have as little non-determinism as possible without sacrificing too much performance. So, for example, `5 &lt;&lt; 100` is undefined behavior in C++, but the equivalent in WebAssembly is defined as masking the shift amount. It's also designed to be safe, in the sense that a WebAssembly VM can only affect its host environment through ways the host specifies. There are instructions to access memory, but they are only allowed to access memory inside the VM. Out-of-bound accesses trap, or halt the execution of the program.
&gt; Maybe i'm overestimating the effort it takes to target different platforms well, basically none unless you're including "random 70 cubic meter computer-room from the 70's" in the "different platforms". C++ code "just works" everywhere.
The big problem is that Rust has a different concept of move than C++. In Rust if you do this a = move(b); // NOTE: pseudocode, not syntactically correct then it is guaranteed that `b` no longer has anything in it. For the equivalent C++: a = std::move(b); there is no way to know (in the general case). `std::move` does not move anything, just flags the variable as _can-be-moved-from_. The actual decision on whether the move happens at runtime (again, in the general case). This makes the work of the borrow checker harder, because the contents of b might go into a or remain in b. It might even happen differently every time this line of code is executed.
Assuming the newer previews have had updated C++ bits, any chance of getting a more recent build on vcppdogfooding?
C++ is defined by help of an abstract virtual machine. Compilation to native code is just a detail.
Nope. Check visualcpp.myget.org. I'll add details when I get to a computermachine. 
Where it just so easy. Almost any non-trivial code that wasn't specifically written with portability in mind calls platform specific APIs and/or makes assumptions about the underlying platform (e.g. size of int, size of a pointer) and most of the time it also relies on some form of undefined behavior that happens or is guaranteed to work for some target platform. This is a far cry away from the portability that Java offers (even ignoring the JIT vs normally compilation asppect). That being said, when you do consider Cross-Platform development from the beginning (meaning you pick the right libraries and compile+test your code regularly on all platforms, writing portable c++ code is much easier than it used to be.
C++/CLI is not c++.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7ch4ns/what_would_the_proposed_c_module_ts_solve_or_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; or makes assumptions about the underlying platform (e.g. size of int, size of a pointer) a I honestly never saw code doing this outside of IOCCC or 1990s libraries and certainly never had to do it myself out of hundred of thousands of line of codes written. The main app I work on compiles cleanly to every relevant desktop &amp; mobile platform without any hackery such as this (except, okay, I concede, one relevant ifdef to allow for the global menu bar on macos), and is nearing 500kloc. &gt; That being said, when you do consider Cross-Platform development from the beginning (meaning you pick the right libraries and compile+test your code regularly on all platforms, writing portable c++ code is much easier than it used to be. well yeah. You can also write platform specific code in Java for instance by using OS-specific libraries like [this one](http://jawinproject.sourceforge.net/) or [this](https://github.com/iterate-ch/rococoa), it doesn't mean it's a good idea either but sometimes you have to. 
It is as much C++ as g++ and clang are C++. https://gcc.gnu.org/onlinedocs/gcc/C-Extensions.html#C-Extensions https://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Extensions.html#C_002b_002b-Extensions https://clang.llvm.org/docs/LanguageExtensions.html I could gladly present examples from other compiler vendors across comercial UNIXes, mainframes and IoT. For some strange reason, Microsoft is the only company is bashed for having C and C++ extensions, while other compiler vendors are praised for having them.
Ooh, I hadn't stumbled across that one yet. Thanks!
&gt; I do not know whether modules will make the feature cutoff for C++20, but a lot of people are working hard to maximize the chances… we’ll know in another 12-18 months when we reach the C++20 feature cutoff. Oh :( Looking forward to see it happen.
Definitely off-topic, but you're the only one I can think to ask..: Any idea what happened to ci2.dot.net (/dotnet-ci2.cloudapp.net)? The daily F# builds were hosted on that domain and it seems to have disappeared. :-S
I failed to understand if boost::statechart allow to build hierarchical state machines like the Machine Object framework above. 
This library only does inference, you can't train with it. That's one big difference. It means it can be much smaller. It's for deploying models, not training.
Trying to grab the dailymsvc release from [here](https://visualcpp.myget.org/feed/dailymsvc/package/nuget/VisualCppTools.Community.Daily.VS2017Layout) using the command from the NuGet (PowerShell) tab in a PowerShell window results in the following error: PS&gt; Install-Package VisualCppTools.Community.Daily.VS2017Layout -Version 14.11.25906-Pre -Source https://visu alcpp.myget.org/F/dailymsvc/api/v3/index.json Install-Package : No parameter with the name "Version" found. + ... -Package VisualCppTools.Community.Daily.VS2017Layout -Version 14.11.2 ... + ~~~~~~~~ + CategoryInfo : InvalidArgument: (:) [Install-Package], ParameterBindingException + FullyQualifiedErrorId : NamedParameterNotFound,Microsoft.PowerShell.PackageManagement.Cmdlets.InstallPackage I'm guessing the parameter `-RequiredVersion` was intended. Trying to run it with that instead results in: PS&gt; Install-Package VisualCppTools.Community.Daily.VS2017Layout -RequiredVersion 14.11.25906-Pre -Source http s://visualcpp.myget.org/F/dailymsvc/api/v3/index.json WARNUNG: Unable to resolve package source 'https://visualcpp.myget.org/F/dailymsvc/api/v3/index.json'. Install-Package : For the given search parameters and the package name "VisualCppTools.Community.Daily.VS2017Layout" no match was found. ... + Install-Package VisualCppTools.Community.Daily.VS2017Layout -Required ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ObjectNotFound: (Microsoft.Power....InstallPackage:InstallPackage) [Install-Package], Ex ception + FullyQualifiedErrorId : NoMatchFoundForCriteria,Microsoft.PowerShell.PackageManagement.Cmdlets.InstallPackage I also decided to try with the PowerShellGET method. Adding the repository was successful, but trying to install results in this: PS&gt; Install-Module -Name "VisualCppTools.Community.Daily.VS2017Layout" -RequiredVersion "14.11.25906-Pre" -Re pository "dailymsvc" Install-Module : Argument transformation for the parameter "RequiredVersion" cannot be performed. The word "14.11.25906-Pre" cannot be converted into type "System.Version". Error: "Wrong format." + ... munity.Daily.VS2017Layout" -RequiredVersion "14.11.25906-Pre" -Reposi ... + ~~~~~~~~~~~~~~~~~ + CategoryInfo : InvalidData: (:) [Install-Module], ParameterBindingArgumentTransformationException + FullyQualifiedErrorId : ParameterArgumentTransformationError,Install-Module I'm guessing I'm doing something stupid. Most of the references and guides I can find are intended for C#. Is there a tutorial somewhere from start to finish on how to grab and use such NuGet packages? NOTE: I use Windows in German for learning purposes, so I had to translate the errors into English. Apologies if they make no sense.
Hi, really nice! Thanks for making this public, header-only, and free of dependencies! One question though: &gt; Currently frugally-deep is not able to keep up with the speed of TensorFlow and its highly optimized code, i.e. alignment, SIMD, kernel fusion *and the matrix multiplication of the Eigen library.* Why don't you just use Eigen? Eigen is header-only too, and widely used in the scientific community. Most people who do anything scientific in C++ are already using Eigen, and it's also header-only, so it doesn't add a dependency. It would be hugely beneficial. You could even think about using the Eigen Tensor stuff, I think Google is using that for TensorFlow. But at least the matrix/vector parts I'd use.
I've sent mail to Immo Landwerth, .NET Burgermeister, with this question. 
What are the advantages over: http://optionparser.sourceforge.net/
I'm sorry, I can't be much help. I'm not much of a NuGet expert at all, and I only ever use the IDE to install packages. I've tested that the most recent package (25907) installs correctly, and we haven't had any bad packages since automating the creation, but I don't know much about PowerShellGet or such. Two suggestions: https://www.reddit.com/r/NuGet/ or page /u/RoSchuma.
Thanks for the feedback. At this stage I didn't pay any attention to MSVC compatibility; maybe I should do something about that in the future. It's funny hat MSVC warns about things that gcc doesn't seem to care about at all. And I compiled with -Wall -Wextra -Wpedantic. About the operator overloading: I was a bit conflicted about that, too. But you don't need to use any of the operators. For every operator construct there is an alternative function / member function. 
If one or the other is a type that defines `operator&lt;=&gt;`, it will have included `&lt;compare&gt;` already. But also... don't use `&lt;=&gt;` directly.
Can you publicate the main header to a code review tool? It would make the suggestions and issues transparent :) 
I've also updated vcppdogfooding. Do me a favor when you have a chance--go into VS and try to install a package from there. See if it's obvious enough : )
MSVC is focused on finishing C++17 features first (early 2018, hopefully) and then we'll start on C++20 features. I imagine /u/STL will ~~nag me endlessly about~~ provide motivation for this feature so it might be an early one in our compiler. 
Since I have no good answer to your question, you are very likely right with your suggestion. ;-) I will have a look into Eigen, and check how I can integrate it. Thanks for the hint. I will let you know about the results.
The library part no longer appears difficult to implement, but aside from the deprecation of rel_ops (which I can do independently), we don’t need it elsewhere in the library, so I don’t consider it ultra high priority. I’ll let the compiler team figure out how to prioritize it for our users. Only for features with special library impact do I try to override the usual prioritization - in C++20 it looks like my “burn the world” feature will be empty member optimization.
That’s the only paper.
The optionsparser - well is just that. You can't build more complex interfaces with it (commands, options with exactly n values, ...). Plus, you have to query the parse result separately. My approach is to "connect" the target variables directly to the command line parameters. Apart from that I find the interface of the optionsparser ugly as hell (looks more like a C lib IMHO), but this ist just my personal taste.
Yeah I'd say so
Have you thought at all about configuration file support? Often when I'm developing quick little command line tool, I want the same set of options to be available on both the command line and in a configuration file. It would be really nice to only have to specify the options in one place in the code and be able to parse both the command line and config file.
Looks cool, probably will swap out tclap with this library
According to my limited understanding, some of the main potential improvements are throughput, cleanliness, and clarity. * Throughput - modules have the potential to lead to faster compile times, compared to headers (even with a decently designed system of precompiled headers). * Cleanliness - in a header world, if I’m working on a header-only library and I need something else (a class, a function, etc.) I need to drag in its header, which is then transitively available to my users. With modules, I don’t have to export my implementation details (regardless of whether they’re classically included or imported from other modules). * Clarity - possibly most relevant to the STL, which tries to immunize itself from user code as much as possible. We must defend ourselves against user macros, which makes all of our internal identifiers `_Ugly`. In a modules world, this is unnecessary. (We’ll probably still need to defend ourselves against unintentional ADL, though.)
Not yet, to be honest. A CLI -&gt; config file conversion facility wouldn't be so hard I guess. Writing a parser for config files would probably be the tricky part. I'm wondering: What kind of config file format would you suggest? I would either favor JSON or probably something even simpler. It would definitly be nice to have something like that. If more people want such a thing I will consider implementing it.
&gt; Apart from that I find the interface of the optionsparser ugly as hell I'm right there with you on that one. Seems cool, I'll try and remember to try it out for my next c++ project.
The stanard doesn't have a way to get that information. MSVC apparently has a few alternate main signatures that allow you to get that information. Unfortunately, Linux/other OSs don't really have a way of doing that either. A future proposal wouldn't be able to guarantee that, as the C++ committee has no ability to control the OS like that sadly.
Can the committee really not add functionality for converting between ~current code page~ to utf-8 and then add a signature that admittedly does more work (so there's a cost associated with using this signature, but it's opt-in) by using that functionality? I've looked at the main stuff a little bit in the standard, but I'm not entirely sure what prevents the committee from doing this. Unless it's just a large contingent of platform vendors voting against it. The MSVC signatures are not what I would call fun to work with, but I do use them when required. Mostly just to call into my own "main" function. 
The description says Quick n' dirty...
The problem is that sometimes the conversion from current-code-page to 8 bit chars was lossy, so that information wouldn't be available anymore. The 'follow on' proposal to this main was going to be a number of conversion functions from this special 'implementation defined' types to a variety of others. It wasn't something I think I could mandate. It would be a "to_utf8_arg" type function that was free to return null/nothing if it was not successful. There IS a group looking into the unicode/alternate encoding strategies that was a big supporter of this proposal for this conversion reason, but it wasn't convincing enough for the rest of EWG.
Oh interesting. I've never heard of the lossy issue. Has anyone written a paper for it? What group is working on the encoding stuff? I'd love to follow their discussions if they have a group like the other SGs. Thanks for all the info by the way!
Looks very interesting! I appreciate that people are always working to make the ideal command line parser :). Recently, in projects that don't require boost, I've been using [CLI11](https://github.com/CLIUtils/CLI11), and have found it very nice. Any thoughts on how it compares to that?
INI tends to be my goto when using Boost.ProgramOptions when others will potentially be using it. I definitely like using JSON more, but the INI seems to cause less trouble for non-technical users to edit. The only real weakness of INI that I regularly encounter is arguments with multiple values dont map real well to the format (at least as boost goes about it). Thanks for putting this library out there! I will give it a try on my next project.
It's similar to needing the &lt;initializer_list&gt; header to use initializer_lists constructor overloads. So, to answer your question, yes it would be ill-formed if you even implicitly use the std::x_ordering etc. types without the header providing them (including using the &lt;=&gt; operator on pre-defined types). That said, similar to the initializer_list case, there will be some conspiracy between the libraries and compiler to provide useful diagnostics.
I actually stumbled across CLI11 while I was developing clipp. It's certainly feature rich. I find it's one of those libs where it's really hard to figure out what the actual CLI looks/behaves like by looking at the code. The examples provided in it's repo speak volumes IMO. I find the CL interface definitions written in clipp's style easier to read and understand. 
Cool! :-) It'll be great, but one thing to consider is that if you've got 3D convolutions, you'll probably need the Tensor module stuff. I'd really be interested in what the status of that is. It's still in Eigen/unsupported and has been there for a long while, but I do think that Google (or at least 1 guy there) is actively working on it. All the 2D vector/matrix stuff in Eigen is awesome but somehow using something in an "unsupported" header comes with a bad feeling, so if anyone on this sub knows more about what's going on with the Tensor module of Eigen, let us know, I'd love to know more about what's going on there.
I'm not bashing anyone - at least that was not my intention - but C++/CLI goes far beyond some simple compiler or language extensions as you find in clang or gcc - it is a complete dialect. The equivalent for clang's and g++'s extensions are the extensions the MSVC compiler provided in normal c++ mode. And the reason msvc got a lot of criticism in the past was not mainly because it had extensions, but because ms invested all those resources in developing and promoting their managed c++, c++/CLI and later c++/cx dialects, but had rather crappy support for standard c++ (As in, it could not compile lots of standard c++ code). At least as far as recent history is concerned, clang's and g++'s support for that was much better. With the latest updates to VS2017 Microsoft has finally cought up in that department and might even be better in areas (kudos for that monumental task).
Sorry, I couldn't find it in your readme, possibly my bad. Does it support multiple floating point values to an argument (negative and positive ones)? E.g. reading into a `std::vector&lt;float&gt;` from an option like `./myapp --vals -1.0 1.0 0.5 -0.2` (alongside other options, of course). If it supports this (boost::program_options does), and it would support VS2017 15.4 (or 15.3), then I would give it a try for my project!
I run my code through a relatively tough gauntlet, these are the g++/clang++ flags I use: -fdiagnostics-color=always -Wall -Wcast-align -Wcast-qual -Wconversion -Wctor-dtor-privacy -Wdisabled-optimization -Wdouble-promotion -Wduplicated-branches -Wduplicated-cond -Wextra -Wformat=2 -Winit-self -Wlogical-op -Wmissing-declarations -Wmissing-include-dirs -Wno-sign-conversion -Wnoexcept -Wnull-dereference -Wold-style-cast -Woverloaded-virtual -Wpedantic -Wredundant-decls -Wrestrict -Wshadow -Wstrict-aliasing=1 -Wstrict-null-sentinel -Wstrict-overflow=5 -Wswitch-default -Wundef -Wno-unknown-pragmas -Wuseless-cast 
Platform details are commonly baked in at the preprocessing phase (e.g. Boost.Config).
I still don't understand why we can't do some sort of `#import` thing which does all that without introducing some entirely new syntax which doesn't really jive with the rest of the language :/
I wonder if tricks like `decltype(1 &lt;=&gt; 1)` and `decltype(1.0 &lt;=&gt; 1.0)` will work, get used, etc.
&gt; which does all that without introducing some entirely new syntax which doesn't really jive with the rest of the language Can you be a bit more specific? If you don't want to export everything in a file, then you need a way to specify what you want to export and what not and there is not much more new syntax in modules than that.
You'd also have to check to see if such a practice would be compatible with ISO working procedures, would you not? 
C++ modules will enable faster compilers, by ensuring that each module interface can be precompiled, and ensuring that each file which imports the module can use the precompiled version. (This was tricky with C++ headers, because macros defined in one #include could change the meaning of later #includes, thus two different files including the same header might interpret it differently.) C++ modules will enable somewhat more modular encapsulation of C++ code, by saying what top-level declarations in the module are visible to importers of the module. **EDITORIAL**: I wish C++ modules supported per-member hiding of visibility, as explored in this paper from 2006: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2006.pdf. The real benefit of modules "in the large" will be **protecting library users from accidental dependence on a module's implementation details**. Most large C++ libraries use the "detail" namespace convention to inform users of this, which demonstrates the real-world need for this feature, and clearly establishes the inadequacy of "private:" and "protected:" for the purpose.
In your [most recent checkin](https://github.com/muellan/clipp/commit/6af6aabb15d2ebe5ec99752e570b9c578916f967), you're missing a bracket in `make&lt;long double&gt;`. Are you actually... building this thing?
Do you know if there is a technical reason the LLVM can't output JVM bytecode? (the same way it outputs x86, arm etc.)
Conversion from push_back to emplace_back isn't for any old call which takes a temporary. emplace_back is most useful for avoiding even creating a temporary, by forwarding arguments to the type's constructor. `vec.emplace_back(arg1, arg2, arg3); // args forwarded to constructor of the type held in vec, no temporary, no copies`
More often than not, auto makes refactoring easier. Type information propagates through the codebase and so types automatically change when, for example, a function's return type is altered. Though this is redesign, not refactoring. 
Are you asking about syntax or behind the scene mechanisms ?
All the normal reasons for using lambdas apply. C++14 already had templated lambdas ('generic lambdas'), the new feature is a generalisation. 
Just syntax sory for not specifying. For example, how do I call a function INTO main, using the variables defined in the second function?
I have been using the ITU/ISO/IEC one (what the reference encoder for AVC, HEVC and future encodings use) and it's quite good for this. It uses the BSD license, so no problem for using it in other projects. Check ["program_options_lite.h/.cpp"](https://hevc.hhi.fraunhofer.de/trac/jem/browser/trunk/source/Lib/TAppCommon) if you want to see. There is `parseConfigFile()` you can use for parsing the config file. The configuration file is simple to do, there's one argument per line, and each line looks like this: `BitstreamFile : str.bin`. The parsing itself is quite powerful, by default it will use streams to parse your parameters, but you can supply a function to do the parsing (like `[](po::Options&amp; options, const std::string&amp; in, po::ErrorReporter&amp;e){}`). I'd say the problem is it's not really C++17 or even C++11, so while it could be improved with new features like `stringview`, it won't because they still maintain compatibility with antiquated shit like VS2010. But I doubt performance is the issue for configuration parsing anyway.
I can't see why people are having trouble understanding you. Painful. 
Your language is not clear can you write an a code snippet of what you want to do ? You seem to be quite new to programming in general. I think you should pick up a C++ introduction guide instead of asking on reddit. You will progress much faster. cplusplus.com as one if you want : http://www.cplusplus.com/doc/tutorial/
Appears to be a dead project, but https://github.com/davidar/lljvm
It isn't always avoidable, which is why the feature was added. 
I think technically our P numbered papers aren't official papers at all. The only official thing are the motions that magically appear at the end of the week. So we could probably put them wherever.
is there any updates of operator dot
 #include &lt;iostream&gt; #include &lt;windows.h&gt; #include &lt;cmath&gt; using namespace std; int NumofWeeks = 0; int days; void giveWeeks(); void giveDays(); int main() { cout &lt;&lt; "Input a number of days: "; cin &gt;&gt; days; giveWeeks(); return 0; } void giveWeeks(int days) { if (days%7 == 1, 2, 3, 4) { NumofWeeks++; } else { } I'm in a computer Science course, and C++ is the first step! I can usually handle it myself, but looking at my textbook and online doesn't help. I need specific advice.. Basically, my teacher wants us ti get used to using functions. Calling them, prototypes, passing values. What I'm confused about is asking the user to read in a numver of days before that variable is being declared! (It's declared in giveWeeks). I'm supposed to be writing code that tells you how mamy weeks are in the amount of days the user put in, as well at te remaining days. But I'm not asking for help on how to silve the problem, I'm just confused on how to read in another function's value like that. He explicitly wants that.
I feel there are many things that shouldn't be in a header but core language features instead. Like `std::move`.
It should be one of the easiest to implement, so it should arrive soon. Especially considering how helpful a feature it is.
hiding macros and included deps requires compiler to do basically everything different. that's why imo you can't just add new preprocessor macro.
Never hurts to make sure, though, right? 
&gt; What I'm confused about is asking the user to read in a number of days before that variable is even declared The statement `cin &gt;&gt; days;` is reading into the global variable `days` which has been (and must have been) declared. It would be better if this was a local variable. It'll make the rest clearer. So pretend you have void giveWeeks(int numDays); int main() { int days; cout &lt;&lt; "Input a number of days: "; cin &gt;&gt; days; giveWeeks(days); void giveWeeks(int numDays) giveWeeks takes a parameter. When you call giveWeeks with the variable `days`, then the value of `days` is passed to the function. When the function starts, the parameter `numDays` starts with the value that was passed - the value of `days`. 
Strict testing should also catch the error because the result will be different.
But it's all the same variable. If I declare a variable days in main, that is a different variable than the one from the giveWeeks function...it would totally throw off the calculation.
It's not the same variable. Your global `days` and the parameter `days` are completely different variables with different life times. The parameter `days` can have the same value as the global `days` if global `days` is passed to the function, but only then. 
So I should have both the global and the local variable then? That's the only way I can think of "passing" the value.. but then what's the point of having a local variable?
the variable day that you have as global now should be a local variable in main. see my example above. You pass its value to the function by putting its name in the () when you call the function getWeeks(day) calls the function, passing the value of `day`
You pass the value with the following syntax: giveWeeks(&lt;some-value&gt;); Where &lt;some-value&gt;, in the case of this function, is an integer. It could be a literal, like this : giveWeeks(12); Or the value held by a variable, like this : int myVar = 23; giveWeeks(myVar); The name of your variable outside of the function doesn't have to match the parameter name. In fact, internally, when you call the function, something like this happens : int numDays = &lt;some-value&gt;; That is, your parameter named numDays gets assigned whatever value was passed when the function was called. PS : your prototype for giveWeeks is missing the parameter numDays.
One of the things I love about Haskell is how it side steps the value vs. reference problem thanks to its purity. C++ templates are is a purely functional sub-language by nature, and it'd make me sad to miss that opportunity. Though I appreciate that the issue is much more complicated than this simple perspective.
In the past I have inttentionally renamed types so that compilation breaks where the declarations are used so that I can review how that type is being used as part of an audit.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7cjp4o/c_functions/dpqn82a/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I worked on a program that assumed that `char` is 8 bits, `short` is 16 bits, `int` is 32 bits, and `long` is 64 bits. These assumptions were used when unpacking binary data formats, and are in no way guaranteed by the standard. I was discouraged from changing these to the types defined in `&lt;cstdint&gt;`, because they wouldn't be what people are used to.
IMHO, module doesn't change the way language works by much. It mainly benefits development of huge codebases for compilation time, symbol visibility, etc. which are not defined by the language itself.
That doesn't seem *that* complicated, to be quite honest. it might not exactly work at a textual level, but at least this hack doesn't prevent us from introducing better modules in the future.
&gt; Cleanliness Gaby likes to use the term *hygiene* here. Modules will allow us to practice good code hygiene, they are like toothbrush and floss for C++. Plus a few more benefits: * Modules are the first step to not needing the preprocessor, at least in some/most translation units. * Modules have a chance of bringing to mainstream reliable and easy to setup distributed C++ compilation since with modules build systems can make sure compilers on the local and remote hosts are provided with identical inputs (BMIs).
Yes it does and its called Meta State in the Boost Statechart . Please see chapter 4 on the above github link https://github.com/9lean/State-Machine-Using-Boost-Statechart/tree/master/Chapter-4 
Using im2col the tensor convolutions can be expressed using vanilla matrix multiplications. Currently I'am already [doing this](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/convolution.hpp#L177) just with my naively implemented [matrix multiplication](https://github.com/Dobiasd/frugally-deep/blob/master/include/fdeep/tensor2.hpp#L95). Profiling shows that exactly this small function is the main bottleneck in most big conv nets I ran, so I will simply start to replace this one with a call to Eigen.
Simpler development. Right now I go to great lengths (e.g., PIMPL, ABCs, and other techniques) to avoid inclusion of implementation details (header file for a device, or just Windows.h) in headers meant for use by consumers. With modules, as I understood the proposal, I can include whatever I need and export to clients only the bare minimum necessary to use the component. No more PIMPL, no more artificial ABCs, no more `typedef void* SOME_HANDLE;` just to avoid inclusion of an include with a huge number of symbols, etc. Yes, I'm using MSVC2017, but I don't dare try it out :( I'm afraid I'll lose a bunch of time setting up search paths, etc. 
So if you have a Base class and derived that adds nothing like [this](https://stackoverflow.com/questions/19741843/if-derived-adds-no-new-members-to-base-and-is-pod-then-what-kind-of-pointer-c) example, you can safely cast them with unions?
Since you're new, maybe you don't know that it's much better to participate in reddit so that the audience knows who you are before you start submitting links to promote your youtube channel. Otherwise, people might think you're just using reddit for self-promotion, and that's against the rules. https://reddit.zendesk.com/hc/en-us/articles/204536499-What-constitutes-spam-Am-I-a-spammer-
&gt; but C++/CLI goes far beyond some simple compiler or language extensions as you find in clang or gcc - it is a complete dialect. There's little difference. GNUisms are infecting open-source projects and code infested with `__attribute__`, `typeof`, `__builtin_..` is just as non-compileable on MSVC as code infested with `String^` is on gcc. On the other hand, places where I've seen C++/CLI in use was to make a bridge between native C++ and CLR (i.e., expose C++ components to C#).
Thanks.. will take care of it.. 
Thanks for letting me know. I'll deep dive into the code and try to make it faster
I think you might want to look into the D language or Crystal.
According to this it either isn't out or isn't a thing: http://www.gotw.ca/publications/ Herb usually keeps that site up to date from what I've seen.
Interesting, I wonder why was it put on amazon at all, provided it's really non-existent...
- Hopefully it will put an end to the giant amount of space used by .pch files through selective exporting of symbols. I have a modest (300K line) project here and I'm having to store 2GB of .pch files, per compile mode (so that's 8GB then for release, release64, debug, and debug64). At the very least a module header needs to be stored only once, but a precompiled header is generated for each project. - No more macro leaks. We have a coding rule that the words 'Status' and 'Success' are off-limits, because X11 happens to #define those. And our member function names will no longer be twisted around by windows.h - admittedly less of a problem, but weird nonetheless. - Better tool support. Well, we can only hope - but at least there will be only one way to interpret a module, whereas the interpretation of a header depends on the headers that were included before it. - An end to those long lists of include files. Instead of having to painstakingly #include each tiny class (because #including all of them is just too expensive), we get to import entirely libraries in one line without suffering a performance penalty. - An end to the artificial split between .cpp and .h files, without the compiler performance penalty you would get if you tried that today. A module can contain interface and implementation in a single file, without having to repeat function declarations, global variable declarations, comments, etc. Basically, everything can become header-only without performance loss. Hopefully ;-) 
I was under the impression that the current proposal lets you export on a per-symbol basis, pretty much. So not only do you have the option of refraining from exporting your detail namespace, you arguably no longer need it to begin with (since everything that is not exported is 'detail' by default). 
Since you are using MSVC2017: copy that file into the editor. Select it. Hit tab. Do "untabbify selected lines". Copy it back to here. 
For configuration files [TOML](https://github.com/toml-lang/toml) is IMHO a bit more readable than JSON.
Not to my knowledge, but I haven’t looked at the details so don’t quote me on that.
I don't want to do extra work because reddit has chosen utterly stupid markup for block/preformatted text.
Can't `push_back(T&amp;&amp;)` be optimized by the compiler to in-place construction?
&gt; single header library Isn't this a big antipattern? If it's a header, does it even build with multiple source files without linker errors? If eveything is inline, how big is the impact on build time?
So what would you choose?
&gt; No way I'm going to prefix each line manually with 4 spaces 1 shortcut in Notepad++. Dude, are you really a programmer?
You've got to start somewhere - C++11 added 'constexpr', but it's a far cry from what we have today (and what we'll have if C++2a's draft is anything to go by!) Solving a single problem is better than solving none.
I agree with you regarding to default parameters. It is probably OK for free functions, but it has much more problems if you do it with a class method because C.140 clearly states that you might have a problem with default parameters and virtual functions.
Only in some cases. Libstdc++'s implementation of vector `push_back(T&amp;&amp;)` just calls `emplace_back(std::move(arg));` But I strongly suspect that in anything other than a trivial type situation, the saving of a copy is real. I don't have time right now, but it's something to look at on gcc.godbolt.org.
That's horrible. Why is a text search insufficient, as you are relying on named declaration anyway? 
&gt; long is 64 bits. WTH ? it's 32-bit on every 32-bit platform and even 64-bit windows. That program is just broken.
Unfortunately it does not. Recently I asked Pearsons about the availability of this book and got this answer: Dear ---, Thank you for contacting customer service. We apologize, the product that your inquiring about ISBN: 9780321636423 is no longer in publication. Hence, there will be no available date for this product. Please let us know if we may be of further assistance. Sincerely, Customer Service --------------- Original Message --------------- From: [---] Sent: 7/11/2017 5:52 AM To: pearsonstorecs@pearsoned.com Subject: Product Inquiry/Feedback Name: --- Title: Company / Institution: Email: --- Phone: Address 1: Address 2: City: State / Province: Zip / Postal Code: Product Title: ISBN: Comments / Issues / Feedback: Can you please give me an updated release date of: Herb Sutter - Effective Concurrency - ISBN: 978-0-3216-3642-3. Thank you! Best Regards TG Contact Us: Contact Us ref:_00Db0e0e2._500b01K8GqV:ref
Herb is like each of us: only 24h per day...
May I ask, what compilers you are using for your respective targets? And what warning levels and language standards you compile with?
`constexpr` was designed to be easily extensible. these modules are not.
Ah nice to know, thanks, so judging by their response, it did exist at some point right? Only it wasn't reprinted after the initially made copies were sold..
Does anyone knows why std::byte doesn't allow integer masking, like b &amp;= 0xAA? The class have only [byte to byte](http://en.cppreference.com/w/cpp/types/byte) operations defined.
I use gcc 7.2 for linux, the latest clang (whatever it is with Xcode's weird version scheme) for macos/iOS/Android and MSVC 2017 for windows, at -std=c++14. On unix platforms I have -Wall -Wextra -Wno-unused-parameter -Wno-unknown-pragmas -Wnon-virtual-dtor -pedantic -Woverloaded-virtual -Wno-missing-declarations -Werror=redundant-decls -Werror=return-type -Werror=trigraphs plus this on clang: -Wno-gnu-string-literal-operator-template -Wno-missing-braces -Werror=return-stack-address -Wmissing-field-initializers -Wno-gnu-statement-expression -ftemplate-backtrace-limit=0 this on gcc : -Wno-div-by-zero -Wsuggest-final-types -Wsuggest-final-methods -Wsuggest-override -Wpointer-arith -Wsuggest-attribute=noreturn -Wno-missing-braces -Wmissing-field-initializers -Wformat=2 -Wno-format-nonliteral -Wpedantic -Werror=return-local-addr and this on msvc: "-wd4180" "-wd4224" "-wd4068" # pragma mark - "-wd4250" # inherits via dominance "-wd4251" # DLL stuff "-wd4275" # DLL stuff "-wd4244" # return : conversion from foo to bar, possible loss of data "-wd4800" # conversion from int to bool, performance warning "-wd4503" # decorated name length exceeded
I don't think modules will allow us to get rid of pimple entirely, because private class members are still visible to the importing module. So while the compile time improvement is less important with modules, the strong encapsulation aspect remains relevant to some degree.
P0202R2: Is anybody working on constexpr for &lt;cmath&gt;-functions? I want to write: constexpr double PI = std::atan(1.) * 4.; 
May be, but I doubt: I'm looking for that book from time to time since I attended Herb Sutter's course on this subject in 2012 (an excellent course by the way). But my search was always without any success.
Much of the material has appeared in Dr. Dobbs journal over the years: https://herbsutter.com/2009/11/11/effective-concurrency-prefer-structured-lifetimes-%E2%80%93-local-nested-bounded-deterministic/
&gt; arrays will decay into pointers Yet another mistake. 
Surround with triple-backticks as used in other markdown variants would be good. I also find prefixing four spaces on every line a truly tedious way to specify multiline preformatted text.
 Of course it does. Either simply: vector&lt;float&gt; vs; auto cli = ( /*...*/ option("--vals") &amp; values("values", vs) /*...*/ ); or even better (parser will check, if the args are actually numbers): auto cli = ( /*...*/ option("--vals") &amp; numbers("values", vs) /*...*/ ); If you want the values to be optional: auto cli = ( /*...*/ option("--vals") &amp; opt_numbers("values", vs) /*...*/ ); If you want the parameter to be required: auto cli = ( /*...*/ required("--vals") &amp; opt_numbers("values", vs) /*...*/ );
Ah, didn't know that one, looks interesting. I think my main concern would be to find a file format that maps to all the possible expressions that you could build with clipp. And since it's basically a language for defining a language I will have to think about all the corner cases.
Antipattern? That's basically how most of the standard library does it. Many modern C++ libs are header only. What about std::vector in 100 source files? Exactly the same problem there. That's the state of C++ right now and I'm not sure modules (if they do come in C++20) will solve these problems entirely. BTW: In how many source files would you include a command line parser? I don't think in more than 1 or 2 usually.
``` preformatted text ``` as everyone else.
Agree, tree backtics are better. Also, they often let to specify language for better highlight.
&gt; That's basically how most of the standard library does it. It's because some parts of standard library (containers, algorithms) are made entirely of templates so they must have to be in headers. But this library is not a everything-template.
CLI11 seems to be opinionated in what style of arguments it accepts so it's already a non-starter.
Maybe I've missed it, but is there any way to specify whether flags and their value are separated or joined? (i.e. separated "--foo" accepts "--foo 42", joined "-bar:" accepts "-bar:42)
Just stared reading it, I had a hard time learning from boost documentation so I give it a go. Seems good so far but I already encountered many typo/grammar errors in preface and chapter 1.
There's a lot of great single header libraries that require you to define some macro in one compilation unit that conditionally compiles the implementation. It's a *really* nice way to quickly add libraries to your project in my opinion. The [stb libraries](https://github.com/nothings/stb/) pioneered this technique i think. In this project's case, can you really see the header being included anywhere but where `main` lives? 
Cool that's awesome, thank you! :-)
Maybe /user/hpsutter himself can comment on that?
Yes of course. But my point is: why would compile time be an issue? We endure much longer compile times for heavily templated code (e.g. std lib); and sometimes for each of 100s of translation units. I don't think this lib would be included in more than 1 TU most of the time. And setting up a build system (make, CMake, whatever) is often more of a burden IMHO than a few milliseconds of compile time. And I don't seem to be alone with my opinion: header-only libs are becoming more and more popular.
&gt; It's a really nice way to quickly add libraries to your project in my opinion. I don't any problems with other libraries. Just clone the repo and add path to top, then just include the core header in code.
Agree, this lib will be usually only used in only 1 TU.
Hey.. Thanks for pointing out. Unfortunately I'm not a native english speaker but trying hard to overcome the grammar issue and typos. Would be grateful if you can fork and change it. I'll merge. Thanks
I think I will do so.
That’s a bold assertion to make without any evidence. In what way is the current modules TS not extensible?
Probably you should have a look at Boost SML: http://boost-experimental.github.io/sml/benchmarks/index.html
That was my understanding as well. Surely there is no need for public/private annotations.
Well, only if its opinion differs from yours (or the one you wish to present to your users); but, point well-taken ;P.
Thanks.. I also got 1 more help.. Please wait for today till i merge.. Hopefully most of it will be answered.. You're welcome to put further improvements
This one nails it. Modules will help solve some of the real problems that beginners run into during the first 1 week of learning cpp.
OK, I did some cleanup (thanks again for pointing out the emberrassing thing with the missing parenthesis). I made it work with MSVC 19.12.25715.0 on a subset of the examples without errors and no warnings on /W4. But I guess there is still some work to do. BTW: if you call the test script PS&gt; python run_tests.py * -c "compiler" -o "string with compiler options" it should work with other compilers.
Reason I said to be glad to not work with them :)
I don't remember if there was a paper, Tom Honnerman lead the evening discussion on it There isn't an SG onit yet though.
This is awesome. What I’m wondering is if it’s possible to put this in some sort of dot file (like .clang or something) and have clang read the options in there every time. If not, it would be awesome if I can steal this list 🙂
Interesting idea. However, I think you need to "copy-on-write" every time you write to the object. For example, if you pass a list by value to a function, and the compiler notice that the function doesn't modify that list and pass that list by const ref, this will break in multithreaded code where the list is modified by another thread.
Well, I just tried your python script and it seems to be parsing options as paths. You're manually parsing options in a loop and I think you're forgetting to index `i` again for an argument with a value, so for `-o "/c"`, `compileropt` is correctly set to `"/c"`, but it's also added to `paths`. Since my python2 install is from msys2, `/c` is the C: drive, so it's been scanning my whole drive for files to compile. Funny. Have you thought of porting your library to python so you could use it in your testing script? Anyways, since command line options don't work, I tried setting `compiler` and `compileropt`, but you have hardcoded options like `-o`, which isn't right for Visual C++. This is why you shouldn't use handrolled scripts for this kind of stuff anymore. Use a proper build system and a proper test framework. As a last resort, I've loaded up `actions_test.cpp` in Visual C++ and tried to build it again. I'm still getting lots of warnings, mostly about signed/unsigned, which tells me you're still not compiling with the highest level of warnings. I'm getting a weird error I don't understand about `action_provider::simple_action` being redefined, so I've moved it outside the class. The test failed with an assertion in the standard library, starting from `actions_test.cpp:103` in `run_wrapped_variants()`. The problems seems to be in `operator==()` for `depth_first_traverser`, which ends up comparing iterators from two different containers on this line (`clipp.h:2835`) return a.stack_.back().cur == b.stack_.back().cur; The two `cur`s are from different containers, which is undefined behaviour. I haven't run any other tests. Honestly, I've spend all the time I could spare on it. I'll cautiously stay away from this project for now, but I wouldn't mind revisiting it in a few months if you did changes to it. Good luck!
The decision to invoke the move assignment operator rather than the copy assignment operator happens statically at compile time; `std::move` is just a friendly wrapper for `static_cast&lt;X&amp;&amp;&gt;(x)` (i.e. a cast to rvalue reference that produces an xvalue) and overload resolution will prefer to match this with a move assignment operator (if provided). The internal state of an object at runtime after being moved from is of course entirely up to the class author, but the compiler does know exactly when moves will be performed. That line can't flip flop between invoking the copy assignment operator and move assignment operator dynamically at runtime, it's one or the other at compile time.
Yes indeed. Andrzey touches on this in a comment to Dave Abrahams's article "Want speed? Pass by Value". Link: http://web.archive.org/web/20131225054841/http://cpp-next.com:80/archive/2009/08/want-speed-pass-by-value/comment-page-1/#comment-80
My "burn the world" would be any kind of `if constexpr` for data members which would emormously simplify generic programming where you want conditional data. It would largely remove the need for the EBO in the first place.
There is a proposal for [partial classes](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0309r0.pdf), like C#, which would allow easy separation of public API from implementation, and which seems like it would benefit from modules. In addition, this would allow classes to be extended in a way which would have previously needed to be done intrusively.
You're a... tab-user, aren't you? ;-)
Clara is great would definetly recommend taking a look into it.
You got me! :D
Maybe I'm misunderstanding, but isn't passing by value in that case a race condition already? If there could be another thread modifying the data and you're copying it into a function without locking it, it could be modified part way through the copy. If so, then both the copy elision and the straight pass by value are going to fail.
Does `[[no_unique_address]]` sufficiently solve the problem? [P0840](http://wg21.link/p0840) will likely be in C++20
You can read the definition of trivial-layout types [here](http://en.cppreference.com/w/cpp/concept/StandardLayoutType). If the base class is a standard layout type, either the base or derived has no non-static data-member and the derived class has no virtual method, then I think the derived class should be of standard layout type. The simplest, of course, is to put a `static_assert(std::is_standard_layout&lt;T&gt;::value, "Needs to be standard-layout for the union cast to work");` to make sure that the compiler agrees and no maintainer accidentally breaks this assumption.
At the moment the parser will first try to match them non-joined and if it can't do that it will try to match them as one joined arg. That is done regardless of the flag string or the value(s) that follow(s). Do you think I should add a parameter property to prohibit joined matching? It would be farily easy to implement. But I haven't come accross a use case where that mattered. Did I miss something?
There is a big potential for bugs if you do such a transparent switch from value to const&amp;. I know that of several functions in my project that would modify the original value pointed to by the const&amp; through a side effect. I know it's a big code smell, but passing by value is the only way to guarantee that the argument is not modified throughout the function. I can give an example how this can happen.
Just curious, in which case would code that alters the state of an object through const&amp; compile?
&gt; That line can't flip flop between invoking the copy assignment operator and move assignment operator dynamically at runtime The problem is that knowing in C++ at translation time which constructor overload is invoked is meaningless. You can write a move operator that calls a random number generator to decide to move, copy, or synthesize a new value. You can write a move operator with tons of global side effects. And so on. The compiler can't make any assumptions about move without knowing the full details of what the move operator is doing and then without doing deep analysis on what that move operator is doing, which is constraining and expensive. Rust _guarantees_ that a move operation is a bitwise copy followed by a Drop on the moved-from value. And all side effects are constrained by the borrow checker. The borrow checker and lifetime ranges also reach into sub-objects/fields. This means the Rust compiler is able to make some pretty strong inferences about the results of a move operation that just aren't possible in C++ at translation time. Now, whether that has any bearing on C++ being able to support something like the borrow checker is another story entirely. There's been some proposals for lifetime-lite to handle some of the more common cases (particularly, functions that take and return references that can lead to surprisingly short-lived temporaries).
I love the idea (and I wonder whether Dave Abrahams found a way to exploit it in Swift?), but I'm not sure if even the best static analyzer could be 100% sure that a parameter would remain immutable for the duration of its scope in a function. It'd be smelly code, but any callstack which accessed the passed object by non-const pointer would be fair game for pessimization, and you could end up unintentionally killing performance. Still I too would be interested to hear if anything has ever come of such an idea.
I think it would be a mess because of backwards compatibility, but even more because there might be times where you actually *need* a copy of an object (in my experience, mostly of strings), and with this change you would then need to make one manually. I would prefer that passing by const reference were the default, while still allowing for objects to be passed by value by using some keyword, e.g. `copy`.
`const_cast` (and C casts) come to mind, but using them to modify const object is `UB`.
using a const_cast&lt;&gt;()
Presumably it doesn't have to go through the const&amp;. I don't think there's anything illegal or undefined, for example, about passing a &amp; and a const&amp; to the same object to a function which modifies the object via the former and sees its own updates via the latter. 
Useful, but AFAICS you have to wrap the template arguments in `std::conditional` in order to configure a type's data members. Bit more verbose than `if constexpr`. 
I can get a misguided C cast, but I can't imagine where a const-cast would have been used on the subject of the OP where the code was initially written for pass-by-value.
Assuming that the code is well-written and meaningful, and that the function was initially written to accept by value, I don't believe there is a scenario where a const-cast would be used. So it's true, but probably not a factor on the value-vs-const&amp; issue.
Oh, true. I guess you are better to lock, make a copy, unlock and pass by const ref. In that case the optimization suggested by OP would be useful.
Only when you alter it through another channel. This is based on an actual bug that I had. // if you change this function to take const vec2&amp;, the wrong position will be passed to clear_position void kill_creature(vec2 position) { creature* c = get_creature(position); c-&gt;die(); clear_position(position); } void creature::take_damage() { if (...) kill_creature(this-&gt;position); } void creature::die() { this-&gt;position = invalid; }
You're right that this compiles and works fine, but that's not exactly what I was asking about. OP is talking about changing pass-by-value to pass-by-const&amp;. If I understand correctly /u/miki151 is referring to changing the object solely through the const&amp; and my question is strictly regarding that.
Yes, indeed. The problem is that const pointers and references are only a soft guarantee in C++. It doesn't mean that the object itself is necessarily const, so we can't even cry UB if something else in the callstack with a non-const pointer/ref to the passed object modifies during the function call. That said, if a function receiving a const&amp; parameter sees that object change during its execution, that's probably an unwanted bug anyway. Value semantics are probably what's required there. However, the compiler would be wrong not to pessimize the code generation in this horrible case.
To be fair, I believe this example could have been written in a way that enforces const-correctness, eg through better encapsulation. Nonetheless, it's an interesting example and I understand that you can't always change the design of existing production code so you have to consider cases like this.
I was just going to suggest- reach out to him directly. I emailed him once in the past, and he responded immediately and enthusiastically. 
&gt; Modules are the first step to not needing the preprocessor, at least in some/most translation units. Not the first step ... just one additional, albeit important, step. C++ has been gradually introducing features that reduce the use of the preprocessor. It's been this way from the beginning, with `inline` and templates as classic examples. But `#include` is by far the most important of all preprocessor uses, currently necessary to compile every C++ source file out there, and it will be a wonderful day when it only exists to support legacy code.
 void foo() { Foo foo; auto x = bar(foo); ... } Baz bar(Foo foo) { ... baz(foo); // takes by const ref, but modifies internally ... } something like this. Or not. It's C++, possibilities are endless =)
I'm not sure I understand. Would the compiler pass by `const&amp;` if it was able to prove that the function doesn't modify the parameter? Or does the it _always_ pass by `const&amp;` and make a copy on write? If it's the former, do you end up with two different functions? Are they overloaded? Can you take the address of both? What if the function is virtual? What if you start a thread with it? To prove that the parameter is not modified, the compiler would have to look through `const` member functions, check `mutable` members, check `const_cast`s, check aliasing, etc. I find this unlikely except in the most simple cases. It might not even have access to the code if it was in a library. If it's the latter, what's the function signature? Is it always `const&amp;`, or is that just an internal detail? When is the copy made? Can it be destroyed before objects local to the function? What happens if you take the address of the parameter? Which object are you getting? Does the address stay the same for the whole function or can it change in the middle? I have to say, the technical difficulties of implementing something like this seem enormous to me, and for little to no benefit, except a few characters less to type. Not to mention backward compatibility.
This has already been [proposed](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3445.html).
I don't understand this snippet. Where is the function that takes by reference and where is the const-cast?
After thinking about it a bit more, I agree with the general consensus here: such a change is too dangerous/impractical. An observation: a lot of the problems mentioned could also occur when implementing a custom copy-on-write type - which is a good argument to avoid them in the general case.
I'm not writing that book at this time, Pearson has been trying to tell Amazon and others for several years but they can't seem to get them to remove it.
&gt; two properties of the Rust language And that's why Rust checks for out-of-bounds writes ;). Seriously, though, I'd put it much more strongly than you have: Rust looks *weird* in certain ways because it has to be different to support its checks; you can't move from a reference, but you can `take` from a reference; you can't take multiple mutable references to a container without splitting it or doing in order traversal; you have to track lifetimes in the type of everything; etc. If you retrofit Rust's approach to safety on top of C++, you'd mostly end up with an ugly version of Rust. More interesting to C++ is to meet in the middle, taking checks where they fit the language and libraries but not going all the way to actually-genuinely-safe.
This would be awesome, but is it so? If I export a class using the "export" keyword, how does the Modules TS enable me un-exporting one of its members?
But why would it matter for the correctness of the transformation?
Ok, upon rereading your post I think I get it now. A function such as func(T&amp; output, T input); could potentially break if changed to func(T&amp; output, const T&amp; input); When `output` is the same object as `input`.
I just care about this part: `class MyClass { // ... possibly many members here , taking lots of code to compare ... /*...*/ operator&lt;=&gt; (const MyClass&amp;) const = default; };` other stuff is probably of interest to people who care about regular types and other crap I am not interested in.
Well, there are quite a few ways, however, I'll only look at a few. First, what does every other modern module system have? Hierarchy. AFAICT, there's no way to add hierarchy to this system, given the fake hierarchy that already exists. Second, (and this is related to the lack of hierarchy), modules are closely tied to TUs; there's no way to define two modules in one TU, or to have submodules. This has been somewhat common for me in other languages with modules. Third, there's no way one could extend these modules towards first class modules. They're a bodge on top of C++, more similar to preprocessor commands than a part of the actual language. They aren't a part of the typesystem, they have a completely different syntax, and in general create new abstractions where extensions of old abstractions would have worked. There are two things I see which could replace these modules, without preventing nicer modules in the future. Add `private` and `public` specifiers to namespaces, and add `#import` commands, which is equivalent to `#include`, but doesn't bubble macros up or down. This is why I think modules are such a mistake. I want a stop gap solution which *doesn't* prevent good modules later.
The entirety of module syntax doesn't jive with the rest of the language. Just look at how one defines a module - `module x.y.z;` these dots mean something completely different to dots in other places - they're just part of the identifier. `export` could literally just be called `public`. Read my replies to the other thread for more information on why I really dislike modules.
`baz`can use `const_cast`. Basically just moves the problem down the line. But the initial `foo` is intact since it was copied.
In addition to already mentioned `const_cast` and aliasing (where there is another non-const ref or pointer to the same object), there is also `mutable` keyword. 
Aliasing will get you: void total(int a, int b, int c, int&amp; result) { result = a+b; result += c; } void foo() { int total = some_initial_value(); //Breaks if the 3rd param is a const &amp;, getting 2*(bar+baz) add(bar(), baz(), total, total); } The same will happen with structs at some point. BTW, also because of possible aliasing, the binary might just end up slower than actually doing the copy.
... it may be easier to simply write the damn book. :-D
I see. Passing by value sidesteps that, sure, but it feels like `baz` is broken and should be fixed anyway.
Here, simple trivial example that is perfectly safe and valid C++ without breaking any taboos, style conventions or anything for that matter. #include &lt;iostream&gt; void f(const int&amp; x, int&amp; y) { std::cout &lt;&lt; x &lt;&lt; std::endl; // Prints 5 ++y; std::cout &lt;&lt; x &lt;&lt; std::endl; // Prints 6 } int main() { int x = 5; f(x, x); } 
This is aliasing, not const-cast. Perhaps you responded to the wrong comment. Judging from the rest of the responses I got, this is indeed the most prominent example of code that breaks by taking const&amp; instead of value.
Hence &gt; I know that of several functions in my project that would modify the original value pointed to by the const&amp; through a side effect. I know it's a big code smell, but passing by value is the only way to guarantee that the argument is not modified throughout the function, even in a single thread. from the original comment =) Nobody argues that it's bad. But it exists.
Great point about the assertion here, that can prevent many bugs.
Obviously he needs to be multi-threaded.
Unfortunately I there really isn't such a dot file, and honestly, when you are compiling other people's projects it's best to only use the ones they program against if you don't want the build output to be a complete and jumbled mess. I personally put them in my cmake files but you could easily put it in your .bashrc file as a variable, then access it with `$VARNAME` or something like that. This would allow you to easily use it when you are doing ad-hoc compiles on random files or are generally not in a project. Actually I might actually do that... Anyway, this list is free to steal! Just be aware, every flag doesn't work for both clang++ and g++, but the majority work for both. Don't ask me about icc, I'm not rich :p
My guess is that compiler can emit the optimized version of the function and call it inside same TU, but it must emit the boring version also since other TU depend on it during linking. Hard to know if I am right without asking some people who work on compilers. There are couple of them on reddit so you may invoke them here if you do not mind pinging them.
`__attribute__` becomes `[[attribute-list]]`: [Attributes](http://en.cppreference.com/w/cpp/language/attributes) `typeof` becomes `decltype` and sometimes a bit of `auto` or `std::decay`. And `builtin` stuff is just that. Direct access to compiler intrinsics. Not much to do about that, unless you want to add to the language standard. If these things are infecting open-source projects, that's their own fault. They should use more portable features that are a part of the language.
 include/clipp.h:2895:5: required from here include/clipp.h:2399:35: warning: placement new constructing an object of type ‘clipp::group::child_t&lt;clipp::parameter, clipp::group&gt;’ and size ‘264’ in a region of type ‘clipp::group::child_t&lt;clipp::parameter, clipp::group&gt;::data’ and size ‘256’ [-Wplacement-new=] case type::param: new(&amp;m_)child_t{src.m_.param}; break; ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~ include/clipp.h:2400:35: warning: placement new constructing an object of type ‘clipp::group::child_t&lt;clipp::parameter, clipp::group&gt;’ and size ‘264’ in a region of type ‘clipp::group::child_t&lt;clipp::parameter, clipp::group&gt;::data’ and size ‘256’ [-Wplacement-new=] case type::group: new(&amp;m_)child_t{src.m_.group}; break; When I compile the examples provided, this warning keeps popping up, is this something I should be wary of? I compiled with `g++ (GCC) 7.2.1 20170915 (Red Hat 7.2.1-2)`.
Its been brought up numerous times in the past and never really gained any traction. e.g. [Omniware](http://www.cs.cornell.edu/courses/cs614/1999sp/notes99/langind.html).
The program's not broken. It just "wasn't specifically written with portability in mind" and "makes assumptions about the underlying platform (e.g. size of int, size of a pointer)." 64-bit long is part of the standard LP64 data model used by pretty much every 64-bit platform. Windows is the only common exception, which uses LLP64 instead. Another common non-portable assumption I see is one of `long` and `int` being the same size, and code freely aliasing `long`s and `int`s. It's a real pain to deal with with such code on LP64 systems. 
From original [design paper](http://open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4047.pdf) and [CppCon 2015 Module Presentation](https://youtu.be/RwdQA0pGWa4?t=591) Module Design Goals are: * Componentization * Macro isolation * Scalable builds * Support for modern semantics-aware tooling Non-goals: * Improve or remove the preprocessor
Righto well go and do that with boost and let me know how you go.
While most all of the Effective C++ books were good, that one doesn't exist. "C++ Concurrency in Action" (by Anthony Williams) was quite good though...
Cool site! Thanks for posting!
&gt; First, what does every other modern module system have? Hierarchy. AFAICT, there's no way to add hierarchy to this system, given the fake hierarchy that already exists. The way submodules work is that in the parent module's interface file you explicitly nominate the submodules. I don't see the problem unless your complaint is that there's no enforced relationship between naming a module and its submodules, or that a module can be a submodule of multiple parent modules. &gt; Second, (and this is related to the lack of hierarchy), modules are closely tied to TUs; there's no way to define two modules in one TU, or to have submodules. Modules are supposed to be a _larger_ organizational unit than translation units. They're aimed at large scale programs and supporting physical structuring. Wanting to put multiple modules into a single translation unit is I think missing the point of modules.
I think the comment was mainly about 'detail' namespaces. In the current proposal exporting a class does mean all the members are visible as well, but anything you would put in a detail namespace you can just not export in the first place. So detail namespaces shouldn't be necessary.
VS2017 has a lifetime checker built in. In the project options go to `Code Analysis → Extensions`.
C++ Haiku ------------ // classic example using namespace std; cout&lt;&lt; "Hello world"; (pronunciation of `cout` and `std` to get 5/7/5 is left as an exercise for the reader)
C++ Haiku It's members are clear It's semantics obvious It's Name?
RAII is Resource Acquisition Is Initialization RAII: Re source Acquisition Is I nitialization C++Haiku Is mad frustration Lotus on the pond 
I don't think you understand how modules work. *there is no hierarchy*. `std.core` and `std.io` exist, but there is no `std`. The only "hierarchy" that exists is the DAG that exists between modules.
😘🍻
Howdy! These aren't really daily F# builds - they're just unsigned VSIXs of the latest master branch which happened to be sitting on a CI server. Our CI went kaput last Friday, and it just now came back online today (with an apparent issue in our Ubuntu builds). No telling where such VSIXs will live. Are you using our [nightly releases](https://blogs.msdn.microsoft.com/dotnet/2017/03/14/announcing-nightly-releases-for-the-visual-f-tools/)? Although they're also unsupported, they are still alive and kicking, with the latest just being published today.
 module std; export { import std.core; import std.io; } Yes, I understand how modules work. It sounds like you are indeed just complaining about the lack of enforced naming relationships. From a user's perspective what matters is 'what symbols do I get when I import this module'. You can write your modules so that there's a 'parent' module that makes all the symbols available, and 'submodules' that you can import to just get various subsets of the symbols. 
That had occurred to me. :)
Note I have not maintained gotw.ca for about a decade. I keep it available so links don't break but my current blog is at herbsutter.com.
that... isn't a hierarchy. That's just a module exporting the contents of other modules.
Nice, thanks!
Good points. Closing this out: - The module proposal does eliminate the need for detail namespaces. - The module proposal does not allow hiding class members.
&gt; From a user's perspective what matters is 'what symbols do I get when I import this module'. You can write your modules so that there's a 'parent' module that makes all the symbols available, and 'submodules' that you can import to just get various subsets of the symbols. And yes, it's a hierarchy, constructed by having each module explicitly nominate its submodules. If you feel there are any concrete issues created by the module proposal's system of submodules feel free to describe them.
Agreed! Refining this further, we'd gain a bit more power if instead of reusing "private:" we introduced a new access specifier (call it "internal:" or "embargo:") that makes a declaration internal to a module's implementation. By not reusing "private:" for this purpose, this specifier can be supported for class members ("this class member is hidden to all other modules"), and compose nicely with the existing uses of private: ("this class member is hidden to all other classes") and protected: ("this class member is hidden to everything but subclasses").
They aren't submodules. Anyways, I'm done with reddit discussions of this. I'm on the cpplang slack if you want to discuss further.
RAII gives A handle to postmodern Tony. Now, release.
Ah, when pasting that link it felt off, but that explains it. Thanks for the correction, and love (your actual) blog!
feels like dangling reference, doesn't it? Gimme a second, I'll post a glowing review to help the process... ;)
Oh would I give for Less behaviour defined by Implementation.
You should post your question over at: https://www.reddit.com/r/cpp_questions/ (see the sidebar).
This was a Linux program, written within the past few years. There were no 32-bit platforms that needed to be supported, nor was compatibility with Windows a consideration.
Ooh, I knew that different systems had different integer sizes, but I hadn't been aware of the terminology for the different schemes. Thank you.
Once I’m home, I’ll take a look and [hopefully] come back with an answer. 
I'm not on the cpp slack. Anyway, I'm not hearing any concrete issue with this method of declaring a modules to be subordinate to another in the hierarchy.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7cscwu/program_throws_an_exception_when_calling/dpsbx6l/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
If you'd listen, maybe you would. I'd like it to be hierarchical. Like namespaces. Like classes. Like everything else in this language. I don't see what's so hard to understand about that.
We just need a meta-herb to write the books that herb would theoretically write if he had time.
And someone is selling it on Steam in 3..2... 
&gt; I'd like it to be hierarchical. It is hierarchical. You apparently just don't like the way it does hierarchy, and want it to be different for no apparent, practical, concrete reason. What's the user impact of doing it one way or the other? You apparently want the syntax to look something like: module std { module core {} module io {} } even though you haven't pointed out actual user impact from instead constructing the hierarchy using references between nodes in a flat node-space, like we do, e.g. with tree data structures. Do you think that tree data structures aren't hierarchical just because they're nodes that exist in a flat space with only pointers to connect them? That they'd only be a real hierarchy if the sub-nodes existed syntactically as sub-objects within the parent node? E.g.: struct { struct { struct {} left; struct {} right; } left; struct {} right; } tree; This ***is*** a hierarchy: module std.core; module std.io; module std; export { import std.core; import std.io; } Just like this is a hierarchy: struct TreeNode { TreeNode *left, *right; }; TreeNode nodes[5] = { {nodes + 1, nodes + 2}, {nodes + 3, nodes + 4}}; The user can say: import std; and get all the symbols for all of the modules contained in the std module. What else does the user need from a module hierarchy? Anything? Even if you were right about these modules not constituting a hierarchy (and again, you're wrong, it is a hierarchy) what would it matter if the feature provides the concrete feature the user needs? What's the real, practical, user impacting problem with arranging modules this way? What's the benefit of disallowing naming flexibility? What's the benefit of taking away the module designer's ability to also produce other, non-tree structures? I can certainly tell you, in concrete terms, some of the problems that would be created by taking away some of those freedoms, starting with making the transition to modules impossible to far more difficult for large (&gt;100m LoC), existing codebases; Something that's actually been done using something akin to the current module proposal's system. These systems often offer _graphs_ of interfaces, so modules needs a system to expose these. Experience with actual systems, and actual problems faced by modules in large codebases, went into P0142 and P0273. Current proposals are by no means perfect, but I don't think vague, aesthetic criticism of no practical impact is what's needed to fix them. 
Because integers aren't bytes. If you want unsigned char, use it. If you want strong type boundaries, use byte.
Don't really see the problem with that.
I think the problem here is there's no reason to make 2 functions, you could put `die` and `kill_creature` in the same function and that would be free of sneaky side-effects.
They'd need to do a const_cast&lt;&gt; to get away with murder like that, and const_casts&lt;&gt; always deserve scrutiny.
I'd argue "mutable" keyword is really a case where you're saying that the "const" keyword doesn't apply, and therefore the compiler shouldn't be making the const assumption about that in the first place.
Hm. Didn't see that one before. I mean I use placement new in a tagged union. See, I didn't want to require C++17, where we have std::variant, so I implemented my own. I want groups to be able to store groups and parameters at the same time. Normally one would use inheritance and dynamic polymorphism in a compound pattern. I tried that - the overall usability was horrible without value semantics and the implementation was much more complicated. So I went for the tagged union approach.
Ooohh.... I got one for you -- a 32-bit platform I worked on where nearly everything was 32 bits. char? 32 bits. short? 32 bits. int, long, float? 32 bits? Only double was 64 bits. long long wasn't supported (as it was a niche pre-C++11 compiler).
I did it with boost already, everything went fine in 1 command: `sudo apt-get install libboost-all`
There are uses for a "compile once, run everywhere" language. And you can compile (much) C++ to a VM target if that's what you need, for example via Emscripten. (C++ to JVM options do seem to be pretty limited though - http://nestedvm.ibex.org/) Or you can compile to x86 machine code, and run an x86 emulator on your target platform. (Or compile to m68k, and run an m68k emulator, etc..) But it's not a common use case. If you wrote a new VM designed specifically to run C++, it wouldn't be widely available to start with, so code using it wouldn't be that easily portable. To become widely adopted, it would have to be significantly better than the JVM.
This is not about unsigned char, this is about applying a binary operation to a literal constant. This is a very common operation and is one the first limitation you find when using std::byte. Requiring a cast to std::byte or to have a variable constructed from std::byte is verbose and doesn't make code more secure taking in count that rhs argument can be easily checked if it is a 1 byte literal.
That would be illegal though, right?
For me it's 90% about reducing the amount of work done to combat compile times. I have to spend time being very careful when writing headers. I'm hoping that with modules, I can just write code in the most natural and intuitive way possible without worrying about compile times. That I can just use the types I want in a direct way. That I can use an `std::tuple` for example directly in a very central header that gets included almost everywhere in the project without even thinking about it. Also, some of the methods currently used to improve compile times are harming value semantics. Using references just to avoid bloating compile times is something that will hopefully die out when modules arrive.
why? 
Couldn't a tool generate a header containing only the public members of the interface, and a blob for the private datas: module MyModule { export class MyClass { public: void f(); int publicMember; private: uint_8 blob[64]; }; } Or does this trigger some form of UB? Obviously, this generated file have to be redistributed each time the API changes.
lambdas
Well, `const` keyword is already so weak in C++, there being at least 3 loopholes, so constness of reference guarantees nothing. Chandler Carruth once said that Clang ignores constness of reference for optimization purposes.
True, but because it has defined semantics in the standard, the compiler can't just assume it doesn't happen.
Thank you for the explanation. I, for one, do not understand why people are downvoting.
Not necessarily: it could call a method on a class which holds a non-const pointer to the same object. With C++, these gruesome constructions are possible, no matter how bad a code smell it might be.
&gt; Print out a comma-separated list of vector&lt;T&gt; using a range-based for loop. The last element can't have a trailing comma. Just do a pointer copy on the delimited string after streaming each element. auto actual_delim = ", "; auto printed_delim = ""; for (auto&amp; item : container) { out &lt;&lt; item &lt;&lt; printed_delim; printed_delim = actual_delim; } Even better, use an algorithm with [an iterator designed for infixing](http://en.cppreference.com/w/cpp/experimental/ostream_joiner). copy(begin(container), end(container), make_ostream_joiner(out, ", ")); &gt; Next, do the same but in reversed order. Wrap the container with a range adaptor such that `(c)begin`/`(c)end` refer to `(c)rbegin`/`(c)rend`. print_container(reversed(vec), make_ostream_joiner(std::cout, ", "));
How would this work when the function is in a different compilation unit to the caller?
that's a really interesting concept that i wasn't familiar. Altough tbh i would have assumed that it would be impractical to do something like that. I'll read up on it at some point.
i don't know anything about webAssembly beyond the introduction of the wiki article. Isn't it more of an improvement to Javascript that happens to support C/C++ fro know, instead of a serious alternativ to C++ nativ applications?
Nice guide! Good length on the chapters and the examples so far are easy to follow. My only complaint would be chapter 3.4. I think if a person uses Boost and statechart that person most likely already knows about dynamic memory and this chapter just felt like a back-to-basics chapter that really has nothing to do with statecharts at all.
&gt; 1 shortcut in Notepad++. Or, reddit can make a reasonable way to paste code and not force me to install some thirdparty software and write a macro for it.
 char*lie; double time, me= !0XFACE, not; int rested, get, out; main(ly, die) char ly, **die ;{ signed char lotte, dear; (char)lotte--; for(get= !me;; not){ 1 - out &amp; out ;lie;{ char lotte, my= dear, **let= !!me *!not+ ++die; (char*)(lie= "The gloves are OFF this time, I detest you, snot\n\0sed GEEK!"); do {not= *lie++ &amp; 0xF00L* !me; #define love (char*)lie - love 1s *!(not= atoi(let [get -me? (char)lotte- (char)lotte: my- *love - 'I' - *love - 'U' - 'I' - (long) - 4 - 'U' ])- !! (time =out= 'a'));} while( my - dear &amp;&amp; 'I'-1l -get- 'a'); break;}} (char)*lie++; (char)*lie++, (char)*lie++; hell:0, (char)*lie; get *out* (short)ly -0-'R'- get- 'a'^rested; do {auto*eroticism, that; puts(*( out - 'c' -('P'-'S') +die+ -2 ));}while(!"you're at it"); for (*((char*)&amp;lotte)^= (char)lotte; (love ly) [(char)++lotte+ !!0xBABE];){ if ('I' -lie[ 2 +(char)lotte]){ 'I'-1l ***die; } else{ if ('I' * get *out* ('I'-1l **die[ 2 ])) *((char*)&amp;lotte) -= '4' - ('I'-1l); not; for(get=! get; !out; (char)*lie &amp; 0xD0- !not) return!! (char)lotte;} (char)lotte; do{ not* putchar(lie [out *!not* !!me +(char)lotte]); not; for(;!'a';);}while( love (char*)lie);{ register this; switch( (char)lie [(char)lotte] -1s *!out) { char*les, get= 0xFF, my; case' ': *((char*)&amp;lotte) += 15; !not +(char)*lie*'s'; this +1s+ not; default: 0xF +(char*)lie;}}} get - !out; if (not--) goto hell; exit( (char)lotte);}
Coincidentally, someone did a talk about this on BoostCon this year, https://youtu.be/Lj1GppqNr8c 
Hey... thanks.. I Agree with your assessment about dynamic memory, but we never know
Why? The template is licensed under UE4 EULA, so, if I'm not mistaken, someone only needs to pay the royalties if they decide to use it in their game.
Hmm okay, in that case, so be it. I was just thinking that it's someones creative work etc. I'm not too savy concerning copright laws :-)
It's snowing on Mt. Fuji.
So your issue with hierarchy boils down to the preliminary proposal for modularizing the standard library? If so, I don’t see how that makes it not extensible... we must have different understanding of what it means to be extensible. Here is my example: in 20 they do std.core and std.io. Then In c++ 23, they standardize module std. it exports everything from std.core, std.io etc.. There. extensible. Q.E.D. Personally I like that there is no enforced hierarchy because it allows a library author to export semi implementation details under lib.experimental. Where they can put work in progress and/or frequently changing APIs. By the, I’m not the one down voting you, but it might be because your comments come off as arrogant and include only vague comparisons to ‘other languages’ without concrete examples. Normally when people make the argument that we’re painting ourselves into a corner they provide hypotheticals demonstrating their point of view... Lastly the fact that something worked well in some other language does not mean it is right for c++. We need to look at the specifics of why it worked well, but more importantly look to see where it does not work well...
Well, me too so I might be wrong. But free examples/templates such as this a generally published under some permissive license/compatible with the engine. Otherwise they wouldn't be that useful if you couldn't really take any part of the functionality they implement in your project.
I do not get how memory allocation is done in another thread, is faster? Does he mean pre-allocate in advance?
I propose we hold a monthly r/cpp poetry slam.
I know I already asked you this 4 days ago but I've still haven't got a reply back, what do you consider "basic"?
You yourself included "basic" in the title. Heck, C++ operators aren't that different from other languages either which makes it even more basic. Basic would likely involve anything in C++ that you can learn from a C++ beginner/intermediate book. These posts won't do well here because our readers already know about all this stuff and they didn't subscribe here for this, but for C++ news and to learn how to improve their C++.
Look for changes in BMIs, not the source. BMIs might not change even when the source has changed. I think compilers are working to add support for giving imports for a particular cpp file and supporting asking if there are semantic changes in the BMIs to avoid unnecessary recompilation, so I would plan to support this. I don't really know how to write build systems, but I hope these suggestions can help.
What if the copy constructor has side-effects?
Very good idea, I'll have to make this change asap.
RemindMe! 1 month
I will be messaging you on [**2017-12-14 15:10:43 UTC**](http://www.wolframalpha.com/input/?i=2017-12-14 15:10:43 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/7crald/a_c_poem/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/7crald/a_c_poem/]%0A%0ARemindMe! 1 month) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
You could take a look at how build2 does it. As far as I know it fully supports modules
Ya I was planning to check it out, I like to not look at other sources too early in hopes of doing some things differently. I'm just looking for a good, easy to use build system I can use with Visual Studio with clang. I'm sure visual studio will have a stable modules build system soon, but it may not necessarily support clang. I should definitely try build2 and see how it works though.
Look, that isn't what I meant by extensible. I meant *the language*, not the standard library. It's not like modules is going to come into being fully formed in C++20, I fully expect the definition of modules to change. I'm so frustrated because adding the dots means making modules hierarchical (the *language feature*, not the hierarchies of modules people create) would become extremely strange in a world with dots in the identifier. `std::std.io` would be a valid module. It feels intellectually dishonest to use dots; just use underscores like you would anywhere else in the language that you don't have hierarchy, don't pretend you do by having strange identifier rules.
WebAssembly is basically just a portable executable format. It doesn't really have anything to do with JavaScript, other than that it is meant to work alongside JS when used on the web. It's still early, but there already are people making non-web WebAssembly implementations. Realistically, it will always be slower than a C++ native application, but often that's a reasonable tradeoff for the additional portability and safety guarantees.
Frankly, I'm still fairly new to C++ so most of what you said are way over my head. The warning mentioned some size discrepancy (`264` and `256`), so I'm just not sure if that could cause issues.
With that style it's possible to slip up and do `std::size_t foo;`, where as the 'right hand style' with auto can never be uninitialised. 
If you accept rewordings of popular songs, I've got a bunch.
&gt; I don't assume that an IDE is a necessary requirement for using the language Me neither. I don't even use an IDE, I code in emacs. I don't code without autocompletion. &gt; I don't know what that means in the context of writing C++. You don't use classes? You don't use libraries that use classes? Classes come in all sorts in C++. The STL doesn't really use OOP for instance, but has a lot of classes. The last time I did any significant OOP work was when I last used Qt. &gt; Preferred by whom? The writer, or the maintainer? By nearly everyone in the community of basically any language with type inference. &gt; I guess I'm approaching this from the point of view of a developer who starts working on an established code base I understand where you're coming from, and readability and maintenance are of paramount importance. I've been using `auto` pretty much everywhere for years now and it doesn't seem to make a difference to my reading ability at all. As always, readability seems to be in the eye of the beholder.
Thanks for the hint! This was actually a bug, caused by some stupid renaming in the past. It still worked on all of my machines, but it could have led to an error on some other platform. Fixed it.
Did you literally made a fps game in c++.. I mean without something like blender etc.. 
You are right. I think the author and I came to similar conclusions/solutions. I'll definitly be watching this one.
You are right about that. I think most compilers would warn if you are using an un-initialized local variable, but that is of course not the same as guaranteed initialization by construction. Personally, I find AAA overly verbose and often not beneficial for readability. But that is probably just a matter of getting used to it.
I do accept that.
Ah okay, understood.
Look for @berium explainations in recent module related threads on this reddit, and/or check how he does it in build2's code. (https://build2.org)
Oh my, UnrealEngine C++ code makes me cry :'(
What do you mean by "not deterministic"? C++ talks about UB a bunch, but in this case there's a fairly bounded number of things that atomic&lt;float&gt; allows as long as you don't have races.
ABBA on the ABA problem of lockfree programming: If you change your mind, on the node first in line Honey I was free Take a chance on me ... Gonna do my very best and I may be a lie If you put me to the [cas] test, if you let me try Take a chance on me (Take a chance, take a chance, take a chance on me) [note the stutter of "take a chance" at the end is probably a threading bug]
How come? I never worked much with "native C++" so I don't know the nuances. I like working with it for the most part.
You can find a high-level overview of how a build system might go about support modules [here](https://build2.org/article/cxx-modules-misconceptions.xhtml#build). If you decide to extract the module dependency information yourself (which is how `build2` does it), then don't forget to preprocess the translation unit since, in the general case, `import` declarations can be `#include`'ed, `#ifdef`'ed out, etc. And you may also want to combine this with header dependency extraction to save a preprocessor run.
Glad I could help.
Sorry, I wasn't considering the case of aliasing. That's a whole 'nother pile of pain.
Totally agree.
&gt; constness of reference guarantees nothing Well, they guarantee that the variable won't be directly used to access non-const methods on the referenced object. They just don't guarantee anything more than that.
If we ever meet in person, I'm buying you a beer.
I have some interest in this, but it's a tricky problem space.
**Company:** [Kitware](http://jobs.kitware.com) **Type:** Full Time **Description** Kitware's mission is to advance the frontiers of understanding by developing innovative open-source software platforms and integrating them into research, processes, and products. Here are some of the positions that require C++... [Computer Vision Developer](http://smrtr.io/2scaGA), [3D Computer Vision Researcher](http://smrtr.io/Dx_fOg) and [Scientific Visualization Developer](http://smrtr.io/gP3XUA) **Location:** Clifton Park, NY and Carrboro, NC **Remote:** No **Visa Sponsorship:** On most positions, yes. **Contact:** Apply via website or email john.westbrook@kitware.com (Subject: reddit C++) 
Lots of hidden magic, generated code, raw pointers, unclear lifetimes and ownership semantics, just to name a few. Usage of whitespace is also annoying, but that's not important.
Finally, someone made underflow and overflow bins. Anyway, fill() interface is wrong. Should be fill(x, w = 1.0), where w is what collected in bins. Bin should maintain counter and sum of w
Hey very informative read there thanks for that! Good idea with preprocessing as I will definitely have to take into account the ifdefs and such.
&gt; Subject to the similar problems with Java's Comparable interface if not handled well. Could you link to info about these problems for those of us not familiar?
With bit_cast, what's the purpose of requiring `sizeof(To) == sizeof(From)`, as opposed to just `sizeof(To) &lt;= sizeof(From)`?
As much as I would like to take credit for under-/overflow bins, Boost.Accumulators has them and the ROOT framework at CERN has them, too. :) I don't understand you regarding the call to fill. You can do `fill(x, weight(1.0))`, isn't that what you want?
It would be inconsistent though with `sizeof (float) ≤ sizeof (double) ≤ sizeof (long double)` as well, not just integrals. What reason do you have to require 16 bits? Would that not be just a mess as soon as we elevate `float` to always be 64 bits due to `${architecture reasons}`? I do agree that one might want to propose a set of `float32_t` typedefs as existent for integrals. That's a different paper though.
There are apparently platforms where CHAR_BIT is 32 since the machine architecture can only address 32-bit words efficiently. Then sizeof(float) is presumably 1 [that is, one 32-bit byte] on those platforms, though I admit I have no idea if floating-point arithmetic is even supported there. If sizeof(float) were required by the standard to be strictly greater than sizeof(short float), it would likely break much code that uses floating-point [again, if there is any] on such platforms, since the size of floats would have to be changed to 2 [32-bit] bytes, i.e. 64 bits.
LEWG gave some feedback on P0789 and sent it on to LWG for wording review.
&gt; The only official thing are the motions that magically appear at the end of the week. ...and of course the N papers used for working drafts and editor's reports on working drafts.
In my experience it wasn't too bad. Now, UScript on the other hand...
We should have done that 20 years ago. int should be 16 bits. long should be 32 bits. Period. &lt;sarcasm/&gt;
It would be ideal if the compiler could do this, although you'd have to parse make fragments. I've run into cases where the build system and the compiler end up with slightly different ideas about where headers actually reside, leading to problems with incremental builds. 
float will never be 64 bit. And I know it is the same for floats as integers, that is why i said number types, (I guess standard wording is arithmetic or numeric...) Basically my point is that current behavor is bad but we have it due to legacy reasons. We can no do the right thing. :D
those platforms(if exist) could just be labeled as unsupported by compilers for code containing short floats. This may seem bad but depends on if those platforms actually matter.
Many DSPs have such properties. For example, on TMS320C40 family, all the types are 32 bits, including floats and doubles (actually, internally they are 40-bit, but only 32 bits are saved to memory. And, by the way, these are not IEEE754). Some modern families, like C5x, IIRC, have 16-bit char. 
( I know people will disagree with this because separation of concerns, bla bla...) But I think library like this should include simple generation of graphs in png format(maybe with minimal customization, like naming axis and colors, but most important are reasonable defaults).
btw links here seem broken... https://htmlpreview.github.io/?https://raw.githubusercontent.com/HDembinski/histogram/html/doc/html/index.html#histogram.getting_started.make_and_use_a_2d_histogram_in_p Could be one of my million extensions but it is same in 2 diff browsers...
I think it's logical since it follows the logic that the short, int, and long follow.
Thank you very much I will modify it..
&gt; Boost.Accumulators has them and the ROOT framework at CERN has them, too. sure HBOOK got it first though... &gt; You can do fill(x, weight(1.0)), isn't that what you want? No `does the same as the first call, but increments the bin counter by the real number x and an additional variance counter by x*x.` is wrong. Counter is counter, weight is weight. .fill(x) { i = find_bin(x); bin[i].counter += 1; bin[i].weight += 1.0; } .fill(x, w) { i = find_bin(x); bin[i].counter += 1; bin[i].weight += w; } that is proper interface for the case when MC generator generates N weighted events, trust me...
Remember that the standard needs to keep these architectures into account.
cringe
It definitely should not be 'more', 'at least' has some very good reasons. One really good reason is that requiring that short&lt;int&lt;long (instead of short&lt;=int&lt;=long) prohibits some interesting architectures. In the Float case, a system where a really GOOD float was available (say a specialty 80 bit float that was done REALLY fast in HW) wouldn't be able to support C++ if you mandated 2 separate float sizes. So the system would have to emulate a smaller one with no gain.
I remember being amused when I learned about the unary + operator on lambdas :). It's not required in this case, since implicit conversion is supported. However, it's good for clarity's sake.
I was referring to the potential inconsistency of Object.equals() vs. Comparable.compare(), for which both may be used to compare for equality in different situations, and may lead to different results if the implementations return different results. After rereading the &lt;=&gt; proposal, it turns out the language will delete the overload if the corresponding implementation of operator may lead to ambiguity, so it seems this is actually not an issue. However, it does mean educators extra work to explain how things work :)
Could you elaborate on 2. ? The abbreviated lambda proposal aims only to create syntaxic sugar so what would be the issue ?
Currently on the bus to work. Will upgrade as soon as I get there.
That's a valid choice for the standard to make, but perhaps also a strange one, and one that could be discussed. Consider this: I don't believe there are any architectures on the market today that do not use char=8 bits, or float=32 bits, (etc), _and that also have a C++ compiler available_ (TMS320C40 is marked as obsolete by the manufacturer, and GCC support for its was removed after 4.2. As far as I can tell all you can get for it are a C compiler and an ADA compiler). The people who program for these platforms typically don't like C++ anyway; they believe things like exceptions and RTTI cause far too much overhead. So given all that, wouldn't it make sense to standardize certain properties (things like the widths of the basic types, and their properties like signed overflow) that are currently left open, just to conform with the market realities of 2020? And sure, that would mean that a special-purpose DSP like TMS320C40 cannot run _fully compliant_ modern C++ code. It could stil run C++ if someone were to write a compiler for it; it just wouldn't support the full set of types available in the mainstream market. That's mostly a problem when porting software, but given that these CPUs are running bespoke applications anyway I doubt that that is a major problem. 
I'm not sure if I would call reproducability of calculations to be 'no gain'. As it is, the outcome and accuracy of a floating point operation on an 80-bit instruction set depend on whether you had data flushed to memory (and thus, rounded to 64-bits or even 32-bits) as an intermediate step or not. That may be efficient, but it certainly isn't automatically desirable to everyone. Besides, is anyone even using x87 now? Or has everything moved into SSE and friends? Oh, and since we're here... Why are there no standard types like vec4&lt;float32_t&gt;? There are plenty of CPUs with such types available in hardware, after all, so why doesn't C++ offer them as part of the standard? (asked another way, why do we have to bother with CPU-specific compiler intrinsics instead of being able to use normal C++?) 
I generally don't trust people, I don't know, sorry. ;) I explain the math behind weights in the Rationale section of the documentation. In your last call, why do you need the additional counter incremented by one? In the first call, keeping a count for weight around is superfluous, the library optimizes this case.
In software design one tries to split functionality into separate projects. The lib does not provide plotting, because there are already great packages to do plotting. I use matplotlib in Python a lot, this lib has Python bindings and there is an example included in the documentation how do to the plotting.
No, this is an issue with htmlpreview. I will try another approach to post the documentation where all links work. Thanks for pointing it out!
I am not going to use python to get simple graph. If boost or std had a library to do the plotting you would be right. But I will not bother with getting another library just to get a png picture. I will just use my own histogram and c/p csv text output into excel and generate graphs. Anyway I do not want to discuss this any more since we agree to disagree, but you said you want feedback. :) 
A mild offtopic but since you say you like competitive programming: There was a interview question I was trying to solve and I think it can not be solved with STL. You have 2 sorted ranges and you need to find the element that would be median after merging 2 sorted ranges. I do not want to spoil it for you how I tried and failed to use STL to solve this if you want to try it yourself... but I am pretty sure it can not be done efficiently with STL. :) 
https://hastebin.com/
Having your library in C++ with python bindings, and then do plotting, scripting &amp; stuff in python, is an awesome workflow though :-)
I saw python and awesome in the same sentence... Hmmm.... weird. :P 
Would be great if there was a standalone, header-only version of this library that uses pybind11 and cereal instead of Boost.Python and Boost.Serialization. Particularly pybind11 would make the bindings code more neat and also it would be completely header-only, without any dependency on any boost library...
Extremely unlikely to happens: it would break too much code. Even changing `NULL` macro to `nullptr` would break stuff (as you're changing the type of a frequently used macro). Deprecation is used as little as possible, as people need compatibility; what has been so far (`std::auto_ptr`for pointer, trigrams, ...) were unused stuffs, or hardly used with an obvious alternative.
I do believe you can use nth_element for that
&gt; nth_element that is linear complexity...
I work on a high-performance [database](http://www.scylladb.com/) and although we don't make assumptions about sizes of int or pointers (as far as I know) there is a lot of platform-specific stuff in our code: * Endianness * Processor intrinsics * Compiler-specific attributes * Low level I/O code (bypassing the OS page cache) * Bunch of other low-level Linux-specific code I you don't care about performance and use some framework like Qt, then maybe your C++ code "just works" on "all" platforms. But if you do then it's not nearly so simple.
I think main improvement is that #include "crap.h" forces compiler to process entire header while import would give compiler the easier/faster to use see what is in the module that implements the same stuff as "crap.h" since it is "already processed" And by reading this I guess I am approximately right: https://clang.llvm.org/docs/Modules.html#problems-with-the-current-model There are some other stuff like hiding implementation, but TBH I think nobody would work on modules if it was not for performance speedup.
my opinion: NULL was never a problem, although I prefer nullptr.(should have been just null, but ISO and BW compatibility...). So not worth the effort since benefits are miniscule. And yes I know the propaganda about how NULL is evil but honestly I find it unrealistic in a sense that I doubt that there are many bugs that are cased by using NULL or 0 instead of nullptr.
Sure, but you only do this because it brings additional performance benefits. But it is not necessary to do this in order to just have your code running on the platforms Scylladb run on, which was OP's question if I am not mistaken. More simply put, a lot of people seem to think that if you want to write a program in C++ you basically have to rewrite everything for every system you want your program to run on, which is simply false.
That is true, but nth_element is the most straightforward approach to finding the median of a range. It doesn't require the range to be sorted though. If you really want to focus on the complexity, taking advantage of the fact that the ranges are sorted points to binary search operations and set operations. No single algorithm in STL will get you the median immediately, but you can take the medians from the two sorted ranges and recursively use upper/lower bound to find the combined medium, which would be in log complexity. It's more difficult to get right though
How do you solve it with better than linear complexity? The best approach I can come up with is a kind of two-list binary search, but without trying it I'm not sure if it would work.
&gt; How do you solve it with better than linear complexity? SPOILER ALERT: I do not solve it since I did not want to bother/I could not implement this since it is quite ugly: you are doing a binary search on one range where you try to find an element that is the median in the merged range. You do this by doing a binary search on one range, but the "value" of element is not the value of the element but the index of the element in the merged range. You can get that index by doing the binary search with the element from the first range on the second range. How? Well what is the index of the element from first range in the merged range? Ignoring duplicates that is another can of worms it is the number of elements smaller than the element in the first range(index of the element in the first range) and the number of the elements smaller than the element in the second range(so you need to binary search on the second range, but not classical binary search, more like a lower_bound one). But STL was no help for me here because although binary_search has an overload that takes custom predicate(so I can compare indexes) it does not have overload that enables you to specify that the value you search for is index. So I could not do this: `binary_search(range1.begin(), range1.end(), (range1.size()+range2.size())/2, predicate_that_compares_indexes);`
C5x series, which is pretty current, has 16-bit char. 
mild offtopic but this would be best option I feel, but C++ will never add this to language. `auto struct func(int a){` `int original = a;` `int modified= modify(a);` `return {original, modified};// returns an anonymous struct with members named as variables ` `}` 
The lib uses a lot of Boost stuff internally, e.g. MPL and variant. The latter you could replace by std::variant, but then the requirement is a C++17 compiler instead of C++11. It should be easy to use cereal, AFAIK it is compatible to Boost.Serialisation, no? Even with pybind11 you don't get a header-only lib, because you have to compile a Python module with the Python interface to the histogram.
New stuffs are depending on special dispensation for 0 . http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0768r0.pdf &gt; 3 The comparison category types’ relational and equality friend functions are specified with an anonymous parameter of *unspecified* type. This type shall be selected by the implementation such that these parameters can accept literal `0` as a corresponding argument. [Example: `nullptr_t` satisfies this requirement. — end example] In this context, the behavior of a program that supplies an argument other than a literal `0` is undefined.
I don't think I can justify trying out any more kde software until I read something about them pushing to use more modern C++, more value semantics and less inheritance / virtual pointers. Everything I've used from them has been so unstable I'm not even sure how it got in that state to begin with let alone why anyone would think it should be released or announced. I would like to think I don't have software that is _ever_ that buggy during its development life cycle. When I encounter crashes I go back and fix them as soon as possible. Most of the early KDE releases barely even stay up long enough to push all the buttons and try out the actual program.
Yeah agreed the only solution that I could think of would be a combination of upper/lower bound. Not sure if that would be valid solution though.
If you class/struct has constructor that takes pointer and constructor that takes integer, when you can easily call wrong constructor by mistake if you use `0`. And with `NULL` it may either compile as if you used `0` or fail with ambiguity error, depending on the compiler and the way you use it.
I'm paraphrasing Daveed Vandevorde, noexcept is part of the signature, and you can sfinae based on it. If you have implicit captures, then you have to understand the body well enough to sfinae on it. Existing sfinae engines don't do that.
As far as I can tell, nothing in this text seems to depend on 0 being implicitly to a nullptr constant. It just states, that under the current language rules it would be possible to use std::nullptr_t as an argument type, but a simple int or book would do too.
I don't want to remove NULL.
I know about that, I just do not consider it a realistic problem... I mean if you are overloading on pointer and int you have bigger problems than NULL :P
I would have to check the standard, but I thought, that an implementation is already allowed to define NULL as nullptr, so any program relying on it being 0 could break with any update to the standard library. Personally I think that the standard should be much more willing to break old code in new standard versions, provided that there is an easy automated upgrade path. Clang tidy certainly can perform 99% of the upgrades from 0 to nullptr, where it is supposed to represent a null pointer and NULL to 0, when NULL is used as an integral constant - assuming the code compiles with clang at all.
Interesting about the log complexity, although I'd probably sooner settle for a more straightforward lazy N/2 solution with range-v3 (which will hopefully become mostly standard some years from now). Forgive my unfamiliarity with this library in particular, but: rng1 | merge(rng2) | drop((rng1.size() + rng2.size()) / 2 - 1) // overflow caveat | first() Only the dropped elements are actually merged in the first place. It's hard to do it with the same elegance with STL when everything is eager and needs space.
What would those problems be? Just curious.
Why? One really common example would be some class that always takes a pointer (for example to it's parent) but can also take some other args. Something like: struct Foo { Foo(int x, Foo *parent = nullptr) : x(x) { ... } Foo(Foo *parent = nullptr) : Foo(42, parent) { ... } int x; };
[Well it could be simplified](https://wandbox.org/permlink/IRPXkmYm7zcvElFB)
I disagree with the 'historical abomination' notion. IIRC C++ like C before it talks about a conceptual abstract machine architecture in the standard hence the types makes sense from that perspective since you don't want to limit the hardware the language can run on, hence why it's implementation defined. Short float really fits nicely into this mostly machine independent way imo and I can't find any valid reason as to why you should want to take this abstraction away and limit the language.
&gt; an implementation is already allowed to define NULL as nullptr Yup (TIL) http://en.cppreference.com/w/cpp/types/NULL Although I bet most compilers keep `NULL`defined as 0. ____ But what are asking is to make `int* ptr = 0;`invalid. And that would break a lot. &gt; I think that the standard should be much more willing to break old code in new standard versions, provided that there is an easy automated upgrade path. Even with the automated upgrade part, many will say "no". There are a lot of long-lived C++ software, and what are asking: - Would require a massive amount of validation/testing - Would require potentially lots of debugging (even if Clang Tidy catches 99% of the case, enjoy the remaining 1% if your codebase is several MLOC) - May be trickier for templated code. - May not work for generated code (or you would get a warning for the generated code, which would require to find the right place in the model, while making sure you don't break anything else) - and as you say, Clang-tidy deosn't work everywhere. Add all the lesser-known compiler that are targeted towards baremetal/microprocessors, and can have large extensions. - Isn't worth it as a result
Well couldn't this be done by having range of ints (e.g. `boost::irange`) transformed to function which returns the indices in merged array. I mean this is not STL but at least range-v3 territory. But I agree that duplicates make it ugly, I was solving this task quite recently and ended up with totally ugly solution.
I would never approve code like that in code review... , for example i would DEMAND!!! :P that default argument is removed for first constructor. 
I considered boost transform_iterator(that transforms to index in merged range), IDK if that is what you suggest... But I consider it not STL and ugly.... But IF I HAD TO DO IT... I would probably do something like that... 
Why? What would be your rationale? It'd create a lot of boilerplate if you want to create a lot of Foo's without parents (no that it's not workaroundable by the use of factory functions but still).
I disagree, one more nullptr argument is not that big of a problem IMAO.
I use tons of kde stuff on all my computers and can't remember the last time I saw anything crash. Have you reported any crashes you found to the developers?
&gt; In your last call, why do you need the additional counter incremented by one? In general, histogram is a way to compress information from billions of tuples into just a few bins. It is worthwhile to consider keeping as much info as possible. And when you're dealing with weighted MC generator, keeping # of events is VERY useful. Suppose I sampled 10^9 weighted events, got histogram, saved it. How I could later query how many events is in histogram? Why save some very small space for such inconvenience? This is the way to go, trust me ;)
&gt; Why are there no standard types like vec4&lt;float32_t&gt;? There is some work on that, see [P0203](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0203r0.html) [P0350](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0350r1.pdf) and especially [P0214](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0214r6.pdf)
&gt; How do you solve it with better than linear complexity? On a single sorted range you just pick the middle element(s), O(1) (given random access). OP’s twist is that there are *two* sorted ranges. But `nth_element` won’t help here, either. Without having thought too hard about it, you could probably develop a divide and conquer approach, comparing progressively refined medians in the two subranges against each other, hence the O(log n) runtime.
I'm more considering a future hypothetical processor that has an x87-like core with direct memory access via those registers (unlike the x87, which required going through the 32/64 bit system). The major processors at the moment all have SSE, but it would be terrible if the language were to enforce such a oligopoly. I can completely imagine 'obvious' features/limitations that we could have made in the past that would have prevented current CPU features, or even GPU advancements. As to why there isn't a vector-float type: It hasn't made it through committee yet. There IS a study group on parallelism that is very involved in SIMD that has those types under consideration.
&gt; But what are asking is to make int* ptr = 0;invalid. And that would break a lot. [as a wise men once said, break all the eggs](http://scottmeyers.blogspot.fr/2015/11/breaking-all-eggs-in-c.html)
So I came out with this range-v3 solution which is really ugly but I hope it works :) http://coliru.stacked-crooked.com/a/8b7071e39f37f871 Actually I think with no equal elements and sum of lengths being odd soluition could be much more concise.
indeed, that must be quite an uncommon thing to do.... #include &lt;iostream&gt; struct printer { void print(const char* string) { std::cout &lt;&lt; "string: " &lt;&lt; string &lt;&lt; "\n"; } void print(uint64_t i) { std::cout &lt;&lt; "int: " &lt;&lt; i &lt;&lt; "\n"; } }; int main() { printer p; p.print(1234); // ok p.print(0); // uh-oh }
How about using neural networks to recognise intermediate representation and output a better performing one?
&gt;&gt; but I am pretty sure it can not be done efficiently(log complexity) with STL. Maybe with something like this: template &lt;typename Vector&gt; typename Vector::const_iterator median(const Vector&amp; v1, const Vector&amp; v2) { auto v2_pos = [&amp;](int val) { return std::distance(v2.begin(), std::lower_bound(v2.begin(), v2.begin(),val)); }; auto best_pos = (v1.size() + v2.size()) / 2; return std::lower_bound(v1.begin(), v1.end(), best_pos, [&amp;](auto&amp; v1_a, auto&amp; v1_b) { return v1_a + v2_pos(v1_a) &lt; v1_b + v2_pos(v1_b); }); }
I hate the phrase 'follow me on twitter', so instead I'll just mention that there's lots more on my twitter account.
Then we can use neural networks to find optimum inputs (source code) in order to solve a problem. 
&gt; Some years ago (might be fixed by now) Chandler showed a case, where a compile time expression that evaluated to 0 is also treated just like the litteral 0. That's just how it worked prior to C++11. [diff.cpp03.conv] in the standard documents the breaking change of fixing that.
best_pos is going to go horribly wrong for pathological cases. Think a little further :) (Hint: I believe you need a recursive solution.)
Well, for KDE to do that, Qt should pushing for a more modern style. At the moment, they promote using heap allocation for all members and objects. The problem is that there is no perfect or optimal way to update the style of the library, and choices must be made and compatibility must be broken. I've seen many people talking about many styles for modern Qt. I think what is missing is experiments. We should fork and try stuff in order to gain experience. No I'm not talking about making copperspice2, but just trying stuff and see what happen to gain experience with Qt and a transition to a modern style. [This talk](https://youtu.be/tNXyNa6kf4k?t=8m47s) is making a very good point about Qt. If this style is adopted, programming with Qt widgets would be closer to the coding style of QML.
"The median is the value separating the higher half of a data sample, a population, or a probability distribution, from the lower half." 
IDK, I never solved it, what smells to me here is that you never return element from v2 if I read your code correctly... if you want to solve it online: https://leetcode.com/problems/median-of-two-sorted-arrays/description/
I posted link to leetcode if you are interested, but they do not have boost or ranges there... 
This is very ugly code that I would never allow to be added to a codebase(disregarding overload resolution I can not stand char*). So for you it may be a real problem, not for me. :)
 void spanish_inquisition() noexcept { throw std::unexpected; } And yes, it exists.
Isn't that oligopoly already effectively being enforced by the entire ecosystem, though? There is an absolute mountain of interfaces out there, both in hardware and in software, that demand things like 32-bit integers, or 8-bit characters, or 32-bit floats. Not to mention other standards (Posix demands an 8-bit byte, OpenGL specifies fixed widths for various things, etc.)... 
Interesting, I wasn't aware of that. Thanks!
There are definitely other standards that enforce said oligopoly. The C++ Committee strives to not FORCE it. We definitely have 'optional' parts of the standard that do (such as the stdint header), but preventing a past or future architecture is not in the language's best interest.
Interesting idea. How could we guarantee that the transformation is correct and preserves functionality?
I may have misinterpreted what your code was intending to do, because it’s broken anyway. Try your code on &lt;1,2,3,4,4,4&gt;, &lt;9,9,10,11,12&gt; or &lt;1,2&gt;, &lt;3&gt; for that matter. It falls over in a heap and waves it’s little legs in the air :)
&gt; We should fork and try stuff in order to gain experience. No I'm not talking about making copperspice2, but just trying stuff and see what happen to gain experience with Qt and a transition to a modern style. My personal wish-list for this would be : * Kill PIMPL usage, to hell with ABI compatibility. No more QObjectPrivate allocated everytime. Ideally, creating a raw QObject on automatic storage should incur zero allocations. * All the core classes (QObject, QVector, QPen, QPainterPath, etc) should be header-only. * Provide helper namespaces that put all the qt classes in `qt::` with lowercase naming policy: `qt::list_view`, `qt::string`, etc and put these in C++ modules * Rename the containers so that their name represent what they actually do (eg QList -&gt; qt::pointer_vector, QHash -&gt; qt::unordered_map) and spin them off in a custom out-of-qt header-only library specialized in COW containers and classes. * Allow to do mixins with QObject, templated QObjects, etc... for instance with [Verdigris](https://github.com/woboq/verdigris) OR * Try to leverage public funds and sacrifice goats to Elon Musk to get metaclasses accepted in a special christmas bonus edition of C++20, rewrite moc with them and enjoy a life of leasure with unlimited appletinis on a bahamas beach with the money gained from the successful investments in Nokia's revival with Qt++ 6. * Switch to CMake 
I don't think that O(log n) solution exists for this problem. You can't reliably binary search 2 ranges simultaneously, especially if they cover different amount of elements.
Same as every transformation out there. There's a set of verifiers, tests, etc.
see the link i posted in replies to other comments. it is log(m+n)
`nullptr` as a name has a hidden message - there is no `nullref`
I would *love* to work with C++ without it warts. However, deprecating so many things wouldn't be creating a new C++ edition, it would defacto create a new language and split the community, as many wouldn't be able to switch. We've seen it with Python 2.x vs Python 3.x. It isn't a change as hard as a whole new language (like from C++ to Rust), but still - and Python programs tend to be smaller and shorter-lived than C++ ones.
Actually, that problem was new to c++11.
Yes, the second lower_bound is broken. The idea is: auto final_pos = [&amp;](int v1_index) { auto val = v1[v1_index]; return v1_index + std::distance(v2.begin(), std::lower_bound(v2.begin(), v2.end(),val)); }; auto final_median = (v1.size() + v2.size()) / 2; return std::lower_bound(v1.begin(), v1.end(), // somehow compare final_median with final_pos(elem) }
That is a great post. Thanks for the link. Too bad Scott's apparently no longer involved in the c++ community.
I think the one advantage the proposal has over the Python 2.7 / 3 Split is that the change can be made gradual. 
Sure, I respect your opinion. :) I am trying to explain why this is out of my scope...
So you agree this code is terrible and one shouldn't be able to even write this, as it makes no sense and has a high chance of errors?
&gt; - Isn't worth it as a result You are probably right
Was there a reason not to use the std::adjacent_difference algorithm for your examples rather than std::inner_product (besides this article's being about std::inner_product)?
Yes, it is not a required dependency. No, a non-normative example is enough to encourage at least some people to depend on it. To realistically deprecate this dispensation, this is opposite of helping.
I mean, Qt *is* pushing for a more modern style. They are deprecating things C++ now provides its own solutions for (e.g. Q_FOREACH) and modernizing their implementations to use the stl where possible. On the other hand, the Qt API is so much nicer to use for newcomers or people who want to write some GUI application with C++ but don't have ten years of experience. Ever tried to explain why and how you need to write vector.erase(std::remove_if(vector.begin(), vector.end(), [](int x) { return x == 3;}, vector.end()); for removing all items equaling 3 from a vector, compared to explaining to write vector.removeAll(3); ? I have, and option 1) is a hell of a lot harder to do. And I think a lot of the choices (parent-child memory management, QObjects on the heap, etc) help this purpose: unlike e.g. boost, the code is usually not a jungle of templates only a C++ guru can see through, but relatively simple and pragmatic. This has its disadvantages of course, but it also has its advantages.
Why do you think we are not trying to do that? We *are* using more modern C++ in new code; however, most of the KDevelop codebase is from like 2009, where it simply didn't exist yet. Modernizing such code is very costly, since it will inevitably introduce new bugs. 
We could teach it the rules, of course. If the neural network break a rule, we induce negative feedback. However, I'd expect the neural network to sometimes not respect the rules, but I'd also expect it to produce a program that behave the same. If we test it with a lot of large applications coded with a variety of styles, and fuzz test the program to see if it somewhat behave different, and induce negative feedback in such cases, it could do very neat thing like devirtualization, or even transform code that uses the heap into code that uses the stack.
`NULL` doesn't work with templates. `nullptr` does because it participates in the type system.
Right, it just seems to me that we would be introducing an aspect of unpredictability. There will always be the risk of it producing bad output that breaks the behaviour of the code. Perhaps small code changes could change which decisions the underlying neural network makes, breaking code that worked previously in very weird ways. I guess if this happens at a frequency that approximately matches compiler optimization bugs today, then there it's no big issue and we could retrain the network with more data to resolve the bug. I guess it just needs sufficient training data to attain an acceptable level of compiler bugs.
One additional value for each bin is not always negligible. Sure, you may sometime like a per-bin count, but you could also keep that in a separate histogram (perhaps with different binning). For MC it's not uncommon to also want to keep track of the sum of square weights for each bin. I had trouble reading the documentation, perhaps I missed something, but is there support for that? Generally, keeping track of one or two (or more?) values accumulated in a generalized way (consider std::inner_product) would be useful, but multiple histograms will also do (most) of it.
You could fork and pipe to something like [feedgnuplot](https://github.com/dkogan/feedgnuplot).
It's not deterministic simply because floating point math is not commutative. Calculating `s` as the sum of `eps, -eps, 10.0d` can give you a few different results. Sometimes this just results in (small) cancellation errors, but it can escalate, for example if you draw `n=floor(s)` random numbers (now in a single thread for the sake of argument), the rest of the execution will be completely out of sync.
I thought Q_FOREACH and stuff were dead long ago. When I'm talking about modernization, I'm talking about something much deeper than the overuse of macro Qt has promoted when macro were the only solution for usability. I'm talking how the whole model could be changed to be more concise, promote automatic storage and value semantic, more concept based, and catch as much error at compile time it can. I must admit that we might need features from C++20 for that to happen. Qt developers actually recommend using the STL when possible. Also, the usability problem of the STL goes away with ranges, and hopefully they are included in the standard soon. You can use ranges-v3 today if you download the library. In my opinion, the parent-child memory management is an abomination today. When I saw a owning raw pointer, all my alarms are ringing. It's only a matter of time, your codebase *will* leak, because the compiler cannot ensure it. Sure, in C++98, that model was quite clever and from an usability standpoint, it was a huge win over manual memory management. However, we got so many better tools today! RAII should be used in future Qt. `std::unique_ptr` is a total game changer. The best we should have is to not even think about memory management. Only about object lifetimes, and doing errors should be hard to do. I saw beginner code that leaked everywhere because "with Qt you don't delete". Explaining the whole parent-child model was overwhelming for him so I ended up telling him where to delete. We should not even have to think about having these problems today.
Hi, yeah it's pretty much the same talk. The differences are: some new material around shared memory, enums, and compiler hints (builtin_expect, _hot/_cold, _always_inline/_noinline). And the intro was somewhat different. I'd have liked to have presented other new material, but it's hard to find the time given that cppcon wasn't that long ago.
You could use neural networks to guide an exploration phase that still verifies the transformations are correct.
I guess the concern then is whether this can be done fast enough for every set of exploratory transformations that the NN optimizer applies.
Yeah, allocate in a different thread, and pass the pointer across. All I am saying is avoid allocations/deallocations in the hot thread as much as possible. Oh, and watch out for inlined destructors... that can be costly too.
Looks like there's a second edition of that book coming at the end of this month.
Hmm fair points with MPL and variant. variant I'd probably go with C++17 or a header-only implementation ;-) MPL is a pretty old beast that I would avoid anyway. &gt; Even with pybind11 you don't get a header-only lib, because you have to compile a Python module with the Python interface to the histogram. Yea sure, but the module that you compile doesn't have any dependency to any non-header-only library, so all it needs is a bare compiler (with STL), nothing else. I completely get where you're coming from, it's "just" boost, it's available on any platform and any machine anyway. I used to think like that. But nowadays there's so many good, modern, small, active, and excellently maintained header-only libraries on GitHub. And so many things in boost really show their age. So things have shifted quite a lot in the past 3-5 years.
&gt; One additional value for each bin is not always negligible. pretty much it is wrt how they usually used &gt; I had trouble reading the documentation, perhaps I missed something, but is there support for that? yes, AFAIK - look at https://htmlpreview.github.io/?https://raw.githubusercontent.com/HDembinski/histogram/html/doc/html/histogram/rationale.html#histogram.rationale.variance 
&gt; In my opinion, the parent-child memory management is an abomination today. in one sense, true, but in another, it is absolutely necessary for UI work to have a tree of objects that you can walk at runtime; if you remove this it just makes Qt much less useful. &gt; promote automatic storage and value semantic, this would be hell. You wouldn't be able to use connect anymore : a very common case is something like connect(my_object, &amp;Foo::bar, this, [=] (int x) { if(x &gt; 2) my_object-&gt;bamboozle(); }); which can't work if you are able to do MyObject my_object; ... initialize some connections .. auto obj2 = my_object; // what happens to the lambdas here ?
Deprecating is not removing. It's just flagging the usage as ill-advised and _planned_ to be removed. It might still stick in the standard for another 30 years before actually being taken out. :) All it would ultimately mean in the short term is that compilers would start warning when a literal zero is converted to a pointer and would offer some kind of `-Wno-zero-as-null` option to silence the warning. And that would only even matter if a developer updates their compiler version _and_ their build system's `-std` setting to a version where zero-as-null is deprecated. Heck, even after the feature _is_ removed, it would only matter with the appropriate `-std` flag _and_ there'd undoubtedly be a `-fzero-as-null` to turn it back on, same the bazillion other flags every compiler has to tweak non-standard behavior. Ultimately, the only thing that matters: is there an actual for-real desire to remove zero-as-null in the (far) future given the cost of applying those changes over the intervening years? If yes, then deprecate ASAP so folks have plenty of time to transition code gradually and still give us reasonable odds of removing it before C++47 and the whole debate has moved on to "deprecate `nullptr` for `meganullexprdeclptr`?" :p
Cool! Thanks for the heads up! Hope it'll be available on Kindle for Europeans...
FYI, [Boost.Mp11](http://www.boost.org/doc/libs/develop/libs/mp11/doc/html/mp11.html) will ship in Boost 1.66 next month, and is _much_ lighter on compile times than MPL (not to mention less ugly). I've ported a few projects over from MPL and Brigand and haven't found any real downsides yet.
I agree for the tree construction. That information is useful. A patent should have a list of child for a variety of use cases. It simply shouldn't be used for memory management. I said promote value semantics and automatic storage, not enforce it :P I believe a lot of use cases don't actually need heap allocation, but with the way Qt works today it's simply easier newing all widgets. The connection + vector problem is a very interesting one. I wonder what's possible to do for that.
I indeed assumed deprecating was removing. If it was done, I fully agree it would be the way to go. However how would it work with the standard? afaik, it either keep functionalities or remove them. Compilers flags (like no-rtti) are out of the standard scope.
This can in fact be done efficiently with the STL. The quick way is to use something like lower_bound. You'll need to back out the integer index in your comparator by subtracting the address of the element you are passed. Then use that integer appropriately to index into the other array. If you do all this correctly, you can actually build a comparator that works. This only works for vectors or arrays or other things with contiguous storage. If you want it to work for e.g. `std::deque` you'll need to build a random access iterator, which internally holds an integer and a passed lambda, and on dereference simply calls the lambda with the integer. This can be reused for many problems, but it is a pain to write in the first place. 
I will port as well, then. :)
You're always finding nitpicks with people's examples without imagining how it could be changed slightly and still demonstrate the same issue. What if it was void* instead of char* in the case that you wanted to print the value of a pointer? Also, the overload resolution problem obviously exists specifically because 0 can be interpreted as multiple things. This code wouldn't be garbage if that wasn't a part of the language
&gt; I wonder what's possible to do for that. The right thing to do would be to pass the "this" pointer as argument but this would make all lambdas more bloated (visually speaking: `[=] (QAbstractItemModel* self, ...) { }`). The fun thing to do is to [abuse reflection](https://godbolt.org/g/2xEvKA)
Ok, but what kind of computation do you want to do with the weight *and* the count? Is it a common case that I don't see? Then I will add an additional counter. But if it is something uncommon, then I would suggest to fill two histograms, one with weights and one with counts to get the same. Adding a counter increases the memory footprint by about 50 %. That is a lot and that why I am asking you these details.
I don't think this would be a particularly good application of neural networks. ANNs are good at pattern recognition, but they're not good at identifying unique, arbitrary, and/or sufficiently complex solutions.
Agreed :) I do that all the time and there is an example in the user guide how to configure the histogram in Python, pass it to C++, let it be filled there at maximum spees and then you get it back in Python. Thanks to Numpy support, it is easy to plot the counts with matplotlib.
Well, Python is awesome. Or do you like Perl? ;P
MPL is pretty awkward, but it is tested and true code. I think you do not give Boost enough credit. Some libs may be a bit old, but they have been tested on a ton of platforms. The code is super reliable and the chance to find a bug is very low. The extensive testing on many platforms is something that many other libs do not do.
Very interesting, thanks!
&gt; However how would it work with the standard? afaik, it either keep functionalities or remove them. The standard has deprecations. One of the more well-known examples was `auto_ptr`, which was deprecated in C++11 and removed in C++17. A whole batch of library features were removed in C++17 that were deprecated in earlier versions. &gt; Compilers flags (like no-rtti) are out of the standard scope. The point I was trying to make is that the C++ standard isn't required to be 100% perfectly back-compat for all time for all code, and it isn't. It's removed language features (`export template`) and library features (`auto_ptr`), it's changed the meaning of keywords (`auto`), changes the semantics or legality of expressions (`bool++`), added new keywords (`decltype`), changed library semantics that cause probable ABI breakage (`list`), and so on. The C++ committee relies upon the fact that it can make reasonably-calculated breakages to language and library and rely upon the vendors to supply extensions or configuration flags for any users inadvertently bitten by the changes.
std::auto_ptr was not considered 'unused'. It had major problems with it and had a better replacement. But it was used quite a bit.
Yes. If you were to use std::adjacent_difference, you would need an output container where to store the adjacent differences. Such container is not really needed, since we're only interested in the smallest adjacent difference after all.
In answer to the last question about finding new warnings: the flags that turn on all warnings actually can be useful and actually usable in production. The key is using a subtractive strategy for warnings rather than an additive strategy. Instead of selecting particular warnings to turn on, and then having to periodically remember to go find new warnings manually, you instead just turn on all warnings in your production builds, and disable individual warnings after analyzing whether they're useful for you or not. That way, whenever any new warnings are introduced in new versions of the compiler, they're already enabled and you get notified about anything new that's triggering on your codebase. One issue is that gcc for whatever reason doesn't have a way to enable all warnings, so you're out of luck if you want automatic notification from gcc. Another issue with a subtractive strategy is that third party and platform headers likely won't have been developed to be clean under the same set of warnings you care about. Since those headers probably aren't warnings clean you need to be able to suppress warnings for those headers. For example with gcc/clang you can list header search paths as 'system' headers, and warnings for them will be suppressed. Unfortunately there doesn't seem to be any equivalent functionality for MSVC. To help make sure your headers don't cause similar problems for third party project consuming them you can disable warnings via pragmas instead of via build-system configuration. Something like [this][1] [1]: https://wandbox.org/permlink/sLlxDupXPzjYUZ6l
A couple thoughts: 1. ABI compatibility isn't particularly useful for open source, but it is a huge deal for commercial stuff because it allows you to distribute binary plugins to software without having to match exactly the version of Qt that the application was compiled against. This can allow plugins to continue to work with new versions of the application assuming that the application ABI didn't break. 2. Qt is unlikely to switch to CMake as their main build system. QBS seems far more likely at the moment. I don't see why it really matters what build system Qt uses though, building projects using Qt is easy and well supported with CMake, QMake, and QBS. 3. Qt already assumes that all const char*, std::string, etc. are utf8. Why does it particularly matter what the internal representation of QString is?
To back you up, you can listen to [STL's experiences changing `NULL` to be `nullptr`](https://youtu.be/AKtHxKJRwp4?t=3436).
KDE Plasma was the worst. I used a release version and it wouldn't stay up for more than a few minutes. 
Are you sure it's logarithmic in the worst case?
This code is pretty dangerous because you will most likely call the wrong function with `NULL`. Thankfully, you can avoid this problem by avoiding raw pointers since smart pointers won't convert so happily from NULL so they force you to be careful.
Simple case - you have phase space covered with histogram, and are getting weighted events. After 10^9 events you have filled histogram - so far so good. But WITH counter you could discover that some part(s) of phase space, while having at first glance good coverage, actually are overrepresented - many, many, many small weight events. Easy to see - you divide bin weight by bin counter and voila! So you have to redesign your algorithm to have importance sampling/variance reduction technique applied. And while filling with two histograms might work, it is a lot of hassles plus it would be a LOT slower - while having counter and weight together in one cache line is simple adn effective
The biggest change is that the `/permissive-` conformance switch is now default for new projects. We will drag our developers kicking and screaming into the future! /s
does it fully support hana or rang.v3 now?
Are structured bindings not currently supported? Could have sworn I used them a while ago. 
Is the internal architecture upgrade of the compiler now complete? Looks that way considering how quickly new features are arriving at least!
Structured bindings were added in 15.3. Odd that they're called 'new' here since the context seems specific to 15.5...
IIUC, that will be the next major update after this one, wherein expression SFINAE should (finally) begin working sufficiently to use libraries like Hana and mainline Range-v3.
There is a port of Range-v3 available for VS2015: it still works with VS2017. But the main trunk does not work quite yet. Our compiler supports Boost, and has supported it for a while now. 
It's hard to keep track with all the new features coming online : ) I believe the issue was that debugging integration for structured bindings wasn't implemented in 15.3.
No, [the compiler rejuvenation effort](http://aka.ms/compilerrejuvenation) still isn't complete. We're working in parallel between a general conformance effort and the rewrite of the parser and internals. The two efforts are closely linked, as the latter enables the former. 
This seems really nice, I was just recently curious about a good gpu computing abstraction library. Several questions though: What about compiler compatibility, is the MSVC supported? Have you got any plans on supporting the Intel HD graphics?
&gt; NULL doesn't work with templates. nullptr does because it participates in the type system. Like I said I know the "party line" why NULL is bad( I even remember your C9 video where you said people used NULL as string terminator :O) , it is just that code I write "never" suffers from this problem... Since your code has a hight &lt;/( ratio :P I guess it may be more important for you. For me it is meh, I got rid of one CAPS LOCK macro, but it was not that bad. 
You can read my reply where I explain why this can not be done with lower_bound/binary_search (IMHO obviously). 
No, but that is the listed requirement on the problem web page so it probably is.
Same goes for `if constexpr`. Been using it since the initial release of VS2017. 
Minor nitpick is that I find permissive- unintuitive. Now it is too late to change it but for the future switches maybe consider using a bit more time when deciding on naming.
I thought I wouldn't be able to use this due to SDK problems from having to build v141_xp, but all that was needed was a forward declaration of IUnknown to work around a simple template issue in objbase.h. Quick addition to stdafx.h and the build ran through and immediately found half a dozen conformance issues in a 380kloc code base. Thumbs up from me. 
https://www.reddit.com/r/cpp/comments/5dh7j5/visual_c_introduces_permissive_for_conformance/da4n79y/
Well that's a sad truth - lack of simple `ints/iota` range/iterator in the standard makes people write hand-rolled binary search a lot in alogrithmic/competitive programming tasks. That's one of the reasons why it would be really great to have range-v3 in the standard.
Thanks for the link. Yes, I find `/permissive-` unintuitive too, but it's a temporary problem. One day we'll have a `/permissive` switch instead. 
I would suggest avoiding at all costs building your own build system. Even writing your own Makefiles is better than building your own build system. I know because I wrote two different build systems and they were both wasted work. Also, I worked with other people's own build systems, and they were painfully unequipped to handle the slightest changes of context. Before writing your own build system, consider all possibilities. Do that before you invest work and affection in a separate project. Consider extending an existing project, and try to communicate with people doing cmake or build2 or any other build system, because they probably are working on the same features you want. Help them, and help yourself in the process. Trust me, it's harder than you think.
did they fix the size_t bug? :P 
Well calendar example was not working with that range-v3 fork as far as I remember, so it wasn't fully usable to be honest.
I can usually eyeball the complexity, but this problem is actually quite tricky and I'm not sure I7d get the math right.
/u/AndrewPardoe any plans on having /permissive- or another switch that disables extra extensions? For example disabling [__super](https://docs.microsoft.com/en-us/cpp/cpp/super) and/or [__interface](https://docs.microsoft.com/en-us/cpp/cpp/interface)
For me it is quite easy if there are no duplicates... If there are it gets uglier... But I still believe it is logaritmic complexity... 
I use it everywhere I can. There's no point trading off maintainability "for" readability when your IDE should tell you the type already. [Autophobia](https://www.youtube.com/watch?v=V4DkJtT2jdE)
Twice the memory usage for most strings, going from std::string to qstring or conversely is more expansive than just doing a copy
I am 99.99% certain that you are mistaken. I recorded `if constexpr` as being checked in for 15.3, not RTM.
I'll take your word on it.
adjacent_difference is really another algorithm. In addition to what /u/transfear wrote: * adjacent_difference does not **map**: the main reason is that you have to pass a destination range which underlying values are constructible from the source range values; * adjacent_difference takes a single input range (e.g. the third example is not solvable and you cannot zip the sequence with itself by shifting by K positions); * adjacent_difference does not **reduce** (e.g. we pay a subsequent accumulate); * adjacent_difference copies the first input element straight into the destination (e.g. maybe we need extra care of that). I put your question in another form: in my second example, suppose we want to find both the number of adjacent equal characters and also where such characters are. This is an easy job for adjacent_difference: string S = ...; vector&lt;int&gt; dest(S.size()); adjacent_difference(begin(S), end(S), begin(dest), equal_to&lt;char&gt;{}); cout &lt;&lt; accumulate(next(begin(dest)), end(dest), 0); Ignoring the first element, dest contains 1 if the corresponding element in S is equal to the previous one, 0 otherwise. In such scenarios, where it makes sense to apply a function to each contiguous elements and store results, adjacent_difference works well.
I am late at the party :) Thanks for sharing this problem, I think many interesting ideas to solve it came out from this post! I'll put it on my list.
Seems nice! How well does it perform in comparison to pure cuda, openmp offloading etc? How about performance portability? 
Really great stuff, Kudos to the VS them. &gt; `export module FileIO` That's crazy though. what's the rationale ? 
If by Raw pointers you mean: UPROPERTY() UMyObject* foo; Then it is not really raw pointer. It is garbage collected and reference counted (though unlike shared pointer you can corner yourself into circular depedency here). Whether I agree or not with the rest I can't tell I would need some more details. In principle I can easily tell how long UObject will live and how owns it. Reflection cloud be probabaly done better than using macros, but I guess when work on UE4 started Clang wasn't in the place where it is now (nor was C++, but then Epic is pretty quick to adopt new shiny things into code, usually the show stopper here are third party depedencies or consoles).
Yeah, you're probably right. Either way, `if constexpr` wasn't introduced with 15.5.
Is anything known about M? For example, is it a power of 2?
Ah, sorry forgot to mention it, we don't have any info about it. If it was power of two it would be much easier, but unfortunately not necessarily.
Is m constant ?
What about dividing (a,b) into high and low 32 bits? a*b = ah*bl*2^32 + al*bh*2^32 + ah*bh*2^64 + al*bl Each of the (a*b) parts, without the 2^N shift, is still less than 64bits. The modulo part is still tricky, but you can use rules such as this to reduce it: x*y*2^64 % z = x*y*(1 + MAX_UINT64%z)%z
what do you mean by constant, you're given a,b and M. 
What about dividing (a,b) into high and low 32 bits? `a*b = ah*bl*2^32 + al*bh*2^32 + ah*bh*2^64 + al*bl` Each of the (a*b) parts, without the 2^N shift, is still less than 64bits. The modulo part is still tricky, but you can use rules such as this to reduce it: `x*y*2^64 % z = x*y*(1 + MAX_UINT64%z)%z`
yes I gave it some thought too, but I still have hard time calculating, xy2^64, because xy is 64 bit and (1 + max_UINT64%z)%z is ~60 bits. so we're not really reducing the problem, we still need to multiply two 64 bits with this split.
It sounds as if you want to run your calculation more then once. If m is the same for many calculations I think this can be optimized
yep, indeed that's the case. M changes, but I have to use multiplication quite extensively for each M. How do you think I can optimize?
Why four times? Should be two times ... I think the utf8 vs utf16 thing is up to debate. To me utf16 seems pragmatic, for various reasons -- surrogates are much easier to handle programmatically than the utf8 multi-byte characters (esp. you can handle them locally, without iterating over the whole string from the start), and the length of the string _usually_ matches the length of its visual representation. I understand utf8 is great as long as your content is "English text", but really, already for German text, it gets relatively complex.
&gt; Explaining the whole parent-child model was overwhelming for him so I ended up telling him where to delete. We should not even have to think about having these problems today. I don't think that viewpoint is realistic. If you program C++, you have to understand how object lifetimes work, no matter how you memory-manage them. The Qt parent-child memory model has the "advantage" that if you have no idea what you are doing, you typically don't leak most objects because they are automatically destroyed, but in the medium to long term, you have to understand how it works either way. That is true for smart pointers or stack allocations as well.
IMHO a recusive lambda is a bad idea, so I don't want syntactic sugar for it.
https://stackoverflow.com/questions/20604840/vectorizing-modular-arithmetic the links in the answer could be useful
But then it wouldnt even be c++, so at that point you can fork it, do all the breaking changes you want, and release as another language.
Well, maybe it should, but in practice $ g++ -flto -O3 -std=c++17 -fPIC test.cpp -I/usr/include/qt -I/usr/include/qt/QtCore -lQt5Core $ ./a.out 530065408 std: 0.228437 QString: 1.00466 I consistently get this kind of numbers, with both g++ and clang, starting from -O1 
well don't use recursive lambdas if u don't like it... but it might be useful to someone else, ["Allowing a useful feature is more important than preventing every possible misuse of C++."](https://en.wikipedia.org/wiki/C++#Philosophy)
I think I disagree, the right thing to do is to not make QObject have value semantics. I'm all for value semantics, but only where it makes sense. A QObject isn't a value -- just like a TCP connection isn't a value. It does not make any sense to treat a button on your screen as a value, copying it has no useful meaning.
I think that the main reason why people want "value semantics" for Qt object is because currently if you want to store them you have to do std::vector&lt;MyQObject*&gt; vec; and many would like to do std::vector&lt;MyQObject&gt; vec; instead to remove an unneeded indirection. The problem is that you can't push_back / randomly erase due to the non-relocatability of QObject. Having a container that allocates QObjects "close to each other" would already be a nice boon in performance.
/u/AndrewPardoe https://docs.microsoft.com/en-us/cpp/cpp-conformance-improvements-2017 states: [[fallthrough]] attribute (available with /std:c++latest) - why is this /std:c++latest and not /std:c++17 ? I thought it was a C++17 feature (http://en.cppreference.com/w/cpp/language/attributes) 
Thanks for the link, but I don't think the results there will be able to help me, because in their case it's sum, which still fits in 64 bits and they can use conditional subtract, but it will take eternity for me reduce 128 bit integer to 64 bits with subtraction.
&gt;The basic principle of this algorithm can be expressed in this formula: a / b ≈ a * (2n / b) &gt;&gt; n This calculation goes through the following steps: 1. find a suitable value for n 2. calculate 2n / b 3. calculate necessary corrections for rounding errors 4. do the multiplication and shift-right and apply corrections for rounding errors. This is the interesting part
Do you have a valid, useful situation where a recursive lambda is a good solution? Writing a `factorial` function is not convincing anyone.
So any idea when expression SFINAE will be supported then?
depending on the exact semantics of the lambda, because C++ does not allow nested functions directly, lambdas could act like nested functions semantically if someone prefers to do nested functions, say if ur writing an implementation for [Introsort](https://en.wikipedia.org/wiki/Introsort), and it should have 2 inner functions, Heapsort() and Quicksort(), and these 2 inner functions have to be lambdas, and Quicksort() does require recursion
If we need nested functions, my suggestion is to allow creation of nested functions. Lambdas are heavier objects with context, context that gets copied around. Lambdas probably cannot be optimized the same way a declared function is optimizable - because they end up as complex instances. 
I don't know about fastest runtime, but for fast development time, OpenSSL's libcrypto bignum library has a BN_mod_mul() function that does just this. Or GMP, but it doesn't seem to have a handy all-in-one function like that (Not super surprising, since it's not tuned for crypto use like BN).
Yep i looked into it, not really attuned to my needs. im looking for fastest runtime method
Use QStringLiteral for the QString, that's the fair comparison imo.
Hm, but do you really have lots of QObjects somewhere? I feel like in my Qt applications lots of things are slow, but never ... iterating over lists of QObjects, simply because I very rarely find myself having more than thirty of them in one place.
if would be nice if nested functions are directly supported in C++ someday and again, about if we need nested functions or not, ["Programmers should be free to pick their own programming style, and that style should be fully supported by C++."](https://en.wikipedia.org/wiki/C++#Philosophy), nested functions make sense logically, if something is semantically an exclusive building part of another more complex function, it should be contained in the larger function and should not be in the same scope with the larger function
what about this: template&lt;class Lambda&gt; struct recursive_lambda { Lambda fn; // decltype(auto) to forward the exact type returned by fn(...) template&lt;class... T&gt; decltype(auto) operator()(T&amp;&amp;... t) &amp; { return fn(*this, std::forward&lt;T&gt;(t)...); } template&lt;class... T&gt; decltype(auto) operator()(T&amp;&amp;... t) const&amp; { return fn(*this, std::forward&lt;T&gt;(t)...); } template&lt;class... T&gt; decltype(auto) operator()(T&amp;&amp;... t) &amp;&amp; { return std::move(fn)(std::move(*this), std::forward&lt;T&gt;(t)...); } }; // typical usage: // // auto fun = make_recursive( // [...](auto&amp;&amp; fun, arg1, arg2, ...)-&gt;ReturnType // { // ...; // fun(arg1, arg2, ...); // ...; // }); // // consider above to be: // // ReturnType fun(arg1, arg2, ...) // { // ...; // fun(arg1x, arg2x, ...); // ...; // } template&lt;class Lambda&gt; inline recursive_lambda&lt;std::decay_t&lt;Lambda&gt;&gt; make_recursive(Lambda&amp;&amp; fn) { return {std::forward&lt;Lambda&gt;(fn)}; } 
We already can achieve anything that a nested function offers using namespaces. Is there some magic feature I'm missing that cannot be developed in C++?
I have multiple such cases in my current metaprogramming library. The combination of explicit template syntax and recursive lambdas would completely remove the need for ```namespace detail``` in my library and improve locality (lambdas don't need to access functions outside their local scope). This is a net win for readability and maintenance from my perspective.
Of course it can. You can find back the index of the element (provided contiguous container, like vector) using something like [](const auto &amp;elem, int dummy) { size_t i = &amp;elem - cont.data(); }
semantically speaking, an inner function should have the ability to capture the local variables of the outer function, which is a lambda with a capture list of "[&amp;]", a "normal" function does not have the ability to capture local variables in other functions, u gonna have to pass all referenced local variables as parameters, **explicitly**, which is just ugly (lambdas do this as well, but implicitly, and that's just a lot prettier)
Thanks for your concern! I can safely say I spent a decent amount of time researching ways to make other build systems work for my needs, but in the end nothing other than possibly build2 could do what I needed. So why not use build2? Because I'm enjoying the process of creating this build system and I have a few goals I also want that I don't see in other solutions. The amount of time I spent trying to make other build systems do what I need, is actually greater than the time I spent working on my own. It already works great for one of my projects and I've barely spent any time on it. As an example, using the simple buildtool I made, I can use clang in Visual Studio to compile to different targets, with support for modules which is mandatory in my case, as easily as using Visual Studios build system. No other tool out there that I could find made it that easy. Granted it may not work great for every project, but its already saving me time on my builds. Thanks for the concern though. 
Ranges TS does not have it either (in the current form). Views are supposed to come later, in some thing like Ranges TS v2. 
And how do you test your inner functions when they grow out of proportion? Because you can't call them without the containing function, so you can't really unit test them, from what I understand. But, as you said, it's a different style of doing things. I would see warning signs and code smells, you probably will like that a lot better. You asked what people think about the idea of having recursive lambdas and, while I digressed a bit, I still think they are not a good thing.
Your solution skips comma after the first item, not the last one. It should be out &lt;&lt; printed_delim &lt;&lt; item;
You can't magically make `return n * fac(n - 1);` work. You're going to change the name lookup rules such that... for lambdas, specifically, name lookup can go find names and refer to them but make the type deduction still tidy? How would this work if I want a recursive lambda but just want to pass it directly to a function, without assigning it? The shortest way to write this in C++17 is just to use a y-combinator: template &lt;typename F&gt; struct y_combinator { y_combinator(F f) : f(std::move(f)) { } F f; template &lt;typename... Args&gt; decltype(auto) operator()(Args&amp;&amp;... args) const { return f(std::ref(*this), std::forward&lt;Args&gt;(args)...); } }; auto fac = y_combinator([](auto self, auto n){ if (n == 0) return 1ull; return n * self(n - 1); }); 
OK, solve it and show us your code. :) No raw loops, just STL, no boost.
&gt; (because the literal format already matches its internal format). well yes, that's the point ! If QString was UTF-8 this conversion would not be needed either.
`#define __super #error`
I believe because C++17 support is still in testing stages (and far from complete) so it wouldn't make sense to have a flag for it just yet.
there's not only the performance of iteration : it leads to less cache cohesion, more memory being used, etc. See also https://woboq.com/blog/qml-vs-cpp-for-application-startup-time.html 
With this being the default now, does that mean MSVC-specific features will just end up being scrapped/unsupported at a later date?
Super excited about this!
funnily enough, just this morning I had a need for something like this ; looked more-or-less like : auto blah = [] (auto obj, int x) { obj-&gt;doStuff(x); if(obj-&gt;whatever()) { QTimer::singleShot(0, [=] { blah(obj, x+1); }); } };
u/STL did you do some experiments how moving from SFINAE (aka overloading if :P ) to constexpr helps with compileing speed of STL code? I do not ask if you shipped any changes, I am more interested if you think it is worth the time to invest time to rewrite existing code that works fine for heavily used STL components from SFINAE to if constexpr. 
there was proposal to add y-combinator into C++, got downvoted hard. :)
 void print_tree(const Graph&amp; g, uint root_idx) { auto print_rec = [&amp;](uint idx, uint indent) { print_indent(indent); print(g[idx]); for (uint child_idx : g.enumerate_children(idx)) { print_rec(child_idx, indent+1); } }; print_rec(root_idx, 0); }
Ok thanks, thanks for explaining, I understand you know. Perhaps I can generalize the library so that your use case can be met, I will ponder it.
Can you explain what you're asking?
&gt; Can you explain what you're asking? Wasnt there a bug with const typedefs and (size_t is typedef...)
Really? Wow - they are the useful part of that library. Damn I wish someone would pay me to work in a good language ;)
&gt; How would this work if I want a recursive lambda but just want to pass it directly to a function, without assigning it? probably also adding new semantics for "this" keyword, "this" in a lambda function body would be a pointer pointing to the anonymous lambda object itself
That won't work either. I can capture `this` in a lambda, so this already has meaning.
Here you are, only one call to `lower_bound`: http://coliru.stacked-crooked.com/a/dfef22e26d664ff4 
Easy: http://coliru.stacked-crooked.com/a/dfef22e26d664ff4
&gt; UPROPERTY() UMyObject* foo; &gt; Then it is not really raw pointer. Exactly my point! It looks like a raw pointer, but it isn't. I don't know when or how the object is allocated and I don't know when it is going to be destroyed. I don't know what causes the reference count to increment or decrement. This is not "real" C++ - this is something that *looks a lot like* C++, but differs in subtle, yet important ways.
u got me here.... but this kind of thing also doesn't work on "normal" functions, cuz there's no anonymous "normal" function, if recursion could work on anonymous lambda, something that looks different from how recursion is written in "normal" function has to be defined for this, emmm, probably f([](auto n) { if (n == 0) return 1ull; else return n * =&gt;(n - 1); // "=&gt;" looks like some kind of forwarding, maybe "forward to another self-calling" or something like that }); ?
And another thing to think about - but that's I would say definitely somewhere in the future - abstract weight type and summation. So with many small weights user could use Kahan(Babushka, add12, ...) summation algorithm
Ah, so this isn't something you've run into, it's something you've heard about? I can check to see if anyone on the team has heard of this. I don't remember any bug reports on it.
OK, just be sure to read the correct problem description from the leetcode link I pasted because I would feel bad if you solve problem I may have represented wrongly. :)
`(1 + MAX_UINT64%z)%z` is also `(-z)%z` (because if z is a `u64`, `-z` = 2^64 - z, and 2^64 - z = 2^64 mod z.
http://open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0839r0.html
I can not read your code, but I can not find any bugs with it(beside you are returning floats, and you should always return value from one of 2 arrays) so here is an upvote. :)
Whether MSVCisms are scrapped is orthogonal to `/permissive-`. With the next major version we'll make `permissive-` the default and introduce a `/permissive` switch. All of the MSVCisms will live there. If this sounds exactly like what GCC did with `-fpermissive` then you understand the design. 
Paging /u/caseycarter. He's been promising me *forever* that he would be updating the repo and pushing back the changes into the main Range-v3 trunk. But he claims we still have a compiler bug or two... If you have a use case in shipping code where this is blocking you (as opposed to just tracking our progress), please let us know.
[We've supported most expression SFINAE throughout the VS2017 release](https://blogs.msdn.microsoft.com/vcblog/2016/06/07/expression-sfinae-improvements-in-vs-2015-update-3/). We've spent the VS2017 cycle fixing the loooooooong bug tail. Is there a specific example in your code that you'd like us to look at?
Depends on definition of median. I used the [one used on leetcode](https://leetcode.com/problems/median-of-two-sorted-arrays/description/), which returns mean of two middle elements if number of elements is even. If allowed to return any of the middle elements, solution would be 5 lines shorter.
/u/cleroth is correct. The idea of `/permissive-` is to isolate conformance changes that may require source-breaking changes in your code. It's about compatibility as much as it is about conformance. If you don't want to use `__super` or any vendor-specific macros, don't use them. By the way, as they are vendor-specific they conform to the standard. 
As /u/encyclopedist says, it can be done, and his solution is basically exactly what i was referring to. It's a bit complicated to get all the arithmetic exactly right, which is why I didn't give the answer (I'm impressed!). As I also said, you can construct another solution using the kind of iterator I described: template &lt;class F&gt; class IndexLambdaIterator { auto&amp; operator*() { return f(m_index); } IndexLambdaIterator&amp; operator++() { ++m_index; return *this; } // keep defining ==, !=, std::advance, etc etc std::size_t m_index; F f; } Once you have something like that, you can construct an iterator with a lambda that does something like `[&amp;] (std::size_t i) { return v1[i] - v2[k-i];}`, where `k` is half the total number of elements. You can then just pass this iterator (at two appropriate index values) into `std::binary_search`, searching for 0 and with the default comparator.
I believe this is a doc bug. We didn't have a `/std:c++17` switch until we got most of C++17. Right now, `/std:c++17` and `/std:c++latest` are the same, but soon the latter will include C++20 features. All C++17 work is being done under `/std:c++17`.
/u/STL likely knows the truth more than I do. He pays close attention. However, there were a number of `if constexpr` issues resolved after 15.3 went out. I believe that's why our compiler dev lead called it complete for 15.5. The high-level bit is that it's now supported. If I erred on the timing, I apologize. But as 15.3 is soon out of support, it shouldn't matter : )
Ask WG21, the C++ Standards Committee. 
Thank you!
Have you tried just using `__uint128_t`?
yes but there's no modulo operator in simd as far as I know at least
OK, sorry, my bad. :)
https://www.reddit.com/r/cpp/comments/6t2y59/c_core_guidelines_checker_in_visual_studio_2017/dli24f4/ Or is Core Check different from Core Guidelines Checker? 
Yes, I have seen the problem on leetcode, thanks!
`(__uint128_t(a) * b) % m` seems to work fine for me.
&gt; Rust guarantees that a move operation is a bitwise copy followed by a Drop on the moved-from value. Tiny note, and sorry for the thread necromancy here, but the moved-from value is *not* `Drop`ped. You'd get double-frees if that were the case.
If you read my long explanation of why it can not be done easily I say similar things. Problem is that you can not pass mid_index as argument to binary_search/lower_bound. so encyclopedist is correct, and I am also impressed he managed to hack that(so many ifs in the code :P ) 
Thanks for the reminder! I'll check on this. 
No, it's not that big of the deal I just wanted to play with ranges in MSVC and thought calendar was basic enough example. But it looks like it's actually not that easy to get it compiling. Maybe I should've tried it with more simple stuff.
Thanks. I guess "Terse static_assert" is therefore also wrong when it states: (available with /std:c++latest) 
Actually you're right, I can use gcc compiler and I think so far this is the fastest method. Thanks a lot!
Most of the DNN example programs in dlib (https://github.com/davisking/dlib/tree/master/examples) don't compile in visual studio 2017. It's odd because visual studio 2017 is worse than 2015 for this code. VC2015 compiles most of it. VC2017 almost none of it. VC2017 will just go into an infinite loop if you try to compile, for example, this file https://github.com/davisking/dlib/blob/master/examples/dnn_metric_learning_on_images_ex.cpp
&gt; Kill PIMPL usage, to hell with ABI compatibility. Tell me you're joking. You expect all your customers to recompile their code every time you make a release? You'll soon have no customers. I've worked in companies where breaking ABI would be a career limiting move.
You'd just do like everywhere else : bump the major version when the ABI breaks. But I must admit that I have yet to see a place that does not do whole rebuilds every time. You'd have to do it for CI anyways.
I don't understand what you mean by mid_index. In the code I wrote above, take `v2` to be the larger array, it is size M, `v1` is size N &lt; M. Then i is valid on the range from 0 to N-1. 0 represents the case where all the elements of v1 are larger than v2, and N-1 represents the other extreme. Then you can solve the problem by just doing: auto lam = ... // as before; auto it = binary_search(makeLambdaIterator(lam, 0), makeLambdaIterator(lam, N-1), 0.0); And probably examining the final iterator a bit to do the final bits of median logic (depends on odd vs even etc).
Yes, that's fine for internal software, but if your customers use your binaries there's no way they're going to compile your code before theirs. They pay you to do that. PIMPL will save your ass.
I would modify the proposal just a little bit, if the lambda object is not anonymous (assigned to a variable), and the optional lambda identifier is not defined, the identifier would be the same as the name of the variable that holds the lambda by default, so no redundant stuff like auto fac = [] fac(auto n) { ... fac(...); ... }; instead, just auto fac = [](auto n) { ... fac(...); // the identifier is "fac" by default because it is not explicitly defined ... };
It avoids surprises if you use it as a template parameter or similar.
I'm looking for C++ jobs in the Midwest myself (5 years experience *wink wink*) and wish I had better advice! My last job started out as a superficially Python and my usefulness in that role wore out and I was transferred to a greenfield C++11 project after a couple of years. So far my best leads in the current job search have been through recruiters on LinkedIn.
Do we really need yet another article about smart pointers? A feature that is almost 7 years old by now.
Still waiting for constexpr char_traits so that string_view can be used properly in constexpr. Writing this is getting old: constexpr std::string_view NodeType = std::string_view("constant", sizeof("constant") - 1); 
Maybe every article is unique?
&gt; is something the compiler should be able to figure out by itself. What am I missing? Only with optimizations and expensive analysis. It would be pretty terrible if code like `array&lt;int, size&gt;` only compiled in release mode because `size` could only be determined as a compile-time constant with optimization, and only on _some_ compiler's optimizers since not all optimizers are equivalent, and potentially breaking with compiler upgrades as optimizer changes. `constexpr` is a strong contract. It _requires_ the compiler to support compile-time constant evaluation of compatible code independent of the presence or quality of backend optimizations (e.g., it works in debug builds, and in tools that don't even run codegen backends), and it guarantees that the values are usable in compile-time contexts like non-type template parameters.
Maybe, but does it *point* to something unique? I'll see myself out :-(.
Waiting for the flood of comments showing how half these examples cause memory leaks, undefined behavior, or how they’re just not the correct way to do it. Followed by 3 other ways to do the same thing. 
By being ready to work it a long time ago when it *really* mattered :-). Still got another, new one, 3 or so years ago though.
And [ “C++17 Features (part 2 of 2)”](https://www.youtube.com/watch?v=qjxBKINAWk0)
Yeah I kinda get the same feeling there's always some requirements which is not easy to pass, like 5 year linux experience for me. Well I guess you just have to keep trying maybe there's some more or less skillset agnostic backend C++ jobs out there.
But wouldn't the effort be the same for a compiler to figure out if something specified as being constexpr actually is, and if something *could* be constexpr?
A constexpr function may be needed for constant evaluation. From what will be added to section [temp.inst] of the draft standard: template&lt;typename T&gt; constexpr int f() { return T::value; } template&lt;bool B, typename T&gt; void g(decltype(B ? f&lt;T&gt;() : 0)); template&lt;bool B, typename T&gt; void g(...); template&lt;bool B, typename T&gt; void h(decltype(int{B ? f&lt;T&gt;() : 0})); template&lt;bool B, typename T&gt; void h(...); void x() { g&lt;false, int&gt;(0); // OK, `B ? f&lt;T&gt;() : 0` is not potentially constant evaluated h&lt;false, int&gt;(0); // error, instantiates `f&lt;int&gt;` even though `B` evaluates to `false` and // list-initialization of `int` from `int` cannot be narrowing } IIUC `h&lt;false, int&gt;(0)` would be fine if `f` were not `constexpr`.
OK, let me try to explain: for range1 and range2 each you do this: you try to binary_search/lower_bound for mid_index(index of the element in the joined range that is in the middle of joined range). Since both range1 and range2 are sorted they are also sorted wrt respect of indexes in joined range. So if you could pass mid index to lower_bound/binary_search you could just be comparing indexes in joined range when binary_searching over r1, then do the same over r2. You will find the element with mid_index in either r1 or r2. But binary_search, lower_bound require that the element you search for must be the element of range, there is no way to tell the algorithm to map the elements and do comparison in that mapped range. 
Thanks for the report. I asked someone to have a look
Actually, constexpr on a function declaration is an extremely weak contract (http://en.cppreference.com/w/cpp/language/constexpr) in particular, it isn't sufficient to guarantee that a function is actually evaluable during compiletime for a given set of arguments.
if constexpr is not specified, the compiler can still figure out if an compile-time optimization is possible: e.g a compiler might decided that int a = 5 + 5; can be compiled to int a = 10; Another compiler might however not see this optimization and leaves it as a runtime expression. However both must evaluate to the same result at runtime. &amp;nbsp; Now this might be a trivial example, because only literals are used and you can assume that even the worst compiler should figure this optimization out by itself, don't you? Imagine it was a much more complex expression that requires some time consuming computations and you want to guarantee it's evaluated at compile-time. Adding constexpr enforces the compiler to evaluate the expression or throw an error if something is missing.
linux experience is indeed a hard one for me too, always developed on windows.. and even rarely used linux.
My first C++ job was an internship at a local game studio, before I graduated. Then I got an internship at a major tech company doing C#, and when I started full time I switched to a team doing C++. So my advice would be to look for *companies* that do a fair amount of C++, especially in an area you're interested in and maybe have at least some school or hobby experience with, and then be willing to do something else there at least to start with. As long as you're in a field where C++ is a big thing you should be able to start writing it.
I could either do my diploma thesis as a Python hack that would get deleted right after, or production grade in C++ for senior position level cash. Seeing how I prefer C++ to Python anyway, the choice wasn't too hard :-)
Looks like it. typedef int MyInt; using OtherInt = int; int main() { size_t a = 5; // 26496 MyInt b = 10; // 26496 OtherInt c = 15; // 26496 const size_t x = 5; // No Warning const MyInt y = 10; // No Warning const OtherInt z = 15; // No Warning return a + b + c + x + y + z; } 
It is indeed surprisingly difficult to get a non-web development job these days unless you live close to a big tech (or industry) hub, or are willing to relocate. My current C++ job is remote and I found it on https://stackoverflow.com/jobs. The pay is well below market rate though (as is often the case with remote jobs), but I like working from home.
Yes, the const warning with aliased types bug was fixed in this release.
I'm stuck on my current job and also looking to get a C++ job. For me the biggest problem is that most C++ jobs I find require a "Security Clearance". Hopefully I'm kind of doing C++ here but would love to find a really interesting C++ shop to work at.
it looks fixed, good to hear this.
And I installed 15.4.4 yesterday. How do I update to 15.5? I don't see any available updates in VS Extensions and Update window. If I run the installer, it only offers to change components of current version or uninstall. I don't want to do a full reinstall.
As you have run into, my domain specific knowledge has gotten me both my jobs where I wrote C++ (among other things). I've said it before, if you have that kind of knowledge in some field, use it! Depending on the domain, being competent in both programming and _what_ you program can take you a long way. Those types are surprisingly difficult to find.
I built stuff and could display serious acumen.
Is there a good way to make use of this when using the "open folder" feature? Adding the flag "/analyze:plugin EspXEngine.dll" via target_compile_options results in the following: fatal error C1250: Unable to load plug-in ' EspXEngine.dll'. Great work on this and other features coming down the line!
What you are missing is that you can reformulate this problem as a purely vanilla binary search. Binary search works to find any value output, on any increasing function, right? It doesn't need to be a container. It is just that this is a common use case and the STL version is biased for this case. If v1 and v2 are of sizes N and M respectively, N &lt; M, and we want to find the Kth largest element (K = (N+M)/2 is the special case of the median), let's consider the following function: f(i) = v1[i] - v2[M- (K-N) - i] i is bounded between 0 and N - 1. The key point here is that the number of elements "above" the point we're indexing in v1 is (N-i), and the number of elements "above" the point we're indexing in v2 is (K-N) + i. Adding these together, there are always a total of K elements larger, in each individual array, then the two elements we're considering. If the two elements we are considering are not equal, this quantity is not very meaningful. But if the two elements we are considering are equal, that means that we have found a value such that there are a total of K larger values between v1 and v2. But, the two elements being equal, just means that f(i) is zero. And f(i) is clearly an increasing function: the first term is increasing, and the second term is decreasing (since it's negatively indexed on i) but subtracted. So, all we need to do is find the zero of an increasing function. So we just run binary search on f(i). Conceptually, this is what needs to happen. As I said, binary search is something that abstractly you perform on functions, not containers. The problem is that the STL formulation doesn't make this easy in practice. My IndexLambdaIterator is just a way to get around that: it creates an "iterator" which is really just representing a point in the domain of a function. So you can do a binary search on an arbitrary function (at least a function that takes integers as its inputs).
The full contract is that a `constexpr` function given `constexpr` inputs can be used in a `constexpr` context.
I don't work exclusively with C++, but have to use it almost everyday and got my current job with computer graphics and computational geometry by referral from a friend that worked with my current boss on the past. Having a masters degree in computer graphics certainly helped me on this.
I oversaw, and now architect, a project with a heavy chunk of C++ code. We're hiring right now, but we have the same experience requirements you're seeing. Typically, a project chooses a native programming language (C, C++, ObjC, etc.) for a *reason*. Development is slower, good developers are less common, classes of bugs exist that don't exist in other languages (naive memory leaks, wrong instruction set extensions, bad linkage, etc.), and you've got a fundamentally slower-moving development environment. It simply costs more to develop in C++ than in most other languages. So you only choose C++ when that cost buys you a net win. Our project provides a framework for in-house supercomputer-accelerated computer vision products. C++ makes sense for our core libraries because we use OpenGL for a lot of image operations, and because the libraries our scientists use are written in C++. It is more work to make those things work smoothly in a different language for our uncommon use cases than it is just to develop high-quality C++. But most of our user-facing tools are written in Java, and most of our server-side glue is written in Python. Those are modules without any external factors pushing us toward C++, and where we value development agility over the compatibility and performance C++ offers. Because of this, when I'm hiring somebody, I'm hiring somebody who can use C++ to write OpenGL code, or HPC code, or networking code. C++ is necessary, but not sufficient, to solve the problems we have. We're more likely to consider somebody with years of writing distributed systems in Java, but who can pass a trivial C++ challenge, than somebody who knows a bunch of fancy C++ tricks but has only written CRUD applications.
Exactly, and that's a very weak contract.
Wait, how do you handle optionally importing something, either because of the platform or because of a feature flag? Or does this just mean that the build system will assume you are importing everything and later worry about what you actually imported?
No one is asking that `constexpr` always get evaluated at compile time, and `constexpr`'s only need to be evaluated at compile time in very few explicit cases.
What exactly would you imagine being the advantage of nested functions over lambdas?
I did not know C++ at the time but was willing to learn. So I offered myself as a passionate learner to a company, for a low wage, and it worked.
Based on my reading of the TS last week, I though that the 'export' was optional? You can write either "export module FOO" or "module FOO"?
nothing from the semantic aspect, but @_dorin mentioned something about optimizations earlier, which is something I don't really know much about
I appreciate the focus on long-term intuitiveness!
I think we disagree on the definition of "weak" vs "strong" in this context. :) A `constexpr` function is _guaranteed_ usable in a `constexpr` context. That's a pretty strong contract in my book.
It seems to work when the flag is written as "analyze:pluginEspXEngine.dll" rather than "/analyze:plugin EspXEngine.dll" as the documentation lists it.
`export module M;` signifies a module interface unit while `module M;` -- its implementation unit(s). Before this change the distinction was communicated in ad hoc manner, for example, via a command line switch or file extension.
No, not necessarily. A constexpr function can even contain I/O functions like `puts`, which can certainly not be executed during compiletime: #include &lt;cstdio&gt; constexpr int foo(int i) { if (i == 0) return 0; std::puts("Parameter was not 0"); return i; } constexpr int c = foo(0); // constexpr int c = foo(1); //&lt;- this will produce a compiler error int main() { return foo(1); }