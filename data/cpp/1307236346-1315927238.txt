Or inside main (K&amp;R) int main() { void input(float &amp;t1, float &amp;t2, float &amp;t3); float average(float t1, float t2, float t3, float &amp;avg); // etc. } 
What? This doesn't make any sense at all. Most of the examples are missing template parameters. You can't have a `std::vector` of an abstract class anyway. You can have a `std::vector` of pointers or references to an abstract class but then how do you manage the lifetimes of those objects?
Are you *serious?* 
Typically go only does static compiles. It's an apples to oranges comparison. 
You might check http://www.charlespetzold.com/dotnet/DotNetBookZero11.pdf which is focused on that scenario (transferring existing C++ skills into .NET and especially C#)
auto_ptr copyable? uh-uh. The problem with the Internet is that it doesn't have a centralized scheme for downvoting blogs with misinformation ;) At least it can be downvoted here.
I think this article demonstrates just how obscure a language C++ is. &gt;Often I prefer to use templates in C++ over polymorphism to avoid confining myself to any particular inheritance heirarchy when writing algorithms. What does this mean? There's no way to prefer templates over polymorphism since templates are polymorphic. The whole point of having a template is to write polymorphic code. Anyhow, the example he gives doesn't require any use of boost::any, in fact it's much better if he avoids boost::any. What he wants is precisely to use polymorphism to specify a base class with a render method, and then have a template that implements that method on any type with a matching signature. That way even if those types don't share a common base class, so long as they share a common signature they will be compatible with this wrapper. class BaseRenderable : boost::noncopyable { public: virtual ~BaseRenderable() {} virtual void render() = 0; }; template&lt;typename T&gt; class Renderable : public BaseRenderable { public: typedef boost::remove_reference&lt;boost::remove_pointer&lt;T&gt;::type&gt;::type BaseType; Renderable(const T&amp; base) : m_base(base) {} virtual void render() { boost::bind(&amp;BaseType::render, m_base)(); } private: T m_base; }; 
God awful article. I'm not an accomPlished C++ programmer by any means even so I look at this code and wonder where is all the missing code. 
The vector renderables_ holds shared_ptrs to the objects. When the shared_ptrs are destroyed, any object they point to are also destroyed (if that was the last shared_ptr pointing to it). Here's a fully working implementation of the idea: [http://pastebin.com/5etCA0vj](http://pastebin.com/5etCA0vj)
&gt; A drawback in C++ is the lack of a built-in garbage collector. How's that a drawback??? It's a feature.
It would have been nice to see the performance/size compared to a .Net application also.
While there's no arguing that C++ is the clear winner here, the paper itself and the benchmark are seriously flawed and should not be classified as "research" at all. Look up the reddit post at r/programming about it, it was interesting.
I wouldn't bet on this over virtual functions if i cared for performance of the solution.
For most business related uses, I'd still code in C# over C++. Many performance evils can be overcome with hardware these days. That's not to say I don't care about performance but rather that I care almost as much about supportability. Edit: I just noticed this was in the cpp subreddit so mine is clearly not going to be the popular opinion. Damn you custom front page.
[lazy link](http://www.reddit.com/r/programming/comments/hqkwk/google_paper_comparing_performance_of_c_java/)
*We don't take kindly to strangers 'round these parts, city boy.*
.Net applications are NOT SMALL if that is what you are getting at. Any language that requires a Framework (such as .Net and Java) or a launcher (such as Pearl and Python) needs to have the entire scope of the application taken into account. It's not enough to say "Hey this program I wrote is half the size of that one there" when that program they wrote will not work without a huge infrastructure alreaqdy in place.
Needs more mouse-over popups.
It would've been sad if C++ hadn't come out on top in this particular comparison. The kinds of algorithms that they implemented fit pretty closly to the kinds of tasks that C++ is designed to be efficient at. (lots of moving data around with some light computation). But there are still areas where C++ is not necessarily the fastest, or even fast. Think heavy computation which is parallelizable (this is of course, where Fortran still rules). You can usually close the gap with considerable effort but sometimes even that is not possible without inline assembly. And if you allow assembly you aren't rellly comparing high level languages anymore, are you? The results are certainly informative, but to me it appears to suggest that C++ is much more generally recommendable than I think it actually is. Disclaimer: I write C++ for a living and quite like it.
I love C++ dearly, but you're dead on about "most business uses". There's simply no reason to write a small GUI application in C++ when you bang it out in C# in 1/3 of the time.
This is actually changing. First the hardware was not powerful enough so we needed languages like C and C++. Then the hardware became so powerful that it didn't matter if we wasted some of the resources on the VM layer. Now, we are back to the point where every CPU cycle counts (battery life, size, cost per unit, etc). Funny how things are coming full circle.
Word. Maybe the hardware has improved, but we are asking more from it than ever before. That's why C++ and assembly are not going to disappear any time soon.
I dunno, I'd prefer it if they also flashed with garish colours.
Haters gonna hate! 
CPUs have not gotten any faster recently. They've just been able to put more cores in a smaller space but the processing speed has not really changed all that much. Disk I/O is still a bottleneck. Parallelism isn't the solution as some problems cannot be sped up with parallelism. You need efficient code. I like languages where I can use inline assembly so as new CPU features come out I can take advantage of them. SSE4.2 for example has some text processing enhancements that I have used. 
shame its only windows and osx. Not really interesting in my book.
How about Qt?
The "1/3" applies to Qt. 1/9 without. 
Actually, the i7 was faster than Core2 on quite a number of benchmarks, especially multiprocessing benches. It's just moving at a slower rate than we had grown accustomed to. 
That's the problem with a lot of developers I've worked with. They think throwing hardware into the problem is the best solution. 
That may be true, but I didn't weigh in on that matter here.
Fair enough -- glibc / msvcrt? boost? Unless you count both, it's not an apples to apples feature comparison. I'm not sure myself which would win on size (for a similar feature set); it's something I'd enjoy seeing. 
Don't get me wrong, I love me some C++, but the article makes a really bad blanket statement: "best performing programming language". Seriously? C++ is perhaps the best performing *"higher" level* language, but well coded C can blow it away, to say nothing of targeted Assembly. Both of those are "programming languages" (just ignore Assembly not being cross platform); neither were tested. 
&gt; but well coded C can blow it away There is no reason for "well coded" C to be faster than "well coded" C++
silverlight? wtf?
I've seen the same thing. Memory leak in your app? No problem, move to 64 bit. High CPU? Parallel processes. Disk IO issues? Blame the SAN guys. It never seems to be a code problem (in the dev's eyes). I still think you can write managed code with an eye to performance though.
Every new video from Microsoft is in silverlight. I know they want to push their technology, but it would be nice if I didn't have to find another computer to watch it. Putting knowledge behind a technical barrier like this seems a little disingenuous.
Herb Sutter is a bit younger than I imagined for some reason.
They are downloadable in a variety of formats, I don't think you need Silverlight to see the download links.
Were you too lazy to note the 6 different download options in WMV, MP3 &amp; WMA (both audio only) and MP4?
This silverlight hatin is getting old. Just install it once and you never need to complain about it again. Or simply click one of the download links to get it in your favorite format.
And I am blind. Thank you for pointing this out. I suppose this makes my previous comment way out of line :)
You're far from the first to miss those so you're not blind. I blame Microsoft anyway for employing dark magicks in order to hide those links so well in plain sight.
 The phrase "considered harmful" is [overused.](http://www.google.com/search?q=%22considered+harmful%22+-dijkstra)
Point taken. Any proposals for a different title?
You have a point there. The qualifier *"considered"* is a bit meek and could boldly be left out. Edit: Seems *"considered harmful"* is an old [meme](http://en.wikipedia.org/wiki/Considered_harmful) in CS. I admit I did not know of this. Now I think all headlines should contain the phrase at least once.
Its not required to have white [beard](http://www.softwarepreservation.org/projects/c_plus_plus/Initial%20meeting%20group%20portrait%201.jpg) to program C++ but it doesn't hurt.
Herb makes a good argument for Pascal-like syntax. I wonder how many people would approve if C++ changed declaration and expression syntax? Something like: function getN(n: int): double; Even Rob Pike and Ken Thompson from the original C camp decided to adopt this syntax for *go*.
I'm not really sure. Maybe "Avoid benign data races by using weak atomics"? 'Considered harmful' seems to be abused as much as the goto statements that originated the phrase.
How about: No more Mr Benign, shouts Hans Boehm at Data Races!
I've seen [one proposed syntax](http://www.csse.monash.edu.au/~damian/papers/HTML/ModestProposal.html) along those lines. It also makes some other changes, like replacing the prefix unary `*` operator with a Pascalish postfix unary `^`, meaning that you no longer need those awful `-&gt;`s.
Yes, I've seen that too. I'm not sure what he means by alternative expression syntax though. Using ^ and := ? 
Seriously, though. No "Aha!" or "That's wrong!"? This is a memory model we'll have to live with for the rest of our lives.
It because the styles of the links make the whole download link area to the right look like a ad that one easily ignores. They could fix it to make it better.
yes, i was :)
"Considered harmful" considered harmful.
Welcome to reddit. Mostly we are just a bunch of grammar nazis. Its a very interesting article and I suspect most of us are new to default atomics never mind relaxed ones. About that [diagram](http://corensic.files.wordpress.com/2011/06/drf.gif?w=339&amp;h=141). I cant seem to make sense of it. How should I read it? 
As i understand it the main benefit of a new syntax would be that tools could parse it easier. Practically this would still mean that humans would need tools to go to and from the old syntax and the new. But if tools could do that then whats the point? Then its just about human readability and most will find the syntax they know to be more readable than the one they dont. So it would have to be a new language and maybe only a small portion of purists would change to it. And as Herb said.. once its a new language one should take the opportunity to change other things. Shed all that C legacy for instance.
Lots of us don't want to install Silverlight for security reasons. It's the same reason I don't want Flash installed on my machine, but Flash is so ubiquitous, it's much harder to avoid. Silverlight usage on the internet is still very rare and frankly, I hope it stays that way.
I'm personally more interested in the speed comparison than the size. But the framework size matters only depending on usage. If your doing one application you dont want a huge framework. If your going to run a whole lot of applications on the same machine a framework matters if they all can use the same global files as is the case with .net.
&gt; But if tools could do that then whats the point? Well, here's one possible benefit of easier parsing: tools can do the job more easily (so the barrier to entry is lower) and more efficiently. The latter isn't a small issue for C++, because C++ compilers are notoriously slow, and (AIUI) lexing and parsing are a major source of compiler slowdowns. You wouldn't need to use a pre-processor, you could just build your new parser into your compiler front-end. As for readability, maybe I'm weird, but I've found that learning a new syntax is rarely the hardest part of learning a new language, especially when you're just hopping between branches on the ALGOL family tree, and the compatibility constraints for C++ code bases tend to be particularly severe. A "new language" with very similar semantics (as in, C++0xB has similar semantics to C++98) but a different syntax might actually be something that could work.
This is how you read it: You want to know if your program is SC or not. To check this, you should, in principle, look for data races in all possible executions. All possible executions should include non-SC executions as well, right? It turns out that it's enough to look for data races in SC executions only, which is much easier, believe me. If you don't find any, the non-SC executions will never materialize. If you did, all bets are off, and your program will likely behave in a non-SC way. The bottom line is that the situation in which you don't have data races in any SC execution but have a data races in some non-SC execution can never happen. 
Thanks. I understand it now. The "Impossible" in the figure means "Data Races are Impossible" and the "Possible" means "Data Races are Possible".
Actually, it means "executions are possible" and "executions are impossible". 
Is there a transcription somewhere?
Unfortunately, no. Doesn't seem Channel 9 provides transcripts for any videos...
Just good intentions. Show me the code!
Thank you! I feel that SO deletionism is sometimes a bit over the line (just like at Wikipedia). 
okay gotcha. i do need to test new gcc to see if they fixed move sem perf. compiling our code base with 0x turned on caused a perf hit last time i tested.
"Some of the C++ clutter has also been stripped out: templates and template libraries are gone." Umm... what? I don't remember hearing anything like this at all, and I am sure that much of the C++ community would be up in arms if it were true. So did I miss something here, or does this merely indicate that the author obviously doesn't actually know very much about the subject matter about which he is writing and so really should have run the article past Sutter (the interviewee) before publishing it? [P.S.: As tompa_coder as pointed out, the article has since been modified to remove the phrase "templates and template libraries are gone". While I am glad that the quality of the article had been improve, the author really should have made an explicit note that this change had been made in response to feedback.]
It must be a misquote because C++0x actually adds more template features, like extern templates, template aliases and some template parser improvements, allowing for nested templates without needing a space between &gt;. 
I was about to say, removing templates would be a major step back.
Not that it would be even possible for them to remove major language part.
Whoever wrote the article was not paying attention or the topic was over their head. The article is full of confusion. This one must be about the "export templates" that was removed. There is other confused stuff like: &gt; "The question is how have [data center and web] environments become standardized and formalized that it's time to standardize one common way of speaking to them and express those programs" "data center and web"? &gt; "When you are talking about splitting [code] across different cores that's in the standard, we are talking about the memory model. We are going to optimize it without breaking the following assumptions people are going to make in the code" And then no assumptions are discussed.. 
The Register is The Daily Mail of tech reporting so this isn't surprising.
From the last paragraph of the post: "In the next few days I hope I will be able to post the first iteration of Scheme_0 and to document the process of implementing this. The code will be released under an Open Source license (probably GPL 3) ...."
I didn't find the phrase " templates and template libraries are gone." in the article. So I suppose the author has made some modification or ...
I like Ars Technica personally. 
Oh, whoa, he did just remove that phrase. I have mixed feelings about that; on the one hand, I am glad that he improved the article in response to feedback, but on the other hand since that is a significant change made a day later he really should have put a notice somewhere acknowledging that he had edited it out, because now it looks like I just made that quote up.
Hi. I know java and I'm learning c++ - I found this excellent: [accelerated c++](http://www.amazon.co.uk/Accelerated-Practical-Programming-Example-Depth/dp/020170353X). If you understand a procedural, object based language like java then this should get you versed in the basics of c++ plus one other harder book. Maybe something like effective c++? Accelerated c++ has some basic stuff but far less than most. I'll be watching here for other ideas as I'm certainly no c++ guru yet.
[Accelerated C++](http://www.acceleratedcpp.com/), probably the best intro to C++ as it should be used. Be aware, though, that it doesn't cover the "C++ as better C"...
Ben saved me some valuable time as I was going to suggest exactly this. Grab Accelerated C++ to get started, you will likely go through it in a week or two. Then get something meatier. Sutter has many good books under his name. I'm certain others will chime in with other books and references. I think it is important to realize that one book won't cover C++ well enough. In fact you will find substantial books dedicated to just parts of C++ and the STL. 
Accelerated C++ is what I'm using. I don't need to learn for the 100th time what a variables, loops, and if statements are. This book is for people who already know how to program and need to get up to speed in C++ quickly.
I can confirm that this is a great book. Be careful however not to skip any parts, the material is quite dense. 
[Perfect book for anyone engaging in this endeavor](http://www.amazon.com/Final-Exit-Practicalities-Self-Deliverance-Assisted/dp/0385336535/ref=sr_1_1?ie=UTF8&amp;qid=1307837283&amp;sr=8-1).
The slides can be found [Here](https://github.com/boostcon/2011_presentations/raw/master/tue/spirit_qi_in_the_real_world.pdf) *PDF WARNING*. Debugging stuff is at the end of the presentation. 
If you have Core Java for Java, you may want to just go through and read some of the boxes that say "for our C++ developers", they kind of work both ways. "How Not to Program in C++" is also a great book, but maybe not for learning. It will help you see the mistakes before you make them the first time.
Scott Meyer's [Effective C++](http://www.amazon.com/gp/product/0321334876?ie=UTF8&amp;tag=aristeia.com-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321334876) and [More Effective C++](http://www.amazon.com/gp/product/020163371X?ie=UTF8tag=aristeia.com-20linkCode=as2camp=1789creative=9325creativeASIN=020163371X) helped me understand how to write C++ with results that I thought was similar to the Java I'd written in the past.
There's this one you can read online, http://newdata.box.sk/bx/c/ It's a popular series but I'd reccomend this one, [Programming: Principles and Practice using C++](http://www.google.com/products/catalog?q=Programming:+Principles+and+Practice+Using+C%2B%2B&amp;oe=utf-8&amp;rls=org.mozilla:en-US:official&amp;client=firefox-a&amp;um=1&amp;ie=UTF-8&amp;tbm=shop&amp;cid=16228997791858743207&amp;sa=X&amp;ei=bjb0TfXeFoz2swPJrfXMCw&amp;ved=0CDgQ8wIwAQ#start=0) It's written by this guy Stroustrup who is most well known for well, creating C++. Check out this list of books, http://www.efnetcpp.org/wiki/C%2B%2B_books And also check out, http://library.nu/ To find them online. My greatest problem with most programming books is that they all sort of teach things poorly. Most tend to start out going over the differences between compiled languages and interpreted ones, and then move onto some basic understanding of an algorithm or program. There's always that lame part where they say "think of all the steps needed to make a batch of chocolate chip cookies...." and then have exercises in the end where they ask their students to write a program in pseudo code for simple everyday things. Then these books just essentially show you the syntax in a long drawn out way like "this is a function...this is a a for loop....these are classes". As far as an introduction to C++ my favortie has been stroustrup's. I had to use the first book I mentioned for a course and it's not bad compared to others I've read. 
I wonder how you'd do if you just went in and took it. I mean, "advanced Java experience" seems to indicate you think you're pretty good! I guess there's the whole memory management, header files, and declaration vs implementation stuff which just doesn't exist in Java, but, ignoring that, I think you could go pretty far with just Java knowledge. Edit: In fact, if this class is along the intro track, they may not even get into those three things very much so really what does it matter.
I'm seeing a growing division between old school "low level" programmers and compiler/language enthusiasts. Perhaps spurned by the recent interest is improving the C++ language. The first camp maintains that C/C++ is a portable assembly language _only_ -- sure, there is an optimizer, but the compiled program must behave _as-if_ every variable named a section of a call stack, that all bytes can be reinterpreted with impunity, and 2's compliment arithmetic is universal so you can safely assume wrap around. After all, they tried these tricks on a compiler back in '95, and they worked then. The latter camp will note that C / C++ never behaved this way -- only the reasons have changed. You couldn't safely reinterpret because different data types might reside in different memories; each processor implemented signed arithmetic overflow differently, or not at all -- now, we've used these _well specified_ assumptions to improve the performance of correct programs. And if the "low level" guys don't like it, they know where -Od is. 
-j for make is _fine_ as far as parallelism goes. Also there are other ways to distribute/speed up the build like increadibuild and distcc (it has some issues though apparently). Another good idea is to use ccache (this one does _wonders_). Pity C++0x failed to introduce modules but it seems they will make it into technical report. Fixing VC precompiled files model (ie. making it similar to gcc one) would also be a big help.
&gt; In particular, you cannot use printf to print a C++ standard-library string -- so if you intend to use printf, you probably have to use character arrays in place of strings. lolwut
To be completely honest, you could use the `c_str()` member function of `std::string`, but I can see Andrew's point. On the other hand, I don't particularly like the design of the `iostream` library.
Precisely. I'm rather fond of printf's format specifier syntax. Equivalent iostream code tends to be hellaciously verbose.
&gt;There is simply no reason to explain quadratic algorithms to beginners except perhaps as cautionary examples of programming techniques to avoid. Don't use quick sort guys ;) (yeah i know) Also, is there variadic template based printf-like function in C++0x?
The point though is that printf and the like are not typesafe, so should be avoided. std::ostringstream is only a little verbose. 
There's a typesafe printf in boost.
spirit::karma (from boost) is typesafe, flexible, fast and very compact. The drawback is that it's slow to compile and you need the boost libs.
what about boost.format?
I can certainly sympathize with the "low level" guys. The motivation behind making things like signed overflow and reinterpret casting undefined is little more than a historical curiosity these days as architectures for which they cannot be supported are rare as hen's teeth. I think it's debatable whether the optimizations enabled by such things being undefined is worth the potential for surprising bugs. Moreover, while one can always disable optimization entirely, this is obviously not what is usually wanted. I'm not aware of any compiler which has added a easy option to say "don't break things which are well defined on every architecture I'm ever likely to encounter".
In my experience there are two factors that are inherent to C++ and its tools that explain why so much gets put in the headers. First, a fundamental property of the language is that any code that uses templates must go into the headers if it does not know the type variable, so if you are writing a generic programming library your entire library may end up in the headers. Second, people do not yet routinely expect whole-program interprocedural inlining for their C++ compilers, so the most reliable way to get small function and method bodies inlined (which can lead to huge speed ups in many cases, in particular when there are a whole lot of calls to functions or methods with small bodies chained/composed together) is to simply put their bodies in the headers so that all modules can see them.
Oh, man. You reminded me of a horrendous piece of code that I wrote to prove a point. I translated this: for(int i = 0; i &lt; 10000000; i++) printf("%07d", i); into `iostream`'d code. The resulting code required seven to ten `#include`s. But it still was one line (if you allowed line continuations). :/ **edit:** [here's a link](http://www.reddit.com/r/programming/comments/dkb90/code_problem_optimization_of_c_code_to_print_all/c10twrc) I am so sorry 
It is worth noting that the Haskell approach (at least, that used by the flagship compiler GHC) is to embed all of the information needed for cross-module optimization as part of the compilation process of each module. That is, as part of the process of compiling A.o, GHC produces a special interface file A.hi that contains enough information about what is in the module A that any module that relies on functions in A can themselves inline the functions in A. So rather than having a whole-program cross-module optimization at the very end, each module does an intermediate cross-module optimization itself based on all of the modules on which it depends. There is a price that is paid for this, though, which is that dependencies need to be compiled before their dependents which reduces the amount of parallelism available in the compilation process, which contrasts with C++ where all source files can be compiled simultaneously.
Yeah, that was probably the first decent attempt to get something like the formatting capabilities of python, but it's slow as hell. See for instance [here](http://www.boost.org/doc/libs/1_46_1/libs/spirit/doc/html/spirit/karma/performance_measurements/numeric_performance/format_performance.html).
Of course there are some die-hard old-schoolers left, but a growing division? C/C++ doesn't only matter on the desktop. There is growing support for embedded systems, signal processors, microcontrollers etc. that have been traditionally programmed in assembly. Compilers for these usually have significant platform-specific extensions. A compiler can specify undefined behavior, and on these systems that makes sense, as portability usually isn't the prime directive (often not even achievable given the hardware restriction).
That's a silly example ... surely the problem is in the API, which should look like this: int process_something (int fd, size_t size)
&gt; A compiler can specify undefined behavior Ah, quite true. I run into a lot of folks that only *think* their compiler sanctions their tricks, but you're right; some compilers actually do.
"prove" a point ... Isn't the linked to code disingenuous? How about this instead ... #include &lt;iostream&gt; for (int i = 0; i &lt; 10000000; i++) { std::cout &lt;&lt; std::setw(7) &lt;&lt; std::setfill('0') &lt;&lt; i; // Edit: i++; }
&gt; Each phase is completely dependent on the previous one, meaning that there's no reliable way to look ahead and, for example, look for #include's and fire off an asynchronous read in advance for them. The compiler cannot look ahead to see if there's a raw string literal and so not do trigraph translation, it must do the trigraphs, and keep some sort of undo list. Is it possible to remove a phase of compilation if certain esoteric features were not processed? For example, could phases be removed if digraph and trigraph processing were removed? &gt; Kenneth Boyd tells me that upon careful reading the Standard may allow a compiler to skip reprocessing #include's protected by #ifndef pairs. I don't know which compilers, if any, take advantage of this. This seems like a rather simple optimization and I've read about it before. I figured both Visual Studio and GCC did this. Is this really that difficult? Why don't compiler writers take advantage of this oportunity? 
Putting those stream modifiers in every iteration seems like a waste (even if your compiler is clever enough to hoist them out) and it seems bad form to leave `std::cout` in that state for the next person to use it. I'd prefer the (lengthier) std::streamsize w(std::cout.width()); char c(std::cout.fill()); for (long l = 0; l &lt; 10000000l; l++) //int may not hold 10000000 std::cout &lt;&lt; l; //don't increment, it's already done std::cout.width(w); std::cout.fill(c); IOStreams are certainly less appealing like this, though.
Sadly GCC still doesn't have a regex implementation, neither in TR1 nor in C++-0x. Yes, I know, I can use Boost but that's an extra dependency which would be nice to avoid. 
Even though our system depends on Boost, I avoid using Boost.Regex solely because it takes so long to compile. We only have a few Regex-using cpp files, but they take more than 10 seconds to compile (as opposed to under 1s for the rest).
Bah! The point was not to make it *clear*. On fact, it was to be as dense and WTF-worthies possible. (your code only prints even numbers, btw, and it forgets newlines. I graded programs for several years. You can't turn it off) /sadmelvin
About a month ago I spent days Googling for a tut about TR1 regex like this, so you can bet this is getting bookmarked.
They do. When Walter Bright states that he doesn't know it just means he couldn't be arsed to find out.
Very interesting, thanks for posting!
So, is the double-checked lock idiom guaranteed to work now? It has been on Java for about three years now.
Why compare arrays to `vector`'s and not mention `std::array`?
&gt; They do. Do you have any references? &gt; When Walter Bright ... Walter Bright is a pretty smart guy who continues to participate pretty actively in the C++ community despite trying to push D. I have the utmost respect for him. He even hangs around on reddit and frequently answers questions like these.
Googling 'GCC include guard optimization', first hit is http://gcc.gnu.org/onlinedocs/cppinternals/Guard-Macros.html For Clang, see HeaderSearch::ShouldEnterIncludeFile in http://llvm.org/viewvc/llvm-project/cfe/trunk/lib/Lex/HeaderSearch.cpp?view=markup (A quick google didn't find me any Clang documentation for this) Can't be bothered to check MSVC.
It's more than that. For programs in the ML family, including Haskell, the .text sections for compiled objects cannot be shared. A big hit in runtime memory use and instruction cache pressure is a consequence.
I highly recommend [Essential C++](http://www.amazon.com/Essential-C-Stanley-B-Lippman/dp/0201485184/ref=sr_1_1?ie=UTF8&amp;qid=1307988476&amp;sr=8-1) by Stanley Lippman.
As I recall the most fundamental problem with double check lock was that reads and writes where not atomic. So as long as you use default atomics you will be fine. Maybe you can even relax it a bit with weak atomics.. although I think anything but the default sequential consistency is asking for trouble. 
Grade your own fucking code! ;-) &gt; printf("%07d", i);
Good point/s. What about std::ostringstream oss;? instead of setting (and then forgetting to unset std::cout ...)
I think you're right. I think there was also the problem that what you are double checking on is likely a pointer and a pointer may be point to a partially constructed instance. It's a big problem if a second thread tries to use that pointer before construction is complete. if (!ptr) { acquire lock { if (!ptr) ptr = new foo; } } ptr-&gt;do_something() 
Modules would be a core language extension and TR is library extensions only. Or do you know something i don't? 
Turns out I was wrong - the width modifier needs to be set before every read (see [here](http://stackoverflow.com/questions/5905467/whats-the-deal-with-setw)). Not sure about the fill modifier. Also: After taking care to reset the stream modifiers in my snippet, I realised I forgot to actually *set* them in the first place... A little embarrassing, but it does illustrate a point.
Touché also, goddamnit.
Main memory is a database. I am surprised this is not taught anywhere. Just like in a database, memory contents may be different from what your app/cpu may have inside, and therefore you must always need either STM/optimistic locking (same concept) or coordination (thread blocking/request queues - same concept). 
Top C++ and Bottom C++? Ever heard about Managed C++ and Unmanaged C++ (unsafe I think THEY call us) 
Managed C++ is a deviation from the standard by MS. The idea from the article is a subset of the standard that would compile even if the compiler didn't know about "top" and "bottom" C++. If the compiler knew about the usages it would mean that it would simply forbid some constructs and it would also mean that it could even mean that it could make more informed decision when trying to optimize the code.
Cool article, but honestly, I thought most people do something similar to Top C++ and Bottom C++ when they develop code. 
&gt; A section of Bottom C++ could be marked with comments or compiler **pragmas** and justified in a code review. I don't see how this simplifies C++ or how is it different from the .net solution to use "unsafe" code especially when the author refers to memory management as bottom (I'm sorry if "unsafe" is not the term I never used managed C++) 
There is no connection between what the article propose and what Microsoft has done with C++/CLI (managed code)! The Top and Bottom C++ should be compiled by any standard compiler, the distinction is just for the programmer. On the other hand managed C++ is not part of the C++ standard (it can however be compiled with Visual Studio and Mono). 
Complaint on twitter, no less. What's the problem, even? (does the C++ programmer show much?) It could use some syntactic sugar, but frankly, if you want syntactic sugar with regexes, you are doing it wrong. Now I'd give a kidney for some libraries baked into the compiler, simply for better compile time diagnostics. Not necessarily my kidney, mind you, but *a*. 
Managed C++ is intended to solve somethign different - bearable syntax for interop with a different runtime, namely. The idea of top &amp; bottom C++ is different: Isolate the dirty, bare metal parts of the program behind a robust, easy to use interface. The power of C++ is that you can do both. Now, Managed C++ *is* regulary used in exactly that sense - connect raw ugly C-ish code to the safe, care-free managed world. So in that respect, you are not really wrong. However the idea of "High C++" is usually *very* different from the idea of safety and easy of .NET. Mainly, determinate destruction drives a deep wedge between the two, not just with regards to resoruce management. 
I was going to write a snarky comment, but after reading the article I've got to agree. Some developers really like to make C++ look a lot more complicated than it has to be. Personally, I dread looking into any MS projects for this reason... their naming convention and coding style just makes me cringe. It's almost like they *want* to make it incomprehensible to the average coder.
I don't know about other people, but Microsoft specifically is trapped by legacy code. They don't recommend hungarian notation to anybody any more, but they still use it in all their code because they used it 20 years ago - and it's better to be consistent than it is to be right.
&gt;Kenneth Boyd tells me that upon careful reading the Standard may allow a compiler to skip reprocessing #include's protected by #ifndef pairs. I don't know which compilers, if any, take advantage of this. I thought this is what #pragma once was meant to fix.
Interesting. I did a cursory overview of the compiler code base. Here are some things that caught my attention: 1. While the source code looks like C++ (.cxx extensions), inside it seems to be all straight C. 2. All the files that I looked at had "Copyright Silicon Graphics Inc". I wonder if this is based on the SGI's C++ compiler?
Is there anything it does better/different than other compilers? 
Isn't it bit awkward to access methods by their index instead of their name?
It's based on SGI's MIPSpro compiler according to Wikipedia. http://en.wikipedia.org/wiki/PathScale
Gotta hand it to MS for implementing it so quickly.
Except lambdas basically ARE classes.
Anyone that says C++ is complicated care to post a code sample to demonstrate how it is complicated? I think that most people repeat "C++ is complicated" without ever considering if that's true or not. 
True, but that is really an implementation detail.
And a reason why you can have lambdas (without the syntactic sugar) in languages that don't offer them as a built in idiom.
Actually, you seem to be right. Just my blind trust in wikipedia. Which only sucks more as i do consider modules to be pretty important (more so then concepts, perhaps even more then lots of features that made it into 0x).
In Scheme, you would normally do it like this: (define (make-account) (define balance 0) (lamda (method . args) (case method ('set (set! balance (car args))) ('get balance)))) (define a (make-account)) (a 'set 5) (a 'get) You could do the same in C++ with an enum for method names.
Not sure why this would be downvoted. This is big news. Full C++ on GPU's!
This is big news. Full C++ on GPU's!
Mmh, I wonder how an abstract base class would look like with lambdas ...
TL:DR; Herb Sutter announces open standard for enabling apps to spawns across any available cores, be they CPU's, GPU's, or Cloud's. Imagine one app on a hundreds millions of cores! The key is a new language extension called restrict.
As a programmer this is great and everything. But as a user I am hesitant. I hope as this gains in popularity there will be a best practice that suggests developers make GPU processing optional in their non-graphical applications. I'd hate for a background app to be mandatorily sucking up GPU clocks while I'm playing a graphically intense video game or rendering a complex CG scene.
There is a [one hour video](http://developer.amd.com/afds/pages/rebroadcast2.aspx) (click third video at bottom) where Herb Sutter explains this in more detail. For some reason it got downvoted into oblivion. Seriously this is big news. Full C++ steps off the CPU for the first time. Lambdas and functional programming on the GPU, for goodness sake! Edit: It's an open standard (not owned by microsoft). This will run on every platform and every compiler. The restrict keyword is the only extension to the language and I bet it has a good chance of becoming standard C++, Herb being on the standards committee and all.
That background app would be the OS. 
Because reality is complicated.
I suspect it's getting downvoted because it's very Microsoft-centric. Want to use this nifty new tech? Gotta use MS' compilers and OS, and that means your app can only run on Windows. *Edit:* It's also a proprietary extension to the language, and not part of the standard, making it tougher to implement across multiple platforms.
Yeah I realized that when I went back and read it again. According to the demo MS showed you can indeed switch between processors on the fly which is awesome.
I didn't know about ccache. Thanks!
CUDA programming gets even better with version 4.0! Time to work on that next-great-game or something else using this neat parallel processing power. I am thinking Xbox360/Halo3 game, but on steroids (if only I had the talent to write such a thing).
What is a function name except an index into a vtable? object.myfunction(a,b); as opposed to, object[myfunction](a,b); The point is not that you would actually program this way, just to point out that that lambdas provide an overlapping functionality to classes.
Yeah sorry, but shut up Microsoft. Nobody cares about you, nobody likes you, and your parents put you up for adoption when you were young. Almost every product and technology you have ever made has had a top-down design, which makes it incompatible with anything designed before or afterwards. Please learn to play with others, as requiring people to play your game alone or you take your ball and go home was pathetic in kindergarten, and now is just sad.
&gt; It's also a proprietary extension to the language so is [#pragma omp](http://de.wikipedia.org/wiki/OpenMP) &gt; and that means your app can only run on Windows OTOH, independent of graphics card. Beats cross-platform most of the day.
Most of the day, sure. But not all of it. There are uses for this outside the Windows realm, if only it weren't a Microsoft-only bolt-on to the language.
It does open up a new segment: general purpose applications that can benefit from but don't require GPU power. In addition, I can't keep my mouth shut, so I'll bite: Why is telling people "You need Windows" in any way worse than telling them "You need an NVidia card"? 
I'm really excited about this direction.
You're not just telling customers "You need Windows." You're telling developers that not only must they be running Windows, but they must also use Microsoft's compilers for their software if they want to use this. It's great news for anybody who already uses Windows and Visual Studio. It's terrible news for people who want to write portable software, or software that runs on a different platform entirely. Suppose they prefer MinGW, or Intel's compiler suite, or another compiler. Suppose they have an existing scientific or research toolchain that runs on Unix but could benefit from this kind of generic GPU interface? They're out of luck with this toolkit. Last time I checked, Windows doesn't run on HP, IBM, etc., Unix hardware, and most of the supercomputers in the top 500 are sporting Unix or Linux, not Windows. There's plenty of computation that can be accelerated by a GPU that won't work that well (or at all) on Windows. Maybe it's a niche market, but it's there regardless.
It's an open standard based on standard C++ with one single keyword extension. How evil of them. This knee jerk MS hating is getting annoying.
Is it visual studio / windows only?
It says it is going to be an open specification, and they will work with vendors to make it available on other platforms.
Cool, been fooling around with openmp lately, but this looks to take it up a notch.
&gt; You're telling developers that not only must they be running Windows, but they must also use Microsoft's compilers That's not true. DirectCompute includes a command line compiler for the HLSL (the language you write your graphics card code in). This, plus the ability to code against COM interfaces, and you are good to go with every IDE you like. Now, Microsoft does not offer native integration - such as debugging and profiling - in other IDE's, but you can hardly blame them for that. &gt; Suppose they have an existing scientific or research toolchain that runs on Unix but could benefit from this kind of generic GPU interface? You are free to use CUDA or FireStream or OpelCL, or roll your own DirectCompute - compatible portable implementation. &gt; Maybe it's a niche market, but it's there regardless. I wouldn't call it "niche", and don't they have a solution already? The power of DirectCompute I see is bringing it to grandma's computer, and integration with other DirectX technologies. ----- What would you expect MS to do? Build on OpenCL? The cries would be "Microsoft is destroying OpenCL", and for MS it's a legal shitfest to happen. Provide a portable implementation? You lose integration with DirectX Provide a tool-chain for competitors products? Now... I assume you don't expect *that*.
&gt; the GPU computing space has reached maturity ... really? So a point-update of the graphics drivers won't break my applications anymore? I find that hard to believe seeing as GPU computing feels anything *but* mature in all of the projects I've worked on.
Read it for juicy soundbytes like: &gt; - *"I have never seen a C program that ran faster than an equivalent C++ program. I don’t think such a program could exist"* &gt; - *"I see OOP as one restricted form of abstraction. Generic programming is a different form of abstraction that you badly miss if you have only “pure OOP."* &gt; - *"C++ is at a disadvantage in that the various [mobile] vendors prefer their users to use proprietary languages and libraries rather than something more open and portable (such as C++)."* &gt; - *"I think it is worth remembering that all the basic Unix interfaces were designed well before C++ was invented and we can’t expect them to change."*
Now that C++0x is here, they're giving away old C++ books :-) Well, they could still be useful, because no compiler implements all of C++0x yet.
&gt; "I have never seen a C program that ran faster than an equivalent C++ program. I don’t think such a program could exist" I would agree since C++ is (mostly) a superset of C ... *except* that C++ doesn't support the 'restrict' keyword. That can lead to some optimizations that C99 can take that C++ cannot. The other statements I agree with.
Actually the "C++ annotations" is updated often and describes the new standard.
&gt; "Sometimes, the use of templates lead to faster C++ code [than C] and sometimes C++’s stronger type system improves optimizations."
I agree with this too. Overall, for large applications, if one were to write them entirely in C++ or entirely in C, then C++ would 99% of the time beat C. But the great thing about C++ is that one can use C for parts of an application where restrict would present some good optimization.
No, cpp has more readers. It's the other way around.
I've always been curious, but never really found an answer that made enough of an argument for automatic types or dynamic languages. What are some of the major advantages? When would you not want to declare a variable's type at compile time?
Constructs like "auto" and "decltype" don't make C++ dynamically-typed; it is is very much still a statically-typed language. It just makes the language easier to write in and less-verbose. It makes constructs like the following easier: std::map&lt;int, std::string&gt; data; // initialize data std::map&lt;int, std::string&gt;::const_iterator i = data.find(10); if (i != data.end()) { // do something } This now (can, but is not required) to become: std::map&lt;int, std::string&gt; data; // initialize data; auto i = data.find(10); if (i != data.end()){ // do something } "decltype" is much the same. It allows simpler and more explicit writing templates without the horrible and hard to read/understand voodoo that libraries like boost have had to resort to. These changes should make C++ more readable and complex templates significantly easier to understand (if the new features are used as intended).
In order to understand recursion, we need more readers.
I like that example. I see how it's made easier to understand and a little shorter to write, but when is it determined, with the auto, that i is a const_iterator in this case? Is it at compile or runtime? Does that affect performance? Also, I'm still curious about one of my original questions in general about dynamically typed languages. Is there any other advantages to dynamically typed languages besides being less verbose? [I'm a newbie here, so be patient, I'm likely to ask a good number of questions as long as you're willing to answer]
&gt; I see how it's made easier to understand and a little shorter to write, but when is it determined, with the auto, that i is a const_iterator in this case? Is it at compile or runtime? At compile time, definitely. It's just a more convenient way of typing: &gt; std::map&lt;int, std::string&gt;::iterator It sounds like you're not entirely clear on the way source files are compiled and then linked, and if that's true, a quick read might help with your understanding of static and dynamic typing. &gt; Is there any other advantages to dynamically typed languages besides being less verbose? I'm a long-time C++ programmer, and dynamic typing seems like a terrible feature introducing a whole new range of possible errors. It sounds like a nightmare to me. With that said, dynamic typing *would* allow for some very fancy OO systems... patterns of the sort that would be more difficult, or perhaps even impossible, to copy directly in C++.
Funnily enough the type determined by auto in the above example will be iterator, not const_iterator (because data is not const and non-const version of find() will be called, which in turn returns non-const iterator). I guess this answers the question why sometimes we may still want to specify the type explicitly instead of using auto.
It would be cool if you could write "const auto" to create a const version of the return type.
Wonder why variadic templates didn't make it onto this list of biggest changes. Perhaps because they are mostly useful to library implementers. 
Bunch of marketing BS at the beginning of the talk. Juicy stuff starts at about 10 minutes (also by coincidence slide 10).
You can write `const auto` to get a const variable. You can also write `auto&amp;` to get a variable of reference type. (Of course, a const variable holding an iterator is not the same thing as a variable holding a `const_iterator`, but you probably knew that.)
I think it is ok for the getter and setter to capture the shared pointer by reference, as you only need the shared_pointer mechanism to prevent destruction. In fact, you could use much simpler smart pointers in there. Great idea, though!
Yes it is, but that can be worked around. This is only a fairly simple implementation.
&gt;C++11 still lacks a few useful libraries such as an XML API That's a feature.
Think of it this way. Instead of writing: SomeLongTypeName GetVal(); //At the beginning there are always function declarations. SomeLongTypeName val = GetVal(); //Because of the previous declaration the compiler already knows that GetVal() returns a value of type SomeLongTypeName so why do I have to spell it out again? auto val = GetVal(); //Here we tell the compiler to replace the auto with the return type of GetVal(). Its works exactly as if we wrote it out manually ourselves like above. Personally I'm not much a fan of auto, for such cases, as its easier to write but harder to read. As in to figure out the type of the auto variable you have to go looking in the declaration which might be in another file.
I guess it also answers the question why we now have cbegin and cend in the container classes (oh, and crbegin and crend. the joy!).
Pity they didnt manage to include destructive moves. That would be pretty interesting. It was a can of worms apparently.
Good stuff.
Everything that puts "c++" and "simple" in one sentence is lying. Except it's a sentence like "c++ is not simple". 
Simple language = complex user code. 
But C++ is not a *simple* language by any measure I could come up with.
Lambda expressions make me happy. If only I weren't developing with RHEL6 in mind, which uses GCC 4.4, and lambda expressions were added in 4.5 :(
The "old old" me, fresh out of college, happily spitting out C code, would have upvoted you. The "old" me, having gotten a job to write "business" software in a managed language, would have downvoted you and posted a snarky comment about "dinosaurs" who "refuse to enter the modern world". The "new" me, after having dealt with the madness that can be bloated "enterprise business" software, well.....here's an upvote, sir. 
Does RHEL ever update its compiler/libc in the middle of a release, or do you have to wait 5-6 years for RHEL 7? That's one thing that drives me insane about "stable" software...I want to use the shiny new toys!!!
The main compiler on the platform won't change till RHEL7 - I'm working in 5.5 on a day to day basis at the moment, and it's using GCC 4.1. They did eventually add another package with GCC 4.4, but it's supplemental - it adds a gcc44 bin so that you can explicitly call it, but doesn't take over for the main compiler on the system, so it's really only useful so that you can compile test builds against it for the extra warnings it can produce. It's kind of a pain - gcc doesn't bug me quite as much, but I hate the ancient version of Boost it includes; however, the area I'm working in requires the binary compatibility, so we don't have much choice.
At least for general iteration there are also cbegin() and cend() functions that specifically return const_iterators. I mention this because when I first started using the auto keyword I didn't know about their existence and it seemed like an oversight.
C++ is as simple as you want it to be, and as complex as you want it to be. It's about the programmer(s) involved in the project which may or may not breed your hatred. Just because there's a nailgun in the shed, doesn't mean you need it to go fix what you can do by just grabbing the hammer. The point is; You have both if you need them and its up to the developers to wield them correctly. This kind of reminds me of that time when advocates criticized McDonald's for making kids fat by luring them with toys in happy meals, when you have the option of apples and juice instead of fries and soda. I don't know does this apply ? 
Thanks for a reasonable reply :) &gt; C++ is as simple as you want it to be, and as complex as you want it to be That applies only if you develop alone. If you work with code written by others, they define what you need to know. I've been working professionally with C++ for over 10 years now, about twice that total. There's no way in hell I can see C++ as simple language - to many exceptions (not just with exceptions ;)), many things you just *have* to know and many things that do not follow intuitively. (To make things worse, such a cosntruct is often accepted by the compiler but crashes.) Now, virtually all of this makes sense in historic context and/or the concept of C++ to be tools, and the developer know what they do. But while I am comfortable with the language, I also see what someone with less than a decade of experience has to struggle with. Simple language leading to (adequately) simple code? Lisp. 
nullptr fuck yeah!
Good stuff. [pertaining to Just for the Curious (with CD) (Cpp Media Video Transcription Series)](http://www.amazon.com/gp/product/0769220150?ie=UTF8&amp;tag=polidebanews-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=0769220150).
#EANF# [to the point GCC: The Complete Reference](http://www.amazon.com/gp/product/0072224053?ie=UTF8&amp;tag=idenprop-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=0072224053).
Is it just me or is the title of this post wrong from the subject discussed in the actual stackoverflow post? 
In what way?
It's just an oddly composed question. You're probably noticing that the SO post seems to be entirely discussing how to detect "C vs C++", but the question does end by re-asking the challenge in the title. I thought something was mismatched too until I got to the end.
But C++ is not a simple language by any measure I could come up with. [to the point Just for the Curious (with CD) (Cpp Media Video Transcription Series)](http://www.amazon.com/gp/product/0769220150?ie=UTF8&amp;tag=polidebanews-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=0769220150).
C++ is as simple as you want it to be, and as complex as you want it to be. It's about the programmer(s) involved in the project which may or may not breed your hatred. Just because there's a nailgun in the shed, doesn't mean you need it to go fix what you can do by just grabbing the hammer. The point is; You have both if you need them and its up to the developers to wield them correctly. This kind of reminds me of that time when advocates criticized McDonald's for making kids fat by luring them with toys in happy meals, when you have the option of apples and juice instead of fries and soda. I don't know does this apply ? [pertaining to Just for the Curious (with CD) (Cpp Media Video Transcription Series)](http://www.amazon.com/gp/product/0769220150?ie=UTF8&amp;tag=polidebanews-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=0769220150).
What is a function name except an index into a vtable? object.myfunction(a,b); as opposed to, object[myfunction](a,b); The point is not that you would actually program this way, just to point out that that lambdas provide an overlapping functionality to classes. [to the point The Complete Guide for CPP Examination Preparation](http://www.amazon.com/gp/product/0849328969?ie=UTF8&amp;tag=idenprop-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=0849328969).
#EANF# [to the point Magnetic Multilayers and Giant Magnetoresistance: Fundamentals and Industrial Applications (Springer Series in Surface Sciences)](http://www.amazon.com/gp/product/3642084877?ie=UTF8&amp;tag=polidebanews-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=3642084877).
I see and use typedefs for this all the time. I'm in favour of auto, but I do have one question. How does the compiler know if you want the const or non_const version of the method's return type? I wonder if const_auto and non_const_auto won't be needed at some point. 
My guess is that auto returns a const iterator if the collection itself is const. If you want a const iterator to a non-const collection, then you might have to specify it manually (or through a typedef). I haven't actually used auto much at all yet so I'm not sure how it behaves exactly. I am a fan of typedef'ing collection types so that they make sense according to their role (like typedef std::map&lt;std::string,std::string&gt; KeyValueMap;) so that's good enough for me in most cases.
EANF# to the point Magnetic Multilayers and Giant Magnetoresistance: Fundamentals and Industrial Applications (Springer Series in Surface Sciences). [to the point Magnetic Multilayers and Giant Magnetoresistance: Fundamentals and Industrial Applications (Springer Series in Surface Sciences)](http://www.amazon.com/gp/product/3642084877?ie=UTF8&amp;tag=polidebanews-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=3642084877).
C++ is as simple as you want it to be, and as complex as you want it to be. It's about the programmer(s) involved in the project which may or may not breed your hatred. Just because there's a nailgun in the shed, doesn't mean you need it to go fix what you can do by just grabbing the hammer. The point is; You have both if you need them and its up to the developers to wield them correctly. This kind of reminds me of that time when advocates criticized McDonald's for making kids fat by luring them with toys in happy meals, when you have the option of apples and juice instead of fries and soda. I don't know does this apply ? [to the point Just for the Curious (with CD) (Cpp Media Video Transcription Series)](http://www.amazon.com/gp/product/0769220150?ie=UTF8&amp;tag=polidebanews-20&amp;linkCode=xm2&amp;camp=1789&amp;creativeASIN=0769220150).
C++ is as simple as you want it to be, and as complex as you want it to be. It's about the programmer(s) involved in the project which may or may not breed your hatred. Just because there's a nailgun in the shed, doesn't mean you need it to go fix what you can do by just grabbing the hammer. The point is; You have both if you need them and its up to the developers to wield them correctly. This kind of reminds me of that time when advocates criticized McDonald's for making kids fat by luring them with toys in happy meals, when you have the option of apples and juice instead of fries and soda. I don't know does this apply ? [pertaining to #EANF#](#EANF#).
The SO nazi mafia strikes again! "Not constructive"...
**WY?**
Does anyone have an opinion about PPL? just wondering.
Really? It loads fast here - AU.
I know this is not strictly C (at least this particular part of the series), so I'm not complaining about the wrong subreddit, just wanted to let everyone know that there is a C subreddit called [/r/c_programming](http://www.reddit.com/r/C_Programming/)
Continue. My reply to Scott Meyers concerning the detection of Copy-Paste errors. http://www.viva64.com/en/b/0103/ 
For me the best reference is still the [CPlusPlus](http://www.cplusplus.com/) website. When I need to figure out which of the 120+ member functions of std::string I need, that's the place I turn. It's not so much a tutorial site as it is a solid online reference for the language, filled with lots of small, yet complete examples for most aspects of the Standard Library. But regardless, I applaud you for imploring others to improve/enahnce cppreference.com.
I use that site almost every day. Sadly, it's missing TR1 and anything C++0x.
So people are going to jump on the C++ bandwagon because of the "C++ Renaissance at Microsoft?" People are sheep if that is the case. You should use C++ because it is the best tool for the task you are working on. Not because Microsoft says so. C++ is a great languange and C++0X is pretty exciting also but you shouldn't need Microsoft (or any other company) to tell you that.
Having said that, people still _are_ sheep.
Microsoft makes development tools and libraries. Whether or not they care about C++ matters for this reason. My guess is that C++ "guru" Herb Sutter has managed to change the culture in MS from the inside in the ten years he has worked there. The focus is now away from ugly C libraries like Win32 and DirectX, to modern C++ libraries (in the style of STL) like the PPL and AMP.
I also want to add that the examples presented on that site are great quality, idiomatic code, that clearly show the intended usage of the various constructs. (both for C and C++).
any body else preferred the old layout?, 
I would like to add that MS is the company that first almost killed C++ with COM, MFC and it's horrible implementations therein (activex et al), then screamed for years how C++ was responsible for all the bugs in windows and tried to kill it again with VB, VJ++, c#, et al again. I mean they're the fox news of software, why do people keep listening to them at all?
What Microsoft needs to do is ditch MFC and make a high quality application toolkit for C++, using all the old and new C++ tricks, like shared ptrs for memory management, lambda functions for callbacks, real model-view-controller (not document-view), signals and slots, properties, etc.
I applaud the effort. I recently had the same idea.
When did they change the design/layout, it seriously looks weird.
[They're working on it, apparently.](http://arstechnica.com/microsoft/news/2011/06/windows-8-for-software-developers-the-longhorn-dream-reborn.ars)
Am I the only one that is terrified at the thought of a legion of mediocre C# and Java programmers jumping to C++ and causing unmentionable havoc?
What exactly points to a C++ application toolkit in that page? it does not seem to have anything related. 
Love the (first) comment. &gt; GCC 4.6.1 x86-64 has the exact same behavior. This coincidence is peculiar: when checking school tests, when two students have the exact same mistake, the teacher suspects cheating. &gt; Z.T. - 29 06 11 - 23:08
I &lt;3 C++, but it's not always the best or appropriate tool for the job.
Why your next language better be the right tool for the job.
&gt; I &lt;3 C++, but it's not always the best or appropriate tool for the job. I couldn't agree with you more, but the fear-mongering in the original post about C# and Java could have detrimental effects. A whole generation of programmers are only being taught enough in school to survive in a managed environment (JVM, CLR) and when faced with C++ you end up with crap like [this](http://stackoverflow.com/questions/6500313/in-c-why-should-new-be-used-as-little-as-possible). 
There's a whole bunch of details in the article. WinRT is a native C++ toolkit (also accessible through .NET through wrappers) to replace Win32, MFC, WinForms, WPF, and all the rest as a unified solution for Windows development.
The first thing those C#/Java programmers must be taught is [this](http://msdn.microsoft.com/en-us/library/bb982026.aspx). 
It only says that it will be named WinRT. There is no information beyond that. Neither does Google provide any information on it. It's vaporware. It's not even in the design stage. 
This really reads like a "told you so" of a frustrated C++ programmer, tormented by constant bad mouthing of his favourite language - and his chance to punch back has presented itself in the form of Microsoft's renewed interest in C++. Either that, or some serious trolling goes on there, couldn't make myself read this all the way through, it's painfull. (I've spent half my life with C++ and come quite close to a bonafide fanboy, but this guy takes the cake).
Of course Google doesn't provide any information. These are internal Microsoft leaks, not product announcements. I suspect we won't hear anything official until much closer to the Windows 8 RTM.
At least there are tools these days like Valgrind to catch memory leaks and buffer overflows, and standard / extended libraries compared to ~10 years ago. I remember writing my own string libraries using Borland C++ back in the day, and hated hunting down those missing semicolons (throws compiler error but doesn't tell you what line).
Tools like Valgrind / Purify and PVS-Studio, libraries like Boost or Poco, and modern IDEs (though I still live in Emacs and GDB) make things "easier", I still contend that C++ is inherently more complex and hence gives the careless (or ignorant, whether intentionally or not) programmer too much rope to hang themselves with. The much discussed Google paper from a few weeks ago said as much: C++ will generate the fastest code, but it requires more skill on the part of the developer to optimize. 
if the author thinks c++ is going to displace java/c# in corporate day to day programming he is in total denial. 95% of the programmers I meet haven't even done C since college.
The author of this is thinking about languages wrong... Languages just don't "Take Over"...it doesn't happen. They find a niche, become the best tool to use there.
yeah, so what. 100% of the software people that I know don't use java or c# in the embedded world.
OK, but why are you telling subscribes to /r/cpp, who presumably already know it?
No.
Must be somewhere between summer of last year and now. I think mostly since c++0x came out, seeing it's now in a wiki format...still weird though
It completely depends on where you are looking. I hear people talking about Java and C# all the time, but 95% of the programmers I meet code primarily in C or C++. I have never worked on a project that used C#, and although I've been on projects where Java has been used, it's been largely relegated to the sideline and only pulled in here and there when something needs to integrate with an existing Java application. I've written more Haskell in the last 2 years than C# and Java combined. Now, I'm not arguing that Java and C# aren't popular languages, I realize they are, but the circles you run in will have a big effect on your perspective about what is popular and what most programmers can or can't do.
I don't get why people have this urge to make the stuff they use look like the best. There is no war between these languages. 
&gt; *WinRT provides a clean and modern API for many of the things that Win32 does presently. It will be, in many ways, a new, modern Win32. The API is designed to be easy to use from "modern" C++ (in contrast to the 25 year old, heavily C-biased design of Win32); it will also map cleanly onto .NET concepts.* Sounds good to me.
&gt; It looks as if the war between C++ and C# is over and C++ has won. that's funny.
Have you seen this? [What's wrong with cplusplus.com?](http://programmers.stackexchange.com/questions/88241/whats-wrong-with-cplusplus-com)
but how big is the business software sector, compared to embedded programming sector? business software development is mostly invisible, it takes place behind the scenes and runs the world without you even knowing it. Altough the same can be said for embedded software, there is one huge difference, and that's the fact that business applications tend to be/become huge applications with millions of lines of code, span multiple subsystems that all need to talk together, and it needs to have a fast development cycle. Embedded software is usually small (how much code can you cram in a microcontroller?), but most importantly, it's developed, released and that's *it*. You don't recall a million units to flash the chip with new firmware, you get it right the first time, so the codebase doesn't grow as much with time (or at all) --- If you're doing a database front-end business application then you should use Java or C# for the job, because there is just SO MUCH to offer; so many libraries, so easy to use. of course you can use C++ for that job if you're comfortable with it, but the fact is, most people aren't, and they aren't comfortable with C++ for a reason: the alternative is easier to use. Want to connect to a Postgres database, call a web service and provide some results in JSON form? Have fun doing that in C++. In the meantime I'll just reference ADO.NET and pull a few assemblies into my C# project with Nuget. If you're programming hard real-time or bare-metal type applications then use C++. Because its fast, because its deterministic, because it fits into everything. I work in a bank, and by day I'm a C# .NET programmer. My code works, it's efficient, it's easy to understand, easy to deploy, easy to use, easy to maintain. By night I build real-time audio effects (VST plugins). The code is fast, it runs on any machine, it plugs into anything that supports the interface. it depends on nothing but a few header files. ...moral of the story: pick your weapon of choice.
I wonder if GCC doesn't optimize to the final version when the 2 is changed to 2U though. Missing an optimization opportunity in both cases doesn't seem terribly suspicious regardless.
I learned a good bit of C++ creating a game with CrystalSpace3d when I was in high school. It's a nice way to skip a lot of the messy and confusing 3D tutorials online that have you implement everything from scratch. But you still learn a lot of the concepts that you can then use to make an engine if you still think that's a good idea after using a real one. That or Ogre3D, or XNA, or just raw OpenGL if you really want (use libsdl to simplify some of the portability and windowing issues). I suggest not wasting time setting up any Win32 API stuff and just using SDL if you go this route. The worst thing you can do is to get hung up trying to get all of the extra shit set up just to draw a triangle in a window.
&gt;&gt;&gt;Embedded software is usually small (how much code can you cram in a microcontroller?), but most importantly, it's developed, released and that's it. You don't recall a million units to flash the chip with new firmware, you get it right the first time, so the codebase doesn't grow as much with time (or at all) YOU FAIL !!! Embedded doesn't mean that it MUST be a microcontroller with limited internal memory, because lots of embedded designs do have external RAM and/or flash or more. Limited codebase, ha, I've been on multiple projects that had over 100K lines of code and one had almost 300K lines of code. Almost every microcontroller part known to man these days has embedded flash, which means that code can and will be uploaded on some products. Oh my, C++ does not guarantee deterministic timing. I can't believe someone said that. You wouldn't be able to run any middleware or upperware because most O/S are written in C. Most newer designs are C++, but we sure the heck won't rule out C. 
Teach yourself c++ by Al Stevens is a good book. Then look at the irrlicht rendering engine and the OpenGL driver. Crystalspace and ogre are good but feel like c code, IMO. Irrlicht uses c++ well, but it won't teach you c++0x 
[Bruce Eckel "Thinking in C++"](http://www.google.de/search?q=Bruce+Eckel+"Thinking+in+C%2B%2B"). Available as free e-book, and often recommended. I actually learnt most from "The C++ Programming language" by Bjarne Stroustrup (back then the the print was included with the Watcom C++ compiler). It's a thorough treatment, maybe a bit on the dry side, and I'm not sure if there's an update for C++ 0x. --- Of course, find a good community, too. [codereview.stackexchange.com](http://codereview.stackexchange.com/faq) is probably a big booster for learning speed, by getting different experienced developers comment on your code. IMO the most important artifact for learning C++ is: *Not everything you can do is something you should do*. That applies to many things in life, but in C++ learning to do things right is a much bigger chunk than learning the language. Plus, libraries etc. **Learn to read code** That's boring and totally no fun, but the most valuable skill of every programmer. Maybe pick an OpenSource program you like, a tutorial how to use a debugger, and then step through ittrying to understand what happens. 
Don't forget his C++ FAQ http://www2.research.att.com/~bs/C++0xFAQ.html.
Which reminds me of ["The" C++ FAQ](http://www.parashift.com/c++-faq-lite/) Bought the book, it's great to keep beside the toilet. btw. your link to the Stroustrup FAQ has a period to much - it's http://www2.research.att.com/~bs/C++0xFAQ.html .
I have to see it to believe it. 
Avoid tutorials and books that teach C++ as "C with classes". That's wrong and false. Leads to many frustrations on the way. Contrary to popular opinion, I think that C++ is a great first language, but it's very hard. Be prepared. It's a long way, but it's very rewarding. If you manage to be an average C++ programmer, then it's likely that you'll know far more than a person who took the easier road of Python or .NET or Java (or similar). Also, for any mildly complex game programming (especially via OpenGL), you will need to understand quite a bit of math to be efficient. You can probably manage without most of it, but that will eventually lead to a problem you can't solve. That being said, the books others recommended are great. Use them, learn by doing and be patient and persistent. Good luck! *PS I recommend stackoverflow.com for questions. Honest questions that show some effort are well-received and answered, no matter how noobish they may seem to yourself.*
On the OpenGL end. You can take a look at 'Glut' its basically a training wheels version of the API and has a number of demos available. 
same
The top recommended text for starting seems to be Accelerated C++, followed by Effective C++, More Effective C++, and Effective STL by Scott Myers. I think all the above books are great, but I will say that after many years and books, C++ didn't "click" with me until I read The C++ Programming Language by Bjarne Stroustrup(the language's creator). I do recommend starting with Accelerated C++ to get up to speed fast with the basic concepts, but do consider following it with Stroustrup to get a deeper understanding of the "why" of the language and to have a better idea how the various styles and concepts possible in C++ fit together. Also invaluable while coding is the [C++ FAQ](http://www.parashift.com/c++-faq-lite/), it's good for little nuance questions that come up as you're learning your way around. For OpenGL, the best book I have read is The OpenGL Superbible. I recommend starting with the 5th edition, as it covers "modern" opengl(shader based) rather than the old deprecated fixed-function pipeline that a vast majority of tutorials and books seem to focus on. Two good online tutorials that come to mind are [Modern OpenGL](http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Table-of-Contents.html) and [OpenGL-Book](http://openglbook.com/). Cheers and good luck!
Nice that you can already spot errors just by looking at that thing for 5 seconds: "void main()" MEEEP! WRONG. main returns int. Not void.
Thanks both of you for the links and information. Most of you seem to talk about this alot but what exactly is C++ "0x". 
Noted, thanks. Ill be sure to drop by stackoverflow for any questions.
Bookmarked all those links, thanks.
Thanks for the reply, but someone mentioned irrlicht and after checking it out, I think I'm gonna go with it for now. I will try CrystalSpace though.
I concur. This is just another series of "How-to-code-C-in-C++" and as such teaches bad habits. It doesn't mention the SC++L at all and insists on using printf/c-headers/c-file-io throughout. It appears the author had little experience in both game programming and C++ when writing these. Give these a miss and check out the forums on [gamedev.net](http://www.gamedev.net) as they are full of capable and helpful people experienced in both C++ and game programming.
You are right, I've just deleted the link, the article was full of non-portable (non-standard) Microsoft C++ code. Sorry of posting this without reading the entire tutorial ... 
I agree. My own path went as follows: * Accelerated C++ * Effective C++ * More Effective C++ In addition to that I also read these books: * Pragmatic Programmer * Code Complete * Design Patterns Explained 
The C++ standard has been extended just recently. It was planned for "somewhere in the first decade", hence the "0x" for year 200x. Due to delays and much hand-wringing, we've all agreed that 'x' might well be a hex digit. Besides some modification of the existing language, it has added significant new features, see e.g. [here](http://en.wikipedia.org/wiki/C%2B%2B0x). Compiler support is quite good already ([VS 2010](http://blogs.msdn.com/b/vcblog/archive/2010/04/06/c-0x-core-language-features-in-vc10-the-table.aspx), [gcc](http://gcc.gnu.org/projects/cxx0x.html)) - in my memory that's much faster than back when exceptions and templates where added to the standard. The downside for you is that it makes the language more complex. The upside for you is that you don't have to wait for the cool stuff, it's already there. 
You're wrong. Game programmers are hard core, and every bit counts. Int's are too slow. &lt;/troll&gt;
If there would be only one programming language allowed on earth c++ would be a fine candidate.
&gt;Avoid tutorials and books that teach C++ as "C with classes" Whereas this may be sage advice, I don't think this should deter OP from learning C before learning C++. My first programming language was C and from there I moved on to C++ and eventually Python, which I think has given me the best of three worlds.
Where does one download c++?
[Wt](http://www.webtoolkit.eu) is the answer. It is also available for iPhone :-) 
The Poco C++ libraries have a lot of good stuff. Look for the "Net" library.
See this link: http://stevehanov.ca/blog/index.php?id=95
I wish someone would elaborate instead of downvoting your suggestion. I have been looking at wt myself, it looks like it would provide a lot of feature relevant to web dev.
That's a very interesting (and quite reassuring) read. A while back I actually made a fastCGI-based web server but instead quickly got into iPhone developments instead. I thought that a lot of functionalities required for a web server (wanted to make session management, captchas) could have been provided by some libraries if I were using some languages more specified for development. After another 2 years of using c++, going back to doing this might be a different experience..
One good place to start is [Poco](http://pocoproject.org/). It's a clean, organized, well-documented set of libraries for C++. They have some nice classes for implementing your own server pretty easily. A basic HTTP server can be put together in a few hundred lines of code. Their example code is easy to understand. If you're comfortable with Boost, the Boost.Asio library might be interesting to read up on. I don't have as much experience with Boost.Asio, but its class organization seems clean and pretty straightforward. There's a decent BoostCon talk on Asio [here](http://wipkip.nikhef.nl/events/BoostCon/2010/Boostcon-MichaelCaisseAnAsioBasedFlashXMLServer499.mov) (warning! 600 MB .mov file!). The video does a decent job of describing the asynchronous "Proactor" pattern used in modern scalable server frameworks. For a "real world" example, check out the [code to Ocelot](http://what.cd/ocelot-0.2-alpha.tar.gz), the torrent tracker used on what.cd. In just 1500 lines of code, it shows some basics of using sockets, timers, worker threads, and mysql. For a more serious real world example, check out [Mozy Mordor](http://code.mozy.com/projects/mordor/). They have a really advanced server framework built on fibers and an I/O Completion Port. Their stream architecture looks solid, too. There are good videos over on [the Mozy Youtube page](http://www.youtube.com/user/mozycode). "Scaling" a C++ server application of course depends on what the application does. You may need to scale for number of client connections, or for database size, or for bandwidth, or any combination of things. There really isn't anything "magical" to Java or C# other than their built-in libraries. With C++, you find yourself hunting for various libraries just to do things you can take for granted in other languages. Sockets, threading, XML parsing, serialization, logging, zip file handling.. there are very few de facto libraries for C++. Almost everyone does things differently, but some people even consider that an advantage of C++. Edit: If you don't want to implement your own server, check out [Lighttpd](http://www.lighttpd.net/). You can make plugins that hook into their already-very-scalable web server.
For some reason many people do not like C++ for web. On top of that, many people who use C++ for web do not like the fact that Wt is NOT page-based but widged-based (it's like developing a desktop application with Qt, Gtk, Cocoa, etc). I happen to like both C++ and developing webapps as if they were a desktop app. Makes my life easier. (I am the packager of Wt in Debian, btw) 
Yes, I agree. I actually think that C is the best starting language, but I didn't want to recommend it since OP seems to determined with C++ - which I think is also good for starting (given the student has patience) but it's harder, so it's only 2nd on my list.
Nobody mentioned CppCMS yet. I've not used it, but it has a very interesting type-safe compiled template system.
dumb question: Can you write iphone apps in C++? I thought that stuff was written in objective-C...?
I've been teaching myself WT for a while, it didn't really 'click' till they added the new WTemplate for me thou. That has made a bunch of formatting errors evaporate for me. Other easy complaint is the lack of well rounded docs., doxygen is great and all but an end to end explanation is badly needed. Other than those quibbles I'm like the qt for web thing. 
Sure you can... all of the core (UI and such) is written in ObjC so you're gonna have to use that to interface with Apple-provided functionality. Apart from that you're free to use C or C++, including any 3rd party libraries and such.
If u need something more mvc like, check [CppCMS](http://art-blog.no-ip.info/wikipp/en/page/main), it is also smaller and faster as Wt.
Since C++ supports sockets, you can always make your own web server from scratch and everything. But are you really sure you want to do it? I mean, this really looks like a prime time to learn another language (specifically, one very much unlike C++) and what it has to offer.
I would seriously consider going with another language for web dev. Even for purely server-side development.
&gt; what databases could be used well with c++ For database access from C++ you may want to check the [ODB](http://www.codesynthesis.com/products/odb/) ORM system.
Whoa, that looks like a very elegant to handle databases in c++.
I like [this](http://www.codeblocks.org/) IDE mate.
I'm glad somebody mentioned Accelerated C++, it is a great little book to launch your C++ education from. Just realize it is a fast start but isn't a complete C++ program. You will need other books and more so a few references. The big problem for you is timing, as has already been mentioned the standard will be updated this year making a lot of material out of date. You most certainly want to focus your learning on the latest techniques and features of C++. Since I expect updated materials to trickle out I'm going to suggest holding off on more involved texts until you finish Accelerated C++. Accelerated C++ is actually a quick get you started on the right path book, you could finish it in a month easy. Hopefully by the end of summer new editions of the more popular books will be out. As to OpenGL that is a wholly different ball of wax. It is so different a different set of texts is required along with a strong math background. I've done very little with OpenGL but realize it is a task separate from learning to program. In any event you are already getting good suggestions from people that know. 
Harder? I really don't get this one, starting out C++ is no harder than C to learn. In some ways it is actually easier. Now further down the road there are some really difficult concepts but those can all be dealt with in time. Some can be completely ignored also. I actually think his bigger task will be coming to grips with OpenGL. The thing here is that by starting with a text like Accelerated C++ he will be able to quickly put together code to start work with OpenGL. The trick here is to not get distracted by the pretty pics and to continue to learn C++. Which just brings a thought to mind, I hope the guy posting the question doesn't think he can put in three months of effort and then call himself an educated C++ programmer. Isn't going to happen in my opinion. This isn't like learning BASIC or Python, it simply takes longer to zero out all the little gotchas, the ambiguities and learn the good practices. 
I meant precisely those difficult concepts. Yes, starting is probably the same, but C can be grasped in its entirety by a beginner in a relatively short time, whereas C++ can not be, in my experience.
What terrifies me more is "expert" C++ programmers who automatically think that C#/Java programmers are somehow "mediocre" just because they can be productive without arcane compiler and language knowledge. The "unmentionable havoc" to C++ has already been done by its own "elite" programmers. The same elite programmers who continued to juggle raw pointers even when smart pointers were available and who looked at std::vector with suspicion for near a decade. The same ones who still don't understand the point of exceptions or RAII, the same ones who still write "C with classes" the same way they learned it in 1993 since "it's faster!!!@%". I'd rather work with "mediocre" C#/Java programmers who at least move with the times vs C++ dinosaurs who are still trying to figure out Unicode strings. I guess my experience with the C++ camp has left me just as bitter as yours with the managed camp. I *love* C++ but I hate the attitude that comes with it. God do I hate it. Mediocre programmers exist everywhere. There's absolutely nothing about C++ that makes someone better for using it. 
I spend a trivial amount of time programming these days but must say this has a sour tone to it. There is really nothing wrong with C++ and it certainly doesn't deserve all the negativity it gets but who cares who uses it and who doesn't? Really guys no big deal here. As to programming I often think the Java guys are just as deeply in the dark as the C++ guys as I warm up my Python IDE. On the otherhand I have C++ code that has run for years without issue. Half the time the difficult part isn't the programming anyway, you have to solve the problem before you can code. 
Yes but at some point you are no longer a beginner. Further very few are fully conversant in C++ because you don't have to be. You simplly use what is requiredto get the job done. The point is you have to start someplace and starting with C++ is no harder than any other language. Frankly this is the case with many non trivial languages, the basics are easy to grasp and then you have to work at the more advanced concepts. Frankly grasping these concepts or more exactly the advanced features of C++ is required to do anything substantial with OpenGL 
Oh I get it now. I agree.
A recent update to the ClanLib layered windows functionality has some potential interesting usages. Version 2.3 of the library contains a CSS layout engine, capable of rendering [CSS zengarden](http://www.csszengarden.com) pages . Thus with conjunction with existing [examples](http://esoteric.clanlib.org/~rombust/ReleaseImages/LayeredNew.png), games can contain interactive web pages in 3D. 
Well, not exactly a podcast, but some [really good videos from Boostcon can be found on blip.tv](http://blip.tv/boostcon/) Note that there are 5 pages of videos (scroll down the page), it's not just the videos on the one page. There is also [Software Engineering Radio](http://www.se-radio.net/), which is not exclusively C++, but it covers some good topics that transcend any particular language. There's also the video series on the STL by Stephen Lavavej, I assume you've already seen those featured here as they become available.
I'm currently reading Accelerated C++, and I completely agree that is the best introduction to the language I've seen. However, for a person entirely new to programming it can be challenging to start with this book. My advice for those currently considering getting this book is to re-read the sections as necessary and do all the exercises. The book is a tutorial style so make sure you supplement it with another more comprehensive book to serve as a reference.
It sucks the "Non-static data member initializers" aren't implemented yet.
So when it says something is dead that just means there hasn't been development on them in a while, right? That wasn't particularly clear to me.
No it means the feature didn't make the latest standard (c++0B).
So is GCC 4.7 released yet and does the table correspond to it?
Bad title.
ugh his blog is like a stream of drivel
I just discovered http://www.se-radio.net/ myself and have been listening to it for the past 24 hours. Thank you for sharing. SER a few pages down has another conversation with Kevlin Henney on the topic of C++.
Interesting. I knew "concepts" have long been not considered, but I could have sworn lambda expressions and closures were still apart of it, though they're listed as dead on the site. They're still on the [FAQ](http://www2.research.att.com/~bs/C++0xFAQ.html#lambda) which was updated a few days ago, as well as in all the latest documents I could find with a quick search. Am I misreading the table or is the table wrong? Did he just group the two dead topics under the "new wording" entry?
http://www.se-radio.net/2010/04/episode-159-c-0x-with-scott-meyers/
C++ will never "jump the shark." It's been around for almost 30 years and we'll still be using it in another 30.
The [link](http://www.codeproject.com/KB/cpp/cpp10.aspx) at the bottom was very good
I'm more worried about programmers who are scared of pointers when they make sense in code that directly accesses and manipulates memory. Passing around std::vector in such situations is a sure sign of a newbie. People usually use different libraries for low level stuff and that std::vector means that you can't use wrapper classes to mix with other packages because vector's already decided what you MUST use. Not only that, but STL doesn't work cross-dll. But it APPEARS to work if you use the same compiler and the same version of STL for ALL dlls meaning that if you ever change compilers or STL version, you're in for a world of hurt and these programmers have to learn the hard way that a simple pointer would have saved the day. 
&gt;I'm more worried about programmers who are scared of pointers when they make sense in code that directly accesses and manipulates memory. I still maintain, based on personal experience, that there are *more* programmers who don't use std::vector when they should, vs the ones who use it when it's overkill. And even when std::vector is overkill, how many use-cases there are for *not* using unique_ptr&lt;&gt; or shard_ptr&lt;&gt; or (oh god I feel dirty) auto_ptr&lt;&gt;? Are we (honestly!) *that* worried about performance that unique_ptr&lt;&gt; is too performance heavy? Embedded code for an 8086 with 32KB of RAM maybe? I maintain that's still in the vast minority of cases. I agree about the issues with the STL. Although, the issues are actually *NOT* with the STL per se, but rather with the fact that the C++ linker model is pretty.....behind the times, if you can't reuse other people's code due to name mangling or what have you. You know, now that I read your response again, for a third time, I don't believe that I'm actually even arguing with you anymore, it seems I just reiterated some of your points :) 
I think we're somewhat on the same page. But a few clarifications. Performance has nothing to do with it. It's about the API. Using smart pointers is fine if you can release the pointer so that you can pass it to other libraries/code and they can handle it whatever way they like for stuff that handles lower level resources. However, even in the general case, when you use vector or whatever else, you then have to be conscious of the effects this will have on the code that calls your API and how well your code will work with other code. I have no problem with people using STL to their hearts content. It's when they start using it as part of shared libraries/code that I find it disturbing. It's like they never learned good API design. Note that for internal stuff that doesn't get called anywhere else or only within a certain set of classes, go nuts with STL, smart pointers, RAII (damn, I love RAII). Also, the problem with STL and DLL's isn't the name mangling. It'll likely compile just fine. But when you run it, it'll crash horribly. It's because the STL is made of templates. So the library is actually inline in the DLL itself. If you compile two DLL with the same compiler, but use two different versions of STL, it won't work because each DLL will be using a different implementation. The header files have changed. So if you use STL, you must make certain that you distribute STL along with your DLL if anyone is to use it. Think about that for a second. But that same baggage happens internally as well if you have a lot of shared code between your own module. It's just not as easy to see until it's too late. I still stand by my point though. When I see people who use big ass containers just to grab a pointer to the first element internally because what they're using won't work with the chosen container, I go nuts. A vector isn't a smart pointer. And if the memory was allocated from somewhere else, good luck with that mess. 
sure
ehrrrr... Don't you think VC++ is a bit dated? Do you want to learn C++ programming, or do you want to learn about MFC, WinAPI and such?
Then would "Thinking in C++" be a better alternative?
"Accelerated C++" is my favorite first C++ book.
It seems like the popular choice. What do you think of Stroustrup's book? Too dense?
Ok, to be honest, it's been a while since I've used C++ for my daily work, however, isn't the STL actually now just part of the *standard* C++ library? So, if I'm using VS 2010 SP1, and you're using VS 2010 SP1, there should be no problem with me using STL, templates, what have you, since we'll both be linking to the exact same standard lib? I thought the problem would only occur if we're using different compilers/versions of the same compiler. I could be off here, again, it's been a while. Are you saying that templates in general (STL or anything else) should not be used in a library as part of its public API at all? Or are we only in danger if we're using different compilers/standard libs?
All of the "... in x days" books are terrible. All of them. Get Accelerated C++.
did no one read that as CAMP? i also read C++0x as cocks. maybe the problem is with my reading/perception.
&gt; The new standard is out now The link you give does not state it is out now. Also The C++ 0x wiki page also states it is not out yet.
"Teach Yourself C++ in 10 years"... Now seriously: "Thinking in C++" is very good. If you're interested in developing "infrastructure/systems" in the long term, I also recommend you to start learning inside an unix box (linux preferably). 
Not CPP. At all.
Apparently the OP thought that even a picture of Stroustrup spreading his butt cheeks Goatse style qualifies as C++. But don't knock him - based on the text on the picture and the title of this post, I'm guessing he took time off from his Java 101 class in 10th grade to post this. So he's got that going for him. Which is nice.
I don't know about you, but I can't code CPP without dual monitors.
Style icon
 the-lich-king login: marktraceur Password: marktraceur@the-lich-king~:$ emacs -nw main.cpp
He looks similar to this [fellow](http://i.imgur.com/YshzV.jpg).
*whoosh*
STL should NEVER be used as part of a public API. That is correct. What usually happens though is that people end up writing DLL's and only share them between the company's own apps. That's fine to use STL as long as you keep the same STL version or rebuild all the apps if you change compiler or STL version. About your question, I'm assuming you mean using different service packs. In such a scenario, there is no guarantee that your old libraries will continue to work with a newly compiled module if you use STL across dlls. As one example, Borland switched to a different company for their STL library. You could still use the old STL implementation if you wanted. However, you must recompile EVERYTHING that uses STL if you switched STL libraries. I had the mistake that one component did not automatically recompile and I had an awful time catching the problem because the app crashed at a completely different location. To simplify the situation, it goes like this. If you write a library, module or any kind of binary executable format (dll, exe, static library, COM object or otherwise), you absolutely CANNOT use STL as part of your public API. That's it. Now, that doesn't mean that using them for your own apps in your shared API is ok. There is some baggage here too though there are ways to avoid it if you very meticulously control how that API is shared as well as what uses it. But I wouldn't want to be the developer that uses those API's since you are then forced to use classes and containers that may not be appropriate for the task at hand. edit: I should add that being part of the standard C++ library just means it has to be available. The implementation is not required to be the same. That throws a wrench on libraries that use templates because they aren't traditional libraries where only the API matters (and stays the same). With templates, the implementation also matters... whereas it doesn't for non-templated code. 
http://www.sgi.com/tech/stl/table_of_contents.html
From my own experience I would recommend reading Stroustrup after 3 - 5 years of programming experience ;)
I'm not really sure which books I would recommend for a starter. You need something which teaches you the basics and especially object oriented programming and more important: object oriented thinking. My first (good) cpp book was "C/C++ Programmierung" by Ulrich Kaiser. Shame it's only available in german. Perhaps get a copy of some "C++ Primer". When you're done with that check out every book by Herb Sutter, the "Effective C++" series and "Modern C++ Programming".
Take the hard way. Use [the holy scripture](http://www.open-std.org/jtc1/sc22/WG21/docs/papers/2011/n3242.pdf).
accelerated c++, and grab visual studio 2010 C++ express
You'd be hard pressed to find a worse book to teach yourself C++. I've actually read it.... Just horrid 
This kind of stuff is good if you want to write optimized containers. 
++++ This is the book to get to get you started quickly. It is no where near the end of your education though, but rather a start. After the start though we run into a little problem in my mind, that is a new C++ standard is to arrive real soon now. So you could end up investing in a lot of outdated materials if you aren't careful. The thing is you should expect to be able to understand and program basic things from reading Accelerated C++ in less than a month. However that is not being conversant in C++. That will take much longer and lots of study. Now about that version of Visual C - JUST SAY NO. Someone already suggested Linux, which is very good but I'd also suggest a Mac. Macs are full Unix systems and are great development platforms. Also it is very easy to run LLVM and CLANG on a Mac. Those tools can be a huge aid in learning as the compilers generate much better diagnostics. You can of course install LLVM &amp; CLANG on Linux systems. The caveat here is that solid C++ support in CLANG is very fresh. Beyond all of that don't plan on learning all the particulars of C++ in one shoot. C++ has a wide array of features, some taking more effort than others to master. Better to get the basics under your skirt , know it well and understand what your code does then take on advanced concepts. Lastly someplace in there you should look at Boost. Again some capabilities that Boost offers are simple to understand others not so simple. Also some features in boost will end up in the latest standard in one shape or another. So you are at a point in time where understanding what your compiler supports is important. Compiler support of the emerging standard is a very dynamic thing. 
For what it's worth Stroustrup has [another C++ book](http://www.amazon.com/Programming-Principles-Practice-Using-C/dp/0321543726), /to learn programming with/, ie it goes more gently and has more examples. I indeed wouldn't try to learn programming with the 3rd edition main C++ book, but then I'm not sure I'd try to learn programming with C++, either (Python). He uses the linked book above to teach, it's probably suitable to learn from. 
Everyone's excited about Boost and wants to mention it, but it's really not suitable for a beginner. 
I once used it to "disable" an overload of member function for a specific templated type. Works great.
It also helps improve compiler errors, since the compile error will be in the user's code rather than in the library's
I don't see what this post adds compared to the Boost documentation: http://www.boost.org/doc/libs/1_46_1/libs/utility/enable_if.html
These are terrific. I think I only made it through the first couple so far, and definitely have to catch up with the series.
Brilliant series, been following them from beginning. STL is a ~~good~~ god among men.
For those who wonder who this guy is.. here's his rather [personal blog](http://nuwen.net/stl.html)
&gt; STL is a God among men. FTFY.
 #elif defined(__GNUC__) Stephan, I love you man.
thanks, fixed
Except he's far too sensible to believe in God's or other such flim flam.
No, Stroustrup is God, Herb Sutter is the pope, Lavavej is a preacher. But he is a good preacher.
this is an awesome reference, thanks!
Hey downvoter, from TFA: 'Although the term "atheist" correctly describes me insofar as it means one who does not believe in the existence of gods, it is an incomplete description' Eat that.
I would add computed goto statements to the list: http://gcc.gnu.org/onlinedocs/gcc-3.4.1/gcc/Labels-as-Values.html They're used in some interpreter acceleration techniques.
It's not a blog, but a hugely interesting website that I've bookmarked and already spent over 2 hrs reading. Thanks for linking to it. I'm such a groupie.
Phoenix looks cool, but I bet without above-standard compile-time diagnostics, it's just a PITA. 
woohooo... my patch (arbitrary radices for numeric parsers in spirit) is included :) my very first open source contribution! :)
This guy is a nutjob. 10 years until adoption? Pfft. Major compilers are almost there already and it hasn't even been standardized yet.
Pretty good timing-I was looking at the random library on Sunday and wondered why it didn't have Weibull distribution, and here it is.
Oh great, around 10-12 fixes for ASIO I had to manually write work-arounds for. Oh well, back to the batcave.
Is anyone else finding the text of this blog completely unreadable, or is it just me? (Firefox 3.5 under KDE 4 on Debian Squeeze)
That was my personal experience with it. I tried using it once as an experiment on a project I was working on, and eventually gave up out of frustration because my code kept refusing to compile and I had no idea what I was doing wrong because the error messages were horrendous. For example, one of my attempts involving a four-line snippet of code resulted in a 7,061 line error message.
Lol. The day programmers get groupies ... is the day after plumbers get theirs.
I couldn't get it to build with gcc 4.4. I tried both the -std=c++0x and -std=gnu++0x flags and neither would build it.
Yeah, some of those issues had a serious "WTF? How do people use this?" factors on them. Glad to see they've been addressed.
A C++ programmer that doesn't use the STL? Another backwards "C with Classes" programmer that don't get what modern C++ is all about. STL standard conformance (and therefore portability) was an issue in late 90s compilers.. but not today. If you cant take the time to upgrade to a modern compiler on your platform then you have noone to blame. Its not C++ that needs to adapt to pre-STL frameworks like Qt. Its those early 90s frameworks that need to, get with the program and, adapt to using the modern C++ types in their interfaces. Edit: There is nothing wrong with C++ unicode support. C++98: typedef basic_string&lt;wchar_t&gt; wstring; C++0x: typedef basic_string&lt;char16_t&gt; u16string; typedef basic_string&lt;char32_t&gt; u32string; Read more about them [here](http://www.devx.com/cplus/10MinuteSolution/34328/1954) You will use std::codecvt to convert between the different encodings.
I think the release notes are lacking.. For instance IPC has a backwards compability breaking bugfix (shared memory files now persists between reboots on windows ([this file](http://svn.boost.org/svn/boost/trunk/boost/interprocess/detail/tmp_dir_helpers.hpp))), but is not mentioned in the release notes.
Pheonix looks somewhat cool, but it also looks like something I wish I never encounter in actual code. 
Congratulations and thanks for making the (OSS) world a little bit better place :)
Woot! Geometry is here!
The first question I would ask myself is in what area is this plugin architecture lacking that it needs to be updated with boost/c++0x usages in order to perform it's function better? Looking deeper into the example code that the article provides the only really reusable piece is the Plugin class itself, and even that is merely a prototype implementing plugin functionality for Windows systems only. It doesn't appear to be a framework on which to build code but rather an example of how to achieve plugin functionality and spark an idea in the reader on how to implement it in their own applications. That said looking over the example code the only real change that I would make that I see immediately would be to replace the std::auto_ptr usage with std::shared_ptr to simplify resource management.
Wait until you have to debug it and actually step through that crap.
I haven't spent a huge amount of time trying to implement the suggested system yet, currently I'm looking at it to allow me to create a number of widgets that are similar in function but with different validations / rules behind them. One of the things I had been wondering about specifically is if the new 'auto' construct would help clean up the system at all but really it's already a fairly straight forward block of code.
I live to serve, my dark lord. (I didn't think portability was that popular, though.)
GCC 4.4 is ancient (April 2009). I used 4.6.0 with -std=c++0x .
It's really you (/Gasp).
Abstruse goose said it best: http://abstrusegoose.com/249
Have you ever seen Boost Graph Library for example? Tried it once for a research project and now just mentioning it gives chills to everyone on my research group (solid state/computational physicists)
No. Please give me an example of its complexity. 
yeah, nobody tells you how much time you will spend with linker issues when using c++. Especially on windows where you cannot mix debug and release libs :( I wish I had this article at the beginning of my c++ career
&gt; especially when you cannot mix debug and release libs Are you saying this works on a different C++ platform (osx, linux)? Many others languages are no better, avoid this by not providing debug libs (C#, Python, etc...) 
Why would you ever WANT to mix debug and release libs/dlls?
Well, Asio before this update was still better than writing it all from scratch. Does that say much? No, definitely not.
I do this all the time. Not necessarily by choice, but by necessity. When dealing with vendor software, you're not always privy to debug versions of libraries. But, you obviously at some point need to debug. Knowing how to safely mix is important. Not so much of a big deal in linux (debug &amp; release share the same heap), but on windows, it can be especially painful where the debug &amp; release runtimes do no share heaps, and if you're not careful, you'll quickly fail with assertions due to freeing memory in the wrong runtime.
I've never had issues with linking debug and non-debug C++ libraries in a linux executable (Qt, STL, boost, ...). Could you give an example in which case it goes wrong? 
&gt; if you're not careful, you'll quickly fail with assertions due to freeing memory in the wrong runtime. The library doing the allocating should also be doing the deallocating. 
you can definitely mix debug and release libraries, unless I just don't understand your meaning.
I do it daily at work. Game engine in release so that it has fast rendering, game code in debug so that I can trace through game logic easier. Engine lives in one set of DLLs, Game in another.
If lambdas are dead, that is disappointing news to me. I hope the table is wrong.
Everything else I've read indicates that lambdas are part of the standard. I don't know why the site chose to list them as dead and go with the "new wording" row only, maybe because that's what the gcc site itself seemed to do, but I don't think you have to worry about lambdas actually being dead; gcc 4.5+ supports them.
That counts as being careful.
People make plugins for my app and I only get the release version. But I don't see why it's a problem, it works just fine for us...
No. That's recommended standard practice. Is driving your car with water in the radiator "being careful"? No! It's standard practice. If you don't do it, your car will overheat after driving for a while. Likewise, when breaking these standard practices of libraries, you might be able to get your application to work for a while. But sooner or later it is going to cause some problem!
I'd say that checking the radiator water level is being careful, and so is reading up on and following best practices in C++. Most programmers I know don't.
There's no linking involved with the STL, and hardly any linking needed for boost. Qt does involve linking but they go through great pains and discipline to allow linking between debug and release libraries.
Interesting, I didn't know that about gcc's crt. VC's debug crt adds extra bookkeeping fields to various structures (esp. iterators in C++) in order to detect incorrect programs (e. g. buffer overruns). You can look for yourself in the crt sources provided with Visual Studio. Of course, if you mix the two, you incur the full wrath of ODR violations. 
It was... except things like not waking up for signals were super annoying.
one time I made a suicidal python program import sys, os os.remove(sys.argv[0]) 
Actually, the STL does have some non-template parts (hence libstdc++.xyz.{so,a})
Interesting, not that I use QAt but that static analyzers are becoming more and more useful. 
This is a very simple garbage collector I wrote in order to experiment with the idea of tracing root ptrs from an object instead of tracing objects from root ptrs. The collector deletes objects as soon as they are unreachable, including cyclically-referenced objects. Objects are deleted in deterministic order, except if there are cycles. If there are cycles, then the collector breaks the cycle by nullifying pointers automatically (it's better to access a null pointer in a destructor instead of a dead object). The algorithm used works like this: each time a pointer is reset, the graph of objects, starting from the released object, is scanned for pointers. If a root pointer is found, then the object is considered reachable. If a member pointer is found, the owner object of the pointer is scanned. If an object has no paths from roots, then it is deleted. In order to scan the object graph towards the roots, each pointer knows its owner object (set manually in its constructor), and each object knows which pointers point to it. It's not very fast, especially if the object graph is complex. Comments, ideas for improvement, and possible issues are welcomed. 
I'd love to see a bigger test suite. How does it know when there's a cycle? Names starting with an underscore are technically reserved by C++ for its own uses. This is a style thing, but instead of calling lock and unlock separately, consider using a scoped lock mutex mechanism. (new simple class, calls Lock in its constructor, Unlock in its destructor). Again, just a style thing. 
&gt;Names starting with an underscore are technically reserved by C++ for its own uses. Actually, only names starting (or was it containing) with 2 consecutive underscores and names starting with and underscore and uppercase letter are reserved for the implementation. Underscore followed by lowercase letter is fine.
&gt; I'd love to see a bigger test suite. What do you propose? &gt; How does it know when there's a cycle? During the function "_mark", it checks if the function is entered again for the same object. If so, then there is a cycle. 
Any name beginning with an underscore is reserved for use in the global namespace. Names beginning with two underscores or an underscore followed by an uppercase letter are reserved to the implementation for any use.
Yup, you are correct. 17.6.4.3.2 says this. _[A-Z].* __.* are for macros and therefore reserved everywhere, _[a-z].* only in global namespace.
http://stackoverflow.com/questions/2586596/fastest-algorithm-for-primality-test
I have to use a base class (gc_object) *and* a smart pointer (gc_ptr). What is the advantage of this garbage collector compared to standard reference-counted pointers, like boost::shared/weak_ptr? I thought the idea behind gc is that I don't need to do anything to manage memory. This looks like I actually have to do more.
Another review. Running the code through PVS-Studio. http://alexchacha.blogspot.com/2011/01/running-code-through-pvs-studio.html
The collector handles cyclic references, unlike reference counting. There is also the class gc_wrapper which uses multiple inheritance to make classes inherit from class gc_object. EDIT: I modified the code so as that gc_ptr&lt;T&gt; can point to classes not derived from gc_object. When such is the case, gc_ptr&lt;T&gt; uses a proxy gc_object. This happens statically at compile time, based on the inheritance relationship between T and gc_object. 
I'd recommend watching [The New Boston](http://www.youtube.com/watch?v=GMx_G05cqYI&amp;playnext=1&amp;list=PLF541C2C1F671AEF6) tutorials, they are really helpful and probably the only good programming tutorials on youtube, however you should probably switch to another IDE as Dev-C++ is really old. I would recommend using [Code::Blocks](http://www.codeblocks.org/) and if you are downloading for windows get the [one with mingw](http://sourceforge.net/projects/codeblocks/files/Binaries/10.05/Windows/codeblocks-10.05mingw-setup.exe) as it makes transition a bit easier.
I have to agree. To be generally useful it would needs to be unintrusive. That means the definition of the object being managed cant be changed (you cant change the definition of 3rd party types like std::vector). That pretty much means you are back to smart pointers. Maybe it would be possible to have a housekeeper that crawls the smart pointers looking for cyclical dependencies. But its probably not worth it. I think there is little need for GC in C++ as destructors makes reference counting easy. GC is only really important for languages that lack destructiors. 
While I find auto makes my code easier to write ... it makes it harder to read. As always code gets written once but read many times, so that's where the priority should lay. I found that auto obfuscated my code. Imagine vectors containing maps containing lists containing strings etc. It helps the reader if the type is visible in the code. With auto the reader will have to go look elsewhere to find what type a variable is. Using auto and to help the reader one would have to go back to hungarain notation ... and that surely is a step backwards. Edit: I didnt think this would be such a controversial topic. The benifits of statically typed languages compared to dynamically typed ones should be uncontroversial to every C ++ programmer. One of those benifits is readability. With auto we are getting the readability of a dynamically typed languages in a statically typed one. What seems to be lost in this debate is that types are not just spelled out for the compiler, more importantly they are spelled out for the human reader. The type (and therefore its interface) of a variable is The most important property of a variable, its name is much less important. Therefore the type should be explicit in code and not implicit. TL DR: Imagine you ran your codebase through a tool that replaced your spelled out typenames with auto everywere it could. You have now lost readability. 
&gt; Imagine vectors containing maps containing lists containing strings etc. Yeah, sure, "`vector &lt;map &lt;stuff, list &lt;string&gt;&gt;&gt;::const_iterator`" is easy to read. `auto` has been made to replace complicated types. You'll never write "`auto x= 42;`" -- "`int`" is easier to type anyway. The typical example is to avoid typing "`map&lt;int,string&gt;::const_iterator i= my_map.begin();`". In that case, `my_map` is typically an object you use a lot in your local code. Often, it's an important member of your class, and you probably remember it, or a local variable, and you have its definition a handful of lines before. Basically, this is OK: map&lt;int, string&gt; my_map= foo(); auto it= my_map.find (stuff); This may be OK or not; use your judgement: auto my_map= foo(); 
&gt; Yeah, sure, vector &lt;map &lt;stuff, list &lt;string&gt;&gt;&gt;::const_iterator is easy to read. Lets flesh it out. Realistically you use typedefs when nesting like this. typedef std::string Word; typedef std::list &lt;Word&gt; SynonymList; typedef std::map &lt;Word, SynonymList&gt; Dictionary; typedef std::vector &lt;Dictionary&gt; Bookshelf; Bookshelf func(); int main() { //barely understandable.. Bookshelf var0 = func(); Bookshelf::iterator iter1 = var0.begin(); Dictionary::iterator iter2 = iter1-&gt;begin(); SynonymList var3 = iter2-&gt;second; Word var4 = *var3.begin(); //completely obfuscated.. auto var0 = func(); auto iter1 = var0.begin(); auto iter2 = iter1-&gt;begin(); auto var3 = iter2-&gt;second; auto var4 = *var3.begin(); return 0; } Even though the one where the types are spelled out in the code is ugly. You can understand it. The one using auto is beyond understanding. 
Interesting I find the second one much easier to read. 
I doubt it. It looks cleaner, yes. But you have to do some serious mental recursion to actually understand it. Just looking at it. What type is var3 ... well to figure that out you first have to figure out what type iter2 is .. and that means figuring out what type iter1 is and var0 ... and then doing a back substituting using the return types of the methods. Programming is hard enough as is without this.. 
Honestly, this is a case where hungarian notation ([properly done](http://www.joelonsoftware.com/articles/Wrong.html), not the kind of shit Microsoft used to do) has its place. I often write stuff like that: auto bookshelf = func(); auto it_bookshelf = bookshelf.begin(); auto it_dict = it_bookshelf-&gt;begin(); auto syn_list = it_dict-&gt;second; auto word = *syn_list.begin(); (Yeah, I know, it's not really Hungarian, but close enough.) That way, the variable itself is easy to understand, not only where it's declared, but also where it's used. Who calls their variables "iter1, iter2" and "var3, var4" anyway? 
Your missing the point. The majority of the times that I read this piece of code I do not need to know the exact type of var3. I certainly do not need to know the exact type of iter1 and iter2 most of the time that I am going to read through this code. I can find out what the type is with either case just there is less noise in the second example. Honestly, compared to figuring out the typedef monstrosity up at the top figuring out the inferred types of the second part is easy. 
&gt; **In recent decades**, a third treatment has crept into some languages: If the compiler can figure out during compilation what type an expression has, why not make it possible to say that a variable has that same type, whatever the type might be? Hindley-Milner type inference is from the sixties.
&gt; Realistically you use typedefs when nesting like this. Then you have to look up the typedef to see what the real type is. How is that any better than having to look up the return type of the function being used as the initializer?
Don't cycle strong pointers? Seems like any design is suspect that does this.
DescriptiveTypdefName var = func(); is easier for the reader than auto var = func(); If you provide a typedef a type its usually in common use. So you wont have to go look up the declaration every time like with auto.
Mentally you have to substitute the auto code into the typedef code, or into the un-typedefed code. Its just easier when its written out. 
Descriptive names are a good thing, I agree. Still hungarian notation where the type is also encoded in the variable name should be avoided. It introduces potential bugs where the type of the variable as encoded in the variable name is incorrect. 
Cyclic references are necessary in a variety of situations (tree relationships, for example), and they also may be easily introduced indirectly via subclassing. 
&gt; To be generally useful it would needs to be unintrusive. I'd love to do it unintrusive, but it is not really feasible: the algorithm requires knowledge of the pointers that point to the object, and also knowledge of the owner of each pointer. &gt; That means the definition of the object being managed cant be changed (you cant change the definition of 3rd party types like std::vector) You don't need to. You can use the class gc_wrapper&lt;T&gt;, which uses multiple inheritance from T and gc_object. &gt; I think there is little need for GC in C++ as destructors makes reference counting easy. GC is only really important for languages that lack destructiors. You are confusing two separate things. Destructors exist to automate cleanup, garbage collection exists to automate the invocation of destructors. Both are useful and complementary to each other. 
As described in the link I gave, hungarian notation is not about the static type (as the compiler knows it), but the semantic type (i.e. what it means). If you need to change the variable name because you switched the type from `float` to `double`, it's not hungarian notation, it's Microsoft notation.
`func()` is a pretty unhelpful function name. Consider: Employee var = getEmployee(); auto var = getEmployee(); That's what my code usually looks like, so I have trouble seeing the value added by typing `Employee` twice.
Your example has unusually terrible variable names. You probably just chose them quickly, but it comes across as fabricated. Regardless, you have a point. If the variable names were something like checkedOut, missing, etc, it still wouldn't be obvious what the types actually are. You could always go one step further and name variables like *missingBooks*, but something like *missing* is still likely to appear in real code.
In the recent 4 or 5 decades or so.... ya know.
Your "semantic type" does not say anything about the interface of the variable though, and that is arguably the most important property of a variable. auto collection_of_books = getBookCollection(); You want to know if the collection is a c array, a std::list, or something else, as it determines what the interface is. Your version of hungarian notation is really not any better than the microsoft version. Type names are for describing the interface and behavior of a variable, and names are for describing the contextual meaning. They are different, and shouldnt be mixed. Hungarian notation is poor mans types. The article you linked does nothing to save Hungarian notation. In his example he has unsafe strings and safe strings. Its a type differnce that matters to him, yet he stores the string with the same type. Doh! His type system is not rich enough. Instead of extending the type system with new types like he should, he does a poor mans type system by inventing a hungarian notation to tell them appart. Enforcing the type system is now a manually task for the programmer. This is ugly and error prone. Better use two different types (wrap string in different class for instance). That way you get the compiler to enforce the type system. 
Next time ill need to embed 30000th prime in my code ill be sure to use this.
Sure, but those typedefs should not exist that is the real problem with the code, not the use of auto. If you really write code like that, please stop.
From one of my C++ Data Structures lectures: Example of dynamic objects in C++ &gt;Consider this C++ function. The object created with new is dynamic and must be explicitly destroyed with delete. Other variables (i, j, x) are automatic. &gt;int foo(int i) { &gt;int j = i + 1; &gt;C* x; &gt;**x = new C()**; &gt;x-&gt;setA(j); &gt;j = x-&gt;getA(); &gt;delete x; &gt;return j; &gt;} Example of automatic objects in C++ &gt;Now consider this C++ function. &gt;Here x names an object, an instance of the class C (not a pointer!), created automatically on the stack, and initialized with the default constructor. It will automatically be destroyed when the function returns. Other variables (i,j) are also automatic. &gt;int foo(int i) { &gt;int j = i + 1; &gt;**C x**; &gt;x.setA(j); &gt;j = x.getA(); &gt;return j; &gt;} 
If you are writing a language it may come in useful.
Or even better, auto employee = getEmployee();
trees can be served with weak ptrs to the parent. Cycle done. i detect design crap here, utter spaghetti and abuse of subclassing...c++'s power is in generics and minimal use of 90's style object hierarchies.
[Part 1/3](http://www.csi-india.org/c/document_library/get_file?uuid=edad5987-a770-41ab-ab1f-5ad2d516ec87&amp;groupId=10616)
Where was this article 10 years ago when I needed it?
You mean this isn't the norm?
I had to write a Windows app once. I spared myself a lot of trouble by using Qt.
Check out /r/winprog made for posts exactly like this one.
Please elaborate.
Did this before. Way harder than you would imagine. Looking back, I cannot recommend it to anyone.
From the top of my mind: * *RegisterClass(Ex)* to register a window class (associates a WindowProc with some defaults, required for CreateWindow) * *CreateWindow(Ex)* to create the window(s) * a *WindowProc* to handle the messages sent to the window * a *Get-/Translate-/DispatchMessage* main message loop * *SendMessage* for doing most things wiht windows and controls * Dialog Boxes almost have their own API, CreateDialog(Indirect) to start. * Manifest + InitCommonControlsEx for a decent look * To associate data with a HWND (your "C++ window class"), the simple way is to register "extra window bytes" with the Window class, accessing them through GetWindowLog/SetWindowLong Happily, I have a few library routines to make this easier :)
You really want to get people to live life on the edge? Ask them to track and delete their own memory allocations. 
I really enjoyed reading Koening and Moo in Accelerated C++ some time ago, and I believe that it shows an interesting approach to teaching a language. That is why it surprises me that the most compelling reason for unified initializers may be the initialization of a temporary vector. More so, as it is presented as a dangerous construct that may produce an error in the logic of the program in the first code snippet only to state a few lines later that the potentially confusing line will not even compile! There are, to me, far more compelling reasons for the uniform initialization, that include container initialization (even if already resolved in libraries) but also the surprising most-vexing-parse ( T a( U() ); == function declaration, not definition of a variable a of type T initialized with a default constructed temporary of type U )
Agner's stuff is some of the best I've seen. Has anyone seen anything like it?
No, Agner's stuff is incredibly useful. I prefer it over Intel's own optimization manuals even.
/r/winprog appears to be dead
&gt;rather that if you want to really benefit from writing your own version Everyone wants to be like Google ;)
Spirit is nice and everything, but it leads to some function names (instantiated tempaltes) that are like a kilobyte long. 
In this case I would say that this is probably closer to platform/architecture-specific behavior (the different ways variadic arguments are implemented on the i386 and x86_64 Linux ABI). I think you should expect the same behavior when compiling for those platforms with other compilers. But it's a nice reminder, that undefined behavior does not necessarily require a different compiler (version) or optimization level to bite you.
Interesting article - I've never ventured much into boost's internals, as they get quite cryptic at some points, although it's interesting that sometimes me or someone in my team reaches the same methods they do.
A huge amount of scalability work has and is going on with postgres right now. The #1 bottleneck in postgres is the WALInsertLock, but some good theoretical solutions have been introduced and are in the coding/testing stages. Right now the dev team is microbenchmarking spinlock contention looking to get linear scaling to 80 cores and beyond. This is going to become increasingly important as the SSD revolution makes databases more cpu bound.
Does it talk about how if your code is complicated enough and has enough templates in it, Lint will just give up eventually and start making guesses?
At first glance it seems you need to terminate the string with a 0. So just above the break statement add something like lines[i][j] = 0;
For one thing, `if(lines[i][j] = '\'')` should be `if(lines[i][j] == '\'')`. Does your compiler not print a warning about this?
does 0 work? i know '\0' works
Yep, '\0' is just maps to the integer value of 0.
this was it. solved my whole program lol another question, maybe i should make a new thread but since you're already here, is it possible to make the lines array a dynamic array? so that it fits to any text file that it receives?
I just wanted to add that this type of mistake is why a lot of programmers place constants on the left when making comparisons. The following would not compile: if ('\'' = lines[i][j])
Use std::vector and std::string.
While this is a very useful trick, it is not "idiomatically correct" - i.e. It causes long-time c++ users to go WTF! when they see it. That doesn't mean I won't use it though ;)
it is well worth your time learning to use abstractions in c++, for strings char* are pretty much deprecated, use std:: string. It will 'manage' null termination and memory allocation. std::string line; std::ifstream file("text.txt", std::ifstream::in); while(file) { std::getline(file, line); for(size_t i=0; i&lt;line.size();i++) if(line[i]=='\'')line[i]='\n'; std::cout&lt;&lt;line&lt;&lt;std::endl; } this prints the file out with a \n where ' is found. Also stackoverflow is probably a better companion for help.
It's a habit I've picked up from working in a large legacy code base that did not have warnings enabled. Once I became accustom to it, it stopped being a readability issue for me, but that's a matter of personal opinion I suppose. In your situation, I would certainly understand not using it. : )
Absolutely - if you are writing C++, you may as well use its features which make your life easier.
One more suggestion: don't bother with &lt;= in for loops, just use &lt; 36 or &lt; 60. This way, when you say you have a vector of size n, your loop condition is &lt; n, instead of &lt;= n-1. It's just cleaner. Although I'm no C++ expert, and there's actually a better way to loop over vectors than just by indexing them.
what does the std:: mean? never seen that before i usually declare a bunch of stuff at the top of my program like using namespace std; #include&lt;iostream&gt; #include&lt;fstream&gt; #include&lt;cmath&gt; #include&lt;iomanip&gt; #include&lt;string&gt; also can you explain line by line how that code works?
do you mean high performance computing, like scientific computing?
Not using supercomputers or clusters. Fast algorithms / tricks for efficient computation.
std:: refers to the namespace, which bob needs to use because he omitted the line "using namespace std". That line acts as a shortcut for defining variable types in code, but can become troublesome when multiple namespaces contain the same class/type names.
http://agner.org/optimize/ 
Any extra temporaries on the std::map example has never been a problem. The return value optimization (on release builds), has always got rid of them. Find out more at: http://cpp-next.com/archive/2009/08/want-speed-pass-by-value/
[Elements of Programming](http://www.amazon.com/Elements-Programming-Alexander-Stepanov/dp/032163537X)
is twist said, instead of importing an entire namespace (which definitions, objects... are grouoped by) I am simply fully qualified each item. All the basic stuff you don't need to include in your code lives in std:: name clashes are rare, but when they happen it is a PITA to solve, further more it seems to considered best practice these days.
Also I can explain how it works. The includes are missing because it isn't a full code listing. You would need to #inlude the following for it to work &lt;string&gt; &lt;fstream&gt; &lt;iostream&gt;. Simply the while loop will run until there are no more lines in the file (when it get an EOF) or until it can't access the file for whatever reason.. getline does simply that, it take a line from the stream and assigns it to the string. I then loop through the chars of the string until i find the token i need, then i swap it out for a new line character. Then I simply print out the modified string and repeat
Well I'd say you're already writing in the right language, maybe use C++0x and learn how to use move constructors etc. Also, better algorithms can be bigger than micro optimizations. And then, cache-friendliness and the TLB play a big role: * [Numbers Everyone Should Know](http://surana.wordpress.com/2009/01/01/numbers-everyone-should-know/) * [What every programmer should know about memory](http://lwn.net/Articles/250967/) - Read it! Read all that's relevant to you, but don't stop it till you've at least skimmed the whole thing. * [EASTL](http://msinilo.pl/blog/?p=668) and friends; not reading, but a library; a rework of the STL. * If you do threaded programming, learn about lock-free algorithms. (I like Herlihy and Shavit's 'Art of Multiprocessor Programming'), also see /r/threads Edit: how far along are you? You should definitely learn the performance characteristics of the STL or in general, the diff. data structures. In general you have to learn it all, to know what matters when. Another edit: if you don't already know this, crank up your compiler settings, you can get speedups that way. But you'll have to read the documentation for it. 
Whenever anyone mentions EASTL, I remember my time working there. Ah, free trips to Vancouver...
Efficient computation of what? There's a world of difference between writing a fast web server and CPU-intensive image processing. First of all: Are you compute bound or IO-bound? If you don't know, then that's the first thing to figure out. But some general advice for performance sensitive bits: Use optimal algorithms for your problem. Profile to make sure you don't optimize things which aren't slow. Don't do system calls, don't allocate memory. Don't touch disk. Be mindful of memory access patterns, make sure your data fits in cache. 
http://kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.2011.05.30a.pdf looks like a good resource for concurrent programming.
Can someone give me an argument for EASTL over STL? I've looked into the design rationale and some of the code, and it honestly just looks like some lead designer at STL had a "not-invented-here" moment. I couldn't really spot any major speed improvement, though I admit I didn't look too deep.
Some people can take that 'don't allocate memory' thing a bit too far. I'd say a more subtle is to prefer the stack when you can, and if allocation is really a problem look into a faster allocator rather than doing static allocation work arounds.
It's mostly a drop-in replacement for the regular STL, except: * You know how it behaves on all target platforms (e.g. does std::vector.clear() change the capacity to zero as well as the size? The PS3 does it one way, the 360 does it the other way. But it matters for performance...) * Easier syntax for inserting your own allocator.
C++ for Game Programming by Noel Llopis is a pretty good start point (for beginners). Effective STL by Meyers is pretty good for STL performance Real Time Collision Detection is a superb all round book mainly focused on 3D math and physics (and related optimisations) but it has a significant amount of stuff relating to performance. Any book on Cuda is good because it really demonstrates some of the key aspects of true HPC. If you're thinking bank software then you'll really want to write your own TCP/IP stack in C/ Have a look at the SSE instruction set. 
Interesting -- I love the sqlite project, but I've always thought it's been dog slow for writing. The numbers they have been reporting are along with my own personal observations. Their own numbers seem rosy to the point of being impossible, it has to be said. 
The LevelDB fast path is append-only (even for random writes), which is why the numbers look so sweet, and AFAIK merges/compactions take place concurrently with further writes. The code makes a great read, everything has been designed for good concurrency, e.g. use of skip lists for memtable to allow lockless concurrent reads and updates. 
Your question as given is not answerable. There are many people here that could answer a specific question., otherwise people are stabbing at the dark. 
I wonder how much of a backlog was left to the compaction thread after the LevelDB benchmark finished. To be fair to other databases the LevelDB benchmark should wait until all the delayed work has been completed by the compaction thread. Otherwise this sounds like cheating (I.e., dump all the data in the fastest possible way to disk and shout "I am done", never mind that I need to go back and sort all that stuff out later). This reminds me of that VDT-XML joke. The author keeps showing much better performance numbers than other XML parsers while forgetting to mention that by "parsing" he means just finding token boundaries. When the application actually requests the data, there is a whole lot of additional processing that needs to happen which the author conveniently doesn't mention.
1. Tweak code in a random way. 2. Test code, if it runs faster, good for you! If not, goto step 1. That's all you really need to know.
I don't know if it's only on my box, but when they've showed the first code snip (07:30) the screen was really out of focus and it looked as if it was written: MyClass ^ptr0 = new MyClass; I thought MS lost their mind and started calling "Managed C++" Native. 
re sqlite - you are aware of the [write lock](http://web.utk.edu/~jplyon/sqlite/SQLite_optimization_FAQ.html#transaction-wrappers)? (Just checking, it's the first thing people seem to stumble over)
They are ^ indeed (you can compare to the * on the comment below). Interesting enough, he's using new, and not gcnew to instantiate the class.
no, they are * Wait until the camera focuses and you will see, after a minute the camera will lose focus again, and it will seem again that it's ^ but it's *.
Great eye sight sir. But why couldn't they just use the video feed from the screen, instead of filming it?
That's why they tested with various memory configurations. The benfhmarks show sustained throughput, I.e. performance even while compactions are occurring, which IMHO is the more useful metric for deciding how well the library might work for your design (unless perhaps you're writing some kind of command line tool that needs fast startup/shutdown)
Yes, iterators. And C++0x has for-each loop construct too.
I don't see what memory has to do with that. LevelDB appends "writes" to some kind of log and cleans them up in parallel/later. I didn't see in the benchmark's description any mention of the state of the database at the end of the benchmark. For all we know there could be a large amount of data left in the log that still needs cleaning up. Also, as someone mentioned on HN discussion, it would be more useful to see a benchmark that is a mix of writes and reads. In this case LevelDB might perform much worse becuse it has to consult both the actual database and the log. If the read performance degrades as the benchmark runs, then we know that the compaction thread cannot keep up and is leaving more and more work "for later".
ya -- I'm aware -- I've done a lot of serious programming with sqlite. I'm not really saying that it's slow, just slower than you'd expect it to be. 
This is due to Silverlight Smooth Streaming, which automatically adjusts quality based on detected bandwidth in real time... Download the video or just click on one of the download links and you'll see that it's actually screen capture, not filming the screen.
These questions are answered in the design documents in the source repository. Writes go into the "memtable", in addition to the log, which is a sorted skip list that can satisfy recent reads in O(log n). &gt; A log file (*.log) stores a sequence of recent updates. Each update is appended to the current log file. When the log file reaches a pre-determined size (approximately 4MB by default), it is converted to a sorted table (see below) and a new log file is created for future updates. &gt; A copy of the current log file is kept in an in-memory structure (the &lt;code&gt;memtable&lt;/code&gt;). This copy is consulted on every read so that read operations reflect all logged updates. So every 4mb of deletes/writes/updates, at least one large write occurs (or more if this triggers compaction). (edit: formatting. currently in a country renowned for their mobiles phones yet their 3G shits itself every 2 seconds. grr). Also, I originally thought memtable/log size was proportional to total configured memory, but seems its fixed at 4mb
[Google](http://www.google.com/#hl=en&amp;cp=6&amp;gs_id=r&amp;xhr=t&amp;q=c%2B%2B+odbc)
I've been using PostgreSQL with libpq, and it's fairly easy. Edit: 3 up votes and 2 down votes. What do you people have against PostgreSQL or libpq? It's free, open source, and fast. It has a C API that's a little clumsy but easy to wrap in C++ code. What more do you want?
If you don't have to use MS Access, then [SQLite](http://www.sqlite.org/quickstart.html) is a good alternative and is extremely simple to get started with. There are several third party apps to view and modify the data in the SQLite database, and even a [Firefox add-on](https://addons.mozilla.org/en-US/firefox/addon/sqlite-manager/) that lets you do this. SQLite is also completely free ([public domain](http://en.wikipedia.org/wiki/Public_Domain)).
ODB seems like a nice way to go: http://www.codesynthesis.com/products/odb/
Although I agree, and I did not downvote, the issue with languages like c++, php, java, and vb.net, is that you got so much shitty advice on google, that you're better off asking. Most of the Freenode C / CPP folks are stuckup and hard to communicate with. for example :"i need help with 'x'", the standard reply you'll get is a lmgtfy/x and READ THIS FUCKING BOOK THAT IS 20000 PAGES LONG TO FIGURE OUT THE SIMPLE TASK YOU NEED TO DO. Although I encourage and love self education. Some and Most people learn faster by "ordering" them 
Please take a look at http://soci.sourceforge.net/
I understand, but in cases like this, there is not one set answer, and simply asking on Reddit isn't going to provide one without further research - either via Google or a book. He is likely going to need Google regardless of the answer he gets here.
programmers.stackexchange.com could be a viable option
Qt has excelent api for SQL! 
I agree, but it's likely the question would get quickly closed and moved to SO, so I'd post at SO and save the time. :P
The traditional way to connect to an Access DB is to use ODBC, to connect to the Jet engine (which is what Access is based on). ODBC is well-documented on MSDN. But really, Microsoft seems to be trying to deprecate Access and JET, so I'd not bother with Access at all. Instead, I'd suggest using SQLite (which is Public Domain) or possibly SQL Server Express (which you can get for free).
If you don't mind venturing into the world of c++0x then this Sqlite wrapper has been my pet project recently, it's design aim is simplicity http://dobson156.dyndns.org/md.php?p=home$sqlitecpp$quickstart 
Wow, that looks easy, love it! :-) Exactly what parts of c++0x are you using under the hood there?
Thanks the specific 0x feature i used the most are + move semantic/RVO + variadic templates (for the prepared statments - I am writing the docs as we speak) + shared_ptr + unique_ptr + std::mutex + range based for loops i think and probably a lot more, it really is a different way of coding c++ I really love the new standard and have exploited it fully here. If you like it and need help feel free to get in touch There is also the git page for what isn't doc'ed
That's awesome! I really like what the the new standard adds to the language myself, and I'll definitely read through and try out your code! Thanks for sharing!
No Problem glad you like it, it is still a young project so if you have any ideas, or find any problems let me know; I'll put an email add on the site shortly.
Young project - sure, but I find it really awesome that there are actual useful project using C++0x, and displaying what can be done with the new standard. I mean, you could read the spec for days on end, but seeing actual code using the new features is (at least for me) much more valuable. BTW - have you considered putting this on github, because then it might be easier for others (myself included :-) ) to follow changes you make to the project and possibly contribute too. If you're against github then nevermind :-). You can setup public repos for free.
I will consider it, but I prefer the control/security I have over an internal git server/site. I will, when get change, try and pretty it up a bit with syntax highlighting. gitweb: http://dobson156.dyndns.org/gitweb/?p=libsqlitecpp.git If you want to track it has rss functionality. (oh if you want to contribute, contact me!)
Wt has a DBO layer as well that can be used freestanding of the base library.
Oh, sure - do what fits you best. I just don't like the hassle of maintaining my own repositories, and with github you could possibly get more exposure on Google as well (I'm not sure they index dyndns addresses at all). But nevermind, do what you find best.
I've been working 0x into a pet library of mine. So far I'm loving auto (especially for STL iterators) and lambda functions, but I haven't gone much deeper. Variadic templates sounds horrifying and wonderful. Anyway, any recommendations on where to get systematically up to speed with 0x?
The result of execute could return an input iterator to be more C++ friendly; you could also provide a .end() method to allow range-based for loops to work out of the box.
Other than just using it, wikipedia has one of the best unintentional "getting started" guides for the 0x standard. Documentation is a little thin on the ground for the new library features, but MSDN actually has quite a bit of it.
&gt;Anyway, any recommendations on where to get systematically up to speed with 0x? [Stroustrup's C++0x FAQ](http://www2.research.att.com/~bs/C++0xFAQ.html)
Now with more STL: std::ifstream file("text.txt"); std::istream_iterator&lt;char&gt; fbeg(file), fend; std::ostream_iterator&lt;char&gt; oitr(std::cout); std::replace_copy(fbeg, fend, oitr, '\'', '\n'); 
Having to embed values directly into query strings sounds like an awful way to do it, especially considering that SQLite supports parameter binding . See ODB for how this could (and, IMO, should) be done: http://www.codesynthesis.com/products/odb/doc/manual.xhtml#4
Well, its not at all what the OP asked for, that might be the reason.
Ah, fair enough. I didn't see the internal description, only the headline.
Hi, this is totally my intention although they would be functions (begin(), end()) of result_set as I do not want sqlitedb to be stateful, I just need to find a nice way to do it. For example, what would be returned by the dereferencing of said iterator, another iterator? A tuple (that wouldn't actually work as every attribute in each field can have a different type)? I think I am going to have to create a friend class iterator to do this effectively, which provides accessors but without the first index. something like: for(auto &amp;tuple: rs) std::cout&lt;&lt;"name: "&lt;&lt;tuple.string_at("name")&lt;&lt;'\n' &lt;&lt;"age: " &lt;&lt;tuple.int_at("age) &lt;&lt;std::endl; 
Hi, sqlitecpp does support prepared statements, the documentation is just not finished for it yet. It will be up in the next day or so. Watch this space syntax is basically/will be sqlite::prepared_stmt pstmt= sldb.prepare_stmt("SELECT * FROM test WHERE name= ? "); sqlite::result_set rs=pstmt.query_with("frank"); `execute` is a variadic template function and simply takes all the values in order. It takes advantage of sqlites weak typing as well so you can put in an of the support datatypes
I've been reading your link, it's fantastic. Thanks again.
Sometimes I think SQLite evolved beyond what it was originally conceived for. In other words should you really expect that a light weight SQL database, that is app embeddable, will be fast? Beyond that I'm not sure of the value in comparing key/value stores with SQLite. It's a bit like Apples and Oranges. 
Database behind STL interface ... it seems a bit dead though. http://dtemplatelib.sourceforge.net/
That's exactly what it is ... some engineers got the bright idea they could do a better implementation than teams of full time computer scientists. They would have been better off writing extensions to STL, in the spirit of boost. Why break the interface of something that has been standardized? Furthermore I'd like to see independent and fair benchmarks. Their own where cheating by comparing EASTL non checked iterators against VC checked iterators. Its already 5 years old ... I bet its badly out of date when it comes to TR1 and C++0x. With C++0x all STL containers use move semantics. There is no way EASTL would win a fair benchmark today.
If you don't know what to do with your life ;) Otherwise it may be smart to build upon other people experiences.
you can mix release and debug libs, you'll just get compile warnings
That's not how you call a pointer to a member function. C++ provides the (.\*) and (-&gt;\*) operators specifically for this purpose. Pointer-to-member-functions are different because they require an *object* to be called on. If you call a.Foo(), a is the object that you're calling the function on - inside Foo(), it becomes the "this" pointer. Similarly, if you're calling a pointer-to-member-function, you need to supply an object. So calling such a pointer looks like this: (myObject.*SelectedCondition)(num); Or if myObject is a pointer: (myObject-&gt;*SelectedCondition)(num); Note that this doesn't apply to *static* member functions - they behave just like normal functions so you take normal function pointers to those.
In this case he's trying to call the member function from within the class instance itself, so he'd need to use the 'this' pointer instead of "myObject".
Also, this is almost exactly the type of question [Stackoverflow](http://StackOverflow.com) was [made for](http://stackoverflow.com/search?q=pointer+to+member+function).
Ah, yes, I missed that.
Still a spot on, concise explanation though. I was disappointed to see that you had it totally covered.
thanks a lot for your explanation, I did not know that, I thought there shouldn't be any difference with respect to regular pointers to functions.
TIL.
I'd highly recommend Boost::bind for dealing with function pointers, far more flexible than the default method.
God... I hate how people use downvotes. I have upvoted to help make up for the ignorance of others. Anyway, I haven't really used boost, but I have no problem with the way function pointers work in C++. In fact I'm quite fond of them as a tool. Would you mind explaining how boost improves over normal function pointers?
There's a couple of good sites about using bind at http://boosttrip.wordpress.com/2011/02/28/boostbind/ and http://blog.orionedwards.com/2006/09/function-pointers-in-cc-and-boostbind.html. It has a couple of nice benefits - it standardizes the syntax between the various types of function pointers (pointers to member functions vs pointers to free functions), plus it allows on the fly remapping of arguments - you can, for example, use a function as part of an event callback that has different arguments than the callback is expecting, bind will present the interface the callback is expecting then remap the arguments to the format the function is expecting when the callback is executed. For day to day stuff it might be a bit overkill, but it's at its best when you pair it with other boost libraries - for example, I've been doing some event-based async IO stuff lately using boost::asio and boost::signals2.
Known as "Yoda conditionals".
What book are you learning from? Most books I have read on this subject have done poorly at explaining it. I think C++ Primer Plus is the one book where I finally really understood pointers to functions. 
&gt; [...] I thought there shouldn't be any difference with respect to regular pointers to functions. Pointers to member functions are actually quite different from pointers to functions. Not only do they need an object to be invoked on, but they also perform virtual dispatch if they point to a virtual method, so invoking the same pointer to member function with different objects may actually call different virtual overrides. There's an [interesting article](http://www.codeproject.com/KB/cpp/FastDelegate.aspx) about the technical aspects of the implementations of pointers-to-member-functions.
C++ Footprint and Performance Optimization by R. Alexander, G. Bensley * noob friendly, good for basics * no advanced stuff (sse/cuda, expression templates) * old (2000) Technical Report on C++ Performance ISO/IEC TR 18015:2006(E) * rather a reference than a readable book 
Scott Meyers Edit: when introducing 'C++ legend' at least don't misspell his name ...
So... Pointers are handled differently by 32bit and 64bit machines? Hardly a surprise, yet an upvote for you since more people need to be aware of that.
Do you need any atomicity guarantees, like e.g. no file corruption in case of a software or hardware failure during the update ? In that case write the new contents to a temporary file, remove the old file and rename the updated file. And if you are allowed to change the file format: use a database library like SQLite.
Thanks, i'll give that method a go. I'm not too worried about file corruptions or anything of that sort.
There is no such thing as insertion when doing ios on a file system (not that I know of at least). You could do this instead: -read the file in memory (RAM), if its not too big, inserting the data in the process (read the file until the desired point, write the new date, then read the rest) -write the contents to the file. Another thing that may be relevant is to use a xml file to store the data, that way you just have to insert wherever you want, the data can be sorted later when parsed (with xslt for example).
Finding the insertion point will require log2(N) comparisons in a sorted list at worst case. If you are not concerned about an I/O bottle neck then you could perform a binary search in the original file to find the insertion point, after which atomically replace the file with the newly created file containing the insertion. The std::sort algorithm requires the less than operator on your types. This is really quick and dirty STL foo, but I hope it might help you: struct mydate_t { unsigned char day; unsigned char month; unsigned short year; mydate_t() : day(0), month(0), year(0) {} mydate_t(const unsigned char&amp;d, const unsigned char&amp; m, const unsigned short&amp; y) : day(d), month(m), year(y) {} // for sorting bool operator &lt; (const mydate_t&amp; rhs) const { if (year &lt; rhs.year || (year == rhs.year &amp;&amp; month &lt; rhs.month) || (year == rhs.year &amp;&amp; month == rhs.month &amp;&amp; day &lt; rhs.day)) { return true; } return false; } // for finding bool operator == (const mydate_t&amp; rhs) { return (year == rhs.year &amp;&amp; month == rhs.month &amp;&amp; day == rhs.day); } }; std::istream&amp; operator &gt;&gt; (std::istream&amp; is, const mydate_t&amp; rhs) { is.read((char*)&amp;rhs, sizeof(rhs)); return is; } std::ostream&amp; operator &lt;&lt; (std::ostream&amp; os, const mydate_t&amp; rhs) { os.write((const char*)&amp;rhs, sizeof(rhs)); return os; } ... std::vector&lt;mydate_t&gt; mydates; // read some from a file std::ifstream inf; // open the file mydates.push_back(*std::istream_iterator&lt;mydate_t&gt;(inf)); inf.close(); //insert some std::sort(mydates.begin(), mydates.end()); // write to a file std::ofstream ouf; std::ostream_iterator&lt;mydate_t&gt; ous(ouf); std::copy(mydates.begin(), mydates.end(), ous); ouf.close(); 
Protip: [ISO 8601](http://en.wikipedia.org/wiki/ISO_8601) regarding proper, internationalized representation of dates in digital formats. Generally: YYYY-MM-DD(THH:MMZ) (T and Z are literal, T is a separator, Z is an indicator)
That's kind of tough. Normally, you use a reference table at the end. That way, you read in the ref table, write the new line at the end of the file as if it didn't have a ref table (where the ref table used to be), and then output the updated ref table. Or just append the new date along with a new ref table and a link to the old table. A little bit more parsing, but a lot faster. You might also try reading from the end of the file and writing it back a little further down (by the amount that your new date will take). I don't know if this is possible though. I haven't actually ever tried this, but it should be doable. You would work your way backward and stop when you get to the point where you want to insert your date. 
Interesting. Under that standard, it seems impossible to go from P1M to P[n]D, since you don't know which month is being referenced in P1M. How do you resolve this issue?
This is exactly why I much prefer epoch, although I am sure there is a sensible answer to the question you poise, comparing an interger value is trivial, as is adding and taking form it
I never actually used that part of the standard, but I imagine the conversion would only be applicable if you did know where the interval would be, since otherwise the conversion would be ambiguous. It *is* possible to go from one to the other, just as long as you have the month in mind. Time intervals (the section below duration) also includes a start and end point, so that would probably be a more flexible format for conversions.
Well, the options of what you can accomplish with C++ are limited only by what you can think of. But even with a basic understanding of C++ you can do a lot. I, as an example, made a basic game using SDL and C++ after about 3 weeks of learning C++ and SDL alongside each other. And yes, I totally just answered a 9 day old question. Sue me.
You can build anything. C++ falls into the category of universal languages. C++ generally isn't suitable for: * fast prototypes (*although fast prototyping in Qt is more then good*) * websites (*although using C++ for CGI is quite possible and simple*) 
In general, C++ is good for heavy lifting behind the scenes type of stuff. It is used extensively in the gaming industry, and in the financial industry for electronic trading and transaction processing. Aside from maybe C#, its also the best language to build desktop applications, though there seems to be little interest in doing that these days. I think it can also be used with C for system programming as well, though Linus would disagree. 
tl;dr: dont use them, or use just 'throw()' Also, this article is soooo old. Also, new standard (C++0x) apparently introduces another exception specification (noexcept) which, apparently, still doesn't let compiler assume the function does not throw. 
It's a shame that the exception specification turned out to be so problematic/useless. It was well intentioned, but poorly implemented.
Haha thanks for the answer. Don't worry about it being old, I think it actually got caught in the spam filter and only now is showing up so I'm glad to get some answers!
If only I could get this thing to build on Windows without installing a crapload of tools from Chromium...
And here are the performance numbers of Postgres compiled with GCC and Clang (from the same blog): http://pgeoghegan.blogspot.com/2011/07/could-clang-displace-gcc-generally-part.html
Square pegs into round holes. If he wants to use c so badly, he should use c.
I don't have a copy of MSVS on this machine, but gcc's vector does not normally use a for loop to initialize a vector. It uses std::uninitialized_copy, which uses memmove for PoD types. It only uses a for loop to init vectors of non-PoD types, or for vectors using nonstandard allocators. I would be *very* surprised if MSVS's implementation did not also behave this way. [Source](http://gcc.gnu.org/onlinedocs/libstdc++/libstdc++-html-USERS-4.1/stl__vector_8h-source.html) for gcc's vector. Line 296 begins the range-based constructor. It routes through \_M_initialize_dispatch. Eventually, \_M_range_initialize is called, which starts on line 1022, which calls std::__uninitialized_copy_a. [Source](http://gcc.gnu.org/onlinedocs/libstdc++/libstdc++-html-USERS-4.1/stl__uninitialized_8h-source.html) for std::__uninitialized_copy_a. Line 230 begins the for loop version and even has a doxygen comment about when it is used. Line 248 begins the PoD version. This author should not be speaking with such authority on this matter, which is surprising, considering what he's built.
C would be overkill just to solve this problem. 
He could write 3 simple functions over a vector to get what he wants. 
&gt; a simple class for encapsulating the memory management of a raw memory buffer &gt; providing a few common operations, such as memcpy, memset, etc. "A valarray object is designed to hold an array of elements, and easily perform mathematical operations on them." "std::fill -- Fill range with value" "std::copy -- Copy range of elements" etc.
Yes, you are right. I saw the first version which looks like this: template&lt;typename _InputIterator&gt; void _M_range_initialize(_InputIterator __first, _InputIterator __last, std::input_iterator_tag) { for (; __first != __last; ++__first) push_back(*__first); } And didn't realize that there is an overload for forward iterators. I updated the article. Thanks for pointing this out. I double checked MSVC 10 and I still believe it uses a for-loop.
Maybe I'm missing something here, but I don't get it "what is the need here"? Admittedly I'm not a hardcore C++ programmer but isn't it a bit of a failure to be resorting to memory buffers in C++? At least in my case i see structure in any thing called data, if it isn't structured in some manner then it is most likely a stream of characters. I'm certain C++ programmers with more experience could argue one way or the other but me I just don't get it. Seems lazy to me. 
Note however, that compiler may not be smart enough to substitute std::copy with memcpy (for lets say T=char), as the former is _very_ specific about what it does. Last time i checked VC2010 did exactly that - it optimized away std::copy on 2 char arrays to memmove instead. It mostly doesn't matter, but there could be cases where it does. 
Nice little article! I don't agree with the viewpoint expressed about teaching though. Constructors and destructors go together like addition and subtraction. It is rather foolish to address one but not the other. 
Buffers are used as (intermideate) storage for data for which structure is not (yet) know or if the data is incomplete. One example would be receiving some data from a socket which can be incomplete (need to receive more) and/or of unknown structure (for example, a proxy forwarding data). It is possible that after the complete messsage has been read into the buffer, it will be converted ("extracted") into a class or struct for further manipulation. Another example would be reading a BLOB from the database. The BLOB can, for example, store an image which your application has to send to the client (i.e., write the buffer to a socket). 
Note, how having move-ctor enables you to (duh) move your object, but then it also requires from you to handle 'invalid' or 'empty' state of your object in the destructor. This is easy to deal with when the resource is memory, but when its not easy to determine from the handle itself whether to free the resource, you are forced to clutter your code with some workarounds. 
Static analyzers are nice but much nicer when free. I don't blame someone for trying to sell their product, I just think the alternatives are of high value. Here I'm talking about CLang and it's static analyzer project. 
I rechecked (a third time) the VC++ 10 implementation and it appears I was wrong -- it does seem to have the POD optimization. So I stand corrected on both counts.
I often feel like "New in C++0x: Boost."
This isn't true - the C++ string class can contain null bytes anywhere in its buffer and the member functions (string::copy(), string::find(), etc) will still work. Of course C library functions like strlen on string::c_str() will use the null byte as the end marker. 
Woah, didn't know this, thanks.
PVS-Studio vs Clang - http://software.intel.com/en-us/blogs/2011/08/08/pvs-studio-vs-clang/
And [Free license for the PVS-Studio for developers of free open-source software ](http://www.viva64.com/en/b/page-2/).
Yes, except for the tersness of interface and efficiency.
&gt; Note however, that compiler may not be smart enough to substitute std::copy with memcpy (for lets say T=char), as the former is very specific about what it does. Valid objection, but then it's a compiler problem. Even then, it would be trivial to fix it with a template specialization.
&gt;Valid objection, but then it's a compiler problem. Your compiler problems are your problems too ;)
Thanks a ton! direct link below http://www.viva64.com/en/b/0092/
The interface issue is debatable, but i do not see any efficiency problem.
* Inability to allocate an uninitialized buffer. * Depending on quality of implementation, initialization of the buffer may be sub-optimal. Don't want to sound rude, but did you actually read the article? The inefficiencies are covered there in detail. 
An uninitialized vector can be allocated in two ways: * using the function vector::capacity to allocate storage for enough elements. The newly allocated positions would be uninitialized. * using an std::allocator derivative class with an empty construct function. If the above is done, then optimal initialization of the buffer is trivial to implement.
Very interesting considering I'm reading it on my iPhone at the minute. Normally the tiny print would have had me loosing interest. In any event what I was trying to get at here is that I really believe that static analyzers should be part of any modern development system. The idea that a static analyzer should be a cost add on doesn't fly with me. Certainly not in the case of Visual Studio which is already an expensive proposition. I'm not dismissing the value of what PVS is offering just that I consider a static analyzer to be as much a part of a modern IDE as the compiler or the fancy syntax highlighting editor. 
How I miss my printed DDJ...
Also true, but it does impact who has the responsibility. If your compiler is not doing its job of optimizing well enough, you need to either use a different compiler, to patch the compiler, or at the very least report a bug to the compiler makers. You should not design your code around compiler bugs. Simple workarounds, like the template specialization I suggested, is the maximum effort anyone should make to that end. :)
 rcode = foo(); if (rcode) { printf("Error: rcode=%s: oh, fuck, I probably won't actually test this," " and my code reviewer will miss it and it'll just crash" " instead of doing something useful\n", rcode); }
You cannot used the capacity() function in std::vector to allocate anything -- it is an accessor. Perhaps you meant reserve()? The short answer is no, you cannot use reserve() to create an uninitialized buffer. For a long answer, see the comment in the article (someone already made that suggestion and I explained why it won't work there) . Regarding std::allocator and empty construct() function, yes you can provide a no-op implementation but then your allocator won't meet the requirements of the standard (table 32 in clause 20.1.5) and using such an allocator with std::vector will be undefined behavior. In practical terms, a lot of the functions (e.g., assign(), insert()) and constructors (range c-tor, copy-ctor) will stop working since they won't be able to copy data into the vector elements. Hell, even resizing the vector won't work since it won't be able to copy old data to the new memory block. 
How does the clang static analyser hold up to the ones he mentioned? 
I would also like to know this if anyone has tried *both*
I suppose I should clarify that I have just gained the opportunity to use clang's static analyser tool, and that I have not used, and am unable to use any of the solutions Carmack had spoken about as I am on linux. 
If I understand you correctly, `output` is an array of `fftw_complex`? If that's the case, it decays to a pointer, so you can just do std::complex&lt;double&gt; *xthat; xthat = reinterpret_cast&lt;std::complex&lt;double&gt; *&gt;(output);
&gt; Perhaps you meant reserve()? Indeed. &gt; The short answer is no, you cannot use reserve() to create an uninitialized buffer. You can do so, provided that you don't care about iterators and size(). The guy wants to use std::vector&lt;char&gt; as a buffer for any type, so he clearly violates some well-established C++ principles. Violating some more won't hurt. &gt; but then your allocator won't meet the requirements of the standard (table 32 in clause 20.1.5) The guy needs a char buffer, so constructing each char in the buffer is meaningless. &gt; In practical terms, a lot of the functions (e.g., assign(), insert()) and constructors (range c-tor, copy-ctor) will stop working since they won't be able to copy data into the vector elements. Hell, even resizing the vector won't work since it won't be able to copy old data to the new memory block. He can always use reserve() and make a few wrapper convenience functions. 
there's also cppcheck which is pretty cool for being free: http://sourceforge.net/apps/mediawiki/cppcheck/index.php?title=Main_Page
I think that cppcheck is not "production" tool. What's about integration to Visual Studio, documentation, support?
Free for what? **If it is commercial the project.** Then fast support is necessary to you. Realization of wishes is necessary to you. It is necessary for you, that errors were quickly fixed. It it is necessary to pay for this. **If your project is free and open source or you the student.** Then - http://www.viva64.com/en/b/0092/ 
I really expect more from DDJ, especially someone who is billed as a "Guru Blogger"... Type-safety over printf arguments is a nice and useful feature, but is hardly blog worthy. `execl` is documented to require a terminating NULL (SLES-11 and Ubuntu 11.4 man page): &gt; The list of arguments must be terminated by a NULL pointer, and, since these are variadic functions, this pointer must be cast (char *) NULL. The fact that the author of the post has written code in the past that works without passing the NULL is a fortunate accident, and GCC warning him about his mistake is valid and correct. It has very little to do with type safety. I can understand why the warning was confusing to the students, though a simple `man execl` would have cleared it up (and been an excellent way for the instructor to teach the students how to fend for themselves). 
Sure, you can beat std::vector&lt;char&gt; into behaving like a buffer by keeping the buffer size somewhere else, providing a custom allocator which vilolates the standard requirements, and adding a few "convenience" functions to hide all the cracks. The questions is, why would you want to? Is this an argument for the sake of argument or do you trully believe that someone should really use the bastardized buffer you just described? 
I've used CPPCheck on a commercial project and it found real bugs. I guess I should revert those changes because I didn't have a support agreement for it though. Seriously, a static code analysis tool isn't some sort of mission critical piece of software that will make you miss your deadline. It's a nice-to-have tool in which the real value in paying for one is that you get a much better tool rather than the support agreement that comes with it. Running a free one over your software isn't going to hurt anything.
This might work but you have to make sure that if you have an array of complex&lt;T&gt; they are created using the **same** allocator that FFTW uses, which is **not** standard (it uses a specific way to make sure the alignment is the way it likes). I did it myself a while ago by creating a standard STL allocator (which is pretty simple) that calls the FFTW functions.
Yes, that would be ideal. I assumed he wasn't using `fftw_malloc()`, just plain `new`.
They have a weekly letter and a monthly PDF version. Often with plenty of C/C++ coverage.
Trying to downplay another product will earn you negative karma. Mention the merits of your software. But please don't advertise your company's suport etc.
Carmack seems to prefer tools which report more issues. I don't think this is a useful metric.
But how will you realize your wishes?! I have no idea what that actually means. But it sure sounds important.
He also mentioned Coverity and their $50k price tag. I was contacted by a salesman from Coverity and instantly added them to my blacklist because of the tactics of the guy. I hadn't found PVS-Studio yet but I think I'm going to give them a try. Looks like it is €3500 and can be used by 5 developers. I'm also going to give Microsoft Analyze a spin, but it looks like it would be significantly more because our developers are using Visual Studio Pro and they would need to upgrade to Premium. I haven't used Gimpel's product since the mid-90's and I wonder if it is still competitive?
&gt; I was contacted by a salesman from Coverity and instantly added them to my blacklist because of the tactics of the guy. What happened? Under handed bribery attempt?
He had a very aggressive tone and used tactics typically associated with used car sales people. He pretty much opened with "I just wanted to warn you that we are selling licenses to all of your competitors and I just wanted to give you a heads up and give you the same opportunity". My response was: "I'm not interested right now and if that changes, I'll contact you. Please remove us from your mailing list". He persisted and I just replied with another request to not be contacted again. I also mentioned that they should put their prices on their website to avoid people wasting time playing with software they will never buy.
I think his reasoning is that if the code is confusing or looks suspicious to the static analyzer, then it might be confusing to other developers and perhaps should be refactored.
clang --analyze is nice (I use it daily, albeit for C99 code), but I don't think it compares (yet) to other static analysis tools. It mostly just tells me about things that GCC &amp; co would warn me about as well.
Their content is still great. My print subscription was turned into a digital one back when they made the change. I miss the excitement of finding my DDJ on the mailbox, the ads, the letters, reading a mag like it was in the old days. I miss that, not the content - their digital content is still king.
[PVS-Studio vs Clang](http://www.viva64.com/en/b/0108/)
PVS-Studio more affordable - http://www.viva64.com/en/order/ :-)
Well, Lint is available for you, for free. Just install "splint".
Beer-free as long as your time doesn't count. Stallman-free because... OTHERWISE EVIL. Both types of "free" still can work to your advantage. However, if you don't enjoy maintaining the glue and plaster scripts that grow around them or would rather spent those resources on something *productive*, approach with care.
Splint does not handle C++ code. 
I am going to give it a try sometime this year. I just don't have the time right now to take on another task.
What do you mean by "production tool"? Yes, it seem to lack documentation or support or integration into your favourite IDE. But that doesn't mean it can't be used in production or isn't useful. You can still use it and find bugs. Static analysis can't proof the correctness of your application or the absence of bugs. Maybe different tools have better integration or support or can detect different "bugs". But that doesn't mean that cppcheck is useless or not a "production" tool. And it's great to have a free alternative. Commercial static analysis tools usually cost a shitload of money and sadly a lot of budgets/managers don't allow the purchase of one. So better use a free alternative than nothing.
Funny then that some larger scale websites are trying to convert to C++ from PHP now. And yes, I'd consider C++ to be one of the default languages to learn. It's very easy to learn new languages from having C++ knowledge, and it just executes programs so damn fast.
I wasn't involved in the Sales side, but I did use Coverity briefly at my old job, and did deal with one of their trainers. Overall I was impressed with the tool and the level of support they gave. My new job is using Parasoft C++ Test and it seems to be much more difficult to use, but that may just be our convoluted build process. 
It depends. If you don't have requirements such as traversing the buffer using iterators, if your buffer is not to be resized, then I don't see why not. On the other hand, if you need a fully STL-compliant character buffer, then using std::vector&lt;char&gt; is the way to go. The issues mentioned on the article are non-issues to me. There is no guarantee any std::buffer implementation would use memcpy, for example, or that memcpy is more optimized than the for loop. The other things are not worth to discuss. 
You should never ever use reinterpret_cast. Casts are bad, as it means fighting the type system. Just create a simple (conversion) function that takes a std::complex and returns a fftw_complex, and vice versa. fftw_complex tmp = fft(std_complex2fftw_complex(x)) std::complex y = fftw_complex2std_complex(tmp); if the conversion costs worry you. You should find a way to only work with one complex type. Say by storing fftw_complex instead of std::complex.
But that's rather close to the pessimistic view of static analysis: most of its effects are simply the result of forcing developers to spend more time with the source code. Most tools do not flag code that they cannot analyze properly. (Without a separate spec, this is true most of the time anyway.) On the other hand, if you have got a product to ship or a product that's actually shipped and successful beyond surprise, you don't want to clean up all questionable code, but concentrate on fixes that matter most to your customers.
Thanks for the help. I realized that it doesn't really speed up the time anyhow. I need to instead implement some parallelization. 
Hurrah?
Not really. They took down the last draft from their web site as soon as the standardization process was near conclusion. It means that the definite document on C++0X is inaccessible to the general public for several months, and it will probably take a year or more until you can buy a version of the text for less than 50¢ per page.
The FDIS was online long enough to archive, it's not really hard to find.
Is this [latest](http://www.mediafire.com/?zxr5z6fovdl77ff) enough?
too bad the MS version is so expensive ... no way I could get the company i work for to pay for it.
I like the name C++0xB
Or C++0xC for extra confusion points if the ISO publishing process takes longer than expected. :)
Yes. I've been very happy with this. C++ has become a lot of fun to program in. 
Very good news! The sad part is reading some of the comments in the thread on Sutters site. I just don't understand some of the negative comments. 
What're you trying to write a compiler or something? Why would you really need this; there are surely much better resources to learn the new features.
&gt;there are surely much better resources to learn the new features. But the source is only one. Its also fun to read ;)
Can someone give me some info on using this "Microsoft Analyze"? Is he talking about the [/analyze](http://msdn.microsoft.com/en-us/library/ms173498%28v=vs.80%29.aspx) switch? How come 360 devs get it for free?
John Carmack 2011 Keynote Annotated: Part 1. http://bit.ly/mSd44z Part 2. http://bit.ly/qj03fb Part 3. http://bit.ly/ovMBOm
&gt;Funny then that some larger scale websites are trying to convert to C++ from PHP now. If you mean Facebook then its not what they do. They keep on using PHP for their development, its just that it gets compiled to C++ and then native binaries.
Haters gonna hate.
I'm assuming you're using FFTW 3+, but the type conversions aren't really different for 2.1.5 (in 2.1.5 fftw_complex is a struct, while it is a typedef for an array of two doubles in 3.3, the memory layout is the same in either case). Following [FFTW's own documentation](http://www.fftw.org/fftw3_doc/Complex-numbers.html), reinterpret_cast is the way to go, contrary to what smargas told you. So, assuming your in/out arrays are different. and you're executing a 1D complex to complex DFT (I'm not sure what parameters you're using to create your plan, but this is the general gist. Also I haven't tested this...): int n = /* Your complex transform size here. */; // You may want to use fftw_malloc() here to ensure correct alignment // so FFTW can use available SIMD optimizations, if you care. // Also this would work for plain arrays of doubles: double *in = new double[n*2]; std::complex&lt;double&gt; *in = new std::complex&lt;double&gt;[n]; std::complex&lt;double&gt; *out = new std::complex&lt;double&gt;[n]; fftw_plan plan = fftw_plan_dft_1d( n, reinterpret_cast&lt;fftw_complex*&gt;(in), reinterpret_cast&lt;fftw_complex*&gt;(out), FFTW_FORWARD, flags // Your flags here. ); // Fill your input array and use your plan, etc... Using reinterpret_cast when interfacing with third-party C libraries is not wrong, it's often necessary. Just remember to keep it contained and try to understand what you're doing. Using fftw_malloc() and fftw_free() is highly recommended. Depending on where you're doing your memory management, [nova77's recommendation](http://www.reddit.com/r/cpp/comments/jfk9q/is_there_a_quick_way_to_convert_fftw_complex_to_a/c2bqb0p) of writing a custom allocator may be something to look into. In any case, if you do use the FFTW memory allocation and end up with more than one call to fftw_malloc() or fftw_free(), you probably want to wrap things up (encapsulate) better. Let us know if this helps.
I guess but it does make them look stupid. To be perfectly frankni don't spend a lot of time programming with C++. However the little bit that I've done tells me this is a major update. 
Uh... I'd certainly credit this as a programming joke, but ++ was an interator long before C++
Ah, hmm, fair enough. I wonder whether the language and its role as a step up from C is more widely known, or if the ++ operator itself and its role is more widely known. I would *guess* that the language name and relation to C is more widely known, but who knows. You may be right.
We're both casting about here with guesses, here's my experience that leads me to think it's more likely to be the iterator than the language: I'm a double bachelor in CS and Business Information Systems. As you'd expect, everyone on the CS side knows about C++ by graduation, but a (slim) majority of them don't hear about it until they take the class on it in junior year. The business side on the other hand never hear about it formally at all. Conversely, both programs teach about the iterator in the first term of Java, which's freshman year. I also know there are programs at other schools that teach the iterator (as it's in almost every language I can think of), but never touch C++ at all
My empirical experience tells me that the lay-person is more likely to know that C++ is a programming language but know nothing of the meaning of '++'.
I think ++ was first used outside of programming, in Orwell's 1984. To say "double-plus something" was to say "something even more", e.g. "doubleplusgood" == "much better". So I don't think the TV show host knew anything about C++, but they had their literary history covered. See http://en.wikipedia.org/wiki/Newspeak.
He didn't say "double plus" though, he said "plus plus", and was referring to Perry as the new Bush after having listed the ways that they're similar. I don't think "much better" works in the context of that segment at all.
You're probably right, I didn't see the segment. But it's not "much better" as such, rather it's "much more Bush[-like]". For what it's worth.
good shit
The bulk of what's proposed in the article can be done just fine in a library and I would argue that the complexity added to the language is not outweighed by any supposed benefits.
This is great. Thanks!
&gt; I would argue that the complexity added to the language is not outweighed by any supposed benefits. Did you forget what subreddit you were posting to? 'Cause you just blew my irony-meter.
The comment that sold me on static code analysers: "I've really gotten behind the static code analysis... even when it's wrong, even when you've got something and you can prove and you can say 'no, it's guaranteed to be ok because of these interrelated things here' that's actually a good time to step back and say 'you know, if you had to explain that to me, maybe you should change the way the code is working'. If the analyser can't figure it out, other programmers probably won't immediately figure it out, and it will cause problems.
I am not sure I can take advice from someone on process who still calls version control "SVN". That smells like an outdated toolset.
also you can remove the loop from your code by using the little used get line delimited variant. std::string line; std::ifstream file("text.txt", std::ifstream::in); while(file) { std::getline(file, line,'\''); std::cout&lt;&lt;line&lt;&lt;std::endl; }
Another C++ version: * http://pastebin.com/rfnqHM1G One might argue however that if your code is doing this, then you're doing multi-threading wrong in the first place. Conceptually, I think ideas like AXUM are the right way, where you avoid concurrent access to the same memory completely. * AXUM: &lt;http://en.wikipedia.org/wiki/Axum_(programming_language)&gt; Having said that, it's about time that C++ had constructor forwarding. Also +1 for your username. 
Thanks.. You forgot the C++0x version in your pastebin. Here it is class A { private: A(const A &amp;a, const std::lock_guard&lt;std::mutex&gt; &amp;) : i(a.i), i_squared(a.i_squared) {} public: A(const A &amp;a) : A(a, std::lock_guard&lt;std::mutex&gt;(a.mtx)) {} ... }; Personally I think avoiding sharing is no solution ... what is that saying again? "*There are pure languages, and then there are useful languages.*"
I'm not trying to be a jerk here, but I want to say "Yeah, what's your point?"
I can think of a few scenarios where getting the wrong value in an array with an inherited class would be sort of troublesome.
I will be very honest. I don't remember when I last used array instead of an std::vector. With initializer lists in c++0x, there is even lesser reason to use array. Unless somehow std::vector is not performant enough somehow. (I can't imagine any.)
You're right, that does suck, but to someone who knows and understands C++, thats an intended conseqence of the language and its not a bug. An array of 6 X instances is a pointer to a spot in memory that stores exactly 6 X instances contiguously. It would be your fault as a programmer for using an array of Foo when what you really intended was an array of Foo* or an array of std::shared_ptr&lt;Foo&gt; To me, its sorta like if I posted this code: void print_element(int af[]){ cout &lt;&lt; af[10] &lt;&lt; endl; } with the headline "Indexing rules: af had better have 10 elements!" It would be a no brainer
&gt; Unless somehow std::vector is not performant enough somehow. (I can't imagine any.) It's rare, but it happens. For a concrete example, I was writing an algorithm to predict traffic levels in transportation networks. Basically a medium sized graph (~10k nodes, ~40k edges) with "flow" specified between subset of the nodes and some other complicating factors making numerical approximation necessary. The particulars of the algorithm required a DAG over a subset of the network's edges to be stored in topological order for every origin node, with data associated with every edge still present. Essentially, I needed two thousand DAGS, each DAG with ten thousand nodes, each node with between zero and maybe five edges, each edge with a pointer and a double. A vector on my arch has an overhead of 24 bytes. If all of my twenty million nodes gets a vector for its out-edges I'm spending nearly 500 megs on useless crap that my CPU has to wade through several times every iteration. Replacing the vector with a pointer and an int cuts that data requirement in half on my arch at the (acceptable) loss of amortised constant-time insert. Smarter data structures and encodings save me more again. (Vectors are obviously a great first-choice for just about everything. This post was only made to provide an example of how vectors can be too heaviweight in specific circumstances. I'm not trying to make wide-reaching statements about them or start an argument about performance and premature optimisation.)
Appreciate the effort, and kudos for trying to increase the awareness, but an array of Foos is not an array of Bars. If you tell it "here is an array of Foos", well by golly, it's going to take your word for it &amp; walk through it like it's an array of Foos. The issues here are pointer arithmetic, the whole "arrays are pointers" thing (no, they're not!), and kind-of-but-not-really object slicing. Normally slicing (in my experience) refers to the derived part of the object being dropped during a copy; here there isn't a copy being performed but the extended part of the derived class is being treated as though it's not there. In effect, by saying "this is a Foo" instead of "this is a Bar" (notice I didn't say "a pointer to" or "a reference to"), you've sliced off everything past the base class. I guess if I hadn't been using the language for a long time, these kinds of things would be more troublesome.
std::vector will allocate memory dynamically (on the heap) if you don't want this then you don't want to use std::vector.
Anything. Though some things are harder to build than others. Better to ask yourself what kind of things would you like to build. I personally think that a language like C# might be better for a new user who's wanting to build some quick apps for example. But I think C++ really shines on areas that are performance critical. Things that involve math and graphics for example.
&gt; af had better have 11 elements FTFY
No brainer to "someone who knows and understands C++" I guess
/r/cpp only contains learned people who fully understand C++.
Over and over I see C++ novices passing around raw arrays of objects in exactly the same manner as is outlined in the example - thinking it's handled as easily as it is in C# or Java - which has resulted in more than a few (long) troubleshooting sessions. Based on the number of beginner threads in /r/cpp, this seems like the perfect place to spin such a precautionary tale.
Great points! Convincing new C++ developers to use vectors over arrays was actually the primary motivation for creating this example.
What really sucks is that the compiler fails to warn you about it (tested on GCC, Comeau, Clang).
Newbie C++ guy here who is primarily concerned with speed. Where would I go to learn what that terminology means in Numbers Everyone Should Know? (i.e. what is L1 cache, L2 cache, etc)
Newbie C++ guy here who is primarily concerned with speed. Where would I go to learn what that stuff means in Numbers Everyone Should Know? (i.e. what is L1/L2 cache, mutex, etc)
I can only say, 'Google'. That's what I would have done to answer you. For 'mutex', add 'threading' or 'thread' to the search, also. Actually skim along through the 'what every programmer should know about memory', for the /long form/ version of what L1, and L2 cache are. Otherwise any Google'd, hardware enthusiast site would be able to give you the quick version. 
Yeah, you're right. I'll do my homework. Thanks.
All their code? Are you sure that's right? I didn't see it anywhere since the VB6 times.
&gt;people who fully understand C++ Id venture a guess that there are probably no such people on reddit. Also, id like to point out that the 'bug' is inherited from C and its due to rules of passing arrays as parameters to function (which are broken). Also, to nitpick, there is no casting in the example.
Still learning C++ here, and it's very encouraging to see just how tightly classes are packed. The only memory being used in the array is that of the member variables.
There's also the benefit of efficient processing reducing battery drain.
That is not so true anymore. Screens have become far more sophisticated overtime, and the corresponding power drain from the screen and GPU far outweighs the CPU alone. I used to think what you just posted, but a post at slashdot opened my eyes.
Could you link us to the slashdot post? I mistakenly thought the newer screen technologies (not gpu) consume less power than they previously did.
Funny anecdote. My UPS is a cheap P.O.S. and it beeps whenever it's drawing too much power. I have a lot of graphically intense native and recent game titles and everything is fine when I play them. Then I load up Minecraft (Java) and BEEP BEEP BEEP BEEP BEEP. I'm not sure what the contributing factor is, whether Minecraft is just designed and written poorly or if it's the JVM, or a little bit of both.
Generic garbage collection is very difficult to get right with games. Games almost always perform better with custom memory allocators. And the memory allocation and deallocation patterns of a badly written game can tax the CPU more than the actual rendering loop itself.
Reminds me of early Intel Atom, where the CPU it self only consumes few watts, but the chipset etc were so inefficient that the total platform power consumption was 25 watts (or something like that).
s/Games/Everything :D. It's just that most apps don't need the runtime guarantees that would justify the headaches. 
I don't get it. If you had a problem that required native code, you should have always been writing native code. If you had a problem that didn't require native code, you could then take advantage of higher level languages like Java, Python, etc. So I'm supposed to believe that everyone's going to rewrite their Python scripts in C++11 now -- because native code is somehow "back in fashion"? And to somehow suggest that Javascript and C++ are in the same trade space seems like a huge stretch to me. They're on two different ends of the universe. If anything, I think C++11 finally gives C++ a richer standard library (which it has been woefully lacking for years). Which means maybe people can write C++ without depending on Boost or other helper libraries. 
Kudos. I actually worry of having to maintain the code of a programmer who carries over the patterns of garbage collected languages into C++. Programming in java is markedly different from C++. I have experience in both and sometimes have trouble switching over quickly.
&gt; But that appears to be changing. Visual Studio 2010 already supports most of the features of C++11. What bullshit. Aside from static_assert, auto, lambdas, nullptr, and move constructors (which has bugs that won't be fixed until the next version), VS2010's C++11 support is pathetic. Enum overhaul? Nope. Ranged iteration of containers? Nope. Unicode string literals? Nope. *delete*-ing methods from a derived class? Nope. Variadic templates? Nope. Initialization lists? Nope. std::atomic? Nope. Most of what they do support that didn't require changes to the compiler is shit that was already in Boost and VS2008 with TR1 anyway. Oh, yeah, and Microsoft's TR1 wasn't even that great despite the fact that they could've just copied it directly from Boost's perfectly working version. std::ref has a bug in it that was supposed to be fixed in 2008, wasn't, was supposed to then be fixed in 2010, wasn't, and now will supposedly be fixed at some later date in the future. How do you fuck up something so badly....that's already written for you?
Well you all know the old joke: There really are only two *good* programming languages, C and, uh, no, well actually, there's only one.
You probably are getting downvoted because you don't mention what C++ environment you are working with.
thank you, edited.
Not to mention that MS has made it clear they won't be fixing any more bugs until the next version of VS. It's actually incredibly painful how poor the C++ implementation in VS2010 is and you're forced to use the new standard instead of sticking with the previous C++03 standard. Something breaks or behaves in a weird fashion and you're left wondering whether you misinterpreted the incredibly bloated and complex new standard, or whether Microsoft misinterpreted it, or whether it's a genuine bug or who knows what else.
If you want to do all the xml processing yourself, why not just use libcurl or whatever to do the network back and forth and then just process the string? 
&gt; i used game maker language, and it had a local help menu with every piece of code i could possibly use, and an explanation of each. does c++ have this? Short answer: no.
Well.. gSoap and such do all the "xml to language type translation" and envelope / xsd validation for you. Unfortunately I only have experience with gSoap, and you ruled that out already. It ain't that hard. You just feed soap2cpp.exe your wsdl-file and it generates all the source files you have to include. The gSoap documentation is confusing at first, but if you take your time, then you'll see that it's fairly easy to use. But since you said you want to do alle the processing yourself: Why not write a simple server that receives a SOAP over HTTP message, jump straight to the SOAP-BODY and parse that stuff yourself. You'd miss out an all the SOAP-Envelope validation stuff of course. Another possibility, if you are developing for Windows, would be the Web Services API: http://msdn.microsoft.com/en-us/library/dd430435%28v=vs.85%29.aspx
What platform are you on? If you are Windows based you could use SoapClient30 in Microsoft Soap Toolkit (COM based).
Minecraft is quite poorly designed, it's well-known by now (lots of technical debt and bugs, no automated testing, not made to be extensible, etc.). You can check out the source yourself with the fans-created modder kit. These guys decompile the application, then deobfuscate the code by hand. Still, I'm sure a large part of Minecraft's computational code is due to the complexity of the problem itself. There's a huge difference between rendering infinite dynamic terrains, complete with "physics", redstone circuits, etc., and rendering a static world separated in smaller levels, like most games do.
I've had good success with gSoap. As soap libraries go, I didn't find gsoap to be all that difficult to use. 
poco project.
You'd think, now that Notch is a millionaire, that he could afford to have professional developers refactor his code and make things right.
[I'd recommend this in lieu of any shortcuts](http://www.amazon.com/Primer-Plus-5th-Stephen-Prata/dp/0672326973/ref=sr_1_2?ie=UTF8&amp;qid=1314283663&amp;sr=8-2). C++ is more complex than Game Maker. What you're asking for is something that you can cobble together as you go along, when in reality you have to have a pretty firm understanding of the language as a whole to make anything of substance.
Thanks, I think I'll try this. Gonna see if I can find a tutorial.
Unfortunately it was [deprecated in 2005](http://www.microsoft.com/download/en/details.aspx?id=13456).
Thanks, I'll try soap in HTTP message. I'd hoped to use WWSAPI initially, but unfortunately its [only available for Windows7](http://weblogs.asp.net/kennykerr/archive/2009/12/24/windows-web-services-fail.aspx). 
Yes, but it's deprecated by the .NET framework, which obviously isn't suitable for those of us still in the native world :-/. FYI, it still works in Windows7 and knowing how much effort Microsoft goes to to preserve backwards compatibility, it won't ever be removed.
Thanks. I thought it was no longer available for download, but the download button is there clear as day. 
Isn't that only true if your move-ctor throws? 
So Visual C++ finally gets good IntelliSense?
No. The point is - there are two objects in existence when move-ctor returns. One is a temporary object (original one) and the other is moved-to (new object). You wont be able to just add move-ctor to your classes, you also need to modify dtor code to correctly handle destruction of moved-from object - before this, dtor could assume that resource it handles is valid and safe to release/delete/whatever. 
"View help locally" doesn't change whether it uses a browser. It just means that the browser is viewing files on your computer, which is very useful when you don't have internet access (for example on an airplane). The Visual C++ 2010 help isn't terrific, but it's not bad. What are you not finding?
 int i; is an instance member. return foo1.i; uses it. Was that so hard to understand?
 int i; is a non-static member (instance member). And the static member function accesses it.
How does that test whether a static member function can access non-static members? Providing an example which doesn't X, is not proof that X isn't possible.
&gt; &gt; Strictly, grandparent is correct. You did not access an instance member. You accessed a member of a static member externally. &gt; `int i;` &gt; is an instance member. &gt; `return foo1.i;` &gt; uses it. &gt; Was that so hard to understand? I wouldn't have thought so, but apparently it was. You have made the exact same error a second time, by repeating yourself in a condescending way and ignoring what was said to you, on the assumption that you are correct. I'll try explaining slower. Please pay attention. 1) Static members of an object are forbidden from accessing non-static members of their member object. 2) The reason for the limitation is that accessing members requires the `this` pointer, which is not present in a static function. 3) In order to get around this, you are explicitly calling an object directly. This is not the same as internal access through the `this` pointer. This is an external access, which is not forbidden, *****not***** an internal access, which remains impossible. By accessing an object directly, you call its vtable directly, eliminating any need for a `this` pointer, *****because you are not calling the object internally, but rather making an external call to an object which just happens to be the same object, which is a very, very different thing.***** Please actually try to understand before replying.
Merely failing to understand what was said to you is not a case of showing it to be wrong.
This isn't actually very complicated, though you seem to be struggling with it hard. It is not that a static member cannot call a non-static member. It is that a static member cannot make an internal call. You are not making an internal call. Please try to understand what was said to you. You made the same botched rebuttal three seperate times, in the effort to feel correct.
the whole thing is a ploy IMO
I've used gsoap. It can generate C++ proxy clients from wsdl files fairly easily, but it gets pretty hairy when you're going the other way around, though the documentation (and performance) is pretty good. If I have control of both the client and the server I go with [ZeroC ICE](http://www.zeroc.com/). Yes, it's not SOAP, but it works very well and has a bunch of other features that I often find useful, like Freeze maps through BerkeleyDB and evictors. **EDIT** One thing to note is that I've sometimes had to trim down .wsdl files to get wsdl2h to generate the proxies properly, especially when the .wsdl file comes from the MS .NET ecosystem.
[Mine already has.](http://www.wholetomato.com/)
*cough* [custom allocators](http://www.google.de/search?q=custom+STL+allocator)
&gt;[00:00] GoingNative(); &gt; &gt;[41:29] ~GoingNative(); hhhh cute.
VAX doesn't work well with auto :(
AH dammit. I'm still on VS2008 for most development, but auto is indeed one of the features I am looking forward to. If vNext is as good as this demo suggests, the WholeTomato guys will have some pressure justifying their product. Hope they "survive" that, they seem like a cool crew.
We use VS2010, and I really hope they will fix the compiler problems and IDE hiccups.
Does the IDE crash sometimes when you build C++ projects as well? No reason for the crash, the code builds fine, the whole IDE just up &amp; crashes &amp; restarts &amp; then magically builds just fine after that? That's what I experience...
Looking forward to next VS. Hoping they'll finally sort out large solution scalability. Loading up, or even closing, a 500 project solution in VS2008 or VS2010 is no fun.
I don't know what you mean by "interator", everyone seems to be saying "iterator", but it's actually the "increment operator" (and may be applied to iterators, but only in C++, and it isn't an iterator itself)
Yes, but, in Java aren't iterators .next()? 
So are we seeing 'plus plus' break into the culture at large? It's already used in the Valley among geeks as 'props to x', 'x is good'. 
You may not have been downvoted, but instead subject to reddit's fudge factor. Reddit likes to randomly add up/downvotes while preserving the difference to confuse bots that would otherwise abuse the system.
You might be in the wrong subreddit.
I posted that edit when the comment went from +4 to zero. Reddit doesn't change votes that way.
Given that the source code is small, he might not want to show the source to anybody else. It wouldn't take much to repeat the infiniminer trick.
This is true, the number is quite low for fudging anyways.
I didn't had many crashes, but sometimes when you auto complete it can freeze the entire IDE. The biggest problem is that a MFC hello world executable in 2010 will take 150% more space than in prior versions.
[This](http://c-faq.com/~scs/cclass/int/sx9a.html) explains the problem while [this](http://c-faq.com/~scs/cclass/int/sx9b.html) presents a solution. Edit: By the way (grid[row])[col] is unnecessary. grid[row][col] works. Oh and I'd use a vector if you're already using C++.
The simplest solution: void print_grid(int* grid, int rows, int columns) { /* ... */ grid[row * columns + column]; } However this is inflexible and error-prone. You don't want to use arrays unless you have to; it's better to use std::vector instead unless you have a compelling reason not to. So a better (but still simple) solution would be: void print_grid(vector&lt;vector&lt;int&gt; &gt; grid) { This is a "jagged" 2D array, i.e. it allows each row to be of a different length which is not what you want for a grid. Even better but more complicated solution: [Boost.MultiArray](http://www.boost.org/doc/libs/1_46_1/libs/multi_array/doc/user.html) void print_grid(boost::multi_array&lt;int, 2&gt; grid) { /* ... */ grid[row][column] } Boost.MultiArray is a general multi-dimensional array library, but is a slightly more complicated solution than just using a vector of a vector.
Or, for a safer equivelent of the C-style fixed size array: using namespace std::tr1; //for brevity array&lt;array&lt;int, columns&gt;, rows&gt; grid; Then you can have: template&lt;int rows, int columns&gt; void print_grid(array&lt;array&lt;int, columns&gt; rows&gt; grid){ /* ... */ } And you can safely print a "grid" of any size without having to pass in the dimensions. I would suggest amending it to pass the grid by `const &amp;` to avoid copying overhead though. 
No really correct way to do this, it's up to the programmer. I would use std::vector&lt; std::vector&lt; T &gt; &gt; Matrix; Your function would then look something like print_grid( std::vector&lt; std::vector&lt; T &gt; &gt; &amp;Matrix ) { ... } The type of this matrix will be pretty messy, but using the new auto keyword from C++11 will help make the code easier to read, especially when you need the iterators.
What do you need the 2d array for? If I were you, I'd consider using a simple Matrix library such as eigen (http://eigen.tuxfamily.org/index.php?title=Main_Page)
I'd use operator()(int,int) on an array class that internally holds a simple vector of size m*n. Who cares whether you can do [][] or not?
While I agree, I must point out the alignment issues passing eigen matrices as arguments (not as references or const references). It can cause segment faults, and understanding these alignment issues might be a tad arcane for new programmers.
Also, `typedef` helps a lot.
In C++, the default type for an array is `vector&lt;&gt;`. You can decide to use something else, but only when you have a good reason.
[Here](http://code.google.com/p/tetris-challenge/source/browse/trunk/Futile/include/Futile/GenericGrid.h)'s a simple grid class.
 It is good to learn to use std::vector&lt;&gt; for problems like this in real world solutions, but you should also learn to use pointers. They are a basic concept which too many CS students with Java backgrounds fail to grasp. Your solution is pretty close. The error is (grid[row])[col]. It should be grid[row][col], as others have said. The added parenthesis changes the order of operation. Another way to look at it is with pointer notation. Your function passes in 'int **grid', which can be read as a pointer to a pointer to an int. //get the column pointer int *columnPtr = *(grid + row); //get the value for that column int value = *(columnPtr + column); //more succinctly int value = *(*(grid + row) + column); Pointer notation helps in understanding that bracket notation is syntactic sugar. As an example: int array[5]; ... int val = array[2]; //get value at 2 index int val2 = 2[array]; //also get value at 2 index, yes this is valid code The above code is valid because: *(array + 2) == *(2 + array) 
How much slower is using a vector than an array?
Access time is guaranteed to be O(1). If you grow it dynamically you'll suffer from reallocs but otherwise it should be the same (unless you're comparing to a stack alloced array).
Since Technical Report 1, [std::array](https://secure.wikimedia.org/wikipedia/en/wiki/Array\_%28C%2B%2B%29) is the preferred type for arrays, unless you need a dynamic array, in which case you probably want to use vector, of course.
Access time is O(1) but in real systems the constant not in the big O notation does matter.
The index operator does no bounds checking, as opposed to at() which does. The libstdc++ implementation was just an inline "return data[i]" last time I checked so there shouldn't be overhead. **Edit** From libstdc++ v4.2.1 (all I have handy at the moment): operator[](size_type __n) { return *(this-&gt;_M_impl._M_start + __n); }
I wanted to represent some boards of different board games. So I think eigen would bit a bit to extensive for my needs.
`vector&lt;&gt;` is still the default for me. `array` only works if you know the size at compile time, which, I find, happens fairly rarely in my code.
This is not necessarily a bad solution, but in general it is. The reason you don't have to pass in the dimensions is because the compiler will generate different code for each array size passed to it, each containing the respective sizes as constants.
Yep, but it's hardly likely that you're going to have enough different sized "grid"s for it to make an appreciable difference to the total code size. Besides, compilers can be pretty clever with their optimizations these days, so picking up that a few functions are identical apart from a couple of constants and having them share code isn't impossible.
The overhead I've seen is from resizing and from copying contents. I've seen ~15%, but that was a few years ago, and on Windows. That said, in general using vector will save you a bunch of grief.
Holy Christ guys. This is why people think C++ is so hard. He asks a simple question about basic arrays (probably for homework) and we walk him through pointer arithmetic, STL, Boost and custom templates.
Many people in this thread have suggested good alternatives to C-style arrays, but so far no one seems to point out the problem with your code. Your main problem is that you declare an array variable as `int grid [rows][columns];` and then pass it to a function that expects an argument of type `int ** grid`. That's not how it works. You need to declare the function's first parameter as `int grid[][columns]` or `int (*grid)[columns]` (the two possibilities are synonyms). To understand why, you need to realize that C++ (and C) does not really have multidimensional arrays. What people call multidimensional arrays are really one-dimensional arrays that contain other arrays as elements. This may sound like a pedantic distinction, but it affects the way arrays work in relation to function arguments. Say, if you declare a variable as `int foo[10][20]` your compiler understands foo as an array of 10 elements, whose every element is an array of 20 ints. C and C++ has a rule that when an array is passed as a function argument, it gets converted to a pointer to its first element. The first element of foo is foo[0], which is an array of 20 ints. So if you pass foo to a function, what is really passed is a pointer to an array of 20 ints, which is not the same thing as a pointer to a pointer to int. Your function declaration must reflect that. People sometimes mistakenly believe that pointers and arrays are the same thing, but that's not true. An expression whose value is an array gets converted to the corresponding pointer, but that only works at "top level". A pointer to an array is not converted to a pointer to a pointer.
Of all the things I tried ... the only one I got working was gSoap ... that will learn me.
Of all the things I tried ... the only one I got working was gSoap ... that will learn me.
If your array doesn't need to grow/shrink (and most 2D arrays probably don't) you could use a `std::array` and get most of the benefits of a `std::vector`. You're not wasting any storage space on "just in case" capacity, and the data-structure space overhead should be only one pointer, in contrast to `std::vector`'s three.
It's actually fairly easy to implement [] so that [][] works. But I agree with you: most of the time, it's not worth it.
Given that grid is a int **, then grid[row] will be of int *. I fail to see how (grid[row])[col] is not equal to grid[row][col]. 
The suggested methods using something like std::vector&lt; std::vector&lt; T &gt; &gt; Array; should be avoided for two reasons. First there is a memory overhead when using std::vector of 3*sizeof(void*).Most of the time this is negligible but it's not a reason to use way more vectors than needed. The second, and most important, reason is that, when you use a vector of vectors, you have no garraty that your resulting array will be contiguous. Therefore, the code will be slower. IMHO the prefered solution would be [something like this](http://codepad.org/YFcgAReo). You have to use only N vectors where N is the dimensionality of your data, you can use funny things like [][] for your domain-specific uses. Some haters will say that this implementation is slower than jsut definig a C array and accessing it with something like that : int array[width * height]; for(int j = 0 ; j &lt; height ; ++j) for(int i = 0 ; i &lt; width ; ++i) array[i + width * j] = /*stuff*/; This is simply not true, i can provide benchmarks that proves it.
&gt;500 project solution What?
This man puts Javascript in the same league as Python and Ruby, but goes on to ignore Perl. Stopped reading right there.
&gt; What is the easiest way to connect to a web service from C++? There is no pain-free way of working with web-services from C++. That said, the most painless way I found was gSOAP. I saw that you already got to gSOAP, so I won't post much about that. I just wanted to say that if you write code with gSOAP, you will have to maintain/extend/adapt to changes in your webservice contract. In that case, you will benefit from isolating the generated code into a separate project and automating your gsoap (re) generation of the code using python/shell/script/automated coding monkeys.
Someone correct me if I'm wrong, but basically the article is saying that C++ supports covariant return types but not covariant parameters? So basically if Cat inherits from Animal then the following method: virtual Cat* Foo(int bar); Is a 'subset' of: virtual Animal* Foo(int bar); But the following method: virtual int Foo(Cat* bar); Is not a 'subset' of: virtual int Foo(Animal* bar); Is this just because C++ has an incredibly crappy type system or is there a technical/implementation reason for this?
Exactly. The following method: virtual int Foo(Cat* bar); Creates a new virtual function which is not an override of: virtual int Foo(Animal* bar); The reason is that the C++ creators probably didn't think about it, because they didn't really think about the C++'s type system in terms of (math) categories. 
C++ also doesn't allow template type covariance; i.e. shared_ptr&lt;Cat&gt; is not a subtype of shared_ptr&lt;Animal&gt; for example, although strangely enough Cat* is a subtype of Animal* 
Forgive me if this is covered in the article, but it's pretty long and I haven't had time to read it yet; does Haskell's type system more closely follow math categories?
You have got the order backwards in the second example. Virtual methods are covariant in return type, and they could be (but aren't in C++) contravariant in argument type. That is, if a base class has a virtual method `virtual Animal* Foo(int bar);` you may override it with `virtual Cat* Foo(int bar);` but, there is no way a base class method `virtual int Foo(Animal* bar);` could be overridden with `virtual int Foo(Cat* bar);`. The reason is simple: suppose you call the base class method and pass it a `Dog *` as an argument, and then at runtime the virtual call is dispatched to the derived method, which only accepts `Cat*`. Conclusion: methods cannot be covariant in their argument type. On the other hand, one might imagine that virtual methods could be contravariant in argument type, that is, a base class method accepting a `Cat *` gets overridden with a derived method accepting any `Animal *`. I don't know why they didn't implement it in C++, I guess it's either because they didn't think about it, or they didn't consider it very useful in practice, or they didn't want to mess with the already quite messy overload resolution rules (note that return type covariance does not affect overload resolution, because return types do not participate in overloading). 
&gt; I haven't had time to read it yet Me too. I just browsed over the C++ part. Haskell has type classes. It doesn't have polymorphism, but closures can be used to achieve polymorphic behavior. 
Haskell also does not have parameter contravariance, and it does not have return type covariance. Indeed, Haskell belongs to the family of Hindley-Milner type systems, and adding subtyping to those results in a hell of a mess. Haskell does have the notion of typeclasses, however, so an `Integer` "is a" `Num`. What Haskell does make explicit, however, is the construction of an endofunctor of its type category (Hask), with the typeclass Functor. Things which are instances of Functor are analogous to functors that go from Hask to Hask (i.e. they take types to types, and morphisms of types to morphisms of types). The example given there is of [], the List functor. It takes, say, Char, to [Char] (types to types), and with map, it takes say, f :: Char -&gt; Int to map f :: [Char] -&gt; [Int].
First of all, in C++ `Cat*` does not really behave as a subtype of `Animal*`. If `Cat*` were a subtype of `Animal*`, then it would be possible to assign an address of a variable of type `Cat*` to a pointer to `Animal*`. That is, you would be able to assign `Cat **` to `Animal **`, but C++ disallows such conversions, and for very good reasons too. If such conversions were legal, it would result in a hole in the type system, like so: Animal * some_dog= new Dog(); Cat * catptr; Animal ** app = &amp;catptr; //assigns Cat ** to Animal**, should be illegal * app = some_dog; //now catptr contains the address of a Dog catptr-&gt;Meow(); //tries to invoke cat method on a Dog You run into similar problems if you treat shared_ptr&lt;Cat&gt; as a subtype of shared_ptr&lt;Animal&gt;. In fact, I can't think of very many examples where making templates covariant or contravariant on their arguments would be useful. C++ however allows you to assign `shared_ptr&lt;Cat&gt;` to a `shared_ptr&lt;Animal&gt;`, through a templated assignment operator, and a `shared_ptr&lt;Cat&gt;` is convertible to a `shared_ptr&lt;Animal&gt;`, so I'd say the implementation of `shared_ptr` has all the benefits of subtyping, without its problems.
Custom allocators will still be allocating memory from *some* kind of heap (as opposed to the stack). There are other solutions, though.
&gt; Id venture a guess that there are probably no such people on reddit. I'm getting tired of this old myth. Sure, C++ is complicated, but it's far from impossible to have a solid grasp of all of its features and quirks. The standard is of a finite size, and while it's around 700 pages long, it requires no superhuman powers to comprehend them.
Allocating from a fixed-size free list isn't less efficient as the stack (except maybe with regards to memory locality), and a incrementing pointer allocator with a no-op element deallocator might arguably perform faster than the stack. My point is that "allocating from some kind of heap" is very much different from "allocating from *the* heap". Still, custom allocators are a PITA - they don't allow state except in custom STL implementations (and then you need a non-standard rebind), and since the allocator is part of the type, it basically turns all your algorithms into templates. 
&gt; My point is that "allocating from some kind of heap" is very much different from "allocating from the heap". Right, but I imagine some of the restrictions that lead people to avoid data types like std::vector could be things like targeting an architecture with very little memory, where heap fragmentation is a big issue (so ad hoc allocations might not be feasible), or where there is no heap at all. And yeah, custom allocators are no fun.
On a core i7 array of rows is definitely slower. I've tested that myself. The overhead of allocating a separate row pointer buffer, then having to index into that in order to get an offset into the main buffer, well it's not good. Declare a grid as a Type * data, and wide and high parameters. Use c++ to encapsulate the hard memory buffer. You can then define the first operator[] to return a pointer into to the data at the offset of the row. The second [] will index into the pointer just returned. I just ran a test with code like what you have and code with a single buffer creating and multiplying a whole bunch of 3x3 matrices (using O3). On a core2 quad the single buffer is 1.5x faster, on a core i7 1.6x faster. Changed over to 1024x1024 matrices. On core2 quad the vector of row pointers is 1.25x faster. On a core i7 the single buffer is 1.08x faster. For "n" dimensional arrays I've been using std::vector&lt;unsigned&gt; to provide dimensions and providing operator[](std::vector&lt;unsigned&gt;()) for indexing.
can he get away with using something based on std::streambuf or something? Guess not, apparentlly he's working with "string" buffers which look to be locked into ASCII. UTF8 might rain on his parade.
Very relaxing, would watch again.
This was cross posted on one of the other subreddits, and there was a top comment saying that video is a terrible medium to deliver this content. I, for one, am with you. With the video you just sit back and watch and sip on a beer. I very much like this form of delivery.
I've apparently hit my two article limit.
&gt; First of all, in C++ Cat* does not really behave as a subtype of Animal*. Indeed, and that's what I said. &gt; If such conversions were legal, it would result in a hole in the type system Indeed, but Cat * * is not a subtype of Animal * * . However, Cat * is a subtype of Animal *: where there is a pointer to animal, the pointer can point to a cat. &gt; You run into similar problems if you treat shared_ptr&lt;Cat&gt; as a subtype of shared_ptr&lt;Animal&gt; Perhaps you meant shared_ptr&lt;shared_ptr&lt;Cat&gt; &gt; ? because if you didn't, then your comment above is irrelevant. &gt; In fact, I can't think of very many examples where making templates covariant or contravariant on their arguments would be useful. How about this? void printAnimals(const list&lt;Animal *&gt; &amp;animals); list&lt;Cat *&gt; cats; printAnimals(cats); If list&lt;Cat * &gt; was a subtype of list&lt;Animal * &gt;, because Cat * is a subtype of Animal *, then the above would work out of the box. Now, it doesn't work. 
bugmenot.com worked :-)
I think part of the problem is that a lot of us would like to watch from work, and office culture generally frowns upon watching videos. Another problem is that you can't copy and paste from a video, and if you want to try the examples out in parallel, its more difficult than an article on the web. None of these are huge deals, but the whole watching from work thing makes me not watch videos like this often enough.
&gt;If `list&lt;Cat * &gt;` was a subtype of `list&lt;Animal * &gt;`, because `Cat *` is a subtype of `Animal *`, then the above would work out of the box. Now, it doesn't work. If `list&lt;Cat*&gt;` was a subtype of `list&lt;Animal*&gt;` you could also do this: void AddAnimal(list&lt;Animal*&gt; &amp; animals){ animals.push_back(new Dog()); } int main(){ list&lt;Cat*&gt; cats; AddAnimal(cats); } This obviously breaks type safety. There may be a template that could benefit from template argument covariance, but it's neither shared_ptr, nor list, nor any other mutable container.
&gt; This obviously breaks type safety. You are right. But only in the presence of mutability. If our list was immutable, the original list would not be affected. 
Register? I think I'll skip.
[An add-free one page version here](http://drdobbs.com/article/print?articleId=231600433&amp;siteSectionName=)
Good stuff
I guess, probably, because you can do it yourself with function overloading to get very similar effect. As we cant overload on return type, language feature was needed for covariance.
This would be a better question to ask at stackoverflow.com There is no requirement to use std::wstring for UNICODE support. Neither std::string or std::wstring know anything about UNICODE or ASCII or any kind of encoding, they are entirely neutral. All they do is store a raw buffer of data with some methods that operate on a unit by unit basis. For std::string that unit is guaranteed to be 1 byte. For wstring that unit will be the smallest integral type that can store the platform's native character encoding, meaning on Windows it's 2 bytes, and Linux 4 bytes. This however does not imply Unicode, as Windows doesn't use Unicode natively. Anyhow, without going into too many more details, the bottom line is that #define UNICODE has no standard or cross-platform meaning.
Unicode is a [big can of worms](http://programmers.stackexchange.com/questions/102205/should-utf-16-be-considered-harmful) that you should not take lightly. 
No. Printing is a platform-specific thing, so it cannot be done portably with pure C++. You will need to pull in some external library, possibly one for each platform you want to support. (I.e. for instance on linux or mac printing will work differently than on windows)
std::string is templated on char where std::wstring is templated on wchar_t, and neither of them is directly tied to Unicode, as Kranar pointed out. See [this answer](http://stackoverflow.com/questions/402283/stdwstring-vs-stdstring/402918#402918) for some detailed information.
http://blogs.msdn.com/b/oldnewthing/archive/2009/01/15/9319761.aspx Windows is UTF-16 internally. The link describes how it accommodates non-unicode applicaitons.
OK, I dunno if you're aware, but std::string is not a part of Linux or Windows. The common ones for these platforms would be GNU's STL or MS's STL, respectively.
Actually a better attitude is that it's something that every single programmer should know: http://www.joelonsoftware.com/articles/Unicode.html ---- Edit: That's an excellent article snarfy posted though.
Ah looks like Windows now uses UTF. In the past they used UCS-2.
This is the general impression I've gotten reading thru different articles on the subject (including the one provided here). The response provided by erengy below is where I got the impression that the std::string implementations in Linux are in fact UTF-8 Unicode aware. As far as I know, and based on the link from superironbob above Windows is natively UTF-16 (no note on the endian, but I would suspect little based on this [wikipedia page](http://en.wikipedia.org/wiki/Endianness#Endianness_and_operating_systems_on_architectures)) This whole little question / rabbit hole cropped up while reading the source code for a project called [pugg](http://pugg.svn.sourceforge.net/viewvc/pugg/include/puggPlugin.h?revision=26&amp;view=markup). That code is unfortunately windows specific and I've been trying to massage it over to a linux friendly state. The Unicode ifdefs in there however had me a bit concerned that I was missing something big with the file handling and seemed like a good thing to read into before simply removing from the base code. I'm inclined to simplify it all down to a std::string and drop the wstring handling entirely, however I suspect this was included initially for some entirely rational reason. Alternatively I guess I could put my hopes in the boost filesystem functions and see where that gets me.
I am aware of this fact.
Yes. Use code to output as a postscript document then call an external script to send it to a printer or something like ghostscript to display it.
On some platforms, you used to be able to print simple text by writing to associated printer devices. For example, by doing //ofstream printer("LPT0"); //windows ofstream printer("/dev/lp"); //linux printer &lt;&lt; "Hello World!\n" &lt;&lt; endl; However, I haven't used this trick since the 90's, so it might not work anymore
Yes. cout. Edit: oh, you mean the anachronism of producing paper with a facsimile of information seen on your screen. Go fish.
I've only ever seen #define UNICODE in old Windows source code that had to compile in both NT and 98, where there were two versions of a Windows function, one ending in A that took char strings and one ending in W that took short strings. ODBC, for example, is full of duplicated functions, and the "real" function is just a macro that expands to one or the other depending on if UNICODE is defined or not.
I forgot to mention this in my update edit, this does seem to have been a misunderstanding on my part as to the intention of this #define. I had based it off an article discussing library usage of both UNICODE and _UNICODE as definable constants that would alter their compilation behaviors. That particular rabbit hole should probably be expunged unless somebody has a current use case for it beyond the pugg project I mentioned earlier.
Yes, I have personal experience with doing this and can attest that it works pretty well in at least some circumstances --- plus you get to learn a new language with a different paradigm! (Well, at least *I* think that is a plus... :-) ) Alternatively you can have your C++ output SVG which models the document as a tree of nested transformations rather than a linear set of commands, as in some circumstances it can be more convenient for expressing the structure of a document than Postscript.
Windows is natively UTF-16, but as you should already know, neither std::string nor std::wstring have anything to do with unicode. Hence it *doesn't matter* whether you use std::string or std::wstring - using one or the other doesn't tell you anything about whether its encoded in unicode or not. All you know is that std::string contains char's and std::wstring contains wchar_t's. On Windows it's convenient to use std::wstring because wchar_t is 2 bytes on Windows and therefore can be used to store UTF-16 encoded text (which is what Windows uses natively). That means you don't need to convert between encodings to interact with the Windows API. If the application is written for Windows and uses std::wstring, it means it probably uses UTF-16 as its native encoding. If you're porting it to Linux, then just convert your UTF-16 encoded wstrings into UTF-8 encoded strings before interacting with the system.
Qt has stuff for printing and it's quite easy to use. Although it wouldn't be a very good option since Qt is quite heavyweight for such simple task.
You are thinking Windows 2000 and before.
You should probably follow the links, and I can tell you only about windows: std::string itself is encoding-agnostic, it works with any "char-sized" encoding. However, you need to be careful with the API's and algorithms you use them with. splitting an ISO 1282 - encoded string is easier than splitting an UTF-8 string. --- Windows API comes in two flavors: let's call them 'A' (using char * strings) and 'W' (using UTF-16 wchar_t * strings). e.g. there are actually two functions, OutputDebugStringA(LPCSTR) and OutputDebugStringW(LPCWSTR). #define UNICODE maps OutputDebugString to the 'W' version to otherwise, it's mapped to the 'A' version. This also affects the definition of the TCHAR / LPCTSTR types. Internally, Windows usually uses UTF16, the 'A' versions involve an additional string conversion. The 'A' versions use the **Current Code Page**. This might be UTF-8, but usually isn't. --- The #define *_*UNICODE (note the underscore) is subtly different: it affects the C Runtime Libraries in a similar way: it maps e.g. _tprintf to wprintf(\_wchar\_t const \* , ...) instead of printf(char const \* , ...). Typically, you want use these defines in sync. 
Use Qt::String man. It will solve all your problems. 
It seems I was conflating more issues than I realized when I started down this path. I was unaware the UNICODE and _UNICODE were specific to windows programming which was probably the first of many mistakes.
To combine two other replies to your question, it's a can of worms every developer should open :) Good luck, and keep asking
Thanks for the pointers. In this case the string handling in question is file system access so there 'shouldn't' be any communication from linux versions to windows versions. If this is the case it, this whole discussion appears to become a non issue. That, or I'm just going crazy.
For one project I'm looking at this is an option and almost a certainty that I will go this route. My main concern with using it however is the 'yet another dependency' issue, when I'm trying to write a library that's fairly standalone. On the other hand, I wouldn't have to figure out how to convert this plugin library, I could just use the one provided by Qt. The other is a Wt project, so I'll use the local framework version. It's not as robust as Qt's, but it is well supported inside the framework and fairly easy to understand.
If you install lpr for windows you can call that from C++ with the system command. 
std::string "works" fine with encodings wider than one char. It doesn't do a lot with it's contents, just stores a bunch of chars. It's basically std::vector&lt;char&gt; with few convenience methods.
To clarify what I meant: It does work well with encondings that use one or more byte ber code point, it doesn't work for UTF-16 (one or more byte pairs) or UTF-32 (4 bytes). 
I recently found this. Its just a couple of files so nice and minimal. http://utfcpp.sourceforge.net/
Neat, thanks :)
Hey, some of us are old. Don't be hating.
I like it. At one moment talks about a flaw in Visual Studio 10, and doesn't get censored by Microsoft.
Very interesting. I have been a hobbyist c++ programmer for about 15 years and have been using c++0x for about a year on my hobby projects. I don't have as much coding experience as the interviewee but I can relate to his enthusiasm for c++0x. I can't wait for full compliance with clang/gcc/msvc.
Bartosz is very good at presenting concurrency stuffs. Can't wait for further tutorials hosted at corensic.com
This one wasn't as good as the other videos.
Got a version of it not behind a paywall?
The standard is open but not free (although you could get some free work in progress versions). You can read the reasons for this in [these comments](http://herbsutter.com/2011/03/25/we-have-fdis-trip-report-march-2011-c-standards-meeting/)
[Not exactly](http://www.reddit.com/r/cpp/comments/jhiyb/we_have_an_international_standard_c0x_is/c2c84v5)
And in another short 10 years, all the major compilers will fully support it. 
Yeah, unless you're working on developing compilers, this draft should be suitable for most people. The changes between this (linked) draft and the final one are minor/trivial, such as the ISO cover page .... 
http://gcc.gnu.org/gcc-4.7/cxx0x_status.html and http://wiki.apache.org/stdcxx/C++0xCompilerSupport
Fortunately they took a much more sensible approach this time and required an actual implementation of a feature for it to be considered so there should be no export-like issues with the new standard.
The status of the standard is 60.60 (International Standard Published) with efective date 2011-09-01, yet there's an additional entry saying Target publication date: 2012-02-28 Can some ISO-savvy guru explain this?
Short, detailed and interesting; good stuff.
&gt;Called by the compiler when you have more than one page of local variables in your function. huh ...
Good idea. I just submitted my app :)
"You've got some nice DSL."
Yes, absolutely. C++ contains all of C and most operating systems are written in C. (Windows &amp; Linux at least) Most Word processing software was also written in C at one point (looking at WordPerfect for DOS) The issue becomes trying to do it cross platform and easily. If your printer is hooked up to a parallel port you can directly write to the memory mapped IO address to send your data. You'll need to find the protocol specifications for your particular printer. This works best with line printers, not Laser or Inkjet that expect data to be sent in full pages. You may have issues under modern OSes though with memory protection so YMMV. Alternatively, most OS may have a set of printer APIs (in C &amp; maybe C++) that you can call. These are very different from system to system though. You could use a 3rd party library that has abstract printing functions, like QT. This is probably the easiest but also the most "bulky" way to do it.
Vectors are traditionally implemented internally as a dynamically allocated c-style array and an integer to hold the size. The access cost is almost identical to a traditional dynamic array, but the cost comes when it runs out of space: it then uses an algorithm to create a new, larger dynamic array, copy the data from the old array to the new array, delete the old array, and assign the internal pointer to point to the new array. You can greatly speed up your system if you know how many elements the vector will have (or a minimum number) by directly calling the reserve(size_type n) function on your vector. This is at least the way it was when I was taking my Algorithms class in college and we looked at the STL vector implementation.
If you know the final size (or approx final size) of your vector, calling vector::reserve(size_type N) will save you most of the overhead from resizing. It tells the vector what your expected size is, performs a resize to that size (even if you have zero elements). You can then insert up to N elements without triggering a resize operation.
Clarified move semantics for me, thanks.
Sorry, but when I read this, I pictured another app developer somewhere earlier in time writing "I'm writing an app to launch on startup, but someone is sending SW_HIDE to hide it. How do I prevent them from hiding my window?"
Bartoz is an *excellent* C++ instructor. These concepts cannot be explained any clearer.
This was rather excellent, please do more.
That's not MSDN (AFAIK). But yep channel 9 is great.
I'm still not quite grasping the move semantics The piece I'm not quite comfortable with here is workers.push_back(std::move(th)); I'm guessing, without std::move , the destructor of the thread would be called as the thread object is copied around, and go out of scope in the loop So, what is std::move actually doing here, and just as important, how is it doing it ?
`boost::thread` objects cannot be copied. Without `std::move`, the code would be invalid (because it would attempt to copy the `boost::thread` object. With `std::move`, the move-constructor is called. That transfers the internal object into the vector (and --I believe -- replaces `th` with a default-constructed object. I believe these pieces of code are functionally-equivalent: V1: workers.push_back(std::move(th)); V2: workers.push_back(boost::thread()); //Add a default-constructed thread to the end of the container std::swap(workers.back(),th); Edited to add: `boost::thread` and `std::thread` have a sufficiently similar interface that the example holds for either. I hadn't watched enough of the video initially to know which he was using.
As I said, std::move does nothing except to convince the compiler that it is dealing with an rvalue. It's like a function that takes an lvalue and returns an rvalue. Then the rvalue is passed to push_back, which accepts an rvalue reference. When you're passing an rvalue to an rvalue-reference accepting function, the move constructor is automatically called. Inside the thread's move constructor, the bit that controls what happens at destruction is flipped (it's actually the "joinable" bit).
The operating system doesn't know anything about local variables. The OS probably knows about the stack as a whole and the process heap, but the program itself is solely responsible for managing variables. A debug symbol file (produced by the compiler &amp; linker) can let a debugger locate the local variable, but again, that's separate from the OS.
Actually not even the program itself manages variables (in C/C++ at least). It just loads and stores stuff from certain memory locations, but it's compilers responsibility to ensure that the memory locations correspond to the space allocated for variables as specified by programmer. I think the best way to understand is to study assembly programming. You don't need to actually learn it (I certainly haven't), but just reading about it illustrates how stuff works.
Call it twice. It may be ignored the first time (seriously). Refer to http://msdn.microsoft.com/en-us/library/ms633548\(v=vs.85\).aspx for details.
The operating system doesn't. It gives a chunk of memory space to the program and says: "Here you go! Here's your memory - and if we're nice, we'll promise other programs can't use that same memory space or access it." The underlying assembly instructions that that chunk of memory and break it up into pieces and give them nice labelled names like "i" using some kind of fancy look up tables. So its the C compiler doing a lot of the magic for you - not the OS.
http://en.wikipedia.org/wiki/Call_stack#Functions_of_the_call_stack ... and if you are serious about looking under the covers: http://www.amazon.com/Inside-Object-Model-Stanley-Lippman/dp/0201834545
despite all the downvotes, i'd like to thank you all for your replies
Eh, just a C++ advertising video. Nothing of value for people who already use C++.
True, i liked it but it's just a motivational. I liked the phrase "C++11: The Return of The King" remembers me of Lord of The Rings...
&gt; True, i liked it but it's just a motivational. It's nice to get back the love, for too many years people gave me the "dying language" talk.
the things related to move semantics are really interesting. It will take some exercise from the reader to understand them as I think they are some consistent addition to the language, and !not for only library writers to use as they were advertised at some point...
you could try some problems from the [UVa online judge](http://uva.onlinejudge.org/). Create an account, go to the 'Browse problems' section, and chose a problem from the problem set volumes. The interesting part is that you can submit your solution to an automated judge that will tell you if your solution is correct and how fast your program is compared to other submissions. Careful though, problems can be tough. You'll want to start with a high solving rate.
You're right, the problems are really challenging. If you want something simpler, assuming you're looking for applications on the command-line (without any GUI/Graphic library), you could try to implement a simple [game of life](http://en.wikipedia.org/wiki/Conway%27s_Game_of_Life). the principle is fairy simple, you could render a small board using characters, iterating automatically or using the keyboard, and the result can be fun.
Why does he say that in the last three years, all that was invested into compiler development was into either Visual C++, Clang or GCC, when there was a browser war with I don't know how much energy put into Javascript compilers? And what about all the languages sprouting on top of the JVM? He makes some good points, but he shouldn't completely neglect what's going on outside his world.
From the article: &gt; Operators &amp;&amp; and &amp; are mixed up. It's a very common error. I come across it virtually in every project where bits or file attributes are being handled. Where I work, we include iso646.h in just about every project and use "and" rather than "&amp;&amp;", "or" rather than "||", etc... I find it somewhat irritating because I'm used to the *native* operators, but after reading this, I wonder if it's actually a good idea. Does anybody else use that header? 
I don't use that header when coding in C. However, in Perl I always prefer "and" or "or" over "&amp;&amp;" or "||" for the sake of making the code more verbose. In my opinion, condition expressions tend to be the most difficult and most error-prone places in programs (in whatever language). If you want to be verbose, that's the place to start.
I prefer to use *and*, *or*, and *not* in place of their symbolic equivalents in C++. Didn't realize that header existed for C.
Yeah, it's been in the standard library for about 15 years now. http://en.wikipedia.org/wiki/Iso646.h 
Still no variadic templates :(
And still no C99 support. :(
Sounds like they need to hire more people. I'm sure there are lots of people who would kill to get to work on a compiler. Hell, I'd quit my job. At this rate it will take another ten years.
I'm really disappointed. No variadiac templates or range-based for. I was just waiting for the next VC version to support these features to start using them, but at this rate it will take a while...
Implementing most of these things would require intimate knowledge of the compiler, and compilers -- especially C++ compilers -- are massive projects. Hiring more people would probably just waste time. In any case, we have no idea how the vNext internal team works, so it's meaningless to speculate on how they could improve their practices.
Not sure I'm understanding your question exactly, but the simplest way to do it is int x = 6, y = 4, z = 0; z = x; x = y; y = z; I'd highly recommend reading up on variable assignment.
Yeah what was the way I was going to do it originally, I was just wondering if there was a more efficient way of doing it. Thanks.
Good ol' xor-swap works too: http://en.wikipedia.org/wiki/XOR_swap_algorithm
If you have access to STL on your platform (shouldn't be a problem in this day &amp; age), there's [std::swap\(x, y\)](http://www.cplusplus.com/reference/algorithm/swap/). It's of course important that you understand how variable swapping works "under the hood" as well, but your code will be more readable if you learn to use things like this early on. :)
That's great, Doug.
Is funny how this comes up a lot. I never understood why anyone would even consider using this trick. Not only does it have the flaws you describe, but its also defeating any optimisation the compiler would normally do, probably making it actually emit machine code that would be slower than the more obvious method. In an attempt to make it "faster" or "more efficient", it would make it slower and error prone. Hence the whole "beware premature optimisation" mantra, I guess.
I haven't used visual studio since I was in high school (was educated on and prefer a unix platform). These sorts of tools are essential in developing robust and performant software. If you're ever in unix land, check out valgrind. It gives you much the same features.
I'm in Unix land all the time, but I much prefer Visual Studio for an IDE. I've always said that even if you hate Microsoft for some reason, they do make a damn good C++ compiler, IDE, desktop operating system (though I'd never use any of the server variants of Windows) and a great office suite (or so I hear, not my realm really).
Oh absolutely. I didn't mean to say that visual studio was a bad IDE. Even if it was, the fact that you've got it working for you and you are productive with it is reason enough to use it. And I guess I assumed that you were developing solely for windows. My apologies :).
XOR swap saves memory, but is slower, and obfuscates unnecessarily. "On modern CPU architectures, the XOR technique is considerably slower than using a temporary variable to do swapping. One reason is that modern CPUs strive to execute instructions in parallel via instruction pipelines. In the XOR technique, the inputs to each operation depend on the results of the previous operation, so they must be executed in strictly sequential order. If efficiency is of tremendous concern, it is advised to test the speeds of both the XOR technique and temporary variable swapping on the target architecture." (Wikipedia)
Very, very bad for large values of x and/or y. (I.e., the multiplication.) Requires more code for the assurance about tighter bounds on the values for x and y because of this. Using a temporary variable is the best way to go for actually *swapping* values and not playing tricks that have multiple additional considerations not addressed.
Nope. That's the best way. XOR swap has issues. Other tricks have issues too. Actually using a temporary variable has the least issues, is the most direct, and readable way. Also fastest.
No apology necessary at all. Generally everything I make is made to be portable, even if only because I like to develop C++ in a Microsoft environment.
These kinds of tricks usually also have the "feature" that if both parameters happen to refer to the same chunk of memory, they destroy the content. Three times. I just love it when people use the XOR swap trick (and similar clever tricks), because it means I can make the code cleaner and more robust by replacing the clever code with a direct and clear solution. 
So much cool stuff that's going to have to wait until the 2014 version. I understand if they're trying to launch early in 2012, but it might be painful to watch as gcc and clang add these features one by one.
I believe these are only available in the Team edition unfortunately.
Yes, profiling tools are an essential aspect of any development process. That goes for OS X, Linux, BSD, or Windows. :) *edit* I should note, only on Windows do you have to pay for them though. :) I've use 100% of what my development environments have to offer…totals about $5 bucks, maybe. And some time for a patch here or there.
As others have noted, in practice you'd use std::swap(x,y) and let the library developers deal with it. If asked this on a test, you'd use a temporary variable (normally professors want bare bones implementation). If I were to implement and was looking for "clever points" in a c++ course, I'd use templates. template&lt;typename T&gt; void swap(T &amp;x, T &amp;y) { T temp; temp = x; x = y; y = temp; }; A driver might look like this: int main() { int x, y; x = 100; y = 200; std::cout &lt;&lt; "x: " &lt;&lt; x &lt;&lt; "\n"; std::cout &lt;&lt; "y: " &lt;&lt; y &lt;&lt; "\n"; swap&lt;int&gt;(x, y); std::cout &lt;&lt; "x: " &lt;&lt; x &lt;&lt; "\n"; std::cout &lt;&lt; "y: " &lt;&lt; y &lt;&lt; std::endl; return 0; } The precondition would require the object type have a copy constructor defined. *edit* If you also required the objects have a defined equal operator, you could do this: template&lt;typename T&gt; void swap(T &amp;x, T &amp;y) { if (x != y) { T temp; temp = x; x = y; y = temp; } }; That way if the two values are equivalent, no temp memory allocation or unnecessary assignment would occur.
I would only think your last example would be useful on specialized hardware where such operations were extremely expensive. For the most part the expense of the if would outweigh gains
&gt; I should note, only on Windows do you have to pay for them though. :) I can pick up Intel's profiling tools for Linux for free?
&gt; XOR swap saves memory, but is slower, and obfuscates unnecessarily. Oh, and it also indicates that you've gone to the internet to complete your homework.
&gt; I can pick up Intel's profiling tools for Linux for free? No, I didn't say "you can get all profiling tools for free" on other platforms. You can get profiling tools for free on other platforms….whether they are as good as the pay for tools or if the pay for tools are good enough to justify their price is an entirely different point of contention.
C++11 has now move semantics which may help.
It doesn't work in all cases, if you swap a variable with itself it ends up being zero. 
 swap&lt;int&gt;(x, y); You can leave out the &lt;int&gt;. The compiler infers template arguments to functions if it knows the regular arguments and if they contain the appropriate information.
So, I agree with you except for the C++ compiler part. The IDE yes, the Compiler no. Microsoft CL is embarrassingly lacking in features compared to gcc from even 3 years ago, and on some informal benchmarks I did recently comparing Mingw64 4.5 to cl 2010, mingw did a much,much better job at code generation. Sometimes as much as 100x faster!
To better understand you might want to compare move constructors and copy constructors. And it really only makes sense on class definitions where pointers are used or user defined types. The destructor of the thread will be called when it goes out of scope however any memory its data members pointed to will have been moved to the new instance constructed and place onto the container.
If you are on windows just use msft winhttp to make http requests then sax to parse the body.
"Damn good C++ compiler?" Where did you get that from. MSVC is absolutely awful, OK, they did a lot of work in the last version, but it is still years behind IntelC++ and GCC.
Realistically, use std::swap. If you want to code it yourself, the canonical way to swap x and y is tmp = x x = y y = tmp
I usually hit up some [Project Euler](http://projecteuler.net/). It's just a lot of fun regardless of the langauge.
Another issue arises if x*y &gt; MAX_INT, you will have an undefined behavior in this case. 
&gt; The precondition would require the object type have a copy constructor defined. And a default constructor, since if an object has one it will probably have the other too I would do it this way: template&lt;typename T&gt; void swap(T &amp;x, T &amp;y) { T temp(x); x = y; y = temp; } 
 *(current)* * Classes only when the entity needs state - otherwise, global (namespaced) functions - in the spirit of "non-friend non-members over members". * *planned inheritance* - i.e. there is no point in making all functions virtual, you need to state which modifications you support anyway. For each virtual function you need to document purpose, contract, the default implementation, and responsibilities for derived classes. That's enough deterrence to make you think twice about sticking a "virtual" on it. * STL containers + a bit of STL algorithms + a bit of boost (shared_ etc. ptr, bind, function) * Separating ressource management from algorithms. STL attempts that does that in a way, but makes allocator part of the type, thus the algorithm is not truly independent. I'd separate a "vectordata&lt;T&gt;" type that provides all / the majority of methods on an allocator-type independent way. (STL would allow to solve that if stateful allocators weren't such unreliable beasts) * I prefer a public, non-templated interface for a set of known types *implemented* using templates over a templated interface. The reasons are many, from template infection to compile-time diagnostics. Templates are A-OK for primary concerns (such as element type in a vector), acceptable for some more (e.g. comparator in a std::map - while it's not exactly part of the *type* it's a performance tradeoff), but not for global aspects such as memory management, error handling etc. * I'm working with a lot of C-style API's, I've learnt to avoid trying to wrap them completely. You are never complete, you are always running behind. I have wrappers and utilities for the most common scenarios involving ressources (scoped / reference counted handles, returning a string in a buffer, [out] BSTR *, etc.), and combine them with native API's * Unhappy with error handling no matter what I do, lots of C API's don't mix well with exceptions; if you do it right the majority of the code is still handling odd cases. * preprocessor only if I can't express otherwise; complex #defines often get broken down to a very simple define and some "real" code (usually a template) ----- I can't make out a clear history anymore; I got into C++ back when compilers just recently added *either* exceptions *or* templates, and std::string was something totally ridiculous. I evolved (a bit (I hope)), Scott Myers helped me a great deal to *understand* STL, and tell apart template metawanking from design choices I consider reasonable. I instantly jumped on smart pointers as a solution to "many problems", above philosophy of separating resource management from algorithms is retrofitted. Making a class behave exactly as expected / as a built in type is a lot of work that's worth the effort only in few cases - with that realization, my use of operator overloading etc. has reduced significantly. 
&gt; Making a class behave exactly as expected / as a built in type is a lot of work that's worth the effort only in few cases - with that realization, my use of operator overloading etc. has reduced significantly. That's such a great point. I keep falling into the trap of "Oh I'll just add a quick operator+ to this class, it makes complete semantic sense!". Uh-oh need an operator+=. Uh oh need to overload it for just one *tiny* edge case. It makes complete sense to use accumulate() on them now, right? Blergh I hate when that happens. 
http://i.imgur.com/VvAuA.jpg
There's no problem that can't be solved by another layer of abstraction!
That's so painfully true. :( I don't have this problem in other languages (C#, Java) but when it comes to C++, I have a tendency to abstract away absolutely everything. I really really need to kick the habit.
Thanks for the heads up!
Long time Fortran and C programmer here. My code needs to be Correct, Robust, Clear, and Fast (in that order), where Clear means rapidly understandable by someone with fair knowledge of Fortran, C, Matlab, and basic C++ concepts. On a side note, this means that my C code tends to stay within the C/C++ common subset (so it does exactly the same thing whether compiled as C or C++) ... I don't really count this as "how I use C++" ... * Never use new when simply declaring a local variable is sufficient. * Always arrange for a delete for any new. RAII where possible. * Prefer references over pointers where either could work. * Arrays of objects are rare, generally limited to read-only tables. * Object oriented code, but only for object oriented problems. * Virtual functions where they might be useful, but not to excess. * Function pointers as needed (virtual functions reduce this need). * Limited use of Templates, usually hidden inside the implementation. * Limited use of STL containers, rare use of STL algorithms. * Boost not available on some work machines (so personal toys only). * Designs frequently constrained by need to interact with Fortran and C. * Designs frequently constrained by need to embed within Matlab MEX function. Looking forward to some of the new C++11 features, and beginning to figure out how I can introduce them into my code while maintaining readability for the folks whose primary job is something other than keeping up with the latest twists and turns of C++ evolution. Making lambda expressions clear is going to be interesting ; ) 
If you need the full set often, there are some templates in [bost/operators.hpp](http://www.boost.org/doc/libs/1_41_0/libs/utility/operators.htm) - but yes, you still have to make sure everything works as expected in those tiny edge cases. 
Yeah I've just really started exploring the boost libraries. Have been pressuring the bosses for a while and finally got the go-ahead! I'm really enjoying the kind of "aw man I hate &lt;problem x&gt; ... oh wait I saw something in Boost that would help!" phase.
Can you elaborate on "... non-templated interface for a set of known types implemented using templates over a templated interface?" I'm new to C++ and I have a template infection problem. 
Extensive RAII, limited text-book OOP (inheritance only from interface classes where run-time polymorphism is needed), much "Herb Sutter Style", for example many free functions instead of member functions for better encapsulation (by reducing the set of functions that has access to private data members), strongly exception safe code and use of exceptions for exceptional conditions, highly multi-threaded code, STL wherever appropriate but no Boost (since using some C++0x which includes basics like shared_ptr), no bullshit, for example a singleton is implemented with a global variable, ... 
I am using C++ ...as a punishment. 