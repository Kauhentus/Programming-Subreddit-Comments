[Neat!](https://i.imgur.com/Y4YFthE.gif) 
Regarding the last point on syntax, this is already a part of the Concepts TS. See http://en.cppreference.com/w/cpp/language/constraints under Abbreviated Templates. I'm not sure without checking whether or not this is included in the parts of the TS merged into C++20 but I suspect not at this time. 
This is a beautiful article! I'm going to just throw this out there, do you think this utf8-checker can be optimized further? https://github.com/boostorg/beast/blob/develop/include/boost/beast/websocket/detail/utf8_checker.hpp#L24
Virtual functions are not the only way to achieve runtime polymorphism. See `std::variant`. You can also implement your own hand-rolled version of virtual functions using something like a struct of function pointers, which was a common approach in C.
Well, as long as you are fine with the drawbacks of templates (definition has to be put into header, long compile times, tight coupling , error messages, no formal interface specification (yet)) then sure.
The previous version was a state machine. This is a simplification :)
Easy to criticize. Hard to propose a concrete improvement :)
I guess the padding requirement could be removed by using a LUT for the indices and a mask as well.
Not really, because every call to an asynchronous initiating function inside the body of the implementation causes the function to return. It is later re-entered through member operator(). Moving code to other functions requires writing additional dispatching code which adds overhead, increases the opportunities for errors, and makes it more difficult to audit the code.
+1 That is afaik one of the very few language features that has been COMPLETELY superseded by a better mechanism.
Yep! I love how Steve keeps up the banter to avoid radio silence, when the software being demoed inevitably behaves contrary to expectations :)
You can but it's sometimes really clunky (e.g. if it's a member function that needs access to private members)
The proposal for standardization of [fmt](http://fmtlib.net/latest/index.html) makes a pretty good argument for why [positional arguments](http://fmtlib.net/Text%20Formatting.html#PosArguments) are an extremely useful feature for localizing format strings.
`&lt;&lt;` is used for both changing formatting and writing output.
Got it, I misread the last sentence initially.
This [has been discussed before][1] but I think the case against `std::bind` is overstated. In particular I think 'prefer lambdas to `std::bind`' is similar to saying 'prefer for-loops to `std::accumulate`.' Yes, lambda is more general and therefore more common. But there are specific use-cases for which `std::bind` is the most readable, conceptually clean way to write code.\* Namely, if you want a functional binding then using the more general lambda feature can obscure the meaning of the code, the same way that using a general for-loop obscures the fact that a loop is doing simple accumulation. Obviously if you're not doing accumulation/binding then you shouldn't use `std::accumulate`/`std::bind`, but if you are then `std::accumulate`/`std::bind` may be the best tool. Also I haven't seen the performance argument adequately demonstrated. In particular the claimed inlining failures haven't appeared in [simple tests][2]. \* I do not refer to 'terseness'; A lambda might be more terse, but if `bind` is more readable and a better conceptual match for the functionality being represented, I'll take the more readable, cleaner, less terse `std::bind`. [1]: https://www.reddit.com/r/cpp/comments/3m0rsk/functional_whats_new_and_proper_usage/cvbs8bq/ [2]: https://godbolt.org/g/SpWTQR
Well, typing an alias is still longer than typing nothing for a bind expression, so they would still complain. At least in C++14, it's just auto, sure you type, but it's more like boilerplate rather than investigating which type (with templates) you really have.
Answer to your title is an unequivocal, "no." Virtual dispatch is the best mechanism for responding to certain problems. Working to not use it just because is kinda stupid. Inheritance is a different story. There are many times when virtual dispatch is desired and inheritance is not. There's a lot of ways to respond to that.
Don't worry, no one is saying we should remove goto from the language. 
Thank you.
Every single lambda I've checked so far has been inlined by the compiler and it is also not difficult to coerce the compiler into inlineing other functions. But admittedly, you don't get a guarantee.
I think if the mindset of using classes and virtual functions is to mark it as "Java style C++", then it's the mindset that's wrong. 
Sure there is! Structs of function pointers, also known as the C-emulating-classes method. Manual implementation of a vtable, in other words. Disclaimer, I'm in no way recommending that anybody does this. 
I agree with johannes. As a sketch of a concrete example: How about a functor class that takes a bunch of parameters and calling operator() does a very complex computation using those parameters? The programmer who uses the functor objects will only ever want to use operator(), but hidden underneath is some serious complexity which is split across many complex private functions. I'd say these functions can be non-trivial enough to warrant testing.
`#define brilliant abominable`
If the Expected proposal moves to LWG in time for C++ 20, in 2018 I'll submit AFIO https://ned14.github.io/afio/ for standardisation as a prospective File I/O TS making up the bottom layer of a proposed std2 iostreams and range based containers. Quite a few folk on WG21 have ideas on how to do iostreams -better- differently, though nothing definite yet. Note that iostreams will be going *nowhere*, these are additional, alternative, less user friendly alternatives for those who need the performance.
In a library I would say *nearly* always, for the simple reason that a library user can transform a templated library into a runtime polymorphism-based library, but not vice versa. In an application I would still say that a template is the correct *default* any time you do not actually need runtime dispatch, but there are pros and cons to each. There absolutely are times that the runtime overhead of virtual dispatch is irrelevant, while the extra compile time or binary size from templating it would matter. 
I wonder what is the speed difference when the input is all ASCII characters. Usual UTF-8 string has mostly ASCII characters. I'd guess that branching version might be faster. Also in some use cases it is good to get the location of invalid UTF-8 character. Anyway really interesting article that gave good ideas for avoiding branches. Edit: Tried out its performance when the input has only ASCII characters. On my computer its thoughput dropped to 241MB/s from 604MB/s. Hoehrmann's implementation had same 536MB/s throughput in both tests.
Hey it looks pretty cool! A few comments: * How does it compare to tiny-dnn? Seems like the goals are very similar (though tiny-dnn has now grown from a nice tiny library to something quite large, not sure how good it is anymore) * What about compiling on VS2017.3 or VS2017.4? * I think importers/exporters for models would be really good, particularly to import certain pre-trained models and then fine-tune on your own data, or for training on a different framework and then using yours for inferencing. E.g. many pretrained models are available in the formats of matconvnet (from VGG group), TensorFlow and Caffe, and it would be awesome to be able to use/import them. * Have you benchmarked multi-GPU training? For a framework to be successful you really need very strong GPU training performance (which you seem to have done, GPU performance of dll looks really nice!), nobody really cares about CPU times (except maybe for inference in some circumstances). But having the ability to train on 2 or 4 GPUs is a must. What TensorFlow version did you test against btw? You should specify the versions you've tested (or I've missed it). * It's a bit of a shame that you used etl and not Eigen. Eigen would be the much better choice, even more so nowadays as apparently TensorFlow uses is as backend for Tensor-stuff so lots of people have quite a high stake in it and it's for sure the best and most widely used thing you can get, many people already use it for their matrix operations, it's kind of the go-to LinAlg library, so it's a bit of a shame that anyone using DLL will now have to use etl as well and convert their matrices into and from that format. Do you have a really compelling reason for not using it? You've got very strong competition (mainly TensorFlow) but your library does looks really great and appealing! (C++14, header-only, RBMs, code looks better and easier than other C++ frameworks).
Oh I see, it's just a few helper functions on top of &lt;random&gt;! That makes sense :-)
But then you have to trade it for additional variables. E.g.: if(some condition) { foo bar; if(other condition) goto xxx; foo bar; } foo bar; xxx: foo bar; 
You can try wt. I've only played with the examples so far, but I thought it was more fun to write Qt like code than configuring Apache... https://www.webtoolkit.eu/wt
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/74ykmc/please_help_me_understand_this_class_member/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There are still cases where (if performance is a concern) raw owning pointers win over something like unique_ptr: resizing a vector of owning pointers for example.
Of course; there's a whole host of options, in fact, depending on how you want to do things: The most direct way I can think of is something like [Wt](https://www.webtoolkit.eu/wt). You can build web apps directly in C++. For non-direct solutions, it's a matter of how you want to interface technologies. One of the more general-purpose and web-centric ways would be to add a REST API to your C++ code. You'd want to use something like [Casablanca](https://casablanca.codeplex.com/), but that's not the only option in the space. Alternatively, you could use something like [Crow](https://github.com/ipkn/crow), which lets you build a Flask-like web appliance. You could use [gRPC](https://grpc.io/) as a cross-language channel and build your website in whatever. There are tons and tons of options, and it's largely a matter of what works best for you.
Thank you, I've never heard of wt. I'll have to look further into this later tonight. Thanks!
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/74ye09/qurstion_is_there_a_good_way_to_create_a_front/do242gn/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It isn't doing it anymore. It was the comic talk bubble, the one that starts "Hello, my name is Jonathan Boccara. ..." It was covering almost all of the text. I always like your posts, and I appreciate them. Thanks for making them.
Whats the mechanism behind this feature? I'm sure you are able to trace all API calls with parameters, but how do you track memory changes?
Those graphs are neat and all but I've never seen maps that go over a few hundred/thousand elements. Although that's probably due to my C++ background being game development. What are the cases where you'd need a map of that size where performance ends up being important?
Do you guys have any plans to add this to Task Manager so that users can make the recording? Or is there an automation API to start recording from an application? I've tried to debug an executable generated with `clang -gcodeview ...`, it worked, but I couldn't set breakpoint (F9) anywhere (except few places), getting: Matched: my_exe!main+0x361e (00007ff7`7b89067e) Matched: my_exe!main+0x3631 (00007ff7`7b890691) Matched: my_exe!main+0x3638 (00007ff7`7b890698) Ambiguous symbol error at '`my_exe!source.cpp:123+`)' But it is probably clang's bug. I couldn't figure out how to redirect file to stdin of a process when using "Launch executable (advanced)", tried to put "&lt; some_file" in "Arguments:" field, but it didn't work. I think your talk is the best things that happened in CppCon 2017. :)
I am not so sure that is true. However my Conan and cmake skills are very limited. I thought Conan was a pure package manager so you still need a build system like cmake + ninja/make/msbuild. So Conan helps you version your pre-built artifacts kind of like a cache. Ea packages are for c++ packages mostly source package and not pre built. (Though can support pre-built packages too). Ea packages are more about helping you find library A or library B header and library paths without using environment variables. Like cmake find_library or find_package maybe but when I used these they confused me more then they helped. Ea global scope file seems much easy to understand version of this. I also assume that a cmake + Conan solution you would need more Code. Conan is in python and cmake custom language I assume some data is duplicated. Ea gives enough data for both and in one consistent language. Speed wise they are similar if they used the same type of generator. (Both use ninja or visual studio etc). But caching could b a factor. Also running generators in cmake might be faster as most packages do not use wildcards and in ea this is the norm. If I am right and Conan is mostly pre-built package system that would have some cost and benefit. On large program with a lot of open source and a small number of devs I could see Conan working well as this would be a good cache of build artifacts. In EA we don’t have enough pre built code to make Conan stile packages worth while. We often have to change debug flags library by library to debug problems as the whole game can’t be run in debug. So we end up with a build config per programmer almost. I think Ubisoft’s fast build (like distcc + cache as I understand it) looks like it is close to what we need given nearly all of EA works on windows. Hope these comment help see the difference between theses systems. Sorry if my limited knowledge of cmake and Conan confuse things. 
A vector is the last place you want raw owning pointers. WAY too easy to leak them. Yes, `unique_ptr` does null out the sources which might be nice to avoid but compared to touching the heap writing a 0 should be microscopic.
Is there a language feature that C++ does not have that would have simplified the function?
Maybe using the (u)int\_fast\_##_t integer types exclusively would make it a little faster. Also more portable.
Often, I need a map to hold 10 of millions of items or more. One example is in [a read mapping tool](https://github.com/COMBINE-lab/RapMap/tree/develop-salmon), where we build a hash map (actually using Sparsepp) from fixed-length prefixes to intervals of a generalized suffix array. Generally, large hash maps are not uncommon in genomics. I imagine there are many other areas as well.
Or `std::function`, which is runtime polymorphism without virtual (in its public interface, and it is possible to implement it without virtual internally too). 
The cost of templates is non-zero. By having a custom version of your function for every instance type, you cause runtime code bloat. And the cache is your friend. Writing templates that explode into quadratic amounts of runtime binary code isn't hard; and cubic or worse can happen easily as well. The cache is your friend. The cost of virtual dispatch is the double-indirection of vtable and method pointer stored there, giving you two chances to have a cache miss; but the cost of template explosion can be much higher. Templates are a very good idea where the cost of dispatch can be high, and really not worth the costs if the costs of dispatch are not high. One simple way to handle this is to *type erase* at a careful spot. As an example, suppose you have a per-pixel operation on potentially mega or giga pixel images. Wrapping that in virtual dispatch (or a std function type erasure) can easily be extremely expensive. However, a simple wrapper that converst the per-pixel operation into a per-pixel-run operation, then taking that per-pixel run operation and running it on your image, can reduce the overhead costs of virtual dispatch by a few 1000 or million fold, *without* leading to insane amounts of code bloat. And as the optimizer has access to the naked per-pixel operation when compiling the long pixel run version, it can do things like vectorize the loop. Learn where to type erase (using whatever technique -- manual, vtable dispatch, std function), and when not to. 
Does using `char` for the length lookup table cause a penalty for unaligned memory access? Making them ints might improve things slightly, but the cache is also important...
&gt; Do you guys have any plans to add this to Task Manager so that users can make the recording? Or is there an automation API to start recording from an application? We don't have any plans yet, but that is a scenario we'd like to address at some point. There are a lot of different ways to approach that problem, and we haven't figured out which makes the most sense yet. &gt; I've tried to debug an executable generated with clang -gcodeview ..., it worked, but I couldn't set breakpoint (F9) anywhere (except few places) You'll have better luck setting a breakpoint on a symbol than a source line. You can do this from the UI using "Breakpoints-&gt;New", but I think it's probably easier to do it from the console right now using "bp &lt;functionName&gt;" because you have a few more options there, and you get tab-completion of symbol names. It looks like clang is generating symbols that are slightly different than the MSVC compiler, which is confusing WinDbg. If I had to guess, it looks like it's generating multiple discontiguous source line -&gt; code mapping entries, which confuses WinDbg because it's now "ambiguous" of where you actually want the breakpoint. Maybe a clang bug, maybe it's something WinDbg should interpret better... but I'll see if we can take a look at some point. &gt; I couldn't figure out how to redirect file to stdin of a process Redirecting a file to stdin is a feature of cmd.exe, not something built into windows. You could replicate this by debugging cmd.exe with a command line that runs your program with redirected input, but you'll have to enable "child process debugging" with ".childdbg 1" (we don't have UI for that right now... I should add that). A bit involved, but you should be able to get that to work (send me a message if you can't figure it out and I can give you a better example) &gt; I think your talk is the best things that happened in CppCon 2017. :) Glad you think so :) 
It's based on CPU emulation. There's a usenix paper published describing a similar technique: https://www.usenix.org/legacy/events/vee06/full_papers/p154-bhansali.pdf
Clearly your industrial experience is lacking. I agree that it should not be a norm but I still see it in R&amp;D oriented projects where the developers are focused on a solution, but not necessarily the *right* solution. 
I wish it was just replaced with an enhanced version, with or without the same name. Sometimes you just want a number
It would be interesting to see a few cases where a raw owning pointer is faster than a unique_ptr. With optimizations turned on
And how do you implement things like allocators without new/delete. Heck unique_ptr/shared_ptr use it, but I guess that could be made compiler magic. But there are uses and in the future static analysis will warn of raw pointers not marked with a usage. But why operator[]? I'm curious.
I just listed one: when the vector resizes a vector of pointers is memcpy where a vector of unique_ptr is move() on each + set old to empty then call the destructor on each item in the old buffer. Edit example: Raw pointers: https://i.imgur.com/EbUl6kz.png Unique pointers: https://i.imgur.com/AFxNmm7.png
Not operator[], raw C-arrays.
*something* has to hold ownership. I'm not saying you should have an exposed vector of basic pointers - you can easily put it inside your own self-contained struct/class to ensure it's not used incorrectly. But at the end of the day something has to hold ownership and a vector of unique_ptr has a larger overhead compared to a vector of basic pointers and if performance matters in your application (it does in mine - gaming) it's something you need to deal with. See [example](https://www.reddit.com/r/cpp/comments/74t184/question_which_c_featureslibrariespatterns_should/do2b6fb/) I'm not saying "don't use unique_ptr" - I'm just saying it's not a 1-1 replacement for basic new/delete and that's something that needs to be keep in mind.
Nice but the branch comes at error checking level, so it's the same. And if your buffer is huge, you still do the decoding operation even if it will fail? You will waste more time doing so. 
What about char const [] for strings at compile time(also literals), I do not know of a replacement? At least C++17 fixed the constexpr'ness of std::array and I can retire my code, but that is very new. 
OK, I see. So pretty much you need to wrap that array in a class that will do the if not nullptr checks of the elements at destruction or whenever appropriate elsewhere
How r u gonna use virtual functions with zero inheritance (or interface), I'm not against virtual functions particularly cuz it's just a mean to do runtime polymorphism, it's the inheritance based OOP that I hate cuz I hate to code interfaces manually, I like duck typing and it's much more elegant and it does not need any manually coded interface (inheritance), but it's not possible in C++, and the closest thing we have in C++ is its static variant, templates 
I don't really do C style header files (declaration-definition separation) anyways, it's always the hpp files (definition right after where it's declared, so implementations within the headers), I don't care much about compile time cuz it's always been within 1 min or so for me
That's the "if error goto endlabel" error handling that we all know and love from VisualBasic, isn't it? There's exceptions (edit: and RAII) for that in C++, and that is **exactly** why I say `goto` is not needed.
Here you are leaking memory: https://github.com/ziacko/TinyShaders/blob/master/Include/TinyShaders.h#L313 Also, in this function file is opened in text mode and ftell is used to get it's size. This is wrong http://en.cppreference.com/w/cpp/io/c/ftell : &gt; If the stream is open in text mode, the value returned by this function is unspecified and is only meaningful as the input to std::fseek
Parsing the whole buffer in the face of errors if something you want to do EDIT: frequently anyway, recovering most of the text and skipping errors.
"Java style" was metaphorical, I meant "Duck (Structural) Typing OOP" versus "Inheritance based OOP"
One of the interesting things about branchless decoding is that is should be potentially easier to vectorize, which would be particularly beneficial when the text is more consistent, coding-wise.
ok changes have been pushed. thanks for the feedback
You're using deprecated [C-compatibility headers](http://en.cppreference.com/w/cpp/header#C_compatibility_headers). You should be using the C++-equivalents, which are prefixed with `c` and don't have a `.h` (ie. `cstdio`, `cstdlib`, `cstring`, etc). Make sure that you're also using such standard library methods from the `std` namespace, after you switch to the C++-equivalent headers.
changes for this have been pushed as well. thanks 
There is https://github.com/ericniebler/stl2 that contains proposals and discussions, and also https://www.youtube.com/watch?v=fjtwfauk7a8 (though I haven't watched this yet and I am not sure if video refers to ericniebler/stl2 or author's own ideas)
There's still a fair bit of work yet to be done (notably in the documentation). But I'd be curious to get a few opinions at this point.
This is "strange" c++, you are leaking a resource [here](https://github.com/ziacko/TinyShaders/blob/2766337a34283d5f738fd639ab5fed6870970d81/Include/TinyShaders.h#L318) because you are leaving the function without closing the file handle. 
Yes, I kept the default identity function to also highlight how sensible each hash map is to a not ideal hash distribution. Other collisions resolution schemes are able to cope quite well (`google::sparse_hash_map` has just a way too high default max load factor, other hash maps with quadratic probing are doing well). Linear probing suffers too much of [primary clustering](https://en.m.wikipedia.org/wiki/Primary_clustering). Even with a better hash function, linear probing is doing quite badly on read misses or after some deletions. Linear probing is in my opinion too naive for a general purpose hash map (could be useful in some cases), it can degenerate too quickly. Linear probing with Robinhood should be preferred, insertions and deletions are just a bit longer but it offers way better theoretical properties than plain linear.
It was only one of the many leaks, all others are still there. Just don't use raw owning pointers. You should go through every new and malloc in your code and use unique_ptr everywhere. And file size fix is still not fully correct: you're getting binary file size, but reading in text mode. Also, you don't need intermediate buffer here, you can resize outBuffer and read directly into it. And even this read isn't needed, you can just memory map source file and pass it into glShaderSource. Less code leads to fewer errors.
"raw operator new", abstracted away in some dedicated lower level resource classes is fine. But unique_ptr can often work even there without overhead. 
It can go quickly if you have to analyze a lot of data (in machine learning, physics, biology, ...). Note that I used large hash maps to more easily highlight the differences, but even on small hash maps the difference between chaining and open-addressing will be huge if there is a lot of queries on the map.
"King of the ^(h)ashes."
You're still using C standard library functions from the global namespace. The C++ equivalent headers for don't mandate or guarantee that the functions will be available in the global namespace, only in the `std` namespace. See for example C++20 draft standard (N4687) section 24.5.3 and 30.11.1. Furthermore, you're using the `NULL` define, while in modern C++ you should *always* use `nullptr` instead. You're also using tab wrong. Only use tab to indent up to the current scope and always use spaces after that. It's a problem for example [here](https://github.com/ziacko/TinyShaders/blob/2766337a34283d5f738fd639ab5fed6870970d81/Include/TinyShaders.h#L337), where you used tabs to align the variable names - if viewed with a tab width of 2, it looks broken [like this](https://i.imgur.com/lQEVUxD.png).
One of the motivations for using RAII is that in combination with exception-handling, it's easy to have leak-free error handling. For larger projects, RAII+exceptions allows not writing any error handling code in the middle layers, which saves both work and bugs.
Consider implementing live reloading, it's a must-have feature for debugging shaders. You only need to use fixed storage for program handles and return pointers to that storage for each handle. Then you need to check if any of source files has been modified either by timestamp or filesystem notification (a bit of overkill for small number of shaders), and recompile, relink and replace old handle with new handle if successful. Remember to delete old program too, if you don't want to spend hours finding that sneaky memory leak.
I can't show you the example right now because I'm stuck on mobile, but the second example optimises away the virtual call just as well as calling the function directly. I'll try and remember to do a comparison later. 
Looks good! Some questions: * Why does this library need C++17 support? I.e., what C++17 features do you deploy? * How long have you been working on this library? I wanted to do something similar but I have a busy schedule. * What kind of parser is it under the hood? Recursive Descend I suppose? Keep up the good work!
It sounds like the argument is coming down to personal preference, for you, but there are real differences between the two approaches as others have pointed out. Hating to do something isn't really a rational or good reason to choose a way to go about engineering a solution. Another point I would add is that to a large extent templates and normal classes/inheritance are orthogonal. You can write an interface class and have a template which derives from it, and so on. Or your interface can itself be a template. You will always get the best out of C++ when you think about it as a collaboration between lots of different languages, not one big one. As soon as you say that it becomes obvious that there is seldom ever a "one true" way to do something when it comes to choosing a programming paradigm, and any discussion like this will inevitably end up in "choose the right tool for the job, and know what the right tool is". 
Doesn't returning an unaligned pointer to `uint32_t` cause undefined behavior or other potentially really bad things? I'm not quite sure, but I found [this question](https://stackoverflow.com/questions/13881487/should-i-worry-about-the-alignment-during-pointer-casting). According to that, this kind of pointer casting also violates the strict aliasing rule. Can someone explain this stuff to me? :)
Thanks for the info. I have been considering it but i wanted to get it stable first. Ill definitely try to add it using your advice
That is exactly what you don't want to do - and that's why C++ offers inheritance. Why would you not use inheritance, why do you think you can do it faster and better than the compiler? 
I was pointing out that there are alternatives, I am aware of the merits or rather the lack thereof. Hence the disclaimer. One real reason, by the way, is because this is how C libraries sometimes implement plugins, and your C++ may need to interact with such code. 
Beautiful! But I have one or two comments... First of all, it is true that branches may be problematic on a modern CPU. However, you introduce a significant amount of processing even for the simplest case, and there are a lot of data dependencies in there as well, which are _also_ a source of pipeline stalls. Since you omitted any performance measurement from the article, and since you made a big point out of this being more efficient because of pipeline stalls, I decided to measure it myself. Here I'm comparing my own, traditional (branching) decoder against your branchless decoder. My environment is MSVC2017, 64-bit, O2, Ob2, Oi, Ot, Oy, GL. That's MSVC-speak for "make it go fast". The first test is for 1'000'000 iterations of a random ASCII text (1679 bytes): traditional: 3.632207s branchless: 10.102578s Ok, that doesn't look too hot. But maybe it works better when each code point is encoded using multiple bytes? Let's try with 1'000'000 iterations over some random Chinese text (3784 bytes, spread over 1276 code points, so 2.97 bytes per code point): traditional: 5.993343s branchless: 7.673439s They are getting closer together, but the traditional approach still wins. The morale of this story? Don't just assume, _measure_! If you build a beautiful algorithm based around the notion that branching is bad for your performance, at least measure it so you know it is actually true! I also have some stylistic points. - Strings, in C++, are encoded using type `const char *`. Don't use `void *`. - You could replace those arrays with `constexpr std::array`. I would assume(!) that this doesn't change performance; that a constexpr array would only be computed once. This is not true; I measured it(!), and the ASCII case now took 15.999915s instead. The difference completely disappeared when I declared them `static constexpr std::array`. - A 32-bit unicode character has its own type in C++, which is char32_t. Don't use uint32_t for it. - Why are c and e not references? - Why are there casts in the computation of c? - buf, s, len, next, and the return value could all be const. The changes proposed above do not change the timing in any way (as long as those arrays are made static - and yes, I measured). I also tried a version that didn't read any continuation bytes, to see if that is what caused the branchless algorithm to run slower. With continuation bytes disabled, the ASCII example runs in 9.217527s - a bit faster, but still much slower than the traditional decoder. Finally, in addition to not reading continuation bytes, I disabled the computation of e entirely. That version runs in 7.314418s - still about twice as slow as the traditional decoder. For the sake of being complete, here is the traditional decoder I tested against: char32_t GetChar (const char *Buf, int &amp;Offset) { char32_t Result = 0; if ((Buf [Offset] &amp; 0x80) == 0) { Result = Buf [Offset]; ++Offset; return Result; } if ((Buf [Offset] &amp; 0xE0) == 0xC0 &amp;&amp; (Buf [Offset + 1] &amp; 0xC0) == 0x80) { Result = ((Buf [Offset] &amp; 0x1F) &lt;&lt; 6) | (Buf [Offset + 1] &amp; 0x3F); Offset += 2; return Result; } if ((Buf [Offset] &amp; 0xF0) == 0xE0 &amp;&amp; (Buf [Offset + 1] &amp; 0xC0) == 0x80 &amp;&amp; (Buf [Offset + 2] &amp; 0xC0) == 0x80) { Result = ((Buf [Offset] &amp; 0x0F) &lt;&lt; 12) | ((Buf [Offset + 1] &amp; 0x3F) &lt;&lt; 6) | (Buf [Offset + 2] &amp; 0x3F); Offset += 3; return Result; } if ((Buf [Offset] &amp; 0xF8) == 0xF0 &amp;&amp; (Buf [Offset + 1] &amp; 0xC0) == 0x80 &amp;&amp; (Buf [Offset + 2] &amp; 0xC0) == 0x80 &amp;&amp; (Buf [Offset + 3] &amp; 0xC0) == 0x80) { Result = ((Buf [Offset] &amp; 0x07) &lt;&lt; 18) | ((Buf [Offset + 1] &amp; 0x3F) &lt;&lt; 12) | ((Buf [Offset + 2] &amp; 0x3F) &lt;&lt; 6) | (Buf [Offset + 3] &amp; 0x3F); Offset += 4; return Result; } // Not a correctly encoded character; return the replacement character. ++Offset; return 0xFFFD; } 
Alisdair Meredith held 3 sessions on his ideas w.r.t. issues with the current STL at the C++ Now 2017, and tried to gauge his audience' feelings w.r.t. where STL2 might need to go and how to implement it... There wasn't really much set-in-stone stuff, it was more about getting people to think about it IMO. I'd like to know what Stroustrup thinks about Alisdair's ideas...
Now I'm curious about why the committee regrets using unsigned values for collection sizes. I can't think of any strong standard interpretation for negatives sizes. Is the problem with unsigned values just that we often want to compare the sizes to signed values - and so the comparison can get messed up?
Yes, and this restriction is lifted with the EBO because the base and derived are effectively the same object. Rust has Zero-Sized structs and indeed they do require a few special cases when iterating arrays (hint: there's no array, just a size), however this pale in comparison of the convenience of not requiring a weird trick to enable memory savings.
As far as I know, signed values are easier to be optimised in every architecture.
I'm not complaining about the fact that map is ordered. If anything, I think C++ made the right choice by using a comparison-based map by default: many languages have been bitten by attacks on their hash map implementations (exploiting collisions) which ordered maps are naturally immune to. My complaint is about memory stability/iterator invalidation which make it difficult to use any other implementation than a node-based tree.
Do you rely on the elements being stable in memory or the iterators not being invalidated? To implement a priority queue (or any other "multi-indexed" container) I've found easier to instead use intrusive containers (or just `boost::multi-index` in a jiffy).
Isn't that the point of the article? 
There is certainly a trade-off. If all you need is memory stability, simply putting the element behind a pointer is easy enough. Iterator stability cannot be achieved externally. However, at the same a look-up by ID is O(log N), and faster in a packed map than in an unpacked one (because cache/data-dependencies). I am not against iterator stability per se, I just wish it was not the *default*. I would prefer if the default standard containers offered a *minimum* of guarantees; this way when you swap it for another more specialized container to fit your needs you don't have to worry about accidentally losing a guarantee that some obscure function may have been relying on.
There is also an implementation that works with GCC (cmcstl2).
what we need is class safe_size { int impl; public: #if !defined(NDEBUG) safe_size operator-(safe_size a, safe_size b) { if(a.impl - b.impl &lt; 0 || whatever sanity check) throw runtime_error("invalid operation"); } #else safe_size operator-(safe_size a, safe_size b) { return a.impl - b.impl; } #endif };
My guess is along the lines of vec0.size() - vec1.size()
Precisely, unsigned ints are not the same as non-negative integers.
It's the opposite. Unsinged mul/div were always faster and also sometimes replaceable with shifts.
It's not the opposite. Some operations are faster with signed values, like overflowing, while others with unsigned.
I believe this library provides this - https://github.com/foonathan/type_safe
&gt; Nice but the branch comes at error checking level, so it's the same. And if your buffer is huge, you still do the decoding operation even if it will fail? You will waste more time doing so. Actually, you can very simply just *count* the number of errors (`!!e` on caller side), and declare decoding successful if the accumulated number of errors is still 0 at the end. It really depends what your requirements are, however I can see rewarding "good" inputs with increased performance and simply biting the bullet for bad inputs. Maybe they are infrequent enough, maybe they kick of expensive processing to report the issue, etc...
Nice micro challenge. I played around with it on quick-bench.com http://quick-bench.com/0UVlDBCrm_98x9jhwX5yf4I69oE I could not make it any faster. But the odd thing is, that the simple decoder (that was only in the blog post) seems to be twice as fast, if the text size is small enough. It seems the processor is capable of recognizing the condition pattern or the code it fully folded, because there is no "external" random involved. I also found this article about a simd implementation: https://woboq.com/blog/utf-8-processing-using-simd.html My conclusions: * measure! * you should not trust that optimizers figure out anything 
I'm curious what people think about this: &gt;I chose void * for the buffer so that it doesn’t care what type was actually chosen to represent the buffer. It could be a uint8_t, char, unsigned char, etc. Doesn’t matter. The encoder accesses it only as bytes. Personally I'd prefer a specific type parameter (e.g. const char* ), then require the caller to cast (safely) if necessary. But perhaps I'm missing something? 
Was `std::vector&lt;bool&gt;` already mentioned? It has bitten me in the past, when I wrote algorithms over `std::vector&lt;T&gt;`.
Not that I suspect it matters, but your decoder isn't equivilent to the branchless one in terms of signature. I'd be curious how the performance differs if you modified yours to return a pointer instead of taking an offset reference.
&gt; Why does this library need C++17 support? I.e., what C++17 features do you deploy? The big ones are std::variant&lt;&gt; and to a lesser degree std::optional&lt;&gt;. I also use a few fold expressions, std::make_from_tuple&lt;&gt; and I suspect that constexpr if will come into play during cleanup. There's also a handfull of TMP tricks I pulled that just worked because of C++17, but I'm not 100% sure. At the end of the day, I could refactor to C++14, but it would be a substantial pain. That's really been my takeaway from writing a library in C++17: it doesn't allow you to do brand new things like C++11 and 14 did. It's just a lot easier. If you look at the accumulated header file [here](https://github.com/FrancoisChabot/abulafia/blob/master/include/abulafia/abulafia_all.h), the entire thing currently fits in under 3000 lines of code. And there is still a bit of DRYness to apply. &gt; How long have you been working on this library? I wanted to do something similar but I have a busy schedule. Design-wise, that has been trotting at the back of my head for years. I did prototype a few different approaches over that period, so when I sat down to write it, it went fairly fast as I knew were I was going. I'd say I worked about two to three weeks on this iteration, part time. &gt; What kind of parser is it under the hood? Recursive Descend I suppose? Kinda-sorta. It's recursive-decend, but everything is coroutine-based. So it will depend on the type of datasource you provide. If you give it a single-buffer datasource, the compiler (GCC at least), crunches it down to a greedy Recursive Decend. However, if you use a multi-buffer data source, and drip-feed it one character at a time, it will be effectively a hierarchical FSM parser. Realistically, if you feed it packet-sized buffers, it will behave more like the former, but with the resumability of the later. That's why the Result type is SUCCESS|FAILURE|PARTIAL. That's actually why I need std::variant&lt;&gt; so badly (and led me to interesting drawbacks, such as [this](https://stackoverflow.com/questions/46147828/is-there-a-way-to-reset-a-stdvariant-from-a-known-alternative)). When dealing with `a &gt;&gt; b &gt;&gt; c &gt;&gt; d`, only one of the 4 branches is active at a time. So the stateful storage of that parser needs to account for that. 
True. The way it returns encoding errors is also different. I tried as you suggested. For ASCII input there was no difference, but with Chinese input it actually gets a little faster: 5.104292s. That's somewhat unexpected, which once again stresses the importance of measuring... 
I don't think so. Given what it does, its already pretty simple. The complexities come from the need to always re-enter member operator() on an asynchronous continuation. 
As I said: If those are none-issues for you, then go for it.
Think about bufferoverflow/hacking attempts with fuzzy input. That's not so uncommon in real world applications
Nice set of measurements on a real world workload with the various clang/gcc compilers and a smattering of compiler switches. Unlike some other benchmarks that go on and on, this nicely summarises the results in a few graphs.
This is why branch prediction was invented 
https://wandbox.org/permlink/9PKW26fFrJXLdzrO Variant dynamic dispatch 1.02337 seconds. Calculated value 773628304 Virtual dynamic dispatch 2.21205 seconds. Calculated value 773628304 This is why I use modern C++.
&gt; https://wandbox.org/permlink/9PKW26fFrJXLdzrO &gt; &gt; &gt; &gt; Variant dynamic dispatch 1.02337 seconds. Calculated value 773628304 &gt; &gt; &gt; &gt; Virtual dynamic dispatch 2.21205 seconds. Calculated value 773628304 &gt; &gt; &gt; &gt; This is why I use modern C++. 
https://wandbox.org/permlink/9PKW26fFrJXLdzrO Variant dynamic dispatch 1.02337 seconds. Calculated value 773628304 Virtual dynamic dispatch 2.21205 seconds. Calculated value 773628304 This is why I use modern C++. 
https://wandbox.org/permlink/9PKW26fFrJXLdzrO Variant dynamic dispatch 1.02337 seconds. Calculated value 773628304 Virtual dynamic dispatch 2.21205 seconds. Calculated value 773628304 This is why I use modern C++. 
https://wandbox.org/permlink/9PKW26fFrJXLdzrO Variant dynamic dispatch 1.02337 seconds. Calculated value 773628304 Virtual dynamic dispatch 2.21205 seconds. Calculated value 773628304 This is why I use modern C++. 
I almost missed that this was from the tiny window guy. Keep up the good work!
I almost missed that this was from the tiny window guy. Keep up the good work!
thanks mate! i'll try
what changes made LLVM 5.0 so much faster for those benchmarks?
I think this is intuitively expected that always covering all possible alternatives is slower than flushing the pipeline in a relatively infrequent case of branch misprediction. More work is being done in vain than just what would be in the pipeline.
Bad example. The difference in runtime comes from the 1000 separate allocations in the virtual dispatch code. Heap allocation is obviously slower, nobody disputed that. Note that you initially clamed (emphasis mine): &gt; Variant **visitiation** is a lot **more performant** than virtual tables Anywho, I went ahead and rewrote the code such that the vector allocations are not being measured but only the visitations (10000 entries this time). Lo and behold, virtual is marginally faster now: Variant dynamic dispatch 0.050252 Calculated value 479844304 Virtual dynamic dispatch 0.047153 Calculated value 479844304
Thanks for this encouraging comment. Don't hesitate to let me know if you'd like to read about something in particular!
Thanks, this was quite informative. FWIW I also always found that gcc compilation speeds were better than clang, which seems to be contrary to conventional wisdom. It would be interesting to add compilation speed benchmarks for `-O0` to your graph, if only as a baseline.
that's only because you do much more allocations with the "virtual" cases. If you only measure the actual "visitation" pass, the virtual function method is faster: https://wandbox.org/permlink/iciDCo7bdaTyINWT Variant dynamic dispatch 0.377879 Calculated value 773628304 Virtual dynamic dispatch 0.197864 Calculated value 773628304 and stays so even at high optimization levels (-O3 -flto -fipa-pta): Variant dynamic dispatch 0.0208 Calculated value 773628304 Virtual dynamic dispatch 0.011091 Calculated value 773628304 
None of the problems I pointed out had anything to do with performance, but thanks for providing this additional information. Again, I would call this an additional technique, not a replacement. It's appropriate in some cases, but certainly not all, and maybe not even the majority.
Exceptions are only for exceptional situations, while code like above may *sometimes* appear in non-exceptional scenarios. Yes, it is rare, but it is not something non-existent.
This is basically testing the time taken to perform heap allocation vs creating variants on the stack. I'll work on a fair test when I get the time. What you asserted about was a comparison between visit and a virtual function call. You can't include creating the objects in there - that's moving the goalposts to Mars. It may well be that *for your particular use case* this is the right thing to do, but it says nothing whatsoever about the general case. 
I thought that overflows on signed values are undefined behaviour in C++? As in, no guarantee what the output or side effects are?
I don't see how malicious input would be an issue here: - the decoder always advance at least one byte, which also happens to be the minimum it can advance in general case (ASCII), so you cannot cause it to loop infinitely, - the decoder returns at most N codepoints, which also happens to be the maximum number of codepoints that it can return in general case (ASCII). Therefore, you need to be willing to spend at least N rounds and use at most N codepoints for valid inputs and no invalid input can cause you to use more rounds or more space. 
Apart from arithmetic generally being a bad idea on unsigned integers, a big part of what makes signed vs. unsigned so deadly in C++ is that conversions between signedness are implicit. This ends up being disastrous in cases. While the preferable solution to me would be to not have the implicit conversions, at least signed types make it easy to throw in an assertion.
The biggest issue with callbacks is the called "callback hell". See this http://callbackhell.com/ This link talks about JavaScript, but the basic problem and solution (continuations) are still valid in C++. 
Which is one reason why they might be faster. unsigned overflow *has* to follow C++ semantics even if the hardware would otherwise offer a faster variant.
I think that has less to do with architectures. Signed integers just have more undefined behavior that compiler writers can exploit. 
 Callbacks are continuations. An API can use a traditional continuation by taking a callback or returning a [future](http://en.cppreference.com/w/cpp/thread/future) leaving it up to the user of the API to do "traditional callback" with .then() or with modern stuff with "await" stuff in C++17. Its all about doing call backs without blocking current thread. 
I would love to see C++ remove the implicit conversions, they have nothing but trouble for me.
The Eigen FAQ has a good discussion of why they use signed types as their index values, and a couple of links to videos. http://eigen.tuxfamily.org/index.php?title=FAQ#Why_Eigen.27s_API_is_using_signed_integers_for_sizes.2C_indices.2C_etc..3F
I like implicit conversions sometimes for the purpose of removing reundant information that can clutter up code. For example, it would be pretty bad in Java if `IFoo foo = new Foo();` didn't work without an explicit cast, including functions taking `IFoo`. However, C++ is definitely in too deep with them, to the point where they cause all sorts of problems. 
Somebody has posted this in r/cpp but the decoder is written in C. This explains the type choices (the use of `void*` instead of `const char*` is explained in the blog post -- the author wanted to allow users to decode `uint8_t`, `char`, `unsigned char`, etc. buffers). Also, the author *did* measure, and decided that using a DFA-based decoder would be a better idea in practice; this was just for funsies.
I watched a previous version of the same talk. It kind of goes somewhere, but doesn't do a good job. All it needed was an introduction and some examples!
That looks cool, you should add support for [MIOpen](https://github.com/ROCmSoftwarePlatform/MIOpen), so it can be used on other GPUs besides nvidia's.
But that is again using a function pointer (GCC implementation).
&gt; The encoder accesses it only as bytes. then use [std::byte](http://en.cppreference.com/w/cpp/types/byte)! 
Hint: Yes 
By LLVM, you mean Clang? Clang is the C and C++ compiler that uses the LLVM compiler infrastructure... but LLVM itself is not a C++ compiler.
But I suppose that future .then() continuations should be executed in a different thread other than the already completed task. But I think callback is not like that though. Could you please take this into account muungwana 
I'm the author of the article. I tossed your [traditional decoder into the benchmark](https://github.com/skeeto/branchless-utf8/commit/44c750d29b8db54ea2c981bcb495aa464ce4bddd) (and adapted it to C since that's what I use). Here's what I got with GCC: johannes1971: 374.666711 MB/s, 0 errors branchless: 513.333395 MB/s, 0 errors Hoehrmann: 468.000056 MB/s, 0 errors Simple: 376.000045 MB/s, 0 errors And with Clang: johannes1971: 350.666708 MB/s, 0 errors branchless: 620.000074 MB/s, 0 errors Hoehrmann: 757.333424 MB/s, 0 errors Simple: 365.333377 MB/s, 0 errors Two things to note: 1) The "simple" decoder is the traditional one that appears in the article. Unsurprisingly it's on par with your decoder. 2) The Hoehrmann decoder is now the faster variant listed later in his article, so it's faster than it was when I wrote the article. 
"Exceptional situation" does not mean anything. I can't believe people still repeat it. That sais exceptions are not even relevant for your snippet (but my fault for mentioning them). It is not relevant because a destructor solves it in C++. The key question is (and you failed to answer), is that the VB-style "on error go to errorlabel", was that your meaning? If yes, `goto` is a stupid thing to do in C++. If not, can you be more specific? 
That's how I understand it too. For example if the compiler can prove overflow with signed integers, that's undefined behavior so it can assume the code and conditions it occurs in will never happen for real. This allows significant code elimination and simplification in some fairly frequent cases. In contrast, unsigned arithmetic has no undefined behavior on overflow (behavior is defined as modulo 2^n) so the compiler cannot assume that overflow isn't intended, and cannot exploit that as an optimisation activity - it unreasonably has to assume that you wrote your code that way because you intended to. Not so long ago, the kinds of optimizations made for undefined behavior that certainly C and C++ compilers now routinely exploit were considered simply invalid - the overflow behavior (with its routinely depended-on *platform*-specific behavior) was routinely used as the example of *why* some seemingly obvious optimizations were invalid. I still like unsigned values. It's nice to know that when you call a function that expects non-negative values that the type enforces that it can only receive non-negative values - it doesn't need to do validation, at least for that issue, because the type system already makes that guarantee. Also, IMO using signed types IMO creates extra temptation to use special-case values (-1 can't really happen, let's use that for condition xxx, oh and -2 for condition yyy, and etc) which of course gets error-prone and over-complex - not if you wrap it in a specialized type, but the wrapped value isn't an `int` at all, signed or unsigned.). Also special-case values happen anyway, even in the standard - `npos` and of course `nullptr` (though pointers aren't really unsigned integers to C++, that's what they are to the hardware). Reality, though, undefined behavior is the new black, and slowing down development and runtimes with more frequent, more awkward overflow checks is the price of, ahem, allowing the compiler to optimise our code for us for free. And despite the way I've worded this, maybe it's the right thing. I seem to remember, back in my relative youth, getting angry and extremely sarcastic because compilers wouldn't automatically apply those optimisations just because of correctness in hypothetical overflow cases that obviously weren't intended so clearly, whether chickening out of those obvious optimizations or not, the behavior of the software couldn't be correct anyway. It's even theoretically possible that one of the echoes of complaints that reached some compiler writer somewhere was one of mine, inspiring him to flip the state of the least significant bit so now I complain about the opposite thing. Basically, whatever the compiler writers do WRT this, some people are going to hate it, including me. BTW - I'm not sure I'm doing the angry ranting thing quite right. 
Yes, ideally, the thread that produces the result in a future should be different from a thread that will run the continuation in .then(). Nothing is set in stone yet so its unclear how .then will work when standardized and i have seen some implementations of .then() that takes an argument that specifies on what thread the continuation should run. I have a library i call [tasks](https://github.com/mhogomchungu/tasks) that offers futures in Qt/C++ world where the result of the future can be retried with .get(),.await() and .then() I have a simple implementation where the result of the future runs in a background thread and the continuation runs on the current thread which ideally is the main/GUI thread. Example use case of the library that uses .then API is [here.](https://github.com/mhogomchungu/sirikali/blob/3c59fbd658f9419565e9fe4ed533d0a51bb8a5db/src/cryfscreateoptions.cpp#L43) In this case, a thread will be created to run a command and the result of the command will be used in the passed in continuation that runs on the GUI thread. 
These are super helpful. Thanx!
I used to be firmly in the unsigned camp, but I've slowly had my mind changed. I used to mock C# and Java for using signed integers for everything, but I'm slowly coming to realize that it was the right call. &gt; Is the problem with unsigned values just that we often want to compare the sizes to signed values - and so the comparison can get messed up? I think this is a big part of it for me. Calculating difference, having a negative delta (for iteration purposes), etc. Running into so many signed vs unsigned situations made me realize that having unsigned sizes/indices wasn't really getting me anything, but I was _losing_ a whole lot. A size of -3 doesn't make sense, but neither does a size of `UINTMAX - 2` most of the time.
&gt; How r u gonna use virtual functions with zero inheritance ... You build your own thunk table. It's sometimes even faster and usually takes up less program space (rtti increases size even if you never apply it). `boost::function`, predecessor to `std::function`, was made this way and the reasons why are documented. Also give a search for "cooperative visitor".
This link is excellent and really hammers home the reason to avoid unsigned ints.
Hey Thank you very much Let's see how .then ( ) will be standardized, https://github.com/STEllAR-GROUP/hpx - This runtime executes continuation on the new user-level threads
Not necessary. Take a look at this... Granted, Chandler is a compiler writer, but he does shows the facts: https://youtu.be/yG1OZ69H_-o?t=41m27s By the way... I'm not saying: Do this. I'm just explaining why signed values are considered a better option.
That's the beauty of C++, it's optimal for many kinds of problems. There are other *modern* architectures that aren't x86 that have tight constraints.
&gt; I thought Conan was a pure package manager so you still need a build system like cmake + ninja/make/msbuild. So Conan helps you version your pre-built artifacts kind of like a cache. Yes, that is true, conan is not a build system, so you still use any build system you want &gt; I also assume that a cmake + Conan solution you would need more Code. Conan is in python and cmake custom language I assume some data is duplicated. Conan indeed uses python to code the package recipes, but it does not implement a cmake custom language, or any kind of DSL in cmake. What it does is to declare all the variables you might need, like include paths, library paths, in a "conanbuildinfo.cmake" file (or in a .props file for visual studio, etc), so your CMakeLists.txt can just include the file and use that information. Some macros with convenience setup behavior are also included in "conanbuildinfo.cmake", but they are not related to the build system at all for your build. &gt; We often have to change debug flags library by library to debug problems as the whole game can’t be run in debug. Conan support the concept of installing different packages with different settings. So given you want to debug just one of the libraries, and by default, only Release version are cached, for some reason: $ conan install . -s MyLib:build_type=Debug -s build_type=Release --build=missing With the above, it will use all dependencies in Release mode, and only "MyLib" in debug mode. It will know that it has pre-built artifacts for those Release versions and only build from sources the Debug version of MyLIb. Just to try to clarify some points. I think that the work you did at EA is awesome, thanks very much for sharing in your talk, really interesting! 
Interesting that O2 and O3 look nearly identical for both compilers, and that Os looks comparable to these with LLVM. It would be cool to see in a followup: 1. The effect march=native and ffast-math. For a ray tracer I imagine (and isn't this actually a path tracer?) these would be a big benefit. 2. How does the Intel compiler stack up? A few years back the common wisdom was that the Intel toolchain would produce better code (on Intel hardware) due to better auto vectorization, but I'd be interested if this still holds. 
Iterators not being invalidated. Specifically, I implement `std::multimap&lt;float, T&gt;` where the float is cost and T is some type. Then I pull from `begin ()` but also keep iterators elsewhere and occasionally need to update the cost. To add some context, this is for implementing an "open list" in an algorithm like A* or something in that family. The float is cost (f-value, actually) and I need to pull in minimum order. Then T is some kind of state ID, usually a 32 bit int. Inside the world map (a different data structure) I store iterators into the open list so that I can reduce cost on those states if I find a better path to them. Usually these operations with multimap profile out to about 3-5% of CPU time, so not totally negligible, but also has never been a big focus of optimization for me. I know better data structures exist for this, but it's never been worth implementing one given how easy the multimap solution is. I'll have to check out multi-index, but I'm usually heavily dissuaded from using boost. 
It's interesting to see about these findings even when they're going against the 'conventional expectations'. I've recently been compiling my learning-at-home project with both g++7.2 and clang/llvm 5.0 with O0 in a VMware VM. I'm consistently seeing results that show that llvm/clang is usually around 10% (sometimes a bit more) faster than g++, but the executable does end up being larger...
There are also CPUs that only have unsigned compare. Building a signed comparison on top of that is slow and ugly.
That example seems actually worse than I expected it to be. 
It's not the comparison that's the issue, it's the semantics around what happens with overflow and underflow. With signed arithmetic those are both undefined behavior so the hardware can do what's efficient. But ignoring that, you can usually implement signed arithmetic in terms of unsigned operations already thanks to two's-complement.
Even if performance matters in your application, I highly doubt the performance of vector::resize does. At least when I overhauled our `basic_string` almost nothing I did in the resize path mattered, the only thing that did was things in the non-resizing path. In the example you linked, unique_ptr did generate more code, but [less instructions != faster code](https://channel9.msdn.com/events/Build/2013/4-329). 
Why should that be useless? It is actually a the most efficient way to handle a continuation. 
Why should that be useless? It is actually a the most efficient way to handle a continuation. 
That's quite a difference though! I'm surprised to see that the numbers are almost the opposite from what I got. What sort of input text were you using? Do you have any idea why the results we got were so wildly different?
It's not just resize; insert and erase being 2 other examples.
[This 2013 panel of C++ gurus](https://channel9.msdn.com/Events/GoingNative/2013/Interactive-Panel-Ask-Us-Anything) including Bjarne Stroustrup, Andrei Alexandrescu, Herb Sutter, Scott Meyers, Chandler Carruth, Sean Parent, Michael Wong, and Stephan T. Lavavej universally agreed that using unsigned ints for collection sizes in the original STL was a mistake; see the discussions at [12:12-13:08](https://www.youtube.com/watch?v=Puio5dly9N8#t=12m12s), [42:40-45:26](https://www.youtube.com/watch?v=Puio5dly9N8#t=42m40s), and [1:02:50-1:03:15](https://www.youtube.com/watch?v=Puio5dly9N8#t=1h2m50s). I particularly like the brevity and frankness of that last bit: "We're sorry!" [Google's style guide](https://google.github.io/styleguide/cppguide.html#Integer_Types) says "In particular, do not use unsigned types to say a number will never be negative." Stroustrup echos those same thoughts above. In practice unsigned integers leading to buggy code. Using unsigned types is like dancing right at the edge of a cliff. All integer types can wrap past their limits due to mathematical operations, and such behavior is rarely desired. With signed types, those danger zones are far away from typical values, whereas with unsigned types the danger zone is right next to the most commonly used value of all, zero. And unsigned types don't let you assert or test to ensure a variable's value never went below zero. This leads to bugs, as Stroustrup indicated in the middle segment above when he said unsigned types are highly error prone. 
Why is that any harder than inline a normal function?
The input in the benchmark has [a uniform distribution of lengths](https://github.com/skeeto/branchless-utf8/blob/ce3f8ac69ece118a88240dfa29554a279e926364/test/benchmark.c#L26), and so the length is unpredictable. As I mentioned in the article, this input is unrealistic and intended to inhibit branch prediction, favoring a branchless decoder.
Besides the fact that you didn't event turn on optimizations - you know that you are just measuring the overhead of dynamic memory allocation right? If you use dynamic allocation in both cases, dynamic dispatch is about double the performance of variant. Oh, and falling back to `clock` or directly calling win32 performance counters instead of just using `std::chrono` is really modern c++ ...
&gt; with the added benefit of not having to compromise your design just for testing purposes. This is actually so wrong it hurts my eyes to read it. Good code is easy to test, bad code is hard to test. If your code does something fancy internally use dependency injection to provide that functionality, test specific implementation of that interface in it's own tests, and for your class you just verify it calls the injected interface correctly... Before somebody complains about runtime cost of virtual just to enable testing: you can use policy based design if you are so worried about virtual. tl;dr 1) people who say you should not be testing private functions are right 2) dependency injection is great. 
It's not, the code just looks awful if you have to pass in references to lots of different member variables
I've heard of Rust, but don't know anything about how it differs from C++. How would you sell me on Rust?
I knew that resize could show a performance difference between vectors of unique and raw pointers, due to unique_ptr not being trivially destructivle (IIRC) - but why is there a difference when doing insert and erase?
Firstly, nobody I've spoken to is seriously considering anything in std2 directly replacing std1. std::stuff will be around for a very long time to come. But from those I've talked to informally, std2::stuff will likely come in chunks as big as a TS, and as small as a P-paper, likely be natively designed around recent improvements such as Ranges, Concepts, Coroutines and Parallelism, and will generally make better use of modern C++ than the twenty plus year old std1 can. More specific I cannot be except on the bits I'm involved in personally. I would hope Expected P0323R3 will go to LWG soon, as soon as it does I'll propose https://ned14.github.io/afio/ to become the File I/O TS under the std2 namespace. If AFIO is considered worth adding, it will come with a `std2::vector&lt;T&gt;` which doesn't have some of the pathologies the current STL allocator based vector has in my opinion. The committee may, or may not, like that approach to layering together an alternative way of implementing containers, one orthogonal to the std1 containers all of which of course remain. It's basically too early to say in detail. We need to definitely ship Ranges first which in turn requires Concepts in place, and have it working well in the major compilers. Then we can prototype stuff on top. So externally visible progress is likely some years away yet. Basically watch http://www.open-std.org/jtc1/sc22/wg21/docs/papers/, you'll see change coming there first.
A proboem is that `bind` has a bunch of traps and quirks and non-obvious behaviour. Like recursive bind, ignoring extra args, etc. Learning those and keeping them in your head has a cost. The same is true of lambda, but lambda has *more power*, so if you are going to learn one you should learn lambdas. And once you are a lambda expert, the marginal benefit of learning and keeping expertise with bind becomes teeny tiny, both personally and expecting it from your fellow coders. 
I was interested in the inlining question, and did a quick bit of experimentation. Obviously, it warrants much more time being spent on it than the fifteen minutes I used, but hopefully this is interesting. https://godbolt.org/g/BGFsg2 So here I am using std::bind and a lambda, and both are being inlined when called in main() - as expected. A side effect of using std::bind is that more code is generated overall, because code remains for the separate, bound function. Perhaps in the presence of LTO etc this may go away if the only use is the inlined bind call, who knows. Two things to try. First, change the flags to "O0" - the difference in the amount of code generated is now even more pronounced, with the std::bind version vastly larger in size, backing up another poster's experiences. Second, uncomment the include for iostream and the lines for std::cout. My intention was just to make the function bodies considerably larger. I believe that when these are added in, the lambda remains inlined but the std::bind turns into a call to the bound() method. I'm certainly no assembler expert and it's midnight, so pinches of salt required!
You got a good point! This remembers me how important it is to motivate people especially for this kind of topic and I am very sorry if I missed on that in my initial post.
Everything after the inserted or erased element has to be moved forward or backwards 1 at a time when using unique_ptr where basic pointers is a simple memcpy/memmove.
Doh, of course - thanks!
Why would you pass references to individual member variables instead of the this pointer (aka, make function to be inlined I also a member function)?
Others have already tweaked your benchmarks and added their results, but I will just add that having done my own benchmarking offline the amount of time taken to actually perform the virtual call or the std::visit *itself*, disregarding the work done IN that call, is so pathetically insignificant that it is never ever going to be something that causes a bottleneck in any program! I would suggest, therefore, that all of your impressions of the performance implications of using std::variant vs inheritance boil down to having used your classes on the heap and your variants on the stack, as in your benchmark. It's true that variant allows you to do this, and I have absolutely made that design choice for exactly that reason. The problem is generalising - one is not better than the other, nothing have been superseded!
Hmm, I fail to find a link or info page about the raytracer software that was used. Neither http://imagine-rt.blogspot.co.uk/ nor https://imagineraytracer.wordpress.com/ seem to contain links to a repo. What about it? Also do you think you could add timings for a `-O2 -march=native` with `LTO` build?
Just curious, why would you build with `O0`?
Wouldn't native coroutines simplify it (didn't find the time to have a close look at the code, so that is just a guess)?
This is the top-level comment for **meta** discussion. Reply here if you have questions or concerns about this post.
&gt;make function to be inlined I also a member function)? You can't really do that directly. If your class is just a normal class with a .h file, then you need all of your member functions to be declared in the .h, and you then can't inline them. Depending on the compiler there may be a way to get it inlined but as far as I know, that's not standard. You could pass in `this` as an argument, but if you need access to private members, you then have to declare the function a friend in the .h, which also can be ugly. It's really a weakness of C++ IMHO that you need to declare all of your privates in the .h, unless you work around it with a design pattern like PIMPL or private inherrtence, which have some issues of it's own. The point being, there are ways around this, but there's not a trivial and obvious way to always break up a long complicated function into multiple functions for clarity. I think the lambda is actually the best approach in many cases
I appreciate the reply but I'm afraid I still don't understand. How does one give `std::make_shared` access to the private tag?
What is the reason for having this thread in contest mode? It makes it difficult to see the latest post because I can no longer sort by newest. I have to collapse every comment until I find the newest post one.
I mean it kind of *looks* dirty but to me, in most cases, it looks less dirty than using `std::bind`.
I agree with most of your items but there are some useful math functions in the C library that C++ either uses directly or delegates to. Copying those into C++ seems like a waste of resources.
This was my first thought as well (at a glance).
I mean they kind of are. It's not like you can remove `new`/`delete` from the language or from some libraries, but you definitely should avoid them in most client code.
Faster compile times for debugging. No sense in spending time optimizing until you're getting ready to ship.
Screenshots was added to documentation, sorry for delay.
spirit is really heavy on compiler. What about your lib
During the talk, he mentions that they lock the L3 cache to a certain cpu, does anyone know how to achieve this?
Abulafia is definitely light for simple stuff. Every unit test actually compiles 4 different parsers (coroutine vs single-buffer and validating vs value-extracting), and they all compile in a snap (in both debug and release). I'm in the process of writing a full grammar for a toy language using abulafia, and while I'm not done yet, it's definitely starting to to take a toll already. My current ill-tested opinion is that it's lighter on the compiler than spirit, but still brings in a non-trivial amount of weight. It's hard to judge because just including spirit without even using it already adds a fair amount of strain to the compiler, so it's hard to be fair without doing a large battery of tests accross many different parsers. I'll definitely get around to it at some point. It "should" be in the same algorithmical range as spirit, but my library definitely has a lower up-front cost. 
I **exceedingly rarely** build with anything else because I want, first and foremost, a quick modify-build-test(debug) cycle. For that, I want good debugging information and the tests **I** run are quick because made for that cycle. Optimization is detrimental to good debugging info and build speed. My build servers, OTOH, do something else, and test servers run that.
**Company:** [Code Synthesis](http://www.codesynthesis.com) **Type:** Full time **Description:** We are developing [build2](https://build2.org), a next-generation C++ build toolchain (build system, package manager) and infrastructure (CI, distributed compilation). We are looking for what is probably best described as a *C++ Build Engineer*, someone who will be responsible for developing and running our build infrastructure (see [`buildos`](https://git.build2.org/cgit/buildos/tree/) and [`bbot`](https://git.build2.org/cgit/bbot/tree/) for the kind of projects you will be working on). You should have experience with the C++ build process on various platforms and be comfortable and interested in systems software development and administration. **Location:** Cape Town, South Africa **Remote:** Yes (but must be Cape Town-based) **Visa Sponsorship:** No **Technologies:** C++14, git, bash, virtualization (Qemu/KVM), Linux (including lower-level details such as systemd, btrfs, etc), Windows/Mac OS/FreeBSD (as build targets). **Contact:** Reddit PM
To me: getFuture().then(foo).then(bar).then(meaw); and getFuture().then([](){foo();bar();meaw();}); Seems to be the same if all those .then() in the first example take place in the same thread. 
Hi. Thanks :) I'd like to add support for more GPUs in the future, but I'm not sure I'll have the time to do it. But it's on the list. 
Thanks for the reply I didn't know about the conanbuildinfo.cmake. As I said I know very little about conan your points are really adding to things here. That seems like a good approach for conan as you can't just force this into all packages as they don't control cmake and might want to support other build systems. At EA we control both cmake like side and conan like side. So we can just integrate this saving you these 1 or 2 lines per package. Then there are things like masterconfig... where I don't really know where that would fit in maybe github submodules are close but quite different in the details as now you have to switch your version in git. For EA it is more like you where using this directory for zlib and now you are using this one when you generate your sln and other visual studio files. Maybe conan has something like masterconfig as well? But I am guessing the workflow would be a bit more as you would have to build the libs post them and then install them or something. Where with EA packages this would just be a changing what code I am building. Anyways nice talking with you. 
Thanks :) 1) I never tried to perform any comparison. From what I can see, the set of features is almost equivalent, with some advantage for tiny-dnn, although they don't support RBM/CRBM. They are solely focus on CPU whereas DLL is optimized for both. 2) I never develop on Windows, so I don't know if it will work. If we look at the support of the standard, it should work starting from VS 2017, but I know that several things are compiled differently by VS. I'm willing to make it compatible, but I most likely won't have time to do it. 3) There is already support for saving restoring a model, but I agree that it would be good if models from other libraries could be loaded into DLL. 4) No, I haven't done any multi-GPU training yet and there is no support into DLL for this yet. I agree that it would be cool. Tensorflow is only 1.0 since the testbed for this was installed during my thesis and I haven't had time to update the testbed since. 5) I used ETL because I wanted to write it myself. Moreover, at the time I stated this library, no expression templates library had any support for convolutions. If I had to choose one library, I would not have used Eigen but I would have used Blaze which seems better to me on all sides. I'm not a fan of Eigen. 
I really don't see the problem. Before, you have one big member function with some gotos in it. Afterwards you have the same code split into two separate member functions defined in the same file and the gotos replaced by function calls. If it is really beneficial, you have good chances that the code gets inlined back and if not, you can use things like __forceinline to make it happen. It is really simple. Or, as I said, you can put the code you are jumping to with the goto into a local lambda and then call that. Again, you have a very high chance that this gets inlined. 
That's true :-)
&gt; The same is true of lambda, but lambda has more power, so if you are going to learn one you should learn lambdas. I certainly agree with that, but its just like if you're goining to learn one of 'for-loops' and 'std::accumulate' you should learn for-loops.
Not really. For one, you probably want to pass on the results of foo, bar, meaw (which may be a future itself), to the next function, which would make your second option much imho less readable: getFuture().then([]{meaw(bar(foo().get).get()).get();}); Second, can execute on the same thread is not the same as must execute on the same thread. And most importantly, you can chain additional `.then`s later in the code (even in a completely different function). E.g. let's say you first start some asynchronous work, then ask the user for some input and then chain some additional work based on the user's response.
&gt; On the other hand: What would be the advantage of forcing the continuation onto another thread? If all involved threads are background threads then i guess it makes less difference what tasks is running in what thread. I do GUI programming and i do care what tasks runs in a background thread and what task runs in a GUI thread because i do not want the GUI to hang and the current wording of the standard that says " the continuation [...] is called on an unspecified thread of execution" just doesnt work with GUI programming because if the continuations updates GUI,then you want it to run on the GUI thread.
A good unit test, in my opinion, is a specification of how your class reacts to stimuli. Since a class cannot be stimulated directly through its private functions, it does not make sense to test those. They are just extensions of your public functions, which are testable (right?). That said, I don't have a personal rule against testing private methods. Instead, I just don't have private methods (at least, no non-virtual private methods.) File-scope statics do it for me.
&gt; two separate member functions defined in the same file This is the potential problem. If you need access to lots of your member functions then you have three choices: 1. Define a private helper member function in the `.h`. This may make it harder to inline (I thought it did, but I can't find a good resource on this that doesn't just punt and say "the compiler does whatever it wants".) 2. Pass all the members in to the `.cpp` defined (e.g. anonymous namespace) function. This is great if it only modifies a few members, but if there's a lot this becomes outrageously clunky. 3. Use a lambda and capture `this`. I actually can't think of a reason right now why this would be bad... my examples all came from times before lambdas where I defended using goto once in a great while
Thanks for including the raw data although it would be nice to see some basic stats on the results (variance/standard deviation especially). As others have mentioned I would be interested in seeing the numbers for LTO/PGO. I imagine the O2/O3 delta will be bigger with these enabled as the interprocedural passes can go to town then.
You seem to assume that functions only get inlined with high probability when they have internal linkage (i.e. declared static or put into anonymous namespace), which is simply not true. Besides the fact that the compiler detect many beneficial inlining opportunities themselves, most offer some mechanism to manually overwrite the compiler's heuristic (e.g. __forceinline). Admittedly, inlining (independent of how it is achieved) is not exactly equivalent to having a faked function call via goto, but I think you will be hard pressed to come up with realistic examples where you see a significant performance difference.
The differences in that example aren't due to `bind`. [Try replacing][1] the body of the `bind` version of `foo()` with: `return &amp;bound;` and you'll see almost identical code generated entirely without `bind`. Since `bind` here is doing nothing it gets entirely optimized away, and the differences with the lambda version are entirely due to using an externally visible function with an utterable type vs. a non-externally visible lambda with an un-utterable type. 1. `bound()` of course is a function with external linkage whereas the lambda is not externally visible. The compiler is obligated to generate usable code. 2. while `foo()` is externally visible in both versions, the fact that the lambda version returns an un-utterable type means that it cannot be forward declared and called anywhere else, so the lambda version doesn't need to exist at all except to create a memory location with a unique pointer value. Notice that the assembly for the lambda version of `foo()` doesn't actually do anything. The `bind()`/function-pointer version of `foo()` can be forward declared and used from other translation units, so the compiler has to generate a function that actually has the written behavior. If you give the functions internal linkage then you [get identical assembly][2] for both lambdas and `bind`. Disabling optimization of course does lead to much more code when using `bind`. This is the consequence of having a feature built into the language vs. implemented as a library. There are circumstances in which that matters, but there's a lot more than `std::bind` which you probably want to avoid if you want your code to be fast without optimization. `std::bind` might be one of the worst offenders, but without optimization you're going to be minimizing use of even things like _function calls_ in some places. Some other examples: - [with `std::cout`, but with internal linkage][3] - It is possible to get the optimizer to make different decisions: [same as above, but with `-Os` instead of `-O3`][3] [1]: https://godbolt.org/g/MWKtXt [2]: https://godbolt.org/g/7nU83j [3]: https://godbolt.org/g/G4KWDs
In contest mode, the employer posts are randomized so they have an equal chance to be seen. I can remove contest mode if enough people think it’s harmful.
You grant friendship to a factory function (or just have it be a static member) which then passes the tag to make_shared.
I think he meant by disabling the cores in bios. 
If you're debugging, you must be using `-g`, and then, the default I think is no optimisation. If your application runs too slow otherwise then maybe it makes sense to add `-O0`, okay. I wouldn't compare executable sizes of debug builds though. (How is that relevant?)
Yea, I didn't think we're talking about debug builds, which is a whole different story.
I guess he is just spinning it, but still disappointing to see somebody claim that SFINAE cr*p is nice design. 
No, your code is harder to read by regular developers. Additionally I think it is harder to [test](https://github.com/google/googletest/blob/master/googlemock/docs/CookBook.md#mocking-nonvirtual-methods). So while you are technically correct writing templates is harder so I would not spend time on it since I do not consider it worthwhile for regular development. But if you insist you should watch [this](https://www.youtube.com/watch?v=NVrZjT5lW5o) talk. 
IF the language doesn't say that std::array&lt;T, N&gt; and T[N] shall have the same size explicitly, then it is not supported, plain and simple. 
Yeah so? where in the standard does it say they should have the same size? where did the authors of the language say that sizeof(std::array&lt;T, N&gt;) should always equal sizeof(T[N])? 
my code is actually easier to write and read if you agree that most Python programs are more readable than C++98 programs while the inheritance based OOP (which has manually coded interfaces) is based on the nominal type system my code is based on the structural type system in modern C++ (95% auto + 4.5% decltype along with type_traits + 0.5% nominal for stuff like constructors and operator overloading), it's pretty much like duck typing in Python, the only difference is that structural typing works at compile time and duck typing works at run time the reason you think my code is harder to read is that you're reading "Python with pointers" C++ as if it's "C with classes" 
What the freaking fsck, you are correct!!!! to my amazement, it seems all major compilers do not unwind the stack if an exception is not caught!!!!!! I really thought it was otherwise, and for years too. My mistake. But, my opinion didn't change about ui_main, even after this: if the language says there should be an exception handler to unwind the stack, then let the user do that; don't catch exceptions for him, because you are altering a basic behavior for them. 
I vote for keeping contest mode.
concretely, you should know if something is "auto" or "auto &amp;" or "constexpr auto" or "auto &amp;&amp;", etc it doesn't matter if "auto" itself stands for "int" or "double" or "std::vector&lt;auto&gt;" or whatever, it's something that the compiler should take care of, not programmers 
I have hit the same issues as well in template-heavy code with force inlines. When I used MinGW GCC, it was manageable, but MSVC just fails to compile (hours of compilation). The problem was that to remove the __forceinline added lot of function call overhead that was very hard on our usecase (20% performance down). The function were used in simulation very often. Have you found some noticeable slowdown as well or the function are not called that often?
For selected Xeons with L3 Cache Allocation Technology (CAT) support, see: https://github.com/01org/intel-cmt-cat Otherwise, you can consider doing it the hard (manual) way with cache coloring (generally requires patching the kernel (virtual memory code), making use of the cache hash functions, likely not yet documented but commonly reverse engineered); some resources that may be useful for that: - https://github.com/CSL-KU/IsolBench#evaluating-isolation-effect-of-cache-partitioning, http://ittc.ku.edu/~heechul/papers/taming-rtas2016-camera.pdf, https://arxiv.org/abs/1707.05260 - https://arxiv.org/abs/1508.03767 https://software.intel.com/en-us/forums/intel-moderncode-for-parallel-architectures/topic/635185
you are delusional and I have no interest in curing you.
besides, u can always get the precise type of **anything** with decltype and type_traits if u really have to like auto p = .... // say the precise type of "p" is const T *, and T is unknown auto vec = std::vector&lt;std::decay_t&lt;decltype(*p)&gt;&gt;{}; // create a vector of T, even tho I don't really know what T is 
Regarding the package structure and layout, both are fairly similar. Conan also stores packages with paths including the version, so switching versions for the same library when you install conan dependencies, has the effect that the final "conanbuildinfo.cmake" variables just contain the path to the other version folder. It also abstract away the version control system, so typically only the package recipes live in version control, and the packages are generated in a local cache, and uploaded to servers. &gt; Maybe conan has something like masterconfig as well? Well, such concept only works well for closed teams or companies, but not something that can be generalized in the wild, both for OSS packages as well for many different teams and companies. So the conan approach for addressing this issue is: * Packages can declare dependencies to exact versions and version ranges of their dependencies * Masterconfig functionality is split in 2 different items: the project conanfile, that can declare dependencies upstream and overrides, typically used to resolve version conflicts, but can be perfectly used to act as a lockfile. Then, conan uses profiles, which declare the configuration, as settings (compiler, arch), options (shared/static), build requirement, environment variables, etc.. The workflow with conan is just change the version in your consumer project or package, "conan install", which can be given "--build=missing" to build from sources if binaries for your configuration are not already available. I didn't know about EA packaging system, but it seems conan shares some approaches with it. Maybe if EA packaging was open sourced a few years ago, conan wouldn't exist today :) There was a conan talk in CppCon last year, and also one this one: https://cppcon2017.sched.com/event/Bgsk/faster-delivery-of-large-cc-projects-with-conan-package-manager-and-efficient-continuous-integration, though the video is not live yet. Yeah, nice talk, thanks!
thanks for link, much appreciated
This is not portable. As soon as you write this code you're writing for specific C++ implementations. That's said, this is precisely the kind of things you would want to put into a collection of libraries like Boost - if you were willing to support, test, and cater for multiple C++ implementations. (e.g. Like Boost.Align, which you're using, or even Boost.Filesystem or Boost.Thread - there's no way to implement every single part of these libraries in pure, portable, standard-conforming C++, of course - but if you're willing to provide implementations for different platforms, the library is worth having in Boost).
| Note that the specific functions that you are using from Boost.Align (boost::alignment::aligned_alloc and boost::alignment::aligned_free) are portable and well-defined on every C++ implementation that has either a function for those, or every C++11 and above implementation which provides std::align (since boost::alignment::align will use a conforming std::align if one exists). | On C++ implementations which have neither, then it falls back to the custom (platform-dependent) implementation in boost::alignment::align (which is only for supported implementations, but a wide range of supported implementations). 
**Company**: [Ubimet](http://www.ubimet.com/), Meteorological Software Development **Role**: Teamlead for scientific software development in C++/Python **Type**: Full time **Description**: Ubimet is a leading weather service provider in Europe. We're experts in meteorology and issue customized weather forecasts for several million private and industrial customers. Together with our shareholder (Red Bull), we pursue the goal to be the weather service provider with the world's best quality forecasts. Our work impacts millions of lives, e.g. through our severe weather warnings or through weather forecasts for airports. We're looking for a teamlead for a group of C++/Python developers working at the intersection of big data, realtime services, and scientific computing. We offer a great work environment and opportunities for growth within an engaged, international team. **Location**: We're located in Vienna, Austria, the city with the highest [quality of living worldwide](https://en.wikipedia.org/wiki/Mercer_Quality_of_Living_Survey). While most people in Austria speak German, it's easy to get by as English speaker. English is used in the office, as ~50% of our developers do not speak German. **Remote**: No **Visa Sponsorship**: Yes **Technologies**: We use C++11/14 and rely heavily on Boost and geospatial libraries like libgdal, libgeos, etc. Python (both 2 and 3) is used for smaller, less performance-critical projects and for glue code. Our automated tests are based on googletest and pytest. We are staunch believers in open source software, and nearly all development machines run Ubuntu Linux. **Salary and Benefits**: The salary for this position starts from 42,000€ per year (~US $ 50,000) and is negotiable. The cost of living is way cheaper than in most international cities. Renting a decent flat costs about 500-700€ / month. Food expenses are in the 300€ per month range, without penny-pinching. Most of the taxes go into a retirement fund that is available even when retiring abroad. We offer 5 weeks of vacation and our employees usually take all of it. We take life-work balance seriously. Additionally, we have great social security, healthcare is essentially free, including dentists visits. Schools are good and free. **Contact**: If you're interested, please apply via our [hiring portal](https://career2.successfactors.eu/career?career_ns=job_listing&amp;company=C0016085212P&amp;navBarLevel=JOB_SEARCH&amp;rcm_site_locale=en_US&amp;career_job_req_id=2122&amp;selected_lang=en_US&amp;jobAlertController_jobAlertId=&amp;jobAlertController_jobAlertName=&amp;_s.crb=RCmPfOwoHb%2bh8Ehq%2bL56lQmwuBE%3d) or send your resume to info@ubimet.com. 
ITT: OP - Only MY WAY IS RIGHT and I AM NOT GOING TO LISTEN TO ANYONE. jk. jokes aside, op you should atleast make an effort to understand what other people are trying to tell you. Read your replies again, it seems talking to a wall will be much easier comparatively. PS - your second example is going to be optimized away :)
**Company:** Optiver **Type:** Full time **Description:** At Optiver, a proprietary trading firm, we need the most advanced technology and continuous innovation to remain successful as a global market maker. We build high-performance software that is used by our own traders to trade a variety of financial instruments on exchanges. Our story begins in 1986, with a single trader on the floor of Amsterdam's options exchange. Today, we are at the forefront of trading and technology, employing around 1000 Optiverians of 40 nationalities across offices on four continents. ****Jobs @ Optiver**** * [Graduate Software Developer](https://www.optiver.com/eu/en/job-opportunities/eu-510831?gh_jid=510831&amp;gh_src=6c0pe11) * [Low-Latency Systems Engineer](https://www.optiver.com/eu/en/job-opportunities/eu-737587?gh_jid=510832&amp;gh_src=7karyx1) * [Control Software Engineer](https://www.optiver.com/eu/en/job-opportunities/eu-804450?gh_jid=510825&amp;gh_src=d0gtnc1) * [And more](https://www.optiver.com/eu/en/job-opportunities/) **Location:** Amsterdam, Netherlands **Visa Sponsorship:** Yes **Remote:** No **Technologies:** C++14 on Linux, next to that C#, Python and Lua and FPGAs also form part of our technology stack. Want to learn more, [watch our CppCon talk from this year](https://www.youtube.com/watch?v=NH1Tta7purM)! Although optimization is important, it's not the only thing to do and certainly not a must! **Contact:** Please e-mail Jan Bernhart or Cátia Sousa at recruitment@optiver.com for any questions. For more information about our jobs and events, click [here](http://optiver.com/amsterdam/contact/jobsevents/).
It's not only about compile times. Sometimes inlining just produces slower code. Compilers don't inline anything for a reason.
I didn't reply to posts that I agreed to, that's not "not listening" I agree to everything NotAYakk said, both approaches has its own advantages from the cache friendly side I agree to also_stl that it's a personal preference thing and I thank him for pointing out Abbreviated Templates, which is something I would love to see in C++20, hopefully I agree to Crazy__Eddie, also_stl and NotAYakk and ArunMu that it's possible to write ur own virtual functions without inheritance, thanks to Crazy__Eddie for pointing that out as I didn't realize that earlier I agree to Plorkyeran cuz I think he also agreed to me I agree to kalmoc that if the down sides of templates don't really matter to me, there's no problem for me to use it and what, I'm supposed to repeat their posts all over again just to show I "listened"?
[Here's][1] a summary of reasons I've gathered for preferring signed over unsigned. [1]: https://www.reddit.com/r/cpp/comments/6ngkgc/2017_toronto_iso_c_committee_discussion_thread/dk9ssly/
True, with native coroutines the function could be decomposed but that would incur additional runtime overhead.
What are a and b? Either declare them as variables or characters. Take a look at the sidebar for code formatting...
`f &gt;&gt; b;` what is `b` ? 
declared them, still not working. :c
homework..?
nope, trying to figure out another way to solve an algorithm, did it before but with 2 vectors, now trying to do just with one. :D
still not working. other idea? 
and what are you trying to do? your code looks weird to me
In Greek it's incorrect to use accents on fully capitalized words but correct when only the first letter is a capital letter. A library implementing toUpperCase would need that info.
if you have 2 identical numbers on consecutive places, then you have a so called "plane". you need to display the length of the longest "plane" and the numbers in the plane. also if there are more planes, you need to display all of them for example. 4(length) 8 8 8 8 2 2 2 2
It will help you a great deal throughout your career if you develop a consistent indentation strategy.
Hum... I didn't remember going to stackoverflow, I thought I went on Reddit.
I commend you on the novel way you dealt with the tabs-vs-spaces issue, but nonetheless it is customary to do a bit of identation. 
This would be (rightfully so) closed within seconds on SO.
By the way, for cpp questions, there's a whole subreddit for them. You should post there instead. And while posting question, be more polite and complete. No one like to see "Help me with my easy algorithm" and then just a paste of badly formatted code. Take the time to format your code properly, find a nice title, explain your problem, what you're trying to do, what is the unexpected behavior and other things you think can help answering the question. For a high quality answer, there must be a high quality question.
Hi OP. try going on the cpp_questions subbreddit. Also try to ask a question instead of just posting your code. good luck
u need a queue, if the element is identical to what's already there in the queue, push it into the queue, else get the count of current elements in the queue, then pop them, and push the new element into the queue, the complexity should be o(n)
Correct, but that doesn't require random access, only a forward iterator.
Declared them as what? And you declare l twice. Is "int l[n]=b;" supposed to be "l[n]=b;"?
This line: int l[n] = b; attempts to declare an array of n ints. Probably 'int' shouldn't be there.
Expanding: signed vs unsigned aren't only about the values they support, but also about the behaviour (and the returning type) of operations. Unsigned is fine if you only do `+ * / &lt;&lt; &gt;&gt; &amp; |` stuff or if it loops around. If you need a `-` that does not loop around, get signed.
I agree, but that's been established in the OP's question. 
I think it's understood that if you override compiler heuristics you have to be really really sure of what you are doing
Wow, the people fighting in your thread are... special. "I've never needed that! So why would anyone else???"
you're right, but still not working, same error. :c
moved it here - https://www.reddit.com/r/cpp_questions/comments/759q92/expected_identifier_or_before_numeric_constant/
It's also a novel way of doing indentation.
TL;DR: more error prone vs less error prone, signed not actually fixing any overflow issue, just making it statistically less prone to happen, but it can happen anyway, so it's like putting dust bellow the carpet.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
This case is a huge logical mistake by the C++ standards commitee and Eigen. The problem is implicit conversions, not unsigned integers. A size cannot be negative. The delta of two sizes can be negative. unsigned - unsigned should result in a signed value. 
Modules are useless without support from build tools. Modules put a part of the dependency graph into translation units. `import x;` in a `y.cxx` file means that `y.cxx` depends on artifacts of compilation of certain `x.ixx`. In Make terms it's y.obj y.ifc : y.ixx ; c++ -c y.ixx x.obj : x.cxx y.ifc ; c++ -c x.cxx This means that either we (programmers) should copy all the imports to the make files, explicitly writing that one TU depends on another. Or a build tool should parse source files for all the `import module;`, make dependency graph and compile the source files. Or a compiler itself should work as a build tool (with parallel compilation). 
The article doesn't mention that MSVC had modules since 2015.
Yes but even in 2017 they are still highly experimental and hardly usable. I hope that with 2017.5 they will be come much better.
Inlining a lot of code can pollute the instruction cache and hinder with pipelining.
Well it could be resolved in similar way to #include dependencies which are generated by compiler nowadays most of the time.
Yes and? Like any other feature in the language it needs support in the tooling. 
First compiler support, then build system support. 
&gt; A size cannot be negative. But the size still sits on the number line, where negative numbers do exist. It may not make sense to have a negative value, but it's not the *value's job* to enforce its correctness. That's the key issue here: the unsigned types aren't there to "remove negatives"; they symbolize something else entirely: bit flags, resource handles, etc. The fact that sizes participate in other arithmetic is the reason they belong in signed values. The lowest temperature is -273.15 C. Is it _wrong_ to use a data type that also supports -274? Or do we mandate that all measurements are stored in Kelvins? Do we just eliminate signed values altogether and just tell the programmer to establish what the "proper min" is for a given number? It's simply fallacious to assume that unsigned values are the answer for values that "cannot be negative".
Not by everyone. And usually it's to bothersome to benchmark such changes so instead of compiler heuristics the "developer" heuristics are used =)
It's not clear to me how one can learn about `__forceinline` and decide to use it for performance reasons, while being completely oblivious of the caveats and possible drawbacks
Don't GCC-compatible compilers already export dependency information for C headers if so instructed? Why could the same mechanism not be used for modules?
Not all function call overhead is equal.
To optimize compile time. It turns out when something takes 50s to build, it seems much much longer than 30s ...
I don't see, why module dependencies should be so much harder than header or linker dependencies.
If you think the modules in 2017 are hardly usable, you haven't tried the GCC implementation (or listened to Nathan's CppCon talk.) This isn't to disparage Nathan's great work. It's only that he started far later than Jon Caves/GDR/etc. in MSVC. Modules are a work in progress but I think they are past the "hardly usable" state in MSVC. We have zero build system/IDE integration, but the compiler has significant support. 
The basic reason why is that just because unsigned cannot contain negative values, does not make them a good model of positive integers. It's hard to construct an efficient, usable model of positive integers: do you implement subtraction? If you implement subtraction, what's the type of the return? Is it a regular signed integer? Then the return type is different from the input types, so `-=` and `--` can't exist. Etc. And whatever a good model of positive integers is, it definitely isn't silently wrapping around on subtraction back to some huge positive number, whose value depends on something (the integer size) which should be an implementation detail in most situations.
Fixed ;-)
Header dependencies don't affect build order. Compiler makes a list of headers and compiles TU in a single run. Those header dependencies are used only for rebuilding when a header file changes. With modules there should be two passes: 1) get list of imports of current TU 2) build interface TUs of imported modules 3) build current TU Step (2) is recoursive. Also it requires synchronization for parallel builds.
**Company**: [Cruise Automation](https://www.getcruise.com/) **Role**: C++ Software Engineer, **Type**: Full time **Description**: We're the driverless car company. We believe in improving people’s lives by making transportation safer, more accessible, and more convenient. Our team is small and we move quickly. We’re currently testing a fully driverless solution on city streets in San Francisco. We're looking for smart, ambitious people to help build the world’s largest fleet of driverless cars. We are looking to hire C++ engineers across the entire company so please check out our [open roles](https://boards.greenhouse.io/cruise)! Check out [this video](https://www.driverless.id/news/video-analysis-new-gm-cruise-self-driving-video-shows-more-mastery-sf-roads-time-with-pip-proof-0176178/) of our car driving fully autonomously through SF! [How we built the first real self-driving car] (https://medium.com/kylevogt/how-we-built-the-first-real-self-driving-car-really-bd17b0dbda55) [Why testing self-driving cars in SF is challenging but necessary] (https://medium.com/kylevogt/why-testing-self-driving-cars-in-sf-is-challenging-but-necessary-1f3f7ccd08db) [How we’re solving the LIDAR problem](https://medium.com/kylevogt/how-were-solving-the-lidar-problem-8b4363ff30db) **Location**: San Francisco **Technologies**: C++ on ROS **Visa Sponsorship**: We can transfer Visas **Remote:** No remote work **Contact**: Anthony@getcruise.com
Other feature like what?
Quite happy that HFT guys know that 0-cost exceptions do what they say on the tin :-)
In my recent experience the most usable Modules TS implementation is actually in Clang. Specifically, I was not able to make modularized [`libbutl`](https://git.build2.org/cgit/libbutl/tree/) work with MSVC but could with Clang (see the demo at the beginning of my CppCon talk for a modules vs headers build). Though to be honest, I wouldn't call any of the current implementations *truly usable*. I personally have big hopes for GCC though. From trying to use modules with all three compilers I feel that MSVC is fighting a lot of "old compiler baggage" while Clang is burdened by its custom modules flavor (though there are advantages to being able to reuse existing blocks if one manages to make them fit). In this sense GCC doesn't have either of these burdens. So I would be surprised if it comes out to be the first with a truly usable Modules TS implementation.
There are build systems that support C++ modules. [`build2`](https://build2.org), for example, supports modules in GCC, Clang, and MSVC.
Easy. Read a blog article recommending to use it on all performance sensitive code and parrot the suggestion. There are thousands and thousands of developers working in C++-using performance-sensitive industries who are just day-to-day developers who don't really care enough to learn deep internals about architectures, compilers, or the language (not judging; some people have different priorities, e.g. might be a world-class expert on AI but a low-rung user of C++) or maybe they aren't given the time by their managers to do anything besides bang out features as quickly as humanly possible but oh also try to make the code run fast.
Fstrings in C++ or I riot.
Literally all of them; "tooling" includes things like IDEs, documentation generators, source code highlighters and indexers, and of course build systems.
Only yesterday someone in this forum suggested using the (u)int_fastxx_t types for additional performance over normal int - and the message was voted up by at least 3 people. If people believe that, why not believe in the magic of __forceinline? 
Why else would it have *fast* in its name? ^/s
No I have not tried other module implementation for now. But if I try to compile my relatively simple and small project that uses {fmt} lib as module then I get this with VS2017.3. format.h(3591): fatal error C1001: An internal error has occurred in the compiler. 1&gt; (compiler file 'f:\dd\vctools\compiler\cxxfe\sl\p1\c\moduleutilities.h', line 21) So may be saying "hardly usable" was wrong but from my experience right now it is not usable in relay projects. To be clear I find it great how fast Visual Studio evolves recently and would say thanks to everyone who is working on it ! Also it is hard to imagine that update 2017.5 would bring so much progress, but I really hope that this will be the case ! 
Yeah but the industry standard is cmake. No project would change their build system for modules. Btw, "there are" - which other build system support modules?
Not sure why that was downvoted; it's entirely correct. Headers don't normally affect build order. If I have two "modules" named `foo.cpp`/`foo.h` and `bar.cpp`/`bar.h` where bar depends on foo, I can translate both cpp files in parallel. Serialization would only be required if `foo.h` were a generated file, and then only the generation step would need to happen before translation; the cpp files would _still_ be parallelizable. Dependency modules must be built before dependent TU can be translated. Compilers cannot realistically compile modules on demand since there's no reliable mapping between module names and the location of module sources. When a `bar.cpp` has an `import foo` statement, the compiler must have the `foo` module ready to go. This in turn means that - unlike with typical headers - dependencies must be compiled before dependents. It's a lot more similar to build-generated headers than typical pre-written headers. We tend to just manually specify dependencies on generated headers, which isn't a huge burden since they're rare in most projects, but that is unlikely a satisfactory solution in a post-modules world. That in turn means that there must be automatic module dependency discovery step, which means either that the compiler needs to provide a `-discover-modules` flag of some kind or that the build tool has to do it itself (as build2 does). This step must run, generate dependency chains, and use that to build TUs and modules in a correct order. This introduces a lot of serialization which might potentially harm parallel builds (though probably not) and will harm the ability to do large-scale distributed builds, since more artifacts (built modules) must be distributed between nodes during the build process. Regular parallel shouldn't be harmed too much and may even be assisted; there will be lots of serialization between dependencies, but part of the point of modules is that it reduces "false" dependencies that are prevalent with headers, and building modules _sources_ is a separate step from building the module _interface_. It will definitely be quite possible to end up in a degenerate case, though; just make nearly every TU an module and make them into a linear chain of dependencies.
Does clang implement the actual TS, with module+import+export keywords?
I hope that all these module implementations go ahead and include the 'Transparent migration' facilities discussed in P0273 (page 10).
Sorry, I didn't mean to offend at all. I'm just saying that the MSVC effort is significantly ahead of the GCC effort. And we do have a fair amount of code relying on the feature now. 
&gt; Yeah but the industry standard is cmake. Recent poll by JetBrains (maker of the CLion IDE) had CMake usage at 30%. Hardly an industry standard. &gt; No project would change their build system for modules. I don't know about that: when you see a 3x build speedup, it makes you wonder... &gt; Btw, "there are" - which other build system support modules? I've heard Microsoft has some internal projects using modules in production so there must be other build systems. But, yes, AFAIK, currently `build2` is the only public/open source.
The language part is incomplete (for example, last time I tried, everything in the module interface purview is exported, whether declared as such or not). But once you get past that, the underlying machinery (symbols, module linkage, etc) mostly works (because a lot of it is re-purposed from their own modules flavor). With MSVC it is the other way around, the language-level part of Modules TS mostly works but things become rocky in the underlying machinery.
&gt; A recent poll by JetBrains Did they publish their metric and measurement approach?
This poll - https://www.jetbrains.com/research/devecosystem-2017/cpp/ 1) MSBuild - 37% 2) CMake - 34% 3) Make - 33% 4) Autotools - 16% 5) QMake - 11% others - less than 10% Welp to me it does like an industry standard. &gt; 3x build speedup We don't know. As of today there is no reasonably sized project to measure build speed change. There could be a speed-up on full build. Partial rebuilds mostly hang on linker.
&gt; We don't know. As of today there is no reasonably sized project to measure build speed change. FWIW, we have modularized the `build2` utility library and it has a bit over 30 modules (and about the same number of unit tests). While probably on the smaller side, it is also not exactly a "Hello, World" toy. For that we get about x3 build speedup with Clang. Considering that these are *very*, *very* early days (meaning none of the compiler vendors even tried to do any kind of optimizations), this looks quite promising.
That site would be a lot more compelling if it had a less ancient compiler. :-/
It would, indeed, I posted that before I realised that I couldn't in fact use std::variant on there. It's a great idea which I think will be very useful in future. 
A far more realistic problem of signed vs unsigned for index types is that you've now halved your indexable area for a single container. Sure you can be an idiot and write `if (a.size() - b.size() &gt; 0) ...` but that is solvable easy. How hard is it to write `if (a.size() &gt; b.size())`?. On the other hand if your types are enforced to specifically Int32 **regardless of platform size** there isn't an in-language solution to allowing more than ~2 billion objects. 
&gt; F-strings in C++ or I riot. I look forward to your detailed proposal on how exactly we do that. :) No, seriously; that's the only way it's going to happen. String interpolation is going to take some work and is going to require a particularly dedicated brand of engineer(s) to make it happen. Specifically in the case of extension and library integration; sometimes I might want to interpolate into a `std::string` and sometimes a `std::u16string` and sometimes a `std::basic_string&lt;mychar, mytraits, myallocator&gt;`and sometimes a `mylib::custom_nonstd_string`. And I probably want string interpolation to be constant expression if all the interpolated values are constant expressions which in turn means that we need a `constexpr` way of converting values to strings. All on top of arguing about the actual syntax of such strings and what concessions it needs to make to accommodate the prior items. Basically, all of how do we do something similar to this (interp syntax made up): constexpr value = array(1, 2, 3); constexpr auto str = u16`value = ${value}`my_string_view; static_assert(str == u16"value = 1,2,3"); This is all solvable, but not trivially solvable by any stretch of the imagination. 
Oddly enough, you can actually use -g with optimized executables and gdb, is something I've heard... Haven't tried that yet, though...
It is full of bugs too low in severity to make it into the fix list but still annoying enough to ruin your day. 
It's interesting to see some -O2 flags result in faster exe than an -O3 one.
Yes, depending on the optimization level, a lot of the variables and code-paths get optimized-out though. It's really useful for debugging things like games though. CMake calls it "RelWithDebInfo" configuration.
Did you communicate the full error details to MS? Maybe it can get fixed for 15.5 release.
&gt; For that we get about x3 build speedup with Clang. If that's when comparing from a "standard" build, that's depressing. PCH can give up to a *5 speedup in my experience in comparison (and unity builds can go up to *30).
&gt; Other feature like what? #include ? extern ? 
On my machine: 392 locales will print "4,2", 459 locales will print "4.2" and 2 locales will print "4/2". My point is that comma in not uncommon.
I'll take a shot: formatted-string:: &lt;format-func&gt; `&lt;interp-string&gt;` Where `interp-string` is a format string, with `${&lt;expr&gt;[:format-spec]}` interpolation items within. For an `interp-string` with `N` interpolation items, `format-func` must be invokable with `N+1` arguments, where the first argument is the input character array of `interp-string` matching the compiler's source encoding (ie. a UTF-8 encoded file will pass a UTF-8 encoded `char[]`). The `Nth+1` argument passed to `format-func` will be an instance of `std::interpolation_item&lt;T&gt;`, where `T` is the decayed type of the `Nth` `&lt;expr&gt;`. The return value of `format-func` will be the value of the formatted-string expression. `std::interpolation_item&lt;T&gt;` has several public members: - `value` of type `const T&amp;`, which is the evaluation of `&lt;expr&gt;` for the corresponding interpolation item. - `begin`, which is a pointer (iterator?) within the string content to the `$` symbol introducing the interpolation. - `end`, which is a pointer (iterator?) within the string content to the `}` terminating the interpolation. - `format` which is a character array matching the contents of `format-spec` in the interpolation, or empty array if none was provided. --- It's kind of based on the ES6 format string. It might look something like this: namespace std { template &lt;std::size_t N, typename... Ts&gt; std::string f(char (arr&amp;)[N], std::interpolation_item&lt;T&gt;... items) { return do_formating_magic(arr, items...); } } int foo(int value) { auto my_str = f`${value} + 2 = ${value + 2}`; } The `format-func` could be a template specialized on what kind of string you want. This still doesn't address `constexpr`: The problem is that the size of the string could vary at runtime, and we have no way of doing `constexpr` allocation (yet). This is just my quick ten-minute musing on the idea. It's definitely full of holes. Still, it might be a start?
I guess it is cool, but I got lost in the talk, esp around solo5 parts, so I guess it demands a bit more knowledge about OS stack than I have. :)
But then, PCH doesn't scale, imply manual management and is a mature technology. It's hard to compare with the current state of module impls, in particular since we can't yet use all our dependencies as modules (best case).
header file #include ...
It was an online poll. With checkboxes.
For clarity, the general idea you've got going there is that the actual interpretation is left up to a `do_formating_magic` function? Would that leave it resonable for the interpolated values to be expressions? auto string = f`twice value is ${value * 2}`; auto string = f`user's name is ${value_or(user-&gt;name(), user-&gt;userid())}`; I believe the approach of many other languages here (ES6 included) is to split the source string into segments of static text vs evaluated value, so you might instead have something like: template &lt;typename... Ts&gt; constexpr string f(Ts const&amp;... items) { return join(to_string(items)...)); } The ES6 version ([template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals)) instead takes an array of string segments as the first value and then passes the evaluated expressions' values in as the remaining arguments, which might make it a bit easier in some cases (e.g., to note which strings are literals and which are potentially user-supplied values, which could be useful to do things like output generation or SQL statement evaluation or the like where user-values should be escaped). A post-C++17 type system could potentially instead do that by differentiating between `constexpr` values though.
Firstly, the bit you actually want to watch is about ten minutes from the end where he proposes the new allocator model. I **absolutely** agree that allocators must stop being part of the type system. That was a severe design mistake from the beginning, and that mistake is multiplying, as the talk shows. His proposed alternative is better, but I still find it fussy. All these problems with allocators stem from the fact that STL containers can expand their storage automatically. I find that too a design mistake. If std2 containers were simply handed a capacity, and used 0-100% of that capacity only, all these allocator problems go away, and we get a much better result. You might then wonder how unfriendly non-capacity-changing std2 containers might be? But the std1 containers aren't going anywhere. They're still there for those who want auto capacity changing. I'm saying that if the std2 containers can't change their capacity, we can wave goodbye to allocators. People then simply call the pmr allocator by hand when they need to manually increase capacity, and execute a Ranged move from the old std2 container to the new. Problem solved, and without messy annotation via attributes of what kind of allocator hint to poke at STL containers.
`std::auto_ptr` does not implement what the article's automatic pointer does. When copy constructing or assigning from another `auto_ptr`, it takes ownership of the managed object, leaving the other pointer empty. It silently treated copy-construction and assignment as though it was a move operation even when not appropriate. That's why it was replaced by `std::unique_ptr`, not because it was prone to double deleting.
This should be higher up as it's the most complete yet concise answer. Point 3 is a bit incomplete, though. One could alternatively have overloaded `operator=(int)` or `operator==(int)`.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/75dyje/need_help_with_only_2_functions_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The `interpolation_item&lt;T&gt;` would have the evaluated value of the corresponding item, so yes, you could have arbitrary expressions inside. I'm actually interested in this idea and might write up something a bit more thorough.
I think what they should do is to change how unsigned works. You only allow it to go to `INT_MAX`, and if it goes over it you throw (or something else), and you automatically promote to signed any operation that could result in a negative number. Basically, it's a signed integer with checks to ensure it is not negative. Also, if you want to convert to unsigned you need to do it explicitly and it will check at runtime. For people who don't want this, make a new compiler switch "i-like-to-live-dangerously" to disable it. I'm not sure if it's in the cpp core guidelines, but any subtraction between unsigned should show a warning so this doesn't happen accidentally.
What locale uses "4/2"?
I've seen you mention this a few times and I have to disagree with you. This type of design is common in the games industry where memory micro-management has been taken a bit too far, and the containers are unbelievably hard to use. Programs are constantly asserting because some artificial limit was bumped up against, so someone goes and makes a number arbitrarily bigger and voila, we're back up and running again. For me, it's far far better to have the behaviour of vector, where it works by default, but will allocate at will. If one wants to bypass this behaviour, to avoid the quadratic growth, for example, it's possible by calling reserve ahead of time. Of course, not all containers have reserve, but maybe they should. 
They are called "fa" and "fa-IR". It is Persian, I guess. From [Wikipedia](https://en.wikipedia.org/wiki/Decimal_mark): "In Persian, the decimal mark is called momayyez, which is written like a forward slash". Crazy, isn't it?
Why doesn't PCH scale?
Terrible title; tl;dr seems to be: "why isn't the naming scheme actually static for importing modules and their actual names". Which if I'm right on that I can't see why its not so hard as doing just that.... mandate that the names are sane. #import &lt;module&gt; just goes and looks for &lt;module&gt;.[module_extension] and nothing else.
Yeah, always amazing for Americans.
This.
So, turn the compiler into a build system? :)
&gt; (or listened to Nathan's CppCon talk.) Is this on Youtube? 
C++ will never have modules. 
Yeah
That's not going to happen. The committee won't let it. :/
How will modules work with libraries that are currently configured with defines? Would we need a separate module for each possible configuration?
If it makes things so complicated to support, why not just disallow module names to be preprocessor macros? I think that's a valid tradeoff to make.
Have you talked to Gaby about this? Seems the problems could be solved by just stating that the evaluation of any module declaration happens before the preprocessor is run and that the filenames have to match the exported module name. It would be a shame if the modules TS dies, just because the authors didn't think or care about that aspect in time. Personally, I fear that the committee takes the approach of evaluating module statements after the preprocessor is run, which would be more natural, but also makes the build system's job much harder (alas certainly not impossible).
ok I completed overhaul #2 - patched up as many memory leaks as I could find, - used Unique pointers - removed the use of new and malloc calls - cleanup more of the code - removed the use of typenames with the GL prefix - improved performance https://github.com/ziacko/TinyShaders
A lot of hand-waiving as well as statements ranging from unsubstantiated to factually incorrect. I will only point the latter in order not to add even more noise. &gt; We will have interface modules, and implementation modules. No, there are no such things. You are probably confusing them with *module interface (translation) unit* and *module implementation (translation) unit*. Also note that you don't have to have implementation units. &gt; The entire goal is to give users a guaranteed exported interface (also known as a purview). No, module interface is not the same as a module purview. Module interface is a collection of exported names. Module purview is the part of the module translation unit (either interface or implementation) after the module declaration. &gt; There is no module hierarchy, no guaranteed single file module implementation, no de facto way of finding a module. &gt; Under the current C++ compilation module, a header is opened by the preprocessor (with guaranteed directories to search). Really? The standard guarantees the list? The current opaque header search semantics (and don't get me started on `""` vs `&lt;&gt;` differences) is one of the biggest pains to deal with in build aspects ranging from cross-compilation (no, you shouldn't search in `/usr/local/include`) to distributed compilation (what if I don't have an exact set of headers in exactly the same location in the remote host). &gt; With modules, there is no translation phase for creating the purview of dependent modules [...] Did you mean *module binary interfaces* instead of purviews? Generally, pretty much every use of the term "purview" in this post is out of context. &gt; a build system *has* to run the preprocessor No, it doesn't have to. In `build2` we have the ability to indicate that the module information in the translation unit does not depend on the preprocessor (which will be the case in most sane projects). In this case there is no need for a separate (full) preprocessor run. 
I totally disagree, and I think you couldn't be more wrong. &gt; But the size still sits on the number line, where negative numbers do exist The problem is that the language allows implicit conversions. Being in the same code with signed integers wouldn't be a problem if the language didn't have implicit conversions. &gt; but it's not the value's job to enforce its correctness. Yes it absolutely is. If a variable takes the value 3, 5 and 7, then it better take these values, else the program is illformed. Same with non-null pointers: it's absolutely the pointer value's job to enforce its correctness. &gt; the unsigned types aren't there to "remove negatives" Yes they are. &gt; bit flags, resource handles Which do not have negative values. Hence, unsigned integers exist to remove negative values. &gt; The fact that sizes participate in other arithmetic is the reason they belong in signed values. The fact is sizes shouldn't be used in other arithmetic except when converted to deltas or something else that can be signed. &gt; The lowest temperature is -273.15 C. Is it wrong to use a data type that also supports -274? No, because in this case the values allowed are -273.15+. If this was Ada, you'd be able to define exactly the range of a value, but then you wouldn't complain if the compiler didn't let you do arbitrary arithmetic on it, would you? &gt; It's simply fallacious to assume that unsigned values are the answer for values that "cannot be negative". You've got it totally backwards. 
Then fork and take over the world. The diktat must cease.
The OP writes: &gt; But I’m unable to do that because there’s no guarantee on the size of std::array. Which is totally bogus, since the code he writes compiles perfectly, so I don't understand where the "I'm unable to do that" comes from. 
You are comparing limited hacks that completely destroys whatever structure headers provide to a sound physical design mechanism that has a chance of actually improving the code structure, not only the build speed. Also try to setup distributed compilation with PCH or unity builds.
Let's see if I understand this correctly: If x.cpp imports module Y which is defined in y.cpp and the build system tries to build x.cpp before y.cpp then the Y module file doesn't exist yet because it would have been generated by compiling y.cpp. (corrections are welcome) And the solutions are either to manually specify the dependencies (yuk), have the build system parse cpp files (this never ends up working in my experience) or turning the compiler into a build system (and at this point developers collectively yell "no way!") So assuming we come up with a rule that module X is always generated by for f(X).cpp and resides in file g(X).module_extension, would it be a stretch for the compiler to automatically generate the module file if it doesn't exist but the cpp file with matching name does?
Doesn't MSBuild?
As someone that was using Turbo Pascal with its units, saw C++ as an alternative (C wasn't it even for MS-DOS), and used several languages with support for modules, the misunderstanding among the community and the way some are attached to a 60's build approach is quite surprising. I can only understand the problem when coming from developers that never used any other programming language on their life, in which case I see an uphill battle to make them understand the advantages of modules and improved tooling for library navigation.
No, you can continue using the preprocessor both in the module interface translation units as well as in the module consumer translation units. It's just the preprocessor macros do not leak through the module interface boundary. So in your case you could adjust the module interface based on the configuration defines. And if you need to "export" macros, then you simply put them in a header and let the consumer include. To put it another way, we already have a perfectly fine mechanism for exporting macros, it's called `#include`.
There is another option: the build system asks the compiler to extract the module dependency information similar to how it now asks for the header dependency information, which, BTW, is essentially a full preprocessor run. In the end I believe this is how it will be implemented.
To be fair, the fact that the STL got it "wrong" is a testament to how appealing the arguments are to have a size type be unsigned.
Well in any other language with modules there has been an integration of the compiler, linker and the package/module system meaning that the compiler and linker is aware to a degree of the dependency graph of what you are compiling. I can't see why that cannot happen in C++. Genuine question: Why is it considered a problem to have some knowledge of the structure of your code in your compiler and linker, today they indirectly have to have that anyway through the parameters passed to them right?
Agreed it is weird to my that this is not just a foregone conclusion / fixed at this point.
So they implement a string class with iteration on Code points, not grapheme clusters, and say that in the future we will need more than 21 bits to store code points. Are they really understanding the Unicode consortium documents ?
&gt; build system asks the compiler to extract the module dependency information similar to how it now asks for the header dependency information That was my initial thought as well, but there is a difference: Today if x.o doesn't exist you know for sure that you need to compile it. Compiling x.cpp to x.o generates x.d containing the header dependencies which will be queried in the future on whether or not recompilation is needed, no order dependency for which cpp files need to be compiled first is present. With modules you *must* generate y.module before compiling x.cpp which imports y which places a dependency graph on the cpp file compilation/generation. So it's either another full pass in the build system that performs the steps necessary for extracting the module dependencies, or have the compiler generate on demand if the necessary source file is in the path. Neither option is very appealing. Another problem is that if generating the modules is done as part of compilation (as opposed to a special preprocessing command) we lose quite a bit of parallelism in compilation. It's not hard to imagine a (synthetic and not real world) example where compiling one file at a time is the only option.
I've fixed the incorrect use of the word purview. As for everything else, my responses follow: &gt; No, there are no such things. You are probably confusing them with module interface (translation) unit and module implementation (translation) unit. Also note that you don't have to have implementation units. A module interface translation unit and a module implementation translation unit are declared in different ways from each other. They might as well be separate handling of modules (especially since a module implementation translation unit cannot export anything). &gt; Really? The standard guarantees the list? The current opaque header search semantics (and don't get me started on "" vs &lt;&gt; differences) is one of the biggest pains to deal with in build aspects ranging from cross-compilation (no, you shouldn't search in /usr/local/include) to distributed compilation (what if I don't have the exact same set of headers in exactly the same location in the remote host). The point of that paragraph is that I can get a list of headers from every compiler for dependency tracking. There is no such way for the compiler to provide this to the user under modules unless the compiler becomes a build system. Cross compilation is a nightmare unto itself, and better left to other discussions. &gt; No, it doesn't have to. In build2 we have the ability to indicate that the module information in the translation unit does not depend on the preprocessor (which will be the case in most sane projects). In this case there is no need for a separate (full) preprocessor run. If there are two things I've learned from working in the games and tech industries they are 1) There is no such thing as a sane project layout unless you've forced your users to conform to one 2) As long as someone *can* use something in a bad way, someone somewhere will use it in a bad way. 3) off by one error jokes are old and tired but show up when you least expect them. Jokes aside, as long as we give users the capability to do this, they're going to use it as an example of "Look at this crazy weird thing you can do in C++ that breaks everything!". I am still *not okay* with a separate tool running outside the lifetime of the compiler to track locations and places, with unspecified behavior that will differ from build system to build system.
&gt; In build2 we have the ability to indicate that the module information in the translation unit does not depend on the preprocessor What do you mean by this? Do you mean in your build system you can say that such and such module being compiled doesn't depend on it?
&gt; So it's either another full pass in the build system that performs the steps necessary for extracting the module dependencies, or have the compiler generate on demand if the necessary source file is in the path. Neither option is very appealing. Hence my post! :v
If one needs to generate module names using macros then one looks for a build system that supports it. If there isn't one then no one will do that. People can write `*((int*) 0x1234) = 0;` if they want to shoot themselves in the foot, I don't see where's the big deal. 
Yes, you can say (individually or using patterns) that the module dependency information in a translation unit does not depend on the preprocessor. In other words you don't do things like this: import MODULE_NAME_MACRO; 
&gt; If one needs to generate module names using macros then one looks for a build system that supports it. If there isn't one then no one will do that. "Well, the language supports it, but no build systems do, so who cares?" If we're going to allow it in the language, I would hope that our build systems support it. If we don't expect our build systems to support it, than we should probably just disallow it. &gt; People can write *((int*) 0x1234) = 0; In an embedded world, code like that isn't really all that crazy.
If you don't see why running a separate tool that is not defined by the language, specification, or whose behavior is implied from either is *kind of messed up*, then I don't know what to tell you.
But then the problem as I see it, requires that your programmers then never go out and do this without fixing the build system. I would generally not ever assume my programmers actually understand the build system, as they so often just don't want to. I know entire projects with tens to hundreds of people whose builds are managed by one or two people. I suppose I could go to them and in a small seminar about the switch to modules, tell them "never do this" but I don't know that I trust them. As it is I've made our cmake such that the most they need to know is how to add another line for any files they've added.
&gt; A module interface translation unit and a module implementation translation unit are declared in different ways from each other. They might as well be separate handling of modules ([...]). I am not sure I understand what you mean here. An implementation unit is where you *can* (note: *can*, not *must*) put your implementation details. But if you prefer to keep everything in a single file, you can: a module interface unit can (unlike a header) define non-inline functions and variables. I really don't understand what's the problem here? Do you want the separate implementation units to be banned so that folks (like myself) who think it is a good idea to have them cannot use them? &gt; The point of that paragraph is that I can get a list of headers from every compiler for dependency tracking. There is no such way for the compiler to provide this to the user under modules unless the compiler becomes a build system. I don't understand why it has to become the build system to provide this functionality? Can you explain? &gt; I am still not okay with a separate tool running outside the lifetime of the compiler to track locations and places, with unspecified behavior that will differ from build system to build system. This is a good example of a vague (but catchy-sounding) statement that I think only adds to the confusion.
Can someone please explain to me what is so terrible about the compiler being a build system?
&gt; Today if x.o doesn't exist you know for sure that you need to compile it. Compiling x.cpp to x.o generates x.d containing the header dependencies which will be queried in the future on whether or not recompilation is needed, no order dependency for which cpp files need to be compiled first is present. Yes, this is the trick/optimization most build systems currently use (and it's good to see someone is paying attention ;-)). It is not without drawbacks, however. For example, with this approach we cannot support generated source code as part of the main build stage (and often have to resort to *ad hoc* pre-build steps). This is, for example, the reason why we didn't go this way in `build2` and instead extract header dependencies (and generating missing ones) before compiling anything. Why did we needed this trick/optimization in the first place? And the reason is build speed: it was too expensive to preprocess things twice. The thing is, on todays hardware (mainly SSDs), the cost of preprocessing is actually negligible, a couple of percent of the complete build. In fact, preprocessing everything at the outset can actually speed things up! You can read more about this in [Separate Preprocess and Compile Performance](https://build2.org/article/preprocess-compile-performance.xhtml).
Thanks a lot for the comment. I will correct this part as soon as possible.
It would be interesting to have something like a minimal module build that does just enough to generate the interface files. E.g. if I only export function declaration from module A, compilations that important A should not have to wait until compilation of module A is complete and it might not even be necessary to wait until transitive imports are compiled if you don't re-export anything from them.
The default in `build2` is to not assume anything and thus preprocess each TU before extracting module dependencies. Which on the modern hardware will cost you a couple of percents in terms of build time. So perhaps it is a reasonable price to pay for not understanding the build system. Also note that if you mess it up (i.e., use a macro as a module name while lying to the build system about not doing it), you will get a build error with a pretty clear diagnostics.
I think in his CppCon 2016 keynote Bjarne mentioned that it would be nice to look into standardizing a package manager for C++ sometime in the future. However, currently, things are not mature enough so we have to wait. Remember, the process works best when standardizing existing, well established practices and not trying to theorize how things should be done. This is probably twice as true when it comes to the build toolchain.
No reason AFAIK; string_view isn't as integrated in the library as it perhaps should be.
I agree that theorizing on how things should be done can be harmful, at least if done in excess. However, wouldn't there be a case here for looking at how other language ecosystems are doing this ? Instead of magically waiting for more tooling to arrive to C++ ? I feel like atm waiting for more tooling to arrive to C++ is sort of a catch 22 type scenario. Since a standardized build system doesn't really show it's worth until it's adopted by a large % of the community and the C++ community is so divided that nothing less than a proposal from the standards committee backed by all major tools and compile vendors would really be able to get that large % using a single build system and package manager.
Is there actually any standardized language that also standardizes the build system? Actually standardizing tooling as opposed to having a de-facto standard tool that is driven by some organization is a monumental task. Also, if the speed of evolution of c++ is any indication, I'd rather not limit tool development by the speed at which people are able to introduce changes to the c++ standard.
&gt; This is, for example, the reason why we didn't go this way in build2 and instead extract header dependencies (and generate missing ones) before compiling anything. That's interesting, I hadn't heard about `build2` before. Reading the "How is this better than CMake (or Meson)?" part of the FAQ was rather interesting as I'm currently using Meson in my personal projects. Gotta look more into build2. &gt; it was too expensive to preprocess things twice. The thing is, on todays hardware (SSDs), the cost of preprocessing is actually negligible Sorry I'm having a hard time understanding this, if preprocessing is negligible how can it be too expensive?
It used to be expensive on computers with spinning disks and little RAM. Today with SSD and lots of RAM it is negligible.
ok i patched that one up and a bunch of others as well
&gt; I would generally not ever assume my programmers actually understand the build system, You're adding a new feature. It's not like you as a programmer actually have to check your existing code to see that it's compliant. If your programmers are so stupid that they can't understand things like "`import MODULE_NAME_MACRO;` is forbidden where `MODULE_NAME_MACRO` is a macro, then you should really get better programmers. I mean, I've been at C++ for decades and C before that, and I have never seen anyone write `#include FILENAME_MACRO` - and I'm not sure why anyone would want to do that. Certainly, it'd stick out like a sore thumb in code reviews...
ok I patched up as many memory leaks and file stream, issues as I could find and I used your tip to speed up file loading. thanks!
Well, would a de-facto standard tool that is developed by the committee not be essentially that, similar to how cargo isn't part of the rust specifications per-say, but there is a huge overlap between the people working on the specs, rustc and cargo. Granted, in my posting I specified a standardized build system, but you can easily replace "standardized" with "recommended" and you'd get more or less the same thing. Also, I feel like the speed at which C++ is evolving isn't that bad, considering new specifications seem to be created every 3 years, and with a tooling standardized tooling system you wouldn't necessarily have to stick that that same 3 year release cycle anyway.
Well technically possible usage of `first`, `second` and `matched` could prevent from direct replacement. It definetily should have at least operator to be casted to `string_view` though, which it doesn't.
To be fair, though, having to `insert` or `erase` often enough for that overhead to matter might mean `vector` is not the appropriate container. For most projects `vector&lt;unique_ptr&gt;` suffices because their only moves will be the infrequent `push_back` or `emplace_back` that requires a resize. I do agree on your general view about `new` and `delete` not being obsolete. C++ has always been about performance and zero-overhead abstraction so it has to allow people to manually manage their memory if they so desire.
&gt;If std2 containers were simply handed a capacity, and used 0-100% of that capacity only, all these allocator problems go away, and we get a much better result. That would pretty much destroy all use that containers have at the moment. I consider dynamically-sized containers to be a major strength of C++; languages without such facilities suffer badly (like Pascal with its 255 character strings, or C with its fixed buffer sizes everywhere). I, and I imagine others like me, deal with systems where containers vary in size from being empty (and have negligible memory cost) to containing millions of elements. Such containers occur on every level in the application, and right now _that is not a problem_, because all those containers scale dynamically to whatever size is needed. And saying "but you can still use old-style containers" hardly solves the problem of providing a more modern version of STL. What you are proposing is not an updated STL; it is something far, far less useful. I'll happily agree that it is a hard problem, but making pointless proposals like this is not the way to solve it. 
I really agree with you on this point. It's actually a really crazy situation. It took me a while to grok what you were saying though.
&gt;You're adding a new feature. It's not like you as a programmer actually have to check your existing code to see that it's compliant. I'm speaking more of future concerns here, not right now at the transition point. I'm sure I'll probably be the one to do the conversion when the time is right, I feel the tools are ready, and I understand modules enough. &gt; If your programmers are so stupid that they can't understand things like "import MODULE_NAME_MACRO; is forbidden when MODULE_NAME_MACRO is a macro, then you should really get better programmers. To be clear, my team would likely never do this. While they like to do cheeky things sometimes, only the ones who actually understand the build system would even think of doing something like this. I was using them as an example of a team of folks who mostly just don't know or care about the build system. I had to explain to a few of them that they didn't have to delete the build directory every time they added a file. (They're still new to cmake.) I hadn't even considered it until I saw folks talking about it, and then I realized "Oh hm, macro names could be useful for configurable module names." And I've absolutely seen people `#include FILENAME_MACRO`, and it's annoying every time, thankfully not in any projects I've worked on. I'll point out that thankfully, as pointed out by /u/berium the build system will be able to provide an error, which should tell whoever's trying something funky what's going on.
That seems fair then, I assume the error would be a compile time error about not finding a module with SOME_MODULE_NAME?
By nature, PCH is some kind of cache for the compiler. If you have a lot of code, you need to maintain what is the common code that most of the cpp files share. The more complex your application, the more heterogeneous, the harder it is to manage. The harder to manage the more resources you lose on it, which makes it hard to scale with the complexity of your application (so you see that only with big complex apps). Modules are designed to allow mostly the same thing than PCH but in a scalable way, as in automatically deduced balancing of what to compile or not, caching on the go. No need to maintain anything, you just organize code in logical components and the tools do the rest. You cannot do that with PCH.
There is a standard build system but programmers refuse to use it because they want to roll their own just like the standard library.
your use of [FILE](https://github.com/ziacko/TinyShaders/blob/2fbcb33bfe2862c25b54f283c823420aa53e7098/Include/TinyShaders.h#L458) API is not ideal because it doesnt use RAII forcing you manually close a file handle at the end of each block. A simple FILE class you can use to properly manage FILE resource handle looks like below. You can expand it to make it do all file operations on your program. ps: code was not tested and i am not sure if it will compile but it should give you an idea of what to do. class File { public: File( const std::string&amp; file,const char * mode ) : m_handle( fopen( file,mode ) ) { } File( FILE * handle ) : m_handle( handle ) { } ~File() { if( m_handle ){ fclose( m_handle ) ; } } FILE * handle() { return m_handle ; } FILE * release_handle() { auto handle = m_handle ; m_handle = nullptr ; return handle ; } private: FILE * m_handle = nullptr ; };
It was suggested at around 30mins that you can't use OpenCL/SYCL with Nvidia hardware - you have to use CUDA. From a quick google it seems that Nvidia have had OpenCL drivers for a number of years. Is Michael mistaken here or is there some nuance I'm missing?
The title is no good. The article itself is damn right. Module names are global unique IDs. With header files, a library would have `#include "foo/bar.h"`, and an application could use `#include "third_party/company-foo-2/include/foo/bar.h" or same "foo/bar.h". With modules it will be something like `import company.department.foo2.bar;`. Or longer. For object files, build tools put them in separate folders. Modules will go to a single place. src/foo/utils.ixx -&gt; obj/foo/utils.ixx.obj , ifc/company.department.project.foo.utils.ifc src/bar/utils.ixx -&gt; obj/bar/utils.ixx.obj , ifc/company.department.project.bar.utils.ifc 
The committee is not some institution that employs c++ developers and library designers, it is made up of volunteers. Therefore, it can not (and should not!) commit to develop a standard build tool. Instead, someone has to individually do that and propose the result of his work to the committee. Also, the reason the committee publications are relevant is *because* it is so conservative and waits for consensus from all interested parties. If it were to wield its influence to push some poorly designed solutions onto the community, all that would happen is that we go back to having 3 slightly incompatible compilers that cherry-pick the parts of the standard that they feel they can support.
In case of `build2` it won't even get to the compiler since the build system won't be able to resolve the module name to module interface file.
Ah, that makes sense, forgetting my build vs prebuild capabilities as I'm always in cmake land.
That build system being ?
Well, volunteers which contribute a lot of code to many os projects and are quite capable of building all sorts of programs. But I can see your second point,it may be a bit childish to think of the committee as being a "leader" when it really is more of a "mediator" between all interested parties and it's main goal should be keeping all those parties on board.
Given that every large organization has some way to build their C++ base which is probably unique: my guess would be that it is very hard to define a compiler/build system that everyone can agree on and use.
If you are interested in a package manager that attempts to address many of the issues you bring up, take a look at https://teapot.nz It's designed from the ground up to encourage small modular libraries.
Or even simpler: tell people not to do that because otherwise their build system will not work. Same with the complaint about fixed module paths. Is there anything in the proposal right now that prohibits compilers to specify a default lookup rule and tell the user that it is his problem (or his build system's) problem to tell the compiler where to look if he does not follow the default? Maybe I miss something but how do the problems listed prevent build systems from saying: if you follow those rules then your build system can manage modules for you. If you do not you have to do the work. Yes, it would be much nicer if the compiler could do that all by itself but given the different approaches to deal with large codebases I cannot see how it would be possible to create a compiler that is also a build system that everyone would use.
ok it's been implemented. thanks mate!
It comes from the fact that if the implementation makes `std::array` take up a ton of space, the stack will blow up at runtime.
Well it's certainly impossible to replace `std::sub_match` with `std::string_view`, because the former is a template while the latter is a class.
&gt;Oh, and lastly, it makes tooling that depends on the build system, such as IDEs, much harder to build or dedicated to a narrower segment of developers (e.g. you can only use CLion if you use Cmake) How so? CMake is very much able to generate project files for Visual Studio, XCode, GHC, KDevelop and Eclipse CDT. Most of these also support opening CMake folders directly, with VS and KDevelop even being able to use the recent cmake-server mode.
One more thing,the fileStream_t [constructor](https://github.com/ziacko/TinyShaders/blob/343b501dc75ebb412331d6f199b5acb0061c1474/Include/TinyShaders.h#L211) takes a std::string making these [.c_str()](https://github.com/ziacko/TinyShaders/blob/343b501dc75ebb412331d6f199b5acb0061c1474/Include/TinyShaders.h#L332) calls unnecessary. 
http://en.cppreference.com/w/cpp/string/basic_string_view
&gt; Actually standardizing tooling as opposed to having a de-facto standard tool that is driven by some organization is a monumental task. They should just standardize a D-Bus API or something like this :p 
patched that too
I think he meant that Clion implies CMake, not that CMake implies Clion
Glorious!
&gt; Module names are global unique IDs. Who enforces this? Is there a registry? Who maintains that? Does my compiler issue a diagnostic if I create a module that somebody else has registered a name for? How would it know? This not a C++ design issue. It's a community issue. It is entirely correct for the TS, which specifies language syntax and semantics only, to not address issues beyond that scope.
How about static_assert(L'💩' == 0x1F4A9, "Compiler lacks Unicode support"); This properly flags Visual Studio.
Maybe not a full build system, but a dependency analyser maybe? Something that produces a dependency map for the build system to consume? Of course, that could also be a separate tool...
&gt; Which on the modern hardware will cost you a couple of percents in terms of build time What about builds where source files are accessed over the network?
I don't see how this makes a compiler resemble a build system in any way.
&gt; Requires ruby 2.2+ [...] Stopped reading there. A C++ package manager shouldn't require anything other than a C++ compiler. 
The compiler already has awareness of some dependencies as it's used in build systems to determine which headers a translation unit depends on. You need to invoke the compiler with a special flag to make it output the header dependency graph. I honestly don't see how the suggestion is much different from what we already have.
Look, with headers I can have this: third_party/lib1/include/util.h third_party/lib1/src/util.cpp -- #include "util.h" third_party/lib2/include/util.h third_party/lib2/src/util.cpp -- #include "util.h" In application I write // app.cpp #include "third_party/lib1/include/util.h" #include "third_party/lib2/include/util.h" Libraries can use whatever filemanes they want. Applications can avoid name clashes by using different path prefixes. This is a design feature. Modules do not have such design feature. Authors of lib1 and lib2 should think of unique module names. Alternatively, they have to rely on preprocessor: // lib1/include/util.h module PP_CAT(LIB1_MODULE_PREFIX, util); This is a C++ design issue. C++ modules are not usable in a large project with many dependencies.
Ah yeah the .d files maybe a bit smarter.
&gt; If you have a lot of code, you need to maintain what is the common code that most of the cpp files share. hmmm... ? at least with CMake and the cotire library you can just do `cotire(my_target)` and it generates a PCH from the common headers you use.
That has nothing to do with Visual Studio but with Windows, as wchar_t is 16 Bits there, so 0x1F4A9 does not even fit into it.
wouldn't it be better to use C++11's u8 literals?
I guess the thing is though, these things need to be specified as part of the standard. If things working well rely on not being able to use macros in the import statement then it should be forbidden in the standard. Otherwise perfectly 'legal' code won't compile in people's projects, and that's not good enough. I can see where the author of this piece is coming from. I just don't see why we need to bend over backwards to support that particular use case. If we constrain the problem to simplify what build systems need to solve (so that they don't need to become compilers) then there is a reasonable path forwards. 
Isn't OP's implementation is endianess-agnostic? The shorter version is great if you don't care about endianess though.
It would, if Visual Studio did not assume that source code without a BOM is encoded in your system's code page, giving the following error: &gt; warning C4566: character represented by universal-character-name '\U0001F4A9' cannot be represented in the current code page (1250) on u8"" literals.
I use transparent comparators all the time. They're great. My only gripe with them is that it's not really obvious to someone who isn't aware they exist why the comparator class has a useless looking "using is_transparent = void".
This flags Visual Studio but Visual Studio with /utf-8 properly handles UTF-8 code, which is fine with me. Your code fails on "/utf-8"-enabled Visual Studio however. 
&gt; This type of design is common in the games industry where memory micro-management has been taken a bit too far, and the containers are unbelievably hard to use. Programs are constantly asserting because some artificial limit was bumped up against, so someone goes and makes a number arbitrarily bigger and voila, we're back up and running again. I wouldn't read too much into that when considering this. Firstly, we have 64 bit address spaces now. Secondly we have Coroutines. That enables options not available to C++ until now. My issue is with the **automatic** expansion of capacity. I don't think that's `std::vector`'s responsibility, it shouldn't be part of its design. But I'm absolutely fine that if capacity were about to be exceeded that a hook be called, just like with Alasdair's proposal, which would default to returning "no can do" but equally might also suspend the current coroutine, expand capacity and resume execution. My point is that we can think bigger than Alasdair's proposal, something less fussy than his proposal, something which takes better advantage of the new facilities. His proposal though is essentially right, just not in choice of form in my opinion.
Not yet, or at least Visual Studio (which generates the MSBuild) doesn't support making MSBuild files that do it. I've never tried to write raw MSBuild, but I imagine it wouldn't be fun trying to shoehorn it in if it's not go built in support.
&gt; That would pretty much destroy all use that containers have at the moment. I consider dynamically-sized containers to be a major strength of C++; languages without such facilities suffer badly (like Pascal with its 255 character strings, or C with its fixed buffer sizes everywhere). You get right that a `std2::vector` can allocate, on its own, from zero elements up to its capacity without issue? It's only when capacity is reached that there is a difference. &gt; I, and I imagine others like me, deal with systems where containers vary in size from being empty (and have negligible memory cost) to containing millions of elements. Such containers occur on every level in the application, and right now that is not a problem, because all those containers scale dynamically to whatever size is needed. If you don't care about cache locality and don't care about lack of fixed latency execution, the current containers have everything you need. &gt; And saying "but you can still use old-style containers" hardly solves the problem of providing a more modern version of STL. What you are proposing is not an updated STL; it is something far, far less useful. As I mentioned in the other reply I made above, I think we need to think much bigger. Calling malloc is sufficiently expensive that a coroutine suspend and resume is unimportant. Let's leverage that to implement dynamic resizing far superior to anything currently possible.
Seconded. Every build system and package manager I've read about use some weird dependencies. Even conan, which looks like a good competitor, is written in Python unfortunately.
What on earth are you referring to?
&gt; VS and KDevelop even being able to use the recent cmake-server mode. Don't forget Qt Creator.
From cotire's README: &gt; Using precompiled headers however is not without issues and may not work for some programs. Then it points to this page which shows how it does not scale: https://gcc.gnu.org/wiki/PCHHaters 
There's been a [proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0235r0.pdf).
I just spent maybe 10 or 20 minutes trying to read what's going on in that library...and it just amazes me that someone put in the time to make that library. I've only written a couple hundred lines of cmake functions and such and I already felt l was straining myself trying to do work. I understand basically what they're doing but dang, that's a seriously intense read. That whole file is 4000 lines. It seems like they're extracting the headers, probably by using the compiler to just spit out the headers of each targets source files? From there the documentation mentions that they're picking the ones that are outside the project directory. If I'm reading it right and making the correct assumptions than while this is technically scalable, it's highly heuristic based (is a header in the project directory, or not). This would fail pretty often if you're using small libraries to separate out your project and they're changing often. The nice bit about modules is that it doesn't require the heuristic to exist.
Is there anything stopping it from being rewritten in C++? Surely that's an implementation detail that can be fixed when the "right" build system has been agreed upon.
There was a proposal (p0506) to do this at the very end of the C++17 cycle, but it was not adopted because (a) it was very late, (b) there was no implementation experience. It will almost certainly be revisited for the next revision of the standard.
Well, I'm just lucky with them I guess :p though I think that anyways, a far bigger (in modern C++) contributor to bloat and compile time is template instantiation. Are modules able to solve this ? If I use std::vector&lt;int&gt; in 2000 cpp files, do I have 2000 instantiations of vector&lt;int&gt;::operator[] ? 
&gt; Look, with headers I can have this: ... Or you can also choose to do something entirely different. There's nothing preventing you from shipping a library that installs headers to `usr/include`, except that it's generally frowned upon. This practice is not defined in the C++ Standard. (It can't be; the Standard does not define how you name your files, what directories you should use, what classes should go in what files, etc. The Standard only defines what is valid C++.) We do this either by convention or because certain distributions or platforms require it. So, again... this is not a language design issue. It's a community issue. 
That is fan-freaking-tastic
&gt; The problem is that the language allows implicit conversions. Being in the same code with signed integers wouldn't be a problem if the language didn't have implicit conversions. I agree here. The languages fast and loose conversion is a source of many problems. &gt; Yes it absolutely is. If a variable takes the value 3, 5 and 7, then it better take these values, else the program is illformed. Same with non-null pointers: it's absolutely the pointer value's job to enforce its correctness. It better _at least_ take those values, yes, but there is no (native) data type that will _only_ take those values. &gt; Which do not have negative values. Hence, unsigned integers exist to remove negative values. This is a stretch. Bit flags decompose the integer into its base parts. It's no longer one value; it's 32 values. That's key to this discussion. Bit flags are not "positive values". And resource handles are not mathematical. Any given handle is neither greater nor less than another handle. They are simply unique. &gt; The fact is sizes shouldn't be used in other arithmetic except when converted to deltas or something else that can be signed. You're waxing a bit philosophical here. Sizes can and are used in arithmetic all the time. I'd argue this happens _more_ often than your unsigned aspect "protects" you from invalid values. &gt; No, because in this case the values allowed are -273.15+. If this was Ada, you'd be able to define exactly the range of a value, but then you wouldn't complain if the compiler didn't let you do arbitrary arithmetic on it, would you? ... Did you mean to say yes? -274 is below the min of -273.15. &gt; You've got it totally backwards. I used to be on your side of the fence and argue as you do. I've since shifted into working on my own programming language, and I saw problem after problem of using unsigned for sizes. You may think I've got it backwards, but that means the standards committee and compiler authors have it backwards too. An unsigned integer isn't a "non-negative integer"; it's a type that says "I want access to all bit-string permutations and modulo 2 arithmetic".
Yay! [Another CppCon talk](https://www.youtube.com/watch?v=oCi_QZ6K_qk) has emerged, and it relates to std2!
Right, and 16-bit wchar_t can't be used since 1996. But at least L'💩' could have been made a compile-time error.
I don't think so. It should be [listed with the CppCon tag](https://www.reddit.com/r/cpp/search?sort=new&amp;restrict_sr=on&amp;q=flair%3ACppCon) when it's uploaded. 
"properly handles" is a long stretch compared to what Linux has had for the last 15+ years. But it's a step in the right direction, that's true.
double halfsize = vec0.size() / 2; Eek, this gives the wrong result too. Better return a float instead just in case.
If it's going to be like nodejs, no thanks.
&gt; no formal interface specification (yet)) then sure. Concepts TS solves this, which will soon be standardized.
&gt; No, your code is harder to read by regular developers. Why is this the case?
I'm getting a bunch of unrenderable garbage characters in the code bits on that page... 
Yes, there are many options, shooting in the leg included. But realistically, what an average medium-sized C++ project does look like? To me it looks like Chromium, [which uses some two hundreds third party libraries](https://cs.chromium.org/chromium/src/third_party/), all in the same source tree, all under same build system. With modules it means that every module of every library has to have unique name. This is a real-life example and the C++ Standard fails to help here. What modules are intended to be - some nice thingy for writing hello-worlds? Or something that people will use in production? And why did you mention `usr/include`? Did you ever work on two or more projects which use different versions of same library? E.g. boost_1_a_b and boost_1_c_d? Also the hell is `usr/include` on Windows?
Yes, but I do not see why that would cannot be offered by compilers. Just because it is not in the standard does not mean people can agree to use something. -MMD is supported by a number of compilers, even though it is not in the standard.
I bet this would get less downvotes if it weren't for the terrible title.
#include "DECLARED_STRINGS_UTF_H" was a common pattern when some platforms only worked with literals of one or another type...
I like that you can get performance benefits from existence of transparent comparators without writing your own. Using `std::set&lt;std::string, std::less&lt;&gt;&gt;` for example gives you ability to perform `find` without constructing `std::string` from raw string literals or `string_view`s
I like that you can get performance benefits from existence of transparent comparators without writing your own. Using `std::set&lt;std::string, std::less&lt;&gt;&gt;` for example gives you ability to perform `find` without constructing `std::string` from raw string literals or `string_view`s
There interface of multi-index is heavily templated which definitely throws a wench into the usability, but at the same time when you need "indexing" it works without having to keep multiple containers in sync. In this case it's also possibly more efficient at updating the cost because in `std::map` you cannot change the key: you have to erase/insert. This implies removing the node and allocating a new one, and unless the map is caching free nodes will incur de-allocation and re-allocation. On the contrary, multi-index supports an `update` operation which will re-adjust all the indices the element is participating in without moving the element; and that's pretty cool.
I'm not well acquainted with this issue, but I find the article a bit confusing, and reading the comments doesn't fundamentally un-confuse me. Currently, the compiler itself will not act as a build system, but will let you export the full list of headers recursively included for any file you choose. In other words it gives you the basic hook point to figure out dependencies, that different build systems then leverage in different ways. Is this not part of the modules TS? Do you think it can't be part of modules for some intrinsic reason, or that nobody has addressed it just because they haven't gotten around to it? Also tbh the title and the tone were a bit more inflammatory then is really needed; nobody is trying to "kill" the modules TS, and surely it's expected that non-experts (on modules) on cpp reddit are going to get many important details of modules wrong.
It might be worth noting that the module _interface_ is different than the _module_ itself, in well-structured module code. A module might have a single `module.ixx` file and 30 `implementationN.cxx` files. Dependents only need that `module.ixx` (and its dependencies) compiled, not all 30 implementation files. This is what I was getting at with the "fewer false dependencies" bit. :) This of course still breaks in the template-heavy "header only" world with which so much of the C++ community has an unfortunate fascination, but it shouldn't severely impact well-structured code.
This is awesome. Thanks!
poop or bust! :D
vulkan
Well, there is [build2] (https://build2.org). It's not quite there yet, but maybe one day. 
Interesting, thanks. When it matters, I usually use a pool allocator to avoid high reallocation costs, but it often doesn't matter since weight updating is often fairly rare (really depends on the domain though)
Sorry, what's wrong with (u)int_fastxx_t ? Is it because narrower is faster (e.g. less memory used, allowing SIMD to be used) and sometimes wider is faster (e.g. not needing to clear the top half of reigsters to satisfy unsigned overflow semantics).
&gt;You get right that a std2::vector can allocate, on its own, from zero elements up to its capacity without issue? You get that I don't want to preallocate megabytes of memory, just in case I need to process more than a handful of values? And that's just for _one_ buffer; a typical application might have tens of thousands. &gt; If you don't care about cache locality and don't care about lack of fixed latency execution, the current containers have everything you need. std2 is about updating std. It is not about providing fixed-size containers for the game industry. Do I care about cache locality? Of course - but not to the point where I want to add my own custom allocators to every container, and also not to the point where I want to start thinking about what the right size is for every last buffer in the software that I write. I'd rather see it was the other way around: the default is the current behaviour, and if you want it to be different, the standard can provide things like a fixed-size allocator (i.e. it does exactly what you want). Considering that you are the person who wants to waste memory like there's no tomorrow, I'd say its only fair that you get to pay for storing an additional allocator pointer. &gt; we need to think much bigger Removing an absolutely vital feature is not 'thinking bigger'. And having to hack in your own allocators everywhere, because the default you chose is 'no reallocation', is a total disaster. 
This is the recommended way to include `freetype2` headers and it's used within freetype2 code itsefl. https://www.freetype.org/freetype2/docs/tutorial/step1.html https://git.savannah.gnu.org/cgit/freetype/freetype2.git/tree/include/freetype/freetype.h
That hook you want is already being called, that's exactly what an allocator is in the first place. And if you want a 'no can do' return, by all means write an allocator yourself that has that behaviour. And what's the point of using a coroutine for expanding memory? Why not just a function call? 
Some of the most common API's are DirectX 11, DirectX 12 and Vulkan. I only suggest using DirectX12 and Vulkan if you really want to learn graphics programming on a very low level.
You can be pretty sure that whatever build system they build would suck more than whatever build system you want to use. Then you'd have one more build system to argue about when you're starting up your project. As for packages, personally I use far fewer third party packages when working with C++. Boost and maybe a math library will do it for me. I prefer this, as I've been on ruby projects where package dependencies required two different versions of the language. That's usually about the time I start seriously thinking about throwing the whole thing away and writing it in C++.
One solution to the "where are my modules" problem I've heard is to have the compiler call back into the build system whenever it sees `module X` to get the path to the built module. This callback would either build the module and return the path or just return the cached module path. A possible implementation of the callback would be to add a `-module-callback="get-module.exe %name"` option to the compiler. This avoids both turning the build system into a compiler and the compiler into a build system.
&gt;Is a build system and a package manager something that [...] [is] only a "kids these days" type trend which will go away in the near future ? Speaking based on my experiences as a one-time Debian Developer, and fully expecting to be down-voted for this opinion: Dear lord, I hope so. IMO one of the most harmful developments in open source software in the last several years has been the invention of a new NIH package manager for every language under the sun (Python, Ruby, Javascript, Rust, Go, ...). The packages provided by these languages do not play well with any OS-native package manager. The language-specific package managers are basically oblivious to each other as well. They have basically no thought given to security (cf. node.js left-pad) as the Linux distribution native package managers do. I doubt that they have much thought given to license compatibility, either. If C++ standardizes a package manager, I can guess that for instance Python or Ruby packages using bindings to C++ libraries are unlikely to use it. Contrariwise, any standardized package manager for C++ isn't going to be aware of Python/Ruby/Node.JS/etc. packages either -- how could it? since they are not standardized, and therefore cannot be addressed in any meaningful way by an ISO standard. I can practically guarantee that C libraries will not use it, so for more than half the libraries I want to use -- being that they are written in C -- a C++ native package manager wouldn't help me anyway. Based on experience, I think (speaking now as an employee of a cross-platform proprietary software company, which software is a mixture of C++, old C and Fortran, and POSIX shell scripts) it is not likely that a C++ standardized package manager will help us much with deployment or license compatibility issues, either. And woe unto the first commercial software that uses that C++ package manager to add a dependency on a BSD-licensed 3rd-party library, for which an upgrade or a new dependency starts to automatically pull in (L)GPL'ed code. I admit that certainly the existing Linux distribution packaging model has fundamental shortcomings for ISVs. At the moment there are three possibilities for 3rd-party software vendors for Linux: (a) patiently wait and hope the distributions package it [not gonna happen for commercial software]; (b) package it yourself [once per supported distribution]; (c) ignore the distro packaging model and just ship something that the end-user (via our installer) can stick into /opt or wherever. My employer has gone with (c) for a long time -- and this isn't a big hardship to us, since we already have to do this on Windows anyway -- so I don't see that changing. The rise of cloud-based solutions and stuff like Docker will only push things further in that direction. The fact is, one major OS (or two, if you count OS X and ignore its unofficial solutions like brew) has utterly shirked its responsibility to provide an OS-integrated package management system. But rather than the various language authors working together to fill in this gap cooperatively, each language has re-invented its own solution instead. I can't blame them, since on Windows this was the path of least resistance. Then on Linux, the easiest thing to do is not to figure out how to cooperate with the Linux distribution package managers, but instead just to pretend they don't exist. That always leads to fun flame-wars between language authors and distribution maintainers :-) e.g. https://news.ycombinator.com/item?id=2059964 My plea to the folks in charge of C++: Stop the madness. Don't invent (and especially, don't standardize!) yet another language-specific package manager that will be duplicative on Windows/OS X and superfluous on Linux etc. Instead, expend that effort outside the standardization pathway, with Linux distribution package manager developers, with 3rd-party C++ library developers, and with build tool authors (GNU Make, cmake, autotools, etc.) to figure out how to better integrate package creation and management. Work with Microsoft and Apple folks (who already are deeply invested in the C++ ecosystem), and with the authors of the various language-specific package managers, to try to figure out a saner solution to package management on those systems. /rant
Real source code uses only 7-bit ASCII
Ugh
Nothing is particularly _wrong_ with it; it's just that on any architecture currently on the market, it is exactly identical to the fixed-size type of the same size (so uint_fast16_t is exactly identical to uint16_t, etc.). The notion that things might get faster because the type has 'fast' in the name, as was expressed in the message I refer to, is deeply misguided. It may be correct on a purely theoretical basis, but in any practical sense there is not the slightest difference. Should you be prepared for this state of affairs to change in the future? That's of course up to you, but my guess is it's pointless. There is entirely too much hardware, too much software, and too many protocols out there that rely on words having certain sizes (and being two's complement, and following IEEE754 layout, if not overal behaviour) that I don't think it will ever be economical or even useful to build an exotic architecture again. If it gives you a warm feeling that you are utterly standards compliant by virtue of using (u)int_fastxx_t and (u)int_leastxx_t everywhere, be my guest, but I'll take my chances with the fixed-size versions. 
It might be worthwhile to put these concerns in writing at a slightly more official place than a blog or reddit, e.g. at the Modules mailing list -- https://groups.google.com/a/isocpp.org/forum/?fromgroups#!forum/modules ... or writing a paper. Maybe also get in touch with build system developers who have had similar concerns, e.g. Stephen Kelly of cmake in this thread: https://groups.google.com/a/isocpp.org/d/msg/modules/sDIYoU8Uljw/BKKCSZFdBAAJ (Apologies that this is just a suggestion from the peanut gallery rather than any actual useful help ;-)
You can get the same thing in any compiler that supports precompiled headers using lots of ugly macros all over the code and a simple tool to generate headers, or less ugly macros and a tool that can process macros to generate headers from source files, as long as the source files are not mutated by previously defined macros. It is a mess but it works. 
For the same reason that a graphics API shouldn't be included in the standard language. C++ is a language for experts, and the language should be small and lean. Every additional feature that's added to the standard, be it a graphics api, or a package manager, or something else, adds more work to anyone trying to implement the language on a compiler or platform for benefit that's dubious at best. My organization already has a standard packaging system. We wouldn't adopt a package mechanism that the C++ committee adopted, or if we did, it would cost us many many man-years of work to do the transition. We also already have our GUI situation figured out, and we are actively opposed to having a GUI library included in the standard because it'll add more work for us when we update our internal version of the STL, and will cause delays in compilers adopting the language features that we're actually interested in. How would such a standardized build system or package manager handle integration into an operating system package manager? Debian, RedHat, Arch, Gentoo, Slackware, BSD, you name it they all do it differently. They each have different objectives with the way they package things, and each distribution is evolving their system as time goes on. Just look at the recent trend toward things like FlatPak, and Snap. (Which, personally, I detest. *shrug*). Any standardized package management system is either going to need to understand how the majority of existing package management and/or build systems operate, and inter-operate with them, or is going to need mechanisms to allow other package systems to hook parts of it's logic. The complexity here is pretty high, and really I just don't see any benefit. While we definitely need to be careful of removing anything from the language or standard library, I personally would very much like to see large parts of the STL made into modular libraries, and move away from the actual language standard defining required bits and piece, and I'd love to see parts of the actual language that are less frequently used be deprecated and/or hidden behind compiler flags. (Yes, I understand that that's a very controversial statement, and no I have no idea what feature I would advocate for removal / deprecation. Just a whimsical thought, could very well be that nothing the language does right now should ever be removed ever. But then again, maybe there's some weird hold-over from, e.g. C lang compatibility, or C++89, or what have you that just isn't worth the headache. Or maybe not.)
My problem with current allocators is the design is inside out. If you flip the current design on its head, you're about at where I'd like `std2` to be. &gt; And what's the point of using a coroutine for expanding memory? Why not just a function call? I'm not proposing using a coroutine for expanding memory. The code *inside* a coroutine needs more memory, so we suspend it and go get it more memory (during which we can execute other coroutines incidentally).
How does Cargo deal with multi-language projects? It is rare that I work solely in C++ (we have C and, yes, Fortran routines), which CMake doesn't bat an eye at.
&gt; You get that I don't want to preallocate megabytes of memory, just in case I need to process more than a handful of values? And that's just for one buffer; a typical application might have tens of thousands. Meh. You don't actually allocate anything until you write into it. So if throwing address space at a problem makes it simple, just do it (if you're on 64 bit). &gt; std2 is about updating std. It is not about providing fixed-size containers for the game industry. std2 ought to be about keeping C++ relevant in the face of technological progress and increasingly stiff competition. That's what I'll be arguing for anyway. People will have to suck up big changes in how C++ does things if they want to keep a job in C++ long term, because how we do things right now won't deliver that. Again, std1 isn't going anywhere. You don't need to use `std2` if you don't want to. And of course we would have a suite of generic range based algorithms which would seamlessly let you interoperate between std1 and std2. &gt; Removing an absolutely vital feature is not 'thinking bigger'. And having to hack in your own allocators everywhere, because the default you chose is 'no reallocation', is a total disaster. What I have in mind is very different from the present, but it will deliver outsize benefits in terms of superb reductions of latencies at 99.999%. I also don't expect to succeed in persuading WG21 incidentally, when I was discussing what I wanted with John Lakos, he thought it would be wonderful, but completely unachievable because WG21 already struggles with his very minor allocator improvements. Turning the allocation strategy on its head he felt would be too much to handle. We'll see. 
Technically ASCII is only 7 bits. 
Do your objections go away if the ruby interpreter was built from source? The core of ruby is just a bunch of .c files after all.
GHC? Did you mean GCC?
I don't think you're taking the time to understand what I've previously written. Of course the C++ Standard fails to help there. Those problems are outside of the Standard's explicitly and clearly defined scope: the language (syntax and semantics) and library facilities. I am not suggesting that there are not real development problems. I am simply saying that this knee-jerk criticism of and raging against the Modules TS is totally without merit on the basis that the Modules TS is limited in the kinds of problems it can solve. If you want to propose a naming policy, then talk to your system and build system vendors. 
I mostly agree... but I think my language would be different. I guess it is a gen x vs millennial thing. :) I hit similar problems with module naming and dependency management when writing my talk. "EA’s Secret Weapon: Packages and Modules" https://www.youtube.com/watch?v=NlyDUQS8OcQ When it comes to these hard problems in C++ I'd choose the solution that act like other solutions in C++ unless there is a good reason not to. It help other C++ programmers can guess how to use them and mean people can guess at the work around for problems. Modules name = file path names seems like a ok idea to me. I don't see what problems this solves by disconnecting them. I am sure there is something. This looks like C# to me and the people working on modules are not dumb they are solving a problem they think they have. But I would like a good understanding of why they are thinking this idea. PS One interesting use case for the #include MY_CONFIG_HEADER. I have used this before for dependency injection. Example EASTL (ea version of stl) has 2 modes EASTL::size_t is 32 bit or 64 bits. The default is 64 bits however 32 bit one was the old default. Some teams are still relying on the old standard so sigh... we have to give them some way to override the default. One way to do this is to give them a macro they can override. If you have enough of these macro you run out of command line fast so you add a macro to pass in a name of a file which can be included if defined. So I don't see why game or application teams would need #include MACRO_MODULE_NAME however some library might to support dependency injection like the EASTL example above. I think we have 10 or so places like this in frostbite engine. We would have to use code generation or just add more macro to solve this another way but it is not a useless trick. 
The Clang Modules implementation is the oldest of all compilers (when was it started? 2010?) but still has many many bugs. I haven't been able to port any reasonably sized code-base to use clang-modules, and the bugs are fixed at a slowpoke pace.
It is not too late to change `import a.b.c` to `import "any/prefix/a/b/c"`.
One of C++'s big strengths is applicability in a lot of domains, from the tiniest of embedded micros to "big iron". The needs of those different targets are wildly different and attempting to design a build system which would make all those customers happy is a nontrivial task. To say nothing of the multi-platform stuff and similar. For better or worse the closest thing we're likely to get to a "standard" build system in the medium term is CMake.
C++ is a language for experts. It doesn't need the kitchen sink. The kitchen sink is harmful. Please: no kitchen sink. The more "features" we add to the standard, the more challenging it becomes for the various STL implementations, compiler vendors, operating system distributions, and really everyone, to use the language, implement the libraries, build compilers, and so on. How would a standardized build system inter-operate with the way things are done on Windows, MacOS, Android, iOS, Debian, Arch, RedHat, Slackware, Gentoo, {Net,Free,Open,Dragon,Etc}BSD ? How does a standardized build system work with Snap / FlatPack / XDG-App type formats? How would a standardized build system get out of my way and let me do things the way I've been doing them? My organization already has a standardized build system that we're very happy with. If C++ adopts a standard build system we'll ignore it. It might even cause us work to turn off. If we did, for some reason, want to adopt it, it would cost us thousands of man-hours. If somehow we were forced to adopt it, we would simply keep our existing compiler and libraries, and stop contributing to open source projects that required the new build system (because we would stop using them in favor of something else). No thank you. My organization already has our preferred way of managing packages. We don't *at all* want to experience the NodeJS left pad package fiasco. https://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/. We'll turn off any package management feature immediately and the probability of ever adopting it is next to zero. And while we're at it, my organization already has our preferred GUI technology, so we'd also prefer that the community stop trying to sneak a GUI library into the standard. We'll have to spend man hours to turn it off, because we won't use it. It'll cause more work for compiler / STL library implementers to support and really it only benefits people who don't know what they're doing. Asking for the C++ language committee to standardize these things is similar to saying "I could easily put together these things that I want in a common bundle, but I'd rather have the C++ standard committee use their authority to strongly coerce the community at large to do it for me instead." A better solution? Build a "getting started" bundle. Include a compiler, a GUI library, a build system, package manager and so on. I wager you could establish your own foundation, and get modest donations from academic organizations to support your work of implementing a bundle like this. Those people who want it, would use it, and those who don't can safely ignore it, and everyone's happy.
What's wrong with Python? Don't get me wrong, I like C++, but it isn't a good "scripting" language and build systems are effectively scripts.
&gt; most harmful developments in open source software in the last several years has been the invention of a new NIH package manager for every language under the sun This!
**Company**: [Pathcore Inc](https://pathcore.com) **Type**: Full Time **Description**: Pathcore is a Canadian business specializing in digital image management for pathology. We're looking for a C++ software engineer to work on a cross-platform native viewing application and image processing backend. **Location:** Toronto, Canada **Remote:** No **Visa Sponsorship:** No **Technologies:** C++11, C++14, Boost, Qt, CMake, knowledge of Linux a plus, knowledge of C# and Python a plus **Contact:** PM or [visit careers page.](https://pathcore.com/careers/)
* That's never ever going to work on platforms with 16 bit `wchar_t`. Which is never going to change because the size of that thing was set back when Unicode said 16 bits would be enough for everybody. * Even if those platforms could change to 32 bit `wchar_t`, that doesn't help much with correct Unicode handling since you need to deal with combining characters anyway. (See https://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points/ )
Just a quick question: If someone pulls a library that is under LGPL (directly of as a 3rd party dependency, doesn't matter really). How would that affect his comercial closed source software ? I mean, you aren't modifying the library in any way. You could argue that linking statically with it is "modifying" but I don't think that's ever been bought in court. Either way, any organization large enough to care would literally only need to modify a flag from static linking to dynamic linking and the problem is solved, the package manager could even do it automatically (or suggest it) if it detect a copy-left license.
You are incredibly focused on one single use case: low-latency applications on powerful machines that happen to suport lazy allocation of memory pages. C++, as a language, currently has a lot more uses than that, and I very much doubt the standards committee is happy about restricting the scope of the language so dramatically. I also still don't see the point of all this. What you want is already achievable using, ironically, a custom allocator. You apparently want us to give up on a major feature, but _why_? Because it is "easier"? "Conceptually cleaner"? It just doesn't make sense. 
The value of format specifiers such as %02i or %.32s or %#.17g is something we very much understand, but the downside of printf specifiers, and specifically C-style variadic arguments, is too large. Google has an internal 64-bit type that we typedef to "long long"; recently we tried to convert it over to "int64_t" instead, but it turns out that int64_t is "long" on gcc/clang, so all our format specifiers that said %lld now had to be switched to %ld. Trouble is, that format-specifier switch has to be made simultaneously to when our internal 64-bit typedef changes, and that is logistically not possible. Not when you have tens of millions of lines of code under active development. On top of that, MSVC's long is not a 64-bit type, so %ld works for int64_t on Linux but not Windows, and... the point is, it sucks. We take our commitment to long-term support for APIs seriously, and that precludes us from vending this nightmare to anyone else. Oh, one more note: you mention how good it is that changing from signed to unsigned would cause a build break. But that does not, in fact, cause a problem. The printf warnings trigger on size differences (even theoretical ones) but not signedness differences (even actual ones). See https://godbolt.org/g/CrBLVz for an example where %ld can be used to format "long", "unsigned long", and "size_t", all without problem. But not "long long" - and this is despite the fact that all of these integers are 64-bit. Someday we hope to provide the formatting-control awesomeness, without the size-check insanity.
Note that `std::sub_match` works with arbitrary bidirectional iterators, but `string_view` requires contiguous iterators, so they aren't directly compatible with each other.
I'm the author of this one. I'm glad people use it because it's really a great concept. I've also have been wondering why this behavior isn't default but instead requires some strange member to be declared and I've ended with the conclusion it's because of the backward compatibility. It's a gold C++ rule that a new version shouldn't change the behavior of the old codes and in this case (if transparent comparators become a default ones) some existing C++ codes can be affected.
The value of the character is 0x1F4A9. Why would endianity be an issue? I do, however, doubt that it properly flags in Visual Studio, given that the type of L'💩' is wchar_t, which is only two bytes long on that platform... 
I'm sorry about that. Could you please copy paste a little bit of that garbage you see so that I see what to look for and try to fix it?
&gt; Why is this the case? Java/C# do use inheritance not generics for stuff like this. Assuming all the developers you work with are C++ fanboys that know templates is unrealistic. Also AFAIK(I may be wrong since I did not do this for a long time) error messages when you f up Concept(aka your template uses a class that does not satisfy the requirements on a type) are harder to read than when you call an nonexisting method on a interface/your class does not implement an interface properly. 
https://4.lithi.io/4TN44t.png Can anyone explain this to me? I am just about to lose my mind.
If the source file you are trying to compile has a BOM, VS will use it as the encoding of the file (otherwise it will use your system codepage or UTF-8 if /utf-8 is set). Make sure you save your source file as UTF-8 without BOM.
&gt;If someone pulls a library that is under LGPL (directly of as a 3rd party dependency, doesn't matter really). How would that affect his comercial closed source software ? If the package manager is unaware of licensing, and the commercial vendor is trusting it blindly (which of course they shouldn't, but stranger things have happened) -- then the vendor might not realize until the product has shipped that an LGPL library got pulled in and statically linked automatically via the dependency chain. &gt;the package manager could even do it automatically (or suggest it) if it detect a copy-left license. Sure, that would be good if possible -- though lots of node.js packages (etc.) have missing or incorrect license info. I'm just saying that an official C++ package manager won't be as helpful for ISVs as one might initially think. And the direction this topic has gone, kind of reinforces my opinion that many concerns of package management are pretty far removed from the sorts of things that (again IMO) make sense for the C++ standard and the committee to be addressing.
The message in that blog is as mistaken as claiming ASCII codes have no meaning because you need to deal with multicharacter collating elements.
No worries! Thanks for trying to help.
Nothing wrong with Python. But for a build system, I prefer it to have as few dependencies as possible, otherwise installing and using it become a burden.
Nope, I mean this https://www.ghs.com/products/MULTI_IDE.html
Hmm, you might be right. It's not reading a value from memory, it's just comparing two literals.
Oh, makes sense. To a lot of people, GHC means Glasgow Haskell Compiler. It would be nice if CMake could produce cabal files...
They should and i hope they do, it is a real problem nowdays and boring stuff that other languages has solved one way or another and it will come to C++ sooner than later (conan for example) so i prefer that the C++ experts do an official one, if it is better than CMake+Conan or whatever anyone is using we will win, if it worst no big deal, you can still use the same tools you are using I dont like going to the makelists to change things or to be sure always is right, VS is not a tool i like but it manages all of that much better, a makelist hidden to the developer, you add the libs with a GUI and ready to go, it should be like this. Plus that VS team created vcpkg wich it is a good solution, you install libs as linux terminal and they are setted auto for the project, it is so easy and elegant, i dream about having something like that with my ide and tools
Yeah, I don't really know of a better way to preserve backwards compatibility off the top of my head. You can always use `std::less&lt;&gt;` as your container's comparator instead of defining your own class, which is what I usually do, but again, it's still not so obvious why you're using `std::less&lt;&gt;` unless you're already aware of transparent comparators. I feel weird leaving a comment indicating why, but I also feel weird not leaving a comment :p
I didn't think of that. That can potentially be a significant performance improvement in just 13 characters.
U'💩', problem solved?
&gt; Assuming all the developers you work with are C++ fanboys that know templates is unrealistic. How come? If I work in a C++ team, why can I not assume everyone knows C++? I haven't coded Java for 3 years now, I can't understand why my teammates are supposed to assume my code might be influenced by idiomatic Java. For example, I'm mainly a C coder, if I write idiomatic C when I write C++ would it be ok? No, that's a horrible idea, and anyone doing such a thing is doing something wrong. &gt; Also AFAIK(I may be wrong since I did not do this for a long time) error messages when you f up Concept(aka your template uses a class that does not satisfy the requirements on a type) are harder to read than when you call an nonexisting method on a interface/your class does not implement an interface properly. Well, no, you got it backwards. C++ errors were utterly horrible and garbage *before* concepts, and one of the reasons why concepts are so essential is this problem. Is error reporting in Java still better? Maybe, but can't see why it's relavant here. If you're coding C++, you're supposed to write idiomatic C++. Java is some random other language totally independent of C++, not sure why are we even discussing it.
That's fair... now I see why you couldn't include it. Thanks for clarifying it. My take on this concern is the same of the chromium team (and I bet of multiple teams at google): I'm gonna take my chances on keeping an on it due to the benefits. I understand that that code is not public-library material, but it is still too damn good to be replaced on our codebase.
&gt; I don't understand why it has to become the build system to provide this functionality? Can you explain? Because otherwise modules need a clear and well defined lookup system for finding dependent modules. We cannot rely on -MMD or similar flags because we need to make sure each dependent interface translation unit has been built before attempting to build any implementation translation unit or a 'root' interface translation unit. As I said below, relying on a tool outside of the compiler to do this for us is *messed up*
I see a lot of U+2028 'LINE SEPARATOR'
&gt; std::not1 No. 
How would you get the .d files from a modules only project? You need to create an IFC (or your compiler's equivalent) for each dependent module before you can compile each translation unit. You need to run the compiler on each dependent module *before* you can get the list of imports.
The only reason I went with this titles is because I said I was going to name the article this on twitter. Other than that, you and I seem to be on the same page with the various issues regarding modules.
or to change `import a.b.c` to `import a.b.c. from "any/specific/prefix"`
I want to note that `RelWithDebInfo` is `-O2 -g`, and `Release` is `-O3`.
Absolutely agree. (Though I see no problem in using another language to help bootstrap it to that point initially)
Is C++ not a good scripting language because the ecosystem isn't there to provide all the niceties that you find in other programming languages? And do build systems *need* to be scripts? If its all C++, wouldn't it be easier to use an actual debugger to debug your build? :)
Hi exactly modules can be split across several files seems to be still under active discussion. In any case, ideally I should be able to put the whole module code into a single TU, but the compiler + build system should make sure that dependencies can be built as soon as the interface part is parsed/compiled.
From what I understand, cargo relies on a `build.rs` file that is compiled and executed for separate dependencies. It's how they interact with CMake and other build tools. The support on their end could be better, but its their current hack (granted, Cargo is at 0.21 and the Rust community follows semantic versioning, so I would be surprised if it became more extensive as time goes on)
Unfortunately, this is not possible for `std::unordered_{multi}set` which has frustrated me in the past (and also right now; I'm forced to using a hacky workaround). There's no reason not to allow finding a non-key entry as long as it is both comparable as well as hashable. [`std::unordered_{multi}set::find`](http://en.cppreference.com/w/cpp/container/unordered_multiset/find) and [`std::unordered_{multi}set::equal_range`](http://en.cppreference.com/w/cpp/container/unordered_multiset/equal_range) should offer the templated overloads just like [`std::{multi}set::find`](http://en.cppreference.com/w/cpp/container/multiset/find) and [`std::{multi}set::equal_range`](http://en.cppreference.com/w/cpp/container/multiset/equal_range) do. This is especially ludicrous in the light of the fact that [boost offers these exact overloads](http://www.boost.org/doc/libs/1_65_1/doc/html/boost/unordered_multimap.html#idp789162912-bb). Curiously enough, boost implements them for `find` but not for `equal_range` (which is more important).
Partially: The important thing is you don't have to reparse them and all the non-dependent lookup has to be done only once. 
Being also a build system developer let me say that this article is so on the nose it hurts. I really hope that compiler developers improve the usability before declaring things final
This is quite the shitpost.
&gt; You are incredibly focused on one single use case: low-latency applications on powerful machines that happen to suport lazy allocation of memory pages. C++, as a language, currently has a lot more uses than that, and I very much doubt the standards committee is happy about restricting the scope of the language so dramatically. Not yet they are not. But exponential growth in transistor density looks to be over now Intel have slipped their timetable again. That means CPUs will stop getting better in any way at all from now on. And that means enormous pressure is going to come to bear on software to deliver the productivity enhancements instead. Why after all do you think Swift, Rust, Go et al have suddenly appeared now and not before? Because the multinationals want to lock people into their specific systems programming technology, then they get to dictate this brand new and very lucrative market. They're investing into a shot at dominance and control. Bjarne at least understands this very well. So does Herb. I assume so others on WG21. C++ could be a major player in this and ensure no one corporation gets to dictate this space. But they'll need to shape the C++ standard accordingly to compete. Regarding low end CPUs, exponential improvement in performance per watt at the low will continue for at least another decade. So even the CPU in your dumb watch powered by your motion will be coming with a MMU and running Linux in a world not too long from now. It's actually very scary what could be done in that kind of micro-watt powered world. &gt; I also still don't see the point of all this. Everywhere in C++ where execution latency at &gt; 99% is more than a few multiples of the median needs to be changed to shave off those unbounded latencies. C++ exception throws, malloc, i/o, all of it. That'll make C++ very competitive in a world where CPUs no longer improve, and we'll all see our livelihoods maintained whilst many, many other developers lose out badly as entire segments of software development go to the wall. You'll probably brush all of this off as hyperbolic mania about future stuff not likely to happen. That's okay. I am in a research institute after all where we think about this sort of stuff and we've not correctly predicted the timing of anything yet :) 
Have you considered using a scene graph library like [Ogre](http://www.ogre3d.org)? This isn’t a game engine, and still provides a nice abstraction over top the low level graphics libraries.
&gt; eading the "How is this better than CMake (or Meson)?" part of the FAQ was rather interesting as I'm currently using Meson in my personal projects. Gotta look more into build2. The points listed in that section hold (arguably, most of the time) against CMake but not really Meson, which has probably just been thrown in the heading after the text has been written.
That's right. In a `build.rs` file, you generally use the `cc` crate to call your platform's C/C++ compiler, which provides a nice API. There is currently a [working group]( https://github.com/aturon/rfcs/blob/build-systems/text/0000-build-systems.md) build upon this system, that aims to let Cargo integrate/interoperate with other build tools.
&gt; C++ errors were utterly horrible and garbage before concepts, and one of the reasons why concepts are so essential is this problem You misunderstood what I said. Because I worded it poorly. :) I am not talking about concept keyword or concepts. I am talking about concept as set of requirements on a type. And when you mess that up errors are uglier than if you use nonimplemented virtual method... For the C++ developers: there are plenty of C++ devs that do not know how to write templates, so it depends on your team.
You can read about the rationale for using Python [in their blog](http://blog.conan.io/2016/09/27/Why-a-C++-package-manager-can't-be-written-in-C++.html).
Compilers have a force include switch, `g++ -include file.h` or `cl /FI file.h`. I can imagine that Boost.Preprocessor would use `#include MACRO` for its magic.
It should be noted that their idea of integration is "call Cargo from your build system, do not look inside it, do not try to change anything, do not use rustc directly". That is to say not particularly integrated.
Oh I see, yeah C++ errors were/are horrible but hopefully we'll fix this problem very soon. It's already fixed in major compilers (gcc/clang) as long as you know Concepts (which, you *most definitely* should). You're also right on team thing, but I would be very weirded out by a C++ team who write idiomatic Java/C# code. If you're gonna write Java code, better use Java, I guess... Personally, I would never work in such a team, but I guess that's personal :) I also hate Java notoriously, so I might be biased.
Thats what I meant by `yet`, but "soon" is a very relative term here. It will take ~3 more years, untils concepts are in the actual c++ standard. As far as practical matters are concerned I'd expect we have to wait at least until the end of 2018 before we get portable, high quality implementations accross the 3 major compilers and God knows how long it will take until a significant part of the c++ projects out there will enable c++20 (I've recently read a statistic somewhere that the majority is currently on c++11 (and a significant amount is still using c++03). Also concepts only solve half of the interface specification problem due to the lack of definition checking.
&gt; Is C++ not a good scripting language because the ecosystem isn't there to provide all the niceties that you find in other programming languages? No. It's not a good scripting language because it isn't designed to be parsed / interpreted and run in place. &gt;If its all C++, wouldn't it be easier to use an actual debugger to debug your build? :) Since when does Python not have actual debuggers?
Well, that's definitely a bad reasoning. Saying that C++ can't be used to write a package manager because "it can't" doesn't fly, and it's sad that such article can, and will put a lot of C++ programmers away from using conan.
On what platform is having Python present burdensome? It's installed by default on every Unix I know of, and it can be copied portably on other platforms.
Major compilers (gcc/clang) already implements concepts, as it appears in the technical report. Everyone paid attention to C++ 17 fuck ups knows why concepts are not in it, the concerns of the committee and what might change in the future (so, although it's a moving target, we kinda know which direction is it moving). I personally use concepts in my code, already. As long as there is no compiler restriction (for some companies, there are, granted) you might as well use trunk of gcc and/or clang. AFAIK gcc merged its concepts branch to its master branch last year, so everyone had more than enough time to experiment and learn concepts (in fact, long before this merge concepts branch was pretty usable, if a little buggy).
@_dorin, thanks for the feedback. The update that went out last week fixed a couple of crashes. If you are still seeing crash issues, please file them on https://github.com/Microsoft/vscode-cpptools/issues, which will get better follow-ups and support from the team. The IntelliSense engine by default runs in the latest C++ standard mode (i.e. C++ 17 at the moment), but yes there're features that are not fully supported yet. Support for CentOS7 and RHEL7 is another thing that's on our radar. But we probably won't get to them until when we are done with the core IntelliSense and code browsing features. Still lots of work to do, but we're on it! :)
ASCII doesn't have multicharacter collating elements. You can split an ASCII string anywhere in the string without regard for damaging characters in that string. If you split a Unicode EGC the character is destroyed. UTF-32 doesn't help you there.
... What you are describing is the current situation. This rfc is to improve on this non-satisfying situation.
&gt; Since when does Python not have actual debuggers? When its running CMake as a subprocess to generate makefiles :v To be quite honest, the while the Rust developers have admitted that `build.rs` is not the best way to go, it's been working wonders for them and I'm jealous of their ecosystem
By definition, the only thing the committee can do is work on the ISO standard. I'm not sure if anything elese is even allowed. If you are talking about some of the people that work on the committee, well, you have individual there that work on tools, but you have representatives of at least 4 different c++ implementations from at least two different eco systems and God knows how many IDE's, buildsystems there, so I find it hard to believe that they will just come together and find a common solution. Also, don't forget that the requirements google has for a build system are probably drastically different from what an open source project or a small company with a handfull of developer needs. Regarding the speed: Yes, there is now a new standard every 3 years, but since 2011 the changes have been pretty minor. Concepts have been in the making for a decade or so. Coroutines, modules and ranges are all things I've already heard several years ago and they aren't even in the draft for the next standard yet. Also it took the comittee almost 6 years to give `std::array` full constexpr support. I'm not complaining, I'm just saying that going through an ISO standardization process comes with a lot of overhead and takes a lot of time and convincing.
So, what is your rationale for requiring C++ tools to be written in C++?
OOP is not nonidiomatic C++. :) I mean nonforced one like I advocate for easier testing may be, but regular C++ developers know OOP.
From your post: &gt; The compiler should work as a build tool. Just to nip this in the bud: None of the compiler vendors want that last option. We're absolutely not going to get it. The author of build2, Boris Kolpackov, starts his CppCon talk with a very important statement from Richard Smith (once more, I'm paraphrasing): "The compiler must not become a build system". It's probably important to not too closely conflate the "don't want to require compilers be a build system" with the specific issue of "module designations" as strings for the purpose of helping the build system. One bit of historical context that might be missing on this particular argument is that Richard Smith (et al.) actually proposed a string as an identifier rather than the dotted syntax and it didn't get much support. In my read of the room that day, that was in part because it was part of a large series of proposals and it's not clear to me that that particular issue was dealt with fully. They were focused on other parts of the proposal. IIRC, Nathan Sidwell has been mentioning that he might bring this specific issue back up and try to change it. This is an area where community opinion can absolutely affect the outcome. To be clear, though, the current standard doesn't actually guarantee much about the random string that denotes a header. We think of it as a filepath but that's not actually required by the standard at all. But still, making it a string does let us reasonably assume it can be translated trivial to a path... and there is some expectation that "almost everyone" will eventually come up with some dotted-path-to-file-path conversion crap that will be slightly different and gross. 
Can you do it with singly linked lists?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/75kqct/merging_sorted_doubly_linked_list/do6y0ut/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Do you mean you are using concepts in production code? And if I may ask: are you working in a company or are you self-employed? Is there any documentation about concepts in clang? I knew they were working on it, but didn't know the status.
I just use static functions whose first parameter is a reference to the object. Fuck exposing private methods in headers. 
If you split ch in Czech, the character is destroyed (I suppose I should have said "in ASCII subset of ISO 8859-2" if you want to be pedantic). It is seriously as meaningless (or as meaningful, depending on your point of view) as stating that splitting a EGC destroys a "character". And not relevant to the point I am raising, which is that Windows can only support the subset of Unicode formerly known as "UCS-2" (can, but doesn't, since the CRT has no locales for it)
&gt; U'💩', It would be, if std::u32stream wasn't killed by the commitee in 2006, in anticipation of a "proper" Unicode proposal. 
I never said OOP as a whole is unidiomatic in C++. Your original claim was understanding templates is harder than understanding virtual function. Which is false. Templates are a huuge part of idiomatic C++, and if you're in a "C++ team" you're expected to understand templates. Therefore, this line of reasoning: "my teammates might have hard time understanding templates, so I better use virtual functions and make use of runtime polymorphism instead of compile-time polymorphism" is very dangerous in C++ and will cause you write Java at the end of the day. If you want to write Java, write Java, just please don't do it using C++.
I use it for personal stuff. I don't know much about clang (I thought clang implemented too but I guess I'm getting forgetful...), but gcc's concepts implementation is pretty good and is in its master branch. If you have gcc installed in your computer, you can try it just now.
It's an interesting discussion point. As one person suggested, if we compile Ruby from source, does it meet your criteria? Apart from scale/scope, it's not that different from the complexities of using autotools/make/bash/cmake. Just for interest, CMake has 37k commits, and Ruby MRI has 47k. CMake still depends on another build system, e.g. make, so they are in the same ball-park. The benefits of using Ruby are pretty great: cross-platform, versioned, great as a DSL, well established testing and deployment methodology, etc. There are some downsides too - it's another language to learn, but at least Ruby is a "standard" language while ninja/cmake/make/autotools/etc all have their own specific languages without much scope except within their own tools. My idea with teapot was to get the process right - for me it's more about what I want to be able to do with my build tools - in terms of forking upstream code, working with all dependencies in the same source tree, have a build that spans all (useful) packages. As an example, I've been doing end to end profiling of performance issues in libpng w.r.t. sRGB and compression. Using teapot makes this trivial since it includes the libpng package and builds it correctly as part of the software I'm creating - so it's quite straight forward for me to make large cross-cutting modifications and have everything build correctly, which I think is pretty awesome and huge gain in productivity. Ideally, in the future, teapot would be rewritten in C++ - probably bootstrapped. But for now it serves it's job well.
Problem's scope here is a package manager for C++. I never said tools for C++ are required to be written in C++. That said, I already said it's a preference of mine: the package manager written in C++ makes sense in a way that cargo for Rust is written in Rust, pip for Python is written in Python, Cabal for Haskell is written in Haskell, package managers for linux distributions usually are written in C, and so on. What conan devs stated on that article sounds like some frustration towards C++, which doens't have to do with their claim that it can't be written in C++.
What even is that? The documentation is confusing.
I disagree, but at least we agree specifically on what we disagree, so in case anybody reads this they have all the information clearly presented. :)
`std::not1(p)` is from C++03 and is _approximately_ equivalent to `[&amp;p](const auto&amp; x) { return !p(x); }` but with a bunch of caveats. Most notably, it imposes some restrictions on `p` to do its C++03-era machinery, which end up meaning you can't just pass in a function pointer or a lambda or anything generic. `std::not_fn` is better in every way, but is new in c++17. Before that you should just write a lambda instead.
Yeah, have a nice day! :)
Because a great many of the libraries that C++ applications depend on aren't written in C++ and don't expose a C++ API. Classic Win32, X11, FFMPEG, OpenSSL, GTK -- All sorts of libraries are either written in C, or written in some other language besides C++ with a C compatible API. I don't know that it makes sense for a C++ package manager to care about ffmpeg, which isn't written in C++. But I very often want to use it. Solving package management at the language level just doesn't make much sense with native code like that in the way that it does with something like Python that needs bindings to call native code.
You know which part of the keyboard you use to type that emoji? The ASCII.
&gt; `void() const` This is the first time I've seen abominable function types in a context that wasn't specifically "what are abominable function types?"
Do you know if the committee is in touch with CMake (Kitware) about their vision/experience/plans on this? Just curious.
If I could sell bottled motivation I would become filthy rich in no time. You will have to settle for discipline and perseverance. 
Drop the course and go chase your dreams. Be yourself!
Modules are just precompiled headers on steroids. We are not even getting syntax candy for PImpl.
at first i thought this joke was crap, butt then i realized it was quite clever
Well you know the saying: "Any sufficiently complicated C or Fortran program contains an ad-hoc, informally-specified, bug-ridden, slow implementation of half of Common Lisp." Considering that Ruby is basically LISP made easier, I'd say there's nothing surprising here. I'd rather have that than 3 times the lines of code to get the same thing, especially if it's still in development.
&gt; ffmpeg, which isn't written in C++ And it should be, seriously why do they feel the need to make structs full of function pointers that can lead to thousands of bugs while C++ has a nice inheritance system that would make the code much cleaner. Or how tedious it is to initialize the struct, especially since you need to call several functions to allocate 3 different buffers but some are actually destroyed when you destroy your codec context but not some others. Using ffmpeg is nightmare fuel, a good C++ implementation would have made it actually easy to use and remove the need to write hundreds of lines to write a video.
Some people just don't want to accept the truth: the modules TS is doomed to suffer the same fate of Itanium if they expect a magical compiler will solve all the big problems. 
Thank you for the explanation!
Intellisense uses EDG, so I can see its options not matching up perfectly with MSVC's.
What does it have to do with "millennials"?
If I could bottle motivation I would have gotten high off my own supply long ago :/
There is a running trend in popular print to say "Millennials Are Killing X". I made a tweet saying I was going to name this article the given title. I'm also a millennial. The title was for my amusement. No one else.
&gt; To be quite honest, while the Rust developers have admitted that build.rs is not the best way to go, it's been working wonders for them and I'm jealous of their ecosystem The dream of being able to express my build in C++.
Same.
&gt;Right, and 16-bit wchar_t can't be used with Unicode since 1996. This is simply incorrect. Unicode does not specify an encoding, and there are several standardized encodings in use today, including UTF-8 (variable width), UTF-32 (32-bit), and and UTF-16 (mostly 16-bit, additionally with surrogate pairs that occupy two 16-bit code units). 16-bit wchar_ts are used for the latter in full compliance with the Unicode and UTF-16 standards.
&gt; We are not even getting syntax candy for PImpl. Is that something you want and need? Is there a proposal for that? You can pretty easily write a small library for it. It's only 100 lines or so at most. That's what I've done whenever I needed PImpl.
What editor is that?
What kind of shitposting nonsense is this?
I would if most programming jobs in the games industry or aero space didnt require degrees, especially NASA, or spacex.
I mean I love programming and the challenges it brings but hours alone in my room tapping away at a keyboard is a bit extreme. I always wanted to work on a team of programmers so atleast i can work together and socialize with other members even if its through the internet
You're thinking of char16_t/char32_t, they are used to store units of an encoding. wchar_t is used to represent every member of a character set (a code point, in Unicode terminology)
The world is full of "should," but that's beside the point. It has great functionality, no matter how arcane the implementation. Whether it was written in assembly or Fortran or Cobol rather than their rather odd idiomatic C, I'll probably have some use for it from a C++ application. If I was writing it, I'd probably use C++ in a style you'd much prefer. But I am lazy and don't know enough about how to implement video codecs. So if you decide to wait for me to write an ffmpeg++, you probably shouldn't hold your breath.
I wish we could use the poop emoji in namespaces. Then I could just move my deprecated classes into `namespace 💩` so that people have to type `using namespace MyLib::💩` to continue to use them.
&gt;move my *defecated* classes FTFY
There is a very good reason why they require it. Btw, big name companies (NASA, SpaceX, Google, etc) are typically pretty shitty places to work if you love what you're doing.
How do you want to use a transparent comparator for `std::unordered_{multi}set`?
This is an excellent use of the poop emoji, mind if I borrow it? We do a lot of cross platform compilation. The biggest UTF issues we've had have been people copying from emails... Freaking Outlook changes dashes into HTML ems and double quotes into other hideous non-ASCII characters. Very annoying.
My objection is more about the Linux world in general that uses C for everything even when C++ would at worse lose 2% of performance for much less bugs and headaches. I ended up writing a couple classes that encapsulate the part of ffmpeg I needed, and it was quite the pain already.
I mean, I don't see anything forbidding it.
Nope, but teapot isn't only a C++ build tool. It's a generic package manager + build system written in Ruby. But, I've used it with C++ and it has a repo of build rules and related packages here: https://github.com/kurocha It has rules for compiling Ragel parsers: https://github.com/kurocha/ragel It has rules for compiling glslang to spirv: https://github.com/kurocha/glslang It could be used equally successfully to compile Java, Rust, etc, you'd just need to put together a library of build rules to do so. There is no C++ specific functionality built into the tool itself.
That doesn't affect this case though.
&gt; It better at least take those values, yes, but there is no (native) data type that will only take those values. That's a language defect. &gt; Bit flags decompose the integer into its base parts. It's no longer one value; it's 32 values. That's key to this discussion. Bit flags are not "positive values". Unsigned values do not exist because of bit flags. Bit flags are valid in signed integers too. For example, the asm instruction BT EAX, 31 is valid regardless on if EAX stores a 32-bit signed or unsigned integer. &gt; And resource handles are not mathematical. Any given handle is neither greater nor less than another handle. They are simply unique. This is irrelevant to the signed/unsigned discussion. Socket handles are 'ints', for example. &gt; You're waxing a bit philosophical here. Sizes can and are used in arithmetic all the time. I'd argue this happens more often than your unsigned aspect "protects" you from invalid values. Values as size concepts are legitimately used in arithmetic operations. Unsigned values should not be used in all kinds of arithmetic. &gt; .. Did you mean to say yes? -274 is below the min of -273.15. Where did -274 come from? What I meant is that temperature should have values from minpossible temperature to max, whatever min/max are. &gt; I've since shifted into working on my own programming language, and I saw problem after problem of using unsigned for sizes. You may think I've got it backwards, but that means the standards committee and compiler authors have it backwards too. They have it, I am sorry. I have also created my own programming language, in which all values have certain ranges/sets, and the compiler ensures the values only get the values they can get statically. &gt; An unsigned integer isn't a "non-negative integer"; it's a type that says "I want access to all bit-string permutations and modulo 2 arithmetic". Nope. 
Totally irrelevant, T[N] can blow up the stack as well. 
Start a learning group with other students that do the same course. 
&gt;Everywhere in C++ where execution latency at &gt; 99% is more than a few multiples of the median needs to be changed to shave off those unbounded latencies. Only in a handful of very specific applications. The vast majority is already fine as it is, and does not need such draconian measures. And you still haven't responded to my earlier suggestion that such applications already have this option anyway, by having a fixed-size allocator that has the exact behaviour that you want. How are you going to run on mobile phones, do you suppose, if you over-allocate memory gigabytes at a time? How about embedded? How about 32-bit systems? I've been known to argue for dropping support for machines from the fifties (anything with a non-8-bit byte and non two's-complement integers), and each time I mention anything like that here I get voted to oblivion. Do you really believe that dropping support for significant numbers of machines that are currently in use is going to win you any friends? Besides, are you even sure you are solving the right problem? You are making a guess about future hardware, and future operating systems, and building a language around the notion that address space will be completely free, which is something you cannot be certain at all will actually be true (or will lead to efficient software). It seems asking a bit much to bank the future of C++ on a vision of the future that may not come to pass at all. And assuming you are right, why not simply fix malloc by making it O(1)? Right now we have allocators that search through lists of free memory in all sorts of clever ways, but if you are going to assume that we do lazy allocation of pages, and if we assume that address space is infinite, why not simply use an allocator that only ever returns the next block after the last block it handed out? The allocator could consist of a single memory address (which is the next free block). An allocation of n bytes simply means returning that address, and raising it by n. That's one, at most two assembly instructions. This also removes the malloc bottleneck, and relies heavily on the same features you want to rely on, but it has the added advantage of not forcing you to mutilate the language with ill-conceived limitations. 
Even if it were reading the value from memory, the compiler knows how to get this right. It does it all the time, after all ;-)
My understanding was that the need for pimpl pretty much disappears with modules. 
He does have a point though. There should be a viable way to avoid name clashes, either by using a mechanism like directories, or by providing community guidance like Java did with their URL-like naming scheme, or through some other means. Just leaving it open and hoping for the best may work if you control the entire chain (i.e. if you work for Microsoft), but for the rest of us that is not an option. This is even more urgent if it turns out the granularity of our own modules is not vastly different from header files, i.e. if we end up with large numbers of modules that may all end up conflicting with some 3rd-party module one day. 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/bestof] [C++ programmer finds a real use for the 💩(poop) emoji](https://np.reddit.com/r/bestof/comments/75na7q/c_programmer_finds_a_real_use_for_the_poop_emoji/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
As to the naming of compare_exchange_weak(), from Anthony Williams' "C++ Concurrency in Action: Practical Multi threading" pg. 113: &gt;For compare_exchange_weak(), the store might not be successful even if the original value was equal to the expected value, in which case the value of the variable in unchanged and the return value of compare_exchange_weak() is false. This is most likely to to happen on machines that lack a single compare-and-exchange instruction, if the processor can't guarantee that the operation has been done atomically - possibly because the thread performing the operation was switched out tin the middle of the necessary sequence of instructions and another thread scheduled in its place by the operating system where there are more threads than processors. This is called a spurious failure, because the reason for the failure is a function of the timing rather than the values of the variables."
Can't speak for aero space, but a degree for the games industry is not required.
Well, yes, but CMake is likely going to either grow and become the de-facto standard or shrink resulting another even bigger schism. I mean, CMake is the de-facto standard for some projects but various compiler and stl vendors as well as huge "modern" libraries like boost don't use it. So would it not help if some "unofficial" push came from those bodies towards CMake, say, in the form of an unofficial repositories and the usage of CMake for the flagship C++ libraries ? Also, isn't the implementation of `&lt;filesystem&gt;` not finished mainly because boost file system basically provides an almost 1 to 1 equivalent to the std implementation ? (As in, I wouldn't think it's a priority for anyone to implement it when a solution exists out there) As for the sub-process mechanism I wasn't even aware that was in the 17 standard or that compatibility between windows and *nix platforms could even be achieved on that front at all (without a degree of pain and verbosity higher than that of just having macroed-out code for windows)
I was just talking with a teammate today about how I didn't feel comfortable knowing when a memory barrier was required. My major takeaway from this is (if I can restate what I learned to hopefully understand it better myself): The use of memory ordering (acquire/consume) is most helpful when using atomic pointers to non-atomic memory locations. That way, you can do all kinds of memory manipulations before touching the pointer, and the memory orderings prevent the pointer from being updated before the pointed to memory is ready. It also guarantees that the reader of the pointer will not see pointed to memory with values of those before the writer updated the pointer. Someone who knows more please help me out if this isn't quite right. I need to reread the section on memory ordering from Anthony Williams' "C++ Concurrency in Action: Practical Multi threading", but I wish there was a more concise explanation/rule of thumb that didn't require language-lawyer-speak.
I am not sure why he has included navmesh here. How you lay out the data has often been very game specific. You could standardize some of the pathfinding algorithms but I am not so sure you can standardize the data structure. Is there any general solution for all types of graphs that make sense?
Ich have played around with them, but the fact that the latestc gcc hast support for them doesn''t help me when I need to use or at least stay compatible with older and other compilers.
So boost implies that if types are equality comparable then their hashes are also of similar nature? I wonder if it's true for all the types. For example you may have custom string type which may provide comparison with `std::string` for convenience but use some different hashing especially because hashing for `std::string` is probably different on different platforms/libraries. Does boost has some mechanism to check that hashes are compatible?
sadly, your joke was not so sweet.
Have a look at the function signature: template&lt;typename CompatibleKey, typename CompatibleHash, typename CompatiblePredicate&gt; iterator find(CompatibleKey const&amp; k, CompatibleHash const&amp; hash, CompatiblePredicate const&amp; eq); You have to provide a hash and an equality functor manually and hence manually ensure that they are compatible with the container's functors.
\#ParityBitsAreBitsToo
Yeah, I found it always annoying, that ideomatic c often had better encapsulation than c++.
&gt; There has been a lot of discussion about how to write unittests of private functions in C++. **Testing private code is an anti-pattern.** It slows down your development and leaves you with the illusion that your code quality is higher. Unit tests test _units_. A private function _is an implementation detail_ of your unit. The whole point of something being private, is **the compiler giving you the guarantee** that you can change it without affecting anything outside the class. It is a tool for improving flexibility (you will be able to remove/replace the private implementation, and as long as your class keeps _public_ invariants (preconditions, post-conditions, effects and side-effects) your application will continue to work. Your unit tests should explicitly be written to test effects, side effects, preconditions and post-conditions. ----------------- If you find yourself needing to test the implementation details of your code again and again, the problem is somewhere else: - check that your design generates the correct granularity level; If you write a unit test for a particular aspect of your functionality (e.g. "I need to make sure the temporary file is in the correct format"), then you should extract that functionality to a different unit (orthogonal to the rest of your code) and inject it where necessary. - break your code into smaller units - check that you respect SRP. &gt; The more popular opinions I saw were: &gt; &gt; 1. You shouldn't have to unittest private methods, they should be implicitly tested through the public methods. If the private code you write has no effect on the outcome of your public APIs, delete the private code as it is dead. If it has an effect, it should be tested when testing the public API anyway. &gt; 2. Make all private methods protected and derive a unittesting class. If you do this, you will (by definition) not test the same thing that executes in your test environment. You also need to build for testing (extra time and effort). &gt; So I've been adding my unittests to the end of the source code being tested, just wrapped in #ifdef UNITTEST. It's so ugly but I'm experimenting with work arounds, and trying this one on for size. What do you guys think about this on a scale of ugly(0) to cool (9) ? You are trying to address a _design problem_ with hacks. Address it through design.
The post I was replying to was suggesting that whatever the official package manger for c++ ended up being, it would have to be written in c++ so as not to have dependencies on scripting languages etc... My point is that if there was a general consensus that _____ was the right package manager for c++ (using the right patterns, features, configuration, conventions etc...), but it was currently written in a scripting language then there would be nothing stopping us rewriting it in c++ so that it could satisfy the above criteria. 
Hm, this is very contrary to the impression I got from discussions on the Clang's mailing list, which is that TS Modules are incomplete while Clang Modules are production ready and used in real projects (like at Google).
Modules should make the PIMPL hack no longer necessary.
Coming in a release or two in `build2`.
You absolutely could do this but teapot uses Ruby as a first class language for defining build rules so it wouldn't work in the case of teapot (very well). You'd have to embed a ruby interpreter :D
Isn't the slot map erase O(n)? He talks about "finding the corresponding element in the slots array after moving the last element into the new, open spot in the data array". But since the elements in the data array are elements of the type T, how is he infering the location of the corresponding element in the slots array without doing a O(n) linear search?
If it is amalgamated with the package manager source code and I don't have to install, and more importantly, *maintain* it myself, sure. The problem with external dependencies on other languages is that I now have to maintain them on all the platforms I want to build/test my projects. Sure it might have been a short-term gain for you to write things in Python or Ruby but it is a long term pain for your users.
The key includes an index into the slot array. The slot element contains an index into the data array. So in order to find any element, you need two array accesses. This is constant, no matter the size of the map. Erasing includes: * Finding the slot (1 array access) * Finding the data element (1 additional array access) * Moving the last data element onto the erased element (1 move) * Erasing the last data element (1 destructor) * Updating the slot information * Updating the 'free slot' list tail. So, for any erasure we have 2 array accesses, 1 move, 1 destructor, and 2 field updates. This is constant, so it's O(1). 
Yeah, fair point. I guess it's not the one!
Well but all it does is just lets you provide something else than `std::hash` as hasher, and all guarantee is just that user somehow checked that this hash is compatible. What if some user checked on his system that everything works since his hash happened to be the same as `std::hash` but it actually happens to fail with `std::hash` from other library. Doesn't look as solid as existence of less-than operator between two types to me. However you could use it in case of `std::string/std::string_view`, `pointer/smart pointer` since they have equal hashes according to the standard (at least since c++17)
Why don't you try jumping in an open source project you like? I usually choose a software I use often and see how I can improve that. You can also socialize in the developer's mailing list / slack / irc chats.
Having been a speaker at a few aerospace conferences, I found that people are generally surprised when they learn I have a degree in computer science. It is not a very common thing; most in this particular field are engineers from more aerospace-y studies that happened to drift into programming. Of course they still have a degree... 
Do a real break. Spend a few days (a week ?) without touching C++. Also, try to be healthy: eat well, sleep enough :) Kiss kiss
If this were done nicely and well enough, and setting up the Open Folder settings for VS isn't a travesty (and they've stomped out the intellisense bugs) I would switch in a heartbeat. This would make so many things easier. Jesus man don't just say life changing things like that and not give me a timeline for when I can try it. 
Boost is (hopefully) moving to cmake.
I would say it is actually UNIX world in general, all variants of it with exception of NeXTSTEP derivatives, given its relation to C.
Great talk. Have started watching some of Fedor's other presentations. Definitely worth the time.
Except the fact that the installed version and dependencies might not be the same thing. And getting it installed might mean lots of fun with IT change requests.
&gt; Updating the slot information I meant this. To update the slot information, you need to be able to infer the slot that belongs to a entry in the second array, based on the entry in the second array. So the entries in the data array need some pointer back to the slot array for this to be O(1), but that wasnt talked about, so I am not sure.
I have tried to port two small-to-mid-sized 10k-100kLOC projects to use clang modules. I started ~1 year ago, have hitted like ~10 bugs in the way that take 1-2 months to fix. Everytime a bug is fixed, a new bug appears. None of the projects compile yet with Clang Modules (they compile just fine with Clang without Modules). The projects use modern C++ with C++11 libraries (range-v3, Hana, fmtlib, variant, etc.). Most of the bugs are related to the interaction between Clang Modules and C++&gt;=11 features (e.g. constexpr) but some of them are also related to C++98 features (e.g. static variables). MacOS X currently ships a modularized system library (e.g. POSIX headers are available as modules) and I've also heard that Goodle uses them internally. However, given that Google has a huge code base, that can only work if they are not using C++11 because otherwise these bugs would have been found. Also, I doubt that anybody is using MacOSX modularized system components because if you import any single component, all components are imported, resulting in name clashes... so... its basically unusable. 
&gt; This of course still breaks in the template-heavy "header only" world with which so much of the C++ community has an unfortunate fascination, but it shouldn't severely impact well-structured code. Having modularized a couple of header-only libraries, 1) modularizing them was easy, 2) the resulting speed-up was almost a 1:1 match with pre-compiled headers.
&gt; with the help of std::wstring_convert and friends from &lt;codecvt&gt; Which are "killed" (deprecated) by the committee in C++17, in anticipation of a "proper" solution.
I've long dreamed about a world where the effort to create dozens of home-grown package managers would instead go into tools that make the creation of .deb/.rpm/.msi/whatever packages from that language really easy and intuitive. Thanks for putting this into words better than I could!
&gt; If you split ch in Czech, the character is destroyed. That's a good example. The Czech ch is not an ASCII character. Using the two ASCII characters c and h to represent it is flawed, because you _can_ split an ASCII string anywhere. 
I'm surprised about that actually, I've never checked. Surprised that with `-O2 -g` debugging still works so well and optimized-out codepaths &amp; variables are not a problem. I'm also a bit surprised as `-O3` as the default choice for Release, and not `-O2`.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/75o6ua/please_help_me_slove_this_exercise/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
These damn millennials. Back in my day we had to hand-compile our source files using nothing more than a toothpick and a rotor blade. Of course, you had to wear an onion on your belt...
Interesting, thanks for the information.
;-) I would say early next year. As you've pointed out, things has to be done well and it is not exactly a trivial piece of functionality. BTW, we are also looking into Open Folder.
While modules should be better than PCH, I think you are overstating the difficulty of pch management. Headers that easily go in the pch are std lib, boost, Qt and other 3rd party stuff, and that alone gives you 90% of the benefit with pretty much 0 thinking. You can put your own code in there, if you have some massive" base" modules, but that is an easy decision, too. I really don't know where is the big churn you speak of...
would it work with any other emoji?
How exactly? How would you maintain ABI compatibility with modules but without pimpl?
How is making the compiler open a specific file makes it a build system? the compiler now does that, i.e. opens the header files. The GP simply meant to replace header parsing with module parsing. 
visual studio
The problem with using the OS package manager is that you're stuck with whatever version works best in that environment. Here at my company we have to develop on a legacy server running a 7 year old distro, which is known for only puting in production obsolete packages. But we needed features available on newer versions of the system's libraries, and we could not update them on the system. If we did, basic tools, like vim, would broke due to incompatibilities with those newer libraries. So trying to use the system's package manager for development is DOA, because then the burden is on the developer to fix every other tool in the box. And ain't nobody got time for that! 
Visudio. *** ^(Bleep-bloop, I'm a bot. This )^[portmanteau](https://en.wikipedia.org/wiki/Portmanteau) ^( was created from the phrase 'visual studio'.)
Should work, yes, although some characters considered "emojis" are actually in the BMP so I'd make sure it's value is &gt; U+FFFF
Downvoted: while the info is interesting, **how to use it** could be presented in three slides and **the rest of it** (most of what is written in the slides, data types, compiler support, comparisons with messageing and logging frameworks and so on) is too loaded and in the wrong format (for a slideshow). I found myself pausing the video every 30 seconds just to read his slides.
I don't get why people are still so afraid of -O3. It gets you some really wondrous things (automatic loop vectorization, loop unrolling) and almost always performs faster than -O2. As for debugging the compiler really does try it's best to maintain debugability even after optimization. 
So, If I understand correctly, the preferred method of extracting build dependencies from code requires the preprocessor to run twice, and that's a problem that should be avoided? How about splitting the compilation process in two processes? 1) run the preprocessor and return the result, which includes module dependencies. 2) compile the code using the preprocessor compilation results. A build system would intervene between steps 1 and 2, read the dependencies, compile everything else first, then compile the current file. 
Ok, let's start with the way we extract header dependency information today, which is by asking the compiler (`-M`, `/showIncludes`, etc). If one thinks about it for a bit (or studies compiler source code), it's easy to see that this requires essentially a full preprocessor run (and, in fact, for some compilers like VC there is no other way). This is the first piece of the puzzle. The second piece is the proposed Modules TS grammar: If one studies it, it's not hard to notice that all the module dependency information (import and module declarations) are *top-level*, that is, they can only appear in the global scope (well, to be absolutely precise, an import declaration can appear inside an exported group but that group must be top-level). This means that given a sequence of preprocessed tokens (the first piece of the puzzle), one can implement a pretty simple parser that recognizes all the import/module declarations without having to recognize the full C++ grammar. We've done this in `build2` so I know this is doable. What's surprising is that (1) [the code] (https://git.build2.org/cgit/build2/tree/build2/cc/parser.cxx) is actually pretty simple and (2) it performs pretty well without any advanced optimizations. All this means that it should be pretty easy (complexity-wise) and cheap (performance-wise) to extend the header dependency extraction support provided by current compilers to also output module dependency information. Now let's look closer at what exactly would we need for this *module dependency information* to be. As an example, let's say our build system needs to update `foo.o` from `foo.cxx` (the `foo.o: foo.cxx` dependency) and this `foo.cxx` happens to contain `import bar;`. What does this mean from the build system's point of view? It means that before compiling `foo.o` it has to make sure the *binary module interface* for module `bar` is up-to-date. Or, speaking in terms of dependencies, this means the build system has to add `foo.o: bar.bmi` to its dependency graph. And since it now needs to update `bar.bmi`, it also has to come up with a rule of how to do that, say, `bar.bmi: bar.mxx` (this is, BTW, where the mapping of module names to file names happens in a way that makes sense in this build system's worldview). Where am I getting with this? Well, what this hopes to show is that if a translation unit that the build systems wants to update imports a module, then the build system has to come up with a rule to update this module's binary interface and which means it will have to extract the module dependency information from the module's interface file (`bar.mxx` in this example) just as it did for `foo.cxx`. This, in turn, means that the module dependency information provided by the compiler need not be recursive -- the build system has to do this itself anyway. In fact, all we need from the compiler is a list of imported module names which the build system can map to file names and then process, recursively. And in this setup the build system can remain the build system (by being responsible for mapping module names to files/rules, etc) while the compiler can remain the compiler (by only giving the build the list of imported module names).
&gt; If std2 containers were simply handed a capacity, and used 0-100% of that capacity only... This is the "preallocate all at the beginning" strategy from the 19th century. It works ... OK... for systems where you have good or complete control over what runs in the first place (embedded (and by that I don't mean Linux on a board), consoles and the like). I *really* don't see that's a sufficient use case to be pushed onto everybody as "standard". I see that below, you even come up with the idea that space taken upfront does not matter because we have 64bit execution. But majority of devices does not have that, nor do they have anywhere near as much memory, nor will further minimization (think IoT) get 64 bit everywhere. I see that you also speak of [cache locality and latency](https://www.reddit.com/r/cpp/comments/759uex/cppcon_2017_alisdair_meredith_an_allocator_model/do62b6x/). But that is not something capped size containers help by themselves. Contiguous memory does, so does "go forward" processing due to prefetching. So a sorted vector beats std::map, etc, whatever - that doesn't need capped size. I think that you're just mixing things that do not mix. I really think you could not be more wrong with this idea of capped container sizes.
Wow the implicit compare of Optional&lt;T&gt; vs T that Michael points out really sucks. Anyway, great talk. I love how he points out the pitfalls with each of optional, variant and any. This guy knows his stuff!
Their point was that when you use an array, you know how much space it's taking, but when you use `std::array`, you don't necessarily. It would be pretty dumb for an implementation to make `std::array` pose a big risk for stack space, but it *could*.
It comes from experience with big projects and having PCH make compile times worse because actually it was a bad idea to add, say boost headers to it in several of the sub projects, for example. Again it does not "scale", it's not universally bad, it's fine if you are not doing very big software, it becomes a problem when you do.
*breathing heavilly*
I'd really appreciate a breakdown of how that `numDigits` implementation works.
Well, part of that pain comes from system packages being harder to create than they need to be. In your case, it shouldn't be too hard to create a `yourcompany-libfoo` package that contains the latest version of the library in some custom prefix, but currently creating the packages takes more effort (both manually and automated) than most people are prepared to spend on packaging.
Containers != Virtualization, but separation.
[randint](http://en.cppreference.com/w/cpp/experimental/randint)
I was thinking of the use of pimpl to reduce compile time. Since you don't leak included headers out of the module, that use would be redundant. But yeah, for ABI compatibility it won't do much, that's true... 
But the distro package manager (like apt, yum, pacman, etc) solves a very different problem than the "language" package managers / build tools (like cargo, gem, etc). It would be nice that the same manager would also be responsible for installing the compiler/interpreter and other tools (like rvm, rustup, haskell-stack, etc). That doesn't necessarily mean that every language needs their own package manager. But given that every language has a slightly incompatible definition of "module" and "dependency" and "version", it's not easy to see how they could all use the same package manager. Maybe something like Nix or Guix will become popular enough in the future but I'm not holding my breath. 
I haven't seen an implementation, but I bet the data element has a pointer to the slot too.
I waited for this episode. What are the advantages over using valgrind?
Any part in particular? The magic numbers are just changing the log base from log2 to log10, I've got a partially commented version coming up..
How? Endianness necessarily entails how the CPU will interpret multi byte values.
I thought I was in /r/shittyprogramming
You could do something like using transparent_less = std::less&lt;&gt;; std::set&lt;std::string, transparent_less&gt;; which is terse enough and gives the reader something to google
I know, right? I did NOT expect this to blow up as it did.
This rant makes sense. I'd rather have a standardized build description format, which could be used by whatever tool (and/or package manager) you'd like. I would also prefer if this format wasn't inspired by CMake.
Thanks! I still don't get where many of the `+ 1` and `- 1` are coming from, but I'm going to guess that it was the result of iterating until it started producing the right result in a minimal number of instructions. I find it especially interesting that `log2` subtracts the `lzcnt` result from 31, not 32 (as I would have expected), but the generated assembly is actually using 32 anyway, skipping a `+1` step later on. The compiler is actually hinting that the algorithm it was given contains a gratuitous step. Neat.
I don't know whether the fact that a moved-from container can be non-empty is counterintuitive or not, but there is already a container that behaves this way, namely `std::array&lt;std::string, 1&gt;`.
What would you gain from specifying that a moved-from optional is empty?
this is the exact kind of shit posting we need
`std::array&lt;std::string, 1&gt;` feels not like a good replacement, since it will always store 1 element (memory AND lifetime wise; optional just holds the memory but manages the lifetime of the object). additionaly, optional represents the intent of the code. if you see optional as a stdlibrary container, then yes i find this uncommon to still hold a value after moving, because all other container are empty afterwards. if i move from a unique_ptr i dont apply move on the pointed-to-object neither. maybe its a bad comparison, but you could missuse a unique_ptr as a somehow poor optional
The compiler has to know which files define which modules and which files use which modules. I think the issue you're concerned about is that you don't know ahead of time which files you need to even look at in order to generate the .d files for a particular translation unit. Instead, there probably needs to be a separate phase entirely, before compilation, where we ask the compiler to look at each file and note for us which files define/use which modules. Yes, this probably requires some amount of the compilation phases to happen before the compilation really begins. I don't see how this necessitates compiling twice. If the compiler has to build a syntax tree twice in order to accomplish this, perhaps the answer is to cache the resulting syntax tree the first time. I don't see how any of this necessitates a compiler becoming a build system or a build system becoming a compiler. What it does require is a lot more cooperation between the compiler and the build system.
That's not a bad idea. I'll start doing something like this.
`std::move` left object in valid but unspecified state, so it can be whatever it want to be, and only specified operations are reassignment and destruction.
It's implementation-defined because it depends on whether or not emojis are part of the basic source character set. If they are then it depends on whether the implementation also considers an emoji to be an *identifier-nondigit*. If the implementation does not consider emoji part of the basic source character set then it's illegal in C++03 but legal in C++11 because the emoji range was added to E.1 to allow it in a universal character name for an identifier.
hmm something like this: struct Result_A{}; struct Result_B{}; struct Results { std::optional&lt;Result_A&gt; result_a; std::optional&lt;Result_B&gt; result_b; }; void ultimate_processing_loop_pew_pew() { Results results; while (true) { // call only sometimes, so there is a usecase for has_value(), since it sometimes just doesn't have any result results.result_a = get_result_a(); // call only sometimes, so there is a usecase for has_value(), since it sometimes just doesn't have any result results.result_b = get_result_b(); pass_to_other_thread(std::move(results)); // the other thread could see an optional indicating a value, but actually the value got consumed one loop earlier } }
What you are actually saying is that pch makes build time slower which I really wish you would corroborate. I have seen people simply not understanding how to set it up and getting bad results. Most eggregious example is people who only ever rebuild everything, even in their modify/build/test(debug) cycle. Well, that's not the point. PCH is first and foremost made to speed up the modify/build/test cycle where one only builds as little as possible. Using them to speed up a "full build" does not necessarily work and is not the goal either.
Other containers are only guaranteed to be empty after being moved-constructed from. They're left in an unspecified state after being move-assigned from, which matches the general rule for move semantics. I would guess the committee decided to single out the case of move-constructed containers because the allocator is also moved from, leaving it in an unspecified state, so extra care needs to be taken to retain valid semantics.
Other containers are only guaranteed to be empty after being moved-constructed from. They're left in an unspecified state after being move-assigned from, which matches the general rule for move semantics. I would guess the committee decided to single out the case of move-constructed containers because the allocator is also moved from, leaving it in an unspecified state, so extra care needs to be taken to retain valid semantics.
Other containers are only guaranteed to be empty after being moved-constructed from. They're left in an unspecified state after being move-assigned from, which matches the general rule for move semantics. I would guess the committee decided to single out the case of move-constructed containers because the allocator is also moved from, leaving it in an unspecified state, so extra care needs to be taken to retain valid semantics.
The way I see it, an object in a moved-from optional behaves like a normal object. If you move from a normal object, it is left in a state where it still exists and is ready to be destroyed. If you move from an optional, the contained object still exists and is ready to be destroyed. I would find it counter intuitive if the contained object was destroyed on move. The reason why moved from containers are often left empty is because the storage itself that contains the elements is taken by the moved-to container. The elements themselves are never moved and destroyed (in the case of `std::array`, they are moved but not destroyed, leaving the container not empty). Expectations aside, maybe some template magic could be used to keep an `optional` of a trivially copyable also trivially copyable while still running the destructors on everything else without raising performance concerns, but I think the real answer is: who cares, empty or not, which happens after you move? The data has moved on, and so should you ;)
So c++ 20? Good to see, I wrote one myself sometimes as someone wants is a number that is too obvious 
Expected and Outcome have exactly the same behaviour. If you want your object empty after moving from it, simply empty it *after* moving from it. Problem solved.
That's not what I said at all. I said it can end up there (even in incremental builds). Just try to build something very big, multi-project, multi-platform.
&gt; Build tools will parse source files over time and keep track of which modules are where and which translation unit needs what. Isn't this is what cmake does? IIRC it already parses the headers.
The other reason is the zero overhead principle. Moving an *optional* just moves, nothing else. It doesn't change the state to empty, it doesn't call a destructor. That would be overhead which could discourage people from using *optional* in general. C++ already has a reputation of doing too much behind the scenes. Additions to the standard library are carefully designed to avoid unwanted magic.
Yeah the data has moved on, but the optional is still indicating its there and so its holding me back :P (well actually in some regard the object is still there. but somehow "unusable/consumed"). but i understand your other points. mhmhm 
&gt; Only in a handful of very specific applications. The vast majority is already fine as it is, and does not need such draconian measures. It is a very wide misconception that latencies &gt; 99% do not matter because of the effect on the average during microbenchmarking which is from what most people derive this conclusion. High latencies &gt; 99% have outsize effects on real world code scalability. The whole language runs slower *as a system*, but it cannot be proven to be the case by isolating any one case. That probably will fly right over your head, and you'll demand proof. There is no proof except to rewrite the code to eliminate all unbounded latency operations entirely. Which is expensive, and always contentious, and will never convince the unbelievers. So I won't bother. &gt; How are you going to run on mobile phones, do you suppose, if you over-allocate memory gigabytes at a time? How about embedded? How about 32-bit systems? I am actually from an embedded programming background you know. The entire of the AFIO library fits into a L2 cache for a reason. &gt; I've been known to argue for dropping support for machines from the fifties (anything with a non-8-bit byte and non two's-complement integers), and each time I mention anything like that here I get voted to oblivion. Do you really believe that dropping support for significant numbers of machines that are currently in use is going to win you any friends? I don't see where you got that I was asking for that from. 32 bit, even 8 bit systems work just fine with what I have in mind. Sure, you can't take advantage of oodles of address space. But nothing I have in mind *requires* the developer to throw address space at problems. So if you're on a 64Kb machine, obviously enough don't do that then. Plus, Ranges, if Eric makes it sufficiently constexpr, should let an optimising compiler elide entirely runtime representation of containers altogether in some circumstances. My GSoC student this summer in fact put together a constexpr Ranges implementation that implemented associative maps entirely in constexpr, so all that appears at runtime is an array written and read at "unusual" offsets in assembler. Cool stuff. &gt; Besides, are you even sure you are solving the right problem? You are making a guess about future hardware, and future operating systems, and building a language around the notion that address space will be completely free, which is something you cannot be certain at all will actually be true (or will lead to efficient software). It seems asking a bit much to bank the future of C++ on a vision of the future that may not come to pass at all. If you plot the evolution of various categories of CPU over time against inflation adjusted ops/sec/watt, the trends are pretty obvious. The reason lower end CPUs are still exponentially improving is because the design techniques from the highest end CPUs which are now stagnant are still being integrated into them. I reckon at least another decade of exponential improvement remains for low end low power CPUs. But you're right that the future is unpredictable, a surprise breaking the trend may occur. &gt; And assuming you are right, why not simply fix malloc by making it O(1)? Those allocators actually have awful performance. The PMR allocator infrastructure is a great start, John Lakos had a good colour heat mapped presentation on it which I needled about stealing the presentation idea from me (he denies it!). But it can't be properly leveraged into faster C++ across the board without addressing the broken STL allocator design, which is of course part of why Alasdair has proposed what he has. You know, you could just trust us on this stuff. John's been at allocators since the early 1990s. Me and him are in general agreement on the fundamental changes needed because, god damn it, we're right and we know what we're talking about. And no, we can't prove this stuff in any non-systems based proof. It's mathematically not possible. You have to take a whole-systems approach to proof like John has been forced to do, and even then, lots of people can't grok and will never grok that if you can't see inefficiencies at the micro-level, there can still be huge inefficiencies at the systemic level. And those are getting urgent! Rust is faster than C++ at the systemic level, we need to up our game.
okay didn't know about Expected and Outcome. consistency is important. but still seems a bit strange for me in the first moment.
&gt; This is the "preallocate all at the beginning" strategy from the 19th century. It works ... OK... for systems where you have good or complete control over what runs in the first place (embedded (and by that I don't mean Linux on a board), consoles and the like). No, not at all. Even many embedded systems now provide virtual memory, yet C++ has zero support in the standard for managing virtual memory. If they accept AFIO as the File I/O TS, they get a full fat and rich interface with most of everything you need to manage virtual memory directly. And that opens up a wealth of new opportunity for standard container design and implementation. Lots of stuff we couldn't do before we'll be able to do, everything from constant time array expansion to address reservation to throwing away the contents of dirty pages and reusing them rather than the system having to write zeroes to them and issue a TLB shootdown. Again, none of this need be mandatory for non-virtual memory systems. Just use std1 containers there.
I am a big fan of a library called FFMS, which wraps a lot of the playback functionality of ffmpeg so you can easily seek and get pictures out of videos. It's implemented in C++, but has a C API. You might like it. Doesn't do any encoding, but the API is a lot more pleasant than the underlying FFMPEG API.
&gt; i find this quite counterintuitive (if you think of an optional as a container of max size 1) That is not the model for `std::optional`. The model and the rationale are described in here: https://isocpp.org/files/papers/N3672.html#rationale.model.
That is not true. Standard library types have stronger guarantees, and user defined types might have weaker or stronger ones.
If you link a proprietary program statically with an LGPL library and don't provide object files such that the user can re-link with a modified version of said library, then you are in violation of the LGPL. Negligence isn't much of a defence, and [both the GPL and LGPL have been upheld in court numerous times](https://wiki.fsfe.org/Migrated/GPL%20Enforcement%20Cases). A standardized way to handle licenses would be nice, but may be tricky to sanity-check programmatically in all but the most trivial cases
 Either at the start or end of lines.
No C++ compiler/library changes? :/
&gt;But the distro package manager (like apt, yum, pacman, etc) solves a very different problem than the "language" package managers / build tools (like cargo, gem, etc). What do you see as being the differences in the problems being solved? (Truly curious, not snark.) &gt;It would be nice that the same manager would also be responsible for installing the compiler/interpreter and other tools By "the same manager", do you mean the per-language package manager? If so, then let's suppose a standard C++ package manager. So it would be responsible for installing say g++ and/or clang++ binaries, libllvm, etc. So how is the OS (distro) package manager supposed to know that a C++ compiler is installed, in order for it to check that the dependencies are satisfied when the user wants to install the package for a program that depends on a C++ compiler or libllvm / libclang for its back-end, for instance ROOT (http://root.cern.ch) ?
Support ARM64
https://en.m.wikipedia.org/wiki/Virtual_memory No language has **any** support for virtual memory. The whole purpose of virtual memory is to be invisible to the userland. In fact, it **is** invisible to it, otherwise it goes against its very purpose. I see no way that virtual memory can become part of the standard in near future, if at all. I don't know what you mean by mentioning file I/O here. Files are files, memory is memory. Are you suggesting that people should preallocate everything and back it with files?! (E.g. memory mapped files)? Are you... trolling?! Or are you management/marketing and don't know what you're talking about?!
Yes, please corroborate that building (not rebuilding) with pch can be slower than without. What is your source data for this claim? I have some between 100 and 200 projects in one part of my work, 5000-6000 files. Builds for three platforms, one Windows. So what about it? When I am in my modify/build/test(debug) cycle, I modify whatever, that affects, say, 5 "prod" and 3 test projects, say 20 translation units, linking is incremental. I build the test stuff which builds 5 others and test/debug stuff. Occasionally , I build the release build of this (to benchmark). I see that it is slower, always. I don't measure, of course, and I know that optimized build takes longer and there's no incremental linking there either, but still... No, you really need to show data, numbers. I might give you mine tomorrow when I am at work...
Cool! Good to know. :-)
thanks for the link
&gt; if you see optional as a stdlibrary container, then yes i find this uncommon to still hold a value after moving, because all other container are empty afterwards. This is not true, for example, `std::vector` move assignment operator does not guarantee that after a move the vector is empty.
Bit numbering starts at 0, like arrays.
&gt; It is a very wide misconception that latencies &gt; 99% do not matter because ... ...because the majority of software already runs plenty fast enough, and if it doesn't, this kind of bit-f*cking is not going to help you anyway because it is typically caused by bad choices of algorithm, the use of massive, but ill-fitting frameworks, and/or the sheer volume of data to be processed. &gt; That probably will fly right over your head Nice. Let's go back to the beginning. Your claims are, and feel free to correct me in case I completely misunderstood you: - Containers with fixed-size capacity are good enough for the general use case, and at any rate better than containers with dynamic size. - Specifying capacity up-front is acceptable. - If you want dynamic resizing, program it yourself. - Hardware will evolve to make your vision a reality. My claims are: - Nobody wants to go back to the situation where you need to specify capacity up-front, and if we do, we will most certainly end up in that hell we only just escaped from where fixed-size buffers that are guaranteed to be large enough aren't, where strings are suddenly once again limited to 255 characters, where the kind of data that can be processed is once again subject to completely artificial limits, and other horrors from a barely forgotten past. Doing so represents a phenomenal step backwards for the language, for usability, and for security. - If pushed forward, it will cause the average programmer to either vastly over-allocate their containers, or strongly reduce the functionality (and possibly security) of their software. - Most programmers can absolutely not be trusted to specify capacity up-front, and programming their own allocators for dynamic resizing is a disaster waiting to happen. - The situation you desire can easily be obtained using a custom allocator, leaving the rest of us to enjoy the use of our dynamically-resizing containers. - There is plenty of hardware around right now that does not meet your glorious vision of the future, but for which we still write software. Bottom line, I am by no means opposed to the standard providing a new allocator model, nor to it providing a set of allocators that give the behaviour you describe. However, I am strongly opposed to making this the default. If you are in the small crowd of people that know what they are doing in this sense, specifying the correct allocator is not a big deal anymore. On the other hand, if you are not, things should just work. &gt; Those allocators actually have awful performance. Oh, seriously? But those allocators would produce the exact same memory image that your fixed-size capacity containers would produce: small blotches of data, separated by vast stretches of unused capacity. Why would it work for your containers, do you think, and not for malloc? Could it be that your notion that "address space is free" is not actually true, and that tracking and loading pages in the OS has a cost that you failed to take into account when you dreamt up allocator-free C++? &gt; without addressing the broken STL allocator design Mind, I'm not arguing against this. Just so we're clear. What I'm arguing against is fixed-size and/or up-front capacity containers. &gt; You know, you could just trust us on this stuff. The moment you come to your senses on the point above I'll happily trust you. Right now, not so much. &gt; inefficiencies at the micro-level Massive over-allocation of memory is also an inefficiency at the micro-level. &gt; Rust is faster than C++ at the systemic level, we need to up our game. Because it has much greater ability to prove things like 'restrict', and can thus choose faster algorithms in some cases. Not because they are stuck on fixed-size containers. 
Actually, it is true. The exact words from the standard are "valid" and "unspecified". From N3242: Table 20 — MoveConstructible requirements [moveconstructible] Expression Post-condition T u = rv; u is equivalent to the value of rv before the construction T(rv) T(rv) is equivalent to the value of rv before the construction [ Note: rv remains a valid object. Its state is unspecified — end note ] Table 22 — MoveAssignable requirements [moveassignable] Expression Return type Return value Post-condition t = rv T&amp; t t is equivalent to the value of rv before the assignment [ Note: rv remains a valid object. Its state is unspecified.— end note ]
Like 15.1 and 15.2, this is intentionally not a full toolset update. There are minor compiler fixes, and we're probably going to add a library fix (yes, our updates are followed by micro-updates). The good news is that 15.5 is the next toolset update adding many new compiler/library features and fixes. 15.5 Preview 1 was released today, see [its release notes](https://www.visualstudio.com/en-us/news/releasenotes/vs2017-preview-relnotes).
I don't have the data anymore, we are not using PCH here and it was in other companies. I can understand that you want proof, but I can right now only tell what 14years of practice reached me (it works but do not scale well with big complex changing codebase). Feel free to provide data points if you want. The link I provided before has the points I already gave.
I have participated in those discussions in the past and have been either ignored or rejected. I don't have high hopes for any future work on this.
In a similar use of attributes (C#): https://gist.github.com/hyrmn/3429595 
The ability to target both, a remote Linux as well as the local windows machine from within a single cmake based project sounds pretty nice.
Steve Jobs?
HTFU!
&gt;seriously why do they feel the need to make structs full of function pointers that can lead to thousands of bugs while C++ has a nice inheritance system that would make the code much cleaner. Agreed. There is a lot of attachment in the open-source world, especially in Linux/BSD/etc., for "object-oriented C", for some reason (also seen with gobject/glib/gtk). There is a classic and interesting book on the subject, [Object-Oriented Programming with ANSI-C](https://www.cs.rit.edu/~ats/books/ooc.pdf). But I've always found it quite amusing that by chapter 7, the author has been forced to invent what is actually a new language, with an accompanying pre-processor for converting it to C, since the coding is otherwise so tedious and delicate.
if I could bottle motivation, I would have drank it giving me the motivation to mass produce bottled motivation that I could sell and become rich so that I could relax on a beach in Tahiti.
&gt; One solution to the "where are my modules" problem I've heard is to have the compiler call back into the build system whenever it sees module X to get the path to the built module. If the compiler is dependent on the build system that way, isn't that pretty much functionally just making the compiler the build system/vice versa except keeping them separate enough to be able to say they're 'technically' different?
How do you know then that someone hasn't placed an `#ifdef`guard around the imports? If the imports run as a translation phase *before* the preprocessor then it would make sense for it to not work, but it also wouldn't make sense to have anything run before the preprocessor. And I want to note, you've placed in your own comment a world where the module name is tied to the filename. If they *aren't*, then what happens? We need to place restrictions like the one you're mentioning on modules or we're going to be in a situation where some build systems enforce specific rules (a dot represents a separation between a directory and a file, a module name must equal its filename) and others that try to support every project layout under the sun. My concern is that this is going to fragment the community further. You won't be able to have one build system's built library work with another, especially if they map module names to files differently. Having them support every possible mapping is (in my opinion) untenable. Give me a mapping, give me some form of rules. Don't let the build system community fight this out. It's only going to make it worse for C++ users. 
But Unix compilers (at least; I’m not too familiar with MSVC) can output dependency information in the same invocation that they also produce an object file, using -MMD (as the parent mentioned) or similar options. This works because traditional builds don’t require dependencies before a full recompile, and it avoids the overhead of processing the same source file multiple times. It seems like that will not be possible with modules, so modules will come with some (not fundamentally necessary) overhead that their inherent performance advantages will have to make up for. Maybe not much, since running just the preprocessor should be pretty cheap…
That's the original rationale, and it mentions container-of-one, but it is out of date anyhow. Yes, it was the original rationale, but optional grew from there, in various ways. It would be nice if there was a single place to point to, but the "rationale" was in the minds of committee members over the course of _years_ of meetings on optional. Optional is most closely "1) Just a T with deferred initialization". Whether that was the rationale, or whether it is ultimately the best model or not, it is probably the model that most closely matching actual behaviour.
The reality of a programming job is that you will spend 6-8 hours a day tapping away at a keyboard by yourself. Most companies try to minimize distractions for programmers so that they can "work". This is particularly true for the sort of middle stretch of your career where you are no longer actively being mentored, but not yet senior enough that you deal with cross team problems that require coordination. This is not to say that there is no socializing or water cooler talk in programming jobs, but the sort of image that is sold to students by coding boot camps and industry propaganda that is aimed at increasing the pool of available programmers is not in line with reality. Collaborating with your team generally means an hour long discussion followed by three days to two weeks of solitary coding with maybe a short discussion or two thrown in in the middle. Techniques like pair programming, that have more that one programmer working on the same code, are the exception not the rule in the industry. I did a informal poll in my office and not a single person on my floor of are office has ever worked for a company that has allowed/encouraged pair programming. If you continue to find this much coding to be a challenge you may want to consider entering a management track where you can use your technical chops, but get more social interaction and do not have to write as much code.
Yeah, you can't use Expected/Outcome/Variant/... as an argument for why Optional is a certain way. Optional came first (mostly). The others work the way they do in order to be consistent with optional. (I'm not saying Niall was trying to make that argument, his comment may have just been a "FYI")
Ya thats what my long term goal in programming is, to enter a leadership position because I love to put together teams and solve problems as a team (My IT project managment class was very much like this and I enjoyed every second of it). Of course C++ has its own benefits that I enjoy, making programs and video games for other people to use feels fantastic as much as overcoming the challenges of building the program in the first place. Maybe I'm just doing too much work a day. Still my goal has always been to become a team leader but In order to do that I need to know how to program as a team member, which I am completely fine with.
For C++, this adds official CMake support targeting Linux. This kind of proper cross-platform capability is what I've wanted from Visual Studio years and never actually expected, but hell has been freezing over for the part few years and the freezing continues unabated. The release notes link to more detail on that.. or here's the detail: https://blogs.msdn.microsoft.com/vcblog/2017/08/25/visual-c-for-linux-development-with-cmake/
There is a mod team I'm going to message for a game I love to play that uses C++ as the primary code base, I just want to finish the course first so I can join with the most amount of knowledge possible and I will be the most prepared. It will be there if I decide I want to go with game programming or stick with windows apps programming.
Ya I love programming, but back 2 back days without breaks working is eating away at my soul. Good thing I'm a bit ahead so I can take a couple of days for a break.
A practical reason: what would a (non-trivial) move ctor with your semantics look like? optional(optional&amp;&amp; other) : engaged{other.engaged} { if (engaged) new (storage) T(move(*other)); other = nullopt; // #1 } But `#1` is unnecessary extra work, as `other` is already in a valid state. So we may as well leave it out. This would be another matter if we had destructive move; in that case it would make sense to leave `other` disengaged, as the destructive move would end the lifetime of its contained value.
So I had a look at that page. Found it quite... thin. Point 1: yes, you need to split C and C++ translation units, what's the big deal? And yes, it's implementation dependent, there's no standard. There's no standard for padding either... Point 2: euh, yes, so? It's not ideal as per some idea Point 3: yes, repeating point 1 Point 4: why, yes! The only relevant build kind for PCH is \_DEBUG, and there, it's O0 anyhow. Point 5: see 4. They are doing it wring Point 6: yes. First somewhat relevant point. Point 7: yes, but they are made to speed up *my* modify/build/test(debug) cycle, on my sources, in my environment... they are not the ideal solution for some ideal... Point 8: yes, but do you have to do it? Point 9: yes, but the correct way is to also have a non-pch build in which the "all" header is empty. If you blow includes, build server tells you soon enough.
Your demand is our wish! 15.4 contains compilers and libraries for ARM64. Is there anything else we can do for you?
Does this release support a single install of Visual Studio that provides both 2015 and 2017 compiler packages that third party tools can properly use? I remember CMake, Qt, and other systems were pretty badly broken when using VS 2017 installer to provide both the 2015 and 2017 compilers. 
Isn't the moved from value of any type considered to be in an undefined state? If so, the state of the moved from optional doesn't really matter since accessing it is undefined.
For standard library types (and only for them and types you use with the standard library as types that have to be MoveConstructible/MoveAssignable), the "valid but unspecified part" is correct. The "only specified operations are reassignment and destruction" is plain wrong. It is perfectly valid to call size() on a vector you moved from, or get() on a unique_ptr you moved from. It is also perfectly valid to have a type (that you don't use with the standard library) that you can't assign to anymore after you moved from it.
Complete C++17 support? :p 
Ah ok. I use clang almost exclusively, and that's how it appears to be for clang (ie, I just tried -std=c++17 and it didn't work). I personally think it's a good idea to refuse to recognize "c++17" until it's official. But your point is good.
Their CppCon slides has that listed as 15.6, which hopefully isn't too far away if 15.5 has made it to Preview.
`It is perfectly valid to call size()` - valid? yes, specified? no. Again, "valid but unspecified".
Looks like _someone_ didn't watch The Latest And Greatest talk this year.
Not undefined — unspecified, but valid.
We'd intended to be feature-complete with regards to C++17 by end of calendar year 2017. However, we're more concerned about actually getting all the features right than we are about blowing our trumpets to celebrate, unlike some other compiler vendor* And so it slipped....but yes, we expect 15.6, early in 2018, to have all C++17 features. We still won't have finished our conforming preprocessor so we won't be standards-compliant. But with all the features, and just a few bugs, we'll be close enough to call it good with an asterisk. **By "some other compiler vendor" I mean "Microsoft, many years ago."*
Beep beep boop boop, I'm not a bot. But here's the Latest and Greatest talk: https://www.reddit.com/r/cpp/comments/741zli/cppcon_2017_steve_carroll_daniel_moth_latest/ ^Downvote ^to ^remove.
See [my reply] (https://www.reddit.com/r/cpp/comments/75eqal/millennials_are_killing_the_modules_ts/do5tqss/) in another thread.
Shit, I upvoted it for the title alone just because the boomers rage at us is fucking hilarious.
I do C, and can someone explain what the whole point of modules in C++ is? is it to help develop a more stable ABI?
&gt; If the imports run as a translation phase before the preprocessor [...] I never suggested the module dependency information is extracted before preprocessing. On the contrary, I suggest that it is combined with the header dependency extraction, which is already essentially a full preprocessor run. &gt; [...] you've placed in your own comment a world where the module name is tied to the filename. Yes, but in my approach this is done by the build system, not by the compiler or worse, the C++ strandard. &gt; [...] we're going to be in a situation where some build systems enforce specific rules (a dot represents a separation between a directory and a file, a module name must equal its filename) and others that try to support every project layout under the sun. So? Is this what makes Modules TS so fundamentally broken in your view? &gt; You won't be able to have one build system's built library work with another, especially if they map module names to files differently. Build systems can communicate this information quite easily, for example, using something like `pkg-config`. You can read more about [how we handle module installation in `build2`](https://build2.org/build2/doc/build2-build-system-manual.xhtml#cxx-modules-install). 
Actually, it is specified. A vector is specified to be empty after you move-constructed from it. A unique_ptr's .get() is guaranteed to return nullptr after you moved-assigned from it. And there's loads of other examples.
Good ~~boy~~ bot
Just because you depend on something doesn't make you that thing. This puts none of the decisions the build system makes into the compiler, it just gives the compiler a way to ask the build system to make those decisions.
This [Introduction to C++ Modules](https://build2.org/build2/doc/build2-build-system-manual.xhtml#cxx-modules-intro) talks about the benefits.
Damn! C11 support then? ;)
[Here](https://www.youtube.com/watch?v=LmiDF2YheAM&amp;t=2549) you say that `boost::variant` uses dynamic allocation during type-changing operation. How can you explain [this](https://wandbox.org/permlink/bO6uzEITJXWatsd8)? Type is changing, but there is no allocations.
It's not the one way dependence either way, it's the two way dependence that makes them functionally inseparable as a concept. A compiler can exist without a build system as it is right now. If you do what you suggest, the compiler can no longer exist without the build system, so they are functionally inseparable even though they exist separately as concepts. This is called out in the article multiple times.
It is a two-character sequence that is treated as a single character by correctly-written software.
U+1F63B is objectively the best possible choice. And that's pretty much all there is to say on the matter.
Ya I heard of the stories of people getting into programming jobs without degrees but it seems like they are the exception and not the standard. Might as well play it safe and wait till i get the degree before sending out applications.
Ya Ill give it a little bit of break. Again this week is a special exception because a new course started recently and the professor likes to go front heavy so i got sacked with 4 chapters of assignments. Next week will be more calmer seas as it will be back to1 chapter from my other class and 1 chapter from my c++ class
The thing about shitting on millennials is that most people who do it are also millennials and don't even realize it https://en.wikipedia.org/wiki/Millennials
See these two threads: https://www.reddit.com/r/cpp/comments/6mqd2e/why_is_msvc_usually_behind_the_other_compilers_in/dk6w0qj/ https://www.reddit.com/r/cpp/comments/66no4v/question_about_c_version_on_nintendo_switch/dgoxaho/ TL;DWR? The simple answer is that we're doing C++ first because that's what we hear about from the vast majority of developers doing MSVC. Our C conformance push has started but it's currently nowhere near the level of our C++ conformance push. We plan to focus more on C once we've finished with C++ conformance. And just in case this is your next question, we did actually look at Objective C support and decided that now isn't the right time to pursue it. 
I'm not sure what third party tools need, but all versions of VS2017 have included the VS2015 toolset. If you know of any specific breaks, or have specific contacts, please get me in touch with them. We want these tools to work with VS2017. We've already reached out to NVidia about getting CUDA 8 to work with the VS2015 (v140) toolset. They're looking into it.
I like the shorter turnarounds, keep up the good work!
AVX-512VL! :)
&gt; And just in case this is your next question, we did actually look at Objective C support and decided that now isn't the right time to pursue it. That would shock me. Does anyone actually Objective C, as a language? Swift would make more sense if you're trying to appeal to Apple devs, and I can't imagine that ever happening, either.
Consistently one of my favorites parts of CppCon. Thanks to /u/JonKalb and the panelists for keeping this going. (And thanks to Jon and the other volunteers for the conference as a whole!)
Ack, right. Meant to say in the standard (as in released document) and mis-"spoke."
Thank you, can't wait enough for 15.5 and 15.6 with full C++17 :)
TBH, I hope the abomination that is Obj-C will just die away.
I did, and noticed that there were no features listed for this version, but wanted to confirm at the source.
[Islandwood](https://developer.microsoft.com/en-us/windows/bridges/ios) was the motivation. Swift wasn't a thing when we looked into it.
Fair enough. Was just joking around though.
[MSVC supports AVX-512](https://blogs.msdn.microsoft.com/vcblog/2017/07/11/microsoft-visual-studio-2017-supports-intel-avx-512/). I don't know about the Skylake extensions but I'm pretty sure that if they're not in the compiler already, our Intel devs are working on it or planning to. If it's important and the extensions aren't there (please check first!) send me a mail. 
&gt; because the majority of software already runs plenty fast enough, and if it doesn't, this kind of bit-f*cking is not going to help you anyway because it is typically caused by bad choices of algorithm, the use of massive, but ill-fitting frameworks, and/or the sheer volume of data to be processed. There is an increasing divergence between algorithmic complexity and computational complexity over time. It's that increasingly yawning gap between how code ought to perform and it does perform that we need to tackle. C++ the language, apart from RTTI and exception throws, is capable. C++'s standard library apart from the containers and i/o layer is mostly serviceable. I intend to start the ball rolling on replacing the i/o layer with something much better next year, and springboard from that the new options that opens up into fixing containers in C++ with ones that don't have so many hidden performance killing design choices. The committee will probably ignore me. But I'm going to try anyway. The very most recent Intel CPUs finally have hardware counters with the granularity to really demonstrate how damaging allowing unbounded execution is anywhere in your standard library. We'll press on that and see how many minds we can convert to the cause. The rest of your post shows you ignored everything I said and have decided I am talking about whatever which means there is no point in me repeating myself once again. And that's fine. People believe what they want to believe. You'll be seeing plenty more of me repeating myself over the next few years. You may even come round.
I'm guessing op is referring to https://developercommunity.visualstudio.com/content/problem/22031/unusable-vc-build-tools-2015-installed-with-vs2017.html
&gt; I see no way that virtual memory can become part of the standard in near future, if at all. I *believe* I have the correct minimum viable subset in https://ned14.github.io/afio/classafio__v2__xxx_1_1map__handle.html I haven't built my planned `std2::vector&lt;T&gt;` prototype yet, so I can't be absolutely sure. But I believe I have it right. &gt; I don't know what you mean by mentioning file I/O here. Files are files, memory is memory. Are you suggesting that people should preallocate everything and back it with files?! (E.g. memory mapped files)? Sigh. *All* memory in any page caching kernel (Linux, Windows, OS X, FreeBSD, lots and lots more) is part of *some* file somewhere mapped into memory. Every `malloc()` implementation either calls `sbrk()` or `mmap()`, almost always the latter nowadays. And in `mmap()` you specifically pass in -1 for the file descriptor to mean "the system paging file". Every single byte of memory returned by `malloc()` or `new` is mapped from a file. **All of it**. AFIO exposes the virtual memory management facilities provided by kernels for over two decades to the C++ standard library. The choice then becomes available to a new generation of standard library containers to utilise those to dramatically improve worst case execution times. You may benefit from reading up on how tcmalloc works to give you some idea of the potential performance gains of utilising 64 bit address spaces and virtual memory management. tcmalloc never frees memory, not ever, letting it skip the very costly free block amalgamation scanning and other parts of what makes malloc slow and unpredictable. Yet system memory does not rise infinitely. Go figure that out and you'll begin to see the potential here.
Well I'll try that out then. In my case I made something that kinda worked for what I needed because OpenCV's wrapper gave no option for quality/encoding speed and that's not acceptable for what I needed. It's really ugly but is stable enough for everything I tried.
I believe that a lot of tools out there were/are unable to properly detect the v140 toolset as installed by vs2017, as for some reason the vcvarsall.bat for v140 is broken (unless vs2015 or the 2015 build tools were installed prior to 2017). The exception is cmake and its 'v140' toolset flag, which has always worked, however this only applies to the "Visual Studio" compiler. Visual studio 15.3 does introduce updated vcvars where the toolset can be passed as an argument, but that's fairly recent, but that is still fairly recent and the syntax is different (different than it has been through the years, I would say)
I believe that a lot of tools out there were/are unable to properly detect the v140 toolset as installed by vs2017, as for some reason the vcvarsall.bat for v140 is broken (unless vs2015 or the 2015 build tools were installed prior to 2017). The exception is cmake and its 'v140' toolset flag, which has always worked, however this only applies to the "Visual Studio" compiler. Visual studio 15.3 does introduce an updated vcvars bat where the toolset can be passed as an argument, but that's fairly recent, but that is still fairly recent and the syntax is different (different than it has been through the years, I would say)
Pretty long winded answers.
I realize there's a time crunch, but can we not request 2-sentence/5-word answer limits to questions? I feel like it wastes time (with people spending time thinking about/counting out answers, then awkward laughter) and we miss out on potentially more interesting and thoughtful answers to otherwise interesting questions. I love these segments, I just also find those parts so cringeworthy. 
Do you have 15.5 online somewhere... This site is unalive at the moment: http://webcompiler.cloudapp.net/
Beman Dawes was [working on a proposal](https://github.com/Beman/unicode/tree/std-proposal) a while ago, but I'm not sure of the status of it -- does anybody know if it's still in progress?
Still no fix for intellisense not working with structured bindings? I avoid using structured bindings until it's fixed to avoid false positives pollution.
Without C there would have been no Objective-C, and without Objective-C there would have been no NeXT, no Apple renaissance and no iPhone. Maybe. Or maybe NeXT would have continued using Smalltalk. Who knows.
It's very rare today to find a mom and pop shop that does quality hand-compiling. It's all industrial now.
The worst is that there are no features that are exclusive to C and could bring better performance than their idiomatic C++ equivalents, except maybe stack variable length arrays, but compilers can remove your dynamic allocation in your vector if they see its lifetime doesn't go further the current scope. Outside of maybe compilation times and inertia, is there any valid argument for using C now? 
Does this mean that existing CMake projects can be edited using VS? I'm one of the few people on my team who primarily work in Linux rather than Visual Studio, so giving an easier way for windows people to edit our project settings means there's less of a chance I'll be forced to migrate to Windows
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4543.pdf https://github.com/potswa/cxx_function http://naios.github.io/function2/ Need someone capable to actually standardize it.
No. The webcompiler would be the only place with it and it's down. [You can install the VS 15.5 preview](https://blogs.msdn.microsoft.com/visualstudio/2017/10/11/visual-studio-2017-version-15-5-preview/). We're trying to make this whole webcompiler thing better, but it's not the top priority. Sorry. 
/u/magila, thanks for the link. The right guy (Daniel Griffing) is on that thread. He's the one who fixed the vcvars bat in 15.3 to take a parameter. If tools are unable to use the new vcvars bat, you should let us know. We are hoping--just like the new toolset binaries layout in VS2017--that we've properly componentized and cleaned up vcvars.bat so that we don't have to change behavior in the future.
That guy asking question around 48m... ffs stfu.
Hmm… interesting. From that reply? &gt; For example, with this approach we cannot support generated source code as part of the main build stage (and often have to resort to ad hoc pre-build steps). How does this work? If a file #includes a generated header, then preprocessing it before the header is ready will just produce an error. You don’t necessarily know where the header was expected to be located (although I suppose there are ways to work around that), and you definitely don’t know what other generated headers may be included from that one (potentially conditionally). Does build2 just keep rerunning the preprocess until it succeeds, or something? Either way, how exactly does the approach rule out combined dependency generation? 
1) This isn't subjective...to... can safely be moved from. First thing first, the code you posted here: ``` struct S { } s; S{} = s; ``` cannot be compiled properly so your statement can not be verified. Even if it is compilable, I cannot see the CONCRETE use case of the code. And pure coding puzzle is not my first priority. I remember the original statement in the article is "A rvalue is one that should be on the right side of an equals sign.". So, again, we do not need to discuss which side an lvalue should appear. 2) I do not see where... to ... changes program semantics is when you move() an lvalue ``` #include &lt;stdio.h&gt; // isTure has two value 0-&gt;false, 1-&gt;true void printBool (int isTrue) { bool bIsTrue = (bool)isTrue; printf("%s", bIsTrue ? "true" : "false"); } int main() { printBool(0); } ``` even though isTrue is declared as an int. I know it is essentially a `bool` by understanding the context. Even though the compiler can not recognize it, I can cast it to `bool`. Likewise, a property of an rvalue (r1) is essentially a rvalue (r2) as it (r2) will disappear very soon with r1. Even though the compiler can not recognize it, I cast it to rvalue. 3) This is an important point...to...That conclusion is very wrong. Reference binding is a term. Reference binding does not generate machine code because "it does not generate machine code". Since it is not that obvious, I would hand test that "it does not generate machine code" directly. "move semantics, as a whole, doesn't do anything." is not a valid conclusion you get from the article. Please let me know if there is still anything that is not clear. Thanks. 
Well Google uses modules for years... I guess they would notice if TS was broken.
The implementation of modules at google is not the same one found in the TS.
Tak!
&gt; First thing first, the code you posted here: `struct S { } s; S{} = s;` cannot be compiled properly so your statement can not be verified. Uh, *of course* it can? First of all, you could just try to do it and see that it does: [gcc](https://wandbox.org/permlink/vwSpUdKLYQytLTfn) [clang](https://wandbox.org/permlink/z6x9gH2YTVh0us7H). Secondly, you could look up the rules for the special member functions and see that they would be (a) generated for this type and (b) not ref-qualified, so of course this compiles. &gt; I cannot see the CONCRETE use case of the code. If you actually bothered reading my post, you'd see that the reason I showed this example is to illustrate that the names lvalue and rvalue have nothing to do with their relevant position in an assignment operation. `S{}` is an rvalue, and is on the left. `s` is an lvalue, and is on the right. The point of the example isn't to be meaningful code, the point is to demonstrate the problem with the definitions your provided. &gt; I would hand test that "it does not generate machine code" directly. Look, you can't just "hand test" your way into understanding C++. You have to learn what the semantics of the language actually mean. You're not going to do that by just plugging code into a compiler and seeing what comes out, with optimizations disabled. The rules are really complex and you do not understand them (the commentary about your `printBool()` function is also wildly unrelated to value categories). I would suggest taking a look at [The Definitive C++ book list](https://stackoverflow.com/q/388242/2069064) and going through some of the newer ones that go over the C++11 features. Once you do that, you'll hopefully see that that entire section of your post is missing the crucial detail that `ResourceOwner &amp;&amp; rvalue = std::move(res);` **does not move anything**. And you're trying to derive the meaning of move semantics based on looking at the compiler output of code that does not actually invoke move semantics. So either help yourself with one of those really good books, or keep arguing with me. Your choice. 
Do what you want but my feeling is that you will feel regret if you give up. 
Never gonna give up, to deep in now for that, just need to probably slow down a bit with the pace of the work.
**If** it was desirable to go this way, I think exploring compiler access at compile time could be a pretty nice minimalist direction, similar to what Jon Blow is doing with Jai. Assuming we get constexpr blocks, along with that compiler object, our actual build process could be written in C++ directly: constexpr { std::constexpr_vector&lt;std::path&gt; obj_files; for (path : std::directory_iterator(".")) { if (path.extension() == "cpp") { auto obj_path = gen_obj_path(path); compiler.compile_file(path, obj_path); obj_files.push_back(obj_path); } } run_linker("my_program", obj_files); } Compiling would just be running our compiler on one file, say "build.cpp". Different build systems could be provided as constexpr libraries, providing all the bells and whistle expected from a full blown build system. And the committee could just standardize what the compiler interface should look like (Can we ask for the list of modules a c++ file imports ? Quickly know which module a c++ file implements ? Do we standardize the notion of include paths ?). Again, I am not sure this is desirable, it would require filesystem access at compile time, and probably the ability to launch external processes as well, which opens all kind of security problems (but well, thats pretty much already the case, you link with a lib, you assume its code is not malicious). Still it seems like a direction I'd prefer rather than standardizing a full blown build system and package manager.
still, they and MSFT have two implementations of modules... Hard to imagine that people that actually implemented modules would not notice all the problems you claim exist...
That's a strong assumption that Steve Jobs gave a shit about the programming languages involved in his vision. He wasn't the one that made the technical things happen, and I'm sure that if we weren't using C there'd be some other high-level language that would have gained popularity in systems. Additionally DOS was originally written in Assembly. So did Dennis Ritchie really "make" Bill Gates? Dennis Ritchie obviously created something great and world-changing, so let's not reduce his impact to nonsense.
Does this break CUDA?
We don't appreciate your sense-making here. This is the internet, damnit!
Last I checked, swift has poor c++ interoperability. Objective C(++) mostly just works. Maybe that has something to do with it?
git worktree support for in-ide blame?
15.5 won't be C++17 complete, but we're getting very close. The number of remaining STL features is in the single digits (Billy's working on parallel and I'm working on deduction guides, that's two right there).
Whether it's true or not, it's excellent dogma to live by. Do not observe the state of a moved-from value.
6502
Hipster.
&gt; The number of remaining STL features is in the single digits In what base, pray tell?
Decimal but not octal - yet.
From what I've read so far these issues sound the same as Fortran 90 modules. I know at least cmake has some support for those, are there significant differences that I am missing?
Merry Christmas!
This was an interesting paper. I wish it had masterconfig like versioning. It has the version number in the code not as a side file. But I liked the idea of making the compiler a build system. But I don’t think it is everyone taste. 
CMake support is something you can do in an extension, so it's still relatively minor I guess.
&gt; In what base Of course 10!
I know Intel's MKL also broke my compilation for running 2015 from 2017, and their uninstall doesn't work correctly so you have to manually delete some files.
`[p]`.
So when does that WDK support come out? 
Because C++ is not Rust.
That's true. I've mostly used external build systems, and eventually written custom extensions for to streamline the workflow (along with another script that generates the project from the source tree, which I've rewritten a bunch of times over the years) - but it's nice to have more things supported, to hopefully have standard support for something decent.
So less than 3,628,800
In my implementation there is another array containing the index of the corresponding slot, which is index locked with the data array. This way you can go to the same index as your data in that array, and it tells you which slot to update.
Company: [Microsoft Visual C++](http://microsoft.com/) **Type:** Full time **Description:** We make developer tools for C++ programmers. The team I need to hire for this time is the team responsible for CMake integration, VS Code C++ extension, and our Android / iOS targeting. I'd consider multiple levels of experience, but ideally more than 3 years of experience. **Location:** Redmond, WA. **Remote:** no. I'm sorry, but we aren't doing that right now. **Visa Sponsorship:** I'm looking for US work eligible candidates only. **Technologies:** modern C++. There is also some managed C# code in our IDE and VS Code has a bit of typescript in it. CMake integration in VS is a relatively new code base. **Contact:** reddit PM
we strive to keep intellisense and the code compiler in sync. do you have a dev community link for me to check on?
I haven't checked with 15.4 yet, but my general impression is that intellisense is pretty unstable with cmake projects (in particular finding includes und goto Definition). Curiously, it sometimes helps to just restart VS.
Recast/detour is the go-to solution for navigation in games, and it is used in both unity and unreal. I included navigation meshes because I think they solve a classic problem far more effectively by representing the data (traversable terrain) in a different way. I didn't go into the memory layout of them because that's not the part that I find fascinating. In general, all connected graphs can be searched with Dijkstra's algorithm. The subset representing euclidean space can likely be searched using A* with a Euclidean heuristic. While not the only solution, this is a pretty general solution that should always be correct, though it may not meet the performance needs of a particular use.
That's a really great approach for lookup optimized versions, but hits iteration speed by taking up cache alongside the data. My implementation uses another array for it, and the entries in that array are index matched with the data. Same general concept though!
I don't think operator new / delete are called, only placement new / delete
Please ask cppweekly to do one episode on this :p
But we're loosing expressive power then. If you cannot do it with the preprocessor, someone somewhere will write his own custom preprocessor one day.
Allow me to add https://github.com/jamboree/CxxFunctionBenchmark to the list :)
/r/cscareerquestions/
&gt; but when you use std::array, you don't necessarily. Yes you do, it's sizeof(std::array&lt;T, N&gt;). &gt; It would be pretty dumb for an implementation to make std::array pose a big risk for stack space, but it could. All implementations automatically provide the means for a stack overflow through the std array class or the raw arrays. If you do either of these: int a[1000000000]; std::array&lt;int, 1000000000&gt; a; Most probably your executable will crash with a stack overflow exception. 
The implementation found at Google does not have the same issues found here. It is completely different in how modules are implemented and used. And considering the number of people working on modules at Microsoft (a literal handful) it's quite easy to see why they would not see these issues, in the same way that many did not see why adding a keyword named "yield" to coroutines will not work. 100 eyes are better than a dozen.
It does indeed. The VL is the Vector Length instructions which bring the new functions in AVX-512 to 128 and 256 bit wide registers (XMM + YMM). The AVX-512F (Foundation) only brings new instructions to the ZMM 512 bit registers. When the VL is enabled in the CPU the code can be more symmetric, especially for compare-select operations because the comparisons result in per-lane k-mask register instead of vector register with all bits set to 0 or 1 to indicate compare result. I could write some ifdef-else magic to work around this in a vector library I have been working on so that when compiling for AVX-512 without VL present (visual studio) to use the older mask register schema but that would defeat some of the advantages the Skylake-X brings into the game. SL-X supports VL of course. The code I been working on can be found at: https://github.com/t0rakka/mango The interesting folders in this case are: - include/mango/simd - include/mango/math I wrote some posts about AVX-512 programming for example this one: http://codrspace.com/t0rakka/software-rasterizer/ The code is tuned for minimum overhead and compiler output is examined regularly. Things must run in registers as much as possible and if not the code has been meticulously refactored until that condition has been satisfied. This is the case with clang and gcc as their default x86-64 ABI promotes passing float arguments in vector registers. On Visual Studio side I need to use __vectorcall which is still pending; I figured I get around to it eventually but so far I been unable to switch AVX-512 compilation on with that compiler unless I add support for non-symmetric handling of mask registers (see above). So, basically, on Windows the 512 bit wide registers are just two 256 bit ones unless either VS implements VL or I implement the fallback mask handling. :) (so it's on me just as much or even more than on you but never hurts to ask, right? =) 
&gt; How does this work? Pure magic ;-). Seriously, though, the compilers have support for handling non-existent headers (see `-MG`), we use a heuristics for determining where the non-existing header is generated, and yes, we keep re-running the preprocessor to discover all the generated headers. &gt; Either way, how exactly does the approach rule out combined dependency generation? Not sure I understand the question. You cannot compile a translation unit if some of its headers do not exist (or, worse, out of date -- you will just be wasting time). 
Concrete code example: // AVX-512VL static inline mask32x4 compare_lt(float32x4 a, float32x4 b) { return _mm_cmp_ps_mask(a, b, 1); } static inline float32x4 select(mask32x4 mask, float32x4 a, float32x4 b) { return _mm_mask_blend_ps(mask, b, a); } // SSE4.1 static inline mask32x4 compare_le(float32x4 a, float32x4 b) { return _mm_castps_si128(_mm_cmple_ps(a, b)); } static inline float32x4 select(mask32x4 mask, float32x4 a, float32x4 b) { return _mm_blendv_ps(b, a, _mm_castsi128_ps(mask)); } // SSE static inline mask32x4 compare_le(float32x4 a, float32x4 b) { return _mm_castps_si128(_mm_cmple_ps(a, b)); } static inline float32x4 select(mask32x4 mask, float32x4 a, float32x4 b) { return _mm_or_ps(_mm_and_ps(_mm_castsi128_ps(mask), a), _mm_andnot_ps(_mm_castsi128_ps(mask), b)); } That's the low-level which is wrapped with operator overloading on the higher level math so the usage can be like this: // result = a &lt; b ? c : d; float32x4 result = select(a &lt; b, c, d); It's not a Big Deal per se if the AVX-512 compilation would use the SSE4.1 code path but then juggling the mark registers between different formats would become more expensive. movemask instruction can do the maskToInt conversion so it's possible just.. ugly. I am more interested in seeing how the CPU instruction support roadmap shapes in coming years if we really need to make distinction between F and VL. If that turns out to be the case then the different paths will need to be crafted. WIP. 
Glad to see people got it.
How does that help? If I currently write #include ` "xx/yy/foo/bar.h" `, the C++ standard says nothing about where bar.h should be located.
&gt; What do you see as being the differences in the problems being solved? (Truly curious, not snark.) The OS package manager provides a set of applications and a consistent set of libraries to support them. The "language" or development package manager supplies a set of dependency libraries at specific versions and builds your application so that it can be reproducibly built in different environments (this involves lockfiles, etc). This often means using some bleeding edge libraries you do not want to install system-wide (because they would break whatever apps you need daily). &gt; So how is the OS (distro) package manager supposed to know that a C++ compiler is installed This is by far the biggest problem there is with language package managers and it goes both ways: how is the language package manager supposed to know that you have a native library (say, OpenSSL) installed when you're building an app in python/rust/etc that needs the lib. It gets worse if you'd want to use a Rust lib from Python, for example. I don't know what the solution to this sould be. Right now a popular solution seems to be using the language package manages to build binaries that get packaged in .deb or other distro packages. On the other hand, delivering commercial software to end users is a whole different deal. Binary packages are distributed through app stores or delivered to the customer as some kind of installer or deployed to a bunch of servers and all these cases bundle all or most of their dependencies. These cases need to be covered by the language package manager and build tools. Version control (git submodules) and containers (docker, etc) solve somewhat orthogonal issues. Software distribution seems to be an unsolved problem. At least there isn't any universal one size fits all solutions.
Shameful plug :) https://github.com/zura-kh/yaf.Function Not a replacement but similar. Works for pre-C++11 compilers as well.
[Here](http://forum.dlang.org/thread/tcrdpvqvwxffnewzohuj@forum.dlang.org) are tips on how the D programming language works. In sort: -the D compiler tool 'dmd' stops if it doesn't file a module. -the D compiler tool 'dmd' can export a module's dependencies. -another tool, 'rdmd' (sort of recursive dmd I assume) calls dmd to export the module dependencies, then invokes 'dmd' to compile the files. Dlang doesn't avoid processing code twice, one for extracting module information and the other for compilation. Of course this might not be hurtful for D because it doesn't have the preprocessor and header files. 
I'm updating later today - is there support for CMake &gt; 3.9.1 yet, e.g. 3.10.0-RC or a 3.9.nightly? They've fixed many C++17/VS2017 things and it's too bad to be stuck on the 3.9.0 that VS2017.3 comes with.
I see 15.4 has a bug (and workaround) that means cmake and linux targeting aren't playing nicely together. Fix looks simple enough and MS say they will roll it into 15.4.1 soon... https://developercommunity.visualstudio.com/content/problem/128569/cmake-unusable-after-upgrading-to-154.html 
I've only used fuzzing on one of my projects; When we introduced it, it doubled the number of active defects in our database. We found: - memory errors (overflows, access violations and corruption) - state errors (put your library in an error state with invalid inputs, then call it again) - silent failures.
Lua has a LUA_USER_H macro that allows you to insert (with -D) a header into compilation of the Lua implementation. For example, if you want to redefine file open calls then #define fopen my_fopen in a my_fopen.h header, implement my_fopen, and compile Lua with -DLUA_USER_H=my_fopen.h .
Could tag him, /u/lefticus.
ah, I wasn't aware he was on reddit too!
Having named tuples would be nice. All one needs is to turn a compile-time string into a type. You do this with macros and template metaprogramming, but there is also experimental support in gcc and clang for this proposed extension. You call it string interning, but your implementation produces the same type for strings that match up to N characters and only differ from N+1 onwards, if I read that correctly. That's a limitation you might want to mention. I don't understand the significance of your "loophole" technique. It just seems to map compile-time numbers to types, and if it is only that then there are already libraries for this. Boost.MPL or Boost.Hana.
FWIW, https://github.com/boostorg/variant/blob/develop/include/boost/variant/variant.hpp#L835
What is the advantage of named tuple other simple structs? Especially now that we have structured bindings,
Hi. I should thank vormestrand for posting the link to my post. You're right in most of what you've written. There is a limitation to the string length. And there is also an N3599 proposal which GCC and Clang implement and it removes it (#define N3599 before including nuple.h or intern.h, should add a note about it). Concerning type loophole, you should check out this Reddit [post](https://www.reddit.com/r/cpp/comments/6ydxya/the_great_type_loophole/). 
Tuples have their own advantages. It's less typing. Also you can use it to return multiple values in one line. A named tuple just makes it less error prone and more readable.
How is the named tuple less typing than the `struct`? And how is &gt; Also you can use it to return multiple values in one line. A named tuple just makes it less error prone and more readable and advantage over struct? I see the `struct` having the same properties.
https://developercommunity.visualstudio.com/content/problem/89750/structured-binding-range-declaration-in-range-base.html I was hoping pending release means the next version (15.4).
tuples have predefined logical operators (like ==, &lt;= and so on).
 struct test { int a; int b; }; vs (using luple - my implementation of tuple) luple&lt;int, int&gt; Also no name pollution with some bizarre custom structs. The problem is when access it with get&lt;0&gt;() you can mess up the index, especially if you make changes. Named tuple would be: nuple&lt; $("first"), int, $("second"), int &gt; Well, may be not so terse as luple, I agree. But still no superfluous types. Also you get the same benefits of a struct, but also convenient access methods like get&lt; name or index&gt;: auto p = get_person(...); //return nuple std::cout &lt;&lt; get&lt;$("name)" &gt;(p); std::cout &lt;&lt; get&lt; 0 &gt;(p); It can be really useful to access not by name, but by an index or type. With named tuple you have this flexibility. For example, you need to serialize your struct. With a tuple you use things like this: template&lt;typename T, int... N&gt; void serialize(T const&amp; t, std::integer_sequence&lt;int, N...&gt;) { char dummy[]{ ( write( get&lt;N&gt;(t) ), char{})... }; (void)dummy; } 
Thank you for the awesome write-up! I ran into this problem the other day when writing a function that took a matrix&lt;size_t Rows, size_t Cols = Rows&gt;::iterator and wanting to specialise for when Rows == Cols. Of course the matrix size couldn’t be deduced from the iterator. I thought that there must have been a good reason for it but I hadn’t managed to find a good explanation until now. Saving for when I get back from holiday. Thanks again. 
A minor point, but Kenny Kerr doesn't wrap Win32 in modern C++. He wraps WinRT in modern C++ - a much easier proposition. Unfortunately, the only way to distribute such apps is the Windows Store.
&gt; So? I'm coming into this thread very late. I can't say I understand everything about the Modules approach; I'm letting the build system experts duke it out. But it seems to me that this is the precise point in the conversation where you agree on what your disagreement is. Your blasé response surprises me. I don't understand how we can expect to be able to grow an ecosystem of cross-platform C++ libraries that can be used in different projects using different build systems unless these things are standardized, or the need to standardize this behavior is eliminated by a different technical approach. What "market forces", so to speak, would prevent the balkanization of our library ecosystem along the lines of competing build system conventions? Why would I, a hypothetical library developer, want to put a lot of work into module-izing my library by guessing at a convention that might simply be obsoleted by some different consensus that emerges five or ten years from now? In that role, I do absolutely want this behavior standardized. You say that "build systems can communicate this information quite easily". You are suggesting that different build systems must communicate with *each other*, using an non-standardized but otherwise agreed-upon file format? I truly don't get it. Perhaps it's because I've been coding in C++ for 26 years, but I've managed to do so having never written a pkg-config file. Your build2 link proposes a .pc file, which I've never heard of before. Why shouldn't another build system invent a different mechanism than your .pc file? 
Thank you for the nice comments and for writing them down :) You're welcome! 
Okay, imagine `import a.b.c. from ABCPATH` where `ABCPATH` a macro is passed by the build system. With your proposition, this would be possible. Now imagine writing this everywhere. You don't have the module path directly in your code, nor turning the compiler into a build system and vice versa. Simply long config, that the build system can easily generate. Then, why bother writing `from ABCPATH` or `from ZYXPATH` everywhere? Pass the path of every modules name to your compiler from the build system like before, but tell the compiler "hey that module name equal to this path!" for every modules, and linked libraries modules. Then, you won't need the `from "any/specific/prefix"`. We're back to the current proposal, and you didn't turn the build system into a compiler, nor you turned the compiler into a build system. The build system already know all this information. It just need to tell the compiler where to look for modules, then the compiler could give the dependency graph back to the build system. If you're putting paths to module in your language, you're turning the *language* into a build system configuration. There should be no reference to paths in the language. The processor is horribly broken in that regards and everyone lives with it. We're moving into something less broken finally.
[removed]
Yeah, that is convenient. I think that struct were going to have them default generated but this proposal was not accepted into `C++17`. Though you only need to implement `==` and `&lt;` and after that `std::rel_ops` can fill the rest.
I'd try backing up its CMake and overwriting it with the one you want. Seeing that its version is "3.9.2-MSVC_2" rather than "3.9.2", I think there's a good chance it includes proprietary changes, and thus won't work.. but I'd be trying it anyway because I'm a loose cannon. Loose cannon I say.
you dont have to declare/name it up front?
Please elaborate.
I actually wonder why hasn't someone proposed to treat aggregate structures as tuples in C++ with built-in get like operators many years ago.
&gt; `std::rel_ops` And then inequality comparison between `std::unique_ptr&lt;int&gt;`s will suddenly stop to work.
Pretty sure you could make it work without relying to the $( ) thing by using a const expr crc of the string
i knew where this article was heading to and found it helpful to have the example of [this](https://stackoverflow.com/a/25245676/3783662) stackoverflow answer at hand. its very short, clear and you can directly see the problem (for the c++ part only of course). in my opinion it's harder to follow your post with all the small code-snippets which finally don't even come to such a clear example like the stackoverflow answer. anyway, i dont wanna rubbish your work and just leave this reference here. maybe it helps out more people :-P 
I think it gives you almost full compile time reflection: you can serialize it or write even more crazier functions by introspecting its contents. Generating models for displaying/editing contents in GUI is another usage. 
&gt; that many did not see why adding a keyword named "yield" to coroutines will not work. agricultural and financial software? LOL. Adding co_ abominations was one of the worst ISO decisions ever, and competition is really good. So anyway IDK a lot about modules but if Google people vote for C++ Modules TS I trust them.
Thanks for the information :) Great talk by the way, I thoroughly enjoyed it.
Like to use the struct you'd have to define it somewhere first. WIth the tuple you just define it as you use it.
I say fortunely, as I am for sandboxing all apps. Specially relevant in the context that not everyone is willing to adopt C++ best practices.
Multi-billion dollar industries with decades of code? LOL**_!!_** &gt; IDK a lot about modules but if Google people vote for C++ Modules TS I trust them. Ah, the appeal to authority — truly the laziest fallacy, for when you don't know WTF and can't be bothered to think things through even the _tiniest_ bit. &gt; ISO ISO ISO ISO ISO Don't you get tired of posting the same tired bullshit every single day?
If you return it from a function you would be writing it out twice yet not giving it a name. 
C++ code can run on systems without disk. On systems you mention, swap can be turned **off**. Windows does not do mmap (userland is different). But you can do memory mapped files there just the same, probably emulate mmap well, so ok. I do not believe you when you say that all of allocated memory is backed by a file. In fact, I rather think that it is a completely preposterous idea to go around some file just to get a bit of heap and that no sane system actually does that. Good luck with that.
your rage filled answer ruins your credibility... I mean a lot of stuff that ISO does is crap, but nerd rage is not a proper way to convince anybody... 
My experience is that named structs end up saving a lot of trouble and pain in the end. Templates without names cause confusion and more difficult compile time errors. Naming structs ends up avoiding unnecessary meta programming and gives clearer error messages and documentation. 
well you could use auto :) And the not giving it a name is significant I think. It implies that it is not an entity unto itself, it's just a few things that are banded together at that point. 
&gt; Multi-billion dollar industries with decades of code? LOL!! Yes, if they can they not be bothered to spend 1k$/MLOC fck them, no reason to butcher language that everybody uses because of those clowns... But you know those clowns have "country" representatives in the ISO, but only country they represent is their company. :) 
Using auto is a good point, I haven't fully absorbed C++14 yet. Not having a name though in my experience ends up being very detrimental however, due to the combination of templates and no name for the compiler. I've tried it both ways and eventually was very happy with leaving the tuple methods behind. I think there may be more value in more generic template heavy situations, but I can't say from experience since I avoid too until I really feel that something needs to be generic. 
I'm not "raging"; I'm facepalming on your behalf if anything. To the point, I'm observing that you can't seem to post anything that isn't rooted deeply in fallacy. &gt; your rage filled answer ruins your credibility... but nerd rage is not a proper way to convince anybody... Tone policing, appeal to motive – more ad hominem bullshit. Try harder or don't bother.
I wont bother with you... And for sure I will trust people who implemented modules over people who rage on the internet.
I've passed this info on to John Morgan, the dev who did the work.
And finishing it off with a straw man... How predictable. No one was trying to change your "opinion" about anything. What I'm doing is giving fair warning to anyone else who may attempt to engage you after failing to recognize your particularly regressive brand of trolling. Interacting with you would have been nice to avoid, but this is a public service.
You use two libraries, both have the same module name "M". // lib1/m.ixx module M; // lib2/m.ixx module M; // main.cpp import M /* from "lib1/m.ixx" */; import M /* from "lib2/m.ixx" */; 
Does it support parallel compilation?
That's not a problem. Since module does not have that transitive property of headers, you can creator those two files: lib1m.cpp export module lib1.M; export import M; /* lib1/m.ixx */ lib2m.cpp export module lib2.M; export import M; /* lib2/m.ixx */ Then, in your main: import lib1.M; import lib2.M; int main() {} // use the two libraries... But then hey, imagine the two libraries export a class with the same name with the same namespace! With header, you're screwed. With module, edit your lib1.cpp to export alias in another namespace. Currently, we could have a ton of name clash! Yet, I hardly see anyone. I expect modules to be the same, and yet, with module you can fix names.
In principle, the 5 answer limit is completely useless as (trivial questions aside) you just can't give a proper answer in Fife words, so the time is pretty much wasted. However, I think it actually worked quite well this time. If there was something to say, the panelists just ignored the limit, but it stopped them from falling into endless monologues. Admittedly, there seemed not to be too many people waiting on the microphones considering that IIRC, Odin asked 3? Questions. So it was probably not a problem that they gave a little longer answers in the first part. 
In 15.4 and 15.5 (Preview 1) intellisense still used EDG 4.13 but only [EDG 4.14](https://www.edg.com/docs/edg_cpp.pdf) support structured bindings.
If you subscribe to this reddit you will see a lot of blog posts coming by. In my opinion most of them will help you. For example, follow the c++ weekly vids by jason turner. 
Composition. One can't write templates that create new structs out of data (I can't synthesize structs) but one can write that with a tuple/named-tuple. The reflection proposals going through the chain right now and Herb's meta-classes are potential imperative solutions to the problem. They work, but they're vastly more complicated for some cases than what you can find in Haskell, Rust, TypeScript, etc. (and vice-versa; one paradigm does not rule them all!)
Good article. The &gt; EXPLICIT TEMPLATE SPECIALIZATION section name seems wrong. This is explicit template specialization: template &lt;typename T&gt; struct foo; template &lt;&gt; struct foo&lt;int&gt; { }; --- Writing for_each&lt;int&gt; is simply providing an explicit template parameter - it has nothing to do with specialization.
We also hired the guy who designed the feature.
&gt; named tuple I call it an aggregate.
&gt; (Not sure what the correct terminology is here.) The correct terminology is.. 'specialization'. ;-] C++14 [temp.fct.spec]/1: &gt; A function instantiated from a function template is called a function template specialization; so is an explicit specialization of a function template. Template arguments can be explicitly specified when naming the function template specialization, deduced from the context (e.g., deduced from the function arguments in a call to the function template specialization), or obtained from default template arguments.
Can we please not overload the term "erasure"? Call it `std::erase`.
&gt; _(Not sure what the correct terminology is here.)_ [temp.arg.explicit] names it "explicit template argument specification".
shouldn't it be `erase_if`? I was googling about the uniform container erasure stuff and found the `isocpp` paper about it.
The code would likely be faster if it breaks the dependency chain to allow more parallelism. Something like static unsigned const PowersOf10Correction[] = { ... }; // adjust as needed unsigned numDigits(unsigned v) { auto log2 = 31 - __builtin_clz(v); auto log10Approx = (log2 + 1) * 1233 &gt;&gt; 12; return log10Approx + (v &gt;= PowersOf10Correction[__builtin_clz(v) &gt;&gt; 1]); return log10; } would probably work. That lets the array index happen ~4c earlier, at the cost of a single extra operation.
[Fluent C++](https://www.fluentcpp.com/) is pretty good and pops up here every so often. I'd recommend reading that and just googling the stuff you don't know.
http://www.learncpp.com/cpp-tutorial/b-1-introduction-to-c11/ http://www.learncpp.com/cpp-tutorial/b-2-introduction-to-c14/ 
there's also blogroll from MeetingC++: http://meetingcpp.com/blog/blogroll/ so every week you get tons of good stuff :)
I'm sure this took a lot of work and energy so the first thing I would suggest is to change the name ASAP. It's your choice of course and maybe you are attached to it, but if you want people to use it, they are going to have to pronounce it (and know when they are looking at the name of the library in the first place!)
If it is about compiling C++ I disagree
Really nicely written, good communication style, and solid technical details. Only weirdness was writing "explicit template specialization" (as noted in another comment) for explicitly passing template parameters. It's worth noting one of (at least in my use cases) the absolute most important reasons to use a `proxy` type class to help with type deduction, and more generally: ADL does not work at all if you explicitly specify template parameters. I use this trick with proxy (I usually call it `template &lt;class T&gt; struct tag {};` a lot for implementation details of libraries with user hooks.
Every time you create a function that takes some data, with tuples you'll have more options (with the help of template argument deduction). P.S. I'm not implying that we can't live without them. Far from that.
`erase_if` takes a predicate, `erase` just takes a value to compare against.
The VL functions will be enabled in the next Microsoft Visual Studio update after 15.4, although in some cases the generated code is not fully optimized. We are still working on improving AVX-512 support, but getting all the functions implemented was our first goal.
It's also the kind of behavior you'd expect from any other type. I wouldn't expect a moved-from std::string to be empty if the length was below the allocation threshold wrt. small string optimization.
&gt;WIth the tuple you just define it as you use it. You can't do it without defining it everywhere too. You can put it in the header but so you can a struct.
...and Bjarne Stroustrup.
Hm, I can see the template argument somewhat. Though manually using such structs/tuples could be a real pain)
I think this is ok if you want to avoid macros at all costs. Otherwise, you can implement a reflective struct instead. Basically, this would be a struct with a special function (free or member) that returns something similar to a nuple. Or really just an std::tuple of pairs of &lt;const char *, reference to member&gt; is good enough for most applications. Using macros is annoying, but aside from being more cross platform, it's also more pleasant to work with. When you are using the structs in a non reflective manner, you can just use regular field access and get auto completion. Overall perhaps "purer" to avoid macros, but I find a macro based approach more practical. `BOOST_FUSION_DECLARE_STRUCT` basically, but with more modern syntax and easier usage, e.g.: DECLARE_REFLECTIVE_STRUCT(Foo, (int, bar), (double, baz)); Foo f; f.bar = 1; f.baz = 1; reflect(f, [] (const char* name, auto&amp; member) { std::cerr &lt;&lt; name &lt;&lt; " : " &lt;&lt; member &lt;&lt; "\n"; } 
I'm into it for that cmake update. Can finally use "find_package(Vulkan)" on my windows machine
The basic problem is the same. For those not versed in their FORTRAN: When you compile a Fortran file it produces a binary "module" file that describes the ABI. This can then be imported by other file compilations. The problem then is that you need to know in advance to compile file A before file B that uses A. In order to do this reliably, you need to parse the contents of _all_ files before starting to compile _any_ of them. This is also true for incremental builds. The problem here is who decides in which order files should be built. Either you have the compiler orchestrating the order ("the compiler becomes the build system" as stated in the post) or the build system needs to parse the contents of the files ("the build system becomes the compiler"). Neither of these is a good solution.
it is the name of the feature... so complain to that STL guy, not to me :P
I would imagine it would be far less painful to use ISPC
I know, I was actually thinking about implementing something similar by myself so I looked up your paper(by googling your name and remove_if), saw last revision 2014, assumed dead, but then stumbled on cpp reference that it is adopted and actually implemented... in VS 2017. So thank you for this. And thanks to ISO for not blocking it because it is not generic enough...
What about in comparison to Spirit.X3? Qi is kinda.. old to be comparing against IMO, and notably, X3 is extremely light on compile times.
You can download 15.5 preview 1 using this link: https://www.visualstudio.com/vs/preview/
The key part is the uniformity. I chose the paper's title before settling on final names for the functions. I don't really care what people call it, though.
No, my logic is correct. Knowledge of modules is not randomly distributed across every person on the planet. It is logical to assume that people that implemented them actually know more than random nerd rage bloggers. So I am not 100% sure that OP is wrong, but nothing is 100%.
&gt; std::byte I keep forgetting that exists, because any attempt to search for the page on http://cppreference.com will always redirect to the std::errc page, for some reason, rather than the [actual](http://en.cppreference.com/w/cpp/types/byte) page.
Oh hey, this was inspired by my talk! I think the take about whether or not a metafunction is injective is an interesting one. In my talk I made a weaker, more handwavey point about how resolving a dependent type name may require arbitrary computation from the compiler since templates are Turing complete.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7602tx/help_understanding_setf_output_formatting/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You should be using the [random number library](http://en.cppreference.com/w/cpp/numeric/random). There are a few different ways you can implement this. The easiest I can think of would be to populate a container with 10 values: std::vector&lt;direction&gt; bag{S, S, S, S, E, E, E, E, N, W}; and then sample one randomly from it via a `std::uniform_int_distribution`. If you want to get more fancy, you can implement [rejection sampling](https://en.wikipedia.org/wiki/Rejection_sampling) (or some other distribution sampling algorithm) as a function and call that. The benefit being you can re-use it throughout your codebase.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7603px/help_with_lll/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
OOC, why must you use `rand`? _Avoiding_ it is the easiest solution..
I'm doing this for a CS assignment, and currently we are only familiar with the rand() function. My instructor went over a way to use rand() but I forgot it.
We're only familiar so far with rand() in the class this is for, so it's what I have to work with.
It's probably best to ask your instructor then.
Is it really that hard to pronounce for english speakers? I chose that name as a reference to a decoding computer in Umberto Eco's Foucault's Pendulum, which I felt was appropriate, and being a french speaker, that name really is no big deal. Thanks for the pointer though, I'll definitely consider it.
They did require proprietary changes (mostly to server mode stuff) very recently, so to be honest the likelihood is so low that it's gonna work that it's not even really worth trying ;-) But good idea!
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7603ox/how_to_track_mouse_movement_in_a_fps_game_using_c/doa98pj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I will admit I did not compare much to X3 yet. Primarely because I was only familiar with Qi when I started off, and X3 did not address my primary concern (the resumability). I just ran a few tests, and my library still seems to be faster than X3 at first glance, but consider that I'm not exactly feature complete yet.
If you know the maximum of range, you can calculate the percentiles. If rand goes to 65536, you can say x = rand() if x &lt; 65536*.4 //40% chance else if 65536*4 &lt; x &lt; 65536*.5 // 50-40 = 10% chance etc.
(typo : std::*exception*::par -&gt; std::*execution*::par)
&gt; Though manually using such structs/tuples could be a real pain) Definitely. It'd be better still IMNSHO if C++ had language tuples and structs actually were just "named tuples," like several other functional or functional-inspired languages popular these days, but alas. It's vastly annoying that structs and tuples in C++ are completely and utterly different constructs: one baked into the language with an approachable syntax and the other allowing (painfully gymnastic) type algebra.
I figured it out, never mind, but thank you for teaching me some stuff I don't yet know haha! I used int bias= rand()%10 and basically stated that, if(bias&lt;4) the object would move South, and if(bias&gt;=4 &amp;&amp; bias&lt;8) it'd move east. Then used the last two values 8 and 9 for the other two direction. 
That's because of `std::errc::illegal_byte_sequence`. Added `std::byte`, will appear on the next index refresh.
I doubt anyone who knows abour range-v3 is going to see your question. You could always ask the [team](https://github.com/ericniebler/range-v3).
I see, and `-MG` (which I hadn't heard of) can only be used with `-M`, not with the options that both extract dependencies and perform other steps (outputting preprocessed source, or fully compiling to object file). That sounds like an unnecessary limitation. But then, how does your [separate preprocess and compile](https://build2.org/article/preprocess-compile-performance.xhtml) feature work? Since `-MG` conflicts with outputting preprocessed source, you can't just be passing it to all compiler invocations. Do you do a non-`-MG` invocation with `-E`, hope it succeeds, and rerun with `-MG` if it fails? If so, couldn't you do the same with `-c` instead of `-E`? &gt; Not sure I understand the question. You cannot compile a translation unit if some of its headers do not exist (or, worse, out of date -- you will just be wasting time). If they don't exist, the compiler will produce an error and stop after the preprocessing stage, so there'd be no difference compared to preprocessing only. If they're out of date, as you say, the compiler could waste time generating code that will just have to be thrown away once build2 reads the dep output and realizes it was using out-of-date headers. But that's a relatively uncommon case, and as long as it's just a performance issue, not a correctness issue, wouldn't the performance gains in the usual case from not re-running the compiler be more significant? (Of course, that still wouldn't work with modules. But my tentative opinion is that a better solution would be for the compiler to get a bit smarter, rather than require build systems to duplicate work. Even without modules, your approach of repeatedly running the preprocessor to discover generated headers, while nifty, seems to be fundamentally a hack: there is no reason the preprocessor needs to run more than once. I think I'd rather see a solution where when the preprocessor/compiler comes across a missing header or module, it runs an arbitrary command, where the command to run can be passed as an option. In a simple Makefile-based build, the command could just be 'make', passing the file needed as an argument...)
... and this is incorrect. For example with rand() returning 0 through 32767 you have 0 more frequent than 9.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Wow. This one was really interesting.
I don't know if it's hard to pronounce because I don't know how to pronounce it. Even if you go the route of using a french word, there must be some that are clearer. 
I think Niebler recently even had a public request for help wrt documentation so I doubt you will find something better. But I am curious: what do you need documentation for? Most of the algorithms are quite obvious...
I was hoping this was something else. I've wanted a tool that could compile a source library to a single header file library. I feel like that would give an enormous amount of modularity. I've already done it manually and it has worked extremely well. 
It would be great, if this would quickly be adopted into library interfaces, but realistically well probably have to wait a decade until it has replaced the use of unsigned char in everyday use.
I have honestly no problem with that. If you need your module name to change based on some configuration parameter, the use a tool for it (e.g. your build system), but let's not make the common case more complicated than absolutely necessary and as fast as possible.
The core library and some proposed views and transforms have been prepared for standards submission so I suspect that readingbthose proposals may give you a good insight. As a user though I prefer looking at examples so look out for Erics blog and presentations. Google it...
&gt; C++ code can run on systems without disk. &gt; On systems you mention, swap can be turned off. Makes no difference. On the major OSs, everything still acts as if it truly is a mapped file. On embedded OSs, sure there is no such thing. And in that situation, obviously enough using a PMR allocator from a file backing is not going to work. But that's okay, lots of bits of the C++ standard are legally not available on platforms not supporting that feature e.g. `std::filesystem` doesn't support access permissions on Windows at all. &gt; Windows does not do mmap (userland is different). But you can do memory mapped files there just the same, probably emulate mmap well, so ok. Windows is actually more of a stickler for all memory being mapped from a file than POSIX is. It also has really excellent virtual memory management facilities. &gt; I do not believe you when you say that all of allocated memory is backed by a file. In fact, I rather think that it is a completely preposterous idea to go around some file just to get a bit of heap and that no sane system actually does that. Yet, that is the reality. Look, you can dump on me and my ideas all you want. But if you choose to believe things which are factually just untrue, you're not going to be persuasive. Go read a few papers by Denning et al and try studying some Linux and FreeBSD source code. You'll see for yourself how the kernel paging system works. Once you understand how it works, a lot more of what I'm talking about will make sense. You can then disagree with me and you might be persuasive. 
/u/CaseyCarter and /u/eric_niebler both post here. Reddit isn't obscure. ;-]
I’d like to know what the copy and move score on string view would be, if someone would be kind enough to puzzle it out.
&gt; Also, isn't the implementation of &lt;filesystem&gt; not finished mainly because boost file system basically provides an almost 1 to 1 equivalent to the std implementation ? No, in fact several changes were made late in the process which means Boost's implementation also needs work AFAIK. It isn't done for us because implementing it will be ABI breaking and it's lower pri than the parallel algorithms we can deliver without an ABI break. &gt; As for the sub-process mechanism I wasn't even aware that was in the 17 standard It isn't. That was my whole point.
A shame he had to skip the DLL hell section. I’m not sure he was going to cover it, but Sometime I need to understand what is going on in the winsxs folder.
I believe the score ends up being 6 Mallocs: Cust c{"Joe", "Fix", 42}; //Two Direct-Constructs std::string s = "Joe"; Cust d{s, "Fix", 42}; //Two Direct-Constructs Cust e{std::move(s), "Fix", 42}; //Oops! Two Direct-Constructs! The problem is that, at least as far as I am able to discern, there's no `string_view` which can represent a "moved-from" `std::string`: In this case, the program doesn't hit undefined behavior (because `s` definitely outlives the scope of `e`'s constructor, which means it outlives the temporary `string_view` object created) but `s` won't get moved-from into `e`, it'll simply be copied instead. And of course, the `string_view` version still needs to have the extra constructor taking a sole `const char *` as its argument, like the other non-template versions.
I am not convinced that you have tried your code or verified the cruciality of your points thoroughly, so I will not apply your suggestion to the article. Thanks for the participation anyway. sphere991 