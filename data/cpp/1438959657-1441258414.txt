Against this as there is no way to circumvent the warning, and some insist in treating all warnings as errors.
expression SFINAE
Personally I think it'd be massively useful if I could enable people to write e.g. filters or simple plugins for my app without them first having to wait up to a few days for the 12 GiB download (or however big VS is these days). So a standalone toolset could help that greatly.
ya, confirmed 
So you install VS once and that's it, it's on the VM. Also, you actually do want VC libraries etc, in which case it's a ridiculous thing to require to take devenv.exe of (and whatever follows).\ Because you do get the compiler with the SDK, and that is your toolchain right there. But you actually want the VC version x compiler and runtimes. So stop whining and install VC. Honestly, your nitpicking is dumb.
I know it's been precluded several times, but I really miss native C99 on Windows. But I fear it still doesn't count as *reasonable user expectation*.
You don't know how to to save the VM image with product x installed or what?
 Little things that are big annoyances: -Keeping the GUI exactly the same as when it was closed. Pinned cpp files stay pinned, but the pinned solution explorer window is unpinned on every startup. -Also the performance session window window pops up every time I start up (after I've done some profiling) and I have to close it. -I'll go back to click on some file tabs and they will close out from under me when I click on them (maybe when the file changes it closes instead of updating?). -Is it possible to run without the debugger attached from the gui? If so I still haven't found it. I have a file explorer window open to run programs at full speed. -The ability to select a project and copy or make a template out of it. -Defaulting build configurations to x64 
That's why off-by-default warnings exist :)
I'm not sure if this is the kind of thing you're asking for, but why not: in the IDE itself, having the ability for ctrl+click to "Go To Definition" would be fantastic. F12 is great when your right hand is on the keyboard, but if it's on the mouse it's quite unfriendly. I also noticed a mismatch with the IDE and the compiler. I had an enum declared and defined in the .cpp, and a private function declaration in the header that referenced it as a parameter for a private function. The IDE did not complain and let me "go to definition" on it, but the build failed, and somewhat oddly. It would fail with "Function does not take 3 arguments" when I tried to call the function. It took quite a bit of time to figure out what was going on, where an error in the header that said "Unknown type" would have immediately pinpointed that I dun goofed by accidentally adding the enum to the cpp. But I definitely like VS2015!
We know your last name is Ashford btw
Doesn't the IDE put debug and release builds into different directories?
Wow is that a bug? I'd expect the global function to fire.
Did anyone file a bug with a preprocessed repro? As a special favor to Boost, I'll file a bug if you mail me a preprocessed repro and corresponding command line. By the way, the `/Zm800` there is *highly suspicious*. That asks for 8.00x the default PCH size, and x64 defaults to an enormously large size to begin with. Multiplying it by 8 is almost certainly unnecessary and potentially harmful.
Bugfix for my Boost visualizers https://connect.microsoft.com/VisualStudio/feedback/details/1509673/natvis-cannot-read-anymore-static-const-member Also, please allow use Synthetic item inside CustomListItems https://msdn.microsoft.com/en-us/library/jj620914.aspx
Although boths links are to Part 1.
I definitely get what you mean about using the compiler and linker from another IDE and a standalone toolkit would help with that but i'm not sure I get the debugger bit. If you want a command line debugger for windows, my instinct is that cdb would be a better choice, no? 
you mean like this? :-)http://blogs.msdn.com/b/vcblog/archive/2015/05/01/bringing-clang-to-windows.aspx
VC++'s current behavior does generally seem to better match the expectations of people not intimately familiar with C++ name lookup rules than what the standard says.
Thanks, great news
It seems to me like it would be much better to improve CMake's `target_compile_features`, because I think it's very nice, and it would maybe not be that hard to iron out the problems you mention. I would personally always prefer a built-in functionality over adding a bunch of additional scripts to my project that most will not be familiar with. But anyway, nice work! :)
I have a big wish: put the STL acronym to rest. Why do we keep using an acronym that IIRC doesn't appear anywhere in the standard?
What version of gcc do we need to get this to work?
&gt;reasonable user expectations Add some experimental reflection :D Or at least modules... do it for Hitler! https://www.youtube.com/watch?v=ND-TuW0KIgg
This would really be awesome. To be honest, CMake &amp; VS already work quite well together, but a few things are very inconvenient: * In combination with using git and switching branches, it takes quite a lot of time: switching branch, running ZERO_CHECK, press to reload all projects. I'm not sure if it's possible to make this better though. But it's actually quite a big deal, as git is all about branches, and switching them often. * If you use gtest/boost-test with CMake/CTest, integration sucks, you get no output at all, you need a custom target. And then it still isn't good, you can't click on line numbers if tests fail etc. And this one's not a realistic wish, just a dream: CMake for Android projects support, so you can have a truly cross-platform project. This is probably not something MS can do on their own without modifying/help from CMake/Google.
Neither does SFINAE. "STL" is a useful term, and a proper use of metonymy.
Then thanks very much.
Then use `alloca`.
The problem is: people who don't (can't) know any better google STL and get crap that has no place in modern C++ design. When you google SFINAE, you get relevant stuff, for the most part. We have C++ standard library. No need for acronyms IMHO. 
Good point on the importer. Assimp is my goto importer. I use sfml for window and input so that works reasonably well for texture loading. 
Ah, that explains a lot. Thanx!
&gt; when you use Qt, the new is pretty much java's new; ... you don't need to delete anything Gahhhh!!! This is one of the reasons why I HATE working with Qt. I really want Qt to use smart pointers here and a different work for allocating Qt objects. Something like a **make_qt&lt;&gt;** function (similar to std::make_unique&lt;&gt; and std::make_shared&lt;&gt;). Seeing 'new' without a corresponding 'delete' somewhere always sets off my memory leak alarm!
While that is an option, I'd prefer not having to.
&gt; Did anyone file a bug with a preprocessed repro? Yes, and it's been verified by you: http://lists.boost.org/Archives/boost/2015/07/224337.php &gt; By the way, the `/Zm800` there is highly suspicious. I don't know, guess this is default `bjam` release settings... Getting to the second point of my previous post, have you considered (or maybe you're aldready doing it) including Boost test suites in your regression codebase? Besides being an extremely popular lib, Boost is also a very good conformance stress harness. 
Exactly! I mean, I know I can do it on my own, but why doesn't Qt provide it for you? (Also, I might add that while this solution can replace the use of new in user code, it doens't really generate smart pointers nor discourage the use of new.)
Cool, I thought it sounded familiar. That's still active and assigned to Tanveer. I believe the FE devs have harnessed Boost, although not always the latest version, and definitely not prerelease versions.
There's a bunch of different debuggers in Windows, but each one works a little differently. It's likely a petty wish but I'd love to have access to VSDB without the IDE, or better use a different debugger (like say... gdb) from Visual Studio.
c++14 constexpr c++17 nested namespaces
The latest trunk. I thought it was obvious in the OP. 
Support for advanced debugging visualizers in natvis would be very helpful. Ideally there would be a way to include scripts for complex types (gdb supports visualizers in python!), but that's most likely too large a feature. Function evaluation in natvis is currently not possible, so this would be a nice start.
I understand that Qt predates C++98. However, Qt5 was designed to take advantage of many C++11 features. The new and delete keywords are things that you should generally not use anymore in C++11 (and later) applications unless you are writing your own smart pointers or allocators. The fact that Qt5 still uses them shows that Qt (despite claims to be adopting C++11 features) really isn't aging well. It really sucks that Qt is the only good C++ GUI interface.
How so? /u/Gangstuh_Nugget expects the global function to fire rather than the silently inherited member function and that's what the standard requires. MSVC is the one doing surprising behavior, it's invoking the member function `f` which is surprising because at the point where the `doit` is called, the only function `f` in scope is the global function. There is no declaration of any member function `f` so whoever wrote that code likely expects that the `f` which gets called is the `f` which is currently visible in that scope, namely the global `f`. If the user expects a local member function to be inherited and wants to call that function, then to resolve the ambiguity the user needs to be explicit: `this-&gt;f()`. The basic rule is rather simple and fairly intuitive. A template should be valid at the point of declaration rather than instantiation and what it parses to should be fully resolved at the point of declaration. By resolving things at the point of instantiation you get inconsistent and surprising behavior because doing so means that names can be retroactively redefined out of order, which causes silent bugs.
How would you suggest this integration be done?
Sorry I made a mistake. I didn't realise that struct S was inheriting from base class T. Given this I'd expect f() to look for a base class implementation before looking in the global scope.
Fair enough, in that case you have two options, you can do: this-&gt;f(); That makes it clear to the compiler that you expect a member function `f` to be available after the template is instantiated. Or you can do the following which in my opinion is an even better solution: struct S : T { // Tells the compiler that T must have a member f. using T::f; void doIt() { f(); // Compiler knows that f is part of T. } };
Syntax highlighting for the file formats in the editor, being able to open a CMakeLists.txt and have Visual Studio generate its solution stuff automatically, etc.
My god, these lectures are so beautiful and comprehensive! Thanks for sharing!
I would also recommend OpenGL because it is crossplatform.
Right, but can you give an example class/data structure where the advantage is clear? The paper says containers, but every data structure I can think, where move makes sense, makes the 'empty after move' guarantee pretty cheap in the grand scheme of things. In particular my understanding of IsRelocatable in Folly is that it was designed to enable things like realloc() 
&gt; Right, but can you give an example class/data structure where the advantage is clear? I did; non-null types. You may not consider them widely used, but e.g. DropBox uses them pervasively: https://github.com/dropbox/nn Qt has some types of its own that are non-null, and face a similar problem. There are significant advantages to non-null types (the ability to do away with a lot of branching to check for null values, for instance). They could be more widely used under this proposal. Currently, they interact horribly with move. A container would be able to use `realloc` with this proposal, for types that are `is_trivially_relocatable`. Depending on your STL implementation, this could be most or all types in your program.
In this relocator proposal, the destructive move does not leave behind a zombie, but uninitialized memory. It would be invoked through a type-clean interface (page 2 &amp;#8211; *Invocation*) that converts the destination storage from uninitialized to initialized; and the source storage from initialized to uninitialized. No zombies. :) At least, none that aren't already left behind by destructors, as-is.
Look at the links in my first post ;)
Perhaps the UB issue could be resolved by tightening up the Standard's object model. Currently the definition of object lifetime begin and end is embarrassingly sloppy. I agree in principle that there should be an atomic move-and-destroy, but must admit that the proposed syntax is daunting.
thanks!
I think the syntax might be daunting to the extent that C++ is daunting. :-) I was similarly bewildered by rvalue references when I was first getting acquainted with them. The relocator syntax follows existing constructor syntax quite closely; it only reverses the direction of initialization. In a constructor initializer, `x(y)` initializes x with a value from y. In a relocator, `~x(y)` initializes y with a value from x. I considered an xvalue constructor instead. However, that would have a number of properties that I'm iffy about: - Introduction of an explicit reference syntax for xvalues. This would be necessary to distinguish the relocating constructor from the move constructor and copy constructor. For example, a relocating constructor might be declared with `A(A~&amp;)`. That gives us yet another reference type. :) - The eventual language might decide that xvalue references have implicit conversions to rvalue and/or lvalue references. Then you have to do this: `A(A~&amp; x) : B(std::xref(x)), c(std::xref(x.c)) {}` If you forget the `std::xref` to make sure you're passing an xvalue reference, you might be accidentally calling the B copy constructor, or move constructor instead. Problem: now copy/move constructor contract requires you to call a destructor on the base object being moved from, whereas no destructor is required on the outer object because the relocation constructor is being used. (???) - The language might now decide to add an xvalue assignment operator. That adds yet another special member. If we want xvalue assignment, it seems better to me to have a single relocator, and for the language to invoke the destructor on the assigned-to object, followed by a relocator to the uninitialized memory left behind. - An xvalue constructor would also not emphasize as clearly that no destructor needs to be called on the moved-from object. By designing the relocator around destructor-like syntax, its dual nature is emphasized. And ultimately &amp;#8211; most users will hardly ever need to see relocator syntax. For most objects, an implicit relocator would be declared and defined. For most where it isn't, the following would suffice: `~A(A&amp;) = default;` Only authors of self-referencing types would need to actually write a relocator.
Based on your remarks, I have drastically changed and improved the interface to it. It is now very similar to `target_compile_features`: # suppose we have a target 'tgt', target_compile_features: target_compile_features(tgt PUBLIC cxx_noexcept cxx_constexpr) # my version include(your/dir/to/comp_base.cmake) # only file you need to download, rest is taken as needed comp_target_features(tgt PUBLIC cpp11_lang/constexpr cpp11_lang/noexcept) The call also activates C++11/14 when needed, plus you've got the features from `WriteCompilerDetectionHeader`. I think this is an acceptable learning curve and you only need to add one file. Note: This breaks any old CMakeLists.txt using it already (if there are any, I don't know).
Haha, you are welcome :D Feel free to use my `comp_target_features` for it. Even if you don't need the workarounds, just use `comp_target_features(tgt PUBLIC CPP11)` to activate C++11 or so.
Oh, yeah, I'll definitely use `comp_target_features` before I even consider using `target_compile_features` now! :-)
It looks great, I really like it and I'm actually considering using it... :D
Yes, it's a very minor bug that is indeed very low priority, and the workaround is trivial. May I ask however why you have "absolutely no sympathy for this code"? It seems fairly innocuous.
&gt; So this means it would generally signal legacy types that are unaware of these new semantics as trivially relocatable? For the most part, no. For details, I suggest the proposal &amp;#8211; page 4, *Impact on existing code*. &gt; Regarding nun-null types I have so far been under the impression that instances that have been moved away from only need to be able to survive a destrcutor call but need not to be prepared to get legally reactivated for anything else. Is this understanding wrong? It's not something you can count on. The object remains alive, there's no promise that a destructor will be the next thing to be called. There are authors encouraging "stealing" stuff using `std::move` from objects that will remain alive and will continue to be used. You can "steal" from long-lived global objects, etc. The object does have to stay in a "valid" state. This is not a specified state, but calling a method normally permitted on this type of object shouldn't crash. For example, `list::size()` should return a value, not segfault. This means you either have to restore the invariant you're maintaining; or add checks to all your methods. But adding checks defeats the purpose of maintaining the invariant, at all.
I know I'm late to the thread, but I have two (small) issues related to the Ctrl+. "Create Declaration / Definition" code action: 1) When a function declaration contains SAL annotations, e.g. `void foo(_In_ const bar&amp; b)`, the generated definition does *not* contain the annotations. While it's not huge issue, Code Analysis will generate a warning for mismatched annotations. 2) When a function declaration contains default parameters, e.g. `void foo(bool bar = false)`, the generated definition *also* contains the default parameters which generates a compiler error. Also, and this is a pie-in-the-sky request, if we could get a code diagnostics/refactorings API like Roslyn has so we could make our own refactorings and stuff I'd be forever grateful. **EDIT:** Also, if we could have a setting to disable opening the 'Peek' window after generating a function definition if the source file is already open in another pane (like Resharper does, as I've just noticed). Usually I have my header open in the left pane and source on the right, so if I'm generating a bunch of definitions at once it gets a little annoying having the peek window show up and slow me down from generating several definitions in a row. Speaking of the annoying peek window, if you generate a definition, press Ctrl+S once the peek window shows up, and press Escape, the peek window goes away as expected. If *immediately after* that, you generate the next definition down, press Ctrl+S, and then Escape, the window beeps when pressing Escape and doesn't close right away. A small thing but a little annoying. Other than those minor things I'm loving C++ in VS2015! I only ever get to use C++ in my spare time and it's been a blast. Keep up the good work.
Or... by asking questions in the right sub.
[it's going ok](http://i.imgur.com/hp7bXug.gifv) :)
Can or can't?
I don't like that it requires a core language change. I'd suggest *only* having a the trait. This is still acceptable for most of the types whose address will never be stored outside the object. A downside is that the class now has to document that you cannot store the address, but this could be resolved by deleting the operator&amp;. But I think, this is still better than a core language change.
I would like to see UTF-8 string literals fixed so that this program [works](http://coliru.stacked-crooked.com/a/877b45cad0990e07): #include &lt;string&gt; #include &lt;cassert&gt; #include &lt;iostream&gt; int main() { using namespace std::string_literals; assert(u8"\xF4"s != u8"\u00F4"s); assert(u8"\xF4"s.size() == 1); assert(static_cast&lt;unsigned char&gt;(u8"\xF4"[0]) == 0xF4); std::cout &lt;&lt; "Success\n"; } 
Did you file a bug?
There is a bug filed for this issue.
noo, I hate that feature, it constantly takes me to places when I am copy pasting... ( obviously my mouse use is not perfect, but in power tools at least you can turn it off)
Nicely done!
If Visual Studio were responsible for generating the solution based on CMakeLists.txt, it'd have to be kept in lock-step with CMake releases.
Like the auto parameters in C++14 polymorphic lambdas, but for regular functions.
Non-breaking change, though. No new keywords... And: * Classes that just use other classes and don't declare special members would get the feature for free, no changes needed. * Classes that do declare special members could take advantage of the feature with just this declaration: `~Type(Type&amp;) = default;` Only classes that require fix-ups, and want to support relocation, would need to implement an actual relocator. The libc++ implementation of `std::string` that uses short string optimization would want this, for instance. And without something like this &amp;#8211; no class that directly contains a libc++ `std::string` can be relocatable...
I have a similar bug, this code fails to compile: for (auto&amp; pt : mStarLayer) pt = Point{ rand() % cvLogicalWidth, rand() % cvLogicalHeight }; but this does: for (auto&amp; pt : mStarLayer) { pt = Point { rand() % cvLogicalWidth, rand() % cvLogicalHeight }; } No offense, but I don't understand why failing to compile innocuous, perfectly syntactically valid C++11 code is not considered an important bug?
 constexpr int fun() { constexpr static int tmp = very_expensive_function(); return tmp; }
I know that constexpr has to be determined at compile-time. I don't want to calculate something at runtime and cache, I want to calculate something at compile-time. See /u/F-J-W answer. It is allowed to use a global `constexpr` variable for this. It is *not* allowed to use a function static `constexpr` (!) variable. I want to know why.
I think I addressed that. 
Ah, that is was you meant, I can understand it. But the same problem is with a global variable storing the result of something and this can be implemented just fine. So a function static could also be implemented the same way a compiler does it for global variables.
I've thought about this argument, too, but since constexpr functions are per definition *pure*, it doesn't matter whether or not they're called. It doesn't matter, when the compiler calls them, since they'll return the same value, regardless of any other state. So nothing depends on the behavior of function level statics in *constexpr* functions. And even if the function is called at runtime, the initialier function for the static is still a compile-time one and will ever be, since it cannot take any arguments from the parent function. So it doesn't matter if the compiler calls them.
I would also love to see the bug with constexpr delegating constructors fixed in Update 1. This is the only thing left blocking me from enabling constexpr in a project when compiling with MSVC.
thanks. It works somewhat like a cross between Doom's rasteriser, and the Build3D one, though I'm hoping to add some features that neither of them were capable of. If I can just get my map editor working that is...
Either a compiler-only SKU, or just make the GUI optional. I sometimes need to compile stuff with any MSVC version between 9 and 14, but only ever use the latest IDE. I don't mind downloading the full installer for every version, but installing tens of gigabytes of stuff I don't need on an SSD is expensive.
Right. That's what I'm using, it just seems like the reference can be returned without having to chain both functions.
I think it's pretty obvious to the OP that he knows why having a variable state inside a constexpr that is dependent on runtime is not okay, but he is asking about a constant, compile time state inside the constexpr, which allows for a determinate compile time result. Why not allow it if the compiler can determine that it would still behave just like a constexpr should?
There's this extension form MS that gives you (among a great many other things) 'ctrl + click': https://visualstudiogallery.msdn.microsoft.com/34ebc6a2-2777-421d-8914-e29c1dfa7f5d
I think you're right. A special case to make `static constexpr` have special meaning and hence: constexpr int i = 0; constexpr int fun() { return i; } equal to constexpr int fun() { static constexpr int i = 0; return i; } doesn't seem to have any problems. `static const` would be impossible of course, but that's not what you're asking for. There can't be any huge objection by the compiler since: class Object { static constexpr int i = 0; }; is perfectly legal.
Yeah, it feels a little like Doom. You're off to a great start.
A good place to start is [here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3814.html). I am not too familiar with reflection proposals either, but I'll try to answer some of your points. &gt; For example – could it walk the type's subobjects; AFAIK this is the prime requirement for any reflection proposal. &gt; see that all of them are relocatable; Yes, you should be able to do something like `mpl::all_true&lt; is_relocable&lt; members&lt;T&gt; &gt;::value ... &gt;`. &gt; observe that the object does not define special members, such as e.g. a copy constructor; This is not mentioned in the requirements, but I assume that the WG is aware that this is a very desirable feature. &gt; Could any objects that require fix-ups provide a relocate method, which the reflection-based solution could detect, and invoke? Well you can do that even now with expression-SFINAE. The problem here is to automatically generate it for the types that do not provide a custom one. It seems to me that 2 major features are required to do that: 1) Being able to iterate over each member. 2) Detect if there is a user-defined (or deleted) special function (constructors, assignment operator, etc.). Honestly I never saw any mention to this one, but it seems much easier to implement than the other features. &gt; What confidence do you have that reflection this powerful will eventually be in the language? High (but not before 2020). The main use case is to automatically generate boilerplate code (such as comparison operators, or automatic serialization). It is probably the most important feature that other languages have, but not C++. &gt;What are the current obstacles? I have no idea of what happens inside the [WG](https://groups.google.com/a/isocpp.org/forum/#!forum/reflection). Reflection is basically `introspection` + `code generation`. I assume that the *code generation* part is a big beast. Also I'd take a look at `Boost.Fusion`. It has a quite powerful reflection mechanism... with the only downside that you have to enable it manually using the `BOOST_FUSION_ADAPT_STRUCT`macro. IMO a language feature that simply automates the work of that macro should be easy enough to implement and cover 95% of the use cases. 
Beautiful!
Optimization is never required. That said, sorting will benefit from this. You skip over O(n^2 ) set-to-default operations. Stepanov discusses this in detail in his Notes on Programming, see Chapter 4 - Implementing swap.
Seems like an assumption that's it's one of these two. I'm not a Windows guy, but I hear very good things about visual studio. On Linux I prefer eclipse to clion. 
According to cppreference on [constexpr](http://en.cppreference.com/w/cpp/language/constexpr) and [literal type](http://en.cppreference.com/w/cpp/concept/LiteralType), this depends on the implementation of std::string. It is unlikely to have a trivial destructor (has to free its buffer). Isn't `__PRETTY_FUNCTION__` already a `const char[]`? Why can't you do this? constexpr const char* type_name() { const char* name = __PRETTY_FUNCTION__; return name; } http://ideone.com/cP3WWd
Eclipse??? Are you trolling?
D can do this and more, so it's probably just a compiler limitation rather than a theoretical one.
And the compiler can do it, as shown with `__func__`. So I don't know which limitation.
I improved it to : T calc(std::map&lt;std::string, ParameterNode&lt;T&gt;*&gt; &amp;inputs) const { return inputs["x"]-&gt;get() * inputs["y"]-&gt;get(); } 
Why don't you try both of these tools and see what works for you?
&gt; Steven T. Lavavej Stephan. What I added in VC9/2008 was the "aux" object, my first major fix. In VC10/2010, it became the "proxy" object, as Dinkumware picked it up and used it for both SCL/IDL=1 and HID/IDL=2. The behavior is the same (a layer of indirection solves all problems), but the terminology is different. Explaining SCL/HID isn't worth it anymore. As we've unified them into IDL (in 2010, *half a decade ago*) and the only defaults are IDL=0 in release and IDL=2 in debug, those are the only things worth explaining. I have found that people are endlessly confused about SCL/IDL=1. &gt; All related preprocessor things happen in yvals.h file: Hey, somebody finally looked at my work! That's me being maximally paranoid with maximally helpful comments. (We usually don't exhaustively comment the STL, but there was enough logic here that I thought it was worth it.) Did you know that in addition to screenshots, you can copy-paste IDL=2 dialogs with Ctrl-C? Base classes (like _Container_base12) should be depicted at the beginning of an object's representation, because that's how it actually works. Well, at least this is mentioned later. In 2015, vector's representation has been reworked slightly, due to my compressed pair overhaul. In particular, the relationship to _Vector_val is different.
Every example you've given can be written in a way that does work. You have demonstrated exactly zero need for static local constexpr variables. Hell, your original example will work just by removing the word "static". Are you asking, "why can't I declare a variable static when it's not needed?"
When working with C++ I have the habit of switching between IDEs and platforms in a way I always touch project code from each compiler at least once in a day. That ensures that I'm not depending on any compiler specific behavior and the code is really portable. On Windows I usually work with Visual studio at right screen and MinGW + Clion at left. From my experience, Clion beats VS in multiple points: Integrated cmake support (Is so great to just pick the `CMakeLists.txt` you already wrote for multi-platform development as IDE project file), code edition and completion (VS intellisense is soooooo slow, tools like Resharper++ or VSX only aggravate this issue), and RAM consumption. Also the debugger, a point where VS was always the king imho, is quite up the VS one. Maybe I'm missing the disassembly view or the edit and continue.
As far as I can tell, all those samples uses new Windows API for everything. Not the user32.dll, gdi32.dll, etc... My point was if I'm making regular "old" Windows API using CreateWindowEx and similar API's to run on Windows XP/7, then I am compiling separate executable than this new universal/xaml app which could use normal C/C++ runtime (msvcr140.dll). 
That's funny, for me CLion was the memory hog. JVM *cough cough*. VAX is blazingly fast on my machine(s), and I prefer it over CLion's completion. But anyway, your workflow is great, I do the same with a Linux VM - code in VS, test with clang from time to time, and even run the analysers. I guess I have to automate this at some point.
See also on [/r/programming](https://www.reddit.com/r/programming/comments/3ge30g/another_clibrary_to_convert_strings_to/).
This is a decision that I would like to steer my career towards, perhaps an embedded engineer or firmware engineer, something like that. I've been enjoying the few small arduino projects that I've done and would like to go further with this. I figured the answer was something like this, I guess I'm just afraid of the raw pointers and stuff aspect of it all.
Since you are on /r/cpp, the majority will probably say C++. ;)
You technically don't *need* constexpr's either, we can just go back to expressing computations using chains of long and obscure templates. No one is arguing about what you *need*, the argument is about what is useful to have. Do you have any actual arguments or examples of code that would break or result in some kind of undesired behavior due to the introduction of constexpr static variables?
&gt; So arguing that a static constexpr variable should be invalid because of state isn't a strong argument. I'm not arguing that it's a strong or weak argument, but rather that this is the argument used by the committee to disallow function statics. Just because you can find examples of a stateful constexpr function does not mean that those exist with the committee's explicit endorsement. A much more likely scenario is that it was always the committee's intention for constexpr functions to be truly stateless in all respects, and they simply didn't think of the hack described on that page. The existence of that hack does not mean the committee explicitly designed it that way. 
Except there is no such thing as truly stateless in all respects, even the strongest proponents of Haskell will tell you that something being *truly* stateless in all respects genuinely makes no sense whatsoever. So the only question left is whether the introduction of `static constexpr` serves a useful function compared to the potential downsides. Now there very well could be some downsides to it but the fact that the compiler has to internally keep some kind of state whose semantics remain entirely invisible to the caller of the constexpr function isn't one of them.
In my reflection library I worked on prior to C++11 I solved this with a registration macro. I just checked and it works as constexpr too. template&lt;typename T&gt; constexpr char* GetTypename() { return "NOT REGISTERED"; } #define REGISTER_TYPE(X) template&lt;&gt; constexpr char* GetTypename&lt;X&gt;() { return #X; } REGISTER_TYPE(int) void main(void) { std::cout &lt;&lt; GetTypename&lt;int&gt;() &lt;&lt; std::endl &lt;&lt; GetTypename&lt;float&gt;() &lt;&lt; std::endl; } Output: int NOT REGISTERED It was pretty shitty though. It has LOTS of limitations. However, I imagine parsing the symbol name to remove Prefixes &amp; Suffixes would have similar limitations. When you call the compiler __func__ a "special case" I'm not sure what you're referring to. You can imagine behind the scenes something like this: void foo() {/*your code*/} is void foo() { constexpr char* __func__ = "foo"; /* your code */} P.S. Lets not have another overloaded meaning for static. oh gawd plz anything but that.
&gt; whether the introduction of static constexpr serves a useful function And what is that useful function, exactly? No example shown here has demonstrated one so far, because every example works fine without static. The "caching" thing is a red herring, because caching is irrelevant for values computed at compile time. Why would the standard committee go out of their way to add more burden on compiler implementers for something that doesn't solve a real problem? What is the *actual* use case of this proposed change? I keep asking for it, and nobody has shown any justification, only a desire to know why it works the way it does. And I've addressed that: because constexpr functions are meant to be stateless, and function static carry state, and allowing function statics doesn't solve an actual problem. 
Modern C++ is becoming a very high level language that allows ease of use and use without knowing how everything works under the hood. The best part about C++ is that it gives you OO and other niceties, but still allows you to tweak things if you need performance, efficiency, etc... Most high level languages don't offer that as easily. That being said -- if you want to get into embedded work you should have a good understanding of both languages. C and C++ are both advanced languages that give you enough rope to hang yourself. They don't really hold your hand. However, modern C++ standards and practices do a good job of helping to not shoot yourself in the foot. Things like RAII, make silly resource mismanagement less likely. [This](http://electronicdesign.com/dev-tools/interview-bjarne-stroustrup-discusses-c) is a good article of an interview with Bjarne Stroustrup, the inventor of C++. He says in there you can learn C++ without having to be concerned with things in C. But it's always good to have an understanding. Also he mentions the book he wrote "Programming: Principles and Practice using C++." It's definitely worth reading if you want to get into C++. Something to remember about C++ though, is that the language is HUGE. It takes decades to become proficient and at least a couple years to even understand certain concepts. It's also not the type of language you just want to spew out code in, it's about designing elegant solutions to problems. Hope that helps.
Thanks for the reply. I'll take a look at that book, and I figured this would be a four or five year investment to get to the point where I felt capable of integrating this into my career path.
As a general question to people more knowledgeable about modern C++ than I am, what is the benefit of declaring the entry point as auto main(void) -&gt; int as opposed to int main(void) Does the annotation not override the use of auto?
Hi, I've also recently started programming 3D applications. I recommend to use OpenGL, mainly because it's cross platform. The downside to OpenGL is that it does not have an official SDK and can be quite tricky to setup. For tutorials and learning references, I recommend [open.gl](http://open.gl/) for tutorials and [docs.gl](http://docs.gl/) for an API reference. Do note that the open.gl tutorials do not touch lighting, for tutorials that do touch on it, I recommend looking on the OpenGL subreddit /r/opengl. In my project I currently use [GLFW](http://glfw.org/) for windowing and input, coupled with boost.signals2 to bind input events to functions. For the math I use [glm](http://glm.g-truc.net/). And for OpenGL API loading (you will learn about this in the tutorials) I use [glxw](https://github.com/rikusalminen/glxw). I did use a few other loaders, but I ended up scrapping glLoad, which conveniently wraps the OpenGL API in a c++ namespace, because I couldn't get certain debugging features to work. Speaking about debugging [this article](https://lva.cg.tuwien.ac.at/cgue/wiki/doku.php?id=students:debugcontext) will be a great help once you get it all up and running. There are also specific debuggers, which allow you to inspect your frames, see the call order of OpenGL function calls, etc. For such a tool I recommend [apitrace](https://apitrace.github.io/), it has helped me out numerous times when I was stuck and nothing was rendering on the screen. Hope I could've been of any help and good luck!
It might be easier to learn C first, which is mostly a subset of C++
You can learn in two ways: - Top-down --- first learn to use things such as vector, etc. later enter the details and inner workings. You can learn how to use it without knowing the inner workings at first. - Bottom-up: learn first the machine details, pointers, new, delete, etc. until you have an understanding of how things like vector can be implemented. Personally, I recommend you to go Top-down: you will be able to do useful things faster, and later you can always learn the details. As an example, I learnt at first year at university with Python (no memory management), later we started with C and C++, when the basic concepts were already in place. I think it is a highly effective way of teaching. So full advice: learn to use things such as vector, map, unordered_map, strings, utilities such as std::function and pair/tuple and algorithms etc. as if you had a high-level language in front of you. Learn at least RAII, copyability of classes and parameter passing. If you are interested in multithreading, also threads, async and futures. After knowing how to use all of that, you can start to get curious about how it is actually implemented. Do NOT forget RAII. Most of these things rely on it to release you from memory management.
&gt; It takes decades to become proficient I disagree. As a counterexample, I went from beginner to expert level in just one decade, and I'm not some bizarre freak of nature. (Okay, I *am*, but not in this respect.) And I wasted a year and a half of my life learning C, which I'll never get back. C++ is challenging, but you shouldn't overstate its difficulty.
I didn't mean to do that. Just wanting to state it's breadth. Takes a long time to become proficient and understand things that are going on. That's what I mean.
start reading a book is too mainstream? 
[Learn How to Program with C++](http://www.pluralsight.com/courses/learn-programming-cplusplus) Or if you're familiair with Java or C#: [Accelerated Introduction to C++](http://www.pluralsight.com/courses/accelerated-introduction-cpp)
Here's my list: 1. Learn to write asynchronous code. 2. Learn to write asynchronous code. 3. Learn to write asynchronous code. * Tell the idiots who design synchronous interfaces to asynchronous processes to start at #1. "I need a thread just for the database driver" "I need a thread for the camera interface" "I need a thread for the http library" No, you don't, or, rather, no you wouldn't if it weren't for the dimwits who design all the crap you then have to work around. If you're an API/library designer, don't assume that you own even one thread. Better yet, don't assume that you will run on any particular thread at all. In spite of all that, you can still provide a single-threaded interface, just make it async with optional sync convenience wrappers - even then it'd be easier to just demonstrate how to use the async interface properly instead of pseudo-sync workarounds. My ideal API: just let me know when things are progressing using a platform-appropriate mechanism, and don't force apartment threading on the objects in the API unless it's some GUI object that absolutely needs to live on a particular thread due to some platform-specific brokenness.
C++ programmer must be able to see the C equivalent of the C++ code he writes.
The audio for the video is awful.
Slides: http://accu.org/content/conf2015/HubertMatthews-Multithreading%20Dos%20And%20Donts.pdf
Not to my knowledge, which is the one downside.
`auto main()` was simply forbidden by the resolution of [Core Issue 1669](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1669).
The only real issue I have with async callback code in an API is that most of them are simply spinning up a their own thread pool to do the work in since the underlying implementation is actually synchronous. This results in a large overhead because you'll likely end up with two thread pools (API's pool for callbacks and caller's pool waiting on your async calls to do more work) that have no idea about the other. If you are writing code that is a library only designed to be consumed by applications - not other libraries - I guess that's acceptable but I feel like you can never know that. TLDR: Do not make an async wrapper that spins up a thread pool in your API
Do your own homework, you lazy ass.
Interesting. Thank you. 
This is much better than the original link.
Here is one #include &lt;stdio.h&gt; #define TA q=/*XYXY*/ #define/*X YXY*/CG r= void p(int n,int c){; for(;n--;) putchar(c) #define Y( z)d;d=c++\ %2&lt;1?x=x*4 +z,c%8&gt;5?\ x=x?p(1,x), 0:x:0:0;d= #define/*X YX*/C Y(1) #define/*X YX*/G Y(2) ;}int(*f)( void),d,c, #define/*X YX*/A Y(0) #define/*XY*/AT int\ m(void/**/){d= #define/*XYX*/T Y(3) #define GC d; return\ 0;}int(*f) (void )=m; x,q,r; int main(){if( f)f();else {for(puts( "#include" "\40\"pro\ g.c\"\n\n \101T"+0); d=!d?x=(x= getchar()) &lt;0?0:x,8*8 :d,TA++c%8 ,TA(1+7*q- q*q)/3,r=c *15-c*c-36 ,p(r&lt;0?!q+ 4:r/6+!q+4 ,32),q||x; c%=16)q?p( 1,"ACGT"[x /d&amp;3]),p(q ,126),p(1, "TGCA"[x/d &amp;3]),d/=4, p(001,10): puts(c%8?\ "CG":"TA") ;puts("GC" );}return 0;}/**/ 
please don't, then we get projects littered with `fopen`, `strlen` and `cstdio` . The only thing that is a subset (and not exactly one, some keywords differ, e.g. void, auto, etc.) is the syntax and grammar. The library is completely different.
Check out /r/cpp_questions if you get stuck
As adzm and metroappelsap pointed out, I'd recommend you start by a book or tutorial (there are free ones on the net, see the links), and ask questions on reddit when stuck. You will not succeed without some effort on your own. You can use riddles as dummy projects, from pages like project euler.
[I wrote program three for you](http://pastebin.com/PXyca5jn), but I forgot which language you wanted and did it in brainfuck instead. I assume that's ok though.
Thanks, but I already got it done. Thanks for trying anyway! 
With ROOT6 it became possible to use modern C++ and e.g. add properly typed interfaces (see e.g. new functions using `TFormula` that are not stringly typed). I believe cleaning up e.g. wrong type hierarchies like in the histogram classes or making ownership explicit are planned for ROOT7 since these would be tons of worthwhile but definitely breaking changes; Axel Naumann publishes some of his idea in his [ROOT7 braindump repo](https://github.com/karies/ROOT7).
Mixing the two is not an issue. If you're doing system level C++ you're sooner or later gonna be calling OS API's directly, and they are always in C-style. Not everyone writes console programs that primarily does std::cout and std::cin. In C++ you have three options; find a C++ wrapper library for the OS functionality you require. Write your own C++ wrapper library for the OS functionality you require. And finally, just go with it and call the C-style API's from your C++ code. 
It may be my complete lack of familiarity with the product (The last time I used Visual C++ was when Windows 95 was new and shiny), but is it possible to just compile an existing single file standalone program through the GUI without creating a project and a bunch of associated new junk files? Also, better documentation for how to install the C++ compiler if you don't realize the default VS2015 install doesn't include it. I only found out how by accident when I went to uninstall it and discovered the uninstaller can also install components. 
It's nice to see more articles about concepts. However, what strikes me is the fact that - following the article - we need macros to make them easy to use... That raises the question: Are concepts already now too cumbersome to write/use? That certainly would be bad. :-)
What about `std::intptr_t`?
While it doesn't make much sense for main(), trailing return types aren't just alternate an syntax / style, e.g. in C++11: template&lt;typename U, typename V&gt; auto add(U x, V y) -&gt; decltype(x+y) { return x+y; } You can't put the decltype first as x and y aren't yet in scope. Plus of course you use this form with lambdas if an explicit return type is desired/required.
Everything is fine with intptr_t! See this small explanation: http://www.viva64.com/en/t/0023/
What I'd really like to see in C++ is a good macro system, like in Lisp type languages.
You're basically asking for a tutor, which is something you can probably find on /r/forhire. If you don't have money and don't want to use online resources or books, your next best bet is going to meetups where you can find people to ask questions or work with.
What I would like to see is Modules, no C preprocessor, and static if. I know, I know, that's D....
Static if is a thing in c++14, kinda - you can have if statements in a constexpr function. Mixing constexpr and non constexpr ifs in the code is a matter of optimization at this point (but I see how "constexpr if" would force constexpr-ness of the tested expression, this is missing, obviously).
I think it's really great idea. Funny enough while googling if there is already such tool for C++, I've found the following blog post: http://www.suodenjoki.dk/us/archive/2010/cpp-checkstyle.htm Looks like the development of tools of such nature for C++ wasn't that popular and that's surprising considering popularity of CheckStyle for Java. Maybe C++ programmers are a bit more relaxed about coding style afterall :)
The blog post is interesting but outdated (from 2010), e.g. `clang-format` by now *does* allow to customize styles and does its jobs really well. Also, quoting the blog post: &gt; The most difficult part is to implement a parser that sufficiently parses C++ source code well enough for checking code layout style. I would prefer a parser that covers C++ 100% (including preprocessor, templates, C++11 stuff and comments) as this will also be helpful as basis for more advanced static code analysis tools. This is what the Clang frontend is for. Unfortunately, right now the tool operates on the AST directly, that is the preprocessor already did its thing. Therefore although we can get all includes we can e.g. not check for the order of includes.
Thanks for the link. I was just talking with a colleague about how they need to get started on ROOT7 since there have been so many changes with modern c++. 
Instead of asking the same question over and over again. Why not look at your own vcblog site for the repeated ranting comments of pissed off users? Some common sense, you're welcome. If you are going to ask me what I'm referring to, the answer is: Everything. Perhaps if you use google instead of bing you would find them all? Seen those comments often enough to wonder why you are ignoring them? Because they don't lick your butt the right way? Is that how microsoft do business? I'm sure not even half of them are allowed through the censorship filter. Which is sad because I enjoy reading them. More material for the pro-open source stuff I guess. Wait a minute. Wasn't microsoft for open source? Why yes. Have been said repeatedly. Time to switch to the conspiracy subforum... 
Could you go into the benefit you see with static constexpr variables? I don't think an actual benefit has been established yet, or any problem with the non-static version demonstrated. I think you are looking at constexpr with runtime colored glasses and are trying to force some sort of memoization for your constexpr function. But constexpr inherently has that property already. Since a constexpr function is something that only depends on its arguments and other constexprs, the compiler is free to calculate a result once for a given argument and cache the result. Sightly modifying your example a bit: constexpr int foo() { constexpr int i = expensive_constexpr_func(); return i; } Do you know of any compilers that wouldn't memoize `i` in the same way you want static to work? 
Yes! I'm using `clang-format` on all of my code bases, but it does code formatting and that's about it. `clang-tidy` is a bit more involved, that is check out [this presentation](http://llvm.org/devmtg/2014-04/PDFs/Talks/clang-tidy%20LLVM%20Euro%202014.pdf): in using LibTooling it 1/ lets you do implement way more advanced features than just coding style conventions but 2/ also requires great additional effort in engineering those checks. In contrast, all this project does is validate user-defined patterns against AST node spellings.
&gt; In 64-bit programs, the size of the pointer is 64 bits and it cannot be put into the int type that remains 32-bit almost in all the systems Even if int was 64 bits wide, it would still be undefined behavior to cast a pointer to int. You can only cast a pointer to intptr_t or void*.
Look at clang/tools/extra's PPTrace for an example of how to hook into the preprocessor.
How is this different from something like [astyle](http://astyle.sourceforge.net/)? Uhm, and that's not supposed to sound assy. I'm a new coder and always on the lookout for new tools.
astyle formats code. This validates that your things have names following your naming convention. AFAICT there is zero overlap between them.
That's incorrect. N4527 5.2.10 [expr.reinterpret.cast]/4-5: "A pointer can be explicitly converted to any integral type large enough to hold it. The mapping function is implementation-defined. [ Note: It is intended to be unsurprising to those who know the addressing structure of the underlying machine. -end note ] A value of type std::nullptr_t can be converted to an integral type; the conversion has the same meaning and validity as a conversion of (void*)0 to the integral type. [ Note: A reinterpret_cast cannot be used to convert a value of any type to the type std::nullptr_t. -end note ] A value of integral type or enumeration type can be explicitly converted to a pointer. A pointer converted to an integer of sufficient size (if any such exists on the implementation) and back to the same pointer type will have its original value; mappings between pointers and integers are otherwise implementation-defined. [ Note: Except as described in 3.7.4.3, the result of such a conversion will not be a safely-derived pointer value. -end note ]"
I'm no D expert, but it looks to me like they have the same potential. C++11 has a pretty restricted constexpr, but C++14 makes it super general. I mean, there's a design choice difference, in that constexpr is an explicit contract while static_if allows you to implictly evaluate any D code in a static context, but that's it. The following code is valid C++14: #include &lt;iostream&gt; using namespace std; constexpr int stuff(int n) { class C { public: constexpr C(int i) : x_(i) {} constexpr int get_x() { return x_; } private: int x_; }; C c(n); return c.get_x(); } int main() { constexpr int i = stuff(42); cout &lt;&lt; i &lt;&lt; endl; return 0; } You can't define a function inside of a constexpr function but that's just because you can't define a function inside of a function. D constexpr has some additional features, it allows you to conditionally declare values at the module level, which constexpr can't. In C++ you can't do that, except with the preprocessor (and you can't use constexprs as part of the preprocessor's input). It mostly boils down to explicit vs implicit: the contracts of the C class and of the stuff function enforce that they are constexpr and will remain so, so client code can safely use them in a constexpr context. In D, AFAIK there's no such contract, which limits the usefulness of static_if. (as I said I'm no D expert so I'll be happy to stand corrected :) )
&gt; Everything you learn in C can be applied in c++. Almost -- there are corner cases. BUT, just because something can be applied doesn't mean it should be. Some things that are common or recommended practices in C should be completely avoided in C++. (Ex: using goto statements to jump to a cleanup section of a function; single exit principle, 'typedef struct', using C-style enums)
For some reason I was under the wrong impression that such as cast is undefined. Thanks for correcting me!
&gt; So the answer to the question, "How is it different in interface to std::future?" is: "It can be used to provide the implementation for std::future. " ? Is that right? It can be used to provide a mostly conforming C++ 1z Concurrency TS std::future correct. The hope is that that implementation becomes *the* Boost future promise implementation. &gt; What is the point? Generally speaking where Boost significantly improves on the state of the art implementation technique, the major STL vendors will copy that Boost technique in their STLs (they are all on boost-dev, and I'm in regular communication with two of them). In other words, if my lightweight future promises prove to be a hit with the Boost community, they'll get copied into all the major STLs and the C++ standard will be adjusted to make them 100% legal rather than 99% legal. If you the C++ practitioner would like a 10 year head start on that, you can grab a copy of Boost and have your code using the step change improvement now. Same as it always was with Boost. That's the point of Boost after all - to be ahead of the curve on older compilers.
This is a really stupid thing, but why can't you drag and drop a .vcxproj file onto the IDE to open it? You get this stupid error message telling you to go use the File menu instead. This used to work in VS2003 definitely, then for some reason it was turned off. The really really stupid thing is you can close VS2015, double click on the .vcxproj file and voila, it launches in a VS2015.
I like this kind of posts. I think it is instructive. 
* We have c++/cli code in some parts of our project so related to that I would love to be able to #include &lt;thread&gt; into code built with /clr. * Support natvis files for /clr code * Support /debug:fastlink formatted symbols when debugging in Mixed mode. * Issue warnings for code using [[deprecated]] classes. Warnings are issued for deprecated functions, just not for classes. (Connect bug filed: https://connect.microsoft.com/VisualStudio/feedback/details/1659228) * +1 for the suggestion to be warned for missing 'override' * Build History! Probably a good extension candidate. cf XCode for how to do it right. So painful to do an analyze, wait for results, then build a file to confirm the fix only to lose all the analysis results. 
A tool like this that checks other types of conventions like bracket placement, indenting style, and other things would be great.
Going from one language to another, you'd expect corner cases and language differences. I disagree about the goto statements, there are cases where goto's fit well within c++. When learning C++, you will understand why typedef-ing structs is no longer require. Same with the scoping rules introduced in c++. Someone without a C background would probably be confused. Having the "C" Domain knowledge will , in my opinion, make you a better c++ developer. Usually when transitioning from C to C++, you can get a list of the "what not to do" or "here's a better/different approach" to solving this problem. So considering your statement ZMeson. Just remember that there are differences between languages (scoping rules, memory allocations, etc) and there are different ways of solving problems between the two. IMO C is much easier to learn than C++.. If you are able to pick up on C and understand the fundamentals, move to the harder, yet more feature rich subset C++. Then eventually c++11/14... 
[Have fun reverse engineering this](https://drive.google.com/file/d/0B0Si0y-68hZyeWNjQ1dEVWNaQjg/view?usp=sharing) The only reason no one would really want to help you, it's because you should learn by yourself (and use some logic, programming is logic for the most part), not copy others work to get a good grade If you can't understand arrays and for-loops, just go on youtube and look for the many tutorials (like [thenewboston](https://www.youtube.com/playlist?list=PLAE85DE8440AA6B83)) Oh, and if you already have done the homeworks, I suggest you to try reverse my .exe for any easter eggs, maybe it will be funny and you will learn something new :)
I doubt it's the setup, and more likely due to bugs in VS2015. Loading cmake-generated solutions with &gt;50 projects, I've had the thing crash when I type a single character into a source file opened for editing. Thankfully I do all the real editing in Emacs and will have to use VS2013 as the default until https://connect.microsoft.com/VisualStudio/feedback/details/1331482/bug-in-stl is fixed since that's an absolute blocker to using VS2015. In all seriousness, I've had VS2015 crash several times an hour while trying to use it for some building mixed with some fairly lightweight editing and rebuilding, with the occasional reload of the solution when cmake needed to regenerate them.
Will it be possible to use libc++?
Closed as not constructive.
You can use any code formatter for that. `clang-format`, `astyle`, etc. 
Ah, sounds good.
Or that c-style code is unreliable and your check-in utility (or your soul) should choke on the use of memset and malloc? Also unsigned types require caution.
The size of the object being returned in these tests is `10000 * sizeof(int)` Looks like GCC does a very good job of eliding copies with MSVC and clang performing poorly.
Interesting, it looks like the only ones clang trips up on are of the form `return param ? a : b;`, but it optimises with `if (param) { return a; } else { return b; }`.
Is copy elision permitted in `return param ? a : b`? I would have thought not. The return statement's expression is not "the name of a non-volatile automatic object ... with the same cv-unqualified type as the function return type". edit: gcc performs copy elision under a ternary in cases, L, P, and R. In these cases, clang, MSVC, and Embarcadero all do _not_ move, which means they all seem to agree that elision is not permissible here. In any case, these and case H aside (which is a bug), basically all the major compiler have the exact same behavior, so I drew a rather different conclusion: the simple rule "don't bet on copy elision under the conditional operator" seems fine.
I did a small investigation regarding the minimum optimization level required to get these results with GCC 4.9.2 (Debian jesse 4.9.2-10). It turns out that GCC performs the same copy elision in -O0, -Os, -O1, -O2, -Og, and -O3. With -fno-elide-constructors, the move or copy constructor gets called in all of these cases, depending on whether or not C++11 mode and -DALLOW_MOVE are enabled. GCC effectively treats this as a language-level feature, not an optimization-level feature. Sweet!
Rather, GCC does a very good job at not conforming to the standard.
To be frank, this entire optimization exists in the first place because Walter Bright decided that it was far more important than conforming to the standard. But ignoring that, which case doesn't adhere to the standard?
All the ternary operator cases, pretty much. These don't qualify for copy elision.
Or you can put in a /n in one cout. Whatever floats your c++ boat.
It's actually a dupe but I can't find the original :)
Given a conventional `operator+=` returning a `T&amp;`, your "unnamed RVO" case doesn't qualify for elision and in fact is required to copy.
Oh, yes, absolutely. RapidCheck is meant to be integrated with your existing unit test framework, it is not a replacement for it. RapidCheck uses Catch to drive its own test suite which is why there is basic integration shipping with it but integration with Boost Test and Google Test is a planned feature. It would not be hard to simply roll your own macro for it either.
RapidCheck (and most other frameworks based on the QuickCheck concept) has a size parameter for each test case that influences the "size" of the generated data. For size 0, most generators generate only a trivial value, which for the integer generator shipped with RapidCheck is 0. So the '0' test case is even guaranteed to be tested. RapidCheck generates data structures instead of binary data which I believe yields less noise and also aids in test case shrinking but it is missing the coverage aspect which means that it something of a blind firing. It would be awesome to combine the two. However, you'd be surprised at how thorough testing you get from very little tweaking...
If I right click a .cpp -&gt; compile I want to compile even if it hasn't changed ( I want to see the warnings for that particular file ). If I double click an error in the error window I want the output window to move to that error, since that is where the interesting information is. It used to do this in older versions, so might be a bug. Likewise double click a line in the output window which is a file + line number should open that file and put the caret on that line, this also used to work but doesn't anymore it seems. Both of the above errors might be to VAX though, but still throwing it out there :) A new feature, but when I add a new file to the project I want it to create the .cpp &amp; .h intelligently at the same time. I want it to have 2 folder textboxes, one for .h &amp; one for .cpp. These should be either remembered from the last time I added something, or be deduced from the common root of my .h files, and common root for my .cpp files. I also want you guys to talk to with the Clang guys on getting the MSVC integration finished. I know this is a sensitive issue, but we all know they will get there on their own in due time ( they're making remarkable progress already ).
I have, in fact, exchanged several mails with one of the Clang devs. I told him what I was fixing in the STL and the bugs I had filed, and he explained a lot of useful stuff and actually fixed a couple of issues in Clang trunk, which we just need to sync to now.
Open now; I would have re-opened it if was not.
Why the word "method" is used so often? I thought for C++ "member function" is preferable term.
I'm not one of the authors BTW, just posted because I'm interested in reading what folks here think.
click bait blog posts...
`T(lhs) += rhs` is not "the name of a non-volatile automatic object ... with the same cv-unqualified type as the function return type", nor "a temporary class object that has not been bound to a reference", so it does not fall in any of the permitted cases in [class.copy]/p31. It's also not "a (possibly parenthesized) *id-expression* ..." and so doesn't qualify for implicit move either. Demo: http://coliru.stacked-crooked.com/a/bb7c81d14f2c6129
Yeah C++ has functions. I think that's a losing battle though.
&gt; calling new or malloc cannot be optimized away (they may have side effects) `malloc` can be optimized away. It's a standard library function; the compiler knows what it does. The issue with optimizing away `operator new` calls under as-if is that that function is replaceable and the replacement may have side effects. [N3664](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3664.html) fixes that by granting explicit permission.
&gt; since range-v3 is intended for C++17 I have no idea what the ship vehicle will be for the Ranges Extensions. Please don't say ranges will be in C++17 as if it were fact. It's not.
[data-driven tests](http://www.boost.org/doc/libs/1_59_0/libs/test/doc/html/boost_test/tests_organization/test_cases/test_case_generation.html) (including cartesian grids) for one
Too many people write C++ like they write C... which I guess is better than the people who write it like Java (shudder), since you know... It's an OO language right? I've seen people from a Java background allocating everything on the heap without any cleanup at all. As for using stuff like memset or memcpy, people need to have a little more faith in their compilers. Most modern compilers will replace code like int array[size]; for(int i = 0; i &lt; size; ++i) array[size] = 0; with a memset anyway. Or memcpy when iterating and copying trivially copyable types anyway.
What does this have to do with the actual content of the blog post?
For me, functions exist outside of classes (ala C), whereas Methods exist within classes. To call them method functions (to me) potentially adds confusion. That and every other language calls them methods, why be different for the sake of being different.
I don't quite know why, but the wording "avoid too big [noun]" really bugs me.
This is incredibly cool.
Anybody else getting the 'warning C4005: 'BOOST_ASIO_ERROR_CATEGORY_NOEXCEPT': macro redefinition' warning when compiling asio code with vs2015?
I also did some work in this direction, although my library has a completely different design. Check out [fp](https://github.com/mizvekov/fp)
[I wrote this a while back](https://github.com/nicrohobak/ansigl) (it used to be hosted on sourceforge, but I moved it recently...this is/will be the most current). The original goal was to have something that would be suitable for a "modern" MUD, but it was large enough to become its own project/library. Not sure if it will fit the bill, but I'm more than happy to pick up work on it again if there's any interest. Edit: Actually, [the sourceforge page](http://sourceforge.net/projects/ansigl/) is worth a look too. It has screenshots and things that I didn't move.
I've been contemplating doing this for years, but never settled on a design that I liked. I'm glad to see others have stepped up to the plate! One significant limitation here is it limits you to a binary radix. I've needed to do things with much more interesting radix points.
I wince when I hear *stood*. If you say *stood*, stop and think whether you're following any path of logic at all.
Mostly very similar to pubby: std:: - like stud but with a dropped 'u' so "st'd" deckle type pointer, reference, rvalue reference usually, although if reading, say, "char *" I'd read it as "char star" const expruh double ewe char tea (a lot of my colleagues pronounce char as "car" which bugs me for some reason). Sometimes I might say "wuh-char" instead of "double ewe char" iffen def ess vin eh Another one which seems to have different followers is boost::asio - I pronounce it "a-zee-o" whereas other colleagues say "a ess eye o"
Thanks to everybody involved and particularly to the release team. Preparing a boost release is a job nobody should be doing in their free time. I wish isocpp would make sure that this does not happen. 
Huh, I say "char" as in charcoal, I don't say "character" as "car-acter" or "care-acter" though.
Checkout Termbox, its in C though. Im writing a C++ [wrapper](https://github.com/dacechavez/cppbox) on top of it but its nowhere near finished (checkout test.cpp for an example). 
standard (as in, "standard vector") deck-ll-type star, and, and-and (int star, int and, int and and) const-ecks-per double-ewe kar tee if-n-def sfinay
stood as in fud, or stood as in feud? Both are wrong.
I mean, better abstractions like blessed/blessings.
* std:: =&gt; stud without the u. * decltype =&gt; Deckell Type * *,&amp;,&amp;&amp; in type *, type &amp;, type &amp;&amp; =&gt; Star, ref, ref-ref. It's good to be consistent. * constexpr =&gt; const-exper. * wchar_t =&gt; I think wuh-char-tee, but I'm not sure I've ever said it out loud. * #ifndef =&gt; hash-iff'n'def. * SFINAE =&gt; sphinnay. I assume some of these are probably wrong. I also pronounce Linux exactly as it is spelled.
Wow!
Additionally: how do you pronounce mingw? I pronounce it "ming - why", yet I never found a canon reference.
There is try_lexical_convert() since Boost 1.56 to convert with error return instead of exception, but boost::convert has other advantages for advandced conversion.
While that is deliciously evil and awesome, I don't think they could actually standardize it due to its dependence on using virtual memory.
Yes, I got that with 1.58 too - still seems to work, I haven't investigated further yet.
Because IPA exists, but few people know how to read it.
I thought `malloc` was protected too in case it was replaced by an implementation with side-effects. If it's not that's one less issue I guess.
Actually, Rust provides destructors (by implementing a `Drop` trait). The it is just that: - Rust does not provide a way to customize moves - Rust does not provide implicit copying, an explicit copy must be performed via `.clone()` (unless the type is `Copy`, but that's very specific) Has a result, idiomatic Rust is: - all about moves, so no copy to elide (no issues with memory allocation and other side effects) - its moves drip down all the way to the IR which can naturally optimize them in a lot of situations (because `memcpy` is known not to have side-effects) Of course, there might still be situations where this does not pan out; but they will much rarer compared to C++.
closed_unit is a little dangerous. From docs it may look as if it maps 1.0 to all set bits (0xff for 8bit, 0xffff for 16bit etc, a mapping which is very common in graphics). But closed_unit just maps [0,2) range.
* `std::` -&gt; ess-tee-dee * `decltype` -&gt; deckle-type * `*`, `&amp;`, `&amp;&amp;` -&gt; star, ref(erence), r-value ref(erence) * `constexpr` -&gt; const-ex-per * `wchar_t` -&gt; double-you-car-tee * `#ifndef` -&gt; if-en-def * SFINAE -&gt; ess-fin-ee
&gt;Our types were implemented in a pattern like this: &gt; … Ugh, no. Its 2015. Just use &lt;cstdint&gt; already.
Million times this. Spotify also seems quite buggy and unresponsive so no offense but I don't really trust their testing methods...
`char` is pronounced as "care" because it's a prefix of "character". It's not an independent word (in which case it would be pronounced like charred wood).
Just curious, how do you arrive at "decal"? I thought `decltype` stands for _declared type_?
I think lacks identity, is movable is a prvalue (pure rvalue). rvalue is the same as "is movable", prvalues and xvalues are both types of rvalues, the same way that lvalues and xvalues are both types of glvalues. There's a good SO question that really helped me with this.
Is aye the same as "eh" (the Canadianism) or "I"? I say SFINAE as sfin-eh, don't see the point pronouncing the "S". Other than that, I used to be identical to this. Then I heard a lot of committee members use "stid" or something similar (very short vowel) for std, which saves not one but two (!!!) syllables. So I switched to that.
Man, you're fast like an AI! Is there some method I'm not aware of that lets you see comments independent of thread, as they're posted? Last time around you also saw and replied to fresh comments under a post that was several days old, where I wouldn't expect folks to be on top of it. :) &amp;#160; ^(*I guess that's what the "quick" in your username stands for? :&amp;#41;*)
Hah. The quick in my username has made me the butt of many a joke. That's what you get for picking your gmail when you're 16. Honestly it was just random coincidence. I clicked on this, saw the comments, posted. Of course, this last comment was a response to me, so I got that orange thing on the right. Since I was too lazy before: http://stackoverflow.com/questions/3601602/what-are-rvalues-lvalues-xvalues-glvalues-and-prvalues. The second answer, the community wiki one, has a nice diagram.
This is very nice. It not only tells some history, but also explains why the names for the various kinds of values are *meaningful*, making them easier to understand &amp; remember.
Ah thanks for pointing this one out, fixed that.
You can link directly to that answer if you use the 'share' url: http://stackoverflow.com/a/3601748/341744
&gt;It gave us a lot of flexibility What is this even supposed to mean? You either need to store a size (and should therefore be using `std::size_t`) or you don't. There's nothing to be flexible about. 99 times out of 100 vague, hand wavy "*benefits*" like this are just attempts to justify or dismiss criticism of objectively bad, obtuse, etc. practices. When I look at your code I know what `std::size_t` is, I have no idea what `ITwitchToo_int_type` is. There's a standard library with standard types for a reason. Code isn't just about doing the right thing, it's also about communicating with the reader.
 #define DEFAULT TB_DEFAULT #define BLACK TB_BLACK #define RED TB_RED #define GREEN TB_GREEN #define YELLOW TB_YELLOW #define BLUE TB_BLUE #define MAGENTA TB_MAGENTA #define CYAN TB_CYAN #define WHITE TB_WHITE [If you're going to write in C++ observe good C++ style/practice. It's a whole different language, not "*C with more cool stuff*".](http://en.cppreference.com/w/cpp/language/enum#Scoped_enumerations)
&gt; He really gives me hope that I won't have to learn Latex to write papers. * https://github.com/Hoverbear/acm-pandoc-paper * https://github.com/djhocking/Markdown-for-Manuscripts You're welcome :-) 
Why would you put all the headers in the same directory as the source? 
You can prolong the life of a prvalue by binding a reference to it: auto const &amp;ref = ReturnsObj(); auto&amp;&amp; ref2 = ReturnsObj(); However that doesn't always work for xvalues: auto&amp;&amp; ref3 = std::move( std::string{"hello"} ); Now `ref3` is a dangling reference, the temporary string does not get extended. Of course this is terrible code, just meant to illustrate a point: if you receive an xvalue then, to be guaranteed safe, it has to be used immediately. 
The safe_multiply doesn't seem safe for numbers less than one. It only increases the integer digits, where it should promote the type. For example, sg14::safe_multiply(sg14::ufixed8_8_t(0.5), sg14::ufixed8_8_t(0.5)) evaluates to 0
The snag with X as expiring is that it helps someone get the idea for a while. I bit like universal references. My view is that the cold hard truth should be taught from day one.
So what's that function do?
ok understand this but (IMHO) it is not that beautifull... moreover it was enough for the legacy compiler to know that contained elements are const pointers and disambiguate why not for the new one?
Basically dispatches a thread to execute some function you pass as a template arg, a "future". The future returns *before* it's finished executing your function. Later on you can get/wait for the result. I mean there are some other MC++ things thrown in for illustration but that's the gist of it. Futures aren't a new thing in a lot of languages.
Heh, doing it outside of work is the only opportunity I'd get to write a for loop where getting the begin iter doesn't wrap a fucking line! Auto? foreach? If only! I can see that would be a nice hobby, I javascript to relax :).
&gt; In my current job we have to support g++-4.1 I'm guessing thats for CentOS 5.9? 
&gt;auto m = fixed7_8_t(1.23); Does that take a double? What is the actual value of m, assuming that 1.23 cannot be represented by a double? 
I work on an embedded system. We’re currently at gcc4.4. It has some basic C++11 support, and we get some of the C++11 features via boost. We have to be conservative about upgrading things, but—as long as we time it right in the development cycle—I’d be surprised if we don’t get up to the latest gcc in the next year or so. But I also write a lot of code that doesn’t run on the device. Automating tasks, testing tools, etc. nothing keeping me from using the latest C++ (or even Scheme) for those things.
The thing that is more unique for C++ is the fact that the template can take any function with any argument list and turn it into a future with compile time type safety . Certainly can't do that in java and I'm not sure you can do it in C# (does C# support variadic templates?). You might be able to do something like this in javascript, except for the threading part.
C# can’t do this either; nor can JavaScript, for that matter, since you’re talking about compile time safety, and that’s actually a pretty crucial aspect here. In C# and Java you’d implement this by wrapping the callable into an argument-less lambda on the call site.
It is true. Javascript could approximate the usage most closely (without the typesafety) as it has all the bits there to make a function that does the same thing. But, as you said, it lacks any type safety.
Create some small helper functions for const and non_const member functions. The example below compiles with Visual C++ 2015. #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;iterator&gt; #include &lt;functional&gt; #include &lt;algorithm&gt; class A { char _msg[32]; public: A(const char* msg) { strcpy_s(_msg, 32, msg); } const char* message() const { return _msg; } char* message() { return _msg; } }; template&lt; class R, class T&gt; auto const_mem_fn( R( T::* pm)()const ) { return std::mem_fun(pm); } template&lt; class R, class T&gt; auto non_const_mem_fn(R(T::* pm)()) { return std::mem_fun(pm); } int main() { std::vector&lt;const A*&gt; const_in = { new A("one"), new A("two"), new A("three") }; std::vector&lt; A*&gt; non_const_in = { new A("one"), new A("two"), new A("three") }; std::vector&lt;const char*&gt; out; std::transform(const_in.begin(), const_in.end(), std::back_inserter(out), const_mem_fn(&amp;A::message)); std::transform(non_const_in.begin(), non_const_in.end(), std::back_inserter(out), non_const_mem_fn(&amp;A::message)); std::transform(non_const_in.begin(), non_const_in.end(), std::back_inserter(out), const_mem_fn(&amp;A::message)); return 0; } 
Yeah, but most people for some reason are incapable of finding that.
Embedded developer here too (consultant). All of my clients' code is "old school" C++, although a couple of them really use every dusty corner of the language (C++03 version), including some pretty heavy use of templates in creative ways. But the only time I use C++11 is my "outside of work" stuff. There are 2 main reasons for not using C++11 in my consulting work (not my decision). First is that many of the cross-compilers used don't support it (still!), at least not well; at least 2 of the projects I'm working on, there isn't a good C++ (C++03) compiler! So sometimes I'm just using C (which unlike a lot of people here probably, I don't mind actually). Second reason is that often the project leader will essentially require me (and others) to write code to the lowest common denominator, i.e., "Please don't use that stuff, only a third of the people in the company will understand it." The client pays the bills, the client decides. That's why in my personal stuff I like to stretch my legs, so to speak...
&gt; C++ (C++03) "*C++*" is C++14. &gt;Second reason is that often the project leader will essentially require me (and others) to write code to the lowest common denominator, i.e., "Please don't use that stuff, only a third of the people in the company will understand it." Sounds like two thirds of the people in your company need to be canned.
[As /u/Krexington_III pointed out, the code snippet could be improved](https://www.reddit.com/r/cpp/comments/3h2pez/why_you_have_to_learn_modern_c_all_your_base_are/cu3tud9). I've aimed to do just that: #include &lt;functional&gt; #include &lt;future&gt; #include &lt;ostream&gt; #include &lt;thread&gt; #include &lt;utility&gt; template &lt;typename Fn, typename... Args&gt; auto do_async_with_log (std::ostream &amp; os, Fn &amp;&amp; fn, Args &amp;&amp;... args) { os &lt;&lt; "[TID=" &lt;&lt; std::this_thread::get_id() &lt;&lt; "] Starting to invoke function..." &lt;&lt; std::endl; return std::async([b=std::bind(std::forward&lt;Fn&gt;(fn),std::forward&lt;Args&gt;(args)...),&amp;os] mutable { auto result=b(); os &lt;&lt; "[TID=" &lt;&lt; std::this_thread::get_id() &lt;&lt; "] ...invocation done, returning " &lt;&lt; result &lt;&lt; std::endl; return result; }); }
Seems to work fine on every single other version of GCC and Clang.
Yes, inside the function. The difference is precisely that in C++ you can do this inside the library, and the caller has a 100% generic interface (at compile time). In C# and Java this has to be done at the call site instead.
I somehow don’t think that /u/Krexington_III would agree with you that this represents an improvement of the original code. ;-) (I, however, do. As noted elsewhere, `mutable` isn’t required though.)
Yay, I understand nearly everything from this func :S
Is there any real change apart from forwarding fn to std::bind? And removing intermediate(superfluous) bound variable? As for second, I think it was intended, to reduce complexity a bit(this lambda is pretty... unreadable(after this change), I think).
No `using namespace std`. All the required headers are actually included. Include `ostream` rather than `iostream`. Let the compiler deduce the return type rather than explicitly specifying it. The superfluous bound variable introduces an overhead of one move copy, so it makes sense to eliminate it. 
As name says, it starts given function asynchronously(passing the parameters from args to it), with some logs(that it started, and that it finished).
I would say yes. I would say the average c++ developer cannot/does not use anything at work that is more than 12 to 17 years out of date. But, my perception of the industry may be off base.
FWIW, [this is a thing](https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/05prNzycvYU%5B1-25%5D). It would certainly be handy sometimes to allow that line to compile.
I'll stand by what I said about canning these developers. I mean if developers who only know C++98 are hireable/employable, then why not developers who work in classic ASP/VBScript? I mean classic ASP/VBScript's last release is ~two years newer than C++98! TL;DR: It's not a very high bar.
I'm also an embedded developer and we use primarily embedded C++ (although it looks more like C with classes). No namespaces, no templates, no smart pointers, none of the typecast operators, no STL, and definitely no Boost. Now with C++14, I'm even further out of date. I'd love to find another job but I'm not sure what to do. In a lot of phonescreens, I've been expected to essentially have STL and Boost memorized, I need to be able to implement data structures from scratch quickly, solve algorithm questions, and know C++11 in and out. On some level this is reasonable but as a junior engineer, I'm often expected to have OSS contributions, personal projects, knowledge of the TCP/IP stack in and out, database experience, and often full knowledge of another OO language. After a 10 hour work day, where do I even start if I want to have any semblance of a life outside of programming?
Most C++ developers I have met outside CERN, couldn't hardly know C++98 properly, let alone modern revisions of the language. They are not alone though. I do JVM/.NET nowadays, and most enterprise developers only update their knowledge when business decides to upgrade the supported language versions. It is up to us consultants to bring them up to speed to actual versions.
awesome, that looks really similar
&gt; most enterprise developers only update their knowledge when business decides to upgrade the supported language versions. They better keep their fingers crossed real, real tight that they never lose their job and have to find another one!
Ah, didn't know that future have void overload, I've never written concurrent program yet :S What happens if you try to get value from void-future? Compile time error?
TIL about existence of std::result_of_t :)
Cool! Do you have any theory why the speeds diverge for large ranges? Have you looked at how the resulting assembly diverges? 
I have no idea what 2008 was thinking here (it's almost certainly a compiler bug, since we haven't changed `mem_fun` in all those years). 2015 and the Standard consider this to be ambiguous for a simple reason: in C++, information almost never flows backwards. That is, the meaning of an expression is almost purely determined by its content and what's previously been declared, but not determined by its surrounding context. For example, overload resolution doesn't consider return types, and the type of `x + y` is not influenced by what it's being assigned to (this behavior of the usual arithmetic conversions goes all the way back to C). There are a couple of exceptions to this rule, one of which is relevant here. When taking the address of an overloaded or templated function (or member function), the context is used to disambiguate in certain situations. This is so special, a whole section of the Standard is devoted to explaining the rule. Basically, if the context provides a concrete type, like assigning to a function pointer of a particular type, then that will be used to disambiguate. Calling a function with an argument of a concrete type is also acceptable. But here you're calling `transform()`, which is templated on a UnaryOp. That could be any type, and the Standard's rules do *not* permit it to keep going and try to guess what UnaryOp should be - so the type of the `back_insert_iterator` is not considered. This is a good and sane restriction. Another context for disambiguation is `static_cast`, which is why you can select an overloaded/templated function pointer/PMF that way.
I had overlooked that! But there's still a similar problem: if you pass a `const int&amp;` to the function, the functor won't get a `const` reference, it having been stripped off by `decay`. Further, the r-value reference-ness of the `args` and `fn` aren't preserved. In fact, `bind` looks a lot like a trap waiting to ensnare the unwary to me. Making it do what I expect (while still taking owenership of the data) results in a lot more code though. edit: on reflection, they should almost certainly all be passed as r-value references.
If you were using a hypothetical GCC command-line switch that made it zero-initialize all variables, yes. It's fine for disabling RTTI to break actual C++ code, since you're no longer writing standard C++. It's not fine for a compiler to have a compilation option that doesn't actually work, and the documentation has always said that the standard library continues to work to the extent that is possible with RTTI disabled.
Why not old good CppIterTools?
No, but adoption of new features obviously needs to take into account the amount of backward compatibility your users/customers require. For example, the development version of my schroot project now requires C++11 language features, but the current stable version uses only C++11 library features with fallbacks (TR1 or Boost) such as std::shared_ptr. That's due to the range of GCC/clang versions which it needed to support. Now that all current and recent systems support C++11 it was possible to drop the fallbacks and use language features as well. For work projects, we evaluate the range of systems we will support for each major release of the software and the features we can use are essentially the lowest common denominator on all platforms. For a while we were held back by MacOS X using GCC 4.2 and more recently CentOS 6. But it's likely that with the release of CentOS 7 and the newer Platform Toolset on CentOS 6 supporting GCC 4.9, and newer MacOS X systems all using a recent clang, that we will be able to start using the subset of C++11 features which are also available in VS2012/VS2013 for our next major release. I think this can obviously vary wildly from project to project. If it's a prototype or for internal use only, I wouldn't have a problem using the latest features without constraints. But my experience with both non-commercial and commercial open source software is that modern C++ features can be slowly adopted as it becomes practical to do so. I'm certainly looking forward to be able to use auto and range-based for loops for the first time at work later in the month!
First of all, thanks, a lot! I miss lambdas so much when working with legacy tool (all the time, sigh). I find them clearer, in this case it seemed to me a bit verbose and I was not sure about the optimizations. Anyway, my understanding of the behavious of VC2008 was that it takes into account the constantness of elements into the container so that the unique applicable methods is the const one. Your consideration on back_nserter_interator apply also for the InIt, right? As a professional user I'm very happy to see this attention from microsoft to be standard compliant (as for my perception it is greatly increased last years). 
&gt;I work on an embedded system. We’re currently at gcc4.4 You can use a later version of gcc, so long as you keep building for the same target. For popular platforms like ARM you can probably find an existing toolchain. I guess if it is some esoteric CPU where the vendor hacked up their own gcc backend you'd be out of luck. 
If you go with binary distribution, you will need to deal with keeping a bunch of builds available for different platforms/architectures plus debug/release for each. An automated build system (Jenkis, et.al.) can help with this. For Linux distribution, just distribute as source with proper makefiles (autotools and CMake are popular). Binary distributon is generally done by packaging the library with the headers like so: yourLibraryName libs x86 yourLibraryName-x86.so x64 yourLibraryName-x64.so include &lt;all headers in here&gt; It is generally easier to release as source, since the end users will compile the library for their system, with the compiler flags they want (static/dynamic linkage, optimization type, etc.). On top of that, someone may want to use your library on an odd platform (ARM, AVR, etc.). If you are worried about people branching your code, make it clear that you will consider suggestions made by users to improve the library (bug fixes, improvements, feature additons, etc).
If you like the python itertools, give a try to [ryanhaining/cppitertools](https://github.com/ryanhaining/cppitertools) and if you wanna go up to 11 (or I'd better say.. 17) you should check [Erik Niebler's ranges](https://github.com/ericniebler/range-v3).
global variables
I was reading Google's style guide for C++ and even they try to avoid stuff like this. From here: [Source](https://google-styleguide.googlecode.com/svn/trunk/cppguide.html#Template_metaprogramming) "Template metaprogramming sometimes allows cleaner and easier-to-use interfaces than would be possible without it, but it's also often a temptation to be overly clever. It's best used in a small number of low level components where the extra maintenance burden is spread out over a large number of uses." and "The techniques used in template metaprogramming are often obscure to anyone but language experts."
Nope, like it is written in the article.
&gt;&gt;there is no "renew" operator Yep, that's true. &gt;&gt; malloc is necessary Yeah, I sometimes use it to allocate to AVX boundaries. We can avoid most problems with smart pointers. I safely hid my allocation malloc with an allocator (2nd argument to unique ptr), and most smart pointers have a `pointer.reset()` (or maybe I misunderstood what a renew does). C++ was invented to avoid the errors in the OP's link!
Google style guide is Google Style Guide For Managing Google's Legacy Codebase. Is not, and never was, a good style guide for standard c++. People should stop using it as reference only because is Google.
That gives you a static, not a singleton, since the constructor of T must now be public. The variant of Meyer's implementation shown in the article (a templated class instead of a templated function) would therefore be better.
Singletons are great... ...until you have to share them across multiple DLLs.
Oh OK now I get it. That implementation was also given in the article. Still, I don't see how you can make T's ctor private. The only way to do it properly is without a generic templated Singleton class, and just rewrite the instance() function for every class that needs it.
I used to think singletons were great until I had a horror story with them. I had to remove them all because it made all my code untestable, lol! At that time I was much more amateur than now. I learnt the lesson already, I guess. :D
Is the expectation that std::experimental::apply would mean that the bind() special cases would no longer happen (meaning eliminating bind similar to below)? #include &lt;iostream&gt; #include &lt;future&gt; #include &lt;experimental/tuple&gt; using namespace std; template &lt;typename Fn, typename... Args&gt; auto do_async_with_log(ostream&amp; os, Fn&amp;&amp; fn, Args&amp;&amp;... args) { os &lt;&lt; "[TID=" &lt;&lt; this_thread::get_id() &lt;&lt; "] Starting to invoke function..." &lt;&lt; endl; return async([fn=forward&lt;Fn&amp;&amp;&gt;(fn),tuple_args=forward_as_tuple(args...),&amp;os]() mutable { auto result = experimental::apply(forward&lt;Fn&amp;&amp;&gt;(fn), move(tuple_args)); os &lt;&lt; "[TID=" &lt;&lt; this_thread::get_id() &lt;&lt; "] ...invocation done, returning " &lt;&lt; result &lt;&lt; endl; return result; }); } 
&gt; The logic is very simple - it's the desired interface that's complex. The interface type is a kind of logic (typed logic), and it’s the one I meant here. That *is* a kind of logic (in fact, in Haskell there’s a whole library ecosystem for writing typed logic). &gt; The reason that this function isn't readable and can't be made readable is because they chose a bad interface It’s *not* a bad interface though: from the perspective of the caller it’s a good interface. &gt; The given code returns a `future&lt;decltype(Fn(args...))&gt;`, but the function actually returns `future&lt;decltype(Fn_tag(args...))&gt;` Yes, I know that. I agree that there’s no good/easy way of writing the return type. What you can/should do is use `auto&amp;&amp; result = b()` and then use the following return type: future&lt;decltype(bind(fn, forward&lt;Args&gt;(args)...)())&gt; But this also runs into intricacies. All in all, the return type should really be inferred here. I agree that the way the function is written originally isn’t correct or good. I’ll also grant that changing the interface is probably the way to go.
Ironic considering Microsoft is somewhat behind on implementing the current C++14 standard. Please tell me their complier team is about to put in a whole bunch of sprints!
Putting variable number of arguments of functions everywhere, auto type everywhere , template programming everywhere and value semantics everywhere are certainly a very bad code practice. These things are certainly useful in some cases. However 99% of code is not using such things. Unfortunately, 99% of the blog examples are focused on that. Never forget that metaprogramming is nothing more than sophisticated MACROs 
You have to **declare** your functions before they are used, so if you use them in ``main`` you have to declare them beforehand. What you can do, is declare them before ``main``, then **define** them after ``main``, and let the linker do its magic. eg: // This is a declaration int foo(int); int main(void) { foo(10); return 0; } // This is a definition // (and technically a declaration as well) int foo(int a) { return a * 2; } Now, for small programs, it doesn't really make any difference, but for anything more than a couple of functions I would prefer to have just declarations on top and then all the definitions after the main. For any semi-serious to serious programming, you should split your functions into separate header and source files. Put the declaration in the header file and the definition in the source file. However, for the love of whatever is holy, do not put just one function per file. Group your functions based on dependencies and what makes sense. For example, the ``stdio.h`` header file contains IO related functions.
I'm interested in this, could you give a more detailed example? Thanks!
There are cases where this isn't a valid solution. My case is that I am writing a pooled memory allocator and I need to ensure there is one instance. The C++03 containers do not allow for passing in an allocator instance, therefore I am forced to use a Singleton.
Very interesting. Thank you!
Absolutely. The problem a lot of people don't get is that even the *best* best practice is not a 100% use-all-the-time weapon. There's exceptions to every rule. More often than not, those exceptions are "legacy" but they matter. In fact, sometimes it's more harmful than anything to try and impose those practices just because.
One external function per source file is reasonable for static libraries, since the linker will generally only include those object files that are actually used. This is less relevant with modern linkers that can remove dead code, but is still practiced by some libc implementations. Not to say you *should* use static libraries, or structure your code to make it work better for shared libraries at the expense of maintainability.
[Image](http://imgs.xkcd.com/comics/compiling.png) **Title:** Compiling **Title-text:** 'Are you stealing those LCDs?' 'Yeah, but I'm doing it while my code compiles.' [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/303#Explanation) **Stats:** This comic has been referenced 510 times, representing 0.6669% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cu4vcc7)
&gt; Never forget that metaprogramming is nothing more than sophisticated MACROs That’s nonsense. It would make more sense (but have a completely different meaning) to say it the other way round: “[C] macros are nothing more than unsophisticated metaprogramming”. But the implication, that template metaprogramming is bad because macros are bad, is a logical fallacy. Both have strengths and weaknesses and neither should be abused. But their respective weaknesses are pretty unrelated to each other. Generally, while templates have drawbacks by adding complexity, it’s well established that decomposing your functionality into small, *generic*, composable blocks is one of the most productive things you can do in terms of software engineering. This is the central insight that functional programming has gifted us. And people don’t do it *nearly* enough — hence the focus on templates in many blog posts.
Nice catch! That's strange, I'll have to check the assembly myself on the compiler I'm using for the benchmark data
Really cool stuff! I'll definitely check those two out
That still only works if you modulo. Unless you're saying the user is trusted to never try to access an index bigger than 2*size?
No information about the complexity which is used to achieve this?
Globals of non-trivial type are dangerous (especially on Linux), and banned in many style guides.
These were all interviews for junior level positions (&lt;5 years of experience required in the job posting). I'm in the NYC area, so maybe that's part of the problem. I don't want to do finance/banking which doesn't leave many companies to apply to for C++ positions. A lot of the remaining positions are for "cool" or competitive companies like MongoDB, Citrix, MediaMath, etc. Any of the reasonable phone interviews I've had ended up being for companies that pay way under market rate for this area ($50k). Money's not everything but I need to be able to pay rent. I'm sure there's good companies here but it's hard to filter out all the cruft on job boards.
You mentioned below that you need the singleton for writing allocators in C++03. Sadly, 03 allocators cannot be stateful, and therefore I can well believe that this is the only way to do this. However, it is still possible to a) prevent the singleton from being a global, and b) potentially have multiple independent memory pools. I don't know if you already did it this way, but since you didn't mention it in your blog post, I thought it would be useful to mention here; other people may benefit even if you're already aware of this. In essence, you can do something like this (Meyer singleton for simplicity, adjust as appropriate for 03): template &lt;class T, int PoolSize&gt; class Allocator { static MemoryPool&amp; memoryPool() { static MemoryPool mem_pool = MemoryPool(PoolSize); return mem_pool; } public: Allocator(...) { ... } allocate(...) { // can call memoryPool as needed ... } ... } struct AllocatorForLib1 {}; using Allocator_t = Allocator&lt;AllocatorForLib1, 1000000&gt;; You can basically now create separate memory pools. What's more, the memory pool is a private class static of the Allocator, reducing its exposure. T is a dummy, the idea is that when you want to create an allocator in some context, you can create a suitably named empty struct and template on that. This all makes it so that you can e.g. write multiple libraries that each use shared memory pools of different sizes, and then use all these libraries safely from main.
Thanks for the tip, I'll play with this idea.
&gt; The standard requires that writing to cout from different threads not cause races At what granularity, statement or per stream operation? If I have two threads running this code: std::cout &lt;&lt; "x: " &lt;&lt; x &lt;&lt; std::endl; ... for values 1 and 2, can it print, e.g: x: x: 2 1 I'd guess this is fully possible, which implies that while `cout` might not have any internal races, there are still races at the application level the developer will need to be aware of.
That looks similar to what they do in half-life 2 sdk.
In my old job I was stuck on g++ version 3.4 for one project so I can relate. Last summer I started working on a small application from scratch and was given free choice of the standard to use. I have chosen to write it in c++11 to get familiar with the new features and catch up with the rest of the world. Unfortunately, it kinda backfired when I quit and had to hand over the code to my colleague who didn't know anything about c++11 ;) Now I'm using compiler with full c++11 support, however our SDP mandates c++98 compliant code only :(
This is really nice, thanks for using snake_case.
Almost all companies having business based on C++ have equivalent rules. This is not restricted to Google. This document is referenced mainly because it has been made publicly available. If another company would have done the same thing it also would have been cited.
I tried storing the result of `step_ &gt; 0` in the iterator instead of calculating for each call to the equality operators and got indistinguishable performance to a raw loop for `range(1000000000LL)`.
I had a look at the Boost.MultiIndex documentation, but I failed to define a data structure that, for instance, maps std::string to int and preserves the insertion order. To me, it seems that it can be done by defining a struct with std::string and int member first, but I would like to use the operator[] to write code like container["foo"] = 1. Do you know what I mean?
I also replied to the discussion in /r/programming but I am subbed to /r/cpp so this came up again. The standard implementation for this problem is to make a hashmap of linked list nodes: http://docs.oracle.com/javase/6/docs/api/java/util/LinkedHashMap.html This data structure comes up as an application for building LRU caches. You can see the same approach suggested here: http://stackoverflow.com/questions/2504178/lru-cache-design. I skimmed your code and I am convinced it doesn't work. You are trying to override map's compare to use the insert order as the sort order. But then how can you possibly look up any of the keys efficiently (since there's no comparator for them any more). Regardless, even if you do fix that solution (or I misunderstood and it is actually somehow correct) it will still have a O(log(n)) complexity which is subpar compared to the standard O(1) solution. Maybe there is some other reason why people are still using std::map compared to the faster std::unordered_map but that seems like a separate discussion for /r/cpp.
I can't find the link with an example. But the basic idea: you write a static global of non trivial type, call it A. There's some object code that initializes it. You build that into a static library. You then build a shared library that uses the static library; it has its own full copy of this code. You build an executable that uses both libraries. It gets its own copy of the code from the static library. At runtime it links in the shared library. So, the supposed single instance global is initialized twice, two copies. Now, objects initialized before main have to register to be destroyed after main. A common issue at this point is that the same copy of the object registers twice. So one object is double destroyed, and one isn't destroyed at all. 
 &gt;You can use a later version of gcc, so long as you keep building for the same target. Of course. We can use the latest version of gcc. But, as I said, there is always risk in any change, and it has to be planned for the proper place in the release cycle and balanced against other work to be done.
It's sad that people are losing their jobs, but I already knew how to handle dependencies and build systems. I had no interest in biicode.
You're hearing what you want to hear. I'm going to +1 the OP of this thread. What would I pay for? Hosting, compiling, testing and packaging. Dependencies are managed once in a while. You guys optimized the wrong part of the C++ dev loop.
http://i.imgur.com/BSiC2bi.png code here: https://gist.github.com/anonymous/01be52808862fb9a9f5a Running just the boost part: 9.87user 0.33system 0:10.23elapsed 99%CPU (0avgtext+0avgdata 1225584maxresident)k Running just the fifo_map part: 45.08user 0.41system 0:45.84elapsed 99%CPU (0avgtext+0avgdata 1784936maxresident)k I'm using libstdc++ with sso strings so the memory usage diffs would be even more dramatic if the strings were longer.
&gt; Dependencies are managed once in a while. You guys optimized the wrong part of the C++ dev loop. Maybe you are right :) But consider this: There are two patterns that infect C and C++, and only C and C++: a) Relying on 3rd party means to have a local copy/git submodule of those. This is even more true in header only monsters like Boost. b) because of the above, having 3rd party is a pain and, this is what most surprises me, zero dependencies is considered a sign of quality, usually used as argument on library advertising. This also means in many scenarios reinventing the wheel is easier than reusing other's wheel. If reusing others work is that hard, I'm sorry but we really have a big problem here. 
I agree with you. Most of C++ guys know how to handle dependencies, and they are not bothered by managing dependencies. I think it's one of the problems of C++. Although it's inconvenient and complex, there is no standard dependency manager to improve it. There were some tries, but none of them are quite dominating. I believe that lack of really nice dependency managers prevents many people from using C++. Why would they complain, "The standard library of C++ is so small!" when there is Boost? And why would they say, "There is no easy way to build a cross-platform GUI in C++!" while there are GTK+ and somethings? Even I want to use third-party libraries in an easier, simpler, and consistent way too. There are several blockers. I guess compile/link options are big, they affect the language but are not standardized ones. Modules support is also a big thing, so I was sad to hear that Modules might not be a part of C++17. Well, in short, I want a standard dependency manager too. 
You're welcome!
We don't disagree but the problem already has a well defined sub optional solution that isn't too terrible. Yes, the lack of a c++ packager makes it difficult to try out new libraries as easily as python or java but that's an artifact of the language implementation.
They are not *entirely* safe, which is demonstrated by the following example, which ends in a segmentation fault: //-------------- // stest1.cpp #include "stest1.hpp" MyClass1 &amp; MyClass1::instance() { static MyClass1 instance_; return instance_; } //-------------- // stest1.hpp #pragma once #include &lt;memory&gt; class MyClass1 { public: static MyClass1 &amp; instance(); void set_x(int v) { *x = v; } private: std::unique_ptr&lt;int&gt; x{ new int(0) }; }; //-------------- // stest2.cpp #include "stest2.hpp" MyClass2::~MyClass2() { MyClass1::instance().set_x(-1); // &lt;-- SIGSEGV } MyClass2 &amp; MyClass2::instance() { static MyClass2 instance_; return instance_; } //-------------- // stest2.hpp #pragma once #include "stest1.hpp" class MyClass2 { public: static MyClass2 &amp; instance(); void set_x(int v) { MyClass1::instance().set_x(v); } ~MyClass2(); }; //-------------- // stest.cpp #include "stest1.hpp" #include "stest2.hpp" int main() { MyClass2::instance().set_x(30); return 0; } 
At home, I build all libraries [from scratch](http://nuwen.net/mingw.html). I don't take a dependency on anything I can't build myself. And my build system is a handwritten makefile, which provides a tripartite, perfectly incremental, completely parallelized build. (Tripartite means: immutable source directory, throwaway build/intermediate directory, separate destination directory. It is a crime for a build system to mix intermediate files with either the source or destination directories.)
"It was just like some ancient electricity-powered computer; it didn't matter how fast, error-free, and tireless it was, it didn't matter how great a labor-saving boon it was, it didn't matter what it could do or how many different ways it could amaze; if you pulled its plug out, or just hit the off button, all it became was a lump of matter; all its programs became just settings, dead instructions, and all its computations vanished as quickly as they'd moved. It was, also, like the dependency of the human-basic brain on the human-basic body; no matter how intelligent, perceptive and gifted you were, no matter how entirely you lived for the ascetic rewards of the intellect and eschewed the material world and the ignobility of the flesh, if your heart just gave out... That was the Dependency Principle; that you could never forget where your off switches were located, even if it was somewhere tiresome." - Iain M. Banks, [Excession](https://en.wikiquote.org/wiki/Iain_Banks)
&gt; What would I pay for? Hosting, compiling, testing and packaging. Well, that's pretty much exactly what most Linux distros do.
Yet Microsoft does see a value in it, otherwise NuGET wouldn't support C++ packages. 
&gt; that's an artifact of the language implementation. I agree.
I totally +1 this, at work we don't use boost but rather adapting certain parts from it because it seems cumbersome to tell every developer to download and compile boost. When I'm writing something involving Qt, I'm very happy that it has tons of stuff in it, but if it doesn't have something (like Base32 encoding :) ), I'm screwed. So after all it looks like the best form of dependencies for C++ are header only libraries which can be managed with VCS for the most part.
Yeah I was kind of surprised they don't use all the cool features.
If dependency managing becomes the norm, developers themselves register every new version immediately. Also, uploading a package is typically a simple one-line command so they don't need to take care of much. Also, almost every dependency manager in mainstream languages has an ability to use Git as a source. You can easily override the package source by editing a file. This is still much easier than manually building from source by yourself. So this is more likely a problem of C++, where there is no central authority for dependency management. Hence the problem of biicode, as they're clearly not authoritative. However, actually I cannot help but think that even if the C++ committee provides a standardized way for packaging, many C++ programmers wouldn't care. "I can handle dependencies just fine" seems to be a typical reaction from many C++ programmers.
That's a bit hostile. He didn't imply that anyone else should do what he does. He just said that biicode was not his piece of cake and explained what he does instead. 
I said that I had no interest in biicode. I wasn't speaking for anyone else. I also explained what I do at home, which people are free to imitate, or not. If there's a problem that should be solved, it's that library build systems are terrible. The problem should be addressed there, not in higher-level packaging. There are many build systems, most of which I haven't used, although I do know two things: (1) autoconf is an abomination, and (2) make is unjustly accused of many problems. (In that respect, it is similar to C++.)
While I agree that I'd never use something like that, he doesn't suggest anyone should do it, simply that it is his way. I suppose he could have simply not responded to the question, but it is fairly reasonable to speak about how one does it in response to a request for advice.
Using C++14 language features to facilitate invoking a function deprecated in C++11? Why..?
It's so that the functions in the file are in a "logical" order, i.e. kind of in the order in which they will be executed. This is done to avoid having people move up and down the file to understand what the code is doing. Of course, it is only a small detail and the actual difference it makes is small, but there is a difference.
Check out my [program](https://github.com/Dekken/maiken)
NuGET barely supports C++ packages. It feels like quite a hack. It doesn't support building from project files which means a lot of the nuget automation doesn't exist. It doesn't support C++/CLI (But then again, what does?). It feels like a half-baked solution, or at least compared to the .net side it does and I understand that C++ is far more complex, but I've not seen much from NuGet on the C++ front for a while now.
Actually I did try to use it recently only to stumple in its Powershell security requirements. Which doesn't happen with normal .NET packages. Nowadays I barely use C++, just wanted to point out that NuGET kind of supports it, given STL's employer and his comment. :) So I cannot really attest how well NuGET does work with C++ libraries.
&gt; I can handle dependencies just fine So developers for every other programming language that has dependency managers are lazy? idiots? Are we so elitists? 
I ... I ... Never knew ... I ... Where were you all this time ?!?!
Large code base?
I predicted this the moment it launched. Never trust critical development tools which are developed by new businesses as 90% of them fail in the first year. I'd be much more interested in a dependency manager developed on a not-for-profit basis by the community and supported financially by a big company like Apple.
&gt; This is even more true in header only monsters like Boost Boost is not header only, WTF!? &gt;zero dependencies is considered a sign of quality, usually used as argument on library advertising Not in my book (that is, there's at least one person in the whole world who disagrees ;-))
90% Boost libs are header only
There are others out there (e.g. https://github.com/armmbed/yotta), though this was perhaps the most developed. IMHO biicode tried to do too much for you – developing and re-using complex C++ modules is not simple, and you can't hide the complexity from the user. I think instead you have to rely on the users following a set of rules to make their software re-usable, which is a much longer game. 
&gt; but I already knew how to handle dependencies and build systems the point is we shouldn't have to do such a menial task ourselves
Could be. Still, if you take all, it's 5-6 megs of binaries for NDEBUG build.
&gt; It is a crime for a build system to mix intermediate files with either the source or destination directories I wish I could get this through the skulls of some of my coworkers and customers.
I think there are a lot of good points in this thread, but I'm going to make one that I haven't seen yet: Where do you draw the line between what is a dependency managed by biicode and what isn't? For most of my projects, I need some c++ libraries, some fortran libraries, Doxygen and LaTeX for the developer and user documentations, and a c++14 version of a c++ compiler/standard library. What should be provided by my c++ dependency manager and what do I have to provide myself? And if *any* of them have to be provided by myself, why should I use a dependency manager that only provides some of these? This is why I've been a bigger proponent for tools like vagrant rather than tools like biicode
That's a static initialization fiasco, not much to do with singletons, kinda unfair there...
Yes, dll or so files. Debug build is bigger.
&gt;I've met/worked with plenty of developers with a decade or more Windows dev experience that still don't know the details of the CRT, or why/how one would pick one method over the other. No escaping that :-(.
&gt; Single or multi-threaded VC has had only multithreaded configurations for over a decade.
That's very interesting. We've been trying hard to eliminate unnecessary rebuilds, but they keep creeping back in. I've never run across this information, though it could certainly contribute to the problem. Are there any _actual_ consequences I could expect from disabling tunneling? Edit: Actually I can't find either of the mentioned registry keys (Win7 x64). Is that because they just have hard-coded default values? Edit2: Some other articles mention having to create the registry value, so I guess it's not supposed to exist if you've never messed with it.
&gt; piece of cake I think in this case the idiom you want is ["cup of tea"][1]. (Compare with ["Piece of cake"][2].) [1]: http://idioms.thefreedictionary.com/cup+of+tea [2]: http://idioms.thefreedictionary.com/piece+of+cake 
&gt; If dependency managing becomes the norm, developers themselves register every new version immediately. For linux distributions, dependency management has been the norm for quite a while. Still, only few developers provide *.deb packages or ebuilds. Of course it's only natural that every maker of a packaging system believes that his one will take over the world, unlike the hundreds before him.
What compiler and options did you use?
Markdown for manuscripts really does look nice, thanks!
The most common issue I run into causing projects to always needing to be rebuilt/linked are header files in the project file that are missing or incorrectly named. This is an easy mistake for us to make because we generate our project files rather than edit them. Using show files on the offending project quickly shows the offending entry. 
&gt; If there's a problem that should be solved, [...] You're sort of contradicting yourself by implication. The above implies that biicode is not solving a problem that should be solved for anyone. I haven't tried biicode or even been particularly motivated to try it out, so I suppose I sort of implicitly agree with you, however intellectually there are some things it seems would be good for C++ development. Currently, when setting up to build some project that has dependencies, C++ 'dependency management' means manually looking up the project's dependencies, manually downloading them and setting up the project to build against them. And of course this means that if you want to build the dependencies from source you have to do the same manual 'dependency management' recursively. This should all be automatic. There should be one line in the project's build description that declares a third party dependency. The build system should automatically download the right things, including transitive dependencies, and then build against them.
Which features aren't covered in the guide you linked? I see a lot of c++11 stuff.
That's my experience too.
If you don't try to exchange resources handled by VCxx with some code using VCyy with xx!=yy, it's quite transparent to integrate the two pieces of code. (And by that I even mean that what is returned by malloc() and operator new() must even be freed by the version that allocated, and not any other one !) Of course you have to know it, and it is quite disturbing when you come from a Unix system with libc and c++ std lib that are both mostly unique on your system AND retro compatible everywhere it's technically possible (which is the case for libstdc++ btw) It's also disturbing in the other way: companies used to windows manage to fuck all that up and sometimes distribute and use a copy of the glibc.so they used at link time for their product. Matworks does that for Matlab and it's utterly stupid: it prevents from using the compiler you want to create MEXs on a modern system but for an old Matlab (and given they don't update at the same rate as your system, sometimes you have no officially compatible compiler on some distro...). The workaround is to overwrite their copy with the real libc (or maybe a symlink so that you don't break libc updates, or maybe LD_PRELOAD the libc all the time when you launch matlab). 
C++ may be unjustly accused of many problems from the POV of those who are expert or at least invested enough in it, and especially for those invested mostly in it in their occupation... Judging from my coworkers who have other things to do than learning the new ways to do things and obtaining authorizations for buying all the tooling needed to use that in new versions of the programs that are actually useful to them, C++ is also justly accused of many problems. C++ from MS even more. You don't judge a language in a vacuum. Ok the new ways are way better than the old ones, but they also are not fully supported on VS2010, that is the most recent MS compiler that both can be get from MS for free (in SDK 7.1) in all commercial context, and is widely supported by third parties vendors. (I don't mean that I would have wanted C++11 in 2010, but it is also only marginally more supported in VS2012, so...) The actually minimal usable version of C++, C++11, is only completely supported since VS2015 (except for a minor detail IIRC), which is something like a month old. In a few more years I guess all programs will at least be compatible with it, and in a few more other years people will actually use the new version of said programs, and in 2020 we will eventually be able to program in C++11... Ok that was a digression. Back to the point I like you have no interest in biicode, and I even can't think of somebody I know who would be particularly interested. And regardless of the context, the more things you use that you can build yourself, the better (just how can you fix the bugs if you can't rebuild most of the things you use?) 
There's a reason that a missing file will trigger a rebuild. This is to handle the situation where you have a build input that is automatically generated during the build.
Please don't think that this class is just like a few talks you can see at the conference. I think this is an actual workshop, and if you have the need to improve or update your knowledge in this area, the class is surely interesting for you. I'll be around in Bellevue already, but will skip the class, as its not too advanced (and I'll still be jet lagged, which is the main reason I don't consider taking it...)
Wow, then I agree; the life of a developer who needs to do that sucks ! :P (and I though automating builds with a few .bat was tedious...)
Well, static initialisation is the method used in this singleton implementation which is unsafe. There are techniques that can make at least this use case safe: [Nifty Counter](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Nifty_Counter). It can be made thread-safe and actually faster than function-scope statics.
You're saying it is logical for you. I consider it illogical because you have to declare your functions twice which is ridiculous and error prone. Editors search backwards as well as they do forwards so there is no advantage at all to put up with the double declarations. I have been writing C/C++ code for 30 years and always put my main function last in the file.
`&lt;cstdint&gt;`
Basically this, but since I'm Dutch, some things are a little bit different: const-ex-pee-are way-charr-tee ess-fee-nai
 template &lt;typename Fn, typename... Args&gt; auto do_async_with_log(ostream&amp; os, Fn&amp;&amp; fn, Args&amp;&amp;... args) -&gt; future&lt;decltype(fn(args...))&gt; { os &lt;&lt; "[TID=" &lt;&lt; this_thread::get_id() &lt;&lt; "] Starting to invoke function..." &lt;&lt; endl; auto bound = bind(fn, forward&lt;Args&amp;&amp;...&gt;(args...)); return async([b=move(bound),&amp;os]() mutable { auto result = b(); os &lt;&lt; "[TID=" &lt;&lt; this_thread::get_id() &lt;&lt; "] ...invocation done, returning " &lt;&lt; result &lt;&lt; endl; return result; }); } Let us analyze a few things here: - Forwarding references, which are not the same as rvalue references in a non-generic context. - Decltype for the return of the future. Helpful, but advanced feature. - Lambda with mutable. Lambdas are implicitely const, unlike the normal language rules. I do not mean they should not. I am talking about the cognitive overhead. - bind combined with forward and variadic pack expansion. I am not talking about the genericity of this code. It is great. What I am talking about is the *cognitive overhead*. All of you who are not quite familiar with C++, I am sure you are either not going to understand it completely or make wrong assumptions about it (such as the forwarding reference). And this is a word from a c++ language enthusiast and adopter. An average example of modern c++ should go more in the lines of what Herb Sutter shows, not this advanced piece of code, which, is very nice that we can do, but it is not for everyone.
Nifty counter doesn't help, the crash is during destruction. :-)
STL waxes philosophical about C++ package management by quoting Banks. Truly, this is nerdvana.
I was hoping for something like [this](https://www.quora.com/Whats-the-hardest-bug-youve-debugged).
Missed the most obvious cause: projects set to "build always." Yes, really. I deal with them everyday. Someday I'll get around to stepping on the boss's toes to fuck with his build system and get it right.
CMake (Kitware) could have a website where one could see which projects could be used by [External Project](http://www.cmake.org/cmake/help/v3.3/module/ExternalProject.html) CMake already shipps lots of [Find Package](http://www.cmake.org/cmake/help/v3.3/command/find_package.html) *.cmake files. Having only CMake doing this would be great. BiiCode needed setup, needed Python, needed hacking existing CMake files. I tried to reuse OpenSSL biicode cmake files, I gave up and used OpenSSL perl build system instead.
Out of curiosity, why are fold expressions part of this TS in particular? edit: `requires requires (T x) { x + x; }` looks a bit silly, but I imagine simplifying it would require adding an exception to the rules and potential ambiguities?
Anyone else building GCC right now to play with this?
You could have a script to run at the start of building a project that generates a header / source file. It would be useful to give a warning if the script doesn't have its output files configured, but it is not mandatory to do so. It would be really useful if there was a warning that an expected file is missing and is not configured as an output of one of the build steps. Or something to make finding this sort of problem a lot easier.
These posts get a little repetitive ...
Too much advertising of PVS, don't you think?
The article doesn't mention "static analysis" or "PVS". I think they have reached their goal – somebody mentions 64-bit and Issues and we already think of static analysis and PVS :)
Yeah, and googletest is just sending my bugs to NSA, so cant trust them either.
`requires requires` isn't really a *feature*. It's just the way the language composes (like `noexcept(noexcept(e))`). But I allowed it to persist specifically to penalize programmers who think that template constraints are just small syntactic fragments of an algorithm. If it's worth writing, it's worth having a name.
No need! Wandbox has GCC head! http://melpon.org/wandbox
The update is not quite correct. Depending on what you do, OpenSSL may touch the error queue internally, and then you have the scalability issue. (But as the article says, it's not difficult to patch OpenSSL to avoid it, especially if you do not care about 100% compatibility.)
On a popular mobile device, 30% of the screen is used for this post's content, and 70% for banners, headers, and footers. 
&gt;Rather than integrating the tool into the team's daily workflow, they contort it to do their whole-file whole-team sit-down reviews ... &gt; they could have integrated Stash with a converted version of their full repository history, and used Stash for reviewing the diffs for each changeset incrementally Um, no. We needed to get to a baseline where the entire codebase was fully reviewed. Prior to that point, we had hundreds of changesets, so it was quicker to review where we are, than to review each of the steps (and some of them are horribly contorted) we made to get where we are. We did convert our full repo history from SVN to Git. (subgit made this easy, yay!) If I could reliably switch to git tomorrow, I would. And by reliable, I don't mean the tools themselves, I mean the disruption caused by the tool switch is not something we can tolerate in our schedule until some months into the future. Now that we *have* a fully reviewed codebase, we *can* (and are) reviewing incremental changes. Not on a daily basis, unfortunately ... We still have scheduling issues; the two-hour window in which our international team lines up is not available each day. So unfortunately we have frequent stretches where the development of changes occurs faster than our QA ability, and it feels a little bit like herding cats. Asynchronous reviews only work when the team is aligned in philosophy and has no communication issues, so we do need the synchronousness. We're working on it.
Given that N4377 also expands the C++14 `auto` parameters to regular functions that seems like a mostly unnecessary shorthand: auto add(auto t, auto u) { return t + u; }
Concepts are like abstract data types. They are not bound to specific types. The correspond to sets of types. The *rationale* (rather than "excuse") for that behavior is to optimize for the common and simple case. Simple generic algorithms don't involve lots of different template parameters because that tends to require more constraints. Here's the constrained template version that I think you want to write: template&lt;Container T1, Container T2&gt; bool set_equal(T1 const&amp; a, T2 const&amp; b); Presumably, somewhere in this algorithm you compare elements from `a` and `b` using `operator==`. But the constraints don't cover that usage. From the declaration above, `T1` and `T2` are totally unrelated. Here's the fully constrained version: template&lt;Container T1, Container T2&gt; requires Equality_comparable&lt;Value_type&lt;T1&gt;, Value_type&lt;T2&gt;&gt;() bool set_equal(T1 const&amp; a, T2 const&amp; b); If you want this level of generality in your algorithms, then this is what you write for constraints. If you don't need this level of generality, if you prefer the simpler version, then you can write: bool set_equal(Container&amp; a, Container&amp; b); Assuming the value type of the container type is `Regular`. There is a tendency to assume, because we introduced shorthand notation for certain use cases, that notation should be used for everything. You need to use common sense here. If the notation doesn't allow the generality you need for your templates, don't use it. Write a template. 
While that's true, my example does no (useful) constraining and is equivalent to this one. I'm just hoping I don't end up seeing my version anywhere. I'd be okay with the new curly brace syntax being used for something useful, like you describe, but in my example, all it does is kind of make a halfway point between the traditional template syntax and the `auto` as parameters syntax.
True, it makes sense that you had to do a full review at some point to "catch up". I guess I didn't think about the fact that this was an initial attempt at implementing code reviews. It does make sense to go back and verify the entire codebase. Also, disruption caused by tool switches is definitely real. Just trying to get a large team to adopt a tool uniformly can be a pretty big challenge.
Looks promising. I wonder how prelude compares with FTL https://github.com/beark/ftl Interested in the transducer stuff too. Needs more documentation/tutorials...
Yeh, that seems really strange but well I have taken the time reading through the draft and yah the syntax is reasonable but there is one thing I don't quite understand. The draft says "The declaration shall have a function-body equivalent to { return E; } where E is a constraint-expression" but why so ? I mean I can basically add variables, requires expression or if-statements in the body by replacing concept with constexpr which is basically the same thing right ? http://pastebin.com/TEVCy2B7
You won't be able to use that `Addable` function using the `template-introduction` syntax (`Addable{T, U}` won't work). You also won't be able to use the shorthand `template&lt;Addable&lt;int&gt; T&gt;` either.
There is no standard, but I prefer something similar for libraries: root-namespace or project name/ src/ namespace/ internal-class.cpp internal-class.h external-class.cpp include/ project-level headers (i.e. project.h) namespace/ external-class.h For executables, I do away with the include folder. All headers are source code, so unless there is a good reason to separate the headers, then throw them all into the same folder with their .cpp file counterparts. (Separating by namespace makes sense of course.)
The problem with io-service-per-core is that you have to assign each connection to a specific io-service, which means that not all io-services will be equally busy (as you could end up having one io-service just handling idle connections whereas another io-service has to handle the high-throughput connections). But the benchmark just tests an ideal scenario.
Clickbait This article is all about PVS-Studio, Doxygen is barely mentioned.
Option 1 and 2 are equivalent. Option 3 means you can essentially add more stuff to the MyEnum namespace. If it were me, I would go with option 2, as you can't dump crap into the MyEnum namespace and it is less boiler plate than option 1.
A nice idea, would be also nice to have an RSS feed :)
Here's a simple macro I've used in the past to emulate enum classes: #define STRONG_ENUM(Name, ...) \ class Name { \ public: \ enum Name##_ { \ __VA_ARGS__ \ }; \ public: \ Name(Name::Name##_ v) : mValue(v) {} \ operator Name::Name##_() const { return mValue; } \ Name&amp; operator=(Name::Name##_ v) { \ mValue = v; \ return *this; \ } \ private: \ Name::Name##_ mValue; \ } Usage is pretty much exactly the same as with regular enum classes: STRONG_ENUM(Color, Red, Green, Blue ); &gt; const char* tostring(Color c) { switch(c) { case Color::Red: return "red"; case Color::Green: return "green"; case Color::Blue: return "blue"; } } &gt; Color c = Color::Red; std::cout &lt;&lt; tostring(c) &lt;&lt; std::endl;
Seriously? Dear PVS-Studio guys, stop the spam already!
Cool macro :-D. I'm not the biggest fan of an macros (in c++) but this one is really cool. This macro works very well, the only problem if encountered was if you need an constructor with no arguments. I use Qt and the QVector template need an constructor with no arguments. I've added an empty constructor with 0 as default, which is not the best solution if 0 is not defined in the enum, but i have not better idea (i could add a default-value in the macro, so that the developer has to choose one but i don't like the idea). Do you have any ideas with the empty constructor problem? Does this marco works on all platforms or does it only work in Windows/Visual Studio?
Personally, I wouldn't call that sufficient doc. Better than nothing, but I'd have to look at the source to begin to understand it.
Thanks for saving me clicking through, I made a similar comment a moment ago on another of their posts.
Guys, you found each other, cool! You can create a new subredit r/PVS-StudioHaters 
I'm so relieved I'm not the only one. 
I don't know if I hate PVS-Studio. I've seen far too many of these to give it serious consideration. It would help, for a start, if they clearly put in the post title that it was related.
This. The typical solution is a single io_service with a thread pool calling run. Non-thread-safe state machines can have all their callbacks wrapped via a strand to ensure only a single thread is processing an event at a time. 
I still don't get lego.
Does anyone know when they will release the source code for CLion? I can't find any sources.
I tried to create one using [mailinator](https://mailinator.com/inbox.jsp?to=cpphintsbypvsstudio), but PVS-Studio site complained: &gt; This email address looks fake or invalid. Please enter a real email address =(
Me neither. My question is, when will it be? Jetbrains' IDEA and Pycharm are open source, so I was assuming CLion will be eventually, too.
I've always used Option 3, but /u/enzlbtyn does make a good argument for 2.
still no make support? *sigh*
So IIUC the zero copy is basically just performing a bitwise copy twice in the tests (for serialization/de-serialization)? I guess that is the ideal performance case against which to measure the other approaches (without taking data compression into account). 
Well they don't even have community edition for now, that should come first I believe.
Some of their stuff is open-source.
most of it is not. and a lot of the stuff that is open is designed to be support items for their closed source product. (ie, pluggins for their IDEs)
Then what is this? https://github.com/JetBrains/intellij-community If I am not mistaken, this repo contains the complete sources for the community editions of both IntelliJ IDEA and Pycharm.
I am mistaken. I guess just most of them are closed source.
Default-initializing an enum class object (i.e., `MyEnumClass obj;`) will give it an indeterminate value. Value-initializing it (e.g., `MyEnumClass obj{};`) would give it a numeric value of 0.
I want to subscribe via RSS.
The function that you pass to std::accumulate they call a reducing function. The function that takes a reducing function and returns another reducing function they call a transducer. That's what I see from the C++ point of view.
I am not sure how that relates. The current concepts lite cannot solve this either, and I am not suggesting that it should try to. The point of having turing completeness is to allow a way to programmatically generate a concept predicate. Perhaps a better way to achieve this would be to allow concept predicates to be defined at class scope, and make them first-class citizens so they can be passed to template parameters(the simplest way would be to make `concept bool` be a template alias to an internal compiler type that is implicitly convertible to bool).
Isn't phpstorm basically a plugin for intellij though?
Have you actually tried both, set them both up carefully on the same codebase, and seen which one offers better auto complete? Better code navigation features?
Agreed. This is getting ridiculous. Stop posting worthless articles about 64 bit errors. No one cares. Everyone moved to 64 bit like 10 years ago. If your static analyzer is not selling, maybe the solution is not to spam reddit, but to make a product that solves problems that people have today not ones that everyone already fixed.
[First article](http://cpphints.com/hints/5): &gt; I'd recommend rewriting this function in the following way: static int rr_cmp(uchar *a,uchar *b) { for (size_t i = 0; i != 6; ++i) { if (a[i] != b[i]) return a[i] - b[i]; } return a[7] - b[7]; } But... that way you don't check if (a[6] != b[6]) return (int) a[6] - (int) b[6]; &gt; This solution has two advantages: &gt; * The function is easier to read and comprehend. &gt; * **You are much less likely to make a mistake when writing it.** 
Yes I have tried both, though I have to admit, that I used CLion only for about 30 Minutes or so.
The article itself is in need of serious proofreading, and I found it fairly inane anyway: clickbait, indeed.
I'm a huge fan of CLion. Works great for me. Keep up the good work, JetBrains! p.s. please release a Julia editor :)
I don't know why you are being downvoted. There are a lot of important projects that require make and / or autotools support. To only name a few: Linux Kernel, Git and Gnome Focusing only on CMake leaves all the people working on those projects behind. A rather simple build dialog (like in Netbeans for example) would completely suffice for me.
Through some googling I found out that for Intellij IDEA community edition and opensourcing happened simultaneously. For PyCharm source code was published around a month later, so I guess I was wrong and for jetBrains community edition = open source. However that makes me wonder how hard it is to get CLion license for open source development.
Sure, but the single io_service with a thread pool (called "naive" in the article) is the approach that doesn't scale that well because of lock contention inside asio.
I like the Go model a lot. It seems simple and very flexible to me. I haven't yet run up against the downside. It makes my wonder why more languages don't have the same model.
You can currently define concept predicates at class scope? I thought they could only be defined at global and namespace scope.
Note this proposal is heavily based on the more detailed proposal here: https://github.com/ja11sop/std-filesystem-relative 
It is OK. I still have no idea why anybody would use anything but vim. ;) IMO IDEs like this are designed to pull people away from GPL'd projects.
Is that the only difference? Why is that you can't get ordering over foo&lt;T&gt;::predicate&lt;U&gt;, but you can over foo&lt;int&gt;::predicate&lt;T&gt;? With the exception of the fact that you've defined a concept at class scope, I'm curious to know why you think this is different than what concepts lite already does. There's an ambiguity resolving concepts at class scope. There's an issue filed against it. Simply wishing that it worked doesn't resolve the issue.
Sure... If you write useless examples, then you get what you get. Useless advice :) That said, I'm sure we'll see lots of both in the coming years. 
emacs, nuff said.
i dont understand how this works: so say u have a concept named Number and a class named Number, how does this work: auto f = [](Number&amp; s){return s+s;}; so what is s? a template arguement that requires a number or an element of type number?
Thank you, you are right, we have changed i != 6 to i &lt; 7
I just love the way Bjarne says "o'erload"
I would be satisfied with qtcreator-like
I am a little bit confused. Will we finally be able to iterate through a directory's file list using C++17, copy files and other typical operations?
Yes, filesystem will(should) be in C++17... This is more a proposal to add a relative function to filesystem, it is not the proposal for filesystem. 
All these examples are using Unix-style paths. What about other formats (Wikipedia has a [decent list](https://en.wikipedia.org/wiki/Path_(computing\)))? Remember that C++ isn't just limited to common/mainstream platforms. If the platform has a filesystem (i.e. it's not an embedded system) then the standard filesystem spec shouldn't exclude it.
Clang was only integrated recently. Maybe your impression about kdevelop is not accurate anymore. I agree that 30 minutes is not enough to build qualified opinions though.
Is there a way to disable the AA on the IDE font (not the editor) ? It looks terrible on my screen.
[Includes this](https://github.com/bolero-MURAKAMI/Sprout). (which completely breaks on GCC6, btw) edit: huh. This should be valid... right? // &lt;long...&gt; also breaks; &lt;int...&gt; and &lt;bool...&gt; not. template&lt;short...&gt; struct MyStruct; int main(){} main.cpp:1:15: error: expected ‘&gt;’ before ‘...’ token template&lt;short...&gt;
The only things I want (and I already wrote JetBrains about this) are heuristic resolution of includes, and a dialog box where you can put a custom build command. Those two features are all you need to use an IDE at 90% efficiency with any build system. I don't know why they didn't pick that over trying to make it work with CMake at 100%.
How does COM not use inheritance? If you generate C++ bindings you get a classic ABC
COM model does not support inheritance. You are looking at how COM is implemented in C++. COM is language neutral OO ABI. A COM object implements a set of interfaces. There isn't any inheritance per se. If you want to extend a COM interface, the new one has to reimplemented all the methods or use COM delegation for the methods that aren't reimplemented.
http://goo.gl/ZPKVSm
&gt; Are the zero copy tests just "getting a pointer to the data and a length" into the archive? Yes, the zero-copy test requires for the data to stay alive long enough. In HPX this is not an issue as we handle this in layers above serialization. &gt; I'm a fan of zero-copy for large buffers but since the non-blocking mpi implementations cannot be futurized without adding an extra thread to user code they are a pain to use asynchronously. That's what we implemented in HPX, so that you don't have to go through the pain of it ;-)
this is only for the new windows runtime for windows store apps right? i mean, this doesnt "modernize" the old win32 API for desktop am i correct?
So, he's explaining (finally) why CGAL was designed the way it was? :)
I think [this page](http://www.boost.org/doc/libs/master/libs/test/doc/html/boost_test/testing_tools/boost_test_universal_macro.html) is a bit more helpful as it has examples. Massive pedantry: isn't the argument to the macro strictly an *expression* rather than a *statement*? Looks cool though. Presumably it builds up some clever expression template to get the diagnostic message.
You can always check out ##c++ on freenode, although it's oriented towards serious questions/discussion. If you're looking for banter, it's not the place.
Then ##c++ is the place for you.
I don't want to be rude, but if you expect to get a good job, then you should also be able to think for yourself. * read the right column of this page: _For C++ questions, answers, help and advice see r/cpp_questions or StackOverflow._ * Use the search function - this question has been answered numerous times before. Short answer to your question: Write code, write code, write code. Make a tiny game. Whatever interests you. Once you have that, write _better_ code: Refactor, restructure, learn new things: Use the search function to find numerous compilations of awesome links (going native videos etc...). On a sidenote, IIRC Bucky's videos are not recommended, you'll find the definite answer again in the search function and previously posted recommendations.
Thank you! I am using alien blue app on my phone and couldn't find them on the side. I just checked on my laptop and found them. Thank you once again! 
People still uses D2D?
It definitely doesn't support everything, and that's somewhat deliberate. 90% of the standardization process was beating away the people that wanted to make it generic enough to support every platform with a filesystem or something kinda similar to a filesystem, and in the process make it completely useless and unusable.
2005? I'm surprised. Guess it's just been that they haven't played that nicely all that time then (e.g., Boost.PreProcessor has lots of workarounds for MSVC). Variadic templates have the same problems, though. MSVC chokes on a good number of valid things.
I know that, but, as messages and signaling exist in the listed libraries, there is a way to implement that using just plain C++, through functors and whatnot. So instead of a list of implementations on libraries, it would have been more useful to show how to do it right from scratch, especially with modern C++. If you already use Qt or gtkmm, you know there are signals and how to use them; if you don't use those libraries, probably you don't want them in your project.
In regular usage, they're all pretty much equivalent. Option 3 allows you to import the enum values into a function scope when you need it with "using namespace". Options 1 and 2 only allow you to import everything into a class by making the enum a (private) base class. So, no strong preference, I've used both, probably depending on my mood.
I can't speak to the std proposal, but in boost there's two representations: native &amp; generic. The generic one is what everything is actually stored in which follows ISO/IEC 9945. Platforms that don't have this as native (i.e non-Unix such as Windows) have a conversion to/from native which primarily is intended for use with native APIs (i.e. you should stick with the generic format internally in your app unless interfacing with native APIs expecting a different format). I don't have experience with VMS at all, but I can't imagine why it wouldn't work. For example, on Windows, an absolute path would be represented as c:/Users/... I don't see why VMS paths couldn't map to the generic format 1:1. EDIT: In fact, boost filesystem explicitly has implementation notes on OpenVMS behaviour so it must work there too.
Well, the C that one learns in EE courses is not that helpful (if not detrimental) if you want to program/learn C++. Even the C++ courses mostly teach pointers and not modern C++. &gt; I just can't imagine how you managed to get an undergraduate degree, much less masters, in EE without doing any serious programming. Speaking from personal experience: That's quite possible. Not all students have side projects, only around 30-50% of students do - these are usually the best students. You can totally get by in a EE and CS degree without any programming side projects. (This is not necessarily bad though.) It gets even worse: I know quite a few students (2 per year or so) that passed the programming lectures exams, but couldn't write a hello-world from scratch if given an IDE.
His blog series is about using C++, Qt and Boost. So, I don't see why change the topic.
Thanks for summing up. Yup,it is possible to get an EE degree without serious programming. I had a programming course(C) in my freshman year which was pretty basic. All other courses were EE related and most of them didn't have any projects. However, during my Master's, the courses which I took were mostly related to IC Design, Design for Testability and Verification. These courses didn't need C/C++ programming, although it did involve Hardware Descriptive Languages(HDL) like Verilog and System Verilog. I can say that I am comfortable with HDLs. C/C++ is a different world for me. From what I read and heard, I will have better opportunities if I am good at both HDLs and programming languages like C/C++, as they both merge at a higher level. So, I am just trying to get the best out of both worlds and increase my opportunities. 
Also, the site seems to be not reachable via https...
It took me way too long to come up with some half-way decent solution. Figured maybe I'm not the only one and this might actually help someone :)
This is nice but its a shame that Travis doesn't offer more distribution support. We have our own Jenkins-based CI and thanks to that we've found that specific distribution (Debian, CentOS, and CentOS) versions are shipping compilers with their own unique bugs.
Yes, there's a lot of potential for CI. Different OSes, distributions, versions of those, all combined with sensible combinations of compilers, versions, language versions (C++03, C++11, C++14, ...). Oh my.
You're correct, and I touched on that when I introduced io_service-per-core and thread-per-core, and in the snippet below: &gt; "io_service-per-core will perform better when there are multiple connections per io_service, as it will result in a more balanced CPU load. Since we're considering a server scenario, though, 20 connections is still a very low number." Basically, the assumption here is that we're building a server expecting a number of connections orders of magnitude higher than the number of available cores. If we distribute those connections over io_services in a semi-random fashion, we should end up with a pretty balanced load. Of course, different applications will have different characteristics, and the post is not meant to say "this is the way you should build applications with Asio" but rather "this is what happens in this relatively straight-forward scenario, and here's some things you can consider to fix it".
I think monads are only hard to understand if you are asking concretely what they are used for. Since they are really just something like an abstract interface, what they are "for" depends entirely on the structure of the type you are applying that interface to. When you write the concrete implementation for that interface for a specific type, like a linked list, or option type, there is often only one sensible way to write it, and a new behaviour or computational strategy falls out that depends on the inner structure of the type. Like for a linked list you end up with what is essentially a list comprehension.
File a ticket ;)
&gt;I don't know what this means. Is `Container` a concept or a class? Because what you intend to express and what you actually write vary greatly. My intention is that `Container &lt;C, Value&gt;` designate the concept that `C` is a container with value type `Value`. If I understand how partial-concept-ids work, then template &lt;typename T&gt; bool set_equal (Container &lt;T&gt; a, Container &lt;T&gt; b); should be equivalent to template &lt;typename T, Container &lt;T&gt; C&gt; bool set_equal (C a, C b); and in turn to template &lt;typename T, typename C&gt; requires Container &lt;C, T&gt; bool set_equal (C a, C b); Is that not correct? &gt;FWIW the least constrained case is the one that does not include concepts. Maybe you believe that concepts should not be used at all. You misunderstand me (which is understandable, because I did not include any further constraints in my example). When I refer to the "least constrained case," I mean the least constrained case *which includes necessary constraints*. For example, `find` shouldn't have an `Ordered` constraint, but that's not to say it should be totally unconstrained. Similarly, `set_equal` doesn't need an equality constraint on the container types, but it *does* need an equality constraint on the value types (or, again, a comparability constraint). For what it's worth, I'm very happy with concepts as a whole, and I'm excited to see it come this far. It's that *one* constraint from 8.3.5/21 I disagree with.
&gt; That's what we implemented in HPX, so that you don't have to go through the pain of it ;-) I know, and thanks! :) I still find kind of cool that MPI implementations can do asynchronous computations without threads because they offload them to the interconnect which has its own CPU which can access the host CPU "freely". Its not composable for user code, but it is zero cost, and HPX can build composable abstractions over it with very low cost. Niall Douglas has some work on constexpr futures that can maybe be used by HPX to provide even more lower-cost abstractions over MPI but because of the MPI API there is always going to be a cost when trying to futurize it :/ That's not HPX fault tho, it's MPI's.
Hello, I'd like to help but the code you've posted is nearly unreadable to me, due to formatting... Could you please use pastebin or something like that to post your code? 
Looks like there's a formatted version [here](http://stackoverflow.com/questions/32129821/i-am-trying-to-implement-a-ramping-fucntion-to-imcrement-values-and-it-wont-wo).
Weird, it's like the same process on there (paste code, hit the code button).
Oh... duh. I overlooked the concept declaration in your original post. You're right. Sorry. But but there's a problem with those declarations, because you can't deduce `T`. The entire partial-concept-id acts as the placeholder, which is a bit more obvious in the fully expanded version. There is an ideal that, if you write constraints for an algorithm, they should fully cover the syntax used by the example. If the arguments `a` and `b` have different types, how do you know their element types are comparable? 
Summary: Initializer list take precedence over anything else when using list initialization. As a bonus you can break code that uses list initialization, or even better, redefine it by adding an initialization list constructor. ]:) 
This article gave me a hard on. 
No, actually talking about D2D. I thought it died.
A bunch was added to it for Windows 10, so it's still kicking: https://msdn.microsoft.com/en-us/library/windows/desktop/hh802478(v=vs.85).aspx
Good work! It's nice to see a beginner's post where someone's playing around with a program and discovering what they can do.
I absolutely agree, signal/slot patten is mostly useful for GUI and in most of the cases both sender and receiver live in main thread. Thus fast, non-thread-safe version is immensely useful.
I don't know why `std::initializer_list` ever made it into the language; all it really does is make code examples easier to read. I don't initialise a `std::vector` with a fixed number of known elements very often. Brace initialisation could've been a good feature to finally remove initialisation special cases, and then they added a new special case.
I am on Clion 1.1 (which was released some days ago, I guess ?, and before I used EAP) and I still have code analysis issues but well I think it's been working on improving sematic analysis. I totally forgot about QtCreator, it actually has a libclang backend which had some serious progress last time I checked git master. But it's also very limited in features compared to Clion also sematic syntax highlighting could be improved also some autocompletion issues could be fixed otherwise it's very useable :) imo :D EDIT: It seems QtCreator 3.5 has been released and the blog article is very promising regards code analysis :)
I had to explain Monads to a couple of OO programmers once. They all got it pretty fast. I started with the statement: &gt; A Monad is a **design pattern** for writing composable type `wrapper&lt;T&gt;`s. Then I just show them 2 wrappers: `std::option&lt;T&gt;` and `std::future&lt;T&gt;`. I made them bear with me during this first contact. I show them the monad operations but never use names like `bind` or `return` (I use the names that each type uses, like `future.then(...)` or `optional.value_or(...)`). I wait till they see the pattern, but at this point they do not find it special. Afterwards I ask them: suppose you had a huge library that works on `T`, but need to use it on `T*` (or `std::unique_ptr&lt;T&gt;`), what would you do? Yes they could always dereference the pointer, but then they need to check if it's null. That's a pain and error prone. They could write a wrapper around the library that does that for you, but then that is a pain to maintain. The best is to write a function that checks if the pointer is null, and if not de-references it and calls a given library function: `map(T*, Functor)`. They just came up with a Monad rule on their own. I ask them, how could you use that same library on `optional&lt;T&gt;` or `future&lt;T&gt;`? They write `map` for those. They slowly start to _get it_ now. Finally, I ask them: "what about`vector&lt;T&gt;`? or `list&lt;T&gt;`? or can you come up with any other type that is like this?" They can write map using `std::transform` for all containers and boom! they can `map` over anything now, excitement. After a couple of days they just start complaining that in C++ there is no "Monad concept", so they cannot write code that is generic over all Monads. "How cool would it be if all the "functions" in the Monad interface would be called the same for all types?". Pretty cool indeed. At this point if you explain them how Monads work in Haskell and do-notation they already know of specific Monad instances and they have already needed do notation in the past so they don't really get confused with the terminology anymore. The type-classiopedia is the last step: Monad is just one of many design patterns.
when you get to window programming, make sure you read "programming windows 5th edition : Charles Petzold"
You can also use a debugger to see your program's execution step by step.
an overlay, say a custom crosshair for an fps game, or a gui for changing values in a program that you didnt make
Looks great. What about something like the debug step filter from VAX? That's probably the only thing holding me back from switching to Re++ :-)
Naively speaking, it's hard to imagine of examples where the same algorithm needs to be applied generically to different monad types. What are some operations on futures that one would also do to a vector or option beyond the laws themselves? Can you give some examples of some useful generic operations over monads? 
We have an issue request for step filter https://youtrack.jetbrains.com/issue/RSCPP-13896. Please vote for it
https://en.wikipedia.org/wiki/Monad_(functional_programming)#Monad_laws I mean `return`, `join`, `fmap`, and (optionally) `bind`. If a type provides the first three it models an hypothetical Monad concept (Haskell defines Monads with `return` and `bind` only). The functions become clearer when we look at their signature in C++ syntax. For a given `monad&lt;T&gt;`: - `return(T) -&gt; monad&lt;T&gt;` (creates a `monad&lt;T&gt;` from a value of type `T`) - `fmap(T -&gt; U, monad&lt;T&gt;) -&gt; monad&lt;U&gt;` (given a function that works on `T` and returns a `U`, and a value of type `monad&lt;T&gt;`, returns a value of type `monad&lt;U&gt;`, this basically lets you use any function that works on `T` on values of type `monad&lt;T&gt;`) - `join(monad&lt;monad&lt;T&gt;&gt;) -&gt; monad&lt;T&gt;` (flattens a monad) Optionally: - `bind(monad&lt;T&gt;, T -&gt; monad&lt;U&gt;) -&gt; monad&lt;U&gt;` (is similar to `fmap`, basically think of it as unwrapping `monad&lt;T&gt; -&gt; T` and then calling the function `T -&gt; monad&lt;U&gt;`).
Just to let you know that "great-pumpkin" is not working for us :) And we didn't added this link to reddit, you can send a private meesage to "great-pumpkin" to remove it.
Could you explain me why QBS is better? Sorry I'm fairly new to Qt.
The introductory post from **2012** gives a good description of why its better. http://blog.qt.io/blog/2012/02/15/introducing-qbs/
To be honest, this post isn't very convincing to me. CMake can do all that, and more. (not that I like CMake, but it's the least of all evil). qbs doesn't even seem to be able to create Visual Studio solution files, which basically makes it completely useless for a lot of people and a lot of purposes. (If I'm wrong, and it can do that, correct me)
Well shit... As someone who manually implements a lot of wierd memory-allocation schemes I could have used this knowledge. I just stopped my research at *operator delete is static* and just wrote a lot of useless code. Why oh why do I insist on using an awesome language instead of a GC one like normal people?
What's with all the clicking noises...
There's something the article doesn't give a very good answer to, and that's the question of why this behavior is needed. It starts out asking: &gt; What about that `operator delete`, though? Is operator delete virtual too? Is is also stored in the virtual table? Because if it isn't, how does the compiler know which `operator delete` to invoke? It doesn't explain until later why this might be needed: &gt; This is because when we delete an object through a pointer to the base class, the compiler has no way of knowing what operator delete to invoke (one of the derived classes may declare its own), This reason is incomplete. In particular, even if none of the derived classes define `operator delete` functions, it's _still_ important that the global `operator delete` be called correctly. Correctly calling the global `operator delete` is not a matter of finding which of multiple `operator delete` should be called. So, why is this behavior of virtual destructors necessary, even in the absence of class scoped `operator delete`, when the specific static `operator delete` function is known at compile time? The reason lies in the conversion from a `Derived*` to `Base*`. Animal* ap = new Sheep; The common case doesn't involve any change in pointer value during this conversion, so we sometimes forget that it can happen. struct B1 { virtual ~B1() {} }; struct B2 { virtual ~B2() {} }; struct Derived : B1, B2 {}; int main() { B2 *b = new Derived; std::cout &lt;&lt; "B2 address: " &lt;&lt; b &lt;&lt; '\n'; std::cout &lt;&lt; "Derived address: " &lt;&lt; dynamic_cast&lt;Derived*&gt;(b) &lt;&lt; '\n'; std::cout &lt;&lt; "B1: " &lt;&lt; static_cast&lt;B1*&gt;(dynamic_cast&lt;Derived*&gt;(b)) &lt;&lt; '\n'; delete b; } [Live](http://coliru.stacked-crooked.com/a/4524f59245739bee) B2 address: 0x743c28 Derived address: 0x743c20 B1: 0x743c20 That means that that type conversion, and the consequent value conversion, must be undone in order to satisfy the well known requirement that the `void*` value returned from the global `operator new` is the value that must be passed as a `void*` to the global `operator delete`. I.e. you can't just pass any arbitrary address inside an allocated block to delete. So even in the absence of a class-scope `operator delete` it's still necessary to know the dynamic type of an object so that this `Derived*`-&gt;`Base*` conversion can be correctly undone in order to pass the correct pointer value to the global `operator delete`.
Cos resources are not only the memory. And finalizers are worse.
It's more a Visual Studio problem. I prefer a config when the IDE calls cmake and make. Don't have that pain with project generation.
I don't have any problems with newer versions of gdb. I can't really comment about performance, but pretty printing works. It gets the job done.
Oops. Thank you for the correction! Well obviously fast is good and for some people it's their first priority. Fine. But a build system that doesn't play well with IDE's is never going to be widely adopted. I think these two features are not exclusive. CMake already can kind of do both: Generating VS files, integration with the IDE is also okay-ish, and alternatively fast builds with the Ninja generator. I'm sure other or new build systems could even improve on that while providing both.
Some from my list of missing things that keep me from switching to the Qt Creator: * keybindings: reformat whole file, jump to last edit (that would be easy for me to fix and contribute maybe) * call hierarchy * double-click near the brace to select text inside braces
GNUs primary concern when developing their toolchain is ensuring that they can't be integrated into proprietary software. This means you can't do nice things like load it as a library. LLVM however have developer satisfaction as their primary concern. As part of this LLDB can be compiled as a library which makes it easy to embed into software like IDEs.
My CLion still uses GDB. There's no option to choose LLDB. How did you do it?
The article is about signaling with Boost and Qt, not about implementing a signals system. About the usefulness of it, knowing how something works under the hood could be constructive, but for the real world work knowing **how to use a tool** is far more useful than reinventing the tool itself.
You can't comment about performance? Does pretty printing work without bugs and without fiddling with script files?
Dang I was hoping there was going to be something in the conference on LLD the llvm linker.
Your post kinda implies you use gdb from the command line. Do you? Or do you use it through an IDE?
It's not like people have been complaining about this just now. This issue was brought up back in 2006 and the justification for preferring initialization lists over uniform initialization involved passing initializer_lists to functions. void f(const vector&lt;double&gt;&amp;); // ... struct X { X(int); /* ... */ }; void f(X); // ... f(1); // call f(X); vector’s constructor is explicit f({1}); // potentially ambiguous: X or vector? f({1,2}); // potentially ambiguous: 1 or 2 elements of vector So it's not a matter of hindsight, it's just an overall poor justification.
I mean, I just said I can't comment on performance, right? I've never measured it, and usually before I pull out the debugger I try to isolate to the smallest possible case that shows the error, so I rarely run it on a long-running program. Yeah, for me pretty printing just works. According to gdb, gcc standard libraries have come pre-packaged with pretty printers since 4.5, so the whole thing should just work. 4.5 is a few years old, so I'm not sure why you've been having trouble.
If using clang-format, you can reformat the whole file, just don't select any text. To select text inside brace: Ctrl+{ or Ctrl+}, depending on where the cursor is. This may be broken on linux since 3.4.2.
You can also do this-&gt;pos; Unlike self in python which is merely a convention, this is a magic keyword, since c++ methods do not explicitly mention the object as the first parameter. It's not really idiomatic in C++, however. Many places have style guides so you can easily see if a variable is a member, e.g. m_ prefix. Style guides rarely differentiate between methods and functions though, so you'll want to have a good ide with syntax coloring to effortlessly make that distinction. 
I graph just pops up in its own window when the breakpoint is hit.
TIL I don't know much about C++. I've always assumed that dynamic_cast in C++ was safe. When you're pointing at B2 how does C++ know that it's ok to change the pointer when casting to Derived? I'm also not entirely sure how many virtual method tables there are in this setup. B1 and B2 have one VMT but then does Derived have two?
Something like this in your .h file: class ClassName { private: float _velocity; float _acceleration; float _pos; public: // constructor and stuff for initialization, etc whatever else... void update_position(float time_step); }; And this in the accompanying .cpp file: void ClassName::update_position(float time_step){ _velocity += _acceleration * time_step; _pos += _velocity * time_step; } People will name the member variables like `_variable` or `m_variable` to distinguish them from local variables. `this` is a pointer to the current instance, so you can dereference it like `this-&gt;_velocity`, but it's kind of a pain in the ass and looks bad and you can just leave it out and type the name instead. If you did want to use `this`, pretend it is like a pointer to what `self` is a reference to in python. The `this` pointer is passed implicitly to each member function, where as in explicit-everything-python, it is explicitly passed.
Yes, but be careful using the this keyword before initialization is complete, especially if virtual dispatch is involved. 
dynamic_cast is safe. The pointer adjustment necessary when casting from `B2*` to `Derived*` can be known statically, so performing that adjustment is not a problem once it has been determined dynamically that the specific `B2` object being pointed at is in fact inside a `Derived` object. &gt; I'm also not entirely sure how many virtual method tables there are in this setup. B1 and B2 have one VMT but then does Derived have two? The vtable for the Derived class can lay out the individual entries in its vtable such that vtables for its bases are directly included. So there can be a single vtable for Derived, where the first entries in that table match the layout expected for the vtable for B1 objects, and some later entries match the layout expected for B2 objects. Then Derived just needs to store two pointers, one which doubles as its own vtable pointer and the vtable pointer for the B1 sub-object, and a second pointer for the B2 sub-object which simply points at an offset into Derived's vtable. For example, here's the actual static data produced by my compiler for vtables for Derived, B1, and B2 objects: __ZTV7Derived: .quad 0 .quad __ZTI7Derived .quad __ZN7DerivedD1Ev .quad __ZN7DerivedD0Ev .quad -8 .quad __ZTI7Derived .quad __ZThn8_N7DerivedD1Ev .quad __ZThn8_N7DerivedD0Ev __ZTV2B1: .quad 0 .quad __ZTI2B1 .quad __ZN2B1D1Ev .quad __ZN2B1D0Ev __ZTV2B2: .quad 0 .quad __ZTI2B2 .quad __ZN2B2D1Ev .quad __ZN2B2D0Ev This is all implementation specific, obviously.
Thanks for the info. I'm not sure if the compiler could always determine statically if the dynamic_cast is valid or not but at least it could take a look at the pointer to the vtable and see if it's pointing to the internal B2 vtable in Derived or if it's pointing to the original B2 vtable or another vtable entirely.
Might be interesting to see the results for a configuration with four io-services that have two threads each.
Sorry, I was looking at the "actual" code at https://github.com/ericniebler/range-v3. Thanks for pointing that out. 
Or you can use QtCreator and it's already setup for you no matter the platform
What is your learning material? It should certainly mention it.
TS's are the new boost. Neither you nor tcanens seem to know the difference between Concepts and Concepts Lite. I have "actually" met Bjarne Stroustrup and got a lesson on that. Do you have anything to contribute to the discussion on how to provide mere mortals writing code with useful knobs for policies to take advantage of the latest cpu and networking technology? My thinking is modern C++ algorithm libraries should support this. Just like C# does. Technology moves fast these days. Let's use this forum to have civil conversations that don't discourage non-experts from participating.
I tried it and it looks really good, performance is much better than I've tried it before (quite a long time ago actually). Some things are not quite as in VAX yet but some other are present and really useful. I especially like the features like pointing out the wrong order of variables in constructor initializer list which actually could be considered a deficiency in VS compiler. If all goes well, ReSharper will become strictly better than VAX pretty soon.
Huh, didn't follow the C++ standardization process then. Really strange they passed it in that case :( 
As a note, you shouldn't use leading underscores to name your class variables - use something like `m_xx` or `xx_`. Leading underscores are reserved for the compiler: &gt;Each name that begins with an underscore is reserved to the implementation for use as a name in the global namespace
Agreed. My main objection to GC (although I do use GC languages for certain tasks) is that it is too restrictive. Even if you don't mind the performance hit, which for most tasks isn't a big issue, GC is makes it harder or even impossible to use RAII or taking manual control over memory allocation for performance tuning. All for what? unique ownership is all you need for about 90% of practical appliactions. So why is is that almost *all* languages are GC? Memory management is a solved problem! Sure RAII isn't a 100% perfect solution since ownership cannot *always* be unique and reference counting has the circular reference problem, but how often is that an issue? The only cases I can think of are if you're working with some pretty complex graphs or computational geometry. For the majority of cases GC is overkill and I think fueled by some wierd perfectionism. As if it isn't *completely* fool proof it's not good enough. And as a result you still have to manually close filestreams in for instance Java because there are no destructors. Hubris, I swear!
Ah, I see. Thanks!
To add to this if you need a reference to **self** to, for example, pass it as an argument to another function use **this**. In the example by /u/flebron ++x; Is syntactic sugar for ++this-&gt;x; edit: to clarify **this** is a pointer not a reference. The reason being, regrettably, a brain-fart on Bjarnes part.
You shouldn't prefix your member vars at all imho. Makes for pretty terrible readability. Either use this-&gt; or rely on syntax highlighting.
Considering reference counting is especially useful for working with graphs the answer to this question should be fairly obvious. Personally I stay away from shared_ptr *because* it is synchronized and thus slow for single-threaded environments. When all the code requiring ref-counting runs in just one thread, as is generally the case for me I use my own shared resource class. Kinda wish a non-synchronized implementation of ref-counting was standardized.
&gt; As far as standards proposals are concerned you won't really find that name. Oh, [it's there in earlier drafts](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3889.pdf) (and some people are still using it more recently, for instance [N4434](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4434.pdf)). The story I heard is that some people felt that "Lite" is too informal, so the final TS is just called "C++ extensions for Concepts".
I do the `m_thing` in real life. 
What about delete[] though?
&gt; I just stopped my research at operator delete is static and just wrote a lot of useless code. It's a frequent mistake. I seem to remember a SO question about `delete this` where the guy was trying to get proper deletion scheme with DLLs using different memory allocators. He didn't know enough about `operator delete` either.
Well I wouldn't call it slow for most purposes. But it certainly falls short on C++'s premise of "you don't pay for what you don't use". Would you mind sharing your implementation of single-threaded shared_ptr?
The speed difference between Ninja and msbuild (both using CMake-generated files) is something to behold. Unfortunately I can't yet use Ninja--for some reason for my superbuild project it miscompiles it subtly so it throws an exception on startup whenever it tries to construct a boost::filesystem::path; still trying to track down why, though I suspect it might be a release/debug mismatch for some odd reason.
This would be an absolute godsend. It drives me up the wall to not have this in the standard.
&gt; Why not put it into boost like his other libraries and get more user experience? Boost already has a ranges library. It's not "range v3" but it's got some of the stuff you might want.
There may be some analogy between the evolution from Concepts to Concepts Lite and what I am suggesting for range-v3. Allow me to remind you of some history: http://www.devx.com/cplus/Article/42448. A quote from that article: "My best scenario for the future is that we get something better than the current "concept" design into C++ in about five years. Getting that will take some serious focused work by several people (but not "design by committee")." It took 6 years from ditching Concepts to getting Concepts Lite into the standard. The good thing is that it seems people new to C++ have completely forgotten the horror of the earlier Concepts proposals. :-) Still hoping to get feedback from anyone with "actual" experience using C# Enumerator/IEnumerable and how Rx and Ix interact with that. People who write code instead of nitpicking standards terminology need useful knobs for policies to take advantage of the latest cpu and networking technology. 
I’ll readily admit this is a bit of generalized grousing, but the problem is that Boost.Range and range-v3 have too much of what I want. :-) They are both too many lines of code for the additional functionality they provide. And neither address the more serious issue of how to write algorithms smart, but not brilliant, programmers can use to take advantage of multicore and distributed programming. I’ve looked at the code and was inspired to take some first steps at simplifying the issue of range sentinels needing to have different types in range-v3. Why not just use STL iterators and add an `operator bool() const` to detect the end of a range? See my ‘Enumerators for C++’ post for more details and actual code you can compile and run. 
I love these and listen to almost all of them, but man you have to figure out how to minimize extraneous sounds like: 1. Mouse clicks 2. Breathing 3. Audible inhaling into the mic 4. Audible sighs 5. Noise fading up and down Also awkward dead air beats between people talking. With so many people streaming on sites like Twitch, there are a lot of guides out there for what kind of setups to use etc. Also I think it would be cool to have people talk more about architectures. General news is fine, but having an expert talk about how to structure and design programs in the general domain they are in is something I think is really fascinating as well as helpful.
Variadic macros were not part of the C++ standard until C++11. However, they were part of the C standard since C99. As a result, even though it was technically non-standard, most compilers allowed variadic macros in C++ before C++11.
Yes, but at the same time, I don't remember MSVC and C99 ever playing together perfectly. Its priority is C++. As I learned in the other reply, though, that doesn't apply to variadic macro support beyond the errors in conformance.
&gt; Sometimes, one gets thrown a codebase and is trying to figure it out on the fly If someone throws a guy who didn't ever do C++ on a C++ codebase this someone certainly deserves to be fired.
Hey guys, I love having a clean slate and a precise goal for a new application. When I do, I try to make everything as simple as possible, and that makes for some good tutorial material. I hope you enjoy the post :)
 auto numThreads = std::thread::hardware_concurrency() - 1; /* 0 is either an error or dual core. -1 single core (does that still exist?) */ if (numThreads &lt;= 0) [hardware_concurrency()](http://en.cppreference.com/w/cpp/thread/thread/hardware_concurrency) returns unsigned value
&gt; std::ifstream::pos_type fileSize; // Total file size used for the status meter. &gt; std::string help = "Usage: parsewinelog [yourlog.txt]"; // --help output. These shouldn't be global. &gt; In an effort to keep things simple, I do not check for spurious wake-ups. It is critical you do so in a real application. **You shouldn't present a broken example.** The predicate-wait functions are simpler to use and automatically handle spurious wakeups. &gt; return in.tellg(); The Filesystem TS (and Boost.Filesystem) provides a simpler and better way to do this. &gt; float ratio = x/(float)n; You shouldn't use float unless you have a specific reason to do so. Use double by default. You should avoid C-style casts. &gt; for (int x=0; x&lt;c; x++) C++ style conventionally uses preincrement. There are minor/historical performance considerations for doing so (with iterators, preincrement is potentially friendlier to the optimizer), but the main reason is for code clarity. Preincrement is simpler, so if you use it by default, the remaining postincrements will stand out as being unusual. Attracting attention to unusual code is extremely valuable. Also, you should put spaces around (most) binary operators consistently. &gt; std::ifstream openInFile(std::string f) std::string should be passed by const reference, not by value. You aren't consuming it here. &gt; std::ifstream inFile(f, std::ios::in); The flag is unnecessary. Ditto for outFile later. &gt; fileSize = getFilesize(f); Due to getFilesize()'s implementation, you're opening it twice simultaneously, which makes my eye twitch. &gt; &lt;&lt; " -- Filesize: " &lt;&lt; fileSize/1000000 &lt;&lt; " MB" 1 MB is 1,048,576 bytes. Anyone who says otherwise is wrong. Again, Filesystem would make openOutFile's path manipulation easier. &gt; if (argc &lt;= 1 || argc &gt; 2) { argc != 2 . &gt; std::string filename = std::string(argv[1]); This is a completely unnecessary temporary. &gt; if (line.find("Call") != std::string::npos) { This will mistakenly detect any function whose name contains Call. Ditto for Ret later. &gt; inFile.close(); This happens automatically (yay RAII). &gt; auto numThreads = std::thread::hardware_concurrency() - 1; This and its later checks are incorrect. It returns unsigned int, and N4527 30.3.1.6 [thread.thread.static]/1 "If this value is not computable or well defined an implementation should return 0." Your later checks believe that this is signed. &gt; for (auto i = 0; i &lt; numThreads; This is just int. It is **not** affected by the type of numThreads. &gt; pool.emplace_back(new Thread()); Leak. &gt; friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, ThreadPool&amp; tp) Streaming should not be permitted to modify the object being printed. &gt; int killThread(const int&amp; i) You should take by value, since there is no need for const reference here. &gt; processCondition.notify_all(); // Get to work! Notifying while holding the mutex is inefficient. &gt; /* We use unique_ptr because there where major move semantics issues. vector handles movable-only objects just fine. &gt; I couldn't use a vector of std::function as I need to store a parameter inside, and later process that. std::function can store stateful function objects, including lambdas. &gt; Remember that constructor initialization order is NOT guaranteed! */ It is guaranteed that members are initialized in declaration order. &gt; int size() Should be const. And the type is wrong.
I'm not sure but I think calling the shorter version syntactic sugar is wrong. The longer version is for clarity. I'm pedantic.
Wow. Ok, I will go through and fix the important things. You point out many small issues (like spaces, the exact MB size), that I didn't really consider being important. I will fix some. I don't use boost, why do you assume mentioning boost is fine? I am sick of everyone always saying "use boost this". I don't and wont ty. No one should use boost in a "C++" example. The progress bar is just eye-candy for fun :) &gt; You shouldn't present a broken example. The predicate-wait functions are simpler to use and automatically handle spurious wakeups. I don't, it works. I may go back and add a wait lambda, I am still posing the pros/cons to someone completely new to threads. I don't know if it is too overwhelming, but I will probably fix that since you are right that it is not OK. &gt;&gt;std::ifstream openInFile(std::string f) &gt;std::string should be passed by const reference, not by value. You aren't consuming it here. True, thank you. &gt;&gt;std::ifstream inFile(f, std::ios::in); &gt;The flag is unnecessary. Ditto for outFile later. Falls in the "really?" troll comment category. lol &gt; You shouldn't use float unless you have a specific reason to do so. Use double by default. Says who? Why? How is this relevant? &gt; C++ style conventionally uses preincrement. There are minor/historical performance considerations for doing so (with iterators, preincrement is potentially friendlier to the optimizer), but the main reason is for code clarity. Preincrement is simpler, so if you use it by default, the remaining postincrements will stand out as being unusual. Attracting attention to unusual code is extremely valuable. I know many people who say the exact opposite. This is an opinion, not a fact. &gt;&gt;pool.emplace_back(new Thread()); &gt; Leak. Nope. &gt;&gt;processCondition.notify_all(); // Get to work! &gt;Notifying while holding the mutex is inefficient. ?? Elaborate please. Explain better solution? Link? &gt;&gt;/* We use unique_ptr because there where major move semantics issues. &gt;vector handles movable-only objects just fine. I spent enough time trying to make it work, it did not, and unique_ptr work just fine. &gt;It is guaranteed that members are initialized in declaration order. True, I misinterpreted what an author was saying on the subject. Thank you! So, you went a long long way to criticize the example, but man you are such a troll. You feel it is necessary to talk about spaces in my code? Or the fact I use a temporary string to make the code intent more clear to the reader? This is not production code. I will admit you also pointed so really bad mistakes. So in the end, thank you anyways :) I will go fix the major kinks and quirks. But stop with Boost ok, it is NOT the standard.
To be fair, MB is standardized by IEEE and more to 1,000,000, MiB is 1,048,576. This is also used by the International System of Units. Just because Microsoft made it different, doesn't mean its correct.
It's not trolling, it's code review, and you should be very grateful that you're getting it for free from a top-level expert. I'd absolutely love to have STL tell me why my code is terrible.
What advantages does this have over something that uses `std::function` and/or `std::future`?
I haven't gone carefully through all the 172 pages, but the same warning bells are going off about how Concepts turned into Concepts Lite. Concepts were too complicated. It is a tribute to the genius and perseverance of Bjarne Stroustrup that he got all the clever C++ standards geniuses to finally realize Concepts are just a Boolean constraint on template parameters. Range-v3 is too complicated. It introduces more, um, concepts that potential users might have trouble getting their head around. Why use sentinels? Overloading operator bool() achieves the same end. (I'll be here all week. Try the veal.) Seriously though, the C# crowd seems to be ahead of the C++ proposals. There is a lot of existing code using the C# analog of this. Regarding N4382, using Proj functions in algorithm signatures just seems wrong. The projection can be applied/mapped/factored out to the range being passed in as an argument. I had to write some code to interface with an Xbox. It has an API that can reduce strong men to tears. Google Bart de Smet. Complexity is the bane of software and anything that can be done to make it possible for non-experts to write useful code is a good thing.
I don't understand why you think it's okay to present bad examples, bad habits, and bad code to beginners. C++ is not an easy language, and honestly you should really avoid teaching it unless you know it well.
It does have "mega" in it, which means million. But then again... _irregardless_ is in the dictionary... :(
It's certainly improved from what we were shipping before, but it still contains some known deficiencies (e.g. it can't detect symlinks) and may contain further bugs. So it's somewhere in the range [pretty good, crystalline perfection).
ew the audio needs to be reworked, the acoustics in that room are horrible for recording
https://www.youtube.com/#/playlist?list=PL24126B3A47B69CB5 or http://www.youtube.com/watch?v=kMzH3tfP6f8&amp;list=PL24126B3A47B69CB5&amp;sns=em C++ Programming abstractions. Stanford Uni
What about `std::async`? Isn't it supposed to do exactly that?
It's too Sunday to read the code. How it differs from a thread pool?
The task scheduler discussed is an advanced form of thread pool which implements both task and data parallel constructs with work stealing and a per thread lockless pipe allowing all threads to issue tasks.
Implementations might work in a similar fashion to this task scheduler, and might not. The task scheduler described also works for C and C++ pre C++11, where std::async isn't available. Additionally the task scheduler enkiTS exposes a thread number which can be used for optimizing thread local type accesses, and has a data parallel interface for spreading work across threads. 
That's just a simplified illustration of what it could look like. The [most recent draft](https://github.com/ericniebler/stl2/raw/master/DXXXX.pdf) has template &lt;class I, class R = less&lt;&gt;, class P = identity&gt; concept bool Sortable() { return Permutable&lt;I&gt;() &amp;&amp; IndirectCallableStrictWeakOrder&lt;R, Projected&lt;I, P&gt;&gt;(); } But yes, you'd still need a `requires`. template&lt;RandomAccessIterator I, Sentinel&lt;I&gt; S, class Comp = less&lt;&gt;, class Proj = identity&gt; requires Sortable&lt;I, Comp, Proj&gt;() I sort(I first, S last, Comp comp = Comp{}, Proj proj = Proj{});
Well, it is opt-in. So, maybe not used there. For making sure it is, you must constexpr the result somewhere. If it hits the compiler limit... I don't know, hehe. 
Maybe it would be a nice idea to add a target to the Makefile for generating the assembly code and be able to inspect. 
If I recall correctly, a lot of thought went into this problem by Eric. And, if you have *the same type* for both the sentinel and the iterator, in some cases, this is going to generate worse code than the optimal (compared to c raw iteration). The problem lies in the fact that both types are the same. This moves the check to run-time checking instead of having compile-time encoded information. Look at the generated code in this post, where he explains the problem with detail: http://ericniebler.com/2014/02/16/delimited-ranges/ And here his solution: http://ericniebler.com/2014/02/21/introducing-iterables/ Which I think identifies that the problem is having the same type for both begin and end. 
Is this the new boost coroutine v2? EDIT: no, it's not. It's https://github.com/jamboree/co2 .
Just dropped in to say this is an awesome idea!
I have a github repo of random utilities I use. It's not by any means industrial strenght implementation and often fairly ugly, but it works for me. http://github.com/cewbost/utils/ The reference counting is implemented by inheriting from the RefCounted class for any object that needs to be reference counted. This was so I could get a reference counting smart pointer to an object from **this**, since std::shared_ptr doesn't get passed into methods and the control object containing the reference count are not always stored in the same location relative to the counted object, so I needed the reference count to be part of the object itself. As for shared_ptr being slow, that's relative. Atomic operations carry a significant cost. Admittedly I probably worry about performance far to much, but I work mainly with games (not professionally, see username).
g++-5 (Homebrew gcc5 5.2.0) 5.2.0
Have you thought about sending this upstream?
Not particularly relevant to C++ but... I was completely turned of from LUA because of the 1-based indexing. And there isn't even a mod1 function like in for example Julia. Sure one could implement it one-self, but that still requires a function call, and since it's a dynamic language it cannot be inlined. Aaargh. Nowadays I use Squirrel.
You should check out adobe labs abstraction penalty benchmarks. It is based on Stepanov's, but is rather more expansive and supports Windows, Linux and OSX and various compilers. It was last released in 2008 though.
&gt; To select the first value in an array named a we would write a[1] You should not present incorrect information, even if you correct it later. (It is acceptable to introduce an approximation of the truth, when clearly noted. But this is just totally untrue.)
What? Not all enterprise uses QtCreator or Eclipse. I primarily use VS at work.
Of course you could replace most constructors that way. It'd have to be a template function or implemented as a class static member so that the interface would be common between containers that implement that kind of initialization. Using it in general would look like: struct S { std::vector v{std::vector::replicate(size, v)}; std::string s; S() : s{std::string::replicate(size, ch)} {} }; etc. It's just that I don't see what's better about _that_ than just using constructors. 
I seriously doubt that another single-man effort could approximate, let alone substantially improve, Eric's range-v3 effort so far. At least with all the Concepts emulation and going over the STL to clean things up, it's a Herculean task. Some lightweight range library might be doable perhaps, or a translation of D's ranges (no iterators as primitives).
See this: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3351.pdf. It gives a good explanation for how algorithms should be constrained. The current library work builds on this. The concept syntax is not quite right, but the constraints are.
I never liked Eclipse. I didn't try Qt Creator in a long time, I will give it another shot.
Oh, yes. Forgot that. It's pretty recent in the C++ timescale. )
Mastering automatic testing is hard as hell. You have to write code not from the problem-solving perspective but from the verifying-of-the-solution perspective.
But it is not free.
Free for students. And it's free for 30 days for evaluation. And is centered around CMake which is what you *probably* should be using. And it gives you refactoring tools and error checking.
&gt;I'm sending you five links that are not as relevant as I think they are
How do you feel about Visual Studio community?
You can use [newton-raphson](https://en.wikipedia.org/wiki/Newton%27s_method) to reduce complexity.
I completely agree with both of you. I've written libraries for clients and move what I can into open source. We no longer live in a single-man effort world. You are welcome to look at https://github.com/keithalewis/fms/tree/master/iter and my latest sloppy work at https://github.com/keithalewis/enumerator. Be kind. I have a big, idiosyncratic wish list for C++ ranges based on experience with using the standard library to implement trading strategies for clients. A concept for monotonic ranges would be nice. See https://github.com/keithalewis/fms/blob/master/iter/zigg.h for an algorithm that is useful for expressing trading strategies. Warning: I'm a fan of APL/A+ and its current iteration, kdb. Ken Iverson started something many people found interesting enough to spend considerable effort on. My top concern with range-v3 is that it is too complicated. Just as the original concepts proposal was. One symptom of that is the current proposal tacks on projections to every algorithm. That is not good factoring. The real issue, as Eric Niebler pointed out, is that the current notion of iterator needs to be fixed in order to allow that.
Inlining is **the** most important optimization for C++ programs.
Well, the goal is not to reduce complexity here. The goal is to have benchmarks that do roughly the same thing but written in different styles to see the abstraction penalty. Thanks for the link, anyway. :)
Yup! It's working now! Thanks a lot! :-)
(for such an array, it's clearly `std::array` that is the C++ equivalent, not `vector` as it is always recommended first)
I hate to be that guy but if you don't know interfaces, instances of objects or classes then you aren't even beginner C++. These are like first week of learning C++ concepts. 
First week is an exaggeration, but first class for sure. 
Maybe start with [http://www.stroustrup.com/Programming/](Programming -- Principles and Practice Using C++ by Bjarne Stroustrup, the creator of c++). He goes through c++ bit by bit, introducing things when he needs to. It can get quite advanced at times. I also don't mind C++ primer as a book, but that one seems to divide a lot of people apparently. The best thing to do would be to visit r/cpp_questions (link in the sidebar) and look at the link in that subreddits sidebar for the definitive c++ book list. (alright then, here you go...... [http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list). Good Luck and stick with it. It could be a long journey but its a fun and challenging one. I've skimmed that book and it's definitely the bible on PBR rendering (it won a technical oscar as a reference for rendering). I keep meaning to go back to it. On a higher level, you might want to look at these guides in two volumes on PBR rendering [https://www.allegorithmic.com/pbr-guide](https://www.allegorithmic.com/pbr-guide) and also the original Disney Technical Paper which a lot of the game engines and renderers use a the base of their tech.
Nearly every C++ intro book jumps into "Cat inherits from Animal" type thing in chapter one. Sort of like all the OpenGL courses have the rainbow triangle in lesson one.
This was the case 10-20 years ago.
Yeah I get the rational, I just thing that; &gt; between parens and braces is a subtle thing and reduces readability Was never that big of a deal and it hasn't really added anything that useful to the language and added another set of syntax to an already bloated language. The last thing C++ needs to be doing is adding more ways to do the same thing for marginal gain.
The hope was that it would be one of those things added to the language that simplifies it. In this case what we want is for there to be a single syntax for construction. We just have to push a bit further and that can be achieved. I think that would be more than just a marginal gain.
&gt; I'm a beginner to intermediate in C++ No offence meant but you are still very much a beginner if you do not understand the things you mentioned. Grab a copy of Programming Principles and Practice Using C++ and write some code.
I think he means that these are the types of things that would be covered in a basic course, but not until a few weeks into the course - i.e. not in the first week.
The word class is ambiguous. Depending where you live it can be a synonym for 'course' as in 'Introduction to C++' which is a class that runs over several weeks, or class 1 of the course 'Introduction to C++ ' where youre talking about the first week. 
Yeah but it's the convention for the libraries as well as the default for expressions such as foo = {12, 23, 34} Squirrel on the other hand does have arrays which are 0-indexed and stored contiguously in memory
* Dynamic vs. static dispatch is always a nice comparison [1] * compare RVO: `std::vector&lt;T&gt; foo(std::vector&lt;T&gt;)` vs `std::vector&lt;T&gt; &amp; foo(std::vector&lt;T&gt;)` vs `void foo(std::vector&lt;T&gt; &amp;)`, etc. (I once did some basic comparison for RVO and iirc it didn't make a huge difference) * Pick one or more of [2] and see if you can come up with a raw version :) [1] http://eli.thegreenplace.net/2013/12/05/the-cost-of-dynamic-virtual-calls-vs-static-crtp-dispatch-in-c [2] https://en.wikibooks.org/wiki/More_C++_Idioms
You should recommend Visual Studio Community 2015 then as it is more standard conforming than 2013 and have more features, also put a link to download. The tutorial seems good (the dark theme availability is a bonus), but of course it needs polishing. The part about linking libraries should be simple to understand, because linker errors are pretty hard to get by for beginners. I would suggest to write some advices how to find out solutions when encountering compile and linker errors, on what to focus attention (there are many posts about "I compile this code and get an error, what's the problem?"). For beginner and drawing related stuff I would use something like SFML.
This is probably the most vocal the Boost developers have been that I've seen. Seems like the discussion is getting quite heated.
OP didn't quite correct it, it seems more like it was deliberate because naturally arrays are [indexed from 1](http://stackoverflow.com/questions/4239907/is-zero-based-indexing-available-in-matlab#4240118), that's why later it goes like "However, we did not say the whole truth. In the C++ programming language, the indices of arrays actually start from the number 0". I think that this should go as "In many languages indexes of arrays actually [start from 0](https://en.wikipedia.org/wiki/Comparison_of_programming_languages_(array))".
_Programming: Principles and Practice Using C++_ put inheritance in Chapter 9. _Accelerated C++_ put it in chapter 13. _C++ Primer_ put it in chapter 7. _Sams Teach Yourself C++ in One Hour a Day_ put it in Chapter 10.
Great work! I am not familiar with LUA. Could you give some brief introduction about what is the benefit of integrating LUA to Qt Creator?
Actually `std::array` is defined as an aggregate type, and as such can be brace initialized even in C++03 just like you can do with structs even in C.
Vector math, open gl, render buffers, shaders, textured meshes and all that fun stuff are where you want to go. I'd stick to the basics for now, but start looking into those topics.
There are no magic shortcuts. Start learning one concept at a time and in an order that makes sense. Before trying to understand abstract classes you need to understand class inheritance, interfaces in general, class instantiation, etc. Before understanding classes you need to understand functions, encapsulation, aggregate data structures, etc. Before understanding aggregate data structures you need to understand types, data alignment, how the variables are stored in memory, etc. Do that in order and make sure your understanding of the base concepts is rock solid before going to the next level of the pyramid otherwise you will only get headaches. 
Thanks, SGH-5450!
&gt; Dependencies: Boost No, thanks. 
Am I the only one to have seen "idiotic" there? :-)
&gt; I hate to be that guy you love it
Deeply rooted habits turn into bugs, and when there are more suitable options I go with them instead. And no need to get salty because I voiced a pet peeve of mine. You don't know what I work on.
Good blog. Reading this tonight!
they call the classes modules? or they call the c++ classes modules? I'm guessing the former... Maybe we should just call them structs with access qualifiers, and I'm talking about the student at the desk, not the C++...
If you don't say it then you are even worse than that guy. But this would be like: I am an intermediate pilot about to take my first flight. I need help with my red vs blue dogfight taking place in the grand canyon this weekend. 
&gt; Dynami That is an interesting benchmark, but it is out of scope. What I want is to compare C-ish or directly raw implementations of things vs C++ idiomatic ones. This would fall in a C++-specific category only.
Yup. Gradle is absolute crap for C++ development. Maybe they'll get there eventually, but it's a risky bet to make, especially since CMake is so mature &amp; feature-full.
&gt; all the issues that native builds face. Like what?
PBRT. It goes a lot deeper into more sophisticated light transport techniques, and covers many topics that are missing from the other book like volumetrics and subsurface scattering. The authors won an technical Academy Award for it. On the other hand, I've heard Suffern's book suggested as a good warmup for those who aren't quite ready to tackle PBRT yet.
Because no one really cares if you don't know what this is. 
CMake's C# support is not as good. Also, writing working pch support is all but impossible (I have written one, it almost kinda works but not fully).
See sakra/cotire for nice PCH
&gt; Any dependency outside of C++ would make the task scheduler not lightweight. Additionally most game developers, myself included, tend to prefer not using boost. You're missing out on a huge amount of highly useful, super high quality code. 
&gt;The useful side effect of using the library algorithms is the possibility to specify container immutability: const auto a = terse:: ... That's really nice, I'm sold.
???
Looks nice, especially given it's header-only and hopefully (?) runs on VS2015. In the medium/long-term however I see range-v3 as the more general and better solution. Thank you for sharing!
Well, then you could walk through `&lt;algorithm&gt;`. It'd be interesting to compare hashmaps, linked lists, vectors, treemaps, etc. with hand-written ("stupid") implementations, hand-written tuned impls, and maybe glib or such.. :)
Unfortunately, I can't check VS2015. range-v3 [example](https://github.com/ericniebler/range-v3/blob/master/example/calendar.cpp) looks too complicated for me.
Watch Eric's [talk](https://www.youtube.com/watch?v=8yV2ONeWXyI), it's very good and easy to follow. You can get [VS2015 community](https://www.visualstudio.com/en-us/products/visual-studio-community-vs.aspx) for free to test it if you want to.
I was referring to avoiding boost. Doing so means you're missing out on a huge amount of highly portable, high quality, highly useful, free code, much of which you don't even need to build, just point the include path at it. Avoiding this makes no sense to me.
Exactly. 
&gt; range-v3 example looks too complicated for me. Do you mean the solution using range-v3 or the example itself? The problem being solved there is non-trivial, but there are solutions in D and Rust to the same problem which arguably look more complicated than range-v3's one.
It does. And on top, since we have `using raw_data_t = std::uint64_t;`, we may also have an unaligned access which depending on the architecture may result in either a performance penalty or a hardware error.
If you're going to refute my experience because it's anecdotal and then provide an anecdote to illustrate your own point I think it's unlikely we'll be able to have a fruitful discussion on this subject.
It's a nice summary of multi-threaded programming, but aside from the hardware examples I didn't find anything really related to gamedev here. Will there be follow-up presentations on applying this knowledge in a fictitious game engine? Or how to parallelize game logic? Why waste your time learning with the low level details when you could potentially just use something like openMP or TBB?
&gt; This was the case 10-20 years ago. sometimes in /r/programming there are posts of guys who have their courses on Turbo C++ 5.0 
just in case anybody wanted to do this in vanilla c++11 i find a self calling lambda can do the trick: const auto v([&amp;vs]() -&gt; std::vector&lt;int&gt; { std::vector&lt;int&gt; v; std::transform(std::begin(vs), std::end(vs), std::back_inserter(v), atoi); return v; }()); or with Boost.Range: const auto v(boost::copy_range&lt;std::vector&lt;int&gt;&gt;(boost::transform(vs, atoi));
I hope to god they fix their warning bugs. variadic templates produce false positive warnings and their warning push and pop don't work. 
In the past I've used `std::inner_product` with `logical_and` and `logical_or` to do sum of products and product of sums boolean calculations. I'm really not overly clever.
Not quite the subreddit you want. /r/computergraphics or /r/gamedev /r/cscareerquestions /r/learnprogramming might all help you more. Most school computer science programs will have a "computer graphics" course or similar. These will get you started at the least. There's good research in the field coming from most solid computer science schools, but the type of research will vary. Some of the big names in research are Cornell, Standford, Purdue, Carnegie Mellon, MIT....not surprising. I'm not sure what you're more interested here but I'd say poke around ACM's library, look at some papers, watch some demo videos on youtube, and try and find research areas you're particularly interested in and go towards those schools if you really want to pick the school. If this is for undergraduate, I'd say just go for a school with a good CS program in general that you like. Graduate school you need more of an idea of your research. Mine is in character animation but my adviser hasn't done much with it recently (more focused on architectural lighting instead of simulated jump animations) so I kind of screwed myself. Each thing you listed is a wide area. Ask yourself how you want to render things, what you want to animate, what you want to simulate. VFX itself also involves a lot of computer vision (/r/computervision) and image processing techniques (inpainting, matchmoving, rotoscoping, compositing...) for sticking things into scenes that weren't there before or removing things that shouldn't be there. There's tons of technologies for building these renderers as well. It could be all CPU side for something that sits and renders for awhile to make movies, but you'll generally want DirectX or OpenGL (the new thing is Vulkan instead of OpenGL I think, I'm behind on this) which is its own realm of learning somewhat tangential to the actual algorithms and techniques, but also sometimes integrally related. **TL;DR** None of this should stop you from learning this, don't worry as much about the school. Find a good place for a foundation in computer science, or start poking into current research yourself. It's a very wide field but so very fun.
Some stuff I wrote on StackOverflow - writing [classical sorting algorithms in modern C++](http://stackoverflow.com/q/24650626/819272) (e.g. `insertion_sort` = `std::rotate` + `std::upper_bound` and `selection_sort` = `std::iter_swap` + `std::min_element`) - [removing the first match from a `std::forward_list`](http://stackoverflow.com/a/19375586/819272) using `std::adjacent_find` and `forward_list::erase_after`
This is absolutely terrifying
Understood, I just meant I saw 3 bugs from 5 seconds of glancing at the code – not a good sign.
These bugs were found by running tests, which is why good and extensive tests are needed (especially for these kind of libraries), still even if is not well tested and implemented library it is a good [proof of concept](http://htmlpreview.github.io/?https://github.com/kberezovsky/Terse-STL-algorithms/blob/master/docs/article-en.html).
I have a function `make_vector(some_range)`, so I can do `make_vector(some_range | transformed(some_function))`, where transformed is a [range adaptor](http://www.boost.org/doc/libs/1_58_0/libs/range/doc/html/range/reference/adaptors/reference/transformed.html).
Why is 'return type deduction' marked as Yes for version 15? http://i.imgur.com/OhNyymZ.png
For the record, Intel C++ compiler has issues where you write a few lines of specific code and the compiler crashes with no diagnostics.
https://software.intel.com/en-us/forums/topic/583936 https://software.intel.com/en-us/forums/topic/538753 https://software.intel.com/en-us/forums/topic/506706 to name just a few 
Oh wow, even after I warned about doing that, good catch! Thanks for reading! /u/changetip 100 bits
More on ANGLE (Almost Native Graphics Layer Engine): - https://en.wikipedia.org/wiki/ANGLE_%28software%29 - https://code.google.com/p/angleproject/
Hmm, looks like the same responses of 'this bug is fixed in the next version' when the next version isn't an update but a full release.
My understanding is that the gaming industry heavily uses C++, when they aren't using something like Unity, because of the performance gains. I believe the high-performance computing world (universities, national laboratories) also uses C++ for the same reason.
In the 21st century, C is synonymous with low-level and systems work. C++ devs tend to specialize and have experience with some relevant framework or middleware. Exceptions exist of course, with C++ used for systems work or shops maintaining large apps written entirely in C, but they're a minority. Your friend would be best off deciding what he wants to work on and continuing to develop specialized skills. He'll be able to find a generic "C++ job" if he looks around. But there's a good chance if he doesn't continue to specialize, he'll land with a specialty he isn't passionate about and it will slow his career track.
And one more thing ... sometimes just putting auto foo = ...; can also result in a copy, vs. not -- again I don't understand when/how.
C/C++ is often used when you need more control of your environment. I.e. the alternative might be using a high level language such as python but then stuff might happen that you did not count on such as gc or beviour of different data structures, vectors, arrays, maps etc. This ability comes at a price, it demands more of the programmer. However it is often worth paying in certain situations such as embedded or special hard ware, extrem real time requirements such as low latency trading, gaming and also for high performance computing where repetitive tasks can be highly optimized. I am relatively new to programming and C++ (only a few years) but I am lucky enough to work in a unique team that wants to invest in me. My realization is that the key to becoming a really good programmer and especially if you are focusing on C++, have more to do with gaining a fundamental understanding of how computers functions rather than how should I implement X in C++. Sure you can memorize design patterns all night long but I do not think it will be of much use unless you understad why you should program accordingly.
The GNU toolchain is slowly converting to C++ (it was C before). C++ is often used to implement completely different programming languages, too. It's not all low-level or real-time stuff.
It's basically very simpe: Using `for( auto x : ... )` creates copies of the elements. Cheap if it is an integer, not so cheap for large objects. If you don't want to copy, use `for( const auto&amp; x : ... )`. If you want to modify the elements, you can also use `for( auto&amp;&amp; x : ... )` which will give you a const- or non-const-reference depending on the container. There are a number of places you can look at for more information, e.g., http://en.cppreference.com/w/cpp/language/range-for The fundamental point is that `auto x = ...;` will deduce the type from the expression, but the type is not the exact direct type. Point 1) here: http://en.cppreference.com/w/cpp/language/auto explains it. 
I am not sure if you read my post, it was out of curiosity. I am in finance, not programming, although I do code a little for fun. 
Entry jobs in c++ - just go looking for someplace that is hiring c++ devs. The "best" entry jobs are ones that are going to give you mentoring to improve your abilities, and teach you how to do other things (ex. use version control, work with teammates in a larger organization, etc.). Exactly what you are developing with c++ is much, much lower down on the list of what is important. That being said, the largest number of entry level jobs in c++ are (probably) embedded development and gaming, and of the two I would recommend embedded over gaming because the pay is better and there are less desperate people trying to get into the field. That being said, it is entirely possible to get a c++ job doing neither of those (and there are probably more jobs doing other things than either embedded or gaming, but it is a much more general field). As for starting with another language, if you look hard enough there are entry level jobs in most of the major languages. For entry level work, I don't particularly think the language matters. You are still going to be early enough in your career that switching languages isn't as big of a deal, and it is more important to pick up good development habits - namely, using version control, testing your code, doing code reviews, etc. That knowledge is useful no matter what the language you eventually end up using is. After you have the good development habits, then you can go deeper into your language of choice.
I actually thought fp was pretty similar in design and aims (esp compared to N3352). A big difference is homogeneous operator return types. The proposal will go into the decision there.
yes, you are right. got it, thx.
C++ is used in every industry you just need to do in depth research and target the correct "faculty" which would benefit from c++. Age doesn't matter and many companies actually a veteran first policy.
The intent is never to promote implicitly. You can use the `promote` function for that. I agree that *safe* may be a confusing choice (better suggestions?) but the guarantee is that the most significant bits are always preserved. That's as safe as you can get without promotion (and rounding).
Yes. Scott Meyers pointed this out in his *Effective Modern C++*. **Even using a reference** for the range variable. E.g. for a `std::map&lt;std::string,int&gt; my_map`, if you had: for ( const std::pair&lt;std::string,int&gt; &amp; p : my_map ) this will create a *copy* of each element that's bound to the const reference `p`. Because the types do not match, but there is a converting constructor. And as you say, this headache would be avoided with: for ( const auto &amp; p : my_map ) 
I agree. I plan to drop `closed_unit` and `open_unit`. Sadly, bit-shifting alone does not get you from 1 to 0xff!
that's not true: 0x20 + 0x0F == 0x2F and doing `&amp; 0xF0` on that will give 0x20. So already aligned addresses remain unchanged.
Embedded Development for all kinds of applications, Automotive industry, home appliances you choose. C++ is versatile.
Who's actually using this library? To me it seems a lot of posturing and using fancy names like monad for fairly simply extensions of existing stuff. I'd also like to see a reproducible performance benchmark. The key question is: "what will we miss when this library gets rejected?"
...until C++17, where `auto foo{5};` is an `int` (your example is still a `std::initializer_list&lt;int&gt;`).
`auto foo = ...` will infer the type to be a non-reference type, so `auto foo = ...` will do whatever copying is involved in initializing a variable of that non-reference type. E.g. `int x = 3; auto foo = x;` will do copying just like `int x = 3; int foo = x;` does. If you want a reference type with `auto` then you have to explicitly say that with, e.g., `auto &amp;foo` or `auto &amp;&amp;foo`. Or in C++14 you can use `decltype(auto)` which is like `auto` but uses somewhat different rules for inference which mean it can deduce reference types.
It's just that uniform initialization isn't so... uniform, and that the ship has sailed. Personally, I wouldn't mind the special rule for deducing std::initializer_list not being there and then double braces being used to call a list constructor. 
The games industry pretty much universally uses c++. Gameplay is usually implemented mostly via script for dynamic updating and much faster iteration and safety, but are ultimately driven by an engine compiled to native code. I'd imagine any high performance native application work will likely use c or c++ but even as a scripted you're going to be hard pressed to land a job in the games industry without good c++ knowledge.
I think the only time it wouldn't be a copy (other than an explicit `std::move`) is if the compiler can infer that the right hand side is temporary. In those cases, copying is elided and the object is just moved into the left hand object. I might be missing another case but from what I understand this should be it.
IMO I don't think "program management" is a higher tier job, as opposed to the other two. It's just a different skill-set all together. 
Often you want to prototype first in a script language like Python, profile, then write in a compiled language and call them from the python code. It's fairly easy to integrate high performance C with Python backends.
I've been trying to find a reference for this, and couldn't. If you're referring to [this](http://stackoverflow.com/a/15934826/2297365) stackoverflow answer, I think you might be interpreting it incorrectly. I think the author of the answer would still use `for (const auto&amp; x : ...)` for immutable semantics, but otherwise use `for (auto&amp;&amp; x : ...)` for everything else. The case you might be thinking about is if the container itself is `const`, in which case `for (auto&amp;&amp; x : ...)` would return `const` references. For modifiable containers though, `for (const auto&amp; x : ...)` is probably the way to go to enforce immutability.
It really is. However, the thing is, Python is better at "write fast", and C++ is better at "run fast" (in broad generalizations). Some of the most successful projects I have seen were written in Python to prove it could work (albeit slowly), then if you ever actually are annoyed at the speed, you rewrite the slow parts, or even the whole thing in C/C++/similar.
I responded to your comments on the blog post. Thanks for your input, it seems there are a few things I still don't fully understand, and I need to read up on. /u/changetip 100 bits However, one thing I did want to clarify is what you numbered #1 above. This is not defective, it is by design, and the post talks about this. The reason that there is some extra space allocated (and the next alignment boundary is used even if the pointer is already aligned) is because in the future, that pointer will need to be "unaligned" again to properly call free. Imagine a situation where some pointers were changed (aligned) and some pointers were not (already aligned). At the time of the call to free, it would be impossible to know what state it was in before it was aligned, therefore getting the original pointer back couldn't be done. For this reason, the original pointer is saved in the space that was skipped over to reach the next alignment boundary. This is the way the Eigen library solves the issue, I am just replicating their idea.
How do you typically get the original pointer back when it is time to free it?
*glenfe* received a tip for 100 bits. -- [^^what ^^is ^^ChangeTip?](https://www.reddit.com/r/changetip/wiki/tipping-on-reddit)
I replied to your reply: It is still not required. A pointer alignment function should return the current address if the current address is aligned. std::align does it, as does the implementation I contributed to Boost (in Boost.Align). The `aligned_alloc` and `aligned_free` function can be portably implemented in terms of such an `align` function too, as I pointed out in the posts on your blog. https://github.com/boostorg/align/blob/master/include/boost/align/detail/aligned_alloc.hpp
I think I'm beginning to see my mistake. Thanks for pointing me in the right direction, I appreciate the help.
This is awesome, thank you for contributing this!
This is true, I definitely prototype in Python first all the time. But in this particular case, my boss wanted results fast, and wasn't willing to entertain the idea of re-writing code since he had already seen it working. In every industry, quite often the prototype ends up becoming the final product without any further optimisation, mainly for the reason of time and money.
Good code is respected in the moment, bad code never dies 
There are definitely aerospace companies using C++. I've talked to their employees.
To ad to this, if you want a pretty kickass non blocking queue, check out moodycamel on github. I almost feel that with a few tweaks it should be part of the standard library. It is just that crazy useful. 
No, not entirely, and for something like Emacs or bash, it seems rather unlikely at this point. But GCC has switched (and is gradually being refactored), and binutils and GDB are next.
Microsoft hires a lot of C++ developers. Not sure if they have any offices near Chicago, though.
If you miss this, you should be able to find it in the Programs and Features (where you uninstall things) as some Change or Modify option on VS.
C++ is traditionally a compiled language. That means c++ source gets processed by another program, called a compiler or compiler driver, that produces the thing you actually run. This processing uses a bunch of configuration which is what the project file is all about. That's not to say you can't just run a c++ file, but that it's not the normal way of doing things with c++. There in fact are c++ interpreters similar to the python interpreter you use to run Python files. Also you can manually invoke the c++ compiler for a single file to get an exe pretty easily. But once you have more than a couple files it starts making sense to use some sort of project file to handle the process for you, which is the reason it's usually done that way in the first place. --- I'd say start with the win32 console project template. Or as long as you are just working with a single file learn about invoking the compiler directly. There should be a shortcut in the Visual Studio start menu folder that's named something like 'visual studio command prompt'. Use notepad to write a 'hello world' program into a file named `hello.cpp`. Open the VS command prompt and type `cl hello.cpp` (You may need to enter the whole path to your file, or use the `cd` command if you're familiar with that). If compilation works then run your program with the command `hello.exe`.
What about that is depressing?
You want `cl /EHsc /nologo /W4 meow.cpp` by default. This requests exceptions, quiet output, and good warnings. Add `/MTd` for static debug builds (the commandline default is `/MT` static release, last I checked). I type this command literally dozens of times per day.
I find that kinda comical.
`g++ -std=c++14 -Wall -Wextra meow.cpp -o meow.exe` and `cl /EHsc /nologo /W4 meow.cpp` are roughly equal difficulty.
Unless it's code you can't test in an online environment, try http://webcompiler.cloudapp.net/ for testing code with MSVC.
I didn't mean that :) What I meant is that, for a beginner, the approach to create a project, build and run isn't that different. You guys should be proud for producing the best IDE in history.
Good point. Works nicely, if you do not need any 3rd party libraries or disc access.
Yeah, I don't recall anything for MSVC with other libraries or disk access. Others that let you use GCC and Clang do, though. For example, [Coliru](http://coliru.stacked-crooked.com/) has a few libraries and general low-privilege access. [WandBox](http://melpon.org/wandbox) is a bit more explicit on some things like Boost version and has *really* up-to-date compiler versions.
&gt;I checked online and everyone says to use Visual Studio for an IDE But that doesn't mean you *have* to use it right? Especially if you're only just learning C++, or how to use IDEs. VS can be quite an overwhelming IDE, and they moved away from C++ development years ago. &amp;nbsp; Don't get me wrong: VS is a powerful IDE, but if you are only just starting to learn about IDEs, then there are heaps of simpler (and free) options, such as [Dev-C++](http://www.bloodshed.net/devcpp.html) for example, that are much more user friendly for learners.
The primary reason is that when writing something in C or C++, it is expected that it's not a trivial application. Therefore the workflow is not optimized for this use case. You can definitely compile and run a single C++ file. You however should not use Visual Studio, which is optimized for massive projects.
The question wasn't about compiling and running a single C++ file, but about why a C++ file can't directly be executed as Python scripts, thus the more general answer.
I've used it for years when I was working in the printing industry. It's mostly used for image processing and real time stuff close to the hardware.
The thing is, nor clang neither gcc are IDEs, just compilers
If you use the [built-in make rules](https://www.gnu.org/software/make/manual/html_node/Implicit-Rules.html#Implicit-Rules) you can simply do: `make program` E.g.: $ cat main.cc #include &lt;iostream&gt; #include &lt;limits.h&gt; using namespace std; int main(int argc, char * argv[]) { cout &lt;&lt; "INT_MIN: " &lt;&lt; INT_MIN &lt;&lt; endl; cout &lt;&lt; "INT_MAX: " &lt;&lt; INT_MAX &lt;&lt; endl; return 0; } $ make main g++ main.cc -o main $ ./main INT_MIN: -2147483648 INT_MAX: 2147483647 
Congrats to embt! I wonder if they're using clang for 32 bit as well.
Perhaps you should actually read the question. That's not at all what the question is about.
Good lord. Are there any non legacy reasons to use this compiler?
Why would you not recommend using `/O2` and `/Za` by default?! Without `/Za`, VC is seriously crippled (in terms of C++ standard support) and doesn’t even implement ISO646, which is seriously annoying. And unoptimised C++ code simply doesn’t make sense, because every use of standard algorithms is ridiculously inefficient, and the runtime overhead is compounded the more you decompose your code into small building blocks (which is a good thing!). Though I don’t know what code VC produces without optimisation — I just know that for g++ and clang++ it’s never a good idea not to enable optimisations.
I feel like all of the current answers are over complicated. This is my method for doing quick testing in visual studio. A. Compile from the command line by opening the Visual Studio Command Prompt B. Use something like cl.exe /EHsc /Zi main.cpp C. In Visual Studio, you can then simply open main.exe via File Open and hit F5 to debug. D. You can also open the cpp file in VS to edit, but you need to return to the command line to compile it. E. Once you have this setup (takes 60 seconds), you can iterate like this. I think this is what OP wants. I do this all the time, avoiding projects entirely for small tests. 
This seems like more work than compiling from the command line and just opening up the exe for debugging. 
It allows you to use other Embarcadero libraries and it's RAD tools, like Delphi does. Imagine something like .NET WinForms visual editor for C++, and that in recent version can somewhat easily target Windows, Android and iOS. Said that, C++ Builder has been a second class citizen for long time, Delphi being their flagship product.
Well, Builder has VCL, which I have to admit is very good, almost on par with .NET, and reminds me of Qt (minus the signalling). Recent releases of RAD Studio are pretty neat with the cross-platform UI and whatnot. But the stale 32-bit compiler really is holding it back... EDIT: Oh and it's the only C++ IDE I know that ships and supports Boost out of the box
That's not low lantency c++ in banking. Your attempt at condescension falls very flat. Also your last comment isn't useful, banks hardly pay any interest now as they don't need savers.
&gt; moodycamel on github. Here the link: https://github.com/cameron314/concurrentqueue And here a blog post describing it: http://moodycamel.com/blog/2014/detailed-design-of-a-lock-free-queue The benchmark results are amazing indeed, thanks for sharing this. 
"and they moved away from C++ development years ago" Someone should tell STL that, I'm sure he anticipates getting paid for the (great) work he has been doing on their libraries.
&gt;But you can't do that with C++? You can. &gt;It needs to be in a "project?" No. Visual Studio, however, creates a project because people who use it normally create stuff that has more than one source file in it.
Interesting, what kind of development work do you do? Mobile? Desktop? Server? Any particular industry?
I really dislike the IDE. Code completion is painfully slow and the visual designer screams 90's. I mean, come on, no undo??
Interesting, thanks.
&gt;You should be able to do this in VS but AFAIK, you can't... In UNIX... Did you just equate VS and Unix!? Anyhow... I just did this: c:\tmp&gt;dir / b x.cpp c : \tmp&gt;cl x.cpp Microsoft(R) C / C++ Optimizing Compiler Version 17.00.61030 for x86 Copyright(C) Microsoft Corporation.All rights reserved. x.cpp Microsoft(R) Incremental Linker Version 11.00.61030.0 Copyright(C) Microsoft Corporation.All rights reserved. / out:x.exe x.obj c : \tmp&gt;dir / b x.cpp x.exe x.obj c : \tmp&gt; Use the Developer Command Prompt, dude!
I agree. Code completion *is* slow and requires an SSD and a well organized PCH-file to be useful. The visual designer also could use some work. Still if you know your way around with it, you can be quite efficient with it. I have to admit though, it's been some time since I last checked the designer of Visual Studio. Has it improved? It used to be so far behind. Can you design complex resizable C++ GUIs with the comfort C++ Builder/VCL offers?
I don't know how i managed to forget that, but the sparse linear algebra is homebrewed and in c++. That changes the ratio quite a bit, since most of the work is reducing the size of the matrices with lanczos algorithm and the like.
&gt; Example: if you want to do any work on an OpenGL context, it must be performed on the thread re context was created on (or you manage passing it around (which is painful). Side note, I believe this thread affinity issue in Windows was resolved for quite a while now. Basically you acquire context with `wglMakeCurrent(foo, bar)` in the current thread, then release via `wglMakeCurrent(NULL, NULL)` as soon as the task returns. GL calls can be made in other threads, provided the same rules are observed. This is also true with CGL on OS X. Of course, one must also observe the usual mutual exclusion practices when doing GL calls, etc.
Pretty cool, thou I could follow only so far until my brain couldn't take it any more. 
That is what the "make main" line in /u/orbitaudio s example does. Without a makefile it tries to compile TARGETNAME.cc . 
The only caveat in the strict aliasing rules is that any `T*` can also be read/write through a pointer to a character type: `char*`, `signed char*` and `unsigned char*`.
&gt; Scripts are usually self-contained, don't need special options and can be directly executed by the interpreter. While code files with compiled languages need to be passed to a compiler with different options and after that need to explicitly be executed. The options are then saved in some form be it a project file, a make file or just a simple batch script. It is very common to run perl scripts, and hence there is a way to pass options to the interpreter using a special comment. Likewise, some C++ compilers have a pragma to set options. But then, you don't need to pass any options to the compiler of you're satisfied with the defaults: "g++ file.cpp" will compile a single-file C++ program into a binary "a.out", and I believe this also works with Microsoft's compiler ("cl file.cpp" producing file.exe).
&gt; Actually, the two constructors just “look” like each other. There’s some tiny difference in the mangled name. ... otherwise you'd have no way to refer to one or the other, making one constructor dead code. In the end this is just an idiosyncrasy of the linux C++ ABI. One c'tor for yourself, one c'tor for your virtual base. Strange but not insane.
Because Visual Studio is an IDE for making projects; specifically, it's meant for many different kinds of complex projects, the templates for which you are offered when creating a new project. The kind of behavior you desire isn't possibly with Visual Studio _itself_, but since VS includes a C++ compiler, it is possible by installing VS.
I think it's VCL that happened to OWL.
I *love* 2015. Actually I really liked 2013 as well, but 2015 is friggin' *awesome*. Thanks for your work!
Strange that nobody spots the missing virtual destructors in the interfaces. 
STL wouldn't recommend /Za anyway: He says that instead of thinking of thinking of this flag as meaning "request extra conformance", it should be considered to mean "enable obscure compiler bugs". As for support for the ISO646 charset, unless you're actually using digraphs you can instead `#include &lt;ciso646&gt;`. Sure, VC++ doesn't conform, but /Za isn't a good solution until it gets fixed.
Oh, that's interesting. Does it have a way to set default parameters?
That's actually really piqued my interest, in Russian we say daughter class for child class, but parent is still parent, etymology of such things could be pretty fascinating I guess.
I'd set up an alias in my shell if I had to type that multiple times a day.
The only positive (which is a very big positive) is that it is fast to make a GUI that looks good . Every other C++ GUI builder I have tried has been horrible. 
Heh, my tutor 19 years ago described it as "Outdated Windows Library" so I guess it would be even more outdated now :) They replaced it with VCL.
Usually I can just type Up, Enter. I also need to vary it occasionally, so I haven't bothered with an alias. I do use aliases for more obnoxious commands.
Is there a better visual designer somewhere?
I take it he's done picking on lisp and haskell now? This guy's a class-A douchebag.
Qt Designer is pretty nice, for Qt of course. Qt has a somewhat different approach than VCL or Winforms though. 
In Windows, does QT require Visual Studio? I remember looking at QT 5 when considering which framework to use for a GUI project and rejecting it for some technical reason. 
$3000+ Fuck that !
Quickest way to deal with this is to just start an empty project. Right click in the file explorer, select Add new item... and add a cpp file called main.cpp. Write the code, hit f7 or f5 and everything works as expected. 
I saw this somewhere $ cat main.cpp #/* output=/tmp/`md5sum main.cpp | awk '{ print $1 }'` # echo $output # check if source is newer than compiled file if [[ "$0" -nt "$output" ]]; then g++ $0 -o $output fi # exec runs command in current process exec $output # will not reach here cause exec has started $output in this process exit 1 #*/ #include &lt;iostream&gt; int main(){ std::cout &lt;&lt; "hello world\n"; return 0; } $ ./main.cpp hello world
Nope.
I can't stand this project naming itself 'modern'. It's confusing, pretentious, and they refuse to change. I might have followed it if not for this but now I just want it to go away since I keep getting tricked into looking at stuff and trying to figure out what is going on. 
What are the benefits of this over Boost.Asio? What is it trying to accomplish?
It is really helpful for debugging. I will have a release checked build or in the debug build I will have validation logic that I don't want to run when I am running in a production environment
The make variables used can be set using environment variables. This includes among other the c++ compiler CXX and its compile flags CXXFLAGS.
There's no such thing as "C/C++" . 
&gt; Edouard is a C++ enthusiast with a strong taste for template metaprogramming, generic programming, and you're not doing it right if the compiler doesn't crash programming.
&gt; owningVector.reserve(5); This is a micro-optimization of questionable merit, and it isn't even for the right amount. &gt; owningVector.emplace_back(new B(1, a1.get())); Potential leak. &gt; auto predicate1 = [a2](B* b) -&gt; bool {return b-&gt;getA() == a2;}; The explicit return type is completely unnecessary here. **Also, this code will not compile.** a2 is a unique_ptr and cannot be captured by value-copy. &gt; It is simpler to make the second operation generic because the STL already provides a functor that does that job for us : std::equal_to. As an example, we could rewrite the lambda expression using this functor: This is not a useful example because there is no genericity. equal_to isn't buying anything here. Please don't make people hate the STL for being overly complicated when it isn't. This presentation is backwards. bind() and similar library solutions were the past. Lambdas are the future, and the best way to construct small unnamed function objects. &gt; std::bind(&amp;B::getA, std::placeholders::_1); This is unnecessarily convoluted, even ignoring the fact that bind is bad. mem_fn() is what adapts PMFs/PMDs to be function objects. 
If you rely on the compiler to maybe do what a #define would have been guaranteed to do, sure. It's not a PERFECT example, I just meant to show the reasons why you'd want to use a #define instead of just declaring variables for everything.
Because C++ is completely different language.
I don't understand why you think this "pre-build" step (whatever that is) would solve anything. Using the preprocessor is *how you do that*, i.e. how you write and maintain a single codebase that expands to several different versions of the code at build time. You keep mentioning this nebulous tool that would avoid that, but the preprocessor is exactly that tool. 
With the same [preprocessor](https://en.wikipedia.org/wiki/C_preprocessor). So in this context, they are IDENTICAL. People only lump them together when they are referring to things they have in common. Did I hit a nerve or something? Is there some pedantic subtlety I'm missing?
In my opinion the last valid use for `#ifdef` is code that won't compile in a given environment, e.g. if a function from the Windows API on a UNIX system. Even then it *could* be solved another way, for example by having platform specific code in separate compilation units, which share the same interface, and the conditional compilation is in the responsibility of the build system. But that does not change the basic need for different code on different platforms inside a single codebase. So the last absolutely valid use of the preprocessor is header file inclusion, there is no other way. `#ifdef`is quite often used there, too: #ifdef WIN32 // on Windows, include windows.h #include &lt;Windows.h&gt; #endif #ifdef __LINUX // on Linux, include unistd.h #include &lt;unistd.h&gt; #endif 
 &gt;assuming the need for cross-platform code is devised via a pre-step (i.e. some build tool), that generates and takes your code sitting in directory "foo", and makes a "foo-x64", and "foo-x86" and "foo-arm", you get the picture. You just described the C preprocessor. Having a standard way of doing code processing as a pre-step that's built into the language standard, and thus is required for all compilers to support it, is the best way to ensure that code is portable between compilers and platforms. Otherwise everyone is rolling their own competing preprocessors with different syntax and varying support and now you're forced to learn a bunch of different preprocessors instead of just one standard one. Java and C# don't need preprocessing as much for a couple reasons (note that C# actually does have #if): 1) There is only one compiler vendor and they can make monolithic decisions about the language. 2) They compile to bytecode which can be interpreted / JIT compiled on multiple platforms. 3) They have modules.
conditional compilation depending on configuration. #ifdef _DEBUG, etc. Also if you're stuck with Visual Studio you don't have constexpr. If done well, macros can be useful for repetitive code.
VS2015(VC++ 14.0) does have constexpr.
Last time I checked (3 years ago?) basic "hello world"-type examples compiled for like 5 minutes and consumed GBs of RAM during compilation. How's compilation time now?
Now there's a guy who seems to really understand the true spirit of programming, good for him.
Bad for us
The only virtual function is in ITaskSet. This doesn't have a virtual destructor in the base interface because it does not need to be deleted polymorphically. Anyone wanting to do so should indeed implement a virtual destructor.
In french it's the same, but it's certainly because "class" is feminine (une classe)
Yah, I didn't mean it as anything against facebook by any means, I just like to see folks follow their passions
 &gt;And a bunch of cretins who try to "compile C as C++" (meaning using the wrong compiler) for some mysterious reason that they are unable to explain. To play devil's advocate, one of those "mysterious reasons" is "C code exists for what I need. I don't want to do a rush job of rewriting it, but I also don't want to be stuck writing only C. I'll do the minimal amount of effort to make this C code compile with a C++ compiler and move on." Also, there are a shitload of C++ wrappers for C libraries, those are not far at all from just "using the wrong compiler" and adding. I get that you don't like the mindset and you're hung up in pedantic semantics. If I'd said "C or C++" or "C and C++", would you still have complained? &gt;Saying "C/C++" reinforces that mindset. IMO it makes no more sense than saying "Java/Lisp" which, unsurprisingly, doesn't happen very often. Because java and lisp don't have anywhere near as much in common as C and C++. Ever see Lisp/Scheme? The slash is IMO enforcing that they are NOT the same. If they were, I'd just use the two interchangeably. The fact that I said both was to emphasize that it's the same for both languages. &gt;&gt;And why O'Reilly, Eclipse, and Microsoft are mistaken? &gt;Sorry, haven't got all day Ok, so you are right, and everyone else, including large and widely respected software and software related companies are all wrong. Oh, and if you Google for "C/C++ Reference", you'll find a page with that title that just happens to be linked in the sidebar of this subreddit. 
&gt; This is not something that I want to do, and C++ doesn’t require it. :-/ Right, C++ says that `&lt;ciso646&gt;` is not necessary for using alternative tokens. However, VC++ doesn't conform so if you want to use `and`, `or`, etc. without using the buggy `/Za` flag then this is how you can do that. This is hardly a large burden compared to other things one has to do for compatibility between many platforms, all of which are non-conformant in some way or another.
No, you.
&gt; Using the right one of "C or C++" or "C and C++" for the situation would be a big improvement, yes. [The slash is most commonly used as the word substitute for "or" which indicates a choice (often mutually-exclusive) is present. (Examples: Male/Female, Y/N, He/She.](https://en.wikipedia.org/wiki/Slash_%28punctuation%29) I hope you see how ridiculous it is to object to "C/C++" but be perfectly ok with "C or C++" when "/" means "or". You're fighting a pointless semantics battle. &gt; This is the whole point that I am complaining about. C code should be compiled by a C compiler. There is no reason whatsoever to try and compile it with a C++ compiler. I just listed the reason. When you are reusing existing code, you can't always use two different compilers. C isn't happy with C++ headers, for example. So now you have to make sure you segregate the code everywhere. It's not impossible, it's just a royal pain in the ass when the much easier and often better solution is to say "Ok, all this C code is C++ code now. It's all written 'wrong', and we can fix it later, but it is **technically** valid C++ code." C is (usually) valid C++. It's not GOOD C++, but it's valid, functional code. &gt; There is no rewriting needed. Just use the right compiler. Exactly. No rewriting needed is exactly the reason why it's done. If it were the "wrong" compiler, the code wouldn't compile. C is valid C++ code, so a C++ compiler is a valid choice. Again, VALID!=GOOD. Compilers don't care if code is "good". &gt; Every C++ compiler comes bundled with a C compiler. The compiler even automatically selects language based on the file extension, in most cases. Yet these people will go and foil the compiler by changing the file extension and then waste time making unnecessary changes (and act all surprised if anything breaks as a result). You know full well people aren't compiling C code with C++ compilers because they don't have a C compiler. It's because they have C code and they want to be writing in C++. Sure, it's sometimes the persons own fault for making a poor choice. Some people learn C and just decide that because they read the "Learn C++ in 24h" book that they can just swap over to a C++ compiler and throw some `cout`s in there and call it a day. Plenty of times it's the right call, though. Something was written in C. Don't know why, doesn't matter. It happened. It was somebody else. They've since retired. The code is here and it works. And you're tasked with working with it. You can: - Stick with C (ugh, why) - Segregate the code. Existing code is C, new code is C++. That's a fucking disaster. I don't care if the compiler is happy - the programmer isn't. Now if I want to add something, I might have to write it twice. Or I'll end up converting data back and forth between different types at the boundaries. - "Convert" the project to C++. Which just means changing the compiler, because C code is valid C++. It is. I know you hate that, but it's true. In a perfect world, you'd just re-implement all of the C code in C++. Go through every appropriate design pattern and really C++ the hell out of it. It would be fantastic. But you'd also spend 6 months writing code with nothing to show for it. In the real world, people don't do that. They write wrappers. They reuse C code in C++ applications. Heck, a lot of "C++ libraries" are actually just C libraries. Zmq and RabbitMQ C++ bindings come to mind. Zmq is pitifully just C code with a couple C++ bits thrown on the top layer.
Am I the only one who misinterpreted title?
&gt; C isn't happy with C++ headers, for example. C++ is happy with C headers (for the most part). In fact C++ is specifically designed to allow inclusion of C headers and link against code compiled with a C compiler. Specifically so that working C code does not have to be fucked around with. &gt;If it were the "wrong" compiler, the code wouldn't compile. C is valid C++ code, This is just not true. I could give hundreds of examples of valid C that doesn't compile as C++. More insidious are the cases where it still compiles without warning, but has a different effect, or causes undefined behaviour. &gt;Existing code is C, new code is C++. That's a fucking disaster. No it isn't. It's a hell of a lot better than using the *wrong compiler*. &gt;In the real world, people don't do that. They write wrappers. They reuse C code in C++ applications. Heck, a lot of "C++ libraries" are actually just C libraries. Yes. They write wrappers. They leave the C code unchanged. The ones who actually have a clue compile it with a C compiler, and write C++ wrappers or bindings. &gt;Zmq and RabbitMQ C++ bindings come to mind. Zmq is pitifully just C code with a couple C++ bits thrown on the top layer. I haven't used those projects, but I checked their github and they both seem to be written in C++. It occurs to me that we might be talking cross purposes. It is fine to convert a C project to C++ . After conversion it is a C++ project and no longer a C project. Perhaps that is how the history of those two projects you mention went. What is not fine is trying to maintain a project that is correct in both languages. That is just a colossal waste of time and leads to code that is bad style in both languages. The ZMQ and RabbitMQ developers have clearly not made that mistake. There is also no need to convert a project that does not need converting. In the case of ZMQ etc. I suppose that they felt the added productivity of converting to C++ was worth the time taken to perform the conversion. Fine. But in the general case there is no need to even spend any time breaking something that is not broken. An example that comes to mind is the "expat" library for XML parsing. It's written in C. Nobody thinks it is a good idea to convert it to C++. It works well. Many people , including myself, use it in C++ projects. We just include the header, build the .c file (with C compiler) and bob's your uncle. I think all the "compile C as C++" crowd do not realize that this is actually possible. 
&gt; C++ is happy with C headers (for the most part). In fact C++ is specifically designed to allow inclusion of C headers and link against code compiled with a C compiler. Specifically so that working C code does not have to be fucked around with. Sure, that works in that direction. And it works fine when the C code is nicely segregated and not changing. Using existing code isn't always as nice as just calling a convenient C library. It's more often disjointed functions and data types all over the place. And when you want to call a C++ function or use C++ data types from your existing C code, NOPE. Not unless you use the "wrong compiler". &gt; This is just not true. I could give hundreds of examples of valid C that doesn't compile as C++. Yes, I stated at least a few times in these comments that there are some differences. Some places where valid C is not valid C++. &gt; More insidious are the cases where it still compiles without warning, but has a different effect, or causes undefined behaviour. That's a really really rare corner case, and usually only when somebody was doing something dreadfully stupid to begin with. Like making assumptions about how data will exist in memory, for example, which will burn you just changing from one C compiler to another, or one architecture to another. &gt; It is fine to convert a C project to C++ . After conversion it is a C++ project and no longer a C project. So we are in agreement. But it's an interesting subtlety. It's not ok, in your opinion, to compile C code with a C++ compiler. "It's a different language". Ok. But if you "convert" (make it compile and work with a C++ compiler), now it's ok. So long as you call it C++ now, and don't call it C. You might see where I'm going with this. The people who would do something blasphemous like compile C with C++ compilers are doing exactly that. They aren't planning on later going BACK to C or anything. And they are obviously going to be fixing whatever pieces don't work with the C++ compiler or they wouldn't have gotten very far. &gt; What is not fine is trying to maintain a project that is correct in both languages. That is just a colossal waste of time and leads to code that is bad style in both languages. The ZMQ and RabbitMQ developers have clearly not made that mistake. Now that I can agree with. It's a royal pain in the ass trying to maintain headers that are valid C just to keep the C pieces happy. With ZMQ especially, the wrapper is C++, but the *style* is C, if that makes sense. Data types are all still structs, functions are a direct 1:1 mapping with only minimal C++-ish improvements. They did what you said was the royal pain in the ass - maintaining a single code base that does both. It's pretty miserable. &gt; There is also no need to convert a project that does not need converting. In the case of ZMQ etc. I suppose that they felt the added productivity of converting to C++ was worth the time taken to perform the conversion. Fine. But in the general case there is no need to even spend any time breaking something that is not broken. And in fact, it was NOT worth it. The C++ wrapper is so bad that it was better to just throw it out and use the C library. But it's hard to know that kind of thing looking from the outside before you start using it. &gt; An example that comes to mind is the "expat" library for XML parsing. It's written in C. Nobody thinks it is a good idea to convert it to C++. It works well. Many people , including myself, use it in C++ projects. We just include the header, build the .c file (with C compiler) and bob's your uncle. I think all the "compile C as C++" crowd do not realize that this is actually possible. That's true. The difference in effort between those two options is minimal (until you end up in the C that isn't valid in C++ corners like you mentioned), so there's no good reason not to use the correct compiler.
Does the same happen with pointers? What about shared_ptr? I started using auto* and auto&amp; just for the sake of clarity, not beeing aware that there are actual differences. However the same doesn't seem to be possible with smart pointers. I rather often have to think about whether something is a pointer or not. auto x = returns_shared_ptr(); x-&gt;foo; // or is it x.foo? Seems to be a good case against auto.
&gt; Does the same happen with pointers? That depends on what you mean by 'the same'. Pointers are values and objects just like any other, so use can use `auto x = ...` to get a copy of a pointer value. Similarly, smart pointers are also just regular values and objects. If you're thinking purely in syntactic terms (i.e., "Are qualifiers like `*` stripped away like `&amp;` qualifiers) the answer is no. &gt; However the same doesn't seem to be possible with smart pointers. If you like writing `auto *x = ...` for clarity then the concepts TS has something you might like: You can write `shared_ptr&lt;auto&gt; x = ...`.
I've always seen erase remove used to remove a range and correctly using the 2nd overload. If you assumed that it only removed 1 item why not use `vec.erase(std::find(vec.begin(), vec.end(), pred));` https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Erase-Remove 
You are right, it would - I was just commenting that if his original assumption was that only one element would match why did he use erase remove? My comment was more trying to point out that erase-remove idiom requires using the 2 param overload which always involves removing a range of elements. So the authors issue here isn't an 'erase remove gotcha' more of an issue of not understanding the idiom.
Should be great when this becomes the idiomatic way. #include &lt;experimental/vector&gt; std::experimental::erase_if(vec, [&amp;orig](auto const&amp; msg){ return orig.id == msg.id; }));
It's totally a gotcha. Have you never forgotten to provide an argument to a function? To me, it's quite like a typo and sometimes happens to me, but when it does, usually the compiler/stdlib is nice enough to yell at me. In this case it silently accepted the code, only the results were completely unexpected. As for erase/(find/remove) - I wanted to remove 0 or 1 elements and I find it nicer to write `v.erase(remove_if(...), v.end())` rather than `auto it = remove_if(...); if(it != v.end()) v.erase(it);`. Pardon the terseness.
This was one of my rationales for `erase_if()`. [N4009](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4009.htm): "Trap #2: The erase-remove idiom can suffer from silent typos."
In the specific case where you need nested bind, then yes, mem_fn won't activate it. But nobody needs nested bind now that we have lambdas.
I would recommend a newbie start with Visual C++ just for the debugger. If you are learning C++, you really don't want to fiddle with GDB. C++ is overwhelming enough as it is.
Nested binds are required when C++11 is available but C++14 isn't as C++11 lambdas can't provide the same flexibility as nested binds in a generic context. Now it is true that the article uses some C++14, but this is meant to simplify the boilerplate code and to make it easier to focus on the parts of the examples that are relevant to creating predicates. Is std::bind still relevant from C++14 onwards? My article isn't taking part in this debate and neither is this comment.
remove() and remove_if() are weird. They move good elements to the front of the range, leaving the back of the range filled with elements in an unspecified state (they may be unchanged, modified, moved-from, who knows). Then you must ask the container to physically erase them. remove() is a non-member algorithm which cannot modify a container's size. As I mentioned elsewhere here, I solved this by proposing erase_if(), which was accepted into the Library Fundamentals TS. This means that you can forget about the erase-remove idiom completely.
Oops. You're absolutely right. It should be ok now.
&gt; remove() and remove_if() are weird This is why you should name your functions carefully. If remove doesn't remove anything, it shouldn't be called remove. I admit that I can't come up with a good name for it (it's sort of like... a dirty partition?)... but neither did the standard committee.
Well in Russian, class is masculine and daughter as adjective is used with both masculine and feminine words in that sense, so must be some other reason in this case, like better pronunciation for example :)
Yes, had that bug.
My [implementation](https://github.com/movatica/cpp-algorithms/blob/master/include/container_patterns.h#L101-L115) on github, if you're interested :) 
Making it the default would probably break stuff.
Yeah, the C++ committee jumps through hoops to try not to break existing code. When they brought constexpr into the language it would have surely broken a lot of code.
The deepest reason is: constexpr is not just a property, but a **guarantee**. Marking a function constexpr doesn't just say "I can be used at compile time", it says "my interface guarantees that I can be used at compile time, and this will be upheld by all future implementations".
I was surprised in an old English-language discrete math textbook when they started talking about "father" and "son" nodes in a tree. Personally I picked up mother/daughter/sister from somewhere (I'm American) and I still sometimes say "sister node" instead of sibling. With classes I always use parent/child though.
Is there a reason why you take the predicate by value? From the top of my head I'd employ perfect forwarding.
Solid answer. Now, why aren't class member functions `const` by default? (Aside from breaking all of the backwards compatibility.)
That's back-compat, like all of C++'s undesirable defaults (implicit ctors, fallthrough, etc.). Note that lambdas were able to fix this.
My [implementation](https://github.com/Cleroth/stlx/blob/master/include/stlx.h#L229-L233), although I'm sure you won't be interested. :)
The elements that match get moved to the end.
`swap_with_end_element_if`
I don't understand what you're saying at all. The elements that _don't_ match (by matching I mean that the predicate returns true) will be at the front of the range, and those that don't will be after it. That means they'll be at the end. The end result means that the elements that match get moved towards the end. If they were already at the end of course they don't get 'moved' at all. The implementation is irrelevant.
In an embedded system, the variable value doesn't necessarily need to end up in the object (depending on how it is used). Think of it as the difference between a global const and a #define.
Oh, yea. That makes sense. I guess I've never really thought of using the 'removed' range from remove_if. In that case you're right. Having a move_to_front_if is the one that would work, where move_to_front_if_not would be the equivalent of the current remove_if.
Like it.
If it swapped the elements, it would be more or less the same as using `std::partition`. The fun in std::remove_if is that the elements at the end are in an undefined state, so the implementation can afford to use less costly operations. The implementation *could* swap the elements, but the most sensible way to implement this would be moving/copying the valid elements in the back into the slots occupied by non-valid elements.
What about a more short and simple, `std::cull`. Cull the wheat from the chaff. Or culling in graphics, although so far I've been using `std::partition` for that.
Having a pre-processor not part of the language is the same as having no pre-processor, or a million different pre-processors. It is chaos.
That's nothing to do with `constexpr` or embedded systems. Any variable could be optimized out if the compiler deems fit. 
Yo lambdas are da shiz don't be spreadin yo negativity.
This feels wrong to me? Like if I'm compile-time initializing another thing, say an array, from some constexpr, that constexpr needs to be available at compile time in all cases, no?
Also, "constexpr by default" in the sense that the OP means ("please precompute this if you can) probably is already what happens inside compilers, I would be surprised if a constexpr-capable compiler wasn't already precomputing any function that can be even if not declared constexpr.
Yes, I know why they use iterators. I understand you sometimes want to sort a partial container, find the maximum of a partial container, or run whatever algorithm on a partial container. Still, even with that in mind, the `&lt;algorithm&gt;` include should have been designed better. For example, these algorithms could have received a "range" object (not a range in the C++17 sense, just basically a `pair` object with `begin()` and `end()` that return the `first` and `second`) So that you could do by default std::sort(vec); if you wanted to sort a whole vector, or std::sort(std::make_range(vec.begin(),filtered_end)); to sort a part of the range See? You didn't lose any functionality, but the usage of the algorithms is now clearer Also, doing that `std::multimap` could have returned a `range` when using `equal_range` instead of the stupid `pair&lt;iterator&gt;` it currently returns... ------------- How will that help the erase/remove idiom? Well, if we have the `range`, it would make sense that `remove` returns the `range` that needs to be erase instead of the new `end`. And it makes sense that `erase` gets a range of elements to erase. So the idiom becomes: vec.erase(std::remove_if(vec,func)); And I did that without losing any functionality AT ALL, because you can always do: vec.erase(make_range(std::remove_if(make_range(vec.begin(),vec.end()),func).begin(),vec.end())); which in C++11 with `initializer_list` overload would look like this: vec.erase({std::remove_if({vec.begin(),vec.end()},func).begin(),vec.end()}); which means it's practically identical to the current version in all use cases, and much much clearer in most common use cases.
I wasn't aware of the definition having to be visible actually. I guess until they change that then there's no point having this discussion since it's quite a big negative. kingofthejaffacakes pretty much answers my reason for why variables could be marked constexpr implicitly, another is that you need constexpr arguments to constexpr functions so that would be another reason to do it.
No, this is separate. How they tie together is that it's the `operator()` member function of lambdas that is `const` by default.
The whole point of constexpr is that you can do things with constexpr functions that you can't do with normal functions. Constexpr is part of a function's interface - people need to know "is this constexpr or not" in order to be able to know in what contexts it can be called. For example, let's say I want to do constant initialization of a static. I need a constant expression for that. Can I call func() or not? Maybe? Depending on how the compiler feels that day? And if someone changes implementation of func() or upgrades the compiler in the future, will it break my code? And no, optimization has nothing to do with constexpr. The compiler will *already* inline functions it deems fit, constexpr or not.
I didn't know you can mutate a lambda. How does that work? What gets mutated?
C++14 added dual-range equal/mismatch/is_permutation, at least.
That makes sense, thanks.
`cull` doesn't sound any better than `remove` to me, it has similar connotations of item removal. 
Did you write that? If so - I have a couple of suggestions: replace `size` with size_type size() const { return end_-begin_;} I know it doesn't always work, (only in random access iterators) but that's the point: the function will only work if it's O(1) to calculate the size. People expect `.size()` to be O(1). If an iterator isn't random access, you shouldn't give people this function that acts differently than what they expect. Instead have a `distance` function that always works (just like `std::distance`). the `const`-ness of `front` and `back` are wrong. It's not how iterator `const`-ness works. There should only be the `reference` version of `front` and `back`. If you want a `const` version of the `range` (as in, a `range` where you can't change the values) it should be a `range&lt;const_iterator&gt;` rather than `const range&lt;iterator&gt;`. Notice that the protection you're trying to set with your `const_reference` version of `front`/`back` is a false protection: you are not really protecting the values in the range, as you still allow people the ability to change them using the `begin` / `end` functions. So your class isn't protecting the range values if the range is `const`. Suggestion for additions: I like to add an `operator*` and `operator-&gt;` that gives you access to the `begin` value: reference operator*()const{return *begin();} iterator operator-&gt;()const{return begin();} an operator `bool` that returns `true` if the range isn't empty operator bool()const{return !empty();} and adding an `operator++` (as well as all other arithmetic operators), which changes `_begin`. allows me to easily loop over ranges: for (auto my_range=get_range();my_range;++my_range){ my_range-&gt;do_something(); } (I know that the range `for` would be easier in this case, but this gives you more power in some cases). Also, add a `make_range` from an `std::pair&lt;iterator&gt;`, just for the `multimap::equal_range` function... and I would add a `make_range` from any container as well just so you can use the additional functionality that `range` gives you. Finally, and this is the thing that took me most of the time when writing my own range, you should "translate" all the algorithms in `&lt;algorithm&gt;` to accept your range. Basically a lot of functions that look like this template&lt;class ITER&gt; void sort(range&lt;ITER&gt; r){std::sort(r.begin(),r.end());} I personally wrote a script that did the translation, but still had to go and manually fix a lot of stuff. Very annoying, but worth it!
The discussion is getting pretty heated, with choice quotes such as: &gt; I therefore submit that this "review" is merely the latest &gt; instance in a long sequence of harrassment by the reviewer, &gt; and is not a fair review. It should therefore not be counted &gt; as one. &gt; &gt; I genuinely do not understand what about me so infatuates him, &gt; but I wish he would stop and leave me alone. 
Google aside, how about a bit of hyperbolic license perhaps?
Programmers being cats. Nothing new to see here :)
Just out of interest, what was the first library?
Your post title conveys the exact opposite of what the quoted message is saying. If you wanted hyperbole, something like "AFIO for Boost given kiss of death" would be more accurate (albeit just as silly)
Hey! I'm not that old! :-P
the boost.http(_server). Bringing a server side only http library called boost::http wasn't that well received.
yikes. I remember raising an eyebrow that some of the documentation around boost::http sounded a bit immature and non-professional - seemed to be doing a bit of a hard sell in the tone. these threads are on another level. I'm a bit confused though. http documentation says "Vinícius Oliveira" while AFIO documentation says "Niall Douglas" and "Paul Kirth" 
2 libraries, but different authors.
yes.
&gt; Sadly, the author decided not to answer a single of my questions (not even did he directly respond to any of my emails) Maybe a queue was blocked somewhere.
&gt; I therefore submit that this "review" is merely the latest instance in a long sequence of harrassment by the reviewer, and is not a fair review. It should therefore not be counted as one. &gt; &gt; link? 
I see - Thanks!
It's a bit funny that Niall is in this case the one so strongly arguing to reject the library, while the library author stands his grounds. There seems to be so much drama between these people, it's really sad. That whole thread evolves into a discussion about the [BestPracticeHandbook](https://svn.boost.org/trac/boost/wiki/BestPracticeHandbook) on the boost trac. It's a bit telling how Neill also brings up his family time in that discussion. Seems to be a big issue for him. Remember: How you spend your time is your own choice.
&gt; not an issue anymore. Author moved some critical parts like spirit parser grammar to cpp files so you compile them only once when you build the library. 
got any idea, why they dont stay back-compat by something like extern "C++98"{} So the new standard could declare functions and variables, eg, default const.
Unless you were born this year, I'd say your chances are probably zero that the university/academic system adapts to accept anything else by the time you get to writing papers... (but even if you were, I'd think your chances would be very slim)
His cat starved to death. More drama!
fixed
Slides (PDF): http://www.vollmann.ch/en/presentations/atomic-counters-accu-2015.pdf
Hm ok, I think I got it. Indeed it seems to be a bad idea to have front()/back() here.
AFIO as an idea might be impressive, but in its current state the implementation / documentation is a far cry from ASIO's. All those `#if 0`, weird abstractions (shared_ptr everywhere?) and a lot of hyperbolic claims about performance can't camouflage that this is a pre-alpha quality attempt at a proper AFIO library.
FYI, `operator bool` is almost always a mistake. It allows code like `obj * 5` to compile (you get a user-defined conversion to `bool` followed by a standard conversion to `int`). You would want `explicit operator bool` instead. 
yes, when looking at the library and comments, it seems to be the way that there is a mismatch between idea and library...
The point of the example is to show how to generate each line of the calendar lazily with minimum look ahead. Your solution is nice but it has to process each year completely first. An approach like that won't work for processing files that are larger than a couple of gigabytes. The range-v3 example demonstrates how to use the library to solve that kind of problems, with reusable building blocks, and also how to build your own ranges (the chunk by range is not needed since it is already provided by the library but the D example also shows how to build new custom ranges and it is a "tutorial" after all, there is an accompanying presentation on youtube explaining it step by step).
I don't disagree with you, but that example is "just" a C++ translation of the article "Components Programming in D" and follows the spirit of that article. Nothing more nothing less. The whole point of that article is to show how to build reusable code that performs well. The constraint that makes it an interesting problem is that the only storage allowed is a single string for a single line. Without following that constraint (which both the C++ range-v3 version and the Rust version follow) you are just solving a different problem. There are other examples in range-v3 that show e.g. how to use getlines to process a file line by line instead of loading it into memory at once. 
This is not a sub for C++ questions. Try /r/cpp_questions As a quick look, you need to prefix your method declarations with `void`, otherwise that code is ill-formed.
As was already said /r/cpp_questions I advise you drop strcpy and family for string manipulation. Use std::string. Much less error prone and better interface for string manipulation.
It is quite a safest macro pattern to use compared to some macro trickery I've seen. Don't think code generation will get any better anytime quick. Best learn the tools that are available now or go with a 3rd party solution/dependency.
For printing and taking notes.
Yea, I think I agree with you. Thanks for the input!
Embarcadero has one thing going for it, its free. Oh wait...
Yes, exactly
&gt; That whole thread evolves into a discussion about the BestPracticeHandbook on the boost trac. No, this OFF-TOPIC discussion moved to a different thread after Rodrigo Madera's request. Discussion around design/motivation/... on Boost.Http continued. So, I wouldn't say "that whole thread".
The benchmark is a bit old. std::regex was not included. From my experience Visual C++ 2013 has a way faster regex implementation than MinGW GCC. Maybe /u/STL can shed some light. IMO std::regex should be fixed if it's slow. Edit: [std::regex_constants::syntax_option_type](http://en.cppreference.com/w/cpp/regex/syntax_option_type) has an option `optimize` which should do what RE2 does. It would be nice to know what std::regex implementors have done and how this compares with RE2.
Massively lazy question, but having spent a few hours looking at cppnetlib, can anyone outline how this library is different? I think they're both based on ASIO. At a guess, this looks to be more callback-based; cppnetlib instead seems to hide futures inside its [response object](http://cpp-netlib.org/0.10.1/reference/http_client.html#asynchronous-clients).
If someone answers this, what's the difference between those and proxygen?
How does this compare to Casablanca performance wise?
I'd give you gold for that post, if I had any. :-P
Yeah, that's a known and especially obnoxious bug. Regexes which request excessive backtracking can cause us to stack overflow.
Well, recursive descent sucks in my opinion, but I am tired of flogging that particular dead horse! Instead, may I suggest a DFA mode for one of the `flag_type` enums in the `std::basic_regex` constructor. Actually, I would have thought the existing `grep` mode would be the ideal candidate?
libc++ has some regex improvements planned for 3.8, as we can see from their updated [TODO list](http://reviews.llvm.org/rL245864)
Nice, interested in the sequel to see the benchmark numbers. There are other libraries that provide such functionality, e.g. [Scattered](https://github.com/gnzlbg/scattered) by /u/gnzlbg/. It would be nice to get some stuff like this standardized/boostified.
Thought some of you might be interested. Scott's books are always a good read. Edit: make sure to switch from "rent" to buy.
&gt; There are other libraries that provide such functionality, e.g. Scattered by /u/gnzlbg/. In hindsight scattered is too complicated and tries to fight against the language too much (or maybe i'm just older). I've been considering rewriting it using Boost.Hana to fix some low-hanging fruit problems it still has, but the biggest ergonomic issues cannot be fixed in C++ today. Maybe someday. &gt; It would be nice to get some stuff like this standardized/boostified. IIRC SoA/AoS transformations was on the initial use-case list for Study Group 7 (compile time reflection). `BOOST_FUSION_ADAPT_STRUCT_XXX` macros are really good (for a library solution), but to me they feel brittle and are a hack. 
Yeah, that's a book I'd buy a dead tree copy but for that price I'll suffer on my kindle.
For students, you can often fill in a form at your school's library to have them purchase the book. I did that for most of the books I wanted to read and kept some for a few months at a time by extending my reservation online.
Syntax options should be orthogonal to NFA/DFA use.
For me it's $10.61. Might still buy it, though. His other books were great.
Realistically, this won't happen (particularly with back references). You can see Russ Cox's notes on RE2 (https://swtch.com/~rsc/regexp/), and TRE (linked on that same page) is well worth a look if you have time. My point is that grep was originally written using a DFA and that the irregular expressions from Perl/ECMA are very hard indeed to do using a DFA. One feature that *is* easily implementable using a DFA is non-greedy repeats, despite popular opinion. If that interests you, let me know as I have an implementation.
And... it's gone
Is there a particular reason why this is being heavily down-voted? I'm not the best of writers, but I'm wondering if I've produced something that I've not communicated well to C++ users (when my goal was the opposite). Or if FD is just not that compelling for C++. Thanks.
Asio is on its way to ISO C++ as a TS. The less dependencies the better. Unless there is a real case for this. One needs to benchmark first, to see if RE2 really brings an advantage. Too bad RE2 doesn't have a std::regex compatible interface. In the future I think it would be better to use std::regex and std::asio.
relevant username :P
~~Well you should've at least mentioned "Kindle" edition in the title... quite misleading like this!~~ Turns out my reading skills are 0/10. Sorry about that :)
perhaps the recently formed [SG14](https://groups.google.com/a/isocpp.org/forum/?fromgroups#!forum/sg14) will take over these kinds of initiatives
Agree that less dependencies is better, RE2 should be an optional dependency used only when available. Also agree it would be nice if RE2 had a std::regex compatible interface, however if I am not mistaken, RE2 predates std::regex by some years.
Surely regex::optimize should attempt to compile a regex as DFA first, up to some bounded memory limit, then compile to NFA only when absolutely necessary? I realise that the standard (deliberately) says little about the requirements for the implementation of this flag. An alternative would be to provide a function to manually convert an NFA to DFA (via the powerset transformation).
I really like catch as an easy to set up alternative.
if you can't grasp those concepts 1) you're not even a beginner 2) you're very far off from implementing PBRT maybe you should start smaller, PBRT is an intimidating read even for an me, even though i'v been using c++ since the early 2000's
ISPC actually does the same thing
[removed]
I dont know that you are being downvoted, and if that is the case it is probably based on title, but... The article is very long and fragmented. I couldn't immediately see where the insight or new information that would make it worth reading was.
Could anyone explain or link to some docs that might help me understand this bit of code &gt; friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const account_state&amp; obj) &gt; { &gt; return os &gt; &lt;&lt; "initial_balance: " &lt;&lt; obj.initial_balance &gt; &lt;&lt; " withdraw_amount: " &lt;&lt; obj.withdraw_amount &gt; &lt;&lt; " final_balance: " &lt;&lt; obj.final_balance &gt; &lt;&lt; " success: " &lt;&lt; obj.success; &gt; }
It essentially lets you pipe your object to cout or logging with the &lt;&lt; operator. It also allows chaining.
I said Ebook at Amazon. What the hell edition did you think it was?
Thanks!
Thanks!
I looked at the examples and the API and my first impression is that this looks like a really interesting RESTFul web server! :-) In addition to the overriding goal (serving resources) it would be great if it added some core web server features (which I couldn't see any support for, at my first quick glance) like: support for TLS, websockets and http/2.0. Do you have any plans for such features?
C++ Builder 10 Seattle (I know, odd name) now has C++11 support for all targets except OS X. All based on CLANG 3.3 except 64bit iOS which is based on CLANG 3.5. Seems quite good in the time I have played with it. - code completion is much faster - boost 1.55 is used for all CLANG based compilers - finally, parallel compiles, up to the number of CPUs in the system. - very compatible with existing code - (edit) IDE now uses a big memory model, no more out of memory errors - (edit) while IDE seems much faster Try the free version before dismissing it completely. 
The reality is that there are many codebases in both open source and corporations which aren't taking advantage of C++11/14 features and compilers for legacy reasons. Many of these projects still need to be supported and built upon into the future -- and that's where these books shine and become invaluable. So yes, it's outdated, but it isn't irrelevant.
I'd say a significant portion of it is not outdated, even if you only have a modern C++11/14 codebase. I'd recommend you read "Effective Modern C++" from Scott Meyers, which complements the previous books and adds C++11/14 and also replaces some older things. After reading it, I think you'll have a better feeling of what's outdated in the older books and what is not.
$978 for the professional version which is all you need unless you are doing enterprise level DB stuff. 
Oh wow, you're certainly correct. Sorry about that. I read the title several times, but I not once saw the "E" in "Ebook"...
Catch is hands down my favorite testing library because it gets out of the way except for its assertion macros. Also a single header with no compiling step is pretty great too. :v
Sometimes I fear that people can misunderstand how the features of C++11/14 work without reading older books.
Looks good for quick hacks. I always hated using pcap APIs directly 
Using this library. Its pretty decent.
If you downvote me, please explain why so I can learn from it... No-one will learn from it if you don't explain why
Google Test is also easy to set up using the fused version - only need to add one file to the build (two if using Google Mock).
Builds on CDSChecker: A Model Checker for C11 and C++11 Atomics - http://demsky.eecs.uci.edu/c11modelchecker.html - http://plrg.eecs.uci.edu/publications/c11modelcheck.pdf 
The title is a bit misleading at best; it should probably say "CopperSpice project forks Doxygen" or at the very least "CopperSpice announces a modernization of Doxygen called DoxyPress". It's not like Doxygen was abandoned--they just forked it because it "was not sufficient for accurate C++11 API documentation" (and it seems to me like they are in kind of a forking mood). That's literally the only thing they have to say about their relationship to the Doxygen project: &gt;• Discovered Doxygen was not sufficient for accurate C++11 API documentation Which, it's not like they're doing anything wrong, but it still seems kind of tacky. Can we at least avoid treating this like the anointed successor to Doxygen (unless there's been some anointing that I missed)?
There are actually issues with Doxygen understanding C++11 and major problems with the internal code. We had difficulties generating documentation on several projects over a period of time. Forking the project was the only viable option since the code was not maintainable as is. Over the course of our development we have resolved several existing problems and enhanced the generated output. Our beta testers have enjoyed the new functionality. We are committed to the success of DoxyPress and if you are looking for a new product we believe we have something to offer. Barbara DoxyPress Developer
It seems devel_watcher is fearing that for instance, one might not understand that a lambda is syntactic sugar for a function object, rather than outright magic. I imagine that if one is interested in knowing how something works, one will look it up. devel_watcher has a tendency to be extremely condescending, so I would not worry about it if I were you.
&gt; Wrote new makefiles to build DoxyPress with GNU Autotools I don't see favouring autotools over CMake being a feature. *edit* Where is the source repository? I can only find a source tar ball. I'd like to see the commits.
&gt; Last release which will run on Windows XP and Windows Vista &gt; This is expected to the be the last major release of Clang that will support running on Windows XP and Windows Vista. For the next major release the minimum Windows version requirement will be Windows 7. Why? I mean, why would they care which platfrom their stuff runs on? Not like there is a lot of system specific code in clang, and the runtime for the user to keep updated.
Ugh, I thought they'd use JSON to make config more structured, like `{"dot": {"path": "/path/to/dot"}}`. But nope they use single-level config with fields like "DOT-PATH". Also I guess there are no comments nor trailing commas.
A condition variable is one of many terms used to refer to a synchronization mechanism that blocks a thread until a condition is met. You might be familiar with a different term for it like a monitor.
I've become increasingly convinced of late that better way of using C++ to serve webapps is to use WebSockets and WAMP or, if you're nailed to the floor and forced take an abomination for a ride, JSON-RPC. Imho, moving the HTTP server in to the app is a step taken far too often. For starters, I don't trust any of these C++ "Oh, HTTP? I can do that" libraries to actually get HTTP right. Secondly, it's inevitable that as your projects grows you're going to outgrow the framework and want access to something it doesn't provide, like the cookie jar, or header injection, or custom header parsing, and then your nice lightweight webserver library steadily becomes Apache compiled in to library form. Served already has signs of a plugins infrastructure. Finally, all projects like this are walking eyes-closed lalalala'ing in to the murk when it comes to HTTP/2 support. Otherwise, this looks like a really clean, well done implementation. It reminds me of [Crow](https://github.com/ipkn/crow)
"*the* modernization of Doxygen" sounds like an upgrade similar to the C++03 -&gt; C++11 one, while the actual situation is much closer to Node.js -&gt; io.js. Concerning the anointment: Dimitri van Heesch's one would the only that matters to make DoxyPress the immediate, true successor of Doxygen. As it currently stands, Doxypress is "just" a new version, with its advantages (listed in the article), and its disadvantages (possible bad choices, unknown longevity, small community, etc.)
Looks like the extended support cycle ends in 2017 though, so calling vista dead might be a slight bit premature. (Windows 7 is also in the extended support cycle already.)
Very few people actually use Vista though. [Wikipedia](https://en.wikipedia.org/wiki/Usage_share_of_operating_systems) says between 1.23% and 2.04% and I can't imagine many of those people will be building software. Much less than even XP has.
Yeah, I guess that's a fair enough reason to drop support for it.
&gt; On top of that the block after it uses something called Bare At a guess, it's something like `std::remove_cv_t&lt;std::remove_reference_t&lt;Tuple&gt;&gt;`.
Yeah that sounds quite probable.
None of the example code given in the two SO links compile for me. Even a pretty straightforward example given [here](http://coliru.stacked-crooked.com/a/668bd7f546654971) from my first SO link gives me a compiler error: *Error C2127 - 'f': illegal initialization of 'constexpr' entity with a non-constant expression* for the line `constexpr foo&lt;int, 10&gt; f(5);` All of the example code I've tried compiles with GCC. 
Good news: constexpr delegating constructors have been implemented for Update 1. (You're using delegating, not inheriting.)
I believe the actual cause of the issue here is that braced-initializer-lists are not concidered constant expressions for whatever reason: constexpr auto a = {1,2,3,4,5}; Since std::array is initialized with an initializer list it is impossible to actually create a constexpr std::array with any meaningful data in it, as the only other alternative is default initialization which fills it with garbage. I spent some time trying to hack around this by creating a class that behaves much like a std::array but internally is implemented on top of a std::tuple, and the result is the following: http://pastebin.com/y1pPSAjG I doubt it will be particularly useful for anything really but I like solving stupid problems by stupid means and this seemed like a good fit.
nice to have a C++ API for aws, but please don't forget to not store plain keys in repos ok? 
thank you, I fixed that. Great news!
How dependent on copperspice is it? It would be great if it were a separate project, not dependent on copperspice. I somehow don't like copperspice that much - mostly because it's IIRC based on Qt4. And it will diverge more and more from Qt, most likely not integrating much of the great Qt5 stuff. Well one thing I actually don't like about Qt is even Qt5 doesn't use much modern C++, it uses so many raw-pointers, and because of backward-compatibility, they can't upgrade many of the things to newer, better code. So maybe a fork and rewrite like copperspice is not the worst idea. I'm not sure what to think actually :-)
DoxyPress uses several of the CopperSpice libraries. DoxyPressApp, our GUI interface for editing your project file uses a bit more of CopperSpice. 
This is our initial release of DoxyPress and moving the project file to a JSON format was extremely important. We are very interested in your ideas about improving the project file. Please feel free to email us directly with your ideas. Thanks.
&gt; I'm not saying they formatted their .json in a good way. Thank you for your feedback. Please let us know what improvements you would like to see. Thanks. 
The JSON format change was only one item. There are at least 100 changes overall. DoxyPressApp was a full complete rewrite and supporting the parsing of a text file was antiquated. We have been using DoxyPress internally for six months and when you find a problem please report it. 
Maybe take a look at /r/dailyprogrammer.
We did consider working on Doxygen but we found too many problems with the existing code. Yes, we actually did try to contact the owner of Doxygen and he was not receptive. We even offered to pay him and this went no where. We took a survey at our local C++ MeetUp group. It is divided as to which is better, Autotools or cmake. Most say, use what works. We used Autotools for both CopperSpice and DoxyPress not just because we knew bit but also because it worked for us. We have a developer working on cmake files for CS. We expect to have these tested shortly. Another contributer is working on the cmake files for DoxyPress. I am not sure sure why you are saying we developed this project as closed source. We announced a beta months ago. I am sorry if you were not aware of the project. But hey, you are now. We would be very happy to have you test DoxyPress and see what you think.
Hard to say without more info. Are you either: using namespace std; Or calling it like std::stoi? It sounds like it might be a namespace issue with the limited information provided.
good news, this + Qt and i'm unstopable
whoah, learned some new reddit tricks
Are you compiling it with c++11 support? Std::stoi is a c++11 addition.
1. You won't learn if you don't do your own homework. 2. See the sidebar: &gt;For C++ questions, answers, help and advice see r/cpp_questions or StackOverflow. 3. I'm not trying to be a jerk, but I have no idea from your post what you are trying to do. I suggest taking a look at the following link. http://www.catb.org/esr/faqs/smart-questions.html
Looks like a synchronous API.
Hmm. Have you tried different versions of Cygwin? I know they have had other standard library bugs in the past. Could also be environmental if your lib and include paths get messed up.
It might be that you are missing something but I don't know, I am not very familiar with Cygwin. Good luck, from what you posted though I don't see anything overtly wrong with your code or compilation steps.
[How a bug in Visual Studio 2015 exposed my source code on GitHub and cost me $6,500 in a few hours](https://www.humankode.com/security/how-a-bug-in-visual-studio-2015-exposed-my-source-code-on-github-and-cost-me-6500-in-a-few-hours) Note: The bug has been fixed, and was is the GitHub VS extension.
The fact that exception safe is a feature that needs enumerating is kind of a disgusting reflection on the body of C++ developers imo. 
How would you like the API to look? 
Well, just off the top of my head, `Outcome&lt;T&gt;` is a straight-up Java bean -- private fields initialized on construction, public non-const-ref accessors with no side-effects. Blech. `IsSuccess()` could be an `explicit operator bool()`, and `error` and `result` could just be made public and accessed directly. Alternatively, keep one or both of them functions, and throw some sort of exception on attempting to access the result of an unsuccessful operation! I didn't open up the other classes, but I'm sure that horrendous default-construct + `SetS()` API could be cleaned up, maybe (or maybe not) by using initializer lists like a `std::hash_map`? This is an instance where either named parameters or C11's designated initializers would be *really* nice to have, but that's neither here nor there.