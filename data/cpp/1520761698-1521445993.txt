What about TS? Any chance for it in 2020?
&gt; It is so far out in the future, I'm not sure if I'll even be using c++ by then. Same here, very funny.
Oh, I didn't realize that. Last time I did C was back in the nineties... Is there any particular reason why elements must be specified in order?
LLVM 6.0 libcxx no std::filesystem and libcxx(clang-cl) not support C++17 on Windows (7.0 trunk support). Pre-Built Binaries not include libcxx.
I think what you should do is write all this down in a document in the repo and maybe go through an example or two of how an existing component is implemented and fits into the system.
You can use a parameter pack (`template&lt;typename... Ts&gt; vector(Ts&amp;&amp;...)`) and then do tag dispatching to achieve reorderable parameters.
ZynaddsubFX is also a very very popular sound synthesis open source piece of software.
that's quite different. ZynAddSubFX is a GUI software, while Gamma is a C++ template library to build your own audio processing graphs.
I've never tried vax but I just assumed resharper was the best, given how great it is in c#. Do you have any experience with it
Well you are right, but still is related to the topic. I thought it would be nice to takeinto account.
Here is a very basic example: https://github.com/everdrone/libsnd/tree/master/examples Initial documentation is coming along with other examples
Maybe in that timeframe, yes.
I mentioned something I cannot see since I see only keywords appearing: if constexpr should be widened even with another feature if needed to class and global/namespace scope. Like D version(...) and if constexpr in D for conditionally defining blocks at class scope. Also feature macros transformed into constexpr or enum. Why? With modules without preprocessor propagation support this is the way to kill the preprocessor forever.
Please ignore. I deleted the comment. I was *horribly* confused when I wrote that...
I've used both, VA is definitely the market leader for C++ but R++ is definitely putting them under some healthy competitive pressure. Some of my colleagues have switched over to R++ after using VA for years. I'm still using VA as I found R++ to be very heavy on performance.
You are joking right? The size of the inheritance tree is `O(2^(n+m))` (roughly). It contains O(n+m) distinct types. You are asking g++ to generate and compile a class with 250,000 inherited bases, then ask it what `::s` is, and it finishes in 40 minutes. And you don't *use* the type. You just create it. Possibly clang worked out that the inheritance wasn't required to solve any problem and said "ok, programmer is doing something pointless I'll just ignore", while g++ instantiated the actual type in question? (Note that naming all of the types is easy; there are only n+m of them. But your system inherits from each of the types an exponential number of times. It inherits from `&lt;1,1&gt;` the number of different ways to reach `&lt;1,1&gt;` from `&lt;n,m&gt;` without going backwards using a Manhatten walk, aka (n+m-2 choose m-1). I'm wondering why g++ should care. 
Resharper does seem to incur some performance penalty, but I think that's because all the checks and inspections. I'll check out Visual Assist, thanks.
TLDR: Guy tested a program written using templates and constexpr. The templated struct in the test took 2 integers. As the user increased the integers, g++ compile time rose exponentially while clang++ compile time rose linearly. Issue is being tracked in a bug report.
Does it no load for you? This is the entirety of the post: I tried to use c++ template to generate code for a personal project, but found that the compilation time needed with g++ is much slower(exponentially) than with clang++. This is a code snippet for testing purpose: #include &lt;iostream&gt; template &lt;int a, int b&gt; struct v : v&lt;a-1, b&gt;, v&lt;a, b-1&gt; { static int constexpr m = a; static int constexpr n = b; static int constexpr s = a + b; }; template &lt;int b&gt; struct v&lt;1, b&gt; : v&lt;1, b-1&gt; { static int constexpr m = 1; static int constexpr n = b; static int constexpr s = b + 1; }; template &lt;int a&gt; struct v&lt;a, 1&gt; : v&lt;a-1, 1&gt; { static int constexpr m = a; static int constexpr n = 1; static int constexpr s = a + 1; }; template &lt;&gt; struct v&lt;1, 1&gt; { static int constexpr m = 1; static int constexpr n = 1; static int constexpr s = 2; }; int main() { std::cout &lt;&lt; v&lt;7, 12&gt;::s &lt;&lt; std::endl; std::cout &lt;&lt; v&lt;4, 3&gt;::s &lt;&lt; std::endl; }; Here is the time information: --- $ time g++ -std=c++11 generate.cc -o bygcc real 0m39.529s user 0m39.418s sys 0m0.053s $ time clang++ -std=c++11 generate.cc -o byclang real 0m0.310s user 0m0.273s sys 0m0.024s --- When using greater value, gcc will require exponentially more time to compile while the needed time from clang grows linearly. For example, replacing the `main` function from above code to: int main() { // change 7 to 8 and drop &lt;4, 3&gt; std::cout &lt;&lt; v&lt;8, 12&gt;::s &lt;&lt; std::endl; }; --- $ time g++ -std=c++11 generate.cc -o bygcc real 5m20.755s user 5m8.509s sys 0m0.260s $ time clang++ -std=c++11 generate.cc -o byclang real 0m0.314s user 0m0.281s sys 0m0.020s --- Just for fun, making the template parameter to 128: --- $ time g++ -std=c++11 generate.cc -o bygcc ... not gonna happen :). $ time clang++ -std=c++11 generate.cc -o byclang real 0m18.549s user 0m18.410s sys 0m0.066s --- I am currently running Fedora 27 with following version of gcc and clang: $ g++ --version g++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5) Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. $ clang++ --version clang version 5.0.1 (tags/RELEASE_501/final) Target: x86_64-unknown-linux-gnu Thread model: posix InstalledDir: /usr/bin
r/cpp_questions 
Tanks!
No problem! 
Genuine question: how do these sort of tools compare to a simple string or regex replacement (e.g. `sed` or a text editor find-replace)? I haven't really used compiler backed renames so far. If there is only one conceptual thing in your project with the name that I want to change then I find a regex is sufficient (usually I want to rename all symbols which contain the string I'm replacing). But if there are multiple unrelated things with the same name then usually they are not used in the same contexts, so I can just run the replace on a subset of the project. Are there other cases where a compiler-backed rename is needed? Also how do you update comments or docs when renaming?
The fact that clang optimizes away the programmer doing a literally useless thing in TMP does not mean g++ is deficient in any way. Imagine a compiler that when handed two cpp files to compile and link, notes that one contains a `int main(){}`, proves that zero symbols in the other can matter unless they are run at static initialization time, does a quick parse through it discarding the 10 billion line complex function body, and finishes the task super fast. This is a cute optimization, but *useless in actual real code*. The thing that makes g++ slow here is a useless construct. All I'm asking for is that the thing generating the slowdown be *used*. (In the code posted, the ~250000 base classes are not used) Does the performance difference remain? If so, great find. If not, cute optimization, but nothing of value. 
The code generates a linear number of types, arranged in an exponentially large inheritance heirarchy. Yes, that means some base classes are inherited from an exponential number of times. The code does not use the inheritance heirarchy. This *may* be because the code was simplified. 
[Here](https://pastebin.com/PmCkZZKU) is a version that prints the entire inheritance from constructors, all 50000+ lines of it. It doesn't affect compilation times too much. 
My mistake. OP may not have filed it yet
&gt; ok, programmer is doing something pointless I'll just ignore I'd argue that's a pretty good feature. Programmers doing stupid things aren't a rare occurrence.
I've used regex replace on smaller projects, but can still be a lot of drudge work in order to avoid false positives when, like you said, the name is mentioned in many files in different contexts across a large codebase. Visual Assist's smart rename is relatively fast when renaming local variables or file-scoped names, so I just default to using it even for local changes. It can also look in nearby comments so those will get updated as well. This works pretty reliably. If I don't have a renaming tool, running regex-replacements on subsets of the projects is something I've screwed up in the past. I find usually it's safer to change the name to something ridiculous (adding a bunch of random characters at the end), compile, change the identifier to the actual new name, and fixing all the errors by writing in that new name.
Why did you choose the GPL 3 license over the LGPL for this library? 
Maybe C++now should be renamed to C++&lt;Tmp&gt; :)
The programmer might even be doing a smart thing. There is good to reason to have code that isn't included in every configuration and ifdefs cannot always block it out.
Good question. Well, GPLv3 came automatically with autotools, so i guess i just left it there
Why should I choose LGPL in your opinion?
template specialization isn't a good way to do such thing, try constexpr function.
&gt; It is quick to set up a project and easy to use… &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Except when you don't want to use one of the IDE's built-in project or file templates; _then_ it's a pain in the keister (though it probably doesn't help that I've tried to set up my own Xcode templates and that the documentation for how to create and maintain them&amp;thinsp;—&amp;thinsp;in terms of first-party materials, anyway, though there's not much third-party stuff, either…&amp;thinsp;—&amp;thinsp;for them is…nonexistent.) Beginner's luck isn't something I ran into here, believe me; it almost makes me want to run screaming (but that'd be a _bit_ like the pot calling the kettle black since I'm brushing up on my LaTeX to do literate programming in C++, and macro-expansion languages and libraries like that are worse than XML property-list files when it comes to syntax, sooooo…) 
When's the survey running again? I wanted to take it, but I missed the window for doing so. 
From §'Questions about solutions:' &gt; * How much run-time overhead is required to use an entry from a map? The ideal answer is “as much as an unordered_map lookup plus the inevitable indirection to access an element (data or function through function pointer).” I disagree and think the ideal answer should be 'no slower than function message dispatch is in Objective-C.' 
Is that a metric you actually expect people to be familiar with offhand? And which implementation are we comparing to..?
The one he showed before forced you to explicitly make them virtual an throwed an error if you didn't.
This sounds to me like a problem with libstdc++'s headers, not with `&lt;stdexcept&gt;` itself. The standard's synopsis of `stdexcept` is extremely minimal: namespace std { class logic_error; class domain_error; class invalid_argument; class length_error; class out_of_range; class runtime_error; class range_error; class overflow_error; class underflow_error; } Most of those can take a string (or a `char const *`) to specify the `what_arg`--but it's always passed by (`const`) reference, so all the header needs is a declaration of `string`, not the full definition. Since none of these is a template, it can be written as old-fashioned code where the header just contains declarations, and all the definitions are in the implementation file (`.cc`, `.cpp`, or whatever).
&gt; but for anybody who actually writes code rather than just looking at spec sheets This is my problem with Jetbrains attempt at comparing both products: https://www.jetbrains.com/resharper-cpp/documentation/resharper_cpp_vs_visual_assist.html (if we were to somehow trust something fair and honest in it) Like everybody on the internet is praising R++ but I'm starting to wonder if people still want to type code or have a keyboard shortcut for every action. R++ is so cluttered with stuff I'm fine doing myself, and VA is light and easy to use. I don't relate at all with the Jetbrains hype and love, but that would be good if they would push Whole Tomato to new inspirations.
LGPL would make it possible to include the library in other projects without having to release the whole project code. 
I've gone further... https://wandbox.org/permlink/uSV5lg9fo0RJ0rAc I call it quits now. I can't do anything else
Talk about having an agenda! 14ned doesn't like exceptions, preferring error returns instead, so he wants them deprecated. Except he doesn't want to come out and say it, so instead he'll just find some silly reason to deprecate the header they live in. Sorry, but I call BS. 
You can certainly do better than `unordered_map`. Even without going into the discussion of better Hash Maps, if the reflection is at compile-time, you can have a perfect hash. For example, you could use an array-backed "hash map" where the "hashes" are actually just an index into the array
&gt; Logger(“this is a log entry from file {1} line {2}”,std::file(),std::line()); Ugh, pass. The reason people still use macros for logging is to avoid boilerplate like this. If you want to actually eliminate the need for macros here, then we need intrinsics to obtain the file and line number of the *caller* and that can be used as default arguments in the declaration of the logging function. Oh, and we still need a way to implicitly nuke the call from orbit in a release build. &gt; I don’t personally feel the need to generate string versions of enumerator names... Really? I run into this all the time in debug logging. 
Not really familiar with SYCL, so I have a question about the ownership of the data. When you create a buffer does it allocate on initialization and delete on destruction? Also when you reinterpret it into another buffer is the original buffer the owner and the reinterpreted one just a view or both are owners like a shared_ptr?
I think you're falling into a subjectivity trap there. I mean, preference for one over the other is a person taste thing. Out of a team of about 30, I think roughly 8 of my immediate colleagues have switched over the last year. That's after 5+ years of using VA. They all write C++ code all day every day. Just because you don't like it doesn't mean other coders don't. Given that almost 1/3rd of my colleagues have switched I think that is the very definition of competitive pressure. VA is great, but for a long time it was the only horse in town so a bit of competition is very healthy. They've recently added new features which seem to me to be in response to R++. Again, this is healthy.
Concepts are great, naming schemes in the C(++) world are weird AF though. It's one of the things that, IMHO, really alienates people from the language. For a long while I thought it was the difficult to get into toolchain but with modern tools that really isn't the case. And I'm not talking just about *values
The minimal exception types live in the &lt;exception&gt; header. Those exceptions don't rely on std::string. You can have exceptions without &lt;stdexcept&gt;
User code isn't allowed to forward declare STL template types. This is an STL header, so it could forward declare std::string, but apparently it doesn't.
Tizen also had it for a while, then they dropped it for C and later instead of adding them again as promised, they went .NET Core. In any case, who cares about Tizen now.
Strictly speaking, I think Sailfish OS is the "leading" mobile OS with first-class C++ support now, if we define "leading" as "not entirely dead and making some weak noises". I was hoping it would catch on in Russia after our government declared a special version of it to be the "national mobile OS", but so far nothing has come out of it.
Sorry, I forgot to post the link to the graph I'd prepared. It was 2am in the morning when I posted it. Here is the graph: https://drive.google.com/file/d/1A1M-Ezy4ZaphhWY-ooPUSQb_c9IzL2XR/view?usp=sharing and I've edited it above.
Indeed, and the C++ exception reform proposals coming off the back of P0939 I've seen circulating around WG21 recently do just that: they rebase a new standard exceptions header off of `&lt;exception&gt;` under the expectation that `&lt;stdexcept&gt;` will become deprecated. I just wanted to get a feel for how much cost `&lt;stdexcept&gt;` there might be.
It's a rather new tool, I think it's getting more mature now. Still has its quirks; QtCreator has years out there.
I'd say modules and reflection are more important to get right, if we don't, it will be hard to fix them later.
I do not think reflection 1.0 needs a canonical runtime representation of an arbitrary type. And definitely not as part ofmthe language. That should startnoutnas an area of experimentation, maybe become a `std` convention, long before we fix it in the language itself. I think we should split reflection the language feature from reflection library features. Having the library features as proof the language features are sufficiently powerful is good; but I'd rather reflection be standardized in 2 steps (language features that enable experimental library, and only then best practices of actual use standardized). *Maybe* extremely minimal non-experimental library in initial release, but nothing building canonical global tables of function dispatchers or the like. Fetting that right without many real world rival attempts and experience in shipping products is unrealistic. Yes, this means that easy mass runtime reflection wouldn't ship as soon, but I'd hope language-enabling features would ship sooner *and* eventual mass market library features would be better. 
tl;dr of the post: Some people don't understand what a debug-mode is, the critizised behaviour is completely sane.
Sure, but the STL implementor surely knows the correct forward declaration for their own `std::string`!
Im my last position I had a jenkins server with a pipeline of modules which would poll an internal github and build if changes were detected, further triggeting other modules if it was a dependency, and running a whole batch of tests
https://www.conan.io/
My fault, I simply meant “function overloading” (aka. static [type] polymorphism, hence my mix-up).
&gt; User code isn't allowed to forward declare STL template types. serious question: is there a reason for all these limitations on standard headers &amp; types in the language, given that no compiler seems to provide specific optimizations for std types and just ships them as standard classes / structs / etc ? Why can't std:: be a library like any other ? 
By judging the interview questions, if I don't know the answer to them the job is likely not for me. Or if I do know them but they are silly, then the job likely is not for me.
[link](http://rextester.com/SAJYV78633)
!removehelp
If you try R++ again some time, we'd really love to hear about examples where you think sorting in the completion list is wrong. R++ works in the same way as a compiler frontend, so it is definitely aware of the completion context and should prioritize e.g. local variables over global macros given both match the completion prefix. You can switch off R++'s completion in favor of Visual Studio's IntelliSense (on the Environment | IntelliSense | General options page).
While this probably won't help you directly (or at least not yet), maybe you will pick some ideas: As part of `build2` we are building our own C++-specific CI infrastructure. Here you can see some [results](https://stage.build2.org/?builds) (check the `config` drop-down field for the list of available OS/compiler combos). Now to answer your questions: &gt; how do you version your build machines ? e.g. specify the version of CMake/python/etc that the machine requires to build? External tools/toolchains like this are expected to be pre-installed on the machine (normally using the system package manager). All other dependencies come from the `build2` package repository. &gt; how do you update build machines ? This one is actually quite interesting. Each machine/version is a `btrfs` subvolumes containing a VM image. For example this is what I have for `windows_10-msvc_15u0` windows_10-msvc_15u0-1.0 windows_10-msvc_15u0-1.1 windows_10-msvc_15u0-1.2 windows_10-msvc_15u0-1.3 windows_10-msvc_15u0-1.4 So if I need to update something on this machine, I will create a `windows_10-msvc_15u0-1.5` snapshot, update what I need, then `btrfs send` it to the build host(s). 
Thanks for the support, glad to hear that! Do let us know if you are missing some feature or have any issues at all.
Since the post is gone. What was it about?
Here's my reasons for wanting reflection &amp; metaclasses: * Being able to list all types in a codebase inheriting from a given base type T, and instantiate them. struct some_base { }; struct foo : some_base { }; struct bar : some_base { }; int main() { std::vector&lt;some_base*&gt; factories; { // checked at compile-time auto types = $some_base.get_child_types(); for(auto type : types) { factories.push_back(new type); } } { // with RTTI 2.0 : std::open_dynamic_library("my_plugin.so"); // types becomes available to RTTI auto types = typeid(some_base).get_child_types(); for(auto type : types) { std::dynamic_type_allocator t(type); auto val = t.allocate(); t.construct(val, int{1234}, std::string{"foo"}); // throws if no matching constructor (int, std::string) } } } * Association of various type metadata to classes: UUIDs, labels, etc... $class attribute { // custom attributes could be a specific metaclass // where all constructors are automatically constexpr // and all members are automatically const }; attribute uuid { boost::uuid value; uuid(const char* str) : value{boost::uuid::from_string(str)} { } }; [[uuid: "12345"]] struct foo : some_base { }; // either dynamically auto find_class(boost::uuid uid, std::vector&lt;some_base*&gt; vec) { auto it = find_if(vec, [&amp;] (auto* base) { auto dyninfo = typeid(base); return dyninfo.get_attribute("uuid") == uid; }); return it != vec.end() ? *it : nullptr; } // or statically constexpr auto find_class_static(boost::uuid uid, std::tuple&amp; vec) { auto it = find_if(vec, [&amp;] (auto&amp; t) { constexpr auto info = $t; return info.get_attribute("uuid") == uid; }); return it != vec.end() ? *it : nullptr; } * Generating UIs: ideally, here is the code I want to be able to write: struct foo { [[ui: slider; min: 10; max: 20]] int bar; [[ui: dial; label: "Baz (x^2)"]] float baz; std::string frobigater; }; auto generate_ui(auto&amp; f) { auto w = new QWidget; auto l = new QHBoxLayout{w}; for(auto member : $f) { switch(member.get_attribute(ui)) { case slider: { auto s = new QSlider; if(member.has_attribute(min)) { s.setMin(member.attribute(min)); } if(member.has_attribute(max)) { s.setMax(member.attribute(max)); } l-&gt;addWidget(s); continue; } case dial: ... } // no ui specified, try to make an ui with the type instead // fuck writing std::is_same&lt;std::remove_reference_t&lt;std::remove_const_t&lt;decltype(member)&gt;&gt;, std::string&gt; if(member.type == std::string) { auto s = new QLineEdit; s.setText(QString::fromStdString(s.*member)); l-&gt;addWidget(s); } } return w; } int main() { foo f; generate_ui(f)-&gt;show(); } * creation of bindings to dynamic languages: struct foo { int bar; float baz; std::string frobigater; void blah(int x) { bar += x * baz; } }; constexpr { #if defined(BUILD_PYTHON_BINDINGS) export_to_python($foo); #elif defined(BUILD_NODE_BINDINGS) export_to_nodejs($foo); #endif } with `export_to_python` a meta-function which enumerates the members and leverages the python API or pybind11 to create code automatically as well as providing the relevant factory function required from either Python or Node's API. * enum stringification has already been mentioned * "open" types. e.g. it is sometimes fairly useful to have a part of a type static, eg. struct { int x; float b; }; and another part dynamic: struct foo { int x; float b; std::unordered_map&lt;std::string, std::any&gt; dyn; }; if for instance for 95% of your 150000 objects, only x and b are used, but the remaining 5% have 4 or 5 additional attributes, such as some std::vector&lt;whatever&gt;, std::strings, etc... there's no point in wasting tons of bytes. However, we don't want to loose type safety, do we ? No one wants to do foo f; ... if(f.dyn.contains("blah") &amp;&amp; std::any_cast&lt;std::vector&lt;int&gt;&gt;(f.dyn["blah"])) { } instead, it should be possible to write: open_struct foo { int x; float b; [[optional]] std::vector&lt;int&gt; my_vec; [[optional]] std::string my_str; [[optional]] std::string my_str2; [[optional]] std::string my_str3; }; and have the conversion occur behind the scene: accessing my_vec would look for "my_vec" in the array ; in addition the cast can be static since we can offer stronger typing guarantees if the map is hidden to the user. * in the same way, automatic struct-to-array conversion: we need metafunctions that are able to convert : struct foo { int x; float y; std::string buh; }; into struct foo_array { std::array&lt;int, N&gt; x; std::array&lt;float, N&gt; y; std::array&lt;std::string, N&gt; buh; }; and container types that allow to do : std::soa_container&lt;foo, N&gt; f; // stores a foo_array ... f[17].y = 12.34; // actually accesses foo_array.y[17]
Not an answer to your actual question but my take on the "issue": the standard library doesn't want to deal with the "but it doesn't work when I do *some smart-ass thing*" cases so they have these conditions: * You can't add things to the std namespace * You can't forward declare STL template types And so on. In the real world if you as a programmer do it anyway it will *most likely* still work but you are completely outside getting any support and your code may break with future versions/changes. That's just my take on it. Maybe I'm completely wrong but it makes sense to me.
Meh, it’s like complaining about the performance of iterator debugging in MSVC... just stupid.
thanks, but this is does not answer how to version tools installed on the amchine (e.g. CMake and python) which is the crux of the issue here. We already use conan for our dependencies.
the part with VMs is what I'm wondering about. How do you tell your CI system which VM to pick ? Which Virtualization layer are you using ? Thanks !
That's a good way to dereference a past-the-end iterator. ;-]
Oops! Edited it.
&gt; Anyway, your link clearly explains how the user can add a new input types, but I was talking about adding new output type. Sorry, I misread that part. The current development version supports output iterators via `format_to` so you can for example write to a vector or any output stream. Anyway, cool work and good luck with your library!
This doesn't make much sense to me as a construct. The majority of compilers already evaluate branches with constant expressions and elide the not-taken branch. Surely is_constexpr() would work, as in: if ( is_constexpr( blah ) ) { } else { } ? No new language feature needed. Just an additional pseudo-library function.
What if there was a function in the same scope called count?
With `gcc -ftime-report`, teplate instantiation is about 30% of time taken.
I think the best example is regarding stuff like the string view example, where you can easily overload all desired cases
Fair point. That makes a lot more sense.
While I agree that if constexpr is a net win I still think it falls short of static if in D. For example in D you can use static if at class scope to define members conditionally or not at all (I know std::conditional but does not cover all). Another thing is that I want to use if constexpr in non-tenplates and I cannot, for example to conditionally compile code at function/class/namespace scope. This is done in D with static if + version. I think this area of C++ should be cleaned up since when modules come we should be able to get rid of macros. In fact I think that feature test macros should be a module with constexpr variables or enums or sort of. That would remove a lot of obstacles for my own codebases.
I read this as the call site of `current` which wouldn't be helpful.
I don't know how much of the problem really stems from unnecessary features (my guess is not really much), but regardless of the cause, it's *painfully* slow by comparison. I also find access to many of its features clumsy, but it's hard to be sure how much of that is simply because ~20 years of use has gotten me accustomed to how VA works.
Would this have any problems with overload resolution? Ie. if I add a new function overload, will this unintentionally change how existing overload calls are resolved?
No, the caller of the function.
&gt; How do you tell your CI system which VM to pick? Each build host has a bunch of available machines (VMs) that it reports to the controller. The controller see which packages needs building on which machines and replies to the build host with a task to build a specific package on a specific machine. The build host then creates a throw-away snapshot (again using `btrfs`) of the VM, starts it up, builds a package in it, and replies to the controller. The results of these build is what what you see at the link mentioned above. &gt; Which Virtualization layer are you using? KVM. 
I have started to use Jenkinsfiles, where the Linux build Dockerfiles are checked in with the source code. For Windows, I just use a VM that is manually set up with the libraries and build environment required for that project. For MacOS I use a Mac Mini configured with the tools required for the project. Example for a library project, using boost, openssl and zlib: https://github.com/jgaa/restc-cpp/tree/master/ci/jenkins Example for a QT project: https://github.com/jgaa/whid/tree/master/ci/jenkins 
Right, but for some - my colleagues included - a slower response speed is worth if for certain killer features. 
The correct thing to do then is to add &lt;stringfwd&gt; and its cousins to the standard. We already have &lt;iosfwd&gt;, so why not the rest of the standard library?
I'm all for better alternatives to macros but so far the language spec doesn't seem to be going towards that. For example: std::variant. It was added as a template-based library type and as such you pay all of the overhead of the template system when doing anything with it. We replaced a 48 member std::variant with a macro-built-union in our code base and it reduced full-rebuild debug compilation time from 1 minute and 47 seconds to 34 seconds, drastically reduced the object size of the code generated. It's not near as pretty as the variant version but that time savings is massive when you have 10 guys compiling 100~ times a day every day. My point being: yes I want to remove macros but what ever replaces them needs to operate at the same speed or better and that's incredibly hard when they're as basic as they are.
As stated try asking questions at /r/cpp_questions/ anyway you can use ignore to ignore everything up to and including a character: http://www.cplusplus.com/reference/istream/istream/ignore/ So you can std::cin &gt;&gt; a; std::cin.ignore(1, '/'); std::cin &gt;&gt; b; 
What I ended up doing at my previous company: A script that downloads (and cache) redistribuable versioned packages of your build tools, and then add them to the PATH and store those packages in some immutable store. That way, if you want to upgrade to a new version of your compiler, you won't break anything else building on the same machine. Not as fancy as Docker, but works on all platforms, so you end up managing just one set of tools. Another way is to check in all your tools in the repository too in some way (or in a submodule for example). That's basically what Chrome is doing. 
I only ever read the posts here, but I get the feeling I am the only DevOps Engineer with enough of an interest in C++ to check out this SubReddit, so I will pitch in here and help you out.' The standard solution for the first question it to use a software provisioner. The most popular software for this is Ansible, but Puppet and Chef are also common in the Enterprise. The standard solution for the second question is Packer. You can leverage any of the three provisioners mentioned above with Packer to build and version your images, and it also works intrinsically with Docker and Vagrant among others. Let me know if you have any followup questions. Good luck!
48 members? Holy shit!
I checked just now and we're up to 70 members and yes it's in a header. But that still doesn't matter in the macro-built-union form as compilation time hasn't changed at all - still 34 seconds for a full debug rebuild with incremental builds being 5-10 seconds depending on the amount of stuff changed.
## Oh boy! This is what I do for real monies! I manage the CI stack at my workplace and I have several important lessons learned. One other person and I took over from a previous team of four and made enormous changes and strides toward sanity. Some of this won't relate directly to your question, but might be useful otherwise: 1. Bring your builders (machines that run the build) under the control of a configuration management tool. Do it. Before you do anything else. Stop. Do not pass go. Do not collect 200 dollars. (At our workplace, we use SaltStack, which I highly recommend.) It has a bit of a learning curve but lightens our load so much that we can devote our time to solving real problems. This keeps the configuration of your infrastructure under proper version control. Now you can see history and blame for configuration changes. 2. Get your builders running _as fast as possible_. When you build as fast as possible, you can have fewer builders. When you have fewer builders, it becomes easier to maintain. When it is easy to maintain, problems surface and resolve quickly. Here are some tips we've found useful: - Refuse the temptation to virtualize (at least for Linux). You mentioned Docker: **For virtually all situations, this is all you will need**. You want the build process to be able to saturate the machine. - Invest in SSDs. Worth every penny. - If using Docker (you should) install some SSDs and use them to store both Docker images and build scratch space. We use ZFS on Linux and put the SSDs in a RAIDZ, then configure the Docker ZFS driver to use the RAIDZ. 3. Get your project-specific build configuration into the project's source tree. - Before we made this change, build configuration was stored in three locations: - The stuff that was **manually installed on the builders**. Requests for new software and dependencies went through a Kanban board with a turnaround time between hours and weeks. Installation of Package A Version 2 would break Package B Version 1, so now all builds that wanted Package B Version 1 had to update to Package B Version 3. And then we'll keep going transitively until we landed on another good state. - **inline scripts and config in the CI software** (We use Atlassian Bamboo). This is an anti-pattern that I hope to see die someday. Many CI tools have progressed past this insane an unmaintainable practice. Even newer Bamboo versions have fixed this. Our solution is to have the builds enter via a generic entry point to run the real build. (eg. On Linux, just run `make`, where the `Makefile` jumps into the actual build, be it CMake or some other tool). When users (developers) needed to change the build script, it wasn't possible without breaking everything. All branches shared the same build script. When we moved to generic entry points and project-managed scripts, people could make changes to the build in branches and send in PRs for review. This also meant that we could re-run old builds since the relevant script was still in source control. - The actual project. This is where everything should have gone in the first place. - I've written an internal tool that consumes a YAML file from the project source tree and uses it to generate a Docker container on-the-fly. It then runs the entire build inside this container. Now, the configuration of the build environment happens on-demand and on a project-by-project basis. This means that a single Linux builder can build an indefinite variety of distributions and environments. But the #1 most important effect of this tool: *Users can reproduce the CI build*. No more pushing "*typo*" and "*fix build thing*" commits dozens of times just to get the CI to turn green. If it builds on their local box with this tool, it almost certainly builds identically on the CI builder. I'm finding myself wanting to take this tool home and use it for personal projects since Travis-CI suffers from the lack of reproducible builds so terribly. ## On the Subject of **Windows** Microsoft and Windows have made great strides to sanity in the past few years. But still. **It's awful.** I tried adapting the Docker-based tool to Windows Containers, and **I succeeded!** I could spin up Windows Containers and run builds on-the-fly in the same way as Linux containers. **The problem** is that Visual C++ just doesn't want to build in a Windows Container, because ``mspdbsrv.exe`` is a raging dumpster fire of deadlocks and crashes. If we could get ``mspdbsrv.exe`` fixed, I'd say to use Docker there too, but it's just not workable yet. So we're still stuck with the old-fashioned way on Windows. We have Windows under configuration management (SaltStack), and that lightens the load considerably. We only use Visual C++ Build Tools, and the new installer infrastructure, while *far from perfect*, is beautiful. No more multi-hour installation times. Automated installs via SaltStack are a breeze. For Python, use `virtualenv` for everything. You'll save your sanity. You can install both Python 2 and Python 3 side-by-side on Windows (and Linux, for that matter). Use the latest CMake. On Linux and macOS, **don't use the system provided version**. Don't do it. Just stop. End the torment. Installing the latest is trivial and worth every second. When a new version comes out, just upgrade. This may sound pretty bad. But here's the thing: If you get your Linux under control, and get all builders in configuration management, you will find the time to version and manage your truly problematic builders (Windows). And maybe someday `mspdbsrv.exe` won't be built from hate and pain.
&gt; I get the feeling I am the only DevOps Engineer with enough of an interest in C++ You're not alone! (Although I want to switch back to dev work and spend my hobby time doing dev work)
conan can be installed using custom tools plugin under jenkins: https://wiki.jenkins.io/display/JENKINS/Custom+Tools+Plugin but I don't know if something similar is possible on gitlab CI
Travis (Linux and macOS) and AppVeyor (windows) worked fine so far. AFAIK, the latter uses Hyper-V images.
That sounds great but I wonder if shared libraries complicate being able to do a perfect hash. What if you dlopen something, should we be able to look at that lib's reflection data? Do you now have to remember which HMODULE a name is associated with to be able to do a type map lookup?
Actually I would say that would be Windows with UWP, given that C++ is first class there. Microsoft might have lost the mobile phone OS war, but I think they are in the good way to win the tablet OS war via hybrid tablets/laptops.
Hm. It's not exactly "pure" C++, but rather CLI or CX (I can't remember which is needed to access Store APIs, but I think its CX?). And even then, not all APIs are exported for C++ to consume (I had a painful experience with that when I discovered I have no access to proper currency formatting when working with Store).
Can we do it withut the `slash` helper variable?
There are three flavours. C++ with Windows Runtime Library, which is similar to ATL but for UWP. C++/CX, the extensions you mention. C++/WinRT, standard C++17 with COM support being generated via an updated MIDL compiler, being introduced to replace the former two, thanks to Kenny Kerr and his team work. In any case, I never understood the hate against C++ extensions on Windows compilers (C++ Builder and VC++), while embracing UNIX and embedded compilers extensions.
Yesss... any toolchains implemented yet?
If you have a moment, would love to hear about clumsy features so that we can try and improve them :)
Yes. std::cin.get() will discard one byte of input, for example (then you have to insist they don't have spaces following the numerator). And there are other approaches too. I was only suggesting one way.
R++'s performance on analyzing solutions has gotten better with each subsequent release. I'll be honest and say that I hardly every use autocomplete and that's not what I use these tools for. I use navigation heavily and I use refactoring heavily. On the occasion where I do decide to autocomplete something, I don't find the performance bothersome.
Oh! I thought you were talking about a book.
Named parameters would be so useful.
The entire test suite is on github, so you're welcome to try out the manual "find in files" style rename yourself and see how it compares to an automated experience. There are some use cases where string replace just doesn't work well. Template arguments named "T" and things like nested structs named "Data" or "Impl" within a bunch of unrelated classes.
I think a 70 member union is just a bad idea in itself
According to [this page](https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2017) (look for "N4519") it's in gcc (as it has "Y" marked as its "Status").
thanks! how about if it needs to be in the form of for example '(a + bi)' input with the spaces included? how would that be done?
Without pattern matching, you're probably right, but with it and true ADT's it's probably not unreasonable at all.
&gt; but for anybody who actually writes code rather than just looking at spec sheets, it's so thoroughly uncompetitive in practical use that it's not putting any real pressure on anything. I suppose it depends on what you use these tools for; speaking for myself I can type code faster and stay "in the flow" when I don't use autocomplete. The first thing I do with VS is turn off all the automatic suggestions. I find the constant flashing of list boxes distracting and annoying, particularly when they pop up over existing code I'm looking at as a visual reference while I type new code. (Without eye tracking, they wouldn't know I'm looking there, so they just popup below the cursor as a default strategy.) I don't turn it off completely because on occasion I do want to ask for suggestions, but I don't like a back seat driver constantly nagging me -- ["It looks like you're trying to write a letter!"](https://www.youtube.com/watch?v=tu_Pzuwy-JY). VAX started as a better intellisense than intellisense, so it's no surprise that it is the best tool for the job if this is your primary use case. When they started to add refactoring, I was excited having found other (now since discontinued) tools lacking. At this time, R++ didn't exist yet. I applied my [test suite to VAX](https://github.com/LegalizeAdulthood/refactor-test-suite/blob/master/results/VisualAssistXResults.md) and they did pretty good on the Rename test cases I had at the time. For Extract Function, they didn't perform as well. When R++ came out, I found it's refactoring and navigation support better than VAX and I switched. I agree that sometimes the perf of processing the solution can be annoying. However, it has gotten better with each subsequent release without compromising the accuracy of the code navigation or refactoring. Navigation and refactoring are my primary use cases. As with most "productivity" tools, the best thing is to evaluate it for a time and see if it is worthwhile for you. I had used VAX for several years on a day-to-day basis before switching to R++ and it was an improvement for me, but as I say, I use autocomplete very sparingly.
If you've got a better alternative I'm all ears. The class represents an action type and associated data that the game should perform. It has a tag (an enum class value) and the associated data that tag has (if any). That data is stored in the union. The action class needs to be copyable, movable, serializable, and default constructable. It also shouldn't have any allocation overhead should you construct an instance of it and move in any of the types it supports. If default constructed it should have an empty and valid state with no allocation cost past the sizeof(...) the class. If constructed with a tag only the value should be default constructed. If constructed with a tag and value the value should be checked to be valid for that tag. Any access to retrieve a value should be checked to to be valid for the current tag. It also needs to support converting the tag to a string and back. If you have something that can meet all of those requirements I'd love to see it :)
Funnily enough, I opened a support ticket because clang-tidy was writelocking my files.
&gt; This sub is toxic. This is the last time I'll try to help here. There are some things you can complain about for this sub, but the replies to this post being "toxic" is not one of them. Turning on detailed debugging checks and then testing performance is insane and pointless. I'm not sure how anyone's supposed to respond when you post something pointless. Maybe with this?: assert(this == nullptr); 
It seems to me like many of your underscores are getting swallowed. The best solution is to use a struct and designated initializers, possibly combining with factories: auto x = std::string::repeated_char({.character = 'a', .times = 5}); To support this you just need to define a struct (it can be private) with fields character and times, and make it the argument to `repeated_char`. This isn't official C++ but it has been merged into 20, and it's supported by the 3 major compilers (for a long time, at least in the case of gcc + clang), so unless you target a different compiler than those there's very little reason not to start using this extension already (note that there are some differences in behavior sometimes as you start changing ordering, or adding defaults, I expect these to reduce with newer compilers as all implementations move closer to the 20 rules pre-emptively).
I love ccache on Linux! For Windows, there is Stashed: https://stashed.io
&gt; I'm still trying to convince my teammate that using PowerShell on Linux is a good idea. It's not. It is a terrible idea. Use Python instead. It is actually portable and it is very easy to write scripts that work both on Windows and Linux. The reduction in the amount of work needed if you do Python instead of platform specific scripts or something awful like Powershell on Linux is astounding.
I just wish we could get real integer and character types that don't implicitly promote/narrow/convert into things they aren't. If you are not used to it, it's actually really weird that you can pass the character 'A' to a function that takes an integer. It's also really weird that you can pass the number 0 to a function that takes a pointer. You can also pass almost any primitive type to a function that takes a boolean value. I know you can write wrappers that can catch most of these, but I can't control what function signatures other libraries provide.
I may have a solution to your mspdbsrv pain: http://blog.peter-b.co.uk/2017/02/stop-mspdbsrv-from-breaking-ci-build.html
Do you happen to have the ISO paper number of this? :-)
&gt;Yes, this means that easy mass runtime reflection wouldn't ship as soon disagree. Dividing one large problem into two smaller problems save time. * first, define the minimal language extension required * see what libraries are developed to exploit the extension * users can start using libraries as soon as they are available * at the committee's leisure, pick a library and standardize it. Meanwhile, a robust TMP facility can be considered/developed separately and in parallel. There is already one proposed - mp11 and perhaps others.
Hehe, it's exactly the opposite for me. Auto-complete is everything. Saves so much typing. Even on small stuff like a variable named `num_iterations` you type "ni" =&gt; "Tab" and VAX instantly auto-completes. (it recognizes the starting letters of snake_case, like every proper tool does). For maybe 80 or 90% of all variable names, function names and class names, I have to type one to two letters, maximum three, and it's instantly there - comparing that to usual function or variable names which are around 3 to 15 letters (remember, variable names should be descriptive, not too short), it's a huge gain. And no, I don't type slow. I type insanely fast in fact, with 10 fingers of course. And I love auto-complete. But it needs to be **instantaneous**. If you don't mind me asking, how do you use the navigation features? I.e. what features and with what keyboard shortcuts?
Nothing handy, but here's a couple of links from quick googling that cover the essentials: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0329r0.pdf http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0329r4.pdf
Yep I think that's the one! I also found it in the compiler support table here now: https://en.cppreference.com/w/cpp/compiler_support Thank you!
I'm a Python programmer in addition to C++. I know perfectly well where Python shines. The tasks you do with Bash and PowerShell are not in the same domain as Python. Installing Python on Windows is possible, but it's a far cry from the "out-of-the-box" workflow with PowerShell provides on both Windows and Linux. Quick, rewrite this in Python: function Get-CMake { [cmdletbinding(SupportsShouldProcess)] param( # Version to install $Version="3.10.1", # Destination for archive $Destination="cmake-$Version" ) if (! ($Version -match "(\d+\.\d+)\.\d+")) { throw "Invalid CMake version: $Version" } $minor = $Matches[1] $url = "https://cmake.org/files/v$minor/cmake-$Version-win32-x86.zip" if ($PSCmdlet.ShouldProcess($url, "Download and extract CMake archive")) { Invoke-WebRequest $url -OutFile cmake.zip Expand-Archive cmake.zip -DestinationPath cmake-$Version } }
I stumbled on your post in my struggles with mspdbsrv, but I was unable to make it work. I wish I could provide more details, but it was too long ago and I don't have the examples handy.
The whole point of C++11 and beyond is that you don't torture yourself using the language, so if the book is also that way it's rather fitting. 
I hope to give the same tooling a run on MSVC's Dinkumware STL next few days and see if the pattern is similar.
Except, as "proof" the language feature is sufficient, you still need to sketch a library out (if not standardize it) with all the must-have features (build time complexity etc). That proof of concept has to exist to verify the language features are sufficient. I am stating we intentionally delay standardizing the library features in order to permit experimentation of the language features. This *does* delay things. 
+1 on generic build targets and having as much of the build process in the repo as possible. Care to share the docked tool? I might give it a try even though we're nowhere near needing it. 
I use F12 to go to definition Shift+F12 to find usages Alt+End/Alt+Home to go up and down a class hierarchy via methods or class names. I might have some of the exact keystrokes wrong because it's muscle memory at this point. The reason I gave up on autocomplete on all the time is that I'm often introducing new identifiers and it kept completing to existing identifiers instead, forcing me to interrupt my train of thought, back up and correct what it "suggested", and then get back on to where I was going originally. For what it's worth, when I have done coding workshops/training and everyone is doing the same exercise from scratch (e.g. no existing code), the people to finish first were always the ones avoiding autocomplete and the mouse and the ones to finish last were always the ones using autocomplete to suggest names they should accept. Along with it needing to be instantaneous to be useful, it also has to be accurate in the suggestion/completion. For the way I code, I found there to be so many errors that I was faster by turning it off.
wew sweet. Is the standard getting updated to C11? (I'm halfway sure this syntax is in C11 already)
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;LOL, I'm too buried in OS X/macOS land. Sorry, I was referring to how [`objc_msgSend()`](https://developer.apple.com/documentation/objectivec/1456712-objc_msgsend) and [friends](https://developer.apple.com/documentation/objectivec/1456712-objc_msgsend#see-also) are, on Apple Darwin platforms, implemented (using techniques described, among other places by other people, by Mike Ash [here](https://www.mikeash.com/pyblog/friday-qa-2009-03-20-objective-c-messaging.html), [here](https://www.mikeash.com/pyblog/friday-qa-2009-03-13-intro-to-the-objective-c-runtime.html), and, most specifically/particularly, [here](https://www.mikeash.com/pyblog/friday-qa-2012-11-16-lets-build-objc_msgsend.html), though this links point to old articles and `objc_msgSend()` _has_ changed some over time, as described _[here](http://sealiesoftware.com/msg/index.html)_ to some extent) is, IIRC, not all that much slower than a dispatch of a C++ `virtual` function using a vtable. 
To truly replace log macros, I think `source_location` is necessary but not sufficient. We really need lazy argument evaluation, with something like [p0927](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0927r0.pdf), for obvious reasons. 
solution: don't be an idiot
The point made in C++ Core Guidelines "NL.26: Use conventional const notation" is about trade-off rather than consistency. The "const west" choice is made not to be consistent with existing code, but because "east const" brings more problems than it solves. Novices are much more comfortable with "const west", whereas professionals can easily deal with both notations. Yes, "const west" is more comfortable for novices for consistency reasons, but those reasons are irrelevant when considering the trade-off. Perhaps, this “east” VS “west” dilemma receives too much attention than it is worth. It reminds me the "Ali G West side VS East side" video :) Just make your trade-off choice (use NL.26, be consistent with existing code base, or do a fair coin toss), and then move on to solving real problems. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The movie was based on a book of the same name, if that's what you mean. :-]
Promotion generally seems to be the worst part of the language for(int i=0; i &lt; vec.size()-1; i++) It seems to just cause bugs all over the shop. We need strict enforcement of types so that the above example either works as you expect, or its a compiler error I've been doing a fair bit of JS dev recently, and 'use strict' seems like quite a solid idea, opt in removal of a lot of detritus I would personally find quite a bit of use out of a similar c++ construct that fixes this kind of crap, so we can keep the ever important backwards compatibility, but opt into no 0's to pointers, no auto narrowing, disabling integer promotion entirely/making the rules sane, 2s complement + defined signed overflow, no UB on left shifting a negative number etc, generally define a lot of undefined behaviour that's ostensibly for performance but really is seemingly just archaic/pedantry at this point etc That way we could work around the classic performance/backwards compatibility arguments. Anyone who wants the insanity of the current undefined behaviour can keep it, and anyone who wants sane behaviour can opt in to it
No one mentions GitLab CI? Self host gitlab instance provides so many things out of the box, CI included. 
IIRC, the original C touted this as needed flexibility and a quality in language.
Ok, but to LEARN the language I think the old way is better. You need to know why things works before using the shortcut version.
&gt; It also needs to support converting the tag to a string and back. Something that is a big pain to do without macros if you want maintainable code. I think with reflection, there will be ways to have enumerations map actual types to their values, but that's not landing in C++ until a while. Maybe clang metaclass fork could be able to run something like that, but right now macros are the most sane option. To be pedantic though, you don't need to have a union, a struct with a `char[sizeof(biggestclass)]` with some alignment requirements would do the job just as well. Unions are basically fancy casts anyway.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/83zpbs/is_tcpl_3rd_edition_more_dense_than_4th_edition/dvm8dh0/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The moral of the story is to always compile with `-Wconversion`.
we're loking into [sccache](https://github.com/mozilla/sccache) instead, it looks like it does all of that and more.
Thanks a lot for your input ! We're looking into Ansible, but the rest of the workflow you describe with packer is still a bit nebulous for me. I wish we'd hire a DevOps Engineer, but it does not look like it's going to happen.
Thanks a lot for your input !
Thanks for your input ! We're actively looking into this idea of provisioning machines using Ansible, but we're at a loss when it comes to pick which machine the CI system should run on.
We actually tried that, but it did not work, we were still stuck with the mspdbsrv pain. What failed for us IIRC was a conan build, where the newly spun up docker would build the library, and when trying to build the 'test_package' the pdb server would error out and fail miserably.
We're actually looking into sccache right now. I'd love to use clang-cl but we sell a SDK and have strong compiler compatibility requirements (we still support VS2012 and gcc4.4), and while using clang could generate ABI compatible binaries, some of our clients that use VS201X would be unable to build if we accidentally use a feature that is not supported by a version of the compiler we officially support. Which means we have to build using MSVC to make sure everything works as advertised.
&gt; All I'm asking for is that the thing generating the slowdown be used Is this sufficient? https://godbolt.org/g/cmKaoV 
Hassle factor mainly. I'd have to build it from source on WSL and from the low reddit votes, I'd say not many care about this sort of stuff. They consider the STL headers to be a sunk cost of doing business, unimportant.
I've had to go through my code and eliminate std:: constructs that take too long to compile or use too much RAM. My interest in libc++ is because I don't consider g++/libstdc++ to be a viable target right now. Way too many bugs (things like missing c++11 features with seemingly no traction on ever getting implemented), way too poor error messages and non-existent tooling. Honestly, I don't know why anyone would choose to use g++/libstdc++ for anything right now.
&gt; In the real world if you as a programmer do it anyway it will most likely still work It will most likely not work due to the presence of inline namespace.
Designated initialisers are something I've really missed coming from C99. Glad to hear they're finally coming in in C++20; better two decades late than never.
Let me know how that works out. I thought it either required manual administrative intervention or messing with the build system to get working.
I too have been negatively affected by ICE bugs in GCC which they cannot nor will not fix for two or three major releases now. libstdc++ has been less problematic, but then I have a direct line to its maintainers who tend to treat bug reports from Boost folk more seriously. Still though, as much as quality has been deteriorating recently as more resources continue to move away from GCC/libstdc++ and into clang/libc++, it's still nothing like as bad as say in the early 2000s when the GCC C++ ecosystem was riddled with quality issues. And the average quality of compilers and standard libraries are orders of magnitude better than even a few years ago. If your org also finds libc++ problematic, I'd remind you that Dinkumware STL (the one which ships with MSVC) is 100% portable and works on lots of compilers. They'll sell you a licence gladly. As a commercial product which must sell itself to paying customers, it tends to be ahead of the curve in quality and completeness of implementation, so exponential behaviour tends to occur much less frequently in my experience on Dinkumware. They've also been shipping a Filesystem TS implementation for more than five years now. I'm not sure how useful header token parsing benchmarks would be to you for libc++. It's likely to be somewhere in between Dinkumware and libstdc++ in truth, but maybe actually benchmarking it would be useful.
&gt; the average quality of compilers and standard libraries are orders of magnitude better than even a few years ago. I totally agree.. and that raises the level at which code exercises the compilers which then makes the (say) 10% of the remaining issues feel nearly as bad as the older versions because expectations have changed. It's definitely not the worst problem to have :)
Indeed. At my current contract the compiler is GCC 4.4 and libstdc++ 4.4, and I count myself lucky as that's the "new" toolset upgraded from some GCC 3.x series :)
Could someone explain to a noob what this code does? Especially this line `struct v : v&lt;a-1, b&gt;, v&lt;a, b-1&gt;`. Also what’s a good book/tutorial to learn templates?
More accurately, the compiler can remove null checks if there is code nearby which dereferences without checking - because your code would be broken _anyway_ with a null input. e.g.: ```if (p != nullptr) { // something } p-&gt;func();``` The compiler can remove the `p != nullptr` condition from the first part of the code because it can see that the second part always dereferences without checking, so it assumes p cannot be null (or this code would be broken anyway). Then you get a crash _inside_ the if block dereferencing a null p, because your code _was in fact broken anyway_.
Except when it forgets to crash, like in those UB cases when a method works even with this being nullptr
With a working example: https://godbolt.org/g/CN8Nbk
 template&lt;typename T, typename U, typename Hash = std::hash&lt;T&gt;, typename Allocator = std::allocator&lt;T&gt; class HashMap { template&lt;typename H&gt; using WithHash = HashMap&lt;T, U, H, Allocator&gt;; template&lt;typename A&gt; using WithAllocator = HashMap&lt;T, U, Hash, A&gt;; }; Then you could so something like: HashMap&lt;int, string&gt;::WithAllocator&lt;MyAlloc&gt;::WithHash&lt;MyHash&gt;
You can define a `multiarray` with a variadic template list of dimensions that resolve to a `std::array` with the dimensions in the right order. template&lt;typename T, size_t I, size_t... Is&gt; struct MultiArray { using type = std::array&lt;typename MultiArray&lt;T, Is...&gt;::type, I&gt;; }; template&lt;typename T, size_t I&gt; struct MultiArray { using type = std::array&lt;T, I&gt;; };
I mainly need reflection for (de)serialization. I always need to write custom code generators that are hell to maintain. I hope to be able to build (de)serialization functions that stay the same even when the data structures changes. Also custom attributes to add metadata to each data member, e.g. https://docs.microsoft.com/it-it/dotnet/standard/attributes/index
It doesn't forget, there simply isn't a reason to dereference p when the exact implementation of func is known at compile time. 
regression from what?
&gt; I have yet to see an instance of it that's anything other than a maintenance nightmare. Usually caused by the developer not actually take responsibility for any action anywhere in his code. Bjarne is posing some questions about reflection. You sound like you are venting about your bad experiences with some developers. &gt; I usually get a "I'm not sure exactly what I want to do here, so I'll make it general enough to do anything," vibe off them. Don't you guys use specifications? Requirements? &gt;And then they only ever write one class to do anything with it, compile that class to a binary file, and load it in from a SQL database. What are you talking about? ... and who is "they"? &gt; Yeah. You know who you are. What are you talking about? &gt; Bonus points for running the binary file through symmetrical key decryption, with the key also looked up in the database, before you start. What are you talking about again? &gt; Then I have to come along and rip all that shit out and replace it with something that the team can actually maintain going forward. Still no idea what you are talking about.
I completely understand and sympathize with that. I guess I have forgotten these issues because I have been so immersed into DevOps for years that I can avoid all of these through instinct, but they still crop up from time to time. I should probably elaborate why I want to see DevOps software written in C++: I know many coding and software languages and they all seem to have failings compared to C++. Also, C++ developers are the easiest to do DevOps with since they understand the failures associated with build, qa, release, deployment, etc. such as not adding pointless dependencies.
I could provide a high-level reference architecture for that. The workflow for Packer in your situation would be a subset of the standard Immutable Infrastructure Pipeline architecture. You could also pay for my time as a consultant through my parent company or our partners, but I am unfortunately expensive by non-west coast or northeast standards because apparently I am highly rated for some reason. So, I can just hopefully point you in the right direction here.
So, I think I've just realized a mnemonic to help remember things like this: "UB = Unexpected (to the programmer) Behavior" Or, maybe more tersely, "Undefined behavior means unintuitive behavior"
&gt; Or, maybe more tersely, "Undefined behavior means unintuitive behavior" Which is wrong. "*Undefined behavior*" means undefined behavior. It's free to actually wind up being perfectly intuitive. Why do people insist on trying to create inaccurate heuristics for understanding something that's already so easy to understand?
The default is to optimize these checks out, so the regression was in gcc 6. If you want them you have to compile with -fno-delete-null-pointer-checks .
&gt; Why do people insist on trying to create inaccurate heuristics for understanding something that's already so easy to understand? Trying to blame compiler writers for their own buggy code?
I meant that we cross-build, including Java and .Net SDKs for Windows. 
C++11 doesn’t hide anything from you. E.g. when learning “manual” memory management, you’re writing more boilerplate than when using a smart pointer, but you end up with same behaviors, just enforced by design rather than by paying lot of attention. Using `decltype` lets you get rid of a lot of template meta programming. Using type deduction lets you write iterator based for loops without typing out two lines of boilerplate. Move semantics lets you avoid even more manual memory management as you pass values instead of pointers. Etc. 
It's unfortunate that aggressive optimizations render the optimized+asserts build type useless. Assertions by design are supposed to uncover "impossible" conditions in code, and such conditions frequently go hand in hand with undefined behavior. Optimizing away code triggering undefined behavior gets rid of assertions as well. I find it quite surprising that assertions can be optimized. Sounds like there is a need for something like "unoptimizable" assertion. Or at least, compilers should be aware of assertions and treat them differently from the rest of the code.
How come there is still nothing preventing std::string from being constructed with nullptr? Wouldn't `std::string::string(std::nullptr_t) = delete` constructor trivially solve this problem?
&gt; We need strict enforcement of types so that the above example either works as you expect, or its a compiler error IIRC with GCC the snippet you gave fails to compile with `-Wsign-compare -Werror`.
You're perhaps looking for [contracts](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4415.pdf)?
&gt;Hassle factor mainly. I'd have to build it from source on WSL and from the low reddit votes, I'd say not many care about this sort of stuff. They consider the STL headers to be a sunk cost of doing business, unimportant. Please don't consider it like this, it may not be the flashy or new, but this kind of information is very useful to know The problem is, the size of the c++ community who this is useful for is inevitably quite small, however for those people (including me) this is very useful to know. On top of that, this post is doing about as well as a post in the /r/cpp subreddit can do, given how small it is :)
It's the difference between a dereference as per the C++ standard and a dereference as per the actual machine - calling a function counts for the former but may not cause an actual hardware read.
seeing as we use CMake, it looks like easy enough to integrate.
Unless `// something` includes an early return or write to `p`.
Note: the part marked ```// something``` must be completely known to the compiler. If ```// something``` calls an external functions, the compiler can't assume that it will return, and have to respect the test.
&gt; Please don't consider it like this, it may not be the flashy or new, but this kind of information is very useful to know Oh sure, but I think only to those who work with really large C++ codebases. They also tend to be those still using a compiler from the early 2000s, and so haven't run yet into how much fatter the C++ 11 and especially C++ 17 headers have become. And in the end, a tokenising lexer can only run so quickly, and I am not personally convinced yet how much better Modules will address sheer header heft. Much of the added girth in the C++ 17 headers is SFINAE complexity :( &gt; On top of that, this post is doing about as well as a post in the /r/cpp subreddit can do, given how small it is :) Dunno, &gt; 50 upvotes would be nice. Down here at &lt; 30 it shows the community just doesn't care about this much.
Not really; as soon as the type shifts to `char const*` the overload ceases to be useful, i.e. the following would still compile: char const* p = nullptr; std::string s(p);
&gt; It's unfortunate that aggressive optimizations render the optimized+asserts build type useless. This can be solved by inserting a call to exit(), std::terminate(), ExitProcess(), or really anything marked up with __attribute__((noreturn)), __declspec(noreturn), or [[noreturn]] as the last thing inside your custom assertion macros. Of course, if you want to be able to step over your assertions, this will not work.
This isn't really correct, if `// something` throws, returns, calls std::abort, jumps to a goto label, etc etc, then the check cannot be removed. That's a rather large set of caveats on `// something`.
The "this" pointer can never be null 
One could wonder why there is no "dead code eliminated" warning here. That, at least, could get the programmer to investigate why some of his code is considered as dead by the compiler, and fix the problem without wasting hours. 
That depends on whether contracts will be used as a means to checking a program, or as a means of further optimizing it. 
Unwarranted null checks are one of the scourge I've been fighting against. 
&gt; Thus the code mindlessly reads garbage memory and doesn't assert I don't really understand what you're complaining about. Let's say that the optimizer did nothing. Then the function returns `nullptr` which is "*dereferenced unconditionally.*" This is undefined behavior. Now let's say the optimizer does as you lay out: Then `back()` is called which is undefined behavior. There's no attempts to avoid this happening because there was no assert outside the function that it didn't return `nullptr`. The outcome of the program is unchanged: It results is undefined behavior.
So lesson learned: Use UBSan when debugging.
Dead code is eliminated frequently, on any non-trivial codebase you'd get 10's of thousands of warnings so the signal:noise would be prohibitive.
I don't think a single word of the above included "complaint". I was explaining what happened. You appear to be projecting a complaint onto it. I was simply reading intent of the code, and noting that the intent failed. 
In fact: you need to know what boilerplate looks like to understand the mechanics behind it, when to use it, when to prefer other solutions, what are the limitations, etc... And don't forget that you might stumble across some legacy code. In general, i think it's very useful and interesting to understand what's going on behind the scenes when you use - say - a range based for loop or how the compiler mangles function names, etc... I guess it depends on whether you consider HW as the platform or Language as the platform.
although `=delete` of unexpected overloads can be a useful technique in general. You can also easilycreate a `strict_type&lt;T&gt;` for params, which only accepts exactly a `T` (at the cost of some occasional inconvenience at the call site).
&gt; noting that the intent failed. Which is incorrect.
Dude, it was a joke. Apparently not a funny one. :( (or maybe you're making a joke? referring to the big thread a couple weeks ago in this sub, about references never being null?)
Even bigger downside: Breakpoints trigger inside the "noinline" function instead of the call site of the assertion. I personally find this to be unacceptable when I am trying to debug the code (my assertions include DebugBreak()). Also, as you said, you have a function call per assertion and to get this to working correctly, I think you would need put the function in another TU with LTO disabled, which isn't ideal.
Was there clear programmer intent to avoid reading garbage memory? Yes. Did it read garbage memory? Yes. The intent (not to read garbage memory) failed (garbage memory was read). It failed because the program did undefined behavior, but I'm not *judging* anything. I'm just reading intent. 
I disagree. Teach the old version and most people are likely to abandon C++ in favor of other languages. While _I_ find C++14 to be superior to a lot of languages, C++03 really isn't. Hell, I'd rather use Java than C++03 to be honest.
&gt; Was there clear programmer intent to avoid reading garbage memory? No. Undefined behavior isn't "*reading garbage memory,*" it's undefined behavior: We can't assume what it will and won't do and attempting to ascribe semantics or meaning to it is misguided because it fundamentally has neither (that's the point of it being undefined). So your statement becomes something akin to: &gt; Was there clear programmer intent to avoid undefined behavior? The answer to which is: Only if `back` were called. But `back` is only called if the container isn't empty, and the container was empty, therefore there was no clear programmer intent to avoid UB. If the assertion were triggered it would violate the as-if rule since the assertion is that the container isn't empty, but if the container were empty the branch that has the assertion couldn't be taken anyway. Whether there's UB or not the compiler should delete that assertion because it's contextually impossible/irrelevant.
(1) I should have said "Undefined behavior *can mean* uninutitive behavior. (2) I had the idea because, while I *know* undefined behavior means it's OK to wipe my hard drive, I expect things to generally behave in a relatively obvious manner. The sample code /u/TheThiefMaster gave is an example of unintuitive behavior. I would *not* expect -- even though it's perfectly allowable due to being undefined behavior -- an entire if condition to be ignored because of code *later* in the code. To be clear: I'm not criticizing UB, nor the compilers. I'm just saying I just realized a mnemonic that will likely help me be less surprised and frustrated if/when I come across behavior like is being discussed. 
It's hard for me to understand jokes in written English :-/
The part marked `// something` doesn't matter, since if `p == nullptr`, then `p-&gt;func();` is executed, which is undefined behaviour, hence `p != nullptr`, so the condition is always `true`. Also, `wont_crash` in your example can definitely crash, no matter what `g` does: http://coliru.stacked-crooked.com/a/d342a57ad9ad719f
It may be for all the wrong reasons, but I actually never would have expected SmallVector::back's assertions to be able to help me here anyway. I learned from doing lots of development in C++ with various compilers for years, and only later went back and read the books on it that I should have read earlier.. so the practice of it drowns out the theory, for the most part. From that, you know that if you don't do every potentially necessary null check (at the very least with some dev-only assertions that have opportunity to be exercised during development), you're damned.. and so that code (I know this is a simplified example) screams trouble. This probably isn't generally the best way to go about things.. but it's interesting to consider that empirical experience teaches the lesson in an obvious way, whereas following all that's happening with a working model of the standard is relatively difficult. Both are valuable.
You really need some CS 101. Inheritance is one of the most important concepts in Object Oriented Programming. You don't always need to use inheritance, in fact most of the time you should use composition, but for some classes of problems inheritance is the best solution. One of the most common is GUI programming.
This is mostly inaccurate since most people only build assertions when in debug mode, and if you're building in debug mode, you're not using aggressive optimisations.
Last year I was working on a game project for school in an entirely custom engine. Our entities were essentially just containers for updating components that did all of the real work (it's the same way Unity and I believe Unreal and Lumberyard handle entities as well). This was extremely useful,as it allowed us to define entities outside of code and dynamically create new objects at runtime, and it would not have been possible without inheritance, at least not "cleanly". All of our components inherited from a component base class and had virtual update, initialization, etc functions; we probably would've ended up with some sort of function pointer type mess if we wanted to avoid inheritance, which would've been a nightmare to maintain and expand, and would really have ended up as some sort of bastardized inheritance, anyway. All that said, our inheritance hierarchies were extremely shallow, the largest was probably two levels deep, and even then it really shouldn't have been. I don't use it very often these days, but it definitely does have it's place. Compile time polymorphism is great, but there are some situations where that just won't cut it and you need runtime polymorphism and dynamic dispatch, or at least really should be using it.
D R Y Don't Repeat Yourself Keep reusable code in inheritable classes /r/learnprogramming for this kind of question
Here's some working Python 3.6: import re import urllib import urllib.request import shutil import pathlib def get_cmake(version, destination=None): destination = destination or f'cmake-{version}' m = re.fullmatch(r'(\d+\.\d+)\.\d+', version) if m is None: raise RuntimeError(f'Invalid CMake version: {version}') minor = m.group(1) url = f'https://cmake.org/files/v{minor}/cmake-{version}-win32-x86.zip' data = urllib.request.urlopen(url).read() pathlib.Path('cmake.zip').write_bytes(data) shutil.unpack_archive('cmake.zip', destination) `$PSCmdlet.ShouldProcess()` implements PowerShell's `-WhatIf` option, which is a "dry-run" mechanism built into the language. Your example is still missing automatically generated help text and command-line auto-completion. Also, using `urllib.request.urlopen(foo).read()` now pulls the entire file into memory before writing it to disk. You're also stuck targetting the lowest common Python 3 version of your target platforms, since updating Python3 on them breaks everything. You could use `pyenv` or build Python yourself, but you've now surpassed the work required to install PowerShell.
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8465nc/why_do_people_use_cpp_inheritance_whats_it_good/dvn3ykv/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I agree most of the time you want composition, so I don't really view it as a very important aspect of OOP anymore. But of course you need to know about it.
I thought game engines all dropped inheritance in favour of Entity-Component-Systems?
Inside `back()` there is an `assert( I am not empty )`. If that assert fails, `back()` returns a pointer to garbage uninitialized memory. That `assert` is clear programmer intent to avoid reading garbage memory. &gt; We can't assume what it will and won't do and attempting to ascribe semantics or meaning to it I'm not asscribing semantics or meaning to undefined behavior. Again, you appear to be projecting. I'm ascribing intent to *what the programmer seemed to want to do* in the code. Well, programmers, because I doubt the same person wrote `back()` and the other code there. &gt; Was there clear programmer intent to avoid undefined behavior? That isn't what I said, nor what I meant, nor does that become what my statement becomes something akin to. I am strictly talking about reading from garbage memory. The binary compiled from that code reads from garbage memory (in particular from uninitialized data in the circular buffer or somesuch). The compiler is not wrong in doing so, because the binary there does indeed engage in undefined behavior, and it can do anything once that happens. However, we can analyze *how the undefined behavior led to this particular behavior*. Second, we can analyze *what did the programmer intend* with various lines of code. You can do this even if the code *elsewhere* does undefined behavior. As human beings, and programmers, we can infer intent from other programmer's code that isn't restricted by what a compiler and the standard states. You are continually saying "you really mean X" and then lambasting me for how X is wrong. Please seek help with that problem. It really doesn't help at all. --- `back()`'s "assert container is not empty, then return a pointer to data that is in garbage memory if it is empty and otherwise to the back of my data" is clear programmer intent not to have someone else read garbage memory. The `if (empty()) return nullptr; else return back();` is also clear programmer intent to not return a pointer into the garbage memory that `back()` returns if the container is empty. Both of these bits of code, which **show clear programmer intent** to avoid reading garbage memory fail. They fail because elsewhere in the code, a null pointer is dereferenced. The compiler proves that this code either dereferences a null pointer, or it reads garbage memory that `back()` would return, and converts that to "unconditional read of garbage memory". I fully understand *why* and *how* this happens. I am not complaining about what the compiler did. I am noting the clear programmer intent, and how it failed. You appear to be rewriting my statements to be something completely different. I don't know why.
I personally don't find the bottom-up approach to learning programming languages to work all that well. You start at the high level patterns and go down, otherwise the starting level has to be machine code if you don't want to be totally arbitrary about where you start.
[Not especially, despite what you may hear on r/gamedev](http://api.unrealengine.com/INT/API/Runtime/Engine/GameFramework/AActor/AActorHierarchy/index.html)
It is an entity component system, but you still typically do use inheritance for defining components. There's still a base component class you inherit from, but that's typically where the inheritance ends (at least in your fairly simple game) You don't have any big monolithic inheritance hierarchies defining objects like [weapon-&gt;sword-&gt;broadsword&gt;steel broadsword] \(which is what an inheritance based system looks like), you have bunch of small, modular hierarchies that look like [component-&gt;collider] or [component-&gt;Sprite renderer] and collect a bunch of those together to define an object.
Exactly: I was introduced to assembly in my youth - just a very basic introduction, mostly focused on the architecture rather than actual programming - and it's been illuminating IMO. The opposite is electron, so...
Omg, you're so right. I typed something different from what I meant. Updating the original post.
&gt;I am noting the clear programmer intent There is no clear programmer intent, which is the issue with your scenario, and which is something you refuse to see. You act as though this tautological assert matters, but it doesn't. You act as though an artifact of undefined behavior (dereferencing the back pointer rather `nullptr`) is something that you can reason about, but you can't. The point of putting `assert` in before possible undefined behavior is to catch **that particular** undefined behavior. Calling `std::vector::back` (for example) when `std::vector::empty` returns `true` is undefined behavior because the standard says that the "*[o]perational semantics*" of `a.back()` shall be equivalent to: { auto tmp = a.end(); --tmp; return *tmp; } and decrementing an iterator through the beginning of the collection is undefined behavior (and even where it may not be (e.g. `std::forward_list`) dereferencing the resulting iterator certainly is). So if we reformulate the "*[o]perational semantics*" of `std::vector::back` to: { assert(!a.empty()); auto tmp = a.begin(); --tmp; return *tmp; } Then (when `NDEBUG` is not defined) we save ourselves from this undefined behavior: Under these circumstances the behavior of invoking `std::vector::back` while `std::vector::empty` is `true` are perfectly well-defined: The program terminates. However this has absolutely nothing to do with the undefined behavior in your example. The undefined behavior in your example is not decrementing the begin iterator or dereferencing the result thereof, it's dereferencing a null pointer. And nowhere in your formulation is there an assertion that the pointer resulting from your coalesce-empty-to-null-pointer function isn't null, so there's no clear programmer intent at all: As best the compiler can tell the clear programmer intent is: *This function will never return null.* The fact that the result of the compiler's code generation in response **appears** to bypass your assertion is utterly irrelevant. The compiler can appear to do **anything** in response to undefined behavior and still be conforming (that's the point).
This. Also, cpp doesn't have interfaces natively. You need to make abstract classes and inherit from them. Once you start doing that, then you realize that some behaviour would be common to all implementations, so you might as well put it in the base class. That doesn't have to be the bottom base class, sometimes you make an implementation class for convenience (so a user can either inherit from the interface or the implementation class). Avoids have to both inherit a class and include the implementation class (two steps), and then call the implementation class to do the common work (just call the method instead of referencing the implementation class). Not only convenient, but avoids errors, especially if you have to do it multiple times. Having said that, lambdas do make having interfaces somewhat less of a basic requirement. But still there are times when they are needed.
Unreal Engine still has a lot of pretty ridiculous inheritance hierarchies. Object &gt;&gt; Actor &gt;&gt; Pawn &gt;&gt; CompanyNamePawn &gt;&gt; SomeMoreSpecificPawn and Object &gt;&gt; Actor &gt;&gt; Controller &gt;&gt; PlayerController. Also almost everything seemed to be public and very seldomly const-correct so you could introduce massive bugs in unexpected places in the code very easily. I was working at a place that had a C++ source license for the engine though so I'm not sure how much of it was my companies fault vs Epic's.
For a lot of people, it's not easy to understand. Where they get confused is that even though everyone warns them that UB means anything can happen (including nasal demons), they don't truly believe that *just anything* will happen. They think UB is predictable and that the same behaviour will always be exhibited on the same platform every time UB is invoked in the same way. They rely on the undocumented behaviour that they observe to happen the first time they invoke undefined behaviour. Because hey, computers are predictable, right? (Obviously this is a bad assumption to make when dealing with complex software such as compilers). There's just a fundamental disconnect between how they believe Perhaps the mnemonic should be *UB is Unpredictable Behaviour*, if anything.
Evolution of a C++ programmer. What is inheritance good for? -&gt; I can inherit implementation -&gt; Virtual functions are cool -&gt; Virtual inheritance can fix my diamond problem -&gt; Abstract base classes for the win -&gt; Watch "Inheritance is the base class of evil" -&gt; What is inheritance good for?
Sean Parent's approach uses inheritance for the implementation. It also involves a lot of repetition for the developer. Which you can try to avoid perhaps using macros, but either way it's nasty. It's really not that different, other than lowering coupling. Whether more complexity/duplication is worth lower coupling depends on your use case.
The assert in `smallvector::back` is the [normal assert](http://llvm.org/doxygen/SmallVector_8h_source.html) that's normally compiled to nothing when built optimized. So I don't see what you mean. As for NDEBUG "unomptimizable" assertions, yes, people use them, why not? And the compiler can't take them out, not unless it can prove they can't fire. But that's not `assert` seen here.
Unrelated to TFA, but a hundred times yes!
&gt; now pulls the entire file into memory before writing it to disk. cmake-3.10.2.zip is 12 megabytes in size. If your computer does not have that amount of work memory to spare, you've got bigger problems than choosing a scripting language.
Any way to use that for Windows / VS projects? Last I checked Clang choked hard on Windows headers.
It may be easy to understand in retrospect after you read a reddit comment about it or work out the cause of a null crash bug after the fact, but that does not mean it's easy or intuitive. Spewing elitist bullshit like that just reinforces C++'s reputation as a language designed for insufferable pedants.
Yet another diamond problem...
Re: diamond problem: When I was first learning C++ and object oriented programming, one of the first things i learned (from Scott Myers book I think) was to not do multiple inheritance. And I never have.
&gt; You really need some CS 101. Inheritance is one of the most important concepts in Object Oriented Programming. Thats is incorrect. Inheritance is not fundamental to OOP, polymorphism is. C++ unfortunately mixes the two up, but they are orthogonal concepts. You can do perfectly good OOP without using inheritance. You can even do it in C++, using std::function, if you ignore the implementation detail of std::function.
Honestly I haven't found inheritance to be good for anything. Polymorphism, however, is sometimes very useful. C++ unfortunately mixes the two up, but they are orthogonal concepts. C++ uses inheritance for a lot of things. Polymorphism, composition, Template metaprogramming, optimization, you name it. It is a blunt tool without much finesse.
I never said it's fundamental, neither that's necessary. What I said is that it's important in OOP, as one of the (many) forms of polymorphism. As I said it's not the best solution for all OOP problems, but it is for some, it's largely used in the industry (most if not all GUI toolkits use it) so it's improtant to understand it.
&gt; Honestly I haven't found inheritance to be good for anything. You haven't done any Desktop GUI have you? Most (if not all) GUI toolkits rely heavily on inheritance. Gtk even implemented a full runtime object oriented system (gobject) to get inheritance (among other things) in pure C. Obviously, as with any other **tool** inheritance have been abused a lot, but it doesn't mean it has no use cases. 
The point of the proposal is not to put forward all these great things that we could standardize if we had this feature. The point of all of the _examples_ is to show potential applications of the metaclass feature itself if standardized. It sounds to me like you mistook the examples for the proposal itself.
Nowerdays you actually have a realistic chance to compile a msvc application with clang. You can certainly compile a hello world program, that includes windows.h, but beyond that I have very little experience with using clang for projects that aren't explicitly designed as cross platform.
&gt;Keep reusable code in inheritable classes No. Inheritance is not for reuse. Inheritance is for **specialization**. For reuse you should prefer creating self-contained do-one-thing-only classes that can be composed together.
No. I didn't mistake it. I inferred it may be the desire or intent of the speaker, who is a member of the committee. I'm quite aware the metaclass proposal itself is beneficial and in no way suggestive of that. 
Inheritance is not a form of polymorphism at all. They are orthogonal concepts. C++ mixes the two up, but in general you can have polymorphism without inheritance. What GUI toolkits need is polymorphism, not inheritance.
Desktop GUI needs polymorphism, not inheritance. They are related but orthogonal concepts.
One of the issues is that when the allocator is not type erased, it really makes it a pain in the ass to write APIs. You can't take `const std::vector&lt;double&gt;&amp;` any more, you have to templatize on the allocator which is rather ridiculous. You can say "pass in an iterator pair", sure, but this doesn't work in many other cases, e.g. unordered_map. So there's a pretty major downside to exposing the type. As to upside, you basically save one virtual function call per allocation. Even for high performance C++, it's relatively rare that this will be significant, I would think. A virtual function call might still be something like 100x faster than calling malloc (around 10 ns vs 1 us; very very rough, context dependent figures). You also avoid any thread/locking/contention issues. And you still get the benefits of memory contiguity. So, I think, at least people who like the pmr approach, would say that it has 95% of the upside, and none of the downside, of statically typed allocators. I think that this is basically the view of people who authored the pmr stuff (I think, people like Pablo Halpern, and some folk at Bloomberg IIRC). Of course, this may not be universal consensus. With an arena allocator, de-allocation is a no-op and allocation is just bumping an integer. So pmr allocators add a ton of overhead in relative terms there, but whether that's significant in the whole still depends on your use case.
Does it support setting the executable used? We're still using 4.0, and they aren't really compatible with each other..
Sorry for my naive mind set, but I don't understand the practical applications of the given examples. This is done at compile time, meaning you need to know at compile time the values you send to template and you test via if constexpr...I know Cpt Obvious. Or is this just a didactic example to illustrate the fact that we can replace some constructs with if constexpr? 
Well, all GUI toolkits I know of use inheritance. Gtk even went on to build gobject to support inheritance (among other things). They are not exactly orthogonal because inheritance *is a* form of polymorphism.
We're talking about an entire branch of an if-statement here. Surely that has enough 'weight' to be worth a warning if it gets eliminated; either "unreachable code" or alternatively "if statement always evaluates to true/false". Both of which already exist in compilers today, I might add. 
Sorry but I disagree. Inheritance is a form of polymorphism, as are templates too. As are higher order functions. They all are different forms of polymorphism. See [the Wikipedia article.](https://en.m.wikipedia.org/wiki/Polymorphism_(computer_science)). Inheritance is the Subtype polymorphism in the Wikipedia article.
I get what you are saying but the thing that bothers me is the fact that polymorphic_allocator constructor accepts only types that inherit from memory_resource instead accepting any T and using type erasure to hold the the memory resource (just like how std::thread constructor accepts any callable and it is the std::thread's constructor duty to implement the type erasure)
Cool, thank you! A few of them are quite standard and don't require any extension (like F12), but a few of these I haven't used before and are very useful. Thanks!
True, I was oversimplifying for conciseness.
If you find yourself writing code like this: void make_sound (Animal *animal) { switch (animal-&gt;type ()) { case cat: play_sample ("meow"); break; case dog: play_sample ("woof"); break; ...repeated for various other animals... } } ...that's a pretty good clue that you are in need of inheritance. Instead of a single, do-everything 'Animal' class that you query for its type, what you need is specialized Cat, Dog, and whatever other animal classes. The base Animal only knows that animals can make sounds: class Animal { public: virtual void make_sound () = 0; }; What sound actually gets produced is up to the specialisation: class Cat: public Animal { public: void make_sound () override { play_sample ("meow"); } }; Callers do not need to know any details about specific animals, so adding further animals is a matter of adding additional specialisations of Animal. This is a major benefit: most of your program can reason about abstract animals, without having to concern itself with implementation details for each type of animal. People who argue against inheritance have typically been burned by Java, where inheritance hierarchies tend to be dozens of classes deep, and nobody knows what goes where anymore. That doesn't mean inheritance is flawed in any way; yes, it can be misused, but so can the other tools that we have. 
Something which hasn't been pointed out yet is the [Empty Base Class Optimization](http://en.cppreference.com/w/cpp/language/ebo) Quoting from cppreference: &gt; Empty base optimization is commonly used by allocator-aware standard library classes (std::vector, std::function, std::shared_ptr, etc) to avoid occupying any additional storage for its allocator member if the allocator is stateless. This is achieved by storing one of the required data members (e.g., begin, end, or capacity pointer for the vector) in an equivalent of boost::compressed_pair with the allocator.
Same question. We need 6.0.
I very much like the idea that this can be triggered automatically. It has been a bit annoying in the past when visual studio formatted a piece of code one way when I close a bracket just for it to be reformatted by clang-format when hitting the shortcut a few lines later.
&gt; You can even do it in C++, using std::function, if you ignore the implementation detail of std::function. "you can do OOP without using inheritance except you actually do". That's like all the people always blabbering some bullshit about "prefer composition over inheritance". Well duh, 95% of the time you still need inheritance if you want to compose run-time behaviours.
Making a post to remind me to read this later.
Next step full clang-tidy integration? 
If `// something` includes the possibility of `return`, `exit`, `throw` etc. then that block cannot be deleted. 
I think it would help this comment chain to post real code rather than pseudocode; I'm not really following your logic. 
That's precisely the idea I was trying to express. Well said. 
&gt; Virtual functions can’t be inlined by the compiler as they can’t be determined at compile time, only during run time. http://hubicka.blogspot.fr/2014/01/devirtualization-in-c-part-1.html in my experience, quite a bit of stuff is able to get devirtualized nowadays if you build with -O3 -flto
Awesome! So this means we can uninstall the ClangFormat plugin :-)
As /u/aw1621107 points out, calling `p-&gt;func()` already implies `p != nullptr` (otherwise you're in UB) and as a result the compiler is perfectly free to elide the "dead" code. Once UB is in play the language does not guarantee any particular set of side effects of the ill-formed program, even if you manage to compile it.
&gt; vendor the single header version in your own repository So with that, you mean copy&amp;pasting the catch header from the Catch GitHub repo to our own repos? In my opinion, submodule is somewhat the superior solution, as you can much easier update the version from upstream. Downloading via cmake is also not such a good solution because then the user has to run cmake to get the catch header. With submodule, everything is included when a user clones with `--recursive`. Or how do you see it?
We are shipping version 5.0 currently, and we'll aim to keep the version updated over time with future releases. Let us know how you find the feature! We want to use these preview builds as an opportunity to get feedback and refine the feature a bit before we hit RTW.
Thanks for the feedback! We're trying to make this as much like the normal VS formatting experience as possible. If you have a chance to try this out and notice any weird quirks, please let us know by filing a bug via Help &gt; Send Feedback &gt; Report a Problem in the IDE so we can address it. 
It is possible to replace Common7/IDE/VC/Packages/clang-format.exe with your own version for the time being. I replace mine with 6.0.
I think the reason is simple - for efficiency. If it takes any type in its ctor, the `polymorphic_allocator` needs to hold some extra space and probably more indirection in call. Also note that `polymorphic_allocator` doesn't own the `memory_resource`. If you want, you can always write a wrapper class that does the type erasure for you.
std::pmr is about stateful allocators, where the allocator is a distinct object, rather than just a type. The allocator manages a particular chunk of memory. We've been using the model at Bloomberg for more than a decade, with good success. Also some pain, as allocator aware types have real costs in writing an maintaining code. They also don't play well with move, and as return types. If you want to control the memory resource in use, you have to pass in the std::vector you're putting things into, rather than returning and moving the guts, since that may not have the 'right' allocator. Making vector have different types depending on the allocator doesn't work well in practice. The mechanism worked well for dealing with different memory models, with near, far, huge, etc pointers, but that went away with Windows '95. 
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8465nc/why_do_people_use_cpp_inheritance_whats_it_good/dvnwxdy/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Do you mean the slides? It is an open issue: https://github.com/CppCon/CppCon2016/issues/4 If you mean something else, could you clarify?
Ah, that makes sense. Much easier when your build is managed in source control and you can "sync and build" with very little configuration overhead.
It's the slides. Thanks for the information. 
&gt; Well duh, 95% of the time you still need inheritance if you want to compose run-time behaviours That is the case *in C++*, but only because C++ conflates inheritance and polymorphism. The concepts themselves are orthogonal and many other languages don't impose this restriction. Which, you know, is the point the comment you're replying to was making.
i recommend the Modern C++ Programming Cookbook. It contains 11 chapters such as modern core cpp features, stl etc. It also adresses many of the new features included in c++14, c++14, c++17.
&gt; Last I checked Clang choked hard on Windows headers. Must have been years ago...
"Most people"? Most people writing C++ at this point in time are doing so because the code is performance-sensitive, and testing debug builds of performance-sensitive code can be an exercise in either patience or futility. IME for the last 15 years at least, most people _test_ (as opposed to debug) their code with optimizations+debug symbols+asserts.
&gt; I inferred it may be the desire or intent of the speaker I think the word you're looking for is 'assumed' – 'inferred' implies you've deduced something factual.
Binge-watch some of the [CPPcon](https://www.youtube.com/user/CppCon/videos) and [MeetingCPP](https://www.youtube.com/user/MeetingCPP/videos) talks from the past few years (2014+). Watch people like Herb Sutter, Stephan Lavavey, Chandler Carruth, Bryce Lelbach, Andrew O'Dwyer, Andrei Alexandrescu and John Brown. They've got really nice talks that taught me a lot of the latest stuff. 
Second _public_ inheritance – private inheritance is greatly undervalued IMO.
In OOP as it's used in C++, which is very much _not_ all there is to OOP.
s/_is a_/_can be_/ The distinction is incredibly relevant.
I agree with this, but Sean Parent's approach does have the added advantage that `object_t` has value semantics. In my opinion, it's often easier to work with uniform value types rather than pointer types. That being said, the complexity/duplication cost that you mentioned is still very high. On one hand, you have to define an `object_t`, a `concept_t`, and a `model_t` and ask that the user implements functionality which is compatible with the given `model_t`. On the other hand, you can just define an interface and ask the user to write an implementation in a derived class. I think the latter is more direct and requires less cognitive overhead when thinking about how pieces interact with each other. [dyno](https://github.com/ldionne/dyno) can streamline the type-erasure approach, but further reduces clarity and (as per the disclaimer) is not intended for use in production.
&gt; that's a pretty good clue that you are in need of inheritance That's a pretty good clue that you are in need of _polymorphism_, for which inheritance is a common approach, but there are other approaches and you are not in need of inheritance.
&gt; accepts only types that inherit from memory_resource instead accepting any T and using type erasure to hold the the memory resource memory_resource _is the_ type erasure; it's in the public interface instead of being done internally, but the exact same net effect is accomplished.
&gt;in my experience, quite a bit of stuff is able to get devirtualized nowadays if you build with -O3 -flto In gcc, devirtualization (static and speculative) happens at [O2](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html#index-O2), but I agree that O3 and LTO are even better. :) Have you tried `-fdevirtualize-at-ltrans` in combination with LTO in gcc?
Inference is a conclusion based on evidence and reasoning. Look it up.
If you are surprised by this result, go watch [*Efficiency with Algorithms, Performance with Data Structures*](https://www.youtube.com/watch?v=fHNmRkzxHWs) right now. That changing `Matrix4` to `Matrix4*` substantially altered the layout to the point that cache invalidation was no longer a serious issue screams to me that `Matrix4` should be a razor-thin handle class (cf. `std::vector`). I don't like resorting to pointer semantics to reduce an object's footprint when doing composition.
Funny; my dictionary shows it as _deduction_ based on evidence and reasoning, with deduction being arrival at _fact_, not incorrect conclusion. I'd stick with 'assume' – it makes you appear less arrogant, though your being wrong on multiple levels is okay for the rest of us, too.
Ofcourse it has the same effects, but it puts unnecessary requirements on the user, requirements that can be solved by the library itself
Would you care to propose an actual C++ implementation of another approach, instead of just spouting generic platitudes? Because I believe this is by far the most straightforward approach. 
That is more or less how programs such as matlab that focus on matrices do it. 
So if I understand that correctly, going from `Matrix4` to `Matrix4*` with custom allocator makes it faster because he turned Array of Structs into Struct of Arrays (with indirections).
You have repeated the same thing 5 time in this thread. Stop repeating, we already got it. Do you think repeating the same sentence makes you point stronger? Have a little respect for others. 
When people use custom allocators, it is probably for efficiency. Using type erasure, or using `shared_ptr` both go against efficiency. 
But inheritance is not subtype polymorphism. In C++, you are basically forced to use inheritance to achieve subtyping, but that is not true in other languages. As a concept, they are orthogonal. Have you read the Wikipedia article you cited? Under the section Subtyping, the section you are referring to, there is a link to the [Main article: Subtyping] (https://en.wikipedia.org/wiki/Subtyping). From that article: &gt; Subtyping should not be confused with the notion of (class or object) inheritance from object-oriented languages;[1] subtyping is a relation between types (interfaces in object-oriented parlance) whereas inheritance is a relation between implementations stemming from a language feature that allows new objects to be created from existing ones. [Here] (https://www.cs.utexas.edu/users/wcook/papers/InheritanceSubtyping90/CookPOPL90.pdf) is the classic paper by Cook on this if you want to read it in more detail.
On the one hand I agree, on the other I then always wonder if I need a default constructed state and what it should be.
I'll just leave this [rtags demo](https://www.youtube.com/watch?v=p6JHriYmVuY&amp;list=PLAL6K6Ycnt4IwjIjWcYV9bFgcTG_4T1Y_&amp;index=4) here. While this uses emacs integration, similar functionality exists for e.g., [vim](https://github.com/lyuts/vim-rtags).
Inheritance is not necessarily a form of polymorphism, where do you get that idea from?
In C++, the most straightforward way to do OOP is inheritance. That is no surprise, the language was designed that way. But that is not true in general, and you can have one without the other. This is ancient history, the [Inheritance is not Subtyping paper](https://www.cs.utexas.edu/users/wcook/papers/InheritanceSubtyping90/CookPOPL90.pdf) paper by Cook et al showed this 25 years back. C++ is flexible enough to allow the "record of closures" technique of polymorphism. I was pointing out that is is feasible, not that it is recommended. BTW, the "record of closures" approach is more flexible than inheritance based polymorphism in C++. I can replace any one of the functions, even at runtime, to customize the behavior of my object. That is the benefit of paying the cost of more vtables.
&gt; When people use custom allocators, it is probably for efficiency. I disagree, what about kernel dev where you would probably want two different pools, one for paged and one for non paged. &gt; Using type erasure ... go against efficiency. Using inheritance *is* type erasure, the difference is that using inheritance forces the user to inherit from memory_resource
Dynamic polymorphism and type erasure mostly. Also DRY to some degree. Even for templates it can also more efficient (both compile-time and runtime) to put the non type dependent functionality into a common base class. CRTP can also be a very powerful pattern. 
Effective Modern C++, by Scott Meyers
Yeah - the ClangFormat binary should automatically update just like it does with the CF plugin today. I got used so much to CF that I can't even think of living without it :-)
You can do it that way, but that's not what inheritance is for. Inheritance is for specialization of implementation, like the classic example of Animal with a method talk() and a Cat subclass that implements talk() as "meaww" and a Dog subclass implementing talk() as "aufauf". Obviously I'm being overly simplistic here. Please find some resources (books, articles in the internet) about inheritance and study those. You can see from the discussion that is a very complex topic with people having somewhat different views on it.
It is very important to know, and is frequently used, it just isn't a magic bullet, and it is overused - in particular, it is used for the wrong reasons. Think less about what all countries _have_ and more about what they _do_. What _defines_ country. For example, a country can let people enter and leave. A country can _tell_ you its population. Yes, it _has_ a population, but in C++, you probably want to express that as an action - a function to get the population. (Now, you don't want classes that have get/set functions for everything they hold, but that's another story). Having all the common variables in the base class might be convenient, but it very often turns into a mess. It limits you. England might decide it would be best to maintain its population by using a list of internal regions, and then summing the populations of all the regions when anyone asks for the population. But you are forcing it to store the population as a variable in the base class. Fine until it isn't. The usefulness of base classes and inheritance, polymorphism, etc, isn't to gather up common code, it is to find abstractions so that you can work at a higher level - where things actually become easier (because you can ignore details - at least when things go well). I've worked with people (very smart people) that managed to refactor their common code into base classes, but they couldn't _name_ the base class anything but "Common" Or "Object" or "base", etc. If you can't name it, you probably don't know what it is. If you don't know what it is, you don't know what it _isn't_. Knowing what it isn't is how you know what code doesn't belong, which is how you prevent your code from turning into a mess. You need to know "this is not the responsibility of this class, this code should be elsewhere". P.S. Try to define what a class is from the perspective of the users of the class, not the implementation. You have some code that deals with countries. What does that code require from a country. That defines what a country is. The requirements of the calling code can often give you good insights. P.P.S. England seems like an odd _class_. To me it seems more like just an _instance_ of country. You probably don't want 195 separate classes in order to implement all the countries in the world. And then each class only has one instance (because there is only one England for example, so you will only ever need one England variable). But it depends what you are doing. If you are implementing _behaviours_, then maybe since each country behaves differently, each really is a separate class. ie every country in the world enacts laws differently, so if you have a virtual `enact_law()` function, then maybe every country needs to be a separate class. And you write 195 different enact_law() functions. Depends on how much detail you need. In the end, every country probably does enact laws differently, but you probably aren't coding that. You might decide at the detail you need, you just need to enact laws democratically vs enacting laws like a dictatorship. This might lead you to have a DemocraticCountry and a DictatorshipCountry, and maybe England derives from DemocraticCountry. And then you only have 2 real implementations of enact_law(). There is a good chance this leads to a mess. It would probably be better to have enact_law_democratically() and enact_law_because_I_said(), and then England's enact_law() can just call that, or maybe that plus some other tweak that is special for the Queen. So there may still be 195 implementations, but they are mostly built from common functions. (But again, it is an odd example) Also consider how would a country change from a Dictatorship to a Democracy - should that require you to change what derives from what, and then recompile the code? Or should that be something that can change dynamically? Having said all that, whenever people bring up inheritance, I always tell a story about how I used inheritance once, and it worked out great. And then I emphasize _once_. Like in 30 years it was only the right solution once. That of course is an exaggeration. But I might easily go 6 months or a year without using it. 
 class Cat { void make_sound() const { play_sample ("meow"); } }; class Dog { void make_sound() const { play_sample ("woof"); } }; template&lt;typename T&gt; void make_sound(const T&amp; animal) { animal.make_sound(); } 
VS will devirtualize any call it can see is being done on a final class/struct/function instance even before LTO.
I love it so far! One thing that would be great is to have some visual feedback of whether VS correctly found the `.clang-format` file in my project and whether it is using it when it formats or when I press CTRL+K+F/D. Like when working with a CMake project where the build directory is somewhere else than the sources. It works nicely but it'd be great to have some visual feedback. I know there was a dialog box the first time I formatted. It said something like "Hey we found your .clang-format file and are gonna use it" when I formatted for the very first time, which is great, but afterwards, I can't find any indication.
Hi! So I've had your issue where I am currently working, where we needed C++ builds in Windows, Linux and Mac, and boy, can I say Windows is a faff. We were also in the process of moving away from TeamCity + BitBucket because of costs and moved to a self-hosted GitLab instead after a few months of trialling the hosted GitLab version (which was waaaay too slow in comparison to the self-hosted GitLab). Anyhow, we started from a green-playing field and wanted to use some of the devops practices ([infrastructure-as-code](https://en.wikipedia.org/wiki/Infrastructure_as_Code) &amp; [immutable infrastructure](https://blog.codeship.com/immutable-infrastructure/)) available to build infrastructure, and because of the whole Windows issues, decided to not go with Docker and containerisation, and instead just use standard Virtual Machines. Although this could raise costs slightly with having lots of VMs around and on all the time, we just had it so that every team has their own couple of VMs in their various OS's (we also have a VSphere ESXI host in house which helped a bit, and because Mac is annoying, we had to use mac-mini's to host our Mac VMs). To actually do infrastructure-as-code though, we used basically all of [Hashicorp's Open Source Stack](https://www.hashicorp.com/), with [Ansible](https://www.ansible.com/), and all of this would be under version control. To put it briefly, it goes something like: Change of program version committed in code -&gt; Packer stands up the VM from a base image -&gt; Ansible provisions the machine -&gt; Terraform puts it in the right place and activates GitLab runners and Consul. (The existing VM is destroyed and replaced with this new one). Ansible is key here, as it's just a yaml file which contains all the programs (and versions) to be installed on the VM, and as it is version controlled, each commit would build a new VM (if that's how you want it). Also it would mean that if you want, you could share the repository with other teams and they can manage their own VMs. One annoying thing we did find with CMake and GitLab, is that if you have multiple VMs for Windows (for example) and multiple stages, and one VM did the starting stage, and the second VM picks up the next stage, CMake would complain as it's in a different directory (due to how the GitLab runners have unique IDs for directories). There is an [open issue](https://gitlab.com/gitlab-org/gitlab-ce/issues/29447) at the moment for the stages to be done on the same runner. You can also add Vagrant at the Packer stage, so that devs can download the exact same machine which is being used by the CI system to their local machines and tests builds locally. 
How do you make a zoo ("container of animals")? `std::vector&lt;unique_ptr&lt;Animal&gt;&gt;` isn't going to cut it... 
This doesn't let you swap dogs for cats at run time though, losing the benefits of what the original solution gives you, that you can: &gt; reason about abstract animals, without having to concern itself with implementation details Here the compiler needs to know the type of animal it's given to issue the make_sound call. If I were to make a Human with a list of pets, I'd have to keep a separate list of dogs and cats, instead of a single list of animals. Now imagine adding in all the various types of birds with their unique calls - your owning class would explode in a mess of vectors of budgies, parrots and cockatiels.
You're right of course, but I still just _cannot_ believe that there is no way to detect and communicate the fact that something like this happened to the programmer. Surely a rule like "any code elimination that relies on detected UB conditions must be warned about" is feasible. The critical part here is the possibility of UB as a precondition to the optimisation triggering. None of your examples feature that. 
so looking at this thread it looks like there's no agreement on what inheritance is good for :) but is there a situation where inheritance is the _only_ possible way to go? I think so (happy to be proven wrong). If you have code that works with some generic concept, e.g. Animal, and there are several possible concrete animal implementations (Cat, Dog, Bird) that all behave similarly, you have three ways of writing generic code that deals with any kind of animal: inheritance (Cat, Dog and Bird inherit from Animal), templates (your code takes a template parameter Animal), `std::variant` (you use a `std::variant&lt;Cat, Dog, Bird&gt;` everywhere). Now, if you can only decide whether your Animal is a Dog or a Cat at _runtime_, e.g. because it depends on a player's choices in a videogame, templates start getting awkward and are probably not a good choice. If, in addition, you want other people to add more types of animals that would still work with your code, `std::variant` is also not an option, because it requires that you list all possible Animals in your code explicitly. So you are left with only one sensible option: using inheritance for runtime polymorphism.
Good article. I tried AMD's Code XL in the past, and I remember it had a gotcha or two that would freeze my computer solid during profiling, I believe it was on profiling 64-bit applications? Does this ring a bell to anyone? I'd like to get back into profiling my code again one day, but as it wasn't something I did all the time it took me a bit of time to setup and figure out, compiler flags and such. is AMD Code XL still the go to profiler for windows?
You mention in the blog post a website for quickly getting started with a dot clang-format file. But a better way to go is running `clang-format -dump-config`, which would write to the standard output all settings. You can also specify one of the presets you mentioned, so the settings output are of that preset rather than the default. If you save that to a file, you get a dot clang-format to adjust to your taste, with all the settings the tool knows. In contrast, the website you mentioned only knows the settings at the time, including settings that have since been deprecated. If you make sure there is no ~/.clang-format file before you run the dump, you’ll be sure to get all settings the tool knows and no deprecated settings.
Please don't post meme-type stuff here. That's what programmer humor is for.
If something requires knowledge of something else in order to be useful, you should put that in the title.
You can, with `std::variant`.
It is indeed Epic's fault. I also do have access to the UE source code, and the inheritance hierachies you describe are indeed in there, as well as the bascially non-existance of const-correctness.
His update method / loop only needs the dirty and transform fields, so everything else wastes cache and with the Matrix4 objects tightly packed by the allocator the next one is likely to be in cache when needed. 
So yea, AoS -&gt; kindof SoA. I wonder if the author realises that.
Wow, thanks for the detailed answer. I have lots of questions about this process, because it sounds a lot like some of us have in mind. Since we also use Gitlab CI, your workflow might be very close to ours on lots of points too. * IIUC you destroy/spin up a new VM for each build, does this have high performance impacts ? * What triggers Packer ? a small program listening to Gitlab hooks ? * how do you configure your runners with Terraform to build the project ? are those project-specific runners ? * how much work was it to put into place ? * how much work is it to maintain ?
Reading these profiling articles really makes me wish I understood more assembly. 
A long time back, I have used kernrate on Windows. Being a command line tool, easy to script around it. Blog that uses the tool: https://blogs.technet.microsoft.com/markrussinovich/2008/04/07/the-case-of-the-system-process-cpu-spikes/
Matlab matrices are based on LAPACK which is written in Fortran. Since the rest of Matlab is written in c++ I'd be willing to bet their internal data structures have pointers to Fortran arrays. 
Yes. I do the same in my simulation code. Every system manages itself, and the instance data it uses is packed into a contiguous array.
&gt; IIUC you destroy/spin up a new VM for each build, does this have high performance impacts ? The VMs stay in place between the teams builds - it's only if they have a configuration change (ie need to upgrade CMake) that their VM gets destroyed and replaced. But at the moment, it does take while and I'm currently working improving the performance impact it has at the moment. &gt; What triggers Packer ? a small program listening to Gitlab hooks ? GitLab triggers Packer on a push to the infrastructure repository (gitlab-ci file there). I have a set of configurations for each project which requires VMs, and each of these configurations are associated with an Ansible-playbook. To know which one needs building, I save a hash of the playbooks between builds and update them at the end of a successful build. This isn't great at the moment, but it works for now as I'm the only one developing at the moment. &gt; how do you configure your runners with Terraform to build the project ? are those project-specific runners ? So I have an Ansible playbook which installs the gitlab-runner to all projects. Terraform then activates it (apart from Mac one which is done in Ansible because Mac's need to be deployed to mac-mini's). These are either project-specific runners or shared runners with very specific Tags if it needs to be used across multiple projects. (Usually the multiple projects one has a very small run time, and so is fine to be shared). &gt; how much work was it to put into place ? It took me (a graduate) ~6 months to get this all in place, with no experience with any of this to begin with (apart from software/coding experience), but with a good manager to direct me places (who also hasn't used any of these tools). Note, this also included the switchover with TC/BitBucket to GitLab, with lots of trials. Someone with more experience can probably achieve this a lot faster, so YMMV! &gt; how much work is it to maintain ? So, to upgrade CMake for example for a project for all Versions of OS, it would be maybe a few lines to change in the specific Ansible Playbook (change the download URL, and version number), and commit it to the repository. This would then rebuild all the VMs from the specific OS base image. Otherwise, maintaining is just doing upgrades and fixing issues which come up. 
Reinterpret aside, SYCL is configurable in buffer ownership. The user may not provide the buffer with initial data, in which case the runtime handles allocation and lifetime of the data. Or the user may provide a raw pointer or a smart pointer and if the type is not const and the pointer not null, the ownership is shared between the user and the runtime. I.E. when the buffer is destroyed the data will not be deallocated. There are may cases about ownership of data between user and runtime in the SYCL spec https://www.khronos.org/registry/SYCL/specs/sycl-1.2.1.pdf In SYCL, any buffer can be copied. This operation will not copy the data internally, as both original and copied buffer will share ownership of the data. As such the data are not deallocated unless all buffer objects that share their ownership are destroyed. If the user also shares ownership, the data are not deallocated. Buffer reinterpret in SYCL is acting like buffer copy. As such, ownership is equally shared between original buffer, copied buffers and reinterpreted buffers. If the user does not share ownership, the data will be deallocated after all of the aforementioned buffers to the specific data are destroyed. Otherwise the data are not deallocated. hope that helps!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/84dvmh/if_i_practice_game_development_with_unreal_engine/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Oh here we go. Yet another inheritance war. This should have been posted on /r/cpp_questions.
Try google: inference synonym 
&gt; then the programmer clearly intended for // something to not be executed if p were null; and I don't even see how anyone could argue otherwise. You have a piece of code with two distinct parts: if (p != nullptr) { // something } You look at this part (and apparently only this part) and assert that the programmer must've "*intended*" (compilers aren't mind readers) for `// something` to run if `!p`. But you completely ignore this part in your analysis: p-&gt;func(); Notwithstanding `// something` changing the value of `p` herein it's clearly the programmer's intent that `p` is not `nullptr`. Your argument is that the compiler should arbitrarily trust the former intent and not the latter, despite the fact the standard has codified that the compiler may do the opposite.
https://hubicka.blogspot.com/2014/08/devirtualization-in-c-part-5-asking.html $ gcc -O2 -Wsuggest-final-types -Wsuggest-final-methods t.C t.C:1:8: warning: Declaring type ‘struct A’ final would enable devirtualization [-Wsuggest-final-types] struct A {virtual void foo() {}}; ^ t.C:1:24: warning: Declaring method ‘virtual void A::foo()’ final would enable devirtualization [-Wsuggest-final-methods] struct A {virtual void foo() {}}; ^
But if you change int to size_t, you get no warning (I think) ``` // we compare vec[i] to vec[i+1] so stop one before end for (size_t i=0; i &lt; vec.size()-1; i++) ... ``` 
&gt; But if you change int to size_t, you get no warning (I think) Which has nothing to do with promotion, which is what the person I was replying to was explicitly talking about: &gt;Promotion generally seems to be the worst part of the language Also unless my understanding of the standard is lacking`size_t` (notwithstanding being within `namespace std` or `using namespace std`) isn't guaranteed to work since the standard requires only that the things taken from the C standard library be made available in `std` not necessarily in the global namespace.
Nice!
So you want to trade compile speed for easy to make linker errors if the class happens to be misspelled ever? In any case; yes its technically a thing that can be done it just seems incredibly hackish.
Technically, the `1` in `size() - 1` was promoted to std::size_t (I think). But whatever, point is that it is easy to get wrong code and no warning. I'm not disagreeing with your points, and just adding to the madness.
The point of lazily evaluating log arguments isn't to avoid side effects, it's to avoid the cost of evaluating the log argument entirely when you've disabled a particular log level.
He does :)
I'm having trouble imaging a scenario where this would give linker errors. You should instead get compile-time errors when the implementation of the class in its .cpp file. Either it uses the right type name, and the compiler detects a type mismatch, or the .cpp file uses the typo'd name, in which case the compiler complains about a type with no definition in scope being used. In any case, this is the kind of thing you break once, while writing the file and fix right away. Then everybody who compiles code using your API benefits from the reduced compile times. Don't discount the benefits this can have on a large code base. A few years ago my employer at the time had a fairly large C++ codebase and somebody made it his mission to improve compile times. Replacing #includes with forward declarations was one of the big things he did and it made an enormous difference.
When in doubt, do as `std::vector` does (but don't specialize for `bool`...).
Old codebase, simple as that.
Alright fair point; Should have probably thought through it a bit further than just the initial complaint/problems of doing.. in .h class vecc3; //(misspelling intended) class that_uses_vec3{}; in .cpp #include &lt;vec3&gt; Not saying I don't see a benefit for doing so; I just still think its hacky and wish we had a better way. Seems like a similar complaint that everyone has with std::enable_if&lt;&gt; and having to duplicate the function + boilerplate a ton of times vs if constexpr().
Forward declaring other people's classes is fragile. For example, if they restructure their code and do the right thing and provide a typedef that allows old code to transition, you'll get a conflict. 
Which is exactly my point ;) An optimizer, upon seeing that the result of a pure function is only used if a certain condition is met, is allowed to move the computation of said result within the if block. Therefore, a call to a "pure" function might as well be "lazy". Except that "pure" is more generic, as it also covers repeated invocations.
I have had a look at the github page and it says it requires boost 1.44. There is a 3 year old (!) pull request open aiming at ‘making it work with recent boost versions’. Recent in this case apparently means 1.49. Is this an actively maintained project?
In the games industry, developers typically run the code with both optimizations and assertions enabled for the main development lifecycle because the code is just too darn slow otherwise. Disabling optimizations is really only something you do if you want to step into a snippet of code with the debugger, because your program can easily turn into a slideshow without -O1 or the equivalent (at the very least). Assertions provide a nice balance because they don't impact the entire codes performance like -Od or -O0 do, yet they still allow you to quickly figure out where problems may be arising (especially when you tell the compiler to keep frame pointers around). If C/C++ compilers didn't generate truely abhorrent code with optimizations disabled, I would probably be fine with just enabling assertions in debug builds. Sadly, it almost as if compilers almost go out of their way to generate terrible code when optimizations are disabled. Even in x86, it wouldn't be hard to beat a non-optimizing compiler just by writing a first pass "it works" solution.
bro you inspired me to try and so a compile-time sudoku solver, but holy hell I don't even know where to start. any resource on how to get good at this dark art?
Not sure if that applies here: Vector has a natural empty state. A 4x4 matrix doesn't. A vector knows it's allocator. A matrix handle probably wouldn't? What would be the semantic of the following code: Mx mx1 = gAllocMx(); // fill mx1 with data Mx mx2; mx2 = mx1; Would mx1 and mx2 point to the same data or would mx2 be a copy (where would the data be stored) or should this assert?
In this spirit, [Dyno](https://github.com/ldionne/dyno) is an interesting library to check out. 
Can't be used for template classes which our code base has a lot of.
2-3 years ago maybe. Are you saying they work fine now?
Yeah, I'm very skeptical of forward declaring classes outside your control. However, forward declaring your own classes is a good idea. I actually like to have fwd.h files, akin to iosfwd, to contain my forward declarations as well as typedefs/aliases to various smart pointer types.
Sry! for the late reply. Awesome bro. I appreciate your help. 
Thanks mate !! 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/84haem/using_const_to_help_optimizers/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
In the same line, I find it weird there are no notnull annotations in the standard libraries I looked at for the std::string constructors. It would be super useful for static analyzers. I had to add them myself to find incorrect usage of std::string when migrating away from a custom string type that accepted null pointers before.
I feel that there is something missing. Input iterators (that are not forward iterator at the same time) only support single passes. This allows reading from streams using iterators. What you have read once, can't be read again. Also not every forward iterator is an output iterator: a const vector iterator for example is random, but read only.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/84gwij/retrieve_documents_pdf_docxls_image_metadata_in_c/dvpk3aq/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sure you can: #include&lt;iostream&gt; #include&lt;memory&gt; template&lt;typename T&gt; class SomeClass; template&lt;typename T&gt; struct Container { std::unique_ptr&lt;SomeClass&lt;T&gt;&gt; ptr; }; template&lt;typename T&gt; struct SomeClass { T item; }; int main (int argc, char** argv) { Container&lt;char&gt; container; container.ptr.reset(new SomeClass&lt;char&gt;); container.ptr-&gt;item = argv[0][0]; std::cout &lt;&lt; "Value is: " &lt;&lt; container.ptr-&gt;item; return 0; } 
With giant code bases, forward declare as much as possible!
Thank you! Another great update for a great library! Small question though, I haven't looked deep into it but is there a way to get a `std::string_view` out of a `nlohmann::json`? Right now I'm doing `std::string_view{value.get_ptr&lt;const nlohmann::json::string_t*&gt;()-&gt;c_str()}`
Since you've been doing C99, you're not on Windows, I assume, and GCC supports them in C++ as an extension. As someone who does cross-platform development, forgetting that it's a GCC extension has bitten me more than once.
Maybe he lost control over the old account?
Nope, just been a little busy with other things. 😁
Yeah, it’s not exactly abandoned but it’s not actively maintained either. If anybody’s interested in taking it on and making it better, happy to help. 😊
It has, but I always aim to write standards-compliant code rather than using extensions.
Constraining special member functions.
Best match is the big one. However ranges V3 shows that a lot can be emulated. A huge cost, though. 
A few things that come to mind: - Type erasure when the thing being erased can be of arbitrary size means that you may need a memory allocation. There's a certain irony in having an allocator whose constructor allocates. And now you have to have some way of controlling where that allocation takes place. Turtles and all that. - Allocators are supposed to be lightweight and must be nothrow copyable. So your copy constructor can't clone the type-erased allocator and basically must do reference counting. - Even when the underlying memory resource is thread-safe, a stateful allocator itself - which is supposed to be a lightweight wrapper - is unlikely to be. So copies of the type-erasing allocator basically can't be used safely from multiple threads no matter what. - You can only type-erase once at the point of construction, and you have to support rebinding to arbitrary types post-construction, so either you don't rebind the allocator being erased (and allocates only in units of that allocator's `value_type`'s size, introducing inefficiencies) or you rebind it to something like `std::byte` or `unsigned char` before erasing, and risk confusing the user ("I passed a `MyAllocator&lt;Foo&gt;` to a `polymorphic_allocator&lt;Foo&gt;`, why is it using `MyAllocator&lt;std::byte&gt;::allocate`?) - The classic allocator interface offers no way to separately specify a desired alignment because it only allocates for the `value_type`. With type erasure and rebinding you'll be allocating for a `Bar` using a type-erased allocator for `Foo`, so you'd need to manually correct for alignment issues. This means more overhead and inefficiency. - It's not possible to type-erase `construct`, `destroy`, or the propagation traits. You're taking an allocator and then silently ignoring many of its customization points. - It may make writing new memory resources harder by requiring the allocator boilerplate.
I viewed it as basically splitting hot and cold data.
The sidebar has resources on getting started. Most people probably wouldn't recommend code::blocks with Visual Studio Community being so powerful for creating Windows applications. If this is your first language, sticking to the one language is probably you best bet. Most of learning a new language is syntax once you understand programming (at least with other OOP languages), so really focus on learning the concepts
Alright thanks. Ive done a bit of Python but to be honest I haven't done it in a couple years and I remember nothing lol. I tried visual studio and found it kinda confusing but I will do some more research on how to work the application. Thanks 
I'm blown away by the number of package managers you support. Can I ask how and why?
Well, the "TL;DR" of it in my view is: because it's easy, straightforward, well understood, and in many cases the perfect solution to the problem at hand.
(Off-topic: Your color scheme makes your text *very* hard to read.)
How : It's a single header library with no pre-compilation. 
Nice! I use this library extensively for my embedded web-backend project at work. 
Are you sure you really want to learn C++ first? It's a very hard language by any measure (not without rewards) and without an expert to pull you out, you'll get stuck in no time. If you, for instance, stick to Unity + C# or NodeJS with Meteor, it'll be 100x sooner that you'll have something cool to show. C++ really is a professional tool, like a welding machine.
alright, might tree C# or unity first.
Which of those would you suggest
I've never used code::blocks myself, but for starting out I'd recommend using whatever works best for you. IDEs like Visual Studio are great and all, but they can be overwhelming if all you want to do is learn how to write C\+\+. I personally use Vim for everything now but I started out with Eclipse CDT. Don't get too hung up on your editor yet. You'll have a lot of time to worry about that later. As far as resources for learning, I've found the most success with picking up new languages by just diving in and making judicious use of Google for any and all problems I encounter along the way. Ask lots of questions; ~~the internet~~ StackOverflow has plenty of answers. Bonus points for asking out of curiosity instead of necessity. I see in another comment in this thread that you've already worked with Python a bit; that's good, and you should definitely revisit that too! You may be tempted to learn C at some point and you should. Not yet though. Please do not try to learn C and C\+\+ and the same time. Really. I did that, and I had to unlearn a lot of stuff later. I would strongly encourage you to make a commitment to just learnin*g eith*er C or C\+\+ for now.
I've heard good things about CPP so probably gonna commit to that. Also thanks for the website didn't know Stack Overflow existed. 
I'm more asking how he distributes to all those channels, in whatever package format they expect. Lessons learned in the process?
If the compiler can prove that it's always of the derived class, it will still work out. Example: finalDerived* getDerived(); Base* myBase=getDerived(); myBase-&gt;foo() It will correctly call `foo()` from `finalDerived` because it knows it is of this type.
Yes, but that optimization is in-dependendent of final
&gt; That is the benefit of paying the cost of more vtables. That's not the only cost though, in my opinion. You also pay for that runtime flexibility with increased maintenance costs, in a similar tradeoff to dynamic vs. static typing in general.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I only maintain the Homebrew formula myself. All other package managers where introduced by the community via pull requests. After a release, I need to open a few issues here and there and the respective maintainers update the formulas. (I am also blown away home many package managers exist :))
Since you mention Cook, I'd be remiss not to link to Corky Cartwright's rebuttal: [Reconciling Inheritance and Subtyping](http://www.cs.ox.ac.uk/ralf.hinze/WG2.8/31/slides/corky.pdf). See also ["Inheritance *Is* Subtyping"](http://www.cs.ox.ac.uk/ralf.hinze/WG2.8/31/slides/corky-extended-abstract.pdf). Essentially he argues that inheritance and subtyping are equivalent in *nominal* type systems. (Note that "inheritance" here does not include C++'s private/protected inheritance.)
Yeah that would be great! I guess the getter would be kind of the equivalent of what I'm doing right now, maybe minus the `.c_str`? I'll be looking forward opening a pull request. I've never went to inspect the source code yet, but this sounds like a good task to start.
That would be awesome!
Let's see if I get this right without a compiler... class Cat { void say_meow() const { /* meow */ } }; class Cat { void say_woof() const { /* woof */ } }; void make_sound(const Cat&amp; dog) { cat.say_meow(); } void make_sound(const Dog&amp; dog) { dog.say_woof(); } void make_sound(int i) { std::cout &lt;&lt; "Ints can't say anything..."; } class Zoo { public: template &lt;typename T&gt; void add_animal(T t) { zoo.push_back(std::make_unique&lt;Model&lt;T&gt;&gt;(t)); } void make_sound() const { for (const auto&amp; animal : animals) { animal-&gt;make_sound(); } } private: class Concept { public: virtual ~Concept(); virtual void make_sound() const = 0; } template &lt;typename T&gt; class Model { public: Model(T t) : t(t) void make_sound() const { make_sound(t); } private: T t; } std::vector&lt;std::unique_ptr&lt;Concept&gt;&gt; animals; }; int main(void) { Zoo zoo; zoo.addAnimal(Dog()); zoo.addAnimal(Cat()); zoo.addAnimal(42); }
&gt; we still need a way to implicitly nuke the call from orbit in a release build. can't you do that with a conexpr if? 
I had the exact same feeling.. i actually expect that C++ dev's are generally well paid. Just consider that quite some work in finance, which are typically well paid jobs.
I don't understand all the fear of people changing things. Just adjust your code and you're done.
Those are Unix functions that probably aren't supported on Windows.
Could it be due to gamedev having quite low salary and being mostly done in C++? Note that java did not make it to the list also.
Anyone have experience with this on linux? I'm using perf + hotspot for profiling now, I guess it could be a big step forward to have vtune instead.
If you're looking for help, try [cpp_questions](https://www.reddit.com/r/cpp_questions/). Please never shorten the errorcodes you get from your system. Anonymize them if possible, but don't try to rewrite them from memory. From a first glance, I'd say you forgot to link against the libraries with the definitions of the types. Look [here](https://stackoverflow.com/questions/5862757/how-do-i-link-to-a-library-with-codeblocks) how to add libraries.
Those are not compiler error, those are linking errors. Maybe you need to link the program with "cygwin1.dll" library.
"Overworked README by adding likes to the documentation (#981)." I'm sure you meant "links" instead of "likes".
I like hotspot - vtune is similar but more powerful in some regards - and sometimes overkill 
Of course one can always count on the C++ community to come up with a wildly impractical, utterly unnecessary template-based solution to what is actually quite a simple problem. Presumably you meant for Model to inherit from Concept, otherwise your code doesn't make much sense. So what, exactly, is the insight you wish to demonstrate: that you can simulate inheritance using inheritance? 
That's exactly it. Outside of game development, C++ makes more than average (see the numbers for back-end developers).
Hmm... It's hardly impractical. 1) You can create "type hierarchies" which can include native types or external types that you can't modify to inherit from your base class. 2) You can get "type hierarchies" with value semantics.
:-) Thanks, fixed.
Thank you for this library! I use it for quite some time now and it definitely is the best json implementation I've ever seen.
C++ isn't actually mentioned in the data linked to by the OP, I think they are actually referring to [this plot of average number of years of experience vs salary by language](https://insights.stackoverflow.com/survey/2018/?utm_source=Iterable&amp;utm_medium=email&amp;utm_campaign=dev-survey-2018-promotion#work-salary-and-experience-by-language). This doesn't match with my personal experience, but the [salary by developer type](https://insights.stackoverflow.com/survey/2018/?utm_source=Iterable&amp;utm_medium=email&amp;utm_campaign=dev-survey-2018-promotion#work-salary-and-experience-by-developer-type) does. I'm just one data point though!
Please use proper text formatting. Why wouldn't you put at least one space after a period ending a sentence - preferably two? Please don't intentionally make your content hard to read.
Quants probably don't consider themselves developers though. 
I wonder if running cl.exe inside a job (https://msdn.microsoft.com/en-us/library/windows/desktop/ms684161(v=vs.85).aspx) could help. Just a wild guess.
Ignore heavily biased sources and look for reports from the industry you are interested in. E.g. C++ in financial services pays considerably more than the top of that list.
90-day free license. [Previous discussion](https://www.reddit.com/r/cpp/comments/7qtwbd/intel_system_studio_free_renewable_commercial/).
I think that StackOverflow results are accurate for C++ devs with three to eight years of experience. It takes longer than that to properly master C++ nowadays. Certainly in the clients I've contracted at in recent years, nobody had less than seven years experience, and usually more than fifteen or twenty, in some cases thirty years. One of the most remarkable things is the paucity of younger engineers. I'm regularly the youngest in a client's team, despite twenty years of experience. Long run that can't be good for C++.
Partial ordering is the thing! (as SFINAE can do member functions too)
That's fucking scary! I'm a C++ developer at the moment and I've been working with it for 3 years. I love C++, but based on you're comment is gonna be hard to find a job if I'll need to change at some point
That's fucking scary! I'm a C++ developer at the moment and I've been working with it for 3 years. I love C++, but based on you're comment is gonna be hard to find a job if I'll need to change at some point
If you're happy to relocate to one of the major C++ cities, there will be work for you. They're the usual suspects. If on the other hand you don't want to raise a family in a large city, you're mostly screwed. C++ doesn't have a culture of remote working like say Rust does.
&gt; and can be refreshed an unlimited number of times
With concepts, instantiating a class template with an invalid type results in a soft error. Without concepts, your only option is a static assert in the class definition, and that will be a hard error. https://godbolt.org/g/xRkdwZ
I really like the simple usage. But damn, I looked at some of the source and it’s still a mystery to me how the C++ committees think they’re making a good language and going in the right direction.
Thanks, could you indicate some place where the rules to choose the best match are explained? I think if I knew more I would better appreciate the improvements over SFINAE
SFINAE can do member functions, but special member functions cannot be templates and you need templates for SFINAE. If I recall correctly, it's still possible to achieve SFINAE-like effects by deriving from a base class in which special member functions have been selectively ``delete``d with some template metaprogramming.
There doesn't exist any language named C/C++, therefore there doesn't exist any C/C++ library.
Is there a cpp specific salary survey that has been performed in the recent past? Thanks!
I would take everything in this survey with a grain of salt. It shows that less than a third of developers have children which I think is an indication that selection bias is heavily skewing the results. 
If anything, their current direction seems to be making it easier to write libraries.
look good
I was reading up about it over at cpp reference: http://en.cppreference.com/w/cpp/language/constraints The legalese can be a bit dense, but the examples seem more straightfoward.
Does "language X developer" even make sense these days? To get a well-paid job you likely need to be proficient in multiple languages and in CS too (to pass the interview, at the very least).
Could it be that this reflects the distribution of the developers across countries? Look at the US where the salary are much higher than the average and the difference between languages way smaller, and again I image the salary differences might be significant in USA. A meaningful list would have been to normalize the salary by the average salary (in programming and overall) in that location.
Very fair point, that could be a maintenance nightmare and breaks the concept of build reproducibility.
How long would you say it takes to master C++? I've been studying it for 5 years and still feel like a noob.
Depends on your skill level and commitment to learning it. I've seen Google Summer of Code students at Boost go from virtually nothing to on the C++ standards committee within four years. They're very rare, though. Most of us normal people probably need at least ten years, and even then you can only ever hope to become expert in some subsection of C++ e.g. low latency. I'll be joining the committee this summer, and I can confidently say that I wouldn't consider myself a master of C++.
&gt; I guess the getter would be kind of the equivalent of what I'm doing right now, maybe minus the `.c_str`? When things are "*equivalent*" it means that they have the same outcome. What you're doing doesn't have the same outcome for strings which contain U+0000. Therefore the two would not be equivalent. 
Then I guess my version with the `c_str` is wrong! The goal would be to return a view to the internal string.
It saves you writing similar/the same code more than once.
True, if it's your code. If it's someone else's code, then all bets are off. Of course, this depends on what the definition of "your code" is. Code by you and or your team is probably fine. Code in a 3rd party library is questionable. Code by someone else in your organization outside your team can be a bit of a gray area.
 To be fair, it's only new in the standard. Boost has had it forever, and plenty of libraries have lower-cost tagged-union types. &gt; Is there any benefit to this, other than its shiny new allure? A couple, actually. How much they matter is situational, obviously: 1) No vtable taking up room in the cache. 2) You can keep it all on the stack. 3) Containers of variant-types have better locality. You can get similar with custom allocators or placement new, but it's not the default. 4) Better optimization; this is *highly* variable, though. Large variants often don't optimize away, and sometimes the compiler can devirtualize the inheritance-based approach. I think both approaches have merits. It's all really situational. I also think that without real pattern-matching the variant-based approaches end up with more boilerplate and aren't as easy to read. 
Be careful when installing this on Windows. On my Win 10 machine, it BSOD with problem in VTSS.SYS (The Event Sampling Driver) - it can be disabled from the install.
**Company:** [Canon Medical Research Europe](https://www.research.eu.medical.canon/) **Type:** Full-time, permanent **Description:** Canon Medical Edinburgh make software for medical scanners. We're looking for [Software Engineers](https://www.research.eu.medical.canon/recruitment/vacancies/software-engineer-3) who have worked with an OOP language such as Java or C++ and are looking for a new challenge. **Location:** Edinburgh, Scotland, UK **Technologies:** C++, C#, Java, Python **Contact:** Email recruitment.edi@eu.medical.canon
ELI5 What is Intel VTune?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; Over half of respondents have five years of professional coding experience or less. That explains a lot of this. This survey has a strong bias towards people with little experience (which should correlate with having children, in my mind) -- which makes some sense, given the site that did the survey.
It would be interesting if we were given the median instead of mean.
No, in that case the arguments would still be evaluated -- assuming they even compile. 
What is the advantage / disadvantage of VTune over Windows Performance Toolkit or the VS Profiler?
I have used both, though mostly vtune. It is a really great tool to have if you actually care about performance. I think that it is good to use both, one does not negate the other
There are still a lot of C++ jobs that are just C++ jobs, maybe a little Python on the side when you need something to do script work.
Not a project, but [Rosalind](http://rosalind.info/problems/list-view/) sounds related to this.
My title is literally "quant developer" LOL.
I think each of those solutions has benefits, that may make it more applicable for certain solutions. The example is too simplified to really argue about the context. There may even be a situation, where the following is useful class Animal { std::string sound; public: Animal(std::string sound) : sound(std::move(sound) {} void make_sound() { play_sample(sound); } }; Animal Cat() { return Animal{"meow"};} Animal Dog() { return Animal{"woof"};}
I agree there's tons of bias (even just participation bias). However, keep in mind developers are getting churned out faster than ever. In 2015, the equivalent of CS101 had more students than the equivalent of chem 101 at my school (which was required for every single STEM major, as far as I remember). I think the number of students in CS101 either doubled or tripled between my freshman year (2011) and my senior year (2015). And that's not to say anything about bootcamps or self-learning.
I have done some in Python, now I want to do more in C++.
I'm in embedded and we've got a number of recent grads and 5-10 year experience people. There are "Junior" level jobs out there.
Or fast.
I’m working on [chemfiles](http://github.com/chemfiles/chemfiles), a C++ library for reading/writing chemical file formats. It’s only partially related to bioinformatics (through biochemistry simulations) but you might find it interesting! There are area of improvement ranging from “quite a bit of chemical knowledge required” to “this is actually a CS problem” (AST optimisation, garbage collection integration)
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/84ouz2/calc/dvr5wqw/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sean Parent's approach outlined in that talk is actually a great choice when it's impractical/infeasible/undesirable to demand that your API's clients invasively inherit from some interface base class (for runtime polymorphism), or have a member function of a particular name and signature (for static polymorphism). Simply overloading a free function is non-invasive and fairly clean as far as these things go. Of course it's not always possible to use that approach, but it is a good tool to know about and have available.
&gt; incomplete.c:4:17: note: ‘INT_MAX’ is defined in header ‘&lt;limits.h&gt;’; did you forget to ‘#include &lt;limits.h&gt;’? This seems redundantly verbose. Why not just: &gt; incomplete.c:4:17: note: ‘INT_MAX’ is defined in header ‘&lt;limits.h&gt; ? Also, is this extensible? Is it hard-coded? 
Does it pay well? ;)
being on the committee is one of my goals in life! congrats! I'll keep at it! I need to improve my TMP skills :)
the more I know C++ the more I like it!
I think if compiler is so smart there should be a switch that automatically inserts missing headers. On the other hand in any modern IDE unknown types are marked and usually there are in-place fixes that inserts missing headers, I guess this compiler feature is more useful for those that work in simple editors without any semantic indexing.
These are really nice changes and in hindsight seem so obvious I'm a little surprised it didn't work like that in the first place.
I'd say yes. 
Legacy medical device support. Yay. Note that I did mention well paid AND interesting. Neither of those applies to those kinds of legacy support roles.
Definitely not a compiler feature. IDEs can do that if they want, but I do not want that in my compiler. 
It's even mentioned in this post that the compiler can generate a diff for an IDE to use to do this
Sure, no argument. I would recommend to any developer to see that talk, it's brilliant and entertaining and the technique is well worth knowing. It just seems like a common pattern that C++ devs watch this talk, fall in love with it, and declare they are going to replace all traditional usage of inheritance with this. IME, a large fraction of the time (more than half), there isn't really any practical downside to intrusive inheritance (heck, half the time or more both the base and any present and likely future derived are controlled by teh same team). In these cases, adding a bunch of boilerplate to avoid something that is bad "in principle" IMHO isn't the right trade-off.
Why bother with the compiler though? Other than GCC and stdlib specific headers how would it even know? The usage is extremely limited
Yes, you can use Format Document or Format Selection for formatting, and you can also get automatic formatting as you type special characters like semicolons and braces. We just run the actual clang-format.exe, so it will handle what the utility would normally handle on its own. 
Can someone explain how to go through page "Register an Account", button is not clickable. Student and free commercial behave the same. :(
I agree. I'd actually like to see the correlation between pay scale and # of languages used. I'm guessing more versatile people make more money. 
In the cases like: int i int j; it would seem more useful to me for the message to be "missing semicolon after `i`", rather than "missing semicolon before `int`". Similar for the `42` example and others.
&gt;normal people probably need at least ten years Do you think this speaks poorly of the language as a whole?
Or near any military/gvmt installation that does R&amp;D. I live in a city with 60k people and half the time we would give an arm for a decent C++ developer. It's almost the opposite -- many people just don't want to live/work in small municipalities.
To be honest, if you can handle yourself in C++, you will be able to pick up other languages pretty quickly. Half of the people you see fantasizing about mythical "language X masters" 1) do not consider themselves masters, and 2) can't tell you what a master is. Employers, on the other hand, don't expect you to be an encyclopedia -- they just want you to be creative, conscientious, and productive. Do those things at a company that has any future, and you will do well.
No problems here; I think it's probably safe to assume your issue is an outlier, not the norm. ;-] Any other details on your setup?
Hardware event-based sampling (if you can get the driver installed), energy usage analysis, very granular cache analysis. It's more powerful if you care about the details; price used to be the primary inhibiting factor, I'd say learning curve is now.
Where I work, we switched to 11 a couple of years ago. Currently some teams work on 11 and some on 14, they are both supported generally (I of course have moved my team to 14). It's likely that 17 will be supported within the next year, or perhaps less. Newer C++ versions are almost entirely backwards compatible, so while demanding to work on an idiomatic &gt; C++11 codebase isn't always feasible, but not being able to at least write *new* code in C++11/14 is pretty bad. I'd definitely jump ship so your skills aren't falling out of date. There isn't a dramatic amount of new stuff to learn post 11, but 03-&gt;11 is a huge transition, value categories, variadics, different idioms for memory management, etc.
[author of the blog post here] Indeed - thanks for the suggestion. Someone else mentioned this in a different Reddit discussion of this; I've opened https://gcc.gnu.org/bugzilla/show_bug.cgi?id=84887 to cover it.
Thanks. I've filed https://gcc.gnu.org/bugzilla/show_bug.cgi?id=84890 to cover the verbosity. Right now it's hard-coded. I might make it extensible in gcc 9.
That's a very United States centric situation. Almost all of the rest of the world has little to no government funded use of C++ for any use case.
Not really. C++ has moved up the value chain, that's all, and there has been a corresponding rise in how much training and experience someone needs. For example, there is a huge difference in skill level required for a MFC apps developer as against almost all modern C++ development.
Seqan2 is a popular library that provides tons of bioinformatics libraries. I'm not a fan of Seqan2 and its style/lack of idiomatic C++, but luckily there's a modern C++ seqan3 in development: https://github.com/seqan/seqan3
Thank you for making these improvements!
&gt; Top end C++ devs earn $300-500k in the US in salary before stock options/bonuses. I will need names. 
Yes, sorry. That could be true.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/84plg5/continue_learning_c/dvri86u/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
We have switched to C++14, and only thing that is preventing C++17, is that most compilers only partially support it (talking about the specific version of Clang used in Xcode 9, Android studio, and the one in Emscripten), when we get to an acceptable level of support we will switch again.
When I was looking around for C++ work accross europe, the tendency was that gamedev payed like 2x less then most other C++ jobs. Best salaries for C++ developers were mostly in the finance industry.
Is my mobile font off or are the green arrows pointing anywhere but the correct column? That would kinda defeat the purpose....
I got like a 50&amp;#37; pay raise when I left gamedev. That was a few years ago. Now, I make more than double what I was making in games, while also not working 12 hour days and weekends. I haven't looked back, to be honest.
Right now I'm developing desktop software. Where can I start looking for C++ for embedded systems?
What do you think a better ballpark would be? At my work the ratio is probably closer to 50\-50, but just down the street at the Amazons and Facebooks of the world I imagine the ratio is much lower.
He could look in the -I directories for the definition of the types. Sure, it seems overkill, it could be a special flag, or a cache, or whatever. It would make IDE life quite better.
Heh. They're all on the committee. And it's not as much money as it sounds, they have crazy living costs. We were comparing our incomes and we had similar disposable income after unavoidable costs back in 2016 which was a good year for me, but I didn't earn even a quarter of that that year. But I don't live in the centre of Silicon Valley or New York.
your mobile font is off :)
Then i duck in shame :)
Sure it's easier to write a MFC app than ever. But C++ developers aren't called to do that as frequently as fifteen years ago. If you're writing in modern C++, generally it's much more specialist than it was. i.e. harder, rarer, more training needed.
ah, i think that makes sense. i never thought about it, but of course the parameters cause a problem. so i checked on godbolt, but now i'm just confused: #include &lt;string&gt; #include &lt;iostream&gt; #include &lt;functional&gt; const bool enable_log = false; inline void log(const std::string &amp; message){ if constexpr(enable_log){ std::cout &lt;&lt; message &lt;&lt; std::endl; } } /* template&lt;typename T&gt; inline void log(T logfunc){ if constexpr(enable_log){ std::cout &lt;&lt; logfunc() &lt;&lt; std::endl; } }*/ int main(){ int var = 1; // just do something strange for(int i = 1; i &lt; 1000; i++){ var *= i; var ^= i; } //optimized away, but not very practical // log([&amp;](){ return "some variable = " + var;}); //what?? //1. as is, the param is evaluated //2. enable the log template, and the param is not evaluated log("some variable = " + var); return var; } i used `-std=c++17 -O3` on https://godbolt.org/ do you have an idea what's going on? 
&gt; I don't live in the centre of Silicon Valley I live in the middle of Silicon Valley and I demand to know where I can pull that salary. I'm not kidding, btw. 
Ultimately if you're happy where you're at, that's all that matters. Some of my colleagues are appalled at how little I earn, but I get to (usually) live in the Irish countryside where I spend actual quality time with my family and children as a remote worker. There are more forms of wealth than money, freedom from labour and commuting is very valuable. But then I would think all of that as a European, many here consider two months of statutory holidays too low! Less pay, more holidays!
I wrote cpp 15 years ago, and i write it today. It's not harder for any program.
Wait, does this mean the compiler will remove nested null checks?
Header order is a huge fucking problem with microsoft's headers. generally include Windows.h as the first microsoft specific header and you'll be ok.
Chrome literally just switched to clang everywhere.
Your directory structure and number of files is very hard to understand...
Yes but the programs being written are harder than they were. Requires more specialist knowledge.
How so?
There's some systemic things you can do for better diagnostics, but most of these come down to someone spending time on finding a better way to present some specific error for some specific bad case. There's tons of "obvious" improvements still possible that just need someone to sit down and implement them.
It can often come down to what's most straightforward to implement. Like if your parser sees `int i int`, unless it's already keeping the previous token stored, it's much easier to have it complain about the `int`. It's also more generic - there are a set of possible tokens that could come next and `int` isn't one of them. To get the better diagnostic here, you have to recognize that `int i` was meant to be its own statement and the next `int` starting a new statement. This is turned up to 11 if using a general parser tool, which I believe GCC did originally, so it's unsurprising that early errors wouldn't change too much over time. It's not exactly trivial to add that token of lookbehind if the tool doesn't already support it.
&gt; Besides giving nicer compiler error messages and better readability
You're not asking too much, but also your employer isn't necessarily wrong either. When you've got a large code base for a product used by a lot of customers, there's a lot of risk and an unknown reward in changing to the latest and greatest; especially when weighed against getting the next set of features out. If you feel it's hurting your career, or even just makes you unhappy, and if you can find a job that's using something newer, then of course go for it. We're using C++14 at my company, and we'll upgrade to C++17 once the compilers are more stable, but we have that luxury because we're small; plus we're engineering driven, and consider it important for morale if nothing else.
Thank you for doing this type of work. I'm intrigued by the private field getter - I'm not sure I've ever needed it, but it seems like a neat idea. The template improvements I will definitely use and am looking forward to. Thanks!
Usability is fine, but they'd better focus on regressions, it is very sad situation.
what regressions?
While generally a very good article, the 100% memory safety claim is dubious. There are still plenty of ways to hit UB or out of bounds accesses, but the methods described are definitely worth following. Think it might be worth mentioning flagging anything going through void* (especially without a length).
Life is short, and programming jobs are plenty. If you're unhappy, change places! The recent stack overflow Dev survey showed that mindset is fairly common. 
You need another set of parens after the lambda to actually evaluate it since the compiler won't do so implicitly. I've heard about proposals to automatically convert parameters to functors; this would be handy for conditional logging. That having been said, this is still relying on the optimizer to strip the call, and that sometimes just isn't good enough: * The expression may not compile: DebugGetName() just doesn't exist in the Release build. * You need an iron clad guarantee. On platforms where you have to go through first-party cert, there are often debug-only calls that you Must Not Call(tm) in Release, or you will fail first-party certification. In these cases you do not want to rely on the optimizer, you want absolute assurance that those calls get compiled out so there is no possibility of symbol references. The preprocessor does that. 
!removehelp
Likely they both copied Clang.
Oh. Cool. I haven't really used clang in product except for its clang-format tool. Great to see their positive influence, then.
I think the point /u/14ned is trying to make is the areas C++ is being used has become much more specialized. 15 years ago, if you wanted to make a GUI program on Windows, MFC would be the default choice. Now it is WPF and C#. Over time, Java and C# has replaced C++ in the less specialized jobs. On the other hand, areas like low latency finance has really taken off, which require C++ and much more specialized knowledge. So, if you are writing new C++ code in 2018, it is more likely that you are developing an quant fin software than desktop GUI. Whereas 15 years back the situation would be the reverse.
Could the error message for invalid tokens such as `0xE+foo` or `0_lit.foo` be improved? This kind of error is not all that common, but is quite surprising when it happens, and currently it's hard to infer what's going on from the error message.
It took me fucking DAYS to figure it out, it's absolutely, 100% voodoo.
Your experience and local competition (supply/demand) has a lot more to do with what you are paid than the programming language you use. Also, it is *not* important what you are paid. What is important is your buying power. A US$150k salary (for example) is not much if you live in an expensive place like Silicon Valley.
This is awesome. Haven't checked, but some (many?) of those actually seem even better than on Clang, just out of memory. Competition between compilers is great!
Oh, i would find it really cool, if the compiler would write all my code for me and I could go surfing..... 
Looks like I really need to start using SCL now on CentOS, so I can get rid of GCC 4.8.5
I am using this awesome json lib in my projects, thank you so much. 
If my compiler started writing code for me, I'd probably start searching for job. :P
I agree with the recommendation to try and change this at your workplace gradually. Talk with your colleagues about this as an experiment, involve the ones who are interested and educate where needed. Now you state you work for an embedded development company but not if you are writing embedded software. If you do, I want to point out that changing jobs does not mean you will find a company which uses the latest and greatest. In my experience (embedded software engineer here) bare-metal tool-chains lack behind in regard to C++ adaption and switching tool-chains vendors is rare (risky). Where I work we have products which use a MCU for which the vendor just doesn't update to new standards, so that code base (and everything shared with other projects) is stuck at C++03. Luckily we also use other MCU types with different compilers and will start switching to C++14 soon, but it has taken quite some time to get there. 
If you are using C++17 then you can write isInSet as: template &lt;typename... Strings&gt; bool isInSet(const std::string_view s, const Strings&amp;... strings) { return ((s == strings) || ...); }
C++11 is a god send. It really is such an improvement to the language. With smart pointers, auto, range based for loops and std move you can write faster and safer code. I'm sure there is other stuff I've missed out but that's what i use the most.
&gt; For std::string I can get away with that because an empty std::string is guaranteed to have a single zero value in its contents Is this correct? I couldn't find anything about this in the standard. Closest I found was: &gt; const charT&amp; front() const; &gt; charT&amp; front(); &gt; Requires: !empty(). &gt; Effects: Equivalent to: return operator[](0); which, kind of contradicts with the post
Before you jump ship, I'd first check if there is a way to speed up the addoption of c++14 and later and in particular to communicate to the tool vendor that support for newer c++-standards is important to you. Nothing is going to change in the embedded industry if chip and tool vendors don't see support for c++14 and later as a competitive advantage.
In this case it is mainly the stability and experience with the (heavily optimized) generated code. Of course the support contract is there in case something does go awry. Regarding GCC: Let's just say there is a specific GCC 2.3 build which supports that particular MCU so not much help there unfortunately.
Then, doesn't that mean definition of front() is contradictory. front() requires !empty() and is equivalent to operator[](0); operator[](0) is defined when string is empty() but for front() it is undefined since its requirement is broken. Thus, they are not equivalent. 
Much more well said. So he means you need a math degree or major to go with your comp sci training? Or business degree with a focus on finance? I'd say that's a pretty narrow interpretation of the market. There's aerospace, defence, embedded, low power devices, IoT, simulation, and specialized hardware utilizing projects. And basically any other program that needs to go fast and not drain a systems memory. To interpret the cpp market as what happens in New York Zurich and London is a good way to kill the language. And it's just not accurate. 
Really, "missing semicolon after `i` and before `int`".
That's neat ;)
I have tried and indeed I have noticed that I spent too much time on useless things (reddit) during work hours due to boredom lately, the problem is that we have to use a countless amount of compilers and compiler versions, each project is build against one specific compiler, most of the projects involve millions of code lines, 10 to 20 years old code patched all over the place, hundreds of poorly coded and archaic build scripts and hundreds of people that most of them do not understand C++ AT ALL, they use C under .cpp files and think they are using C++ properly. The other thing is that 95% of the compilers used do not support C++11 or newer, I have pushed in so many ways that I am tired to try, I have rewritten complete modules to show how much can be gained from using proper C++, I have made presentations to the higher tech leaders about what can be obtained from using proper C++ and its newer versions. They have a unofficial saying that is contaminating newer generations, something like "if it is working, don't change it", they don't want to invest on teaching proper C++ and I hate teaching (don't want to spent the next 5 years teaching the basics of C++ and I am not a trainer), they are a bunch of old people controlling new people that see no gain in switching to new (7 yers old or older in real life) technologies until forced to do so.
I have tried, I would love to stay, it is a company with many benefits, it is really near my home (for a big city standards I mean), but I have reached a breaking point where I am tired now of trying, I have tried so many things to push the switch to proper C++ and later C++11 at least but the people that decide the tools and where to lead the company have zero interest on neither of older or newer C++ versions properly used, it is a big company and moves like any other big company, like an elephant no matter how much you push it, it there is no effort from management nothing will get a dime to change it.
The article should be called "an hypothetical usable C++ Dialect that is Safe Against Memory Corruption" because that's what it is, this dialect doesn't exist. It also probably cannot exist, at least as described in the blog post. They define safe iterators as fat iterators with a pointer to the collection and an index, claiming that this prevents memory unsafety. Spot the bug: std::vector&lt;int&gt;* a = new std::vector&lt;int&gt;{1, 2, 3, 4}; auto b = a-&gt;safe_begin(); // returns safe iterator delete a; 
&gt; While generally a very good article, I found the article a waste of time. The following sentence is the TL;DR: &gt; The second rule about collections is that all the access to the collections (including iterator dereferencing) MUST be written in a way which guarantees safety. So in a nutshell, memory safe C++ is the C++ dialect in which programmers only write memory safe C++ code. The rest of the article is basically built on top of that assumption. For example, they define safe iterators as fat iterators with a pointer to the collection and an index, claiming that this prevents memory unsafety. Spot the bug: std::vector&lt;int&gt;* a = new std::vector&lt;int&gt;{1, 2, 3, 4}; auto b = a-&gt;safe_begin(); // returns safe iterator delete a; That's where the second rule above comes from: memory safe iterators require the programmer to not write memory unsafe code.
What makes you think this guy has the know-how to do anything about your favorite regressions?
Cool, I'll just waste my time on a wild chase to prove the point that you are too lazy to make.
Yes, though it generally has to inline functions to be able to do that
My god, I had forgotten about Delphi, when I say C++03 I wanted to say that the compiler supported that but in reality the code is C with a few sprinkles of C++, my daily work is a callback and macro hell.
We focused more on Elm than clang.
Yes, but I've been very busy with work so I haven't done anything with it in the past few weeks.
A compile time hash (I'm fond of FNV-1) of the cases and a runtime hash of the switch value might be faster in most situations.
I mean, it’s not really an insane error. Since you didn’t have &lt;string&gt; included, the compiler didn’t see the operator overload for &gt;&gt;. If you’re using something from the std namespace, you likely need to include the file It came from.
&gt; the compiler didn’t see the operator overload for Problem is that it sees std::string. My guess is that it is fwd declared in some header. 
Is there any online guide or book that will help me understand how to read this kind of expression? 
In my experience... Small companies move way faster than big ones. My first gig let us pretty much do what we wanted with that. I was able to convince them to use boost and then again to begin using C++0x features that were available in VS 2010. Large companies are completely different. Pretty much every one has a huge codebase that they're very squeamish about changing. They do not want to introduce risk. I've been working in C++03, at best, ever since I left that job at the small company. In my current one we simply cannot change because we need to compile into Flash and that compiler is ancient. I've also found that developers are frightened of modern programming in C++. So many of them, the great majority that I've worked with, want nothing to do with it. They want to stay in the old C with classes style of development and want little, if anything, to do with templates. I thought it was just an old-timer issue (which I now pretty much am), but even the young ones are like this. They just don't have the drive or desire to learn. &gt; My current employer is an embedded developer, hence the longer adoption curve also. Maybe show them what can be done with C++11/14/17. I'm, very slowly, working on AVR library that uses C++14 (latest available for that architecture). I'm able to do quite a lot with hana style metaprogramming. My current effort (which as you can see hasn't been touched in months) is in the 'capacities' branch. I don't know that I'd showcase what I did in the `chip` directory though; at least not right away. It's far from anything resembling production, and I'm sure it's more complex than it needs to be right now, but it does showcase some of what you can do in an embedded environment with modern C++. What would normally have a bunch of functions, many of which you don't need, compiles down to the least necessary items to get the job done. It does as much as possible during compile time, leaving runtime to be minimal in size and execution. https://github.com/crazy-eddie/arduino_modern
True. It's very similar to how my MIPS emulator's instruction lookup worked. It went over every instruction, and calculated the bits that were relevant to the instruction (that is, could be used to define the function) and the values of those bits, as two integers. I then had an offline algorithm that went over all of the instructions, and generated masking sequences (that ended up as nested switch statements - starting with the mask that generated the most subsets first) which progressively constrained the instructions further based upon the relevant masks, until it isolated an instruction. I wish I could have done that at compile-time instead, but I don't know of an explicit way to expand such a thing into a switch statement. It was also beneficial because I didn't have to keep a separate array of instructions - the codegen scanned the instructions source file, and extracted the instruction data from the instruction definitions directly. I *really* wish that C++ had some reflection capability so that could have been done *without* a separate program. Pipe dreams.
I have tried showing the benefits of using newer versions, I have several shortcomings to improve on my own and show the improvements with deeper changes for example, I have no time assigned to improve and experiment and I can’t work after work because of hardware limitations, I work with very expensive and limited hardware that can not be taken home for example and the build times take ages as to spent my family time trying to convince people that most likely will not appreciate it, that is why I am thinking on jumping ship as soon as possible. I am not learning anything new or valuable for my future career, I am one of the most experienced and I tend to outperform by miles most of my colleagues on my local area (I am a modest person just trying to set the idea mentioning this) and even with that they do not listen to reason or want to set aside a small budget to test further.
Yeah. I've basically learned to skate by and enjoy the downtime. I sort of gave up being challenged a long time ago and instead just look for job security...and rocking the boat too much sort of kills that too often. Sounds like maybe you need to be on the lookout for something better. Unfortunately I think you'll find that most places are like this. Some for good reason...but often not.
That tells me precisely nothing. The expression given above ends in `...`, so it can only be form (1) on that page, but on the left hand side we don't find the pack but instead a conditional expression that I don't know how it will expand or why. So is there any online guide or book that, rather than merely being the first thing that pops up in a Google search, actually helps me understand that type of expression?
For one, *semver* can have an arbitrary number of components in the pre-release part so you will have to have something like a vector in the parsed representation. On the other hand, if you constrain *semver* to something less arbitrary (like we did in [*stdver*](https://build2.org/build2/doc/build2-build-system-manual.xhtml#module-version)), then, yeah, a parsed representation (or even an integer) will work.
Where I work we switched to 11 ~2 years ago, and just a week or two ago we upgraded the compiler to one that supports 14. Not allowed to start using 14 features yet though.
Although folder expresion has 4 syntax as "First result of "fold expression tutorial" on Google" mentioned. Actually they are very easy to understand, there are only 4 key points: a) it will expand to: 1 op 2 op 3 .... N b) left/right fold just to determine one of the form below: (((1 op 2) op 3) .... N) (1 op (2 op (3 ...(N-1 N)))) c) init just add a initial value at begin/end d) item 1,2....N could be expression
Now let it be available via C++ package managers like buckaroo, cget, conan, conda, cpm, cppan, hunter, vcpkg ( ͡° ͜ʖ ͡°)
True. It ends up looking nicer syntactically, though, since it looks like a traditional switch statement. Isn't as efficient in the specific case, though.
Give PowerShell a go. It looks arcane and overly verbose, but -- once I got a handle on the design and rationale -- writing shell scripts in any other language felt bafflingly fragile and unintuitive. PowerShell definitely has its quirks and oddities, but those oddities are minimal compared to the strange behaviors in Bash and Batch. A comparison to C++ might be drawn: It has a lot of different interacting and initially unintuitive components, but learning about those components will give you a powerful tool. &gt; the execution policy which requires bypass or script signing This is something pervasive in Windows. A lot of components require signatures before being run. It's the same deal every time you open an installer and it asks you to prompt: The installer wasn't signed properly. For the average user, it's simple enough to disable most script prompting: Set-ExeutionPolicy -Scope LocalMachine -ExecutionPolicy Unrestricted And it won't ask again. And remember: Don't confuse familiarity with simplicity.
If you look at the declaration of "strings" you'll see that it's a pack `const Strings&amp;... strings`, which means any usage of `strings` will later need `...`. in some form.
&gt; Your example post fails the rules of this framework, so of course there are no guarantees (and indeed it is wrong). Rewriting it to conform: Which rule does this fail? safe_iterator&lt;int&gt; foo() { owning_ptr&lt;...&gt; a = new std::vector&lt;int&gt;{1, 2, 3, 4}; auto b = a-&gt;safe_begin(); // returns safe iterator return b; }
I had this too. It would BSOD when idle, and the driver isn't removed when uninstalling the product.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/84y195/beginner_guides_for_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That link doesn't show that you can call a function on each member of the pack before the fold operation, so it's not clear what are the limits of this.
I think it’s an issue with the VC++ Compiler forwarding the declaration of string. I have not observed that behavior on GCC or Clang with my multitude of compiler flags...
That sounds like a very bad place to work, tbh
It is some of those things that you don’t know until you work in a company, things that of course will never be explained by the HR teams or that everyone finds it so normal that think it is the only and optimal way to work.
It says it's a pack expansion. It's a tutorial aimed for people that have already some basic understanding on how variadic templates works. I assumed the user posting the comment already knew how packs worked. With packs you can expand any expression that contains a or multiple packs. Fold expressions aren't any different.
Well, then it might indeed be time to change
Thank you very much for the infos! Is Arduino good enough to start looking into it or should I look at something else?
The article starts with reactors, that's where I left off. I've done that style before, it makes programs very hard to understand.
Looks like we still spew a couple of dozen lines of diagnostic on this simple typo; ouch. Thanks for the idea - I've filed it as https://gcc.gnu.org/bugzilla/show_bug.cgi?id=84918
So this is C++… You could just have an std::set of std::string and return if find(target) != set.end(). I’m sure with the proper use of const or constexpr, this probably gets optimized better than you can do by hand.
I don't find myself really saying "I wish I could throw/catch an exception!" in Rust
... has some interesting ideas but isn't good enough or popular enough to withstand the test of time.
I can write shitty bug-filled spaghetti code in any language, I might as well do it in a language I already know.
The other 1% would be the `-fdiagnostics-apply-patch` which was proposed along with `-fdiagnostics-generate-patch` but didn't make it in
Rust code looks like it is trying to get my eyeballs to explode... If it is a game to get safest language possible, I'd rather bet on ADA. Because it is not only about making it is technically impossible to shoot your feet, but also about making it easy to read and verify the actual logic of the code. P.S. Last time when I've checked, ADA was pretty much same capable as C++98. 
So how do you deal with error handling, then?
I just want to draw/blit pixels to a buffer/screen and have options to find out what resolutions are available and set it. Maybe a few shapes like lines and circles, but that isn't necessary. With that libraries can do the rest. This would be enough to get a lot of new programmers engaged and doing func things. Remember writing ping pong as a kid in BASIC or graphing the trig functions.
Rust uses sum types plus a `?` operator for easy upward propagation.
So if you add a new exception "at the bottom" you don't have to change everything all the way up to where you catch it?
Are you asking whether Rust can have a function whose signature says it doesn't ever expect you to handle an error case, but actually it does?
I'd argue that only value/variadic generics are needed. Function overloading has been proposed and rejected and exceptions are rather antithetical to the goals of Rust.
Rust's approach is arguably better, since the use of sum types encodes error states into the type system.
... would have been a compelling alternative if it came out 10 years ago.
Rust makes a point to _not_ allow that. If code errors recoverably, it should use Rust's fantastic algebraic type system. If it errors irrecoverably, it can panic and crash the program. There shouldn't be a way to for code to randomly throw exceptions.
is a good language but the community is toxic towards people not using rust. (atleast in my experience)
Im curious why you find Rust code so hard to read. I don't think it's particularly _easy_ to read, but certainly not worse than C++. Also, the idea behind Rust isn't to write verifiably correct code. It's to provide stronger memory, thread, type, and UB safety than something like C++, while maintaining the same goal of writing expressive, efficient code.
I think Rust improves on C++ in many ways, but it's got a ways to go before it can really claim to be mature and have stood the test of time. When it comes to languages features, I think Rust has the stronger type system, with traits, algebraic types, and basically no implicit casting. I also think its zero-cost ownership model is great, albeit hard to work with at times. That said, it needs features such as non-type template parameters. As for non-language stuff, C++ really needs something like `cargo`, but in every other way C++ has superior tooling due to it's age and popularity. Rust also obviously loses in the availability and quality of libraries, again due to age and popularity.
Why can't it be compiled by GCC? That seems like a weird restriction, with GCC being (almost) completely conforming to the C++ standard
std::set is going to heap-allocate every node in it individually and then perform hash-lookup to do the find. That's orders of magnitude slower than the simple == || == || ... he originally started with.
Similar to my take. Feels a bit like C++ if it were born today, with a few different design choices. They are far behind in terms of community and momentum, but some of the standard stuff (like cargo) will probably accelerate things. Wish C++2 or C++next would have eaten up this space
I've been doing C++ throughout the span of my career. I've definitely been able to pick up other languages. Problem is, C++ has spoiled me and the other languages feel like cheap toys. One example: What do you mean I can't leverage RAII because your destructors aren't deterministic? What, you say I can by inheriting from a special interface and wrapping my all instances of my object in some special block that isn't tied to normal scopes...? Another example: What do you mean I can't design a class hierarchy that leverages multiple inheritance? C++ is great because it gives you all sorts of tools to work with rather than idiot-proofing itself down to the lowest common denominator like some languages.
On my machine, it kept rebooting + BSOD-ing.. A coworker of mine, just had to reboot once. I had to rediscover how to get into Safe Mode (I had a period of not touching Windows for 2-3 years, and now on Windows 10) - and I think pressing Shift, then a bunch of boxes, until I saw Command Line. Then went and deleted c:\windows\system32\drivers\vtss.sys - I even thought (jokingly) of creating a folder called c:\windows\system32\drivers\vtss.sys\ so that a file can't be created nomore there (well who knows... ) - hahaha. So tried using VTune, and without the sampling driver not a lot of things are useful, but still some are - the Visualization is pretty nice, but clicking on certain things an you would have "Loading..." which never finishes (the UI is still responsive, but no data). Seems like a lot of these tool just do normal ETL/ETW tracing, with custom events, and their own vis/reinterpretaion of data. I might be just better off with XPerf/WPA or Visual Studio builtin "Diagnostic Tools" (also "Concurrency Visualizer", etc.)
Why would it? Are you still not using C++? You just learn a different environment/framework/library on the fly but your C++ skills improve, which is ultimately what matters.
I agree that plain ol' business software is no longer done in C++. C++ is normally employed for projects that are doing something "hard" that 3/4 of programmers wouldn't touch. Examples of "hard" might include dealing with the computer as a machine or doing some high performance stuff. I have the impression that the vast majority of programmers today work on web apps &amp; enterprise business apps; they have no particular need for C++.
Now your turn Microsoft ;)
That's likely a result of Rust's ML heritage. Like in ML family languages, variable bindings are allowed to shadow others within the same scope. It's worth noting that those two variables are completely different, which is relevant when doing something like this (though it's bad practice to shadow like this): fn foo(i: i32) -&gt; i32 { i } fn bar(s: &amp;str) -&gt; &amp;str { s } fn main() { let x = 1; let _ = foo(x); // Works! let x = "a"; let _ = bar(x); // Also works! } I agree that it's not a good design decision, but I hardly think it's a dealbreaker when it comes to a language. I'm sure you could easily find tons of such quirks in any language.
This was a nonsense question the first time you asked it on the qt subreddit. 
If anything, it'd improve them. There isn't really any good alternative to Qt for writing powerful cross-platform GUI in C++. Just don't forget to keep up to date with both Qt and STL libs (and others).
If you are worried that your experience with Qt is conflicting with your experience with C++, then it might be a problem if you become more familiar with the SDK than the language itself. Qt is a cross-platform GUI framework, but it also provides additional functionality that does overlap with modern C++ and STL (i.e. QString, QThread, etc.) If you're using Qt for your application, it's better to scope your use of the framework for anything that's GUI related, but use standard C++ and STL elsewhere to keep your dependencies clean.
Personally, I've found Rust fans to be more...overly enthusiastic than toxic. It's a shame you've felt that way - I've found much of the community to be rather welcoming, if a bit zealous about Rust's greatness.
&gt; and then perform hash-lookup to do the find That would be std::hash_set&lt;&gt;; std::set&lt;&gt; will effectively perform a binary search to do the find.
&gt; I agree that it's not a good design decision, but I hardly think it's a dealbreaker when it comes to a language. Well, it makes easier to write code with bugs. For me it is a deal breaker already. &gt; I'm sure you could easily find tons of such quirks in any language. In the recent 4 years I've learned at least 3 new languages: C#, Python, Kotlin, and I didn't find anything that made me feel "f### this s###" in C# or Kotlin. (But in python - a bit, see below). I was charmed by C# and Kotlin, and mostly by python as well, they feel helping me to write safer code easier and faster. And C#+ReSharper combo was just like a nuclear bomb, never felt having so much power in my hands.... As for python - the only real thing is lack of proper threading support in cpython implementation (i.e. standard implementation). Certainly there are quirks in all these languages, but they usually hide somewhere quite deep under the surface, and usually you would not hit them unless you are doing something very specific. P.S. Having learned all the languages above I still use C++ a lot - just using correct instrument for correct task. 
&gt; C++ has shadowing, too MS VC's /WX will make it an error for you :) &gt; It sounds like you've just never had exposure to any ML language. Rust is't really looking like a functional programming language, so it is not intuitive to expect any ML-style behavior unless you've read the history page on Wikipedia. 
I agree with you, but the point I intended (and probably failed) to make is that C++ is almost as bad. Personally I think shadowing shouldn't be allowed at all. C++ allows you to do it - it just disallows it within the same scope. To me, that's not inherently better than what Rust does.
I have some experience with Haskell and F#. Rust is certainly very very far from these languages. 
You can keep it on the stack with inheritance, Cat wiskers; Dog spot; make_sound(&amp;wiskers); make_sound(&amp;spot); Also I'd like to make it take a reference so I can guarantee not null.
Is this a one-up subthread? I mean, I have multiple years of working with each of F#, OCaml, SML, and C++ in professional settings, and find nothing about Rust "very very far" from _any_ of the four with regards to their respective overlaps. I might go so far as to say that if you don't see the similarities, you must be doing it wrong. But, how am I supposed to reply seriously to just a blanket subjective, statement? Spend time detailing why your expectations are wrong? I'll just leave it at "you're very very wrong", I think, in keeping with the shitpost nature of this entire thread. ;-]
Well, you can forgive C++ because it must maintain some level of compatibility with C, and back in 70s K&amp;R didn't think much about possible implications in 2018. In C++ this problem is older than the language, it is 48 years old this year. Rust was supposed to be better, and it is relatively new language compared to C/C++ family. 
That's a good point. Given that, I agree with you on this.
a CAR object **has** a WHEEL object (probably and array of them) a CAR object **is** a VEHICLE (i.e. it inherits things like forward motion)
For me Rust looks like an imperative language that supports functional paradigm. The code below: fn factorial(i: u64) -&gt; u64 { match i { 0 =&gt; 1, n =&gt; n * factorial(n-1) } } Is looking like an imperative code written in a functional style. For a functional programming language I would expect syntax like (Haskell): factorial n | n &lt; 2 = 1 | otherwise = n * factorial (n - 1) or (F#): let rec factorial n = match n with | 0 -&gt; 1 | _ -&gt; n * factorial (n - 1) Yes, difference is subtle, but it turns a switch from "it is Lisp" to "it is C" in my head at least. There are other imperative languages that are close to Rust in terms of syntax here, but they would not claim "being influenced by ML", for example: fun factorial(i: Long) :Long = when (i) { 0 -&gt; 1, else -&gt; i * factorial(i-1) } That's Kotlin - still very imperative very non-ML. 
Actual name of hash set in the standard library is `std::unordered_set`.
There's nothing like learning C++ while working on GUI programming. You'll be exposed to several design patterns and OOP concepts as well. Take it in your stride. My first tryst with C++ at an Enterprise level was using MFC programming to develop a GIS mapping desktop application. 
The problem is that, unless you're game programming, you're never going to have a CAR, WHEEL, or VEHICLE object. You're going to have INVOICE, and PURCHASE REQUEST, and CUSTOMER, and USER, and INVENTORY and SALES TAX and VENDOR. You could argue for weeks about the right inheritance hierarchy. In the mean time, I'll be making simple data structures with a few methods attached to them with no inheritance and thinking about how the data flows through the system, you know the actual problem we're getting paid to do.
Example: I interview and hire devs. That's been part of my job for over 20 years. If you learn Qt (or any other tech) and then interview for a job with me, I might ask "Oh, you've used Qt. What did you like about it and what did you dislike?" I don't care whether you like/dislike the same things as me. I care that you've formed some reasonable opinion, ie you have reasons to back up that opinion. I care whether you've learned from your experience. I care about what types of things you have learned (is it syntactic? is it performance? is it about program structure?). I care that you can learn. If my team is currently using Qt, it would be a small added bonus that you are familiar with Qt, as it would be one less thing you need to learn before "getting up to speed". The only downside? Maybe there is some other thing you could have learned instead? But, like I said above, I don't care so much _what_ you learn, but that you _can_ learn.
Yeah... Have fun writing all those `printReport` functions to handle every single data type. At best you could have one giant master function that determines what type of report it is, and generates that one. Instead, you can have all these classes inherit from a simple abstract `Reportable` base class, and just call that when appropriate. If you have an object that exists as a collection (Customer has an Address instead of being subclassed from Address), internally it could be calling that function for each of the objects within it. This is both a perfect example of where inheritance is useful, and where 'has a' is better than 'is a'.
So you think the syntax details are not functional?
The fact that you can do this is probably the biggest reason we don't use exceptions...
... solves a non-problem if you use modern C++.
I find this to be a very weak argument. It boils down to this: &gt; On the other side, for the generic approach a class A collaborate with B if B has some specific methods and fields, no need to inherit from a specific class. ...which is really not much. On top of that, the difference between *has* and *is*, is really small in the example. It **literally** boils down to a measly `public ICalculator` for each class that wants to have a ... (pun intended) concept of a calculator. The *real* difference IMO is the performance difference. Generics (templates) allows for a performance difference that might be significant in some cases. Also, the "has" relation is generally associated with composition, so the TFA makes the water murkier by using that term here.
Pure abstract base classes/interfaces is the good part of OO. When the designers of Go and Rust threw out most of OO, they kept that bit for a reason. However, there isn't any inheritance here in the behavior sense at all. It is just a contract that the class promises to hold. &gt; Yeah... Have fun writing all those printReport functions to handle every single data type. At best you could have one giant master function that determines what type of report it is, and generates that one. &gt; &gt; 
That's a very good write-up! That said... How are generics difficult to debug? Do you mean "understand compiler errors"? Why do you say there is an executable bloat? That is a thing of the past, no?
Except it goes further than that. You have an invoice, but then have say a specialized invoice for a customer large enough to require special reports. Declaring the entire invoice class to be abstract would cause massive amounts of code duplication, so you just subclass invoice. After all a `BigCompanyInvoice` is still an invoice, just with special reporting. The classic C way to handle that would be to have a special `generateBigCompanyInvoiceReport` function, but you get right back to everything having to support it. The danger is always in overusing OOP, and having a convoluted mess. I've worked on projects that basically instantiates everything from a database at the start, and never touches the database again. That's going too far. However simply passing around data objects and having loose functions that act on them rapidly gets confusing as we all try to remember what goes where, and what objects can work with what functions.
I would say you’re getting dangerously close to violating the Open/Closed Principle and/or the Liskov Substitution Principle with your BigCompanyInvoice example. You should probably elaborate that BigCompanyInvoice’s “special reporting” is just more reporting on top of Invoice’s reporting.
Reactors are the worst form of the programming except for all those other forms that have been tried from time to time. 
Why would you argue about any inheritance hierarchy here? All of those things are unrelated. Inheritance doesn't mean you _must_ inherit everything from something, it means you _can_ inherit something from something else _if that's a good solution_. 
&gt;VAR block You can define dynamically allocated variable everywhere, afaik. VAR block is for variables allocated on stack.
No, event based programming is notably worse than other popular styles.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/850fgi/does_getting_a_job_with_the_qt_framework_limit/dvu7mch/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
So the compiler telling you what you need to write is ok (and most of the time it is exactly what you will write), but if compiler writes it is not ok. Also including headers is hardly writing code and as far as I know is one of those annoying things that will be hopefully somewhat optimized by modules, especially in 3rd party libraries with a lot of separate headers.
&gt; if you can write an engine [to] formally check these specific rules - then your code will be safe We already have rules for this way better specified in the ISO C++ standard. The problem isn't "having rules", the problem is having an engine that automatically is able to verify and enforce these rules. The article does not provide such an engine, and right now whether such an engine can exists in a way that writing C++ programs remain practical it's an open research question. This article does not improve our knowledge about this question at all.
Your example code (if I get everything) breaks no rules and thus is safe! My previous example was slightly unclear about this, but it was showing the scope of a Reactor::react() function. The lifetime `owning_ptr&lt;T&gt;` is not tied to the scope where it is declared, it is tied to the scope of the Reactor::react() function, thus calling your `foo()` from `react()` is safe and moreover, safe_iterator can detect that you are accessing something that normally would be out of scope. To help with the understanding, imagine that all `owning_ptr`s store their allocations to a global/thread_local block (with a deleter), and event processing code that calls `react()` calls `collect_garbage()` afterwards that destructs and frees all objects in the block.
Returning naked pointers are not allowed per the rules, this also extends to `safe_iterator`s containing naked pointers. Otherwise they are always safe, so that's how they know (I suppose you could have a type `super_safe_iterator` so that you can typecheck that you don't return naked pointer iterators). When you create the iterator, you know if it will contain a naked or owned pointer. Yes, indeed, this is a type of gc. I don't see anything in the article about races, my guess would be that this guarantees nothing about races, so you'll have to ensure that yourself, but again, tracking your stuff in a thread_local manner makes it safe to have multiple reactors running at the same time (one per thread).
&gt; Returning naked pointers are not allowed per the rules, this also extends to safe_iterators containing naked pointers. This means that `&lt;algorithm&gt;` is not usable, because most algorithms return iterators. &gt; When you create the iterator, you know if it will contain a naked or owned pointer. This code would be valid for some containers but not others, depending on what their iterators do: template &lt;typename Container&gt; auto foo() { owning_ptr&lt;Container&gt; a = new Container{1, 2, 3, 4}; auto b = a-&gt;safe_begin(); a = nullptr; return b; } &gt; tracking your stuff in a thread_local manner makes it safe to have multiple reactors running at the same time (one per thread). The problem is passing a safe iterator from thread A to thread B, and then joining thread A while the iterator is still live. That will destruct the reactor in thread A, or reinitialize it with something else if you put it in a thread local (e.g. if a new thread is spawned that reuses the thread local).
Honest question - how fast is rtags on large solutions (e.g. LLVM/Clang, UE4, etc)? If you touch a common header file, do you need to wait for it until it processes all the source files that use it?
Saving one byte to then have to reallocate the whole string in case somebody uses e.g. c_str()? I don't think so.
My point is that pretty much every modern non-functional language supports FP-paradigms in pretty much the same way Rust does. It doesn't make these languages functional purely because they support some functional features. As for Rust - does is support things like currying, lazy function evaluation, high level functions (functions taking functions as arguments and returning another functions), etc? I'd guess if you play with lambda a bit you can do most of it (same as in most other modern languages), but these are not the features supported by syntax in a first place. 
The thing that bothers me about this is that simply having a function called `hashCode` that returns `size_t` really isn't enough to say that it's a valid hash for the purposes you want to use it for. I really think C++ should have some concept of 'namespaced symbols'. So instead of writing `v.hash_code()` there you would write `v.[std::symbols::hash_code]()`. Notice that I specifically *don't* mean Koenig lookup. In fact, the opposite. Then your class could define: struct foo { size_t [std::symbols::hash_code](void); }; Lisps use a similar concept for namespacing for packages and such.
Needs a "slogan". Every language heavily used has a implicit or explicit slogan, a mental anchor that connects the problem you are trying to solve with the best language for the job. Python has "simplicity and terseness" , C has "close to the hardware", C++ has "powerful and cheap abstractions", etc. What does rust have as it's slogan? "safety"? I mean, that's a great choice if I'm ever writing space shuttle software... 
&gt; This means that `&lt;algorithm&gt;` is not usable, because most algorithms return iterators. Returning naked pointers is disallowed in *reactor code*. Library code can do this, and you can still wrap iterators coming from `&lt;algorithm&gt;` if you want to return them in reactor code. &gt; This code would be valid for some containers but not others, depending on what their iterators do: Why? The safety is provided by the `safe_iterator` part not the wrapped iterator. &gt; Thread safety From the article: &gt; What’s important, though, is that even if react() can be called from different threads, it MUST be called as if it is one single thread (if necessary, all thread sync should be done OUTSIDE of our (Re)Actor, so react() doesn’t need to bother about thread sync regardless of the infrastructure code in use). and &gt; In addition, let’s observe that whenever (Re)Actor needs to communicate with another (Re)Actor – adhering to the ‘Do not communicate by sharing memory; instead, share memory by communicating’ principle – it merely sends a message, and it is only this message which will be shared between (Re)Actors. In turn, this means that we can (and should) use singlethreaded allocation for all (Re)Actor purposes – except for allocation of those messages intended for inter-(Re)Actor communications. So I'd say this is in general not allowed, but if you really want to call make long-lived threads (eg. where lifetime is not contained) that can call `react`, you can make `owning_ptr` an atomically ref-counted pointer (like `shared_ptr`). Or if you want to be able to recursively call `react`, you can make the allocation tracking block a stack. I do think that these are not great usecases though.
I don't get all that hate on polymorphism via inheritance and virtual functions. Both generic programming and OOP have their valid uses. Take for example the approach taken in std::random: There are different random number engines that can be used with different distributions. They are completely independent of each other and one can add another engine without having to inherit from a given interface. Very Nice. But lets say I want to write a program where the user can specify the engine to use in a configuration file. How do you do that without OOP? At some point, I'd have to instantiate an engine based on the configuration and pass it to other parts of the program. Easiest solution that I came up with is to have a class RandomEngine that inherits from different unrelated engines and exposes a virtual function to generate random numbers. The base class for RandomEngine can be written as a template, so there is no need to write dozens of different versions manually. What should be wrong with that approach?
No, other words and requirements in the standard make it being a global nul impractical to impossible. You have to really twist the wording and impute temporal logic (without basis) to phrases in the standard; what more, the space for the nul *must* be there even under the most twisted wording. In short, a global nul is not allowed.
See his tweets: https://twitter.com/ericniebler/status/974115132161839104 https://twitter.com/ericniebler/status/974278786752577537
&gt;Have fun writing all those printReport functions to handle every single data type I don't quite follow your logic here, you are going to have a different *print* routine for every data type because every data type has different attribute values and a different output format. If they were all the same then you wouldn't have different data types to begin with. So each of your OO classes may have a *generateReport* function declared in say an IReport interface but everyone of them has to be implemented. Or, as you point out, you could have a single report generation function that is aware of each of the data types and that single function is responsible for generating the entire report and formatting each data type appropriately. Both models work and depending on the application in question either could be the correct choice.
The plan is that MSVC is nearly compatible. Casey has some changes to make, but they generally improve the main Range v3 codebase. He’ll push those changes in and MSVC will be at parity with Clang with regards to Range v3. Note we don’t yet support Concepts. GCC is your only alternative there. 
Thanks for the info. Looking forward to it. Edit: to be completely honest: For me, concepts is the least interesting feature for c++20.
Both models work and depending on the application in question either could be the correct choice. However, there are major consequences for going with the second. First, things that should probably stay together get split among multiple files. Second, especially if you try to avoid number one, you see quite a bit of code bloat when including that one super function. Third, anyone debugging that super function or anything that generates a report is going to have "fun". Think about it, at best we're talking about each object having there own report function and then a super function which is just a giant switch statement based on the data type. If you're using any compiled language, then that function would require at least the headers for every single possible thing that could generate a report. Now, all of this assumes you have at least basic abstract class/struct support. The moment that's no longer true you start having to cast to void and give up even the semblance of type safety.
excuse me but I'll have you know Rust has * zero-cost abstractions * move semantics * guaranteed memory safety * threads without data races * trait-based generics * pattern matching * type inference * minimal runtime * efficient C bindings
Yes but it's clearly outside the scope of the compiler. It also means that every compiler ever would need to implement this and then my IDE would need to support how all those compilers provide that information or do that job. It's stepping on the toes of IDEs and as someone who builds with 5 different compilers at all times, this screams IDE feature. 
The C++ committee meeting in Jacksonville is about to finish. Our reddit trip report will be posted to this subreddit, and there will be an update on ranges.
I still don't get the point either. C++ is more powerful in every way. Rust only brings safety to the table, nothing that can't be done with C++ sanitizers. I hate cargo!, I mean, I love it... but I hate the "nodejs" philosophy of Rust that for anything you want to build you'll need to depend on hundreds of third party crates. The C++ community sometimes decide to rewrite stuff as to not have to depend on third party libs, this is expected on a so called "systems language". Anyways, Rust seems very interesting... but not really enough, at least for me! 
Aho-Corasick is appropriate for substring matches. For exact matches you should just use a trie, and I would be surprised if it stood up to a well-implemented hash table anyway, especially if you can choose the hash function at compile time. For a small number of matches, as per the example in the post, manual approaches do a lot better, though the article's generated code is pretty mediocre.
Concepts is fantastic for template library writers, and for user code where "auto" alone isn't quite clear enough - being able to write e.g. "iterator" instead.
Concepts are relevant here because the real Ranges depend upon Concepts. 
Did you mean 60 minutes after the closing session? Because I still can't see the trip report.
this thread scared me.. i work at an mobile game development company and i do 9-10h a day of pure c++ work, and my pay is.. not optimal. i love the industry but maybe i should start looking in other areas? really sad to know about this though..
It's not done yet :)
Okay, but what is it BEST at? Out of all programming languages? 
And there you have it ladies and gentlemen...
I agree that Rust is not a truly functional language along the lines of Haskell or OCaml. It lacks features such as easy currying and encourages mutable state. That said, it has first-class functions (not quite as ergonomically as a pure functional language, but better than C++), algebraic datatypes, and pattern matching. That brings it about as close to functional as you can get in a systems language. The fact that it uses curly braces and semicolons doesn't invalidate that.
Thank you very much for the insights. I've always found myself struggling while trying to track discussions and priorities of the committee just to have an idea about the direction(s) the language is pursuing in the short term. A crystal clear report like this would be greatly beneficial to the whole community I think.
&gt; Reflection &gt; C++26 What a fancy way to say "never".
&gt;nothing that can't be done with C++ sanitizers There's a fundamental failing of that - sanitizers are at runtime, whereas Rust checks safety at compile-time. The only way to get something even similar to Rust's safety guarantees in C++ is with expensive static analysis tools. As for your complaint with `cargo`, there's nothing forcing you to use third-party libraries. It just makes it easy to manage dependencies. If you want to write things yourself, you're free to.
&gt; [[no_unique_address]] And here I thought we will never get this, because it would break everything.
Huh? No, it means in 5 to 8 years. We'll say never if we mean never. 
Optimistically C++20 looks like a major release 
But conservatively we'll get only Concepts and core of Ranges in final versions.
&gt; CD = Committee Draft. A draft of an IS/TS that is sent out to national standards bodies for review and feedback ("beta testing"). What does the "beta testing" look like? Are they really testing the early implementations or just performing thought experiments?
Just to chime in -- at zenAud.io (https://zenaud.io), we're using it in production. In fact it's fair to say it's completely taking over our codebase. We use it in UI code (including our OpenGL-based rendering engine), business logic, and even increasingly in performance-sensitive audio code. (Our demo synth was recently rewritten based on lightweight, semi-regular operators and is ultimately rendered to sample data using range v3.) What we're finding is that not only is range-v3 usable, but indeed the *harder* the problem, the more indispensable range-v3 becomes, precisely because of a) the excellent suite of views, actions, and algorithms, and b) because you're encouraged into creating small, unit-like functions that are much easier to reason about. Another tip: range-v3 interacts *very nicely* with libraries like Boost.Fusion and Boost.ana.
In this case, C++20 would turn out as a *major* release - in the sense of **major disappointment**. But I am optimistic for *at least* Modules to be merged into C++20. I am really tired of this macro stuff holding back such an opportunity to think hard about all that old cruft in peoples interfaces (mine included) and take action on that.
I was not aware of those awesome news: * Calender and timezone library added * Tooling (Dependency/packaging management) and Unicode groups
&gt;We spent an entire day discussing the Module TS v1 [...] We discussed merging parts of the alternative design for modules with v1 of the TS. I really hope the idea of dragging the preprocessor into modules (aka the ability to "export" macros) was rejected.
Is there any time line for this? I've been excited about using ranges for a long time but have not wanted to mess with the 2016 fork since it seems quite out of date.
Agree. My feeling is if the preprocessor is left out of modules, then there is a good chance to make C++20. But in the end, who cares what year modules are officially blessed as standard -- if we have usable implementations, then nothing stops us from using them. And there is good progress in both GCC and MSVC (15.6 looks *much* better than the previous releases).
Sadly no... From what I heard, people are very much in favor of that, which I attribute to short sighted-ness (their primary goal being to port their humongous code bases to module without any refactor whatsoever), rather than making a clean long term solution. I actually meant to ask you your opinion on the alternative proposal and the idea of module partitions which I find of dubious utility ?
Thank you for providing this information! For the Reflection TS: so this means the WG has decided that TMP-based reflection is the path forward, rather than CXP-based, right? For SG15: &gt; Dependency/packaging management. This is the first time the committee has had a major discussion on this topic. It’s not clear what, if anything, we’ll be doing in this space - but are talking about it. That is good news. Even if the SG just decides the answer is "nothing", it would be useful to have a paper explaining why. Hopefully the SG can get some experts in this area to contribute.
As long as your app doesn't need to support multiple compilers (the whole point of standardization)
&gt; Your opinion on the alternative proposal Unfortunately I haven't had a chance to read it. But my understanding is that it is (or largely based on) Clang modules and I agree with your assessment of its goals (ability to auto-magically port large code bases from headers to modules). &gt; idea of module partitions which I find of dubious utility? I am not against module partitioning per se as long as the discovery of all the partitions by the build system is taken into account. There was a paper by Gaby which had this issue. And there was a paper by Nathan which suggested listing all the partitions in the main interface unit, which would have worked.
Well, I think many people don't want to use features that haven't been officially standardized. Implementations might be available, they may change when the feature has been standardized, thus making them less stable. Regardless, I'd prefer that they get Modules right rather than rushing it. Just like any C++ standardizations, really.
&gt; For the Reflection TS: so this means the WG has decided that TMP-based reflection is the path forward, rather than CXP-based, right? No. There is strong agreement that we want to go constexpr-based, but we did not want to delay the TS for that. The constexpr-based approach should end up being a superficial API change (albeit an important one), but shouldn't change the feature set of the TS significantly. This is my interpretation only.
SG15 (Tooling) had its inaugural meeting this week. SG16 (Unicode) was formed today. 
never &gt;= 8_years; Like Networking, Concepts, Modules.. Uhm whatelse
That is money to these corporations, and no one wants to go back to their boss and say "sorry we got to spend millions for no tangible business benefit". Which is sad because they'll eventually need to do it anyways as part of regular modernization.
For (1), I'm not sure, I'll have to ask someone else. For (2), we don't know yet - things should be clearer after next meeting.
At the draft stage (CD for an IS, PDTS for a TS), many features will already be implemented in shipping compilers, so anyone can try them out &amp; provide feedback to the committee. Check out [the clang status page](https://clang.llvm.org/cxx_status.html) - there's still over a year before the CD is complete, and you can already use a few C++20 features with clang 6.
It's worse, because I'm afraid that the exporting of macro is something that will cost money down the road ( 5/10/20 years ) - but I guess it will be someone else issue so they don't care.
&gt; many people don't want to use features that haven't been officially standardized. And even if they want, the companies they work at won't let them.
Thanks for doing these! Checked for it as soon as I woke up :-)
&gt; For the Reflection TS: so this means the WG has decided that TMP-based reflection is the path forward, rather than CXP-based, right? Not at all - we had a [paper](http://wg21.link/p0953) this meeting from the authors of the current reflection proposal about going in a more constexpr-style direction, which was generally well received. Everything can still change before the reflection TS is published.
Fixed.
I've been playing with the gcc modules branch. I've watched the cooperation between gcc love and left in this space and I'm confident we'll get something good. gcc is working on an Atom interface with modules.
5 to 8 &lt; 10
That... really wasn't the point of my comment.
That's actually something that I find reasonable. Please do ! I'll also like to see `*` go. If you want to export a macro, then you should need to type out its full name.
&gt; Consider testing and logging libraries [...] This can be adequately handled with modules without macros: 1. Define a module that exports C++ entities required by the macros. 2. Provide a header that imports the above module and defines the necessary macros. 3. Users `#include` the above header. With this approach you still get all the benefits of the modularization (like improved build times). Plus the use of `#include` rather than `import` clearly signals that macros are to be included (and thus care must be taken). Also, what a lot of people don't realize is that if modules are able to export macros, then it will have to be `#import` the preprocessor directive, not `import` the C++ language declaration. BTW, in the Clang modules (on which this alternative design is based) it is `import` but it *is* a preprocessor directive -- Clang requires the BMIs to be available during preprocessing.
&gt; gcc is working on an Atom interface with modules. Interesting. Do you mean there is an Atom library that is modularized and compilable with GCC modules branch? Can you give some more pointers?
I would rather libraries like that ship with a separate header containing the macros so I can `#include` it and not worry that `import foo;` breaks my build because somewhere someone thought it was a great idea to `#export min`. In addition, the common pattern of defining some configure-macros before including a header won't work with modules either so there you already have code that cannot easily transition. Leave the preprocessor where it belongs. `import` is not a preprocessor directive and thus it should have ZERO effect on the state of the preprocessor. This is all just catering to people whose only argument is "we have a big code base and want a semi-automagic low-effort transition to modules". I have yet to hear a sound technical argument in favor of exporting macros that is not "because we need it, trust us". These people are more interested in solving the problem they have *right now* with complete disregard for the future health or vision of the language, or the direction it is evolving in. This short-sighted approach is going to cost the community at large down the road. C++ is here to stay for a few decades at least, and at some point I want to stop worrying about macros entirely. The preprocessor lives in a separate universe and it should stay there. Allowing macro export is sending the signal to the community that the preprocessor is here to stay and that getting rid of it isn't really a concern. We have a unique opportunity right now that shouldn't be ignored.
What's in library fundamentals v3? The link is 404.
After discussing with core experts the syntax was changed to what I have shown - this is to be consistent with the fact that declaration during pack expansion has the dots on the left side everywhere else (e.g. function parameters)
Were any concepts related changes / decisions made? 
I'm not sure what you mean. There were no TSes that failed. We created two new working papers and shipped one draft TS. Which TS are you referring to?
The paper isn't up yet. I'm not sure if we actually have anything in it yet.
Was the "constexpr reflexpr" proposal discussed? What about the third revision of the Metaclasses proposal?
He did that: https://github.com/ericniebler/range-v3
The tangible business benefit is faster, cleaner compiles, and (something that's often overlooked) far less storage of intermediary files. If that's not enough of an advantage, why bother switching to modules at all?
That's not a business advantage -- lower compile costs would be, but that has to be offset with higher labor costs.
Thanks as always for these updates Bryce
If you look at the previous post https://www.reddit.com/r/cpp/comments/854mu9/2018_jacksonville_iso_c_committee_reddit_trip/ you will see that a `[[no_unique_address]]` attribute is proposed for C++20 to allow zero-sized objects. The attribute would be used on a per-data-member basis, allowing the data-member to be zero-sized, from I could gather from http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0840r1.html
Seems to be a dumping ground for compiler specific flags (ie. what version of GCC you're compiling with). Edit: actually the wording seems more library focused, as it's intended to contain feature test macros.
&gt;I've had conversations with people ... who were unaware of the size 0 issue That's me right now. Can you expand on the inheritance workaround, how does it work in practice?
Regarding your point (1), I think the main problem is not that it wouldn't be possible to make it work but that nobody took the time to write a proposal for this. Keep in mind that for a proposal one has to make a full case study with motivation and possible benefits, side effects, feasibility from the compiler dev's point of view, etc. Probably, there are many more important features the exports spend time on and that there are easier possible solutions for problems where zero size objects arise than allowing `sizeof(...) = 0`. I think the biggest problem of size zero objects would be that it is a huge special case with questionable benefit. When would size zero objects be important? If you had large collections of them. 1.) Is this a common problem? I don't think so, considering what objects may be of size zero anyway. 2.) You already mentioned addresses of these objects. How would iteration over an array of a size zero objects work, etc.? How could this fit into the current memory model? Probably it's a better idea to directly look at the problems where you want to use the zero size objects and introduce something to make the problems easier to solve without inheritance and without trying to fit zero size objects into current memory model (small impact special case vs. large scale special case). For example the new [[no_unique_address]] attribute which was already mentioned by another redditor is a step in this direction.
&gt; In addition, the common pattern of defining some configure-macros before including a header won't work with modules either so there you already have code that cannot easily transition. In fact, modules without macro support is compatible with configure-macros. Just compile the BMI and implementing module unit with the definition. The cool thing is the the configure macro won't leak into your code, and you'll only need to add the definition for the code that need to be configured.
What about extending `std::hash` with more specialisations? Boost has had `boost::hash` written with [this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1837.pdf) in mind and it has worked perfectly for my (fairly limited) use case. Seeing that it's an old proposal, is there any plan on extending `std::hash` in some way?
&gt; attribute is proposed for C++20 to allow zero-sized objects. I don't think this would allow `sizeof(...) = 0` objects... &gt; on a per-data-member basis, allowing the data-member to be zero-sized ...this is more precise. One goal: solve padding issues and wasted space introduced by members that *could* have zero size.
&gt; Why do you say there is an executable bloat? That is a thing of the past, no? How can it be the thing of the past though? At least if we only consider static generics (and dynamic ones make little sense in the statically-typed language), then for each generic class/function invocation it needs to be instantiated and as such produce more binary.
The library thing turned me off too the first time I tried experimenting with Rust. I was on a flight and had downloaded the Rust distribution and an offline copy of the docs ahead of time. I'd had a program in mind and thought the flight would be a nice opportunity to try Rust. But I ran into a wall when I discovered that random number generator had been moved out of the standard library and into it's own external crate. What kind of general-purpose language doesn't come with an equivalent to rand() or drand48()?
Here's an example illustrating the issue: https://godbolt.org/g/U5sb4o It can be significantly more efficient to store something that you expect to be a lambda as a base type rather than as a proper member. Most programmers wouldn't expect that -- they wouldn't expect that the compiler will insert unused and totally unnecessary padding data into your object, or at least, they would expect that it can always be removed by the optimizer. I guess I don't know a good overview of how does it work in practice, here's a SO question that talks about it: https://stackoverflow.com/questions/4325144/when-do-programmers-use-empty-base-optimization-ebo
Cool, I didn't know about this, thank you! This isn't quite what I was expecting but it sounds like it may effectively resolve the issue. I need to study it more.
All objects have at least size 1. But object size can overlap with their members and base classes. All distinct objects of the same type must have a different address. Suppise A is an empty class. Its size is 1. An array of 100 of them has size 100. If we have struct B:A{}; then the type B also has size 1. What more, if B contains an int: struct C:A{ int x; }; then size of C can be size of int; no space is needed for A, as it can overlap with C. This is the empty basr optimizaton. However, struct D:A{A a;}; this must have size 2, as the base A and the member a must have distinct addresses. 
&gt; 2.) You already mentioned addresses of these objects. How would iteration over an array of a size zero objects work, etc.? It could work if you do `for (int x = 0; x &lt; N; ++x) my_array[x].do_something();` If you expect to use pointer arithmetic to iterate over the array then it won't work, but it's not clear that that matters. We could even forbid C arrays of size 0 objects, it would still be very useful in generic programming if we could nevertheless use them easily by composition in classes IMO. Edit: Maybe more constructively, we could allow C arrays of size 0 objects, but forbid pointer arithmetic with pointers to size 0 objects, similarly to how we forbid such arithmetic with `void *`. And specify that the array indexing syntax `arr[x]` still just works as expected if the type has size 0. From my point of view, giving an empty object size 1 instead of size 0 breaks the cardinal C++ rule of "you don't pay for what you don't use." Why do I get a bunch of totally unused and unnecessary padding inserted into my structures?
It's not only proposed, it's already added to C++20 draft.
Were there any proposals that were discussed but rejected?
&gt; If you expect to use pointer arithmetic to iterate over the array then it might not work, but it's not clear that that matters. The problem here is that array access *is* pointer arithmetic. You would have to introduce a special kind of array to allow this and as you mentioned, forbid C arrays of zero size objects. There is a huge rat's tail with special cases involved. &gt; From my point of view, giving an empty object size 1 instead of size 0 breaks the cardinal C++ rule of "you don't pay for what you don't use." That is definitely a problem but, as I said, I think it is more sensible to fix the special use case for the zero size objects (member variables, addressed by the new attribute) instead of messing with the type/memory system which is so much more complicated. Obviously this contradicts your quote but on the other hand the relation between `siezof` and memory layout is so fundamental that every more experienced C++ programmer should know this if the unnecessary padding were critical for his code. Certainly, it may not be intuitive for new programmers at first glance but at second glance there is no way that zero size could be possible in current C++ if you know about pointer arithmetic.
Sounds like Pandora's box of abuse potential. In theory you could probably use CRTP inheritance and an inlined static comparator method to achieve a `map` with the same stateless comparator effect, with a bit more code overhead. Definitely far from ideal, but for a niche case it's pretty acceptable. I don't see any benefit that couldn't be achieved by other means, and this sounds like a massive overhaul. A `map` with a size 0 comparator ceases to be a map, opening the gates to confusion, with two objects of identical interfaces having different sizes and types. That would also mean operator overloading for every function accepting a map to also accept a stateless comparator map. 
Paging /u/CaseyCarter
"Atom" in this sense is Google's "Another Take On Modules" paper.
Concepts were never removed from C++17 because they were never added. They _were_ removed from C++0x, but that was in Frankfurt, IIRC.
right, it wasn't added to the C++17 standard. Thanks for pointing that out. 
More disappointment
Just to clarify, since it's a little unclear. p0424 would have allowed: template &lt;char const* &gt; void foo(); foo&lt;"hello"&gt;(); // error today, ok with p0424 template &lt;auto&amp;&gt; void bar(); bar&lt;"hello"&gt;(); // error today, ok with p0424 p0732 doesn't allow either case, but it does allow you to have a type that is _constructible_ from a string literal, such as `basic_fixed_str` in the paper: template &lt;basic_fixed_str&gt; void quux(); // error today, ok with p0732 quux&lt;"hello"&gt;(); You can ultimately write all the things you want to write anyway, and p0732 let's you do lots of other cool stuff that has nothing to do with strings too.
IIUC, ranges core includes eager, range-based algorithms (with projections) and concepts, whereas rest includes views and the rest of the pipe syntax shebang.
I really don't see, why you need modules to interfere with the preprocessor (or vice versa) for that. Just `#include` the macros and `import`the rest. And in fact, as berium pointed out, you can just put the `import` into the `#include`d header. 
Does C++ demand a specific heap implementation? There's more than one possibility. They all have different costs. Sorting can be as cheap as O(1).
It'd be `[...&amp;args=std::forward&lt;Args&gt;(args)]`
No news about co-routines? That doesn't bode well.
It's disappointing that we should wait C++23 for standard networking support. Networking is fundamental, and almost every other language has libraries to handle it in a cross-platform manner...
For (1), I didn't read the whole proposal but just skimmed and also looking at http://en.cppreference.com/w/cpp/experimental/ranges it looks like core only contains range-versions of already existing algorithms (function-wise). For example range-v3 additionally contains views::cycle, view::repeat etc.
We got a good vote in Evolution group reaffirming the intention of putting coroutines in C++20 (but not yet). There were also an understanding from Concurrency and Parallelism group that coroutines do not have to wait until Executors are finalized and can proceed independently. Hopefully in Rapperswil in June we can get Coroutines merged in the working draft of C++20.
Cool story, bro.
I think the people involved are hard working and do a lot to make the C++ ecosystem a better place. That is not in dispute. But looking at it as a black box, I don't need to attend. I read most commentaries and trip reports and I care about where it is heading. But our libraries ecosystem that was touted as such a problem in comparison to other languages pre C++11 will not likely show much improvement 10 years later for C++ 20/21. After a week intensely working on the standard, a post like mine can seem ungrateful or just plain wrong. But try and measure c++ productivity improvements for the average programmer. I'm not talking about the modern language features, but the ecosystem of productivity enabling libraries.
For cross-compiling embedded Linux systems, take a look at Yocto. You'll need to dive pretty deep into the source code initially to figure out what's going on, but after a week or so it should click.
You're welcome!
There are 100+ papers in each mailing. These updates focus on features that are voted in to the next standard/TSes/etc. Anything else is just too speculative.
This library looks nicer and nicer every time I see it! I'm really looking forward to having a proper formatting library in the standard. Using iostreams is so cumbersome that I have to fight the urge to just use plain old `printf`. Not to mention the localization aspect.
I would like fibers at some point, but I really can't wait for Coroutines. Thank you very much for you work on this!
`std::map` contains a pointer to the comparator. Since it is sometimes stateless, it could be size 0, and resolved at compile time. You can also construct a map with a comparator defined at runtime (`std::map::map` definition 5), which necessitates a pointer of some kind. As a result, two `std::map` can have the same key, value, comparator, and allocator, but be different sizes, since one has a size 0 stateless comparator and the other has state.
Why should such individual utilities go through a TS instead of being merged directly into the standard?
&gt;But our libraries ecosystem that was touted as such a problem in comparison to other languages pre C++11 will not likely show much improvement 10 years later for C++ 20/21. C++'s library ecosystem is head and shoulders above pretty much every other language, if we're talking about libraries that do real work. In fact an FFI to call C++ libraries is a desired feature in most of these languages. What C++ doesn't have is a lot of small utility libraries that you can just glue together with minimal extra code. And yes, the standard does need to be as close to perfect as possible. It's not just an implementation, it's the ISO approved document that tells implementers they must do things *this* way. You can't really afford mistakes in that. On the other hand, the great thing about libraries is that they really don't need to be standardized, so they don't need to be slowed by the standardization process.
Feedback is appreciated, but to have a true understanding of the standardization process, you have to experience it.
p0732 sounds really cool! Do you know, where it currently stands? Can we expect to see it in the standard and if we can, when? That it was sent for wording review sounds promising, but I don't really know, what that actually means in the context of standardization progress.
Sorry, we write these reports during the closing meeting (so that we have the latest information - for example, we didn't know SG16 would be forming more than an hour before this was posted) - it's always a time crunch to get them done in time, and sometimes we forget stuff.
This. A hundred times.
Today when somebody wants to find out if their library (middleware) code is compiling against libstdc++, libc++, or VC++, the advice is "`#include &lt;ciso646&gt;`" and look for things like `#ifdef _LIBCPP_VERSION` (which would mean your library is compiling against libc++). Why `&lt;ciso646&gt;`? Because that header is specified to contain nothing, thus it is dirt cheap to include. `&lt;version&gt;` is simply a better name for `&lt;ciso646&gt;`.
80% of the features of a perfect solution. Often sufficient for most use cases and considerably lower effort and complexity. "I'd really like to use the preprocessor in my module so that I don't need to rework my existing code" Makes the modules feature far harder to implement. Assuming that most preprocessor use can be implemented in other ways in the module, or we could allow each module to use pre-processor internally but not leak outside the module. Is this restriction a real problem if it means we can deliver with an order of magnitude less effort? Tradeoffs to make modules available and usable.
The hope that enough std libs implement them in experimental that there is real experience. Also hope the small, but possibly important ones, won't get lost. There's an overhead of looking at a paper. This makes one, instead of a dozen. 
If I had no templates , same would have happened, except, I would have had written it myself. Template bloat is associated with multiple identical instantiations (e.g. `vector&lt;type*&gt;`) or instantions that aren't used, but that has been eliminated.
Everything my company does is in a top level namespace. We will not have a module with a quarter million implementation units. 
When compiling with clang you can choose whether to link with libc++ or libstdc++. Recently I had the use case where operator== of string\_view was constexpr for libc++ but not for stdlibc++. I had to put a magic macro switch following which standard library implementation I was using. That didn't even depend on the compiler version. Maybe with this header I would have had some macro defined for this case. In my case I put : #ifdef \_\_GLIBCXX__ ...
A few key changes were landed into Coroutines, too, if I understand correctly. My feeling is that there's been good feedback, it's going well, and should be nailed down soon. And there's still time for the library papers that won't depend on executors, so we should have range compatible generators, and something in the closed task area. 
There "core" here is just the concept definitions from the Ranges TS, and really only the foundational ones like `Constructible` and `Semiregular`. Everything else, including the algorithms, are coming separately. I have high hopes we can get the algorithms into C++20. There's an outside chance I may even be able to land a few of the more important view adaptors, but we'll see.
Troll. Concepts have already landed.
constexpr and lambdas are just two examples of features added but then later extended with "more features". I don't see much evidence that this approach isn't taken when it can be. 
Okay cool! I see :-) Thank you very much for this simple explanation and example! That's a small but really nice improvement.
Core Working Group didn't have time to review it during this meeting, but hopefully the wording will be approved (possibly with some changes) during the next meeting in June.
arrays of such objects? a[n] == n[a] == * (&amp;a + n) == *(a *)((char *)&amp;a + n * sizeof(a))
Time for the downvotes but, as a CPP dev I really think the ISO standardization process is unnecessarily elitist compared to most other open software decision processes... the need for spending significant time to lobby your idea in person to win over key people lacks fairness and is fundamentally not transparent and unaccountable. You can't seriously say "just take a week off and book hotel and flight" when that's out of the means of most of the worlds' population in terms of time and money... and that's just to _look_ at it since actually swaying opinions would require a lot more trips and more politics. The current situation in my opinion restricts decisions to insiders or employees of major companies. I think other languages like Rust have a much more fair and open standardization process where in theory, you can actually make a RFC at home by yourself (with caveats)... I'm not saying the current standardization is awful but IMO it could easily be more inclusive towards developers that don't have the ability to make that time and money investment as their job won't support it or are from poorer countries. 
&gt; C++ designers tout "you only pay for what you use", but that's simply not true when the cost of learning, using and reading these features is factored in. What? If you don't use a feature ever, you don't have to learn about it, because they're well designed enough to be avoidable. You absolutely only pay, in terms of learning, for what you use. Hell, if you really want, you can still write C++98 style in C++17 and not have to learn any new features. &gt; but they are distracting from basic networking, execution control, reflection, even the prospect of simplifying use of the language with meta classes. I think that's more of a chicken and egg thing, and not just the committee. They now prefer if there are tested implementations, but the compilers don't (seem to) prioritize keeping up with things that may or may not be in the future standard, so people don't use those proposed features, and so we don't have enough experience with a proposal for the committee to make a quick decision on.
As someone who is developing their own systems programming language that allows objects of size zero, I have some thoughts on this. In terms of the memory model, there are three operations one might want to perform on an object: load, store and taking its address. For zero-sized objects, loads and stores are simply no-ops and are never actually seen by the compiler backend, so there is no optimization to be performed or broken. Taking the address needs to return some pointer value different from the null-pointer (this is useful for generic code), but it does not matter what the value actually is since such a pointer is never loaded from or stored to. Hence, for my language I made the choice to simply use the value 1 as the address of any such objects. Now as for arrays, clearly using sizeof as a means to determine the end of an array of such objects cannot work. Fortunately, in my language arrays know their length so this is not an issue. This problem needs to be resolved in C++ somehow, but I would argue that it isn't too bad if begin==end and iterating over such an array is always a no-op too (again, this needs to be valid for generic code to work). I think EBO is a hack and I would rather have the language support (and require!) that empty objects have a size of zero precisely so that people do not have to worry about it. On another note, the lack of this feature also shows in that it was decided to add std::monostate for std::variant. void would have been the perfect type for that purpose - had we had zero sized types and regular void. tl;dr: I don't think it's all that hard, but someone needs to propose it. Personally I have given up on C++ so that person is not me.
You don't actually need to be there in person to write a paper.
Is a paper whose author never attends a C++ ISO meeting likely to be approved? I had the impression it was pretty unlikely but I honestly don't know. How would he defend it?
Depends on he paper, if someone has questions and no one is around to answer them, you might find a slow turn around. Plenty of active contributors don't make every meeting. While there's cost associated with traveling, once you're there the power to contribute is magnified; anyone can participate, and in person discussion is so much more productive.
Correct me if I'm wrong, but rust and python can work with small user submitted RFCs because they have a small core of central designers who actually approve it reject the submissions. C++ is a very unwieldy thing, with many technical snags, and lots of interested parties.
I'm sure you know, but just in case, you can already use [fmtlib](http://fmtlib.net/latest/index.html) for this, and the coming standard is based on this. Highly recommended.
Wouldn't it be much easier if the standard was written as a suite of automated tests? That way any person could modify its content and instantly know if they broke some existing functionality.
Are these meetings open to the public? What's the best way to get involved?
It seems like you're wrong, this "[Life of an ISO](https://isocpp.org/std/the-life-of-an-iso-proposal)" page says so: &gt;A lot of people outside the committee think they’re done at Stage 0 or 1, and think that the committee will just run with their idea. Don’t expect anything to happen until a detailed design paper exists with a champion who will personally present it to the committee and contribute work on it to incorporate feedback and refine the proposal. you can write the RFC but you still need to have some friend that has time to travel and wants to present it for you, and it will likely require more than one trip. So yeah, requirements are very high.
"Don't write a paper and think you're done" != "You must personally present it". You should have someone to champion it at the meeting where people decide things, and you have to respond to feedback.
Missing my point. It's the case where a proposal is delayed significantly because of the points I mentioned. As a developer, you do have to be pragmatic. You update the major version when no longer backwards compatible. You may only aim to solve 'most' use cases, knowing some are not yet solved. (Often in far less time) Some solutions aren't elegantly reduced to simplicity or if they become so, only after several releases as the essence of the problem crystallises. Your examples illustrate things the standard committee have done well. I certainly know they do a lot of good. I am however asking if some of the tenets they hold dear are actually more harmful to evolution. 
I would assume such a change would break a lot of legacy code that depends on separate objects having unique addresses or expects that division by `sizeof(Object)` won't result in division by zero.
J1 exchange program, for the duration of the internship
Yep. It's mentioned in the begging of the linked article/blogpost. I've been loosely following it's development for quite some time, hence the comment.
Fair points but ... By making features complementary to existing ones, do you not think that the overall complexity of C++ increases vastly? I see the need for something like the huge opus that is the core guidelines as a necessary evil due to what C++ has become. Big picture. Most of that advice and the various effective books, exceptional books etc are indicative of the problem. Lots of new ways are being proposed as we learn what's good, but none of the old ways are being shut down firmly enough. Core guidelines go some way to suggest and warn about the old, but other than a few deprecations like auto ptr, the language places too much importance on allowing old, bad code to run. For instance, I'd love to see some meta class definitions for value types, RAII classes etc as per the very exciting talk given by Herb Sutter. I'm not even bothered whether the feature provides a mechanism to replace MOC or others. What I want is not to have to think about the rule of zero, five, seven or whatever number. I want a value meta class, a resource owner class, an interface class and an implementation one. Maybe composable variants for noexcept etc. I then want the clear guidance from the standard possibly backed up by enforcement in compiler to Not roll your own class with all its pitfalls. The cost of the fine grained control is the shotgun misuse opportunity and the vastly increased mental complexity. This is the false promise of "don't pay for what you don't use" in conjunction with "we give you the tools". To be fair, there are a lot of attempts to provide modern safer alternative features, and the core guidelines are a marvellous attempt to automate new guidance, but they are indicative of how the current approach to evolution is making C++ more unwieldy.
Ah misread you there, referring to the iostream/printf-mention.
Yes? If you know how to please let us know. Well, hopefully with constructive criticism. We already know that undecibable types leak and make things awful forever.
What was the reason given for the single strong oppose to the user-extensibility? Was it just an opposition to the specific details of how it's done, or to the entire concept?
Hard to say, please post some code you've got to get a clearer picture?
I’ll post some in the morning, (late at night and can’t be fucked)
Thanks
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/859046/csfml_problem/dvvp77p/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes, thanks for clarifying.
&gt; Maybe the precious backwards compatibility is more damaging to progress? If backwards compatibility is dropped, we might as well design a completely new language. It would be D, but without the GC. Is there anything that's easy to do in C++ but not in D, according to just the language? I haven't had time to mess about with D yet.
TBH it would be more like Rust, which I was about to introduce to OP.
But not 'rust' as it is now. From what I've read, it compiles at about the same speed as C++ (and so does D), and it doesn't have compile-time reflection (yet?). And it's syntax is much more different than C++/D. But if Rust was otherwise perfect, sure, the syntax wouldn't be a problem.
I'm little late to the party but want to add another example where diagnostics will improve overall experience - https://godbolt.org/g/kGKowz The diagnostics produced by MSVC here are just perfect, clang does seem a bit verbose but readable otoh gcc confuses anyone who hasn't been writing c++ for about 5 years :D
You mean, as opposed to `void foo(IBar&amp; t) { t.bar(); }` ? I don't know, man... unless the compiler can devirtualize the above call, the above function is inlined and compiled into a virtual call, whereas the template one is also inlined and compiled into a non-virtual call.
Objective-C uses `#import` already, so if you do write this proposal you'll probably get shot down. You'll should use a different directive.
Transactional memory ?
It's a fucking discussion forum idiot.
The point is that I think modern C++ is very good. (I'd pick GO as a backup btw 😀 ). But it needs to get a better strategy to reduce its complexity and deliver quicker. I don't want a new language to be effectively a c++ subset. I want C++ itself to become simpler and more able to deliver.
Do you know if anyone is working on modules-ts support for clang?
Am I reading the likely/unlikely paper correctly that the envisioned usage is not if( [[likely]] a&lt;c ) { // ... } else { // ... } but rather if( a&lt;c ) { [[likely]] // ... } else { // ... }
Modules is a really immature feature and it still needs more understanding before moving forward. In my tests, modules made close to no benefit in terms of compilation speed and benefits. My guess is that modules might be a feature only important if you exporting libraries but there is a bit of misunderstanding that modules is the solution for all problems.
MOMMY WHY DON'T THEY MAKE C++ WHAT I WANT IT TO BE INSTEAD OF WHAT OTHER PEOPLE WANT IT TO BE?!? WHY ISN'T WHAT I WANT THE MOST IMPORTANT THING IN THE WORLD TO EVERYONE ELSE?!? WAAAAA. That's what your post sounds like to me.
You often want to load format strings dynamically for l14n and i18n. 
Would be greatly improved if it didn't try to emulate C syntax. For instance, significant whitespace would make it a lot more readable.
Thoughts on Rust and why have you given up on C++?
&gt; Disclaimer: GCC 8 has not been released yet, so this document is a work-in-progress.
In Rust, those are called [zero-sized objects](https://doc.rust-lang.org/nomicon/exotic-sizes.html#zero-sized-types-zsts) and they interact weirdly compared to rest of language as far "unsafe" code is concerned. In particular: - 0-sized allocators may return null pointer which is indistinguishable from out of memory situation. Whatever allocator is used, it needs to be aware that it may be used to allocate zero-sized objects. - Pointer arithmetic is pretty much a no-op. This is a big deal, in particular it breaks iterating over an C array. A specific rule could be added about arrays that if an array element is 0 sized, it will be 1 sized in array. So for instance `sizeof(A)` would be `0` and `sizeof(A[10])` would be `10`. Such a rule would complicate implementation of `new[]` operator, as usually `sizeof` includes alignment. Rust deals with that by iterating over 0-sized arrays differently, but this isn't an option for C++, as pointer arithmetic is likely to be used for such iteration, without an abstraction dealing with an iteration. - There is code that assumes it can divide by a sizeof. For instance, an usual ARRAY_SIZE macro in C does exactly that. This will cause compile-time errors for zero sized structures. In the end, it's probably better to have `sizeof` of empty objects to be `1` and relax rules about pointer uniqueness for those. I can imagine there will be code that depends on pointers being unique and/or usable (perhaps somebody was crazy enough to use 1 byte storage of a zero-sized object) however.
Yes you're right but in the previous cycle it was always updated during development so i was just asking. 
_"excuse me but I'll have you know Rust has"_ makes for an excellent slogan. After all, this kind of unwanted advocacy is just what most people associate with Rust nowadays... 
One other Idea was to change some general design decisions, like using signed integers for sizes, changing how to use custom allocators or the way that futures work.
&gt;Maybe the precious backwards compatibility is more damaging to progress? The world needs a language for software that lives for decades. Not everything is a shitty throwaway app. 
I'm not saying C++ 2.0 cannot run alongside C++, they can even seek binary compatibility. I also completely agree with your sentiment. Let's face it though, your software will sometimes have a major version uplift making it incompatible with previous. This is probably a side issue though. My main point is that the current approach to adding new features is crippling C++ with technical debt and complexity. 
"Unwanted advocacy" as a response to a question directly asking about Rust... Get over it.
I was not talking about this specific instance of it. 
It is 70-30, i agree on many things but i dont on others Dont worry that much, natural selection will do the job as always do, if the C++ awesome people dont adapt as well as any other rival, well... it time has come to end. Now that Rust is the THING you can see it as a direct rival, if it isnt another will arise and compete making the committee change or be replaced by other language And if you really care take part and try to Make C++ Great Again, dont be like many others that roam about things but do nothing and expect to change, do your part citizen! https://images-cdn.9gag.com/photo/ap2QVMM_460s.jpg
Why do you think decisions about C++ syntax should depend on other languages? 
&gt; the problem is having an engine that automatically is able to verify and enforce these rules. Well, yes, but a prerequisite for developing such an engine it is to develop a set of _enforceable_ rules (ISO C++ rules are not really enforceable); what OP does is describing such a set. 
The only good bug is a dead bug ;)
"Should" has little to do with it, and is rather missing the point. The fact is that it will cause problems in Objective-C++ front-ends, as well as MSVC which uses `#import` for COM type-libraries, so the committee won't accept the directive name as a matter of practicality. Downvoting /u/m42a for being realistic instead of idealistic is just petty.
Not that if you go the way of "faking" pointer addresses, then you could simply space the begin/end pointers by the appropriate size to allow iteration (1 byte at a time). There may be issues if some hardware validate addresses when computed (rather than used).
Speaking of Python: their Python2/Python3 thing is annoying. In C++ even the std::string COW change creates friction in the development. Most of third-party libraries think that they're the center of the universe and want you to recompile your project with their funky settings, build system and implementation of the standard library. I dreamed about Asio in C++, but it was like 5 years ago. Now it's very late, it's time for the high-level protocols.
This was an interesting article but was focused on tge usability not on all the changes. 
&gt; Calender and timezone library Thank god! This will be so helpful! &gt; Unicode Study Group (SG16) Formed Yes! I am really happy that the committee is listen to the community suggestions.
Yes. That's correct. 
But you need someone to present it for you ("a champion") and the proceedings of the meeting are not transcribed, since they happen orally. If the "discussions" were to happen offline in writing: - you would not need a champion, - all discussions would be recorded for the posterity. Face-to-face is useful, and oral discussions proceed quicker, but it's not clear it's the best approach, especially seeing as other languages do not seem to need them as much.
&gt; Boost.ana Or Boost.Hana ?
&gt; Rust is heavy on static checks so it will likely stay slower in compilation. Actually, the static checks are really fast compared to C++, it's the code generation step (generating LLVM IR and then having LLVM generate object files from that) which is slow... notably because the compiler generates heavyweight IR. Fortunately, LLVM is used to crawling through heavy LLVM IR files thanks to C++ massive translation units, otherwise it'd be worse! It's gotten better since 1.24 which introduce incremental re-compilation, since before that it would re-compile the whole library/executable from scratch every single time. Still not quite there though. There are from time to time some exponential blow-ups in the type inference/type checking algorithms, but those are bugs and get fixed with time, just implementation issues, nothing "inherent" to the language.
According to my reading of the Standard, this should be possible: if (condition) [[likely]] { cats_are_cute(); } else [[unlikely]] { stl_buys_a_dog(); } This is due to how a *statement* can be an *attribute-specifier-seq[opt] compound-statement*. (I don’t know if `[[likely]]` and `[[unlikely]]` should be used in pairs, or if it’s sufficient to tag one branch, all I’m talking about is where attributes can go in the grammar.) I always have to look up the grammar for attributes since the locations can be surprising. For example, marking a `typedef` as `[[deprecated]]` is very different from marking `using`.
I like what they're doing with Rust in terms of safety and I think it is a good contender for replacing C++. That said, I'm not a fan of Rust's syntax and I disagree with some design choices, the biggest disagreement probably being immutability by default. Some other languages trying to do the same thing are [Zig](https://ziglang.org/) and JAI (which is not available yet except for "beta-testers" as far as I know). I think they all have good ideas, some of which I might steal. Note that Rust hadn't really taken off when I first started (it also looked very different from now) and I was not aware of Zig or JAI at the time. Right now it is hard to make the case for yet another language and I am not done with the design yet, but I do believe there is still room. Now as for C++, there is a lot of issues with the language itself, the ecosystem and the standardization process as well. We needed modules years ago, forward declarations should not be a thing anymore, definition order should be irrelevant. Built-in arrays are being abandoned in favor of std::array. Uniform initialization is obnoxious and doesn't work well with generic initialization code. Move semantics add all these new things into the language like rvalue references, reference collapsing and perfect forwarding, which make the language unnecessarily complicated and libraries hard to read and write. This is just issues with the core language and not a complete list either, just a few things off the top of my head. There is also a lot of problems with the ecosystem (or lack thereof). Compile errors are still terrible (yes, that includes clang), there is no standardized build system (and even if CMake becomes a quasi-standard, it is still terrible being its own scripting language) and I also believe that separate compilation is an outdated build model that hampers language evolution. The reason why I gave up on C++ is that I simply see no way of fixing these things without starting over. The standardization process suffers from the "too many cooks spoil the broth" problem, there is a lack of decisive decision making. The committee overwhelmingly tries to make everyone happy, thereby making no-one happy with compromise-solutions. I could not believe my eyes when I saw IBM kicking and screaming about the removal of trigraphs, luckily the committee went ahead regardless. But that's about decisive as these decisions get.
C++ is multi vendor, not just one implementation, so you always will have to deal with the many implementers and listen to their feedback. I do agree with your criticism, but that is how the ISO system works. But there are mailing lists, online forums and other ways to participate.
I think we need both.
Suppose it does a bit more things than simply forwarding the call (that was just an example) so inlining it is not feasible. Now, with templates the compiler generates new binary for every instantiation of this function. With inheritance approach there is only one function. Same with other templated objects.
&gt; That only works sort-of. You would need sizeof(T) to return 1, unless I misunderstood? Not for iteration, `Empty* e = p; p += 1;` would move by 1 byte. Though it might desirable for consistency. I really like Swift solution in that regard, with both `sizeof`, the real *unpadded* size and `strideof`, the stride in arrays. In this mode, one can have a sizeof 0 and a strideof 1 with no discrepancy. Of course, retroffiting strideof in C++ would be *really* hard :x
&gt; It seems somewhat wasteful to first parse the format at compile-time, and then parse it again at run-time when actually formatting. You don't have to do parsing twice with the current API. In fact it encourages the opposite because the format string is not provided at the formatting time. So the client should normally parse the format string, store the parsed specs in the formatter object and then use these parsed specs at the formatting time. &gt; Also, a nice benefit of using functions is that they work with derived classes by default. I think it should be possible to handle derived classes with constrained specialization (at least that was my impression from the discussion at LEWG). A few advantages of the specialization API: 1. You don't need to pass parsed specifiers explicitly in the format function. 2. It's a bit easier to re-use other formatters, e.g. if you have an int-like type you can just do: template &lt;&gt; struct formatter&lt;T&gt; : formatter&lt;int&gt; { auto format(...) { ... } }; Otherwise I don't have a strong opinion either way.
There isn't much information around: you can find a bit more on the libstdc++ status page: https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2017 As you can see a few C++17 library features have been implemented: `constexpr` for `std::char_traits`, putting the Filesystem TS into the `std::` namespace and plenty of assorted fixes. The page hasn't been updated for C++20 yet, but I have seen a few changes here and there in the mailing lists. A few C++20 language features such as `__VA_OPT__` have been implemented too, but no changelog reflects that yet.
It would be nice to see a split into cpp-legacy and cpp-modern that is allowed to scrap pre-cpp11 compatibility and update every year. Then have the committee primarily work on the legay branch..
As far as I know, the import directive in Clang takes a framework name, inside double quotes. Here there is no quotes, so there is little reason why the import preprocessor couldn't not be compatible.
If it does more than simply forward the call then how would you have solved this with virtuals in the first place?
If we are swapping anecdotes, modules resulted in 3x times build speedup in our case. You can even [see](https://youtu.be/E8EbDcLQAoc) the builds side by side (a couple of minuted into the presentation).
Sadly I don't believe anyone is. There is also a bunch of patches that fix/add Modules TS- related features that have had zero feedback for months: https://reviews.llvm.org/D40443 https://reviews.llvm.org/D41566 https://reviews.llvm.org/D41627
From what I’ve seen, if you have a good idea and show initiative, you’ll easily find someone to present it at meetings.
We have to wait for more detailed trip report for various committee members. There are several of members who normally publish trip quite detailed reports. And since there are several groups working in parallel no single person could know everything that was happening, so we'll have to combine pieces of information from different reports. 
From gcc's git log, the majority of the work on C++ is on bug fixes. 
I was referring to D's way of importing modules. It recompiles them just like C++'s include system.
Nah, not really 
Yes, after how many years? My simple statement still apply. But I would say Concepts worth the wait. I hope the newer terse syntax suggestion will be merged 
Exceptions are problematic in C++ already, they went with return type error handling with good type safety forcing you to deal with error cases as close to the problem as possible. It's just less problematic.
[This nonsense](https://doc.rust-lang.org/std/primitive.slice.html#implementations) is why they're necessary – all those trait implementations for `[T; 0..32]` merge into one, and trait implementations for slice lengths &gt; 32 become implemented.
Function overloading is not something I miss. A lot of problems can and did come from that. Value generics can be replaced by the nice macro system it has. There is no need for a Turing complete generics. Exceptions... I wish we didn't have them in c++
To clarify: the opposition was to the user-extensibility of format string syntax as in format("{:%d/%m/%Y}", date); It's still possible to support formatting of user-defined types by wrapping them together with format specs in a function call similar to [`std::put_time`](http://en.cppreference.com/w/cpp/io/manip/put_time): format("{}", arg("%d/%m/%Y", date)); Note that the current proposal allows both, but limiting functionality that can be expressed by other means is a valid argument (sometimes less is more). In this particular case I think it can be beneficial to have user-defined syntax for the reasons of consistency (why user defined types should be different?) and localization.
Solved what? Are you implying that it's impossible to write functions accepting pointer to some base class that do anything else besides simply forwarding the call? That's simply not true. See for example: `void foo(IBar&amp; t) { auto x = t.bar() + t.baz(); cout &lt;&lt; x &lt;&lt; endl; }`.
The committee is always listening to the community. After all, we’re all just members of the community that decided to get directly involved. SG16 was formed now because we finally have enough people with interest and sufficient expertise regularly attending the committee meetings. If you have relevant experience in a technical area that you feel is not getting adequate attention, then please, write proposals and join in!
You seem to be trying to convince me of something. I'm merely relating the calculus of others. I guarantee you the people who decide what is worth millions in developer time are not reading r/cpp. The people representing their companies are doing exactly that. 
Backward compatibility is BS. If you have old project then probably manager will not allow you to use newer compiler.
&gt; It's more a tool to allow clean interfaces between libraries and end uses. Exactly! And therefore it has to be clean as possible. Design Modules in a way that using Modules is a *pit of success*. I've looked hard and found no good place for macros in there...
Thanks, I am not sure if I have the technical skill needed, but I will probably have a look at the proposals process in the future. ;)
Including later versions of the same compiler?
Thankyou!! 
I don't subscribe to the idea of bootstrapping, I think that's a distraction and waste of time, especially if you're working on your language by yourself. My compiler is written in Java and while it's not perfect, I think it has worked out really well so far for me and was the right choice.
Hope they Bachport those to gcc7 too
What’s the advantage of signed integers for sizes?
I’m very excited about ranges. What are you finding to be the downsides?
&gt; So the client should normally parse the format string, store the parsed specs in the formatter object and then use these parsed specs at the formatting time. I see, so the formatter object is actually treated as FormatSpecifier with a format method. Clever. &gt; I think it should be possible to handle derived classes with constrained specialization (at least that was my impression from the discussion at LEWG). I hope this is relatively easy. &gt; You don't need to pass parsed specifiers explicitly in the format function. Doesn't really matter, it's handled by the framework anyway. &gt; It's a bit easier to re-use other formatters, e.g. if you have an int-like type you can just do: I like reuse indeed, however I am not sure that your solution requires less boilerplate. Compare: namespace mine { struct S{}; } namespace fmt { template &lt;&gt; struct formatter&lt;S&gt; : formatter&lt;int&gt; { auto format(...) { ... } }; } versus: namespace mine { struct S{}; constexpr auto parse(fmt::type&lt;S&gt;, const char* begin, const char* end) { return parse(fmt::type&lt;int&gt;{}, begin, end); } auto format(...) { ... } } Same number of lines (though the second snippet has two empty lines), and a slight advantage on the number of characters. However, the second example is not optimal; it's possible to "inherit" the format specifier by allowing an ADL function to specify it (by default, it'll just forward its parameter): namespace mine { struct S{}; auto fmt_parse_selector(fmt::type&lt;S&gt;) { return fmt::type&lt;int&gt;{}; } auto format(...) { ... } } Whether it's more readable is up to the reader, but it does benefit from avoiding breaking out of the namespace.
We all want backward compatible breaking changes. 
&gt; C++'s library ecosystem is head and shoulders above pretty much every other language, if we're talking about libraries that do real work. I find this an odd stance. I've worked professionally for multiple years in various languages -- the past couple I have gotten back into C++ after a long break. C++ libraries issues i often have: - The library for task X simply doesn't exist (or is really hard to find). - The library exists but hasn't been maintained in years. - The library exists but provides an old/clunky API. - The library exists but comes with a kitchen sink attached that makes it's use undesirable. - The library exists but is just a wrapper over an existing C library (see the clunky api item again). Anyway, you seem to think this is a slamdunk for C++, and i think youre kinda nuts. 
Maybe i don't agree with everything as put here, but i do agree that C++ simply just has to become more agile. Compiler technology, like LLVM, has really enabled the competition, and there are languages out there ready to challenge C++ in its core competencies: speed and efficiency. Do you think Rust would be where it is today if it had to wait until the developers of 3 or 4 various C++ compilers were happy before making a change? I doubt it.
1. Increased compile times. My way of looking at this is that, yes, it sucks, but the advantages in terms of programmer ergonomics *far* outweigh the costs. 2. Learning curve. range-v3 is more stringent as to requirements of its "inputs"; this caused a few WTF moments for me. As an example, you can apply std::algorithms on an sg14::ring_span, but you can't apply range-v3 stuff because ring_span isn't semiregular. (I raised an issue on github!) Also, one that threw me off at first was that `std::back_inserter` doesn't (always) work with range-v3 -- but there's `ranges::back_inserter` which *does* work. What's going on is on the one hand sentinels in which the `std::end` result iterator is of different type than the others. Trust Eric Niebler (and Casey Carter, both of whom deserve massive praise for this amazing library) that it's a good design choice. That said, I had to tweak some of my own containers and views to work with the library, and here the lack of concepts makes things harder -- the `std::enable_if` magic tells you that your input doesn't match the requirements, but you don't know exactly what went wrong. I have taken to peeling away constraints until the damn thing builds, which, while enlightening, is probably not a great use of developer time. On the other hand, in at least one case, this focus on concepts made me realize that aspects of my design were wrong, and the changes I was forced to make ended up improving the code. Basically, IMO concepts oriented design becomes more necessary when using range-v3, and it's difficult if -- like me -- you come from an OO background. (Even though I dabbled with Haskell, which -- with this library -- officially toast.) Just to counter that, some more positives: 1. It's super easy to create your own views, and they're *incredibly* useful. For example, we have a UI object which represents a track. For legacy reasons, it owns a vector of polymorphic loops (they will become variants soon, but one thing at a time). To find the set of loops overlapping a given time range, you basically do a binary search (lower_bound, upper_bound). Range-v3 does this, and then I added a little `rsv::transform` to convert the cast the polymorphic object to what I know it needs to be given the track type. One extra little function, and now a huge pile of horrible code involving searches, casts, etc., becomes: `track.regions_during(ival)`, which can be looped over using range-for, and allows the full armory of range-v3 algorithms. I put this stuff in a track_node.hpp header (because I was too lazy to figure out the types), and while my compile times wen up (it's a critical header), the advantages are so huge, there is *no* way I'm going back to the old code. 2. For really tricky code -- an example in my codebase is drag-and-drop of regions, there are corner cases which you invariably forget. It's simply complicated. The cool thing with range-v3 is, each of those corner cases is a short new `transform`, or `remove_if` -- before, the code would become littered with if-statements, loops, etc. and it eventually became a mess. Especially for this part of the code, I think range-v3 gave me the tools to accomplish the task. 3. Ironically, even though in rare corner cases you *may* lose some performance. And I say rare, because Casey and Eric have gone to enormous lengths (both in design -- e.g. views/actions separation, and implementation -- just look at the issues) to make the library blazing fast. That said, it's clear that sometimes the "clean" formulation can be slower than the "hand-rolled" one. This worried me at first. But what I realized was this: once you had the compact, clean, formulation, that you could just look at and you *knew* it worked, suddenly, you could start having new conversations. "What if I run this algorithm interleaved instead of per-channel?" Using Boost.Hana and range-v3, it's a few lines of code. If your code is hand-rolled, that's going to be a painful change. This had a huge impact on my OpenGL code, where I was able to make quick decisions about what granularity I should make the shader (tradeoff is more variables = more flexibility and therefore less draw calls, at the expense of slower shaders and memory transfer). The conclusion I arrive to is if you can't make quick architectural changes, you're kind of screwed because you almost certainly won't "guess" the global optimum. Optimizing for code clarity allows you to do that search across the global space. If you then still don't have the perf you need, only then should you consider another approach. It hasn't happened to me yet! Anyway, as I hope it's clear -- I love this library and I can only encourage the relevant decision-makers to lose their cold feet and adopt this library as fast as possible. By the way, at some point soon I intend to make a blog post with before/after code snippets; people can judge for themselves then. 
What was the thing you are trying to do? If it was something common, what you're looking for almost certainly was available, and probably (if you're lucky) as part of one of the large libraries like Qt or Boost so you don't have lots of dependencies. Even if it's something highly specialized, C++ can access C libraries as easily as C can, which isn't true for almost any other language.
Eh. I go out of my way avoid mentioning inconclusive discussions, unless they are on major topics.
Making even a basic OS is super complex 
It will take a year or so to actually do that. Even making a simple program like File Manager will take a decent amount of time. That’s a pretty good beginners guide: https://samypesse.gitbooks.io/how-to-create-an-operating-system/ But it is not even close to what a real OS is. Apart from C++ you need a good understanding of low level programming and OS architecture. 
I'm talking like a basic MS-DOS.
You will have more luck with x86 assembly and C. Get started with this https://arjunsreedharan.org/post/82710718100/kernel-101-lets-write-a-kernel
I don't think it's very useful to talk about percentages, percent of features is not really quantifiable. I think "don't let perfect be the enemy of good" is a reasonable sentiment. At the same time, it's important that we don't "fix" a problem in a broken way, and then have the need to be backwards compatible prevent us from ever actually fixing it.
Ok, but how much of that old code would actually be taking `sizeof(lambda)`? I would expect almost none of it?
Yeah, u got me. Either way Networking &amp; Concepts will be over 10 years by 2020; Can't say for Modules... yet
Possible inspiration: [IncludeOS](http://www.includeos.org)
[IncludeOS](http://www.includeos.org) might help.
I like the first line of your second link. 
I know, but, I am not going to copy MS-DOS.
I didn't say you had to. You can learn from the source code for how to solve any problems you might encounter. 
The folly of your ways is that you think that some code knows whether its errors are recoverable.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/85d2xh/new_to_c/dvwiumo/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I completely and utterly disagree. **Vast** amount of code react to errors by cleaning up and bailing out, nothing else. Exceptions cater for that state of affairs, and that is why they're the prevalent error handling mechsnism in all mainstream languages (e.g. Java, Python, C#, Ruby, JavaScript etc.)
&gt; Troll **error: deduced initializer does not satisfy constraints**
&gt; **Thou Shalt Not Specialize std Function Templates!** &gt; [...] &gt; - Taking the address of a standard library function is not allowed. Of *any* std function, or only templated ones? 
Just to be clear, submitting a Rust RFC also requires quite a lot of politicking.
...is a topic way too often spawning on this __C++__ thread.
Why is reflection such a hard problem? Or is it a matter of priorities? Is there a situation where a 10-15 year design timeframe pays off, compared to having *something* available?
Well if you write off the two big batteries included libraries, I'm not surprised you're having trouble finding libraries. It's even worse if you also refuse to use C libraries, which for simple tasks are perfectly fine. Qt licensing isn't complicated. The easiest route is to licence your own code under the GPL or LGPL. If you can't do this, dynamically link to Qt. If that isn't possible either, you'll need a commercial licence. In my experience, it's other languages that provide a shabby experience, where you have to research and choose between multiple options for each task, and you don't know how well each will be maintained. With C++, you can just decide to use Qt and KF5, for instance, then use the included modules for whatever you need, secure in the knowledge that it'll always be maintained. 
&gt; Qt's dual licensing is confusing. how is dual licensing confusing ? You have the choice between using Qt as any other LGPLv3 lib OR paying for it if you want to remove LGPL restrictions / support. 
You're right, i editted my response. It makes things more complicated, not confusing. The commercial licensing is undesirable in comparison with the large body of totally open source libs in other languages.
There have been a lot of discussions around it. Mostly it is about reducing the chance to run into trouble due to accidential signed/unsigned conversion or because you forget that `a -1 &lt; a` is not always true with unsigned types.
No one is born with the technical skill needed ;) For the proposal process, see https://isocpp.org/std/submit-a-proposal
CppRestSDK FTW! :)
No it doesn't. Qt is one of the big C++ libraries driving C++ FFI in other languages. A lot of the big libraries in other languages are just wrappers around FFI calls to C or C++ anyway. If what you need isn't in Qt or Boost, there's almost certainly a library available for it in C++ or C, and it'll generally be maintained by people who know what they're don't (often being the official / reference library). The exception is if you're doing something specialized and that community has settled on something other than C++. E.g. statistical analysis should be done in R or Python, not C++. And yes, having choice is harmful if you have lots of low quality options. It's much better to have a single high quality option. 
Would be nice to have a "Realistic Estimate". I'm pretty sure the different Features have a different likelyhood of getting into c++20. But I understand that such estimates might be next to impossible.
Any function in the std namespace. You are allowed to take the address of some functions in the global namespace
&gt; But what I realized was this: once you had the compact, clean, formulation, that you could just look at and you knew it worked, suddenly, you could start having new conversations. I've been trying to convince people of this for years. I still run into a lot of programmers that are afraid of STL, let alone a fancy new range library, because they're convinced that generic means slower. So, I'm happy to run into someone else who's trying to change people's minds about high level libraries.
I agree with what you say about rule of zero/five/seven etc. &gt; By making features complementary to existing ones, do you not think that the overall complexity of C++ increases vastly? And yet when needed, you'd be cursing the committee for not making features complementary. Most of that work is about making the features work with the C/C++ abstract machine. There are indeed cases where some features of C++ already don't work well with others. eg, I never found a satisfactory way of combining runtime polymorphism with compile time polymorphism. On the one hand, it was good the committee didn't hold off on templates for that reason because having templates is better than not. On the other hand, I really need to have virtual functions and templated functions and classes work better together. In this case, the problem may actually be solved by a combination of modules, concepts and reflection. So even adding features that aren't complementary to existing ones will still increase overall complexity (for the compiler developers) in the future because people ultimately DO expect features to work together. And by not paying attention to that in the beginning, it makes it harder to do it later.
&gt; template&lt;class T&gt; void f(T::R); // Ill-formed (no diagnostic required), attempt to declare a void variable template Great, just what C++ needed: another most-vexing-parse...
It would be nice to have more flexible release dates than just "You didn't make it on time? Better luck in 3 years".
&gt;Qt is one of the big C++ libraries driving C++ FFI in other languages. I know of zero languages that introduced C++ FFI in order to use Qt. Feel free to point any discussion anywhere to that effect. -- Don't make things up to try to make a point. &gt;A lot of the big libraries in other languages are just wrappers around FFI calls to C or C++ anyway. There are wrappers for some C++ libs in some languages -- how you expand that to this statement i have no idea. &gt;E.g. statistical analysis should be done in R or Python, not C++. No. &gt; And yes, having choice is harmful if you have lots of low quality options. It's much better to have a single high quality option. I'm not sure your dismissive attitude towards other's work, or the ease with which you make bigoted statements about the same is more offensive. Pure ignorance.
Thanks a lot! I have bookmarked it and I will read it soon.
IIUC = If I Understand Correctly IIUC?
Hi, is the code/setup for your project available anywhere publicly?
I'm sorry, I didn't know it was a help post.
It was for more of conversation, but I guess it turned into help?
I don't know. Considering, how slowly new c++ standards get adopted, I'm not sure if it would make that much of a difference. Personally, I think the standardization process is the main bottleneck, closely followed by tool adoption.
&gt;&gt;Qt is one of the big C++ libraries driving C++ FFI in other languages. &gt; &gt;I know of zero languages that introduced C++ FFI in order to use Qt. Feel free to point any discussion anywhere to that effect. -- Don't make things up to try to make a point. I'm talking about SIP. &gt; &gt;&gt; And yes, having choice is harmful if you have lots of low quality options. It's much better to have a single high quality option. &gt; &gt;I'm not sure if its your dismissive attitude towards other's work, or the ease with which you make bigoted statements about the same is more offensive. Pure ignorance. How are you offended by me saying I'd rather have a few large, well vetted libraries than lots of small, unvetted ones? I understand disagreeing with it, but I don't see how it could be offensive. 
I'm quite excited for `span` :-) I wish there was some progress on a multi-dimensional array-view too, but I've mentioned that already a few times here :P
I see. It appears that GCC internally stores the pointer and deleter as a tuple so I assume `std::tuple` is implemented to utilize EBO.
So what? Just because the software lives for decades doesn't mean it has to work unchanged with the latest language versions. I think Google / Titus made a very good point that if you want your software to live for a long time, you have to make sure you can evolve it over time - new c++ standards are only one reason amongst many , why your code might have to change. And on the long run, every bit of complexity that gets introduced into the language in order to stay backwards compatible makes maintaining the software that much more difficult. All that being said, from the top of my head, I can only think of a handful of instances, where breaking backwards compatibility would bring a significant benefit and could be done without breaking all code written in the last 5 years.
Question from an aspiring language developer: how do you implement unique_ptr and similar objects without move semantics?
The default recommendation will likely be `namespace rng = std::ranges;`, with some shortened name you like that doesn't collide with another namespace you use.
If it was a beginner reading this article, I'd be left confused by the conflation of the benefits of this cache as a way of reducing in-memory data and of improving runtime performance. The assumption implied by the headline is that the naive implementation would hold all symbol data in memory and that this could cause swapping. The runtime performance benefits, however, come from two sources. One, not doing the opposite, keeping it all on disk, access to which is slow. Two, reducing the search space for the data by keeping recently used symbols in a small cache, leveraging temporal locality. The article doesn't adequately separate these reasons for using a cache. As caching is a widely used technique, I assume that the target audience is beginners. As such, I don't think the article is well written or useful, and is probably just confusing. 
Yes AFAIK
[author of that article] FWIW; I'm working on getting those changes into the release notes; https://gcc.gnu.org/ml/gcc-patches/2018-03/msg00821.html is the current state of the patch
What I meant to say was that I don't like how move semantics work in C++, not that they're inherently bad. I think a sane way to do move semantics is to simply treat them as memcpy + "forgetting" the moved-from object, with no way for the user to write custom code for it. This approach is easy to understand, prevents errors and works for the vast majority of use cases, including unique_ptr. It doesn't work for self-referential objects, but how often do you really need those? I think that's a good trade-off. Admittedly, I haven't implemented move semantics yet so there could be issues with this design that I haven't stumbled across yet. 
We have limited resources and have to prioritize, which also affects things. I think it's impossible that we get nothing from the optimistic column, and it's also impossible that we get everything.
&gt; SNR Huh?
I'm not sure how I feel about strideof, but I suppose it would work. I just think that iteration using pointers should be discouraged anyway, given that it is harder to optimize for than iteration using indices.
Today you wouldn't try it without `typename` anyway; in C++20 you likely would. It's not a "new problem", technically, but it's a problem that people aren't running now and will soon, so...
&gt; What should be wrong with that approach? Nothing, article is just bad. :)
Does this mean you can't have function pointers that use `std` functions? I get why you wouldn't want some to be used, but it seems weird.
Standard committee The words of the bosses cannot be trusted, and they may publish Network on C++30. Either C # or Golang, or even Java, network HTTP do better than C++. The C++ Standard Committee has been disappointing. C++17 's release is an empty delight, without any exciting features. Compiler vendors only care about decaying compatibility, std::filesystem (not experimental) has not yet been supported by any compiler. Members are keen on the metaphysics of grammar and do not care about the building of the standard library. A sad C++ fan
Might be a better fit for /r/devblogs, since it's more a blog about your project than anything specific to C++
Namespaces exist for you to manipulate. No one is telling you to spell the full namespace at every point. And if it was in a std namespace it'd be std2, which I personally find pretty ugly.
Here you go: https://github.com/hef/imgui-in-browser
I'm sorry you feel that way, but what exactly where you expecting?
I now it's easy to get around, but in the end it's annoying and it might not be optimized so you get more indirection.
Okay, there is a substantial amount of FUD in this thread abour dates. We started working on the current reflection effort within the last 2 years. We are saying the feature will likely land in C++23, maybe C++26. That's 5 to 8 years from now - 7 to 10 years since we started working on it. Not 10 to 15 years. Work on other major features started earlier. Reflection is a more recent initiative. Reflection is a hard problem, yes. It's not substantially hard than other problems we are solving, and it's not taking longer than other major features. If anything, it's going faster. These things take time and we have limited resources. So yes, priorities is a factor. No matter what priorities we select, some large part of the community will desire a different set of priorities. We try our best to pick priorities that align with as much of our userbase as possible. There are 5 million C++ users and dozens of different implementations. It's the backbone of most computer platforms. Evolution takes time and a careful hand. 
`span`, because `array_view` wouldn't be shit enough
Consider my pitch-fork raised at you! Lesson to be learned : Never make jokes about names at a c++ committee meeting -____-
This is a bell curve, really. It's extremely unlikely we get everything conservatively. It's extremely unlikely we get everything optimistically.
Eric, can you expand on this a little more - what's the status of the algorithms vs the core concepts. Are they in design review for C++20 in LEWG? Or in wording review for C++20?
c++03!? That is pretty good honestly. I don't know what you expect, but if you are working on serious, impactful software, it won't be modern. That's just life.
If we can land Executors for C++20, we can land Networking.
You are most welcome.
When trying to explain `gsl::span`, it just seems wrong to have to repeat every time : "think of it like a string_view for data". And every time: "I don't know why it isn't called array_view". For me personally, you could've called it `potato_slicer` and I'd still use it all the time ;)
`view` was taken by `string_view`. I think it's good to have the name be short and succint.
There are just two things that I have “against” 03 now, one is that is can be a nightmare to mix it with poorly designed embedded C, specially debugging MACRO and callback hells, the second is just because I don’t want to be supporting old code based the rest of my life, I would rather create new designs or work with talented teams using newer language features as much as possible. Love every version of C++ but they are being updated for a reason and we should try to upgrade as much as possible as long as it makes sense IMHO.
But it is the same concept no? So it is logical (from a less advanced perspective) to use view for other things that operate pretty much the same. Albeit `array_view` is immutable, is that why you felt the need to have a separate name? Immutable "wrappers" are views, mutable "wrappers" are spans?
I deal with "c++" written in 1988 these days. You just can't escape that. However, our new code is in c++11 which is quite refreshing. It's hard to find jobs without some legacy nurturing. I guess try and find a startup, or learn a language like rust or D.
Oops miss-spelled `string_view` there. That answers my point. I still think the distinction is needlessly frivolous, but I understand why one might go down that road.
If this is not optimized to the equivalent code, I would recommend filing a bug report with your vendor. It's trivial to inline, so I would expect it to be zero-overhead. If you really want to be careful, assign the lambda (or function pointer) to a `static constexpr` variable: `static constexpr auto f = +[](int i) { return std::to_string(i); };`
Forgive me if my understanding isn't perfect, but wouldn't the inlining work only if the `std` function itself can be inlined? Assuming it is not possible (because it's in a .dll for example), unless you end up taking the address of the `std` function itself, you can't do anything. But then, it violates the rule saying you can't take their address. Or is it fine because it's the compiler doing it?
want more lispy style rather than ocaml style. (oops i am c++ programmer).
&gt; You can't seriously say "just take a week off and book hotel and flight" when that's out of the means of most of the worlds' population in terms of time and money... and that's just to look at it since actually swaying opinions would require a lot more trips and more politics. The current situation in my opinion restricts decisions to insiders or employees of major companies. To be fair, things have improved with the study groups. One can participate with group discussions and teleconferencing. It still feels elitist to me in the discussions I've joined, but not nearly as much as what the committee used to be. I believe that things are heading in a better direction. Bjarne and Herb keep hammering the point about expanding the number of C++ libraries and making C++ more accessible. It takes a while to turn a freighter, but I think it's slowing happening.
When you're declaring a pack, dots are before the name. When expanding, after. So: typename ... T (declaring pack named T, before) T ... t (expanding types, so after; but also declaring arguments, so before new name) [...args] (declaring pack, so before) 
So even `static_cast&lt;int(*)(int)&gt;(std::toupper)` will be UB? That might break quite a few innocent programs.
If you never care about updating your standard library, it would work if you took the address of function in `std`. When you upgrade, your code may simply fail to compile (or potentially compile but not work). The compiler is absolutely free to take the address of a function in `std`. *You* are not. So the prior lambda should be compiled down to just a function pointer to the function in `std`
Yup!
Your link doesn't work. Try Googling SIP PyQt.
Not UB. Just unspecified. Technically, those innocent programs are already equally "broken" since the standard library is already allowed to do things like add default arguments. The point isn't so much to _change_ the rule as it is to clarify it. The change is about function templates.