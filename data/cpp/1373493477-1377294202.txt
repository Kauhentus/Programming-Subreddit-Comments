I really like it with for loops+iteratos but right now returning the size of a vector from a function = headexplosion.gif. See http://stackoverflow.com/questions/17506908/what-type-of-value-should-it-be-returned-by-getters-that-return-size-of-vector/17506931#17506931
Using auto is really dangerous because it does not automatically add the &amp; if a reference is returned, so you could end up in additional copies if you are not careful.
Well it can't really add &amp; automagically, consider : auto getObject() { return myObject; } If you don't use &amp; explicitly how does it know to return a reference or a copy. 
Disappointed, expected this one: https://twitter.com/postgoodism/status/354249200852140032
Must be a troll, holy shit.
Manual annotations would be necessary. More importantly, even when a linear search can be replaced with a binary search, it isn't always better to do so. For short inputs, the linear search might even be faster. In general, humans should take care of high-level algorithmic optimizations, and compilers should focus on low-level optimizations. They shouldn't try to do each other's jobs.
Meh - people are still using PL/I, COBOL and Fortran 77. There is a lot of existing code that needs to be maintained.
 constexpr decltype(auto) getObject() const { return (myObject); } The parentheses are important because myObject is an id-expression and so decltype won't be a reference.
It's useful to know about the effect of linking order in practice, however: &gt; Now, suppose this is part of a larger project that consists of many &gt; object files and libraries, and somewhere within the project there’s &gt; a library that contains this code: &gt; void memcpy(char* aa, char* bb, char* cc) { &gt; int i; &gt; for (i = 0; i &lt; 100; ++i) { &gt; cc[i] = aa[i] + bb[i]; &gt; } &gt; } Such a program, if it uses the standard library, has undefined behavior, because in that case `memcpy` is a reserved name.
Yep. §17.6.4.3.3 &gt; Each name declared as an object with external linkage in a header is reserved to the implementation to designate that library object with external linkage, both in namespace std and in the global namespace. And earlier: &gt; If a program declares or defines a name in a context where it is reserved, other than as explicitly allowed by this Clause, its behavior is undefined. &gt; Otherwise all programs that define their own library functions would be "undefined behavior", no? Correct, if a program uses any facility from the standard library such that these constraints apply, then it is UB to try to define anything using any reserved names.
I was surprised to learn that the developers who couldn't be convinced to fix some of the bugs were from [PostgreSQL](http://www.postgresql.org/)(§7.2 in the linked draft) and curious about their reasoning, but couldn't (easily) find the bug reports. Anyone know? 
I believe you can find the bug report (or at least a discussion of it) searching for the phrase mentioned in the paper: https://encrypted.google.com/search?hl=en&amp;q=%22its%20optimizer%20isn%27t%20quite%20smart%20enough%20to%20prove%20that%20the%20code%20is%20testing%20for%20an%20overflow%20condition%22
Why are you surprised? Postgres is famous for this sort of thing. The issue with serial is along the same lines of stubbornness for no good reason (serial creates a bigint behind it and throws a completely obscure error once the 32-bit value is passed instead of doing something reasonable).
If I'm going to think about cereal &amp; serialization, I'm thinking about [Cap'n Cru\^H\^H\^HProto](http://kentonv.github.io/capnproto/).
Just installed today. As usual, if you use sudo to install, do not leave Start Qt Creator on the final step enabled or it will completely clobber your .user . pro files. New features like clipboard history and better git rebasing are AWESOME! 
Thanks for the link. I'd use msgpack for any network targetted serialization, but this project (Cap'n...) sounds good for IPC systems.
Glad to see more people less concerned about maintain compatiblity with old compilers. This would be a big issue for C++11 adoption and the future of the language, I think.
These optimizers have it exactly backwards: just because the users uses `s-&gt;f` before testing for null *does not imply* that `s` cannot be null. It means that the programmer made a mistake. Instead of "optimizing" the sanity check code away, it should flag the mistake.
yeah. just did that with Qt5.1 too...
Fantastic IDE, even for non-QT projects!
Ah thanks.
Agree, forget about bloated VS2012...
`unique_ptr` doesn't do that. Yes, its is a bug in the version without `unique_ptr`, but that actually strengthens the main point. I might add a comment mentioning it, though, just in case someone gets any ideas.
&gt; Here's some code, which probably is the fastest way of understanding what Boost.Mixin is about: I.. disagree. That example code left me confused if anything. It made no sense to me and was really really bad. `object` wasn't defined anywhere, it had no type. Not to mention it used `new`. It just felt really bad to me and I still have no idea what this library is about. I hope that when it goes into consideration into actual boost that they polish it a lot more. According to the page it's in it isn't even up for review (let alone submitted yet) so I find it weird that they're using boost's name on it. &gt; This library is not an official part of the Boost libraries collection. It will be submitted for review somewhere in late 2013.
It looks a bit confusing now, but it is still in development. I guess later it will become more strong. Actually, anybody knows some alternative for the run-time mixin's?
Looking closer at the docs, of course you have to add a lot to make this work. This library depends on many macros and some background magic I guess. But, if you need something like this, that's really cool. For me this is currently beta stage, boost review is alpha, and if accepted one should consider using it. 
&gt;unique_ptr doesn't do that. Ha indeed, which is pretty strange considering default_deleter already special cases nullptr.
"Until VC++ gets more complete C++11 support, it is not supported" Shame as it looks interesting. So frustrating being stuck using Visual Studio.
I personally use auto for lambdas and iterators, because you know, getting the iterator type is a greater evil than auto :) I don't write that much generic code, and when I do it's very basic and simple so I can't speak of the usefulness of auto in that context.
Now it makes sense. So boost.mixin is a library to create objects with random interfaces.
This is looking stellar - already have one of our firmware designers using it, and we'll all probably going to move it this fall, and just give up on VS2013 before it even comes out.
I think mixin may be a poor choice of name for this. It's not *wrong*, but in most languages I've used mixins are about adding functionality to classes rather than to specific objects, and so this does something quite different from what I would expect a library named "boost.mixin" to do. What it does do is a very interesting idea, though. The concept seems better than the standard ECS approach, and the syntax for defining mixins and messages isn't actually all that bad. "Reflection. Create objects with mixins by string. Call messages by string." excites me as well, if the author manages to make it work without increasing the amount of boilerplate involved in defining messages. I'm dubious that this all could perform reasonably well, but I'll hold off judgment on that until it's not in such an early state.
Previous discussion: http://www.reddit.com/r/cpp/comments/1i3wr3/cereal_a_c11_library_for_serialization/
How much of that do you get with VC++ 13? (Variadic templates are in that for example)
Well, damn! I was sure that wasn't gonna be true, but lo and behold it is! Good info, appreciated. 
It's easier to answer the things we don't get in the projected RTM (going off of the roadmap) for 2013 that we currently use: constexpr and expression SFINAE. These can both be worked around however, they just mean the code will get much more verbose.
maybe "aspect" would be a good name
Just guessing but this probably wont be portable to linux... right?
Whoop!
stroustrup always looks like how I imagine an older version of those finnish demoscene coders look.
https://casablanca.codeplex.com/wikipage?title=Linux%20Features
std::function
Ignore the article and look at [this talk by Herb Sutter](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/C-11-VC-11-and-Beyond), 37min in. 
Casablanca looks very promising. An even more ambitious goal would be to create something a servlet container like [Tomcat](http://en.wikipedia.org/wiki/Apache_Tomcat)
Rcpp and RInside are awesome, there are a few gotchas but other than that no complaints
I concur. I've been using Rcpp with RStudio on Windows, everything (pretty much) works seamlessly.
http://ideone.com/PhX2av (should be readable offline).
Thanks :-) 
Variadic templates are not in VS2012. There is a CTP that adds support for them, but everyone I know that uses VS2012 just stays away from it because it is really really buggy. It's not fit for serious code.
Sorry mate, that'll only work for COD... You do realize that this is /r/cpp right? The code you just wrote is C#. Maybe you can try /r/csharp .
Thank you very much. I will go to them. 
Care to elaborate on that story?
So, you died?
Yes
People were like "hey rapping programmer, we need to be able to use this stuff offline." I was like "oh man. im fucked. i dont want to do all this work." Then they were like "make it so, motherfucker." okay.jpg I thought to myself "what if i could just simulate the remote database locally caching as the user uses the app?" I made a IDatabase interface. I made a NetworkDatabase inheriting from IDatabase. I changed everything to use IDatabase instead. Then I added a InMemoryDatabase that had a couple of [multi_index&lt;fjkakdsfjaksdjfkasjfkasdjfjkasdf,&lt; &lt; &gt;&lt; &gt;&lt; &lt;&gt; &lt;&gt;&lt; &gt;&lt;&gt;&gt;](http://i.imgur.com/5F2rCDo.png) as a member. I modified NetworkDatabase to sync to a InMemoryDatabase. I occasionally wrote out the InMemoryDatabase. I also added the ability to switch the app's db to the InMemoryDatabase (duh). It took me 5 hours. That was 3 years ago. 0 bugs. I then went home and had glorious sex.
I was gonna say "the only situation in which virtual inheritance is useful is mixins". Pleasantly surprised. Good article.
You get that with any language-feature though: If there is one way to use them wrong, people will insist, that the feature was designed by the devil himself and it should be banned from all languages. The fact that these features solve some big problems with ease and are not designed for the use-cases where they are problematic will be ignored. (For other examples of this phenomenon see exceptions, goto, templates, value-types, the preprocessor (yes I agree that this one really sucks most of the time, but every now and then it solves some problems in great ways)…).
Meme account &lt;_&lt;
Because preprocessors are dumb plain text hacks that basically have no relation to the language itself. We have things like templates that are the 'proper' way to do things, currently they are limited but with things like '[static if](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Static-If-I-Had-a-Hammer)' we could probably see an end to preprocessor stuff totally. Although I'm not sure about passing #defines on the CLI (possibly done instead via the build system and a .h.in file, but that's just a different type of preprocessor) and header guards (if static if could set some kind of a 'global' value then this could work). If you wanted to you could write your own preprocessor in python or whatever and just dump it into your build system (if you are really pedantic about the python requirement, then write it in C++ itself since you can garentee you will have a system setup to use that).
Hm, true. It is what QT does as well if I'm not mistaken. Would be nice if templates could displace all macros so the errors would be a bit more sane. 
I believe because of ambiguous base classes or something. I can't remember the exact issue I had but I had to solve it once.
amigaharry said : "Comes with MS certified NSA backdoor." It is open source.
Good to know - we'll target VS2013 support then. Either way it looks like our next release will have VS support in it.
&gt;↑ That should have been added 15 years ago! It's a shame that the commitee didn't do it then, a huge shame that they didn't do it 2011 and a major-fuckup that it won't be in C++14. What does it matter? Why do you need committee blessing to use something universally supported?
The point is to allow calls between sibling classes in the hierarchy: #include &lt;iostream&gt; #include &lt;ostream&gt; using namespace std; class I { public: virtual ~I() {} virtual void g() = 0; }; class Mixin : public virtual I { public: void g() { cout &lt;&lt; "g" &lt;&lt; endl; } }; class Main : public virtual I { public: void f() { g(); } }; class C : public Main, public Mixin {}; int main() { C c; c.f(); } `Mixin` magically provides the interface implementation for `Main`, even though neither class knows about the other. Each depends only the interface. A similar technique: you can build up an implementation of a fat interface piecemeal from small classes, each implementing part: #include &lt;iostream&gt; #include &lt;ostream&gt; using namespace std; class I { public: virtual ~I() {} virtual void f() = 0; virtual void g() = 0; }; class A : public virtual I { public: void f() { cout &lt;&lt; "f" &lt;&lt; endl; } }; class B : public virtual I { public: void g() { cout &lt;&lt; "g" &lt;&lt; endl; } }; class C : public A, public B { }; int main() { C c; c.f(); c.g(); } Not sure if I understood the author properly when he says a mixin usually only has pure virtual functions. I couldn't find a legal copy of the book he references.
Sometimes one might want to do calculations that involve negative values. ;-) But I agree on the part that signed integers are often more of a problem then unsigned ones. 
Because ‘universally adopted’ does not imply that it is C++. While using such stuff is not as bad as relying on undefined behaviour (like those stupid people who belive that INT_MAX+1 == INT_MIN and cry out loud, when the optimizer destroys these believes) but I definitly wouldn't call it good style. I really like, how early versions of GCC handled pragmas. ;-)
In my personal experience, the reason for signed size types is laziness (including my own in the past.)
It's not universally supported. GCC and MSVC interpret #pragma once differently, and I'm sure Intel and clang probably have subtle differences as well. Yes for 99% of cases it will work but in the rare case when you include a file via a symbolic link or over NFS using two different paths or you have a build system/routine that exposes about these subtle differences then it makes your life a living nightmare. The committee could have standardized #once to avoid all these issues, for example by requiring that it applies strictly translation units whose tokens are identical.
They were hoping for something like [this](http://xkcd.com/1168/)
Because computer science derives from mathematics. And in mathematics, integers can go negative. So there was need to find a way to represent those numbers. Default mathematical behaviors transported onto binary computing systems.
Yep, definitely this. Even if the only valid values are unsigned, you may still need negative numbers for clamping. Its hard to clamp to zero when your unsigned 32 bit int underflows to 0xffffffff
Good to hear about possible VS2013 support.
This is technically why you would use them but I think real world "most programmers suck" trumps this rationale in practice. Many programmers, even decent ones, will constantly make edge case errors. Integer underflow by stupid programming is more likely in most real-world uses than that you're going to have an array large enough to warrant that 32nd bit.
I don't mean to be rude, but that was a pretty useless blog entry. &gt; Author: "This is the wrong way to do recursive specialization" &gt; &gt;Me: "Oh, interesting. I use this exact pattern. What's the correct way?" &gt;Author: "I will write about it in a few days when you forgot about the issue already." &gt;Me: "..." Seriously, if you have a topic to write about, please take the time to write a complete article. Don't post teasers like this that only leave people wondering what your point is.
Agres, downvote
There are no useful C++ certifications (comedy option: [CPPGM](http://www.cppgm.org/)). In general certifications are considered a complete joke for software development. There's a handful that are useful for getting soul-crushingly boring jobs at large enterprises, but that's about it.
&gt; In general certifications are considered a complete joke for software development. This. At any company where you would actually want to work they won't care about any software development certifications you possess. They will care a lot about you being able to actually produce something. Your best bet is to write something cool and stick it on github/bitbucket/whatever. Bonus points for actually handling bug reports and providing documentation. Or show you work well with others by learning their code and joining their development team. Show you can perform and don't fuck up the interview. Job is yours.
Any place that requires a certificate is not a place you want to work. Trust me.
I suppose that in practical terms (as opposed to a piece of paper ;]) getting a library accepted by Boost can be thought of as a way to *certify* your C++ level: http://www.boost.org/development/submissions.html http://www.posscon.org/wp-content/uploads/2012/04/Welcome-to-Boost.pdf It's even possible to document the contributions in an open format: http://www.ohloh.net/p/boost/contributors Successful ISO C++ proposal may be even better: http://isocpp.org/std/submit-a-proposal HTH &amp; Good Luck! :-)
While true for software devs the most idiotic certs can be found in computer security: [Certified Ethical Hacker](https://en.wikipedia.org/wiki/Certified_Ethical_Hacker) That's the epitome of idiocy.
In the entire realm of computer science only sys-admins and network-admins really use any kind of certifications. Your best bet is to spend some time contributing to open source stuff. Doesn't have to be anything major.
signed overflow results in undefined behavior, which allows for certain optimizations and better performing code in some cases. This has nothing to do with signed vs. unsigned per se, however, just how C++ arithmetic operations are specified. - [What Every C Programmer Should Know About Undefined Behavior Part 1](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html) - [What Every C Programmer Should Know About Undefined Behavior Part 2](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_14.html) - [What Every C Programmer Should Know About Undefined Behavior Part 3](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_21.html)
I work in the industry and don't know a single person with a c++ relevant certification. The best way to show you can do something is to do it, then show it (write some hobby games - don't have to be complete, just demonstrate that you understand some game programming concepts). Include these in your resume and bring them with you to your interviews. Most junior programmers don't even do this. IMO, this is a lot better than a certificate as it shows self-motivation and a drive to learn. 
I was thinking of doing that. I actually am making a small silly game, for fun, but stoped, toughting it was a bad idea. Good to know it isnt! 
Most places I have worked actually consider certifications to be a red flag, unless of course when the candidate went to school and worked in another country where they may be more meaningful (in which case we just ignore the certs)
It's never a bad idea to learn new stuff :)
"Technically correct" is the best kind of correct.
I would consider a certification a minor negative on a CV to be honest. I don't want to work with the sort of person who thought it would be a good idea to get one. Better option: small open source project in a language would be a big positive.
Yikes. That's a terrible idea. What if the prospective employer actually looked at the source code for your boost library? Although I use boost frequently, I couldn't name a single boost library with readable, clean source. I also couldn't name a single boost library with good performance, except (hopefully) for threading/atomic. Maybe you could link to some clean, readable boost code as a counter example. Good luck :-)
Could you please elaborate?
solid advice! But its just that , at this moment, c++ seemed somewhat interesting, considering it is used in rather broad spectrum. I have 3 years of experience in Delphi(pascal) programming, and want to get out of it.
Interesting point of view! I think I agree the source code is often not "textbook clean", however, that's often for practical, pragmatic reasons (as opposed to a lack of competence), like keeping backward compatibility with the existing compilers. Given that the alternative is dropping support, I'd think that from the business point of view (where using the latest toolchain can unfortunately be a luxury more often than both of us may probably like) it's better to have a developer being able to get this done instead? I'd say that, e.g., Boost.Algorithm is pretty readable, given these constraints. Not sure I agree on performance -- as compared to what? The only lib I can think of is Boost.uBLAS (where I personally prefer Eigen) -- which explicitly states that its first goal is stability/accuracy (so I guess it's just a matter of trade-offs), but Boost.Asio, Boost.Chrono, or Boost.Multiprecision aren't exactly known for performance problems. In fact, Boost.Spirit regularly outperforms C standard library functions: - atoi: http://cppsoup.wordpress.com/2010/01/08/boost-spirit-v2-x-versus-cs-atoi/ - strtod, fscanf: http://stackoverflow.com/questions/17465061/how-to-parse-space-separated-floats-in-c-quickly/17479702#17479702 Boost.Regex significantly outperforms a certain well-known standard library implementation of C++11's &lt;regex&gt;. Boost.Lockfree is specifically targeting high-performance use cases -- http://www.boost.org/libs/lockfree/ -- I'd be interested in hearing whether there are similar but better performing C++ libraries?
There are a few certs that my boss views as relevent, but it's an industy niche thing: * Functional Safety Engineer Certification (IEC 61508 &amp; related standards, not directly CS relavent) * [ARM Accredited Engineer cert.](http://www.arm.com/support/arm-accredited-engineer/index.php) If you're going to work in embedded or compiler/debugger/toolchain having certs on the various processor platforms will help a bit, but it's not relevant to someone doing user application development.
&gt; I agree the source code is often not "textbook clean", however, that's often for practical, pragmatic reasons like keeping backward compatibility with the existing compilers. I mostly agree. I still wouldn't care to show off that code. &gt; Not sure I agree on performance -- as compared to what? Some other library, or roll your own. &gt; I'd be interested in hearing whether there are similar but better performing C++ libraries? * Boost signals is infamously bloated and slow. I typically see around 15 calls in the call stack between caller and callee. I've never been able to usefully debug into that code, or inspect to see what's hooked up to a signal. * lexical cast is dog slow when converting between floating point numbers and strings, as compared to C functions. As I recall, it's a factor of 3 slower. * BOOST_FOREACH is notably slower than a simple for loop, from my testing. * Pool is so slow that it serves no useful purpose as far as I can tell. It's outperformed by general purpose allocators in most all situations, and Pool compares poorly to a dead simple roll-your-own implementation in the remaining situations. * PropertyTree is very slow from my testing. I think it's even slower than similar functionality in C#. * Regex uses a poor algorithm compared to Perl/grep which can have exponentially slower performance. I've seen very small example searches where grep could complete it in a tiny fraction of a second while Boost Regex would never complete. * Serialization was shockingly slow in my experience. I rewrote an equivalent library last year which improved serialization performance by an order of magnitude. It took me 3 days to rewrite, mostly because I had to support several compilers. Those are the libraries I can fully speak to. Based on that, I have a tainted expectation for other Boost libraries including the ones that are supposed to be quick. I wouldn't trust anything in Boost to be quick without evidence.
The good thing about having C++ on the top of your resume is that the skills necessary to be good at C++ means you are 99% of the way there in almost any other language already. It is better than seeing Javascript and never considering that person for a non-scripting language role.
A great way to start building proficiency is to just start learning the mistakes by doing lots and lots of programming on your own. Make some things for fun. Never finish anything... It always seems like crap after a few months.. That is how you know you are learning. 
What makes him sad is probably the fact that * you should use an unsigned type for iterating, e.g. std::size_t * you should use std::array, or at least std::vector instead * operator!= is used while working with iterators, on intergers it does not document intend * you should use std::for_each() or, even better, range-based for loops if you do not need the index and have to iterate over the whole container
Knowing both languages pretty well, the idea is good, but please use php as an example, or VB or whatever. But not my precious Javascript :) Javascript is the only mainstream language that has an more powerful and elegant (as in less syntax) inheritance system as c++. Mastering it is by far not simpler as mastering c++. That prototypal thing in a scheme like language is really nifty. 
Best certification would be the history of your github contributions. This is highly effective at showing others your portfolio / skills. Sign up for a github account, and start participating in some interesting open source projects. Looking up bugs and fixing them.
Is it? Because security guys often need to testify in legal environments, and judges and lawyers love that shit.
I'm not harking on JS at all, I'm actively trying to move into QML apps right now with Qt 5.1, and writing them entirely in QML / JS and running them over qmlscene is amazing. I'm just saying a language with limited object orientation, a few basic types, a standard library of comparable scale to C++, and a simple access and inheritance model doesn't demonstrate an ability to move around a lot.
Again...a place and person you don't want to work for.
No don't stop. These silly games, while not what your future employer may pay you to do, are a small microcosm of what they WILL pay you to do. If nothing else, its something you can talk about during an interview. I made what may possibly be the dumbest game of all time on an even dumber platform... I'm confident that experience and what I was able to mention about it during my interview are what got me the job.
This is just me playing around with some fun math-y concepts from functional programming. I make no claims about the usefulness of this code in the so-called "real world".
No certs. Just do it.
Do you serve web content? Do you use Wt? Do you like it? 
Cissp is prob a better certification for those anyway.
What's with std::array?
Been listening to a few developer podcasts lately (good way to pass time i might add) and a fair few strongly suggest OSS involvement. Prepare to use a github account as an equivalent to a graphic designers portfolio. Also check out SO and some other stack change portals. Most of all, learn by doing and keeping your proud works public so somebody checking out a résumé can actually see what it is they're hiring you to do.
Very good advice, though I would amend/clarify it slightly: don't forget to learn languages from other paradigms! For example: learn Haskell, OCaml, or similar to get a taste for functional programming. You will become a better programmer for it, whether you like the languages or not. Then, learn a lisp of your choosing. Perhaps not a new paradigm as such, but still quite different, and I feel everyone should have at least tried a lisp. Finally, try at least one of the arguably more esoteric paradigms. Perhaps concatenative programming as in Forth, or logical programming as in Prolog. Or both. Doing the above, you will learn *much* more and a lot faster than just sticking with the "normal" languages.
&gt; operator!= is used while working with iterators, on intergers it does not document intend This is the comments sections of /r/cpp and my original comment applies to C and C++. 
It's easy to roll your own `my::array` if you don't have access to C++11, that and boost provides a version too. I was personally was never going to nitpick the != point, but since it's been brought up I definitely prefer != because it's consistent across all iterators and indices. Rather than using &lt; for some and != for others. &gt; More C++11 / vendor specific `for_each` is not vendor specific it's std. Same for range for but that is c++11. That said, I know you employer may stipulate these things, but C++14 is around the corner we really need to stop using C++98 and move on. 
It should really have been *Learn to use array in C with simple example*.
Your usage of "call" is incorrect.
&gt; Yeah, but without lambdas (C++11) you are forced to separate the code, etc. etc. I have usually found that actually improves the code quality, writing element wise functions often makes things clearer. Not always though, lambda are useful there. It's not as though I think the for() loop is totally redundant or anything like that. It still has it's place. &gt; Its more the customers who pay a ton of money for our libraries and haven't yet moved (or finished moving) to the latest and greatest compilers. We just stopped supporting VC6 a few years ago. Imagine what that must be like (hint: no complete C++98 support). I know, I know, as a programmer these kind of decisions are usually out of our hands, but I do like Herb Sutters take on this. If you want C++98 the customer will have to pay more (or discount C++11). Then you'll find out how hard it actually was to upgrade their software stack.
I think they fixed performance problems in lexical_cast http://www.boost.org/doc/libs/1_54_0/doc/html/boost_lexical_cast/performance.html
Nike?
ah, nice.
Forgive me if this is a dumb question, but would using auto i assign a properly signed type to the index that matches the bound's signed-ness in a for loop?
Good find. The problem in my mind is that it took them *years* to make this fix. Performance just isn't a priority for the Boost project.
Is it possible to force GCC or clang to not use certain instructions, such as fmadd?
Make it Waaaaaay simpler. Create an object, load the code into it, run it, get results. CLThing *thing=new CLThing(); thing-&gt;setStreamCount(1000); thing-&gt;setCLCode('int main()...'); thing-&gt;run(); EDIT: OK I guess my code was away from my point. My complaint about OpenCL is that it typically requires 8 billion lines just to do Hello World. I love C++ but hate how some people seem determined to use every obscure feature as if they are trying to show off their esoteric C++ knowledge instead of keeping it simple. 
Okay, someone argue why we shouldn't support the IEEE-floating-point-is-mysticism position.
One of those features that beginners were always surprised to find that it didn't always work that way.
As someone in the middle of his first real C++ project, I was surprised this wasn't a thing already and opened the article to see what was what and see how I might be able to use it. I couldn't figure out what all the fuss was about, I'd been using this exact same pattern for weeks now... oh wait I'm using VC++ 13. Oops. Is this part of C++11 or is this a compiler-specific thing?
It's part of C++11, and VC was a little late to the party in getting it working. Make a mental note that you might not be able to do this "in the real world" for a while, as shops are often quite a few years behind the cutting edge for adopting the new version of a compiler.
C++ is slowly turning into C# and I love it.
I know some of the words in that article.
What do you think is wrong with it? ^(Genuinely curious)
For starters, he's going for the heap. Why is he going for the heap? He doesn't seem to be passing the pointer anywhere that the callee would need a persistent reference to the object, and he's not using polymorphism. So the first thing wrong with it is: The overhead of an unnecessary heap allocation. Second, where does this block of memory get freed? What if run -- or one of the other functions -- throws? Third, why is he going for the heap and not using a unique or shared pointer (sort of follows from #2).
Use [kcachegrind](http://kcachegrind.sourceforge.net/html/Shot3.html) and weep. It uses the valgrind output to show you the time spent in each function/method. You can optimize every little detail and speed up your program!
To add more criticism of this piece of code: * [Raw pointers should never own memory](http://klmr.me/slides/modern-cpp/) – and in fact, using a pointer is useless. Just use an automatic object. * Why use setters instead of the constructor? In fact, [getters and setters are an anti-pattern](http://www.adam-bien.com/roller/abien/entry/encapsulation_violation_with_getters_and) ([yes!](http://www.idinews.com/quasiClass.pdf)). * Having classes with only a single method – `run` – [is another anti-pattern](http://pyvideo.org/video/880/stop-writing-classes). Just use a function. Taken together, this leaves us with: clthing_run(stream_count, the_code); One line instead of four, simpler code, no memory leaks.
edit: Argh godamn cache!!! 
I am confused as to how you came to that conclusion? especially with the quote.
Because it’s godawful code.
Well I would say all three arguments depend on the design on CLThing which isn't defined because it seems to be a basic example in response to OP. The example given is basically psuedocode that uses correct syntax.
&gt; all three arguments depend on the design on CLThing No, they fundamentally don’t. Regardless of the *internal* design of `CLThing`, those points stand. In fact, it’s well established that modern C++ doesn’t require manual memory management at all, and, since it’s error-prone and offers no advantages, [it should be avoided by all means](http://isocpp.org/blog/2013/04/trip-report-iso-c-spring-2013-meeting) (relevant quote from that page: “now we can teach C++ developers to mostly never use explicit `new` again” – and while the post is about C++14, the same is true even today).
[This](http://invisiblegdev.blogspot.com/2011/04/branch-prediction-lhs-and-casting-with.html) (or at least the articles it links to) may explain some of them. [This [PDF]](http://www.agner.org/optimize/optimizing_cpp.pdf) is even more thorough; HTH :-)
The PDF looks like an awesome resource. Thanks a bunch!
Do they do it this way so that they can return an error code from the method?
 Your cousins refer to you as "the cool cousin". 
Has anything important happened to C++ in the meantime? :-) ^(Joking. C++11 feels like a new language, ^again.) 
As a C++ dev of around 12 years experience (and pretty good in C# &amp; Python with some experience in Perl &amp; Java and long forgotten JavaScript) who has interviewed former members of the ISO C++ committee and contributors to Boost, I have definitely reviewed their work. Definitely gives a greater insight to their abilities than the short 45 minutes I had to make a snap judgement in an interview.
I suppose you could always run-time monkey patch the function.
*"While not as widely-used as GCC's libstdc++ or even LLVM's libc++ for a C++ standard library"* Are they saying that many more people use LLVMs libc++ than GCCs? I'm having a hard time believing that, considering llvm is still fairly new. 
&gt;getters and setters are an anti-pattern I think it depends on what was the point of the getters and setters. If you are using them to do additional arithmetic, or caching expensive values, then no, they aren't an anti-pattern... though they are commonly misused. I think the biggest reason that people tell themselves that they need getters and setters is because they *might* need them in the future. You don't want to change the interface, so you start with getters and setters so that the interface isn't subject to changes. D actually deals with this the [best](http://dlang.org/property.html). Allowing you to use change an internal implementation of a getter and setter without changing the external interface. ( using CLThing.streamCount = 1000 calls the function CLThing.setStreamCount(1000) if you have defined the property)
Hey STL, when you refer to the standard library, its just "the standard library", not "the STL". freenode##c++ thanks you :) 
Um. Why? It pretty clearly says that they are ending support of their C++ standard library. Not really sure what could have been said to make it more clear. In fact what you quoted, and the title contain the same information...
Valgrind is a fantastic suite, but be aware of some of the drawbacks. In order to perform its profiling, it [synchronizes](http://valgrind.org/docs/manual/manual-core.html#manual-core.pthreads_perf_sched) your threads. This means that the behavior exhibited by your program may differ than during normal running. OProfile is great for whole system profiling. This is particularly useful when you want to know where your whole computer is spending its time. For example, if your program is IO bound, but you absolutely must improve performance, you use OProfile to determine if you can alter your IO access patterns to improve performance or even work with the kernel driver itself. I'm an embedded engineer, this kind of thing happens a lot. gprof, the profiler that comes along with the GNU toolchain is okay, but I find that it is at times either misleading or fails to really pinpoint the cause. I sometimes use gcov, the GNU code coverage tool, to get a count of how many times each line of code has been executed.
&gt;Effective use of C++ requires only the knowledge of a couple of its essential features. Heh.
Yes. Next question.
Well then they better get maintaining and extending.
You'll also find out that the program starts much faster when there's no debugger attached (i.e. you press CTRL-F5).
Apache is confused with httpd.
&gt; "We want someone else to maintain it for us" just makes PathScale sound like freeloaders. Typical enterprise attitude I would say.
I don't think so. And even then the std:: like way to do that is: std::tie(plats, err)=cl::Platform::get();
Bergstroms remarks are possibly the most idiotic I've seen in years and as such does not put PathScale in a good light. Instead of stepping up to the plate they demand that somebody do the work for them. 
I would read this article but it has so many double underlines adverts that pop up when I move my cursor that I lost patience accidentally activating them before I even read past the first paragraph.
[Relevant xkcd](http://xkcd.com/1172/) (or source of the reference).
Exactly. "Apache" in common IT use is ambiguous, but usually refers to httpd, not the foundation as a whole.
Genuine question: Who used this standard library, and why ?
Surely he said that the wrong way, but I'm giving him a big benefit of the doubt. Based on context, it would seem that he would help if they stay with the Apache clib, but not if they moved away. Maybe his communication skills are just weak? He wouldn't be the first software engineer with that problem.
Until you get the first error msg, that is.
Only if you have never touched have. If you have. Apache is everywhere
&gt;Just choose what looks better and accept we live in an imperfect world. Naturalistic fallacy. The correct response to that imperfection would be to try and improve it instead of concluding with a thought-terminating cliché. In my own C++ code I have precious little inheritance (generic programming is just so much more powerful), so I'm side-stepping the problem somewhat. For the inheritance I *do* have I omit the tests as they are somewhat a second-class citizen for me: They are only means to an end (a working application), so it doesn't make sense to me to complicate the application's code just for them. 
I doubt that's possible as from what I know on modern systems the code in memory is marked read-only. But maybe you could link against a custom version of the C standard library that redirects file access to the mock framework. It would be very low-level, but it should still be simpler than to make sure the real required files are at the real required locations. Of course that's only for file access, but you could equally link to a custom OpenGL library to test your rendering code, a custom sound library for your sound code etc. (coming from a game developer perspective here). And because I could not resist: In Soviet Russia, C++ mocks you.
Overall a nice introducion to test-driven development and refactoring but some of the style seems a little weird. Particularly using a C style array of structs with silly *sizeof* arithmetic to get the length smells to me. Surely using a map along with brace initialisation and a range-based for loop would make things much nicer.
I don't see any advantage of using a map here. It's just different. What would be better ? You could expand it a runtime. But you don't need to. sizeof isn't silly, it works perfectly.
Thanks to C++'s C roots, you can get really evil with your objects (casting to and from `void*` or using `reinterpret_cast` (see [#3 here](http://www.gotw.ca/gotw/076.htm) with warnings turned off), but in the end, it's not worth it.
Warning: 438 slides
Says it on the bottom right of the slideshow.
I am not sure who this is targetted at. The TDD part is good but seems to fit a medium level programmer, on the other hand the code that shows that 3 ifs that do the same can be changed into a while loop is annoying.
I guess one could use seams, http://mockator.com/projects/mockator/wiki/Refactoring_Towards_Seams, like http://mockator.com/projects/mockator/wiki/Intercept_Functions (it does seem it's pretty limited, though). But, there's more fun, we can even do that at link time: http://mockator.com/projects/mockator/wiki/Link_Seams // No, I wouldn't necessarily describe any of this as particularly clean or elegant :D More info: * http://www.scandevconf.se/db/presentation%281%29.pdf * http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6228979 // If this is behind a paywall, there's also an article in the Overload Journal: http://accu.org/var/uploads/journals/overload108.pdf#page=29
This is why I don't like TDD. Anyone who's true to themselves will realize the tests had very little to do with writing the code.
Fails after slide 247 in both FF and IE. :( Edit: Appears that some slides are just not working.
It is only about the libraries. Microsoft was quite clear on their BUILD 2013 session that they won't support C99 standard and the main native language remains C++. See Herb Sutter's session, http://channel9.msdn.com/Events/Build/2013/2-306 Slide number 24.
C++11 references the C99 libraries. To get a (C++11) standard compliant compiler MS needs to implement all referenced C99 stuff (see Stephan T. Lavavej's comment in the linked post).
External linkage means a symbol for that object is exposed in the object file created when compiling that compilation unit. By default functions, types and non-const globals are extern, but const global variables aren't. If you happen to have two extern symbols with the same name, you will get linker errors or worse, silent failures and really confusing behaviour. External linkage of types was a little confusing for me, since in C declaring structs doesn't create any symbols, so I looked it up. AFAIK, in C++ for simple data like in this article it has the same behaviour, but if you have a class with virtual functions (and maybe inheritance?), then the type declaration will actually cause the compiler to emit a symbol containing that information, causing the same issues if you have a duplicate.
ah, thanks a ton for the great explanation.
check stb_image for a bare implementation.
Pixel data aren't stored "directly" in jpeg files, you'll need to decode it/reconstruct it which is a pretty involved procedure, which is why most people use a library. https://en.wikipedia.org/wiki/Jpeg
Honestly? Get the [standard](http://www.jpeg.org/jpeg/index.html) and read it. Alternatively, go to the [libjpg](http://www.ijg.org/) site and click on files. Download the source code and start looking through it. If you're lucky they have some documentation that explains how it works. From my (small) understanding, jpeg compresses the image data by chunking it into square regions and then approximating each square region using some algorithm (2d dct). There isn't a magic or easy way to get at the data in a file (unless you use a library) - you have to decompress using the inverse of the approximation. Edit: changed fft to dct
I really appreciate making a point through dialogue then say ... a blog post. This was fun to flip through.
This is a school assignment, we are given a template of a program to complete. We have to create basic functions, like resampling the image to a smaller size, adding random noise, things like that. I cannot use any non-standard windows libraries, as they won't necessarily be on the computers used to test the program. From my research online, this task does seems extraordinarily complex without use of libraries (especially when the focus of the assignment is NOT to learn the JPEG standards). I can supply some of the template code if anyone would be willing to take a look to maybe get an idea of how to approach? 
It needs to be JPG format? The most simple graphic format is the BMP, it's relatively easy to access raw pixel data without a library. If you use JPG or PNG or something like that without a library, your assignment will be 2% of the work, and the other 98% will be the access to raw pixel data.
The practice files he has provided are all jpg. However, in the assignment file he says we can use any file type. (I heard png is more straightforward as well) I am more than willing to abandon the JPG format to be able to complete the task using BMP
PNG is more straightforward, but it's compacted. So, without libraries, you'd need to reimplement the compaction algortithm. I would go with BMP. The wikipedia article has a lot of information on this format. http://en.wikipedia.org/wiki/BMP_file_format
As time goes forward, they may find some attributes make sense to be standard.
Maybe in some cases, but definitely not for all (see e.g. the halting problem).
The compiler does similar checks in other languages and it really doesn't have to solve the halting problem for that. For all practical purposes it is enough for the compiler to assume that any conditional that can't be checked at compile time may evaluate to any value so it can perform a simple flow analysis to see if the end of the function is reachable.
Does this mean that when the code is visible, the compiler can determine with 100% accuracy whether a function might end (assuming all possible user input is fair game)?
No, as it would need to solve the halting problem for that. I mean a very limited analysis where the compiler sometimes incorrectly reports that the function can return even if it does not. Eg. it is accectable to report that the following code terminates because the test x==0 involves a non-constant variable: void func() { int x=0; while(x==0) {} } If it is really necessary to write code that might terminate according to this limited analysis then the programmer can of course always wrap the code in a while(true)-loop to ensure the compiler that the code will not halt.
That's what I thought (but it's always good to check :)). False positives (i.e. reporting that a function can return even when it can't) aren't that expensive, though. A false negative however would likely crash the program. But I don't think simple flow analysis can give a false negative.
Suppose the function being optimized calls some other function `foo()`. `foo()` is in another translation unit, completely opaque to the optimizer. `foo()` calls `exit()` or `_Exit()`. This makes the function a no-return function, but it's completely impossible for the compiler to know that, short of LTCG/LTO/WPO type things. 
Why do you think this is pointless? Are you referring to the concept or the new syntax? The concept is useful for several reasons. It's a way to avoid spurious warnings, for example: char *p; if(cond1) { if(cond2) { p = ...; } else { fatal_error(...); } } else { p = ...; } // use *p At the point marked by the comment, `p` is guaranteed to be initialized, assuming that `fatal_error()` terminates the program. But the compiler has no way of knowing that, so it's probably going to warn that `p` might be used uninitialized, which is a false positive. False positive warnings can be detrimental, because it adds noise to the compilation output which can obscure true positives. Or it can lead to someone "helpfully" disabling that warning to clean up the build output, but then they miss out on real bugs that the warning would have caught. If we can inform the compiler that `fatal_error()` doesn't return, it won't warn. The code could be reworked in a number of ways to avoid the problem, but it often comes at the cost of being much uglier. It can also result in slightly better optimizations, such as the example in the link of being able to eliminate dead code. If your objection is not the to semantics but the syntax, then I don't see how you can maintain that position. The current situation is that these features already exist, but wrapped up in compiler vendor extensions like `__attribute__((noreturn))` and `__declspec(noreturn)` and who knows what else. Now that the syntax is standardized, future developers can eventually throw out all that cruft and conditional `#ifdef` mess and use one standard way of specifying attributes.
As I recall (it's been many years since I last worked on Windows), GDI+ provides functions for reading JPEG and PNG files. There are some severe bugs and limitations to the GDI support of both formats, but you can get pixel data out of it. And it's a damn sight easier than learning how to decode JPEGs.
my task was to complete a partially written project. This included header and cpp files for a handful of different classes and structs. I was required to make all the necessary modifications to only one driver cpp file. Considering my prof may not have certain libraries when he is grading, it was not a risk I was willing to take. I complete understand, however, that there are plenty of libraries that are incredibly helpful (and save a ton of time). I just got into a bind this time and was hoping someone would suggest a unique idea! All is well, I have submitted the assignment with five hours to spare!
Who is he? He says he's an STL maintainer - anyone most people up on C++ would recognize? 
Random thoughts: * Certs: I've never heard of any for C++, though that doesn't mean they don't exist. * I just interviewed for a job that advertized for C++ people, but we talked about Python the whole time until I thought to ask whether there was any C++. No; he just had had better luck with C++ people than with Java people, even those with certs. * Places that use C++: games, embedded programming, financial companies, or old industrial or other Windows desktop apps (have I missed anything?). Really high-performance bioinformatics places; well, anything high-performance really. Older server code, randomly distributed. * C++ has long declined as an _application_ language, and so has gotten harder to find jobs in (my experience). Still, it seems to have prestige as a hard-core language. * If you want to learn other languages for employability, I'd start with Python - it's easy to learn and use, has libraries galore, and is very employable - at least in Silicon Valley. 
How is it at all pointless?
That variadic template example with the head template parameter and then the catch-all tail reminded me of [Greenspun's tenth rule](http://en.wikipedia.org/wiki/Greenspun's_tenth_rule), except for the bit about being slow (unless you consider compile times).
&gt;Few functions in my typical program return void, few types in my typical program have user-defined literals. There are lots of features I might not actually use particularly often in my program. That doesn't make them useless. I fully agree (with your examples and more general point), however I believe most constructs are trade-offs and in the case of the noreturn attribute IMO the benefit isn't large enough. Note, this is why I wrote 'almost pointless' in my first comment. &gt;The compiler can skip emitting code that WON'T ever get called. That can often be a significant amount of code, but even a tiny amount of code can be the difference between fitting a function in a single cache line or not, which can be CRITICAL in performance-critical situations. You might think that each individual optimisation is small, but OVERALL they add up to being a significant reduction in cycles and memory consumed. My point was that in the case of the noreturn attribute the amount of code the compiler can skip emitting is small. This is a conjecture of course. The rationale being that if large amounts of code emitting is skipped it most likely due to bad or erroneous coding on the part of the prorgrammer. I agree with point about small optimizations. This of course is a part of the trade-off mentioned above. I may be biased as most of my cpp is done in large scale business applications.
I suppose this could be fixed (probably infeasible I'm sure). But if the output from the compilation of foo contained such 'metadata' beside the emitted code. The compilation of the function-calling-foo could use that. (Perhaps this would work best if the prototypes in header files could be attributted too).
&gt;I fully agree (with your examples and more general point), however I believe most constructs are trade-offs and in the case of the noreturn attribute IMO the benefit isn't large enough. Note, this is why I wrote 'almost pointless' in my first comment. `noreturn` isn't actually a tradeoff, in this case. Because it's an attribute, if the compiler wants to ignore it, it can. An example of something that wouldn't return would be something like `execl`, though in fact that isn't `noreturn` firstly because it's C, and secondly because it will return on an error. Something like `execl` that terminated the program on an error would be `noreturn`. &gt;My point was that in the case of the noreturn attribute the amount of code the compiler can skip emitting is small. This is a conjecture of course. The rationale being that if large amounts of code emitting is skipped it most likely due to bad or erroneous coding on the part of the prorgrammer. It's not unreasonable conjecture. However, even if the amount of code skipped is small, that can still have a very large effect, for example by being the difference between getting a whole function on one cache line or not. And remember that this might be a step taken after a bunch of other optimisations, like unrolling a loop or something. Alternatively it might take place after generating code from templates, where the decision as to whether to return could depend on the template parameters. But overall you're right - it's not an important feature. It is however a very easy feature to add to the standard - it doesn't conflict with anything, compilers don't have to do anything to ignore it, and it can give small optimisation opportunities and occasionally large ones.
I wish for some kind of [[static]] if(expr) statement; anotating that you intent expr to be known at compiletime and beeing optimised away. I think that would be a good alternative to the current static-if proposal which Bjarne hates enough to write a “considered harmfull”-text (OK, completing the title was left as a trivial exercise to the reader). The attribute-method for this has the advantage, that it doesn't do much, that the current if doesn't and ships arround all problems of static_if, that are listed in Bjarnes paper. Edit: formating
Yes, it can compile and run that without issues.
"several" features? when's it going to be C++11 compliant?
http://www.reddit.com/r/cpp/comments/1h9uq7/c1114_stl_features_fixes_and_breaking_changes_in/ (there's a couple others threads in the last 100+ in /r/cpp about this with folks from the VC++ team participating
timely, I've been wanted to learn Qt. Can someone clarify what the deal is with the Qt license? There seems to be a lot of dispute over what's allowed/disallowed? Statically linked + closed source + free? What's disallowed?
I've written in the first part about the licensing. In short there are two options: Write commercial Applications with LGPL, many do this. Get the commercial license from digia, which brings a few advantages, such as being able to change/adopt qt to your needs if you are a bigger organisation, or most notebly, get the support from digia. Also this allows you to link statically, with LGPL there is an endless discussion, if its allowed or not. And you might want to consult a lawyer if you want to be sure, but thats a difficult topic, so if you ask 2 lawyers you'll get 3 opinions...
What is the most C++11-ish GUI framework at this point? I guess there aren't any.
Qt5 supports C++11, also you can use lambdas as handlers for SIGNAL/SLOT. But there isn't really a good, modern C++ based UI Framework that I know of.
Using a LGPL library requires that you publish the source of the library itself (if you modified it), and that it be possible for people to replace the compiled library with a copy they compiled themselves. This can be done by releasing the source to your application under a compatible license, releasing the compiled (but unlinked) object files for your application so that someone can relink the final binary, or by just dynamically linking the LGPL library. Commercial software generally goes with the third option (except for on iOS and other platforms with no dynamic linking that require the second (although there's some debate as to whether the other appstore restrictions are LGPL-compatible)).
Realistically, wxWidgets and Qt are the only general-purpose cross-platform options. Both support lambdas for events/signals and otherwise don't really take advantage of C++11. TBH I don't think there's really all that much in C++11 that's relevant to GUI frameworks anyway (API-wise at least; the implementations could benefit from it just as much as anything else).
Previous discussion(s): http://www.reddit.com/r/programming/duplicates/t1mo7/ceres_solver_googles_large_scale_nonlinear_least/
There’s nothing wrong with using a C style array here – a `std::map` would be wrong. Granted, it would be better to use a `std::array` (that would obviate the need for the horrible `sizeof` calculation) – but you need to hard-code the number of elements in a `std::array`. There is no way of dynamically initialising a `std::array` the way it’s done in the presentation. You *can* write a helper function `make_array` to allow the following syntax: auto arr = make_array(1, 2, 3); … but that doesn’t work with the uniform struct initialisation used in the presentation, and indeed there doesn’t seem to be a workaround in the current standard.
gtkmm does qualify for that. From what I've seen of it, it's a pretty nice API with the main con being that the simple fact that it's a GTK+ binding makes it a pretty poor choice unless you're targeting solely Linux. Adobe's Adam and Eve might be a more interesting example of a modern C++ GUI framework. It's built heavily on boost and is very clearly a product of Stepanov-era Adobe. It's a rather different beast than something like Qt though, since it doesn't try to handle everything a GUI application needs to do in a single monolithic library.
Making a GUI framework is ridiculously hard. If you started one today (in C++11), by the time it matures enough to be taken seriously, C++11 would be completely obsolete. AFAIK, both Qt and wxWidgets are pre-C++99 libraries, and it shows.
Great paper. It introduced something I wasn't aware of before. Thanks for sharing.
Good paper, but why doesn't my compiler *already* warn me about such mistakes?
Cause, someone needs to write those checks?
[Many](http://www.viva64.com/en/examples/) things can make a [PVS-Studio tool](http://www.viva64.com/en/pvs-studio/). The tool will learn with time to do other things. :)
Windows only = useless.
&gt;It's a rather different beast than something like Qt though, since it doesn't try to handle everything a GUI application needs to do in a single monolithic library. Well, then I guess Qt is a different beast than Qt, since it does not do that neither (anymore).
s/library/project/, if you prefer. The point is that ASL focuses on solving a few specific parts of creating a GUI application, and doesn't do enough to support building a nontrivial application with just it.
I wonder how long til a game can be played entirely on the gpu.
Hey that looks pretty nice! Is it solid? Have you used it?
CPU controls disk io, networking devices, etc inherently. Even the PCIE commands to move memory (ie, from ram -&gt; pcie bus -&gt; gddr) are cpu-side. Otherwise, opencl is turing complete. A modern game would probably have very little going on cpu side, since you can do the rendering, geometry, animating, collisions, AI logic gpu side. Some complex behavior algorithms (lots of ifs) usually lend themselves better to cpu pipelines, though. All a CPU needs to do is control network connections, forward input events, write an audio PCM out, etc.
I am still trying to grok it.
Wow, I could write the same thing about the OP. Linux only = useless. Catch those issues GCC already catches, in case other compilers don't! Come on.
More like how long till the GPU gets merged into the CPU. 
If a PCI-Express device is designated as a bus master, then it can initiate commands over the PCI-Express Bus. This enables things like DMA transfers.
The new console SoC are very close.
Well, OP is on the management team of the company that makes PVS-Studio (http://www.viva64.com/en/management-team/). He posts here a lot, and while it's often related to or about something to do with their tool, it's usually good/interesting content. Still, I agree with you -- calling it useless is dumb.
Keep it going all.. 
what libraries are going to support this in the near future? Isn't SDL still on some ancient version of opengl? and apple is on an even ancient-er...
You don't have to use SDL's built-in rendering though. I use SDL purely for managing windows and input, nothing more. Rendering I handle all myself.
how exactly? sdl + gflw? i'm an opengl newbie...
If you were particularly crazy, you can directly access network / sound cards from a GPU. See something like [GpuDirect](http://developer.nvidia.com/gpudirect). Also there are interesting things like [this](http://shader.kaist.edu/packetshader/) where they implemented a packet processing on the GPU.
See AMD's "March of the Froblins" for a graphics demo that's done pretty much entirely on the GPU.
SDL and GLFW basically fill the same niche, so it would make little sense to use both. What they both (can) do is provide you with an OpenGL context to use. One major difference is that you have to explicitly ask SDL for an OpenGL context whereas GLFW does this unconditionally. Now, SDL also provides non-hardware-accelerated 2D rendering facilities, which is why providing an OpenGL context is merely an option.
I'm sure this is all basic stuff ... but if each platform has a different API, aren't I still limited to what's exposed in SDL/SDL_opengl.h? I see it has some #infndef GL_VERSION_X_X in there (my version, 1.2 seems to only go up to 2.0 though). "it's each OpenGL implementation that will have to be updated" - so I should probably wait about 20 years before I start using the 4.4 API for anything cross-platform? =P
Unfortunately the compiler can't warn every time it takes advantage of some optimization opportunity because that would lead to so many false positives that it would be useless. Here's an article that discusses this more: [What Every C Programmer Should Know About Undefined Behavior #3/3](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_21.html). The first section is titled _Why can't you warn when optimizing based on undefined behavior?_ The tool in the paper avoids false positives but takes from 2x - 10x as long to do the analysis as the builds take.
I wouldn't hold my breath, if their OpenGL updates are any indication.
Yeah... but you can always mprotect that memory writable, fix it up and mprotect it read-only again. Hell, I've automated that in HippoMocks for global functions and static functions.
It's called SIGGRAPH.
Hi. I'm the author of the library. Actually, referring to mixins by string, and even calling messages by string is relatively easy to implement in the library as it is, but I've postponed it until after the formal submission to boost, because I don't think it would be of much use to people. Why do you think it's useful?
The new console SoC are AMD A-series APUs by a different name.
A-series has unified memory?
So, the console SoC are not AMD A-series APUs by a different name?
Weh, I cant read. Ill walk myself out:) Didnt see the new.
In case you haven't seen it: http://www.anandtech.com/show/6976/amds-jaguar-architecture-the-cpu-powering-xbox-one-playstation-4-kabini-temash
Well, they are "current-gen" in the sense that the Kabini and Temash parts are *already shipping*. But they are new in the sense that this is their new APU architecture, part of the refresh of their A-series. That's all I meant.
Aye, sorry I missed that. Exciting times ahead for CPUs! I wonder when they will start merging FPGAs into CPUs. That will get interesting.
Honestly, as much as I like the idea, I don't see it happening outside niche ARM markets. Those are the only areas that the likes of Altera and Xilinx target.
I only see it as a matter of time. A kernel could effectively configure itself to be an integral part of the CPU and make parts of it even more absurdly fast. It will/must happen, though the technology isn't that far along. If it does not happen, I will be even happier, since something much better will have to superseed the technology.
Aye, I have no good examples to give, since my experiences with FPGAs are limited. The slowness part is partially technological partly technical, though as you say, it will never reach ASIC implementations. A more realistic example might be selecting/adding/upgrading extension sets on a CPU. Not everyone needs AVX and similar extension sets, they would be better off using that die space for some other operation. Hell the CPU might even use it to enhance out-of-order performance. Again, Im speaking out my ass here, since I only see the possibilities but do not know the actual problems with FPGAs due to lack of experience. I'll read up on the Amiga One. Peaked my interest there :)
This tool teached me for sure some more about the innerworkings of boost... Preparing a new release, as some libraries aren't showing up yet (MPI and system beeing the most prominent).
for me its the first time using it, was always nice to know about it, but never had its (imho very rare) use case. But I'm sure its useful to people. I've seen whole buildchains and all dependencies being put in one repository, bcp is then surely a big help...
Using a singleton is no different than using a global. It can be accessed from anywhere via it's static get_instance method. Except it's even worse than a global: it's a super global. Anything the singleton allows access to also becomes a global. https://www.google.com/search?q=singleton+antipattern
Have you tried the latest boost::filesystem version? It came out a year ago or so. [boost::filesystem version 3](http://www.boost.org/doc/libs/1_54_0/libs/filesystem/doc/index.htm)
std::filesystem and std::network will come.
&gt; When you strip away the fancy GUIs Yes, and there's the problem. The core of an application is usually trivial to port (OS X, Linux, Windows) but then the GUI stuff is a pain in the ass if you want your software to feel native and not look like the common open source shit. 
&gt;Support for accelerators Can't wait for it to be implemented!
Emscripten has MIT license, which means no issues using it in whatever software I want. Duetto on the other hand:"The company plans to release Duetto as open-source for non-commercial use while a commercial product will also be available in the coming months." Which probably means GPL. Which means a lot of developers, won't even look at it.
Boost.Filesystem v3 has *terrible* error reporting (a single exception type which wraps platform-specific error codes) and a moderately awkward API. It's not unusably bad, but it is the least pleasant to use filsystem API I've used that's trying to be high-level.
You are absolutely correct despite the downvotes you are getting. The GUI is key; that is what users interact with. No how matter how fast and robust your core is, if the GUI is crappy your app has little chance of making an impression. 
And I thought my CRTP-monad implementation was fancy. Very cool!
This is actually pretty awesome. My main gripe about boost is the excessive compile time that it adds to your project. This somewhat mitigates that.
one day... hopefully soon.
GLee is dead.
Oh well. GLEW was always better anyway.
Security researchers would probably be out of a job if everyone went to interpreted languages anyway. 
Sadly this is so true! However the vastly improved OpenGL stack in Mavericks gives me hope. 
Yeah, I switched 3 years ago and haven't regretted it.
Now all we need to do is to get the LLVM/CLANG guys working on this! 
That made my day, thanks.
It's a huge web of dependencies. How unlike most software projects I've ever worked on.
&gt; look It's not only about the looks. It's how it feels - and OS X users will instantly sense a Qt application as something alien. Windows and Linux users on the other hand seem to be pretty OK with Qt. (Note: We're using Qt for Linux and Windows UIs and for the Mac we go the extra length and do it natively in Objective-C++)
Perhaps the problem is not in Qt but in Mac OS X users :P (just kidding)
Yeah, the user is the problem. Everything would be so much easier if it weren't for users. Everyone in the software industry knows it. The problem is: User's don't know this. :(
What is the advantage of being able to compile C++ to javascript? Wouldn't it be more reasonable to have a more high level language like coffeescript compile to it?
Would be boost::regex an alterantive?
It certainly would be one. `std::regex` is a copy of `boost::regex` AFAIK. Edit: Am I incorrect? The API appears to be the same in all respects that I've seen.
g++ will have an implementation. There is a student who is working on this for Summer of Code 2013: http://www.google-melange.com/gsoc/project/google/gsoc2013/tim_shen/56001 One could watch the progress here: http://gcc.gnu.org/wiki/Regex/Status
So basically just because scintilla can't be assed implementing regex support, that automatically means regex support is poor... that's just... wow. 
But could you imagine how slow Chrome or any other complex program would be in an interpreted language? But yes har har :) 
cpp14 perhaps? Atleast for std::filesystem.
I think this is less about the api and more about support for the actual regex syntax. 
Nice to hear.
Have you even looked around before posting? g++'s regex implementation is nonexistent. http://stackoverflow.com/questions/12530406/is-gcc4-7-buggy-about-regular-expressions
My mistake i must have glossed over latter part of it due to the tiny font.
&gt;Windows and Linux users on the other hand seem to be pretty OK with Qt. Possibly because at least on Windows (know too little about Linux to say) applications have been using slightly differing looks&amp;feels for a long time now. Not even Microsoft applications use unified GUI elements and keyboard shortcuts (to search type either ctrl-f or f3 or ctrl-f4...). And yes, a Qt application on Mac behaves subtly different from a native application, e.g. by not supporting horizontal scrolling with the mouse wheel or an icon toolbar that does not follow the icon/toolbar design and functionality of a native application.
Your title makes it sound like c++11 is deficient in some way when it instead appears that some current implementations are just poor. Or are there actual problems with the spec?
Why can't they port the boost impl? licensing?
Came here to say this. The spec for `std::regex` is mostly fine, but implementations are still catching up. I presume this has something to do with the fact that C++ developers are still learning that regexen are something they have access to as a tool…
not surprised. A part of this headache stems from the lunacy surrounding utf8, utf16be/le, utf32be/le, etc. I just wish c++14 would do utf8 internally only, drop this wide crap and then provide an api or functions or whatever for translating from crazy wide stuff to and from utf8. That would at least simplify and streamline the core internals. If people have special needs they can do custom paths for these wierd and legacy wide characters.
According to http://www.reddit.com/wiki/faq I can't edit the title. Sorry for the misleading title.
`boost::regex` supports more things than `std::regex`, like lookbehind assertions.
Yeah, it's been proposed, Ms implemented it... No one else has yet though. 
Different UTF encodings are not the problem when implementing std::regex. Things like coding back references are where the complexity lies as well as supporting multiple regex syntaxes. C++ is not going to go UTF-8 only any time soon. The best we can hope for is better C++ Unicode support in general.
I wonder how much of this is due to that Cocoa is a much nicer API than any of the native options on Windows. Even if Qt applications felt perfectly native on OS X, I probably wouldn't use Qt for an application that inherently would never run on another platform. On the other hand, I don't see anything at all questionable about using Qt for a Windows-only application despite the fact that it's not quite native. As a result, I suspect there's a lot less motivation to try to make Qt native-quality on OS X.
This is somewhat embarrassing as the message was a bit of a vent. I was hoping that someone would reply pointing out an overlooked option or that upcoming releases have improved. Some regex libraries have a multi-line option to enable '\^' and '$' inside the text being searched and this may have been exposed through a non-standard flag. Scintilla contains a very simple old regex implementation from Ozan S. Yigit and there is an extension point where projects can insert their preferred regex library. Applications like Programmers Notepad and Notepad++ extend Scintilla with Boost to implement more complete regexes. Using C++11's regex was meant to allow applications to choose better regular expression support without adding a library dependency. Initially it would be opt-in by defining a preprocessor symbol and as compiler support improved and older compilers dropped off the supported list, it would move to opt-out, and then be permanently on.
In broad strokes, Scott's advice here is good: think very carefully before overloading a function that takes a universal reference. It's probably not doing what you think you're doing. But please disregard slide 23. You can hear my strenuous objections at 57:30.
Could they make the font a little smaller? I can almost see it.
Your mostly correct. I had to migrate from std::regex to boost::regex and it was a simple search and replace.
I like the idea behind this. However, I think redefining the meaning of common operators is dangerous and can make code very difficult to understand for people not intimately aware of it. Example: ++rg // redefined from pre-increment to rg.front() ++pair // redefined from pre-increment to pair.first In this specific example, what happens when the type is a function template argument? template&lt;typename T&gt; void do_work(T&amp; data) { // do something with data auto i = ++data; // what is happening here? pre-increment? range.front()? pair.first? // do something else with data } I think this could be a stumbling block in the path of wide-spread adoption of your library.
Eric's strenuous objections were fully valid. In the [revised slides I've made available](http://nwcpp.org/talks/2013/URefs-and-Overloading-revised.pdf), I've added comments below slides 23 and 24 indicating that the example makes no sense. This is one of the technical shortcomings of the talk I refer to in [my blog post on the topic](http://scottmeyers.blogspot.com/2013/07/video-for-universal-referenceoverloadin.html).
C++ standard defines "&lt;&lt;" for output stream. So if I see "someStream &lt;&lt; x", I know "&lt;&lt;" is output, not shift left. 33 letters symbol, if it's readable, then it's OK. I can't remember a 33 letters symbol, nor can I remember overloaded operators. But for function names, I can always go to the header, or with auto complete in the IDE, to see the name and understand what the function does immediately, but for operator overloading, how can I know what "-" does without reading the document? Maybe you can comment it, but code that needs comment to be understood is not self-explain any more. 
With proper formatting, I'd rather have a more verbose line that I can parse without hunting down the definition of each operator overload. In [wqking's example](http://www.reddit.com/r/cpp/comments/1izw3g/ro_range_operators/cb9tjhw), a more readable formatting could look like this vec.erase( std::remove(vec.begin(), vec.end(), x), vec.end() ); If we now wrap this in a (templated) function called `removeAll(collection, value)` and provide overloads for different collection types, it's absolutely obvious what it does. With something like `vec - x`, I find it far from obvious, as wqking already said. At first, I even thought it returns a copy of the vector with the value `x` removed.
&gt; Both GCC and LLVM/Clang have already been working towards C++1y support with regards to the likely proposals and changes Isn't it too early to support C++14? Who dares to write code based on "likely proposals"? 
Seems to be a victim of "when all you have is a hammer". Overloading *can* be used to great benefit, but when you try to put *everything* into overloaded operators rather than just defining simple functions, you end up hurting readability, comprehension and really having no benefit other than saving a few characters. I think it would be nice to have more vector-like vectors, where you can carry out multiplications, additions, inner and outer products like you would in math, but why on earth try to co-opt those operators to mean completely different things. 
At least there already is a Committee Draft for C++14, so major changes are unlikely at this stage. On the other hand, it's also important to get implementation (and user) experience before the standard is finalized.
I personally like the idea of operator overloads for this sort of thing, but there's one grip I have with the library as it is. I'd prefer if non-assignment operators returned copies of the range, rather than modifying it in place, and for there to be additional assignment operators which do things in place. e.g. if `vec = vector&lt;int&gt;{1,2,3}`, then vec2 = vec - 3; should keep `vec == {1,2,3}` and have `vec2 == {1,2}`, while vec -= 3; should modify `vec` to be `{1,2}`.
C++14 is already feature complete. It's currently at the next to last step before final approval.
It doesn't look thought out at all to me. It looks pretty much just grown organically, with thought added afterwards (look me in the face and tell me `scc 'vint V{1,2,3,2}; (V|2 = 42)'` being `{}` was thought out)
You'll note that the terseness of APL or Haskell doesn't involve giving a bunch of new meanings to the same old symbols over and over again. APL has an large set of different symbols, and Haskell actually forbids overloading entirely.
 NLTemplateLoaderFile What exactly is wrong with namespaces? NL::TemplateLoaderFile Would have been far better.
Let me guess, Windows?
The reason it doesn't work with deleted special functions is that deleting a function leaves it in the overload set (it just makes it an error to call it). This lets you do things like prevent conversions: onlydouble(double); onlydouble(std::intmax_t) = delete; There you can only call `onlydouble` with floating point values; any integral type is a better match for `intmax_t`.
CentOS 6 actually. gcc 4.4.7, and no official update to anything newer. 
&gt; You'll note that the terseness of APL or Haskell doesn't involve giving a bunch of new meanings to the same old symbols over and over again. APL has an large set of different symbols, and Haskell actually forbids overloading entirely. That's my point: going for terseness on this as a library has a steep price to pay; a price that the examples you gave didn't have to pay.
It is, in many ways, the *best* time to implement the standard. Why? If you find out something isn't viable (because it conflicts in a really subtle way with something else, which often is the sort of thing not realized until you're implementing it), it's still possible to change the standard. Certainly, you don't want to have to be chasing the spec endlessly, but once it has settled down somewhat it's ideal.
Nothing wrong with namespaces in particular. I'm just not used to them because I mostly use Objective C, where the two-three letter prefix in the type name is a common replacement for a proper namespace. This code is from a larger codebase which I maintain, so it would be a pain to switch now. I will consider it for future projects though. Thanks.
People have mentioned it countless times here: lack of clarity, inconsistency with established idioms, etc. (see http://www.reddit.com/r/cpp/comments/1izw3g/ro_range_operators/cb9tjhw)
Why dont you cross compile to an earlier glibc, instead? I did that for centOS 8, but perhaps centOS 6 is too old.
&gt; GCC 4.9, Clang 3.4 Will Have Better C++14 Support And here I thought they'd be the same as the last version. Good thing we have reddit to tell us these things.
Thats why you do some sanity checks when instantiating the template, if it is not a generic one that is. If template parameter is malformed, do a static_assert and be done with it. 
Have you grabbed the centos devtoolset? It's gcc 4.7. Better than nothing. There's a devtoolset 1.1 also, but I can't find the centos version of it. http://dev.centos.org/~tru/devtools/6/x86_64/RPMS/
CentOS 8? The latest version is 6.4. http://centos.org
Yeah, I'm using 1.1, it comes with 4.7.2 which is ok, I guess.
Sorry i meant 5.8
Even things nominally ported from boost have their differences. Also, boost structures their libraries differently from stl and has dependencies to non standardized sections. It's not prohibitive, but it's not a copy/paste job.
Well, I'd consider it in line with the principle of least surprise here: since I'm used to seeing "`-`" return a new object, I wouldn't expect it to mutate either of its parameters (unless they were an rvalue). Similarly, btw, I'd be interested in seeing "`+`" and "`+=`" for adding to vectors, what you currently have as "`&lt;&lt;`". It'd be symmetric with "`-`"/"`-=`", and somewhat compatible with [Boost.Assignment](http://www.boost.org/doc/libs/1_54_0/libs/assign/doc/index.html#operator+=).
devtoolset 1.1 can be found at: http://people.centos.org/tru/devtools-1.1/6/x86_64/
I understand your point, but operators should follow the expectations of people familliar with the common (non-programming) versions of the operators. operator * makes perfect sense for complex numbers, but not so much sense for vectors. There are some operators that have historical significance (&lt;&lt; for streams, + for strings), but I have to agree that &gt; vec - x Does not convey the message. Now if C++ were to expand the number of operators or allow user-defined operators, then we could write things like: vec \= x; // vec = vec \ x; using '\' as the [relative complement ](http://en.wikipedia.org/wiki/Complement_\(set_theory\)#Relative_complement) operator. But allowing user defined operators opens up another can of worms. (I will not discuss the topic here. Google it if you wish.)
The "trap" is actually with `std::string::c_str()`: it returns a pointer to the contents of the `string` object, which is only valid as long as said `string` object exists. No need for such a long article...
No need for such a long article to limit itself to that particular instance of the problem: reference to (content of) temporary that goes out of scope before the reference does.
Agreed that this is a simple issue. However this exact code (writing .str().c_str() ) has caused problems in my project more than once, so it's probably a useful reminder.
As a rule, you should never write `char const*` (or `char*`) anywhere. If you need a `char const*`, it's probably for a function with an improper argument list; you call `.c_str()` inside the function call: string const filename= ... ofstream ofs (filename.c_str()); 
Nah, it'd be the same for any C++ compiler.
As a side note: Since C++11 ofstream and family finally possess a ctor taking an std::string parameter. 
Yes, if you explicitely construct a *const* (!) C++ reference to a temporary. Above, I used "reference" loosely (i.e. including pointers, which .c_str() does). Sorry for the inaccuracy. 
Why not return a const std::string &amp; (to static const objects) then? Regarding string_ref: Not sure if I understand you correctly, but I think std::reference_wrapper should do the trick.
I would teach std::string before cstrings and std::vector before arrays. I would teach cstrings and arrays after you have thoroughly gone over array.
I am still studying C++, but the kind of unneccesary complexity presented in the article boggles the mind. What is wrong with the following? const double pi = 3.1415926535897932; Its the most straightforward way, I can't imagine why using the other methods considered somehow "better".
I dont think he's looking for a better way, just different ways.
It would require code: static std::string const errmsg_invalid_ref("invalid reference"); return errmsg_invalid_ref; Also, this would copy the string into the static std::string object. The thing with a string_ref is that it would have the semantics of a string, it just wouldn't *store* a string. Just like the idea of ranges vs. containers in C++. A reference_wrapper cannot immediately be used as a string. A string_ref could. In a fully generic sense, you'd have some kind of String concept, and string_ref would model this concept (so would std::string). Ideally, the concept would be rather small, doing away with most of std::string's methods (since honestly, this class suffers from a kitchen sink syndrome). Stuff like "find_last_of" could be done with non-member functions.
&gt; You could return an std::string, but that is wasteful, Don't overestimate the problem. First, typically, errors are not the norm. Most of the time, `strerror()` isn't called. Also, if you do request the string in question, I suppose it's because you want to do something with it: either save it onto the hard disk (very slow), or display it inside a GUI (even slower). The string copy is negligible compared to the rest of the process. --- Not to mention, I believe exceptions usually are better than return codes. But that's another can of worms...
Makes sense. Thanks for the info!
You can still have a constant array of std::strings. You don't have to initialize a constant for every message.
&gt;Calculating with atan/atan2 is also an alternative. I'm pretty sure there are no requirements on precision of transcendental functions in C++. Using those to get a constant that can be obtained with known precision seems like a pretty bad idea.
I stand by /u/mttd's points in their entirity, this along with every other on-line tutorial on C++ just isn't up to scratch. If you are going to teach C++, which in all honesty is a very complex language, you need to know it inside and out, which the author has failed to convince me of. Another point, although I accept this is subjective, I really don't like when people teach an IDE along side a language, especially for a language like C++ and especially when that IDE is the platform specific Visual Studio. There is so much merit in teaching/learning how the tool chain work and what competent does what. My advice to anyone learning is to pick up a good C++ book like The C++ Primer (5th edition covers C++11). 
Here I sit, pondering the agony of hunting down a bug caused by someone swapping two digits of pi. 
thx. added a comparing paragraph and linked to the example of boost.multiprecision.
I've seen code looking exactly like this before which caused serious issues in production projects. I've seen this value where someone simply skipped one of the digits - causing actually wrong values. I've seen this value where someone simply truncated the value a little early - which resulted in serious visual weirdnesses that had to be tracked down (because of the singularity in tan(x) around x=pi/2). As you write a lot of production code - code in _any_ language - you realize that while writing code is fairly easy, fixing problems is _not_ at all easy. Having a local value for pi is a little easier to type, but you are introducing unnecessary risks - small risks, but real risks. Perhaps that risk will never come about - but if you add a lot of small, unnecessary risks you'll be running into some of them sooner or later. Remember also that, if your code is successful, you are not the only one reading it - in fact, most production code is written once but read more than ten times. _You_ might know for a fact that your pi is the correct pi - but I, the person maintaining the code later, I don't know that your pi is right. If I were reading your code that implemented a production-critical system, I'd be forced to check that you really got this right when I got to that line, or even better, replace it with a library reference - because I think of myself as an engineer, not just a computer scientist, and I am professionally obligated to reduce or ideally even eliminate _any_ possible source of risk. 
[Solution: Just legislate what the value is](http://en.wikipedia.org/wiki/Indiana_Pi_Bill)
&gt; Almost any project of substantial size will already have a dependency on boost I'm not sure that this is true. I don't use boost in any of my projects, all of which are pre-C++-11, and those projects use literally dozens of open- and closed-source C and C++ libraries, none of which require boost. While I'd probably like to be able to use boost, there are many reasons that I don't. One of them is that I use [JUCE](http://rawmaterialsoftware.com/juce.php), a cross-platform, open-source C++ library, which doesn't require boost and gives me most of the features that I'd need from boost, and a ton of stuff that boost doesn't give me (like cross-platform audio, graphics and DSP). Another is that I'm often (though not always) targeting multiple systems which include "smaller" platforms like the pi3d or BeagleBone. And boost is huge. I just downloaded and extracted the current version while watching my disk space - it took, at peak, well over 900MB of disk space, and ends up being almost 488MB of disk space before you build anything. And that's 488MB of source. By comparison, my largest personal project has less than 7MB of source (which includes over 3MB of generated code, which isn't strictly "source") and the largest library I use, JUCE, has 25MB of code - about 5% as much as boost. I have almost two dozen projects in my development area, some active, some archived - and about as many again third-party libraries. Their total source code size all put together is less than a third the size of boost's source code. 
Doing a "one shot" installation of gcc if you want to play around is pretty easy: tar zxf gcc-4.8.1.tar.gz cd gcc-4.8.1 ./contrib/download_prerequisites cd .. mkdir gcc-4.8.1-build cd gcc-4.8.1-buid ../gcc-4.8.1/configure --prefix=/SOMEINSTALLDIR --disable-multilib --disable-bootstrap --enable-languages=c,c++,objc,obj-c++,fortran make -j #NUMPROCESSORS make install then add to PATH, LD_LIBRARY_PATH etc 
Put this immediately after the definition: assert(std::abs(sin(pi)) &lt; 1e-15); Problem solved?
&gt; What in the world is this: It's probably necessary to cope with terrible examples like this one: char var; //Menu cout &lt;&lt; "Press a \n"; cout &lt;&lt; "Press b \n"; cout &lt;&lt; "Press c \n"; cout &lt;&lt; "\nEnter a character a, b, or c: "; //enter a, b, or c cin &gt;&gt; var; cout &lt;&lt; "\nYou chose: " &lt;&lt; var; Nowhere is it explained that `cin &gt;&gt; var` leaves a newline in the input stream, so the console would still close with a single `cin.get()`. This is one of the most common misunderstandings among beginners trying to write programs that interact with the user, and here the tutorial is just reinforcing that misunderstanding by neglecting to explain what really happens. I've seen newbie code that's just plastered with these kind of "`cin.get()` prayer beads" -- they know something is wrong and they figure out that putting a call like that in there tends to fix it, so they just start doing that whenever something doesn't work. Thank you for creating legions of cargo cult programmers, bad tutorial authors. `&lt;/sarcasm&gt;` 
But it's still an approximation! We must go on!
He's being a little bit facetious but anyways to give a rough overview... As X approaches PI, sin(X) approaches 0. IEEE double precision floating point values (what is typically used by C++ compilers to represent double) always guarantee 15 decimal places of accuracy, so what he's doing is adding an assertion to check that the value of PI provided is basically good enough that taking the SIN of that value also produces 15 decimal places worth of accuracy. There are obviously issues with it, you wouldn't actually use an assertion like that, but it's nevertheless nifty.
What? I wasn't being facetious. What obvious issue is there?
Going from my memory it looks like you got it right ;)
All you use in this case is a single header from boost. Ofc its overhead if you only need pi, but if you already have boost (after all, a bunch of people find it quite useful) on board, why not use it? The alternative is probably using M_PI, as the C Standard provides it. Or calculating pi with atan/atan2.
If you want value semantics, you should NOT use inheritance. C++ is built around value-based polymorphism. Having a `clone` method is what is used in languages like java, that don't provide value semantics.
Thanks for pointing out the error in the example. It's fixed now.
Can you elaborate on the problem with using M_PI? That seems like by far the best solution to me. The article says: &gt; This will give us pi with 48 digits (well, double), but in order to compile, we need to add a #define _USE_MATH_DEFINES before the include of &lt;cmath&gt;. but I don't understand this. It's not true for me. Does it depend on the compiler? I've never see that macro before.
If you already have boost then it's probably okay because you already have to deal with all the boost trouble. `M_PI` is neither C nor C++ standard. It is available on most platforms though. However the precision might vary. And worst of all because it's non-standard there are many libraries doing something like #ifndef M_PI #define M_PI 3.1... #endif and you might end up with an `M_PI` from somewhere completely else maybe even differing between compilation units due to differences in header include order... Using `atan`/`atan2` might result in precision issues depending on the platform as well. And it's hiding the value making it even harder to spot any issues than simply using a double literal. 
If you do that you don't get the `make_shared` optimization, so it's less efficient than the hand-rolled code.
Wouldn't the clone_impl virtual function always return shared_ptr&lt;base&gt;? It could just use make_shared&lt;derived&gt; instead of shared_ptr&lt;derived&gt;(new derived). 
I'm not clear on what you mean. The particular scenario I had, when writing the article, is a type tree in a compiler. Given the complexity of types you have no choice but to use a lot of pointers. On some occassions I need to create a similar type, which involves me cloning the source type and making modifications. I'm not sure why "clone" wouldn't be a suitable option.
It works, but it doesn't have the same level of type safety as covariant returns. The "clone_impl" isn't bound to return a correct type in this approach. That said, it is the approach I use now.
Not an issue when using std::unique_ptr&lt;char[]&gt;. \* Although a message should really be stored in a std::string. With small string optimizations that might even result in no memory allocation at all.
Exactly. The message in the article is an important one but is being conveyed using a bad style (raw pointers vs. C++11 smart pointer idiom). I think especially in tutorial-like articles one should try to use the best coding style possible (and maybe even avoid showing bad code altogether).
This isn't really delegating constructors stabbing you. It's always been bad to leave fields uninitialized in constructors and like hyperthreaded said, using unique_ptr will help you avoid mistakes like not initializing char *message.
Why not initialize message to nullptr via inclass member initialization? More so, why not initialize all _raw_ pointer to nullptr in via in class member initialization. Though, this is good info. I didn't know that the destructor will get called after just one of the delegated constructors return.
The method `shared_ptr&lt;A&gt; B::clone_impl()` could accidentally return something which isn't a shared_ptr&lt;B&gt;.
Can you give a simplistic (but real) example of your type tree? Are we talking some kind of duck typing?
If you need .clone() methods your architecture sucks. 
use separate initializer methods and be happy.
Now that it's fixed, there's nothing wrong with the code. If new[] throws, the delete[] will handle being called with a nullptr just fine.
&gt; All you use in this case is a single header from boost. This is not correct. That one header, `boost/math/constants/constants.hpp`, starts: #include &lt;boost/math/tools/config.hpp&gt; #include &lt;boost/math/policies/policy.hpp&gt; #include &lt;boost/math/tools/precision.hpp&gt; #ifdef BOOST_MSVC #pragma warning(push) #pragma warning(disable: 4127 4701) #endif #ifndef BOOST_MATH_NO_LEXICAL_CAST #include &lt;boost/lexical_cast.hpp&gt; #endif #ifdef BOOST_MSVC #pragma warning(pop) #endif #include &lt;boost/mpl/if.hpp&gt; #include &lt;boost/mpl/and.hpp&gt; #include &lt;boost/mpl/int.hpp&gt; #include &lt;boost/type_traits/is_convertible.hpp&gt; and those headers include other headers... There's a tool that lets you extract just the subset of boost you need, though it usually still results in thousands of files that you need. Calculating pi with atan/atan2 is also not correct unless you have very strict guarantees on the precision of these functions - which as far as I know, no real-world implementations do. `M_PI` might also not work, as it's non-standard, and other libraries might have it defined. Not such an easy issue! If you are already using boost, then you should use `boost/math/constants/constants.hpp` as the best solution.
It's not possible to use the copy constructor on a derived type. In many cases I have only the base type but need to clone the most derived type without knowing what it is.
The "A11(int ans)" constructor is not a correctly implemented constructor since it leaves "message" undefined, thous violating one of this class's invariants. So there isn't a new issue due to C++11 at all.
Doesn't work if you have const or reference members as they have to be initialized in a constructor's initialization list.
It's good to remind people that constructors have to be sure to set up the object so that all of its invariants are met before returning -- even private constructors. But I think that delegating constructors are going to be a small tool in the back of my toolbox; they aren't going to become the big hammer that gets pulled out for every project.
Pi is evil anyway. Tau is the way to go!
I'd like to clarify a few things. I agree with pretty much all the comments here. Yes, `std::unique_ptr` or `std::string` would've solved the problem and yes, just (zero-)initializing all the fields, even in a private constructor, would as well. That being said, the message I tried to convey (although it seems I was a lot less successful than I'd hoped) was that you can't take your old `CommonInit()` method and rename it to a delegated constructor without considering the consequences - it's not a perfect drop-in. The case of `char*` is trivially fixable (unless there is a lot of refactoring to be done), but I only chose `char*` because I tried to make the example as simple as I could, yet still work (or not work) in an online compiler. In the real world, this might be a resource that has no empty state, or that doesn't allow destruction of such state (for example: WINAPI's `CriticalSection`).
Exactly, thats why you dont use inheritance with value semantics(at least no subtype polymorphism). Like i said, you can use type erasure or a variant type, instead. boost::any and boost::variant will copy construct the correct type.
But how does that differ from the covariant return types? B* will implicitly convert to A* the same way shared_ptr&lt;B&gt; will implicitly convert to shared_ptr&lt;A&gt;; going the other way needs a static cast in both cases. In the covariant case you could accidentally return something that wasn't a B* as well. 
In the covariant form, "B* B::clone_impl()" you cannot return something other than "B*" from the "clone_impl" function.
I'm just going to add a small comment on the `+=` vs. `&lt;&lt;` topic: I think `&lt;&lt;` works better in a chain. It's not immediately obvious what `v += a += b` would do. :) Of course, both could exist, but I'd expect `+=` and `-=` to take *other ranges* instead of *single elements*.
I was thinking more along the lines of what Boost.Assignment does, i.e. v += a,b,c though that's arguably a massive hack, and relies on somewhat unexpected operator precedence. I do agree that chained `+=` is a bit weird, I was really only suggesting it for symmetry. I'm not against keeping `&lt;&lt;` though, given the precedent set by iostreams.
I missed this and just spent hours working it out (nearly) some great tips. Well done to the author. A further example of taking existing non qt c++ code and wrapping it would be very helpful. When Qt folk talk of c++ code they nearly always mean code inherited from Qobject etc. and there is a complete lack of examples of taking an existing c++ library and providing a mechanism to use that with QML, now that would be a great blog entry! Another good example would be to use cmake and not be stuck with qtcreator / qmake builds as they force too much *all* Qt code type examples.
Have you tried MS Visual Studio Express? It does C, C++ and C# through a GUI interface. There are plenty of tutorials for it online / on YouTube. IMO, the only reason you'd want to use Cygwin is if you have an existing Unix command line tool that you want to get up and running on Windows quickly.
Pretty sure Cygwin has a gcc package. You can install MinGW, and if you want an IDE, Code::Blocks isn't bad. Or download the free version of the latest Microsoft Compiler.
Your question has been answered 3x over, but I'm going to leave this here too for other options: http://www.cplusplus.com/forum/windows/663/
&gt;for my job express should technically not be used for work. Just pointing it out. I would go with STL's excellent http://nuwen.net/mingw.html More seriously though, if you can't get a compiler up and running for C/C++ for work, maybe you should get help from a professional because there's potentially a world of pain between having a compiler and having a binary. 
If you are working for a larger company that has licenses for MS Visual Studio, ask for that. They should be providing the tools unless you're a contractor. Otherwise, there are tons of open source alternatives, like MingW or gcc on cygwin, but as a novice you'll probably have a lot of trouble. I'd just use the free Vis Studio Express and tell them you'll use that until they can provide a licensed copy.
&gt; express should technically not be used for work. Just pointing it out. I don't believe the licensing prohibits commercial use. I've done a lot of searching, and cannot find anything stating that it does, and actually found several posts on MSDN stating that it *can* be used commercially... I wouldn't worry about in-house development, but if I was shipping a product with it, I'd contact a lawyer first. It definitely doesn't have as many features as the full version, so that might be an issue. It's a good starting point, and you can always upgrade to Visual Studio if its an issue. Much more friendly towards beginners than MinGW, too.
Ah right, that looks like an overloaded `operator,` — one of the greatest hacks in C++!
&gt; unless you're a contractor. It's still typical to provide those kinds of tools to contractors, as most of the time they're expected to be working in a team, where everybody is expected to use the same toolset.
Yes, he is initializing member variable in constructor body, the member should be initialized in constructor initializer list (to nullptr or to other value). This is done automatically for class-type members, but build-ins and PODs are garbage-initialized.
You CAN use VS Express for developing commercial applications just fine. There are no restrictions.
Cygwin is perfect for your needs. But g++ is probably not installed by default. You need to go through the setup again, but this time search for g++ and mark it for installation. To compile you cpp file: &gt;g++ main.cpp To run: &gt;./a.out
There's also Eclipse CDT. I haven't used Eclipse's CDT, but I like how Eclipse works for Java. Plus it's free to try and a lot of companies today like it if you have experience with Eclipse.
Depends.exe is handy for checking stuff like this: http://www.dependencywalker.com
To write code that can be used across DLL boundaries across different compilers (for example MSVC and G++), take a look at my answer for an example. http://stackoverflow.com/questions/17885060/passing-reference-to-stl-vector-over-dll-boundary/17924465#17924465 
In C++11 you can mitigate this somewhat by making such functions lvalue-only. For example, this would become `const char * c_str() &amp; const` - note that &amp;. Of course this doesn't really fix stringstream.
I thought that Express would only compile to a command line executable (at least at one point) and if you wanted proper Window's GUI'd application you'd need to step up a level. Am I crazy in my memory?
Yeah it works fine for GUI apps.
Is it worth the $299 registration fee? (or am i reading this incorrectly, and it's free online)
That's a bad idea. Keep to C api and you will be fine if you keep CRT dependencies (allocations mostly) inside each module. If you really want, provide C++ wrapper over that API. Other then that if you still need to do so, compile all modules with the same compiler (and options) and link against the same DLL version of CRT.
I've been closely watching the status of G++ implementation. I'm in dire need of it right now. Thanks for the info!
Are all sessions going to be available for online viewing?
Yes. /MD will let the two share the same *instance* of the runtime, which means the same heap. (When using the same compiler version.) Don't even think about a C++ API without this.
The $299 registration fee is if you want to physically show up to the conference in Redmond. It'll be free to watch the talks online, as always.
Note that in the first constructor delegation example constructors that take fewer arguments pass their parameters along with default values to a constructor that takes more parameters. Basically you have a fully functional constructor that the other, less functional constructors which use default values, delegate to. However the latter example not follow this pattern. I think this shows one reason that the way initialization is factored in the latter example should be considered an anti-pattern. The original code in the latter example should have been structured: A03() { common_init(NULL); } A03(std::string const &amp;msg) { common_init(msg.c_str()); } void common_init(char *msg) { answer = 42; if (msg) { message = new char[std::strlen(s)+1]; std::strcpy(message, msg); } else { message = NULL; } } Additionally there are other tools in C++11/14 that are even better for this code: struct A03 { A03(std::optional&lt;std::string&gt; msg = std::nullopt) : message{msg} {} int answer = 42; std::optional&lt;std::string&gt; message; }; 
They were live streamed last year. Hopefully they will be again.
Maybe. We might not stream live this year.
I can't recommend highly enough that you try and be there in person. When's the last time you got to hang out with C++ titans for three days - and the weather is excellent in Seattle in early September. This is a C++ festival. Kind of odd watching from the sidelines if you don't have to (obviously, many folks can't attend, but want to, but for those of you on the fence... Jump on over. And soon.)
Organizing two conferences, I can tell you: That price is a joke. Normally, you'd have to pay much more, but MS wants you to come and stick around. Short overview over european C++ Conferences and their ticket price: ADC++ 1083€ + tax (thats a Microsoft conference btw) Qt Dev Days 550€ + tax Meeting C++ 499 € (early bird was 399, tax included). So, 299$ is pretty cheap. C++Now charges something around 640$ for their tickets. But they also offer a week of true great C++ content. So 299$ is really a no brainer. Going Native will be sold out very quickly.
But why do that, if everything operates under a common interface, and only the implementation details differ from node to node? Cloning is such a basic, simple idea, I can't imagine why it would be treated as a code smell. It's just like having a virtual constructor!
Whenever I read the name of that event I think of a nudism festival.
&gt; But why do that, if everything operates under a common interface, and only the implementation details differ from node to node? I assumed the nodes were closed, and case based. If they are open with a common interface, of course, its better to use type erasure. &gt; Cloning is such a basic, simple idea, I can't imagine why it would be treated as a code smell. C++ uses the copy constructor to copy a class. In languages like java, a clone method is used, since it lacks value-based semantics. I prefer the C++ way, which seems to work a lot better without a lot of headache. Trying to do it the java way just leads to lots of issue along the way(like in this article, as one example). C++ is not java. Treating it as code smell, I guess, depends if you believe writing java code is code smell.
Reddit formatting is mangling your source code (most obviously with the `#include` directives, but it's also eating stars and producing italic text). Please click on "formatting help" and see "Lines starting with four spaces are treated like code". Additionally, you're including node.cpp, which you haven't provided (although I can guess BstNode's definition easily enough). Note that you should never include .cpp files. Edit: You should also provide main() and an example text file that triggers the bad behavior. This is Bug Reporting 101, which also applies when the bug is in your code - provide *everything* needed to demonstrate the bug, so people can actually help you.
Main function: int main() { BinarySearchTree bst (test1.txt); } 
Here is the output I get from some cout statements. The only errors seem to happen with remove. Line reads insert root == NULL. Calling insert with NULL n == NULL inserted root 56 Line reads delete deleting value 200 200 &gt; 56 going to right child n == NULL. return Line reads insert inserting new value 22 22 &lt; 56 going to left n == NULL inserted 22 as left child of 56 Line reads insert inserting new value 99 99 &gt; 56 going to right child n == NULL inserted 99 as right child of 56 Line reads insert inserting new value 26 26 &lt; 56 going to left child 26 &gt; 22 going to right child n == NULL inserted 26 as right child of 22 Line reads insert inserting new value 110 110 &gt; 56 going to right child 110 &gt; 99 going to right child n == NULL inserted 110 as right child of 99 Line reads insert inserting new value 99 99 &gt; 56 going to right child 99 = 99 Line reads insert inserting new value 16 16 &lt; 56 going to left child 16 &lt; 22 going to left child n == NULL inserted 16 as left child of 22 Line reads insert inserting new value 60 60 &gt; 56 going to right child 60 &lt; 99 going to left child n == NULL inserted 60 as left child of 99 Line reads delete deleting value 56 n has two children. assigning the min value to n left child of 99 exists. going deeper no left child. returning 60 removing 60 from the right subtree 60 &lt; 99 going to left child n has no children. removing 60 Line reads delete deleting value 26 26 &lt; 60 going to left child 26 &gt; 22 going to right child n has no children. removing 26 Line reads insert inserting new value 104 104 &gt; 60 going to right child 104 &gt; 99 going to right child 104 &lt; 110 going to left child n == NULL inserted 104 as left child of 110 Line reads insert inserting new value 158 158 &gt; 60 going to right child 158 &gt; 99 going to right child 158 &gt; 110 going to right child n == NULL inserted 158 as right child of 110 Line reads insert inserting new value 18 18 &lt; 60 going to left child 18 &lt; 22 going to left child 18 &gt; 16 going to right child n == NULL inserted 18 as right child of 16 Line reads insert inserting new value 9 9 &lt; 60 going to left child 9 &lt; 22 going to left child 9 &lt; 16 going to left child n == NULL inserted 9 as left child of 16 Line reads delete deleting value 22 22 &lt; 60 going to left child n has two children. assigning the min value to n no left child. returning 104 removing 104 from the right subtree n has no children. removing 104 Line reads delete deleting value 99 99 &gt; 60 going to right child n has two children. assigning the min value to n left child of 110 exists. going deeper no left child. returning 7738096 removing 7738096 from the right subtree 7738096 &gt; 110 going to right child 7738096 &gt; 158 going to right child n == NULL. return Level order: 60 104 7738096 16 7737328 158 110 9 18 7737328 158 In order: 9 16 18 104 7737328 60 158 7738096 7737328 110 158 Pre order: 60 104 16 9 18 7737328 7738096 158 110 7737328 158 Post order: 9 18 16 7737328 104 158 7737328 158 110 7738096 60 
Here is the file that it reads from: insert 56 delete 200 insert 22 insert 99 insert 26 insert 110 insert 99 insert 16 insert 60 delete 56 delete 26 insert 104 insert 158 insert 18 insert 9 delete 22 delete 99 
&gt; friend class BstNode; Do you intend that BstNode have access to BinarySearchTree's private members/functions, or that BinarySearchTree have access to BstNode's private data? BstNode doesn't look like it has a lot of private stuff. &gt; BinarySearchTree::BinarySearchTree(string inFile) Is there any reason you're doing all your work in the constructor of the class? &gt; insert() This works. I didn't think it did, but it seems to be pretty good. The only thing it does weird is if you insert a number that's already in the tree, it will not be added to the tree, but the number of nodes will still be incremented. &gt; remove() Yup, this is a weird one. I'll add a comment after this to help with some examples of &lt;what this code does&gt; vs &lt;what this code should do&gt;. (Are you allowed to use wikipedia as a reference? Because that's usually a good resource if you're having trouble with an algorithm.) &gt; void BinarySearchTree::levelOrder() const This works. &gt; inOrder(), preOrder(), postOrder() These work. &gt; findMin() This works. I'm not sure why you're passing a BstNode by reference just to take it's value, though. Any reason this doesn't just take a pointer like the rest of the methods? &gt; getHeight() This works. &gt; if(root == NULL) { &gt; insert(atoi(line.c_str()), NULL, NULL); &gt; } &gt; else { &gt; insert(atoi(line.c_str()), root , NULL); &gt; } If root is null, isn't insert(atoi(line.c_str()), root , NULL); the same as insert(atoi(line.c_str()), NULL, NULL); ? 
As you can see from the tree traversals it's getting crazy high numbers from somewhere when the remove function is called 
Yeah, you're right. That would be the same. 
I have a pretty good conceptual grasp of the algorithm, but I can't seem to translate it into code
Okay, question for you about remove(): You're passing `prev` around, but you never use it. Was there a reason why you wanted to have the current node's parent available? Did you want to do something to it?
So, it appears you have discovered the joys of reading from freshly `delete`d memory! These exceptionally high numbers come because you followed a pointer to a BstNode that you had already deleted. This usually means you haven't done enough cleanup on your pointers before returning from the remove function.
I used it in a previous try and neglected to take it out. It's been quite a day. Sorry man.
Want bonus points in Bug Reporting 101? Put a preOrder printout in the loop of readFile. It will show you/us the transformation of the tree as we insert/remove nodes. Hopefully, we can follow along and show the first time when the tree gets out of sync.
You actually want it there. `Prev` is the parent of `n`. If you `delete n`, prev-&gt;leftChild or prev-&gt;rightChild (whichever one n was) now points to deallocated space, and "spooky things" happen (like getting 7738096 out of the tree, when you never put 7738096 in)
Oh so that's why. What exactly do I do with prev then?
If you're following along with the wikipedia code, there is a replace_node_in_parent() function that you haven't implemented. It could have something to do with that.
One of the bits I didn't understand was: if new_value: new_value.parent = self.parent In my implementation, new_value would be an int, so I don't really know how this would go for me.
Alright. So I've got the case where the current node (n) has two children. How does this look? if(n-&gt;hasTwoChildren()) { temp = findMin(n-&gt;rightChild); n-&gt;value = temp-&gt;value; remove(temp-&gt;value, temp, n); } Specifically, I'm a little iffy on the last statement.
Okay, back to replace_node_in_parent void BinarySearchTree::replaceParentNode(BstNode* newValue, BstNode* n, BstNode* parent) { if(parent != NULL) { if(n == parent-&gt;leftChild) { parent-&gt;leftChild = newValue; } else { parent-&gt;rightChild = newValue; } } //I'm guessing since I don't keep a parent data member in BstNode, I don't need anything beyond this }
Actually, that last line *is* wonky. You want to remove the value from the right child, with n as its parent, not from temp, with n as its parent - n isn't the parent of temp - it could be a grandparent, great-grandparent, or something more distant. Remember, your code has the assumption that prev is the parent of n. If you pass temp as the argument for n, and the current n as the argument for prev, then you had better have a reason to know that temp is n's direct child. If you wanted to remove temp's value from the rightChild's tree, you could pass rightChild instead. You know rightChild is n's right child, so you can guarantee the parent/child relationship 
Like this? remove(n-&gt;rightChild-&gt;value, n-&gt;rightChild, n); And I apologize if I fail to grasp things; it's so late.
Looks right. Now you just have to call it
What value did you want to remove from the right child's tree? Not the right child itself, right? You were removing the right thing earlier, just from the wrong place.
That was my best interpretation of the pseudocode at lease. The default argument threw me off a little.
Right. I changed it above.
So: void BinarySearchTree::replaceParentNode(BstNode* n, BstNode* parent, BstNode* newValue) //I'm confused about what the parameters for this function should be. I set newValue as NULL by default in the prototype . . . else if(n-&gt;leftChild != NULL) { replaceParentNode(n-&gt;leftChild, n); //I'm not entirely sure what goes here } else if(n-&gt;rightChild != NULL) { replaceParentNode(n-&gt;rightChild, n); //or here } else { replaceParentNode(NULL, n); //and especially not here }
The first snippet is the header for replaceParentNode and the second one is the code in remove where I make the calls to replaceParentNode
Why c++ chose &amp;&amp; both for lvalue and universal reference?
But ~ is only doing the bitwise NOT, not reversing it: the MSB has to become the LSB...
The slides won't work with firefox on os x.
That seems to be the case with Firefox on Windows too. I uploaded a pdf copy at http://bayfiles.net/file/TLFT/JBg4l0/What%E2%80%99s_New_in_Visual_Studio_2013_for_C%2B%2B_Developers_%28slides%29.pdf However, you might be able to download the slides or print pdf with Firefox though. edit: Channel9 presentation for the topic http://channel9.msdn.com/Events/Build/2013/2-305 (1 hour 2 minutes)
I can't wait for Bjarne's keynote. I wish I could go in person, but semester would have started for me.
ah, reverse, not inverse. Ok. Thanks. 
replaceParentNode() takes three parameters: 1. The node that you want to replace (your code calls it n) 2. That node's parent (called parent) 3. And a node to replace that node with (your code calls it value) If you replace a node with NULL, you've effectively deleted it from the tree. (you still need to free its memory with delete, but the tree no longer has that node in it). You really only have to do this for one particular case, and your code was actually freeing the memory properly already. If you replace a node with its own left child, you remove that node from the tree, but maintain everything about the tree. You lose the right tree, but if the right tree is NULL, there is no loss. (Same thing happens for the right tree) The code snippet you are unsure of basically means: "I'm at the node I want to remove. I want you to replace my left child with NULL (the default replace parameter) (by the way, that node's parent is me)" You want it to be closer to: "I am the node I want to remove. I want you to replace me with my left child. (by the way, my parent is &lt;my parent&gt;)" (I had to change parameter order a bit to make it fit English phrasing a little bit better. Hopefully the meaning is clear)
You are doing your own C networking, but I don't see any signal handlers. What happens if you receive a signal that interrupts your library?
Why would you take the name of a popular SQL library (SQLite) but just spell it differently?
I took a brief look at some of the source. C++ written like C. No copy constructors, assignment operators. Passing by raw pointer when a reference would suffice. 
[Uhhh, dude...](http://sqlite.org)
&gt;#if defined(_WIN32) || defined(_WIN64) The _WIN64 is superfluous.
This is not a very good API. Here are some things I take issue with: * Why `connect`? What is an unconnected SQL client? It’s an object that shouldn’t exist. Hence `connect` should be replaced by the constructor. Uninitialised connections should not exist, they weaken the type system (= make it harder to reason about the state of the object). I know `std::[io]fstream` offer the same but that’s a mistake in hindsight. If you need to signal a connection error, throw. * Likewise, `disconnect` makes no sense since it doesn’t even signal error. Remove it and use the destructor instead. For the same reason `reconnect` and `is_connected` should be removed. * The callback type should be either a template argument or `std::function`. Don’t use C-style callbacks. The `userdata` argument is unnecessary; C++11 offers closures. * Merely offering to return unparsed JSON is very low-level but okay; it’s a lightweight client after all, and can be hooked up to a JSON parser effortlessly. * But wwy offer a `json` function that doesn’t return its value, rather passing it via an out parameter? By its name and by logic, `json` should *return* the result. Need to signal failure? No worries – use exceptions or `boost::optional&lt;std::string&gt;` as the result type. *Do not* use out parameters. * The API **must** offer a means of be accepting queries in a type-safe manner (à la `PreparedStatement`). Only accepting a raw string is inacceptable. As it stands, your library invites SQL injection attacks which are one of the most common and most serious security holes. A library which doesn’t offer this established mechanism of guarding against this attack is by design unsafe, and must not be used.
11 commits? This is weird for a project with more than 331k lines of code.
Xapian is a C++ search engine / indexing solution with bindings to every popular language and is much better designed and more robust and has been in proven commercial use since the mid-90's! And it is actually Object Oriented, not C code compiled with a C++ compiler like this one is.
not sure if trolling, or...
Perhaps you need the contents of the container to be modified in a different thread or function, but also need to retain the original contents.
thanks! fixed
I took it cos I wanted to. It's a lightweight mysql client, so sqlight sounds ok to me. Even if they sound similar search engines wont be confused, written words are quite different :D 
Yep, legacy code that I have yet to fix. Thanks for reminding :D
Thanks for the comments! Will do nothing though :D - I am against exceptions - I dont like my constructors to do voodoo magic every time I create an object, specially when dealing with collections - There is a json() function that returns json data, the one you are talking too is a workaround to avoid exceptions - Including boost defeats the purpose of 'lightweight' and self-contention However, - std::function is a good hint, will consider it thanks :D - Prepared statements are another good hint, will consider it for next revision. thanks :D 
:D
:)
Regarding dynamically allocated objects (wrapped in smart pointers): Aside from the mentioned non-optimal memory usage there's another - in my eyes very important - issue: The *quantity* of living objects usually is higher compared to using scope-bound lifetime, and humans (and developers ;)) only can keep in mind a limited amount of distinct things. And worse overview equals worse code quality. (Red's conjecture? ;))
But consider something like `std::vector` which can look and feel entirely stack-based, yet internally stores on the heap. This seems like a nice compromise for a lot of scenarios, and is the premise behind the handle/body idiom. Dynamic allocation can be there for where it makes sense, but there tends to be too much desire to jump to it. 
I guess as an example, consider a vector&lt;Foobar*&gt; in C++98 versus a vector&lt;Foobar&gt; in C++11 where Foobar has move semantics. The code will naturally simplify itself, the presence of dynamic allocation disappears in client code, and you get roughly close to the performance of the C++98 version. You, of course, lose dynamic polymorphism; and to support that is where the "Sutter" position comes in. 
Yes, I agree with both points. But I'm sure the skill of standard library authors is way higher than the average programmer's, and how often do you really need custom abstract data types that can't be realized with using the well-tested and tweaked standard types?
Fair enough. I think you're touching on who each "titan" is speaking to. Sutter seems to be targeting advice for application programmers, and Stroustrup tends to advise system programmers. I'd like to think, though, that the "right" answer lies somewhere in between. 
Sometimes people write blog posts where they answer a question posed in the title. If someone was to see such a title and answer the question without even reading the blog post he'd seem a bit foolish. Especially if his answer is the very first one posed by that blog. 
I've watched loads of talks by both authors and never got the impression that Sutter recommended smart ptrs when stack allocation was viable. Just the opposite in fact.
&gt; Prepared statements are another good hint, will consider it for next revision. thanks :D I often go for factory methods instead of heavyweight constructors. However, in your case I wouldn't mind the constructor opening the connection.
By library, do you mean the standard library?
boost::variant/any doesn't allow programming to an interface on the polymorphic object the way inheritance does.
SQLite is a trademark, and confusingly similar. 
The point where you need `enable_shared_from_this`, let alone the point where you forward every object construction through a variadic templated method, is the point where I beg for you to discard `shared_ptr` and use a simple intrusive reference count. 
I won't disagree with that, but 'shared_ptr' is a standard and generic feature. I'd not like to see a program that uses both 'shared_ptr' and an intrinsic counting mechanism. It'd get even more confusing.
More confusing than that magical create static function in every class you ever want to instantiate? (Which, incidentally, prevents you from creating true protected/private constructors, as well as forbidding `make_shared`.)
&gt; Obtaining a ‘shared_ptr’ from ‘this’ is possible using the ‘enable_shared_from_this’ class. It would be a good idea to explain why saying `shared_ptr&lt;T&gt;(this)` in a member function is an exceedingly bad idea. [Well-known things aren't universally known.](http://xkcd.com/1053/) &gt; Beware an ugly implementation detail that renders their natural use somewhat unsafe: the ‘shared_ptr’ itself is not automatically created. That's not an "implementation detail", it's a law of nature. No object can create *itself*. &gt; void register_service( shared_ptr&lt;service&gt; ); Like `vector`, `shared_ptr` should be passed by const reference to pure observers. &gt; This requirement is unfortunately never checked: if the object is not owned by a ‘shared_ptr’ no compile-time, nor run-time error will be generated. The code ventures into the land of undefined behaviour. "Unfortunately"? It's *good* that the Standard doesn't mandate checking, just like `vector&lt;T&gt;::operator[]()`. Note that implementations are free to perform checking, e.g. in debug mode. (In practice, calling `shared_from_this()` on a non-shared object should fail noisily, although I haven't verified this.) &gt; auto good = service::create(); I can tell you wrote this snippet without compiling it, because `create()` wasn't marked `static`. (It is marked in the next snippet.) &gt; don’t suspect much is lost; the purpose of ‘make_shared’ is a small memory optimization. It's not "small". `make_shared&lt;T&gt;()` combines two dynamic memory allocations into one (and similarly for the deallocations). That saves space (internal allocator overhead) but also saves time, because allocating memory is relatively expensive (as far as pure computation goes - of course the disk and the network are way worse). Reduced space consumption *also* helps performance due to locality. (If your `make_shared&lt;T&gt;()` implements the We Know Where You Live optimization, the space consumption is further reduced, although that is most significant for small objects.) &gt; I would hope that marking a class ‘enable_shared_from_this’ is also enough to get the same optimization. No! No! No! I'm sorry to scream, but this demonstrates a complete lack of understanding of how `make_shared` and `enable_shared_from_this` work. It is totally, totally impossible for `enable_shared_from_this` to activate the `make_shared` trick of combining the refcount control block and the object into a single allocation. `make_shared` can do that because it constructs both simultaneously. As soon as you independently say `new T` outside of `shared_ptr`'s implementation, this "fusion" opportunity is lost. It's worse than that, actually. Far from improving performance, `enable_shared_from_this` has nonzero cost. In particular, it injects a `weak_ptr` into the object (this is not mandated, but strongly implied by the requirements, and it's what everyone does). That increases the object's size by two raw pointers. This post doesn't mention a useful trick for "granting friendship" to `make_shared` (which is admittedly an unsolved problem; the LWG may think about this in the future). Specifically, if you make your constructor public, but taking a private tag type, then you can give such a tag to `make_shared` while preventing anyone else from using it and therefore the constructor. Finally, the **second most important rule** for using `enable_shared_from_this` isn't mentioned here (the most important one is that the object must be owned by a `shared_ptr`). Specifically, you must derive from `enable_shared_from_this` *exactly once* and give it the *most derived type* of the object.
Hmm, I think I have to retract the bit about `enable_shared_from_this` not being able to fuse the allocations. I believe an implementation could _also_ put a refcount control block into `enable_shared_from_this`, then have traditional `shared_ptr` construction use that, and have `make_shared` also detect it and not glue on another. VC's implementation does not attempt to do this. My other objections stand, though! :-&gt;
Using `enable_shared_from_this` is actually a better idea than hand-rolled refcounting. `shared_ptr` does a ton of useful stuff: * It respects derived-to-base conversions. * It uses atomic operations to achieve the usual thread safety guarantee. * It permits "aliasing", where you can get a `shared_ptr` to a data member that shares the outer object's refcount. * It has `weak_ptr`, and implementing *that* while respecting multithreading is nontrivial.
&gt; It is totally, totally impossible for enable_shared_from_this to activate the make_shared trick of combining the refcount control block and the object into a single allocation. make_shared can do that because it constructs both simultaneously. As soon as you independently say new T outside of shared_ptr's implementation, this "fusion" opportunity is lost. Which is frustrating, because it's possible in theory (you just need the two reference counts embedded in any class that derives from `enable_shared_from_this`) but greatly hindered by the fact that you can't call the destructor of the base object without destroying your `enable_shared_from_this` implementation.
Isn't the problem there that you destroy your control block as soon as you want to destroy the object, making `weak_ptr` the sketchiest thing in the standard library?
Yeah - at a minimum, the Standard's object lifetime rules would have to be dramatically bent. ~enable_shared_from_this would have to avoid scribbling over its bytes, hoping that weak_ptrs could still observe/modify the refcounts, until the death of all weak_ptrs finally destroys the control block and deallocates the memory. It might be permitted but it would be very very squirrelly.
&gt; It respects derived-to-base conversions. What's the technical limitation here for intrusive refcounts? &gt; It uses atomic operations to achieve the usual thread safety guarantee. Intrusive refcounts can do this as well. It's not even that hard (though trivial to fuck up). &gt; It permits "aliasing", where you can get a shared_ptr to a data member that shares the outer object's refcount. This, while legitimately cool, is something that I have never personally needed and also find somewhat suspect (witness the awesomeness that is java.lang.String, with a shared char array such that you have fast substrings but the ability to leak arbitrarily large amounts of memory). &gt; It has weak_ptr, and implementing that while respecting multithreading is nontrivial. Sure, it's not a replacement for the whole kit and caboodle. `shared_ptr` plus `weak_ptr` have many things going for them. (`enable_shared_from_this` is not one of them—it's an unfortunate implementation detail.)
No technical limitation, it's just more machinery to implement.
&gt; Specifically, if you make your constructor public, but taking a private tag type, then you can give such a tag to make_shared while preventing anyone else from using it and therefore the constructor. 100% this is my favorite pattern for working with enable_shared_from_this. class foo : public enable_shared_from_this { struct HiddenStruct{}; public: foo(HiddenStruct){}; static shared_ptr&lt;foo&gt; Create() { return make_shared&lt;foo&gt;(HiddenStruct()); } private: //Copy/Move Assignment and construction } Elegant, simple, no long distance friendships, nothing the consumer has to know beyond "the only way to compile code that makes a foo is to use foo::Create()". As a library dev, the less I have to trust the users of my library to do right, the better. The sad news is that we use VS2012 still and are thus unable to use those beautiful variadics you laid out. I look forward to upgrading to 2013 for them. 
&gt; Finally, the second most important rule for using enable_shared_from_this isn't mentioned here (the most important one is that the object must be owned by a shared_ptr). Specifically, you must derive from enable_shared_from_this exactly once and give it the most derived type of the object. Thank you. Very few people say this.
&gt; Like vector, shared_ptr should be passed by const reference to pure observers. As you said 'well known things are not universally known'. Please enlighten me why shared_ptr should be passed by const ref in that case? Because passing it by const ref doesn't increment the refcount. I know that increasing the refcount is pretty expensive but isn't increasing the refcount what I want in this case when I call register_service()?
&gt; you must [...] give it the most derived type of the object Is there a reason for this other than the need to cast? In other words, would the following snippet using `std::dynamic_pointer_cast` introduce a bug? class Base : public enable_shared_from_this&lt;Base&gt; { // Base stuff }; class Derived : public Base { // Derived stuff }; int main() { auto derived = std::make_shared&lt;Derived&gt;(); auto sameDerived = std::dynamic_pointer_cast&lt;Derived&gt;( derived-&gt;shared_from_this() ); }
There are two reasons. First, the Standard says you have to do it, so you get undefined behavior if you don't. Second, this is a physical consequence of how `enable_shared_from_this` is implemented. Remember that it secretly injects a `weak_ptr` into the class (so it can know where its control block lives, without keeping itself alive). You could do that yourself, but `enable_shared_from_this` is special because the Standard Library knows about it and can automatically set that `weak_ptr` when the object is given to a `shared_ptr` (either through traditional construction or `make_shared`). But *how* can the Standard Library set that internal `weak_ptr`? It needs to ask the question, "hey, X, do you derive from `enable_shared_from_this&lt;X&gt;`?" It has to ask this question for a specific type and it can ask only once, so it's going to use the most derived type of the object.
why does he consider the the handle/body idiom the antithesis of smart-pointers? Am I missing something?
I tried to be careful by saying "pure observer" but this is a subtle issue. Strings and vectors are a simpler case. Imagine you've got some function that only cares about the length of a string. This is a "pure observer" - it is examining some property of the string but it's not interested in copying the string's data. In this case, it is unambiguously proper to write `foo(const string&amp; s)`. Writing `foo(string s)` is unnecessarily inefficient, because that will trigger unnecessary copies. `shared_ptr` has a nontrivial copy constructor - the atomic increment isn't exactly *expensive* (certainly not like a dynamic memory allocation and N element copies), but it's more than an ordinary increment and it certainly isn't free. There's no reason to invoke it more often than necessary. If you have an object owned by `shared_ptr`, transitioning back to the "raw pointer domain" with `.get()` is verbose and potentially dangerous (I consider such transitions somewhat scary and I prefer to minimize them). So you might pass that `shared_ptr` around even when you don't need to *share* the object. This is especially useful when having an empty `shared_ptr` is meaningful to functions. So you could easily have a function that takes a `shared_ptr`, tests if owns an object, and if so examines some property of the object - all without ever wanting to copy the `shared_ptr`. In this case, `const shared_ptr&amp;` is the right thing to use, just like the string case. When a function *is* interested in copying the `string` or `shared_ptr`, that's when move semantics come into play. Ultimately, the most efficient thing is to overload on copies versus moves, and a somewhat efficient thing is to take by value and then move (this results in a copy+move or move+move). If you ignore moves completely, writing code like C++98, then taking const references and copying results in one copy, while taking by value and then copying results in either two copies (horrible) or move+copy (worse than a copy). Basically if you aren't going say `std::move()` then you don't want to be taking by value. In general, the only things I take by value are scalars (integers, floating-point, pointers, etc.) with very rare exceptions (e.g. when I really want a local copy to modify).
Yes, the type erasure library in boost lets you define an interface.
[N3690](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3690.pdf) is the latest Working Paper. The Standardese is 20.9.2.4 [util.smartptr.enab]/7: "`shared_ptr&lt;T&gt; shared_from_this();` `shared_ptr&lt;T const&gt; shared_from_this() const;` Requires: `enable_shared_from_this&lt;T&gt;` shall be an accessible base class of `T`. `*this` shall be a subobject of an object `t` of type `T`. There shall be at least one `shared_ptr` instance `p` that *owns* `&amp;t`." This is somewhat less explicit than I'd prefer (my spidey sense says that there is a Library Issue here), but the bit about "*owns* `&amp;t`" strongly suggests it's talking about the type given to the `shared_ptr` at the time of its original acquisition of ownership. I don't think it's even physically possible to deal with multiple `enable_shared_from_this`es, although template argument deduction could probably be used to ask the question for a single `enable_shared_from_this&lt;Unknown&gt;`. I believe that the Standard should not require implementers to do that, though. We have to tolerate a lot of crazy nonsense from users (overloaded `op&amp;`, `v.emplace_back(v[0])`, cats and dogs living together) but we have to draw the line somewhere!
Yes, this is another apporach I actually use. The problem with this one is that you can't use the default constructors, you always have to write your own which include the HiddenStruct parameter.
I think "unfortunately" is a valid concern about this feature. Failing to create the shared_ptr is a very simple mistake to make. Most other places in C++ the lack of safety is very apparent, you are doing casts, calling new, or taking addresses. With 'enable_shared_from_this' the users of your class have no easy way, at instantiation point, to realize that the class has been marked as such. Additionally, code which worked prior to it being marked as such can suddenly break, without compile time warnings. Very few other C++ features can so easily break code while looking so unassuming. I understand why the limitation is there, as it is implemented now. A cleaner solution would probably require a semantic change in the language.
People are not search engines.
Oops. For some reason I thought it was a self post, more fool me...but ya can't get fooled again.
That code made me cry.
Looks like that would be `boost::type_erasure::any` rather than `boost::any`. It doesn't appear to let you limit the contained object one one of a particular set, i.e. a type that would otherwise be in the inheritance hierarchy. It seems to allow any type that implements the declared interfaces. Also, in my quick look I didn't see how one would convert a variable from a type that only specifies a base interface to a type that specifies a more general interface, mimicking a downcast or double dispatch (e.g., like with the visitor pattern) in an inheritance hierarchy.
Care to elaborate?
I guess it depends on where you are in the stack. In a library, that is an extra 10 minutes to make sure that your consumers can use your class in a sane way. Always worth it. In an application, then maybe your class won't be reused and you can get away with being lazy.
When I am initializing something with a shared_ptr argument, I usually take by value. In my head, the shared_ptr move constructor/assignment are ~4 register set instructions and thus are extremely cheap. It is very nice to give the caller the choice of passing by lvalue or rvalue which is obtained by taking by value. Likewise, I have taken to taking unique_ptrs by value. This is nice in all cases where you want to unconditionally take over the unique_ptr. There is no chance that the calling scope will keep ownership, whereas if you take by rvalue reference then it actually matters what the function implementation does with regards to the content of that pointer when it returns. In my opinion, the function signature should tell you ~90% of what you need to know about what a function does. 
&gt; I assumed the nodes were closed, and case based. It sounds like you're not familiar with the particular domain that the article writer is working in. As further evidence of that, in another comment you said "I'm not quite sure what a type tree is exactly" when the author expanded on one example of what he's using covariant return types for. Perhaps there are better solutions than the inheritance based polymorphism that is one of the traditional solutions in this domain, but I'm not sure you're going to be able to provide them with only the understanding of compiler implementation that comes from reading descriptions of the problems in this thread.
I'm guessing the amount of raw pointers being thrown around and the passing of things like std::vector by pointer. It also looks like there are bugs in the code, e.g.: the very first code snippet, `OutputBinderParameterSetter` has an `std::vector` passed by pointer that has an `is_null` (???) field set to some custom bool type. It seems like the use of templates here is a bit misguided and could be cleaned up considerably by using normal function overloading. Why is `OutputBinderParameterSetter` a templated class? This thing has no state and could just be a function. It doesn't take advantage of its template parameter to do anything other than specialize, which makes it superfluous.
&gt; When I am initializing something with a shared_ptr argument, I usually take by value. In my head, the shared_ptr move constructor/assignment are ~4 register set instructions and thus are extremely cheap. Move construction is two raw pointer copies and two raw pointer assignments to null, which is very cheap. It's copy construction that involves atomic operations. &gt; Likewise, I have taken to taking unique_ptrs by value. There's no performance concern there, because `unique_ptr` is movable-only (and it's the size of a single raw pointer).
This guy really needs to redo them in a pentatonic scale... Or in Dorian so it sounds kinda like wild jazz.
Hey there, blog author here. &gt; I'm guessing the amount of raw pointers being thrown around and the passing of things like std::vector by pointer. Yeah, I'm mostly doing this because Google's C++ standards recommend against sending non-const parameters by reference, and instead recommend sending by pointer. I'm not really sure if what I'm doing is better. I do send around a `MYSQL_STMT` by pointer, but that's because I was lazy and didn't want to wrap it in a class because it didn't really seem relevant to the rest of the post. &gt; the very first code snippet, OutputBinderParameterSetter has an std::vector passed by pointer that has an is_null (???) field set to some custom bool type. You're right, that was a typo on my part. I'll fix it. The `my_bool` type is a type defined by the MySQL C API; it's probably just a typedef of char or something. &gt; It seems like the use of templates here is a bit misguided and could be cleaned up considerably by using normal function overloading. I think you're right here. For some reason, I thought that you couldn't partially specialize templated functions. I started out trying to define overloads instead of doing this ugly pattern, but I ran into some problems that I don't quite remember right now. I think that once I found that this pattern worked, I just used it overzealously in the rest of my templates. I'll go back soon and see if I can clean those up. Thanks for the feedback!
I approve of this.
I think he'd really have to limit how many notes there were in it then. 
Will now use LSD radix sort because it looks/sounds the coolest. 
I absolutely agree. My article is meant to do nothing more than present one option for working with enable_shared_from_this.
From http://msdn.microsoft.com/en-us/magazine/dn342867.aspx &gt;The Windows Runtime defines a new remotable string type to replace the traditional BSTR string type, and any class identifiers need to be provided using this new medium. The HSTRING, as it’s called, is far less error-prone than BSTR, chiefly because it’s immutable. The simplest way to create an HSTRING is with the WindowsCreateString function. WindowsCreateString allocates enough memory to store a copy of the source string as well as a terminating null character and then copies the source string into this buffer. To release the backing buffer you must remember to call WindowsDeleteString, unless ownership of the string is returned to a calling function. This is classic WinAPI, and it makes my bloody blood boil. I don't understand why Microsoft doggedly refuses to create and/or teach C++ wrappers to simple remotable classes like these that use RAII and are refcounted/scoped to all but eliminate the pain and liability of manually managing memory like this. It drives me nuts (glaring at you BSTR) and I haven't ever seen a justification for it that makes sense. 
I don't think this (Edit: t being considered an lvalue) is supposed to be the case outside of argument deduction, which isn't happening inside 'struct ref'. static_cast&lt;T&amp;&amp;&gt; should be equivalent to static_cast&lt;int&amp;&amp;&gt; here, which should cast 't' (which is an lvalue, as you said) to an rvalue.
Yeah, you're quite right. template &lt;class T, class U&gt; T&amp;&amp; forwardish(U&amp; u) { return static_cast&lt;T&amp;&amp;&gt;(u); } template &lt;typename T&gt; struct ref { ref(T &amp;&amp; t) : t(static_cast&lt;T&amp;&amp;&gt;(t)) {} int value() { return wat&lt;T&amp;&amp;&gt;::value(forwardish&lt;T&gt;(t)); } T &amp;&amp; t; }; Having an rvalue reference variable doesn't preclude having to have an rvalue, hence why it has to be squished through a return. 
So why the hell isn't x an lvalue? It should be. It works with auto, auto&amp; and auto&amp;&amp; as well. My money is still on this being a gcc bug.
Is this is for REST clients only?
https://en.wikipedia.org/wiki/C%2B%2B11#Range-based_for_loop
damn, missed that one. Thanks, that totally solves the problem, with auto and all.
The Linux version of Casablanca uses ASIO under the hood. So I wonder why MS would go out of their way to use their own old and cruddy APIs in the windows versions, when they could simply use the better designed and more modern ASIO API and in turn support the current C++ networking proposals. http://casablanca.codeplex.com/SourceControl/latest#Release/src/http/client/ 
Curiously, if you wrap the int in a struct... struct Int { Int(int i) : i(i) {} operator int() { return i; } int i; }; int main() { Int i(3); return uni(i).value() + uni(Int(13)).value(); } ...then GCC accepts the program. Why it should treat int differently, I don't know. EDIT: formatting.
Sweet, will keep that in mind. That's a really educational video too, thanks for that. Emplace is going to be useful, if only it also returns a reference to the newly placed (and created) element, or would that have made extra performance cost? p.s the coincidence with your name and your work is quite amusing
Too bad it's hosted on sourceForge. SF is now famous for their malware installers. Even though this project hasn't opted into malware, everyone will assume they have.
They recently added `http_listener`, which you can use to create an HTTP REST server. http://casablanca.codeplex.com/wikipage?title=HTTP%20Listener&amp;referringTitle=Documentation 
I tried porting Casablanca to Mac OSX twisting it to use the Linux namespace/macros. After a couple of hours tweaking XCode settings, no real progress. There are a lot of desktop Macs that could use a native REST library (think linking all those Apple native desktop productivity apps with SharePoint) - shame MS went for Linux first. I like and we use Boost Asio in several parts of our core products too. Anyone had any luck with Casablanca on Mac OS X?
Sure, one gradually improves their code over time, they don't intentionally "retard" it - right ?
It's a pity they're still going down the text lex/search avenue, when most viable options have moved on and begun doing static analysis for real by using clang as a backend. To many false positives as it is now with modern c++ code, and it's only going to get worse with more uses of auto/constexpr et al. 
also http://en.cppreference.com/w/cpp/algorithm/for_each
[You haven't heard](http://www.ghacks.net/2013/07/17/sourceforges-new-installer-bundles-program-downloads-with-adware/)?
Slides (PDF): http://www.pvv.org/~oma/UnspecifiedAndUndefined_ACCU_Apr2013.pdf
&gt; In C#, we have things like FxCop to alert you when you've written something against best practices, etc. Is there something like this for C++? There's a number of [static analysis tools](http://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis#C.2FC.2B.2B). I'm not sure how good any of them are and if they say anything about best practices. &gt; I don't really use any of the C++11 smart pointers right now (I'm much more focused on the DirectX bits of my engine working), but are they something you should be using whenever you create a pointer to something? Yes, smart pointers are wonderful. The terrible thing about raw pointers is that they express no ownership at all. Let's say you use a library that returns a pointer to an object to you. How do you know what you can and should do with this pointer? Are you responsible for destroying the object? Does the object even need to be dynamically deallocated? If, on the other hand, the library returned a `std::unique_ptr`, that means it's passing unique ownership to you. It doesn't care about the object any more, it's yours. When the `std::unique_ptr` you have goes out of scope, the object is points to will automatically be deallocated. With smart pointers, you should never need to use `delete` - the smart pointer manages this for you. When you want to pass a `std::unique_ptr` elsewhere, you have to `std::move` it, since copying it would mean it wasn't unique any more. This forces you to be explicit when you want to pass ownership on. That's just one example but you can find lots of articles and Stack Overflow posts about it. &gt; What about memory management within functions? e.g. if I create a std::ostringstream inside a function, do I need to delete it before the function returns? It depends how you create the object. You need to understand that there are multiple ways to create objects, each giving the object a different storage duration. For the most part, you should be creating objects with automatic storage duration, which is what happens with declarations like so: int x; std::ostringstream ss; Automatic storage duration means that the objects will be destroyed when they go out of scope. This usually means at the end of your function. An alternative is to create objects with dynamic storage duration. You do this with `new`: int* x = new int(); std::ostringstream* ss = new std::ostringstream(); Note that the *pointers* `x` and `ss` have automatic storage duration. They are just normal variables that will go out of scope and be destroyed. The objects that they point at, however, are the ones with dynamic storage duration. They will not be destroyed at the end of the scope. They need to be manually destroyed with `delete`: delete x; // Deletes the object pointed to by x delete ss; // Deletes the object pointed to by ss You generally want to avoid using dynamic allocation yourself, and C++11 goes a long way to help you do that (especially with smart pointers!). The major problem with it is that you have to keep on top of manually deallocating all of your objects. It's very easy to end up with memory leaks this way. &gt; I assume when a program exits with live objects they're cleaned up by the OS, so is it necessary to delete objects that are only ever dereferenced when the program exits (e.g., an ID3D11Device)? Yes, in pretty much all cases, the OS will clean up any remaining resources when your process ends. It is a good practice to make sure you clean up everything that needs it (anything dynamically allocated). &gt; Also, exceptions can be hard to decipher. Is there a way to somehow make them more useful? You'll have to be clearer with this question. What is hard to decipher about them? &gt; When you write a function prototype in a header, you have to go back to the cpp and manually enter in the signature. Why doesn't Visual Studio update function sigs in the .cpp/.h file automatically? It doesn't seem like it's a difficult task so I'm wondering if there's a good reason this isn't implemented. It's always a massive pain-in-the-ass to me to create a new class because I end up writing more than I feel I need to. Is there an extension or something that will update the .cpp file to match the .h? I don't use VS, so I'm not sure. Does it not provide a smart way to edit both function names at the same time? If this kind of refactoring tool is not available, it might be because C++ has a pretty complex grammar and it would be difficult to implement well.
&gt; if I create a std::ostringstream inside a function, do I need to delete it before the function returns? A general rule of thumb is that if you created it with `new`, you're responsible for disposing of it with `delete`. If you just declared it as a regular local variable it will be automatically destructed when execution leaves the scope it was defined in. If you're coming from C# you're probably greatly overusing `new`. Avoid it. Get used to value semantics. Use containers from the standard library, and use smart pointers. Manually trying to keep everything in your head and remembering what needs to be freed when is a losing proposition, especially when you start to learn about exception safety. (If you have a manual `delete` call at the end of a function you can still leak memory if an exception is thrown before the `delete` statement was reached. It is absolutely essential that you arrange for resources to be automatically managed through RAII and not manually.) &gt; Why doesn't Visual Studio update function sigs in the .cpp/.h file automatically? They aren't necessarily always the same. The declaration might omit variable names, for instance, and the definition might have additional annotations such as `__declspec(dllexport)` that aren't present on the declaration. You can avoid some of the hassle by writing member functions inline, and there are some patterns where the internal guts aren't exposed in the public header at all (opaque pointers/pimpl pattern.) 
&gt; If something is absolutely not supposed to happen, and continued operation of the program is dependent on it, throw an exception. Than remember to catch it somewhere. Bad advice. Don't catch such exceptions. Allow your program to terminate and capture the dump for analysis. &gt; For instance, in a game engine you wouldn't want to have any function accidentally copy a texture that is already loaded. To prevent this, you keep a vector of std::unique_ptr's and just pass along a pointer with the .get() function. Games absolutely do not need this extra overhead. It's not difficult to manage your graphics pointers without resorting to smart pointers.
Actually, exceptions are for recovery, so if you detect an unrecoverable error, you shouldn't even throw. You should die instantly through `terminate()` or your "less subtle error handling technique" of choice. &gt; Games absolutely do not need this extra overhead. It's not difficult to manage your graphics pointers without resorting to smart pointers. `unique_ptr` is literally zero overhead in space and time. `shared_ptr` is the one with small but nonzero overhead.
Regarding the right way to use smart pointers: http://herbsutter.com/2013/06/05/gotw-91-solution-smart-pointer-parameters/ 
Smart pointers are pretty much essential. It's like driving with a seatbelt: optional, but horrible things happen when you have an accident without using it. Consider the following: Foo* ptr = new Foo(); foobar(); delete ptr; While this looks safe, consider what happens when foobar() throws an exception. The stack frame unwinds before 'delete' is called. Using at least unique_ptr&lt;&gt; here protects you from this circumstance since it behaves like a "guard", and deletes foo *when it leaves the scope*. This includes when an exception is thrown: unique_ptr&lt;Foo&gt; foobar(new Foo()); foobar(); // foobar is automatically cleaned up &gt;What effect do orphaned objects have on a running program other than increasing memory usage? That depends on design. The concern of managing an object's lifecycle is really about resource management, with memory being one of several kinds of resources available. Windows is very "handle-happy", and gives you handles to do all kinds of stuff - talk to input devices, perform file i/o, drawing to the screen, etc. It also expects your program to return those handles when done, or else they can leak. If you're depending on object destruction to free those resources (not unusual), "orphaned" objects become a huge problem.
&gt; Really, does it say that in the standard? The Standard generally doesn't tell people how to write good code. &gt; I find them useful for various things, including termination. They can be used for control flow too, but that doesn't make it a good idea. &gt; You can even gather helpful debugging information and place it in your exception, to help you diagnose the problem. You can gather that information, log it, and terminate. If you throw, you're potentially executing destructors and giving someone the chance to catch. &gt; Assuming you know at the "throw" site that it's not a recoverable error... This is true. Throwing exceptions for potentially recoverable errors is fine, even if some callers consider them unrecoverable. In fact, `bad_alloc` is the best example of this. &gt; Have you proven that, or are you just assuming? I, uh, maintain a `unique_ptr` implementation (and though I didn't write it, I do know how it works). It was carefully designed for zero overhead. &gt; std::vector is a great example What? `vector` has obvious overheads (although not terribly large ones). For example, it must track both its size and its capacity, even if they never differ. And famously, `vector`'s geometric reallocation policy implies that continually inserting elements results in some amount of unused capacity at the end (although it is easy to see that on average it is not worth worrying about). &gt; and so is BOOST_FOR_EACH. I don't know what that expands to; C++11 range-for has superseded it, and it is zero-overhead. In fact, it is potentially faster than the way many people write for-loops (as it captures the end iterator instead of repeatedly evaluating the end-expression; I have heard one report where this made a difference in practice).
I'm going to watch every minute of this tomorrow. Thanks for the link! Mostly because I'm new to C++ in some way (I've understood some of the basics for quite a while but I've never actually written anything worthwhile in C++) and I *love* learning about all the interesting things it can do. The C++11 spec for whatever reason made me feel more "at home", like it had evolved to a language with an easier-to-use standard library. That said, I find it incredibly frustrating having to deal with LPCSTR/LPCWSTR/etc. when we have standard strings now... I keep wanting to write my own conversion functions between the aforementioned types but I feel like there must be some reason they don't exist already. C++ has been around so long that whenever I feel like I've come up with an easy solution to a problem that requires several lines of code to implement that I'm somehow doing things wrong. I used to not care for C++, but since embarking on this game engine project, I've come to like it.
Also in that example you are trying to delete the type, not the variable.
DirectX objects are usually reference-counted, so there's less need for the STL smart pointers in their case. For the OP: there are times when you want to go beyond the usual object lifetime rules. For example, many use per-frame arenas, which are large chunks of memory from where objects are allocated when needed and everything is deleted in one go. But this doesn't work too well with smart pointers and the C++ object lifetime.
Smart pointers aren't *that* mysterious. Of course, if you use shared pointers without any sort of idea what the lifetime of your object is, or who might own it, you're in for a bad time. Shared pointers aren't a way to avoid designing your software. But if you have well defined lifetimes, almost any C++ solution can work great.
What's the overhead on smart pointers compared to regular pointers?
&gt; No, not even a throw in the constructor will leak memory, because it still calls the destructor. This is not true. Any base classes, already constructed, will have their destructors called; but the class under construction does not call it's destructor on exception. #include &lt;iostream&gt; #include &lt;stdexcept&gt; using namespace std; class Obj { public: Obj() { clog &lt;&lt; "Obj()" &lt;&lt; endl; throw logic_error("Purposefully throw during construction"); } ~Obj() { clog &lt;&lt; "~Obj()" &lt;&lt; endl; } }; int main() { try { Obj x; } catch(logic_error &amp;e) { clog &lt;&lt; "Obj constructor threw exception" &lt;&lt; endl; } return 0; } And the output: $ make temp &amp;&amp; ./temp clang++ -ggdb3 -O2 -Wall -Wextra -std=c++11 -Wfatal-errors -c -o temp.o temp.cc clang++ -pthread -rdynamic -lcppunit -o temp temp.o Obj() Obj constructor threw exception No "~Obj()" means no destructor. Constructors should be written with atomicity in mind -- either they completely succeed or they completely fail. Do not write constructors that can partially construct; if you meet an exception condition tidy up everything you've done so far in that constructor. Even better, avoid writing constructors that throw.
&gt; exceptions are for recovery Exceptions are not for recovery specifically. Nor are they for any of the other purposes raised in the replies to you. Exceptions are specifically for one thing only: separating the generator of an exception from the handler of the exception. It's almost never the case that the part of the code that discovers the exceptional situation knows how to handle it. It doesn't know if the application considers it recoverable or not; nor how to log, if any; nor how to recover, if possible. That being said, this is not true either... &gt; Bad advice. Don't catch such exceptions. Allow your program to terminate and capture the dump for analysis. _Always_ throw an exception, if the caller wants that to terminate, then they'll have indicated that by not catching. 
Do you have any idea as to when his new edition with C++11 additions will come out? I've been holding off on getting it until then.
There have already mentioned static code analysis. I suggest that in addition to try our [PVS-Studio](http://www.viva64.com/en/pvs-studio/) tool. It is more [powerful](http://www.viva64.com/en/b/0151/) than the analyzer in VS.
Pretty much this. All the other advice in this thread, while good, will probably just confuse someone who is not familiar with C++.
&gt; No, not even a throw in the constructor will leak memory, because it still calls the destructor Wrong, only a *completely constructed* object will call its destructor. /u/kingofthejaffacakes already alluded to the case of derived classes, but worse, any composed object can run into the situation of a partially-constructed object. Using raw pointers here is simply a **very** *bad solution*. Don’d use it, use a `std::unique_ptr` or a direct object instead. There’s a very simple rule to follow: raw pointers must never own memory.
Out of curiosity -- how does `std::reference_wrapper` tie into this (i.e., what are the respective overheads in comparison)? Both when compared to regular reference and when, say, storing in a container -- e.g., `std::vector&lt;unique_ptr&lt;Base&gt;&gt;` vs. `std::vector&lt;reference_wrapper&lt;Base&gt;&gt;`?
`reference_wrapper` stores a single pointer, so as far as the machine is concerned, it's just like an ordinary reference. `vector&lt;unique_ptr&lt;X&gt;&gt;` and `vector&lt;reference_wrapper&lt;X&gt;&gt;` are both vectors of pointers, but the latter doesn't manage lifetime. (As a result, copying/moving a `reference_wrapper` is just a pointer copy.)
&gt; I find it incredibly frustrating having to deal with LPCSTR/LPCWSTR/etc Could this library help? http://dx.codeplex.com/ (and an article about it: http://msdn.microsoft.com/en-us/magazine/dn201741.aspx ) 
From personal experience - this book is highly regarded in the games industry. When John Carmack discussed his jump from C and Obj-c to C++ for Doom 3, he said that he wish he had read Effective C++. Also, [Carmack's and id's style guide](ftp://ftp.idsoftware.com/idstuff/doom3/source/CodeStyleConventions.doc) is priceless.
I also recommend Scott Meyer's books, Effective C++ and More Effective C++. A lot of these recommendations are included in the rule sets for the common static analysis tools. His C++11 update should be available later this year - but that's no excuse to not buy the current releases (available pretty cheaply used) 
Thanks!
I actually picked up Bjarne's book last week and have been reading it. Not a good intro for someone who has never touched C++ before, as he just dives right in, but hot damn am I learning cool stuff.
Without throwing from constructors, how else can you signal an error cleanly? You can set some internal flags or something, and then the user can poll them through member functions, but then you're just writing C with classes, where each object constructed must then be checked with a bunch of if's.
Welcome home. C++11 introduced three new smart pointers: * std::unique_ptr&lt;T&gt; which expresses unique ownership: it can be moved but not copied. * std::shared_ptr&lt;T&gt; is a reference-counted smart pointer that deletes it's data when there are no more references to it, and * std::weak_ptr&lt;T&gt; which can be used to break cycles of std::shared_ptr&lt;T&gt;'s. 
&gt; Without throwing from constructors, how else can you signal an error cleanly? True enough. I guess I've just not often found the need to have constructors throwing anything -- just initialising member variables wouldn't generate exceptions. If you're acquiring resources, then it's true that that acquisition can fail, but often you're configuring an object through more than just its constructor. Resource R; R.setName("name"); R.setThreshold(x); R.setMode(Resource::MODE_2); R.open(); I like this style because it makes the object configuration self-documenting versus Resource R("name", x, MODE_2); This is a similar style to Qt's [design philosphy](http://qt-project.org/wiki/API-Design-Principles). See particularly "The Convenience Trap" section.
Aha! This does look really useful. One of the questions I didn't ask was why there weren't more helper methods for some of the 'standard' things that require a bunch of lines of code, e.g. creating a ID3D11Device. This will help greatly. Also I've been learning DirectX 11 with the help of a very good book but it uses the DirectX SDK which no longer exists and is superseded by the Windows SDK, so things like the math libraries I have to update in my head when reading the book. Some of the code in there will give me a good idea of the *right* way to write some of the helper methods I would like to reduce a ton of redundant code (creating UAVs/SRVs, etc.). Thank you for this! DirectX is in a weird position right now where many books, tutorials, and online articles reference code that worked with the DX SDK, but as I'm writing for the latest and greatest (which is in the WinSDK) some things don't work quite right or use still valid but outdated methods, such as effects.
&gt; Automatic storage duration means that the objects will be destroyed when they go out of scope. Ah, see this is something I was unsure of. I "knew" that in C++ there was no real GC, so you had to manage memory yourself, but I wasn't sure if the runtime knew to destroy objects that have lost scope.
Ooh, and as it turns out I can get that book online for free through work. Thanks, I'll get reading that ASAP.
[Visual Assist X](http://www.wholetomato.com/) has refactoring tools for C++ that can do that kind of thing. ReSharper is [adding C++ support](http://blogs.jetbrains.com/dotnet/2013/06/resharper-to-support-c/) soon, though I don't know their timeline.
My understanding is that *Effective C++11/14* is going to be an entirely new book, not a new edition. If that's the case, I'd consider it more of a third volume in the *Effective C++* series (along with *More Effective C++*). If you're a C++ programmer, I wouldn't hold off. They are still relevant and will help you write better code.
So basically like object variables in Java, but explicitly defined? I'm sure I'll be using them too often though, probably due my old habits. In fact, even when I code in Java I think of how I would do it in c++. Nice to see that they're making pointers easier, though. It'll help new guys.
Fuck, I misremembered that. If you do `X* foo = new X();` and the constructor throws then `*foo` will not leak. But the same is not true for subobjects that are initialized with `new`.
Using old tools is incredibly corrosive.
I was a little scary on the title, but now I'm happy that VC 2008 is not on the list. Most likely I will continue using VC 2008 for several years. 
YES! remove the support, they can use an older version of boost if really needed.... this will make devs lives much easier
No reason to drop VS 2008 unless they were dropping C++03 support entirely, and there's no way that's happening anytime soon. The proposed new minimum requirements are still a decade old.
Upgrading a project to a new tool chain might be corrosive to its wallet, though. There are many projects that neither get nor deserve the maintenance to make them easily transferrable to a new compiler. It would just be the interseciton of low maintenance and needing new boost features that is odd. OTOH I've learnt long ago that one shop's odd is the other's best practice - and neither of them is wrong. 
Just curious, why are you still using VC 2008?
Using gcc 4.8, clang 3.2 and VS2012 at work. If you have resources available to keep updating boost versions in your projects, surely there must be some scope to be upgrading you build tools as well. Old compiler version = old boost! Here's to the future!
Yeah that is why I don't recommend Bjarne's book.
If your code doesn't work out of the box with a new version of your compiler, the problem is usually your code. In C++ I never encountered a situation in which code of mine didn't work anymore because of this; only ever because of a new library-version or a new standard (a library stopped working (make_pair&lt;int, int&gt; in the code is not nice…)).
Yesbut: Even if the problem is in code, it's not necessarily *my* code. It may be in a 3rd party library that has long ceased to exist. A 3rd party library might be provided source-less as .obj or .lib - or as a .dll with a heap-sharing API, all of which commonly break with a new compiler or linker. A toolchain consists of more than just a compiler, e.g. your automated build, automated generation of IDE project files or other artifacts may be broken. The new compiler might come with utilities that break other processes, see e.g. the SQLite amalgamation problem under even newer Visual Studio versions. I bet there's a notable number of projects still on VC6, because changing to "new" for loop variable scope ma break silently and noone is willing to take that risk. Even if the problem is in my code, the risk or cost to fix could be prohibitive. 
Sure, but in those cases the project can stick to using the old tool chain. This is just removing support for old compilers in upcoming versions of boost. If you are using an old version of boost with an old tool chain there's no reason why the code wouldn't work anymore.
That sample code is sufficiently weird to make me wary of what otherwise looks like a fairly nice library. I'd also consider CLI test suite filtering to be a required feature for a test runner, which it appears to be missing.
Lambdas, within lambdas, within lambdas doesn't strike me as "friendly". I've recently started using [cppunit](http://sourceforge.net/apps/mediawiki/cppunit/index.php?title=Main_Page); and after a bit of a learning curve, this is my standard template for simple modules... #include &lt;stdexcept&gt; using namespace std; class Obj { public: Obj() { throw logic_error("Purposefully throw during construction"); } ~Obj() { DestructorCalled = true; } static bool DestructorCalled; }; bool Obj::DestructorCalled = false; #ifdef UNITTEST // --- cppunit #include &lt;cppunit/TestFixture.h&gt; #include &lt;cppunit/TestSuite.h&gt; #include &lt;cppunit/extensions/HelperMacros.h&gt; // Runner #include &lt;cppunit/ui/text/TestRunner.h&gt; #include &lt;cppunit/TextOutputter.h&gt; // ---- class ObjectTest : public CppUnit::TestFixture { public: // --- Prepare void setUp() { } void tearDown() { } // --- Tests void testConstruction() { Obj::DestructorCalled = false; CPPUNIT_ASSERT_THROW(Obj x, logic_error); // FACT: Destructors are not called when a constructor throws CPPUNIT_ASSERT_EQUAL(false, Obj::DestructorCalled); } // --- Auto-generate suite() convenience function CPPUNIT_TEST_SUITE(ObjectTest); CPPUNIT_TEST(testConstruction); CPPUNIT_TEST_SUITE_END(); }; // Add result of AxiomsTest::suite() to test registry CPPUNIT_TEST_SUITE_REGISTRATION(ObjectTest); // -------------- main() #ifndef UNITTESTALL #include &lt;iostream&gt; #include &lt;stdexcept&gt; int main() { // --- Boilerplate cppunit code // Set up runner to run all test in registry CppUnit::TextUi::TestRunner runner; runner.addTest( CppUnit::TestFactoryRegistry::getRegistry().makeTest() ); // Redirect output to clog, runner.setOutputter(new CppUnit::TextOutputter(&amp;runner.result(), std::clog)); // Run all and give success indication try { return runner.run() ? 0 : 1; } catch( std::exception &amp;e ) { std::clog &lt;&lt; "EXCEPTION: " &lt;&lt; e.what() &lt;&lt; std::endl; return 254; } catch( ... ) { std::clog &lt;&lt; "EXCEPTION" &lt;&lt; std::endl; return 255; } } #endif #endif This is just a simple example to show that destructors aren't called when constructors throw. Most of that is boilerplate -- it took me a while to work out what boilerplate was necessary, but now I have it's just a cut-and-paste job for every new module. Hopefully that's helpful to someone.
Where I work, we have 3rd party dependencies for which VC 2008 is the latest supported compiler. That's usually one of the big holdups for us.
As I said, the intersection between "need new boost" and "need old toolchain" is odd. Still, it might very well be that there's a siginificant number of projects sitting in that ugly spot. Telling them it's their fault for being so crappy won't help anyone - chances are they already know. I've listed in another reply some reasons that could pin you to an old compiler while you still might want to use newer boost in another corner of your program - *all of which I encountered one way or another*. I'd bet there are many more reasons out there, some better. I'm *not* saying boost should still support old compilers; rather: probing your community and making your actions dependent on the response is good. In the end it's a question of how the world is vs. how it should be. 
Here: Does what we need, upgrade does break several script, and it always seems to make sense to wait for the next visual studio version before shelling out the money. Make no mistake: I'd *kill* for `auto` and delegating constructors alone. However, moving ~1MLoc is never without trouble, and the tangible effect for users of this product are far fetched. 
I work with very VERY old code using vc6, the situation you describe isn't true in all cases. Now I wish it was, don't get me wrong, I curse a lot because of it. 
I really cant see why people using really old compilers cant stick to using old versions of boost. Who out there is using gcc 3.2, which is a decade old, but needs cutting edge boots libraries? If you are maintaining your code on an old compiler, you can use an old library.
&gt; And the longer you wait the harder and more expensive it will get. Arguably, one three-version upgrade can be cheaper than three one-version ones. But for us it's simply lack of available resources -or, in other lingo "better things to do". 
This is why I try my hardest to avoid these libraries at all costs from the outset - even if it means using an inferior alternative or re-implementing large portions of it. I'd rather pay the cost of redevelopment early on than late in the project's lifecycle.
This is really interesting and an example of how far you can push the language. However, I've spent a little while reading the examples and the readme and still don't feel I really understand what those examples would do. I guess that this is one of the risks of going too declarative.
The company I work at has a ~90 project C++/C# solution, with roughly 2 million lines of code total, 90% C++, 10% C#. Using 2013, with these 'performance improvements' it completely fails to build the solution, every single attempt. It runs into all sorts of threading problems where it starts trying to link things together before ever finishing building them. The only way I can sometimes get it to build is if I go into the options and drop the build down to use only a single thread. Which makes build times horrendous. Taking someone else's advice on here, I downloaded the "Enhanced Mitigation Experience Toolkit" and used it to disable ASLR, made no difference at all, didn't help. After screwing us over with C++11 support in 2012, and deciding to just release (not even) the rest of it in a new IDE version, and supplying a system that just straight up fails to build a C++ solution, there's no way our company will upgrade past 2012. Not to mention the complete screw ups over the last year with dropping XP support multiple times through bugs that made it seem like that functionality wasn't tested at all. (Our 2012 system still has bugs supporting XP, the Connect bug reports are still open and haven't been updated in months). If anyone has anymore suggestions for what I can try to get it to build I'll at least give it a shot, but I'm really not that into it anymore. 
You did an excellent job IMO. Keep it up!
Agree. Remove support for VS 2012 too. Its support for C++11 is pathetic.
In my case we need to be able to compile on slse10 for one customer, thus old-ass gcc, but another customers only have boost 1.53 installed.
Good thing it's just a preview and not production code yet, huh? 
Herb sutter gives great advice. I highly recommend reading all of the "Guru of the week" posts (gotw). New ones for C++ 11/14: http://herbsutter.com/gotw/ Old ones: http://www.gotw.ca/gotw/ 
You may send me email lishao at microsoft dot com so that we can investigate more on your issue.
I'm not so biased against macros, but I think macro-ing away the brackets is pretty heinous. An auto-formatter would likely lose your indent and then there would be little indication that there was control flow going on here. C++ programmers expect to see brackets in ifs, loops, and such, so why hide away from them what they expect to see? And what kind of name is "sloopvec?" I'd also remark that there is a long tradition of macros being name IN_ALL_CAPS
That's great, but what is then the Connect page for? Isn't this the place VS bugs are supposed to be reported?
I'll definitely give it another shot when the final build comes out. I've always tried out any VS previews/RCs as soon as they come out, and none of them in the past have acted up as much as 2013 is, so we'll see how it turns out.
I'm currently about to start working on a project that requires a good understanding of concurrency in c++ and this seems really helpful, thanks a lot!
Looks interesting, I'll give it a good look later. In the meantime, he might pick a couple of clues from this one here since it's quite good and fast to write for (header only): https://github.com/philsquared/Catch There's other interesting articles about unit testing frameworks and comparisons from that guy or linked on his site. A feature bandit seems to need (unless I'm missing something) is running specific tests.
yeah, at least write xpost from /r/programming or something... 
It's hard to predict what will stop being supported. I mean, I do my best to stick to established libraries, but sometimes you just gotta use something off the beaten path.
Oh, I'm not saying we shouldn't go off the beaten path. Only that we should consider the implications of the library we're using needing a particular ugly feature, and avoid them when possible.
The standard has this to say about `static_cast` in section 5.2.9, paragraph 2 (emphasize mine, "B" and "D" are Base and Derived class, respectively): &gt; If the object of type B is actually a subobject of an object of type D, the result refers to the enclosing object of type D. **Otherwise, the result of the cast is undefined.** So no, it's not legal and therefore not portable. It might work in a pinch though, if you are in a really tight spot where you have to call a protected function in badly designed third-party code.
~~Only if `MyClass` is copyable, though.~~
MyClass does not need to be copyable. MyDerivedClass only holds a reference to the original object. 
I think derivation will not work if MyClass has private constructor. It can be created by some factory method like MyClass* MyClass::make(). This also apply on my original example.
There are a few ways you can fix this: 1. [Create a new project as a Win32 Console Application](http://msdn.microsoft.com/en-us/library/vstudio/46e82t5z(v=vs.100\).aspx) 2. [In settings, change sub-system to Console and find where it says Entry Point and enter 'main' (I'm assuming that's what you're using)](http://msdn.microsoft.com/en-us/library/f9t8842e(v=vs.100\).aspx) 3. [Replace `int main` with the standard `WinMain` entry point](http://msdn.microsoft.com/en-us/library/windows/desktop/ms633559(v=vs.85\).aspx)
Is this really supported? I'm getting ` error C2248: 'MyClass::myMethod' : cannot access protected member declared in class 'MyClass'` from VS2013's compiler.
As Nimbal said, this is not legal. However, you can use a derived class to return a member-function pointer to the function in question from a static function, and call that with a MyClass instance to legally access a protected method. class MyDerivedClass : public MyClass{ public: typedef int (MyClass::*FnType)() const; static FnType get_myMethod() {return &amp;MyClass::myMethod;} }; MyClass c; (c.*MyDerivedClass::get_myMethod())(); 
Protected members are not publically accessible through the instance. You can only access protected members through a derived class or a friend.
Sorry to wake up an old thread, but this is absolutely the right answer. The usual motivation for sticking with an old compiler is that it is a dependency for an old codebase. So you have the cost of moving to a new compiler for your project, vs the dislike of maintaining support for an ever growing list of tools on the part of the library maintainer. In the end, the situation is neatly resolved by sticking with the older versions of stuff until you're prepared to upgrade everything. Besides, this is the internet: where everything is archived and available forever, since it's really cheap to do so. I'll also add that the reality of working on "supported" libraries only makes sense as a preference if the library maintainers publish updates on a timescale that's useful to your product. If your product will become obsolete or unsupported before the next version of boost comes out, what difference does it make if you use an unsupported library or not?
It's not just CVs that can be bothersome. There are also times where you'd really like to favour a conversion over a generic function. Lame example: template &lt;typename T&gt; std::string get_name_of (T&amp;&amp;); struct Greeter { template &lt;typename T&gt; void greet (T&amp;&amp; thing) { std::cout &lt;&lt; "Hello " &lt;&lt; get_name_of&lt;T&gt;(std::forward&lt;T&gt;(thing)) &lt;&lt; std::endl; } void greet (std::string name) { std::cout &lt;&lt; "Hello " &lt;&lt; name &lt;&lt; std::endl; } }; int main() { Greeter().greet("World"); } Here you have 4 options to get to the std::string function, as I see it: 1. Use std::enable_if + std::is_convertible to disable greet(T&amp;&amp;) for anything convertible to std::string. Doesn't scale well with many overloads. 2. Introduce an intermediate type, e.g. a Name class. Scales well, but tedious for simple cases. 3. Add a user-defined literal for std::string, remember to use it. Only works for literals. 4. Add a has_stringy_name trait of some kind. Disable the generic based on that. Scales reasonably well. Probably the right approach.
Don't forget about Scott Meyers' recommendation. Write *one* `greet` function that takes a universal reference. From there, dispatch to one of two helpers based on the result of `std::is_convertible&lt;U, std::string&gt;()`. That's the correct approach here, IMO.
It would be rather difficult to write copy constructors and such if you could not access protected members of other instances. What you can't do is access protected members of instances of your superclass, even though you can access them in instances of your own class.
I don't know what it is, but something has gone horribly wrong when passing in a parameter requires such an unbelievable amount of complexity. And then what do you do with two parameters? I have found next to no performance penalty for simply passing by const reference for functions that simply observe a value, and passing by value in cases where a cheap move constructor exists. The interface stays simple, there's no concern for any ticking time bombs as mentioned in the article, it just works out nicely. For example with MSVC2013 and GCC 4.8, I thought that maybe passing an std::string by value would be less efficient because it would involve doing two moves instead of one, for example: struct X { std::string m_value; X(std::string value) : m_value(std::move(value)) {} }; struct Y { std::string m_value; template&lt;typename S&gt; Y(S&amp;&amp; value) : m_value(std::forward&lt;S&gt;(value)) {} }; ... And then using it like so: // Two moves get performed here. std::string s1 = "hello world"; X x(std::move(s1)); // Only one move gets performed. std::string s2 = "hello world"; Y y(std::move(s2)); As it turned out both approached yielded the same performance, if there is any difference between them it would be so incredibly minute it's not noticeable.
Hmm, maybe, but it has a kind of hacky switch-casey feel to it I don't really like
Oh sure. Nobody is saying this is beautiful. Choose your poison, or use Haskell. ;-)
 int main() { char dt = '\1'; long tdt; tdt = -dt; printf("%ld\n", tdt); } The above code should always print -1 whether char is signed or unsigned. I don't know why the article says otherwise. Both signed and unsigned char will be converted to int, which can represent both 1 and -1 just fine and then it will be converted to long, which can also represent -1 just fine. Edit: excluding the case where char is unsigned and both char and int have the same size, in which case the char will be converted to unsigned int and negating that will have the value UINT_MAX, which may cause implementation-defined behaviour when assigned to a long.
&gt;You argue for passing by const reference, but your code passes by value. I argue no such thing. My argument is pass by const reference if all you do is observe or if a move operation is expensive (such as std::array), and pass by value otherwise. That way if someone wants to copy their parameter they can do so as they did in C++03, and if they want to move their parameter they can use C++11's std::move like in my example. In my post I give example of struct X and struct Y. My argument is that struct X is the preferred option despite the fact that in theory it is performing two moves instead of one. &gt;it would have forced a copy, which (if std::string isn't using the small-string optimization, or "hello world" doesn't fit), would force an allocation. And passing by value forces a copy when passed an lvalue. So, either way, it's inefficient in some cases. That's why I benchmarked it, because sure in theory this may be the case, but in practice this isn't what is happening. The reason why I benchmark is because I simply came to the conclusion long ago that it's futile to think I know how C++ compilers work, how CPU architectures work, and all the nitty gritty details about what happens behind the scenes. I can make some hypothesis about what happens but without an actual benchmark that's pretty much all it is, a weak assumption with no actual evidence backing it up. It turns out in many more cases than I had originally assumed the compiler already gets rid of unneeded copies, an optimization that was part of the C++03 standard but which actually happens quite often. In addition it seems that the cost of two moves is the same as the cost of one move in the example I provided with struct X and struct Y. Now perhaps that's because the compiler simply eliminates one of them, or maybe the CPU architecture can run them in parallel, or some other thing that I fully admit I'm ignorant of, but the point remains that some optimization is taking place that avoids the need to write a whole bunch of template metaprogramming to get the same performance but risk having a ticking time bomb in production code, something you say you observed happening.
&gt; My argument is pass by const reference if all you do is observe or if a move operation is expensive (such as std::array), and pass by value otherwise. That's pretty good. I think you're wrong about `std::array`, though. Moving one is potentially far more efficient than copying one. Imagine a `std::array` of `std::vector`s. Element-wise move is going to be *way* better than element-wise copy. The big caveat to your advice is this: if you're writing generic code, there is no way to know whether a given type has an expensive move operation, or will acquire one in the course of maintenance. Do you then take everything by const reference, and give up move semantics? Try writing an optimal `std::pair` without perfect forwarding. It's not possible without *even more* template hackery. A lot of library code needs to be this general, so the issue is real. &gt;&gt; it would have forced a copy, which (if std::string isn't using the small-string optimization, or "hello world" doesn't fit), would force an allocation. And passing by value forces a copy when passed an lvalue. So, either way, it's inefficient in some cases. &gt; That's why I benchmarked it, because sure in theory this may be the case, but in practice this isn't what is happening. IIUC, what you benchmarked was taking a `std::string` by value. What I was saying was that if you took it by const reference and benchmarked again, you'd see a perf hit. You're right, in the case of `std::string`, two moves isn't going to be noticeably worse than one. And you're 100% right about benchmarking. I'm glad to see someone who takes that seriously. Your rule of thumb is very good, though, and is exactly right when the types are known and under your control. But the rules change when writing generic code.
use the terminal instead of the xcode console http://forums.macrumors.com/showthread.php?t=656032
I wonder if some day in the near future, rvalue references will be considered a bad move. It has increased the complexity of reasoning about the most trivial code - argument passing and assignment - only to provide a way so that (facetious exaggeration) `push_back` and return by value maybe sometimes eventually don't copy if you are lucky. While I'm happy that something is happening with C++, it's this one thing that is far reaching and seems only partially understood. Maybe I am growing grumpy grandfather, leave me alone with your newfangled &amp;&amp; crap, C++ was good as it was. But if I learnt something in the last decade it's that you don't put something into a product that isn't fully understood and affects everyone out of the box. 
[here's](http://blogs.msdn.com/b/vcblog/archive/2009/02/03/rvalue-references-c-0x-features-in-vc10-part-2.aspx) a more in depth read on the topic.
Since the author usually claims how much emphasis being cross-platform has for him, it is still disappointing that there are no sources released.
What part of "Xcode" are you talking about? Do you mean the clang compiler? In a default Xcode "Command-Line Tool" project using the C++ option: #include &lt;iostream&gt; int main(int argc, const char * argv[]) { char c = '\b'; std::cout &lt;&lt; static_cast&lt;int&gt;(c) &lt;&lt; std::endl; return 0; } This compiles in Xcode 4.6.3 Clang-LLVM 4.2 and outputs '8' as expected. If you're trying to generate console effects in the Xcode output log... remember that Xcode's output log is a *log* not a console (despite Xcode's menus calling it a console) and outputting a \b to this log outputs an actual \0x08 character to the log.
You're mixing up std::vector and std::array.
You know this is ~~spam~~ a repost.
Well, its not the only thing I'm working on, and most of it is company code, which I plan to release later as GPL.
Yeah but it's a common misconception that C-style arrays are pointers, they are not. An array is a randomly accessible contiguous region of memory. Moving an array involves moving every individual element of that array.
That doesn't work for a few reasons, but primarily because deleted function still exist for the purpose of overload resolution. If they end up getting selected, it's an error. In this way, `=delete` is different than SFINAE.
Out of curiosity, why not [Boost Software License](http://www.boost.org/users/license.html)?
What the hell is CX?
Essentially.
"Component Extensions". It's a non-standard language extension, part of the MSVC compiler (VS2012+). It's Microsoft's way of projecting their new WinRT library into C++ more "naturally" than using the Windows Runtime Template Library (WRL), which feels more like ATL. Basically, if you've ever worked with Managed C++ or the newer C++/CLI, it's just like that, but compiles to native code rather than the CLR. 
My plan is to have a GPL/Commercial Licensing model, such as for example JUCE has. After all I have to make a living from my work, after all this project is just a testfield for my libraries which I plan to use for more commercial work later on.
So its not C++.
Right. It's as much C++ as C++ is C.
I've added the possibility to skip tests and specify subsets. It's on master only as I want to test on some more compilers first. You can specify that you want to skip tests by using 'describe_skip' and 'it_skip'. There's also the possibility to select what tests to run from the command line by using --skip=&lt;substring&gt; or --only=&lt;substring&gt;. These will skip or target matching describe/it that have matching substrings. 
It's a "superset" of C++, if you will. 
I understand where you're coming from. In the right hands, rvalue references are a boon, and everybody's code is more efficient because the STL is fully move-enabled. That's a win for rvalue refs, and it's nothing to be sneezed at. The downside is that journeyman programmers get a shiny new shotgun to play with. My advice would be to avoid rvalue references, unless you really know what you're doing and you have a darn good reason.
It's important to point out that that post was written before the standard was finalized and it describes an earlier version of the draft standard. There are a few important differences, notably the fact that rvalue references cannot bind to lvalues in C++11.
Fantastic book. I came here to suggest it if no one else had. I try to read it at least once every few years as a refresher.
Ha I remember doing stuff like this when I was younger. But this is not really the appropriate place. Maybe try the learn programming subreddit. Regardless, look at TIMES and step through it with a debugger. Or try something more interesting - perhaps use GetCursorPos and add a wobble to it when calling SetCursorPos. 
You'll have to use a time-related function and move the cursor to the position nonstop until the duration ends.
Yup. The GoF essentially organized and provided a formal, structured way to communicate these ideas that were present in the scene of programming, but abstract and nameless.
Singleton lololol
Yeah but the fact is that WinRT is basically COM. Suppose that you have some big business reasons to write a WP8/Windows Store app. Given the set of features it will have to offer you have to write a native app (no JS or .NET). The options are C++ and WRL or C++/CX. Given the options I think that using C++/CX at the boundary is the way to go (C++ and WRL is less productive, IMO).
The word you are looking for it codify.
You could make it work by not instantiating the derived class and using a static function: int myFunc(MyClass const&amp; mc){ class MyDerivedClass : public MyClass{ public: static int myDerivedMethod(MyClass const&amp; c) { return c.myMethod(); } }; return MyDerivedClass::myDerivedMethod(mc); }
He lost me when he mentioned "multi-polymorphism" without defining what it means. It sounds like "how to make C++ more like Lisp for Lisp programmers". If the audience is C++ programmers, then some examples would be nice.
Not an author, but I'm assuming when he talks about "the multi-polymorphism trick at run time" he just means "dynamic dispatch for multiple arguments". (Note that he's discussed an example of *static* dispatch for multiple arguments just before mentioning "multi-polymorphism" and then mentioned he wanted this at run time, hence the "dynamic" part.) So, in other words, the examples he's discussed (with templates and overloading) are what can be called "static multi-polymorphism", while multi-methods would be "dynamic multi-polymorphism". Does this help? Multi-methods are a (relatively) generally known concept in programming, although I haven't seen the particular term "multi-polymorphism" used before (could be just an informal, shorter way to say "multiple dispatch polymorphism", I suppose): https://en.wikipedia.org/wiki/Multiple_dispatch There's also more detail in the Stroustrup's paper (that's also mentioned in the next paragraph): http://www.stroustrup.com/multimethods.pdf
Well the thing is, this program already is at O(n^2) so I really would not like to make the query any larger than it is. So while this would be the easier option, it would only make the program less efficient, which is not what I'd like to do with a search engine lol. I'm writing a search engine from scratch for a school project(is this against the rules?)
They mean you should have implemented at least three [AbstractSingletonProxyFactoryBeans] (http://static.springsource.org/spring/docs/2.5.x/api/org/springframework/aop/framework/AbstractSingletonProxyFactoryBean.html) during your career.
One of the problems with multi-dispatch for me, or even existing operators generally, has been there's no simple way to express commutativity Consider: // Both Spaceship and Asteroid derive from SpaceObject bool collision_occurred (virtual SpaceObject&amp;, virtual SpaceObject&amp;); bool collision_occurred (Spaceship&amp;, Spaceship&amp;); bool collision_occurred (Asteroid&amp;, Asteroid&amp;); bool collision_occurred (Spaceship&amp;, Asteroid&amp;); collision_occurred (some_asteroid_as_object, some_spaceship_as_object) is now ambiguous... which is fine, expected, and a widely understood as a problem... but if there was a simple way to express that parameter ordering didn't matter then you could avoid defining additional forwarders and the dispatch table size could be reduced. e.g. bool collision_occurred (virtual SpaceObject&amp;, virtual SpaceObject&amp;) commutative;
Most search engines are "stateful" in that they keep their index active somewhere - most likely in memory, though some implementations could back it up to a disk with fast access times. They don't regenerate it from scratch on every query (imagine if google literally read in all of the internet every time you ran a search!) After all, if you're going to parse the source documents every time, you might as well just check for the words from query as you go, rather than creating the index.
MOCAMBO, There is nothing wrong with posting a school project, but it is better to mention that. To address your question, I think the best option is for you to add a check in the inner loop that has this line of code: document[i][j] = line2; Before executing that line of you, you need to be certain that line2 is not a stop word. Note that you will want to have already read the stop words file and put it in a fast look up structure. The best choices are probably a hash (std::unordered_set) or a sorted vector (roll your own or use boost::container::flat_set). The trade-offs here are constant time lookup (the hash) vs good locality (sorted vector). Given that you are likely to have relatively few stop words, I suspect the sorted vector is the better bet. Note also that checking for stop words is just one of the things you need to do with words in a search engine. For example you name need to lower case all words, remove punctuation, or otherwise "normalize" them. E.g. "Cars" =&gt; "car" and "house?" =&gt; "house". You will want to do this on both the words that you are indexing and also the query keywords, so this should be a function you reuse in both indexing and querying. This may allow you to remove parse_string_array(), but I'm not certain what it is trying to do, so I don't know. Here are some unrequested comments: Consider dynamic containers instead of fixed size arrays. Even if your current requirements specify a hard limit on the number of documents (for example) you'll need to know how to deal with dynamic containers in the real world and you'll find them not difficult with some practice. This would make your count_string() function pretty simple. Regarding your loop within a loop, there isn't any reason to read a line at a time. Just read a whitespace delimited word at a time. std::string word; while (input &gt;&gt; word) { text_pipeline(word); // Takes word by reference and normalizes it. If a stop word, clears it. if (!word.empty()) { index[file_id].push_back(word); // assumes something like: // std::unordered_map&lt;int, std::vector&lt;std::string&gt; &gt; index; } } Use RAII to close the directory. 
Eh - collision_occurred(Spaceship&amp; s, Asteroid&amp; a) { bang(); } collision_occurred(Asteroid&amp; a, Spaceship&amp; s) { return collision_occurred(s, a); } I think wanting to be able to specify commutativity is asking a bit much of the language. How would you extend it to 3 or more arguments, eg? 
Typos: Boost.Mixin focuses on maximal perofmance and minimal memory overhead If you're familiar with entitny-component-systems This is the way to call Boos.Mixin messages
In such cases it helps to look at the assembly output along with a benchmark---that way, you can see what the compiler is actually doing. I extended your example slightly and observed the assembly output using `g++-4.8` and `clang++-3.4` on OS X 10.8. ## C++ Source #include &lt;string&gt; #include &lt;utility&gt; struct a { std::string s; a(const std::string&amp; s) noexcept : s{s} {} }; struct b { std::string s; b(std::string s) noexcept : s{std::move(s)} {} }; struct c { std::string s; template &lt;class T&gt; c(T&amp;&amp; s) noexcept : s{std::forward&lt;T&gt;(s)} {} }; int main() { asm("# begin const ref"); std::string s1{"Hello, world!"}; a x{std::move(s1)}; asm("# end const ref"); asm("# begin value"); std::string s2{"Hello, world!"}; b y{std::move(s2)}; asm("# end value"); asm("# begin universal ref"); std::string s3{"Hello, world!"}; c z{std::move(s3)}; asm("# universal ref"); } Here are the relevant parts of the assembly output when the source is compiled with `g++ -std=c++11 -march=native -O3 -fno-rtti -fno-exceptions`. # Results for `g++-4.8` ## Using Const Reference leaq 16(%rsp), %rbx leaq 64(%rsp), %rdx leaq LC0(%rip), %rsi movq %rbx, %rdi call __ZNSsC1EPKcRKSaIcE leaq 32(%rsp), %rdi movq %rbx, %rsi call __ZNSsC1ERKSs ## Using Value leaq 64(%rsp), %rbx leaq 48(%rsp), %rdi leaq LC0(%rip), %rsi movq %rbx, %rdx call __ZNSsC1EPKcRKSaIcE movq __ZNSs4_Rep20_S_empty_rep_storageE@GOTPCREL(%rip), %rdi movq %rbx, %rsi movq 48(%rsp), %rbp leaq 24(%rdi), %rax movq %rax, 48(%rsp) call __ZNSs4_Rep10_M_disposeERKSaIcE ## Using Universal Reference leaq LC0(%rip), %rsi leaq 64(%rsp), %rdi leaq 15(%rsp), %rdx call __ZNSsC1EPKcRKSaIcE movq __ZNSs4_Rep20_S_empty_rep_storageE@GOTPCREL(%rip), %rax movq 64(%rsp), %rdi addq $24, %rax movq %rax, 64(%rsp) # Results for `clang++-3.4` ## Using Const Reference leaq -64(%rbp), %r12 leaq L_.str(%rip), %r13 movq %r12, %rdi movq %r13, %rsi movl $13, %edx callq __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6__initEPKcm leaq -88(%rbp), %r14 movq %r14, %rdi movq %r12, %rsi callq __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC1ERKS5_ ## Using Value leaq -112(%rbp), %r15 movq %r15, %rdi movq %r13, %rsi movl $13, %edx callq __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6__initEPKcm vxorps %xmm1, %xmm1, %xmm1 leaq -176(%rbp), %rdi movq -96(%rbp), %rax movq %rax, -160(%rbp) vmovaps -112(%rbp), %xmm0 vmovaps %xmm0, -176(%rbp) vmovaps %xmm1, -112(%rbp) movq $0, -96(%rbp) movq -160(%rbp), %rax movq %rax, -128(%rbp) vmovaps -176(%rbp), %xmm0 vmovaps %xmm0, -144(%rbp) vmovaps %xmm1, -176(%rbp) movq $0, -160(%rbp) callq __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEED1Ev leaq -208(%rbp), %rbx ## Using Universal Reference movq %rbx, %rdi movq %r13, %rsi movl $13, %edx callq __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6__initEPKcm leaq -240(%rbp), %rdi movq -192(%rbp), %rax movq %rax, -224(%rbp) vmovaps -208(%rbp), %xmm0 vmovaps %xmm0, -240(%rbp) vxorps %xmm0, %xmm0, %xmm0 vmovaps %xmm0, -208(%rbp) movq $0, -192(%rbp) Results for `g++` and `clang++` on Linux were very similar to those on OS X. Results for `icpc 14` on Linux were similar to those of `g++`. # What's happening? I don't have time to write the explanation right now, but I'll come back and write it in a few days if someone doesn't get to it before I do.
Would definitely be interested to hear your insight.
Please use /r/cpp_questions for posts like this. :) Good luck with your project.
Thanks, that explains a lot. I understand the problem now. I would love to see an example of a situation where it becomes a real issue. I wrote some matrix classes a long time ago (back when C++ compilers weren't capable of the level of optimization needed to make the template class approach any better than simply having a single "matrix" class and using overloading in special cases), so his example got me interested. However, I don't see how multi-methods would make that particular case any easier or simpler. I wonder if you need to view objects in a lisp-ish kind of way to run into the problem, or if there are any realistic examples of where it would actually be useful. Edit: Ok, I wrote this before reading Stroustrup's paper. That clears things right up. I can see the use case now.
Not to break in on the OO parade here but... What's the point of using variadic templates in a non generic way? If I wanted to write a matrix add function that would add two matrices together, I wouldn't write 15 different operator+ overloads that differ in only how many elements they add; I would use variadic templates to write a function that can add an arbitrary number of matrices of arbitrary dimension together (as long as their dimensions are the same, I.e all 3x3 squares). After reading Stroustups paper on multimethods posted by mttd, I have to say I'm convinced. I'm just widely skeptical of why OO guys would want to do this much work to keep everything OO and dandy in C++11 when generic support is better than ever now, especially with upcoming concepts and axioms.
Yes... forwarders, but consider that polymorphism requires reference parameter types, of which you have 3 types (&amp;, const&amp;, &amp;&amp;). A two parameter function therefore has 6 possible overloads with just a homogeneous type (e.g. Asteroid), or 30 with just two types (Asteroid and Spaceship.). Even with a commutative keyword you only reduce that to 3 and 15, respectively. This is without supporting pointers. We have Boost.Operators already for a reason.
I don't get it. Why would you ever want to implement both the string&amp;&amp; and the const string&amp; variant? Isn't the pass-by-value variant as good in both cases? Seems like just more code to me..
Just to elaborate, these patterns include well-understood idioms like iterators, Singletons, Factory, Bridge, Adapter, Observer, Model-View-Controller, double-check lock, thread pool, and a whole slew of others. The book could be considered a catalog since it contains reference implementations of many ubiquitous patterns, but I would say it's more of a guide for identifying any design patterns in software and giving you a way to communicate them. 
In one sentence? [Missing language features](http://c2.com/cgi/wiki?AreDesignPatternsMissingLanguageFeatures). 
Surprised that it doesn't mention one of the most useful parts - that std::set takes an optional second template parameter for the type used for the comparison. We use it at work in some places, it allows us to do comparisons with certain structures that we can't use &lt; for, for a couple of different reasons.
Regarding tail recursion: If you read the blog post, you'd think that it's one of the big features that's missing here. What's interesting then is the fact, that Clojure, although being a functional language, has no "proper" tail recursion, too, because the JVM it's running on doesn't support it. Look how Clojure is [doing it](http://clojure.org/functional_programming#Functional%20Programming--Recursive%20Looping). Kind of funny to have a *loop* "label" and a *recur* "goto" that jumps to the label. But this trick is working quite well and thousand of people are implementing their tail recursive algorithms this way. I'm sorry if this is kind of off topic, but I stumbled upon this and found it interesting nevertheless.
 if ( a.x &lt; b.x ) return true; if ( b.x &lt; a.x ) return false; if ( a.y &lt; b.y ) return true; if ( b.y &lt; a.y ) return false; return false; While I agree using a pair comparison makes sense here, you could also write this as: return a.x != b.x ? a.x &lt; b.x : a.y &lt; b.y;
That's not actually equivalent to the example, as it requires the existence of a suitable `!=` operator. Such an operator happens to exist for `int`, but it's not guaranteed to exist in general. Notice that the example uses only the `&lt;` operator, as a [`LessThanComparable`](http://en.cppreference.com/w/cpp/concept/LessThanComparable) type is all that's needed for enforcing strict weak ordering.
I will sometimes create a quick wrapper `struct` and define no functions in it except for `operator &lt;`, specifically because that's all I need for storing it in an associative container. I've seen others do the same as well. I agree with the rest of your reply, but of course that's just a style thing. I'm guessing the author was being overly verbose for the sake of supposed clarity.
Doesn't this work? class A; class B; class C; bool collision(const A&amp; a, const B&amp; b, const C&amp; c); template &lt;typename T, typename U, typename V&gt; bool collision(T&amp;&amp; t, U&amp;&amp; u, V&amp;&amp; v) { return collision(std::forward&lt;U&gt;(u), std::forward&lt;V&gt;(v), std::forward&lt;T&gt;(t)); } The template rotates its arguments, as soon as an order is found for which an overload exists, it will be preferred and thus template instantiation is terminated.
return a.x &lt; b.x || (! b.x &lt; a.x &amp;&amp; a.y &lt; b.y);
That's an actual link...
... like case insensitive string comparison. 
The difference is that using relational operators tests for equivalence, not for equality. Even if a type has equality defined, it might be different than equivalence. For example, if x and y are doubles: a.x=0.0/0.0; a.y=2.0; b.x=0.0/0.0; b.y=5.0; b&lt;a; //false a&lt;b; //true in the original, false in yours This means that with your scheme you can't place both `a` and `b` in the same set, but with the original you can. 
The documentation for the class says: &gt; Convenient proxy factory bean superclass for proxy factory beans that create only singletons. And this is good because I have always wanted a convenient one of...those...
One should mention that, while AFAIK not mandated by the standard, gcc seems to implement it even for advanced cases (like the trivial fibonacci) if you activate optimisation and clang manages to do it for simple cases like a recursive exponentiation-function.
I started a [blog](http://functionalcpp.wordpress.com/) about functional programming in c++, which will hopefully give more concrete examples and implementations of the things discussed, mostly higher order functions. Some stuff I have prepared includes some of the worst (best?) code I have ever written.
Wow what a response! It took me a while just to comprehend it all, but much thanks for it! Personally I don't have any experience working with vectors which is why we took the strings 2d array route, which looking back now, would have been worth to learn and made these types of implementations much easier. Again, thanks for the response!
You ain't kidding. The only Google results for “Metatemplate Programming Basics” are the linked page and this page, discussing it. Because I've said “Metatemplate Programming Basics” twice in my post, there's a good chance this discussion becomes the definitive source on the subject :|
It looks like it's organized as a Google+ Hangout. Perhaps this is the one to pay attention to: https://plus.google.com/u/0/103293161096669156578/posts Dcravey is the same username on the blog and the submission. Seems like he's the organizer. Perhaps a PM would wake him up.
&gt;return a.x &lt; b.x || (! b.x &lt; a.x &amp;&amp; a.y &lt; b.y); You have an operator-precedence bug. Fixed version: return a.x &lt; b.x || (!(b.x &lt; a.x) &amp;&amp; a.y &lt; b.y); With extra parentheses to make it easier to read (for me, anyway): return (a.x &lt; b.x) || (!(b.x &lt; a.x) &amp;&amp; (a.y &lt; b.y));
For those interested in this subject, there's a library called [FTL](https://github.com/beark/ftl) attempting to bring a bit more of a functional style to C++. It's not really release ready yet, but it's slowly getting there.
None of these features ever seem to be 'complete' for C++ in Visual Studio. 
I did the first three exercises before it became too much. What I did I liked a lot; - I learned a lot of funky details. - A very good support forum. - Well defined exercises with given test-sets. You can see the exercises by looking at http://www.cppgm.org/pa1.html for exercise one, pa2.html for two etc.
Damn, that first one looks like fun. I think I will try it out - I'm not insanely good at C++, but I bet one could learn a lot from it. 
On a somewhat unrelated note: I have to ask, why is it called Preview? Something missing? 
I've been looking at the exercises; as of today, I would say almost all of the programming assignments focus my least-favorite-part-of-compiler-implementation: lexing/parsing/tokenizing. 
The post says it works w/C++.
They're still working on it.
Because it's not released yet. Also it's free.
It is indeed closed for this year, they will run again next year though.
It's a really neat class. Not too difficult for the students as you get a very well laid out assignment plan, with everything broken up into manageable parts with test cases, design guidelines, and all that. The assignments have been fun and interesting so far, and I'm definitely learning new stuff about useful C++11 features I had never heard of (I've been using C++98 for many years). I'm a little worried about the instructor though. As far as I can tell it's all done by one guy. He definitely knows C++ inside and out, but it must be so much work designing and creating the course materials. I hope he's up to the task as it moves into the harder parts of C++ implementation. I expect the course to run behind schedule (it was originally supposed to be 18 months) but that's OK. It definitely takes a special kind of ambition/craziness to run a course like this on a volunteer basis, for which I for one am very grateful.
are there any open source opencl implementations yet?
I don't think that Intel has one, so probably no one does.
This is a 100% legit.
I was taking it and quit for the reason that I had better ways to spend my time. In the end, you create a non-optimizing, single-platform, throwaway compiler. I think that time is better spent contributing to GCC or Clang, or one of the standard library packages out there. (gcc STILL doesn't have full C++11 support) I actually wrote an article about how I felt about the program which caused some controversy on /r/cpp and /r/programming. http://grahampentheny.com/archives/115
Anyone ever used this? Any pros? Cons?
Actually I would argue that you don't need in depth knowledge of how a compiler works or read the dragon book to take this course. I find the dragon book a sore read and skipped it after the second chapter. My way of doing this is to read the assignment a few times and just start coding. Usually my first design doesn't fully cut it so I refactor a bit untill I really get what the assignment is about. Then I start ticking of test cases and while doing so attempt to find new cases that could potentially break the solution. Wherever I don't know what to do I look through the forums, google or read the standard.
Unfortunately that's false. The original scheme doesn't work either for NaNs. The equivalence relation you implicitly define by using the floating-point comparison operator is not a true equivalence relation, because it fails transitivity. Specifically, if you define `x ~ y` as `!(x &lt; y || y &lt; x)` then `1.0 ~ 0.0/0.0` and `0.0/0.0 ~ 2.0` but not `1.0 ~ 2.0`. This winds up having just as many problems as my scheme. In the end, you can either accept wonky behavior in edge cases, avoid NaNs in your data, or include a bunch of isnan checks to make the comparisons follow the rules.
I agree. You can learn that stuff as you go along. I look things up in the dragon book sometimes and read sections of it, but there's no need to read the whole thing.
If you can be sure that the compiler output is correct, a non-optimal compiler could be useful for something. A working compiler and libraries without fatal flaws is valuable for producing programs that must be trusted.
Got it. Thanks a lot.
I'm not sure what the definition of "correct" would be in the C++ world, considering there is (for very good reasons) many vague areas concerning code generation in the standard. In fact, there are often circumstances where "standards compliant" output varies wildly between different compilers, settings, or versions. Another possibility of "correct" output maybe comes from a more educational perspective, e.g. "If I can see what the semantics of this code is interpreted as, I can know when and how to use it correctly." To this I'd say that it's much easier and faster to read the standard -- you'd be doing this anyway if you're implementing a compiler. For code generation, I'd find looking at clangs llvm IR output will be much easier and productive. Speaking more directly to your wording, I would think that any result of this course would be nowhere near 'without fatal flaws.' Again, these are my opinions.
Obviously, if the code you are compiling relies on undefined behavior, then it's not really possible for it to be compiled in a canonical way. Maybe we could say that all interpretations are correct when behavior is left undefined. In any event, I was referring to correctness in the common sense: if behavior is defined, then the compiler should implement it that way, otherwise, it should do something sane that isn't a security hole. &gt;I would think that any result of this course would be nowhere near 'without fatal flaws.' Again, these are my opinions. I guess it depends on the skill and dedication of the implementor. If you implement a reliable standards-conforming compiler for a nontrivial language like C++, that's got to be worth something even if it's a "throw away" project. When you compile code with it you can rest assured that it's not going to have malicious bugs in the output.
An important note: vector will choose to move elements only in case it knows the move operation cannot throw an exception. So if your class is move enabled and doesn't throw, it is important to mark the move constructor as [noexcept](http://en.cppreference.com/w/cpp/utility/move_if_noexcept).
&gt; I can't wait to get to the really cool stuff, i.e. implementing the back-end and the standard libraries I was kinda waiting for this too, before even beginning with the syntax analysis stage. And it was a let down that we won't have a optimization assignment. &gt; I spent a lot of hours in the hotel room on my vacation coding (I have a very understanding girl friend) Marry her! 
&gt; I'm a little worried about the instructor though. Any ideas on the instructor's identity? 
good stuff, i like reading your articles! #define RtlFillMemory(Destination,Length,Fill) \ memset((Destination),(Fill),(Length)) #define FillMemory RtlFillMemory i can imagine how the author thought "this macro is not confusing at all, THIS must be a right arguments order" ) also error links (V645, V513) in second article lead to the wrong page (502). same in the ru version.
It would be nice to also see how std::strstream fares there.
Failing to parse the string isn't always an exceptional case, so shouldn't be treated as such. Doing validation/sanitizing UI input is the typical case here. using a 'try parse' method ends up being much cleaner in the client code.
It's already there: &gt; ◾std::istringstream
Anyone know if this was taped?
I agree that C++11 support is great but it would be nice if it were available as g++47 or g++48 instead of through the devtoolset package that isn't available for use in the EPEL.
Yea, but from the article isnt stringstream 13 times slower than everybody else.
[Example](http://www.reddit.com/r/cpp/comments/1khtdp/dont_be_afraid_of_returning_by_value_know_the/)
Use value semantics. Take a look at a great talk by Chandler Caruth of Google https://github.com/boostcon/cppnow_presentations_2013/blob/master/tue/cppnow_2013keynote.pdf?raw=true The video should also be available on BoostCon youtube channel
Added a comment to the post with results in debug and release for visual studio 2005, 2010, and 2012. edit: Installing the 2013 preview, will put up there when done, though I don't see it being different from 2012.
Similarly it's fastest for [`doubles`](http://tinodidriksen.com/2011/05/28/cpp-convert-string-to-double-speed/) too.
The most often one that I've seen is people trying to optimize memory bandwidth limited code, when instead they should be thinking of ways to reduce their memory bandwidth. eg. they spend days converting some code to SSE or some other tweaks and end up getting a 0 to 10% improvement because their code is memory bandwidth limited.
I guess it's not strictly relevant to the article (which seems basically to be about traits classes) but monoids don't have to be addition. For example a very useful monoid is Integers + XOR. Because of this it doesn't really make sense to look up monoids purly by type. You could have `addition_monoid&lt;T&gt;` or `monoid&lt;T, F&gt;` perhaps.
This, like many things, is something I'd do for all my code *if I could guarantee all compilers would do it* - such are the joys of writing code to run on over ten different platforms, most of which have a proprietary compiler toolchain. I feel like such optimisations should be part of the language standard.
There should be an update to this article from 2011, that mentions move semantics. And, not to forget: Your compiler often isn't able to optimize your passed in (const) references, because it doesn't know if someone else also has a reference to the passed object. So the first solution from this article, to pass in a vector by reference, should be avoided, too. Relevant: [Summary of the compiler's inability to optimize when passing a (const)-reference](http://www.youtube.com/watch?v=eR34r7HOU14&amp;feature=player_detailpage#t=2922s) (Watch the whole talk if you have the time!)
Well it is in the C++11 standard. Not RVO. But move semantics, and it is the solution to the demonstrate problem.
This. This right here. The structure of boost interacting with the C++ compilation model makes it essentially useless for a lot of projects, based on their iteration constraints.
It is part of the standard. C++03 §12.8.15: &gt;When certain criteria are met, an implementation is allowed to omit the copy construction of a class object, even if the copy constructor and/or destructor for the object have side effects. In such cases, the implemen- tation treats the source and target of the omitted copy operation as simply two different ways of referring to the same object, and the destruction of that object occurs at the later of the times when the two objects would have been destroyed without the optimization. This elision of copy operations is permitted in the following circumstances (which may be combined to eliminate multiple copies): &gt; &gt; * in a return statement in a function with a class return type, when the expression is the name of a non-volatile automatic object with the same cv-unqualified type as the function return type, the copy operation can be omitted by constructing the automatic object directly into the function’s return value &gt; &gt; * when a temporary class object that has not been bound to a reference (12.2) would be copied to a class object with the same cv-unqualified type, the copy operation can be omitted by constructing the tempo- rary object directly into the target of the omitted copy
Hello, I am the author! In the library I am writing along side this blog, there is indeed an `add_monoid`, `multiply_monoid`, etc. I just figured that the `default_monoid` should use addition because things like `string` and `QList` tend to use `operator+`. But yeah I wanted to focus more on the type classes than the monoids. Thanks for reading!
It's not really that bad. On -O0 a file with multiple nontrivial parsers only takes about 10 seconds to build for me, and while it takes almost 40 seconds on -O3, on a quadcore that ends up adding under ten seconds to the build time unless your project is small enough that building everything else takes under 40 seconds. Compile times are definitely one of my biggest complaint about boost.spirit, but by the general standards of C++ I haven't found it to be incredibly painful.
So what am I gaining by defining those monoids? Are there any larger applications written in such a style in C++?
Just a small note: // Returns reference to argument vector&lt;C&gt;&amp; getObjects(vector&lt;C&gt; &amp;temp); // ... vector&lt;C&gt; temp; doSomethingWith(getObjects(temp)); Almost as nice.
&gt;So what am I gaining by defining those monoids? Ideally the type classes (monoid, container, forward_container, monad, etc.) would already be defined for you in a library. They give you the safety of concepts without concepts and really let you take advantage of generic programming. &gt;Are there any larger applications written in such a style in C++? Functional style is relatively uncommon in c++, but it is the norm in Haskell. There is also [ftl](https://github.com/beark/ftl) which does something similar, though I have some different ideas about how to go about things.
Doing optimizations on their own that reduce code visibility that the compiler is able to optimize far better than they can. They don't even realize sometimes that their attempts at optimizing might damage the compiler's ability to optimize more aggressively because their code makes unexpected things that the compiler is not ready to handle. Any decent compiler is able to do basic things like replacing 3 * 4 with 12 or understanding that an expression gives always the same value and thus store instead it of re-calculating it in a loop (depending on the expression). If you do those things you're just making your code more unreadable to humans and hiding possible optimizations from the compiler.
Sure, but in the situations described by the author, move semantics in C++11 would guarantee the performance on all compliant compilers. RVO would just be beneficial in other situations.
It's basically like this: * RVO **may** happen, but is not guaranteed by the standard (and not optimizing it is totally fine with the standard). * Move semantics **has** to happen (where applicable). This is guaranteed by the standard. Please keep in mind that move semantics have to be supported by the type itself (move constructor/assign operator). This is not needed by RVO, so there may be situations where RVO may help you even with C++11.
It is deprecated for good reasons. So i appreciate that it is not used in examples that show techniques for new code.
For the search impaired: http://www.youtube.com/watch?v=eR34r7HOU14
&gt; For example, “123,000″ will parse as 123000 on some locales. This post is not locale independent.
True, but still worth it though. Besides simple conversions you can do stuff with Spirit you'd never bother otherwise.
Non-educational, non-informative, and lame.
stdio.h is wrong, as others have said. Between cstdio/printf and iostream/cout, I like neither. cout mixes form and content, while printf is just abominable in every way except possibly performance. My current library of choice is Boost.format.
iostream performs some buffering in addition to the buffering already done by stdio, which can lead to slightly worse perfomance for certain applications. 
[STL](http://www.reddit.com/user/stl) (who maintains the standard library at MS) has a good overview of why using cstdio is futile and that stdio.h is part of C++11 [here](http://www.reddit.com/r/cpp/comments/188ulg/rate_my_code_rcpp/c8d6582?context=3). &gt;About this point, I used to be a big believer in this, but not anymore. C++11's rules changed to reflect existing practice. N3485 D.5 [depr.c.headers]/3 has a convenient example: "Example: The header &lt;cstdlib&gt; assuredly provides its declarations and definitions within the namespace std. It may also provide these names within the global namespace. The header &lt;stdlib.h&gt; assuredly provides the same declarations and definitions within the global namespace, much as in the C Standard. It may also provide these names within the namespace std." &gt;Because &lt;cfoo&gt; isn't actually guaranteed to keep the global namespace clean (and doesn't in VC's implementation), I just include &lt;foo.h&gt; now. Namespaces are good, but we've surrendered the war to get the C Standard Library out of the global namespace. * This isn't to be contrarian, I appreciate that you didn't just say that c std library is bad like so many people tend to online, but I found STL's post informative, and I hate having to type std::sprintf if i want my code to compile on g++
I don't think that's true, as far I can tell both `libc++` and `libstdc++` just hit the same buffer as `stdio` by default with the option to disable that synchronization.
Here's what I do. It's complicated because this is a partially unsolved problem in C++, despite the Standard Library usually being filled with kittens and rainbows. stdio is fast, separates code and data, and has syntax that's generally easy to remember and look up. However, it has major downsides. It doesn't respect the type system (compiler warnings can help, but they're a bandaid over a hull breach), it's a recipe for buffer overruns and other plagues from olden times, and it doesn't respect RAII so you have to avoid leaking `FILE *`. iostreams have a deserved reputation for slowness (although this is less important now that the CPU is the second-fastest thing in your computer), they mix code and data (`cout &lt;&lt; "I have " &lt;&lt; k &lt;&lt; "cute fluffy kittens and " &lt;&lt; p &lt;&lt; " stupid ugly puppies"` means that if I want to swap the order of kittens and puppies in the string, I have to actually move code around rather than just changing a format string), and their syntax is impossible to remember for anything nontrivial. I feel like, as an STL maintainer, I should be able to remember which manipulators set "sticky" bits and which take effect for only the next thing streamed - but for the life of me I cannot. Conversely, they respect the type system, they respect arbitrary-length strings (if you know what to use), and they respect RAII so you don't leak file handles and so forth. They're also "extensible" so things can define their own streaming operators, although in practice I don't see this used every day. Extra extra annoyingly, they introduce new pitfalls for beginners - I speak of the streaming operators that leave delimiters on the streams. This is insane and undesirable and tutorials are just awful about pointing it out. Finally, there's Boost.Format, which is built on top of iostreams (so you get their performance or lack thereof), but you get better-than-printf syntax - both positional (`"I have %1% cute fluffy kittens and %2% stupid ugly puppies"` says to print the first thing, then the second) and type-agnostic. It doesn't solve everything (particularly parsing) but it makes iostreams actually usable. So, the criteria in my head are like: * Do I need performance? Then I must use stdio, very carefully. However, few things nowadays are dominated by the performance of formatting strings, so this has actually been a theoretical concern for me. * Do I need to do binary I/O? Then stdio is actually the simplest option, although its `FILE *`s must be wrapped in classes. It is *possible* to do binary I/O with iostreams, but it is hilariously obscure how to blast a file into memory. * Do I need to do very simple text I/O? In that case, iostreams aren't bad. Reading a file line-by-line with iostreams is actually very elegant, if you know how to do it (`for (string s; getline(cin_or_your_ifstream, s); ) { do stuff with s; }` - this doesn't handle jokers with 5-gig lines but that's not iostreams' fault, that's just an obnoxious case for anything). If I need to *parse* those lines, I go straight to regex - absolutely no hand-parsing with iostreams. Writing lines is also nice and simple, as long as I don't have to do things like format hex. Sometimes in test cases I use stdio's `puts()` which is the best there is at printing literal lines, but it's not a strong preference. * As soon as I need to do any sort of complicated formatting, like printing hexits, I'll use stdio only if I am printing to stdout. If I need to do in-memory formatting (e.g. exception strings), I absolutely do not touch `sprintf()` and its unindicted co-conspirators. Instead I grab Boost.Format and get a nice arbitrary-length string out of it. * Finally, none of this involves i18n. I don't do that at home (it gives me enough of a headache at work). Adding locales basically amplifies the misery of everything a thousand-fold.
needs to be on /r/cringevideos
Bind incurs overhead with copying and produces a bind expression object. It also can't accept references unless wrapped in a `ref` or `cref`. Semantically, this r = eval(f,a,b); is different from this auto f_ = std::bind(f,_1,_2); r = f_(a,b); Eval also treats member object pointers as valid function-like objects.
Be that as it may, there are no scenarios where: C c; c = f(); ... is more efficient than: C c; f(c); ... but there are plenty of scenarios where it is _less_ efficient, move semantics notwithstanding. My advice: leverage RVO/move semantics when it makes sense, just remember that it doesn't always make sense.
OK Thanks, and nice metaphor.
clean code would suggest adding a prepare() and commit() noexcept method, which would be equivalent and already supported.
This is actually incorrect for a subtle reason. First, C++11 has already specified this, and it's called INVOKE. Second, INVOKE correctly specifies the return types, unlike here. If I have `int Foo::*` and I apply it to `const Foo&amp;`, I need to get `const int&amp;`. Instead this code returns `int` by value.
If only we could define mini-functions within a function, and somehow mark them as `noexcept`... C:\Temp&gt;type meow.cpp #include &lt;iostream&gt; #include &lt;stdexcept&gt; using namespace std; int main() { try { []() noexcept { cout &lt;&lt; "Hello, noexcept world!" &lt;&lt; endl; throw runtime_error("BOOM"); }(); } catch (const runtime_error&amp;) { } cout &lt;&lt; "Can't get here." &lt;&lt; endl; } C:\Temp&gt;g++ -Wall -Wextra meow.cpp -o meow.exe C:\Temp&gt;meow Hello, noexcept world! terminate called after throwing an instance of 'std::runtime_error' what(): BOOM This application has requested the Runtime to terminate it in an unusual way. Please contact the application's support team for more information.
&gt; Before creating the producer, let sleep for a tad, so that we are sure the consumer starts first (and won't find anything to consume). No. No no no no no. No! Sleep is not a synchronization primitive. You can use it in examples to demonstrate what happens when tasks take varying amounts of time, but you *must not* use it to be "sure" of anything. Never ever never for ever. Also, this code is terrible. In the consumer, the lock is held for way too long (it should be released after popping and before doing any work). [Anthony Williams' article](http://www.justsoftwaresolutions.co.uk/threading/implementing-a-thread-safe-queue-using-condition-variables.html) is actually useful, although presented in an unnecessarily complicated manner. In my code at home, I use a single-producer, single-consumer queue with one twist: The producer `push_back()`s work into a shared `vector`, and the consumer `swap()`s it into a local `vector`. That way, the consumer can grab multiple work items at once, while spending an absolutely minimal amount of time under the lock. (This is a highly overengineered screenshot-saving thread.)
Personally, I like `boost::lockfree::queue`: http://www.boost.org/doc/libs/release/doc/html/lockfree/examples.html All of this synchronization only makes things complicated! // ;-)
I looked at that, but it requires T to have trivial assignment/destruction, which isn't true for my vectors of pixels. Additionally, my scenario isn't appropriate for Lockfree anyways - my screenshot thread has nothing to do the vast majority of the time, so it should be idle and waiting on a condition variable instead of continuously spinning and looking for work. At that point I need a mutex for the condition variable, so putting the work in an ordinary vector is simple.
That would be useful actually. Maybe that could be a revision in C++14, the ability to mark lambdas as constexpr and noexcept? 
Yeah, going with Lockfree for this was somewhat tongue in cheek (together with the comment on sync making things more complicated). That being said, are you having dynamically polymorphic pixels (...interesting), or is this something else? // Regarding the requirements on `T`, there's also `boost::lockfree::spsc_queue` (a single-producer/single-consumer queue): http://www.boost.org/doc/libs/release/doc/html/boost/lockfree/spsc_queue.html 
C++11 allows lambdas to be marked noexcept (my code was actually executed), although not constexpr.
&gt; That being said, are you having dynamically polymorphic pixels (...interesting), or is this something else? When the screenshot key is pressed, I construct an appropriately-sized `vector&lt;unsigned char&gt;` (e.g. 15.6 MB for 2560x1600) and use `glReadPixels()` to fill it with pixels. (I am actually using Pixel Buffer Objects now to reduce the impact on the main thread even further.) This is the absolute minimum amount of work that I must do on the main rendering thread. Then I send the vector over to my screenshot thread for PNG compression and disk writing. Hammering the screenshot key merely queues up a whole bunch of vectors like this. (I also use Boost.Atomic to tell the main thread how many screenshots are waiting to be saved so I can display a message.) &gt; Regarding the requirements on T, there's also boost::lockfree::spsc_queue (a single-producer/single-consumer queue): Looked at that too, also unsuitable for my purposes. It is sized either at compile-time or once at run-time, but I need a dynamically sized "queue". Yeah, the user probably isn't going to have 100 screenshots in flight, but it's the principle of the thing.
&gt; while(queue_.empty()) // 3 { std::cout &lt;&lt; "waiting queue" &lt;&lt; std::endl; cond_.wait(lock); // 4 } If you read the docs carefully, you will notice that std::condition_variable has this 'wait' overload that takes a predicate: cond_.wait(lock, []{ return !queue_.empty(); } ); 
Neat! See also http://en.cppreference.com/w/cpp/utility/functional/bind
Haha, I was actually there and remember the singing. It was all Herb Sutter's idea - the guy is a natural showman. 
What do you gain from using x macros there rather than just regular macros like the following? #define DEFAULT_MONOID(T) template&lt;&gt; struct monoid&lt;T&gt; : public default_monoid&lt;T&gt; {} DEFAULT_MONOID(bool); DEFAULT_MONOID(int); // ... #undef DEFAULT_MONOID
Yes, of course, std::bind *is* a default way to do the partial evaluation. This is more a convenience variation of it, for something that I'm planning to do at a later stage. 
If there's not much work going on in the main thread how about giving it some? Try moving all the queue management in to a single thread with [Boost.Coro](http://www.boost.org/doc/libs/1_54_0/libs/coroutine/doc/html/index.html). It seems you only actually need the extra threads for PNG compression.
It's nice to see more people doing things with typically functional concepts in C++. Been working on [this](https://github.com/beark/ftl) for a while myself, it's got currying too (among many other things). I'd be interested to know how you approached the subject, your blog post doesn't really go into any details and by a cursory look it, seems you went about it differently than I did.
Out of curiosity, where do your ideas differ? As the author of FTL, I'd love to hear about them.
Hm... I sort of went a different direction on the definition of some monads. For example, you use shared_ptr as a separate monad, but for me, shared_ptr is one instance of the optional/maybe (haven't settled on a name) monad. I relaxed the purity restrictions so that functions with side effects that can fail also work. Similar thing with containers all being in the same monad. Here is a contrived example where i get a sorted vector of all the quotients of two containers: auto a = std::list&lt;int&gt;{1,2,3,4}; auto b = std::deque&lt;int&gt;{2,3,5,7}; auto c = a &gt;= [&amp;](float a_){ return b &gt;= [&amp;](float b_){ return std::set&lt;float&gt;{a_/b_}; }; } &gt;= [](float a_){ return std::vector&lt;float&gt;{a_}; }; I also have absolutely nothing on your Haskell features :) I didn't even start on currying or laziness yet!
I actually have a few different monoids (add, multiply, etc...) so it helps cut down on repetition. Also, it's a cool trick that more people need to know about!
I see. There seems to be a subtle difference that I'm not quite grasping. For example, how is your less_than implementation different from using std::less? I understand that partial application isn't the same thing exactly as currying, but I have some trouble understanding the practical difference. On second glace, having thought about it a little harder, I see that make_curry is doing more than I realized earlier. Does it enable stuff like this? auto fn = make_curry( std::find ); std::vector&lt;int&gt; v {1,2,3}; auto a = fn( begin(v), end(v), 2 ); auto b = fn( begin(v) )( end(v) )( 2 ); auto fnv = fn( begin(v), end(v) ); auto c = fnv( 2 ); Where a == b == c? I can't quite imagine how the lambda capture works for this. Would this behave as expected? v.push_back(99); auto d = fnv( 99 ); In any case, very interesting. 
Good catch, I think it should be fixed now. Also, what is this INVOKE? I can't find anything on it.
This is a game's main thread, which is busy rendering stuff as fast as it can. There is essentially no "queue management". As I explained, here's what the main thread does: * Allocates a frame's worth of memory. * Fills it with pixels (only the main thread can talk to OpenGL for this). * Locks the mutex, push_back()s the vector&lt;pixels&gt; into the shared vector (that's a vector&lt;vector&lt;pixels&gt;&gt;). This is a move, so the only real cost is a potential reallocation. * Gets out of the mutex and notifies the compression thread that it has work to do. The compression thread then locks the mutex, sees if there's any work (if there is, it swaps the whole vector of work, processes all of the frames, then comes back for more). If there isn't, it waits on the condition variable. The only optimization I haven't performed here is attempting to reuse the chunks of memory for uncompressed frames (right now the main thread always allocates and the compression thread throws them away), mostly because this is an insignificant cost and would add further complexity.
[N3690](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3690.pdf) 20.10.2 [func.require]. If you're going to write this sort of code, you need to understand how the Standard Library does it, forwards and backwards and inside-out. (Note that INVOKE is a theoretical function not actually exposed to the user, but other Standard Library functions are specified in terms of it.)
`std::less&lt;int&gt;` is a functon that takes 2 ints and returns a bool. `less_than` is a function that takes 1 int and returns a function that takes 1 int and returns a bool. They're different because they have different types. The difference between partial application and currying is that partial application does application, whereas currying just changes the type of the function. A curried function takes the same number of total input parameters to get a result, whereas a partially applied function takes less. Currying makes it easier to partially apply functions, but you can partially apply to uncurried functions, as `std::bind` does.
Out of curiosity, how many screenshots can you cram into this queue before the compression thread gets to them?
&gt; log(1, 1, "Arguments: 3 - 0")(); How does this work? (one of the examples in the second article)
&gt; They're different because they have different types. I was thinking of something like this: partition(ns.begin(), ns.end(), less_than(i)); partition(ns.begin(), ns.end(), bind1st(less&lt;int&gt;(), 5)); It seems the only practical difference in this case is the syntax? And one will be a compiler-generated closure while the other will be a normal object, I guess. Clearly the less_than syntax is easier to read, but it requires definition. And obviously that's where OP's second post comes into play. &gt; A curried function takes the same number of total input parameters to get a result, whereas a partially applied function takes less. If I don't count the parameters that were previously applied, then this makes sense. But it seems like splitting hairs. I probably just need to spend some time on practical application of this concept instead of annoying you all :) Thanks for the help.
That is one example that I might decide to kill in the future - that and ()(...). In essence, what the behind-the-scenes-code does is to split the arguments into two tuples - so, one of them can be a 0-tuple.
Nice. Bookmarked for future reference. Shame these libraries are not more known - in the past, I've found quite a few c++ functional libraries. The code is a bit dirty and far from being finished (aka, works *only* for the case I need it for atm). That is the reason I didn't post it at this time. It concatenates the arguments from the two (the current implementation's limitation) calls - first call retruns a functor whose () operator actually executes the code. So, it is not *real* currying at this time.
b does not work now, but it is in plans, and it will be the same as a and c.
But how can you tell that log(1, 1, "Arguments: 3 - 0") doesn't return a functor, and that I want to call that?
Here's a C++14 implementation: https://dpaste.de/qGWcq/ `f(a, b, c)` becomes `curry(f)(a)(b)(c)`
At the moment, the first call always returns a functor because I need it to do so. But, what it *should* do is count the arguments and when all are provided, call the function.
In that case you're correct that the only difference is syntax, but in more complex cases there are substantial differences. Consider the following function: template &lt;class Func&gt; auto partially_apply_to_2(Func f) { return bind(f, 2, _1); } Now, if func is a 2 argument function, everything is fine. However, what if func has 3 arguments? Now we need an overload, and some SFINAE to pick the right function: template &lt;class Func&gt; enable_if&lt;takes_num_args&lt;Func&gt;(2)&gt; partially_apply_to_2(Func f) { return bind(f, 2, _1); } template &lt;class Func&gt; enable_if&lt;takes_num_args&lt;Func&gt;(3)&gt; partially_apply_to_2(Func f) { return bind(f, 2, _1, _2); } But what if func takes 4 arguments? Or 6, or 24, or 120? Are you going to write 120 overloads for this function? Of course not, that'd be a total waste of time. What we can do is curry the function. Now, there's only 1 function to write: template &lt;class Func&gt; auto partially_apply_to_2(Func f) { return uncurry(curry(f)(2)); } Because f is curried it can accept a single argument. We don't need to mess around with binding and overloading on different numbers of arguments to do partial application; it works automatically. It may seem like splitting hairs, but the difference is important if you're trying to be precise. For example, you can uncurry a function by flattening its parameter list, but you can't unapply a partially applied function. This is only possible because currying doesn't do any application. 
&gt; It is possible to do binary I/O with iostreams, but it is hilariously obscure how to blast a file into memory. Can you clarify what you mean by this? It's certainly a lot easier than the C stdio way, you don't even have to muck with seek/tell to get the size in advance: ifstream f("foo.png", ios::binary); string file_contents {istreambuf_iterator&lt;char&gt;(f), istreambuf_iterator&lt;char&gt;()}; // or vector&lt;char&gt; file_contents {istreambuf_iterator&lt;char&gt;(f), istreambuf_iterator&lt;char&gt;()}; If the problem is that most people don't know about `istreambuf_iterator`, then I think I'd certainly advocate learning it before advocating doing anything with `FILE *`. Or is the issue about reading some POD struct (with the normal admonitions of danger that entails)? struct foo { ... }; foo x; if(!f.read(reinterpret_cast&lt;char *&gt;(&amp;x), sizeof(foo))) { cerr &lt;&lt; "error: encountered eof after " &lt;&lt; f.gcount() &lt;&lt; " bytes, expected to read " &lt;&lt; sizeof(foo) &lt;&lt; " ...\n"; ... } It's not the prettiest thing in the world due to the cast, which admittedly `fread()` does not require on account of taking `void *`, but otherwise it's pretty much an identical interface, no? 
I also put together a quick currying hack a year or so ago: https://github.com/LeszekSwirski/cpp-curry
Well, that much I'd gathered, that's more or less a requirement. I was after a bit more detail :) However, I think I have a fairly good idea anyway: it's probably quite similar to how I make `fmap`, `foldl` and other pre-defined function objects curried in FTL--except with those I have the benefit of knowing arity at compile time and don't need to handle the general case. As for currying user defined functions and function objects, I actually currently require them to have a visible signature, e.g. `std::function`, function pointers, and sso on, which is why I said it seems we've taken different approaches. In the end, I think I might support both types (I don't want to lose type signature information in cases where it's not necessary, as it makes certain higher order functions much more convenient to interact with).
So that's what `istreambuf_iterator` is for! I was talking about `gcount()`, which is aggressively hostile to my brain. As far as I'm concerned, if I call a function to read some stuff, it should tell me how much stuff it read. It shouldn't squirrel away state in the object and require me to call some other member function.
So your saying that this is incorrect because c++ already has this behavior.... But only in a theoretically non accessible hypothetical function? Care to elaborate on this?
The only reason for the existence of `noexcept` is that for many functions it is possible to write more efficient implementations if they can assume that an exception won't be thrown by a given method; this is is because if exceptions could be thrown then they might have to make copies of the data being operated upon in order to be able to safely roll back if an exception is thrown, which means, for example, that it is not possible to make full use of move operations to improve efficiency as copies still need to be made for safety reasons. Given this, it is not clear what the point of a `noexcept` block would be given that there would be no external functions making use of it to provide a more efficient implementation.
Sounds similar in principle to the DSP real time displays we have in our application. They work in the following way: * Two threads - The real time DSP thread + GUI thread (DSP thread ~= your main thread, GUI thread ~= your compression thread) * Two ring buffers allowing lock-free read and write between the threads (atomic indexes) * We decide how many "frames" we wish to allow to be "in flight" - and the GUI thread allocates N buffers, and writes pointers to them onto the DSP "free frames queue" * DSP thread checks if a frame should be generated and a "free frame" is available, if it is pop a pointer to one from the free frames queue and start filling it * When frame is full, push the pointer back onto "filled frames queue" and signal on condition variable. Given a target FPS, work out the time-stamp on which to begin filling the next frame. I've skipped some of the implementation details(*) which make things more complex, but I think this could equally apply to your "screen-shotter". I'm guessing the atomics would be cheaper (and non-blocking!) compared to the mutex and malloc/frees. * We have multiple DSP threads and displays, too * Audio output has latency, so these displays are timestamped for when they should be displayed to get audio/visual sync * DSP thread start/stop must signal the GUI thread to correctly clean up the ring buffers and allocated frames
Essentially you have a ring buffer with the following segments, listed below clockwise, with an operation sitting between each, consuming counter-clockwise (up): 1. SFBs (Screenshot Frame Buffers) awaiting compression. // PNG compress pre-op 2. SFBs undergoing compression. // PNG compress post-op 3. Dirty SFBs. // Free-op. (e.g. free if sizeof(unallocated segment != 0) || (sizeof(preallocated segment) &gt;= 2)) 4. Unallocated SFBs; // Allocate-op (e.g. allocate if sizeof(preallocated segment) &lt; 2) 5. Preallocated SFBs // Fill-op (your game thread) Each op only needs to lock, perform the operation, move its segment iterator clockwise and unlock. Operations run clockwise, with notify/wait between threads in only two places, depending where you decide to slice the cake.
You can always check if the the function is callable rather than requiring the function to be monomorphic. In my library(which is still a work in progress) I use [this](https://github.com/pfultz2/Zen/blob/algorithms/zen/function/is_callable.h#L167) construct to detect callability in C++11(it also detects callability in C++03 using techniques developed by Eric Niebler). I have a [partial_adaptor](https://github.com/pfultz2/Zen/blob/algorithms/zen/function/partial.h) that does partial application for functions. It has a lot more code in it since it is designed to work on non-C++11 compilers. Basically, if the function is not callable it returns another function. It keeps doing this until the function is callable. In the code, you don't see `is_callable` because the [conditional_adaptor](https://github.com/pfultz2/Zen/blob/algorithms/zen/function/conditional.h) takes care of that logic. Also, every function takes a fusion sequence of its arguments in order to abstract out varidiac templates on non-C++11 compilers(it uses the [variadic_adaptor](https://github.com/pfultz2/Zen/blob/algorithms/zen/function/variadic.h)). Basically, it tries to call `partial_adaptor_invoke`, if thats not callable it will call `partial_adaptor_join` which will join the two sequences(the closure and the arguments passed in to the function) and return another `partial_adaptor`.
Thanks, I hadn't realized `noexcept` could be used on a lambda.
Having this in C++ would be nice. I wonder if we will see any language features to make Go/CSP like concurrency easier to implement, or even if we need any.
This is a great feature in C# and I'd like to see it in C++.
Yes, I have a similar `is_callable` trait implemented too. However, in most of my own use cases, I've found I prefer to have the parameter types of a callable be deducible from its type alone. It really depends on what exactly you're doing though. As I mentioned, I have another set of function objects that do not have discernible type signatures, because that's more convenient in their expected use case. They're all kind of "pre-curried", however. Anyway, I'm already using essentially both methods, so I expect I'll end up implementing an overload for `curry` to work on arbitrary function objects sooner rather than later.
&gt; Yes, I have a similar is_callable trait implemented too. Ok, cool, I hadn't realized that. &gt; However, in most of my own use cases, I've found I prefer to have the parameter types of a callable be deducible from its type alone. To do that, the function has to be monomorphic, however, I use a lot of polymorphic functions, so it wasn't really an option for me. &gt; They're all kind of "pre-curried", however. What do you mean "pre-curried"? &gt; Anyway, I'm already using essentially both methods, so I expect I'll end up implementing an overload for curry to work on arbitrary function objects sooner rather than later. Cool, so eventually you will implement `curry` for polymorphic functions as well? Or do you have it already implemented?
&gt; To do that, the function has to be monomorphic, however, I use a lot of polymorphic functions, so it wasn't really an option for me. Yeah, like I said, which type of function object you prefer depends largely on the situation. &gt; What do you mean "pre-curried"? Well, these function objects are essentially structs with an overloaded set of `operator()`s built in, they are not the result of a call to `curry(obj)` or similar. My point was basically that I don't yet have a curry function that deals with polymorphic function objects, but that I do see the need for it--to the point where I have "hand crafted" such objects. Well, not really, of course; they all inherit the currying from a base class. DRY and all that. So yeah, to answer your final question, it is my intent to implement `curry` for polymorphic function objects at some point :)
Updated the article with a more complex example provided by Herb Sutter.
In this case, the behavior is accessible through `mem_fn()`, which is specified via INVOKE.
Wow, that's incredibly nasty. I just use non-member `getline()` for line-at-a-time input. (When doing binary I/O, I sometimes want to read up to N bytes, but I never want this in text mode.)
I'm the author of the library. I decided to finally release this after sitting on it for a while. Yes, it's another unit test library. Except you don't need to inherit from anything and everything. You just declare a bunch of tests and tasks and place your assertions into lambdas. It is a header only library. It assumes you'll use CMake. You need to have exceptions enabled. There are no macros. Yes, this means no line numbers in the errors. It goes by the number of assertions performed within a task. Line numbers are helpful, but I'm tired of macros. I figured I would try something different, and unittest is the result. I took a few pages from python's unittest module (hence the name), and I think I did "alright". Please don't hesitate to call me an idiot and make fun of me.
I think the syntax is nice, very concise, and an interesting use of c++11. Just by looking at the sample I've been given some new ideas to try in my own frameworks. The line numbers will be killer though, since in very large unit tests the failure lines really help narrow down the issue. You should consider at least providing some form of them through either an api that takes the line so someone else can write a macro around your methods, or just relent and go back to a macro. Personally I use boost unit test, and its been good to us. Its one key quality is its ability to auto create a unit test by mere inclusion of a CPP file to the project. That's really allowed us to grow and re-use tests easily. 
I wonder how this feature would be combined with async I/O operations. Threads aren't the most scalable feature we have. Does anyone here can enlighten me?
It would be fantastic to have this as part of the standard. I am currently using boost::context to implement the side-stack technique described in the await draft paper. However, it means the code is not very portable and is difficult to integrate with other libraries. I've had to write my own scheduler and async i/o wrappers. If C++ code could standardize on await it would make writing and sharing async code much easier.
Signup is closed, but you can still view the assignments and follow along from my understanding.
wow, wow, wow, are you working on a game now? Do tell more!
I really think line numbers are essential, and I really don't want to have to use CMake. [Here's my own](https://bitbucket.org/neilb/minitest) (purposely very minimalistic) framework that does use macros to provide file/line information. 
Have you looked at HPX (https://github.com/STEllAR-GROUP/hpx) which has already implemented all of this?
I know. Will do it eventually. p.s. I knew the first comment will be about that :)
Why wouldn't you just expose the C++ type directly? // api.h extern "C" { struct Klass; Klass * make_klass(); } And then somewhere else: // Klass.h struct Klass : public Whatever { ... }; And finally: // api.cpp #include "Klass.h" extern "C" { Klass * make_klass(){ return new Klass; } } What am I missing? Edit: Missing extern "C" blocks
Yes, and my library (https://github.com/toffaletti/libten) has different and more modest goals. I had some libevent based http servers that were becoming difficult to maintain and reason about because of all the callbacks. The libevent http api was essentially unmaintained and performance left a lot to be desired on multi-core hardware because of global locks. I also had some requirements like integrating with existing event loops that required a set of concurrent tasks to be executed on a single thread, which made the boost::context approach preferable to work-stealing threads. I don't see this type of lightweight stack-swapping concurrency in HPX?
Fair enough, but this is the only reason AFAICT.
HPX relies completely on lightweight stack-swapping concurrency (as you put it). It can be even configured to use Boost.Context for this - and in fact it uses Boost.Context out of the box on MacOS.
Wouldn't it be better to do: #include &lt;new&gt; bool make_klass (Klass * ptr) { if (ptr==nullptr) return false; try { new (ptr) Klass (); } catch (...) { return false; } return true; } void destroy_klass (Klass * ptr) { if (ptr!=nullptr) ptr-&gt;~Klass(); }
Glad to hear it!
"Better" depends on your goal/tradeoff profile.
Maybe you do, maybe you don't. Depends on how frequent said allocations are intended to be. API simplicity is maybe more important than controlling allocation. Besides, if you have a C API, you should have a C++ API as well (IMO).
This is only a problem if your object is totally opaque. Otherwise the consumer will need to know the layout of the object, which leads to knowing its size.
The consumer does not need to know the layout of the object with what I posted earlier. What I've done often is expose a set of C-style functions to call functions on the object itself: extern "C" { struct Klass; Klass *make_class(); int do_something(Klass*); void do_something_else(Klass*,double); } 
The article does a pretty good job of covering why exposing only totally opaque types is often a good idea.
I'm curious, will the standard library be extended too, or will we need to roll our own async semaphores, IO, and timers?
My understanding is that this is what Go does for pretty much all code. In Go, all the "blocking" APIs are really "awaiting". It's usermode coroutines/async.
This is a really good article. How long did it take you to come to all these conclusions? Did you read about a lot of these problems before hand, or did you run into them before and these are your solutions in c++?
Generally good advice, but there's a bit more to the story. I'd say that `std::vector` is not the best example here, because it acquires a resource (heap-allocated memory). A better example would be an object that's big in itself, like most matrix implementations. In many situations, you want the caller to be able to specify how to allocate the external resource, because in the end it's the caller that has to release it as well, and it is therefore able to make certain guarantees — for instance, by providing an allocator object that has a fixed lifetime, which might be significantly faster to allocate from compared with system heap. That's still possible with return-by-value, but requires an extra parameter to the function (the allocator).
Suddenly firefox 100% CPU usage and unreasonable disk IO
This looks pretty nice indeed, especially font rendering. What did you use for that? Are games your hobby project? Do you work on games for MS? With OGL 4.3 I take it you don't plan to target any of mobile platforms? Regarding the other post: I -think- you can copy a render buffer (target) to a PBO (and then get it to a local mem) from other thread (with shared ctx)
This isn't a mystic functionality like copy elision or inlining which may or may not occur at the compilers whim. The rules concerning r values &amp; move semantics are well defined by the C++11 standard.
You know, I get to the part that says #define TRACE(msg) wcout &lt;&lt; msg #define TRACE_ACTION(a, k, v) wcout &lt;&lt; a &lt;&lt; L" (" &lt;&lt; k &lt;&lt; L", " &lt;&lt; v &lt;&lt; L")\n" and I can't convince myself to read the rest. Your example might be brilliant, but the terribleness of those defines (and the uselessness of the first) makes me doubt the rest.
You mean instead of "injecting" your own allocators? The syntax is simpler for the majority of clients that do not need custom allocators. If it turns out the allocator is the bottle neck, it's much simpler to switch for clients - just provide your own allocators, instead of modifying / wrapping each make_klass call. 
The way I implement it, it is an opaque handle.
The topic is implementing it in a shared library. You *can* export a C++ class from a shared library, but that can be consumed only from binaries coming from the same compiler (technically, even a minor patch may "break" the DLL's C++ interface.) With a "plain C" API, you have a well-defined interface that can be consumed by virtually any language. However, you run into a few problems: - You cannot export classes. Only structs of "plain old data", and global functions. - Everything that gets allocated in the DLL must be freed in the DLL If the caller is written in a different language, how should it know how to free a pointer allocated by, say, gcc 3.2? Even if you have the same compiler on both sides, the DLL is likely uses its own heap (rather than sharing it with the host process), so again you cannot pass "delete responsibility" across the interface. This leads to the common API pattern as linked by OP: allocating opaque "handles" to objects, and every member funciton is translated to a global funciton taking an additional handle. This generally works fine. However, in some scenarios, the default allocator turns out to be the major bottleneck. This is not uncommon in languages with deterministic resource management, the common solution is a custom allocator (which may even be a garbage collector in disguise). So that's why you (may) need the ability to inject your own allocator into the shared library. This is not always necessary, but at least a good precaution if there is a possibility of the client making you allocate many small objects. ----- FWIW, static libraries are even less portable, and source code distribution is not always viable - as well as hindered by the braindead C build model. Shared Libraries provide the best portability - at cost of a limited interface. 
You've totally missed the point. Did you even read the example code I posted, or did you totally miss what I was getting at? Obviously a C++ class can't be consumed as globally as a C struct/handle, this is a well-known limitation of C++. Obviously attempting to free pointers across library boundaries is a bad idea. **But that has nothing to do with what I was talking about.** You're presupposing that some kind of allocation of memory has to happen for these objects, which is exactly my point. There are two basic ways to create an object: 1. On the stack. 2. On the heap. If you go for #2 you're going to incur the overhead of going to the heap manager. Sure, you can get a really fancy, fast heap manager, but you're still going to the heap manager, it's still slower than #1. Which brings us back to my point: The API should be designed in such a way that the consumer can pass in a pointer, and the object is constructed in place at that memory location. For example consider this class: class foo { private: int x; public: explicit foo (int x) noexcept : x(x) { } int get () const noexcept { return x; } }; Obviously this will not fly in C code, but this object is **layout compatible** with: typedef struct { int x; } foo; And then you simply provide: #include &lt;new&gt; extern "C" { bool foo_create (foo * ptr, int x) { if (ptr==nullptr) return false; try { new (ptr) foo (x); } catch (...) { return false; } return true; } int foo_get (const foo * ptr) { if (ptr==nullptr) return 0; return foo-&gt;get(); } } And your C header: #include &lt;stdbool.h&gt; typedef struct { int x; } foo; #ifdef __cplusplus extern "C" { #endif bool foo_create (foo *, int); int foo_get (const foo *); #ifdef __cplusplus } #endif
I am not convinced. If this had been tied with a uniform async I/O library and a sharper definition of the workpool / threading model (preferably a configurable one) I would have been happier but from my wishes I can tell that this does not belond as a language wrapper around compiler magic (so it becomes compiler dependant and thus inconsistent) but rather a more solid set of libraries and documented behaviour in the STL/C++ runtime. I feel about it in C++ like I do about it in C# it is syntactic sugar more than a core language element. Basically it is a bit like MS forwarding their PPL work into the language due to their influence rather than it being a core language need that has come from a wide range of sources. 
I agree. Especially since the client example doesn't use the macros. The usage of "\n" reduces a bit the readability, endl would be nicer. The mixture of wcout with cout, and "using namespace std;" with "std::exception" is a minus for consistency. The author used wcout, it would be nice to use wmain and wchar_t instead of the _tmain and _TCHAR* Microsoft extensions. This would make the code a bit more portable. I wonder if Microsoft would retire _tmain and _TCHAR* in Visual Studio 2013 project templates, now that we know that they want to remove MBCS support for MFC.
Much better: https://github.com/toffaletti/libten
I think a few more of these self promote blogs and you'll definitely get that MS SDET role you've been after....
First paragraph of the article has a link to Part 1. The link is broken.
It is good practice to never make assumptions about APIs. If you pass a pointer that may receive a buffer, always clean up after it. In this case, the documentation says: &gt;ppErrorMsgs [out] ID3D10Blob &gt;A pointer to memory which contains a listing of errors and warnings that occurred during compilation. These errors and warnings are identical to the debug output from a debugger. This implies that warning messages that do not cause compilation to fail will be returned in a buffer you now are responsible for and must clean up afterwards. Using a safe pointer that understands how to automatically release the reference when it goes out of scope would be even better.
Ah ok..thank you! 
Try ComPtr&lt;ID3DBlob&gt;.
You can't use a standard library safe pointer, you need to use one that understands about COM objects. I can't think of one in a public library off the top of my head, but they're simple to write. The ATL probably has one, but I wouldn't suggest that library.
Looks interesting, but I'm a bit confused. MSDN has ComPtr and CComPtr - what's the difference? Also, the MSDN for ComPtr says I need to include &lt;client.h&gt; but on my system there's no such header file... Edit: Worked it out, I just need to add #include&lt;wrl/client.h&gt;. Thank you Sunius!
I use [FreeType](http://freetype.org) for rasterizing both the "core" and the "border" as I call them (FreeType's [stroker](http://freetype.org/freetype2/docs/reference/ft2-glyph_stroker.html) generates the border), then I carefully combine them with shaders. &gt; Are games your hobby project? Yep. My day job is maintaining VC's STL, whose machinery is invisible and partially compile-time - when investigating bugs I write small console programs. I enjoy that world (the hobby that got me into C++ was data compression, also invisible), but it sure is nice to render stuff. &gt; With OGL 4.3 I take it you don't plan to target any of mobile platforms? I'm not planning that far ahead. My C++ machinery largely conceals the underlying API, so I could swap it out if necessary. &gt; Regarding the other post: I -think- you can copy a render buffer (target) to a PBO (and then get it to a local mem) from other thread (with shared ctx) Hmm. It's not clear to me whether that would buy anything, though. While I'm using PBOs right now, I seem to be stalling the render loop, probably because of implicit synchronization - I don't know what I could be doing better, and I don't think having a command queue on a separate thread would fix it.
The cout was a slip. The _tmain was just there from the VS templates. The point of \n was that is was easier to use with the TRACE macros that I created (and some hate). Besides endl flushes the stream and I tend not to use it. Thanks for the comments, I made some changes addressing these issues, hope you'd find it more consistent now.
Hey, Here is a snippet from the code I found somewhere and am using now: // normal pointer //IStream * inStream = nullptr, // * outStream = nullptr; //encapsulated pointer CComPtr&lt;IStream&gt; inStream, outStream; hr = CreateStreamOnHGlobal( memBufferForIStream, TRUE, &amp;inStream );
4.7.3? In this one destructors are still C++03-like, but in newer (I believe, 4.8.something) it is fixed. You have to manually specify noexcept( true ) or switch to 4.8.* gcc. http://stackoverflow.com/questions/15721544/destructors-and-noexcept Oh, and pardon my clunky english. :)
Ooops, thanks for the pointer. Fixed now.
Not sure I am understanding your comment correctly but, I think the answer is, we didn't want to change the native gcc in the OS. As a result, we deliver the "newer tools" through software collections (http://bit.ly/fedora-scl). The software collections also supports forward binary compatibility. If you have any other suggestions or comments please feel free to send an email to rheldevelop@redhat.com. The component is still really new and we are definitely looking for feedback.
I still have huge MFC apps to support, so I am glad some things are still being fixed. ATL is still great for creating COM objects, and now static! Awesome!
Why not use Boost.Python?
&gt; Be careful, WRL (used to be known as WindowsRT before that got stolen for the ARM laptops) in windows8 + metro apps only. You /may/ be able to get away with using just the ComPtr part, but I wouldn't be surprised if it broke in interesting ways. If you're going for a win8 metro app though, use it. No, that's not true. WRL is just a regular C++ library. Microsoft recommends using ComPtr (part of WRL) instead of CComPtr (part of ATL). CComPtr was designed 20 years ago, and contains a bunch of dangerous features (like implicit-conversion-to-pointer-type).
 { ComPtr&lt;ID3D11VertexShader&gt; solidColorVS; d3dDevice-&gt;CreateVertexShader(..., &amp;solidColorVS); } // vertex shader released when this brace is hit
So much text for such a simple concept: save the state before changing it and resore it afterwards.
so far i've only used pthreads; is std::thread good? 
&gt; Be careful, WRL (used to be known as WindowsRT before that got stolen for the ARM laptops) in windows8 + metro apps only. You /may/ be able to get away with using just the ComPtr part, but I wouldn't be surprised if it broke in interesting ways. If you're going for a win8 metro app though, use it. It comes with Visual Studio 2012, and not Windows 8. It will work in Windows XP, Vista, 7 and 8.
I've actually tried that but found it very hard to do. There's so many options and possibilities that change everything...for example, the code given in that sample is for a windows 8 metro style directx XAML app but I am writing a windows 7 desktop app..so that example is not applicable...
WRL is very similar to ATL; you would use Attach to assign to a CComPtr and/or ComPtr so as not to increase the reference count. 
And as others have said you can use one to begin with and use &amp; Not to be pedantic but it might help to understand that these are pointers to interfaces rather than objects. 
Still doesn't work. Because I use this variable in several functions, it cannot just be instantiated by ComPtr&lt;ID3D11VertexShader&gt; solidColorVS; it must also be declared in the header file which I do like so: ID3D11VertexShader* solidColorVS; When I attempt to run this, the app halts and after a few seconds I get a message about my video card recovering from a halt. Do you know how I should declare a variable that later will be instantiated as a ComPtr? Also, I just realsied I am using WRL/client.h to provide by ComPtr. Maybe I should be using ATL instead? 
What is the difference between a CComPtr and a ComPtr? ATL seems to be an older library *but* I am writing for windows 7; perhaps I should be using ATL not WRL?
&gt; &gt;Sorry, there was a problem with your last request! &gt;Either the site is offline or an unhandled error occurred. We apologize and have logged the error. Please try your request again or if you know who your site administrator is let them know too. The ironing, it burns
The only time you could ever willingly use undefined behaviour is if you're absolutely 100% certain that your code will forever and always be run on a very specific machine compiled with a very specific compiler and you know *exactly* how that code will behave under those conditions and it will never be used in any other circumstance ever. Which is never. To add to your answer, any behaviour described as *implementation-defined* by the standard is required to be documented by the implementation. So look up the documentation for your favourite compiler. For example, [GCC documents the implementation-defined behaviour for C++](http://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Implementation.html#C_002b_002b-Implementation).
&gt; How do I know if I'm using a big endian or a little endian machine? The ice you stand upon here be thin; tread lightly. There's probably other cases where it matters, but the only time I've run into this is when transmitting raw bytes across a network (to a machine of potentially unknown endian-ness). It's best to use `hton`\* and `ntoh`\* (or some equivalent) than to try and manage it yourself, especially if the code may ever some dark day in the future be run on some _other_ machine. Most other [ab]uses of knowing a machine's endian-ness are probably not something you'd want to put in production code (e.g. [type punning](http://en.wikipedia.org/wiki/Type_punning) or bit-banging as mostly unneeded "optimizations").
Thank you for the links! I was kind of hoping I wouldn't have to look up each one individually, seeing as how other questions like these will pop up as I dig deeper into C++. As you can see, answers usually aren't as clear as "x86 is little endian always" and more along the lines of "this is what it used to look like on these glorious old platforms" and "here's how to check it (during runtime!)".. It's not like these things actually change all that often for desktops (otherwise how could there be off-the-shelf software?). Kind of like Herb Sutter putting that die shot of the Intel Itanium on his slides .. I mean, really?! How many people programmed for that thing, even when it was popular? Why not present a more common case like a Core2Something or an iSomething CPU instead? I was just kind of hoping there'd be a collection of these details somewhere, after all it is common knowledge to some degree. Nevertheless, thank you for the help - I do appreciate it. My rant above is just because I'm tired of having to look through all these (seemingly?) irrelevant details, while just trying to catch up on what everyone else already knows. &gt; NO. NEVER Well, that works in theory .. but when you e.g. look at things like whether the numbers stored in a pointer keep increasing or decreasing after allocations, and try to infer things from it (like in that SO answer), then you're essentially utilizing undefined behavior.. Which is why it's still helpful/interesting to be familiar with these more common cases, imho.
Sure it's applicable, they're calling the same functions and using same classes :).
And instead of using push, disable, pop, you can just use suppress by itself (presuming you only want to disable the warning for the subsequent line). Eg) #pragma warning(suppress : 9000) http://msdn.microsoft.com/en-us/library/2c8f766e.aspx
Not undefined; unspecified: http://stackoverflow.com/questions/9086372/how-to-compare-pointers And in practice, NO, unless you're a systems programmer (e.g., working on Linux kernel, writing device drivers, low-level networking code, etc.) you should NOT rely on things like stack growth direction or endianness. In other words, it is extremely uncommon that familiarity with these will be of much use. If you're an application developer, you should use a library that encapsulates these details for you. And if you are indeed a systems programmer, then you already know these details in-depth. TBH, it sounds to me like you're observing that a systems programmer needs to know more platform-specific details than an application developer. Well, *duh*! :-) At the end of the day, since these are platform-dependent, "a collection of these details" is somewhere: manual(s) for your platform :-) 
If your code depends on the things you are asking about, you are either Doing It Wrong or you are in the 0.01% of programmers who legitimately need to know these things. I doubt that, given that you've been a Java dev thus far, you would suddenly find yourself in an OS, firmware, embedded, compiler, or similarly low-level C++ job. Look, play, learn. Open the hood of the car and see what makes it work. But when you're ready to write real code, close the hood, and open the standards specifications and CODE TO THOSE.
I don't use MFC, but I'm very glad to see some improvements to the ATL. I've been on the fence about whether to upgrade, because the C++ improvements are rather anemic, but this is one more factor pushing toward upgrade.
&gt; How do I know if I'm using a big endian or a little endian machine? &gt; Whether my stack grows from high to low or the other way around? Why would you possibly need to know these? Are you writing a compiler or using lots of inline assembly? &gt;what encoding do strings actually use utf-8 &gt; how do I know if int8_t is supported by my compiler I assume the macro INT8_MIN would be defined. Really though, if you need to use `int8_t`, you *need* to use it. Don't feel bad about the 0.001% of computers that don't support it. 
oh boy I'm really starting to get confused... I'm going for a windows 7 desktop app on x64. Even if WRL is available if I have VS2012, I don't think that's much use to me, since I want my users to be able to use the program without having to have vs2012 installed. I think I'm just going to go with ATL...
Use ATL unless you are targeting WinRT
I'm not sure I understand the part about the first example with evaluation order. Why would it sometimes print 347 447 and other times 447 337 ?
&gt; the C++ improvements are rather anemic Really? All of [these Core Language and Standard Library features](http://blogs.msdn.com/b/vcblog/archive/2013/06/28/c-11-14-stl-features-fixes-and-breaking-changes-in-vs-2013.aspx) in a single year?
With pImpl, from the point of view of the user of the class, it is just a class that lives wherever you put it, on the stack perhaps. The user doesn't have to think about the chunk of memory sitting on the heap, or manage it in any way. It is all taken care of behind the scenes. With a pure virtual interface, the user of the class still has to get the interface instantiated with some real implementation. The creator of the object will have to fully know the implementation details of the real object created, or a user will have to use a factory class to take care of creation and allow the details to be hidden. You can only hold a pointer to a pure virtual interface, never as an object on the stack, forcing you to use things like unique_ptr as an adapter if you wish to have stack-like lifetime management, or to be safely usable in containers. So to get all the functionality I have with pimpl, i need: a pure virtual class, a "real implementation" class, a factory, and unique_ptr. If you took your unique_ptr and added a constructor with the object creation logic, you'd find yourself almost with an object using a pImpl. It's just a matter of moving the member function calls out to the holding class so you can completely hide the implementation class and you are done. 
Yes, it is inexcusable to still not be feature complete on C++11 by VS 2013. As it is, I'm only using Visual Studio for legacy code now. I'm using gcc for new code using C++11 features. So improvements to the ATL, which I already use in some projects, are a motivation to upgrade. Still-incomplete C++11 support does not motivate me.
This response is worrying to me. The problem with those macros is not the intent but how badly they are written.
On Windows char uses your system locale encoding, while wchar_t uses UTF-16.
&gt; I'm using gcc for new code using C++11 features. Including regexes?
slides?
If you want old platforms, know that bytes (chars) aren't always 8 bits, ints may be only 16 bits and longs may be no longer than an int, and the machine may use 1-s complement instead. And use 14 or 18-bit opcodes.
&gt; ints may be only 16 bits and longs may be no longer than an int True, then false. C89 required `long` to be at least 32-bit.
Look up different schools slides for assembly language and c classes, do the tests and assignments as well. You'll learn it very well. If you need access to any of these materials, let me know. I can give you some links from my school.
I think [these](http://www.pvv.org/~oma/DeepCPP_NDC_Jun2013.pdf) should be the corresponding slides (found on [http://olvemaudal.wordpress.com/talks/](http://olvemaudal.wordpress.com/talks/)).
I'm afraid you misread the example. In the expression `foo(3) + foo(4)` there are two subexpressions `foo(3)` and `foo(4)`. Because order of evaluation is unspecified, the compiler is free to chose which subexpression is evaluated first (so either `foo(3)` or `foo(4)` may be evaluated first). Therefore the two outputs may begin with either `34` or `43`, but always end with `7`, because addition of integers is commutative (`3 + 4 = 4 + 3 = 7`)
Ah! my fault entirely, I mistook it for another component
Thanks for the reply. It seems you basically confirmed what I was saying, but did a better job of emphasizing the labors behind my supposed alternative.
Take them for granted. If they do not exist (not to expect at all on any plattform that you will encounter, especially since you claim, that you aren't using exotic ones), you will get a relativly nice compiletime-error which is the best thing that could possibly happen then. The reason that these things are not required is most likely, that there are some plattforms that do not support this kind of integer (for instance: if you write for an eight-bit-plattform you should not expect uint64_t to exist). About the stack: Why do you want to no the direction of growth? I cannot think of even one way how this information is relevant in a wellformed (= not undefined) program.
But pImpl is way better!
&gt; Now they have two problems. I think you're being extremely optimistic here. :-) (Yes, I get the reference)
There are different levels of undefined behavior. Relying on something like integer overflow and underflow working correctly (i.e. wrapping around) is incredibly safe.
I agree and have used the idiom when its handy. From the view of automated unit tests, however, pimpls are less attractive.
Relying on something like integer overflow and underflow wrapping around is **incredibly unsafe**. See [Vulnerabilities Resulting from Undefined Behaviors](http://www.informit.com/articles/article.aspx?p=2086870), in particular [CERT Vulnerability Note VU#162289](http://www.kb.cert.org/vuls/id/162289), "C compilers may silently discard some wraparound checks." The compilers are allowed (and are increasingly exploiting this for more and more codebases) to _fully_ optimize-out any code affected by an UB like signed integer overflow. * http://stackoverflow.com/questions/14495636/strange-multiplication-behavior-in-guile-scheme-interpreter "The bug came into existence when C compilers started optimizing out overflow checks, on the theory that if a signed integer overflow occurs then the behavior is unspecified and thus the compiler can do whatever it likes." * http://www.cs.utah.edu/~regehr/papers/overflow12.pdf + "A C or C++ compiler may exploit undefined behavior in optimizations that silently break a program. For example, a routine refactoring of Google’s Native Client software accidentally caused 1&lt;&lt;32 to be evaluated in a security check. The compiler—at this point under no particular obligation—simply turned the safety check into a nop." + "Another illuminating example is the code in Listing 1. In this program, the same computation ((INT_MAX+1) &gt;INT_MAX) is performed twice with two different idioms. Recent versions of GCC, LLVM, and Intel’s C compiler, invoked at the -O2 optimization level, all print a 0 for the first value (line 6) and a 1 for the second (line 7). In other words, each of these compilers considers INT_MAX+1 to be both larger than INT_MAX and also not larger, at the same optimization level, depending on incidental structural features of the code. The point is that when programs execute undefined operations, optimizing compilers may silently break them in non-obvious and not necessarily consistent ways." + Undefined behavior also leads to time bombs: code that works under today’s compilers, but breaks unpredictably in the future as optimization technology improves. The Internet is rife with stories about problems caused by GCC’s ever-increasing power to exploit signed overflows. For example, in 2005 a principal PostgreSQL developer was annoyed that his code was broken by a recent version of GCC: "It seems that gcc is up to some creative reinterpretation of basic C semantics again; specifically, you can no longer trust that traditional C semantics of integer overflow hold" * http://blog.regehr.org/archives/213 "There are also, it should go without saying, compilers that do not have two’s complement behavior for signed overflows. Moreover, there are compilers (like GCC) where integer overflow behaved a certain way for many years and then at some point the optimizer got just a little bit smarter and integer overflows suddenly and silently stopped working as expected. This is perfectly OK as far as the standard goes. While it may be unfriendly to developers, it would be considered a win by the compiler team because it will increase benchmark scores." * http://blog.regehr.org/archives/880 "There is a long, sad history of programmers becoming seriously annoyed at the GCC developers over the last 10 years due to GCC’s increasingly sophisticated code generation exploiting the undefinedness of signed integer overflows. Similarly, any time a compiler starts to do a better job at interprocedural optimization (this has recently been happening with LLVM, I believe) a rash of programs that does stupid stuff like not returning values from non-void functions breaks horribly. Programmers used to think it was OK to read uninitialized storage and then compilers began destroying code that did this." * A few [examples](https://startpage.com/do/search?q=host%3Awww.kb.cert.org%2Fvuls+%22integer+overflow%22) of security vulnerabilities: + "Microsoft Windows LoadImage API routine is vulnerable to an integer overflow that may allow a remote attacker to execute arbitrary code" + "Adobe Flash contains an integer overflow vulnerability. This vulnerability may allow an attacker to execute code on an affected system." + "Mozilla products contain an integer overflow that could allow a remote, unauthenticated attacker to execute arbitrary code." Worth reading (and following, IMHO): * https://www.securecoding.cert.org/confluence/display/seccode/INT32-C.+Ensure+that+operations+on+signed+integers+do+not+result+in+overflow * https://www.securecoding.cert.org/confluence/display/cplusplus/INT32-CPP.+Ensure+that+operations+on+signed+integers+do+not+result+in+overflow * https://www.securecoding.cert.org/confluence/display/seccode/MSC14-C.+Do+not+introduce+unnecessary+platform+dependencies * https://www.securecoding.cert.org/confluence/display/seccode/MSC15-C.+Do+not+depend+on+undefined+behavior 
That sounds like a good idea - thanks!
I understand. I fully endorse exploring and understanding how it all works. But when it comes time to write code, forget all that you may have learned about that. If you depend on an int's size, you don't want an int. You want an int32_t or int64_t. If you have to check how much stack you are using, you shouldn't be using the stack.
It is possible to detect the operating system, kernel, compiler, compiler version, architecture name, architecture word size, and architecture integer word order (e.g. little endian, big endian, or little word endian), and the platform's newline character during compile-time. [This library](https://github.com/adityaramesh/ccbase#platformhpp) makes it convenient to access all this information, either using macros or a static constant data structure.
Also, regexes are now part of C++, even if g++ doesn't implement them. You can have three problems for the price of two!
I compiled it (why not?) with, "time g++-4.9.0-alpha20130811 -std=c++11 bf.cpp". During the compile I watched htop climb up some ~7 GB RAM. The output from time was: 72.33s user 3.21s system 99% cpu 1:15.72 total Know the error message output on the line with the computed type is some 11,289 characters long. FYI, clang 3.3 quickly (i.e., ~0.1 seconds) stops compiling due to template instantiation depth when only using the -std=c++11 option. Compiling it this way however: time clang -std=c++11 -ftemplate-depth=1000000 bf.cpp succeeds with this output from time: 36.57s user 1.14s system 99% cpu 37.799 total clang also nicely outputs a CR after each comma in the type expansion so the error message is not all on a single 11,289 character line. The clang compile also appears to run roughly twice as fast. EDIT: Unless you have many GBs of RAM don't expect a fast compile.
&gt;the numbers stored in a pointer keep increasing or decreasing after allocations For this specific case, you can just increment pointers as usual and the compiler will take care of it for you. For example, when you create an array: int * numbers = new int[4]; `numbers+1` will be the second item in the array, no matter what.
Whenever I start to suspect I might have at least *most* of the ins-and-outs of C++ figured out, I read something like this that shows me otherwise. Thank you!
Reminds me of a template meta-program I [wrote](https://gist.github.com/PkmX/6317480) earlier to transform Brainfuck programs into a C++ function which executes the program on the `BidirectionalIterator` (a pointer to the tape), `InputIterator` (for `,`) and `OutputIterator` (for `.`) of your choice.
Also, I started my tracker at 4 with the intent of skipping prime #s 2,3,5,7 to save on some code and compile time. 
If I get this right, then you are testing if a number is prime by dividing with 2..9? What about all the higher numbers? You must test up to the square root of the number you want to test. So you totally output far too many numbers that actually are not prime. [Here](http://stackoverflow.com/questions/1538644/c-determine-if-a-number-is-prime) is a good discussion.
That for-loop does not test for primes. Play it through with `prime=121`, which is 11\*11 so not a prime. Your program still counts it as a prime though, because you only test for divisors below 10. Have look at the [Sieve of Eratosthenes](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) or, if you want something faster but more difficult to implement, the [Sieve of Atkin](https://en.wikipedia.org/wiki/Sieve_of_Atkin).
wow, those were very helpful. As of right now, I'm just trying to see how fast I can get the code to work. I've been doing optimization after-the-fact to see how quickly I can get the program executed. I'm still fairly new to coding(halfway through sophomore year of Comp. Eng. degree). I have a finite mathematics course this semester that I'm hoping will help with these types of problems. 
It may sound odd, but this is one of the things that I really like about C++. There is always new stuff to learn and there is almost never a problem that cannot be solved by more advanced techniques.
Think again. You never need to divide by more than prime/2. Every result above this is &lt; 1. Actually for some other reasons it's even lower, the limit is the square root of the number. If you want some simple stuff to enhance speed, then test only every second number. Even numbers can't be prime, only odd numbers can. You could also store the prime numbers you already found and use those for the divisions. All other numbers are not relevant. But this would make things a bit more complicated. 
&gt; You never need to divide by more than prime/2. Actually, the square root of prime (which you can round down). If you can divide A by B, where B &gt; sqrt(A), then C = A/B will also be a divisor of A and by definition smaller than sqrt(A).
I personally think you made an excellent choice choosing c++. However, you are still very green to the language and should worry about learning the mechanics more than how to optimize your code. Don't worry, the compiler will do all the optimizations for you. In time, the topic of optimization will come naturally as you study the mechanics of the language in depth. Regarding your problem, try not to hardcode 10001. Instead, have it as an input argument to your program. Finally, read up about prime numbers. One freebee on primes: If you want to check if 1000 is prime, you need to check if it's divisible by all primes &lt; sqrt(1000). Think about why that's the case. Have fun!
using everyone's help I was able to get the right answer(and much quicker). I'm not sure how to get 2 or 3 to pass my prime check however. 
&gt; 2. I just realized the error of my ways. Should I stop count at prime -1? That would work, but you don't have to go that far. Consider that the factors of a number are always paired; factor(24) -&gt; 1, 2, 3, 4, 6, 8, 12, 24 1 x 24 = 24 2 x 12 = 24 3 x 8 = 24 4 x 6 = 24 If you find a factor in the first half of that list, then you simultaneously find the paired factor from the second half; which means if the entire first half is empty except for '1', then the second half is empty except for the prime, and you don't have to search it by going all the way up to prime-1. So the question is, what is the largest possible value that could be in the first half of a list of factors? That is, what value is at the boundary where the two halves meet? 1, 2, 3, 4, ?, 6, 8, 12, 24. And since the values in the first half multiplied by the correct value from the second half equals 24, you're looking for the positive value where ? x ? = 24.
I realized that after I posted. "correct" code is above in my edit. Still not perfect, but it outputs the right answer. 
sqrt(2) is ~ 1.4, so if you check all the integral values from 1 to 1.4 and find that the only divisor in that range of two is 1, then 2 checks out as prime. sqrt(3) is similar. for (int i = 1; i &lt;= sqrt(n); ++i) { if (n%i==0 &amp;&amp; i!=1) return NOT_PRIME; } return PRIME; Or since you know 1 will always be a divisor you can skip it: for (int i = 2; i &lt;= sqrt(n); ++i) { if (n%i==0) return NOT_PRIME; } return PRIME; This never bothers to check any divisors because it starts at the next integer greater than 1 and finds that that integer is already larger than the square root of n. It just says any value with a square root less than 2 is prime. 
it's usually a good idea to read the sidebar when first visiting a subreddit. as you can see, /r/cpp is more for general news and topics related to C++, whereas /r/cpp_questions is where you should have posted this thread. so if you encounter any c++ coding problems in the future, that's the place to go. in any case, you seem to have solved your problem by following advice rather than being given a correct implementation by someone, which is far more useful than a few karma points. cheers!
Honestly? Hard-code them. The one I use for real project has the first 50 or so hard-coded. Joke-versions always have the first 2 or all the single-digit primes hard-coded.
That is exactly the reason. There are so many subreddits that are dedicated to newbe-questions (/r/cpp_questions, /r/Cplusplus, /r/learnprogramming…), that it took me quite a while to find this one, which is finally about news, advanced stuff and some people presenting their code. As the sidebar here is *really* short and mentions the correct place to ask questions in the second(!) sentence in bold(!!), I don't see an excuse not to read it. Therefore I vote this kind of posts down on principle and would encourage others to do the same.
Yeah almost never a problem, except for the problem of writing code that is easy to maintain, can be debugged and tested sensibly, can be changed and worked on without pages and pages of demoralizing error messages if one tiny detail goes wrong, etc... Unfortunately for me anyways, when I am delayed on a product or failing to meet some business requirement, it's usually not because I didn't use some advanced C++ technique, if anything it's because I used too many.
stroustrup be praised. amen.
You use `prime/2`. In the example I gave with 24 that would mean your loop conditions is `i &lt;= 12`. But notice that 12 is actually the largest factor (other than 24 itself). You're looking for a value in the middle of the | V 1, 2, 3, 4, ?, 6, 8, 12, 24. and to get that you solve: `? x ? = 24`
I apologize, I'll keep that in mind for future questions. 
Yeah, I spent a whole lot of time getting container things to work, I figured it was an interesting detour into generic template programming land. Functor will be its own type class, though I might call it mappable to avoid the confusion with the c++ definition of functors. I won't have a distinction between fmap and map though, since fmap for lists is the same as map and feels redundant. How do you make a `future` into a Functor? The same way as normal functions?
I'm not. OS X 10.9 aliases gcc to clang. ~/scratch ❯❯❯ gcc --version ⏎ Configured with: --prefix=/Applications/Xcode5-DP6.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1 Apple LLVM version 5.0 (clang-500.1.74) (based on LLVM 3.3svn) Target: x86_64-apple-darwin13.0.0 Thread model: posix
Future has a pretty decent monadic interface, if you include the support for chaining them together (I think this is coming in C++14, but don't quote me). Assume future&lt;T&gt; has a member function then() that takes in an arbitrary lambda of type T -&gt; future&lt;U&gt;. Then you have a way of injecting (return in Haskell) types into a future&lt;T&gt; (constructor), and a way of chaining them ( &gt;&gt;=, or bind in Haskell) which corresponds to then() in C++. You just need to prove the monad laws and you're golden! Even if future&lt;T&gt; doesn't pass the laws, it at least supports the interface, which in C++-land I think will be more important. We can treat monad as a design pattern. And since all monads are functors, we should be able to get the functor interface for free. I have some semi-working code for monads in C++ that, through simple inheritance, exposes global operator overloads that all your type to be treated as an arbitrary monad. All you need is a unary constructor that creates a type&lt;T&gt; from some T, and a function for application (I call it bind, but think of then() again) and you're cooking with nuclear power. The code isn't ready for prime-time yet, so I've held off publishing it anywhere. Interface driven programming in C++ is awesome. Some day we might even have a Monadic Concept!