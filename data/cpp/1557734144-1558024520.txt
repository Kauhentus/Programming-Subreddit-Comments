&gt;packages at random points in time There is nothing random about it, it would be 1. when a new software version is released and added to the repos 2. when you decide to upgrade your packages The rolling model is much simpler for users since it's a lot easier to deal with small progressive changes than a lot of big ones every 2 years. If I report a bug to some software and it gets fixed quickly, I don't want to wait years to get this fix. Compiling everything myself also gets old fast. Obviously I'm not saying you should do this on a production server.
Great suggestion! I ported a big project to that layout as I found it very reasonable. Essence: Every target has `src`,`include`,`CMakeLists.txt`and the root folder has some "standard" names for subfolders (data, external, extras, libs, tests, tools)
It can be more performant as well. Thread 1: Locks mutex 1 Thread 2: Locks mutex 2 Thread 3: Locks mutex 1+2 If thread 2 first locks mutex 2, and then thread 3 locks mutex 1 and then blocks when trying to lock mutex 2, thread 1 is now blocked as well. Using std::lock, thread 2 would probably end up blocking on mutex 2 without holding mutex 1, allowing thread 1 to lock mutex 1 and progress.
How exactly do you get 8 as the output? I'm getting 12.
But doesn't this break backwards compatibility?
Yea, whoever designed C++ native casts was being idiotic.
The version in the OP has extraneous semicolons. Your version actually has the increments as part of the if statement. OP's version unconditionally increments and should display 12. Yet another reason why if statements should always be braced.
Both are valid c++ though
only kernel is in pure C
Not if it's the same as the screen shot you posted. That one prints 12.
Please don't post code as an image file. Thank you.
ABI stability and defined interface is probably the only thing that C has but not C++. Still, you can write the entire program in C++ and just expose C interface.
Why does MSVC all these things on the stack? Some weird backward compat? I'm not surprised that something not allowed by the language is compiled (many compilers allow more than the lang spec) but it's a surprise that it is allowed but doesn't work.
It depends on the access patterns that one expects. If one is likely to have truly random access, then nested vector is probably not good. If access is mostly sequential, it is OK I think. &amp;#x200B; One can also use a single vector of size S1 \* S2.
Im using printf quite often, std::cout is just horrible to format std::cout &lt;&lt; "a: " &lt;&lt; a &lt;&lt; ", b: " &lt;&lt; b &lt;&lt; ", c:" &lt;&lt; c &lt;&lt; std::endl; vs printf("a: %d, b: %d, c: %d\n", a, b, c);
Some things need to be broken, and comma being an overloadable operator is a mistake.
But is it easier to learn? Many people evidently have trouble understanding pointers well into their careers. To me, it's always that they are mistaking compile errors for being "hard to learn".
Yeah, usually I type first one and let IDE change it to the other one.
&gt; — which both do. Well, no, that's the point - in C, f() does not state that there are no parameters. It states "I'm not telling you the parameters", and f might be defined in a different translation unit, taking parameters. That is a great way of shooting yourself in the foot, but legal.
There are semicolons after each if statement, rendering them useless. the increments after them happen as they are not tied to the if statements.
sometimes you have to make the best of 500 bytes...
If it wasn't valid c++ it wouldn't be a useful answer, but c-style casts imho definitely fall under " ... \[Things\] to do the C-way"
Well, it follows the philosophy of "Things you should not be doing should look ugly / stand out in the code". If you have to perform casts all over the place it is very likely that there is some design flaw. Otherwise I don't think it really matters what it looks like. &amp;#x200B; Other languages that support `(type)` - style casts have ususally much stronger restrictions (a.k.a safeguards) on what those casts can do.
Embedded Systems, especially on microcontrollers with no more than a few KB of RAM and ROM
This should go to /r/cpp_questions probably, but I'll answer. Your problem most likely is that you are trying to multiply doubles with the integer pipeline. That's not how the x86 works. Floating point operations are done with the FPU stack and instructions.
The rule was written at a time where `[[nodiscard]]` wasn't a thing, and disallowing all discarded return values is less overhead than maintaining a white- och blacklist for cases where it does/doesn't matter. There are dumb rules in MISRA but this isn't really one of them.
I don't see the problem: The whole multidimensional array would be allocated as one block. ARe you mixing a multidimensional array with an array of pointers to arrays?
That's not trivial thou because C is missing lots of vocabulary types that are common in C++. Imagine you've this: ```cpp class myclass { public: explicit myclass(map&lt;string, string&gt; data); vector&lt;string&gt; some_process() const; private: map&lt;string, string&gt; data; } ``` How would you expose the "some_process" method to a C interface? You need to instantiate `myclass` which requires a `map&lt;string, string&gt;` and you need to somehow wrap the returned `vector&lt;string&gt;` in a C type. I've done this stuff lots of times and they always turns out ugly :)
But then the f in the other translation unit is simply a different function? I don't see how this relates, maybe you can provide an example?
No because there is no function overloading in C, dispatch is based on the function name only.
TIL, I stand corrected.
This is probably what you really want : http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1228r1.html
Breaking boost::phoenix though? It will trap people that can't upgrade again.
It \_is\_ that - at least in function parameters. Hilariously, T\[n\] is also an alias for T\* in parameters - the 5 is ignored entirely.
I don't think it can be pretty. I have seen C APIs taking callbacks of type `int(const char*, void*)` and calling them for each entry (here: string).
It's not being fully deprecated, however its use inside \[\] *is*.
I'm a C++ gamedev of 12 years now - the "C" things I've seen done in C++ have been: 1. manual memory management 2. C casts 3. Printf / sprintf / etc 4. Strings / arrays passed to functions as a raw pointer (null terminated or +size) Of those: 1. is being stamped out 2. is considered bad practice/dangerous (but still common) 3. is due to be replaced with std::format (hopefully that follows through into the games industry which is very std:: averse) and 4. should be using string\_view/span instead (at least one codebase I know of has had its own version of those for several years).
Java isn't fully memory safe. In particular, null references can still be a cause of bugs. This doesn't occur in languages like Rust. I agree with the distinction between C and C++ though, although while C++ offers abstractions that improve on C's model, it doesn't force their usage, and errors frequently still creep through.
It's a lot worse than that. In the current C standard, merely loading a pointer to an object whose lifetime has ended is UB. This is somewhat ameliorated by lifetime for dynamic storage being that of the dynamic storage in C, not the objects themselves. Still, it's rather hard to write code which has more than one thread of execution without doing UB. Or, rather, if you want to write UB free C code, you can't use threads, despite them being supported in C11. C++ has lots of that UB corner case quirks too of course. Like `std::vector` isn't implementable without UB in the current standard. Both committees are on the problem, it may get fixed.
That's rather your opinion in the first place. Sometimes it's not only about code readability which we got used to use for years, but for less error prone final products. You surely can write beautiful C code, but are you 100% sure that this code will be maintained by all the employees in the same manner? Moreover C++ right now has a lot of features which are hard and sometimes impossible to mimic in C. Like constexpr.
To be fair, with `float` those are identical - C casts are only dangerous with pointers where it will readily do a reinterpret rather than error if the cast isn't sensible.
You really, really should not rely on type punning working in a future C++ standard. We are actively working hard to enabling compilers to hard assume no type punning can occur so the optimiser can be much more aggressive than right now, where it basically must give up as soon as it sees a potential storage alias. It won't be for the C++ 20 standard, that's shipped, but the hope is strong for the C++ 23 standard that we can get these changes through. I raised the idea with WG14 that C bans type punning last meeting, despite that it's explicitly permitted by the C standard, and it could happen in order to retain compatibility with C++, and to more aggressively optimise C code. The C committee are aware that increasing amounts of C code is compiled as C++ precisely because of the much stronger optimisation (e.g. Python). Before people complain about how much of the world will break if we actively enforce type punning being UB, this would only affect unported old code compiled under the new standard. Code would need to be upgraded to use the currently undecided new facilities for specifying that storage contains reinterpreted objects. I am not downplaying the work involved here, the new facilities are decidedly incompatible with existing software architecture. A lot of existing zero copy serialisation code would need to be completely rearchitected.
C++ has very little which will take up extra ram/rom if you don't use it - and those are generally excludable via compile options (e.g. exceptions). I'm not just saying this theoretically, I have *used* C++ on embedded chips. Only in a hobby capacity admittedly, but I've used C++ on chips down to an ATTiny85 with 8kB flash and only 512 *bytes* of ram. Using C++ doesn't have to mean using heap allocation.
How would WLS2 ext4 drive work if you are using multiple distributions, do they all get their own VHD?
It's hard to balance all those opinions and ideas. There are useful use-cases inspecting the details of a `double` or `float`. &gt; I raised the idea with WG14 that C bans type punning last meeting, despite that it's explicitly permitted by the C standard ... I saw you write that before, it's a bit worrying I think, and Linus is not gonna be happy either [i.e. it will always be possible in gcc, possibly with a flag], he's expressed strong opinions on this particular subject in the past. What I was writing about really is the dis-allowed [UB] involving intermediate pointers pointing outside an array [like you could have implementing a non-zero-based array (a la Boost.Multi_Array). I just did some testing in respect of this, on a 2D array implemented over a flat array, the UB-version is at least 10% faster than the complying version (requiring an extra addition for every access). Admittedly (after reading up), this is UB both in C and C++, so maybe not a valid example anyway. Like I said, it's a bit worrying that C now has to become like C++.
Here's what I experimented with a few years ago: https://github.com/SuperV1234/ecst I wrote my BCS thesis on the subject and around this library.
Hi thanks, what should I do then?
I prefer C++ but one thing that I envy C is it's much easier to see what is going on. I have sometimes been amazed when looking at some open source C code for how clean and easy it was to understand for someone not familiar with the code. C++ is much uglier but I jokingly use to say it has inner beauty because behind all the ugliness is some awesome expressive power.
you can do double/float -&gt; uint64_t/uint32_t via bit_cast safely. this is pretty much a memcpy to the result. The memcpy get's optimized away and you are left with essentially a cast.
If comma overloading is an integral part of boost::phoenix, then they've made a mistake. I suspect comma overloading is just feature of boost::phoenix, and not an integral part of it. If people using boost::phoenix rely on comma overloading, they have also made a mistake. I'm pretty sure comma overloading was never promoted as a sensible thing to do, and to me was always presented as the bane of library implementers, having to resort to tricks to disable comma overloading.
&gt; ... bit_cast ... std::bit_cast? Is that C++20 [I know the std::memcpy 'trick', seen that on Compiler Explorer (one has to see it before believing), but I've seen people arguing that that entails UB as well]?
I end up having to relatively frequently cast between int, float and double to avoid (wrong) implicit types in math heavy code.
It depends on the underlying abstract model: For most (but not all!) big-O analysis, things such as offsets are implicitly or explicitly assumed to be constant (“uniform cost model”). I totally agree that it often makes sense to neglect an additional O(log n) factor in practice but the reason it’s included while sizes of offsets aren’t, isn’t a mistake or oversight.
I still use use raw function pointers instead of std::function whenever possible. I do like the std::function syntax and flexibility but I don't want to pay for it if I don't actually use the extra functionality.
Use FPU instructions. I'm sure your school course covers how those work if they want you to use assembly for this stuff.
Sometimes it's easier to write an explicit for-loop than to use std::for\_each().
I think there is a bug there. I didn't think you can have a constexpr variable in a constexpr method. It catches it when that isn't there because the non-const operator[] isn't constexpr, only the const variant returns a bool and is constexpr. with clang/libc++ it does generate just the ub2 instruction but, this is weird.
bit_cast will be in 20 yeah. I am fairly certain it isn't UB prior, but for sure after 20. Assuming the sizeof( Source ) == sizeof( Destination ) and both are trivial. cppreference has an implementation I think
It's not listed on [cppreference](https://en.cppreference.com/mwiki/index.php?title=Special%3ASearch&amp;search=std%3A%3Abit_cast) at all, that's why I was asking.
Expanding on that: What is probably wanted was: typedef std::queue&lt;std::string&gt; arg; arg param; func1(std::add_lvalue_reference&lt;arg&gt;::type(param)); // func1(arg&amp;) func1(std::add_rvalue_reference&lt;arg&gt;::type(param)); // func1(arg&amp;&amp;) // Which is same as: func1(param); func1(std::move(param)); // or func1(arg{});
I totally agree it's a bug. I don't see why so many people are so against me pointing out that this aspect of the language isn't well supported or implemented to a sufficient degree to rely on it to identify undefined behavior. All compilers have MAJOR bugs when it comes to this requirement and the amount of effort needed to fix it will be enormous.
No.
Add output formatting and you get: std::cout &lt;&lt; "a: " &lt;&lt; std::hex &lt;&lt; a &lt;&lt; ", b: " &lt;&lt; std::dec &lt;&lt; b &lt;&lt; ", c: " &lt;&lt; std::oct &lt;&lt; c &lt;&lt; std::endl; // some code later std::cout &lt;&lt; "d: " &lt;&lt; d &lt;&lt; std::endl; // d gets printed in octal, much head scratching ensues Which can be partially amended by appending `std::showbase` to the stream before printing numbers, which will add leading "0" or "0x" (and AFAIK hex/oct is all it supports), so it's at least visible later that number formatting is off. So gotta remember to follow formatted `std::cout` chains with a `&lt;&lt; std::dec &lt;&lt; std::noshowbase`, and that's the sane solution here. The generic alternative is using `std::resetiosflags`, which requires you to `#include &lt;iomanip&gt;` and can't simply be appended to the stream, rather you call it and append the result: std::cout &lt;&lt; std::resetiosflags(std::ios_base::basefield | std::ios_base::showbase);
Firsr, a std map from string to string is a low level detail, and often unwise to expose. An std function from string to optional string is less unwise, and can wrap a lot of different implementations. Use that. Returning a vector; that is a function that says it can fill a buffer for you. As written it says it has to allocate, but I'd bet dollars to donuts it can be written more efficiently not. An easy efficient replacement to a function returning a `vector&lt;string&gt;` is one takimg is `std::function&lt; void( std::string_view const*, std::size_t )&gt;`. Replacing a std function takes a similar bit of work. And the strings/string views as well. And everything ends up living on the heap. struct string_vt { void(*dtor)(void*); char*(*chars)(void*); // null terminated }; struct string_c { string_vt const* vtable; void* state; }; struct string_map_vt { void(*dtor)(void*); string_c(*get)(char const*); }; struct string_map_c { string_map_vt const* vtable; void* state; }; struct myclass_c; myclass_c* myclass_ctor( string_map_c ); void myclass_someprocess( myclass_c*, callback_strings_c ); Etc.
It's either that or something based on handles. Either way it's not great not trivial. In case of \`std::string\` there's also the issue that it doesn't map nicely to zero-terminated const char\*. \`std::string\` can contain '\\0' just fine and its size is stored separately. So in C you're going to need something like: &amp;#x200B; \`\`\`c struct string\_c { size\_t capacity; size\_t size; char\* storage\[1\]; } \`\`\` &amp;#x200B; I'm waiting for a better interop ABI since ages.
I think a big advantage that C has over C++ is its simplicity. When you're trying to debug a complex problem in a C++ code base, and you're not familiar with the code, unexpected stuff just *happens* all over the place. Constructors and destructors can make it very difficult to understand what code is actually executing; even worse if they have side effects! I don't think an improved debugging experience is worth the loss in productivity, though, so I wouldn't go back to the C way of doing things. Side note: It would be a GREAT debugger feature (hello Visual Studio debugger team) to inject calls to constructors and destructors in the source code view when debugging. They could be slightly grayed out or something. If presented correctly, this could help a LOT with understanding, at a glance, what a block of code is actually doing.
It depends exactly what you consider the C way, but function pointers are still very useful sometimes. If you want a stateless type erased callable it's still the way to go of course. And even aside from that, sometimes using them is a good strategy for performance. I don't think I can think of anything else.
Oof, I suppose printf() does count as the C way rather than the C++ way of doing things. In that case, yeah, my team will continue using that for the foreseeable future... output streams are hell to work with.
&gt;output streams are hell to work with. They're also pretty poor for performance (virtual functions everywhere!) and no good for localisation!
The discontiguous allocation will hurt cache usage, and forces an extra penalty of indirection that increases with the number of row accesses. Consider a common case of sampling four logically adjacent elements within a 2D array: 0 1 2 3 4 5 0 . . . . . . 1 . . . . . . 2 . . . A B . 3 . . . C D . 4 . . . . . . 5 . . . . . . These could be pixels in an image, cells in a spreadsheet, etc. [This godbolt link](https://godbolt.org/z/1MB2Zr) shows two functions that perform such a sample on a 2D int array passed by reference, one on a vector-of-vectors, one on a single vector with a known stride. (To give the functions something to do, we just sum the four values.) The work to be done, at minimum, consists of A) dereferencing an argument pointer to get the base address of a vector's buffer, then B) performing four reads to get the values. Both versions start out with A: `mov rdx, QWORD PTR [rdx]`. ("load a 64 bit pointer") And both versions end by doing B: (×4) `add eax, DWORD PTR [...]` ("load a 32 bit integer and add to result") But the vector-of-vector version also has two extra `mov ... QWORD PTR [...]` steps in between, before the int reads. This is because each sub-vector is its own allocation, the location of which is stored in the the respective vector's object in the meta-vector we were passed in. For every row we wish to examine, an additional pointer must be followed. This function reads from two rows and so must read two extra pointers. In the worst case, scanning a column of values - one from each sub-vector - will pay this price in full for each value read. By contrast, the single vector version does the minimum work necessary to accomplish the result. This is because it is able to leverage *a priori* knowledge about how the array elements are laid out relative to each other. An element in a contiguous 2D array will always be located at `base_address + stride * row_num + column_num`. This is so prevalent that x86 processors have instructions to compute memory addresses in exactly this way. With all the data in a contiguous 2D array, once we have read the base address from the vector object, it is a matter of simple arithmetic to determine the addresses we're interested in. All of these read requests can be issued immediately. There are other penalties incurred by the vector-of-vectors. Each sub-vector is another object, which means more object construction/destruction overhead. Each sub-vector allocation adds malloc traffic. The smaller allocations risk more memory fragmentation. Processors may also be able to accelerate contiguous 2D arrays when they are read in a constant stride (e.g. reading the nth value from every row). There's no guarantee that a vector-of-vectors will be allocated contiguously, or in order, which loses this potential prefetch bonus.
&gt; Discussions, articles, and news about the C++ programming language or programming in C++. &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. What bit don't you understand?
Random access or no, the extra layer of indirection incurred by the vector-of-vectors is just asking for trouble, and makes for worse assembly: https://godbolt.org/z/1MB2Zr If you know in advance that your data is densely 2D, there's almost no reason to not to take advantage of this fact. A vector-of-vectors is pessimized towards the worst case, which is containing variable length sub-arrays where the notion of stride is of no value.
putting it in a static_assert finds it too. But I think the point is, you are going to get more than zero. And right now, that is still awesome. Bring on C++20, and constexpr code will have access to vector and a lot more. So now I can choose to implement, at the cost of compile time, more code as constexpr and give the compiler the best opportunity to either const fold my stuff or have full view of the code and optimize it more heavily with the added benefit of much of my code getting compile time UB checks. def not perfect, but I have a bunch of things now where the unit test is a static_assert of a test method.
1. You can set the state explicitly. See `std::basic_ios::setstate` function. The state is also set by some operations on the stream, as specified in the documentation of those functions. 2. Bad state is set in irrecoverable errors. For example the documentation of `std::basic_ostream::put` says *"If the output fails for any reason, sets badbit. ".*
I think C still should be leached in University, for some reasons: \- It's a simpler language than C++ way more simple \- It's useful when learning data structures, like linked lists, binary trees, hash tables, etc \- C is everywhere \- C++ is OVERWHELMING for computer science students. Don't get me wrong I would prefer C++ (or let's say, Rust) unless I'm forced to use C. But the simplicity of C is helpful when learning data structures and algorithms.
Have you tried using Swig? It's meant to create glue-code for interfacing with other languages, but for C++ it first creates a C API. &amp;#x200B; [http://www.swig.org/Doc1.3/SWIGPlus.html#SWIGPlus\_nn3](http://www.swig.org/Doc1.3/SWIGPlus.html#SWIGPlus_nn3)
Raw pointers are very useful if used right: - Custom allocators - Optional references - Interfacing with C APIs - `std::reference_wrapper&lt;T&gt;` is annoying to use. &amp;nbsp; Post C++20 specific: `volatile`. Some people know how to use it right and need it, but C++ is trying to tell them "Hey, you don't want a keyword, you want `std::volatile_store()` and `std::volatile_load()`!"
Ah, that must've been why I thought it was, but yeah, I think I shouldn't post late at night when my brain is a working slow lol.
actually I am wrong, constexpr variables are fine in constexpr functions. I got trained by compiler errors in the past on that one. Still a weird compiler bug in all 3 compilers
/r/cpp_questions
&gt; Discussions, articles, and news about the C++ programming language or programming in C++. &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
&gt; Discussions, articles, and news about the C++ programming language or programming in C++. &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
IMHO cppcheck is bad because it's a simple parser, not a compiler. I use clang-check or clang-tidy which are better.
I zip my source code before committing it because it adds a security layer if something goes wrong.
&gt; It will certainly open the way to multidimensional array. What about just using array[row][col]
I think that's changed within the last few years.
\&gt; At this point I'm kind of wondering if it's worth diving into cmake... You won't have to dive very deep into cmake to handle 4 files, and doing so will teach you enough to get by for quite a while.
I absolutely *hate* seeing cpp gamedev talks where the speaker just tries to shit on all the C++ features, and their only arguments is that they don't even need them for their games, but they hate it because their devs abuse them. Like, if you don't need a vector for more than 3 different types, just fucking use vector for those 3 and refuse code that uses it for other types. Don't use "ur dur templates are programmed once for each template type. It's *much* easier to just write our own vector for each type 3 time!". Back to the topic at hand, though, I'd think you'd be in favor of teaching C if you're working in gamedev. The amount of libraries that rely on C to work is staggering. I can count on my hands the amount of game libraries I've seen that are "pure C++".
Source? Inb4: `_Generic` is _not_ true overloading and has nothing to do with linking a function that is declared without a prototype.
I've run into a lot of gamedev libraries that use C. Stuff like SDL and OpenGL are basically just C libraries (I know OpenGL isn't exclusive to gamedev). Some of the "C++" game libraries I've tried and use have their own types that are simply too basic to use in anything more than the simplest ways, but they give you access to the raw internals (typically C implementations), and knowing C makes it easier for me to implement solutions that use their internals to achieve what I want.
This has not changed for C. The symbol for a function in C is \_{function name}, so it cannot be made to support function overloading without a pretty major breaking change. In contrast C++ uses a much harder to read format (eg. _Z3foov) which encodes all the type information, making function overloading possible.
Yes, of course I know swig. However it's just a generator for the ugly code above; it doesn't help solving the problem, it just hides it. And beside, it only supports a [subset](http://www.swig.org/Doc4.0/SWIGDocumentation.html#SWIGPlus) ( they say it's a large one, but probably it depends on the codebase ) of C++.
Embedded systems where memory is a blessing. Otherwise I use c++.
&gt; It seems that C++ inherited this from C, but only in C++ does f() seems to have the semantics of “f takes no arguments” I don't understand what that means :-P C++ inherited what from C?
C is much easier to profile, debug, disassemble and obj-dump. Basically everything that involves name mangling is better in C since there is none.
&gt; is there actually anything you still prefer to do the C way memcpy()
I am similar in that I use my own functors over std::function often because of overhead.
A newbie asking for simple cmake advice, got good answer, which then turned into a mess. Sigh. Use the original answer with the added specs of C++ version: # In CMakeLists.txt: cmake_minimum_required(VERSION 3.5) project(MyProject) add_executable(my_exec src1.cpp, src2.cpp src3.cpp) set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_CXX_EXTENSIONS OFF) Then apply it in a Modern CMake style (for a bit more complex projects than four simple files) using targets and dependencies as described by: https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right/ Modern CMake is really not more complex than that. Of course there are details that are technical but you can safely ignore them for now and later refer to them in the reference documentation.
C for embedded systems, I use STM 32 where where use use HAL and Mbed.
Aside from raw pointers which we are trying to limit (we want to use references so that null pointer checks are super rare) but we generally failing to curb their use so that is a solid me too. &amp;#x200B; But I am curious, what embedded code has a lot of manual memory management? Most system I work with disallow anything even remotely to do with memory management. Objects are allocated as globals or on the stack and everything is pretty well entirely known at boot time. My off the cuff guess on the systems you are working with are.... some sort of network gear or stuff with a lot of network interaction? Please do hint at it :) I am genuinely curious. &amp;#x200B; As for printf-ing I am very ambivalent about the habit in Embedded of just constantly debug printing to a USART. Anecdotally we removed about 10% load of our microcontrollers by making all printing C++ through runtime controllable settings that is independent for different modules (we use a std::format like library for this stuff) and by doing that we can even allow higher frequency writing for modules in debug situations without overloading our systems. Another anecdote and a worse example we once got a vendor bluetooth stack at one point which spent more time debug printf-ing than actually working on bluetooth stuff.
There’s a lot of crappy programmers in any language
Thats corporate world. They'll be having big discussions about how you may or may not use static methods in classes and things like that.
Casts, and the fopen family, because it usually doesn't require any boilerplate to be as fast as possible.
My guess is you've gotten used to a standard for hiring that isn't present at your now previous employer. Lots of C++ developers really do know what's going on. I've also seen plenty who are every bit as bad as the C# developers you were describing.
&gt;They also rely too heavily on libraries to do things for them. No joke; they were literally taking ***1 byte at a time*** off a TCP/IP stream, concatting to their local buffer and passing to the built in XML parser asking "is this a message yet?". This resulted in their network code processing 3 messages every 10 seconds. There are obvious mistakes there, but using a (built in) library is not one of them.
This, 💯. I’ve spent over 15 years in C-based languages (C++ and Objective-C, mainly) and last year took a job in a C#/.NET shop because I thought the language and tooling looked awesome. And they are. But I’ve had *exactly* the same experience as OP: the folks I work with now are of an entirely different breed than I’m used to. The most disheartening moment for me was when I realized many of them have entirely missed the boat on threading. Some don’t even realize the code they write is by definition multi-threaded. (Aside:`async`/`await` is a cancer.) Thanks a lot for for posting this, it’s brave and honest of you. And as I’ve been struggling with exactly the same feelings for awhile, if anything it’s nice to know we’re not alone in our misery. 🤣👍
I wouldn't be surprised if the XML lib had the ability to read from a stream input source and with a little wrapping they could have got the lib to do all the work in a fraction of the runtime...
Its an interesting observation. I wonder if it has to do with back ground of employees. Maybe C# developers typically have more business backgrounds makes me wonder about python too.
I know as many bad C++ developers as I know bad C# developers... so it has nothing per se to do with the language (I just found a performance sin close to what your describing but in C++ code). On the other hand all the really good C++ developers I know don't have problems in basically any other programming language.
My current work is a .NET shop as well. I feel .NET developers think more like a technical business analyst than a software engineer. They don't really care about how codes are utilized by CPU and such, they just care about development effort to create this cookie cutter solution and how they should abstract the dependencies. One of their favourite words is 'decoupling'.
Consider yourself lucky for not having to work with JavaScript millenials... I've seen things that cannot be unseen.
Awesome. Now we just need a `sscanf` replacement as well.
Yep. Just ask the guys working on Kestrel if they do not what they are doing about network programming because it is C#. His expeirence was about competence for the job at hand. Those guys didn't know shit about network programming. They were going to read 1 byte at a time in C#, Java, C, C++, etc.
&gt;async/await is a cancer. Why?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bo4zl1/i_want_to_get_into_game_codingdesignprogramming/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It eats its way up the call stack. Though there are ways to stop it.
This is completely unrelated to the language. I've seen (and wrote) horror code in C++, C#, Python, you name it (ofc enterprise grade software).
But `[[nodiscard]]` is available now and using a whitelist as opposed to a blacklist is much more sensible... So why keep this check when many false positives are expected?
And how to name, abstract and group dependencies. That probably is 90% of how C# developers spend their time at my job.
It's the byte by byte method...it was insane. But the reason they didn't come up with something more clever is because the XML object exists. So they just relied on it and never really "thought" about what they were doing. I null terminated that shit straight away! Speed increased by an un-Godly amount.
OMG YES - Threading!!!! I have some stories about this as well. Absolutely terrible.
`fmt` has made me fall in love with C++ again, after doing mainly Python work for a while.
Oh they love all their buzzwords. 'the business logic layer' is the best one. Because if you ask them "what is the business logic layer" they literally just come out with "oh...ummm, the main programme...?!" They say it like they are unsure.
I'd probably rank him on the pragmatic front: [The Design and Evolution of C++](http://www.stroustrup.com/dne.html) tells a great deal about his down-to-earth approach to language design.
C does **not** have ABI. Maybe ABI of typical C implementation is more stable because there is not much need for extensive name mangling, but that's it. There is no guarantee that library compiled with older version of a C compiler would be consumable by newer linker, yet alone by a linker from another vendor.
compiler bugs are off topic for /r/cpp. Please post questions to /r/cpp_questions
Why?
Well at my work, C# developers are generally competent but will often give opinionated answers and if you deviate from what they say, you are ousted from the clique. There's also very strong focus on Devops - Dockers, Kubernetes, etc.. all this bloat to improve IT productivity. It's a factory mindset where they expect every unit of work to be cookie cutter so that producing multiple units of work can be very fast. C++ engineers generally tend to have craftsmanship mindset where they strive to be in control of very low level technical details that can almost border on electronic engineering. When they look at a C++ library, they aren't often content with just knowing how to use the API, many think they can do better than the API and strive to improve the inner workings of it or write their own. As Scott Meyer said in one of his talks, it's the two clashing mindsets - prioritizing developer productivity or software efficiency. C# developers often get paid big money to write very feature rich softwares and the business does not care if it's not super optimized as long as they have the option to scale up their hardwares in the future where needed. Whereas C++ engineers work on problems where they are not writing tons of flashy software features but the softwares require very demanding performance requirements where just a milisecond improvement can be significant to the business.
Bad programmers can write in any language. But it is important to notice that the things the language wants you to think about are not the same things that C++ wants you to think about. C# wants you to think about object lifetime, but doesn't want you to think much about memory usage. C++ wants you to think about both, because they're related concepts (the lifetime of an object potentially tells you when you can deallocate it). If a programmer has only ever used C#, they're naturally not going to be inclined to think about things that the language does for you.
I've been doing C# the year after it was released, and I _completely_ agree about `async`/`await`. It's exactly as bad as Java's checked exceptions.
Sadly there's still plenty of C++03 (which MISRA targets) work being done where MISRA is a thing, so naturally people would want to keep this check. It does seem like it's successor (AutoSAR C++14) kept the rule as well, which is unfortunate.
I found [this comment pretty useful](https://www.reddit.com/r/gamedev/comments/9xuaa6/how_should_i_start_learning_c_for_game_development/e9wcuq2/). I recommend really getting to know C++ however keeping yourself interested by making something cool. So on one hand, don't just dive in Unreal Engine or something similar without having good grasp of the language. On the other hand, mastering C++ takes years and you will fare better if you start making pet game projects a lot sooner than that. Good luck! Edit: More resources, some of them for later. https://www.coursera.org/learn/game-development https://www.gameprogrammingpatterns.com/ https://gamedev.stackexchange.com/questions/854/what-are-good-games-to-earn-your-wings-with
Will be. It was not voted in plenary yet. I'm hoping we can reuse the syntax in 2023 especially as we will have mdspan by then. we will see.
Just start writing :) You'll soon encounter problems and by googling for a solution you'll find lots of game design concepts to help you out.
https://handmadehero.org/ Games industry veteran Casey Muratori has a years-long educational streaming project in which he makes an entire game engine from scratch. It's the definitive grand tour experience for someone serious about learning what a real engine looks like from someone who has spent his career solving hard problems for some of the best in the industry. He implements collision detection, custom asset management, a SIMD software renderer, and much more. There are hundreds of hours of lessons depicting the development of the entire project. If you are serious about learning, and put in the time to follow along and practice yourself, it is a hugely beneficial series that will also introduce you to many more personalities and authors to learn from. Casey is a bit of a C programming curmudgeon who doesn't use many C++ features, but language details are not your foremost concern learning about game engines.
[https://en.wikipedia.org/wiki/Sturgeon%27s\_law](https://en.wikipedia.org/wiki/Sturgeon%27s_law)
[I think it is a solved problem](https://www.ageofascent.com/2018/01/26/stack-trace-for-exceptions-in-dotnet-core-2.1/). Could be wrong though.
I honestly thought cpp questions was for more beginner questions and this post seemed completely fine to me.
Gotta give it to them that they enjoy wasting time with the utmost boring crap. I don't know how they manage.
I've heard the word "facade" so many times that I want to shoot the next person that I hear saying that.
&gt; Some don’t even realize the code they write is by definition multi-threaded. (Aside:async/await is a cancer.) It's a bit hard to follow, but are you saying that async/await is by definition multi-threaded, or that they are using tasks and don't realize it is multi-threaded?
You can find a C++ 11 partial implementation at https://github.com/ned14/quickcpplib/blob/master/include/bit_cast.hpp A full implementation requires compiler hooks, but the above is not terrible on the clang compiler. GCC gets confused with codegen sometimes (I reported it as a feature request), for MSVC it completely fails to optimise, so I opened a bug report :)
&gt; when a new software version is released and added to the repos That is pretty much random. Software releases are not synced. &gt; when you decide to upgrade your packages You cannot, because you would risk to be out of security updates, which is a non-starter. Unless you are proposing supporting several branches of packages at the same time. At that point, you are basically back at what traditional distributions offer. &gt; The rolling model is much simpler for users since it's a lot easier to deal with small progressive changes than a lot of big ones every 2 years. Citation needed. It is way easier to being able to rely on something by *not* changing it and then check the release notes (and porting documents, and test) whenever the user wants. &gt; If I report a bug to some software and it gets fixed quickly, You cannot justify stopping a business even for a few hours just because some software got a new release that broke something. &gt; Obviously I'm not saying you should do this on a production server. Sure, but most desktops at an office are also production. Refer to non-Home editions of Windows 10: companies want to avoid any update that isn't strictly security fixes.
But if you lock them in the same order all the time and unlock in the opposite order, no deadlock can occur, ever, and no probing and backing off and all that would have to be done. That's been the basic standard multi-lock strategy forever, and it works perfectly. Of course the assumption is that if you ever need to lock one, you need to lock both, else they are separate things that only need to be locked separately. And that is almost always the case So a simple lock janitor that locks 1, then 2 and then unlocks 2 then 1 will never deadlock and will do it with minimum overhead. If you want to have a timeout, which is often not a requirement, then the janitor just catches timeouts and unlocks in the opposite order anything it locked. I guess the best way to go about the above would be to implement a 'multi-lock', not a multi-locker. It would implement the same lockable interface as the single lock, and so could be used in place of one. Give it two things that implement the lockable interface, for it to adopt and own. It then does the above logic just as though it were a regular single lockable object.
"only" kernel like one of the most important software projects of the last decades
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bo56dk/no_idea_where_to_start_with_game_design/enciokc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Completely agree: one is feature oriented and the other is efficiency oriented in theory. And in practice the former quite often leads to bad quality as a side effect
This isn't exclusive to C# or any programming language. I once saw an application in C++ that would open a file, read a line, close the file all in a loop, so for every iteration it would open the file, read a line, then close the file. It was one of the most baffling idiotic things I'd ever seen. &amp;#x200B; "// It works don't touch it"
I saw a guy on a professional website who had 15+ years of programming experience (mainly .NET) but couldn't understand why 0.1+0.2 == 0.3 was returning false. &amp;#x200B; Seemed like a good guy, but it was just very surprising to see how he didn't know this thing with his 15+ years of programming experience.
Threading is so mind-bogglingly simple in C# I don't know how anyone missed the boat on it. &amp;#x200B; These days you can Parallel.ForEach and the compiler will do all the work for you.
&gt; I saw you write that before, it's a bit worrying I think, and Linus is not gonna be happy either [i.e. it will always be possible in gcc, possibly with a flag], he's expressed strong opinions on this particular subject in the past. There are multiple things going on with Linus' opinion. Some of it is justified. For the need for `-fno-strict-aliasing` when `-O2` is on, all OS kernels that I am aware of need to do the same. This is because it is probably impossible to write a zero copy i/o implementation which is strict aliasing safe and doesn't do UB. Lots of people would like to fix this, but it's much harder than it looks, which is why we keep shipping standards, compilers and OS kernels which fall down on this. For all the other optimisations from `-O2` that Linux has to explicitly disable, there is very little sympathy from the standards committees, or the compiler vendors. Other OS kernels invested the significant effort to refactor themselves to work correctly under aggressive optimisation (apart from strict aliasing). Linux should invest the same effort, and probably actually is, just behind the scenes, so quietly that Linus may not be aware. A similar quiet effort fixed POSIX `read()/write()` acquire-release semantics in Linux with zero fanfare. Linus had a long history of declaring that whole part of POSIX to be insane, yet all the other OS kernels implemented it just fine, and now so does Linux. &gt; 'e.g. Python', what does that mean? Don't mix Python in it, please. It was just one of many examples of a pure C codebase which is intentionally compiled as C++. Lots of performance sensitive stuff does the same. &gt; Are you able to point me to some code that would be optimized better, if and when type-punning is prohibited? It's not type punning specifically. It's that the C++ object and memory model is much more amenable to aggressive optimisations. If your C code doesn't do any of the relaxed things which the C object and memory model permits, then you get better codegen if you use a C++ compiler instead of a C compiler. Many performance sensitive C codebases therefore target the C++ object and memory model, despite being written in C. &gt; Like I said, it's a bit worrying that C now has to become like C++. It feels a bit like C is getting features nobody asked for, sticking to C99 [don't take away my flex-arrays and vla's, hands off, please] will fix the problem, without missing out on too much, really. There's lots of C++ stuff coming in C2x. `nullptr`, `static_assert`, `bool` and so on. A delegation from WG14 may be attending the next WG21 meeting in order to port over more stuff from C++. I keep asking for C++ lambdas, but the main work item will probably be whether to reconcile the memory and object models, specifically whether and how to formally specify object provenance in maths or not. We may also decide on a common implementation for lightweight exceptions, WG14 made a counter proposal to my proposal, and everybody can see the outline of something in between which might just work, and finally eliminate the `errno` evil once and for all. C has the unique position of defining what the world is for almost all the other programming languages currently in popular use. Changes to the C language aren't anything like as important as changes to what the C language defines to be "the world".
Isn't there a warning or clang-tidy check or something that ensures that any C cast functions the same as a static_cast? So you can use C casts in place of those, but if you need reinterpret or const cast you need to use the C++ version? I've not tried using that on a real code base, but that strikes me from an in-theory perspective as likely being a good balance between safety and not reading like crap.
Have you read [Real-Time C++](https://www.amazon.com/Real-Time-Efficient-Object-Oriented-Microcontroller-Programming/dp/3662567172/)? It gives lots of strategies for doing embedded work in C++.
I got it working! I learned that I don't have to implement protocol buffer for `Sequence` class if I want to prevent copy of `feature` and `label` members, not the actual `Sequence` class as a whole. Example: ``` PYBIND11_MAKE_OPAQUE(std::vector&lt;Sequence&gt;); py::bind_vector&lt;std::vector&lt;int&gt;&gt;(m, "VectorInt", py::buffer_protocol()); py::bind_vector&lt;std::vector&lt;float&gt;&gt;(m, "VectorFloat", py::buffer_protocol()); py::class_&lt;SequenceReader&gt;(m, "SequenceReader").def("read_sequences", &amp;SequenceReader::read_chunk, py::return_value_policy::take_ownership); ``` Important to notice that I am using `pybind11/numpy.h` and `PYBIND11_MAKE_OPAQUE` to prevent copies
And you probably have never worked with grown Java programmers. Everything is a reference for them, once you discover there are tons of memory leaks everywhere
Bad programmers are in every language yeah man. But I think my point is more, their Computer Science is shoddy. They know an int holds a “counting number” for example but have no idea what an int actually is.
But Java has automated garbage collection, you don't have to worry about memory! /s
Please tell, I'm curious lol
@bmanga with the assist!!
Since you can't unsee them you might as well infect others?
This sounds like a case of the hiring manager not using fizz buzz to weed people out
Ok, but it's been discussed before and is off topic.
Yes but funnily enough, C, **the language**, knows nothing of padding, calling conventions, even sizes of integral or enumerated types - all of which is 100% required to speak of an ABI.
&gt; couldn't understand why 0.1+0.2 == 0.3 was returning false. Just in case there is some C# guy wandering here, [this is why](https://stackoverflow.com/q/588004).
I was rather referring to the fact that there's no "truly clean" way of blocking on an async method [1]. Instead of blocking, the recommendation is to make the caller async as well, and it spreads throughout the code base. But at times, you must block on async due to "reasons". And then you're in the land of `SomeMethodAsync().GetAwaiter().GetResult()` working unless it's called on a serializing SynchronizationContext (e.g., when running in an UI app). [1] https://blog.stephencleary.com/2012/07/dont-block-on-async-code.html
C++ is unforgiving, not as much now, but it definitely was. So a bad developer will perhaps be much worse in C++ than in another language. My experience is that good developers have good process. Test things in small batches, use good tooling, write tests etc... That always carries over, but it is (or at least was) a necessity for good c++.
2. Nicer, if a tiny bazooka is your weapon of choice.
CMake, and any other meta build system, by construction introduces more points of failure between invocation and getting the build target on the other end. If CMake does not save you significantly more effort, then you are introducing more incidental complexity for marginal benefit, which is something you should always be very cautious of as a software engineer. If you are already invested in CMake and are okay with its quirks and limitations, then there's not much point in moving away from it. But if CMake drives you crazy or if (like seems to be the case with the OP) you are uncertain if you should invest time learning it for a new project, then know that the "CMake is the de facto standard" is not necessarily true outside of the visible-C++-advocate-internet-sphere.
Look at the open issues. Plenty of unaddressed bugs, performance issues, and template improvements.
I can agree with that. I was working on my own C# project a while back, specifically writing an HTTP API endpoint. The first request would take a second or so to respond, and subsequent requests were in the region of 50-200ms (hugely variable) - and we're just talking the API equivalent of hello world here. "This is ridiculous" I thought to myself, whereas I know plenty of programmers who'd find that performance acceptable. I wasn't content until I managed to get it &lt;1ms, which I did by stripping out all the default bullshit.
Can't really offer much on the topic itself (I'm more fluent in C# than C++), but I remember taking this parallel programming course in university where some assistant wrote some code for sending images between nodes, and it was taking a suspiciously long time to the point where the whole goal of parallel computation wasn't really working anymore. Turns out the image was being transmitted in XML. Like this: &lt;pixel&gt;&lt;red&gt;200&lt;/red&gt;&lt;green&gt;0&lt;/green&gt;&lt;blue&gt;100&lt;/blue&gt;&lt;/pixel&gt; and so on.
I would say, C++ is made for performance and C# for convenience. But neither work as intended if you dont’t know what you are doing.
fair point, edited my post
No true developer* would ever touch python. ;-)
Oh man, that’s insane.
Lol
They hired two programmers. One senior and one normal guy. I was the normal guy. Within days I realised the senior didn’t know how to use threads. The idea of using one when I would suggest something to was crazy. I suggested we spawn a thread called HeartBeat to send a msg to the other computer and have that one reply with “still alive”, common as muck, right? Nope - “seems like a waste to have a thread for that I don’t know?” And another time he had crashing due to accessing data from two different threads, I suggested a lock. He basically ignored the advice and waited for the chief tech the next morning and asked him. Who came out with some random C# function that enables multi thread data access. He couldn’t tell me what it does. But I was wrong to use locks apparently. The function they used, literally just fucking locks the data structure you give it, you even pass in a lock if I remember rightly. Typed in a rush...
yes, but spawning threads dynamically isn't a good idea.
&gt; Of course the assumption is that if you ever need to lock one, you need to lock both If you think this is the case, why even have two locks to begin with? If you always lock both locks, why not just merge them into one lock?
If you get tons of Mbytes of memory wasted thanks to some XML, well, there's no gargabe collection that can help
Actually, I didn't say that right. The assumption is that, if you lock the second one, you always lock the first one. You might only lock the first one. So a tiered locking scheme of some sort.
To be fair, I think it took me at least 5 years of professional experienced before I bumped into that situation. It's rare to need to compare a float, except maybe when writing tests. Also, I believe you could go an entire career and not know floats are scientific notation under the hood, unless you're working with money or something else that needs to be precise.
`set (CMAKE_CXX_STANDARD 17)` sets the standard globally for the project. That is, all targets pick up the requirement unless you specify otherwise. This was the way to do C++ standards before `target_compile_features` was introduced. `target_compile_features` lets you set it individually for a target. The PUBLIC/INTERFACE/PRIVATE bit also lets you communicate to targets that might depend on it which standard to use. So if you have one target that doesn't require anything when linking but uses C++17 internally, you could specify private; and on another target that relies on C++14 in its outward-facing interface you could use `PUBLIC cxx_std_14`. TL;DR: They do basically the same thing, but `target_`\-based functions are considered better practice in modern CMake (and they allow more granular control).
1. You need cmake when you need to move a bunch of code from your executable into a library. &amp;#x200B; You need cmake at this point because then cmake will take care of build dependencies and ensure that any change to your library will force a rebuild to your library THEN build of your executable(s) that use the library. Any change to your executable will not cause the building of the library. &amp;#x200B; 2. You need cmake when you need to do some conditional build (i.e. check for python2.6 or python2.7... this is just one example). &amp;#x200B; 3. You need cmake when you need to check for specific software deps or compiler features. &amp;#x200B; 4. You need cmake when you want to automate more of your work flow (i.e. unittesting, packaging, etc etc). &amp;#x200B; 5. You need cmake when you want a fast recursive build... that is easy to maintain the build.
That's no fun. A good framework takes care of this stuff for you.
Guessing you mean [lock](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/lock-statement)?
Saved you a click: &gt; Doesn’t matter for C++.
You don't "grow talent" by definition.
T[][] isn't dynamic, right?
That's really interesting.
Did you mean “you’re describing”?
If/when it is standardised, do you think you'll switch to [`std::function_ref`](https://wg21.link/P0792)?
I'm glad you like it! :-) Just out of curiosity, have you ever used it for something gone public?
This is really great. My own source of inspiration in many cases. Great work.
OP allocated a `T[]` via `new`, so...
async/await doesn't dynamically spawn threads, it uses a thread pool. Pretty sure the Parallel.ForEach does similar.
I'm the author of EnTT. Personal opinion here, the result of a two-year project mostly about ECS stuff and so too. EnTT started with a registry that required to provide it with a list of components like it happens in your solution. After a while, the users of the library found that it was kinda annoying to use it during both prototyping and development. There are several techniques to get rid of this list and achieve even better performance at the end of the day (even though I didn't know them at that time). Therefore they asked me to remove this constraint. I wasn't convinced initially from this proposal/request. However, after more than 1 year and several projects developed with EnTT, I must admit they were right. Definitely right. I think forcing users to specify in advance components and systems could represent a limit more than a feature in the long-term. My two cents.
But probably not in Sweden.
You can write shitty code in assembler and you can also write highly optimised python. The point is to pay attention to the low level details.
There might be no *absolute universal guarantee*, but in practice most compilers and even platforms provide an *extremely* stable C ABI, at least for the core language, and often even for the standard library.
Holy crap. Naming conventions I had a guy who, every time he saw anything I wrote he would pause for 20 minutes to tell me about how his brother who’s a programmer says the most important thing about writing code is choosing a good name. I understand naming conventions are important but this is a prototype I whipped together during the 15 minutes in the day I could think straight just to get something moving; I never planned for anyone else to see that alpha code. He was a good PM though; just was sometimes frustrating if he would ever randomly pop by to read through what I was working on.
r/me_irl How and where do I learn?
Exception I can think of: platforms that only have proprietary compilers without c++ support. This exception should be rare in 2019.
Does fmt have an error handling story that works without exceptions? It's great, but I think the version I have pulled in just asserts instead of throws. This works fine since errors are rarer in fmt and the errors you do get are typically caught in dev/test, but would be nice to have real error handling capability without exceptions.
Maybe for some situation. It doesn't seem like std::function\_ref is an option if I want to store the callable. I guess std::function\_ref is mainly useful when the the callable is passed to a function without being stored. In these situations I would normally use templates the same way the standard algorithms do it. If the function is big and the callable is only called a few times I can imagine std::function\_ref being beneficial to avoid code bloat but if the callable is called inside a tight loop I'm not sure how it would perform.
That would definitely be attractive to have. You might want to collaborate with these guys if you decide to do that: https://midipix.org/
Something something Dennis Richie something something lunch napkin, maybe?
Toolchain files are an under explained and shared feature of cmake. I use them at home and extensively at work to make sure artifacts can be shared consistently. But most people see the common patterns of open source projects that sniff the compiler and turn on or off particular flags, and think that's the right way of doing things, when really it's just the self contained way that makes the Out Of Box experience for a random project a little better.
That can be problematic if you compose projects by \`add\_subdirectory\`. Changing a project to C++ 17, or C++ 2a, because one library would like that isn't good, since it can cause all sorts of ABI problems if you are bringing in libraries built outside the project.
rtfm
https://github.com/ValveSoftware/source-sdk-2013/blob/master/sp/src/mathlib/almostequal.cpp#L45
Here's the conversation I spoke about: https://www.reddit.com/r/cpp/comments/apj6bu/c_weekly_ep_154_one_simple_trick_for_reducing/eg9mh95/ Maybe tired-brain was remembering something that didn't actually happen, with regard to the issue that I spoke about. If I was making that up, I'm sorry. :( &gt; You sure? If the non-trivial class holds few strings, the class copy ctor will invoke strings copy ctor. I think that the call of the class copy ctor will be inlined but to few calls of string copy ctor. I don't think that you pay the sum of costs of all members all the time - I don't think that the copiler would reiterate over string copy ctor in each class that contains it. Sorry, I should have been more careful with my language. I meant that code generation happens for your code whether that function gets called or not, even if it gets inlined in every situation the compiler currently knows about. This is because the compiler can't know about every situation that might happen, including shared libraries and the like. My intention was to communicate build-time issues, not really compile time performance. Hopefully that explains everything. I should be more careful when redditing after midnight :-)
I think what you're saying is that you'd like to see smart pointers which have different ownership semantics according to runtime conditions. One example of such a smart pointer which I've wanted before is a `maybe_owning_ptr&lt;T&gt;`. This would only be responsible for destruction if it is the owner (tracked by an additional bool internally). I'm not sure I have a good example of where I'd want to write this into new code but I've seen old interfaces which conditionally take ownership and can imagine that a smart pointer would fit the rule of zero better.
I’m new to C++ so clicked the link 😂, i’m glad i’ve learned this sooner and not 15 years down the line 👍
"Why are you using `int` here? How big is an `int`?" *"32 bits."* "Is it always 32 bits?" *"Well..."* "How big was an `int` in 16-bit Windows?" *"Um..."* "16 bits. How big is an `int` in 64-bit Windows?" *"64 bits."* "No, 32 bits. Why are you using an `int` when you don't even know what it is?"
There are definitely bad coders in every language. However, some of the C# code I've worked with is definitely at the top of the list for some of the worst code I've seen. I was asked to make some changes to some C# code that pulled order data from a database and sent it to a PLC that ran a machine filling and boxing custom orders. Maybe a dozen fields for address, name, order number, etc. Should be pretty simple right? The code base was an absolute monstrosity. There must have been a dozen layers of abstraction, if not more, just to send some string data to a serial port on a PLC. It took me almost a week to understand it. The guys who put it together took almost a half of a year to do it looking at their repo. I could have written much more readable and efficient code over a couple lunch hours. Boggles my mind.
That’s a false dichotomy between printf and output streams. Libfmt
I'm currently screaming in MPI.
That’s the one. A simple “oh you should lock a data structure in some thread” thought leads to a 2 second Google of how you can do that with C# But they had some C# method where you pass the data structure in with a lock and it’ll auto lock that structure, no matter who is trying to use it. Saves you putting locks everywhere in line, nice....but now they’ll never know how it’s done. Know what I mean?
That’s my point also. The fact that people learn with C# means they are literally kept in a state of ignorance as to how “things are done”. In C#, there is usually a method for whatever you want to do. Meaning speaking to a C# coder you can’t talking engineering the same way.
Had a similar experience, but with Java... but as a wise reddit user once said, [https://www.reddit.com/r/cpp/comments/bo4dyd/from\_cpp\_to\_c\_rant\_about\_work/enc2aoj?utm\_source=share&amp;utm\_medium=web2x](https://www.reddit.com/r/cpp/comments/bo4dyd/from_cpp_to_c_rant_about_work/enc2aoj?utm_source=share&amp;utm_medium=web2x)
You don't need the exact science. Efficiency is less valuable when you have near endless resources. Getting it done matters more. I mean sure it helps to know ground up in cases. But end of the day an int that is auto handled size wise doesn't matter because again plenty of resources.
Is that a WinForms app? It sounds like how I used to do multithreaded access when I started learning WinForms, setting `Control.CheckForIllegalCrossThreadCalls` to false instead of doing a `this.Invoke((MethodInvoker)delegate(){/* ... */})`
we rank and file (where I am) C++ programmers have been preoccupied for so long with not shooting ourselves in the feet that we don't take anything for granted. well, apart from the need to read a dozen effective/exceptional/whatever books that teach us not to step on landmines. a poor C#-er can't even properly aim a gun at his foot. there's probably something in the gun mechanism that makes it a no-op. what an utterly boring life.
Found the guy whom has "-pedantic" set.
You found the guy who respects other people enough to not butcher the language.
I guess the biggest difference would be how far bad practices can get you in a fairly complex project before problems get out of hand. My first programming experience was with C, and the point where things were broken beyond repair arrived pretty quickly. As I moved to Java, a lot of the causes for said problems were abstracted, so I encountered "higher level" problems, and it took much longer for that point to arrive. As soon as I got back to C, poof, back to not going far. Took me a while to understand all those warnings, the hows and whys.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bo8jab/problem_with_void_rangesv3_transform/endf48v/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes; removed.
That's weird. Maybe it depends what kind of development you do. I do scientific simulation and run into it very frequently.
Javascript cannot be unseen
I know the guys, our goals are slightly different though. Their goals is to somewhat be a fast cygwin, my goal is simply to wrap Windows specific executable code in a different coat. As, again, I don't attempt to be compatible with anything, just change the executable format for the behavior I want.
Makes sense
Unfortunately no. I'll let you know if I ever finish something using it... I do recommend it when I can, so maybe someone will build something cool and public with it!
Removed; this thread isn't about C++.
I disagree that it relates to this topic. function pointers is not a c only feature, it's c++ too. as well as pointers to member functions and data members. also new, delete and raw pointers are c++, it's a different matter that those should not be widely used in a codebase, but there always may be some well encapsulated code which uses these lower level features of c++.
I like playing Worms.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bo9y54/book_recommendations_for_learning_cpp/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You can write extremely performant code in C#. Unless you're working on a resource-constrained device or something, I think the speed deficit for properly written C# compared to C++ is completely negligible. We as developers like to salivate over getting an extra 10 cycles out of a loop or something, but unless that manifests as a tangible benefit for a user, it's really just intellectual masturbation.
133 points. 7 hours. Not gonna upset that balance
Whenever I've encountered someone that used C for work, they were still with C89, *maybe* C99, absolutely not C11. C11 compilers don't have a complete library, for instance &lt;thread&gt; is not implemented. No one will use C11, let alone C17 and C2x.
Good job guys. I'm glad you're uploading the talks to YouTube as well. I attended using stdcpp many years ago and it was great.
&gt; Last updated 4/30/2019, 5:45:50 AM
Nothing. C++ has for more facilities for speeding up the code than C. One of the major problems of C is the lack of namespaces. In order to avoid name clashes, it is necessary to annotate all private symbols with static in shared or static libraries. Another major problems is memory management and implicit unsafe conversion that makes easier to introduce security vulnerabilities related to buffer overflow, stack overflow, numeric conversion and so on. &amp;#x200B; It is even possible to make C library with C++. A C++ library with extern "C" C interfaces or functions with C-linkage and opaque pointers can be used as ordinary C-libraries or binary components. The only reason one should use C is if he or she is crafting code for low-end embedded microncrontrollers or contributing to Linux Kernel.
write a bash shell in C. learn how to perform a buffer overflow exploit in your shell. Then study compilers
You mean you just fed the whole buffer into the xml parser, did you write just write the bytes of the struct to the wire, trusting the other side has the exact same layout of the data?
Mmk ty
It is when you include undefined behavior. Now if the compiler writers were less antagonistic towards the users, it might be a different thing.
&gt;And in practice the former quite often leads to bad quality as a side effect True, but this isn't due to the focus being feature oriented. The focus can be feature oriented and you can still write good software - you just need to know what you're doing. Knowing why using buffered IO over unbuffered IO is good or how your thread pool operates, for example, can make all the difference in performance. The issue isn't the focus, it's knowing the fundamentals.
CMake documentation really sucks and lacks examples. One of the best way of learning about and dealing with platforms idiosyncrasies is to look at CMakeLists.txt used by open source projects. &amp;#x200B; * Should I still use cmake with a relatively small project (4 cpp files) that I have on github if I want other people to use my program? CMake may not be the most pretty solution, but is one of the few that has the largest IDE support and works on all operating systems. CMake is not hard if you compare to Visual Studio Solutions, Makefiles, and other building systems. A project with just Makefile is hard to be used by any IDE or in Windows, there is no even a standard Make, actually there are GNU Make used in Linux, BSD Make and Windows Make (NMake). &amp;#x200B; All it is needed to build a project with CMake is: &amp;#x200B; add_executable(application1 srcA/source1.cpp srcA/source2.cpp) target_include_directories(application1 ./srcA "C:\\Boost\\ublas") target_link_libraries(application1 PRIVATE gl blas user32 ...) # Build DLL add_library(mathsolver SHARED srcB/lib1.cp srcB/lib2.cpp ....) &amp;#x200B; All what some guys who download the library or executable has to do build is: open the CMakeLists.txt with any supported IDE or just build from command line.
It does. The built in xml lib lets you pass in streams, URIs, and other Reader types so you can compose readers in both the [reader/fwd-iterator](https://docs.microsoft.com/en-us/dotnet/api/system.xml.xmlreader.create?view=netframework-4.8) and [DOM](https://docs.microsoft.com/en-us/dotnet/api/system.xml.xmldocument.load?view=netframework-4.8) APIs. It's trivial to do the right thing in most circumstances.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/boaeh9/good_books_for_beginners/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This mindset is how we get shitty software. You don't need to micro-optimize every little thing, but there's a minimum bar of knowledge and competence that I expect people to either know or be eager to learn about.
The big disadvantage of C over C++ is it's verbosity. When you're trying to debug a complex problem in a C codebase, and you're not familiar with the code... good luck figuring out where the thing you're concerned about actually happens, cause for every line of code a C++ program might have, a C program's going to have about 20, none of which make it clear what those particular lines of code do, or that they're part of the same conceptual operation.
The possibility of using C or C++ depends on the particular embedded device. For low-end 8 bits or 16 bits microcontrollers, most manufacturers only provides C compilers. The problem of C++ is the higher code size and the complexity of building a C++ compiler. However, there are proprietary and open source compilers for 32 bits microcontrollers or embedded processors based on ARM core, MIPS core or Power PC. The ARM core that is the "Windows" of embedded world, has its production license sold by ARM company to hundreds of manufacturers such as Atmel, Samsung, Apple, Qualcomm and so on that add this CPU core into their microcontrollers or embedded processors. This core being used by most smartphones, IOT devices, printers, internet routers and so on. &amp;#x200B; TL;DR1 it is not possible to use C++ with low-end 8 or 16 bits uController such PIC microncontrollers from Microchip. However it is possible to use C++ bare bones or within an operating system with ARM-based microcontrollers, embeeded processors or development boards (single-board computers) such as Beaglebone black which contains an ARM-based processors. &amp;#x200B; The greatest advantage of C++ is the abstraction through classes that allows greater code reuse and separating the client code from implementation and changing each other disrupting one another. Despite that C lacks object oriented programming support, one can emulate OO techniques in C using opaque pointers to incomplete types not exposing the data structure and only allowing manipulation of the data structure through the opaque pointers. See: * [http://verplant.org/oo\_programming\_in\_c.shtml](http://verplant.org/oo_programming_in_c.shtml) * [http://www.alejandrosegovia.net/2011/05/16/opaque-type-oriented-programming-in-c/](http://www.alejandrosegovia.net/2011/05/16/opaque-type-oriented-programming-in-c/)
I used to work on Bluetooth and that had a lot of dynamic memory allocation. I think a more general take on it is that global objects still count as manual memory allocation, just rather poor form of it. Basically, on an embedded system you want to be able to decide when and where from to allocate memory (DTCM vs SRAM vs SDRAM). In my current project, the SDRAM, which stores most of the large structures, will not be initialized until the USB negotiation is finished or a standalone PSU is detected. That means I _must_ be in control of when the memory is allocated (and freed) and trying to shoehorn that to what "modern C++" advocatesd recommend (which are _way_ overly simplistic) would just add extra complexity and bugs for zero benefit. I consider printf to include all custom equivalents. C++ streams just are a particularly badly designed API for formatting output. A properly designed (read: trivial alteration to default printf) printf alternative can easily handle selective debug prints with practically zero runtime cost apart from the flash the print statements use.
I guess that it uses memory-mapped files feature that allows accessing a disk file as it was an ordinary memory. Any changes in this mapped memory is immediately written back to disk and any object with all its fields allocated in the memory mapped segment in the virtual memory is immediately serialized.
Nobody sane sends embedded nulls in a std string, and with that ABI it isn't possible. But sure, pointer and length (no need for capacity in the ABI). Handles are no good, because half of the point of the above is you wrap it in a C++ API on both sides. It isn't much C++ to convert any of that into C++ types. With a bit of work you can even generate some C++ API boilerplate using TMP; r = abi_call(pfunc, a, b, c);
I use it for my codebase which is a C++14 codebase. I have had very little problems with parsing issues, and the few problems I had were fixed fairly quickly. They seemed to improve cppcheck a lot. There are a lot of checks that cppcheck provides that clang-tidy does not. Cppcheck can track container sizes, check for mismatching iterators, warn about dangling lifetimes, stl algorithm suggestions, and find copy and paste code(ie duplicate expressions). On the latest master(yet to be released), it supports tracking null pointers for smart pointers. There are still some syntax errors that will be hopefully fixed soon: * [8526](https://trac.cppcheck.net/ticket/8526) * [8890](https://trac.cppcheck.net/ticket/8890) * [9109](https://trac.cppcheck.net/ticket/9109)
Thanks for the link.
Haha sorry but I'm for sure not spending my time on building gdb. I have to regularly build so many things for work that are unavoidable because they're not in a package manager in the latest version, but a compiler or debugger, I just want to do \`sudo apt install gdb\` or the equivalent \`yum\`/\`pacman\` command. I expect those to be in an official package repo. It's good that apparently this will land in the ubuntu-toolchain-r PPA?
I am not 100% sure but I think yes, they do/will. There's a video around where they talk about some details of WSL 2 and you can see them "converting" a WSL 1 distro to a WSL 2 distro which IIRC they say creates a VHD, so converting a second distribution would presumably create a second VHD.
&gt;A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. gee thanks
I don't disagree philosophically, but I've never seen checking in VS solutions (and related files) go well, especially for a library. It's pretty much a non-starter in that case.
Linux kernel development. Because you have to. Embedded microblaze. Technically it can do C++, but all the support libraries are C, so what's the point? ZeroMQ. The C++ "library" is a shitty wrapper header. Same applies to a bunch of libraries that claim to be "C++" but are really just C. Command line argument parsing. Getopt isn't great, but it's here and works. There's no decent C++ equivalent that can be easily system installed. Sockets. Polling (kernel `poll()`) multiple file descriptors.
Do you know the current status of the proposal for C++20?
This sounds like homework, but it should be posted on /r/cpp_questions instead.
&gt;/r/cpp\_questions my bad, will do. Thanks!
The curt answer is no. A slightly less curt answer could be that the reason for new is run-time memory allocation on the heap, which is the only way to grow or shrink the list dynamically. A weirder answer would be to use smart pointers, because I feel weird advocating their use for practice data structures like this. But keep in mind that heap allocations are still happening. The answer you probably want can be found at r/cpp_questions &amp;#x200B; But I cannot have you moving along without telling you to change those list names (they are not descriptive, and they look like numbers at a quick glance), and fix the spacing around your arrow operators (get rid of them).
https://en.cppreference.com/w/cpp/numeric/bit_cast
I mean, don't check in the related files. Most of those are supposed to be local-only so you can have different working directory, program args, etc. from your collaborators. The case for CMake is stronger when you are building a widely distributed library, yes.
&gt; A newbie asking for simple cmake advice, got good answer, which then turned into a mess. Sigh. CMake in a nutshell.
&gt;I understand naming conventions are important but this is a prototype I whipped together during the 15 minutes in the day I could think straight just to get something moving; I never planned for anyone else to see that alpha code. Every company has the same origin story for a piece of software somebody hacked together that unexpectedly outlived its shelf life. It's easy to focus solely on the problem at hand and take shortcuts on maintainability (After all, it's just *me* working on this right now) but you'll rarely find time to go back and properly address those shortcuts before you've moved on and the code is in someone else's hands. You'll never run into trouble doing it right the first time around. That PM sounds like they're doing their job well IMO. Making sure that code is maintainable and that it will outlive the developers who wrote it.
I've used it in 2013-2014 or so. Holy mother of all that's holy that's some ugly code it made. Ever since then, unless I would have some huge monstrous API that I would have through some unfortunate set of circumstances to maintain/extend, I would not use Swig. For something big: certainly, it beats writing crap by hand. For a few classes with around 20 native operations, i'll write it by hand, thank you very much.
All data structures can be implemented more easily in C++.
What are the types of x,y,z? Why are you casting them? Why do you not write a single constructor if you frequently need it?
You can write a toString template, and write: s = toString( "hello world" ) + toString(5) + toString( ", todays value of pi = " ) + toString( 3.14 ); template&lt; typename T &gt; std::string toString( const T&amp; t ) { std::ostringstream os; os &lt;&lt; t; return os. str( ); }
GNU is de facto standard for C ABI on Linux, and pretty much everyone assumes it will work the same way at that point.
There are many name demanglers though.
Raw function pointers are useful because it forces the caller to send a function with no internal state (outside of some functions with static members that are not so common). It avoids potential really bad performance if you end up sending stateful functions around. It's also much easier for the compiler to find what you are calling and inline it when needed than if you go through 5 layers of "zero-cost" code.
This currently works by making 2 calls/indirections, instead of calling a function with two parameters.
You can make a `volatile` type that wraps your value correctly for your needs, and decays to the type using the stores/loads internally.
r/cpp is not a sub for learning/teaching the basics of C++.
By that logic, it is the same for C++ though...
There are some breaks, like you don't expect exceptions to work if you don't have the exact same compilation settings, but with C it will usually just work.
Thanks! Somebody [a sneaky bugger ;-) ] fiddled with the web-site, the search that rendered nothing [which I added to show I did do the search] renders the requested result now [something good comes out of anything].
Yes. In a way, the reason this works with C is: C is dead simple when it comes to interfacing options (compared to other languages). There's only primitive types, aggregates and function calls, which is easy to keep under wraps, even though C language is completely oblivious to any ABI question.
std::to\_string has been in the standard since C++11: [https://en.cppreference.com/w/cpp/string/basic\_string/to\_string](https://en.cppreference.com/w/cpp/string/basic_string/to_string) You may want to see the link by /u/jonesmz above for more details, but that kind of concatenation is considered unnecessarily slow in most cases.
Thanks for that write-up, appears there's some good stuff coming to C as well, just don't throw away the child with the bath-water. Lambda's would be great of course, that changed a lot in C++. &gt; Many performance sensitive C codebases therefore target the C++ object and memory model, despite being written in C. Nit-picking, but it's C++ that happens to look like C.
Very fair point. Also one thing that is important for ABI stability is no overloading, so no need for name mangling.
But only for numeric values, right? &amp;#x200B; I don't buy the slowness argument. If it really really matters, one could probably define a variadic toString that uses += .
&gt;Does fmt have an error handling story that works without exceptions? Yes, format strings can be validated at compile time, for example`std::string s = format(fmt("{:d}"), "foo");` will give a compile-time error because `'d'` is an invalid format specifier for a string: [http://fmtlib.net/latest/api.html#compile-time-format-string-checks](http://fmtlib.net/latest/api.html#compile-time-format-string-checks) The API isn't super pretty due to current language limitations but it works.
&gt; ... but the above is not terrible on the clang compiler ... That's what I use, so good! I've stuck it [the file/impplementation] in amongst my installed repos, thanks.
Name mangling is not a problem if everybody does it the same way, just like struct padding, calling conventions and enum sizes. C++ adds 3 other moving parts: name mangling, virtual call implementation and exceptions. Which is a funny base to conclude that C has ABI and C++ has not.
&gt; They know an int holds a “counting number” for example but have no idea what an int actually is. For 99% of the cases, int is used throughout the standard library, hence is a "blessed, standard, default" integer type, and that's all they need to know. And that's the right attitude, at least in the case of integer types. [1] If they don't know about unsigned, even better, lest they be tempted to use it to represent "always positive" numbers. It took the scale of google and many (millions?) of years of run-time to find the integer overflow in Java's binary search, so not knowing how big an is int is not going to harm anyone. [1] Numbers are finicky. The only language that does it somewhat right is Scheme's numeric tower that implicitly "upgrades" the number if the result of an arithmetic operation can't fit into the types. Like `fixnum &lt; bignum &lt; rational &lt; complex`. Say you do `sqrt(INT_MIN-1)`... The subtraction will "upgrade" fixnum (assuming it's 32 bit) to bignum, after which `sqrt` will return a complex result. Even "mathematically sane" answer might not be desireable in some applications and you'd prefer an exception. On the other hand, Javascript has only "number", and for most high-level applications, "number" is all you need. Stdlib has `CountLong` (or smth like that, I never use it :p) overloads that return long when your collection gets over 2G elements. `FileInfo.Length` returns a (signed) long, as it should. Implicit narrowing conversions are forbidden (i.e., compile-time error), so you can't fuck up as easily as with C++. So when they encounter such a situation, they'll be forced to learn how big int or long is. (Unless they're stupid ignorants and just cast long to int.) Additionally, you can turn on overflow/underflow checking (`checked` statement) or compile with checking always turned on. In many applications, when you *know* you're handling small files, I'd find the code as `checked { return (int)fileInfo.Length }` acceptable. If somebody feeds the program a huge file, it'll burp. C++'s obsession with flexible integer types should become a thing of the past. "How big is an int" is an ego-boosting question designed to make the other person feel stupid. If they don't know it but work on a project where they *should* know it, they're working at way above their competence level. Some manager fucked up when putting the team together. This is in now way defense of their other deficiencies, like not getting acquainted with stdlib and reading streams byte at a time. But "what is an int and how big it is" should be not be of concern most of the time.
This is just plain wrong. As someone who has written realtime music and video software, I can say that it’s not about ”getting 10 extra cycles out of a loop”. It’s more about making the software possible at all. There really is no competition.
That's not true, though. For every one line of C there is also one line of C++ - the C++ just abstracts the code away more effectively using some additional language features. When debugging time comes around, you can't ignore it any more and you have to step through it.
Probably the first. `async/await` is *usually* multithreaded, unless constrained by a `SynchronizationContext` which forces the continuation to run on the same thread and thus leading to deadlocks if you try to block on async call. The default synchronization context will run the continuation on some free thread from the thread pool. A serializing sync context is set up by UI framework (WPF, WinForms) or ASP.NET (but fortunately, NOT ASP.NET Core). It gives you the illusion of single-threaded environment even though everything is massively multi-threaded.
That's more potential breakage, so while it is not 100% safe to rely on C ABI either, it has been kept mostly stable so far, while it is much harder to do so with C++.
Sounds like a combination of you not fitting into/being acquainted with business application development and their being half-competent. Because, when writing a business application, a lot of care has to be taken about object persistence. I have a bunch of assemblies defining just schema classes that know how to persist themselves to db or xml, whereas the "business logic" you're mocking has the algorithms and rules manipulating that data. It's not a buzzword, it's a necessary way of structuring a business app that's going to last 5+ years and still being able to access data written in its first year of life. In that context, "how big is an int" is irrelevant. What is relevant is "how do I extend the existing XML/DB schema without making existing data unreadable"? And it's far harder than you'd think.
Well first of all "realtime music and video software" is a pretty small percentage of the overall use of software, and secondly, if I was able to get C# to safely stop a 12,000 pound printer in less than a second, I think it's probably capable of performing pretty well. The speed fetish that most programmers seem to have is just weird. Why spend the _extra_ time working to make something faster when it's already faster than the users asked for? I understand the desire to write good code and leave a well-documented trail behind, but there has to be a limit _somewhere_. Writing good code for its own sake is fine until it interferes with producing solutions to problems.
I never said I can't or that it's a hard thing to do. I am saying that I don't see the benefit of doing that for those who really do have a real need for `volatile`. For a language that likes warning signs over guard rails, dropping `volatile` in favour of `std::volatile_{store,load}` seems like taking away the warning sign and placing a guard rail.
The coding standards we use at work recently re-allowed plain int (rather than int32) as it's 32 bit on everything current, except possibly some microcontrollers that aren't relevant to us. "long" is still banned though.
Part of the reason is that overloading `operator[]` to return a proxy that also has an `operator[]` overload is not clear at all, let alone when you have something like `mdspan` that can have any number of dimensions. The proposal authors probably could have tried to change the language so that `a[foo][bar]` can call `operator[](foo, bar)`, but there are still backward compatibility issues there as well, and quite possibly larger than what you get with repurposing `a[foo, bar]`.
12,000 pound printer software is also kind of exotic, isn’t it? :-) Most software a user runs everyday has probably been written in C or C++, including the .NET runtime and JIT compiler. The ”speed fetish” is about utilizing available resources efficiently to make other stuff possible, like running C#. Different tools for different purposes.
If cache misses are a concern, nested `std::vector`s are a bad idea. Read this thread: https://old.reddit.com/r/cpp/comments/bnueu4/multidimensional_dynamic_arrays_with_smart/enaeo0t/
The printers were _extremely_ exotic, given that we were an R&amp;D shop. &gt;The ”speed fetish” is about utilizing available resources efficiently to make other stuff possible, like running C#. Different tools for different purposes. See, that, to me, isn't a speed fetish. It's using the tools to solve a problem. A speed fetish is someone writing yards of unreadable template code just so he can get a speed up. A speed fetish is performing unbelievably esoteric compiler commands to get a potential memory benefit on certain systems. Wanting the solution to be quick and responsive is completely rational. But I feel like almost all of the C++ developers that I've known share this obsession. Once the program works and doesn't impede the workflow in which it runs, further performance enhancements add a swiftly vanishing amount of value.
&gt; Nit-picking, but it's C++ that happens to look like C. If it's 100% valid C, then it's C. (The C object and memory model is deliberately compatible with the C++ one. C code written for the C++ model is fully legal and portable C, but code written for the C models may not be legal C++. This is quite counterintuitive, but the C++ models are far stricter and less permissive of ambiguity, and will get ever more so with time)
&gt; If it's 100% valid C, then it's C. No, it's not, if you compile the code with a C++-compiler, it's C++, that's exactly the reason you give for compiling the Python code with a C++-compiler [because it's gives better optimizations]. If it's 100% valid C, then it's **also** C.
I'm currently (very slowly due to lack of free time) writing reference attach cast and detach cast operations for P1631 into the same repo. You'll already find a finished `ensure_stores()` implementation in there. The reference implementations use very inefficient UB to work, again clang does the best. GCC and MSVC fail to optimise. If approved, these new casts would finally enable a zero copy codebase with strict aliasing enabled, and that enables memory mapped I/o without UB etc. It's a very big if though. That said, WG14 greenlit them, so maybe there's a chance at WG21.
When targeting WSL, we use Clang or GCC
I don't think there is any *type erasure* going on with function pointers.
&gt; ... writing reference attach cast and detach cast operations ... I watched your presentation on YT [couldn't follow all the detail, but got the gist of it], interesting stuff indeed.
Out of curiosity, do you target Windows as a platform, or only doing Linux development? Could WSL + Windows, or Windows + Linux VM be an option for you?
I have seen some amount of C99 recently, not so much C11 except for small projects (also any project using a recent GCC and not specifying which version of C they're using since GNU11 is now the default option). Anybody using C11 will probably end up using C17 anyway at some point since it's mostly defect reports.
&gt; Haha sorry but I'm for sure not spending my time on building gdb. If you need to build the latest version of GDB, it is because you *need* it, not because you just want to use *a* GDB. &gt; I expect those to be in an official package repo. They are: the supported version, not the latest release which is untested. &gt; It's good that apparently this will land in the ubuntu-toolchain-r PPA? Those are unsupported.
We were writing military simulation software. Processing a message byte by byte is bad enough, but when those bytes are part of a massive XML....it's terrible. Our (simulated) jets should not be relying on Dead Reckoning THAT much. Come on man, give me some bloody credit!
&gt; "How big is an int" is an ego-boosting question designed to make the other person feel stupid. Unless the guy next to you is looking at an array of bytes recived on the network and has no idea that 4 of those bytes are an int...and the next 2 are a short...so on. Unless the guy next to you is staring at a 64bit int and wondering "how" it contains "3 shorts and some 0's" and he's sat there just looking at its integer output scratching his head. It's important! You have missed the point a bit I think buddy. Knowing the size of data types makes many aspects of our job possible. If I want to pack 3 shorts into an int64, with 16 trailing 0's, I expect the guy next to me to know what the hell I have done! Not sit there lookign at a number like 6546854646546 and wondering the fuck his 0's are!
As I say above; Knowing the size of data types makes many aspects of our job possible. If I want to pack 3 shorts into an int64, with 16 trailing 0's, I expect the guy next to me to know what the hell I have done and not sit there looking at the integer output, some random non-important number....and wondering where his 16 trialing 0's are. Or how they would sit there staring at a byte array wondering where their strings, ints, and other values are. They had no concept of "oh the first 4 bytes in this byte array are an int...." Hope that is more clear :)
&gt; Knowing the size of data types makes many aspects of our job possible. If I want to pack 3 shorts into an int64, with 16 trailing 0's Depends on the domain. It's a couple of years since I had to pack ints, and even then it was an implementation of some device protocol. 99% of the time I happily use an int and don't give it a second thought. So we come to the following applying: people are put to work on task at way above their competence level.
How can it be faster than not knowing the list? By ignoring the list you could at least get the same performance as without it (and maybe there is something that can be optimized if you do know about it).
In fact you can have dynamic containers from which you can literally remove pools when they aren't needed, without having to define different types and to copy over whole sets of entities and components. But yeah, those are rare cases, in general performance differences are negligible.
The article is about exploring.
I usually feel bad for downvoted posts... But what the heck is the point of this article?
C has as much undefined behaviour as C++, in terms of the base language. The same rules about aliasing and union punning applies, for example, but C++ actually has high level ways around them in a standardized library.
And nearly all other languages support C bindings. That is why new APIs like e.g. Vulkan still use it as de facto standard.
&gt;template&lt; class... Args1, class... Args2 &gt; pair( std::piecewise\_construct\_t, std::tuple&lt;Args1...&gt; first\_args, std::tuple&lt;Args2...&gt; second\_args ) - do you know what it is and what is it for? I strongly suspect you don't, and it is very important to know about it, because it's usage plays a great role when populating associative containers. Wow, you have some ego dude. Arguing that knowing the importance of this is important for the average person to program in C++ is just downright moronic. A person could program in C++ for 30 years an never use all the features of the language. But I bet you are a master at writing unmaintainable code because your ego compels you to go overkill on everything. You're the type of person that costs a company thousands of dollars because your code is unmaintainable by the average engineer which requires the company to higher someone more senior because you feel the need to validate your worth as a programmer by the complexity of your code. C++ becomes a difficult language when people like you code in esoteric ways that have uncommon pitfalls. I find it hilarious that you are accusing the OP of doing a disservice when you are the one ranting about pedantic issues like STL semantics like that matters at all. Don't you understand that software development isn't just about you, but for the people that come after you? Or maybe you just don't write very large or useful programs and that isn't an issue.
Yeah, the implementations I presented at ACCU turned out to be all wrong. WG14 pointed it out, they can't work right. But they did tell me what to do instead. Two steps forwards, one backwards.
Thanks for the reply (and for your book ;) ) I think I see now : )
That's exactly how it is! I think the TI compiler only supports C99 to start with but the default in the IDE is still C89!
Sorry to hear that, and better than 1 forward and 2 backwards.
"C" may not have an ABI, but _platforms that run C code_ do define strict ABIs that mean libraries (especially shared libraries) are almost always interoperable between compiler vendors and versions.
"GNU" is not an ABI. The ABIs for most (non-Windows) platforms including Linux are based on the "System V" ABI, which originated with AT&amp;T. Linux in particular also uses the ELF binary format which is part of the System V ABI, but other systems can and do use the run-time ABI with a different binary format.
Could you clarify: Did they actualy NOT use the builtin .net locking, and used some custom method instead?
Depends on the exact situation. When you convert from a stateless lambda to a function pointer, yes, there certainly is. It's also used to implement other type erasure mechanisms like std::function. The bottom line is that function pointers are indirection, unlike function objects and lambdas, but like std:: function. Indirection and type erasure are very closely linked.
The people I talked with told me that they use C89 because: - what the new standard provides has been implemented for decades by now (C89 to C99 are 10 years) - some use a particular embedded compiler that has security certifications, as they need them to release their firmware
Is avoiding typing those 2 extra characters worth the possible future issues? This is mostly an issue for external /'stable' API's though
As far as I know, not everyone uses GCC and if they do it's not the latest release, probably somewhere near 4.7. Also, just because GCC offers C11 doesn't mean it's complete, for instance they lack the threading part. But in the end, probably, everyone using C89 and C99 had already implemented their own thread abstraction. Or maybe they don't need to compile with multiple compilers or OSes, and just use the OS API.
OK, so this is *undefined behaviour*? std::function_ref&lt;void()&gt; f = []{}; f(); While this is well-defined? std::function_ref&lt;void()&gt; f = +[]{}; f(); :-/
No no, they had no concept of “locking” whatsoever. So when I mentioned we need to lock the data structure to stop the crash, it went over their heads. Being new to C# I didn’t know they had the lock keyword but a two second google and I found it. Using a lock is pretty basic to those of us who know what it’s for.... Anyways, their senior didn’t like it. So waited until the next day and asked chief tech. Who after an hour of googling, found a built in C# function that locks the data structure. So you don’t have to use lock{ do stuff}, It simply locks the data structure whenever you try to use it. Which is a nice C# feature. But under the hood it’s just doing what I suggested. Now, since the function exists, it’s nice...and I’d use it. But it’s more the understanding of what they are doing. Not just relying on a stack overflow answer. So the moaning isn’t “the didn’t like my lock solution”, it’s “they didn’t know locking data structures being accessed by multiple threads was a thing”.
The article doesn't make it at all clear what this ranking is based on. From [the TIOBE index page](https://www.tiobe.com/tiobe-index/) itself: &gt; The ratings are based on the number of skilled engineers world-wide, courses and third party vendors. Popular search engines such as Google, Bing, Yahoo!, Wikipedia, Amazon, YouTube and Baidu are used to calculate the ratings. It is important to note that the TIOBE index is not about the *best* programming language or the language in which *most lines of code* have been written. That methodology seems... suspect, to say the least. This seems much less closely aligned to where the development community as a whole is going than, say, [StackOverflow survey data](https://insights.stackoverflow.com/survey/2019/#technology).
This is good. I hope they make it possible to port to Android using cmake too.
wrong. union type punning is not ub in c, only c++.
I know people give a lot of importance of what you do with the languages and a lot of people programming in C++ are because of the types of projects are programmed in it. To me, however, the most important metric is the number of jobs, and here in Spain, there are a lot more jobs to program in Python.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bok910/binary_file_iosapp_c/enh9uqk/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Agreed that, for example, on Windows final DLLs are all same format, because that is PE format defined by the platform. However there are two caveats: a) Whoever produced DLL had to use EXPORTS in DEF file (or otherwise populate EXPORTS table in PE file) with expected spelling. Compilers are free to mangle symbols (yes, even "C" symbols), and there is no guarantee that mangling is same between different vendors, or even between different versions of compiler of same vendor. Ref: https://devblogs.microsoft.com/oldnewthing/?p=7533 b) OBJs/LIBs are generally not guaranteed to be interoperable...
Go Perl... it's ya birthday
As somebody who is kind of fond of [VB.Net](https://VB.Net), no way it is more popular than C#. Tiobe is simply broken.
Both are flawed imho. If there is a lot you can write about or say about a programming language, or a lot of questions on how to fix bugs, that doesn't make it a "popular" programming language. What these metrics most likely mean is these are the languages people are learning programming on. imho the metrics should be on number of jobs posted looking for that language.
I trust stats of real projects more: [https://octoverse.github.com/projects#languages](https://octoverse.github.com/projects#languages)
r/cpp_questions is probably a better sub for this question. To answer your question though, I never found a really good online resource for learning the basics. I would recommend investing in a good mood like programming principles and practices by bjarne stroustrup
TIOBE is clickbait that means absolutely nothing. It's literally based off the number of Google hits for the programming language, which is just about the dumbest metric I can imagine.
&gt; Only MSVC does this weird “construct it on the stack and then move it to the heap” business. Because presumably one seldom uses the `exception_ptr` and heap is **slow**. Good MSVC, really. &gt; The above program is ill-formed (by [except.throw]/5). But every vendor will compile it successfully. And every vendor will run it successfully — except for MSVC. Nobody should have any interest in ill-formed program running successfully, screw that.
Vendors try to lock you into their platform. TI for example fully supports gcc in its IDE, but it's not even installed by default and a bit hard to find iirc.
It's a decent metric of how much the languages are being talked about online, which could have some correlation to popularity. It depends on your definition of popularity when it comes to programming languages though; if popularity means jobs, this is a shitty metric but if popularity means people showing interest in the language, this can work.
Really interesting! My project is just a proof-of-concept I've never done anything like that before but now I'm really curious. I'll take a closer look at EnTT, thanks!
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Yes, it is guaranteed (also for C). If you are allocating a massive block in some machine with not so many addresses after you made a mess of your heap, well, that is on you...
VLAs aren't allowed, and even in C, it is not a good idea, given the problems they carry.
Oh indeed, my mistake. I was mislead by the changelog. Thanks for the clarification.
50% of those could be people complaining about how badly C++ sucks or something. It's without context. I mean, by that metric, Hitler is probably one of the most popular guys of all time.
I like that you're documenting the design process with issues, very cool to see the reasoning behind everything.
I was gonna say, how in the heck is [VB.NET](https://VB.NET) top 5 and above SQL, javascript, and C#?
&gt; Something that also directly does incremental builds... I would rather have non-incremental builds (e.g. a `buildme.sh` file that contains `g++ foo.cpp bar.cpp -o baz`) than builds that don't deal with header file dependencies, and getting that with a makefile depends on copying in a dozen lines of boilerplate. My build system of choice is SCons, but I'd suggest almost anything before a raw makefile.
Unfortunately, I don't have any information. It would be fantastic if it was included in C++20. I wrote my own version of it for an old job (C++11), and then later made it sexy with C++17. (Note: this version has an off-by-one issue. Don't use it without fixing it first. I'm just too busy with other things to fix it right this moment) https://github.com/splinter-build/splinter/blob/10-string_concat/src/string_piece_util.h Everything in that file below EqualsCaseInsensitiveASCII is copyright me. You may use it under any copyright license you want. Public domain, "do what you want" license, "don't be a dick" license. Whatever. It's not enough code for me to concern myself with it. (Again, you'll want to fix that off by one error).
The slowness argument is that you're incurring an allocate and copy for every use of the operator+, when something like the proposed paper ( http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1228r1.html ) or the similar function that I created, as described here: https://www.reddit.com/r/cpp/comments/bnwj06/stop_teaching_c_right_but_is_there_actually/enhxp1z/ would avoid the extra allocations.
Sorry, it really is true. E.g. try debugging : https://github.com/coturn/coturn/blob/master/src/server/ns_turn_server.c That codebase is a monstrosity. And I can say that with absolute authority because at my last job, I wrote a full ICE protocol implementation single-handedly, and integrated it into a full WebRTC solution with the rest of my team. My code, to implement the same feature set that coturn offers, is well under 75% of the size (despite having copious amounts of comments, which I include in my size estimate), and a hell of a lot easier to read and understand. I spent easily more time debugging co-turn to find out why the packets I was sending it weren't working than I did debugging my own code. It's a bloody nightmare of debugging because C language makes it very hard to keep code cohesive. Or this: https://git.openwrt.org/?p=project/uci.git;a=summary (Ugh... just Ugh). &gt; For every one line of C there is also one line of C++ - the C++ just abstracts the code away more effectively using some additional language features. Templates automatically invalidate this assertion. You could, I suppose, argue that type erasure as done in C language provides the same mechanism, but it does so in a very unsophisticated and error prone way. The thing with abstracting things away is that abstractions can be reused. Code reuse in C++ is (in my unsubstantiated opinion) significantly higher than in C. The standard library is also easier to use, less error prone to use, and takes away a lot of the guesswork. &gt; When debugging time comes around, you can't ignore it any more and you have to step through it. I don't ever debug the guts of std::vector (well, I did once, but that's because my team was using a custom standard library implementation which was buggy as could be) (And it turned out to be a visual studio bug, which I reported and it was fixed in VS2019, so that's fun). I do debug the guts of, e.g.: https://git.openwrt.org/?p=project/uci.git;a=blob;f=list.c;h=25aec56fb31afde8bcc1526fe070ad7574c4b4cc;hb=HEAD Because the C language doesn't offer the same types of guarantees at compile time that C++ does, and because this particular list implementation is exclusive to OpenWRT's UCI library, and used literally no where else, I have no way to know if my problem comes from the list implementation or somewhere else. And good luck understanding where anything is, or why that 50 line function does the stuff it does, or given it's name is 3 letters and there's no documentation, what the function is even supposed to be doing.
I do agree with most of the things you've written here, especially regarding the typical level of code reuse in C++ versus C, but I still don't think that inherently makes C any more verbose than C++ is. I think it depends on the writer of the code. It just happens that the typical C++ programmer values abstraction and compact code compared to the typical C programmer, so the C programmer will write 50 lines of code to iterate a list rather than using a container to do it, while the C++ programmer will just use std::vector with a range-based for loop. Regarding debugging, I didn't mean stepping into the internals of a container - as far as I'm concerned debugging a templated C++ container and the equivalent container in C that uses type erasure is equally as difficult, though of course the C++ version, as you've pointed out, is safer due to the type safety introduced by templates. I was talking about the usage of custom operators, constructors, destructors, lambdas, etc - all fantastic language features that I wouldn't want to live without, yet also things that make code much more difficult to reason about at first glance or otherwise harder to debug, especially if you're unfamiliar with all the types involved with the code. When you read C code, you know that what you see is what you get, for the most part. When you read C++ code, things happen automatically silently in the background. Again, my opinion is that this is a great thing for productivity, but it does make the code more difficult to understand when it comes time to debug.
I can agree that C++ frequently has stuff happening that isn't directly in your face in the code editor. Thanks for talking about it with me.
You never need *cmake* specifically, but as soon as you're typing in more than one file to build, you should be using a build system (and I prefer cmake). You need to be able to do debug/release builds, set up dependencies, install files, etc. If you don't set it up right at first, you waste a bunch of time and then end up having to do the work anyhow, so why not just do it right away and save yourself some time.
C++ doesn't seem like a very good option for a build configuration DSL. String manipulation, among other things, is pretty painful.
The complexity of multithreading is directly tied to how well your actual problem lends itself to threading. If it's very simple to break apart into pieces that aren't reliant on each other a lot in the "middle" of processing, then it's easy. If you don't need it to be fast, then it's easy. But when there's lots of interaction and it has to be fast, then it gets REALLY hard.
Sharp coders aren't going to be learning from a cheat sheet. This should be a refresher.
&gt;But yes, would definitely recommend using CMake for every project at this point. Also, if you're authoring a library for public consumption, make sure that you also export your build targets correctly to make it easier for others to install your library. That makes sense. It would have been nice at least to mention it, perhaps in the last lecture of class or something.
It seems like a DSL in an existing language would work well? Is there a python binding for cmake for example?
&gt; I keep asking for C++ lambdas How would lambda's even work in C? Isn't templates by and large the thing that makes them usable in C++, because templates allow you to not have to name the type, or define something that let's you type erase (e.g. std::function)?
Interesting. Function pointers have very different semantics from `function_ref`, because a function pointer that contains a valid pointer will never dangle, since functions are always "globals".
Start making games?
Newer versions often have important bug fixes and newer features that very often increase productivity and/or workflow. That's not _strictly needing it_ but it is beneficial for lots of reasons to stay on a recent version, particularly if a medium large-ish update like this one comes out. Now that doesn't mean that me or anyone for that matter should have to spend half an hour or an hour compiling that software, and you must know as well as I do that more often than not things don't compile right away, there are unforeseen, system-specific errors, library incompatibilities, non-standard build systems, etc., so that half an hour can become half a work day or a day **rapidly**. This is why it is important that software like this gets into prebuilt standard package manager repos. The ubuntu-toolchain-r PPA might be unsupported from an official support perspective but it's very much official and maintained and it's kept very well and tidily, I have never ever had any problems with it.
You mean Qt itself, right? Because writing Qt apps for Android with CMake already works.
I'll ask more directly here: Will this updated gdb land in the toolchain PPA?
Wot, I still dont think Im capable of doing that cause I only know a little OOProgramming, I still get confused in some concepts. I probably need alot more work before I can start making games.
Those will help you with any kind of programming language: * Bachelor's degree on Computer Science or equivalent. Advanced education is a plus * lot of math, trigonometry, geometry, quaterions, integrals, Taylor series, more.. * algorithms and data structures, understanding algorithm complexity * understanding of Operating Systems, with a focus on Windows. I suggest OSTEP book and Windows Internals. * knowledge of cpu architecture, cache, RAM, assembly (if needed for debug, not to write in it directly) This is C++ specific of course: * Bjarne Strostrup, The C++ Programming Language 4th Edition * Effective C++ * Effective Modern C++ * C++ Templates 2nd Edition After you've built a solid base, you can create your own game to be shown in your portfolio. I know it's a lot of stuff, but it's doable. Also, start to make simple games while learning the things above. For instance, make a simple text only story driven game, then maybe tic tac toe, then pong, and so on. Divide et impera. Big project, small tasks.
The trick is to start small. Make a simple game. Get something that works. Try adding a featuring or refining it. This will lead you to knowing more. Maybe you will learn about graph algorithms and A\*. Maybe you will learn about geometry and collisions. Maybe you will learn about GPU programming. Maybe your code is slow and you will learn about optimizations. Just start small and keep evolving.
Make simple games. Text-based dungeon game (see Microsoft Adventure), then find an engine and make Pong, then make breakout, and so on. Use games to practice your c++, soon enough you'll have a stack of ideas for games you want to make
A pointer is 8 bytes on a 64 bit system and adds an indirection. I haven't benchmarked it but I would say for types &lt;50 bytes passing by value will be faster in most cases.
Game industry guy here. The best advice O can give to you is to not cater your education to games. There's a high turnover rate in gaming. I'm not trying to discourage you, but someone who's a good software engineer in general can do anything. I'm in the industry, and I use stuff I learned from High Performance Computing more than I'll ever use the stuff in Game Programming. Someone who is a great game engineer isn't necessarily as flexible. I'm in the industry, and I use stuff I learned from High Performance Computing more than I'll ever use the stuff in Game Programming. That said, key concepts to grasp are OOP, computer graphics (which involves matrix transforms, shader programming, pushing vertices to the GPU, etc.), and event driven programming. Learning to use a game engine like Unreal or Unity would also help.
the c++ core guidelines have a pretty good discussion on this subject: https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rf-in
This should probably be in /r/cpp_questions, by the way. void foo(char); /// But passing by value requires sizeof(char) which is almost always 8 bites. void foo(char const&amp;) /// Passing by reference requires 64 bits on a 64bit architecture. You have to be careful with your design. "Pass by value always" is bad advice. "Pass by reference always" is also bad advice. I recommend the following general guidelines. * If your function wants to take ownership (whether it wants to modify the thing or not), accept the parameter by value. This allows for the code that's calling your function to either give you a copy, or to give you an rvalue reference. You're passing the buck up to the layer above your function. It's not your problem, you don't care, as long as you get the thing by value. Then, once you have the thing by value, you use std::move() to stick it in it's final destination, which will likely be as a member variable in the object that your function belongs to. * Passing by non-const-reference should be relatively rare, but happens. Use this for when the function won't own the data (e.g. won't make copies), but will only modify and then return. * If you want non-owning, non-mutating access, use const-ref if the object in question is larger than sizeof(void*) on your platform, or has a non-trivial constructor / destructor. At some point or another, I heard that there was a macro, or type_trait thing in Boost somewhere that would automatically deduce this for you, but I never thought it was very elegant looking so I forgot about it until I saw your question.
Additionally passing by ref may prevent some optimizations because of possible aliasing.
This is a complex issue whose details change with each new C++ standard and improved optimizing compiler. In days of yore, passing an `int` by value was better than passing it by reference-to-const, since the former required copying the `int`, while the latter required copying a pointer and, later, dereferencing the pointer whenever the `int` was accessed. And so that rule of thumb you mention came into being. The reason this advice is still given in these latter days is that recent C++ standards give compilers options to speed things up when passing by value -- move semantics, RVO, copy elision -- but these are not available when passing by reference-to-const. When passing an `int` and using a good optimizing compiler, there is a good chance the performance of the two is identical. And passing by value involves less code, so why not? If you really want to be sure about the performance differences, do some profiling.
That. Don't make the error to try start writing your own 3D MMORPG. If you're still getting into C++, start with something useful, which doesn't necessarily need to be a game. Some small tool to make a job easier for example. Once you have grasped the concepts of OOP, go larger. Learn how to use third-party libraries and then larger frameworks like Boost, POCO and, later, Qt. This way you will continuously increase the complexity of your programs, learn how to build larger applications with multiple dependencies and also read some quality code of these high-quality libraries. If you are quite secure in writing C++, try to use a game engine. I personally recommend the Unreal Engine. While it's a huuuuge piece of software, it is very well designed, documented and has a very clean API. Start creating smaller entities with some C++-based logic, then venture deeper into the engine. Make some simple games, then more complex ones. Explore networking, procedural generation and other advanced topics. At this point you may already be able to get some internship with a game development company and start your career. All in all this will take time. Don't try to rush it, but be persistent. Read some books (some great suggestions were already posted here), talk to experienced developers. And always write clean, well documented code, even if it's just for yourself.
create your own renderer with OpenGL or preferably Vulkan, then build a game engine with sound, general collision detection, physics, a procedural universe and networking. Then create a massively multiplayer online role-playing game with awesome storyline. And do NOT use any library that you didn't write yourself**!**.
&gt; When passing an int and using a good optimizing compiler, it is likely that the performance of the two is identical. No. Calling conventions are squarely in the domain of "compilers can't generally mess with this." If the call is inlined, sure, the question is irrelevant, but people are often surprised at where inliners decide to inline stuff, and the inliners are usually correct.
Because stack allocation is better than heap allocation.
I recall someone saying (from CppCon?) that the 1-3x the size of a pointer is a rough guide.
I don’t think there’s a “default” case. I usually look at the merits of passing by value/reference/pointer on a function-by-function basis. Eventually you build an intuition that makes it less taxing than it sounds.
C once again is years ahead of C++ with `restrict` 😝
I usually think of typical swap implantation with native word sizes. Everything is done in registers despite the fact that the function takes references.
That's because swap gets inlined away, not because implementations can do anything about calling conventions.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bop3kc/i_need_some_advices_about_getting_into_video_game/enj5ber/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Very informative, thanks! Sorry for not posting in cpp_questions, but it looked fairly inactive from user asking vs answering. I'll take my questions there next time.
If you operate on preallocated blocks of memory, then flexible arrays are ok.
Why does a "rough guide" need 300% span from low to high?
Please post cpp questions to /r/cpp_questions
Because it's rough, and at the end of the day it's a very poor substitute for profiling.
You mean with qt-android-cmake? I never could get that to work.
It depends on your situation. My general rule of thump is if you need to manipulate the original value in the called method but don't want to/can't touch the original value (for example, because the original value is needed further along in the calling method), then you use pass by value. If you need to manipulate the original value for use outside of the called method, then pass by reference. Lastly, if you aren't needing to manipulate it, and you just need the value, then either works.
That doesn't answer my question. A rough guide could say "at 3x pass by reference." Rough means it doesn't have to be completely accurate, but making a range increases accuracy at the expense of conciseness - a rough guide should be concise.
Interesting. I've always assumed that there shouldn't be a difference between `const&amp;` and not for primitive types like `int`. Is that not actually the case? I.e. should I be using `const int&amp;` instead of just plain `int` when possible?
There is a difference, they have different calling conventions. int might be passed in a register, but const int&amp; can never be.
&gt;but const int&amp; can never be. Ah, that makes sense. So, then, is the moral of the story: use value types for primitives, so they can be put in registers?
No. Don't use const&amp; for trivial types smaller than or equal to sizeof(void*), and potentially not even for types smaller than or equal to 3*sizeof(void*). Your mileage may vary.
By GNU I mean whatever GCC makes.
&gt; Passing by non-const-reference should be relatively rare, but happens. Use this for when the function won't own the data (e.g. won't make copies), but will only modify and then return. &gt; In that situation I would recommend pointers. That makes it really clear from the API that the function should be expected to modify the underlying data.
I guess maybe you could say it's a rough guide on where you could set your guideline. If you insist on consistently passing by reference at a specific number, you can pick a number in that range. Speaking for myself, I'm not super consistent with where I put the actual threshold. Sometimes I forget or change my mind. I don't have a linter enforcing it or anything, so I generally just sort of eyeball it and do what feels right in the moment. It's very easy to change a const reference to a value and vice versa, so making a "mistake" isn't that bad.
Let me clarify: the guideline was some multiple of the pointer size. I don't remember if it was 1x, 2x, or 3x.
Ahh. That makes a bit more sense. Thank you
Passing by value is also a good way to implement the assigment operator if you use the copy and swap idiom.
Not a c++ expert by any means but in college I think if you do competitive programming then for example for a recursive dynamic programing code, you have to pass by value as every function call has to work on different variable states. Similarly while doing dfs on a graph you have to pass by value as every dfs call works on different nodes and edges depending upon what the question is. But then again in competitive programming use of global variables is recommended so I don't think that fits the ideology of projects.
It's stuff like this that makes me thrilled that fmt is getting standardized.
I don't see how a pointer implies that the function should be expected to modify the underlying data. Do you mean because the caller is required to use operator&amp; ?
&gt;That’s my point also. &gt; &gt;The fact that people learn with C# means they are literally kept in a state of ignorance as to how “things are done”. &gt; &gt;In C#, there is usually a method for whatever you want to do. Meaning speaking to a C# coder you can’t talking engineering the same way. C# was my first language. I also chose to go back to school after 4 years working as a developer. A lot of that was C and C++. Granted, I chose to teach myself systems programming because I enjoyed it. Most people seem to not really give a shit. If that's the case, it's natural that the quality of software won't be as good as it could be. But at the same time, so what? Those who are passionate can excel and stand out. Those who aren't can do whatever they feel is going to be best for their needs. Ultimately, there's nothing you can do about it. Knowing the fundamentals will certainly give you an edge over those who don't. Currently the demand doesn't require that, though, so the amount of developers without that kind of knowledge is going to be significant. They're not incentivised to learn more, because the chances of their job security being threatened over their lack of knowledge is sufficiently low. Oh, well. I've lost the capacity to really give a shit; instead, I choose to just do what I know will benefit me for my career goals.
C++ has different semantics for aliasing than C. The standard (note that I say the standard, not the implementations) says that if you send a function two pointers of type Foo and Bar, they are guaranteed to not be aliased (ie they point to different memory regions), and you have no guarantee if the pointers are of the same type. In practice, many implementations either don't implement optimizations based on that, or they offer a way to say you don't want that, so they will treat all pointers as potentially aliasing other pointers. You can implement `restrict` by using a template type that will be unique and wraps your other parameter, triggering strict aliasing rules (that may not be applied in practice however). Some functions like `memcpy` assume it's safe, even if there's no restrict.
I'm not OP, but I believe that's the reason. It makes clearer to the caller that they're passing a object that can be changed. At least, when they know about this "rule". The problem with this one is that you then must check for null pointers (well, at least until contracts are standard). At the end, this is usually a guideline issue. Just choose one and stick with it on your projects. Personally, I prefer mandatory output parameters as references and optional ones as pointers.
For anyone interested, [this discussion](https://stackoverflow.com/questions/22724980/why-is-the-restrict-keyword-not-part-of-c) about `restrict` in C++ was interesting. I imagine the compiler extensions for `__restrict__` are because there's an obvious sane reason to implement it for, e.g. free functions, and they already support it for C, so it makes sense to add it there.
&gt;but I would say for types &lt;50 bytes Whoa there. That's a lot of bytes. Copying 6x pointer size seems a little high to me. If there's evidence to the contrary I'd love to see it.
It has nothing to do with the type of the argument. The \`str\_cat\` link above has concrete numbers if you want. The problem is more fundamental: any series of binary concatenations will be slow. Using \`+=\` doesn't fix this: a1+a2+...+an If you have n strings of k bytes each, this will end up taking O(n^(2)) time with almost\* all implementations, as well as O(n) allocations. \`str\_cat\` does this the more sensible way, using O(1) allocation and O(n) time, like everyone else would do it. \* I say *almost* since it is possible for a (non-conforming) string type to return temporary objects that collect an expression object and concatenate them all at once when converting back to string type. Even that won't solve all problems, and create new ones with lifetime management and exception safety.
Thanks for the link :) But for I think I'll just stick with \`sstream\` until \`str\_cat\` makes it through. I have actual str\_cat libraries at work, and for hobby I'm not working on anything performance-sensitive.
\&gt; It has nothing to do with the type of the argument I read from the link that to\_string exists only for numeric values. &amp;#x200B; \+= will be linear time (amortized). It is the same as push\_back in vector. It holds raw memory, and always doubles. &amp;#x200B; \+ can be implemented on rvalue references through +=, so it will be also linear. &amp;#x200B; So, I don't agree.
I'll second the link to isocpp Core Guidelines. I have often found it useful to pass by value and then expect call with std::move(), for avoiding the kind of combinatorial explosion of overloads as described here: [https://www.codesynthesis.com/\~boris/blog/2012/06/19/efficient-argument-passing-cxx11-part1/](https://www.codesynthesis.com/~boris/blog/2012/06/19/efficient-argument-passing-cxx11-part1/)
See my other post. Just write a version of + std::string operator + ( std::string&amp;&amp; s1, const std::string&amp; s2 ) { s1 += s2; return s1; }
Laughs in rust
This has obviously prompted much discussion, hardly a “how to” question appropriate for r/cpp_questions
&gt;The standard (note that I say the standard, not the implementations) says that if you send a function two pointers of type Foo and Bar, they are guaranteed to not be aliased (ie they point to different memory regions), and you have no guarantee if the pointers are of the same type. Don't see anywhere in the standard where it says that and don't see how that could even be true. The following are two pointers of type ```Foo``` and ```Bar``` that point to the exact same region, in fact, they are identical. struct Foo { int x; }; struct Bar { Foo x; } auto bar = new Bar(); auto foo = &amp;(bar-&gt;x); In the above, ```foo``` and ```bar``` are different types that point to the exact same object as per the standard. They alias one another despite being different types.
Could you elaborate on how that implementation of restrict would work? I think you would have to use reinterpret cast...
Right, I suspected that might have been what they meant. Pointer doesn't imply modified though. Const pointers are a thing *shrug*.
This does not do what you think it does. Every time this line is executed: s1 += s2; You're incurring an allocation and a copy. You have to reserve the total size of the string ahead of time, in order to avoid those allocations. Simply using operator+ in this way is insufficient.
See https://github.com/lewissbaker/cppcoro/blob/master/README.md#recursive_generatort for an example of a recursive coroutine.
The standard says that if you use tricks to make them point to the same region of memory, it is undefined behaviour. In practice, compilers are more conservative with UB because it would break too much code.
You can make a type that contains the object you want, no cast needed. Add a tag for uniqueness. template &lt;class T, class tag&gt; struct restrict{ T val; };
There is no undefined behavior in my example. My example is perfectly well defined behavior as per the standard and there's nothing even fishy about it. All I'm doing is taking a pointer to a member... Is it your suggestion that the snippet of code I wrote is undefined behavior?
Out of the two if one had to be considered correct it would be pass by value always. If you were someone who felt they needed a single rule that you could always follow, yu'd get in a lot less trouble that way.
Because if you really need to know you should benchmark?
You're missing the point. A *ROUGH* guide doesn't need to have a wide range because it is rough.
Well in this case you're not doing anything that could actually create a problem, because the compiler knows where you got your `foo` pointer from. The issue is if you send the two pointers to a function, because it would then be UB (as the function has no way of knowing where the pointers come from). I'm not 100% sure of the rule for structs that contain a single element, they actually might be considered compatible types with the type they contain. Couldn't find a example with that.
all sorts of bad questions generate discussion. That doesn't mean it's on topic.
I think an average incremental non-header change is something like 8-15 seconds whereas a total rebuild is something like 15-20 minutes. I miss having instant startup in JS and Python stacks.
&gt; You're incurring an allocation and a copy. No, because std::string reserves extra space. It always doubles capacity. In this way, one gets linear amortized complexity.
My example is intended to be minimalist... are you suggesting this is undefined behavior? Because it contains two pointers of distinct types, but they alias one another: #include &lt;string&gt; struct Person { std::string name; }; void f(Person* p, std::string* n) { std::cout &lt;&lt; p-&gt;name; *n = "hello"; std::cout &lt;&lt; p-&gt;name; } int main() { auto p = Person(); auto n = &amp;p.name; f(&amp;p, &amp;n); } There is nothing undefined or even suspicious about the above program. And as for your argument that the compiler knows where ```n``` came from, there is nothing particularly difficult, tricky, or obscure about hiding the implementation of ```Person``` within its own translation unit in such a way that the compiler has no way of knowing that ```Person``` even has a member of type ```std::string```. It's just not something I can paste in a reddit comment but I'm sure you can imagine how that can be done without much effort and without any trick whatsoever.
\#include &lt;iostream&gt; \#include &lt;string&gt; &amp;#x200B; int main( ) { std::string s; for( size\_t i = 0; i &lt; 1000; ++ i ) { s += 'a'; std::cout &lt;&lt; s. size( ) &lt;&lt; " " &lt;&lt; s. capacity( ) &lt;&lt; "\\n"; } return 0; }
Uhhhhh yea, don't pass std::vector's by value "always". That way leads to madness. Also, not possible to pass std::unique_ptr by value. Must use rvalue-references.
That general best practices and myself differ on many key issues.
It's trivially easy to construct a set of strings that would abuse the "always double capacity" behavior to still allocate for every item being concatenated. You could, you know, simply count the total length of all the items being added ahead of time, and reserve the appropriate amount of storage. The link that I provided in my original reply already has code that will do this for you elegantly. Just use that.
A related question: in generic code, where I don't know whether T is a big or small type, is there an agreed "default"? Or should I build a type alias that'll work out the best way to pass?
If you need to pick a default, pick pass by value. Particularly for simple types. But typically it depends on size. I've been told by some compiler writers that &lt;= 3 * sizeof(void*) is a good rule of thumb for pass by value *but that it should actually be bigger than that, but they know if they told people it is bigger, no one would believe them*
15-20 minutes? how big is your codebase? (also curious as to how big your .o files total)
&gt; It's trivially easy to construct a set of strings that would abuse the "always double capacity" behavior to still allocate for every item being concatenated. It's mathematically impossible. What one could do it make the strings very long, (every next one twice longer) but complexity will still be linear in the lengths of the strings.
I use an open source gameengine that I've made some minor modifications to called cocos2dx, which takes ages to compile. I make good use of precompiled headers, but still the serialization library cereal slows things down if you use it anywhere. I think my game has maybe 50k lines of my own code though.
Ah, I thought you were going to have something that would let me apply it to a particular function without me having have to have thought of it when creating my object.
Well your example (after checking) is fine because it is legal to alias a struct containing a single element with that element itself (see https://stackoverflow.com/a/50383349/). Also I guess because in this case it's not about `Person` but the type of the member itself. In case you had two structs that are identical in anything but name, it would be a strict aliasing violation. Strict aliasing is a complicated thing, and I didn't read your example correctly, my bad.
I'm merely looking for things to get started with in C++ preferably in embedded domain. I have STM32 board but I don't know if I can write a C++ code on it. I am still exploring options but I do prefer doing something in C++
Finally! This is the first step to move forward in using Conan for packaging
I'm not 100% sure of how to make it work, but something like that should be possible.
Now i work on many small projects sonfrom. Cmake to. Build in 1-3 minutes. Ive worked on multiple Hours long build time (multi target plus kernels)
Out software is a collection of multiple services that work in conjunction with each other. An incremental build of one service while developing is up to 2 min depending on the files touched. An incremental build of the whole software is usually around 15 min. A clean build (including a fresh clone from the repo, building APIs, tools and tests) is 2 hours
how long of those two minutes are spent on linking?
The issue isn't so much that pointer implies modified, as wanting lack of pointer to imply not modified. The fact that this code can modify x is unfortunate and makes it much harder to reason about because you have to know the type of the argument to foo. int x = 5; foo( x );
Rust never laughs.
In passing parameters in constructors from what I understand (Josuttis), pass by value and then `std::move` into the class member.
&gt; If the call is inlined, sure, the question is irrelevant Which supports exactly what I said, no?
If anyone here has not watched these presentations, I highly recommend finding the time for them. [Richard Hickey: The Value of Values](https://www.youtube.com/watch?v=-6BsiVyC1kM) [Sean Parent: Value Semantics and Concepts-based Polymorphism ](https://www.youtube.com/watch?v=_BpMYeUFXv8) They explain why pass-by-value is a good idea at a high level.
A real function wouldn't be called foo though. Imhotep, with proper naming, this is almost never an issue.
Sure you can pass a unique_ptr by value . Also l-value reference.
Please support your claims by a quote from the standard. Also, giving an example, where you think it is UB would be useful for the discussion.
&gt; there is nothing particularly difficult, tricky, or obscure about hiding the implementation of Person within its own translation unit in such a way that the compiler has no way of knowing that Person even has a member of type std::string. Then you couldn't access any memory behind the pointer (e.g. name) anyway and the whole question would be moot. I agree with the rest of your statement though
\`void f(std::unique\_ptr&lt;T&gt; ptr);\` If you are taking a reference to a unique\_ptr, you are doing something odd.
The question is not big or small, but how expensive is copying (std::shared_ptr is relatively expensive to copy even though it is only two pointers in size). For generic code, if you really know nothing about T, pass by reference, unless you need a copy anyway.
For those on Linux/gcc, you can combine ccache with distcc to improve rebuild times. On Windows platforms, Incredibuild and Stashed offer similar capabilities (commercially). Unreal Engine with Stashed goes from like a 40 minute build to just a few minutes. There are some opensource alternatives for Windows, but getting them configured and working is a bit painful and changes to your project may be required.
Here is a simple rule: If the argument type is a language primitive (char, short, int, long, bool, float, double, pointer, etc), then pass by value, otherwise pass by reference. For template parameters, always pass by reference, as the cost of references for primitive types is far smaller than the cost of copying structures.
6 seconds after touching one file, 3 minutes for a clean build. 160 kloc, 660 c/h files, one target Software: Ubuntu under Windows 10 using gcc 7.3 (-O3) and GNU Make (-j8). Hardware: laptop with an i5-8350U cpu (1.7 GHz, 4 cores)
If you use the value in your function cache locality will improve (especially if it was copied from a heap value). But as with every performance optimization: Benchmark!
You're welcome. Feel free to ping me if you've questions or suggestions. Being you so skilled with template programming, it could be you that you spot room for possible optimizations here and there!! ;-)
That case is actually not UB (as you can see in the further discussion). The most common UB in theory/fine in practice is when doing type punning. In this specific case, because you are accessing the value as `Foo` in both cases, aliasing is allowed. For the standard, if cppreference is ok then https://en.cppreference.com/w/cpp/language/reinterpret_cast#Type_aliasing
Rust's Serde library.
I don't remember and can't check at the moment. Not a huge amount I'd think. A smaller change like adding a function in a file that is rarely referenced is about a 10 sec build
The part of the standard allowing this behaviour: [basic.lval] (11.6) — "an aggregate or union type that includes one of the aforementioned types among its elements or nonstatic data members (including, recursively, an element or non-static data member of a subaggregate or contained union),"
you can take it by value, you can't pass it by value. I suppose this is mostly a semantics thing, we're probably saying the same thing in a different way.
&gt; It's mathematically impossible. Yet in the very next sentence, you provide the trivial example that would do exactly what I said could be done, which you think is mathematically impossible. Gonna need some clarifications there. &gt; What one could do is make the strings very long, (every next one twice longer). Yep. Simply += with a string that's the current length plus one. You'll incur an allocation every time. &gt; but complexity will still be linear in the lengths of the strings. What are you even talking about? "Complexity" has nothing to do with the cost of an allocation. Memory allocations can result in, among other possible problems, triggering the operating systems' memory compaction procedures, reading from disk, accessing resources from another computer on the network, triggering the OOM killer, and a whole host of other possible behavior. If all other things are held equal, fewer allocations are *ALWAYS* better than more. Your proposed method of concatenating strings is *guaranteed* to result in greater than or equal to the number of allocations as my string_concat function. My string_concat function is guaranteed to cause exactly one allocation, no more, no less. Thus, my solution is better than yours, in every way.
What is qt-android-cmake? I mean with the normal CMake + Android NDK + [Qt for Android](https://wiki.qt.io/Android). Here's an example application: https://github.com/jhasse/pwcalculator-qt
I think one should not write library functions if one doesn't understand basic theory of data structures. Constant time optimizations are rarely worth the effort.
&gt; must check for null pointers Yuck. I'd add a comment like `// The behavior is undefined if 'arg1' is not a pointer to a valid object` and call it a day.
that looks really useful. google protobuf is the closest thing i found to that buts its a bit of a faff
Eventually everything is still passed by value, even if you think you are passing a pointer, you are still passing the value of the address of the pointer. The thing is you don't want to pass a big value, since it causes memory copy of whatever you pass. Passing a pointer is copying 8(64bit)/4(32bit) bytes, so it's pretty small. If you have something on the heap, you probably will have to pass it by reference/pointer, unless you want to copy the whole thing to your stack, which you rarely want to do.
This is where Hungarian notation can help.
As long as the value is a temporary (e.g. returned from a factory) you can also pass it by value. You can't pass a copy.
I can't tell if you're being sarcastic here or not... That constant time optimization you're dismissing was responsible for increasing throughput capacity of a big enterprise application by several hundred concurrent transactions per second per cpu core. Representing about a 1% increase in overall system throughput. As stated previously. 1 allocation is less than "at least one" allocation. And allocations are one of the most expensive things you can ever have a computer program do. I think someone who doesn't understand that classroom theory has little relationship with real world applications should find a different field to work in.
Django (or at least a decent ORM).
Thank you for the link! I'll study the library a bit as it has many functionalities :)
\*\*Company:\*\* \[ViTrox Corporation Berhad\]([https://www.vitrox.com](https://www.vitrox.com)) &amp;#x200B; \*\*Type:\*\* Full time contract &amp;#x200B; \*\*Description:\*\* Our company mainly builds machine vision systems for quality inspection of industrial products. The systems often require sophisticated algorithms with stringent throughput and latency requirement. &amp;#x200B; Our team focuses on creating in-house software tools and libraries to ease development of such systems in C++. We are looking for experienced software engineer to help in developing an optimizing source-to-source compiler using Clang, as part of our active library solution. Our aim is to achieve an innovation breakthrough in C++ programming by marrying ease-of-use, flexibility and high performance computing on modern parallel hardware. &amp;#x200B; Responsibilities: &amp;#x200B; \- To implement optimizing source-to-source compiler using Clang Libtooling \- To develop tools that complement the source-to-source transpiler, enhancing debugging and Visual Studio integration experience \- To participate in design and evolution of our active library \- To assist and train developers in adoption of our active library \- To assist in writing technical articles and documentation &amp;#x200B; Requirements: &amp;#x200B; \- Solid skills in C++11 or later \- Experience using Clang Libtooling, with good understanding of Clang AST \- Comfortable with C++ template metaprogramming/compile-time programming \- Good understanding of multithreading, parallelization and concurrency \- Good algorithm and problem solving skill \- Good software optimization skills (i.e. reducing algorithmic complexity, dynamic programming, memory usage, cache optimization, etc.) \- Good understanding of modern computer architecture \- Basic understanding of operating system (Windows and/or Linux) \- Excellent teamwork and communication skills \- Good technical writing skills Any combination of the following has added advantage: &amp;#x200B; \- Basic understanding of CUDA or OpenCL \- Basic understanding of vectorization in CPU (including using Intel SIMD intrinsics) \- Know-how in creating a source-to-source compiler using Clang \- Know-how in creating a custom compiler toolset in Visual Studio 2015 or later \- Know-how in creating Visual Studio Extension &amp;#x200B; \*\*Location:\*\* \[Batu Kawan, Penang, Malaysia\]([https://www.google.com.my/maps/place/ViTrox+Technologies+Sdn.Bhd./@5.2278951,100.4452866,17z/data=!4m5!3m4!1s0x304ab7543575cf09:0x884219d2437808cb!8m2!3d5.2267072!4d100.442633](https://www.google.com.my/maps/place/ViTrox+Technologies+Sdn.Bhd./@5.2278951,100.4452866,17z/data=!4m5!3m4!1s0x304ab7543575cf09:0x884219d2437808cb!8m2!3d5.2267072!4d100.442633)) &amp;#x200B; \*\*Remote:\*\* No &amp;#x200B; \*\*Visa Sponsorship:\*\* Yes &amp;#x200B; \*\*Technologies:\*\* C++11/14/17/2a, Clang, Visual Studio (+ Visual C++), Windows, Linux, SIMD, CUDA, OpenCL &amp;#x200B; \*\*Contact:\*\* Email our HR department at \[hr@vitrox.com\]([mailto:hr@vitrox.com](mailto:hr@vitrox.com)) or call us at +6045459988 (ext. 7206). \[Official job description\]([https://www.vitrox.com/careers-jobs/vacancy-pos-rd-software-developer.php](https://www.vitrox.com/careers-jobs/vacancy-pos-rd-software-developer.php)).
Yeah ORM is totally missing , like what ORM? hibernate?
Thought the same. Especially Qt is a PITA to handle as a dependency
I would assume the estimation comes from the amount of arguments passed in the registers (48+ bytes on x86-64 and aarch64) so in some cases it can as well be an optimization if e.g. the function does do some simple computations and the register pressure is not high.
Something like Express.js or the Go http module, which allow you to just set up route handlers and serve pages with no hassle.
Too long.
A full release rebuild takes 30 minutes, debug takes 5x as long. As long as I don't change any headers, the time for incremental is &lt;1min.
What is left then? that sizeof('a') is sizeof(int)?
Absolutely. This is a topic I've spent a lot of time thinking about. A few months back I decided to experiment with coding a new project in a C-like manner. It wasn't exactly C, because I used templates (I really like compile time type-safety) and namespaces and lambdas, but it wasn't exactly C++ either, because I didn't use classes (only structs with no member functions) or constructors or destructors or the STL. The project was the core of a game engine written in Vulkan. I found the following advantages with this approach: * Debugging the code was really easy. There were few surprises compared to the equivalent C++ code. * I could treat everything as raw data rather conceptually rather than stateful objects, which I found made coding some things to be much easier. It's harder (but not impossible) to do this in C++. I think it comes down to the mental model used when coding. * The performance of my code was improved, but this is because I reimplemented some poorly performing (for my use case) STL containers. There were also disadvantages: * Coding was slower because I had to dedicate time to reimplement functionality that is already in the STL. But, on the flip side, the performance of some of my containers was much higher than the STL's equivalent, because I could implement them specifically for my use case. * The code was slightly more verbose; my types had a constructor and destructor, they were just called Init() and I had to call them explicitly which meant an additional two lines of code for every container. And observations: * I always thought RAII wrapping allocations and resources was very important, but now I think it is convenient but not so important. I never forgot an allocation's equivalent delete - I often found myself planning how it was freed before I wrote the code that actually used it. I wrote some simple memory tracking that asserted if any memory was still allocated when I shut down the application. This gave me protection against leaks. My conclusion from this little experiment was that it made reading and debugging code much easier but it was cumbersome to code in this way. I missed the convenience of having the lifetime of objects managed for me by scope; I did have to spend significant mental bandwidth on these things which can almost entirely be ignored when using C++ with RAII. All-in-all, I think the convenience and increased productivity from some C++ language features does outweigh the small time lost when trying to understand the code due to the additional complexity.
5:30 for a completely fresh rebuild, 30 seconds for an incremental change at least, because we include a build timestamp that requires re-linking.
Also clocking in with a 20..25 minute rebuild: last time I checked, 1.2 million lines of code. (Yes, some of that IS generated during the build.) Industry applciation, on the market for 20 years, feature pressure, backward compatibility, yaddayadda.
Just throw a custom exception and drive everyone crazy.
Matplotlib
Got used to Django ORM, though sqlalchemy is preferred outside Django. For C++ I'd expect something good will come up once static introspection is landed in the standard.
My last job had 2 major code bases that I was involved in. I was the guy who overhauled the build system to cut out as much of the "omg this sucks" as I could. Cut builds by like 20% before I left for another opportunity. The first codebase was broken up into 5 "tiers", with higher tiers building off of lower ones. System, core, data, media, application. System was things like 3rd party libs and custom stl implementation, and boost. Core was core functionality. Custom smart pointers, data formats like Json, XML, and things like an asio implementation and a multi-thread job dispatcher framework. You know high level concepts that provide the backbone of other applications. Data, media, application all did what they sound like. System took 1-2 hours to compile and link. Core took 4-5. Data was 1-2 Media was 8-10 Application was 6-8 There were another 3-4 minor " tiers" that all together added another 1-3 hours to the global build, but they were minor. The other codebase built directly on top of the first. I only messed with it if my code changes in the first codebase broke things in this one. It took 48 hours to compile and link. Sometimes longer depending on the whims of the day. All times listed are with regards to the companies continuous integration infrastructure. Big servers. Many of serveea. All the cores. Lots of ram. Much SAN.
&gt; The 8-15 second incremental skips building cocos because even just linking it takes like 30 seconds. What linker are you using? And are those for debug builds?
I imagine that passing a char by value is simply cheaper then passing a 64-bit address (pointer or reference). There's really no point in passing simple type by const ref imo. You could also try and take a look at the differences in the generated assembly.
\+1 for this. Serde feels like magic
asio/network ts
`((void (*)())(size_t)(-1))();`
There's [stackoverflow.com](https://stackoverflow.com) which is quite active.
Working on a Chromium-based codebase as an intern right now. Building from scratch takes almost a day (I blame this on my ancient workstation, which sports a i5-3330). Incremental build probably takes about 5-7 minutes, 80-90% of which is spent on linking the humongously huge `browser.dll`. The resulting build directory is ~40GB in size (this is for a Debug build, a Release build takes up considerably less at ~15GB).
Rust is boat cancer
Ouch. Am I reading this right? Cast -1 to a size_t, then cast to a function that takes a pointer and returns void, then call it? What does that do?
const reference* unless you need to modify of course.
A good reason to pass by value is if you were going to copy the value anyway. Let me illustrate with some background first: Imagine you have a function that takes a string and returns it with the first letter replaced with 'a'. (To keep things simple I won't check for non-emptiness.) std::string setFirstToA(const std::string&amp; s) { std::string result = s; result[0] = 'a'; return result; } This makes a copy of the string (in the first line we copy `s` into `result`), which is necessary so that the caller can keep access to the original unmodified string. But what if the caller doesn't need to access it e.g. it is the result of a temporary expression: std::string x = "x"; std::string y = "y"; std::string foo = setFirstToA(x + y); std::string bar = setFirstToA(getStringValue()); In those cases we'll be making a copy of a string which we're about to throw away anyway. If the string is very large this could take a long time and is wasted effort. This is a classic case for move semantics. Just define an overload that takes an rvalue reference (so that it will be called whenever a temporary expression is used as the argument) and moves from the argument (to avoid the copy): std::string setFirstToA(std::string&amp;&amp; s) { s[0] = 'a'; return std::move(s); } Now we come to the reason you would you pass by value. The above pair of overloads work, but now we have to maintain two versions of the function. But it turns that, using pass by value, we can write a single function that covers both scenarios: std::string setFirstToA(std::string s) { s[0] = 'a'; return s; } Let's explore what happens in the two scenarios that the two individual functions would have dealt with: * Passed an existing `std::string` variable: This is copied in to a new object (called `s`). That object is modified. Then it is returned, and because it is a local variable it is moved even though we didn't use `std::move` (not using `std::move` maximises the chance of the NRVO being used). That's a total of one copy and one or possibly zero moves. * Passed a `std::string` rvalue (e.g. temporary): The variable is *moved* into `s`. We then modify `s`, which is a different variable to the original temporary but points to the same underlying memory, and return it (same move/RNVO explaination as in previous point applies here). So we have gone from one move in the original function to two or possibly one moves and no copies. Note that, in reality, there is still function overloading going on. It just that it's the `std::string` constructor overloads being used, rather than us having to manually write our own. We are relying on `std::string` having both a move constructor and copy constructor for this trick to work.
These two are worth checking out: - Madplotlib - https://github.com/madplotlib/madplotlib - matplotlib-cpp - https://github.com/lava/matplotlib-cpp
Do you imply that you would find it surprising if: SomeDataStructure s; assert(!is_sorted(s)); sort(s); assert( is_sorted(s)); ... `s` was modified by `sort`? Would it really make a difference in readability if it used `sort(&amp;s)`? In my opinion, it should usually be deducible from the name of the function and the context whether an argument is modified. The problem with using a pointer is that you then have to either check for null, or you introduce undefined behaviour.
C very sorely needs a facility for writing generic functions with varying types of parameter, as they have all the same problems with macros as C++ does. There is no warmth for template syntax, and quite rightly too in my opinion. Nor is there any chance for function overloading, except maybe for operators, one day. But the idea for multi-parameter-type lambda functions was surprisingly warmly received. So, for example: [](auto x) { return _Generic(x, int : 5, double : 1.0); } The key here is that C11 `_Generic`dispatches based on input type. The lambdas can take specific types or `auto` types, and if they are `auto` types, one can use `_Generic` to implement type-match-based dispatch. This lets you implement all of the `tgmath.h` functions using generic lambdas instead of defining tons of functions with slightly different names and having `_Generic` dispatch to those instead. WG14 recognises that that is not a scalable way of implementing generic dispatch, hence their surprising warmth to the idea of porting C++ lambdas into C. The biggest concern was over captures. I suspect most of that is ignorance, but there were grave concerns over `[&amp;]`, and I certainly can see why. My counterargument is simply ban reference capture in C, let people pass pointers if they need that.
A tiny drop-in thing that just says "Congrats, now your daemon has a sensible https web ui", preferably running in a separate process and communicating with the main app via shared memory or something, so that you can still read the diagnostics while you are sitting on a breakpoint in the debugger. So far every company I worked in had to assemble a web UI from like 5 different libraries and a cubic meter of glue code, and it never had all the desired properties. I'm seriously considering writing something for this as a pet project.
These are very similar to my build times in avionics.
Try building LLVM :)
It tries calling a function at address (let's assume 64-bit architecture with a full 64-bits of virtual addressing) 0xFFFFFFFFFFFFFFFF. It probably crashes.
What's even worse is how grossly the problem is ignored by SW management. I used to work in a team maintaining a large windows application, which took about 45 minutes to link. Which means every tiny code change, when you wanted to test it, took at least this long. Devs complained a lot and tested speeding up things with SSDs, which were not as common back then as they are today. IO times went down by a large margin, leading to us requesting an invest into SSDs from management. It would have cost about 500 bucks apiece but would have dramatically improved effectiveness. And was refused. 500 Bucks was too expensive. They'd rather waste their developers time. Happened to me two times in two different companies. Guess what was the first thing I bought for the guys when I was in charge ;-)
I actually had to, to get lld running (left my PC to get KFC, came back, ate it while watching youtube vids etc etc). In the end all I copied to /bin/ was ld.lld and ld64.lld, but it was absolutely worth it
Haskell’s parsec
But not an `std::mutex`, for example.
Offtopic, but you're supposed to run \`make install\` or \`ninja install\` after doing a build.
Briefly, my observations on the difficulty of installing `buck` stem from two sources: 1. I'm not using a mac 2. They are switching to Java 11 and don't have nice instructions on the website There is a much easier way. Right now, a summary of the easiest instructions for installing `buck` on Ubuntu are: 1. Install `linuxbrew` (it seems that [the package name may be changing](https://docs.brew.sh/Homebrew-on-Linux)?) 2. Install Java 8 JDK 3. Switch to Java 8 JDK (you'll need to do this whenever you're using `buck` too) 4. Use `brew` to install `watchman` (It crashed a lot (literally every 3 minutes on average) on my system ... but `buck` is *so* much faster when it works because `buck` refuses to use `buckd` without it and so you have to pay a penalty of many seconds for the JVM to start. I eventually quit using it because of the crashes, but YMMV. 5. Use `brew` to install `buck` I suspect the not-nice instructions are because if you compile everything from source on your own system manually (rather than letting `brew` do it for you) you can get everything to work together the right way.
In my last three jobs, the clean recompile would take hours: 3 - 11 hours depending on the product.
I'm really happy to see that I'm not the only one thinking this. Imo, arguments should be const references by default. If you want a copy or a mutable variable, you should have to specify it. Not the other way around. But I'm probably wrong. I haven't really read the discussions, and I'm sure the design is well justified.
something that would make hosting websites from a program as easy as reading a directory and feeding the html code to anyone that would input your ip.
I was suggesting `std::function_ref` as an alternative to raw function pointers, which you mentioned preferring whenever possible. Obviously there will always be a place for `std::function` when you want to store the callable.
We have a good sized code base (I think about 2Mloc) that takes between 1-2 mins for full and incremental builds. We cheat a lot with Fastbuild (distributed, cached and blobbed). Most of it is link time. A uncached build takes about the double amount of time. Much better than the previous code base (bigger about 6Mloc) who was about 15mins (full) - 5 mins (incremental) again using Fastbuild. I can send more details later
`string.format()` hopefully satisfied in C++20 with fmt library
Rust’s standard library
Have you tried Boost.Beast? Has been working fine for me so far 😂. There is also crow which I haven't tried.
Home project using tons of boost having 10k LOC, GCC 8.3.1 on Windows 10: - full release build: ~1min on 4 cores, although I have a make version that doesn't work correctly with `-j` which can only be made to either use 1 job or spam infinite amount of jobs (in reality as many job as source targets) - incremental build: ofc depends on the header, my application has a lot of templates and so many changes are forwarded to other modules, from few seconds to half the time of full rebuild - debug: not doing it unless I have to; reason: Boost Spirit+Fusion which nests recursive instantiations hundreds of times. If you demangle names on `nm -C parser.o` they can take up the whole terminal screen. About 50-90% of build time is linking.
You'll be sorry when that new-fangled compiler of yours becomes self-conscious and attacks.
I find myself going back to C alot of the time
Depends on how much time you have. It's a big goal. If you just want a job ASAP, start hacking things together in C++, like looking up resources on how to do this and that, copying/pasting stuff together until it kinda works like a game. Start small, keep things simple and don't be afraid to try over a few times, eventually you'll get some "raw" experience with the language and doing gamedev related stuff, even if you don't really know what's going on in the code. This might get you a foot in the door. If you can take your time, and gamedev is your goal, I don't recommend starting with C++. Start with hacking together a few games in Unity, you'll learn a lot more, a lot faster, about making games that way. Play with other languages to learn different aspects of programming, try building some UIs in scripting languages like Python (easy to setup/start), play with C# to get a feel for working with graphics/algorithms/multithreading (decent standard libraries and resources to get started, closer to C++), finally learn how to do all these things in C++ along with all of their low-level intricacies that were previously hidden/abstracted away. Going to some sort of college is also a good idea, typically comp-sci courses won't make a great coder out of you but as long as you pay attention, you'll learn a lot about how computers work and what programming is about. I suggest learning to code first though, so you can focus on the other stuff they're trying to teach. You'll get a lot more out of higher education if you go in with the basics covered, already kinda knowing the "how" of things and focusing more on the "why" part. C++ is a very powerful tool, but even if you learn how to use it well, you still must know what it is that you want to do with it. There are faster ways of understanding high-level concepts behind gamedev than writing a C++ implementation. Without knowing the theory behind how some code works, understanding what it does won't help, making parts of your program black boxes.
.NET Core
C++ has stricter strict aliasing rules. C++ indeed does not have `restrict` (obviously every major compiler offers it anyway) but if you wrap your values in types that do not share the same hierarchy you can express this. C++20 contracts can be used for aliasing optimizations in release and pointer checks in debug.
&gt; either give you a copy, or to give you an rvalue reference should be "give you an rvalue" - value categories do not care about referenceness of a type &gt; use const-ref if the object in question is larger than sizeof(void*) on your platform, or has a non-trivial constructor / destructor. I agree with non-trivial ctor/dtor - if it (de)allocates any resources it will surely be more expensive than to pass by pointer but, `sizeof(void*)` only? By this logic you would pass 3 ints by value but a struct of 3 ints by reference? I would pass any trivial struct by value unless it's really big.
Automatic serialization with reflection, like Java has, where you only need to add annotations to class to make it serializable. &amp;#x200B; I guess boost::serialization or cereal are the closest thing, but you still have to list all fields in the serialize() method. Also, cereal doesn't support C++14 or C++17 types. I wish I checked that before I started using cereal as default serialization method for my project two years ago.
Impressive build times! Reporting from the opposite end of the spectrum. Working with a suite of applications built around a collection of header-mostly libraries leaning heavily into `ranges-v3` and `boost::hana`. Incremental rebuilds are basically not a thing. Typically we're building with CMake + Make. Initial and subsequent configurations are on the order of 10 seconds on my development machine (a Macbook Pro circa 2015). Clang is our preferred compiler (relative to GCC on Linux and MSVC on Windows), winning across the board on + compile time + compilation memory usage (which has been an issue for us), and + performance of the resulting binary. I haven't tried ZapCC, but it sounds like it's worth giving a shot. Each translation unit is \~40 seconds to compile. Applications have less than a dozen TUs with the vast majority having fewer than four. With debug symbols, a TU is around 4 Mb and without, around 900 kb. Building out the unit test suite is a kick in the pants, coming in around 40 minutes on my development machine. Fortunately the project has access to two monster 112 core big memory build and test machines (although they are shared with other projects and we try to be polite). I generally commit and push to trigger CI on these machines and read a configure + build + test + memcheck + coverage report on an internal CDash server, which is typically available in 2-8 minutes depending on server load.
&gt; I’ve been persuaded by the argument that C++ casts being ugly is actually a feature I agree with this whole-hearted, with the exception of `static_cast`ing numeric types. It's always bugged me that the same cast operator is used for pointer type changes (which should smell a little bit) and narrowing numeric conversions (which should be explicit, but don't necessarily represent a flawed design). In my mind as a programmer the two are entirely unrelated operations: one is changing the meaning of some bits while the other is actually converting from one set of bits to another. I wonder if a `std::numeric_cast` or `std::narrow_cast` has ever been proposed?
I see a lot of people saying that passing by value for small objects is more efficient, but can’t compilers optimize that since a const ref is basically the same syntax wise as a const value?
yes, you type less
A lot of things from Rust, but for me mostly embed\_string! and embed\_bytes! macros which compile strings and bytes from files into the program's executable. There's a library built around them, creatively named rust-embed, that does it for whole folders, and optionally switches to using std::fs in debug mode. I miss it dearly in my C++ projects as now I have to include a bunch of extra files and folders.
&gt; In debug (no optimization, debug symbols on) both the standard library bundled with MSVC++ and libc++ (and presumably still libstdc++, but I haven't poked around in there recently) do a lot more than merely fail to elide some code. They use things like bounds-checked iterators, instrumenting metrics, and so forth That's definitely not true for libstdc++. Assertions to detect undefined behaviour and bounds checked iterators and have to be explicitly enabled (see the docs for [`_GLIBCXX_ASSERTIONS` and `_GLIBCXX_DEBUG`](https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_macros.html)). You don't just get them by not optimizing (and certainly not by turning debug symbols on, which has no impact on performance). I'm pretty sure the same is true for libc++, you have to define [`_LIBCPP_DEBUG`](https://libcxx.llvm.org/docs/DesignDocs/DebugMode.html) for those checks. I think the MSVC std::lib _does_ enable those extra checks for the common "debug build" settings, but you can disable them so you have unoptimized code with debug symbols but without the extra checks.
I am no expert, so I might be wrong, but I don't think it's the same. When writing a function, you might be taking the argument as a const reference, but outside the function, the object passed at the call site might not actually be a const object. Because of that, there are assumptions you cannot make when optimizing the function whereas if you take the parameter by value, you have an independant copy inside the body of your function, which is completely isolated from the outside. My understanding at least.
from scratch: Generate makefile with cmake: 3.9 seconds. build makefile with just `make` (no multi-threaded compilation or anything fancy) 2.7 seconds. According to `cloc` there's 61,077 lines of code including comments and headers, about 50,000 of that is in a single header StringIOTables.h which is only included by StringIO.c actual source code is about 10,000 lines, and I built the FoundationIO library as a dynamic library on MacOS with Clang, and the library size is 622kb. Rebuild time: .2 seconds.
But if you have a const reference, the outside value cannot be changed either even if it’s not a const object, so both the reference and value should be isolated from the outside.
What the hell, ccache is great. I'm surprised that I haven't heard about it before, even though I did look into the general topic of improving compile times.
Oh god, thanks for the flashbacks to 3 hour compile times and then at the end it flips out cuz some setting is incompatible with some other setting.
Pistache works alright for this, but there is a little bit of boilerplate involved.
Antigravity, of course. [https://xkcd.com/353/](https://xkcd.com/353/)
I think both GNU and MSVC supports __restrict
3 reasons IMHO to pass by reference or pointer : 1) You want to modify original data. 2) You don't want to copy large amounts of data again and again. 3) You don't want to again and again create temporary variables which occupy large amounts of memory while calling some function. So you define the data outside of the function and send it by reference to the function to let the function use it again and again without needing any memory reallocation.
Talking about compilation times without mentioning build hardware is meaningless. In the past one of our apps took 45mins when compiled single threaded, when run on 16 core server (so make -j16) dropped to around 5 mins and running build via distcc on 8 servers 16 core each was around 2:30 min which was mostly just linking time.
Let's hope the [metaclasses](https://www.fluentcpp.com/2018/03/09/c-metaclasses-proposal-less-5-minutes/) proposal will make it into the language someday!
Yeah, but instead of having one symbol whose name exactly matches the name of one function, you end up having a billion extremely verbose symbol names for all the different ways one function was called.
I had the same problem with cocos2d-x and I managed to reduce the compilation time to less than a minute by dropping the source files for classes I do not use (physics, scripting, editor-support…) and by using compilation units. The compilation units were a pain to setup because there is a lot of `#define` without `#undef` and some name clashing in static functions but it was worth it. You may want to give it a try.
&gt; Then you couldn't access any memory behind the pointer (e.g. name) anyway and the whole question would be moot. It's a very common pattern in C to create opaque pointers. Person.h struct Person; Person* new_person(); std::string* get_name(Person* p); Person.cpp #include "Person.h" struct Person { std::string name; }; Person* new_person() { return new Person(); }; std::string* get_name(Person* p) { return &amp;p-&gt;name; };
So, we have fairly significant codebases. So, with incredibuild, the times for the games I work on are anywhere from 15 minutes clean to 40 minutes clean with iterative builds around 1.5-5 minutes (unless you change a fairly global header). A “final”/retail build with LTO (or PGO which has negligible effect compared to LTO) adds 30 minutes to 90 minutes when linking. Without incredibuild, we’re talking at least an hour to three hours for a clean and as little as 1.5 minutes for an iterative, again depending on the changes. MSVC generally produces the best code with LTO and especially PGO compared to clang. Without LTO, clang is a little better. The differences are negligible across a big codebase until you add in PGO and such. Clang generally builds faster under the same settings and has the added flexibility of PGO independent of LTO, which MSVC does not. With MSVC, you get LTO or LTO+PGO, clang adds PGO only.
True. If it is neither copyable nor movable you have to pass by reference.
Oh i didnt know that existed! None of the google search results suggested that as a possibility and none of Qt Creator's examples supported cmake for android.
As someone who's got only the vaguest idea of Rust, can I ask you to elaborate on the differences in the standard library?
A reflection TS is being worked on, so perhaps you'll be able to get that wish in a release or two.
I had a bike that died of that.
Been wanting this for decades now. Not sure about other fields (pardon the pun), but it is a huge deal in game development.
&gt; If you want non-owning, non-mutating access, use const-ref if the object in question is larger than sizeof(void*) on your platform, or has a non-trivial constructor / destructor. I mean that "or" definitely needs to be an and. You can easily have for example a deep copying version of a unique pointer; you definitely don't want to pass that around by value even if it is only one pointer in size. Also, it seems like the typical advice is more likely 2*sizeof(void*) at least, because string_view and span are pretty consistently passed by value in examples. But you should never pass things that are non-trivial by value if you aren't taking ownership.
Your example does not work. You can't write `p-&gt;name` in `f`, if `f` doesn't see the definition of `Person`
It takes something like 10 minutes to build my app from scratch, targeted to either iOS or Android. It used to be 45 minutes two years ago on the same computer but thanks to the use of compilation units, a lot of modularization and using a package manager for the dependencies (even those developed in-house), we managed to get something bearable. On these 10 minutes, 1 is used to install the dependencies, 4 to build some tools and preprocess some resources using them, 3 to compile the game itself and 1 to publish the artifacts.
In the past, I have used TinyHttp. https://github.com/larryhe/tinyhttpd I would be surprised if someone doesn't have a more contemporary alternative to suggest.
Honestly if you want to go this way then it's way better to create your own type `out_param` and make that the "rule" so that API calls would look like `foo(out_param(x))` which is clearer than both `f(x)` and `f(&amp;x)`.
I think something like that is coming -- if I understand what you want correctly -- in the [std::embed proposal](https://thephd.github.io/vendor/future_cxx/papers/d1040.html).
and then there are people who come and say "nah we don't need reflection"
You just can't recommend value (or anything else) as a default, when things like vector and string are incredibly common and passing them by value is usually an insane performance pessimization. It's nice to provide simplified defaults for beginners but this is one case where suggesting one is just doing them a disservice; for better or worse in C++ you have to learn how to pass things correctly from almost day one.
At $WORK: nothing to do: ~2min &lt;---- that incremental: ~10min rebuild: ~50min and then ~5min of unit test and ~40min of regression tests. That's a shame.
\* In libraries where the consumer of your library could throw anything, including a derived type at you. If use cases are known up front, then you can do better.
Mockkafka, mostly because a good third of my current project can't be unit tested until I write it and I'm not particularly hyped about writing yet another test framework.
Value semantics have basically nothing to do with how you pass arguments. You can pass a value semantic object by reference or by value, or a non-value semantic object by reference or by value (sometimes). These talks explain why value semantics are a good idea but this is a higher level concept and something you design your types toward. if anything, pass by reference is especially crucial with value semantic types because typically these types own their own data. E.g. std::vector has value semantics and passing it by value is really expensive, so you really need pass by reference there.
You can use `const_cast` to cast away constness and, since "const reference" doesn't say that the "pointee" is const, it surprisingly isn't UB, so your compiler has to take that into account.
Python's Pandas Library
I forgot to mention that im on Software Engineering course on that university and right now im first year 2nd semester (end of it) and I wanna see how the path looks if I want to become a player in the game industry.
Aliasing is one effect but I don't think it's even the main prevented optimization. When you pass by reference, the compiler basically has to assume that every single call to a non-inlined function might mutate the argument. I.e., it has to reload the value. For example: double foo(const double&amp; x) { auto y1 = f(x); g(); return y1 + f(x); } Let's say that f is inlined but g is not. The compiler surprisingly still has to go through f's operations twice, because g could change the value of x. Because x could be a reference to a non-const global which g() could mutate. Aliasing is worth mentioning but it's really just one part of the story, value types just allow the compiler to reason better in many different ways.
&gt; integrals Everytime I see this word I just wanna cry.
The [reflection TS](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4766.pdf) is probably more closely related, right? But metaclasses do look nice!
itertools, I know there is cpp-itertools, but something in the standard library that made it effortless to wrangle iterators would be nice.
Sometimes it is better to pass by value and move if your function will mostly receive temporary objects as arguments. Example: class FooByValue { public: FooByValue(string s) { d_s = move(s); }; private: string d_s; } class FooByReference { public: FooByReference(const string&amp; s) { d_s = s; }; private: string d_s; } FooByValue("abcde"); // string(char[]) creates string from chars // copy elision prevents extra copy when you pass it to constructor by value // string(string&amp;&amp;) moves s to d_s FooByReference("abcde"); // string(char[]) creates string from chars // string(const string&amp;) copies s to d_s FooByValue constructor works faster than FooByReference because move constructor is faster than copy. Here's more info: https://clang.llvm.org/extra/clang-tidy/checks/modernize-pass-by-value.html
Have you tried trase-cpp?
I'm not that deep into c++, I just know that there isn't an equivalent to serde in c++ (after doing some research on a project I'm doing). Could you explain the concept of reflection to me and what it enables?
Wouldn't metaclasses enable reflection? Or what is the main difference between the proposals?
Definitely! We have gotten by alright with rolling our own solutions in the interim though. Some of the code gen approaches have worked out pretty well, and i imagine even once support for this makes it into the language, we’ll still be using our own versions for the extensibility
It would be meaningless to pass a mutex by value, but if you're writing multi threaded code you'd actually get yourself in less trouble doing this meaningless thing than you would following an "always pass by reference" rule (which was my point, that having a single rule is wrong but if you're going to be wrong, that passing by value result in a higher probability that your code will work). If you want to see how screwed up "everything as a reference" will get you Google "python global interpreter lock". Python is an example of someone thinking that "everything as a reference" was a good idea and as a result it is a pile of rubbish.
Take a look at this godbolt: [https://godbolt.org/z/fyT0C\_](https://godbolt.org/z/fyT0C_) &amp;#x200B; As other commenters have noted, passing a small object by reference causes an additional superfluous read from the stack, instead of being passed in the registers.
I'm pretty evenly split at work between C++ and Python. I'd love to have something like Python's requests and Flask in C++. They're so easy to set up and work with, and I love them.
I think if it is done well, the bespoke solutions will be weak by comparison. We aren't talking about just serializing field values, but also accessing member functions and some very powerful, dynamic capabilities driven by deserialized data.
Fair enough, but you can hide or use aliases for the names (that you have to set up manually, I know).
reflection is the ability in a programming language to get information about the code you are typing. e.g. you can do things like struct foo { int x; std::string blah }; foo f; f.x = 123; f.blah = "hello"; for(each field in foo) { printf("{} ({}) = {}\n", field.name(), field.type.to_string() field.value()); } which would give out something like x (int) = 123 blah (std::string) = hello (ok maybe it will be std::__1::basic_string&lt;char&gt; but still) when ran. C++ does not have this ability (yet), Rust does (to some extent, it's not Java/Python/C#-like runtime reflection but you can do actions for each field of a type at compile time which is more than enough for me).
So, I definitely agree. I’ve seen solutions that do this either with template metaprogramming and a lot of macros, code-gen via verbose annotation (Unreal), or using something like clangtools to walk the AST and generate reflection code for marked up classes. I’ve worked in codebases using the TMP style approach to reflect field values, names, descriptions, associate getters/setters, define property grid/editor options, expose methods, describe inheritance hierarchies and network behaviors etc. So the language can already do a lot of what the new feature aims to, but the code is horrible (at least via templates). You are totally right though, a well done standard solution would hopefully make these other approaches unnecessary
Rust doesn't have reflection.
I find that pretty funny because Serde itself is a hack for Rust lacking reflection. You should be able to automatically serialize structs you don't control, not just ones you write yourself.
AFAIU metaclasses require reflection.
I don't believe I have -- looks interesting, thanks!
In a pinch you could use ROOT
Spring Boot, easy web UIs and so much more
can you elaborate more ? what do you mean ? use case?
A, makes sense. Is there any ETA for this feature in coming c++ versions?
Whilst not quite as slick as serde, and not applicable for all of protobuf's use-cases, I often use https://uscilab.github.io/cereal/; it's the most hassle-free C++ serialization library I've found.
it has macros which are able to do stuff with the AST which is more than enough to qualify as reflection imho
24 core machine takes about 20 minutes. Incremental about 20 secs, though if I touch something core, about 2-3 minutes. Full CI process takes 2 hours or so.
"but you still have to list all fields in the serialize() method" Hmmm - if you don't do this, how would the compiler know which member variables should not be included in the serialization? How is this different than " add annotations to class to make it serializable"
I've come into a legacy project, originally outsourced to India, was originally going to be a server, turned into a "thin client", and now we have to support this mess. Just like literally every C++ code base I've professionally worked on, almost every header and source file ultimately includes every other header. Rewriting from scratch would take me 2 months and would be superior in every way, but management isn't interested. &amp;#x200B; \~300k LOC, 80 minutes wall time. Throw 28 cores at it (why did they give me this machine?) and I got it down to 1 minute 15 seconds, combined with CCACHE and I'm down to 45 seconds provided you don't change a header. I have the only Linux machine in the office (it started off with Windows). I'd totally be running Ice Cream Sundae, but I can't get the Mac worker nodes visible due to all the security layers on that platform I can't be bothered to figure out. Since I've come onboard I endeavor to cut this code base down by at least 2/3, for what it is. It's actually really embarrassing. &amp;#x200B; I worked for a company that made it's own tools; this one editor I was stuck on was 12 M LOC, Qt, and we did use Ice Cream on that project to cut compile times from scratch down to 33 minutes, I remember. Don't recall how long it took to build standalone, but why would you ever? We did rely on Linux VMs for our main product, which had to be built from scratch often, due to the nature of their development process. 4.5 hours. I think they just liked wasting time and milking the company for money. No one listened to me when I said the whole editor project was bullshit. The team was dissolved internally when we hired a new guy who rewrote the whole tool in Python in two weeks, over his lunch breaks, and it was everything our tool did and more, and it was better and faster. No one listens to me... &amp;#x200B; I wrote trading software. When I joined that company, it was one of the oldest trading platforms still around (though not anymore) - still had pre-standard C++ I had to gut when I started. Took over an hour to build from scratch on 4-core systems. Don't remember LOC, but it was in the millions, not as big as that shit editor from before. A rats nest of singletons and god objects.
Given that cereal and boost::serialization have an almost identical API, what is the difficulty from switching from one to the other?
This is what I follow. If you really to optimize a specific part of the program later, profile and then look into it.
You mean const &amp;?
Undefined behaviour. Crashes on most platforms. On some embedded platforms without MMU, and where that is a valid address, weird stuff could happen.
You could also: `((void (*)())rand())();` to emphasise the "U" in "UB" ;)
That's a good idea, stripping stuff I don't use. Thanks!
The minimal wishlist: stats, histograms, graphs, conventient buttons and switches to observe and change the state of a running service. Larger wishlist: log service over shmem, proper telemetry, etc. Example (simple): shit is weird. Solution: you type the link in the browser and see that the current number of Stuff is over 30k and Things are happening at a rate of 831 per second, which is not something that you like. You click the button "do the thing" and the demon starts emitting additional telemetry that you can see right here. You go to the graph (that is maintained by this system and doesn't depend on your demon) and notice that yesterday the Stuff was only 23k. You scratch your head and reach the correct conclusion. Alternative solution without a web ui: spend 5 minutes grepping the log, then 10 minutes making a graph out of the numbers, than 15 more minutes figuring out whether your graph is incorrect or your daemon is borked. Regarding other wishes. Any sufficiently performant and insufficiently stable system has two types of a log subsystem: 1) The one that makes everything too slow because it flushes everything on every sneeze. 2) The ones that fails to flush the critically important message 3 milliseconds before the crash, and therefore useless. It's not that uncommon to have logs and telemetry dumped into shared memory (and properly handling it is something that another process is doing for you, regardless of when your demon crashed). Every time I saw something like this it was an internal project-specific thing, and every time it did basically the same. Now, imagine there was a 3rd party lib consisting of a watchdog process with all the features mentioned above, and a tiny lock-free client interface to dump your stuff to shmem. Suddenly: 1) Logs are always non-blocking, crash-safe and fast (a few atomics and a memcpy). Waiting for the IO is not your app's business. 2) Telemetry is almost free. You are writing to shmem, other guy is reading from shmem. 3) Want a runtime switch for the ease of development (or, let's say, to play around with settings)? Just add a button to the web ui. Or a slider. Or a complex menu. Or, well, anything. 4) Want a nice graph or histogram? Don't make your code more complicated, that's a watchdog's responsibility. Your code won't be contaminated with Javascript/CSS heresy. 5) Your demon crashed and was relaunched? You didn't lose any stats, the watchdog will still collect your last messages from shmem. 6) Wanna check this stuff remotely while you poop with your phone in hands? Just drill a hole to the external web. I saw various combinations of the above multiple times, but I never saw everything as one open-source project with minimal requirements for the client app. And I really wish there was one.
I'm on visual studio 2013. My cpu is a little old as an i7 4770k. Yeah debug mode
My goal with the [C++ Middleware Writer](https://github.com/Ebenezer-group/onwards) is to automate the creation of serialization functions. I'm willing to help [someone use it](http://webEbenezer.net/about.html).
For Qt apps I use Qwt which works pretty well for most standard plot types, and has event handling (object picking, zooming), and VTK for 3D. Other than the API and selection of plot types, one of the most useful features of Matplotlib is device-independent rendering via AGG and cairo backends, so you can access the pixel buffer and render it using any GUI framework you want. Matplotlib provides all of the plotting abstractions. It would be nice to have that capability without embedding Python.
Keep an eye on the [xframe](https://github.com/QuantStack/xframe) project. It’s still in early development so you can’t do too much with it yet, but it will really be useful once they support multidimensional data formats like netCDF and HDF5.
Reflection. C++ doesn't have it (yet), but many languages do.
Metaclasses would help in some cases, but not where you can't modify the definition of the class you want to serialize. Or at least I don't see how it would.
ODB
The technical specification has been merged for C++20. C++23 will aim to have reflection as part of the international standard, albeit with a different syntax (constexpr over magic types).
This is correct. Sutter presented metaclasses as "after reflection", targeting the release \*after\* C++ with reflection, so probably C++26.
There is also "coro-async". C++ coroutine based networking library :D
[FakeItEasy](https://fakeiteasy.github.io/) Impossible without reflection like in C# or Java.
Yea, larger than sizeof(void\*) is fine, up to an unspecified limit. Though, 3 ints by reference is 3\*sizeof(void\*) + cost of dereferencing, where as 3-int-struct is potentially larger than sizeof(void\*) depending on your platform :-)
Oh yea. I feel you. That server that I used? I own it. I bought it with my own money. Including the 7200RPM drives that I used in it. I wore out 2 7200RPM drives, and went to my manager and said he needed to ship me 2 500GB SSDs (no more than $200 each. So we aren't talking about thousands of dollars here. This was literally 2018 when I demanded this). It was like pulling fucking teeth. He agreed with me. But HIS boss did not. Great idea to waste a Sr. engineer's time. It's not like that's expensive, or anything, right?
Yes, sorry, it should be an "and". Also yes. 2\*sizeof(void\*) is more reasonable.
I try to close the gap: serialization and member field iteration for plain structs is working without precompiler and macro magic. Link: https://github.com/felixguendling/cista
&gt; or the STL. Could you clarify a bit why you decided not to use the STL?
I don't want to turn this into a hair splitting contest over the definition of reflection, but basically I will simply say that when people say "programming language X has reflection", they are typically talking about facilities that allow examination and manipulation of written code, generally. Not a specific feature that lets you manipulate code that its passed through (that would be called, well, macros). If you think about all the other languages that are regarded as having reflection, e.g. Java, python, C#, Go, none of these languages have issues iterating over all the fields of a struct that has been defined, in general (there are always caveats of course). These languages typically solve serialiation very generally, and you have little problem serializing types you don't control provided they meet basic requirements (e.g. pickle in python). As I said elsewhere, the solution that serde gives you is *fundamentally* no different from boost fusion; yes the macros are crappier and less hygienic etc etc, but either way you can opt into reflection simulation via macros and from there you can write generic serialization code. This is miles away from what those other languages give you. A common issue from me at work is using some simple (all public) type1 from lib1 I don't control, and I want to serialize it according to some scheme from lib2 that I also don't control. In both Rust and C++ you are typically screwed in these situations, and in all those other languages you are usually ok (in Rust you are double screwed because you control neither the type nor the trait but that's another story).
Seems like you should be able to create a [document](https://poppler.freedesktop.org/api/cpp/classpoppler_1_1document.html), spam (the somewhat poorly named) [document::get_page()](https://poppler.freedesktop.org/api/cpp/classpoppler_1_1document.html#a39257206a337df2f56049f385d433821) to get a [page](https://poppler.freedesktop.org/api/cpp/classpoppler_1_1page.html), then use [page::text_list()](https://poppler.freedesktop.org/api/cpp/classpoppler_1_1page.html#aa575c693a82ff6bf1c55434f1251ff75) to iterate over the [text_box](https://poppler.freedesktop.org/api/cpp/classpoppler_1_1text__box.html)es on that page, then use text_box::text() to get the actual strings.
Yes, thank you, I've been able to query the number of pages and get some data out. It seems the API has actually improved since some of the examples I've found were written. I'm still wondering if this is the preferred free and open pdf reader solution or if there are others out there that are more widespread in use.
Passing by "pointer" or "reference" is in a sense an implementation detail. You can have a "value" which uses pointer or reference semantics on its underlying state. For example, `string_view` uses pointer semantics; `std::string` uses value semantics. Passing one by value is not the same as passing the other by value. Passing a reference or pointer semantics type by pointer or reference is a great way to become a "three star programmer" http://wiki.c2.com/?ThreeStarProgrammer ; indirection of that kind is the same regardless of how it is implemented. So if your type has reference or pointer semantics, pass by value. Any sane reference or pointer semantics type will be cheap to copy anyhow. About the only exception is when you want to use the "return by parameter" pattern. My advice on the "return by parameter" pattern is, generally, don't. --- Now, what if your type has value semantics? When you pass a value semantics type by value, when the value changes is clear. When you pass it by reference or pointer, logically that value can be replaced with a different one whenever control flow is non-local (say, you call a function). You have to audit the entire contents of that function to determine if it will somehow go and change the thing being pointed or referred to. Now this is rare, but that in a sense just makes it worse; you assume it doesn't change, until it does and your code explodes. Compilers also have to do this proof. So if you pass: void foo( std::string const&amp; s ) { auto first = s[0]; bar(); // some function auto second = s[1]; } the compiler **cannot** cache anything between getting `first` and `second` unless it first fully examines `bar` and proves that `bar` cannot change what `s` refers to. void foo( std::string s ) { auto first = s[0]; bar(); // some function auto second = s[1]; } in this case, there is no way for `bar()` to change `s`, so the compiler can easily prove that it can cache intermediate state between assigning `first` and `second`. This kind of knowledge allows the compiler to make sometimes huge optimizations in your code. Passing value-semantics types by value means both humans and computers can reason about the behavior of your program a whole bunch easier. Computers reasoning about it leads to better optimization; humans ease reasoning about it prevents bugs. --- So, the answer is, pass value semantics types by value unless you can show that it will be a significant performance hit. Pass reference and pointer semantics types by value as well. If you are passing a value semantics type by reference, consider replacing with a reference semantics type; often you can get tighter invariants and simpler code. Ie, `gsl::span&lt;T&gt;` instead of `vector&lt;T&gt; const&amp;`. If you are passing value semantics types by reference as an out parameter, consider changing it to a real return value, or use continuation passing style and pass by value into the continuation. Forwarding reference adapters are an exception to this. They should be brief and only written because you cannot get the language to do it for free. --- There are other exceptions; copy/move constructors. They define what taking by value means, so they cannot take by value. Assignment operations also also conventionally by reference; by value has some issues involving composing and inheritance. In some cases, you'll want to *insist* your input is moved-into you. Then taking by rvalue reference and immediately moving into "final" storage is justified.
Incidentally, `document::load_from_file()` and `document::create_page` return pointers. Am I to assume they need to be deleted? None of the examples online do any kind of cleanup.
golang I/O library
You just said it wasn't C, then said it is **also** C. Being **also** C means it is C. It is also a sequence of ASCII characters. It is also binary bits on disk. It is also a series of text encoded files. The many things the python code base is **also** doesn't prevent it from being C. It is the subset of C that is also valid C++, and it is compiled as C++ because the C++ object memory model permit the compiler, which compiles either C or C++ on request, to more aggressively optimize it as C++. But it is 100% valid C, so **it is C**. Heck, I'd bet the behavior in terms of the abstract machine will even be the same between the C++ and C compilers, but **the compiler has no hope of knowing that** because the C object and memory models make it intractable to prove that the C++ optimizations can be safely applied to the code.
Given [the `load_from_file()` implementation](https://cgit.freedesktop.org/poppler/poppler/tree/cpp/poppler-document.cpp#n1121) looks like the caller is responsible for `delete`ing.
Modern GUI frameworks like- WPF Dependency injection library like Dagger
Easy; add `[*]` capture. When you use `*` capture, you can use any variable in scope as a pointer. int foo( int y ) { return [*]( int z ) { if (z&gt;0) return z; return *y; // here `y` is a pointer-to-y }(-1); } C++'s `[&amp;]` is actually `*` "under the hood" based on what lambda=lambda does. We could even mollify the implicit this: int foo( int y ) { return [*s]( int z )-&gt;int { if (z&gt;0) return z; return *s.y; // here `y` is a pointer-to-y }(-1); } in this version, an implicit parameter `s` is introduced by `*s`. So it expands to: struct anonymous_type { int* y; }; int call_anonymous_type( anonymous_type s, int z ) { if (z&gt;0) return z; return *s.y; // here `s.y` is a pointer-to-y } int foo( int y ) { return call_anonymous_type( anonymous_type{ &amp;y }, -1 ); } with the note that pointer-to-temporary violation is ignored here. Now, if C is ameniable to overloaded operators... struct anonymous_type { int* y; }; int operator()( anonymous_type s, int z ) { if (z&gt;0) return z; return *s.y; // here `s.y` is a pointer-to-y } int foo( int y ) { return anonymous_type{ &amp;y }( -1 ); }
"Almost" is the key word. I have hundreds of classes serialized by cereal and I don't want to refractor it all back and forth.
I'm writing a p2p networking framework. Lots of packets to serialize.
Best bet today is protobuf.
I usually want to serialize every field in a class. If I want to add stuff that shouldn't be serialized, I'll just move it to different class and use composition.
Augmenting it a bit to removed possibly confusing `auto`s. #include &lt;bitset&gt; #include &lt;iostream&gt; constexpr bool f() { constexpr auto x = std::bitset&lt;8&gt;(); return x[99999999]; } int main() { constexpr bool i = f(); std::cout &lt;&lt; i &lt;&lt; std::endl; } basically, it appears that the `std::bitset` is using shifts for small `bitset` implementations. Make the bitset larger than 64 and it switches to an array implementation and the UB detection works. #include &lt;bitset&gt; #include &lt;iostream&gt; constexpr bool f() { auto const x = std::bitset&lt;65&gt;(); // x[99999999] = true; return x[99999999]; } int main() { constexpr bool i = f(); std::cout &lt;&lt; i &lt;&lt; std::endl; } http://coliru.stacked-crooked.com/a/7630a8f00dee685c
I don't think you will find anyone to work for free unless the software is free *and* open-source, and even then it won't be easy.
I’d *love* to see something like this. I’ve done the same - built parts of it / integrated others together, and worked at past companies which had (closed-source) subsets of such infra, and always missed it when I’ve moved on.
I understand that. I'm just relying on luck at this point. If someone interested wants to help, great. If no one does, so be it.
FWIW https://github.com/couchbase/phosphor is an open source tracing library which does a small subset of this - namely an in-memory ringbuffer to record events into. It does the low-overhead writing bit, but the reading is currently just done by a different thread in the same process.
Thanks for taking the time to write down the problem I never run into this problem i must say , we just run banch of regexp + greps on our logs to create reports or kibana
r/gameDevClassifieds is a better subreddit for posts like this. Good luck!
Cool buddy. Hey I have some stuff that I want free help on too. Why don't you work for free for me and then I'll think about working for free for you.
something like : python flask ?
Thanks mate! Just concerned they would be even more pissed at a playless job offer.
What do you need help with? I specialize in writing.
Writing C++?
Writing dialogue and narrative. If i was good at code i wouldn't be doing this.
&gt;protobuf Nah, I don't like any code generators. &amp;#x200B; I like to keep things simple. In my framework you only need to make three things - request class, response class and a function that takes request and returns response (a packet processor). And even if you omit one or two of those things, it will just use default ones (if you don't care about response to request or it's just a simple ack). It would be best if I didn't have to write serialize functions for those packets, but for now I'm just using cereal and live templates in CLion to write them for me.
I just realized that when reflection TS will be merged into standard (I guess C++26), it would be more than 20 years since I started writing in C++...
How much would I get paid? I presume you will give your devs a cut of the profits.
The game is 100% free, no microtransactions or ads. No one will get any money. It's purely a passion project.
Maybe you would know that if you read beyond the title.
I read the whole thing thank you very much. I got a little caught up on some of the wording is all.
Looks interesting, but I don't like the fact that I have to wrap every field in a structure from your lib. Cereal has the advantage that you can have ordinary class with normal fields and serialize function can be added outside of the class.
And to be blunt, you can’t be particularly passionate about your passion project if you want other people to do the bulk of the work.
It's a big project. I have many people in the dev team as of now and am just looking to expand it. We want this project to be the best it possibly can be.
1. How would this game be licensed? 2. How many people are working for you right now? 3. How many C++ coders do you have and what are their qualifications? 4. What other projects have you done?
Might be time to learn
If you're using GoogleTest/TDD and compile times hit you, you should read the section in the cookbook on reducing compile times. In my own tests involving a good-sized codebase it reduced my compile time an addition 10-15%. The short version is that you declare mock class constructors in a .cpp file so you don't have to rebuild them in every test class that uses them.
1. Yet to be discussed 2. 8 people 3. 2 coders, both decent 4. I've done mostly novellas and filmwriting, and have programmed one game a while ago with C#
If it's free and completely non-profitable, why not make it open source?
There's a third one, which is quite similar: [https://github.com/ThijsWithaar/matplotlib](https://github.com/ThijsWithaar/matplotlib) (shameless plug)
We tried that, someone went and stole our shit.
You can try [RESTinio's express router](https://stiffstream.com/en/docs/restinio/0.4/expressrouter.html).
Decent is not a qualification. I suppose they asked for education and career.
&gt; Technologies: We're still deciding on what C++ we want to use, and you can use any OS as long as you can code with it. Unity and C# is better without previous knowledge. Pick an existing game engine or library, if you'll make your own game engine you'll fail for certain.
They have neither. This is for experience, not an actual professional project.
We have tried both, but got farther on the time we used C++.
There is also [this repo](https://github.com/arBmind/2018-cogen-en/tree/develop/code) that shows various ways of exploiting coroutines for optionals, statemachines etc
/r/cpp isn't for code reviews. Please use /r/cpp_questions or https://codereview.stackexchange.com/ And I suggest going and looking at all the other libraries that already do this to see how they do it and trying to figure out what you think you can improve upon.
Not even their own project on github? Education? Computer science student at University? Still in high school?
I usually target Linux + Windows, but prefer to work in a Linux environment. Right now I can make my project with QtCreator, and cross-compile for Windows using MXE outside the IDE. If I were able to use VS to do all that there's no question I'd switch to it, but it'd have to be completely on Linux.
I can do this in my CIDLib system, and you don't have to do anything special. Anything that implement the MStreamable interface (which makes them streamable to/from my binary streams) will be streamed in a way that allows it to be streamed back in, sent as parameters to ORB remote methods, etc... And you can do polymorphic streaming of a collection of stuff based on a common base class and stream them back in as well. But it requires that I toss the old and crufty standard libraries/STL and do my own system that supports this kind of thing from the ground up. The benefits are huge though.
Are you going to use an existing game engine or make your own? Vulkan, DirectX, OpenGL?
"Stole" is a wrong word to use if we are talking open source.
You're right. Its not stealing, but we didn't like it. When the game releases we might make it open source though.
High school and university. We're all young and are interested in getting experience working on a game. No interest in cash whatsoever.
Still thinking about it, but leaning towards native.
This doesn't let you get the names of the member variables as a string, I assume?
5. has anyone in your team completed a game before? 6. If you decide you commercialize later, how much profit share are you willing to extend? 7. Since this seems to be open source game right now, can you direct me to the script? 8. How much work do you expect? Yes. I am asking for other coder's education and career. As far as I am concerned, I have left the coding job a long time back. ( I was a quant programmer in a Fintech company). I would consider myself an intermediate C++ coder.
Thanks! It's not clear whether it's maintained, but looks like it can be a useful example!
5. Yes 6. I'm willing to keep 5 percent for me and split the rest out between the devs. Yes, you will all make more than me (but its unlikely we will commercialize) 7. It isn't 8. I don't expect any, you just do what you want. If I'm not paying I won"t force anything. Yes. You are asking for other coder's education and career. As far as you are concerned, you have left the coding job a long time back. ( you were a quant programmer in a Fintech company). You would consider yourself an intermediate C++ coder.
Thanks! Although it's already been under the talk, it seems it makes sense to explicitly include the repository as an example, too!
Thanks!
Oh, I didn't see it. Yeah, the repository might be worthy of inclusion separately, although I don't know if it is maintained or not.
Wouldn't it be safe to assume the compiler would mark functions as "pure"/whatever (don't mutate their arguments) even if they're not inlined? Then during codegen it would know they don't need to be reloaded after non-inlined calls. Or am I expecting too much of the compiler?
&gt; It would be meaningless to pass a mutex by value, but if you're writing multi threaded code you'd actually get yourself in less trouble doing this meaningless thing Until you start locking the mutex that doesn't do anything...
I am not familiar with Rust. Can you provide an example how this type would find use?
If you want a simple, embedded web server for internal use, there's https://github.com/civetweb/civetweb I've used it to serve a simple html interface from inside of smartphone games as a tweak UI.
Crow is dead project. Can check drogon, httpbeast, and few others.
how is it different from std::expected?
I saw in your other replies that you guys are in highschool/college. To gain the attention of experienced people you guys should at least give a link to the demo game and design. Link to storyline and sketches would be super useful. By doing this, you might gain the attention of someone who shares the same interests as you and is willing to work for free. It also shows that you guys are dedicated. Experienced C++ developers get paid a lot so you guys have to show utmost passion and that guy has to share the passion. Let me know when the demo is ready and I "might" help.
Thanks, but I don't think any parts are salvageable. Even ignoring the entirely different concept, the implementation is... let's say I wouldn't go as far as calling it "low-overhead" (opened a few files at random, looks like pretty much all ordering constants for atomics are misused, spinlocks are flying everywhere for no obvious reason, etc.)
This is a bit jarring bool is_ok() const { if constexpr (std::is_pointer_v&lt;T&gt;) return (std::get&lt;T&gt;(value_)); return value_.index() == 0; } If `T` isn't a pointer, `is_ok()` is true if the Result is holding a `T`. Great. If `T` is a pointer, then `is_ok()` is true if the Result is holding a non-null pointer, false if it's holding a null pointer, and throws otherwise. Bad. It's generally pretty bad to have multiple different semantics based on types. The throwing there I'm assuming is just a bug (and illustrative of the lack of unit tests), but more generally if a `Result&lt;int, E&gt;` can successfully hold `0` then `Result&lt;int*, E&gt;`should be able to successfully hold `nullptr`... especially since `Result&lt;unique_ptr&lt;T&gt;, E&gt;` can!! Other issues worth calling out: - Your comparison operators should take const on both sides and not have rvalue overloads - All your unwrapping methods are very unsafe in their use of moves. You should not have const vs non-const return different value categories! Very surprising! - Your panic()s are in noexcept functions, so they all terminate regardless of whether it throws or not. - `operator bool()` should be `explicit` and just call `is_ok()`
I guess because `std::expected` isn't in the standard yet...
The TS itself, n4775, is a fairly good reference. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4775.pdf
You could check whatever LibreOffice (OpenOffice or whichever) uses. Their PDF import is pretty shit thought but nothing can compare to Adobe PDF (which costs lots of money and no library available of course). For just reading text, it should be fine. I suspect they might even use Poppler.
You can - depending upon which stm32 you have. GCC supports several ARM targets
Seems like the community disagrees
Agreed. OP pretty much made a custom truthy system.
Huh? This isn't something to disagree with. It's in the side bar.
🤷🏻‍♂️ apparently there’s contention lol
one more actively developed: https://github.com/facebook/folly/tree/master/folly/experimental/coro and a relevant cpp cast: https://cppcast.com/2019/03/kirk-shoop/
Consider also [this coroutines cheat sheet](https://hackmd.io/s/S1H_loeA7), which a list of the customization points, a list of coroutine-related standard types and functions, keywords, and some templates (not in the C++ sense) for promises, awaitables, etc.
AFAIK they're not marked automatically, but you can mark functions at definition with the \[\[gnu::pure\]\] and \[\[gnu::const\]\] attributes, assuming you define them.
Lol. Pretty sure he put the star there to mark his comment as a correction. So yeah const &amp;.
Personally I'm not interested. At my old job, we had simply ridiculous build times, and I was actively involved in a multi-year project to improve that. But at no point did I ever read anything about modules that made me think they'd be an improvement over what my group was already doing.
[Here's Rust's explanation](https://doc.rust-lang.org/std/result/index.html) &gt; Result&lt;T, E&gt; is the type used for returning and propagating errors. It is an enum with the variants, Ok(T), representing success and containing a value, and Err(E), representing error and containing an error value. &gt; Functions return Result whenever errors are expected and recoverable. In the std crate, Result is most prominently used for I/O. It's a type that holds a value of one of two types, and it doesn't let you directly access the inner value unless you check which one it is. It's intended as an error handling and propagation mechanism. In Rust it comes with convenient functions/operators that let you manipulate and transform the result. There's the `?` operator which allows access to the inner value if it's the first variant and returns from the function if it's the second variant, the `if let` language construct that lets you check which variant it is when you enter a block and skip the block if it's the wrong one, and the `map` and `map_err` functions that let you modify the inner value. Compared to exceptions (which Rust doesn't have), it forces the function's signature to specify whether or not it can give an error. For example, the function for parsing a value from a string returns a `Result` because the string is not necessarily a valid value, while the function for displaying a value as a string does not because all values have a valid string representation. It also requires handling every possible error when accessing the inner value. You can use the `?` operator to pass any errors to the function's caller (equivalent to doing nothing with C++ exceptions), or handle it locally (equivalent to try/catch).
Does doing that take a long time for people? It's like half an hour tops on my machine.
Ccache occasionally gets some bad PR because sometimes it does weird things (or used to, anyway).
Feel free to copy ideas from my attempt at porting the Rust Result type to C++. https://github.com/ampron/functional[https://github.com/ampron/functional](https://github.com/ampron/functional) One thing worth pointing out is that C++ std::variant does not support reference types, which is an important design choice that my library took the opposite approach to because I really liked using Result&lt;T&amp;, E&amp;&gt; in a Rust.
While reading Dawid Pilarski's articles I kept thinking, "It isn't _really_ this crazy complicated, is it?" With much respect to Mr. Pilarski, I recommend reading Lewis Baker's series _first_. Baker writes: &gt;The facilities the C++ Coroutines TS provides in the language can be thought of as a _low-level assembly-language_ for coroutines. These facilities can be difficult to use directly in a safe way and are mainly intended to be used by library-writers to build higher-level abstractions that application developers can work with safely. Similarly, the cheat sheet linked to by u/Sanzath reassures us: &gt; This is also intended for people who need to know the inner workings of the TS, such as people *writing* libraries. This is not for people who just want to use coroutines with one of these libraries, since that is _much_ simpler. _Thank God._ Thank you for the resources, everyone.
My main interest is the ability of encapsulation. There is currently no way to encapsulate (read: hide) code, except for between translation units as entities can have internal linkage. But then this meant nothing could be hidden if it was necessary to define I type, aka in the header. Now there’s a way with modules since headers are unnecessary.
The [root of the repo](https://github.com/arBmind/2018-cogen-en) might be more helpful, as it includes the slides of the talk for which the repo was made.
&gt; Your example does not work. You can't write p-&gt;name in f, if f doesn't see the definition of Person. Oh right, good catch.
That's fair. I use namespace impl for that, but it's never been a satisfying solution.
You can use on-line services to hide some code. That's what I do with my C++ middleware code generator.
Mind giving an example?
Thanks for the valuable input. If T is a pointer, I wanted to offer a way to query a null pointer using is\_none(). I forgot about assigning nullptr to unique\_ptr and that this check would fail. I'll remove it. Regarding the other issues: \- noted. Will change. \- Returning an r-value ref requires a non const function. Or am I wrong? \- I wanted unwrap to always terminate on failure. While the expect() variants are for uses with exceptions enabled. Expect can be used in try catch blocks, unwraps can't. However, custom actions can be added by using std::set\_terminate. \- noted and will change.
Oh nice...thanks. I'll have a look at it. I was wondering how to implement that.
Thank you for this response.
Static exceptions are on the top of my wish list. I wouldn't stop your projects waiting for modules.
I’m definitely excited for those too, although it seems like it’ll be quite a few years before they’re standard. I use error codes and structured bindings currently and imo it’s fine.
Maybe try /r/cpp_questions
* Option &amp; Result types are more composable than optional &amp; expected * Mutex owns it's data * Arc (comparable to shared\_ptr) has copy-on-write built-in * mpsc::Channel (a fast thread-safe, non-locking queue) is included, nothing comparable in C++ * All of the safe integer operations * println! is type-safe That's a short list off the top of my head. I highly recommend trying the language, I learned a ton from it and it made me a better C++ programmer.
Of course not, i'm not going to doing something i enjoy just to wait for a feature. What i'm really hanging out for is a timeline for implementation by the compilers and (perhaps more importantly for me) CMake. My hobby projects are already set up with CMake so i'm not going to retool my build process just so i can use modules.
Nah. I like building stuff more than waiting for new features.
Fair.
&gt; Release build takes up considerably less at ~15GB). Is this because of media? images/video/music/etc ? Static linking? Are you including `.o` and other files in this calculation? My Chrome is 450 MB. I found the size back in 2011, it was mostly data not used by regular users. &gt; So lets look at an example for Windows, if you look at the core browser code in src/chrome, you will notice the following: - Chrome 10 for Windows at 26.2 MB - The size of the folder is ~1.1 GB (my early clone) - The test data is around ~900MB - The Linux, Mac, and ChromeOS files take around ~100MB - Comments around ~30%. &gt; That leaves around ~100MB (excluding compiler optimizations), I don't know how well it compresses, images, files, etc. So from 1.1GB till 100MB by just removing the stuff that interferes
Part of my code generator is closed source.
Is it possible for c++ to use a rust-like `check` ? https://doc.rust-lang.org/edition-guide/rust-2018/cargo-and-crates-io/cargo-check-for-faster-checking.html
By on-line, what do you mean?
I think ranges might help with this a bit.
Have you tried Catch?
Have you tried [cpr](https://github.com/whoshuu/cpr)?
I think modules are a huge mistake that will hinder the language for the next 20 years.
Mind sharing your thoughts?
&gt; Also, cereal doesn't support C++14 or C++17 types What do you mean by that? I switched from boost to cereal a few years ago and couldn't be happier. The only feature it lacks from boost is serializing raw pointers, but I got around that using some tricks.
mostly just this: https://vector-of-bool.github.io/2019/01/27/modules-doa.html
Mildly, yes. I would expect sort(s); to return a sorted copy of the data structure.
I think the primary worry outlined by this post has already been solved by clangs partial implementation. It requires a supplementary file in s directory that defined where module definitions can be found, and a whole host of other properties. So, instead of the compiler running around, we tell it where to look. This is a fine solution in my eyes, as the hypothetical speed up from modules will not be bogged down by this search time and get to shine.
If you really mean hide, that's not going to happen. You are going to have to ship source files for the module interface units. There is no model being pursued where this isn't true. You will have tighter control over the names that are visible to the importers of your module, and you can avoid \`detail\` namespaces, but even names that you don't export may be entities visible to importers.
Ahh.. ok, I read your initial comment and have been experimenting with implementing memory management. I got things working by calling `load\_from\_file` and then immediately creating a `unique\_ptr` with the document pointer as an argument. This is what you meant? I just read through the [resource management section](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rr-raii) in the core guidelines and read the looong exception description. Lastly, am I reading this right? [One `create\_page` overload](https://cgit.freedesktop.org/poppler/poppler/tree/cpp/poppler-document.cpp#n919) uses a smart pointer and then calls another overload that then allocates with `new`?
He's slightly more optimistic now: [https://vector-of-bool.github.io/2019/03/04/modules-doa-2.html](https://vector-of-bool.github.io/2019/03/04/modules-doa-2.html) We're working on a TS that will be a treaty between compiler implementors, build systems, and programmers, about how to make modules work. Cautious optimism is in order, with the understanding that your current build system may not survive contact with modules, particularly if your own code is attempting to use them. We think the story about consuming external modules is manageable.
I should have clarified what I meant by “hide”. By that I mean from IDE intellisense. Don’t like that it’ll suggest my impl namespace, or other details if I don’t put them in their own impl namespace.
They seem to use `Xpdf`. I tried to hook into them last night but I still needed headers.
Tbh I kinda stopped coding for about 2 months in order to wait for `char8_t` because there was no point writing any code that involved text.
I wrote one for C# called [Scarp](https://www.github.com/ryancerium/scarp), feel free to steal any ideas you find useful.
Don't you think that even needing to do this means that the feature is half baked and therefor fundamentally incorrect? That's how it feels to me.
The fact that this kind of stuff needs to happen means that this is being railroaded by those with power without any respect to the language.
Well, they are quite different then most features. It’s the first feature introduced that creates an encapsulation layer since classes.
Is it the first **PROPOSAL** to add an encapsulation layer?
I’m not sure what you’re implying. I’m not sure?
I want lambda classes/structs, to just be able to plonk down a small object that will work inside that scope would be really something for me
Still waiting for VC++ IDE support.
modules are for code isolation, and just happen to probably decrease compilation times. &amp;#x200B; You mean something like singleton types? It'd be great if C++ had duck-typing, but sadly it does not. If it did, object literals with an inferred type could exist (kind of like in python and javascript).
The advice i've had is that you should pass by value when the type is small and *cheap to copy*. std::vector and string (when larger than the SSO buffer) violate that second part
I'm having trouble figuring out how the Rust syntax carries over here. In what situation did you feel Result&lt;T&amp;,E&amp;&gt; makes it more convenient? On GitHub I see that you have tests that use the idiom of as\_ref().match(...), is that the only use case? Also, related: would it not have been easier for .match() to always pass arguments to clauses by reference?
I think this is what the fairly recently introduced QHttpServer is.
this may be esoteric, but fortran arrays and intrinsics. as a millennial scientist that keeps evangelising the expressive power of C++, there is nothing more depressing than conceiving and building most of a new simulation framework that's fast and intuitive and sleekly designed, only to get dragged down into the muck of pointer offsets and memory management required for multidimensional arrays. current third-party solutions are brilliant efforts that still lack the sublime ease and performance of fortran. eigen comes close, but eigen only supports 2-d matrices. which is awful, because fortran is so awful for everything else.
Python's math, statistics and machine learning packages.
Reminds me of looking over one of our EE's shoulder by coincidence and immediately recognizing they were compiling their firmware single-threadedly. They didn't even think about speeding it up since they are used to half an hour builds or more with their FPGA stuff 😅
I like to just output whitespace delimited tables and pipe them to [feedgnuplot](https://github.com/dkogan/feedgnuplot). Makes for a nice separation of concerns and composition of tools (you can read a whitespace delimited table using NumPy then the plot with Matplotlib).
So did you tell them about -j 4 or did you let them have their swordfight on chairs?
For example, cereal doesn't have built-in support for std::filesystem::path and other types added in C++14 and C++17.
Sounds like you really want .net core running in Azure with appinsights enabled. Why bother with C++?
Idk if it would be called duck-typing, but like a lambda, an object, that would exist inside of the scope only. A small thing that wouldnt need its own cpp/h include, or exist globally, but just to throwaway after use. Something to give more oversight as you bring various other data into scope. Imagine having a kart/toolbox with methods/variables you will (only) need throughout the current scope. You could make a lambda or 2, and declare a few variables, but having a lambda object would make keeping track of the ones used throughout easier. Something like: lambda_struct relevant_things { int user_count=0; //users int min,max; //keep track of youngest, oldest void add_users(int i){user_count+=i;} void minmax(int iage){if(iage&lt;min)min=iage;if(iage&gt;max)max=iage;} }; As you bring stuff into scope, you could perform methods and keep track of the data as you go on. Declaring variables as you go along would clutter up anything, as the lambda_object would help keep focus as you walk through the task. This would be one use anyway, just a lambda that instead of being a fucntion, would be some data and methods to go along. I guess you could do this another way, but I feel a lambda object would be useful
&gt; If you really mean hide, that's not going to happen. I don't understand the implications. Will modules make it possible for me to NOT bother with PIMPL, yet at the same time hide all the crap that is needed by the implementation? (E.g., my `MediaProcessing.h` has `#include &lt;libavcodec/avcodec.h&gt;`, yet the module hides all of the included crap?
Really cool. Also, readable code :D
Thanks. :D
I've proposed a similar idea some time ago on std-proposals but it was not that well received : https://groups.google.com/a/isocpp.org/forum/#!msg/std-proposals/vYsnIbdI_lQ/8C8GtXhtBwAJ could make sense to try to make a paper though
Have you considered implementing your Result following the AUTOSAR Result specification (maybe modulo Google-Style Naming)? [https://www.autosar.org/fileadmin/Releases\_TEMP/Adaptive\_Platform\_19-03/General.zip](https://www.autosar.org/fileadmin/Releases_TEMP/Adaptive_Platform_19-03/General.zip) \- it is included there in AUTOSAR\_SWS\_CoreTypes. &amp;#x200B; In regards to rusts Result: The thing I liked most about it are the combinators, conversions from/to optional etc. Although without \`try!\` / \`?\` it becomes unreadable fast - and I am uncertain if this can be replicated by a CPP macro :/
Unfortunately, i still think the feature is half baked.
You might be disappointed. C++20 has a lot of great features... modules is by far the less ready
I am assuming you're the Corentin Jabot referred to in the vector of bool post? Do you think the half-baked-ness is on the tooling side of things or on the language side, and how hopeful are you that things will get fixed before C++20 goes final?
You could also use other data structures like std::vector https://github.com/felixguendling/cista/blob/master/test/std_vector_test.cc But this has other downsides (manual destructor call as in the example above). Also: I assume that Cista's approach has better performance (faster deserialize) than cereal (see benchmark).
No, that's not possible with this approach. Here, you would still need to use macros.
You can already declare [local classes](https://en.cppreference.com/w/cpp/language/class#Local_classes); what would a hypothetical "lambda struct" bring to the table?
How will this effect my build system, which is basically a portable clone of msbuild that can also build its own projects?
For me they will have to actually prove themselves first. Do they actually lead to better compile times? Is it worth having to write export in a number of places in order to get better encapsulation? If I can't set up a regular Makefile (GNU make) to work effectively with modules I'm probably not going to use them.
Thanks!
Thanks a lot, this looks great!
Added, thanks!
After reading the blog post I still don't get what is fundamentaly wrong about the proposal, apart from the potential perfomance issues. Quoting: "We have module dog defined in meow.cpp! That's crazy!". I mean, why is it that crazy? I should be able to name the file in whatever way I want, just like we now with classes. Am I missing something?
I'm not really waiting. I'm experimenting with modules implementations using Build2. You can try it today too. For my current projects that use CMake, I just make sure that they will work once C++20 is implemented. I always make sure that the whole code base is easy to change drastically, so switching to modules doesn't scare me much.
Maybe it doesn't make sense from a technical point of view? Like I bet its possible to find good examples where it would be useful (atleast in an esthethic/logical sense). Personally, I just want to make a throwaway variable with memory and functionality, like a little thing with arms and a head. Nothing serious, like what a lambda is for functions. Something like that might free up some creative space I think, not being forced to declare a class just to keep a little oversight when gathering data from various places. Im sure there must be more examples
I would say that OP's code isn't either, so that is not a difference? BTW. What is the status of std::expected? I can't find anything recent on it.
&gt; sqlite_modern_cpp - Zero overhead C++14 wrapper for sqlite3 Strongly disagree. - the library looks abandoned - see issues and their dates - **the library does not support iterators and ranges** - how is this modern C++? - the library assumes every BLOB input is `std::vector&lt;T&gt;`, there is no other API - the library does have any any span-like API in the form of (pointer, length) - you have to allocate std vector - SQLite supports non-null-terminated inputs - the library does not (implementation feeds SQLite with length = -1) - the library spams with `std::string` constructions, even for C-strings
You're not missing anything. The whole thing comes down to performance.
&gt; Never manually format code automatic formatters make version control a bit useless. i was on a team who did this, and it drove me crazy not to be able to diff easily.
Compile times. I need to be able to iterate as quickly as possible when I'm tweaking gameplay behaviour. I think that compiling in under a second for the module I'm building (in this example, the game module) is a reasonable expectation. STL headers can significantly bloat compile times, so I tried not to use them on this project, and as a result my compile times were much improved. Combined with hot reloading code on build, this made iterating on mechanics very pleasant.
No. You will still have to worry about PIMPL.
step 1 - format all the code, and commit one single commit that align the whole repository step 2 - do your changes, format them, commit. The formatter will not affect any other part of the code, since it was already formatted. If it does, your formatter isn't a good one.
&gt; probably decrease compilation times. Compilation time is the same as for pch, and you can use those today. Modules might increase compilation times depending on how automatic your build system ends up being though.
Not sure what op meant by that, but clang-format allows to restrict formatting to selected region or scope. Keybinding clang-format is a way to go imo.
in step 1 you lose the ability to diff. step 3: the formatter style changes (because that thing is a trend, not absolute). now you're back at step 1.
yep, that makes sense to me. but it's way different than "never manually format"
Of course I did, \`-j8\` and suddenly it compiled in no time. But as I said he wasn't that impressed.
PIMPL is more about binary compatibility (ABI) and build time than API compatibility. I don't see how modules (which improve API) will change anything about PIMPL.
Try compiling gcc or clang. Takes hours. Especially on Windows where LLVM doesn't support being built as shared libraries (basically because symbols are not properly exported explicitly).
That's the problem right there. Employers need to understand that working on large codebases require fitting their employees, interns or otherwise with beefy machines with high core count and enough memory (which should scale with the number of cores) as having developers waiting around for the end of a build is completely unreasonable financially
You probably also want to disable `operator bool` if `T` is `bool`. I have been bitten in the ass by my own `Result` class before because `if(func_that_return_result())` only tested the state of the result and not the actual value.
It exists, for one thing. :-)
The thing is that you can't git blame "old" code anymore.
&gt; “There are only two kinds of languages: the ones people complain about and the ones nobody uses.” &gt; ― Bjarne Stroustrup Good and bad are somewhat subjective. I personally think that C++ is a very good language. It does exactly what I want it to do, in almost the best way possible (still waiting for reflection). It is not secure in that there is no in-language facility to prevent you shooting yourself in the foot. If you need something like this, use Rust or a safe library. &gt; I also see these people comment that Rust is the future of C and C++ Nonsense. Rust will probably take a piece of C++'s market share (the one that care about safety). There are still many case where C++ does as well or better than Rust, so it is not going anywhere any time soon. &gt; I find all this hard to believe when C/C++ are such popular languages used to write important software. Why? And what other alternative would you propose?
&gt; It exists, for one thing. :-) I mean, people have implemented the std::excepted interface as well, [this](https://github.com/TartanLlama/expected) one comes mind.
Still lacking `zip` and `enumerate` (in the standard library incarnation of range-v3) but they should come later.
Did this for a fairly large legacy code base and never looked back. Also added a git hook that checks if clang-format was used.
It's a complicated question. When in doubt, C++ will allow you to shoot yourself in the foot. It is certainly possible to find a trade-off between freedom and safety and C++ leans heavily towards freedom and not safety. But programmer skill plays heavily into this as well. It is a bad language if you are a mediocre programmer. The more important metric by which to judge a language is expressivity and performance cost of expressivity. C++ leans heavily towards performance, but is pretty good at expressivity too, but again assuming a perfect programmer who knows the language. C++ is very difficult to learn, it may be the most complex programming language in existence that has notable relevance. Which language dominates the future is a question of how good your marketing among new programmers is. C and C++ are still first choice when it comes to systems and high performance applications. People who work near those areas of computer engineering and programming get to learn C++ every day. For interactive GUI applications where performance is not critical, C++ is not the best choice and people in that field usually learn something else. Whether Rust will eat into the c++ domain is a question you can only answer in hindsight. Which language is better is by no means the only concern. C++ is huge, Rust is negligible as of now. At this point in time, it's your choice where you want to place your bets. Even if rust is objectively 5% better than C++, it could still take 2 decades before that translates into a numerical dominance over C++ or it may never happen. To make up 5% worse with the infinite resource of programmer frustration and endurance is certainly doable. Rust is not on a meteoric rise at the moment.
Lol. I'm used to build times measured in literally days. Anything that compiles faster than 5 minutes is almost too fast. How can I properly get a snack while its compiling if it finishes right away?
You can use `git blame -w` or even better with [git-hyper-blame](https://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/git-hyper-blame.html) you can ignore set of commits (and if step 1 is only one commit, it's easy to do).
See my response to qvrock above. The advantage of using a formatter is that you will never have a misleading level of indentation like ``` while(foo) bar(); baz(); ``` Yes it's bad code, and should be caught at code review, but it's always better to have a tool to help you.
same here, this stops all the useless discussion around formatting in the code review. Now the whole code base is correctly formatted (with the same rules everywhere), and formatting is checked on every pr automatically. We used clang format for the formatting
There are many implementation of this construct, especially after Alexandrescu popularized the concept, and there is Boost.Outcome as well. None of them are planned for inclusion in the C++ standard library, as far as I am aware. The WG paper [here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0323r7.html) still has many open questions with no obvious answers yet.
GCC now fortunately detects misleading indentation like this.
Currently I use PIMPL not for binary compat, but to prevent implementation details (the said include) leaking into my own code. If modules can't help with that... what's the point?
Some tutorials on YouTube, watch some from several channels and you will know then which is the best for you.
So yeah, the construct exists, just not standardized yet (if ever). Just noticed I wrote excepted earlier instead of expected, that was not expected :D
That's because the question is formulated as "Which framework or library that exist in other programing language you wish to exist in C++ ?" so I didn't bother with listing things that I already have and take for granted. If I was using the stack that you are proposing, it would partially solve this problem, but then I would write a similar wish list on a .net forum like: &gt; Hey guys! I'm really enjoying everything, but could you please: &gt; &gt; * Redesign all your data structures. &gt; &gt; * Change this and that in the language so that I can do things with required efficiency. &gt; &gt; * Allow Azure to be hosted on my local server for sub-ms latencies (actually, 1ms would already be a catastrophe). &gt; &gt; * Change about 25 things in Appinsights so that it matches my perf. requirements. &gt; &gt; * etc... Then someone would write "Sounds like you want a C++ app and an extra small process running alongside it to do the boring stuff. Why bother with .net core + Azure + Appinsights?" Difference is: that someone would be right to make his assumption.
The performance problem is very severe. In the worst case suggested by the original article, you'd need to try compiling a file, find that it references a module you haven't compiled yet, and stop and try compiling all other files to build that module (but you can't build *all* other files because they might also reference modules that haven't been built yet). Once you finally build the required module, you can come back to compile this file, but you might get further and discover there's another module it needs that still hasn't been built. In principle, for many files in your codebase you will need to partially build them many times, maybe dependant on the number of other files in your codebase. This might technically be "just" a performance problem, but possibly an exponentially expensive one. You couldn't fix it by just speeding up compilation slightly. And of course C++ is already notoriously slow; that was one of the things modules were meant to *fix*.
Hah! My compile times at work aren't quite that bad, but a full rebuild takes 45 minutes... in a code base that has been optimized to hell and back to build as quickly as possible already! My dream is to get the incremental build times for the module that you're changing down as low as possible. This works really well with dynamic hot loading. If you build your game module as a shared library, and you can get the compile times for the one compilation unit you're changing plus the link time for the module below one second, you can reach a point where you can hit ctrl + b then the game tabs back into focus instantly and your new logic starts running. If you're changing something like the jump speed of a unit, I'm sure you can see how this would be incredibly useful!
damn, thanks, didn't know that!
Similar to a lambda, it would be less cumbersome to declare and manage. It would "feel" like a variable almost, and not a large structure declaration at the beginning of the scope. Altho I havent thought about this for a while, lets see, say you want a class with callback functionality, or the option to change out its methods/functions. You make an array of function pointers and make it possible to register lambda functions with it. Whenever you want to register something new, pass it a auto lambda=[](){}; from wherever you want to do so in the program. Method1 will now be this lambda. Very convenient use of lambdas imo. But say you could have an array of lambda_objects instead. Registering functions would now give each callback a state as well. method1(); will now do more than just run a function, it will now have its own memory/state. Sure, you could do that with inheritance, we already have that, but similar to callbacks, using a lambda is often alot more intuitive and expressive. I think lambdas offer some creativity by being small in scope by nature, even when registered as more permanent callbacks. The same would be true for lambda objects.
that has nothing to do with formatters. also it's a problem i've had maybe three or four times in 20+ years of coding. if you want to pad yourself on the shoulder over your indentations and line breaks, go ahead. i feel like i have other things to do. while you're at it: go refactor your code base from camel case to snake case.
&gt;In what situation did you feel Result&lt;T&amp;,E&amp;&gt; makes it more convenient? To me the appeal is more about safety than convenience (but I did want my implementation to be ergonomic as a 2nd priority) Results of references can allow you to write a safe, fail-able accessors without throwing exceptions (which can be aggressive at interrupting control flow in an undesirable way sometimes) The method signature for vector element look up is `auto std::vector&lt;T&gt;::at(size_t) -&gt; T&amp;`, and what that doesn't say is that if you are out-of-bound then it doesn't return `T&amp;` it *throws*. Of course returning by-reference instead of by-value here is important if you want a mutable accessor or if you'd like to avoid some copies. So, with my Result implementation one could instead have the following: `auto std::vector&lt;T&gt;(size_t) -&gt; fun::Result&lt;T&amp;, E&gt;`. This puts the fail-ability in the type signature, *and* it will force the user to check which they got (it's really easy to forget to add a try-catch block for a potential throw that is not recorded in the public headers). Of course, in the real world, the more appropriate choice here would be to return `fun::Option&lt;T&amp;&gt;`, because there isn't much in the way of meaning full error information to be returned. &gt;I see that you have tests that use the idiom of as_ref().match(...), is that the only use case? No, that is not the only way to get at the inner value. I should probably get some more examples in the tests. The `as_ref().match(...)` idiom is a way to make use of the data without moving or copying. `as_ref()` creates a new Result instance that contains references to the source instances values. Another design choice I made (and a very debatable one) was to make all of the Option/Result operations move the instance they are acting on (similar to Rust). With that choice in mind, `as_ref()` becomes very necessary. &gt; would it not have been easier for .match() to always pass arguments to clauses by reference? This was sort of the way I went on my first pass, and the major stumbling block becomes how to extract instances of move-only types. (e.g. `fun::Result&lt;std::unique_ptr&lt;...&gt;, error_type&gt;` Sometimes it will not be enough for the user to take a reference to the contained types, they may need to get the data out and send it somewhere else. Thanks for the good questions! Hope those were helpful responses.
&gt; Is this because of media? images/video/music/etc ? Static linking? Are you including .o and other files in this calculation? My Chrome is 450 MB. 15GB is the size of the build directory, not the size of the resulting browser. The final installer is only ~78MB (compressed from ~250MB of DLLs and stuff) so almost all of that 15GB doesn't make it to the end users. 8.6GiB 29228 obj 4.5GiB 42 pdb 388MiB 81 dll 313MiB 2 7z 204MiB 5252 ninja 175MiB 1006 lib 160MiB 30 exe 151MiB 1140 pak 111MiB 5238 cc 99MiB 10028 h 74MiB 23 res_ms_rc 74MiB 23 res 60MiB 1084 info 47MiB 2061 js 34MiB 6 dat Judging from this statistics you can see that most of the size comes from the object files and the PDB debug symbols.
yep, a compiler warning is the right solution to this problem imho. same as vexing parse.
I've used PoDoFo ([podofo.sourcefourge.net](https://podofo.sourcefourge.net)) to extract text from PDFs. It doesn't actually do text extraction. You have to do that yourself, but it's not hard to implement. It gives you a stream of PDF commands which you can process to extract text. On the plus side, it handles the conversion of PDF's various internal character encoding schemes to utf-8 and gives you access to detailed glyph size and position information. The documentation is generated by running doxygen on the source.
pat* yourself on the shoulder. Although maybe it's an apt typo.
C++ without classes? :D
&gt; cmv: learn how to be less obsessed about details. i've never seen code where i thought "omg, there is space after the brace, i can't figure out what's going on" This is a bizarre opinion, when it's trivial with modern tooling to unify your formatting, with essentially zero cost (except having to pass '-w' to git blame), and considerable potential upside.
I tried using GCCs experimental implementation, but I didn’t get far before hitting an internal error :/.
I think you can use typical makefiles because I’m able to use cmake to generate makefiles (at least with GCCs experimental implementation, as of a week ago).
:( yeah I know it’s going to take some time. One of my main reasons is I’d rather wait then have to refactor my code when c++20 rolls around. I have other projects to keep me busy in other languages currently.
Sorry, but what is a Hearthstone Simulator? What is it simulating?
We making a computer program that plays Hearthstone such as AlphaGo and AlphaStar. The goal is to let the program play the game on its own and create a deck.
Hearthstone is a turn based card game. Similar to magic the gathering. Made by blizzard.
Hmm...? I don't understand.
I’ve always though having generic captures on blocks is a good idea (and I think the jia language does this). Not sure why it always has to be about compile speed.... that’s not the most important feature of a language I’d argue. Expressibility will keep c++ modern.
&gt;But say you could have an array of lambda\_objects instead. Registering those would now give each callback a state and methods, not just a function. So in essence you want to leak the local type into some unknown scope, but type-erase it, and still have enough information to know that it is an object with certain member functions? I can't fit this into my mental model of C++ at all. &gt;Sure, you can do that with inheritance, and I do this atm, but similar to this kind of callback, using a lambda would be more intuitive and expressive. In smaller cases anyway. I guess I just don't see how your hypothetical lambda syntax is "more intuitive and expressive" than a local class: struct { int user_count=0; //users int min,max; //keep track of youngest, oldest void add_users(int i){user_count+=i;} void minmax(int iage){if(iage&lt;min)min=iage;if(iage&gt;max)max=iage;} } relevant_things; The thing you want is not really a lambda, it's (automatic) type-erasure, potentially across translation unit or even library boundaries. That's far from trivial to reconcile with what C++ aims to be (e.g. type-safe and zero-overhead), I think. It's easier in e.g. Python where literally everything has a dynamic type.
That's good to know :)
Best C++.
[TheChernoProject](https://www.youtube.com/user/TheChernoProject) on Youtube. It has good series on C++, OpenGL and Game Engine. It is especially good for beginners. [LearnCpp](https://www.learncpp.com/) is also a good resource for beginners if you prefer reading.
Yeah I tend to have the same experience even with MSVC version (which models the Modules TS, not the modified one we are getting in C++20) even if it's the most stable implementation so far I think. But the nice thing is that all compiler implementers tends to fix these fast (as long as your report the issues).
1. everyone has different formatter preferences and conventions. in the long run this means i have to sync style files somehow or make it part of the repo. 2. some (!) tooling has no problem with changed white space 3. i'm not a machine and i don't have ocd, i don't need everything tidy-tidy 4. it's one less thing to think about how is this bizarre?
Hi, From my experience working at IncrediBuild and talking with a lot of C++ devs, the compilation time varies and in some cases can take several hours to finish (when building from scratch). In some cases, even incremental build can take a lot of time to finish, since the files being changes has many dependencies. If you want to learn more about what we do, and what and how we accelerate that time, I invite you to visit our [website](https://www.incredibuild.com/?utm_source=Social&amp;utm_medium=reddit&amp;utm_campaign=Homepage)
Or…your build system could be smart enough to do the information gathering before starting the compiler down a "who knows if it will work?" road. That's basically what's going to put a lot of build systems on the outs for modules. The alternative is to have the compiler do it all for you and that has been reported to slower than just having the build tool do some up-front bookkeeping.
AFAIK, msbuild doesn't have a way to express the "please order these other rules based on the output of this rule" feature that is required. I suspect that there will be a way to say it, but that's something the msbuild team is probably not publicizing until it's working for them.
1. A codebase shouldn't permit mutliple styles and conventions, it's added cognitive load. 2. Yes, include a .clang-format file. This takes 20 seconds, you're now done forever. 3. Only an issue for legacy codebases since new codebases won't need a reformatting commit. Most workhorse tooling (git etc) deals with this fine. Which tools can't deal with this? 4. Incosistent formatting increases the cognitive load of working with your project. Saying "it's not that bad" isn't a compelling argument. You could make the same arguement about using, say, CVS as source control. 5. It's one more thing to constantly think about if your codebase is incosistently formatted. It's one less thing to think about if you use tools to enforce a style. Decide a convention, setup clang-format, format your code, never think about it again.
This is the "implicit" model. The problem here is that the compiler is likely duplicating work all across the tree and if your `-D` and `-f` flags don't agree, say hello to ODR violations. You really want your build tool in the middle of this so that there is one-and-only-one `foo.frobnitz` module in a build graph.
Hmm. That is news to me (who wrote support in the Ninja generator for GCC experimental support). What CMake did you use? It is possible with (POSIX) Makefile syntax, but it isn't trivial and I know of no CMake patches to support C++ modules with it (Fortran modules are supported though).
&gt;So in essence you want to leak the local type into some unknown scope, but type-erase it, and still have &gt;enough information to know that it is an object with certain member functions? The scope would change if you moved the object, or? No undefined scope here. And wouldn't you create a specific type for each new lambda object? This type&lt;T&gt;would have its info, i.e. methods and variables in the jump table, just like a normal struct would. I dont know why it would be any different for a lambda-esque object (declared on the spot). &gt;I guess I just don't see how your hypothetical lambda syntax is "more intuitive and expressive" than a local class It would be created where you write it, and passed where you pass it. It would not be like a template declared seperately with its own header file with #includes or whatnot. It would just be a small object that exists in front of you, and that is about as intuitive as it gets as far as I can tell. &gt;The thing you want is not really a lambda, it's (automatic) type-erasure I dont want type erasure, (tbh) I want variable return types from methods without using constexpr (like I do atm) if constexpr (is_same&lt;_console, T&gt;::value)return (_console*)active_modules[console]; //return access to console else if constexpr (is_same&lt;_gui, T&gt;::value)return (_gui*)active_modules[gui]; //return gui but as gui* type and I would like a standard way to get that functionality, without too much clutter. I believe lambda-objects could be a way to achieve that. You can do this with inheritance, but is it really necessary? This comment could have been about variable return types, as much as as it is about potential uses for lamba-objects. Again, I've solved this, but it feels convoluted as it is, using constexpr if to get different type access to my general container.
Why? I'd expect that to check the state of the result. `if(*func_that_returns_result())` would test the inner value (throwing if it is actually an error). Put another way: Does `std::optional&lt;bool&gt;` lose its `bool` cast if it contains a `bool`?
Heartstone meaning this Blizzard's trading card game?
Yes, it is.
May I ask why don't you prefer a book?
It make sense to check the state of the result. My problem with it make it easy to fuck up if you don't know that the function you are calling can fail. It's not hard to avoid, but I tend to prefer explicit over implicit so I prefer disabling `operator bool`. In my case, I had something like this: `if(exists(path))`. `exists` was a failable operation so it returned `Result&lt;bool&gt;`. The condition didn't check that the path actually existed, but that the operation succeeded which isn't what I wanted. By disabling the conversion you get an error and you can just write `if(exists(path).unwrap_or(false))`, which is almost as readable and a lot more explicit.
This is basically what I was thinking, as far as I know CMake already keeps track of files and builds them accordingly if there have been any changes. Does people want to stop using build systems or something? We need to accept that modules is not going to bring build system support in the compiler. Performance should be fine... If anyone else can participate and tell me what we won't be able to optimize that would be great.
That is true. Although I just admit, I have no idea how to report bugs, at least for the gcc branch. Maybe they mean a github issue, or bugzilla. It’s not clear.
To be fair, my example was pretty simple, but instead of calling target_include_directories for headers, I added the .cpp files where modules I wanted were defined to add_executable’s list of .cpp files. ``` add_executable(test.cpp filewithmoduleA.cpp filewithmoduleB.cpp ) ```
Nice collection. I'd add fmt ([https://github.com/fmtlib/fmt](https://github.com/fmtlib/fmt)) to the libraries and maybe group the libraries by topic, not by name.
That's a documentation problem. The other side of the coin is "how do I know it returns a bool in the first place and doing `if()` on it checks the value, not the state". This weird hole for `bool` that doesn't exist for `T*` is very odd to me. There's one project I've worked with which had a "checked_bool" that threw if it was `false` on deconstruction and its `operator bool` hadn't been called. I don't know if there's a way to do that with a result type (usefully). On one hand, the `operator bool` makes it so that you can use it in `if()` statements, but the other is that it's kind of dumb that `if()` takes non-`bool` in the first place :) . But, C++ lacks match statements (for now), so we're stuck with that decision until match allows compilers to meaningfully have a `-Werror=cond-bool-conversion` flag :) .
The main thing is that build tools need to be smarter. Ninja only merged the support in the past month. POSIX make *supports* it, but I suspect that "no one" knows how to write it properly (I'd like to extract the pattern CMake uses for Fortran and document it somewhere, but time and all that). I don't know that performance for real-world projects has been tested all that well (publicly). There have been benchmarks and toy conversions, but until some real-world bigger project gets fully converted over and gets numbers, performance is more, IMO, divination than prophecy at this point. My gut feeling: from-scratch builds will be slower (due to lower available parallelism), but incremental builds can be much faster (due to tree-pruning being more available).
That works by luck :) . The implicit module mapper GCC uses works for this, but as soon as modules are split across directories, this will fail. It will also fail in multi-config generators because the Debug module and Release module end up being written to the same path.
Awesome, that makes a lot of sense to me. Thanks!
&gt; There's one project I've worked with which had a "checked_bool" that threw if it was false on deconstruction and its operator bool hadn't been called. I don't know if there's a way to do that with a result type (usefully). That's one way to do it. You can do the same with `Result`. In C++17 `[[nodiscard]]` achieve almost the same thing at compile time, by erroring out if you don't use the value. &gt; it's kind of dumb that if() takes non-bool in the first place :) . But, C++ lacks match statements Agreed, matches would solve the problem beautifully. In the meantime we have to make due with `explicit operator bool`. And like every other conversion, I prefer to disable it if there can be any doubt. &gt; That's a documentation problem. Yup, but many people don't have the privilege of working on a well (or at all) documented code base.
`[[nodiscard]]` doesn't work because the problem is that it was *used*, but the error condition wasn't *checked*. I don't think there can be a syntactic solution to this without removing the implicit operators C++ has become so accustomed to having around (i.e., *requiring* that `.unwrap()` be called to get the inner value) but then you don't need the attribute because to find code doing shortcuts, you just grep for `unwrap`.
It's inline assembly, you'd probably be better off asking r/osdev for the specifics
i just found it somewhere ... it requires borland cpp compiler.... and it was a part of raytracing program . here is the link https://bisqwit.iki.fi/jutut/kuvat/programming_examples/raytrace.cpp it has a youtube video also...
It's a call to ask the BIOS to set a video mode as the comment says... What more do you need to know? Of course, that's not the way you'd do it on any modern OS, but it worked perfectly fine on MS-DOS.
This code seems to be for the Intel 80287. The 287 was a floating point co-processor for the Intel 80286. I'm afraid I won't be able to help you any further, but I can tell you that that thing is OLD (the 287 was released in 1987).
This is about where I'm at, building with CMake, testing with Catch, trying to use different libraries as often as I can. I would add the following books: * [A Tour of C++ (2nd ed)](https://www.amazon.ca/Tour-C-2nd-Bjarne-Stroustrup/dp/0134997832/ref=sr_1_fkmrnull_1?crid=19Q7BBIUX7256&amp;keywords=a+tour+of+c%2B%2B+2nd+edition&amp;qid=1558013877&amp;s=gateway&amp;sprefix=a+tour+of+%2Caps%2C183&amp;sr=8-1-fkmrnull) \- The C++ Programming Language is exhaustive but unfortunately getting old. The original "Tour" was an excerpt fromTCPL but the second edition has C++17 and 20 additions. Its a nice supplement to the big beast. * [Professional CMake](https://crascit.com/professional-cmake/) \- This is an excellent, modern book on how to use CMake.
You are using the asm directive to inclide that 2 instructions into the code as they are written You are putting the value 0x12 into the register AX (16 bits not the EAX of 32 or the half lower part of EAX so i think it is a 16 bit code) and an interrumpt with the value of 10h to print text So if i has to guess it is only changing one register and forcing an interrupt to print text but nothing will be displayed as after the interrupt nothing happens. I have 0 idea of what 0x12 it is mean for, it is supossed to be an I/O port i should imagine but no further knowledge, i only know a few like 70 for the RTC that only works on Linux but 12 no idea at all and it will matter what hardware is running, under x86 the directions between 0x00-0x1F are for DMA controller so could it be the monitor memory? If you want more you will have to tell what it is the program and where it is used
how to do dis in a modern OS ? any idea ? any resources ?
Probably easiest to use a library like [SDL](https://www.libsdl.org/).
You don't end all your lines with ; in python?
&gt; Newer versions often have important bug fixes and newer features that very often increase productivity and/or workflow. New major versions of core tools should not fix "important bugs". If they were that important, they would be fixed in the *minor* or patch release (or backported). And those are officially supported. As for new features, if you are using the newest features of a toolchain in a production project, you are doing it wrong. &gt; Now that doesn't mean that me or anyone for that matter should have to spend half an hour or an hour compiling that software False dichotomy: you don't spend "half an hour" to compile GDB or GCC, unless you are counting CPU time. &gt; The ubuntu-toolchain-r PPA might be unsupported from an official support perspective but it's very much official and maintained and it's kept very well and tidily Sure, but that is not a rolling release model, which is what I was discussing. Building packages yourself or installing a pre-built version is equivalent for the purpose of the rolling release discussion. The point is that the main/official packages are *not* rolling.
Thanks for the detailed response. I missed your choice for *moving* on a `match()` call, so the point about `as_ref()` makes a lot more sense now. I do feel like if you had `match()` always pass in a reference, you wouldn't have needed anything special with move-only types like `unique_ptr`, and may have worked better in C++ vs. Rust. But that's a matter of preference. As for the example you gave about `std::vector::at`, I agree with you that exception has its pros and cons, and Result types do make things more explicit. I meant to ask you about the comparison between `Result&lt;T&amp;,E&gt;` vs. `Result&lt;T*,E&gt;`. Returning reference makes sense for `std::vector::operator[]` where you really want the syntax `v[i] = 5`. But if you are going to use something more like `.match(v.at(i))`, a pointer gets rid of a lot of special-case handling from your code. I was wondering why you felt so strongly about supporting reference types as opposed to plain pointers. Could you not have chosen to just not support reference types?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; [[nodiscard]] doesn't work because the problem is that it was used, but the error condition wasn't checked. Tracking calls to `operator bool` doesn't guarantee that the result has been checked either, you can just call `operator bool` and not do anything with the result. &gt; the implicit operators C++ has become so accustomed to having around (i.e., requiring that .unwrap() be called to get the inner value) but then you don't need the attribute because to find code doing shortcuts, you just grep for unwrap. I am not sure I follow... The implementation in the OP doesn't implement any implicit operators (beside bool, which I think is fair, and relational operators which are a little weird, but have a sensible behavior). You seem to agree that "box" types shouldn't be implicitly "unboxable". My original point about disabling `operator bool` was that to do this you might also want to avoid `Result&lt;bool&gt;` having the same semantics than `bool`.
&gt; This type&lt;T&gt;would have its info, i.e. methods and variables in the jump table, just like a normal lambda would. I dont know why it would be any different for a lambda-object. Here's the thing; when you pass a lambda somewhere you (usually) erase the local type, either by letting it decay to a function pointer or by storing it in an `std::function` (which does type erasure). The equivalent for classes is RTTI, and even with RTTI you need a definition of the (base) interface visible on the receiving end to be able to use that type in any meaningful sense (with function pointers, the pointer type conveys this information; same thing for `std::function`). &gt; It would be created where you write it, and passed where you pass it. It would not be like a template declared seperately with its own header file with #includes or whatnot. It would just be a small object that exists in front of you, and that is about as intuitive as it gets for me. Did you look at the code I posted? You could but that inside a function right now, no need for separate header files or anything. It'll be a type, with a local variable, visible in that function alone. &gt; I dont want type erasure. To be honest, I want variable return types from methods without using constexpr. So you want a dynamically typed language, in essence? That's not what C++ is.
`import dog` Now what? You now have a dependency on something, and whatever produces module dog must be built before your code. What is it? How do you find it? If it's internal to the project, you have to scan all your code. If it's external, you still have to build the module, and you have to figure out how to do that. Build systems are generally not good at dynamic build DAGs. They are barely good at dynamic dependencies, that is discovering what headers your code depends on.
i do that aswell lol
This looks interesting, though I believe it's a bit late to the party. Nowadays it's trivial to create a server using one of the many libraries available and with a reverse proxy in front to easily be able to scale. And that makes fcgi not that desirable anymore.
That's true, but it is a higher barrier. C++ just doesn't make it easy :) . It doesn't have the same semantics. I expect that `if (some_result)` checks whether it is in a success or error state regardless of the contained type. You asked that it instead query the value for `result&lt;bool&gt;`. This is surprising to me and makes generic code have *very* different semantics depending on `T`. There's no 100% foolproof way to catch "I didn't read the docs" errors. I'd rather optimize for those who do (either before or after) encountering an error related to API usage rather than those who don't think to do so before filing an issue.
If you export a class Foo from a module, and it contains a Bar, then the constructor for Bar has to be available to consumers of Foo and will be provided via the module. The name Bar doesn't have to be, although if you have a function returning a Bar, someone can `decltype` and get at it, or use auto.
Honestly, the biggest thing I'm waiting on is _Generic support in MSVC.
Nice!
I admittedly don't understand modules all that well yet, but are they not basically their own translation units?
Depends how fast you learn and how often you train or do anything relevant. Just few months if you do it really intensively (like multiple hours per day from some course or a book). Or up to multiple years. Maybe like 10 000 lines of code written to learn the language. Everything depends.
A lifetime. But thankfully you can get a job with less.
cant you return auto already? besides, you can do varying return types with constexpr if and it is really useful(!). I dont think falsely limiting yourself is what any language is or should be. that being said tho, lambda objects might not be necessary
And I will when we are ready. Thank you for the advice.
The other c++ podcast: [http://slashslash.info/cppchat/](http://slashslash.info/cppchat/)
Also, the software is free and will be open source upon release.
How long does it take to get to a skill level where you can get a job PS: Thanks for the reply
&gt; cant you return auto already? Yes, but that's compile-time type inference, not dynamic typing. &gt; you can do varying return types with constexpr if Yes, but that's also compile-time and in essence generates a separate function for each different return type you branch to. I was under the impression that you wanted this to happen at run-time ("without constexpr").
Inetersting, whats the best source to learn it?
&gt; I got things working by calling load_from\_file and then immediately creating a unique_ptr with the document pointer as an argument. This is what you meant? Yup, exactly. &gt; Lastly, am I reading this right? One create_page overload uses a smart pointer and then calls another overload that then allocates with new? Hrm, I'm guessing they're using that unique_ptr capture to give exception resilience/memory management laziness for that GooString temporary.
&gt; This is surprising to me and makes generic code have very different semantics depending on T I would argue the opposite. Generic code can still (and should) use `is_ok()`. If you pass a `Result&lt;bool&gt;` to a code that doesn't, **it won't compile.** If you don't do that, you can pass functions that return `Result&lt;bool&gt;` to code that expect it to return bool, and it will compile, into something that probably doesn't do what you want. &gt; std::vector&lt;File&gt; existing; &gt; std::copy_if(files.begin(), files.end(), [](auto&amp;&amp; f) { return file.exists(); }); If `operator bool` is always valid, this will do very different things depending on if `file.exists()` returns a result or not. by disabling conversion to bools if any ambiguity is possible, you get compilations errors instead of unfortunate conversions. And you write `file.exists().unwrap_or(false);`. It also make the code more refactoring proof, as changing the return type of a function that returns bool to return a result will fail compilation instead of doing something different.
because it's used to write real software
*depends on the job*
read the subreddit sidebar
&gt; because it's used to write real software &gt; by gvargh That's literally the entire comment. Why do you bother posing stuff like that?
What’s that?
Welp, lol. Looks like the guy that works on it, Nathan, works on it daily so hopefully we’ll have something functional sooner than later! My guess is it’ll be usable somewhere around October.
You could think of them that way. In that sense, they’re also their own headers too. API and implementation all in .cpp files.
Have you heard of the 10,000 hour rule? When trying a new hobby (like a new programming language) try it for roughly 10,000 hours to see if it is for you. Some hobbies take far less time though. If you've played with something for 10,000 hours and still can't get behind it or like it, then it probably isn't for you.
It can be used for some things. See this repository: https://github.com/mathstuf/cxx-modules-sandbox/
We use C++ and the [Wt Framework](https://www.webtoolkit.eu/wt/) where I work for one very complicated / resource intensive web application and it seems to work well. Most of the other web stuff we work on uses a Python back-end: performance is good enough since there isn't usually too much back end processing and it seems quicker/easier to modify and add features to. We can hire almost any decent junior developer and they can be productive quickly on the Python stack, but finding people who understand web application development (and want to work in that realm) and who are also good C++ programmers is more of a challenge.
It seems like we're agreeing (I was reading it as `if (result_of_bool)` acts as if it were `if (result_of_bool.unwrap_or(false))`), but where I would say that passing `result&lt;bool&gt;` to a function requesting `bool` is…always wrong, you're saying "but people might shoot themselves in the foot". That has almost never stopped C++ from adding stuff before. If `if (result)` is going to work *at all*, it should check the pass/fail state of the result itself. I'd be fine with saying you *always* need to call `.is_ok()`, but people are going to complain that it doesn't work like `optional` and that's a never ending stream of issues and feature requests because the nice rationale you put in the documentation is never going to be enough. All I can say is I'd be very surprised if the STL would not have an implicit `operator bool` for any `std::result` type.
Well, I think it's still quite controversial and in many cases a matter of style and personal preference.
I know this rule, but it doesnt apply for every acitivity, gonna try it though
Big amount of backends is written in C++, i.e. facebook, amazon, google. Where performance matters - C++ is a king.
I think Josuttis often talks about his take on this in some of his talks.
The 10,000 hours rule refers to mastering a skill, not finding out whether a hobby is for you or not. Which makes sense if you consider that 10,000 hours are the equivalent of 417 days. So you would have to spend quite a few years to find out whether a hobby is for you if you were to follow it in that way.
&gt; That has almost never stopped C++ from adding stuff before. The fact that it has been done before doesn't justify that we should let it happen again. &gt; If if (result) is going to work at all, it should check the pass/fail state of the result itself. Agreed. &gt; but people are going to complain This will happen no matter what. For my own code I can tolerate small inconsistencies likes these if they allow me to avoid dump bugs. The STL has other requirements that my own code (and has a doc) so I expect it to make different decisions.
Thanks for your feedback. Both Apache and NGINX has fine support of the FastCGI protocol. Thus, this library is just another option for building WEB backends.
&gt; It has been optimized to highly reduce memory usage for empty components and very sparse ones. Yea I noticed this when I was profiling your solution to the one we use. It's good you've taken steps in resolving this! Are you using a paged sparse array as well now, or did you resolve this using a different method?
I mean they are not that bad. When I make a change on a cpp or an h file the system knows that it has to recompile everything thay depends on those. Wouldn't it be easy for the build system to remember which files modules are defined in and do the same? New file changes, as well as added or removed files, would need to be interpreted first I guess, but that's about it.
I don't think it's the compilers job to care what code looks like (as long as it is syntactically valid). This is what static analysis tooling is for. This allows me to have one static analysis style checker and any number of compilers in my build setup.
Just 21 day http://imgur.com/gallery/Qfjgm8h
Adding more. Please correct me if I'm wrong. - Is there a better way to generate templates strings in c++? I tried searching, but all the results are about c++ templates, not a string used as a template. Maybe I'm not familiar enough -- but generating queries as plain-text from bitshift operators does not look great from a readability or code-smell perspective. - Values are implicitly using params, based on bitshift order operations. This is scary. auto ps = db &lt;&lt; "select a,b from table where something = ? and anotherthing = ?"; // get a prepared parsed and ready statement // first if needed bind values to it ps &lt;&lt; 5; int tmp = 8; ps &lt;&lt; tmp; - I'm not clear on the use of `db`. It appears to conflate: 1] Create a DB connection 2] query creation, 3] calling actual query , 4] query results, 5] table declaration / creation, and 6] prepared statements &amp;nbsp; db &lt;&lt; "select age, name from user where _id=1;" &gt;&gt; tie(age, name); &amp;nbsp; Queries can fire by themselves from destructors ?! // But beware that it will execute on destruction if it wasn't executed! ps &gt;&gt; [&amp;](int a,int b){ ... }; - `#include &lt;sqlite_modern_cpp.h&gt;` naming - He's polluting the entire scope with `std` and `sqlite`. To make it weirder, in files when he imports all of `std` sometimes writes `string`, other times `std::string` - Queries are relying on the user of the module to always write raw SQL statements and ones that don't allow injection. - Why does he use so many lambdas? [Is this scary?](https://github.com/SqliteModernCpp/sqlite_modern_cpp/blob/master/hdr/sqlite_modern_cpp.h#L457) if(int result = sqlite3_create_function_v2( _db.get(), name.c_str(), traits::arity, SQLITE_UTF8, funcPtr, sql_function_binder::scalar&lt;traits::arity, typename std::remove_reference&lt;Function&gt;::type&gt;, nullptr, nullptr, [](void* ptr) { delete static_cast&lt;decltype(funcPtr)&gt;(ptr); } ))
A lot of web applications are just different flavors of waiting on I/O. You don't need C++ to do that capably.
C++ is used for some web apps. A big one off the top of my head would be Plex, which I believe is a C++ core with Python plugins. Web interface is written in React though.
Right, do what doesn't drive you insane or what is required by the project leader. Don't just be a trend follower.
There is absolutely no reason not to use C++ with [CppCMS](http://cppcms.com/wikipp/en/page/main) as a framework and I do in fact assert that doing so is a much safer thing than using any untyped language like php or JS. CppCMS is really well defined, especially considering the age of it.
Bjarne Stroustrup shows some good alternatives using concepts in this talk: https://youtu.be/PU-2ntDuF10 Basically you would not use auto, but the name of the concept that you expect as return value from a function like this: Inputstream auto s = openStream();
I dont use auto when i know the type it is, if i put auto everywhere i will have code less readable and it will make my life harder And i saw Herb talk who did the job, i understood that when an iterator is involved i should use auto to avoid an inncesary cast and also anywhere else i dont has a 100% certainty of what type it is but it is far from always, a defined class is that type and not auto and i only use it ocasionally
Most web applications doesn't need the strengths of C++, but you'd still have do deal with the drawbacks: - (Slow) compilation to a target arch - Relatively high risk of security flaws - Highly complex language that few people know well
That's great on C++, you never know it :)
I fully got rid of instances of empty components and ofc pagination is at sparse array level, with a flexible size if users want to change it. Does your solution use sparse sets as well? Since you profiled EnTT, I'd be really glad if you've any feedback to share with me (either publicly or by mail if you prefer).
the 10,000 hour rule is a total myth anyways, and doesn't apply. &amp;#x200B; for anyone interested - you can read the original study [http://projects.ict.usc.edu/itw/gel/EricssonDeliberatePracticePR93.pdf](http://projects.ict.usc.edu/itw/gel/EricssonDeliberatePracticePR93.pdf)
It is a shame but thankfully it is going to change soon, from some time now there are some C++ based Webserver, Boost i think has one if my mind doesnt fail me And i am planing to use a C++ server, the server cost money so if it can deliver it faster will means less servers or less expensives ones plus the enhanced experience of the user I hope in the next coming years C++ trends that way to
The increased complexity in most cases will not be worth the benefit. The latency of the network is going to be the bottleneck is any case that doesn't involve very substantial computation requirements, and the benefits of high end frameworks in other languages almost always trumps c++ performance increases.
I dont downvote that but men, every software matters, i enjoy Reddit and it is written in Python, i dont like that language but i am grateful that some coders did it to bring us this platform You should show more respect because all of us are on the same boat, some are using C++ and others other option, in fact many of us has a stack of many more and use it when neeeded. C++ it is not the "Master Race" of computing while the rest are "peasants"
&gt; The technical specification has been merged for C++20. As a clarification and little bit of a nitpick, your wording here I think reflects (no pun intended) a bit of confusion, unless *I* am grossly mistaken on the process. The TSs are separate documents from the IS that are issued out of line. So it's not like the refection TS is "merged" with anything, nor does it have any particular relationship with C++20. It's just that the TS was published at a meeting where a bunch of work on C++20 happened.
You say trend follower as if it’s a pejorative, but the thing is, I can be wrong, the project leader can be wrong, public consensus based on thousands and millions of man hours of experimenting is potentially less wrong.
Deployment is a pain in the ass. I use it to serve REST objects where it makes sense, but I have to do all my instrumentation myself. I'd get much faster turnaround using another language, if I wasn't already pushing that data around in C++ anyway.
Well, this feature is called **type inference** which is common and pervasive in functional programming languages such as Haskell; F# and OCaml that has the keyword let for it, let x = 2 \* y + z and so on. Auto is more readable and flexible than explicit writing the types, that can be inferred by the context and also modern IDE shows the type of a variable when one hoovers the cursor over it. &amp;#x200B; For instance, it is easy to see the types for auto variables: auto xs = std::vector&lt;double&gt;{3, 10, 15, 20}; auto n = long{10}; auto nn = 10L; auto fun = [](int k){ return k * 100; }; That is way better than: std::vector&lt;double&gt; xs {3, 10, 15, 20}; long n = 10; long nn = 10; ....
I think it could be streamlined more, and not have such a hacky feel yeah. Consider this pseudo approach: Lambda objects inherit from a base lambda type &lt;L&gt;, but would also hold knowledge of a secondary type, &lt;M&gt;. The type &lt;L*,M&gt; would be a virtual reference to the objects location on the heap and its unique type &lt;M&gt;. Could this provide the basis for varying return types, or branches if you will, almost like a compile-time switch. Perhaps if there was an option for a missing return type, or default: switch-constexpr, if that makes sense. Like I'm not great at what goes on under the hood, but im almost positive this makes sense, and that it would offer some functionality. Functionality that would require a constexpr-switch, in particular a default return say a null-type &lt;0,M&gt; or no functionality, for a run-time option in case the lambda object in question wasnt there. Does that make sense? Because I think it almost does.
isn't this being merged into the standard as we speak?
Copyied from the OG post at r/gamedev &amp;#x200B; To clarify on the group stuff. The main idea of groups in general is that they hold a cache of what entities have the required components. A group that has the components A,B,C and Not D will hold a std::vector&lt;entityID&gt; of the entities that meet the requirements. This is the same as how the old persistent\_view worked. The trickery with the "strong owning" groups, is that, apart from the std::vector&lt;entityID&gt; they directly hold a pointer to the array of components. If your group owns A and B, that means that the group will also hold a pointer to the first A, and to the first B. This essentially ends up looking like this `struct MyGroup{` `std::vector&lt;EntityID&gt; entities_in_this_group;` `A * direct_to_A;` `B* direct_to_B;` `}` The library itself guarantees that all the components on the range direct\_to\_a, direct\_to\_a + entities.size() is going to be correct, allowing you to do a direct for loop. `for(int i = 0; i &lt; entities_in_this_group.size(); i++){` `A&amp; AComp = direct_to_A[i];` `B&amp; BComp = direct_to_B[i];` `EntityID entity = entities_in_this_group[i];` `}` With this, the compiler can likely vectorize this stuff, and the direct access to the component arrays works like a charm in brute-force scenarios. This feature has been battle-tested in my Godot fork, where i have a renderer that is **more than twice faster** than the normal godot. The downside of this feature is that a given component type can only be owned by 1 single view. Doing a group that strong-owns A and B and then another group that strong-owns B and weak-owns C is illegal and wont work. You can sidestep that by creating multiple registries and communicating beetween them. By abusing the multiple-registry approach and then strong-owning almost everything, you now have a **data-oriented table management engine.**
Yes, your "nitpick" is correct. I'm still hopeful that we'll see some `&lt;experimental/reflection&gt;` support now that the TS has been published.
I took a quick look... it looks like it's primarily open source libs/tools. I'm working on a [code generato](https://github.com/Ebenezer-group/onwards)r that is partially closed-source. The link for "Bandit" took me to a gambling website.
&gt;(Slow) compilation to a target arch I continue to see people complain about C++ compilation times but I've never understand that argument. I remember in earlier decades I worked on C++ projects that we'd kick of a compile so we could go get coffee and talk around the water cooler. If the boss asked what we were doing we'd say "just started a full build". On today's systems, with a properly defined project structure and build tool, I don't see those delays. Perhaps a complete rebuild of something like Apache with all the built in tests might take a little time, but how often do you really do that type of build? Why does this continue to be raised as an issue? How many projects are so big/complicated that a compile takes more than a minute or two?
&gt; I fully got rid of instances of empty components and ofc pagination is at sparse array level Both are great, yeah that should bring the memory consumption really down, and depending on the size per page the memory overhead is negligible anyhow. &gt; Does your solution use sparse sets as well? Yea it does, it provides us with the easiest interface to deal with, as well as simple to understand for long term development. (besides that the performance of a well written sparse array is _really_ good in this problem domain). We entertained having duplicate components for some time, but it wasn't necessary in the end, so we didn't have to overengineer this part. &gt; Since you profiled EnTT Ah it was mostly a quick check to see how it fared compared to our use case. In general I found it the best out there for most scenarios we threw at it. It was far better at creating and destroying entities (ours was 2-4x or so slower), but ours had an easier time in creating components (3x), this was over millions of components, so a bit artificial stress test. I never investigated in why this was the case as it was just a quick test (so the test can be wrong) to see if our internal solution was grossly incompetent or not as it was quickly written over the course of a month or two. We were pleased with being in line, and moved on. The allocation of components happens in virtual memory for us as we already have a custom memory allocator, that might be causing discrepancies as we don't allocate dynamically (and it's a requirement for us). We don't initialize either unless explicitly told so by the user providing a constructor, or a lambda that can initialize the component. Ours was written with auto-parallelization out of the box as we needed it, where you had to explicitly say read only (const) or write access to components before using it. So anything deeper than simple creation/destruction was hard to profile for, we mostly threw cpu profilers at it like v-tune, etc.. to see if we had any egregious bottlenecks in our design to iron out.
What did it say? Also Hello, fellow monkey. What does your username mean? Maybe - MMA match between two lady monkeys who are married? - Monkey fights with your Human wife? - Male monkey fighting each other to get a wife (presumably another monkey)?
I've become completely disillusioned with AAA, and now for regular code I prefer to write types, if they are not std::blah&lt;moo&gt;::iterator. No extra effort for me (R++ can convert from auto), and it improves readability for others. For templates I prefer AAA.
\&gt; Why is C++ never used for web applications? Compile time would discourage many people. Another reason why many people prefers dynamically typed scripting languages such as Python, Ruby, PHP or JavaScript with NodeJS is because they can change a single script file and modify the site without recompilation, linking or making the web site going offline. &amp;#x200B; \&gt; Plenty of web browsers, servers, and other web tech is developed in C++, so it obviously is capable. Yes, but the server actually uses a scripting language, Apache can use PHP as scripting language and Nginx uses Lua or PHP. &amp;#x200B; There are plenty of C++ web frameworks, but it would not be funny if Reddit for instance was written using them. They would have to stop this whole site to recompile everything and re-upload to the server. With the site being written primarily in Python, they just need to edit locally or remotely a single script to make changes. I guess that is only worth using C++ web frameworks in high performance and low latency applications or embedded systems such as routers, printers and etc.
But, as I said, there's no right or wrong here. Some people like auto'ing everything and some people like it only for certain things (like lambdas, iterators, etc) and some people don't like using it at all. Soo, I certainly like auto in some cases, but declaring everything with auto is not exactly my favorite.
Every time I read `clang` I hear in my head &gt; Clang, Clang, went the trolley!.
I was looking around and I'm surprised that there doesn't seem to be an implementation on one of the mainline compilers? Is that right?
Keep one thing in mind: While Herb's advice was to always use auto he explicitly pointed out that that doesn't necessarily mean to always hide the type (even though it is accroding to him what you should do by default). E.g. you can use auto like this : \`auto s = std::string("Hello")\` or this \`auto myobject = \`std::make\_unique&lt;MyBigObject&gt;( ... ); \`). &amp;#x200B; Even in that case, auto still gives you some of advantages and no real drawbacks: \- You can't forget to initialize a variable (\`auto myobject;\`) doesn't compile. \- You don't have to write and read redundant types ( \`std::unique\_ptr&lt;MyBigObject&gt; myobject = std::make\_unique&lt;MyBigObject&gt;( ... );\` vs auto myobject = std::make\_unique&lt;MyBigObject&gt;( ... );\` ) \- It leads to a very consistent visual style (auto &lt;name&gt; = &lt;expression&gt; ), where the variable name is always at the start of the line (well - at least very close to it). So as a result, you have the same style, regardless of whether this is a situation, where you want to spell out the type or not . &amp;#x200B; So, using auto sometimes has clear advantages (e.g. easier refactoring, less visual noise if the actual type is not important or when it is completely obvious) and otherwise it is not really worse than the "classic style" using it except, that you have to type 4 more characters. That is the core idea behind Herbs advice. &amp;#x200B; That is not to say that I personally follow or recommend AAA. I just want to point out that Herb's one hour talk - as happens so often - usually gets reduced to a single catchy phrase. As a result, everyone likes to complain about what he/she thinks what the catch phrase means / implies instead of reading up/listening to what advice was actually given.
&gt;They would have to stop this whole site to recompile everything and re-upload to the server. With the site being written primarily in Python, they just need to edit locally or remotely a single script to make changes. LOL. That's not how it works, and if you work in a company where this is the case then leave.
"Mastery" is not what you need to get a job. If you are a student, then (good) employers will understand that you need training, and that you will become better as you go. It is often possible to get a job having zero experience in the language you will be working in -- it is easier for a skilled programmer to pick up a new language than for a bad programmer to become skilled.
Because it's a lot of effort for very little reward. ASIO gets you so close, yet so far unfortunately. I'm not sure if Beast is ready for primetime and it (understandably) has no HTTP/2 support.
Do you also remember, that Herb explicitly said that using auto doesn't prevent you from spelling out the type where it is important (\`auto a = std::string{foo(bar)};\`) apparently everyone seems to forget that part of his talk. Just want to point that out for the sake of the discussion. I'm not an AAA advocate myself.
A minute or two is ages among the other web stacks you could be using. Many stacks now include hot reloading capabilities so it's a matter of half a second between making a change and seeing the effects live. It's an enormous difference for cognitive flow and tight feedback loops.
Great library that made me want to learn c++ again, I really like how simple it is to use and how fast it is. Great job!
I'm having trouble seeing this. How could moving a member variable outside the class be simpler than just taging it as serializable, which is pretty much what the current packages do? How is that going to work with things like a member variable mutex, static variable, const variable, and others. Many state variables have no reason to be stored/recovered outside of an execution context? Dealing with these "exceptional" cases is going to be messier than just tagging the variables to be serialized.
Without digging into the code, say you have a group of two components `A` and `B`, would a `group&lt;A, B&gt;` contain two sparse sets, one each for `A` and `B`?
Oh dear lord, is that actually a thing?