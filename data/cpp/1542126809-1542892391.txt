I already knew what the bottleneck was so the test was a bit biased, but I have updated it now and the text stream doesn't take much time.
I'm not seeing why this applies to trivially copyable and standard layout types? If bit casting works in constexpr, then it seems to me that constexpr placement new of a trivially copyable type into a constexpr dynamic allocation of an array of bytes ought to work as well. From the compiler's perspective, it just sees an array of byte. How one sets its bits is immaterial. Does this make sense? Perhaps you're more thinking of constexpr unions, where the compiler would need to track the current active member within an array of bytes. And I'd agree for non-trivial types. But C types are always trivially copyable, and standard layout. There is no UB in there when you flip bits by byte access, or casting the thing to a float and flipping bits that way instead.
I was not really measuring the rendering performance, but rather the loading time. If you do run the code you would notice that there is no window, so there should be no wrapping yet (I am assuming this). Also the bad case here which takes ~10 sec and is just 4 MB, is a file which has just 1 character per line, like this &gt; 0 &gt; 0 &gt; 0 &gt; 0 &gt; ...
WG14 currently feels that widening multiplication, and narrowing division, are already covered by the language and they have given feedback that that aspect should be dropped from my proposal. Draft 2 will definitely be much smaller than draft 1!
WG14 voted by a large margin to agree with that approach in principle. WG21 have not yet considered that paper. Maybe at Cologne.
the Design flaws of c++ literally start with its name...
They are?! How can I do 64 x 64 -&gt; 128 multiplication and 128 / 64 -&gt; (64, 64) division in standard C? Only function I can think of is `div`, and that only does 64 / 64 division.
&gt; Looks like the libclang API has not kept pace with the compiler. That's not quite it - the compiler has always had to be able to get template value arguments, it's just not exposed via the C API.
COM is just a binary protocol, it can be used from C with manual vtables, from Delphi, VisualBasic etc... but the most "natural" use is from C++ since its binary protocol is based on C++ inheritance.
those libraries are generally quite simple - in particular openframeworks, I've taught it to complete programming beginners. They won't "understand" the language at all but it doesn't matter since the point is just to show 50k pretty circles doing animations on screen or stuff like this. however (I don't know for you /u/lithium :) ) but while it's a very rewarding and fun domain, the pay is generally.... not high.
Perhaps you don't know what libclang is? (That's the C API)
This is fantastic, I was looking for something like this the other day. I came across [https://astexplorer.net/](https://astexplorer.net/) a few days ago and was wondering if something similar existed for C++. It would be great to take this a bit further and allow interactively writing both queries and rewrite rules. You could then run the rewrite rule and see a diff previewing the change on the entire codebase.
Yep, Delphi is older than C++ Builder. Why VB 4 instead of VB 6, which actually supported compilation to proper native code, instead of embedding the P-Code into the executable?
c++/wasm with opengl/webgl should be a good solution for cross platform frontend dev. Qt qml had its chance,but they gave up on c++ support.
Good talk. There's one more aspect that rarely gets mentioned: efficient cache usage reduces burden on the memory bus (a shared resource between cores on a single CPU package), which easily becomes a bottleneck in HPC, for example.
How would you even do destructive moves with variables still being in scope? Sounds like a runtime problem which doesn’t seem like it meshes with c++ core tenets well. 
&gt; OK - use the noconstexpr as a keyword. Use them both if you want. Not an option now, because all libraries would need to be updated (and all users of such libs should immediately switch to the latest versions). It might've been a valid design decision at the time of the language creation (though it's really arguable, see just the technical problems exhibited by even simple constructs made constexpr mentioned in other posts here), but not anymore. &gt;those are two entirely different things. and when you say "versions" are referring to compiler versions, C++ versions, header versions or what? I don't doubt you have a point, but I'm just not getting it here. Between library versions in the current context. Though between compilers/compiler versions is also a concern. The STL would need a complete overhaul to mark everything not currently constexpr as "noconstexpr" (imagine some implementation being implicitly constexpr-able in one compiler and not in the other, it could even be the same compiler, just different version). Also, what about C functions? You can't add additional "markers" for them? Would compiler make exception for functions with C mangling? It's just seems not worth it.
yup, i started on VB6 as a young'un. getting ownerdraw menus to work with the ones created through the IDE was the pinnacle of my achievement. 
Is there sample code of what c++ would look like if you had destructive moves? What does it mean to have a variable of type T in scope but not be a valid T?
Accessing those variables after a move is already UB in many contexts, and something the compiler should just flag (rust does this for example). I’d rather the compiler be given the knowledge that the memory owned by that moved-from variable is free to use. 
It's always nice to discover the work that I didn't even know was being done to improve the usability of the tools I use on a daily basis! Great work!
I did fix the thing where our OpenMP runtime couldn't work on machines with more than 64 hardware threads, I think that'll be in Dev16/VS2019.
`using const;` `using constexpr;` could be nice.
There is one small detail I do not like. expected should not throw on \*result. I think it should be unchecked to be consistent with optional and raw pointers. Maybe a result.get\_value() or similar should be more appropiate for the checked case.
Do you have a question?
So there is this program I am working on for my high school comp. programming class, and am very confused on how I am supposed to get this result. I have limited knowledge of c++ (my teacher goes at a very slow pace) but I do know loops, if statements, etc. The basics really. &amp;#x200B; Basically, I have no idea how I am supposed to nest these for statements, and how to initialize them. Do you guys have any ideas? Any help is welcome. &amp;#x200B; (Please don't spoonfeed me the program. I would really like to learn how it works)
thanks, I'll post this over there.
COM is designed in such a way that C structs with function pointers and C++ vtables as produced by Windows compilers have the same binary layout. So while you can use the C struct with function pointers approach, only masochists with deep hate for C++ actually use approach. Everyone uses C++ or in order to keep some sanity other languages with first class support for COM like Delphi and .NET. Although UWP aka COM 2.0 has improved the productivity regarding using COM from C++. While using COM from C is still as hard as when it was called OLE.
It’s not a cost in this hypothetical case. Exactly the opposite as now the compiler does not need to invoke a destructor and can reuse the memory (registers and or stack storage or otherwise) immediately after being moved from. There is nothing runtime about this optimization. The compiler knows everywhere a move is happening. 
This seems like a recursive problem that could be enhanced by using dynamic programming. Although, based on the paper here, it doesn’t seem like that’s what he’s looking for
Hold control to make it transparent
Probably best if you point out the issue, so that casual readers of the sub aren't left wondering and can learn.
&gt; VCL was written in Delphi IIRC. It was a good advertisement for Delphi, but bad for C++ since no C++ developer wants to touch a class library written in another language. I'm using VCL with C++ and I very rarely need anything customized. In these rare cases I can subclass existing component or create my own component in C++. I wouldn't modify standard libraries even if they would be written in C/C++ as this creates problems in my opinion - same as I wouldn't like to modify RTL or STL sources.
Yeah, we wrote a .NET binding generator for C++ using libclang and - trust me - you don't wanna see that abomination. But it works... The biggest issue I have right now is that, apparently, there's no way to parse custom attributes without compiling your own clang version.
I don't think this is quite correct/what the original commenter had in mind. Often are things supported in the C++ API from libclang, but they are not exposed in the C API. For example, getting the binary operator of the binary operation is possible using C++ API, but not using C API (libclang has both C++ and C API).
&gt; What does it mean to have a variable of type T in scope but not be a valid T? It means you can't name it again for any reason, and to do so is an error.
I see your point. Personally I liked VB 6 more because native code meant it was less dependent on C++. However I was on the C++/Delphi side of the fence back then. :)
Has anyone ever implied that they are magic.
&gt; Std::map is literally never worth using. Then why does it exist?
What about [wxWidgets](https://www.wxwidgets.org/)? I've used wxWidgets for several projects.
&gt; Extracting the value? That involves going through the tokens of the struct and finding the ith token in the angle brackets. Sigh. That also seems totally broken for std::integral_constant&lt;1 + 1&gt;
Short answer: "[because, apparently there's not enough of \[UB\] in the C++ language](https://youtu.be/PH4WBuE1BHI?t=1888)" Long answer: `optional` has (sort of) pointer semantics - "value" or "no value", so it's (sort of) natual for it to behave like a pointer: by accessing it we either get the value or we dereference a non-dereferencable thing and get UB. `expected`, even though it's similar at a first glance, is not an extended `optional`. Quoting the author, it's "either a T or an explanation E on why the T couldn't be produced". Following the very same logic as above, by accessing it we should either get the value or the explanation. I can imagine that some might think it's the same as `std::vector`'s `operator[]` vs `at()`, e.g. speed or safety, but optional is not a container, it's basically just a lazy `throw` \- yes, lazy, but still throw. By making it UB the committee undermines the whole concept of "lazy throw" - the point of exceptions is that you can't afford to ignore them - they must be handled or you will be forced to go back and never forward. With the current approach no one will use `.value()` \- is mouthy and unnatural, so ultimately it will be like "meh, I'll just use \* here. What's the worst that could happen?"
It’s pretty niche work and in pretty high demand, at least where I am, so my salary is competitive with general C++ devs. I’m also very senior at my company (as in a started in the first few months It opened nearly 13 years ago) so that might have something to do with it too. 
The standard was built independently from hardware considerations and in this case the cache is King. Trees and lists (map) are really bad for cache coherency but really good for algorithmic solutions. However I can iterate through a list of thousands of items faster than doing it with a map because CPUs are really good at it.
So when you say “literally never worth using” you actually mean “usually not worth using, at least when running on mainstream contemporary hardware”?
Wow, amazing to see how far that twit reached!! https://twitter.com/diegorlosada/status/1062107265476509696 &amp;#x200B;
As excited as I am for that feature, I'm even more excited by the proposal to remove K&amp;R-style function declarations.
C++20 looks promising. Im especially happy that people finally settled on some terse notation for concepts and can now spend their time on other things. Is there a tldr for why some people apparently don't want coroutines in their current form in the TS (Problems with the general design vs some details of th ed TS?)
Damn, so much already approved for C++20. Ranges, concepts, contracts, consteval, the list goes on(my personal favorites). If we are lucky we can get some more approved in the february meeting... I am excited for the coming years!
One thing I wonder: Are their any alternative Ideas of how networking could work in c++ other than the way ASIO does it? Just wondering, because ASIO was first released in 2005? and by the time std::networking will be widely available it's probably 20 years old. Is everybody still happy with the model? 
Is there any implementation of concepts out there that tracks the c++20 version of them?
IIRC, trivially_relocatable is more narrow but provides even better optimization opportunities than a generall destructive move. A destructive move can still be sm arbitrarily complex operation, whereas moving a trivially relatable type is always just a memcopy. Doesn't mean that some form of destructive move wouldn't be very useful anyway. 
From what I understand there are 3 main reasons people are currently against merging the TS. * Not enough bake time or experience with it. They could likely be swayed by Kona. * They think Core Coroutines are a better design. * They think [resumable expressions](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4453.pdf) are a better design. For those that want an alternate design it's possible that minor modifications to the TS towards what they want would be acceptable for them if it meant getting it in C++20. Others are ok with waiting until C++23 for a different design.
I think one problem is that you often can't really tell, if an object has really been moved. std::move is just a cast and if you pass the result to a (non- online) function taking an r-value, the compiler can't tell if it was actually moved in that function and hence can't tell if it should consider it destructed or not.
I'd also add a .gitignore so that it doesn't push up the bin directory to the repo :-) &amp;#x200B; But it looks awesome, having a read of it now. I'm very intrigued to see where this goes :) &amp;#x200B; p.s. [gitignore.io](https://gitignore.io) will create a gitignore file for you to also stop the VScode stuff being pushed as well.
&gt; The compiler knows everywhere a move is happening No, it doesn't. If you pass around references / pointers to the object, a move may or may not happen in any arbitrary TU the compiler doesn't know about. Or consider arbitrary complex control flow that depends on user input. 
Forgot to mention - by "last update" I meant "excluding patches for important bugfixes". 15.9.0 will be followed by 15.9.1 etc. in response to bug reports. As usual, such patches won't contain new features or ordinary-priority bugfixes.
Just a typical medium blog post tbh
No offfense. I'm just pointing out the obvious. If there is no evidence supporting his statement then he is by definition full of shit. I'm waiting for the evidence to see if that's not the case.
Anybody know any status updates on Deducing This (lead author Gašper Ažman) [http://wg21.link/P0847R0](http://wg21.link/P0847R0) ? &amp;#x200B; This looked like a really promising way to avoid having to write multiple versions of a member function overloading for const, non-const, l-value, and r-value. Every time I have to write const and non-const member functions which are have exactly the same code, I think of this proposal.
Surprisingly, many people assume that lambdas must be more magical than they really are. Sometimes this goes as far as believing that lambdas are `std::function` objects.
&gt;VS 2019 16.0 (which will be binary-compatible with VS 2015 and VS 2017 Oh no. Does that mean that bloody bugs like [this one](https://developercommunity.visualstudio.com/content/problem/61684/stdthis-threadsleep-for-depends-on-system-time.html) will stay unfixed for another N years "because compatibility"? :(
Still can't enable conformance mode due to various windows sdk headers :( I'd love for a #pragma conformance(on/off) push/pop
Yes - that's one of the sacrifices that we have to make for bincompat. We've figured out lots of ways to get around bincompat limitations (e.g. we added `std::filesystem` alongside `std::experimental::filesystem`), but we still can't change representations in major ways, or change the interface of separately compiled functions.
gtfo
Can you provide repros and/or submit bugs on Developer Community? The WinSDK team has been trying to clean up their headers and has made significant progress, but there's still work to do, and user reports help. (e.g. Right now I see that `&lt;Windows.h&gt;` works with `/permissive-` if I include it and do nothing else.)
The Linux kernel also marks accesses but not types. It is a major project, and my personal opinion is that in practice that makes a lot of sense.
I'm one guy. There is no group of devs. I ignored it because I don't use exceptions in embedded systems. I shouldn't have ignored it. I should have told you it wasn't a priority to me. Or as Chris Lattner and others in the LLVM community are fond of saying: "patches welcome".
GCC plugins are *far* more useful: * technically unstable, but porting effort is minimal between any 2 versions, and doable all the way back to 4.5. Even the "stable" C API for LLVM required a lot more porting effort in my experience. * supports a *lot* more information. * no possibility of mismatch between what the compiler sees and what you see
Not sure if it’s been fixed, but last I saw the win10 sdk had a class with an `internal` access modifier.... 
&gt; Every solution to chip design heavily features caches. You're still talking about mainstream contemporary hardware. The CPUs I grew up with had no caches at all.
I'm in robotics these days. I see the utility even in common mid level layer libraries (think "the local boost used in your company"). It's definitely helping a lot as soon as you have rules to apply to a big set of values. Vectors are nice but easily misused in this general case.
Note that that particular paper relies on another standard (HTML5) and basically propose to expose an implementation into C++. So maybe that makes it more reliable. I don't have an opinion on this proposal though.
Note that this is not up to date. Last module version allow inporting "legacy headers" and in that specific case the macros are imported but only if imported directly (you don't get the macros imported by the header importing another header). So while it is correct that there is strong separation with modules, a mechanism have been added (from the ATOM proposal) that allow a strongly compartimented import of macros.
I don't see any occurrences of `"internal\s*:"` in our copy of the WinSDK, except for a single comment `// internal: Tells menubar to ignore Submenu positions`.
This seems bad. Can we have a /permissive- version of the standard library that users who care more about conformance and performance than about bincompat can opt in to? There are already different standard library builds (for example debug, release, static, dynamic, (XP in the past) etc), maybe we have a conformance build which has the latest and greatest standard library, but is not bincompat.
Can you add a duplicated symbol like `real_sleep` that does what we want? While I would usually say that the PHP way of bugfixing is not great, it could be better than leaving it as is.
There are metrics (search Build2's authors report) but they are either not in enough quantity or not verifiable (Microsoft and Google report preliminary tests shows "already worth it" improvements). So apparently, at worse, it will be better.
That's not really a viable solution, sorry.
\&gt; We've added the ["step back" feature in the debugger](https://blogs.msdn.microsoft.com/vcblog/2018/09/26/step-back-going-back-in-c-time/) for C++ in the Visual Studio Enterprise Edition. &amp;#x200B; How does it compare to [rr](https://github.com/mozilla/rr)?
There is no full-fledge alternative that have been proposed ever, but the networking Study Group initially started a bottom-up approach, by working on URI types for example, etc. They realized things were to slow to go through and Asio does most of what we want already so let's focus on that. Asio (recent versions) is probably the only networking library I know that doesn't assume that your code have to work one way or another and it mainly interfaces with OS interfaces, so I guess it's the closest to what someone would want from a standard.
I think it's not so much the model but the interactions with other features. Just as Boost.ASIO has an executor class, so too will std::asio rely on std::executor. From what I understand, std::executor has gone through several iterations gathering requirements from ASIO, async, futures, and possibly others.
/u/cjdb-ns just gave a wonderful answer to this: https://www.reddit.com/r/cpp/comments/9w8q4f/resourcesinspirations_for_using_c20_concepts/e9jgq8v/
&gt;https://www.reddit.com/r/cpp/comments/9w8q4f/resourcesinspirations\_for\_using\_c20\_concepts/e9je6bv/ He didn't mean that. He meant beginner level C++.
Seeing the words 12th grade and C++ in your post I had a hunch you were probably an Indian student and turns out you are. I had the misfortune of going through the same school system and if the CBSE is still using that ancient, horrible excuse for a C++ book as their textbook then most of the advice on the sub will not work for you if your goal is to get good grades in your exams. If the textbook still uses stuff like `#include &lt;iostream.h&gt;, #include &lt;conio.h&gt;` and your school uses Turbo C++ for programming then you are using a very outdated pre-standards version of C++ that became extinct a long time ago. Any good resources on this sub are C++14/17 specific so ironically using the correct C++ practices in your school exams might be deemed as wrong.
Thanks for looking into it! Permissive ftw. 
Yep - Billy has overhauled the atomic/multithreading library, I've (mostly) overhauled iterator debugging, we'll be able to purge a bunch of dead code (e.g. old iostreams floating-point stuff). The compiler will also be able to fix long-standing headaches.
Ooh, this looks nice too: https://gcc-python-plugin.readthedocs.io/en/latest/
I know this is far from your decision but it makes me disappointed that the step back feature, something that is useful to almost every dev, is limited to enterprise only. It seems to go against the ideals the microsoft vs team has been running with the last few years providing these amazing updates. Other than that, I'm very glad to see some wonderful progress within the compiler and the STL, and I'm looking forward till you can break binary compat :D
Along these lines, I'd be interested in seeing `libclang` (and namely the Python bindings) getting a bit more love, if possible. Would be up for trying to be a contributor myself, not yet sure about a maintainer.
well... thats very cool, but writing your own scene graph engine is quite the task. So it kinda boils down to "just implement your own front end!" which comes back to being impractical for most people... unless youre really good and it's your whole job. Cinder is super cool, but there is a lot of work to get from just Cinder to a workable front end.
Yeah, but if you're doing too much, python can be a bottleneck.
If you want to open that can of worms, that's called Sleep or SleepEx from windows.h.
The concept of a cache goes way back to the first microchips. The concept of STD::map goes back to the introduction of the stl. Contemporary is relative.
!removehelp
I haven't had the need to deal with people changing time in my programs so I'm fine with the current options for now at least.
 if (rand) move object; use object;
you mean at best it will be better.
Thank you
&gt; This C interface to Clang will never provide all of the information representation stored in Clang's C++ AST, nor should it: the intent is to maintain an API that is relatively stable from one release to the next, providing only the basic functionality needed to support development tools. https://clang.llvm.org/doxygen/group__CINDEX.html
Yes this is exactly the example i gave in a different comment. My point applies to the scope the move was taken. Or am I still misunderstanding something?
Consider a variable with automatic storage duration. If destructive move has happened, the destructor **must not** be called, whereas it must be called if no destructive move happened. Now the problem is that tere are at least two reasons, why the compiler can't always know if a destructive move had happened or not: 1) The compiler doesn't know about code in different TUs where something might or might not been moved. 2) consider a simple if/else, where a vector is moved on the if branch, but not on the else branch. Now, after both branches converge and the vector variable goes out of scope, should the compiler add a call to the destructor or not? Effectively it had to add a hidden runtine flag, that indicates, which branch has been taken and call the destructor based on its value If you combine these two and consider more complex control flow you effectively have to add a flag for most stack objects to tracks if the object is still alive or not. 
but then what does it mean to refer to variable of a type that doesn't refer to a valid object??
Any plans to support modules in MSBuild? It can build things, but never in the right order. Also it would be nice to see an update to your `std::atomic_flag` according to P1008R1. 
All these changes are awesome - I'm particularly thankful for the step back feature - but could you make the commit message text box in the Changes section of the Team Explorer have a color that fits better with the dark theme when the dark theme is applied? The box is an eyesore 
I guess you should start by defining a list of things that you do not understand. And then come back to /r/cpp_questions with this list or just google it all. If it's the case that you need outdated stuff like /u/TCPisBetterThanUDP mentioned. Maybe you could just reference some good old book on the topic. For example I've heard that C++ Primer 5th edition is a good read but it includes modern stuff from C++11, that means you could just grab an older edition without all that stuff in it (4th or 3rd one) Hope I helped
[Bug filed](https://developercommunity.visualstudio.com/content/problem/382290/give-commit-message-box-a-color-that-better-fits-w.html). Thanks for the quick response!
Technically, it is not a reverse debugger. As far as I understand, this feature is powered by process snapshotting Windows feature and is implemented solely in Visual Studio. Every time a breakpoint is hit, a light-weight process snapshot is created and Visual Studio allows you to switch process state between captured snapshots when you debug. [Microsoft Time-Travel Debugger](https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/time-travel-debugging-overview), presented on CppCon last year, on the other hand is a true reverse debugger, allows rewinding to any executed instruction and provides a ton of other useful features. It is also free (at least for now) and is included in WinDbg.
Crazy I've never seen that.
Just guessing, but in consequence of introducing namespaces there would be name mangling on the binary level?
https://developercommunity.visualstudio.com/content/problem/311131/error-on-compiling-eventh-that-is-in-windows-kits.html It's a known issue I believe and documented on MSDN. I figured they may have fixed it with the new SDK. Sadly, telling a 60+ dev team to manually modify the windows SDK doesnt seem like a great solution. We've just disabled conformance mode for now. We do compile for android/linux/iOS, so that helps prevent code rot. Again, thanks for the updates.
There have been various different suggestions. My preference is for it to be a compiler error if you use an variable after it has been moved from. In order to achieve this, I would place restrictions on where destructive move can be requested, to ensure that at any point in the code it is always well-defined whether you have a live object or not. So for example you can't request a destructive move inside an `if` block unless the block ends in a `return` or `throw`. If you do want a variable which may or may not contain a live object, you use `std::optional`.
That works partially since it is prone to crashing depending on the previous state you are reverting to
I vaguely remember that some inefficiencies in the standard library implementation are due to WinXP compatibility. If that really is the case, could you also drop XP compatibility for v20? I understand that there are projects out there that still want/need to support XP, but it would be great if not everyone else had to pay for that.
Does that also mean no new versions of cmake?
A lambda may be dynamically allocated, if you do e.g. `auto m = new auto([]{f();});`. This can be useful when passing a lambda to a different thread. &gt; The key thing to know, is that only _automatic variables_ can be captured. This is any local variable to your function, including the `this` pointer. These are pushed on and off the stack, and automatically destructed when you leave the current function. Well, `this` is not a variable. Also, a nested lambda may capture a variable captured by an outer lambda, in which case it actually captures the member of the outer lambda.
Is there an ETA on fixing copy elision? eg.: https://godbolt.org/z/tZo-3N https://godbolt.org/z/gxMYUP
One comment regarding Dev community (not sure if this is so something for team has control over): If I remember correctly, I have to log in to even upvote a bug. It would be great if that restriction could be removed. Also, last time I tried to submit a bug (quite some time ago) formatting (of code) was a horrible experience. Generally, the user experience for that website had much room for improvement considering that other websites like github or stackoverflow have been doing a much better job for quite some time.
That would be great - there are quite a few project out there that use static linking and don't care about bincompat at all, but do care about bugs/features.
With destructive move, the trivially\_relocatable trait would still exist: it would simply be defined as whether the destructive move operation is trivial. (Much more natural than the current proposal!)
Oh damn. Curious as to why we still use the outdated version. Did you have trouble grasping the newer concepts once you were out of 12th?
I simply can't wait for some version of Reflection or, better yet, Generative C++, so I can finally have short, generalized serialization code instead of boilerplate and/or macros hell. I guess it comes from working on game logic, but these are the only features of the upcoming standards that really excite me - and they are so, so far away :(
Agreed
Yes, please! Just wondering: do you have a lot of customers demanding ABI compatibility (compared to those that don't)? Are there a lot of third-party closed-source dynamic libs that depend on the C++ one those customers use and their vendors don't provide updated ones linked against the newest ABIs? It would stand to reason most enterprise-level customers aren't likely to move to 2019 (or even 2017) soon; and when they do in a few years, they will most likely have newer versions of their dependencies available. Am I missing something?
I also think that resumable expressions are better for the following reasons: - they look less magic (just function objects) - can compose await snd others - they are inlineable. - seems to be easier to compose since you pass them downwards for the basic use case. I never understood completely why they were left behind. It looks to me like a much easier to understand model. You can control allocation, avoid a bunch of hooks in the code generation, can understand what is going on and on top of that they can be inlined or erased as necessary. Abstractions can be built on top of it as needed (as the paper shows). I find Coroutines TS, though clean, harder to reason about and has too many predefined customization points. I think resumable functions are easier and more future proof, since the basic abstraction is very easy to understand.
Their opinion is that code of the form: int32_t a, b; int64_t c = (int64_t) a * (int64_t) b; ... will be transformed into a single opcode widening multiplication under optimisation. Similarly: int64_t a, b; int32_t d = (int32_t)(a / b), m = (int32_t)(a % b); ... will be transformed into a single opcode divide and remainder. So, seeing as the compiler can and does already do this, it would do the same with any extended precision integers. I'll admit this was news to me, but there are lots of compiler devs on WG14, and if they say this will be so, I have no reason to doubt them. 
&gt; libclang has both C++ and C API From https://clang.llvm.org/docs/Tooling.html#libclang &gt; LibClang is a stable high level C interface to clang What C++ API are you talking about? Is it part of libclang? 
It made me calmer knowing C++ is difficult for everyone, not just me. :) CBSE hadn't standardised CS curriculum when I was in 12th so we had to study from those awful Sumita Arora books. Buy a [good book](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and involve yourself in a project that uses c++. That's the best way to learn c++ and not hate it, IMO.
Many people have proposed that the non-async parts of the Networking TS could be standardised immediately. Those championing that TS have felt that unacceptable, and that waiting until potentially C++ 26 was better than splitting the TS into two. And that is of course their decision. However, I have noticed at least one major STL vendor has gone ahead and implemented the non-async parts of the Networking TS already. I would not be surprised if all the major STLs shortly followed suit. It's low hanging fruit, it delivers lots of value to C++ users long before the 2023 standard, and even if a major STL vendor does not do this, one can always just use ASIO. Unlike say Coroutines or Ranges, a delayed Networking TS is nothing like as impactful on the C++ ecosystem as there is a very high quality substitute available.
- `const`, already very powerful with multiple meanings - `constexpr` - `consteval` I can feel the memes. ___ Anyway, nice to see important changes like `char8_t` and ranges. Are there any plans for pure functions? Stuff to tell the compiler that calls purely depend on the input and have no side effects? ___ Seeing new groups formed - what is the difference between SG19 (machine learning) and SG14 (gamedev and low latency)? Don't they have very similar goals?
Sigh, you're right. Thanks for the failing test!
No, you were right.
I didn't even know that was an option. I'll check it out. Thanks!
Except it doesn't support my development tool, because it doesn't expose the information I need (and that it knows!).
Yeah, I don't know the process. Und honestly, I don't see a problem with providing all of clang's AST.
People depending `std::this_thread::sleep_for` for synchronisation deserve to have their life disrupted. But if you have a different use, than fair enough.
&gt; If you have any template you can visit it's children, they are the non-templated entity and all template parameters. They are fully fledged entities with appropriate kind. I can see that a specialised template struct has an integer literal in there, but there's no way to get its value that I can see other than looking at its tokens. There's no equivalent of `clang_Cursor_getTemplateArgumentValue` for instance. Probably better than the mess I have right now though. Thanks for bringing this up. &gt; What do you mean by this one? I was a bit confused here. I tried to recreate the issue and realised there's nothing much libclang can do for me. I had a struct templated on an int and an enum set to that integer value. `clang_getEnumConstantDeclValue` gave me 0, but there's no real value to return since it depends on how it's instantiated. Again, I'll have to look at the tokens. &gt; Yeah, look at the tokens for actual names. I would, but I can't. `type-parameter-0-0` doesn't show up in the tokens, anywhere, since it's not in the code. It's clang's internal name for the unnamed parameter in the declaration. Unless you mean figure out what token in the class definition means the type parameter, which is what I ended up doing but it's a massive hack and I expect it to fail at some point. 
This actually was brought up in EWGI and made discussing Arthur's proposal somewhat challenging. The issue is that no one knows how to design a destructive move in the current language, there are way too many unresolved questions. Approaching it from relocatibility is I think a better solution ( move destructive is the better solution from a holistic point of view but that ship sailed almost a decade ago) 
The committee is fully aware of that but we have time to come with solutions before 23!
&gt;I can see that a specialised template struct has an integer literal in there, but there's no way to get its value that I can see other than looking at its tokens. There's no equivalent of `clang_Cursor_getTemplateArgumentValue` for instance. Yes, because that would mean evaluating arbitrary constexpr... &gt;Unless you mean figure out what token in the class definition means the type parameter, which is what I ended up doing but it's a massive hack and I expect it to fail at some point. &gt; That's what I meant. And it's what cppast does *a lot*. 
Code formatting for DevCom is something I'm going to try and move forward; I've seen a few reports like this recently.
An advice, to keep in mind when we start using a "new things": don't abuse of it! 
&gt; This can be useful when passing a lambda to a different thread. why wouldn't you just move it ?
Oh, good point.
The download speed is horrendous this time, I guess you are still publishing in your mirrors? (by the way, VS Installer does not tell anything about where the download comes from...)
Aaaaand.. it's gone. Thanks for your feedback! The specific size is settable now and it's default derived from the number of cores you have. Doing so according to load or expected resource use is something else still planned, so there's still a TODO.
KDevelop is getting better than Qt Creator.
Right, I'm sorry- it's the clang, and not libclang that exposes C++ API. https://clang.llvm.org/doxygen/classclang_1_1RecursiveASTVisitor.html for example.
Let's see if this helps; in order in which I find them easiest to answer - File generation and unit test execution are covered. File generation is using another type of compiler on another type of file, which is then later on fed through another compiler - nothing out of scope. Unit test execution is demoed actually in the movie on youtube - it's in fact unavoidable to do a build without running tests. - Working with prepackaged or prebuilt (or cached) binary packages is easy; the tool has a specific location it expects outputs to be and your package manager can place the libraries where it's to be expected. Right now there's no configuration-wise way to indicate you want a prebuilt binary package, but the code does already support it internally and has a few hardcoded packages (like boost-filesystem) that it uses to build itself. - Versioning of libraries, detailed configurations, linking and working which third party libraries - most of this is not the task of your build system; it's the task of your package manager to feed the right external dependencies to your build system. Most systems have never had a good C++ package manager, so it's expected that people want Evoke to support this, but it's a bad idea to merge both. See also CMake. - selecting different libraries per target platform - This is actually a bit of a point. So far the solution I think works best is to make the code compile on all platforms, and the relevant code be output on the relevant platforms. This also allows you to not have dependencies that wouldn't compile, if the code that could use them just doesn't actually use them. I'm not 100% convinced - but then again, no other build system has this covered well so I'm all ears for solutions. I'm currently running it from a "live at head" approach. For this you don't really *need* a package manager. As soon as you have a fixed config, you need some tool to fix that configuration / environment for you. That could be docker, that could be virtualbox, it could be a package manager. Whatever it is, it puts your code and build system in an environment with what it should use, and tells the build system how to use it. From that point on, this whole approach works.
If someone believes lambdas are `std::function` objects, then I don't think they are thinking they are magical. It is a reasonable expectation, after all, which shows the person at least understands what the general topic.
I would most definitely like to do that. But my priority right now is the board exam. I don't even feel like approaching the teacher because her last words to me when me I actually conversed with her were , "I don't even care if you fail".
So among IDEs I’ve only worked in VS Code or eclipse, or just a basic text editor, mostly based on what my professors have used - what does VS have going for it that should make me decide to switch from VS Code?
Interesting, thanks! That’s a pretty interesting design.
It was also on the final slide, but that seems to have dropped off the video.
I'm sure that would be welcome. Feel free to add me to reviews.
I meant: in the current state of not-finished implementations, it's compile-time is already better, so at... a minimum :D speed will be better. Better seems to be over 2X so far. There are privately expressed expectations (from people who have more data than I have) of a far bigger improvement but not immediately. Yeah at "worse" it will introduce new categories of problems. XD
Is it possible that the download servers are overwhelmed? I'm downloading with 40kb/s normally at work I should be around 12Mb/s. I tried following the advice and disabled IPv6 but to no avail.
same here, cannot cancel, cannot run MSVS. Have to work logged into one of the server remotely because of this :(
Part of the idea is that we hope for better solutions for lambdas, coroutines, executors and exceptions! It's unclear what this might looks like yet. But hopefully, we can get a cohesive whole rather than a set of libraries. Of course, this is challenging as the language, libraries and our understabding of how to design libraries evolve at the same time but not always in lock steps. The design space is widely different than what it used to be 10 years ago. Also, asio being widely available and quite great as a standalone library, there is no pressure to rush thing as far as network go. 
you forgot `constinit`
See [This blog post of mine](https://cor3ntin.github.io/posts/translation_units/). For your idea to work, we would need to forgo forward function declarations and the idea of ABI, and as louis said, there is the contract-with-users part
move to what?
Yes, that's what I'm talking about in the second halve of my comment: While it is necessary, it could TRIVIALLY be done in a way that wouldn't cause ANY of the usual issues. Currently `::` cannot be part of a function-name, thus adding it as a namespace-seperator would not cause any issues in the binary function-name.
void f1(auto a, auto&amp; b, const auto&amp; c, auto&amp;&amp; d) {...}; // unconstrained &amp;#x200B; Haha, we GCC fans knew ISO have little to no choice on this.
&gt;It looks to me like a much easier to understand model. I wanted to say this, but gosh you completed your speech! Paper intro is dope
&gt;I can feel the memes. \#MeToo
Is clang still in core?
... the other thread ? auto x = [whatever] { }; std::thread t{[fun=std::move(x)] { fun(); }}; 
hmm, I disagree - Qt Creator had clazy integration for some months for instance.
&gt; The basic idea is simple: since the definition of an inline function is available along with its declaration, it's not necessary to import or export it from a DLL — the inline definition can be used directly. The effect of the flag is to not apply class-level dllexport/dllimport declspecs to inline member functions. In the two examples above, it means S::foo() would not be dllexported or dllimported, even though the S class is declared as such. what happens if you need the function inlined most of the time, but also sometime need to take its address ? Qt does this with signals, and the signal must have a single address across the whole binary, else runtime connections may not work. With this, every dll which uses the function may see a different address for it.
So this is a hack to work around the fact that you put dllimport/export on inline functions that you didn't mean to put it on? It would make more sense to me to make dllimport/export on an inline function into a warning, and then fix up the code to not declare the functions as import/export in the first place!
A fair bit of hardware also implements saturation arithmetic. It's not very common on desktop machines (MMX, which is still present actually does for a limited set of operations), but a lot of DSPs do it, especially ones related to image processing.
Are you hiring entry level?
Sorry, but I don't see the connection you're making between the two and why this is contradictory. Can you please explain?
I know very well that C11 supports generic, I work on a C and C++ compiler. _Generic is compile time and works well in macros, this is not function overloading unless you're willing to go to macroville.
Same problem doesn't happen with Qt normally because the signals generated by moc are never inline.
Yes this also works. In this case `std::thread` will do the dynamic allocation for you. 
It's easy to get very slow compile times for even trivial projects since every file tends to end up effectively including the whole of wxWidgets headers.
OK, the original design of `expected` (by Alexandrescu) had the property of "don't ignore me", and (IIRC) it threw on operator*, and also on destruction if it hadn't been read. So yes, we've lost that "lazy throw". On the other hand, everything else has operator* as being non-checking (ie faster), and something more verbose as the checking version. Maybe that was the wrong choice from the beginning - maybe the verbose one should have been UB and the terse syntax throwing. But we lack a time machine. So an extra argument can be said for expected's operator*, but I'm not sure we should go against the common pattern.
I watched inside the code generated by Clang and GCC, when a resize is done on a vector of unique\_ptr, the compiler generate exactly the same code as if a memcpy where done to move copy object from the old memory location to the new one (the destructor call to unique\_ptr is elided). What are cases where \[\[trivially\_relocatable\]\] may be necessary to get optimal code, considering what modern optimizers are able to do?
You should ask this over at [r/cpp\_questions](https://www.reddit.com/r/cpp_questions)
Sorry ... new here.
Ah, I missed that they were applying the import/export to the entire struct. So this switch essentially opts in to how the ABI should have always been? Does it still allow explicitly importing/exporting an inline function for cases like other commenters have mentioned?
So, C++ on Linux in 2018. What's your favourite? * vscode * KDevelop * Qt Creator * something else
Check this out and tell me whether you think that's UB (I'm pretty sure it is, but your comment seems to imply it isn't and I could be wrong): https://wandbox.org/permlink/P5oAKu5ZR205aZ0H If this is indeed UB, then this means the constexpr evaluator has to track each byte of memory like I said. Otherwise, it *may* be possible to do it. 
Sublime 
I use Qt creator because it’s really easy to deploy to remote and debug. VS code for small projects and proof of concepts. PlatformIO for VS code is really nice for embedded. 
Do you find vscode cumbersome for large projects?
\&gt; Only 1 integer is required as the state maybe, but I'm not smart enough to write it with only using one variable and if you do it will be pretty hard to maintain. Small changes will result in drastic changes in the state machine. With coroutines you don't have to meticulous "craft" a state machine by hand and you don't have any disadvantages. \&gt; you are not showing all the extra boilerplate you need to support calling your coroutine there is no boilerplate in invoking a coroutine. You call a function - eg. fib - and you receive a stl compliant container with begin and end. This can be conveniently used in a for-range-loop. \`\`\` for(auto x: fib()) {...} \`\`\` \&gt; entire complex library like Conduit. There is barely any complexity: \`\`\` auto filter = \[\](auto xs, auto f) -&gt; seq&lt;decltype(first(xs))&gt; { for (auto x : xs) { if (f(x)) co\_yield x; } }; \`\`\` [https://github.com/LoopPerfect/conduit/blob/master/include/conduit/filter.hpp](https://github.com/LoopPerfect/conduit/blob/master/include/conduit/flatmap.hpp) conduit seems to mostly provide functional vocabulary for composition. \&gt; Irrelevant. \[...\] What is relevant is what abstractions a library offers and what it makes easy or hard to do. Your approach makes several things difficult to do and you just defending it by providing workarounds like: \- building the state machines yourself \- optimizing statemachines \- creating adapters for compatibility &amp;#x200B;
Not yet. You'll just have to wait for the post-meeting mailing.
I actually haven’t yet tried VS code for my work projects because QT creator has more features and has good community. In QT creator I can browse through classes and modules in the navigation pane. I can create devices and kits much more easily than VS code. QT creator SDK is automatically created when you create a Yocto project. You can do all that in VS code too. But I don’t think it is that straight forward. VS code’s config files are still undergoing changes and lot of tips online are outdated already. 
Same here. I've given up, will try to download tomorrow again. The real bad thing is that VS doesn't work until completely upgraded...
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9x23i4/books_for_learning_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's pretty cool! I can see that being useful for development, but I'm not sure many apps will need to run both as a local app _and_ in a browser...
but this is truly compile once and deploy everywhere (as far as there is a decent browser).
VSCode team and VS team both use the same intellisense engine, EDG is cross platform, remember? That's how they do it. https://www.edg.com/c looks like that lists literally everything they have...
Ah. I thought the code people were moving to clang, looks like a learned something today
Web development is in an awful identity crisis.
Atom.
They use clang-format, but it's pretty obvious that they use the EDG frontend because... https://github.com/Microsoft/vscode-cpptools/issues/1987 Clang doesn't do that.
:( I want target_link_options asap
My benchmarking found `to_chars` to be 70-90% faster than `dtoa_milo`, and I additionally found that `dtoa_milo` performs mathematically incorrect rounding. See [my comment](https://www.reddit.com/r/cpp/comments/9fiko6/fmt_version_52_released_with_up_to_5x_speedups/). (I didn’t keep my benchmark sources but could recreate it.) Can you share your benchmark showing `to_chars` being slower? That is very surprising given what I’ve seen.
Thanks! Hopefully it should be an easy fix.
there are other ways than moc to get signals
In general, customers absolutely love ABI compat. It is enormously popular and people hate rebuilding the world. The strength of their preferences surprised me.
\&gt; no binaryen method succeeded. What's the requirements?
I believe we will be able to do so; I am not sure about Vista compat (dropping both would be ideal). No promises yet.
That seems like a bug given how CDNs are a thing. I recommend reporting it as an installer bug through Developer Community. Including the SpeedTest results for your work connection could be a useful baseline.
That adjusts the instruction pointer; it does not rewind the program’s state.
I am not sure if the CMake integration team is an exception; /u/TartanLlama, do you know?
The lack of C++ jobs I think is the culprit of perpetuating this idea. 
It's probably mostly to avoid being constrained in changing the AST. With current policies once something hits a C API it's difficult-to-impossible to change, so we want to be careful about what gets in.
a browser released in last 6 months?
But what's wrong with adding a way to get a non-type parameter? It's a part of C++, so it will ways be there.
How is this an example of getting better if it's just matching what Qt Creator has had for a while now?
Vim still. I’m not a vim fan boy or anything, I’m just better with it than anything else. The customizability just gives it a huge advantage. 
I'm sure they would add a way to get that (from other posts here, it sounds like it already exists for function templates). But it'd be reviewed so that it doesn't just expose the guts of the AST in a way that would be annoying in the future.
I've been using vscode since I've used Visual Studio in the past. I also like Atom a lot too though
Ah. Yeah I can't afford to do that. 
[std::includes](https://en.cppreference.com/w/cpp/algorithm/includes)
You are welcome writing a paper. It won’t go to C++20 though. LEWG and LWG is highly overloaded and the cut off for new papers for C++20 was San Diego last week. You also need to factor in that those two functions have been added without having to go through LEWGI. A new one would have to. 
care to give a code example?
It's a different approach from rr. rr takes snapshots at intervals of time, traces non-determinism (signals, I/O, syscalls), and replays the non-deterministic events along with the deterministic behaviour from the snapshots. IntelliTrace (step-back) takes lightweight snapshots of the process at set points (breakpoints, step operation completion) and allows you to step back to older snapshots. &amp;#x200B; The two approaches have advantages and disadvantages. rr will give you more freedom in where you can navigate in your execution, but it emulates a single-core machine and can incur a large overhead in execution. IntelliTrace is more limiting, but the snapshots have a much lower overhead, and are more suitable for multi-threaded applications. &amp;#x200B;
&gt;and also on destruction if it hadn't been read It didn't - the original motivation was "if a tree falls in a forest and no one is around to hear it, does it make a sound?". IIRC it threw on destruction in some alternative implementations (LLVM?) &gt;everything else has operator\* as being non-checking (ie faster), and something more verbose as the checking version Yep, that's exactly what I'm talking about - it's amazingly similar to this checking/non-checking, terse/verbose, fast/not-so-fast approach but it's true meaning is completely different - "I'm just another way to return an exception, I can fail, so don't ignore me". Maybe it was a design mistake to introduce operator\* here in the first place and induce this false similarity. Anyway, thanks for the answer. &amp;#x200B;
While it's too late for C++20 I think it's quite beginner unfriendly that there is no contains member function for stl containers... I also wish there was a string replace member function...
&gt; when a resize is done on a vector of unique_ptr, the compiler generate exactly the same code as if a memcpy where done Hmm, can you post a link to the codegen you observed? This is what I see when I try resizing a vector of unique_ptr: https://p1144.godbolt.org/z/cJRk8f With P1144 (left-hand pane): 88 lines, with a call to memcpy on line 34. With clang trunk (right-hand pane): 164 lines, no memcpy. 
The standardization process is quite open. If you feel strongly about this you should write a paper and find someone to present it. That someone may be you of course. 
I had slightly sloppy wording before, but to clarify with code, the following program ought to work in constexpr https://godbolt.org/z/eOpePD. You can replace the memcpy with P0476 `*b = bit_cast&lt;Bar&gt;(*a);` if you want, it means the same thing. Anyway, if you can support that, it's a small step to also supporting `malloc` and `free` where somebody does a C cast to an object. And that opens the door to us specifying a new safe C dialect based on what's valid in C++ constexpr. And that would be huge.
does this also include std::thread? Currently my threadpool has to assign threads to a single but all available cores by hand using windows calls. (120 core machine)
One could also approach this from the other end: Create an algorithm-function: is_subsequence() `std::is_subsequence_of(needle.begin(), needle.end(), haystack.begin(), haystack.end())` or `needle.is_subsequence_of(haystack)`
C++ needs a new string class to support UTF-8, anyway. And for that matter new text i/o. And, oh yes, support for UTF-8 command line arguments: we don't have that, there's no way to pass an arbitrary filename in Windows. For example, consider a simple thing such as presenting a table in a console, using `std::cout`. Let's say the person doing this decides to use `setw` to create nice columns. However, current implementations do not detect that the basic execution character set is UTF-8, and the standard doesn't require that, so `setw` gets it wrong for non-ASCII characters: it counts bytes, not characters. Handling UTF-8 characters is non-trivial. For example, consider replacing one UTF-8 character with another. For ASCII one can just assign to a an individual `char` in the string, but for UTF-8 it's a substring replacement, and potentially changing byte indices further on in the string. And e.g., what should be the result of indexing when that result should logically be an UTF-8 character? A `string_view` of the bytes? Then it's dependent on the string's continued existence. In contrast, `contains` is trivial to do for anyone. 
There's actually a bug in GCC 8 right now where the Skylake tuning tables are incorrect. Clear Linux is using `-march=haswell` instead until it gets patched.
Of course there is a replace. [https://en.cppreference.com/w/cpp/string/basic\_string/replace](https://en.cppreference.com/w/cpp/string/basic_string/replace) All of these are at least a little tricky because people still think of "string" as containing text, and these functions are all encoding-unaware. &amp;#x200B;
&gt; so somebody must fix how windows create threads ;). Basically this. The Windows folks apparently think that exposing applications that aren't explicitly opting in to thread groups is likely to create breakage, and we can't see any reason the answer for std::thread should be any different.
Hi /r/cpp, this flashcards project came out of me wanted to learn more programming. We put together this collection of flashcards for C and C++ developers. I hope you find it helpful! Here's the source code if you are curious: https://github.com/nlaz/flashcards-for-developers
VS Code + cquery
A probable better choice would be to std::any\_of() like this - std::string str{"cpp is great"}; const auto c = 'p'; auto res = std::any_of(str.begin(),str.end(), [&amp;](const char &amp;e){return e==c;}); This one works for finding only char occurrences. Using `std::string, std::regex` could be done like Java's contains() implementation 
I asked recently, and libc++ support for Windows is still highly experimental; you need MSVC's STL (and UCRT).
I started learning Vim a few months back and haven't been able to switch since. For me, it's combination of: (1) huge C codebase, (2) native support for tags + cscope, and (3) writing code + building on a remote machine.
Perhaps surprisingly, all of the new features in C++14/17/20 aren't really causing bincompat headaches (now that Casey and Billy have figured out how to add separately compiled functions like for Special Math and Filesystem). It's all of the existing C++03/11 code that we want to overhaul. I think there's a case or two where the new features have interacted with bincompat but it's uncommon. That said, there are definitely drawbacks to supporting bincompat for so long, and we are trying to figure out the best path forward for everyone.
&gt; It would be great if that restriction could be removed. That would be more convenient, but it would also be easily gamed, significantly reducing the value of the upvote signal to us. (I observe that GitHub also requires sign-in to mark comments with reactions.) While I don't work on DevCom, I see a clear rationale for requiring signin.
Well, as soon as you are using a non-open source library(or at least one where building it yourself is annoying) you have to start hunting for a binary version that is compatible to your project settings and you are less likely to find one, if compatibility gets broken over and over again. Also, you don't hande to redistribute all dependencies with a new version of your app, so I'm not that surprised. 
I've asked the compiler front-end team to comment, thanks for providing repros.
I should have been more precise. What I mean is that you replace all occurances of string A with string B inside of string C. Basically similar to this (which I copied from SO). std::string ReplaceAll(std::string str, const std::string&amp; from, const std::string&amp; to) { size_t start_pos = 0; while((start_pos = str.find(from, start_pos)) != std::string::npos) { str.replace(start_pos, from.length(), to); start_pos += to.length(); // Handles case where 'to' is a substring of 'from' } return str; } 
I don't think that's really necessary. IMO, it's not that complicated to use string.find(substring) != npos. &gt; But when you read 'find' in code it's not directly clear what the purpose is. Are we looking for the actual position? Or checking if the string contains a substring? Or checking if the string doesn't contain a substring? It depends on your code, and if it's not clear, then add a comment to your code to say what your purpose is of using string.find(). &amp;#x200B; In your code, you could always derive your own class from std::string and add a 'contains' member function to your class. It would still be compatible with std::string (since it would derive from std::string) and it would have the function you want.
Kdevelop for the guts, QtCreator for QML parts, VSCode for the Rust I inevitably pine for and want to move all the janky stuff into.
&gt; Also, you don't hande to redistribute all dependencies with a new version of your app This is (perhaps surprisingly) inaccurate; we've tried to [document this](https://docs.microsoft.com/en-us/cpp/porting/binary-compat-2015-2017?view=vs-2017) but it's easy to miss with the vast volume of documentation. Although the 2015 and 2017 (and 2019) release series are binary-compatible, there are still restrictions that need to be followed. One is mentioned in the docs (the 19.0 vs. 19.12 example). According to my understanding, only the toolset used to perform the final link needs to be the newest of the versions involved - it should be okay for an application to be compiled with 19.00 and link against libraries compiled with 19.14 and 19.12, as long as the 19.14 (or newer) toolset is used to perform the final link. Also, when redistributing the CRT/STL/etc., we support old applications using newer VCRedists (this is what binary compatibility means - installing the VS 2017 15.9 VCRedist overwrites VS 2015 RTM's and the in-place upgrade doesn't break anything), *but* a new application cannot use an older VCRedist in a supported manner (it will "work" sometimes but not always). So if you released an app with the VS 2017 15.0 VCRedist, then you recompile with 15.9 and reship, you also need to ship the 15.9 VCRedist.
Concretely these are the objections: \- TS doesn't expose a first class object to the compiler, so there remain cases where an extra allocation is required during type erasure. There's claimed to be ways to eliminate the issue, but until you actually eliminate it, people feel uneasy. &amp;#x200B; \- TS is async-centric (it's baked into the keyword co\_await). People who imagine broader use prefer an "unwrap" operator \`\[&lt;-\]\`. &amp;#x200B; \- TS captures variables, but doesn't offer a syntax for explaining to a programmer what/how. Core Routines introduces a lambda-style capture interface (that also has its own problems). &amp;#x200B; \- TS doesn't have declaration level identifier to tell you it's a coroutine -- you have to look inside and spot a \`co\_\` keyword. &amp;#x200B; \- TS exposes a number of "extension points" in terms of methods that must be implemented in your types for them to be used as TS coroutines. They lack some simple or uniform pattern and people suggest this smells of bad design, instead of just practical implementation experience. &amp;#x200B; Core routines address all of these issues, but since they're a late addition, it's not clear that after Core Routines had the same implementation experience they wouldn't grow to end up looking much like the TS does. And those are the objections of people who have actually been \*reading\* the papers. I know from talking to voting members who have strong opinions but haven't been following along that the mere existence of a rival proposal means we're not ready to standardize. I've heard from compiler implementers that the TS is hard to implement well -- but again there's no guarantee another proposal wouldn't end up in the same place given the same amount of end user experience. The problem is getting people to us TS is a chicken-egg problem: people don't want to invest either compiler development or end user development in a dead end, so they take their cue from the committee. The only way to break the log jam is if Facebooks proposal to merge the two competing proposals actually gains traction, and that's very unlikely before C++20.
Error on IOS browsing trough the redit app
Honestly Clion beats them all imo. Not the fanciest, not the fastest but it definitely has the best cmake integration. I can build console programs, GUI apps, OS kernels and even Wii homebrew without ever needing to leave my IDE. And thanks to cmake everyone can build my project as well.
I think it's worth noting that the post states that gcc and clang are compiled by the author. What in my opinion would be more interesting as an end-user is how the "out of the box" packages perform, for example from the ubuntu-toolchain-r repo and the LLVM apt repo. As a user of a compiler I'm not really interested in compiling my compiler. I'm just doing `apt get install g++` or `pacman -Ss g++`, and I want to know what the speed of these compilers are! :-)
Hm, in terms of perf gcc/clang has been trading blows for a while. Clang is much, much more aggresively doing unrolling (wonder whether this costs users on icache misses), gcc still seems to be doing some things more smartly. Both are equally horribly slow to compile (clang used to be much faster, nowadays it's often slower than GCC). I'm still using clang for dev, gcc for release, mostly for legacy reasons (also gcc has much better hardening options than clang).
&gt; As a user of a compiler I'm not really interested in compiling my compiler. Gentoo is a great distribution though.
This is called out in the "compatibility" section of the link: &gt; /Zc:dllexportInlines- breaks the C++ language guarantee that (even an inline) function has a unique address within the program. When using these flags, an inline function will have a different address when used inside the library and outside.
I see no dynamic allocation in this code example, except for the std::thread internals.
Neovim and CLion for debugging.
Why should someone use this library instead of competing ones? 
Not when you're debugging multiple multi-threaded applications in the same time. Look at the parallel stacks graph as an example of tool you don't get in VSCode (but maybe in the future...)
\^ :heart: :toque:
`find == 0` is not a replacement for `starts_with`/`ends_with`. For starters, they have different complexities.
i'm not sure if omitting std:: is such a good thing in c++, especially if we talk about beginners. Most of it was more like weird c style syntax to make up a question nothing too c++ related. I kinda was expecting Questions about Undefined Behavior since this is one of its greatest pitfalls for beginner. Some Questions were straight up wrong like for example: What is the use of void main() in C++? https://en.cppreference.com/w/cpp/language/main_function I'm not 100% sure if some compiler would allow it but thats another level. And not the only one (so you don't think i just judge by 1 example): How do you return the function pointer? (Proposed answer is typedef the function pointer) std:function would be more suited imo since it would force you to be clearer about your intents. (There is a reason cdecl exists :) ) I'd say its a good idea, but in terms of c++ you have to flesh it more out. Like make it either more beginner friendly and explain a bit more the answer or go deeper into C++ teritory and have Questions about undefined behavior or algorithms or templates. Maybe i was just unlucky with cards. 
I had to figure this out when working on my MIPS emulator. Took a while to figure out how to properly load and execute the binaries.
I compiled from stage1 on a 300 MHz Celeron back in ~2002. KDE took 3 days. My college dorm roommates called that PC "The Reactor" because its fans were spinning full speed for weeks without pause. I stand by what I said.
Sounds great for Embedded platforms. No DMA, no exceptions.
Another question about `consteval`, would be the return value of this function always the same or not? ``` consteval auto f() { return [] {}; } ```
Interesting, I didn't know that std::string was not designed to be inherited from. I suppose alternately, you could create a stand-alone function called 'stringContains' or similar that takes 2 strings and returns whether the first string contains the 2nd string. You could potentially add any number of functions to a class to make various things more readable. And where do you draw the line in adding such functions?
VIM with customized vimrc for C++ with CMake.
That's *NOT* intellisense, that's debugging tools, 100% separate.
&gt; C Fundamentals &gt; What is a module? I don't know what C module is, are they thinking of translation units? &gt; Modules are a mechanism to package libraries and encapsulate their implementations. ok, too bad C doesn't have any notion of a "module" in the language.
Definitely don't omit `std::` if you are teaching C++ to beginners. `void main()` is terribly wrong. Agreed
There's a bug in the anti-aliasing of the miter-capped line-joins, you can see "crawling at one point of the animation). ( Chrome, Windows 10 ).
Personally I used [nana](https://github.com/cnjinhao/nana) for some projects and was quite happy with it, maybe it could be sth. for you too ? I liked that it feels/is modern to code and by far easier on your build process than QT 
Personally, I find it jarring to use non-native looking apps.
q.q Thanks for checking for me, I'm on mobile
I don't think so. But imho if you have to take the address just turn it into a non-inline function.
I like CLion, but QtCreator is my second favorite.
I like that MVSC is moving more and more towards standard compliance. Thanks! Is UTF8 support getting better? I recently run in a lot of issues with VS generating UTF16 files (resource.h for MFC projects) and simply refusing to work with UTF8 without BOM. This doesn't play well with Git and some other tools like clang-tidy
&gt;Both are equally horribly slow to compile (clang used to be much faster, nowadays it's often slower than GCC). Agree that Clang is often slower. &amp;#x200B; Clang usually produces executables that are over 30% larger than GCC on [my code.](https://github.com/Ebenezer-group/onwards) I haven't tested with Clang 8 though. &amp;#x200B;
You get marginal performance gains by optimizing for your specific processor. This is a bigger deal on x86 than x64 because x64 is often compiled with support for stupidly old processors, whereas x64 has at least all the features of the first x64 processor.
I use clang for dev, mostly because vim plug-ins work better with clang based compile_commands.json 
&gt; What is the block scope of a variable in C++? &gt; &gt; A variable that is accessible only within the block it is declared in is called a block scope variable. The model answer mismatch the question. Besides, I don't think "block scope variable" is a widely used term. &gt; What are the different types of Loops? &gt; &gt; `for`, `while`, `do-while`, and nested loops. Nested loop is not a kind of loop. It is simply the language rule does not change inside and outside a control structure. Besides, the `for` keyword can signify two kinds of loops. &gt; What is the purpose of the `delete` modifier? &gt; &gt; The `delete` modifier is used to deallocate memory for a class object. The question is wrong. `delete` is not a modifier. The answer is more wrong. The delete expression is used to invoke the destructor and then the deallocation function. And it applies to all dynamic objects, not just objects of class types. &gt; How do you return the function pointer? &gt; &gt; By using typedef during its declaration. The question and model answer mismatch.
The committee adds what its members need, not what the poor people want. This is not entirely bad, but this is also why it took 40 years to add freaking std::filesystem to the standard. And let's not forget about asio... 
/u/TartanLlama should be able to find an IDE dev/PM to comment about files being generated as UTF-16. As for the toolset, the compiler supports [/utf-8](https://docs.microsoft.com/en-us/cpp/build/reference/utf-8-set-source-and-executable-character-sets-to-utf-8?view=vs-2017) which will accept UTF-8 without BOM.
Is there an official place for feature request's? I assume it would be a long shot to actually get anything implemented but figure why not ask.
How are you doing that? Do you have an old copy of c++ builder or delphi? The VCL was and is the best, most comprehensive library I've come across. I wish Borland had open sourced its kylix equivalent (I think it was called CLX?).
Looks very good. Is the library will be part of boost?
That depends on the result&lt;T&gt; of a formal Boost review, which I have not yet requested. :)
i just played around with the pdp7 IDE, the small typewriter/table on the right. It was an interesting experience but i can't really recommend it: the screen is very paper like, there's no code completion or syntax highlighting, it is very loud, the keyboard has a horrible feel to it (but it gives you decent finger strength) and the version i checked out of the company just didn't work.
You really gotta try vs code with the c++ plugin. You can get extensions for the Atom keybinds and themes in like two seconds, and the editor has way better completion and performance.
Out of curiosity - **why** is binary compatibility so important now? (well, in the last 3-4 years). What was so wrong with msvcrt110/120...? (I didn't even mind the WinSxS approach of VC 2005/8; am I weird? 😁😁😁)
But it's the vcredist executable or the merge modules in your VS install (and hopefully Build tools install, didn't look). How hard can using that be?!
I haven't used vscode, but given a choice between qtcreator and KDevelop I prefer the latter, especially on larger project where navigating through the code and understanding what's going on is key.
I do a lot of async programming. I have a couple of quedtions here. - resumable functions seem not to have a problem with composition. They suspend inside withou returning. Would this be possible with the fixes proposed? - why don't we just settle on something reified and similar to function objects? This seems to have so many advantages to me: allocation control, being able to figure out what the compiler does, inlining... I am not expert but I always saw Coroutines TS as a “port” of C#-style coroutines. Yes it is different, more powerful, but at the cost of code generation tightly tied into the compiler. I really think the way to go is to have a simple function object with jump information and resume/suspend and all abstractions on top of it. This would not tie anything into the compiler code generation unnecessarily. Also, from the point of view of a C++ programmer, the resumable functions look much more like what you expect from C++: function objects with reification. Personally, for making an abstraction in the TS I do not know even where to start. For resumable functions I would know exactly how to proceed. Want an allocator? Same problem: I know how to do one not the other. Want it inline? I think that is left to the optimizer in the current TS? This is just not a C++-ish design at all. I say this with a high respect for the amount of work that Mr. Gor Nishanov has put in it. I saw some talks. The resulting code is clean. But I think the abstraction should be changed to something that fits better with C++, honestly.
Not quite a response on the experience, but I saw in https://www.youtube.com/watch?v=cH0nJPbMFAY#54m00s , the response from Titus seems to really not like the feature and the audience seems to agree. Sounds like there's some bits that might have been rushed about the definition of the feature?
Makes sense, but what I was talking about 3rd party dependencies that are compiled with an older toolchain than my app. That should work, no? Personally, I usually don't have to worry about binary compatibility on windows, so I'm not too proficient in that topic.
Not sure what you are saying. I was not referring to the runtime but 3rd party dependencies. But I usually don't have to worry about such things anyway, so I don't know if that is a problem in practice. I just remember times, when I was unable to find a version of library X that was compatible with the latest version of VS we were using. But again. I'm definitely on the recompile the world side of things and really hate it when progress is hindered by backwards compatibility (be it ABI or API).
I've been trying for some time and I shamely failed, but I'd really like to use CDT at work. The main obstacle here is debugging. Is there a way to use cdb in Eclipse? 
Check boost.beast you can even make use of the HTTP client example to download from the internet, read about asio buffers too. 
snake's brain is a neural network. So genome is weights in that net.
Has [P1105](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1105r0.html) been discussed?
... They're pretty bad.
But the question still remains: what's it's interface with the game? In this case, what are the inputs and outputs of the network?
&gt; Also containers like std::string are not designed to be inherited from. Please do not advise this to anyone. It might not be designed for it, but what is the harm if you do?
&gt; 2018 &gt; can't split strings &gt; can't find substrings &gt; can't iterate over unicode strings "oh okay but do you have a moment to talk about our cool 2D graphics library in upcoming C++35?"
Compile-time networking please. I'm tired of my slow ISP.
Apparently the UTF16 issue has been fixed in this release https://developercommunity.visualstudio.com/content/problem/169566/visual-studio-2017-creates-utf-16-source-code-file.html Not tested it yet
Inputs are binary: Is there apple or not or is there safe or not in 4 directions. Outputs are 3: Go front, turn left and turn right.
Counting characters is no less incorrect than counting bytes. You need to count graphemes, classifying them by width (zero, half or full). And that still won't work for emoji, which can have platform specific ligatures. You need to ask your rendering library the number of cells occupied by a string to pad columns. 
Can you point me towards any resources which might help understand how to go about doing this please?
https://godbolt.org/z/szEdRE - prints to_chars = 826 ms dtoa = 733 ms. Maybe it's because of the cpu - its EPYC 7401P, on E5-2630 v4 results are practically the same. 
So do you think the compilation overhead was ultimately a net plus or minus? I mean, on the one hand, you save a few nanoseconds here and there. On the other, you did spend weeks compiling it... 
To be fair, this isn't entirely a bad argument. Why should other people have to pay for your convenience function?
As /u/Alastair__ pointed out below, there's been some changes to UTF8 support in this release. Please give it a try, and if you have any issues, update that Developer Community ticket or ping me :)
I agree on comments. I usually use a line comment above like: `// (world, position) -&gt; object` `std::map&lt;std::pair&lt;int, vec3&gt;, WorldObject&gt; worldObjects;` But /\*\*/ is maybe a better idea. 
[https://www.boost.org/doc/libs/1\_66\_0/libs/beast/doc/html/index.html](https://www.boost.org/doc/libs/1_66_0/libs/beast/doc/html/index.html)
Have you considered strong types? class MaterialIndex { ... }; class MaterialColor { ... }; std::map&lt;MaterialIndex, MaterialColor&gt; material_colors;
&gt;Clang is much, much more aggresively doing unrolling Indeed. I'm curious if a few of the cases where Clang is faster (e.g., HPCG which tends to be bandwidth limited) would not be made up for with `-funroll-loops` in gcc.
It might do better if it has apple and safe inputs not for just the four directions but for every square of the grid. It could then have all the information about the field like a human looking at it. Perfect information is needed to avoid it blocking itself into a corner. The neural net would get significantly larger too though.
There's no reason for your wrapper lambda function; you can move the inner lambda directly: auto x = [whatever] { }; std::thread t{std::move(x)}; In fact you could have defined the inner lambda directly in the parameter to std::thread, and it would still have moved because it would be an rvalue. Of course you already realise this since you rely on that for the wrapper lambda in your own snippet, so I assume you were just talking about the case that you want to define the lambda at a different point of the code to its use.
The ISO process is anything but open. Improvements are being made, but it is still very opaque.
What are you referring to? i.e. what others are paying for?
I have been involved in it since 2004 and it *is* quite open. 
&gt; I see no dynamic allocation ... except for the std::thread internals. That sounds like an agreement expressed in the tone of a disagreement. The internals of std::thread will surely perform an allocation to store the footprint of the function object (and arguments) passed in because they could be arbitrarily large. Of course there is likely to be some memory reserved in the std::thread object for a small object optimisation. But any further discussion down that line is a distraction. Memory allocations are cheap compared to creating a thread anyway. The real response to cpp_learner's last comment is either "good, the standard library authors are better than me at dealing with pointers in an exception safe way" or "whatever, the point of the move wasn't to avoid a memory allocation, it was to make the code simpler, which it is". 
I have also been involved, and it is *not*. Do not confuse being "open" (public) with being actually "open" (transparent).
Why are you trying to define what meaning of the word I was using? You make up a statement I have never made by changing the meaning of a word I used and then starts arguing with something I have never meant to say. I was saying, as my following words clearly clarify, that the process is quite open to take in proposals. Nowhere have I even implied that I have meant “transparent”.
You don't pay anything here.
I read somewhere that VS Code syntax coloration doesn't rely on Intellisense (or whatever) but on regex...
I could say exactly the same to you, but in my case, I actually gave a synonym for my definition ("it is still very opaque"), yet you tried to appeal to an argument of authority. Nevertheless, I am not trying to argue here: I see you tried to say people was welcome to publish papers. However, the point is that even if writing a paper were easy, the process afterwards is opaque unless you can manage to attend the meetings. Nowadays, things are getting better, as I said, and more and more documentation is provided for outsiders. Still, far from a replacement for being there.
&gt; And that still won't work for emoji ... We're all doomed then, I tell you dooooommmmeeeddddd. 
Good fun!
Could you please continue linking dynamically to OS APIs in ucrt even after that? And, ideally, terminate in case of their absence not immediately, but on the first usage? And initialise more things lazily in general? There's quite lot of synchronisation-specific code in ucrt that requires Vista+, but apps that don't use modern stuff from &lt;shared_mutex&gt;, &lt;condition_variable&gt; etc. never call that code and theoretically can work perfectly on XP (and even 2k), even though it's not supported. 
I'm a student, and currently in a group project making a game in C++ using SDL, with me being the only one with prior experience in C++. We have Linux users, Mac users and Windows users. The easiest solution was for everyone to use Linux, but there was some backlash. Second option was Windows.. but still not everyone agrees. So, let's just make our game cross platform, right? Setting up the development environment in Linux was dead easy. Mac was OK, most problems are using the package managers not fully supporting all libraries. We are using CLion as IDE on these OSs. Installing packages in Windows has surprisingly been very easy, thanks to vcpkg. Finding a proper CMake supported IDE not so much. CLion does not support debugging under MSVC, so had to find something else. Visual Studio supports CMake, but simple things as switching branches broke the configuration. Kept getting errors on unknown debug targets. Had to restart VS and do a clean a couple times to get it working again. Also, sure, it supports CMake, but it is not as friendly as say CLion. You can't right click on ur solution and create a class. U need to manually make 2 files, name them properly as header and source, and manually add them to CMake. Mind you, I'm trying to explain all these things to absolute c++ beginners. The only response I got is, "Why is everything so unfriendly/complicated". And rightfully so. In the end, Windows users had to end up using MingW/MSYS and CLion. It works fine so far, but comes with it's own problems. (incredibly long linking time with Catch, for example) TLDR: Building a CMake project on VS is easy. Developing not so much. Maybe I'm missing something?
Wow you have my dream job, I've been building a audio visualiser in oF on and off for two years but the real tough project is making a GUI to control it. Just started toying more seriously with lib cinder (because of poScene + other reasons). How did you get into your position? My current plan is to leave current asp.net software engineer internship and apply to a million 'creative coding' places but what are things I can do to show I'm dedicated? (also if that term is awful, what's your preferred term?)
&gt; Unity can target WebAssembly with sizes of a few hundred KB. Bullshit. That's why they are going with Tiny Unity in the first place, which is still 150kb compressed. An empty Unity scene is uncompressed 16MB, compressed(gzip) it's still sitting at 4 MB.. 
So how do you embed arbitrary information in a `leaf::result&lt;T&gt;` without using dynamic allocation?
Theres been two efforts at least to implement Rust support in Kdev but they never got into a usable state.
That's a real shame. I love working with KDevelop, but I am also going to be learning Rust soon and was hoping to use the same IDE...
I was doing similar stuff in flash 15 years ago and when the bottom fell out of that i went the c++ route rather than the JS/webgl route which is where a lot of my fellow flash orphans went. I haven't applied for a new job in a long time so i don't know what to recommend in terms of getting a gig, but i will say having a good portfolio is impossible to deny. They don't have to be big projects, just cool little things that you make. Toss them on github or instagram or whatever. As for your UI, you can't go past [dear imgui](https://github.com/ocornut/imgui/). There's drop in bindings for ofx and cinder too.
We all have to read the writing on the wall. It says that employers are in heavy demand for other tech. It took me 3 months out of school to get a 6 month contract. I think the demand for C++ will increase greatly in the future though!
Did you generate Visual Studio project files with CMake or just directly use CMakeLists as project (supported by MSVC 2017)? CMake development is horrible with the first old method. Latter works much better AFAIK. I prefer using QtCreator so I dont have much experience on Visual Studio
Remember the "direction for C++" paper: &gt; address major sources of dissatisfaction So far C++ has many great libraries but language struggless with convenience and some basic-level usage
\&gt; That sounds like an agreement expressed in the tone of a disagreement. Nope, that's a disagreement expressed as pointing that the statement doesn't imply it's conclusion. \&gt; But any further discussion down that line is a distraction. As i think you misunderstood my point, I'll still clarify. The discussion is about the copy. Or the "transfer" (move or copy or pass by pointer) of the object to another thread. That the thread is from std::thread or not is not important as the point is if the object being transfered is so through copy, assuming it does not do allocation in it's copy/move operators, it's still moving from one stack to another. Which means that if your thread was already there, there is no dynamic allocation at all. &amp;#x200B; From the whole discussion, I believe cpp\_learner misunderstand that to make data available for a thread, you do not need dynamic allocation at all. &amp;#x200B; \&gt; The real response to cpp\_learner's last comment is either "good, the standard library authors are better than me at dealing with pointers in an exception safe way" or "whatever, the point of the move wasn't to avoid a memory allocation, it was to make the code simpler, which it is". &amp;#x200B; That's not the real point here. The real point is there is no reason to allocate dynamically something except if you want to share it or if it needs to survive exiting the scope without passing it to some other owner first. &amp;#x200B; That's not even a standard library thing.
Build time: - other languages: O(n), where **n** is the number of source files - C: O(n) + O(h^(2)), where **h** is the number of header files - C++: O(n) + O(h^(2)) + O((n+h)t^(2)), where **t** is the number of template instantiations
You're focusing on the implementation of std::thread when the whole issue is about transfering the object from one thread (stack) to another (stack) which involve no dynamic allocation. What if the thread alredy exist and you're just passing an object to it? Etc.
It's more of write once and compile everywhere
If you can have a strong type with the same interface as the original type then I'd try that for sure.
I have to admit that inline comments are basically the same as what I was considering. That seems like a reasonable approach.
Very nice introduction, including the peek at `nm`. Not a lot of people appreciate the role of the linker. Probably the fault of these integrated environments.
I can't think of anything that boost python had that pybind11 doesn't. Pybind11 adds extra things like auto vectorization, better handling/use of lambdas, built in support for eigen c++ types, and probably more that I can't remember. To be honest, I dont see a reason to choose boost python over pybind11 (unless you have to deal with a legacy version of python that pybind11 doesn't support) 
Tiny Unity is still Unity.
Is this a homework assignment? If not these restrictions don't make aot of sense. Friends don't let friends depend on boost.
You can overload the operator() with no arguments for a single type. You can also overload the cast operator to cast to the type you are trying to mimic.
What's your arrays size ?
&gt; `I_LATS = 73, I_LONS = 144 , I_LVLS = 17, I_RECS = 7300 ;`
I recently included a boost header... and now I understand why people complain about c++ build times.
Thanks! We fixed it. 
&gt; I recently included a boost header... ya dawg, I heard you like includes so we incl...
Why wouldn't you?
What have you reduced in array size
Friends dont let friends use boost.
Not sure, never tried using strong types. Is there a library out there that you'd recommend for it? Or do most people create their own solution?
I changed I_RECS to 730
Hard to reuse code. Say I create FooString which inherits from std::string to add `contains()`, now I use FooString everywhere in my code, so I can call `contains()`. Another lib needs to reverse string, so it create BarString, which inherits from std::string to add `reverse()`. Now I have 3 string types and they are not compatible with each others :/ If those methods were in std::string or declared as standalone functions, I could use them easily on std::string.
Yes, same happened to me yesterday. Spent about 3 hours waiting for the installer to download everything at 40kb/s over a 600Mb/s connection.
But it's not here.. It's not even in a public beta. It's also heavily crippled, feature-wise. 
\&gt; Both are equally horribly slow to compile (clang used to be much faster, nowadays it's often slower than GCC). &amp;#x200B; Yep. Two things have happened. One is that GCC have sped up their front end a lot in response to Clang, reducing the advantage. The other is that Clang has grown a much more powerful optimizer than it used to have and those are slow to run. The result is that Clang got slower and gcc got faster. 
bit too old msvc: https://godbolt.org/z/dDQk61 warns on void x)
I can't say I understand any of this, but it's refreshing to see that people write C++ libraries for something other than logging, error codes, or better enums...
Nice explanation. What do you think the best solution is?
Nothing what you are saying is special to standard library types. My question was what harm would it do to inherit from standard string. Not if `contains` should be a member or free function (I agree with you that it should be a free function).
In places where I have control of the build environment (closed source services) I'm happy to consider Boost. But in other contexts, I don't want the headaches.
I tried to expose a coroutine to C via C FFI. And does not seem to eliminate the heap allocations.
&gt; `.find` is direct replacement for `contains` **but even more powerful.** And that is precisely why we need `.contains`: A very good rule of thumb for which feature you should pick is “the least powerful one that does the job.”. Just as `goto` is more powerful than a loop and how a general for-loop is more powerful than a range-for, `find` is more powerful than `contains` and therefore should be replaced with the more specific function that does exactly what it's name implies. 
Well, it is possible to use regex-replace to get what you want for many cases. Apparently people really do that because it's just so much more convenient, despite being much slower. It is however really telling, that there are 9 (!!) replace-methods, yet the one that people are actually interested in is missing.
I think it's a learning experience as well. Learning experience is maybe the main (only?) reason to do it. I learned pretty much all my Linux, terminal, compiler, system etc. skills using Gentoo, compiling everything, configuring my own kernel, setting up everything by yourself, from scratch, always using all bleeding edge stuff. Things break often and I learned so much fixing all that stuff. It took hours, days of course, and is completely not worth it if you don't do it for the learning experience, and you're e.g. young and in school and have the time. Once you got a job, you want OS-things to just work so that you can do your *actual* job.
+1 for emerge/portage, definitely one of the main reasons for using Gentoo. The past few years I have the feeling they don't keep the packages that much bleeding-edge though, I checked a few times and didn't find the latest gcc/clang versions. Whereas in Manjaro I could find them almost instantly when they were released.
It's explained in the [introduction](https://zajo.github.io/leaf/#introduction), but briefly: `result&lt;T&gt;` is essentially `variant&lt;T, leaf::error&gt;`. `leaf::error` is a value type, a unique identifier of the failure being reported. `leaf::expect&lt;E...&gt;` is essentially `std::tuple&lt;E...&gt;`, except each `E...` object is associated with a `leaf::error` key (can't store more than one object of each `E`). At the point where you handle errors, you have `leaf::expect&lt;e_this, e_that, ...&gt; exp`. In case of failure, `E...` objects are moved in `exp`, but only if their types are listed (otherwise they're discarded, because the error handling scope(s) have no use for them), while the `leaf::error` key needed to access them is transported in the returned `result&lt;T&gt;`.
Didn't know about the -H flag for gcc. Very nice. &amp;#x200B; Related: it is pretty amazing we (C++/go/rust (correct me if I am wrong) users) are still using the linker/object schemes created for C 50 years ago. They were either designed very well or this area has been overlooked (or deemed good enough / too hard to change).
VOP - Value Oriented Programming. Worth watching. I'm a big fan of all his talks.
That would impose costs on Win7+ users.
Thanks for taking an interest :) Quantum mechanics can mathematically be formulated in several different ways. One of the most commonly used formulations is second quantization ([https://en.wikipedia.org/wiki/Second\_quantization](https://en.wikipedia.org/wiki/Second_quantization)), which is able to capture the general structure of many-body quantum mechanics. There has been a lot of work in the research community over the past several decades to develop code to solve such problems. However, this has largely been algorithm centered without a lot of thought going into the development of general purpose data structures. The result is a fractured community with code that is difficult to integrate and which can require years of experience to be able to use. TBTK aims to provide data structures that are tailored for these types of calculations, providing abstractions that capture the general mathematical structure of quantum mechanics, while at the same time provide high performance. Such data structures can help provide abstraction layers between people with different expertise and make it easier to share data between different applications. I find this particularly important to work on at this point in time since Moore's law is coming to an end with 5 nm technology being target within the coming years. Quantum mechanical effects are a very real boundary that this technology is running up against. It therefore seems more or less necessary to be able to leverage the algorithms that has been developed in the scientific community to provide proper quantum mechanical simulations of the smallest circuit elements in the coming decade. TBTK is intended to help bridge this gap by making it easier to interface the electrical engineering and quantum mechanics communities. This can also benefit for example the quantum chemistry community, and hence be important for drug discovery, as well as be important because of the increasing focus on trying to build quantum computers. More information is available in this preprint [https://arxiv.org/pdf/1808.02409.pdf](https://arxiv.org/pdf/1808.02409.pdf) and through the links listed on [http://second-tech.com/wordpress/index.php/tbtk/](http://second-tech.com/wordpress/index.php/tbtk/).
I get that, but for day-to-day apps like text editors, web browsers, etc., I'm not sure the gains are worth the trouble, never mind other potential administrative issues. Now, if it's a hard-core numerical simulation or something, there may be a point, but those are special cases. Gentoo and similar distros smell to me a lot like forgetting the 80-20 rule at the OS distro level.
Conan made boost extremely painless on all platforms. Still prefer not to use it when able.
&gt; However, there is some good news. Not everyone is in denial about this problem. Rust (**disclosure: Rust’s primary sponsor is my employer, Mozilla**) is a relatively new programming language...
\&gt; and in a memory safe programming language (for example, Python or Java) I will concede that Java makes memory safety a lot easier than other languages, like C++, do. But saying either of those languages are "memory safe" is laughably ignorant.
Its almost like a language that is as widely used as C/C++ in critical infrastructure is bound to be used in software that has bugs or vulnerabilities, just like any other software (the combining of C/C++ is another issue entirely IMO, also not to mention that those are written in C, which has a huge legacy behind it). Rust is not magic and "memory safety" is not a silver bullet, the killer of all software bugs. It has its own set of issues (leaking of build environment details, obtuse error handling, and an extremely stubborn central package repository). C/C++ won't be going away any time soon, nor is it the cause of software problems. It is simply one of the only sets of languages used at this level of computing in such a widespread fashion. 
Your explanation pointed me to: https://github.com/zajo/leaf/blob/master/include/boost/leaf/error.hpp#L181 So you're using `thread_local` to store the error information, that was what I was wondering about.
&gt; But saying either of those languages are "memory safe" is laughably ignorant. Please do enlighten us, I'd consider both memory safe, if not particularly attractive for development.
&gt; [C/C++ has issues] &gt; Alex is a software security engineer at Mozilla hmm... rust?
This is a little something I've been working on lately which still in a very early state ( definitely not ready for production ) that I think could become useful to more people. Any kind of feedback is appreciated. Contributions even more so. 
Indeed, but isn't intellisense part of the main C++ pack in VSCode? I assume they come together (although they are not the same thing).
These kind of problem is mainly fixed today (raii, ranges, span, unique_ptr, etc.) But legacy still exist. And there will always be bugs. Buffer overflow doesn't have to be access past the end of a buffer. It can happen within the buffer itself. For example, another process ask yours to get some data in a buffer. It should only have access to elements in the range of 32-128. If your buffer is of size of 1024, the language won't stop the buffer overflow, even if it's a "secure" language. I'm pretty sure from what I know that heartbleed was a similar problem to this, so even if the language would do bound checks, you'll have security problem. To solve this kind of issue, there's no way around it: write your own secure abstractions or write no bugs. This applies to any language. Language based resources management and security will never be enough for large scale programs. Many applications written in ruby, python or java have security problem and memory leak problems. C++ has them too, but at least we don't pretend we don't have them.
In that case, the browser plays the same role as any other runtime. I wouldn't be surprised to learn that there are actually more platforms with a Java Runtime Environment (JRE) than platforms with a modern web browser (i.e. embedded java code; which I'm not saying is the way to go, but it does exist). 
&gt; Rust is not magic and "memory safety" is not a silver bullet, the killer of all software bugs. Certainly. Heartbleed was ultimately about buffer re-use more than anything else. Eliminating Undefined Behavior is still a noble goal though; if anything: - without Undefined Behavior, debugging is *much easier*, - with easier debugging, and half the number of bugs, there are hopefully less bugs surviving. Not a silver bullet, certainly, but a welcome improvement. &gt; It has its own set of issues (leaking of build environment details, obtuse error handling, and an extremely stubborn central package repository). - *leaking of build environment details*: not quite sure what you are referring to, but personally I am concerned with the unrestricted access to the user data that build scripts have, and wish less build scripts were necessary so that developers would not get inured to their presence. Still, most build scripts necessary would probably be necessary in C++ (and realized in bash, Perl or Python), ultimately with the same issues. - *extremely stubborn central package repository*: interesting complaint, C++ developers generally drool in front of cargo. You can solve the problem like you'd do in C++ by vendoring dependencies, completely bypass the central repository at all; and yes it's not ideal. There's work in progress for [private repositories](https://github.com/rust-lang/rust/issues/44931) which I think are necessary for professional use: I certainly don't want my CI machines connecting to the Internet! - *obtuse error handling*: I actually find it rather straightforward; it's certainly in line with functional programming languages, are you familiar with any of them? &gt; C/C++ won't be going away any time soon, nor is it the cause of software problems. It is simply one of the only sets of languages used at this level of computing in such a widespread fashion. I'll agree that it's not going away any time soon; mostly because any attempt at a widespread rewrite is most likely to introduce *more bugs* in the short/medium term. On the other hand, I very much disagree that C and C++ do not cause woes. Since my objectivity is likely questionable, I'll let a professional C developer do the talking. Enter [Linus](http://www.yodaiken.com/2018/06/07/torvalds-on-aliasing/): &gt; Honestly, this looks questionable to me. &gt; I'm not talking about the changes themselves - I can live with them. But the _rationale_ is pure and utter garbage, and dangerously so. &gt; The fact is, using a union to do type punning is the traditional AND STANDARD way to do type punning in gcc. In fact, it is the *documented* way to do it for gcc, when you are a f*cking moron and use "-fstrict-aliasing" and need to undo the braindamage that that piece of garbage C standard imposes. &gt; So the commit message that talks about how horrible union aliasing is is pushing a story that is simply wrong. Using the standard to push it - the same standard that came up with the completely mis-guided aliasing rules - is not a valid argument. &gt; Andy, what is the background for trying to push this idiocy? Don't tell me "the C standard is unclear". The C standard is _clearly_ bogus shit (see above on strict aliasing rules), and when it is bogus garbage, it needs to be explicitly ignored, and it needs per-compiler workarounds for braindamage. The exact same situation is true when there is some lack of clarity. &gt; This is why we use -fwrapv, -fno-strict-aliasing etc. The standard simply is not *important*, when it is in direct conflict with reality and reliable code generation. &gt; [...] When one of the most prominent C project explicitly works around the C Standard, it seems illustrative of a problem to me. *And I'll note that the consequence for violating strict aliasing are dire; the optimizer is likely to mangle your intent beyond recognition, and processors with weak memory consistency such as ARM may play havoc even with straightforward assembly conversion.*
I've got license for Turbo C++ 2006 and this is what I'm using primarily. Back then it was free and it can be used commercially, limitation is that no third party component packages can be installed - I can live with that. In 2005 Delphi Personal was available for free with some newspapers. I think registration was not required back then, but from I recall you had to have physical medium to keep it legal. It can also be used commercially. I prefer C/C++ though. About two years ago C++ Builder Starter was available for free - also suitable for commercial usage but with limited income ($5000 per year). I've also got myself license, but this version kinda sucks as debugger is limited in functionality. Now there is C++ Builder Community Edition, also limited to $5000 yearly income, from what I read with full featured debugger. The problem here (at least for me) is that license is granted for only one year and you are supposed to install next newest and greatest edition after that. I don't want to put my trust in this. If you are interested in Kylix (Pascal) you should definitely look at Lazarus.
Are resumable expressions at all related to Facebook's proposal? Is Facebook's proposal what Eric is referring to as senders/receivers [here](https://www.reddit.com/r/cpp/comments/9vwvbz/2018_san_diego_iso_c_committee_trip_report_ranges/e9gv1dk)? Or are those something orthogonal? 
Did you get the wrong sub? I'm optimistically thinking this isn't just spam
I'm pretty sure Alexandrescu's original idea was to throw on destruction if it had been ignored. But I can't find a reference/link to quote this. This started at least 10 years ago I think. It evolved over time.
Have you heard about our lord and savior rust?
Story is the same for CMake.
I looked at the code a bit. C++17 is definitively a nice language to read ;)
bonus points for quoting wittgenstein
That's a dumb rule of thumb. Then we'd also need the method `contains_foo` to check if a string contains the exact substring "foo", as well as a `contains_bar` that checks for a substring "bar". A generic `contains` method that can check for an arbitrary substring is too powerful.
Yeah, this is a known issue. The optimizer is unfortunately unable to optimize across translation units. I'm pessimistic that this can be fixed with the current Coroutine TS
Actually, if there are methods `contains_foo` or `constains_bar`, these are indeed what you should use. The reason they appear to be silly is that *usually* they shouldn't be there. I have a hard time thinking up a valid example for `contains_foo`, but once we widening that to `find_foo`, the situation changes a bit: `find_newline` can be a very useful thing, and interestingly we have something very similar in the standard-library, namely `std::getline`. Granted, it is more general than just that, as you can pass it a newline-character, but that might actually be bad design, and maybe we should really have two functions here, where getline is more hardcoded to capture the 90%-case in a clear manner, whereas the other function directly states with it's name that it is more general than that and thus requires a closer look. But of course: A rule of thumb is not a hard thing and common sense with regards to which functions you should define is still necessary. (Though I conjecture that most people don't define as many functions as they should, but that's a topic for another day.)
I'm not going to comment on the technical merits but we need another name beyond "MC" which clashes with other projects.
It depends on what method you want to apply. Assume for example that you know the matrix elements H\[n\]\[o\]\[n'\]\[o'\] = &lt;\\Psi\_{no}|H|\\Psi\_{n'o'}&gt;, where n(n') and o(o') are atom and orbital indices, respectively, then you would set up the model like this: `Model model;` `for(unsigned int n = 0; n &lt; 3; n++)` `for(unsigned int np = 0; np &lt; 3; np++)` `for(unsigned int o = 0; o &lt; 3; o++)` `for(unsigned int op = 0; op &lt; 3; op++)` `model &lt;&lt; HoppingAmplitude(H[n][o][n'][o'], {n, o}, {n', o'});` `model.construct();` &amp;#x200B; You can then setup a solver and diagonalize it as follows: `Solver::Diagonalizer solver;` `solver.setModel(model);` [`solver.run`](https://solver.run)`();` &amp;#x200B; Finally the energies can be extracted using &amp;#x200B; `PropertyExtractor::Diagonalizer propertyExtractor(solver);` `Property::EigenValues eigenvalues = propertyExtractor.getEigenValues();` `for(unsigned int n = 0; n &lt; model.getBasisSize(); n++)` `cout &lt;&lt; eigenValues(n);` I hope this gives an idea about the general workflow. If a method is needed that can also determine the matrix elements themselves, this is not included in TBTK itself. Such methods may be added in the future, but the main aim of TBTK is to provide data structures that can transport data in a portable way between algorithms, different softwares, etc. rather than to provide the algorithms that perform the calculations themselves. If you can provide more details about what you are after, I may be able to give a more specific answer.
Linkers are a really good design idea: break up multiple compilation units (source files) and then have some other program do less heavy work (parsing source files then applying optimizations is heavy work) then take all of these, see where they reference eachother, and point the references the same place, add a header and footer, and print it out. It's really just there to allow you to compile multiple things at once.
It's both, but obviously we need better and faster compiler chains. That's why C++ modules are one of the most ground breaking additions that may come with C++20. Even so, I don't know if template meta-programming slow compile times can be improved substantially. It's hard for a newbie like me to know.
At MeetingCpp today there was a talk by a guy who built something very similar. https://meetingcpp.com/2018/Talks/items/Building_a_Cpp_Reflection_System_in_One_Weekend_Using_Clang_and_LLVM.html His design was intrusive and required macros alongside the type/memeber definitions, which to me completely defeats the purpose of using clang. It also wasn't C++17 so, I think I prefer what you've done here. I guess this is like Qt moc for normal types. 
You need to prefix each code line in a block with `4` spaces (similar to SO), see https://www.reddit.com/r/raerth/comments/cw70q/reddit_comment_formatting/
I'm working on this in terms of an on-line code generator called the [C++ Middleware Writer.](https://github.com/Ebenezer-group/onwards) It automates the creation of serialization functions. 
&gt; which to me completely defeats the purpose of using clang Well that depends on your pov. While I don't like manually tagging my types (my reflection libs never require that), I see the point of the speaker of taking explicit control of which types and fields are exposed to the reflection system, so you can control the final size of the database, which types are part of the public API that could be introspected, etc. The point of using clang is to get as much metadata as possible automatically, not having to write all the metadata registration boilerplate manually (that's what the talk was about). That's true either if you gather all your translation unit stuff or just the stuff you explicitly pick with a couple of attributes. BTW the guy was /u/arvidgertsmann
Thanks a lot! (I had to switch to markdown mode to get this to work too)
I'm sure he [would've mentioned](https://youtu.be/PH4WBuE1BHI?t=2961) such a dramatic change in his own opinion :) &amp;#x200B;
Those classes do not have a virtual destructor. You trigger UB if you delete a `std::string*` if it actually points to a `FooString`. 
Agreed. I just commented on someone's website that was named "sr". Get outta here with your 2 letter names!
I don't disagree with the ability to exclude certain members from the reflection. What I disagree with is using macros to achieve this, I would have gone with C++17 attributes. Additionally the default should be "on for all members" for any type that you've opted to do this for. From what I saw today it was a case of macros all over the place. I would much prefer the ability to add an attribute to exclude a given member from the reflection system. 
&lt;3 &lt;3 &lt;3 As I've told you some time, just trying to learn from the masters ;)
Last time I tried, boost::python was actually faster at run-time (less per-call overhead). Not sure if that changed though (this was almost two years ago...)
Remake of that Code Bullet Video?
(Apparently this is known behavior of Grisu2; I just noticed readme.md saying "Grisu2 is chosen because it can generate better human-readable number and &gt;99.9% of results are in shortest." Still, this algorithm is unusable for charconv.)
yeah sorry, the questions often don't make sense and the answers are incomplete, misleading, or wrong most of the time. &amp;#x200B; The site itself functions well, but I think you're out of your element trying to write c++ educational tools
Gaming. Just like there's no reason to have a fast car (cause you can only go the speed limit) but people will have crazy fast cars they carefully tune anyway, PC enthusiasts like to tune everything to crazy degrees for marginal gains as well. I understand it, but frankly, don't have the time to partake in it. 
It would be really interesting if that was reported as an issue to the pybind11 GitHub repo and then we could track it. The maintainers over there are usually really responsive and very interested in this kind of stuff and how to squeeze the last bits out of it if possible. I'd say that if pybind11 still has more overhead than Boost.Python (unlikely imho), then open an issue and it'd be really interesting to get their take on it. As for OPs question, in my opinion &amp; experience a comparison is pointless as pybind11 is better in every single point :-)
&gt; What do Heartbleed, WannaCry, and million dollar iPhone bugs have in common? C or legacy C++ code. Yes, that's a problem. Modern C++ code following best practices and using adequate tooling &amp; compiler warnings is not.
What I do is go to https://www.youtube.com/user/CppCon/videos?view=0&amp;flow=grid&amp;sort=p (sort by popularity) and then scan the page for "CppCon 2018".
&gt; You completely ignore the parts where c serves as a lingua franca. ..thats the `2. Legacy projects without much change.` part though. You can't go around changing the lingua franca everywhere, that defeats the entire purpose! It's already defined and used all over the place, changes to the C ABI from whats used as the lingua franca may as well not exist. 
Do you mean it changes the Hello World program because it changes the includes/imports or something else? I'm only moderately familiar with modules.
Maybe
This may not work because it will take too long to learn.
Sorry for the slow response. We build that with the compiler, and ship it with the application, installing it locally in the application binary directory. I guess these habits formed because the code we develop all has to be cross-platform. So on Windows of course we could use any version of Visual Studio on any version of Windows (these days it's all Windows 10, but for a while we had developers on Windows 7, 8, and 10) building executables that also run on any version of Windows (we could build on 7 or 10 and make executables that would run on anything XP or newer...) So we wanted that same ability on Linux, and found it wasn't too hard if your willing to build your development tools from source and keep them in locations separate from your OS tools.
There is also a c++14 project, [reflang] (https://github.com/chakaz/reflang), that does a similar sort of thing I have found really useful as a basis for my own custom utilities (serialization, automated code generation, etc).
As long as you can use the clang tools (clang-tidy e.g.) with your workflow I think there's not a big difference nowadays. Don't trust me much because I code with Visual Studio 2017 (and even VS has support for clang tools, cpp-check,...)
Yea
I was thinking about mind control... 
I'm assuming he's referring to the garbage collector and its indeterminism.
Ah, yes! I'm not too happy with it myself. I tells nothing about the project and clashes with well established names. I'll grind for a better name so we can get this fixed soon. Open to suggestions too! 
Neat, but second quantization is a misnomer. It's field quantization. It's like an old timer not being willing to use C++11 and smart pointers because "in my day we just used raw pointers" the same way that 65 year old physics professors say "in my day we just called it second quantization."
In a way, I'd say yes. Hell, even the name is very much similar - meta compiler vs meta object compiler. &amp;#x200B; The intention however is for this to be used as a lower level utility. Moc provides you with signals and slots, property accessors and whatnot. I used QT myself a lot and I loved it. Inspired by that I always wanted reflection in my projects but I didn't find any library/tool that didn't require me to decorate elements in an already very verbose language so I came up with this eventually. &amp;#x200B; If you browse the history of the repository, you'll learn that this was also opt-in at the start using annotations wrapped in keywords such as slot/signal/property and so on. That just looked unmanageable to me so I switched it around to having every public declaration exported by default and if a declarations shouldn't be exported than it should go in a private header that isn't processed by this tool.
/u/ned what do you say ?
None, most of them are good but most of them you probably won't care about if you are not interested or using the things they speak about. I'd say the most general videos i watched have been those: CppCon 2018: “Grill the Committee” CppCon 2018: Titus Winters “Modern C++ CppCon 2018: Robert Schumacher “Don't package your libraries, write packagable libraries!” 
Ok, my mistake then. I actually thought that the winrt/cxx (UWP) types would exactly use those c-structs internally.
I don't see how that's relevant to memory safety That said as someone who's recently worked with Pythons c API I think it makes it too easy to mess up safety
Kate Gregory’s keynote is well worth the time.
I can definitely recommend anything by Jason Turner and Chandler Carruth. Their presentation style is amazing, their topics are often very accessible and you are bound to learn something useful!
Yes, the use case is unlikely in small projects if all developers are aware of this issue. For larger projects the risk is high. The compiler can help via `-Wdelete-non-virtual-dtor` or equivalent. But still noone should use it, since we have an obvious, clean solution available: use a free function. 
On the other hand, \[\[trivially\_relocatable\]\] could be very usefull if standard container and allocators where "aware" of the possibility of relocation without memory copy through manipulation of the virtual address space.
Well he has a point. If you ever checked CVEs the amount of basic issues like memory related bugs is baffling and worrying at the same time. Most CVEs I looked into are for programs written in C or C++ and would have been avoidable with other languages. Heck even CVEs for higher languages are often caused by them being implemented in C or C++. And no. So called modern C++ does not cut it yet. In contrast features like string_views make the situation worse! Undefined behaviour is often very close. Security should not rely on the developer being on edge most of the time when using something like string_view. That's why I find Microsoft's efforts for static analysis commendable. Really, what is the worth of performance when you have an insecure system? We need these typical errors to be found before production. They lead to a class of security issues that did not change in decades. And that is a shame. The effort is twofold: first methods that mitigate these risks and second education. This sis necessary for c++ to be feasible in the long run. 
While I generally agree with the first paragraph I don't see how Linus' rant (he pretty much rants about everything) on the strict aliasing rules is relevant to this discussion. Every language standard with focus on backwards-compatability will at some point introduce issues that cannot be easily resolved without breaking stuff.
Oh someone added captions for the Compile Time Regular Expressions. Thanks to whoever did that &lt;3.
Thanks. Banned.
A ton actually. Exactly on the low, C level, of the language a lot of progress has been made to modernize it. int main() { auto num = 2; //&lt; C++11 auto type deduction int c_array[] = {1, 2, 4}; //&lt; old C array, not recommended, but still can be used better for(auto num : c_array) //&lt; C++11 range for loop // loop the entire array for(size_t i = 0; i &lt; std::size(c_array); i++) //&lt; C++17 std::size for C-arrays { // loop the array using an index auto num = c_array[i]; ... } std::array&lt;int, 3&gt; array = {1, 2, 3}; //&lt; C++11 array std::array array = {1, 2, 3}; //&lt; C++17 array (type of elements and size deduced) // std::array is an object and can be copied and returned functions } In general simply search "new features C++11" as well as C++14 and C++17. You can watch/search CppCon YouTube channel as well. Check also related question [https://www.reddit.com/r/cpp/comments/9vip8u/learning\_c\_like\_its\_2018/](https://www.reddit.com/r/cpp/comments/9vip8u/learning_c_like_its_2018/) &amp;#x200B;
Nice project, but I would note somewhere that this is basically a wrapper around the llvm demangle api
Wow, thanks for such a detailed answer! So I guess, as always, benchmarking is hard - you get what you measure. dtoa_milo really sometimes suffers from strange results, we've noticed that too.
&gt; I don't see how that's relevant to memory safety Garbage collector doesn't clean up your memory immediately and thus allows memory leaks. &gt; as someone who's recently worked with Pythons c API I think it makes it too easy to mess up safety CPython API... have you tried running python through valgrind or address sanitizer? Thanks to python I can't use ASAN in CI. Also the difference between C and fairly recent C++, in this aspect is huge. When was the last time you saw a naked `new` in a C++14 or newer codebase?
I'd also add Bjarne Keynote: [Bjarne Stroustrup “Concepts: The Future of Generic Programming (the future is here)”](https://www.youtube.com/watch?v=HddFGPTAmtU&amp;t=4725s)
I've recently had to deal with vectorization and noticed that the compiler actually does a really good job at producing SIMD code without need of extra libraries https://godbolt.org/z/k9dGKY When should I use a library as opposed to hand-written code? 
Very annoying article. I found it to be a mixture of good points, bad points, and naivety. &gt; The Internet Has a Huge C/C++ Problem and Developers Don't Want to Deal With It Remember when your manager _asked you to deal with your C/C++ problem_ and you just didn't want to? Now face the consequences! Alex has written about you and your C/C++ problem for everyone to read! That's what you get for not having opinions that Alex agrees with! &gt; At first glance these [Heartbleed, WannaCry, and million dollar iPhone bugs] might seem unrelated, but in reality all three were made possible because the software that was being exploited was written in programming languages which allow a category of errors called "memory unsafety." The category is called "memory safety" (reading about "memory unsafety" to the end of TFA made me cringe). Also, the ... anecdotal evidence (?) (of three things, hand picked to support your argument) seems contrived and does not make for a strong argument. &gt; What should happen if you asked the list for its 11th element? Most of us would say an error of some sort should occur, and in a memory safe programming language (for example, Python or Java) that's what would happen. Not in C++. Hell no! (have you heard the story of [Darth OutOfRange](https://en.cppreference.com/w/cpp/error/out_of_range)? It is not a story the Jedi would tell you). &gt; If these vulnerabilities are so prevalent, can cause so much damage, and there are languages that don't have these pitfalls, then why are these languages still so common? [long paragraph about C and C++ being old and Rust and Swift becoming recently available] The argument forgets to err ... argue why C and C++ are so common; After all, Ada is a comparably old language, from when Rust and Swift were not available, and this doesn't make it very common. &gt; A bigger issue is that when developers sit down to choose a programming language for a new project, they're generally making their decision based on what languages their team knows, performance, and ecosystem of libraries that can be leveraged. Very big issue indeed. Why is it an issue in the first place? It seems to me, that TFA tries at the same time to argue that C and C++ are a problem (using a class of errors that exists mainly in legacy code bases and anecdotal evidence) and to assert _a priori_ that they are a problem. [C and C++ being a problem] appears both as a precondition of the article and a conclusion of it (?). &gt; [...] Finally, the largest problem is that many developers don't believe there's a problem at all. I don't believe there is a problem in C++. There was one that is still prevalent in legacy code; The language has changed recently though. &gt; According to this theory, the problem isn't that trying to get the 11th item in a 10 item list can result in a critical vulnerability, the problem is that someone wrote code which tries to get the 11th item in the first place, that they either weren't a good enough engineer or weren't disciplined enough. "The strawman" is strong with this one. I don't think the problem is with _other developers_ who don't know how to write code. We have a team and team practices which avoid memory overflows (also, have you heard the story of Darth OutOfRange? It is not a story the Jedi would tell you). &gt; the evidence makes it clear that "try harder not to have bugs" is not a viable strategy. "try harder not to have bugs" is not a strategy of any kind, it is wishful thinking. TFA does not mention where this strategy was encountered - only generic statements like "Many developers find this position compelling", "thousands of vulnerabilities that are preventable" and "Many software engineers believe". TFA continues in this vein and I have work to do :( I will stop here.
&gt; msvc exporting inline functions as well was a mistake that can't be changed without breaking the ABI. I'm not sure I'd call it a mistake. It's necessary to give the inline function a unique address for example, which is required by the standard.
Yes, putting dllexport/dllimport directly on the function declaration is not affected by the new flag. The new flag only affects whether class-level dllimport/dllexport is inherited to inline members.
This year there was a very good one about DoD and OOP showcasing cod examples in chromium codebase.
Well in that case this sounds like a great idea. Microsoft should do the same.
Sorry I didn't phrase that well... what I really meant is that KDevelop is showing much more progress than Qt Creator, despite not being a commercial project with people working full time on it. Also, it's true that Qt Creator had the CLang code model for a long time, but I still don't find it usable.
Name clashes are not important if the project are in different domains. I wouldn't want to change my project name only because someone used that name before me. 
As a result you will he hated because of your arrogance. How do you know for sure your project will not conflict with another on some users machine? Especially in the case of a name that is widely used? 
Check ai-bots.net next year some time. I'll have up a tcp server for two player and n player snake you can write bots for. 
Indeed, this is not special to standard library types, but I have seen it in some scary code bases so I assumed the bad practice or inheriting from string to add new methods was what the GP meant.
Here are some talks I really enjoyed that don't get mentioned very often: * Bob Steagall — Fast Conversion From UTF-8 with C++, DFAs, and SSE Intrinsics https://www.youtube.com/watch?v=5FQ87-Ecb-A&amp;t=1s * Gor Nishanov — Nano-coroutines to the Rescue! (Using Coroutines TS, of Course) https://www.youtube.com/watch?v=j9tlJAqMV7U * Robert Ramey — Safe Numerics https://www.youtube.com/watch?v=93Cjg42bGEw * Simon Brand — How to write well behaved value wrappers https://www.youtube.com/watch?v=J4A2B9eexiw
\&gt; It would stand to reason most enterprise-level customers aren't likely to move to 2019 (or even 2017) soon; ABI compatibility was the single reason we were able to upgrade to VS2017 right away and kept up with VS updates ever since. Updating everything would be a nightmare.
&gt; c++filt defaults to demangling type names Are you sure about this? `c++filt` man page writes, &gt; Attempt to demangle types as well as function names. This is disabled by default since mangled types are normally only used internally in the compiler, and they can be confused with non-mangled names. For example, a function called "a" treated as a mangled type name would be demangled to "signed char". 
The correct title is "C++ Weekly - Ep 141 - C++20's Designated Initializers And Lambdas".
Yes.
Oh gosh I totally forgot I wrote that comment and saw in my inbox your message and thought I got banned from /r/cpp haha
Thanks. You're banned.
Touché!
Nah, Jason is embracing C now ;) (Great video as always, Jason)
Collision? Are you talking about the executable name or package name? That doesn't need to be the same as the project name. 
&gt; Garbage collector doesn't clean up your memory immediately and thus allows memory leaks. Interestingly, memory leaks are safe. Unwelcome, yes, but safe. Fundamentally, there is little difference from a behavior point of view between a "sessions" maps in which entries linger in some cases and a "forgotten" pointer. Both keep unnecessary objects around for longer than they should. For example `std::mem::forget`, which allows leaking an object's resources, is in the safe subset of Rust.
Looks very interesting. I like how you can convey arbitrary information out of a function without changing the type signature. Just a request. Since LEAF has no dependencies, would it be possible to have a non-boost version like ASIO has. There are some companies that have restrictions on using boost, but not on other open source libraries, and having a non-boost version would make things easier.
I was wondering if memory leaks could actually be considered safe. Thanks for pointing that out.
Yes, being able to convey arbitrary information out of a function without changing its interface is the main motivation behind LEAF. The lack of this ability increases physical coupling, which in large scale projects can become problematic, more so in error handling code, which already is difficult to test and maintain. When you say a 'non-Boost' version, do you mean a different license? AFAIK the Boost license under which LEAF is distributed is more permissive than other open source licenses. Other than that, the unit tests need `&lt;boost/detail/lightweight_test.hpp&gt;`, but you don't need Boost to use LEAF.
Well, maybe he want us all to forget he ever suggested otherwise, and he also removed all evidence from the internet. Hard to say which, really. :-) So who had the version that threw in the destructor? Meyers? Someone else?
All chandler carruth and herb sutter talks are absolutely outstanding.
There is no standard, use what you like, but even more so, keep your codebase consistent.
No. There is no 'standard style'.
I'd definitely agree with this!! 
&gt;When you say a 'non-Boost' version, do you mean a different license? No just something not in namespace boost. The example is what asio does https://think-async.com/Asio/AsioAndBoostAsio
It appears that this would require a script to produce a non-Boost version from the Boolst source code, which would pretty much just delete the boost namespace. I don't mind doing that if there's interest. Definitely would welcome a contribution, too.
Half of what makes the branching version faster is that you're avoiding a bunch of useless stores. Your code is not doing that. Change it to if(likely(i &gt; 255)) { i = 255; } to achieve the desired effect.
I have half a mind to make a version that uses by evolving bytecode VM instead of a neural network.
writing production level C++ code for years for big companies, it is only last month I learnt how to link manually a library. My appreciation for giant makefiles in my source codes have grown a lot.
Good start :) You may find this (http://unitary.fund/) useful for keeping your motivation up and your aims high :)
You can do cool things with makefiles such as force recompilation if you change compiler options. I use makefiles often as a short hand for complicated commands. If running a program involves first copying data, then setting some environment, then actually running, I make a "make run" line in my makefile. Et cetera.
This looks cool. I have a question though, the readme says " the only two languages with builtin support for typeclasses seem to be Haskell and Rust" but aren't protocols in Swift typeclasses?
It says "503 Service Temporarily Unavailable".
More bizarrely: Why is **Turbo** C++ so popular there (rather than standard C++)? 99.9% Turbo C++ Stackoverflow questions appears to originate there.
It's not that C++ is popular in India, its that there are so so so many Indians who post tutorials or answer on SO across all the languages. Why that is, I don't know. I think it's one of many ways to get them to stand out to employers.
Should I learn Turbo C++? 
No. Stick to C++. 
Because the professors there don't teach anything newer.
What good things have you heard? From what source? Or did I miss sarcasm? Turbo C++ has been obsolete for about 20 years now. I would be surprised if any significant amount of new software were developed using it.
Indians are more frequently fluent in english than the chinese and they form a very significant part of the total human population, and an even larger part of the total human population that lives in regions where computer science is frequently available as a field of study.
Only if you own a time machine
OK, sounds like a plausible explanation. But I'm curious: What could be the motive of the professors to teach an ancient dialect that is (as far as I know) hardly used at all in the industry.
Removed as off-topic.
Great interview:)
That, and there are 1.3 billion Indians. So, assuming that India "produces" proportionally the same amount of CS PHDs compared to US+EU, then the occurrence of {YouTubers ∈ programmers} could even be a half of what the US+EU's combined is (900 million citizens) and there would still be more Indians C++ videos on YT. 
I don't think there is a "motive". For whatever reason those professors obviously have not tried to keep up with the developments in the field. That happens with university professors everywhere, even though they're job is to keep up with developments in the field. Some people in general don't like learning new things. They learn the one programming language in university, it was hard, and so they don't want to learn any more because of how it made them feel. Lots of other people just don't realize things develop. There are lots of C programmers who don't know how many of their boilerplate problems have already been solved by C++, and old-school C++ programmers who don't know their problems are solved by C++14.
Thanks!
I'd call that a mistake of the language ;) What was the rationale? Cause you can just make it non-inline if you need a unique address.
I wish they paid more attention to compile times though. Solutions like compile-time regex are awesome and she shows it generates efficient code but it should be weighed against their compilation cost: https://www.youtube.com/watch?v=NPWQ7xKfIHQ
I still hope you can push P1105 through.
I really hope your version of the freestanding library will exist eventually in some form. It is so damn annoying not having access to perfectly safe parts of the STL in exception free environments because the compiler vendor hasn't done the work to separate that stuff out. For example in Windows we have a type called `wistd::unique_ptr` that is almost identical to `std::unique_ptr` but can be used when the STL isn't available.
Thanks for your reply. I tried out the free version of C++ Builder a year or two ago myself, but it seemed broken out-of-the-box and I just got a bad vibe, like it'd be an uphill battle getting productive on it. Added to that, the local distributor kept asking me how my "evaluation" was going and how many licenses I was likely to purchase. I have played with Lazarus and you're right, it's pretty much what Kylix was but modern, not sure why I didn't think of that.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9xukn5/a_few_questions_before_i_learn_qt/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Oh, that makes perfect sense. Thanks.
No, **you** are given. &gt;Discussions, articles, and news about the C++ programming language or programming in C++. For C++ questions, answers, help, and advice see r/cpp_questions
this is codde...... \#include &lt;iostream&gt; using namespace std; int main(void) { int n, x, y; cin&gt;&gt;n&gt;&gt;x&gt;&gt;y; int arr\[60\]; char map\[20\] = {}; for (int i = 0; i &lt; n; i++) { cin&gt;&gt;arr\[i\]; } sort(arr, arr + n); int cost = 0, sumd = 0; for (int i = 0; i &lt; n; i++) { sumd = 0; int j = arr\[i\]; if (map\[j+100\] == 1) { while (map\[j+100\] == 1) { sumd += y; j++; } } map\[j+100\] = 1; if (sumd &gt; x) cost += x; else cost += sumd; } cout&lt;&lt;cost&lt;&lt;endl; return 1; }
No, the Swift protocols are dumb interfaces: they lack almost all features of typeclasses. Instead Swift has monkey patching in the form of "extensions". Being a very flexible technique (albeit a little dangerous one) monkey patching allows one to easily emulate typeclasses almost in their full glory using protocols and extensions (of a protocol and with a protocol). But strictly speaking a possibility of emulation isn't the same as a language-supported feature. More so, it seems that multi-parameter typeclasses (without functional dependencies of all but one parameters on that one) aren't easy to emulate in Swift.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9xv9os/differentiate/e9vfg2k/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt;Sadly, `optional&lt;T&amp;&gt;` died in a fire, which is a shame as I am afraid it will encourage people to use non-standard optional types. Thanks, JeanHeyd Meneide for trying to make thing happen. The best path forward might be to completely replace `std::optional` with a new type with more generic, better semantics. `std::maybe`? `std::box`? Please don't introduce any more of these meme types until sum types are added as a language feature.
Any progress on the CTAD extensions? 
Yeah, don't introduce new types. Just fix the existing `std::optional&lt;&amp;&gt;`
Introducing `std::optional&lt;&amp;&gt;`. We currently have to use `boost::optional` or the insanely inconvenient `std::optional&lt;std::reference_wrapper&lt;&gt;&gt;` workaround. I don't see a problem with supporting reference types. 
That was killed in Lewg really badly, i don't expect it will ever be proposed again in that form. We tried though !
Do you want to Get Rich? Yes? Then watch this one: https://www.youtube.com/watch?v=7FQwAjELMek
Your presentations improve with time and are pleasant to follow. They provide some great... Value!
Hopefully CTAD for partial template argument lists makes it.
Welcome to the embedded system world.
Could you please elaborate on how string_view makes it worse? 
What parts of optional-ref do you use? Rebinding? Operator*? Is it ever const? Can you modify T when const? What do you do with it?
coroutine should be postponed till we got a namespaced keyword. I don't want to co_prefix co_every co_routone co_keywords.
TU with std::regex is compiling longer than TU with CTRE included and used, I don't know how better it should be :)
The last time I used it (or tried to use it) was a member function giving out values from an internal unordered_map. The function is const and the value may not exist. What do you return if throwing is unwanted? Right, an optional. But wait, we don't want to copy the value. So it should be a reference. An optional reference. "No, that doesn't work! You can use a pointer!" You mean a `const Value const*`? What if someone doesn't check for nullptr and dereferences the pointer? Bummer, that's UB. So yeah, we had internal discussions about this and there's some controversy on whether this feature makes sense. I personally understand "philosophical" objections with having optional references, but on the other hand appreciate having consistency and symmetry in a language as it greatly improves readability and teachability. 
I can't use clang plugins if I'm writing in a different language - the C API is all there is.
Niall and I have been debating error-handling library design for a couple of years and I've been working on error handling since 2005 (Boost Exception, p0640r0). The main point of contention in the debate is whether or not it is appropriate to embed error objects in the object returned by functions which may fail. I think that it is not acceptable to physically couple (by the static type of the returned object) functions which may fail with the error types returned by lower level functions they call (and lower level functions they call...), while Niall, judging by the fact that `outcome` keeps acquiring more and more template parameters, seems to not worry too much about that coupling. However, LEAF is the first error-handling library I've written which meets my design goals at nearly zero abstraction penalty (no dynamic memory allocations). So who knows.
With string views it is easy to have dangling references. One example that has been given is the addition of two strings or views and then returning a string view. Storing string views is also quite dangerous. These are errors that can happen easily and which are hidden when using auto or template parameters. Like you change strings to string views, everything compiles but deep down there is an addition and thus undefined behaviour. 
Saved you a search - http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1207r0.html
&gt; What if someone doesn't check for nullptr and dereferences the pointer? I've never quite understood this argument, as dereferencing a null optional is also UB. The most convincing reason I've heard for `optional&lt;T&amp;&gt;` is for consistency, that generic types don't have to do any sort of specialization or fancy footwork for reference types. Thay being said, I have yet to see a convincing use case for it. In general, one of the core attributes of a reference is that always points to the same object, so I don't believe it's a good idea to have any sort of mutable container of references (and optional itself is something of a mutable container). So I sort of side against `optional&lt;T&amp;&gt;`.
Between the options of get it now and suffer the bad design for 10 years or get it 3 years later with no suffering. I choose the later.
Depends on what you consider bad design. The only thing you mentioned was the spelling which imho should definitely not be a blocking issue . Some of the other issues I've heard over the years are more troublesome, but in the end, you'll never have a feature that is perfect for everyone you'll always end with a compromise. 
What features are they missing exactly? You can't mean higher kinded types, since Rust doesn't have them either. Are you referring to the fact that existentials aren't always available? Because that's largely considered an implementation deficiency, and there's already [active work to allow them in more places](https://forums.swift.org/t/lifting-the-self-or-associated-type-constraint-on-existentials/18025). Also, aren't associated types roughly equivalent to multi-parameter typeclasses?
Generic comments on this benchmark's presentation: * It is difficult at first to figure out what the units are since the units are where I would expect the title to be. * The change between seconds and Mop/s is annoying. It is made worse by the fact that it is in tiny font and not in the location where I expect the units to be. * It lists the GCC options but not the clang options. * I don't know what these benchmarks are testing. I can guess by the some of the names, e.g., memcached. However, others like Himeno or John the Ripper, I have no idea. * The numeric precision is way toooo great. E.g., 47827811 vs 46179707. I don't know why I need more than 3 sig. figs or precision, unless there is some sort of guarantee that there is no system variability around that. E.g., if the std. dev. of the test is 8%, that wipes out the average which differ by about 3.5%. Even if the variability were 0, I would not be making decisions of the basis of 47827811 vs. 47827819. * I don't need to see GCC 9.0.0 20181112, they can truncate it to GCC 9.0.0 and then make a footnote that it is the 20181112 build. 
I'd like the following assertion to be true for all values of all types: assert((a == b) || (a != b)) It is hard to reason about code when this assertion can fail. Unfortunately, this assertion doesn't hold for all standard types, but, fortunately it does for all integer types. I don't want that to change, but it would if integer NaN were introduced (with the expected semantics). 
This is a vague question, and not related to the cpp language itself. I believe you should figure out what exactly you’re trying to accomplish first before deciding that “game objects” are the solution. And r/gamedev will have more domain specific help there. 
Thanks
What I don't understand is: removing the else of the shorthand if (i.e. avoiding an additional store) is entirely different code, it's doing less work. So of course the compiler generates better code for it....?
Well, I you want my opinion on coroutine. I don't like the return type of coroutine must have members with specific identifiers which is treated specially by core language. Yes we have the same design with Range-based(begin/en) for and structured binding(get), but on coroutine, there are so many of them. It's really confusing and hard to learn.
\`\`\` \#define await co\_await \#define yield co\_yield \`\`\` It would be nice to have a standard library header containing just that, but you can always put it in your own header. 
I see your point but this might be about what we are used to today. What if you could compare int to NaN to check your self but if you compared int to int where one or both where NaN it would trap/throw much like how divide by zero does today? 
This seems relevant to cpp due to the high degree of interoperability with c++, it is also a big project being undertaken in c++ alongside common lisp. That and this is just freaking impressive
I don't know, I assume the talk was aimed at people unfamiliar with processors. It's also a weird example, because the benefit is very marginal and can easily go wrong.
I won't be watching this since I have zero idea what the talk is about. Save nonsense titles for naming sitcom episodes. If you are going to do a professional talk just label it clearly.
Or you could listen to the first minute and get an idea on what it's about without coming off as a twat? 
This video is way more interesting than the LLVM/C++/Lisp content!
This was a talk at cpp con. As such, I'm sure all attendees assumed that it was serious. The conference program might even have given an abstract, though I'm just guessing here. It's very nice of the conference to post videos of the talks on YouTube so we all get to watch them for free.
This proposal gets linked often on /r/cpp, but I haven't heard any recent news about it. I really hope it moves forward because the lack of sum types / lvariants is one of the biggest holes in the language IMO. I feel it every time I implement double-dispatch visitation or try to use `std::variant`.
I'm not sure what you are trying to say exactly. The problem is the title, not if the talk was 'serious'. No matter how much explanation there was live, it doesn't excuse a title like this. Also the talks are free for a reason. The conference gets speakers and money, the speakers get exposure. I like that the talks are out there and I feel like it works out for everyone, but it isn't a gift.
https://www.boost.org/community/generic_programming.html#tag_dispatching Basically what you want here is a switch(type) construct. There are several ways to emulate this. In D you'd just use static if and reflection.
To be more precise: it was a lightning talk. Lightning talks are entertainment and you typically don't pick the lightning session for an individual talk, bit a larger series of very different talks.
Missing `#define return co_return` — what could go wrong?
&gt; Also the talks are free for a reason. The talks are free because the organization is a non-profit foundation (Washington 501(c)(6)). There are for-profit C++ conferences where recordings of the talks are not made available for free to the public.
How is it clearly labeled?
You clearly understood that this was a silly talk since in your original post you referenced sitcom episodes. That's exactly the point, this is intended to be a silly and entertaining talk rather than a serious and "professional" talk. As such the title conveyed the correct impression to you.
Most developers will never see or touch any of the coroutine customization points. It is for hobbyists or experts. Complexity in Coroutines TS is layered: Top layer is for everybody (\~2,000,000 people): * Safe by default, novice friendly * Use coroutines and awaitables defined by standard library and boost and other high quality libraries Power Users have to know await\_resume/await\_suspend/await\_ready to develop awaitables (\~10,000?) * Define new awaitables to customize await for their environment using existing coroutine types Experts: (\~1,000?) * Need to know all, to define new coroutine types True, at the moment, Coroutines come naked, just the language facility, but, you have to start from somewhere. BTW, if you are an expert interested in developing new coroutine types and haven't seen this talk, it can help you to get started. It shows how to bootstrap yourself on Linux from nothing but Coroutines TS and Networking TS. [https://youtu.be/UL3TtTgt3oU?t=278](https://youtu.be/UL3TtTgt3oU?t=278) 
Correct impression? It didn't convey anything, I have no idea what it is about. I don't care if it 'silly' or not. 
It conveyed that it was a silly and entertaining talk. If you're claiming you really didn't get that impression from the title then you're being disingenuous or lack basic comprehension.
After watching the video I think the title is perfect. 
Send me an email if you want the source code. eldor5zufarov@gmail.com
Send me an email if you want the source code. eldor5zufarov@gmail.com
The epilogue section is confusingly labeled “foreword”.
I'm really curious to see how the actual interop works.
I can't tell you how weird it feels that std::string still doesn't have a split() function. I read that this is due to some compatibility rules([Discussion](https://www.reddit.com/r/cpp/comments/5dxnwm/why_doesnt_stdstring_have_a_split_function/)), but to be honest I still don't agree that we have to make this so complicated !
Uh-oh, the fun police are here.
&gt; CTAD for partial template argument lists Like `std::tuple&lt;int&gt;(1.0, 1)`? Personally I feel that it goes a bit too far.
Great little talk!
I'm curious what you mean by east const being more consistent with C++ grammar than west const. You don't see "int static" or "func() void". I'm actually having a hard time thinking of any other cases in the language that are backwards from normal English. Maybe what bothers me about east const is that "const" is a whole word reserved token, while a pointer is just another symbol? Although "int pointer" doesn't sound as wrong to me as "int const" does. Just curious as to what's the foundation for why you believe east const is more consistent with the language than west const.
This is not a good talk
CLion with WSL works very well for development. My experience with Visual Studio has been quite good though, our main problem is writing CMake files that work with both vcpkg and Linux (looking at you FFTW).
Could you be more descriptive on why you think it is not a good talk? While I think there could be debate on the title, there was still value in some of the takeaways.
I'll never understand everyone's obsession with the meaning. We'r have so many badly named things in c++. Does it really matter if a keyword gets a two letter prefix or not?
`auto func() -&gt; void` is a thing now. 
Oh yes, C++ and its weak enumerations. \*sigh\* That’s the one thing I really miss from Delphi … I like that you use a generator instead of trying to force the additional functionality into templates and macros. It keeps things clear and readable. If you have a generator in your project already, imo it’s the natural way to enhance enums. I also see some problems in your implementation. You probably have reasons for the atrocious hungarian notation and for not using `enum class`. But you’re breaking the type system without needing to. The problem is *count*, *min* and *max* lumped together with the enumerators. From a type system perspective that’s wrong. For manually written enums I can understand why people do this from a maintainability point of view. However, with generator support there’s no reason to use that hack. An enum represents a set of distinct values. *Count*, *min* and *max* are not members of this set. They are metadata describing properties of the enum type. And that’s how they should be modelled. Otherwise when calling a function that returns a value of such a lumped enum, as a diligent developer I have to check for the three enumerators that are not in fact enumerators – similar to pointers and that pesky `nullptr`. Even worse: I lose the compiler warning when I write a default-less `switch` over all the enumerators and forget to handle one. With a generator that ensures correctness I don’t see a reason to not pull the metadata out of the enum. Thinking one step further: Maybe the metadata doesn’t have to be publicly visible at all. Do you really need iteration over the enumerators for everyone? And if you do, maybe providing iterators is the better choice. After all in C++ that’s the idiomatic approach to iteration. Internally having *count*, *min* and *max* is useful, though. It simplifies at least the implementation of the `isValidEnum()` function.
- advocates using shared_ptr with offsets as a means of avoiding allocations, instead of just....providing an allocator - benchmarking cout without turning off synchronisation with stdio - takes entirely too long to get to the point - yes, allocating everything up front is good, we didn't need 50 minutes of iteration on the design to get there
But super fucking pointless most of the time.
I think variadic arguments like in tuple are not part of the proposal.
Writing 100% of your code to be consistent with the 1% (const pointers) doesn't sound right.
Why are commands named as if they are properties? "Sort" and "filter" are commands. "Sorted" and "filtered" are properties of a set. 
I always understood stuff like "sorted" and "filtered" as "get a sorted version of this object"
I converted to East const the first time I spent half a day debugging a compilation error which just didn't make sense to me. The problem ended up being a macro (ah!) buried behind another one or two layers of macros (ugh...) which was essentially: #define CONSTIFY(Type_) const Type_ And I was the first one, I suppose, to happen to pass a pointer (say, `int*`) as an argument... I suppose we could rule that the issue has to do with macros operating at the syntactic layer rather than the semantic one, or that the writer should have used `add_const` (though it was before C++11, so no luck). However, it did turn out that rewriting the macro as: #define CONSTIFY(Type_) Type_ const was a minimal change which fixed the problem, because `const` and `volatile` generally apply to what's on their *left*, apart from the case in which there's nothing on their left (West const).
Speaking out, you may not believe that C++ Network takes 20 years to enter the standard, which is enough for a language to mature. 2006~2026(Pessimistic expectation). I hope that the C++ standard library can be as rich as Go. Like rust is not bad. [rust: std::net](https://doc.rust-lang.org/std/net/index.html) 
Not the original commenter, but I'm also an East conster, and for me it has far less to do with consistency with english, or grammatical consistency with C++ (there are already many issues with both of those, so they're both weak arguments in my opinions) , as it does that I simply care about the type more than const most of the time, so I want to see that first when scanning code. Foo const&amp; Bar::Find(SearchParam const&amp; p); Conveys the important information more quickly than const Foo&amp; Bar::Find(const SearchParam&amp; p); In my opinion...
I think it's a factor of many things, but the obvious come to mind: 1). This is pretty common in modern, high-level languages like Python. `sort` modifies data, `sorted` returns a modified copy of said data, without changing the original. 2). Difference between the unconjugated or present and past/passive tense (English basically has no conjugation rules, so it's likely a conflation of all of these). To sort is an action, which suggests you modify the underlying data. Sorted clearly does not imply this, since the data is/was sorted. This doesn't imply getting a copy, but it's a lot easier when you use it as a convention than `sort/sorted_copy` or `sort/sort_assign`, IMO.
Being a noob at all this, I’ve never come across East const before- is this something to worry about?
It's a bit frustrating that optionality of a function parameter (and optionality of variables in general) has to be expressed by different means, depending on whether the parameter is passed by value or by reference: ScalarAlgorithm { ScalarAlgorithm(…, double regularization); ScalarAlgorithm(…, std::optional&lt;double&gt; regularization); }; VectorizedAlgorithm { VectorizedAlgorithm(…, const Vector&lt;double&gt;&amp; regularization); VectorizedAlgorithm(…, const Vector&lt;double&gt;* regularization); }; Compare to Rust, where in order to get optionality, you just add Option: fn scalar_algorithm(…, regularization: f64) { … } fn scalar_algorithm(…, regularization: Option&lt;f64&gt; { … } fn vector_algorithm(…, regularization: &amp;f64) { … } fn vector_algorithm(…, regularization: Option&lt;&amp;f64&gt;) { … } Additionally, in C++, raw pointers are ambiguous. For example, given a raw pointer variable, we need a specific mention in documentation to ensure that it doesn't point to an array. Many gurus recommend to only use raw pointers when dealing with allocation, but not to pass/store an optional reference.
`#define CONSTIFY(Type_) const (Type_)` should also work, right?
[This article](http://slashslash.info/2018/02/a-foolish-consistency/) defends East const. There's also a petition where you can register support for East const -- [http://slashslash.info/petition/](http://slashslash.info/petition/) . &amp;#x200B; &amp;#x200B;
It doesn't appear to [on godbolt](https://godbolt.org/z/Etcw7L): #define CONSTIFY(Type_) const (Type_) CONSTIFY(char*) transfer(char* const s) { return s; } Yields: &gt; &lt;source&gt;:3:10: error: expected unqualified-id &gt; CONSTIFY(char*) transfer(char* const s) { return s; } &gt; ^ &gt; &gt; &lt;source&gt;:3:10: error: expected ')' &gt; &lt;source&gt;:3:1: note: to match this '(' &gt; CONSTIFY(char*) transfer(char* const s) { return s; } &gt; ^ &gt; &gt; &lt;source&gt;:1:31: note: expanded from macro 'CONSTIFY' &gt; #define CONSTIFY(Type_) const (Type_) &gt; ^ &gt; &gt; 2 errors generated. &gt; &gt; Compiler returned: 1
I hope more will sign this petition - [http://slashslash.info/petition/](http://slashslash.info/petition/) . &amp;#x200B;
Not something to worry about. It is in itself not hugely consequential, and there is also nothing important in C++ that requires you to know east const in order to understand it.
Your particular example is meant to be covered by ranges, I think. It should end up as something like `make_range(x) | f | filter | transform | sum`
Yes, both UFCS and overloading operator. are at dead end - they are rejected and there are no new developments that need reevaluation. Also note, there are plenty of features for 20 and people are quite occupied already. 
The title went over your head. The title is phrased as "Riding Hood Little Red" (noun-adjective) whereas normal English speakers would say "Little Red Riding Hood" (adjective-noun). The talk is a comedic play on how that kind of naming conflict arises in C++. It's actually a perfect title for the subject.
I really like both ufcs and op. Nim has both in and also has a pretty much identical overload resolution system and a very similar template (called generics in nim) system. It works quite nice, and helps you pick and choose what bits of “OOP” you want to use. I think it needs someone to fight for it in c++, and so the work of gaming out all the edge cases.
No.
That looks good. I want that.
Yep, and that's superior too. A pipe is different from chaining some random function calls in a train wreck
Yep note though that only makes sense in languages with reference semantics like Python. For C++ I'd strongly recommend 'sort'
This distinction is mostly relevant for languages with reference semantics though
The way I see it, the only (but significant) advantage of smart references over smart pointers is compatibility with code that uses value semantics (as opposed to pointer semantics). And since the "dot" operator can't be overloaded, smart references are otherwise inferior to smart pointers. So it seems to me that the preferable way to implement customized reference types would be to implement a customized smart pointer, then if needed/desired, create a corresponding smart reference that simply stores the smart pointer and calls any member functions/operators through the smart pointer. For me, the library would be more appealing/useful if it supported this strategy. (My understanding is that it currently doesn't?) There are already a bunch of smart pointer implementations out there. Why not allow people to leverage existing smart pointers to minimize the effort needed to create corresponding smart references? A specific case of interest to me are the memory (/data race) safe smart pointers of the [SaferCPlusPlus](https://github.com/duneroadrunner/SaferCPlusPlus) library. It would be nice to have corresponding smart references. Let's say for example, you wanted to create an "owning" smart reference that stored an `std::shared_ptr`. The library currently doesn't support this? &amp;#x200B;
Including allowing member functions to be called like free functions? That's annoying.
`sort()`, `filter()` should always have active component, they are **verbs** after all. I always prefer `vec.is_sorted()` over `vec.sorted()`, but those denote properties of the thing. Something like `vec.filtered()` or `vec.filtered(param)` makes no sense in context that you are suggesting, it should retrieve the property ("is the thing filtered (by param)", true or false). Only exception I can make here is if you add `get_` or `make_` or some other verb and make it `object.make_sorted(thing)` or `object.get_filtered()`, but even that seems somewhat confusing (does it return sorted/filtered thing or does it modify the state? Who knows).
1. why in an IDE vs a text editor? 2. why should we do your homework?
I try my best to do it! but time is getting out! :( &amp;#x200B; help me if you can do any of it!
LEAF works perfectly with exception handling as well, in this case you get a more elegant Boost Exception. :) Here is the same example program using LEAF, written with and without exception handling: https://github.com/zajo/leaf/blob/master/example/print_file_eh.cpp https://github.com/zajo/leaf/blob/master/example/print_file_result.cpp
Earlier today somebody recommended notepad++ apparently it has syntax highlighting.
Operator dot is dead but is `using` inheritance is? Because that proposal seemed to play nice with other rules.
~~I thought range-v3 made syntax like this possible?~~ Edit: ignore the idiot with poor reading comprehension and a goldfish memory. 
Yes, but ideally we would have a dedicated operator for that, with the correct precedence and associativity, instead of hijacking `operator|`. Something like proposed by [P1282](https://wg21.link/P1282).
Yet it would be very nice to `std::array&lt;string&gt; arr = {"hello", "world"};` &amp;#x200B;
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9y8xew/beginner_needs_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The Standard has become less and less relevant as the language has split into two diverging categories of dialects: 1. Those which are based on the idea that the Standard is merely intended to describe a baseline set of behaviors which all implementations should support, regardless of their target platform and intended purpose. Quality platforms should be expected to uphold the Spirit of C described in the published charters and rationales for the various standards, recognizing that implementations intended for various tasks should treat the principle "Don't prevent the programmer from doing what needs to be done" differently, according to the tasks in question. 2. Those that are based on the idea that the Standard is intended to describe everything programmers have a right to expect from implementations, and that unless an implementation makes explicit promises to the contrary, programmers have no right to expect it to uphold precedent in any cases not mandated by the Standard. Unless the Standard can recognize enough behaviors to satisfy the needs of at least a substantial plurality of programming tasks in various fields, the dialects used in those fields will continue to diverge from the Standard, making the Standard less and less relevant. The authors of the Standard expressly state in the charter that they do not wish to preclude the use of C as a form of "High-level assembler". If that is true, they should define a behavioral model consistent with that and a category of implementations that uphold that model precisely. Then, to make the language useful for purposes not requiring such a rigid model, it should define ways in which implementations intended for various purposes may diverge from that model, and ways in which programs could invite or forbid such divergence. A few of the tasks that programmers do with C require a very tight execution model. A few can get by with an incredibly loose execution model. Most require an execution model that is in at least some ways tighter than what the C Standard presently provides. Efforts to define a single execution model for all purposes are fundamentally misguided because different programs have different needs. A single execution model that would satisfy the needs of even 2/3 of C programs without forbidding optimizations that would be useful for at least 1/3, would need to be extremely complicated, if it could be designed at all. By contrast, it would be fairly simple to devise a set of three execution models whose total complexity would be far less than that of a single model, but would serve most programs better than any single model ever could. Essentially: 1. Treat all memory accesses literally. 2. Assume that reads and writes can be cached and deferred in the absence of evidence suggesting otherwise, but treat things like pointer casts and volatile accesses as prima facie evidence that the real and abstract machines need to be synchronized. 3. Assume that no storage which is ever accessed as one type will be accessed as any other within its lifetime. The first model would be compatible with any expectations programs might have about how memory would behave. The third would be satisfied by the present behavior of gcc/clang, and would meet the needs of a significant number of programs in some fields, even if it would be insufficient for many programs in other fields. The middle model would meet the needs of most programs that for which the third would be inadequate, while allowing most of the optimizations that would be forbidden by the first. If the Standard were to define all the behaviors necessary for a program to do what it needs to do without needless obstacles, then it might be reasonable to suggest that quality programs should limit themselves to Standard-defined behaviors. Unless or until that happens, however, the vast majority of code in many fields will need to rely upon UB, making the Standard useful only as a set of baseline guarantees for implementations. 
I didn't fill the form only because it forces to upload writing a cover letter. Which in my opinion is a total waste of time! 
You can already have it. ranges-v3 is supported by the 3 major compilers.
Looks too weird.
Math had that before computers were invented. The point is having that in the C++ standard library.
The pipe operator is for piping. It's already used in math
I haven't heard of this proposal, and I can't find anything about it from the description. What is the name/proposal number?
Can you provide a link to more information about this? Thanks.
That's a good point. I love the ranges library and the pipe method of composition. But I'd still love to be able to easily and effectively extend classes like std::string or even built-in types.
Oh, I understand there are plenty of other C++20 features, I'm just kind of surprised since operator. was nearly merged into C++17 and then seemingly just disappeared.
That is exceedingly cool. What is missing are two examples that I usually code first: detect cache size, and effects of strided access. Ok, detect cache associativity..... Effects from TLB size. (Those are in my HPC book, btw)
I guess I am lucky. I was totally in need of something like this. Thank you very much. 
This is such a nice idea! For Linux I strongly recommend to add some shell scripts (or more python) that make use of the Linux perf counters (perf stat, perf record/report, etc.), so that you can demonstrate the difference between those metrics in the programs that showcase the issue. Most of the time with `perf stat` is enough, but who knows how much better this could get! Giving the lack of examples for perf, this has got a big potential.
Cool, might mess with it at some point in the near future.
BTW, it's been some time I wonder about this and probably should do some benchmarking. Would batching software prefetchs for strided memory access help (for a linear algebra lib for example) or are hardware strided prefer hers already doing the best that can be achieved?
Got an equivalent set of programs for embedded CPUs, in order to showcase problems with them? Mainly unexpected progmem loads, unexpected LHSs, and such?
In your examples, one is incorrect, so to me that makes a case for east const. const char\* ch; and char const\* ch; Are equivalent, so const char const\* ch has a redundant const. For this example, I would write it as. char const\* const ch; And actually, pointers are how I came to be an east-conster because I was working in code that would have double and triple indirection, so you'd see code like; int\* const\* const\* i; &amp;#x200B; Which I found confusing if I didn't start stacking const's on the right of the type. 
*Or* we could add first-class not-null types.
This is like asking whether a cat should be a mammal. It just is. The merge algorithm inherently operates on sorted ranges. (If the sequences are like 10,20,21,22,23,30 and 15,25,35 then it can take several elements from one range consecutively.) If you want “every other element from each range”, then that’s some kind of interleave algorithm.
From what I heard, operator dot died because it was too difficult to make a reference implementation - it couldnt work due to some compiler machinery
You mean taking interleaved strided accesses and reading them as one? Then you still have to pick them apart which negates the benefits. But maybe I'm misunderstanding you. Code up some model of a use case, I'd say.
The main issue with the pipe operator is that it has higher precedence than `&amp;&amp;`, `||`, `?:`, and a few others. This can cause unexpected behavior in some cases, and once ranges become common place will probably become another "gotcha" thing we have to teach. I admit, I don't think it's that bad. But this could be an oportunity to introduce a new operator with proper precedence that can be used not just for ranges, but also for other things like coroutines or monadic interfaces. That's why I like P1282.
HPC book? Do tell?
Unexpected left hand shift? What’s wrong with that?
https://bitbucket.org/VictorEijkhout/hpc-book-and-course
 I can't tell if this sarcasm, but if not, LH[Load Hit Store](https://en.wikipedia.org/wiki/Load-Hit-Store)S is a common abbreviation for 
This is great, thanks for writing it.
No, not sarcasm. Never heard of that before, but it makes sense. How do you avoid things like that?
You're welcome. Maybe you can leave a review on amazon for the printed edition?
&gt;There wouldn't be anything inherently wrong with a cat not being a mammal. When just wield that "power of some scientists" and call/will the result of `merge` interleaved. Problem solved. It won't actually be like that (and not only because `merge` takes sorted inputs, but also because it simply does different thing), but it should be good enough for you with such approach to the world.
Probably a very dumb question, but why am I getting ```error: ‘_mm_hint’ has not been declared``` ?
I heard it has a built-in compiler
Figured it out, needed: ```#include &lt;x86intrin.h&gt;```, or ```#include &lt;xmmintrin.h&gt;``` into prefetching.cpp.
I haven't read the paper on operator. but I assume it would be the same as overloading operator-&gt; I do believe it is great that it is dead because it would be too confusing and you'd be in doubt everytime you see a variable being accessed. At least with operator-&gt; it is clearer because you know an object that is not a pointer doesn't has it by default where as the dot is used everywhere. As for UFCS, I see really little use and it has the same problem as operator., you'd be in doubt whether the function is part of the object or not. It also gets problematic once you start dealing with namespaces.
How about you overload `,`? It has the precedence you want after all.
If you want interleaving then you are assuming that your two ranges are the same size. Merge has no such restriction. Regardless, if you write your comparison lambda as the following, it should interleave: auto cmp = [first = true] (const auto &amp; a, const auto &amp; b) mutable { first = !first; return first ? b : a; }; 
Pipes, I meant. Pipe syntax even. 
&gt; If you want interleaving then you are assuming that your two ranges are the same size. I don't think there's anything saying an interleave algorithm can't put the extra elements at the end just like a merge would. If you didn't want that behavior you could always check the sizes of your ranges first. &gt; Regardless, if you write your comparison lambda as the following, it should interleave That's what I did but it only works with sorted input or MSVC fails an assert because it enforces the standard.
So you're saying that the extra 76 lines of code are just an inlined version of `memcpy`? That's a reasonable hypothesis. But in that case, I would expect to see that the inlined version would be faster than the out-of-lined, library version of `memcpy`. Right? http://quick-bench.com/bpDNnMLZNAIGO-MkSbNtz6Iw-vc What I see on Quick Bench is: The `vector::resize` itself is extremely slow. The hand-coded version that uses `memcpy` is blazing fast. The hand-coded version that inlines memcpy as a loop over bytes is also blazing fast. The hand-coded "cleaner" version that calls the move-constructor of `unique_ptr` is just about as slow as `vector::resize`. I assume the difference between the first and last cases is due to the fact that in the last case, we skip the destructor of `unique_ptr`. I cut-and-pasted the benchmark code into my terminal and ran it with vanilla Clang. The results matched up well with Quick Bench: ``` $ clang++ -std=c++14 test.cc -lbenchmark -O3 $ ./a.out 2018-11-18 22:01:09 Running ./a.out Run on (4 X 2400 MHz CPU s) CPU Caches: L1 Data 32K (x2) L1 Instruction 32K (x2) L2 Unified 262K (x2) L3 Unified 3145K (x1) ---------------------------------------------------------------------- Benchmark Time CPU Iterations ---------------------------------------------------------------------- ResizeIt 34098 ns 31809 ns 22428 ResizeItByHand1 8333 ns 7990 ns 88015 ResizeItByHandOptMemcpy 8004 ns 7728 ns 91177 ResizeItByHandOptMemcpyCleaner 20443 ns 19569 ns 35217 ``` Then I ran the exact same benchmark using the P1144 version of libc++ ([here](https://github.com/Quuxplusone/libcxx/tree/trivially-relocatable/include)). The results of this run were the same as the first run, except that `vector::resize` magically became as fast as your hand-coded `memcpy`. ``` $ llvm/build/bin/clang++ -std=c++14 test.cc -lbenchmark -O3 $ ./a.out 2018-11-18 22:02:00 Running ./a.out Run on (4 X 2400 MHz CPU s) CPU Caches: L1 Data 32K (x2) L1 Instruction 32K (x2) L2 Unified 262K (x2) L3 Unified 3145K (x1) ---------------------------------------------------------------------- Benchmark Time CPU Iterations ---------------------------------------------------------------------- ResizeIt 8905 ns 8164 ns 90339 ResizeItByHand1 8592 ns 7880 ns 87497 ResizeItByHandOptMemcpy 8152 ns 7721 ns 92479 ResizeItByHandOptMemcpyCleaner 21395 ns 19648 ns 36413 ``` My conclusion is that those extra 76 lines of code are not "just" an inlined memcpy. They're doing something much slower than memcpy. I don't know what it is, but it's 3x slower than your hand-coded versions, and 3x slower than the P1144 library version.
The standard is pretty clear that they are required to be sorted: [http://eel.is/c++draft/alg.merge](http://eel.is/c++draft/alg.merge) &gt;*Requires:* The ranges \[first1, last1) and \[first2, last2) shall be sorted with respect to operator&lt; or comp[.](http://eel.is/c++draft/alg.merge#1.sentence-1) &gt; &gt;The resulting range shall not overlap with either of the original ranges[.](http://eel.is/c++draft/alg.merge#1.sentence-2)
&gt; 2 Requires: The ranges [first1,last1) and [first2,last2) shall be sorted with respect to operator&lt; or comp. The resulting range shall not overlap with either of the original ranges The standard requires them to be sorted and MSVC enforces that, gcc and Clang don't.
I wonder how MSVC's implementation manages to check whether the ranges are ordered while conforming to the complexity requirement? &gt;*Complexity:* Let *N*=(last1 - first1) + (last2 - first2): &gt; &gt;[(4.1)](http://eel.is/c++draft/alg.merge#4.1)For the overloads with no ExecutionPolicy, at most *N*−1 comparisons[.](http://eel.is/c++draft/alg.merge#4.1.sentence-1)
Really cool, nice work!
how does MSVC enforce that? That seems terribly wasteful.
They have a debug only assert that just checks if a range is sorted.
This is great! Would be good to see more performance numbers, e.g. a perf output for [branch-target-misprediction](https://github.com/Kobzol/hardware-effects/tree/master/branch-misprediction#branch-target-misprediction).
std::merge requires the inputs be sorted with respect to op&lt; or the provided comparison function. Your lambda isn't going to meet that requirement.
That’s true. It’s not standard compliant. But it goes work with libc++ and libstd++ implementations of merge
Ah thanks, you're right. I'm on Windows, guess I haven't updated my gcc in a while.
I'm hinting at another flaw with using `std::merge` in this way - you are assuming a lot about the implementation. If the implementation is allowed to call the predicate an arbitrary number of times in debug builds then you could get different results from your stateful comparator in debug vs release builds. Consider also that the implementation is free to copy the comparator as much as it likes. It could create a fresh copy of the argument every time it wants to call it, for example.
It didn't go over my head, I just have very little tolerance for nonsense. If you have to watch a presentation to understand the title, the roles have been reversed. Maybe what a title is for went over your head.
I must use const pointers a lot more than the average person then...
`int const* const&amp;` is a reference to a const pointer to a const int. Only the first `const` is allowed to go on the right or the left. It's a very minor advantage, but when reading sequences of `const`, `*`, and `&amp;`, you get the correct semantics by reading in English right-to-left - but only if you use East const. `*`, and `&amp;`, and non-initial `const`s are already French, so the first `const` should be French too.
I think the argument has achieved meme status at this point.
This is great. I have a suggestion too. I-cache miss are one of the most expensive things that can happen and difficult to demonstrate. Thanks would be a great addition. Also whatever they call the loop stream decode buffer.
Thank you so much for the reply! I don't really know anything about arrays as I'm still very basic at c++ but i will keep your advice in mind while learning. 
Intersting read, there is some typos : - Literally* instead of literaly - There was a verb missing but I can't find it again
Hi @duneroadrunner, The primary motivation for my library was indeed to preserve the value-based *notation* (the actual semantics can be whatever your smart reference class requires, i.e. value semantics or reference semantics). The way how this library tries to emulate the "operator dot" overloading, is by adding some additional behavior upon accessing a member-type, a member-function (template), a non-member function (template) or a member-field (i.e. a data member). The latter I have not yet implemented yet, because most of my use cases don't require this. Regardless, I consider this last feature crucial, as it opens up the possibility for many more use cases (e.g. strong typedefs, properties, observable data models, etc.). This extra behavior can be implemented in two ways, either by providing a user defined conversion function which should eventually return the underlying object, or alternatively, by implementing the on_call function, which allows you to fully intercept any (member) function call or access to a member-type/field. While intercepting, you can do things like changing the way how the underlying object is called (e.g. using a non-member function call syntax), transform the parameters to the called function, and control the result type returned by the function call, for example by wrapping it inside of yet another smart reference class (e.g. to control reference leaking, or to allow chaining of operations). I like to think of this latter approach (i.e. implementing on_call) as a kind of mechanism to perform name lookups: if the identifier (e.g. member-function, non-member function) is not found by regular name lookup, the on_call function can be used to provide an implementation (similar to __getattr__ in Python). Having said this, I'm not entirely sure whether I understand the problem you're trying to solve, considering you mentioned it requires support for overloading operator dot. The features my library provides (or at least what I intend it to provide), is to support exactly that. Also note that my library is loosely based on the paper "Smart References through delegation" (wg21.link/p0352). I might be missing something of course, so I'm quite interested in your use case. Could you perhaps provide some more details, like how you intend to use such a smart reference class (from the user's point of view), and maybe also how you'd envision it would be implemented using a language based feature (e.g. Stroustrup's operator dot proposal). 
Thanks. I will fix that. I am clearly more at ease with C++ than natural languages...
Cache size can be demonstrate by the hierarchy bandwidth example (there should be bandwidth drops after going to a higher level of cache). Strides are a nice idea, although they are also partly in the memory-bound example (it's hard for me to categorize it :) ). TLB is also something I wanted to demonstrate, however TLB misses imply cache misses, do you have an idea how to demonstrate the TLB effect alone? &amp;#x200B; To detect your cache size and associativity, I usually use `getconf -a | grep CACHE` on Linux.
I have some `perf stat` examples in the branch misprediction demonstrations. But you're right, I shall add more of them to show what's going on. I wanted to use Google Benchmark originally, however as you say it's a dependency and I wanted to this to be as self-contained as possible. Maybe I will add it in the future, but for now I think the Python scripts are enough.
AFAIK you could still have problems on Linux if you set -fvisibility=hidden
Thanks, pointer aliasing is another nice example (although that is more a software effect than hardware effect).
To be honest I don't have much experience with embedded CPUs (apart from doing funky stuff with Raspberry Pi/Arduino/Atmel). I want to keep this x86/64 oriented so that it can be demonstrated easily, but if you want to, feel free to create a new repository with embedded effects, I would be very interested to see that :)
You're right, thanks. I added the `perf stat` output for branch-target-misprediction :)
Good idea :) I'm not sure right now how to do that (maybe large loop bodies or a large chain of function calls?). I'll try to think of something.
This looks like an awesome look, I will definitely take a look at it :) Thanks.
No, as-in could still make it to C++ 20/23/26?
Unix has that.
The table that you showed in your response does not come from the Julia challenge submission that you refer to, so the comment is at least misleading. In our post, we explicitly said that there is nothing in the Julia language that intrinsically would make it slower and that the relative slowness wrt C++ was certainly going to be solved.
Ah yes, reading my comment again I see it can be misleading. The second paragraph was supposed to be about OPs link only.
Awesome, will check it out! 
Impressive, this guy has 4 different lives * world class chemist * C++ compiler author * Lisp compiler author * GPU compiler author Where does he find his 96 hours per day? &amp;#x200B;
\&gt; I wanted to use Google Benchmark originally, however as you say it's a dependency and I wanted to this to be as self-contained as possible. Even without any package manager (e.g. conan), it's trivial to integrate it as an external dependency as git-submodule. Integrating it into the CMake build is also fairly trivial (you will probably want to integrate it without having a dependency on Google Test which is required if you want to be able to run the unit tests of Google Benchmark itself which you probably don't want to). It's documented on the page but it can be done with `-DBENCHMARK_ENABLE_GTEST_TESTS=OFF`.
You could also do a very similar thing for recent-ish x86 CPUs that have an LSD instruction cache, showing how unrolling small loops can have a negative effect if the unrolled loop no longer fits in the LSD cache.
Perhaps looping over a vector of polymorphic objects and calling their respective virtual function calls via base ptr? Also, objects should not be sorted in any predictable way.
Interesting idea.
Which part doesn't look right?
Right, I missed that part. Then your only bet is to patch the `libclang` API itself or doing it in a less performant but quicker proof-of-concept way by making use of dynamic nature of Python to implement the heuristics yourself. I've done something similar in order to extract more details about dependent-types in which case `libclang` didn't expose enough of them (or doesn't even have an API to handle it). [Example](https://github.com/JBakamovic/cxxd/blob/master/parser/clang_parser.py#L284-L322).
Something like python's enumerate would be a potential solution to this non-problem. 
If I remember correctly the number of `if`s in function function `digits10` in video [Fastware - Andrei Alexandrescu at 18:20](https://youtu.be/o4-CwDo2zpg?t=1100) is 4 because at higher numbers the function doesn't fit in instruction cache so is slower.
None of that is in the current ranges proposal though, is it? I thought that views (and algorithms?) are more of a C++23 or later thing and we just get the very, very basic stuff for now?
Please check my HPC book (I gave the link later): there are codes for stride &amp; TLB. You can demonstrate the TLB by going through a 2D matrix two different ways. Set the row size two more than a small page, then jumping to the next row means the next TLB entry; jumpting to the next column is no problem.
You're right, there were some typos and language issues, but your post has a typo as well. The blog is very interesting, good work /u/jguegant .
I have had the same thoughts as of late wanting an `noexcept(auto)`. The about of times I've had to copy paste the same code, and wrap it in `noexcept(noexcept(/*... */))` is rediculous. They also can't handle lambdas, so I have had to rewrite perfectly good code which is arguably more readible, so something arguably less readable just to forward on the `noexcept`s... arrrgghhh
I have conflicting thoughts about this. `noexcept(auto)` would drastically simplify code like template &lt;typename T&gt; void test(const T&amp; foo) noexcept(auto) { if constexpr(T::trait) { foo_noexcept(); } else { foo_except(); } } but the addition of `noexcept` to the type system would require the compiler to do a non-trivial amount of work to parse out void foo(void (*fn)(void)) { fn(); } template &lt;typename T&gt; void test(const T&amp; foo) noexcept(auto) { foo([]{}); } to determine that `foo` is `noexcept` even though neither it nor its arguments are specified as such. Of course, this would be an optimization, but when relying on the compiler to do the work for you, I think this would be an essential one.
This project seems like a very good idea. Would it be additionally possible to show the effects of 1.) saturated CPU memory bus and 2.) non-temporal stores? 
Note that you can already do something similar for `std::function` signature, e.g.: `std::function&lt;int (int x_coord, int y_coord)&gt;` So for map this can be emulated with type alias (a bit uglyness aside): https://gcc.godbolt.org/z/prZXPo
Didn't believe it could work, but trying it, it seems to run consistently faster (although not by much). Did you know about this ? Are you using a similar technique ?
\&gt; You mean taking interleaved strided accesses and reading them as one? No, I meant batching a few software prefetchs before actually reading the memory. \&gt; Code up some model of a use case, I'd say. I did this morning and to my surprise it seems to work and give a small speedup (posted it, although it's a quick and very dirty benchmark): [https://www.reddit.com/r/cpp/comments/9ygyhj/small\_speed\_gains\_by\_batching\_software\_prefetchs/](https://www.reddit.com/r/cpp/comments/9ygyhj/small_speed_gains_by_batching_software_prefetchs/)[https://www.reddit.com/r/cpp/comments/9ygyhj/small\_speed\_gains\_by\_batching\_software\_prefetchs/](https://www.reddit.com/r/cpp/comments/9ygyhj/small_speed_gains_by_batching_software_prefetchs/)
Thanks, I'll take a look.
Good idea, also you can propose a more familiar and compatible syntax: std::sort(people, [] { _1.name() &lt; _2.name() }); 
`foo` is not `noexcept`, regardless of `fn` or the lambda. Therefore, `test` isn't either. Optimizations cannot change whether a function is `noexcept` or not.
I will probably add it as an automatic download during the CMake build step instead of a git submodule, but good idea :) Thanks.
Thanks for the ideas! Saturating the memory bus probably shouldn't be too hard by spawning a few threads, however what would you like to see with non-temporal stores? Effect of non polluting the cache with the writes? Or raw performance difference between classic and non-temporal stores?
cat /proc/cpuinfo declares 4 'AMD Opteron(tm) Processor 4332 HE' But playing with it I am not so sure the gains are "consistent". I will need to try further at home, it could be measuring something else. With doubles, a stride of 64 and a prefetch batch of 32, we seems to have a speed-up of around 10%. 
Nah you can't use types in parens like that because that's parsed like a cast
The prefetch makes no difference. Try commenting it out, you still get the same performance differential. It's the different loop structure that makes a difference here.
You're right (should I've tried it from the start :)), not sure why this should be a better loop structure though.
If keeping with these specs, " Other directories should not be present in the root directory, except for what is required by other tooling. " how about you put your C++ code into one folder and have the other stuff for example in a separate folder (or simply one level up or something)? If you're not mixing just C language dialects, you maybe should not mix folders. &amp;#x200B; However, most people simply add a "python" folder next to the "src" etc folders and that is also what I personally prefer so far (in my case it's simply bindings of the library API). 
I will, once I read through it a bit. Cheers.
Well...it looks like its even faster if we clean the cache before: [https://coliru.stacked-crooked.com/a/2864c5df8c565b47](https://coliru.stacked-crooked.com/a/2864c5df8c565b47) (maybe I'm doing something wrong ?) &amp;#x200B;
I get completely different results locally, so I have no idea. Combination of compiler plus different hardware, perhaps?
Well, double without() { CHRONO("without"); double sum = 0; const double* ptr = _data; const double* tail = _data + _size; while (ptr&lt;tail) { sum += *ptr; ptr += STRIDE_SIZE; } return sum; } is even faster.
TLB misses depend heavily on the size of the pages. E.g. if you get 4KiB or 1MiB pages (x86 example) or something else. So you probably need to get pages directly from the OS API and not go thru the glibc or whatever implements malloc.
Sorry, I was misunderstanding/misassuming how the library worked. It doesn't provide the smart reference classes directly, but rather a base class that can be used to derive your own smart reference class. (I think the "Proxy" example threw me off a bit because, a) I assumed the `Proxy&lt;&gt;` class was the one that the library was providing rather than the `using_&lt;&gt;` base class, and b) in the example the `Proxy&lt;&gt;` class stores a copy of the data, so it's not really being used as a "reference".) So the library does support the use case I was talking about. I just tried it out. Works like a charm so far. Automatic support for standard member functions/operators is very convenient. But I guess we still need reflection for the complete automatic solution. Btw it seems to crash the msvc compiler. Works fine with clang. 
Heeey thanks for doing the digging!
Yes, as pointed out by u/F54280 [here](https://www.reddit.com/r/cpp/comments/9ygyhj/small_speed_gains_by_batching_software_prefetchs/ea1hpgs) the while loop with ptr comparison alone is faster: [https://coliru.stacked-crooked.com/a/89783eebb5366168](https://coliru.stacked-crooked.com/a/89783eebb5366168). Not sure we can draw any conclusions here. ¯\\\_(ツ)\\\_/¯ 
Do not use manual prefetching on modern CPUs. They do that fine all by them-self, if you do not send them pointer chasing down some linked lists.
I'm working on this myself. [https://thephd.github.io/vendor/future\_cxx/papers/d1214.html](https://thephd.github.io/vendor/future_cxx/papers/d1214.html) This paper is going to get an overhaul for the post-meeting mailing, in particular it's going to feature some stuff from std::overload.
Wow, this is an incredibly useful repo both for reference and for learning. I have no other feedback other than to say that you are making a great contribution, please do keep it up. 
Problem is from a language design stand point you have to weigh misuse chance versus the benefits. As the paper says the syntactic cost in templates is annoying but not common while the misuse likely would be very common.
Thinking about it. I guess I could do it incrementally. I could put in a temporary flag to indicate in any given file whether it should do new or old style, and tackle them a bit at a time. It's my own code so the temporary disconnect would only annoy me and no one else.
So uhh, that thing where the video stops when you switch to another tab so we can't continue to listen to the talk while looking at something else? I'm... not appreciative of that. 
I knew I was missing something.
If the enum identifier is unique across the entire codebase (which weakly typed enums do) you could easily just `sed` it across all files to the strong version with prefix.
I think the situation could be better if no exceptions was the default and we had to explicitly tell that something can throw. Then putting a throwing function into a non-throwing one would force compilation error. Hopefully zero-overhead value exceptions proposal can do something about it.
I'm actually working on a pure-library solution that is loosely based on that paper. You can find it here: https://github.com/erikvalkering/smartref I also have a presentation about it at CppCon2018, in which I showed how to use the library to achieve what the OP was talking about, unified call syntax. You can find the video here: https://youtu.be/bfm9m3xJQRY
&gt; Should it still produce a sorted output? No it should do the exact same thing it does now. Compare the front 2 elements and choose which one to take based on the comparison function you give it.
I'm sure there is a time and place for everything, but it is very difficult to beat the prefetcher manually.
I don't think recursive parsing would be needed. Assuming that we mark everything once parsed (like with `const`), we would need to go at most 1 more level in.
It's actually the other way around. Manual prefetching probably does more harm then good. AMD for example actively discourages the use of any kind of manual prefetching on Ryzen. http://32ipi028l5q82yhj72224m8j.wpengine.netdna-cdn.com/wp-content/uploads/2017/03/GDC2017-Optimizing-For-AMD-Ryzen.pdf
This was definitively an extremely interesting presentation.
A flag in the IDL would at the very least give you the opportunity to use enum classes for new code. Changing the old enums could really be a huge task. It’s not just the scoped names. They look unique enough for search&amp;replace. But enum classes also don’t convert implicitly to their underlying type. If you pass enums where integers is required, you’d have to introduce casts everywhere or redesign the affected APIs.
If they want ABI compatibility at module boundaries, they should be using COM or, at a pinch, `extern "C"`. Otherwise, make them rebuild the world!. Every other release should be ABI compatible. 15-17, 19-21, etc.
They are also of course namespaced which makes them easier to be unique. One thing I find kind of unfortunate is that namespaced enum classes become: MyNS::MyEnum::AValue so it's not quite so clear what it is as it currently is. But that's a small thing to give up for the compile time type safety.
&gt; The title is phrased as "Riding Hood Little Red" Holy crap! I hadn't realized, my brain totally autocorrected it!
Still not `boost::asio::ip::tcp::socket::shutdown_send`.
The `=&gt;` for single statement functions was a nice solution to that. I really hope the committee will reconsider it.
Prefetching helps a lot if: * one knows well in advance they’ll access certain memory, but it also won’t be so long you’re just pointlessly polluting the cache * access patterns are such that it’s not predictable what you’ll access next * you have cache bandwidth to spare * you have strong priors that this memory is not in the desired cache level Then prefetching can make a *huge* difference. I haven’t experimented a lot with whether the prefetchT(0/1/2/nta) instruction to only hit certain levels work as advertised, but they could theoretically help with point 1. This also relies on the cpu instantly retiring prefetches and sort of just handing them to the cache system, which I believe intel does.
Why "heaven forbid"?
Mind explaining what it does now then? Looking at some of the implementations that seems to be how it works but maybe I missed something.
Consider {1, 2, 4, 5} and {3, 6, 7, 8}; clearly it can't just compare heads and must seek into each sequence as well.
Considering the 450 euro/month commercial license, is there a benefit to this, versus using a plain HTML container like Chromium Embedded or Electron in conjunction with C++/Emscripten? I don't know how I feel about Qt "signals" needing the`moc` to make them happen; and how valuable is the whole Qt ecosystem in the first place? We have enough signals libraries already (e.g. `synapse`), and the various libraries in std (or at least boost) are coming pretty close to filling any gaps in functionality an app writer would need?
I guess it makes most sense if you already have a large Qt/c++ codebase and want to make a web interface for it.
 This is a very active topic of conversation throughout the community and on this subreddit. You'll surely be able to find a ton of stuff on the topic with a few well-typed google queries. 
The [pitchfork repo](https://github.com/vector-of-bool/pitchfork) has more than just a spec; it has a tool for dealing with a project which adheres to the spec. There's already a "create new project" command and a "update CMakeLists.txt file list from source tree" command, and other actions are planned. Note that the tool is still in early stages.
Fair point about the fee. Otherwise, that is somewhat my point though; why do I need the whole Qt universe, then?
That's a great development! One comment: &gt; The reason this may be preferable is that the build-debug cycle is usually faster on desktop, and you have a working debugger. So... no working debugger in the WebAssembly scenario? :-O Sounds like the dark ages... And one question: Does it work with QtWidgets based apps too or only with QtQuick apps?
I could give arguments for keeping the `libfoo/` folder, but in the end, it's not that important IMO. The important thing is to just go with an option and choose that for the spec. It's literally impossible to come up with a useful spec which describes every existing project structure exactly. At any rate, I'm not actually as interested in the specific structure that's chosen, but I'm interested in the tooling that can be built around it. I'm contributing to pitchfork, but I'm not contributing to the spec.
Does the desktop app immediately translate to the web? My understanding is that there is a QML thingy for the desktop, and a completely separate HTML-ey thingy for the web? Sorry, my research has been cursory (but I've run into threads basically giving up on the hope of painlessly migrating existing Qt to the web).
Ahah! The difference though is that `bit_cast` would be implemented specially in the compiler. The interface of `bit_cast` itself is a typed interface, so the compiler does not need to do magic to track where the memory came from. It only needs to implement the bit casting logic specially.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9ymlyz/xcode_cant_see_classes/ea2hwe2/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This probably won't be 100% of what you're looking for, and may only be 20% or something, but give `-fverbose-asm` a shot.
MSVC `/FAs` and `/FAsc` preserve source code and comments.
No, it's still a joke (I'm assuming you're defining the function in a header). The definition of `foo()` may be different as seen from different translation units based on the time at which they are compiled. If they're different, it's technically an ODR violation and the behavior is undefined. Using `__TIME__` is rarely a good idea. It can be useful when used in a single translation unit to encode something like a build timestamp, but it's not great in most other use cases. Also consider how it makes it impossible to have 100% reproducible builds. But now we've digressed into something unrelated to `constexpr` and I have better things to do with my time, like adding `constexpr` in the standard library :-).
Good luck with the cmake community. The maintainers hate useful features and think they perfected the system in 2002. The cmakelist language is perfect in their eyes. 
Good luck with the cmake community. The maintainers hate useful features and think they perfected the system in 2002. &gt; Brad King @brad.king · 3 hours ago Owner &gt; IMO such a wizard would be best maintained as an external tool. Who would have guessed...
As far as I understand, you can just take existing Qt app and compile it for WebAssembly and it'll just work (how well is another question). I.e. regular QtWidgets application is supported.
So what are those arguments then?
Qt has open source/free to use licenses also.
Gaming might fall under the same category as "hard-core numerical simulation." But most gamers are running Windows anyway...
I think you misunderstand my first point. The goal there isn't to flush lines (for which the clflush instruction exists), but to not have the following happen: &amp;#x200B; \* prefetch line\_1 into cache, evicting line\_2 to make room. &amp;#x200B; \* time passes &amp;#x200B; \* line\_3 is pulled into cache, evicting line 1 &amp;#x200B; \* time passed &amp;#x200B; \* Line 1 is accessed, but is not in cache anymore. &amp;#x200B; There are plenty of access patterns which aren't meaningfully predictable to a prefetcher, especially L1/L2 prefetches which afaik stick to fairly rudimentary patterns. &amp;#x200B; Imagine you have something like this: &amp;#x200B; int index = rand(); /\* some unpredictable computation \*/ prefetch(&amp;array\_needed\_in\_1\_us\[index\]); ... &amp;#x200B; Or take a tree traversal as another pattern, where you pointer chase but have reason to believe that the 'right' pointer will get accessed fairly soon after the left pointer, but the addresses are basically arbitrary and hard to predict without dedicated hardware to recognize this pattern.
How many of those games let you recompile them, though? I'm not sure how much of a boost you'd get with some custom compiles for your standard libraries, kernel, etc., vs. how much of a boost you'd get vs. custom compiling the game logic. I'd need to see the actual benchmarks here.
It's one of the few libraries out there that will let you write a cross-platform application without sacrificing performance. Writing a GUI in QML is a quite enjoyable experience, with automatic data binding and native-looking widgets available, and Qt provides you with tons of ready-made components.
Did you not read the article? That's the whole point of webassembly. You can use your existing (or new) code written for a desktop UI and run it as a webapp.
Looking at their example, it looks like they are doing an example where the stride through an array is one. That is something that the hardware prefetcher can easily predict. 
That's more branch target prediction I would think. 
I'm guessing (I can't see the video right now) that he is talking about the the Instruction Decode Queue and Loop Stream Detector which is able to lock down the decode queue (even power down the decoding logic, IIRC) and stream uops right out of the decoder queue. This isn't quite the same as an I-cache miss, but related. 
QML and Qt widgets can both be used on desktop or mobile and both can be used in applications compiled to web assembly and deployed online.
Speaking as a co-author of operator dot, there were a lot of work to get done quickly in a short amount of period when EWG opened for C++20 business - notably concepts, contracts, modules, and other major features to evaluate. Opeartor dot fell through the crack, but it is not dead; and certainly not because of implementation problems. I do hope to see Unified Function Call Syntax back now that modules are on their way - there were concerns about “accidental” reach.
Qt signals/slots significantly predate most of the other signal/slot libraries, why not ask instead why those were necessary? As far as what makes Qt signals/slots particularly useful, the killer feature is the integration with QObject and QThread. Qt signals can either call directly to the slot, or queue on the event loop. They know what thread the signal and slot are on, and will automatically queue on the correct event loop in a thread boundary is being crossed. They also automatically disconnect when lifetimes expire, and generally are easy to use.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9yow99/unix_user_needs_help_doing_anything_with_c_on/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Not really, but everyone likes ves a good reddit pile on. 
What a delightfully inaccurate and useless comment this is! I wouldn't care to respond, other than seeing it sitting at +3. Can't have this Poisoning the Mind of America's Youth... &gt; The maintainers hate useful features and think they perfected the system in 2002. That is quite an accusation! CMake has been flooded with new "useful features" every minor release for the past six years. Of course, if you use Stack Overflow for your CMake education, you'll only know mountains upon mountains of flaming garbage information. You also seem to be implicating Brad King (the man who almost single-handedly manages the entire CMake build and release pipeline) as blatantly lying about wanting this feature as a useful external tool, and would rather see his user-base wallow in suffering and agony for all of eternity? I'd bet if they _did_ create a wizard tool you'd probably dwell on how horrible it is, eh? Perhaps I'm biased since _I_ am building such an external tool. Alright, I'll bite. Give me an example of a "useful feature." I give it a 40% chance of CMake already supporting it, 55% chance of it being unimplementable and/or undesirable, and 5% chance of actually being something useful that CMake should add. In fact, if you can hit that 5%, I'll go start development on it _right now_! And here's a bit of a test: I have an executable `my-program`. How do I enable support for multithreading on that target?
Not exactly a performance thing, but a hardware effect - I once wrote a demo of processor instruction reordering. [https://github.com/ClockworkV/Odds-And-Ends/blob/master/memReorder.c](https://github.com/ClockworkV/Odds-And-Ends/blob/master/memReorder.c)
I think effects of not polluting cache would be very interesting to assess, although I'm not sure how the effect would be easiest to arrange - the raw performance between NT and classic would be interesting, too. 
Fake News! :-)
Thanks, memory load/store propagation and the memory model in general is definitely something I plan to demonstrate :)
That's exactly what I added yesterday :) Check this: [https://github.com/Kobzol/hardware-effects/tree/master/bandwidth-saturation](https://github.com/Kobzol/hardware-effects/tree/master/bandwidth-saturation), the difference between classic and non-temporal stores is huge.
Google has demoed a WebAssembly debugger for Chrome at the state of WebAssembly talk last week. https://www.youtube.com/watch?v=zgOGZgAPUjQ
I'd argue it's the opposite, this makes it more difficult to have generic tooling. The general way to have multiple libraries with public APIs is to split at the top level. This is also required when each library have their own repo, or if you have your dependencies in submodules. Example: libfoo/ src/ include/libfoo/ libbar/ src/ include/libbar/ executable src/
`clang_getCursorSemanticParent` `clang_getCursorLexicalParent` can return the parent. However, these libclang functions were designed with some specific use cases in mind. You may find they still do lots of things than simply returning the parent `Decl`, which makes them clumsy to use as you add more of your own logic. I have also hacked some libclang in the past and then I realize I should just switch to use Clang C++ API. The AST part seems pretty stable.
The best you can do with the CMake language is "printf debugging," yeah. There has been some work by interested third parties on a CMake script debugger, but it hasn't gotten off the ground yet. Regarding their "refusal" to support package management: It's a little more complex than them simply "ignoring" the problem. I could go on a lengthy rant on this one, but I'll save it. Suffice to say: Build systems and package managers are far more distinct than it would otherwise appear. I'll refer to [P1177](https://raw.githack.com/bfgroup/std_cpp/master/doc/package_ecosystem_plan_P1177R1.html) from SG15 on this one. I'm doing work with the SG15 group to help alleviate some of the package management pain, including discussions with CMake developers on how to best support modern package management features going forward. Contrary to popular belief, CMake has almost all of the facilities in place to support a good package management solution, minus a few missing bits and bobs that are easily added. The bigger "blame" is on the package manager developers themselves, as they have to cater to people who still want to write Autotools and CMake like its 2009. In particular, the two biggest players, Conan and vcpkg, do not emit package information in a way that is consumable by modern and idiomatic CMake code. I'm working on this exact problem as this exact moment (Reddit-ing aside), collaborating with the developers on Conan, vcpkg, CMake, and even Boost.Build. [Take a look here](https://api.csswg.org/bikeshed/?force=1&amp;url=https://raw.githubusercontent.com/vector-of-bool/libman/develop/data/spec.bs). Also, PMM isn't a "workaround" for anything wrong with CMake or package managers. It's a tool that automates the installation and invocation of your package manager as part of your build process. It's a CI tool, not a bodge/hack.
I'm not sure why you're comparing Qt + webassembly to electron. Qt is cross-platform by nature so instead of electron you have a single code-base to build native apps for different platforms, with all the relevant performance gains. And yes, it works, I've build several desktop apps that run on linux/macos/windows. I would compare Qt + WebAssembly to using javascript framework(s) + html for building web applications. My experience with the latter is limited, I can say though that building a front-end with `qml` is an absolute pleasure. If you already have C++ code then Qt + WebAssembly might be a no-brainer. Whether they will be a contender for choosing a framework for building rich web applications from scratch remains to be seen, it should be super-easy to get started for one, this is far from the case, `cmake` not yet supported for webassembly for instance. Note that the Qt docs are a shining example of how to write documentation.
Very nice, I'll try it later!
I've "ported" (tweaked a few tjings here and there to make it build) a large widget app to qt wasm, works fine
Thank you for this, really appreciated!
The performance seems very, very bad, to be honest. And that is with hardware acceleration enabled.
Why not publish it on github or something?
Or we could introduce some mechanism to specify precedence for operator overloads. That might turn into its own mess though.
Ignore that example. That is just about not standing in the way of the compiler doing its optimization.
No, that’s fundamentally a bad place to prefetch since the hardware prefetchers are purpose built to handle that case, and by manually prefetching you just waste prefetching bandwidth. It’s a great example since people frequently try to prefetch in that scenario and it’s a very common one in gaming engines, but it doesn’t demonstrate that prefetch as a whole is bad on ryzen.
Big fan of your VS code extension. I just quickly checked the libman proposal, it feels reminiscent of boost build. Does it integrate with cmake. Another question regarding PMM, how would it know if the target already has vcpkg for example, especially if it wasn’t in the PATH? Or would it download it locally? Do you think that the modules TS would render the package and dependency situation better?
Convenient? You have race condition in setUsage/getUsage, also your example have memory leaks, and undefined behavior due to access to local variable queue from detached thread.
`int typedef my_int;` 😣🖐 `using my_int = int;` 😌☝ That's interesting though - I'd never considered that `typedef` could be reordered.
Thanks! I'm sure I can use that code at some point in the future.
Great, glad you're enjoying it. It's a good questions and there are several aspects to performance when using clang-tidy. Performance will be part of the topic covered in the next post in this series, but that will only cover one aspect. There will be more about performance in follow-up posts.
Yes, but I would say that icache miss effect are only amplified by branch mispredictions? Calling into a virtual function should result in icache miss if target function we're calling is "too far" away from the one we will be calling next.
I don't get your eviction example. Especially since line 1 seems to be evicted after it already got evicted?! &gt; There are plenty of access patterns which aren't meaningfully predictable to a prefetcher Any example except multi core communication? There is only the case of "always prefer path A over B, and I'm totally fine to pay a huge performance price if path B is ever taken". E.g. for error handling code paths. This will work just fine, any modern CPU/core has all it needs for prefetching on its own terms here: int index = rand(); //... do stuff do_work(array_needed_in_1_us[index]); That example form AMD is just to show that you can hurt compiler optimization with inserted prefetch commands. It is otherwise independent from there general do-not-use-manual-prefetching guideline.
Note that https://coliru.stacked-crooked.com/ seems to run on a Opteron 4332 HE. (CPUID told me so) You may want to consider if that is your target platform for performance optimization or not.
I still don’t understand your confusion about the first example. 1. You want to access line 1 later and it isn’t in the cache. 2. You prefetch line 1 and evict line 2 to make space 3. You try to access line 2 and miss the cache 4. You evict line 1 from the cache for other memory 5. You now try to access line 1, but it’s not in the cache anymore. You’ve lost since you evicted line2 to make space for 1 and wasted time on that miss, and then wasted time on line 1 anyways. In the large array example, that will not prefetch. The cpu has absolutely no way to know that in ~3000 instructions (1us), you will load that specific line from the cache but you as the programmer do. Prefetches aren’t magical things, they generally listen to cache patterns and try to predict where those go. If you don’t have access patterns leading up to the memory you want ahead of time, the prefetcher won’t see it. That’s why the three example works, since the pointer chasing is rather arbitrary there. Again, you misunderstand the amd presentation. It shows both that MSVC has trouble optimizing around prefetches AND that prefetching with the linear pattern gets you nothing, that’s the point of their ‘cycles wasted on prefetches’ slide and benchmark in general.
&gt; https://github.com/shadonovitch/MSGQ/blob/master/includes/MSGQ.hpp this doesn't inspire confidence... I'll stay with https://github.com/cameron314/readerwriterqueue, thanks
Yep, right proper. :)
what is the advantage of this vs just not putting anything there?
Wow. I thought the pitchfork proposal was great. In all my past I would have agreed. But now seeing how you suggest the layout to be...that is actually great. It solves many issues that I have with pitchfork. My biggest issue with pitchfork is the uncontrollable 'include-path' problem. &amp;#x200B; Does your layout have a name? Or do you know any where to read more about it?
nothing = can potentially throw `noexcept(auto)` = depending on the implementation: `noexcept` or can potentially throw
Try r/codereview if you want to get some feedback.
Why is that? I would have expected similar performance to JavaScript, or better.
I've never actually written a single line of Boost.Build code, nor do I understand the build system itself (too busy trying to juggle CMake to learn other build systems, unfortunately). And yes, libman will integrate very naturally with modern CMake code. It's up to each particular build system to define its own import semantics. For now, there is a `libman.cmake` importable module that will import libman-defined packages. I have a Conan module that already exports some of this data, and I just merged in some PMM code for experimental Conan support (but it is still extremely early. Don't rely on it). I'm waiting for the tooling to mature before I start making a big fuss about it. At present, PMM will always download and build a vcpkg for itself unless you set the `PMM_VCPKG_EXECUTABLE` cache variable. It does not yet have any logic to find an already-existing `vcpkg` executable. The effect of C++ modules on library packaging is a tricky subject, and there is a huge amount of discussion in this regard. TL;DR: No. It _may_ help build systems, but it won't do much for package managers (for the same reason that package management and build systems are very disparate topics).
Not that I know of. 
Reader is broken, always assumes that the bitmap info structure is a BITMAPV5HEADER and that the data bits immediately follow that structure, ignoring the data offset field. GIMP is not a good program to test against since it is a photo-editing program that's more likely to use the advanced fields; most programs including MSPaint use a BITMAPINFOHEADER. That's not even counting the programs that write a OS/2 era BITMAPCOREHEADER instead, which do exist and are valid in the format. I'll give points for acknowledging and rejecting the seldom-used top-down mode. OTOH, deductions for not validating at least the file signature before allocating the bitmap array (and blowing up on a randomly sized allocation), using #pragma pack instead of using a structure with normal alignment and reading/writing/memcpying the necessary subset, and magic numbers for sizeof(BITMAPINFOHEADER) and BI_BITFIELDS. 
But surely in constexpr the compiler always knows the true type of what memcpy is looking at right? So I'm not seeing the implementation difficulty if bitcast is supported. Simply make it refuse to compile memcpy if one isn't copying whole objects. That enables much of the utility, whilst preserving safety.
This is actually genius. If you're at least an intermediate level dev and have seen expected/outcome like interfaces before, and you are also wondering how the heck you can return a type erased error object without using heap allocations, I actually strongly consider consider skipping down to the "Design Rationale" section. OP, I'd consider having a 2-3 sentence summary near the top, explaining the magic, linking to the design rationale. Realistically a lot of the potential clients of your library will be fairly experienced people who will immediately want to understand the "trick". Given that, I'd quite literally have a section "The Magic" after abstraction but before introduction. Would you consider this library production ready?
We don't, because noone actually cares. If you care, turn off iterator debugging and we won't do that check. Note that merge is one of the cases we've kept order asserts because it's a linear time assertion in a linear time algorithm; the logarithmic time algorithms have had such asserts removed.
cmov is faster than unpredictable branching but slower than predictable branching. 
I'm not asking to change the algorithm at all. I just want to be able to call it with unsorted inputs which would produce an unsorted output.
The problem is that exceptions are insanely slow in the error path. Some iterations of the `expected` and `outcome` proposals/types have the same issue; they use some kind of type erasure w/ heap allocation to type erasure the error type in the returned object. So they are reasonably fast in the happy path but in the error path you have heap allocations which while probably better than exceptions are still terrible. LEAF seems to have basically no overhead. If there's an error, the actual error object is constructed directly at the handler's location. I haven't precisely analyzed the number of branches or pointer dereferences so it may not be exactly identical to error codes (in the error path), but it will be very close, unlike exceptions.
Try lowering the `REPEAT` value in the bandwidth-saturation.cpp file or the number of repetitions in the benchmark script `benchmark(data, repeat=2)`. Or lower the number of tested threads in the [benchmark.py](https://benchmark.py) script. I try to use a reasonable balance of repetitions so that it's not excessively long, but it also cannot be too short to even out the measurement noise. And of course it will vary with your system specs :) This example is probably one of the longest, because the cache thrashing is extreme.
Ah, understood. Thanks for all your hard work sir!
This sounds like the right decision to me - the strict requirement on the number of comparisons seems a little ridiculous and encourages people to rely on a particular implementation.
There are cases were the explicit complexity requirement matters -- remove_if is a good example where we wouldn't want to break the guarantee that the predicate is called once on each element in forward order :)
I'm thinking of: template &lt;typename T&gt; void f(T t) ??? { t.bar(); } case: bar throws, then t throws too. if ??? is empty, then the exception will propagate. if ??? is noexcept(false), it will propagate. case: bar is noexcept, then any exception in bar will call std terminate. if ??? is empty, then an exception could propagate, but this will never happen since we are in the case where there is no potential exception to throw. if ??? is noexcept(false), then again an exception could propagate but there's no chance it could even be thrown by the case statement. so it seems like noexcept (auto) has the same behavior as leaving it empty. the only potential issue with leaving it empty is if you try to introspect (via template or otherwise) about the exception-ness of the template function... but as you say in the post, I don't think that's possible 
There's a bunch of tools that are suitable for this, one example being (Python) cookiecutter https://github.com/audreyr/cookiecutter#c Fairly easy to build a template that suits your needs.
BMP's are one of those formats where its fairly easy to get something that works most of the time... Plenty of example code out there covering 80-90% of it. It's that last little bit thats tough (and really its just a documentation problem).
A possibility to add a type to a protocol and a possibility to specify default method implementations. Both of these are provided by a \_separate\_ mechanism of extensions (which isn't tied to protocols specifically).
Yes, but there's a difference between a BMP loader that can't load BI_RLE4 images and a BMP loader that can't load a 24-bit image produced by MSPaint. The code in the blog post has been updated, it now does the necessary seek to the bitmap bits, but the bitmap info struct handling is still wrong: it assumes that BITMAPV5HEADER fields are present if biBitCount=32 instead of checking for biSize &gt;= sizeof(BITMAPV5HEADER). The problem appears to be that this code is either being written by looking at the raw bits, someone else's code, or unofficial documentation, because the author is apparently unaware of the Windows GDI conventions that the format is based on. There's no need for this, BMP has reasonably decent official documentation: https://docs.microsoft.com/en-us/windows/desktop/gdi/bitmap-storage 
&gt; so it seems like noexcept (auto) has the same behavior as leaving it empty. No. This is the problem: &gt; case: bar is noexcept, then any exception in bar will call std terminate and will never reach f **BUT f will be marked as potentally throwing**
So, just to see how it would go, I tried a few single enums. There are a good number that are not done via IDL, since they are part of a handful of fundamental facilities that the IDL generator itself depends on, or they are things that must be shared by the virtual kernel layer which everyone depends on. Ultimately, it really sucks in practice. The primary reason being that the enums can no longer be used as indices. And that's one of the primary purposes of enumerations. You want to have lists of things where you know that the slots in that list are values associated with a set of enumerated values. Having to cast every single usage of this type to a cardinal value would just be seriously ugly and messy and I question whether it would ultimately be worth the other benefits.
That seems like a rather arbitrary reason to exclude them as being typeclasses
Thanks for sharing, very interesting! 
Or you could just use any of the small and simple one-file implementations of TIFF, PNG, JPG and GIF readers/writers from here https://github.com/nothings/single_file_libs#images
Ah, I think we're roughly in agreement then. I feel that there are enough tradeoffs in the implementation details of `std::string` that it's pretty reasonable to expect that at some point you'll want to have your own. This assumes that at some point you're going to have some performance sensitive code somewhere, which is of course not always true.
Please go to /r/cpp_questions.
Aren't stateful comparators a big nono with STL to begin with? Afaik the STL may copy them internally as they wish and I wouldn't think the algorithm implementations are set in stone.
if bar is noexcept, then wouldn't noexcept auto be deducted as false?
No. The difference is that if you leave the spot empty, it will always mark enclosing function as potentially throwing, even if all code inside is noexcept. In such situations, `noexcept(auto)` would correctly mark enclosing function as never throwing.
Wave files are another example of that. 
Parsley idiom
I've just implemented this. One thing I had to do was define my own milliseconds duration since the default storage type used by `chrono::milliseconds` exceeds the size of an unsigned int (which is what is required by the C API and the underlying OS API's). I was also about to complain about the verboseness but then found out C++14 has chrono literals which solves that problem. Thanks for the suggestion!
Can we please, as a community, stop speaking of C/C++. Nobody uses C/python or C/rust even if both python and rust have an FFI based on C. Modern C++ is really different from C, and his backward compatibility doesn't means that C and C++ should be considered together.
Isn't what the [libs](https://api.csswg.org/bikeshed/?force=1&amp;url=https://raw.githubusercontent.com/vector-of-bool/pitchfork/develop/data/spec.bs#tld.libs) directory is for?
\\\#
As of now, it's only possible to wait for a single process at a time. However, I did some research and it looks like it's possible to implement a function that waits for any process in a list of reproc processes to exit. Is there any specific use case you'd need this for? 
What you are doing is a hack of a particular implementation of std::merge. Also, the lambda you pass does not conform to the [specification of Compare](https://en.cppreference.com/w/cpp/named_req/Compare). I really don't think it makes any sense to hijack the computer science merge concept into something different. There should probably be an interleave algorithm in the std library. This way, it can also be implemented in a more efficient way (for instance via some bit twiddling for booleans](https://graphics.stanford.edu/~seander/bithacks.html#InterleaveTableObvious) )
what if your CPU is not superscalar.
I'm afraid this question is way out of place: see the sidebar, questions and help posts are off-topic and to be posted in r/cpp_questions. &amp;#x200B; Also note that a [quick google](https://www.google.com/search?q=g%2B%2B+produce+.so) search finds you what you are searching for: \`\`\` gcc -shared bin/shared/add.o bin/shared/answer.o -o bin/shared/libtq84.so \`\`\`
Looks like the extra code is a clang bug of some kind, GCC's code is basically identical apart from some registers: https://godbolt.org/z/UrDA07
[https://en.cppreference.com/w/cpp/algorithm/minmax\_element](https://en.cppreference.com/w/cpp/algorithm/minmax_element)
Should this: void ReadBytes(gsl::span&lt;uint8_t&gt; buffer) Be this? void ReadBytes(gsl::span&lt;uint8_t&gt;&amp; buffer) I'm not familiar with gsl::span, but that feels wrong to me. 
Agree, when talking about security with people they always show C style stuff thats unsecure... 
\&gt; will automatically queue on the correct event loop in a thread boundary is being crossed They'll also automatically preserve references when signaling synchronously within a thread, and make copies when communicating across threads to avoid data races. Quite a joy to work with, really!
!remove
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9z36zg/how_to_prevent_space_bar_from_being_used_as/ea5y8bc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
thx so much
Good to know, thanks!
&gt; wasm is a 32 bit platform Oh wow, that's a surprise! Thanks.
Oh, I did not try GCC - that looks really nice, thanks!
I read a trip report somewhere (or maybe heard on CppCast) that after the San Diego meeting, span is now (or will be in C++ 20) a view. I don't recall specifically though - maybe someone can fill in more details.
I glanced at the github address and for a second thought you were going to talk about lobsters.
Before posting these kinds of questions on r/cpp, consider doing a bit more research on your part, otherwise people might think you're just trying to use it as a "do my homework pls" kind of service, which is 100% not cool.
Sorry, I don’t get it. What do you mean?
Jordan Peterson talks a lot about lobsters.
Your name resembles someone famous. It’s a political bag of worms, don’t open it :D
Oh, yeah - no relation 😀
that's because gcc chooses to not check the bounds at all. you have zero cost, but you don't get the actual feature.
I don't mind at all :-). This is the tl; dr when I put the link in my company's slack; if you find it useful to add in that section feel free to add it. &gt; tl; dr: an error handling framework that returns *type erased* value/error objects, without heap allocations i.e. functions return things like `result&lt;T&gt;`, which can hold either a `T` or arbitrary error information. the one liner is that it achieves this seemingly not-possible result by actually having the storage created in the function *handling* the error; creating that storage in turn updates a thread_local pointer, which tells the function *creating* the error where it should construct the error information
gracicot is correct here. As a side note, though you may want to do something like this: &amp;#x200B; \`void FindSubSpanInAnInterestingWay(span&lt;uint8\_t&gt;&amp; range);\` &amp;#x200B; Although I don't know if it would be in practice any different than &amp;#x200B; \`span&lt;uint8\_t&gt; FindSubSpanInAnInterestingWay(span&lt;uint8\_t&gt;&amp; range);\`
and i found that 'correct' answer actually wrong answer for this question i have think before i thought array haven't pop or push function actually,creat one class and define pop and push function but there are same output code a.pop in the end how can i sort for that ?I'm still don't known
There is a nice research on the topic [https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2587](https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2587)
It should be able to elide that check - on entering the loop it's comparing non-zero to 0 (never true), and on repeat it's testing the exact same condition it just repeated on (redundant, never true). It's unnecessary.
true that. didn't even look at the conditional jump at the bottom of the loop. anyway my actual point would be that not all bounds checks can be optimized away. if span guaranteed bounds checks universally, it would no longer be a zero cost abstraction.
Thanks, I'll try passing span by reference instead.
There are a lot of use-cases that work similar to `make -j`. It's actually quite tricky to do efficiently, especially when you consider: * there may be hundreds of processes started by your library * there may be processes *not* started by your library
0.707 is not a probability; it's a probability amplitude. You need to square the 0.707 -&gt; 0.499849
Something that I've sort of wondered how helpful it would be is if you could mark class data members as "*really* private" and make them inaccessible from even most member functions. For example, suppose you're writing your own vector class for some reason (think just example code) -- you might have a `m_size` variable, a `size` function that is just `return m_size;`, but want to make sure that even other member functions always go through `size()`. I'm torn on whether such a constraint would even be a good idea as opposed to a smell (though I tend toward sometimes a good idea) let alone worth whatever annotations are necessary to make it happen, but it seems like at least an interesting thing to consider, anyway.
I think that's the opposite of what Splanky was trying to tell you
The CML enum thing was easy in the end. It turns out the ONLY time that that parameter is used is when a C++ enum is being wrapped and it's ordinals are being used. So, I got rid of that parameter on the existing method and added a templatized overload of it, and that took care of all of those calls. So I have a working system again with, I think, all the infrastructure required to just start converting enums over time. The only thing I have to deal with are those specific cases where I've taken advantage of an implicit cast, which should get fewer and fewer as I get up out of the more bootstrappy lowest layers.
What is the status of the proposal? 
This might not be possible after all. For POSIX `waitpid` to wait on multiple processes, they have to be in the same process group. However, the process group cannot be changed after calling `exec` which means we cannot put sets of processes in arbitrary process groups after starting them in order to wait for them all with a single `waitpid` call. I think this prevents us from using `waitpid` to wait for any process of a group of processes to exit.
So basically the difference between this and a unique_ptr is that it is copyable without using the Clone pattern? Or am I missing something?
I didn't know of `WNOWAIT` until now. That's definitely another possibility although all the caveats you mentioned apply which seem to make it rather hard to implement correctly. `signalfd` looks promising but won't it have the same problems? Calling `read` on a signal fd consumes the signal, so if a process exits that doesn't belong to the group we're waiting for we'd be in trouble (but it seems we need to call `read`to get the pid the `SIGCHLD` comes from).
There is a possible argument for passing by reference here: The function could modify the span such that it only covers the region that has been filled with data, but I usually prefer to return a span instead.
`&amp;u_;` is bad in generic code. Most of your code is a mediocre duplicate of `std::any`. template&lt;class D, class Base&gt; struct poly_base { Base* get() { return self()-&gt;get_base(); } Base const* get() const { return self()-&gt;get_base(); } Base* operator-&gt;() { return get(); } Base const* operator-&gt;() const { return get(); } Base&amp; operator*() { return *get(); } Base const&amp; operator*() const { return *get(); } explicit operator bool() const { return get()!=nullptr; } private: D* self() { return static_cast&lt;D*&gt;(this); } D const* self() const { return static_cast&lt;D const*&gt;(this); } }; template&lt;class Base&gt; struct poly_any: private std::any, poly_base&lt;poly_any&lt;Base&gt;, Base&gt; { poly_any() = default; poly_any(poly_any const&amp;)=default; poly_any&amp; operator=(poly_any const&amp;)=default; poly_any(poly_any&amp;&amp; o) = default; poly_any&amp; operator=(poly_any&amp;&amp; o) = default; template&lt;class D, std::enable_if_t&lt; std::is_base_of_v&lt;Base, std::decay_t&lt;D&gt;&gt;, bool&gt; = true, std::enable_if_t&lt; !std::is_same_v&lt;poly_any, std::decay_t&lt;D&gt;&gt;, bool&gt; = true, &gt; poly_any( D&amp;&amp; d ) { emplace&lt;std::decay_t&lt;D&gt;&gt;( std::forward&lt;D&gt;(d) ); } template&lt;class X, class...Args, std::enable_if_t&lt; std::is_base_of_v&lt;Base, std::decay_t&lt;X&gt;&gt;, bool&gt; = true &gt; std::decay_t&lt;X&gt;&amp; emplace( Args&amp;&amp;...args ) { get_base_f = nullptr; this-&gt;std::any::emplace&lt;X&gt;(std::forward&lt;Args&gt;(args)...); get_base_f = [](std::any const&amp; self)-&gt;Base const*{ return std::any_cast&lt;X const*&gt;(&amp;self); }; } using std::any::reset(); using std::any::has_value; using std::any::type; private: friend class poly_base&lt;poly_any&lt;Base&gt;, Base&gt;; Base* get_base() { if (!get_base_f) return nullptr; return const_cast&lt;Base*&gt;( get_base_f(*this) ); } Base const* get_base() const { if (!get_base_f) return nullptr; return get_base_f(*this); } Base const*(* get_base_f)(std::any const&amp;) = nullptr; }; this relies on `std::any` to type-erase storage instead of rolling its own. Overhead over a `std::any` is a single function pointer. It supports `*` and `-&gt;` and `.get()` to get at the underlying `Base` interface. 
But anyway, that's what I meant by `rt_sigqueueinfo`. You requeue it, stop listening for the signal, return to the caller, then start listening for it again the next time your `poll` analogue is entered. Actually, I'm not 100% sure if you have to explicitly unregister it, or if simply not trying to `read` your `signalfd` again is enough. Alternatively ... hm, does `tee` work on `signalfd`? 
&gt; the keyboard has a horrible feel to it (but it gives you decent finger strength) There are people (like myself) who use keyboards with very strong springs. I use 150g, but plenty use stronger. It hurts for the first month but you get used to it. That's how people were able to write on typewriters all day in the past. You get used to it.
I think the way to do that is to encapsulate that into a separate class. For example &amp;#x200B; namespace detail{ template&lt;class T&gt; class vector_rep&lt;T&gt;{ size_t m_size; size_t m_capacity; T* begin; public: size_t size() const{return m_size;} // Other accessors and mutators }; } template&lt;class T&gt; class vector detail::vector_rep&lt;T&gt; rep; // Implement using member functions of vector }; &amp;#x200B; &amp;#x200B;
&gt; &amp;u_; is bad in generic code Why?
Well, all humans are distantly related to lobsters.
And if the buffer is a buffer of pointers, you can become a three star programmer.
yes, if you shove godbolt in there with a crowbar it becomes c++ related.
I guess to rephrase... why do you want to have a function marked noexcept if you already know it doesn't throw/doesn't call can't functions that throw? 
iirc from the proposal, the wording also recommends small buffer optimisation.
I will let you know. I think for now, I polled my immediate team (we could make our own independent decision), and the main question is whether we want something like this, or something that more rigorously enforces exhaustiveness. One of the main reasons to not use exceptions in certain parts of our code is because you can't statically verify that you've handled all the exception paths. This means that if you used exceptions to indicate errors while trading, you could easily and non-obviously throw right into main (which is never what you want). With this library, you get a small amount of type safety/exhaustiveness but it's binary: a function can either fail, or not. All the `assert(matched)` statements in the test code are examples of places where in a complex codebase you could very easily fail to handle an error. What I am picturing right now is a `result&lt;T, E...&gt;` that has the following few properties: 1. `E...` are unique (no type repeated). 2. `result&lt;T, E1...&gt;` implicitly converts to `result&lt;T, E2...&gt;` iff E1 is a subset of E2. 3. To narrow the pack of errors, there has to be some kind of explicit function, e.g. `r.handle&lt;E2&gt;(Visitor&amp;&amp;v)`. This would indicate that current function is going to handle `E2` locally, and will need to return something like an `optional&lt;result&lt;T, E'...&gt;&gt;` where `E` is the original pack with E2 removed. `Visitor` needs to be a type callable on `E2`. Although the types and such will get a bit unwieldy, particularly because of the lack of pattern matching, this still makes it reasonable to combine errors from completely different sources, decide which errors to handle locally and which to pass on, and generally speaking the type system will make the majority of errors (shy of completely forgetting to type return) impossible. Not sure if you'd be interested in incorporating something along these lines into your library or not. Either way if you wanted to chat more interactively on e.g. the cpp slack I'd be up for it.
+1 herb sutter is the best speaker
Last i checked c++ had references and reference semantics are a core language feature.
Sorry if I communicated poorly -- you should pass span by value in almost all cases
I think optional (and variant) would be covered by pattern matching.
&gt; `noexcept(noexcept(std::declval&lt;Factory&gt;()())) ` This is should be `std::declval&lt;Factory const&gt;()`, as the `operator result_type` is a const member function.
Sorry to bump, any news?
Enumerators as array indexes is a new one to me. On first glance it sounds like a weird alternative to a simple structs with data members – that’s the normal way to name data, after all. But of course you can’t iterate over members … Is that the reason why you have those “semantic indexes” in your code base?
C++ and C both are languages with value semantics. Variables are copied unless they are explicitly passed as pointer/reference. The opposite behaviour is something like python or java where everything is passed by pointer/reference.
(To /u/jguegant) &gt; `noexcept(noexcept(std::declval&lt;Factory&gt;()())) ` This should be `std::declval&lt;Factory const&amp;&gt;`, as the `operator result_type` is a const member function and consequently `factory_` is a const lvalue therein. -- &gt; `using result_type = std::invoke_result_t&lt;Factory&gt;;` Likewise this should be `std::invoke_result_t&lt;Factory const&amp;&gt;` as it should reflect the value category of `factory_` when it is actually invoked.
Whoever reads this, please don't ever write clever code like this. Your future self will thank you.
 struct base { virtual ~base() {} }; struct derived : base {}; polymorphic_value&lt;base&gt; a = make_polymorphic_value&lt;derived&gt;(); auto b = a; //&lt; does the right thing
To be clear: I wasn't advocating doing this, as it is not standard-compliant. I was just providing the code snippet to show that if you're aware of an implementation, you can make it happen.
Isn't that basically the same as asking why bother with noexcept at all..?
The point is not to have "any value that can be copied", but to have a polymorphic copy. polymorphic_value&lt;base&gt; a = make_polymorphic_value&lt;derived&gt;(); auto b = a;
I don't already know. Maye it's a template and I do not know what the user puts in.
`cmp r12, rbx` appears in both clang outputs and the one using `span&lt;...&gt;` has an adittional one. How would you suppose a compiler deals with a for loop without doing such a check? The difference with GCC is that it put some things left or right and uses `rbp` and `rbx` differently. You still see the pattern where using `span&lt;...&gt;` introduced an adittional branch at `.LBB0_3`. The difftool considers the left side 'old' so if even a single character is replaced it marks the left line as removed (red) and the right line as added(green), but it will actually highlight which substring differs, is this what leads you to believe no checks are made?
The visitor idea you're describing is similar to `leaf::handle_error`: you pass it an `expect&lt;E...&gt;`, a `result&lt;T&gt;`, and a series of `match` sets, each with a visitor. If `handle_error` finds a match, the `expect` object is flagged as "handled", which causes its destructor to clear its content. Otherwise, each individual `E` is moved to the next `expect` object up the call chain which has storage for it. How do you envision `r.handle&lt;E2&gt;` to work though? Presumably it would return `result&lt;T,E...&gt;` with the narrowed `E...` pack, which must contain a special `E` to allow `r.handle&lt;E2&gt;` to report that it failed to handle `E2`? But then `E2` is still gone forever, replaced with "in the process of narrowing some `E...` pack, some `E` object got discarded". How can you reasonably recover from this error? Further: often `E2` is an error enum of some sort and the handler could easily have a logic error and fail to check a specific enumerated value. On the other hand, it is not necessarily a logic error for handlers to not handle each and every enumerated value. The point is, error handling is a dynamic process. It's unlikely that all the programmers who have been `switch`-ing dynamically on error codes for many decades now got it all wrong, and even if they did, it is a fact of life that different errors are not always represented by different C++ static types. Therefore, the C++ static type checking system can not be relied upon to ensure correct error handling. Hence the `assert(handled)` in the LEAF examples. I'm zajo on Cpplang Slack if you want to talk there.
Thanks a lot! Unless you are sending a pair directly or try to use a key with a different type, emplace is kind of useless nowadays. It might be also convenient to keep this member function for generic code (templates): you can rely on the fact that you can call emplace with a params that can create a `value_type` on almost any container.
Really appreciated, thanks!
No, my fault, I misunderstood. Thanks for clarifying!
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/9z8jgj/help_making_a_function_recursive/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I thought their coding standards are horribly outdated, but they're stuck with them because they have too much legacy code to change things now?
There are a number of reasons. A very basic one is that I already many thousands of classes and templates and structs and such. Creating yet still more types just to hold something like a homogeneous list of points or areas or counts or boolean flags (or a polymorphic list of somethings via base class, which is still basically a homogeneous list in terms of the actual type you are referring to), it's just not worth it. Either a basic array (down in the low level stuff) or an array collection in most of the code can do that just as easily. And you'll end up using way less code to access the slots. Lets say you did create such a structure, and you wanted to encapsulate it within a class, because how the info is stored is an implementation detail. Or they might even just be direct class members. But, you need to allow the outside world to read/write them or update them in some way. How would you do that? It's not worth having a separate method for each value, that's a lot of work. So most folks would probably create an enum and use it to let the outside world indicate which of the values to affect. If you use separate members that though will mean having a big switch statement inside the class to find which one to target (in every such type of wrapper method). Instead, you can just directly use the enumeration to index the list. Now both you (internally) and the outside world has a strongly typed index to use. All the switch statements are replaced with a simple validity check and direct indexing operation. With my new changes, even my internal indexing of the list is type safe.
To be completely honest: I'm fine with not supporting such types.
As long as methods are allowed to mutate the object they're applied to (which they are in C++, `const` notwithstanding), then it doesn't matter whether there's reference semantics or not. Sorting in place and returning a sorted copy are two different operations.
ok sure. but given that the compiler deduces noexcept from noexcept (auto), then you do know that the function doesn't throw. and therefore the deduced noexcept will never stop an exception
no -- noexcept has runtime behavior: it calls std terminate if an exception tries to propagate through its stack frame. and it has compiler warnings if you forget to catch something however, you won't get a warning if the noexcept-ness is being deduced. and you won't ever catch an exception if you are only noexcept because all your members are also noexcept 
What exactly do you think `poly_any&lt;base&gt; a = derived{}; auto b = a;` does? It is any value which has Base as a base. And any such value can be extracted as Base. 
The latest grill the committee had him declaring a hatred for capital letters. Apparently they've been using Capital_letter style naming for concept names. Most style guides I see have a big section on naming. It's mostly about consistency. Some, for instance name all of their member variables starting with m_ and others use a trailing _ ... Both are fine as long as it's consistent - also makes it easy when reading code to see what are from the class and which are locally scoped. This example code wouldn't pass code review if a style guide was in place. :)
That is the distinction. Are you modifying the span and/or the underlying buffer, or are you modifying the underlying buffer only.
I have to admit it's 3am for me and I don't fully understand what you just wrote ... maybe itll make sense tomorrow
The age old truth: the first 80% of a project take 80% of the time. The remaining 20% also take 80% of the time.
&gt; Why does one member use camelcase and the other underscore? Is this some convention? No. Coding conventions vary, but you should be consistent within a project. The code you showed looks like it's showcasing either several common conventions, or how _not_ to name things. Or it's just sloppy, who knows. &gt; And why the mixed caps and underscore in the class name? Some people like it. I don't. YMMV.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9z2yqy/ask_for_template/ea7p70i/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Possibly Microsoft are providing the compile service. They used to provide their own, but godbolt is more used. It might just be using Azure cloud Windows VMs. It might be related to compiler crash collection and analysis (especially if it's a preview compiler). Any number of options.
The goal of naming conventions are: * tell something useful about any identifier through eg. letter case and prefix or suffix * do the above with strong consistency. If you are driven crazy, this is because rule #1=2 is not respected. And I understand you. 
I think he said he hated capital letters just in the middle of names, so he would still be fine with Capitalized\_snake\_case style if that's the case, but I don't know if he still advocates for it. Though I still prefer regular snake\_case just to be consistent with the standard library (don't see a big point for differentiating against it when we have namespaces anyway).
Putting "data" in the name of something is usually something I nitpick too. Generally it means nothing, of course it's data. Maybe the author thought "Sales" was too generic of a name and was afraid to use it directly, but that's what namespaces are for.
There was *An Eye Tracking Study on camelCase and under_score Identifier Styles* though which came to this conclusion: &gt;An eye-tracking study analyzing the effect of identifier style (camel-case and underscore) on accuracy, time, and visual effort is presented with respect to the task of recognizing a correct identifier, given a phrase. Visual effort is determined using six measures based on eye gaze data namely: fixation counts and durations. Although, no difference was found between identifier styles with respect to accuracy, results indicate a significant improvement in time and lower visual effort with the underscore style. The interaction of Experience with Style indicates that novices benefit twice as much with respect to time, with the underscore style. This implies that with experience or training, the performance difference between styles is reduced. These results add to the findings of Binkley et al.’s study [4]. Future work includes conducting more eye- tracking studies (with a larger subset of identifiers and larger subject sample), on reading source code consisting of both identifier styles, in the context of a specific task such as debugging. Another possible direction is to determine if there is an advantage for a programmer to change their current style to what is determined to be a better overall style. Of course besides your private projects you rarely get to choose your programming style and just have to go with the one your team agreed upon.
Thanks. Could you provide a link (or at least the title?)
I did give the title ;) [An Eye Tracking Study on camelCase and under_score Identifier Styles](http://www.cs.kent.edu/~jmaletic/papers/ICPC2010-CamelCaseUnderScoreClouds.pdf)
Thanks, should have drunken more coffee today ;)
Why should it cover two completely distinct use cases?
You just need to use std::addressof. There are some types with legitimate uses of operator&amp;. Particularly in smart pointer / handle types, for convenience calling C APIs which often like to return owning handles and pointers as out parameters. This makes using something like unique_ptr painful, as it doesn't let you get at the underlying storage at all. You need to declare some raw pointer or handle type, pass &amp;handle as the function parameter, and then in a separate line, declare a unique_ptr to own the raw value. Most libraries for working with COM or WinRT offer a ReleassAndGetAddressOf and an operator&amp; overload that both free the underlying resource and return a pointer to storage for easy out parameter interfacing.
Is there something wrong with that? Or are you asking about what it does? To be fair here, I was translating from some custom template-voodoo that I cooked up a long time ago into what I recall of the standard SFINAE syntax. I might have messed it up.
Coroutine TS can be used to implement early return from functions. For example: optional&lt;std::string&gt; foo(int value); double bar(std::string left, std::string right); optional&lt;double&gt; example(int left, int right) { return bar(co_await foo(left), co_await foo(right)); } If either `foo(left)` or `foo(right)` returns empty optional then `example` returns empty optional.
&gt; I currently believe that the C++ language's over-eagerness to decay arrays to pointers is counter intuitive, and would like to see that change in a future C++ standard. There are so many other implicit convertions just for the C compatibility. I don't think C++ could ever get them removed, unless something like Python 2 =&gt; 3 happens.
There's no `disable_if` in C++. Boost has it, though, and so does your in-house voodoo, apparently.
Yeah I got nerd sniped by this recently. Making a catch-all template overload and SFINAEing away overloads feels icky. If you want to go to the dark side, here is a way to do it without SFINAE: https://coliru.stacked-crooked.com/a/c698f1bac284403a (standard disclaimer about not using this in actual code..)
This is indeed inconsistent. There is no such convention, maybe `Sales_data` which was suggested to differentiate own types from standard library but it does not appear nice to most people and we type `std::` anyway. There is no universally accepted coding style but no one has the right to blame you if you do it exactly as standard library does.
&gt; results indicate a significant improvement in time and lower visual effort with the underscore style. That's just nonsense, it's the opposite for me, and frankly I think you or someone made this "study" up to try to convert people to their preferred style.
Coroutine from Coroutines TS is generalization of subroutine (function). Coroutines allows multiple operations: calling (transfer control flow from the caller to start of the coroutine), suspending (transfer control flow from coroutine to caller or another coroutine without destroying local and temporary variables), resuming (transfer control flow to most recent suspension point of the coroutine), returning (transfer control flow from coroutine with destruction of the coroutine frame - local variables and temporaries), destroying of the suspended coroutine (all temporaries "in flight" and local variables will be properly destroyed). Implementing futures with coroutine uses calling, suspending (when awaited value is not ready), resuming (when awaited value becomes ready), returning (when reaching the end of the coroutine) and destroying of suspended coroutine (when the task is canceled). Implementing optionals (or other "early returns") with coroutine uses calling, returning (when reaching the end of the coroutine), suspending and then destroying (when awaiting empty optional). Implementing generators with coroutines uses calling, returning (when reaching end of the coroutine), suspending (when passing next value to the caller), resuming (when the caller requested next value), destroying (when generator is destroyed before reaching the end of sequence, for example infinite generator). Coroutine abstraction is not tied only to asynchronous computations. It is more general tool.
It may be possible to do that, but again: I'd much rather have a separate syntax for that (e.g. try) than for the case where foo and bar are resumable functions and/or calling them may suspend my current function for an indefinite amount of time. 
&gt; Something that I've sort of wondered how helpful it would be is if you could mark class data members as " &gt; really &gt; private" and make them inaccessible from even most member functions. Not very useful. I say this because the canonical solution for that already works: wrap whatever constraints you have behind a public interface/private implementation. &gt; I'm torn on whether such a constraint would even be a good idea as opposed to a smell Consider the case for std::atomic: You _could_ use a normal variable with a mutex, but because you have a synchronization constraint on accessing the atomic value, it is wrapped in a separate class. When you use an atomic variable, other private members of your class [the class using an atomic variable] cannot modify the mutex directly (the synchronized value is encapsulated at a different level than the private variables of your class).
I both love and hate their choice of title.
Right. I'm not arguing unique_ptr should do that, but there are some smart pointer types for some domains where it's useful and not totally insane. It is possible to just provide some other method, but some people like that taking a 'Foo(input1, input2, &amp;uptr)' as the last parameter of a function call LOOKS like an output. As opposed to 'Foo(input1, input2, uptr.ReleaseAndGetAddressOf())' , which is less visually obvious as collecting an output from the function. In any case, it's nice when generic code just uses std::addressof. There is no downside. We ran into a bug where on libc++ where we could not make a std::vector of ComPtr due to a stray &amp; usage in the STL implementation. The maintainers happily fixed that within a day or two of us reporting it. 
No doubt. It's more for something like /r/cpphumour ;)
How much time do you have? Do you want to work exclusively on an Open Source project?
My day job involves a custom stl implementation. Sometimes I lose track of what's in the "real" stl compared with our own :). Thanks for keeping me honest though. Seems really odd there's no disable_if in the standard.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9zcnfn/can_i_use_c11_lambda_with_libevent/ea837tp/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Personally I struggle to understand how this particular situation would be a c-compat issue. C doesn't have templates, or function polymorphism / overloading, or references, so there is no such thing as a c function that can either take an array by pointer or by reference-to-array with template parameter deduction for the size.
From the release notes: &gt; Some of the more significant changes in CMake 3.13 are: &gt;*The Visual Studio Generators for VS 2010 and above learned to support the “INTERPROCEDURAL_OPTIMIZATION” target property and supporting “CheckIPOSupported” module. &gt;*The “Green Hills MULTI” generator has been updated to include support for platform, architecture, and toolset selection. &gt;*The “cmake” command gained the “-S &lt;source_dir&gt;” command line option to specify the location of the source directory. This option can be used independently of “-B”. &gt;*The “cmake” command gained the “-B &lt;build_dir&gt;” command line option to specify the location of the build directory. This option can be used independently of “-S”. &gt;*The “cmake” “-E create_symlink” command can now be used on Windows. &gt;*The “target_link_directories()” command was created to specify &gt;*link directories for targets and their dependents. &gt;*The “target_link_options()” command was created to specify link options for targets and their dependents. &gt;*The “target_link_libraries()” command may now be called to modify targets created outside the current directory. See policy “CMP0079”. &gt;*The “install(TARGETS)” command learned to install targets created outside the current directory. &gt;*A “VS_DEBUGGER_COMMAND_ARGUMENTS” target property was created to set the debugging command line arguments with Visual Studio Generators for VS 2010 and above. &gt;*A “VS_DEBUGGER_ENVIRONMENT” target property was created to set the debugging environment with Visual Studio Generators for VS 2010 and above. &gt;*The “option()” command now honors an existing normal variable of the same name and does nothing instead of possibly creating a cache entry (or setting its type) and removing the normal variable. See policy “CMP0077”. &gt;*The “target_sources()” command now interprets relative source file paths as relative to the current source directory. This simplifies incrementally building up a target’s sources from subdirectories. &gt;*The “CMP0076” policy was added to provide backward compatibility with the old behavior where required.
Personally I struggle to understand how this particular situation would be a c-compat issue. C doesn't have templates, or function polymorphism / overloading, or references, so there is no such thing as a c function that can either take an array by pointer or by reference-to-array with template parameter deduction for the size.
Thanks. This is a useful example. I might just end up using this in real code ;) After through testing to see if it holds up against the template version of course.
The problem lies in any such C code: void func(int* arr, int size); int arr[] = { 1, 2, 3 }; func(arr, ARRAY_SIZE(arr)); // ^^^ implicit convertion from int[] to int* With removed decay, it would not be valid C++.
&gt; resumable functions and/or calling them may suspend my current function for an indefinite amount of time I don't think that it will actually be a problem. You need to jump through hoops to implement coroutine promise type which allows co_awaiting both optional and futures at the same time. When you writing a coroutine it's return value (and types of the arguments) determines semantic of coroutine which will be used in the body of the coroutine. task&lt;int&gt; foo(); optional&lt;int&gt; bar(); task&lt;int&gt; my_task() // return value type + co_* keywords is opt-in for using "task coroutine" semantics { auto value = co_await foo(); // OK auto value2 = co_await bar(); // Compile error co_return value; } optional&lt;int&gt; my_opt() // return value type + co_* keywords is opt-in for using "optional coroutine" semantics { auto value = co_await foo(); // Compile error auto value2 = co_await bar(); // OK co_return value; } Another example is composition of coroutine "semantics": task&lt;optional&lt;int&gt;&gt; my_composite_task() { auto value = co_await foo(); // co_await from task: current coroutine can be suspended here for some time co_return // co_returning from task [&amp;]() -&gt; optional&lt;int&gt; { // we now inside optional coroutine auto value2 = co_await bar(); // co_await from optional: can return empty optional from current lambda co_return value + value2; // co_return from optional }(); } If last example is what you don't like then don't write such code. This code is not worse than nested lamda inside lamda. Instead use coroutines as implementation detail of functions: task&lt;optional&lt;int&gt;&gt; my_composite_task(); // I don't care if it is implemented with or without coroutines optional&lt;int&gt; calculation(int value); // I don't care if it is implemented with or without coroutines // implementation task&lt;optional&lt;int&gt;&gt; my_composite_task() { auto value = co_await foo(); co_return calculation(value); // no confusion } optional&lt;int&gt; calculation(int value) { auto value2 = co_await bar(); co_return value + value2; // no confusion } 
It is forcing a conversion to `volatile` (one of the few conversions available on pointers) in order to make it a worse match than the size-templated overloads. (ps. I discovered now that the template on that last function is no longer needed)
From the slides, I think that it's fine that CMake isn't a build system. But I also think that it should ship with an internal ninja build by default so that you can have an out-of-the-box working experience. 
&gt;In particular, object library build-targets do no longer require special treatment and can be used as other build-targets, too, and setting dependency-relations between targets became easier in general because some restrictions were lifted. We're getting close, but that is not correct unfortunately. If you will closely look at the second example, you will notice that when you link an object library to an object library, you will notice that the first object libraries objects are **not** injected into the second libraries `INTERFACE_LINK_LIBRARIES` or added to the `SOURCES` property: add_library(A SHARED a.c) target_compile_definitions(A PUBLIC A) add_library(obj OBJECT obj.c) target_compile_definitions(obj PUBLIC OBJ) target_link_libraries(obj PUBLIC A) add_library(obj2 OBJECT obj2.c) target_link_libraries(obj2 PUBLIC obj) add_executable(main2 main2.c) target_link_libraries(main2 obj2) &gt;compiles obj2.c with -DA -DOBJ, creates executable main2 with object files from main2.c and obj2.c, and links main2 to A. Notice the lack of the `obj.c` source file in the final compilation. This is not a documentation mistake, this actually bit me when I was merrily porting over my source files to CMake 3.12. I just don't understand why, and which restrictions there are that prevent this. We are so close to making object libraries first-class citizens, but then we "forget" to propagate its source files, requiring me to manually inject them via `target_sources` and generator expressions? IMO, if we call this collection of object files a "library", we might as well let it behave like an actual library, in particular linking the library code to the target in one way or another.
And this is why we cannot have nice things in c++
So don't remove decay. Make function overloads where the array's "array-ness" is preserved preferred over decaying to pointer, where such an overload exists. E.g. no one expects to see void foo(int&amp;); ignored in favor of void foo(bool); When passing a variable declared as an int. But thats, from a high level conceptual point of view, what's happening. I have an array being passed to a function, instead of the "array" version of my function being called, the pointer-to-type version is being called instead. Since this specific situation involving 3 features that C-lang does not have, function overloading, references, and templates, can be given a special case in the standard without breaking C-compatibility, I struggle to see why it hasn't been addressed before now.
I have to admit, I'm still not seeing how that's working. Is the right-most const relevant? I'll test it on my compiler tomorrow to see what you're doing. If the rightmost const isn't needed, then the example makes much more sense.
Sorry yeah, that right-most `const` was superfluous.
&gt; The term "Modern CMake" came up with the release of CMake 3.0 in 2014 This is wrong. https://steveire.wordpress.com/2017/11/05/embracing-modern-cmake/ &gt; I coined the term “Modern CMake” while preparing for Meeting C++ 2013
I see a potential mistake. Tell me what the error you get, and let's see if we can guide you to the answer. I'd also suggest using `std::array` which would make things potentially easier. However a `std::vector` would likely be best here. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9zd32r/how_to_use_setter_and_getter_for_an_array/ea873tj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
IMO coroutines notation and pattern matching notation complement each other. Pattern matching can be used when you want to cover all possible alternatives: void example() { optional&lt;std::string&gt; msg = read_message(); inspect(msg) // We need to specify both non-empty and empty cases { [value] =&gt; std::cout &lt;&lt; "Ok, got a value " &lt;&lt; value; // non-empty case _ =&gt; std::cout &lt;&lt; "Where is my message?!"; // empty case } } Coroutines/try notation can be used when you care only for successful path: optional&lt;int&gt; example() { std::string msg1 = co_await read_message(); // In case of empty optional return empty optional from current function std::string msg2 = co_await read_message(); co_return computation(msg1, msg2); } 
For those who are confused that they had seen this before, blog post is actually from September. Previous discussion is: https://www.reddit.com/r/cpp/comments/9hmoqb/herb_sutter_blog_lifetime_profile_v10_posted/
Ah ha! I came across this today, and reddit usually tells you when posts have been previously submitted, so I submitted it thinking it would point me to any previous discussion. Thanks!
Yes, the STL is required to do this (and a couple of other things like defending against overloaded `operator,`). But luckily, not all generic code needs to be quite as generic as the STL (my code will never be used by nearly as many people or on as many diverse platforms as std::vector), which is why I'm happy with saying "I don't support types that overload `operator&amp;` or `operator,` in a strange way", because it reduces the amount of testing I have to do and simplifies the code (I know of at least one standard library implementor who had a similar opinion).
Here's my response when I got asked the same question when I posted about reproc 1.0.0: https://www.reddit.com/r/cpp/comments/92labv/reproc_crossplatform_c_and_c_process_library/e36png0/ Nothing seems to have really changed since then, it seems Boost Process still only supports terminating processes with SIGKILL and TerminateProcess, while reproc also supports SIGTERM and CTRL-BREAK which allow the child process to perform cleanup.
&gt;From there you can click 'other discussions' tab. They removed this from new reddit and it's my #1 complaint about it, very frustrating. &amp;#x200B; I was not aware of the [reddit.com/{URL}](https://reddit.com/{URL}) trick, thank you!
First of all, I think you should start by pointing out your area of interest. Do you want to make a game, desktop/mobile app, server, embedded project, OS, compiler, project in CV, project in ML, etc etc. Also, as others allready pointed out, consider joining an existing project. You could find those on github or on some "team finding app" like that [one](https://www.teamups.net/) for example. Myself, I would've liked to participate in some opensource project, but I'm not sure if I would have enough free time in near future. Fell free to PM though.
Annoyingly providing an overload for a `const char * const &amp;` causes it to prefer that over the array again: https://coliru.stacked-crooked.com/a/650084f262f2f286 Using volatile like that is a horrible hack.
If a kind soul can explain why I'm being downvoted I would be grateful... Is it really stupid to care about the semantic of your structs ?
Sorry, been busy throwing and catching exceptions at compile time in D. &gt; No, it's still a joke (I'm assuming you're defining the function in a header). Now you trying to prove something by making wrong assumption. I had normal (declaration in header, definition in cpp) function with __TIME__ in it. After changing it to `constexpr` (and moving it to header) got instant bug. `constexpr` is a source of ODR violations, slightly worse than `inline`. (`inline` is also a joke. They make everything inline, then wonder why compilation time is 100 times slower it should be). &gt; The definition of foo() may be different Right, this looks really bad for `constexpr`. It is not just this example makes `constexpr` bad. 1. Having 5 C++ Standards each with different notion of what `constexpr` is is a bad thing. constexpr auto foo() { // What I'm allowed to do here? // You can't answer this question without specifying what Standard is used. // Sure, I can `return`. // Everything else depends on some obscure non-standard command line parameter of the compiler. } People work really hard, risk their lives to adopt C++11, all they got is `return` statement. 2. Years and papers needed to spread `constexpr` over STL. I'm wondering, in such a big committee nobody asked a simple question: "Are we going to spend decades putting `constexpr` here and there and everywhere?". And guess what! We will! This might work for such a tiny library like STL, it is just not for real life. 3. How many years it will take to make std::from_chars `constexpr`? If `constexpr` is not a joke, why std::to_chars is not `constexpr`? `constexpr` got ignored by new things. 4. If `constexpr` is that good, why do we need `constexpr!` or `consteval`? Are you sure you can teach the difference? 5. Does `constexpr` imply `inline`? Does `constexpr` imply `const`? I don't know, but if it does, it is bad. Will compiler complain about `constexpr inline` or `constexpr const`? Will you colleague at code review complain? 6. Look at, for example, what D does (disclaimer: I'm not using D for myself or recommending it to anybody): static auto my_variable = arbitrary_function(); // `static` instructs to execute `arbitrary_function()` at compile time my_variable++; // modified at runtime auto arbitrary_function() // no constexpr here { // whatever, just try not to format drive C: when executed at compile time } 7. We are doing compile-time computations for 50 years, nobody asked for `constexpr`. To summarize, nobody knows what `constexpr` does, not for real life, not for new things, not teachable, still need `consteval`, implies `const` unnecessarily, nobody asked. 