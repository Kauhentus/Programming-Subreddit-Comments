Very true. I do wish there were a better way to unit test for performance. You can have absolute timings of tests, but that depends on the particular computer, and that the test was designed to check a particular feature. Maybe the tests could compare against the performance of a previous version on the same machine, but that could get quite tedious.
isn't it? Not native english speaker, and after reading 3 times here i am in the comment section trying to figure out what that means... 
&gt; call an expensive copy constructor Somewhat unrelated, but I've come to view expensive copy constructors as a design bug. If a type cannot be cheaply copied then it shouldn't be implicitly copyable. With C++'s semantics being what they are, I prefer to have a `clone` function for explicit copy operations. Generic code that really needs a copy can `clone` everything and user code is never accidentally copying a `vector` or something silly. If something is a bug, it shouldn't be easy to do accidentally and hard to spot in code review, and expensive copy operations are lurking performance bugs that fail that litmus.
Technically speaking, an open source fan reimplementation of the engine is available ([and has been for a couple years](http://opentomb.github.io/)). :)
In those cases, if I am disabling the copy constructor, I make absolutely certain to have a move constructor. Otherwise, you can't use many of the STL containers. I usually make the distinction on whether something is conceptually copyable, rather than it being slow to copy. A vector class gets a copy constructor, but a thread does not, because it doesn't make sense to copy a thread.
"Unless you know otherwise for sure, move operations are not available or they are crazy expensive." My summary.
Move semantics are preferred but the idea behind this chapter in particular is that move semantics should not always be a default go-to (even if available). For example, move semantics makes perfect sense in heap allocated containers (e.g. std::vector&lt; T &gt;). Copy construction/assignment in that case results in O(N) operations and move construction/assignment results in O(1) operations due to what is essentially a pointer copy. In practice, this might be slightly more involved depending on the container. In stack allocated containers (e.g. std::array&lt; T, N &gt;), both copy and move semantics are fully supported. However, in this kind of container, move construction/assignment results in O(N) operations. As a result, somebody can mislead themselves into thinking about a potential performance improvement. This is even worse if they make the mistake of eliding [N]RVO by returning a temporary by move construction, which is arguably not a big deal for heap allocated containers. With that said, there is a performance benefit in moving stack allocated containers. Although moving the container will result in O(N) operations, each element of the container will be subject to its own move semantics policy. If we have a stack allocated container of heap allocated data, the end result is still O(N) operations for moving the container but O(1) operations for moving each individual element.
Being Rust-dev first and lurking at r/cpp to keep improving my C++, I have a question. Why are C++ moves so problematic? In Rust moves are the simplest thing ever. In the low lower view: you have a given byte sequence representing an object, now you use it elsewhere and forget about the original one. The total amount of objects stays the same, nothing else needs to be done.
What you *can do* and what you *will do* are different things. Groovy programs are typically more prolific with closures than other languages are with lambda expressions because the concept was introduced early in the language's evolution. As a result, you'll find them in large portions of the framework and in design decisions. Some discussion on the [formal definitions of lambda expressions and closure here](http://stackoverflow.com/questions/220658/what-is-the-difference-between-a-closure-and-a-lambda) if interested.
I don't know if it exists for that platform but if it doesn't and that's important to you then Python would be the logical choice. The platforms I'm concerned with are more common, various versions of the main distributions (redhat, suse, ubuntu, etc). Across these platforms, Java has extremely consistent behavior.
You can make the copy constructor private (and with `= default`) and call it in your clone method.
I would prefer that MSVC supports C++11, C++14 and even C++17 first (sure C99 and C11 support would be nice too, but right now it doesn't even support all of C++11 without bugs that completely inhibit certain use cases).
It's kind of interesting that this is sort of how rust works. Variables bind by move semantics by default unless a type implements either [Clone](https://doc.rust-lang.org/std/clone/trait.Clone.html) or [Copy](https://doc.rust-lang.org/std/marker/trait.Copy.html). 
C++'s semantics make it tricky, yes. That said, I find that implementing a friend `clone` constructor isn't all that much different than writing a copy constructor. Assignment remains a problem. I've tried playing around with `explicit` copy operations and haven't yet formed an opinion on whether those are acceptable. :)
I'm not sure it's possible to truly represent "moved from" variables in C-like language family. Mainly because how variables are represented in the language. 
Absolutely have move if it makes sense. In my experience, we've essentially never wanted to copy a `vector` in our code, but I've fixed or found in code review more instances of accidental vector copies than I can count. _Especially_ with `auto` in the mix. It just makes absolutely no sense to say that a `vector` should be copyable because semantically and conceptually it's copyable even though every use of those semantics is a bug. I want correct and efficient applications far, far more than I want semantically clean types. :)
Huh, this is interesting. Before seeing this, i've always assumed that `unordered_map` was a pretty fast approach. The rabbit hole is deep! http://bitsquid.blogspot.com/2010/10/static-hash-values.html https://blog.molecular-matters.com/2011/06/24/hashed-strings/
Yea, I thought of that, but with complex classes, that could maybe result in undesired copies within the class itself.
https://chromium.googlesource.com/chromium/src/tools/gn/ Build system from Google. It claims to better than GYP (another build system from Google). I wonder how does it compares with Bazel (also from Google)? 
It is better than GYP by any comparison, but especially on performance (at least 10x). It is also better than bazel, especially because it was built to manage a repository that is open source, and it is entirely in C++. I think that gn will eventually replace bazel. Any google engineer to comment on my guess?
gn was written by Google to replace GYP, a build system for Chromium.
If you're using g++, you could try 1. compiling with -fno-elide-constructors -O0 2. running a performance benchmark 3. compiling with just -O0 4. running the same performance benchmark -fno-elide-constructors prevents the compiler from... eliding copy constructors. -O0 (that's "Oh-zero") is supposed to disable optimizations (to produce more deterministic code). If I understand these flags correctly, then I would expect that the times for steps 2. and 4. should be pretty different if you're successfully implementing move semantics. If the two times are the same, then I'd suspect that something wasn't implemented properly.
&gt; What you can do and what you will do are different things. Why would the second matter the slightest ? it's only a matter of human behaviour, which is in my opinion entirely irrelevant to the properties of a programming language
Shouldn't this be called hashtrie or hastrie - rhymes with pastry! - or hastie - ie hasty? Missing out on so many pun opportunities.
I thought one of the things that the official eliding included was the move constructors wouldn't break it.
Maybe something like Example ex(&amp;&amp;"test") or maybe Example ex( rvalr "test") Where you can implicitly construct a soon to be deleted Example using its Example(const std::string&amp;) constructor, and at the same time say, "I am expecting an R-value reference to result from this."
https://isocpp.org/get-started
I think you can make big projects with Python go. You just have to be much more disciplined, and have more controls in place to get the benefits out of it. I would say you can't lean as much on the language itself as C++. In other words, a small script written in Python and a large-scale codebase, in my experience, are practically two different languages. I don't think the gap is so big in C++. Not just a question for you, but for everyone: What's a good language for large projects, where development time is priority over performance? Perhaps something a little less verbose than C++. I guess I'm thinking interpreted, or negligible compile time. Having package management on the order of Python would also be a requirement.
Well reference counting is all about lifecycle management and are far less frequently invoked, so I think the performance comparison should really focus on method invocation and data access. As for the claim that PIMPL is always slower, I have to backtrack somewhat now (see [my response](https://www.reddit.com/r/cpp/comments/66t2qg/reduce_c_build_times_with_the_pimpl_idiom/dgq5tr3/) above). When I wrote my comment, I was thinking back to the project which had used PIMPL, and it was definitely slower (and more pain to maintain) compared to *regular* classes, but we had no ABI constraints. So /u/oracleoftroy is right in that the cost of PIMPL is a pointer dereference (assuming the wrappers are inlined!) whereas COM has a pointer plus vtable lookup. However a non-trivial app is unlikely to be composed of discrete classes with no virtual methods and no inheritance. Real apps have interfaces for callbacks and all sorts of things, and they really get messed with if using PIMPL. Anyway - I figured I really ought to do some benchmarks to get some real numbers rather than work with conjecture or fuzzy memories. So I wrote a dead-simple class using both PIMPL and COM idioms, and compared the relative performance. The test was set up to measure invoking methods and accessing a data member. I published [the test code on Bitbucket](https://bitbucket.org/gavinb/pimplvscom/) so please have a look and experiment and let me know what you think. It was written to be simple and standalone and portable, so take it with the usual grain of salt you need for benchmarks. The results are surprisingly mixed. For some reason, the number of iterations makes a huge difference. With the source as is, the test shows the PIMPL code is 1.6-1.7x slower than the COM version. However, fiddling with the loop counters can change this around and PIMPL can be ~0.8-0.9x the speed of COM (ie. slightly faster)! I wrote this code late last night and haven't come up with an explanation as to why the loop counts would make this difference. Open to suggestions! 
**Company**: [A9.com](https://a9.com) **Type**: Full time **Description**: We are the search engine that powers Amazon. We have a large scale distributed system for building search indexes and handling complex search queries that support all of Amazon's crazy business initiatives. This is much more than just a plain old search engine. Generally speaking, we're looking for very strong C++ engineers with good knowledge of computer science fundamentals and systems programming. Distributed systems, networking, Linux internals and information retrieval are a plus, but not strictly required. We're open to all levels of experience. We are a small team with very high standards and very high impact. More specifically, I am personally looking for C++ library developers to help me modernize our current search engine into a set of generic C++14 components. If you have a library-based approach to problem solving and want to define the future of product search, I want to talk to you. **Location**: Palo Alto, California (but we also have offices and Dublin and Tokyo) **Remote**: No **Visa Sponsorship**: Maybe **Technologies**: C++03/C++14, Boost, Python, Linux, AWS **Contact**: PM me 
Thanks for writing that benchmark, it's great having concrete timings to talk about. I noticed a couple of things. First, it looks like you are compiling without any optimizations. In Windows under [WSL](https://msdn.microsoft.com/commandline/wsl/about), I can confirm that PIMPL is slower, at least until optimizations are specified. I compiled under -O3 in clang (3.8) and gcc (5.4) (clang and gcc were run under WSL), and with cl.exe (19.10.25019) using `/O2 /EHsc /W4 /GL`. (Not a lot of thought went into those switches, I wanted optimizations and a clean compile.) Under clang, the COM version and pimpl were neck and neck. Using Microsoft's compiler, PIMPL generally performed about 15% faster, with occasional swings +/- 10%. Under GCC, pimpl consistently performed 33% faster (there was one outlier where the PIMPL ran unusually slow and COM unusually fast where the timing was near identical). Note, these numbers aren't rigorously calculated, I just ran the program a bunch of times. Second: the COM example doesn't seem quite right. You are including the implementation header in main.cpp, not the interface header. I changed main.cpp to include COM/IWorker.hpp and not COM/Worker.hpp, changed IWorker to inherit IUnknown (and removed it from COM::Worker), and moved the CreateCOMWorker() declaration to IWorker.hpp. My theory was that the compiler would have a harder time de-virtualizing the COM version and thus would run slower. In actuality, it had no noticeable impact in clang or cl.exe, and _improved_ the COM version under gcc (now only about a 8% difference between them). My (unverified) guess is that removing the multiple inheritance simplified method lookup. Interesting, cl.exe produced the fastest binaries, gcc took about 1.5 times longer, and clang about 2x. I assume it is due to WSL overhead, but I didn't verify. Anyway, that's what I observed with a quick look and admittedly sloppy methodology. It would be interesting to see how they perform with some more carefully chosen optimization flags and newer versions of the compilers (and not run under WSL). 
A better approach would be the compiler emitting an error if it found functions in derived classes with the same name as in base classes and no override/non-override keywords. 
Thank you, that's what I understood but i was really confused and didn't trust that. 
&gt; Now, a rhethorical question -- can you do that in Doxygen? How would I do that with your tool?
I don't think encouraging people to put cleanup in your macros is a good idea, at all. The place between where you create the resource, and where you check for an error (in something unrelated) could be quite far, and can easily lead to bugs. You could add an exit in between causing a leak. In essence you are encouraging people to use C style cleanup instead of RAII. You should just prefer to use classes that clean up after themselves. When you need additional clean up, ScopeGuard is a far preferable solution to what you are suggesting. I understand that your not using exceptions make these concerns less critical, but using ScopeGuard is still strictly better (and if you want broader usage/uptake, take into account the fact that many/most people do use exceptions, in many cases). Other than that, I think this exactly shows why people do use exceptions. Having to have this boilerplate in 10 layers of call stack just to report a clear error to the user and exit the program seems totally unnecessary.
You're referring to platform as machine architecture, so you're correct. I misunderstood the terminology you were using.
You're right, my bad.
&gt; TLDR - I'm going to avoid `std::vector&lt;bool&gt;` and stick to `std::vector&lt;int&gt;`, at least in my time-critical sections. That's going to be 4x increased memory consumption on a typical architecture; surely `std::vector&lt;char&gt;` would be a much saner way to bypass the `std::vector&lt;bool&gt;` specialization..?
I mean, if you wrote a library for C and you're asking for feedback, then the feedback is going to be: this is not suitable for C++, because C and C++ are different languages. We don't want to do C style cleanup in C++, because there are far better ways to do cleanup in C++. So called "C/C++", is basically idiomatic C with very small tweaks to make it compile with C++ compilers. It has basically nothing to do with C++.
1. I tried `std::vector&lt;uint8_t&gt;`, and it wasn't as fast as `std::vector&lt;int&gt;`. 2. My current job is in HFT, so low-latency is more important than low RAM. The application I'm working on typically pre-allocates 5GB of RAM, and it can go as high as 15GB under certain configurations. As long as it's not allocated during run-time, and it doesn't affect latency, nobody minds. RAM is cheap :)
pybind11 is great, I played around with it and was very impressed by how easy it was to use, how quick it was to get started with, and how thorough it is.
I suggest http://semver.org
Alternatively, try Haskell's [PVP](https://pvp.haskell.org/).
Any semver is too broad to provide any additional functionality/automation by the build toolchain (see the details for examples of what I am talking about). For example, this is a valid semantic version: 1.0.0-alpha.123.beta.20130313144700+exp.sha.3d0f921aa8868d91ee0aeb9088fa07200d6bdbf0
For such a tool like yours which aims to be used by different people with different concerns, I'd look at what packaging systems which have had to unify versioning from a lot of different things provides and find out what are the issues they are still facing. It is fine to have an stronger opinion of what versioning should mean, your kind of tool should not try to impose such an opinion. (Yes, that means that I'm thinking more about rpm and dpkg than language specific packaging systems which came early enough to impose their choice to their community, trying to do that for C++ has a risk to alienate part of the potential user base for something quite auxiliary). My personal POV has been for a long time that public facing version information is more a marketing than a technical issue -- excepted for a few things like .so and symbol version, but in practice those things are already not tied to the public version information.
&gt; your kind of tool should not try to impose such an opinion You clearly didn't read the details. Let me quote the first paragraph for you then: *A project can use any version format as long as it meets the package version requirements. The toolchain also provides additional functionality for managing projects that conform to the `build2` standard version format. If you are starting a new project that uses `build2`, you are strongly encouraged to use this versioning scheme. It is based on much thought and, often painful, experience. If you decide not to follow this advice, you are essentially on your own when version management is concerned.* 
They _can't_ have internal references (without help from something like [rental](https://crates.io/crates/rental)) &amp;ndash; that's rather the point. ;-]
Ah I think you may be correct.
All of them. Or ... you know ... you could just look over there -&gt;
&gt; So you could set it to "rc1" That won't order properly (assuming you use semver/sane ordering semantics) since 1.2.3 will be less than 1.2.3.rc1.
It's not about RAM being cheap, it's about it being slow. If you use 32-bits where you need 1 (or at most 8) you'll increase cache pressure, which in real-world, non-benchmark scenarios will be much slower.
 Cow::Cow() : pimpl{ std::make_unique&lt;cowIMPL&gt;() } { pimpl-&gt;do_setup(); } cowIMPL also has a ctor, why not initialize the members (string name, ...) in the ctor like a sane person would?
Feature request to any Microsoft folks out there: ability for the plugin to invest CMake files and automatically grab the required include paths, build targets, etc. That would rock so hard.
That's because in Rust, once you move an object, you can't access it again. It's a compile error. But in C++ you can, and moreover the moved from object will still have its destructor called, and so it needs to be in a valid state. So moving becomes more complicated. Plus for types that pre-date move semantics, moving will invoke the copy constructor. If C++ had so-called destructive moves, it could be simpler. Or just more complicated in a different way.
This link? http://stellar.cct.lsu.edu/files/hpx-1.0.0/html/hpx/whats_new/hpx_1_0_0.html Works fine for me?
&gt; The snapsn component should be either the special value 'z' or a numeric, non-zero value that increases for each subsequent snapshot. &gt; Where do the snapshot sn and id come from? Normally from the version control system. For example, for git, snapsn is the commit date (as UNIX timestamp in the UTC timezone) A date for is insufficient to assert the order of two commits in git, and therefore probably shouldn't part of what you call prequel. &gt; snapid is a 16-character abbreviated commit id That should definitively not be part of the prequel, it's not sortable at all. Git date cannot be used as part of a version number, and even with svn is difficult to assert an order ( because multiple branches ), so they should be put *after* the plus sign. ( everything before is assumed to be sortable) I did read the doc but my point is that I shouldn't have to ( as a final user trying to install a package, a distro maintainer, etc, aka someone just eyeballing a sort). If everyone use the same standard, there is no trap to fall in, or no subtle bugs. Sorry If I lead you to think otherwise. 
Stop telling me what to do.
**Company:** Cohesity. See the company [info](http://cohesity.com/overview/). **Type:** Full time **Description:** Hyperconverged Secondary Storage. Cohesity makes large organizations productive by consolidating, protecting and sharing your non-mission-critical data assets. Your essential data is instantly available when you need it, where you need it. Our ground-breaking distributed systems technology hyperconverges all secondary storage workloads into an efficient, agile and infinitely scalable resource pool. This greatly simplifies both your infrastructure and the resources to administer it. We are looking for world-class engineers to develop our disruptive, converged storage architecture. This position includes everything from building the core of an infinitely scalable file system to exploring huge information sets to presenting complex information in an easily digestible format for our customers. Our team has worked on technical feats including the Google File System, Google Search and Ads, hyper-converged scale-out systems, Netflix Real Time Bidding &amp; Cloud and Veritas Data Protection. **Location:** Santa Clara, CA, US. **Remote:** No **Visa Sponsorship:** H1 transfers. **Technologies:** C++14 on Linux. Lost of internal and open-source libraries. Networking, storage, distributed systems. **Contact:** jobs@cohesity.com or via [LinkedIn](https://www.linkedin.com/company-beta/3750699/).
Your overly aggressive and defensive attitude are doing more harm to you than good. Take a look at some of your responses to people who are freely offering their precious time. Learn the lesson quickly or don't expect much traction in the wider community.
I keep meaning to try VSCode for C/C++ but it seems like a hassle to configure when Sublime "just works" with GCC. Is there an idiots guide to getting it working? Things like build, build/run, step debugging, ??? Edit: So I just spent some time getting VSCode working with GCC and it all works but it is a bit of a pain in the ass. For some reason I had to manually set "MIDebuggerPath" even though gdb is in my system path was a bit weird. Maybe a bug? Also it is a bit annoying how it has to be *given* the output exe when I had hoped it would have been smart enough to work it out. I guess it is still preview though and these things will be fixed in time. It is nice to have step debugging in an editor, something Sublime lacks. However hitting F10 too quickly can cause it all to fall down :P 
Sorry to jump on your comment but do you know of an idiots guide to those things in sublime? Thank you.
I didn't need any for Sublime. Just make sure GCC is in your path and select Build (Ctrl+Shift+B). Sublime doesn't support step debugging which is why I am interested in using VSCode. 
This looks great. Does anyone know how we can enable intellisense auto complete/ prediction for external c++ libraries like OpenCV, Eigen, PCL etc in VS code. Thank you.
Thank you so much it is in my path didn't know I could Ctrl+Shift+B. I recently switched to ubuntu from windows and miss Visual Studio dearly.
That's because /O3 isn't a flag in MSVC. If you compile with /Ox (full optimizations) you will notice that the code gen is a lot better. The compiler is producing a warning that it is ignoring the flag /O3, but godbolt doesn't seem to be displaying that directly. Updated godbolt link: https://godbolt.org/g/slH9cL
Yes, it really needs per-workspace include paths. Having a global list seems like a fertile ground for subtle bugs.
This looks like it's getting to be pretty good! Nice work MS! I'm still on Emacs with RTags for C++ because VSCode (even with the new changes) isn't as accurate or complete. Code's GDB interface is pretty anemic too, it doesn't even support `target extended-remote`. But damn if Code doesn't look beautiful. Surprisingly good performance, too!
It's a nice extension I have to admit but its template parsing/semantic analysis is rather poor than I have expected. Is there more information about the IntelliSense engine itself? For example what standards does it support? What is missing? I've quickly disassembled the "Microsoft.VSCode.CPP.IntelliSense.Msvc.linux" file and it seems that they are using technologies like antlr (For parsing and analysis, I guess), msgpack, protobuf, ... It actually seems that this isn't the IntelliSense engine which is used in Visual Studio (understandably)...
Setting up the build commands can be a bit tough coming from sublime, but they're much more versatile and can be customized pretty thoroughly. There are default tasks setup for debugging and such (iirc), but building comes down to you: https://code.visualstudio.com/docs/languages/cpp github got mad about syntax highlighting but here's an example of the build command I use for a super simple single-file build but w/ a decent amount of external libraries: https://gist.github.com/fuchstraumer/fd880220e5eb21fec9c3b77f80dc8f0d I'm no expert though, there are probably some issues with that
No kiddo, they modify it to suit their needs and for them doesn't matter if they screw the performance of anything they don't need or don't use. 
I was going to say the same thing. The benefits aren't worth how much it slows down the IDE. 
CMake support is on our backlog. There is an open issue for [compile commands JSON](https://github.com/Microsoft/vscode-cpptools/issues/156). I'm not sure if anyone put one up for full CMake support, but we are tracking that internally anyway. Feel free to head over to our [GitHub issues list](https://github.com/Microsoft/vscode-cpptools/issues) and report issues or ask for features. -Bob [MSFT]
Ah, thanks. Good job
Prior to this update, semantic analysis wasn't actually being attempted anywhere in the extension. The parser employed was just looking at "tags" in the header files it opened to provide relatively quick results. However, [please report any issue you have with the extension on our issues page](https://github.com/Microsoft/vscode-cpptools/issues). We are bringing features online in the new IntelliSense engine bit by bit. For this update we have quick info tooltips (hover over a symbol), and error squiggles. The engine is actually based on the same engine that Visual Studio uses in the IDE, but for Linux and Mac there is a "clang mode" that we use instead of the "Microsoft mode" which is used for Windows. We use the C++14 standard to compile C++ files. We actually didn't end up using protobuf, but some classes haven't been renamed yet. It's on my list. :) -Bob [MSFT]
I'm the maintainer of the main CMake extension for VSCode, and I've had cmake-server support for a few months now, as well as an [extension API which exposes it](https://github.com/vector-of-bool/vscode-cmake-tools/blob/develop/src/api.ts). A lot of the C and C++-related extensions for VSCode have been very poor in terms of releasing regular updates and the kind build system integration that I've wanted for a long time. I used to use vim with YouCompleteMe, and set it up to find and read `compile_commands.json` for the current directory, and it gave me the best C++ autocompletion/go-to-definition experience I've ever found in an editor. (I also use Python regularly, and the Jedi-based completions were excellent as well, but those are already present in VSCode). One of the reasons it is *so bad* in other editors is that I regularly use non-standard include paths (in large quantity), and having to set those up in the editor is an absolute chore. YCM consuming `compile_commands.json` made it a breeze, once a project was configured, I got *perfect* completion and go-to-definition immediately, without any setup required. `compile_commands.json` isn't perfect, though: it doesn't export headers, so the default YCM reader just shrugs when asked to complete in a header file. I wrote my YCM config to "normalize" the file paths so that a header's "compile command" would be the same as a corresponding source file. On the other hand, cmake-server exports include paths and flags for *source groups*, not individual files, and files themselves are members of source groups (including the headers). All the tools are there, it's just a matter of gluing them together.
[@cohesity's latest tweet](http://i.imgur.com/KRJcPdN.jpg) [@cohesity on Twitter](https://twitter.com/cohesity) - ^i ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Cheers. I got it working. Still more work than it should be imho. Progress is being made though which is good. Maybe one day it will be my editor of choice. 
Proper monospace declarations are already there, actually. For everything else, use the ~~force~~ frames. Specifically, to reformat function declarations according to the coding style of the library being documented, change Lua function `getFunctionDeclStringImpl` in `c_utils.lua`. As of now, the most straightforward way to tweak the frames on per-project basis is to make a copy of `doxyrest/frame` dir, adjust it for your project and then pass it to Doxyrest with `-F $NEW_FRAME_DIR` command line option. You can even mix the project-specific frames with the official ones by supplying multiple frame dirs. 
I am acknowledging your comment for what it is and letting it go. Namaste. ;-) 
&gt; The third part I use is a half-baked attempt at encoding build configurations. These ones and zeros correspond to compile-time flags that affect the behavior or supported feature set of the compiled library. I actually use this to check that users load the right library that matches the headers they compiled against, and it has been really helpful for that. Basically, the ability for users to ask for certain capabilities to be present. That's an interesting idea, thanks for mentioning. &gt; I'd recommend spending a bit of time thinking about encoding configuration in there as well. For now we concentrate only on source packages. The nice thing is that the source package revision (the only part that use `+&lt;something&gt;`) will fall off for a binary package so you can re-purpose it for something like this. Definitely an interesting idea. &gt; Thank you for working on this. Thanks. And I appreciate the feedback.
The problem I hit with this, when I open a file i have no useful information. It can then take a while to index the relevant symbols. Is there a way I could specify what I want indexed now and what can be deferred. The core of our app is around 2000 files(with a lot more symbols), having that information indexed while deferring the rest would save a lot of time! 
&gt; VS Studio Visual Studio Studio?
We do prioritize indexing the files currently open in the editor and any includes referenced by those files. Everything else is deferred. If you open a new file we will index it and its includes immediately. Unfortunately, we don't currently report that status back to you in a way that lets you track progress. If you are not seeing symbols for the files you have opened, that sounds like a bug and we would like to get more details from you on our [issues page](https://github.com/Microsoft/vscode-cpptools/issues). -Bob [MSFT]
&gt; Implement such a tool instead of fussing around [...] My plate is kind of full right now so why don't you take a stab at it? I will then integrate it into `build2` so we have automatic version compatibility checking. 
Let me try to explain the "irrational" part (and, to be clear, I don't mean it in a sarcastic/insulting/etc way; this is basic human psychology): I believe we all agree that existing build systems for C++ (CMake, autotools, etc) are, well, let's say *hairy*. But you have to use something so you went through the pain and invested in one of them. And now it more or less works. Now comes some random guy and says that he is building a new build system for C++ from scratch. And not only a build system but a build toolchain (with package manager, etc). At first you probably thought he was some flake like so many of them. But he keeps at it. And the stuff that you've seen kind of makes sense sometimes. So, *irrationally* you start to worry: Did I make the wrong decision? Was all this pain and suffering unnecessary? Will I have to redo all my projects if this thing takes off? The natural human response to a situation like this is to fight it. I am sure you have heard the saying: *first they ignore you, then they fight you, then they join you*. So I guess we are in the fighting stage.
&gt; My plate is kind of full right now so why don't you take a stab at it? What's in it for me? 
Fame &amp; glory? Seriously, though, solving a nasty problem for the C++ community sounds like a nice motivation to me. Though from reading comments here I would think twice if I were you ;-)
I eventually get them. Just, very slow :( At least it doesn't crash the language server in this plugin. So there is hope! 
Rock! ✊ We drew
Does this version finally works with visual studio 2017?
UB is not a great workaround; the supported workaround is to define `_HAS_AUTO_PTR_ETC` before including any headers.
You don't need to do any of that. `std::map` has a nice `at` function that gives you a reference to the value, or throws `std::out_of_range` if it doesn't exist.
But then you end up with a bunch of crap, like `auto_ptr`, the old binders and who knows what. I prefer to use a clean standard library and add a temporary workaround until boost gets a fix out. Although I understand this is undefined behaviour, it has no consequences in practice.
UB has the consequence of making it a non-option for any real codebase. ;-] I'd rather take 30 seconds and patch any code using std::*n*ary_function than take 30 seconds and intentionally inject UB into my code, but to each their own I guess. EDIT: I guess people love technical debt? Downvote away, children!
There's no _real_ good solution here. You can: - patch boost manually; - use `_HAS_AUTO_PTR_ETC`; - add missing definitions to namespace `std`; or - downgrade to C++14 All of them are [global solutions to manage a local problem](https://blogs.msdn.microsoft.com/oldnewthing/20081211-00/?p=19873) and they all make me unhappy. The one that has the _least_ impact on a codebase is, in my opinion, adding the definitions to namespace `std`. [edit: It will also be portable to other standard libraries like `libstdc++` and `libc++` once they become C++17 compliant.] [edit #2: A quick `grep` of the include files for `ry_function` gives me 327 hits, so it's definitely not a "30 second" patch.]
This is not a local problem; it's a problem in Boost that affects everyone, or will when they upgrade toolsets. If it were a local problem there wouldn't be multiple people discussing it in multiple places. ;-] Consequences aren't inherently negative. Indeed, one solution&amp;mdash;patching Boost and _contributing_ those patches&amp;mdash;has _positive_ consequences, which is surely better. &gt; edit: It will also be portable to other standard libraries like libstdc++ and libc++ once they become C++17 compliant UB is portable now? Yikes.
The Ranges TS adds the ability to pass such a function (or pointer to data member) to most of the standard library's algorithms. It calls these functions "projections", and can be passed in addition to comparison functions (avoiding altogether the need for a sort order parameter since the comparison function already takes care of that).
In C++ if you declared a virtual method in base class, the method with the same signature in all derived classes is implicitly 'virtual' and this is a requirement of the backward compatibility. So you can't just fail the compilation because it will break a lot of legacy code.
Everything is working for me *except* I have been unable to build the Boost.Python libraries. It finds my python install and everything seems to work, but I am missing all python libs and dlls from my output libs directory. There are no build errors, it just fails silently. 
&gt; Undefined behaviour isn't some magical thing that cannot be controlled or understood. I can control UB by not introducing it to my codebase in the first place. ;-] My original comment was simply to point out the supported mechanism for working around this problem until Boost is fixed. I'm not sure why you feel so strongly about defending ill-formed code, but we'll just have to agree to disagree on this one, because spending any further time defending the idea that UB Is Bad™ is just silly. EDIT: If you alter your stdlib the way you're advocating and _don't_ rebuild Boost then you already have ODR violations. And yes, ODR violations **do** break things.
&gt; Indeed, one solution—patching Boost and contributing those patches—has positive consequences, which is surely better. At least report this issues to appropriate library in Trac. I think you talk about this issue: https://svn.boost.org/trac/boost/ticket/12972
Sure, but then you're throwing and catching an exception, which is generally a very expensive thing to do, and best reserved for truly exceptional cases. If the "key not present" case is relatively common -- as it seems to be here -- then using `map.find()` is likely to be very much more efficient.
True, but the problem is very easily fixable. Even in a code base with a thousand classes, adding a keyword would take a few days, tops. The task can easily be automated. 
Oh cool, you're on Reddit! (I'm the guy from github who can't get clickable errors working. Everything else is awesome though, thanks for your hard work)
Holy crap, that seems to be working! I love you right now. 
The browse engine treats paths as recursive by default. The IntelliSense engine acts more like a compiler, so it needs all of the folders containing header files specified since it won't go searching for them. Knowing this about the compiler, many frameworks I've used (e.g. Boost, msgpack) generally only have a single include folder that needs to be added to the include path. I know about Qt, but have never actually used it before. If you would like to [file a feature request](https://github.com/Microsoft/vscode-cpptools/issues) for us to investigate a way to support Qt better, please feel free to do so and we can discuss the requirements in more detail. -Bob [MSFT]
I don't work on any of the debugging features, but I can certainly pass this feedback along to the debugger team. -Bob [MSFT]
&gt; You'd be far, far better off contributing to a widely recognised open source project e.g. fixing bugs for them. That's the stuff employers actually need in an employee. But unfortunately not what they usually look for. Even though that piece of paper is pretty much useless--[CS != programming](https://scontent-dft4-2.xx.fbcdn.net/v/t1.0-9/18118720_1690947737586233_2267119243427547094_n.jpg?oh=408057fd44f6f0656c7ffbe756839e9c&amp;oe=59818F72)--it's pretty damn tough to get through to an HR drone that you'd rather someone who has chased knowledge themselves than buy into a "degree" from someone that did nothing at all outside their immediate school assignments. That self-educated person had better be massively over-qualified and they're going to get less pay. Just how it works.
Just install Xcode and use the version of clang that comes with that. Note that it also comes with a binary named gcc and g++ but those are actually copies of clang and clang++, not GCC. If you want GCC you must install it from something like home-brew.
Amazing! In this case maybe it's even feasible to go one step further and take the pointer to member as template parameter. sort(vec.begin(), vec.end(), mless&lt;&amp;Candidate::id&gt;);//constexpr template variable would make operator() inline the member access.
If you're using CMake, I'll shamelessly plug [my extension](https://marketplace.visualstudio.com/items?itemName=vector-of-bool.cmake-tools), which is meant to simplify the build process within VSCode. It also has support for "one-click" debugging with no additional setup.
I'd really like to see some form of "compact lambda" in C++. I'm particularly fond of Swift's syntax (I use Elixir which has a similar syntax: `std::sort(vec, &amp;(&amp;1.d &lt; &amp;2.id))`). One of the challenges of implementing "compact lambdas" in C++ is capture semantics. Should captured variables be by-ref? by-value? I dabbled in trying to add it to Clang, but I didn't get very far. I still think projections have a place, and I think having designatable/named arguments would really help. For example, in Python: l.sort(key=lambda l: l.strip()) l.sort(cmp=lambda a, b: a.upper() &gt; b.upper()) Since both `key` and `cmp` have defaults, I only need to specify the one I want to change by name. In C++ this isn't currently possible.
&gt;rvalr This is C++, new keywords are generally a big no-no.
The idea of move semantics is fairly new, and before that, the C++ committee thought having a billion auto-generated member fuctions and implicit referencing were bloody great ideas. That shit needs to be worked around now.
Xcode is not a compiler though, its an IDE. It ships with a compiler (clang).
&gt; Indeed, one solution—patching Boost and contributing those patches—has positive consequences, which is surely better. My take on Boost [GitHub](https://github.com/DanielaE/boost/tree/my-1.64.0) builds (and passes the testsuite) with /std:c++latest and /permissive- just fine. PR are slowly trickling back into Boost.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [DanielaE/boost/.../**my-1.64.0** (my-1.64.0 → 45afe67)](https://github.com/DanielaE/boost/tree/my-1.64.0) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dgu0nqk.)^.
Pointer arithmetic in general is only defined in certain cases, like arrays. `vector&lt;T&gt;` doesn't allocate an array of `T`s, just a large blob and creates elements within it. So how can `vec.data() + 2` work?
Hi Bob, thanks for the response! The VSCode team is really attentive and has a great community outreach. &gt; 5) I'm not familiar with these codebases but the symptom sounds a bit like (2) in the sense that I would expect preprocessor support in the new IntelliSense engine to help here. In these cases, it's not preprocessor issues it's build system issues. For example, let's say the code uses a function `void port_isr_switch()`. Within the project directory structure, there are folders for different targets with a file that defines this function with an implementation that's appropriate for that architecture: `ports/arm/cortex-m0/port.c` and `ports/arm/cortex-m4/port.c`. Only *one* of them is compiled into the resulting binary, based on rules in the Makefile. I think if it were setup like this instead: #if defined(PORT_CORTEX_M0) #include ports/arm/cortex-m0/port.c #elif defined(PORT_CORTEX_M4) #include ports/arm/cortex-m4/port.c #endif Then preprocessor support might do the job. However since the target choice is done within the Makefile, it wouldn't help. The indexer would still see all implementations of `void port_isr_switch()` in all the target directories, and Go To Definition would most likely go to the wrong one. One workaround on my end is to simply remove all files that aren't used in my port. However this means I have to fork the code for each project, which is kind of painful and makes it more difficult to keep the code up-to-date (it's third party).
Don't bother about inlining of `operator ()`. The optimizer will do his job in that case. The value of a member pointer can be traced back to its constant initial value at both points where dereferencing taking place. So the variable `_mptr` will be wiped out completely. And without this variable all the wrapping stuff will become unneeded. Any modern compiler can do such a simple optimization. In the machine code there will be only the comparison itself.
Note that implementing just about anything to the standard levels with 100% compliance is damn near impossible for most mere mortals, and that's ignoring the specifics of `vector`. :) With `vector` some of the big issues that I am aware of can arise around the requirements of things like `vec.push_back(vec[x])` and similar variants needing to work. Typical re-implementations of `vector` found in perf-sensitive domains will just assert that no self-references are used in those cases and call them unsupported rather than trying to conform to the standard, since the gymanstics required to support it can be a bit complex and involve making extraneous copies. Microsoft's copy of the STL just fixed a bunch of bugs in that area as one example. The further reason why it may be worth to loosen the standard is evidenced by Microsoft's STL being broken there for many many years and relatively few people even noticing or caring. :)
I'm not sure that's true, but I'd have to dig around in the standard to check. `vector` doesn't actually allocate a bag of bytes: it uses standard allocates which return array-like types, e.g. `allocator&lt;T&gt;::allocate(n)` returns storage as-if `T[n]` I think. Or that's the intent anyway, though perhaps the wording is too weak there. That wouldn't need a loosening of requirements, though, it would require a strengthening of the wording around allocators.
in all seriousness, in such cases I'd use a string, not because I really care, but if you're not necessarily limiting to two cases I'd just let people type in whatever and not think about it this has nothing to do with c++ though
How would that work if `T` isn't default constructible?
You can't create arrays of a non-default-constructible type.
I' just skimed through the doc so I'll just provide a usecase. For instance, you shouldn't rely on the 1sec commit date frequency. Imagine a release bot tool automaticaly merging and building from multiple branches from different repos, automaticaly rebasing stuff in order to generate the proper validated release. It's easy to assume that a lot of thing will happen in a very second (those tools usually run on large build clusters).
You wrote `new T[n]`. The `operator` is untyped, and wouldn't give you back an array of `T`s. It just gives you a blob of data.
The code the compiler emits is always correct (modulo unintentional bugs.) The thing you're referring to is not talking about the code the compiler emits, it's talking about unwinding the stack by external tools, such as a debugger. In the specific case of (a) no debug info or explicit unwind table data, (b) no stored frame pointers, and (c) certain architectures like x86, it becomes impossible for a third party to reliably unwind the stack. But that has nothing to do with the inherent correctness of the code, which will always work properly according to the requirements of the language standard. And the debugger can be made correct simply by giving it the debug info, i.e. the missing extra metadata that the compiler had which allowed it to generate correct code, and which the debugger does not inherently possess. 
I don't quite see a difference here. When I throw an exception the runtime stack-unwinder seems to have enough information about the stack to do stack unwinding, even with no stored frame pointer. Can't a debugger use this information? My guess: The information available is simply not enough for the debugger and it only intended for stack-unwinding when an exception has been thrown?
&gt; The annoyances are where the Standard specifies too much of the strong guarantee Interesting. I'd love to hear more about it. Offering the strong guarantee at all for the flat containers (e.g., sorted vectors) was a design problem until we got sub-committee guidance to only support the basic guarantee (if an exception is thrown in the middle of an insert/erase, there's no way to safely and efficiently return the container to its prior state).
&gt; When I throw an exception the runtime stack-unwinder seems to have enough information about the stack to do stack unwinding, even with no stored frame pointer. Can't a debugger use this information? That only really applies if the implementation is using table-based unwinding, like DWARF. That's not the only way to do it though. The code to unwind the stack for a given frame can be directly emitted as code and then just executed if there's an exception. The debugger can't really do anything with that. Having the debug information tells it the extra data necessary (e.g. what objects need to be destructed, where they live on the stack, what registers to restore, etc.) But that information isn't needed by the code itself since it's inherently handled in the generated code, and can be stripped. 
It was funny for me.
Does this bug exist in other compilers too?
This bug is very serious. Ability to write complex classes without memory issues main advantage of C++ over C. Such bugs should not happen in a compiler.
Hopefully this brings more attention to a _serious bug_ that's been present and reported for over _2 years_...
&gt;I am wondering how reliable stack-unwinding really is? Does it always succeed in calling all the destructors and clean up the stack when an exception has been thrown? If a destructor called during stack unwinding exits with an exception, `std::terminate` is called (aborting the stack unwinding process, obviously) - C++14 [except.ctor]/3 If an exception is thrown but there is no matching `catch` then it is implementation-defined whether the stack is unwound before `std::terminate` is called. ([except.terminate]/2). So the following program could differ amongst compilers: int main() { T t; // T is some type throw 1; } `t`'s destructor may or may not be called, but the compiler must document what happens (and should behave consistently). I always ensure my destructors can't throw, and I start my "real programs" by something like: int main2(int argc, char **argv); int main() { try { return main2(argc, argv); } catch(...) { // handling } } which ensures that stack unwinding completes (important for threads to clean up properly!) and we get sane error messages even in the most unexpected situations.
Allocate storage, then create several contiguous elements with successive calls to non-array placement-new. 
Oh I see now I should have been more specific. I meant construct the array at once. My bad.
Use [`std::function`](http://en.cppreference.com/w/cpp/utility/functional/function) and lambdas. // your button class class Button { public: std::function&lt;void()&gt; onClick; }; // register a handler button.onClick = [](){ std::cout &lt;&lt; "button clicked\n"; } // invoking the handler if (button.onClick) button.onClick();
/r/cpp is a tough crowd Don't worry though, I laughed :)
Not a Microsoft product. Nobody got the joke that Microsoft infamously coined that phrase first?
Constructing an array actually involves constructing each element in the array, there isn't a distinct procedure "construct array as a whole". It seems to me your question is just about the syntax of providing the arguments corresponding to each element's constructor call
During optimization, there are no data members in the code. They have already become offsets. One of the basic optimization techniques is to make a lot of passes through the code trying to push all the constant stuff into the functions and removing redundant variables. The initial value of the pointer `_mptr` can be computed at compile-time. In fact, it's just a fixed offset. And, after several passes, this offset can be pushed up to the comparison operation. Expression `lhs.*_mptr &lt; rhs.*_mptr` will become something like `lhs+offset &lt; rhs+offset`.
https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66139
_mptr is a data member. MSVC's optimizer can do constant propagation and the other things, *but it has trouble seeing through data members*. It is within the realm of possibility that C2 has gotten smarter since I last checked years ago, but I'm pretty sure my knowledge is still accurate. I offer reddit gold for a counterexample (note: with MSVC, not any other compiler).
The swapping requirements rule out the small buffer optimization. As I recall there's also some requirement that rules out optimization for POD types via `malloc`/`realloc` (used as *as-if* implementation of standard allocator). And you can't pass raw uninitialized buffer space to API functions and accept data placed there. And the code for adding items has to deal with aliasing in the middle of possible buffer reallocation. These design choices make `std::vector` needlessly inefficient for the most common use cases: it's like it's designed for inefficiency.
How about constexpr data member pointer, is that optimizable the same way as template parameters? Then I would think about something like... template&lt;typename T, typename U&gt; constexpr auto mless(U T::* mptr) { return [mptr](const T&amp; lhs, const T&amp; rhs) { return (lhs.*mptr &lt; rhs.*mptr); }; } //mless is constexpr sort(vec.begin(), vec.end(), mless(&amp;Candidate::id)); //still possible at runtime sort(vec.begin(), vec.end(), mless(m_keyMember)); But this still doesn't get rid of the use of mless() yet. I'm inclined to build an implicit wrapper for member, so it would become... template&lt;typename T, typename U&gt; struct InlineMemberAccessor { constexpr InlineMemberAccessor(U T::* mptr) : _mptr(mptr) {} inline U operator() (T&amp;&amp; object) { return object.*_mptr; } U T::* _mptr; }; template&lt;typename T, typename U&gt; void Sort(std::vector&lt;T&gt;&amp; container, InlineMemberAccessor&lt;T, U&gt; member); Sort(vec, &amp;Candidate::id);//Sort&lt;Candidate, int&gt;
Me too 
You are absolutely right about code should be optimized for reader, but I would argue the lambda is just bad for both writer and reader. Not that functors would be any better in this case; Any additional class, helper function or template parameter would increase the confusion level for the reader. To my experience, most of our colleagues would feel comfortable with max. complexity capped to C + class. But lambdas and templates are the basics! Yes they are, but like a lot other C++ features, the best use of them is to hide them in libraries. That's also what I consider to be truly "optimized for readers": We are willing to write more library code, put extra effort on simplifying the API, and properly document them so the readers no longer need to go through all the type-system mind model.
Switch doesn't use FreeBSD, they use a heavily modified 3DS (custom) kernel. WiiU was unixy though. 
+1
FYI, Just tested in 4.4.6 and it's also present in this version as well
Hey, this is very nice! I only had five minutes to look at the code, but I only found one minor quibble. I honestly don't remember seeing such a well-documented package before - the comments are complete and clear, but also not wordy, and are clearly distinguished from the similarly-good implementation comments. The one example file I saw was equally well-documented, and would be an excellent place to start cutting and pasting for your own work. Good stuff! The next time I start a C++ program that needs command line arguments, I'll look at your package first. -- Oh, the quibble? Structure inheritance is by default `public` - so this: struct unexpected_argument_error : public std::invalid_argument { is equivalent to this: struct unexpected_argument_error : std::invalid_argument { I told you it was a quibble! EDIT: and your dog (on your github page) looks a lot like ours. :-D
Although it's focused on performance measurement data, you may also find it interesting to compare with or benchmark against: https://github.com/HdrHistogram/HdrHistogram_c Further information and examples: - http://hdrhistogram.org/ - https://github.com/HdrHistogram/HdrHistogram/blob/master/README.md - https://psy-lob-saw.blogspot.com/2015/02/hdrhistogram-better-latency-capture.html - http://massfords.com/HdrHistogram/
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [HdrHistogram/HdrHistogram/.../**README.md** (master → 4f36f7a)](https://github.com/HdrHistogram/HdrHistogram/blob/4f36f7a74f33e374b9b1ba218a63168b0d58aecf/README.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dgv8gk2.)^.
btw, you don't need to define constructors of the derived classes if all they are doing is passing to the base class. e.g. ``unexpected_argument_error``. You can use the ``using`` clause. e.g check this: https://godbolt.org/g/jcy8k8
&gt; Because writing a histogram is easy, right? ...right? Hardly, and dimensionality isn't the hard part, floating point precision is. The simplified form of the issue is that due to how truncation errors work, you are over constrained if you do the intuitive thing and specify all three of min/max/width. If you're not very careful your histogram can be either subtly inconsistent, or else behave "surprisingly" in certain edge cases. It's trivial to write something that takes a collection of data and creates a bar plot. It can be surprisingly less simple if you need to consistently move bi-directionally between histogram and raw data (e.g. use computations done on the histogram to go back and manipulate the raw data somehow) I've worked on multiple projects where both raw speed and numerical accuracy were primary concerns, and so far every time the original author of the histogram functionality failed to think deeply about the mechanics of floating point precision, and the same set of subtle bugs eventually cropped up. Do you think this is something you've properly handled? (I poked about in your code briefly, but didn't stumble on any relevant sections).
Hi lurkotato! Of course, clang-tidy will work, because it's only parses source code and doesn't compile it by the fact. I think the worst case that can happen - false positives. But every inspection in clang-tidy has many protections to reduce false-positives and be accurate as possible.
A histogram differs from a plain multidimensional array similarly to the way std::vector differs from a plain C array. Sure, you can do all of the same operations manually, but it's more work and more error prone. (Would you rather compare the size and capacity in order to decide whether to reallocate and copy data before inserting a new item, or just call `push_back`? Would you rather do N side calculations to find the bin index in each dimension, keeping track of whether it overflows or underflows, or just call `fill`/`insert` to put the next datum into the correct bin?) I've written a very similar library with a slightly different set of features myself because it would be virtually impossible to do my work without it (I work in more or less the same field as HDembinski). That said, I still find the choice of storage type in this library very peculiar. The issues noted with overflowing integers or saturating floating point numbers are real, but I have truly never heard of anyone having difficulties with them, despite the many users of the rather simplistic histograms provided by ROOT, for example. In my own work I have found it far more valuable to define bin types which do things like compute appropriate errors/uncertainties on the contents (the variance is not always the right choice for this). It looks like this library does support different storage types, although I can't find how to actually do so in the documentation. I would never use the included `standard_storage`, and only sometimes want to use the `adaptive_storage`. 
You're talking about floating point issues with the bin edges, right? I've certainly run into some of these as well, but fixing them (at least the ones I found, and then others I imagined after I realized what was happening) mostly didn't add any new blocks of code, but involved subtle changes to comparisons used in the axes' bin look up code. It would be interesting to hear more about what kinds of edge cases you've run into. 
I dare anyone actually designing something into a compiler that leverages this UB. This is a case of "yes, technically this is UB, but oh well, we've got to ship". Furthermore, this is hopefully only needed for boost 1.64. I'd hardly call it "technical debt". As soon as you upgrade boost, this hack is not needed.
I confirm. And it doesn't have to be directly: throwing in a destructor during an exception will call abort (that's why only protecting your main with a catch-all isn't enough)
Writing ill-formed code to work around a problem that you don't want to deal with properly, even if "temporary" (which is always how it starts), is the **epitome** of technical debt. And I envy you if you've only ever experienced benign ODR violations rather than actual "consequences"... ;-]
&gt;`-Wall -Wextra -Werror` What about `-Wpedantic` tho? ;P
The GP indicated that they insist on using prebuilt Boost binaries; those binaries must necessarily have been built with existing definitions for these types.
Hah! I forgot about `-Wpedantic`. You helped me catch [two extra semi-colons](https://github.com/vietjtnguyen/argagg/commit/65e1538858d1ace098d554ddab23906d298467a1).
This is me spitballing from memory so it's possible I'm misremembering some key detail but... Yeah, generally all boils down to data lying essentially on a bin edge. The simplest form of the problem everyone runs into is that you have some data you know spans the range [min, max]. You want N bins, so you pretend you've got infinite precision and compute the bin width to be `(max-min)/N`. Then you define a function that takes a value and returns the bin index as `bin(x) = floor((x-min)/width)`. Of course then due to floating point vagaries you're likely to find that `bin(max) == N` (we're zero indexed so it should be N-1) and stuff is falling outside of your histogram that you're not expecting. That's when you might start adding clamping, or outlier bins, or just getting very very precise with how you write your functions that find bin indexes or look up bin edges. It still doesn't necessarily save you though. Imagine you did some computations on your histogram, and figured out you wanted to split up your data into two groups, everything in `[0,i]` goes left, `[i+1,N-1]` goes right. You write a simple function `LEdge(i) = i * width + min`. But again due to floating point vagaries you find that sometimes `bin(LEdge(i)) == i-1`! According to your histogram you should have split the data with maybe 50 values to the left and 50 to the right, but if you actually compare each entry against your split point, you find it's 49 and 51. Depending on your application and needs the world is now on fire... So then you vary carefully re-formulate things so that even with floating point arithmetic you *always* have `bin(LEdge(i)) == i`, but if LEdge is still a "simple" (floating point) mathematical equation, there may well exist some `epsilon` where `bin(LEdge(i) - epsilon) == i)`, and you're still in the same boat. I think the final solution is going to depend a lot on your actual needs, which is a part of why I wouldn't trust a third party library to handle this kind of stuff unless I don't care too deeply about the results.
It's been almost a month and my book still hasn't arrived and i feel comfortable enough to say i know the basics, but i really don't know where to start, do i use other libraries? Should i use other libraries? If you have some sort of link for any starter up projects in C++? And yes, i did Google but nothing really realistic comes up, just asking on what kind of programs to start?
I should expect advice on compilation times from the author of doctest! Great library by the way, I use it in `argagg`. Anyway, if I understand this correctly the default behavior of the header will be just declarations and the onus is on the user to ensure that the implementation preprocessor definition exists before at least one `#include` for the library?
Yea, like, for example, bias.
Exactly. So the header would be more like a header file and a source file of the library being concatenated into one for convenience with the contents of the source file with an additional ifdef guard. But I don't think this is the right way for argagg to go ;)
That is an awesomely insightful comment! Thanks a lot just for that! And yes, I did think about that a lot! :) I assume that the workflow consists of histogramming data first and then doing analysis with the counts. My class internally uses integers for the counting to avoid the issues with floating point numbers (floats get capped once you run out of bits in the mantissa: 1e16+1 == 1e16), and a special machinery successively increases the integer bits to makes sure that the integers never overflow (you rather run out of memory). If you are interested in more details, click on the documentation and the section "Rationale" where all this is explained. After filling the histogram with data, you can query its counters, which are returned as doubles. So you can do computations with them in double precision.
I guess jokes make it impossible for a bug to get taken seriously somehow?
One thing you should be aware, clang on windows is very slow as far as I remember, i may be wrong and hopefully others will correct me, but just keep in your mind 
That's not a joke, that's just snark.
Ah, thanks for the extra context, I misunderstood you. I thought you wondered about whether I use floats for the counters. Some implementations do that and it can lead to counts getting capped. And yes, I also thought about the special case of integral data. My library offers specialized binning algorithms for both cases. You can customize all the binning algorithms that use floats to use integers instead so that the integral arithmetic is exact. The concept "left edge of bin" and "right edge of bin" only make sense for floats, not for integers. The template machinery has been adjusted to take care of this. My library is also extensible. If you have a very special binning scheme in mind, you can plug it in and still use the rest of the machinery provided by the library.
I think there should be a distinction here between "stack unwinding" and "stack tracing". Debugging tools need to perform stack tracing in order to provide you with information about the state of the stack in its current state. When an exception is thrown, stack unwinding can work in a mechanical way without the restriction of having to provide an outsider with information about the stack (ie. just executing a block of machine instructions) and doesn't have to *interpret* the current state of the stack.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [vietjtnguyen/argagg/.../**test.cpp#L876-L898** (master → 21da9eb)](https://github.com/vietjtnguyen/argagg/blob/21da9ebd430eedcd901650f750324c8394e1e421/test/test.cpp#L876-L898) * [vietjtnguyen/argagg/.../**test.cpp#L901-L917** (master → 21da9eb)](https://github.com/vietjtnguyen/argagg/blob/21da9ebd430eedcd901650f750324c8394e1e421/test/test.cpp#L901-L917) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dgvod6y.)^.
dunno, It's fast enough on my Ivy bridge, however, benefits what Resharper++ brings far outweights theoretical slowdowns
Really? https://pbs.twimg.com/media/C5_KSL7UsAAyVJT.jpg sure looked like a claim they're using FreeBSD at least partially as it's part of the license agreement screen. I wouldn't be surprised by them just borrowing parts of FreeBSD though since it's been done MANY times before by everyone from Microsoft to Sony. 
In addition to the other comments, I will point out that stack unwinding has been part of c++ since the language started in 1998 (and actually Bjarne Stroustrup had a version in Bell Labs in 1979). Destructors have always been a part of the language. If it didn't work, a whole lot of code would have problems.
True... I just wanted the memheap init (could be expensive) happen once globally.
**Company:** [Leap Motion](https://www.leapmotion.com/careers) **Type:** Full Time **Description:** We are building hand tracking software and hardware for next-gen mobile VR/AR systems. We are both a hardware company and a machine learning company, so when we say full stack we mean everything from managing AWS instances to PCB layout. We're hiring C++ developers for a number of very different things, including optimizing CV/ML code for particular hardware architectures, Testing, API development, and more. We're open to enthusiastic junior candidates that have done work on their own, but generally speaking are looking for intermediate or senior developers with demonstrated expertise. Personally, I'd *LOVE* to hire a build and tools engineer to help me wrestle with Jenkins, upgrade our compiler versions, and make our developer workflow simpler. **Location:** San Francisco, CA! Specifically, we're in a shiny new office in SOMA right near several iconic music venues and a whole lot of great food. **Remote:** Generally speaking, no, but in VERY rare instances some exceptions have been made. **Visa Sponsorship:** For extraordinary candidates **Relocation support:** Yes **Technologies:** A lot! We are currently making use of and could use more help with the following. Every one of these things is currently used. Standards &amp; Languages: C++98 and C++14, adopting C++17. C. x86, amd64, arm, SSE, and NEON ASM. Python 2&amp;3. Platform/Build system: CMake targeting: Windows x86 and x64 with MSVC2013 (I'm working on 2015-17 right now), Mac (clang), Linux x86 and x64, arm32 and arm64, and Andriod (all gcc presently). Jenkins, Bash and sometimes Docker for automation. Libraries: Boost (regex, program options, some C++11 compatibility for older compilers) Qt5, OpenGL, SDL, protobuf, flatbuffers, Bullet, GTest, Eigen, libusb, and many more. Also we built and actively use [Autowiring](https://github.com/leapmotion/autowiring) among others. Other technologies and important skills: Unity &amp; Unreal plugin development, Computer Vision algorithms, Machine Learning, Software Architecture, C API Design, Linux kernel/usermode driver development, Distributed systems (AWS), Remote Debugging, FW/HW Reverse engineering. **Contact:** Ideally, apply through our website! Feel free to email your resume to recruiting@leapmotion.com with the subject line "Leap Hires Redditors".
Thanks for the feedback! You're right, unfortunately, the only way to parse custom types is to set the option's type to `po::string` and then convert the string to the custom type, which is cumbersome. This is indeed a drawback when setting types first. As to the single hyphen: If you say that it comes up often, I'm definitely going to change that. I suppose I don't have to do anything beyond just handing over the hyphen, right? I don't have to replace it with /dev/stdin or something?
They're just borrowing, based on a browser exploit that showed 3DS functions and not FreeBSD ones. 
How were any of the versions released since then considered "ready" for release?
"Do A unless B." How is that self-contradictory or "nearly" self-contradictory?
In my experience, the authors of most C++ histogram libraries have written them exactly because they are fed up with dealing with ROOT. A lot of us in particle physics absolutely detest ROOT. Personally, I prefer to write my analysis code in C++ because I can write obvious code, and typically have it run at least as fast as numpy, and if I have to I can write fancy code which is often a good deal faster or more memory efficient. Anything that would have been done in pure python would be far too slow, and I haven't yet encountered anything that I could do better with any of the python libraries than I can do for myself in a few minutes of coding. 
It literally takes 10+ seconds for it to update my editor after each change. Any gains I get in productivity is quickly negated by waiting 10+ seconds every few minutes.
One of the great advances made by [[nodiscard]] is the new ability to apply it to *types* instead of functions. Proposed Boost.Outcome applies [[nodiscard]] to expected&lt;T, E&gt; and I would expect so will Expected as eventually standardised. I don't know why it can't be applied to lambdas, or more specifically their member operator(). One would have thought from the standard wording that it was intended.
For the single hyphen I think it's typically treated as just convention, as in the parser doesn't do anything with the hyphen other than parse it like a positional arg and it's up to the program to interpret that as "hey, you should read from `stdin`". At least that's how I've been doing it.
Someday, the struct might become a class and you'll have things to remember to change. No harm in being explicit.
As a functional programming guy, I'd rather say God bless for being explicit! ;)
How is it different from GNU's `getopt_long`? Note that there is a fairly portable [musl implementation](http://git.musl-libc.org/cgit/musl/tree/src/misc/getopt_long.c) in 146 lines of code including the header. Yours has 713 LOC excluding comments. What functionality makes it 5 times as long in terms of LOC? Also, `getopt_long` supports multiple options like `./foo -a 1 -b -a 2 -a 3` and keeps the order of options (i.e. successive calls give you a, b, a, a in that order). In your example, you are using an associative array. How do you implement these features?
Wow, I have been looking for something like this, thank you!
Very good job. I have been working on something very similar, but yours looks much nicer.
Funny I arrived at the same conclusion last w-e and whipped out a header only arg parser. Maybe I'll share when it's debugged and tested.
yes, I think, nothing at the user level can compare with a system level malloc w/o tradeoffs... but if you can make some, it's worth to see what you could get out of it... but what memory arena implementations did you refer to with some solid benchmark runs?
Are you referring to the ETW trigger? Reading malice into that is serious tinfoil hat territory.
I've just started out learning C++. Thusfar I've been using CodeBlocks and GCC. Could someone please recommend an alternative compiler? Preferably open source but not copyleft, ie. MIT or similar. I'm looking at Clang atm, and it seems to match my needs, but I was wondering if anyone with more knowledge and experience can recommend something. TIA
The `INTERFACE_INCLUDE_DIRECTORIES` property was introduced in CMake 2.8.11, and the `INTERFACE_*` properties really came into their own with 2.8.12. (If upgrading CMake to a version newer than 3.0 is viable (and it almost always is!) I would highly recommend it). If you haven't learned much about it, read up on [`find_package()`](https://cmake.org/cmake/help/v3.5/manual/cmake-packages.7.html) and the kind of magic that you can do with it. **SERIOUSLY IT'S SUPER USEFUL**. I'd also recommend using CPack to generate system packages: then you get packaging for RPM/DEB/MSI all for free without much hassle. CPack can be a bit tricky for more complex packages, but a header-only library should be fairly straightforward. And to allow people to add argagg as a submodule: The most reliable way to detect being submodule'd is this: if(PROJECT_SOURCE_DIR STREQUAL CMAKE_SOURCE_DIR) # Will only be evaluated if the last call to project() was at the root of the source tree message(STATUS "I am not a submodule") else() message(STATUS "I am a submodule!") endif() You'll want to do this to skip things like `install()` so that you don't end up installing files in a parent project's install tree.
&gt; add it as a submodule If you're willing to add `libname` as a submodule, why not `#include &lt;libname/libname.h&gt;` in your files? It's quite a bit easier that dicking around with so-called "C++ build systems". 
* The code is clean, consistent, easy to read, and professional. * Great use of standard library functions. * I definitely do not like the mix of braceless / fully braced statements. * I'd prefer asserts over exceptions, but let's not discuss religion. Nice work!
After a 3min random read... In "array list", the loop for `contains` has the wrong upper bound, no? To avoid copypasta, consider implementing `contains` in terms of `find`. To avoid reimplementing the wheel, consider using std::find. The looks are neat :-)
Yeah, to be honest, I have trouble understanding you, although I stand to what I said. My library has several binning algorithms. You can make bins with equal width or non-equal width. The goal of the library is to cover all imaginable cases, since it is supposed to become a standard (as much as boost stuff is standard). When you want to cover an integer range of [0, 99999] with 10 bins with equal width then the bin width has to be either a floating point or a rational number. My library allows you to use rational numbers for the bin width, so that you have exact arithmetic again. But even if you use floats, I don't quite see the problem. Whenever you enter the realm of floats, you have to deal with rounding errors. There is nothing this or any other library could do about it. It is really interesting how much people here care about binning integral data, because for me as a phyicist that is an exotic case. I added some support for integral data, but so far I thought it is not something that people would use. Fortunately, because the library is so flexible, it is easy to add better binning algorithms for this case, once I understand better how you people expect it to work.
I got your main point. I use Python for analysis, too. Nevertheless the code that fills data into my histograms is invariably written in C++, because loops in Python are slow (if you don't use numpy as a workaround), and because the code that delivers my data is written in C++ anyway. What I am saying is that this library was designed for exactly this use case. Define your histogram layout in Python, pass it over to some code that runs in C++ and fills it. Then get your histogram back in Python and do data analysis with it. PS: I will not rewrite ROOT, that's not a one-man project. Writing a good histogram class already took me a fair amount of my spare time.
https://github.com/rampantpixels/rpmalloc - there are actually many implementations that fare better than most malloc implementations. Also your title says general-purpose, which this is not. Also with 10 seconds of googling I was able to find multiple resources on memory arenas. https://github.com/cleeus/obstack http://www.boost.org/doc/libs/1_63_0/libs/pool/doc/html/index.html http://loki-lib.sourceforge.net/index.php?n=Idioms.SmallObject https://en.wikipedia.org/wiki/Region-based_memory_management 
What is rare? * Storing several resources in an aggregate? * Factory functions that throw exceptions? * Using aggregate initialization? This is not "rare," it has a test case of perfectly normal C++14 code that fails reproducibly.
ASCII text will definitely provide you proper cross platform representations but as you say that tends to take up more space. Straight binary type representations run the risk of changing the value from save to load due to the inherent in-exactness of floating point representations. Using the IEEE format is one possibility but have you considered [binary coded decimal](https://en.wikipedia.org/wiki/Binary-coded_decimal)? With a packed format you effectively have ASCII style serialization with half the bytes needed since the digits 0-9 can each fit in a 4 bit nibble, you get 2 digits per byte.
&gt; because loops in Python are slow (if you don't use numpy as a workaround) NumPy isn't a workaround. It's the correct way to work with arrays in Python. With [root_numpy](https://github.com/scikit-hep/root_numpy) you can read a TTree in as a numpy array, then call `np.histogram` to get a histogram from this. Having to manually loop over a container and fill a histogram item-by-item is one of the deficiencies in ROOT's design, not a positive. EDIT: Missed the bit where you said you could fill a histogram from a NumPy array faster than `np.histogram`. Assuming the benchmark is accurate (e.g. you didn't specify the binning for your histogram, while letting `np.histogram` calculate it automatically), this definitely makes your library interesting.
Asserts are a very C kinda thing... I think in C++ it is generally a good idea to use exceptions. It is similar to use malloc in C++.
I have a question about line 308 [here](https://github.com/matheussilvapb/data-structures/blob/master/array-structures/array_list.h): static const auto DEFAULT_MAX{10u}; I've never seen this "10u" before. What's going on here? 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [matheussilvapb/data-structures/.../**array_list.h** (master → e62e7dd)](https://github.com/matheussilvapb/data-structures/blob/e62e7dd7f899eda5cc3232a359b47ce1681f928b/array-structures/array_list.h) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dgwoj8c.)^.
You just started learning C++? You should not care about this bug. The mere fact that it's been around for years implies that you likely never would have known this bug existed without having read it here. GCC will work fine for your needs for many years, trust me. All software has bugs, so all compilers have bugs. If the bug's not biting you, you have no concerns. Most of the hollering around here is just people who want to holler. 
If you're only using the command line, you may have to configure the Clang/C2 environment yourself. Details about file locations can be found on the [VC Blog post about compiler toolset layout](https://blogs.msdn.microsoft.com/vcblog/2016/10/07/compiler-tools-layout-in-visual-studio-15/).
If you're using a decent debugger, crashing immediately is a wonderful thing (can access the callstack and all var values - it's often enough to identify and correct the problem without needing to reproduce or file a bug) - so I'm fond of development-only assertions. In contrast, breaking into debugger only after realization that exception wasn't caught is too late since the context that led to trouble is already lost. First-chance exception catching is an improvement upon usual practice, but most teams blow it and allow exception throwing to be too noisy for this to be practical.
When doing computation on graphic cards or simd like avx on Intel, for the full speed you are not ieee754 because of no special values like NaN...
Your teachers don't care about code repetition?
My teacher just had some unit tests ran on our inmplementations, he didn't actually looked at the code.
Sure, PM me your email and your name.
If you can ensure all senders and receivers use the same exact representation of the IEEE 754 format then the binary representation from one to the other should be exact. But IEEE-754 has the concept of both normalized and non-normalized which could have an impact. Consider this example from [Low-level Floating Point Marshalling Between Different Instruction Level Architectures ](http://ecet.ecs.uni-ruse.bg/cst06/Docs/cp/SII/II.4.pdf) &gt;Program A and program B are exchanging floating-point data over the network. Program A is working with very small numbers without using normalization, for example - exponent 8 bits, fraction 24 bits. Program A is sending this number to the program B, which keeps all floating-point data normalized. Trying to normalize the number program B causes exponent underflow. The result is fatal loss of data. To prevent this, there must be a consistent floating-point data conversion from one format to the other. And this description of denormalized values: &gt;If the exponent is all 0s, but the fraction is non-zero (else it would be interpreted as zero), then the value is a denormalized number, which now has an assumed leading 0 before the binary point. Thus, this represents a number (−1)s × 0.f × 2−126, where s is the sign bit and f is the fraction. For double precision, denormalized numbers are of the form (−1)s × 0.f × 2−1022. From this you can interpret zero as a special type of denormalized number. &gt;As denormalized numbers get smaller, they gradually lose precision as the left bits of the fraction become zeros. At the smallest denormalized value (only the least-significant fraction bit is one), a 32-bit floating-point number has but a single bit of precision, compared to the standard 24-bits for normalized values. The OP didn't mention if the host machines / applications were using the exact same architecture/IEEE-754 format. So as long as both ends are using the same assumptions then no issues. 
The PlayStation 2 uses an "Almost IEEE". Bit layout was the same, but rounding differed. The PlayStation 3 and some GPUs encourage great SIMD performance on a "half precision float" not defined by IEEE 754. 
short answer: no, as explained in boost.endianness FAQ: &gt; An attempt was made to support four-byte floats and eight-byte doubles, limited to IEEE 754 (also know as ISO/IEC/IEEE 60559) floating point and further limited to systems where floating point endianness does not differ from integer endianness. &gt; Even with those limitations, support for floating point types was not reliable and was removed. For example, simply reversing the endianness of a floating point number can result in a signaling-NAN. For all practical purposes, binary serialization and endianness for integers are one and the same problem. That is not true for floating point numbers, so binary serialization interfaces and formats for floating point does not fit well in an endian-based library. But, if you restrict your requirement to those well defined platforms (that's actually most of modern desktop and mobile platforms), you may simply do something like that: uint64 EncodeDouble(double value) { union {double f; uint64 i;}; f = value; return i; } double DecodeDouble(uint64 value) { union {double f; uint64 i;}; i = value; return f; } and read/write uint32/64 as little endian or big endian bytes.
This looks confused to me. Lossy conversions only happen when you have two different representations which each support different sets of values, and convert between them. Even then, it depends on which two representations, and the conversion direction. Endian conversion, for example, isn't lossy. If your file and your internal variables use the same format - e.g. both use IEEE754 floating point - there's no conversion and no loss. Conversion from ASCII to IEEE754 binary floating point is lossy for the following reasons... 1. The ASCII string may represent a too-large or too-small value. 2. The ASCII string may represent a large value with too much precision - values of that size can be represented, but not with that much precision. 3. The ASCII string is presumably decimal. Finite decimals cannot (in general) be represented exactly as finite binary numbers. For example, decimal `0.1` is binary `0.0001100110011...` (copied from [here](http://www.exploringbinary.com/why-0-point-1-does-not-exist-in-floating-point/)). 4. Is there any significance to leading zeros (or spaces) in the ASCII numbers? 5. Not all ASCII strings are numbers. Reason (3) would also apply if you were converting two ASCII number representations (e.g. decimal to binary) where both have points, or where the from-representation uses rationals (or symbolics). The incompatible bases are the issue, not how you encode the resulting digits. There are also numbers that can be represented in ASCII in other bases, but which can't be exactly and finitely represented in decimal (such as the base-3 number `0.1`, more commonly known as the rational `1/3`, with decimal form `0.333333333...`). IIRC, excluding whole numbers, the set of values that can be represented finitely and exactly in base 2 doesn't overlap at all with the set of values that can be represented finitely and exactly in base 3 (or base 5, or base 7 etc). The overlapping possibilities for the fractional part (other than zero) depend on shared prime factors in the bases. 
Generally nice code, but.. delete node; return node-&gt;parent;
Half-precision has been included in IEEE754 since the [2008 revision](https://en.wikipedia.org/wiki/IEEE_floating_point#IEEE_754-2008). I imagine the PS3 etc are still doing "almost IEEE". 
x87
Asserts are for ensuring internal invariants are correct. Assert early, assert often. A failed assert should always result in an immediate int 3 breakpoint. Even in production code. Exceptions are for communicating error state in normal operating conditions.
Actually, with my implementation you aren't required to preallocate a memory arena/region. It helps if you have an idea of your application memory requirement, but it will grow automatically as required if you don't. I think it makes it general purpose, doesn't it. 
Software Developer here. Your code looks good and clean. Congratulations. I've seen production code WAY worse than that. Suggestion: how about implementing some algorithms now that you have the data structures?
Assertions in production can yield unintended consequence of developers using them more sparingly - but I somewhat agree in principle, depending on application.
Seems more a fit for /r/cpp_questions, but http://stackoverflow.com/questions/1452721/why-is-using-namespace-std-considered-a-bad-practice-in-c
The point of an exercise isn't performance-centric. It's just about implementing the data structure. Thus, asking about performance metrics is just moot and orthogonal.
Usually it limits the scope. If you do using namespace std, the whole library gets imported. If you use std::cout, you only import std's cout. So, if you want a different ifstream, you replace std with a new ifstream Some people don't use using (example: not *using std::cout* and type *std::cout &lt;&lt;* every time). I'm mixed on that one. 
I don't think there is anything groundbreaking there, just does what it says...
!removehelp
Yea, submodule inclusion or the "externals" folder is a bit of a design smell to me. Really who's responsibility is it to provide dependencies? The user or the project? I say the user. Why should a project force me to use their version of dependency A when I have dependency A installed on my machine and managed by the package manager? However, there's a lot of give and slack, especially with header-only libraries, so long as the one definition rule isn't violated when linking.
I'll take a look at the `INTERFACE_*` stuff if they're available in CMake 2.8.11 (most of my `$WORK` is in the enterprise Linux 7 environment which has 2.8.12). I haven't used CPack directly but the few packages I've seen generated from CPack are very non-standard. After learning how to do RPM packaging I see that there actually isn't that much complexity that CPack is hiding. I still need to learn Debian packaging but my guess is it's the same story there. Packaging is really easy when the build is sane and has sane install targets. Also, I see that you want to not install files in a parent project's install tree, but I need an install target for users who are not including things in a submodule way, like during standard packaging. If you were to include this in some externals-folder submodule setup are you invoking `add_subdirectory()`? It's been a while since I've used `find_package()`, but I remember moving away from it for some reason. I think a big part of it was how non-standard it felt, where I was having to look up every CMake module to see what variables it was setting and what variables to use. I believe I also ran into a find package module that did not respect `CMAKE_PREFIX_PATH` when searching, which was a big no no since that effectively takes control away from me, the one configuring the build with more information than the find module script about where the dependencies are. Out of curiosity, for the projects that you use this set up for, what are your target platforms? Is everything statically linked? Is there a way for the user to override your provided dependencies and provide their own?
At least it's true to the reality of the industry...
Sorry wasn't precise enough. On Intel which can compute IEEE754 when you want speed on ICC, GCC or visual you use the float_control to fast, and in that case you are not conformant on exceptions rounding... 
That may be a good point. I haven't tried using an assertion implementation that also throws an exception. I don't think that would get in the way, and I think it would be a good thing in some situations. Actually, just about every time I've used assertions I've been using a custom implementation/wrapper for it (sometimes even with a dialog with options), so I agree it's a good idea to consider what works best in the situation and put it there.
Look at the sidebar, its got rules and where you should post these (not here), think about it more carefully. :P
Asserts are for reporting precondition violations, even/especially in C++. Exceptions are for reporting postcondition failures.
That might be fine for release builds, but when I'm developing I want a crash dump. If the stack is unwound, that crash dump is useless.
That's very true, but the important bit is that the _representation_ will always be the same, so serialization will always be consistent on IEEE-754 systems.
How would you not use new or malloc for an user-level memory management. Well, I guess you could do a static allocation with something like char heap[whateversize]; As for the generality I agree with obstack you referenced: "General purpose memory allocators request memory from the operating system and provide it to the programmer. When the programmer frees a block of memory, the allocator is free to return it to the OS or to keep it for later reuse. For performance reasons, the allocator will probably keep it and organize these free chunks in linked lists, so called free lists. " And with memheap you can request arbitrary sizes. 
Thanks for the answers
This is hardly something new, to be honest.
95% of the libraries in Boost only depend on Boost &amp;ndash; ***crazy***!
Boost is hundreds of megs, uses its own custom build system, and is rightfully known for bloating build times. It isn't something to add to a project lightly.
If you hang out on the Rust IRC, I've tried to compile some of them. Some of them require explanation which I don't feel like giving right now, and many don't immediately feel like mistakes. This is from multiple years as a Rust programmer, I'm on two of the Rust teams, so I hope that you trust that I know what I'm talking about. - Ever stabilizing `transmute`. It's a negative benefit abstraction. - Not having true references - references in Rust are pointer types, as opposed to C++ references. Rust people are actually attempting to get around this, kind of, with the 2017 ergonomics push. It's not great. - `std::copy` and `std::copy_nonoverlapping`'s parameter ordering was swapped from what you'd expect wrt the other pointer functions. (this made a lot of people very angry, and was widely regarded as a bad move) - `as` casts are absolutely the worst (after `transmute`). C style casts in a modern language (`main as u8` D:) - function pointers can't have lifetimes - The syntax in general is incredibly non-extensible. For example, generics are `&lt;'a&gt;` for lifetime params, `&lt;T&gt;` for type params -- how do you add const generics to this system? or mutability generics? This is the stuff I could think of. I'm not sure if there are other things that don't just boil down to "we need to wait for Rust to mature".
x86 FPU registers are 80 bits wide; dumping to disk as a 64-bit double and then reading it back in will lose the 16 extra bits of precision, which could change stuff down the line. That's a bit of a reach though.
Just a minor note re versioning: b35 won't order properly against, for example, b4 or b123. I would recommend the b.35 form.
Agree. The difference is in the following: - if compiler fails the compilation you *SUDDENLY* have to spend a lot of time fixing the issues on code that was already tested and ran successfully - if it is a new code or code being reworked / refactored working hours are already supposed to be allocated to it
I should have been more precise: orders according to the semantic versioning rules (I assumed it is semver based on the use of - to separate the pre-release component). Sort's -V seems to favor shorter strings.
thanks for the pointer, I will have a look how they do floats. EDIT: it looks good. i like that cereal tries to make the transition from boost.serialization easy. it also seems to keep the good parts of boost.serialization, while fixing the annoying parts. one thing that puzzles me, however, is that it drop support for versioning? so how does one write an evolving class so that it can still read older versions of itself? EDIT2: Well, cereal just takes the easy way out: //! Saving for POD types to portable binary template&lt;class T&gt; inline typename std::enable_if&lt;std::is_arithmetic&lt;T&gt;::value, void&gt;::type CEREAL_SAVE_FUNCTION_NAME(PortableBinaryOutputArchive &amp; ar, T const &amp; t) { static_assert( !std::is_floating_point&lt;T&gt;::value || (std::is_floating_point&lt;T&gt;::value &amp;&amp; std::numeric_limits&lt;T&gt;::is_iec559), "Portable binary only supports IEEE 754 standardized floating point" ); ar.template saveBinary&lt;sizeof(T)&gt;(std::addressof(t), sizeof(t)); } 
i was thinking along the lines of your approach, with the difference that i would not assume that the host uses a IEEE 754 representation in memory. I was thinking of implementing the IEEE 754 composition/decomposition in platform-independent C++ code.
This is off-topic for our C++ subreddit.
You might include a single header file, but that doesn't mean the single header doesn't depend on other parts of boost. The fact is that you can't just copy that one header file somewhere an use it, it is still interwoven with the rest of the thousands of boost files. 
Use the abstractions. If it's actually critical to get it optimized, check the assembly and fix if necessary. Avoiding abstractions is not worth it.
Its a little bit early for that but I like your optimism! I am thinking, that a logical progression would be to try for going into Boost first, while networking-ts gets finalized and goes into the standard. This gives Beast time to mature, test the interfaces, and evolve. Once the networking-ts is part of the standard then a Beast proposal could happen.
True - I plan on switching to a single integer for the "version" once Beast makes it into Boost (since Beast will inherit the Boost versioning system).
That's a nice list, thanks. I was actually expecting mistakes in D that could be discussed in the context of Rust (whether Rust had addressed them or not), so I don't have much to discuss about Rust's mistakes :)
&gt; And with memheap you can request arbitrary sizes. It looks like in a very round about way you are allocating memory by calling operator new - which will just call malloc underneath, which in turn will call system calls/kernel functions to actually map the memory into a process' address space. Are you really saying that this is 90 times faster than malloc? I have a very difficult time believing that. This really looks like quite a mess of misunderstanding. 
In terms of separation of concerns, I consider weighted sampling to be a very small concern / conceptual block, ideally separated from the rest of whatever you want to do (be it selecting a string, calling a lambda, etc). Avoiding loads of templating and just mapping a weight to an integer index seems the most simple approach to me, and keeps the implementation truly tiny; I would imagine this is also the thinking behind [std::discrete_distribution](http://en.cppreference.com/w/cpp/numeric/random/discrete_distribution), which seems to be largely what's being reimplemented here. In such an article, I would hope for at least a diagram of how/why the inversion method works (it's a beautiful and easy to explain thing) for didactic value, and maybe for practical value, going further than binary search to constant time via the [alias method](https://en.wikipedia.org/wiki/Alias_method). Personally I like to use a fixed point CDF for my selection, so that I can directly use the 32 bit output of an integer RNG without losing precision to 23bit float, or expanding way too much to double precision (53 bits).
Hi, Thank you for the pointers, I did not know about this alias method, it looks really interesting. I will have a look at it and also look into your other suggestions as well. In particular, I think I can get rid of most of my code based on std::discrete_distribution indeed. It looks I have some reading and catching up to do :) Thank you again for the good pieces of information, I completely missed these, it will be a good opportunity to work on this for the second iteration. Quentin
Ah, lol. I don't know anything about D :3
I sometimes wish the SPEC benchmarks were abandoned; or at least, the test cases exhibiting undefined behavior pruned instead of introducing switches to "hold back" for the sake of continuing benchmarking this specific case... and new tests introduced instead.
Looks like both plain arrays and std::array are producing the same output with 2017,though neither are being vectorized: https://godbolt.org/g/VMiVqp
:) probably not, you have a good point. I guess the real question is: why is boost.serialization not just settling for the same and be done with it. IMHO it is better to have a feature that works for the 99 % than not having a feature at all, but Robert Ramey seems to feel otherwise.
&gt; Whether you externally convert that to a float is then entirely up to you. That's what I meant about kicking the can down the road. You can't choose the needs of your users. If they need this and you force them to handle this "lossy" conversion themselves, then they are far more likely to do it inconsistent with your internal machinations. &gt; In practice, however, it cannot imagine a case where this would be relevant. Neither could I, until I watched our very expensive software explode in the hands of a million dollar customer:) It's not about the magnitude of a particular error being large, it's about surprising inconsistencies. Its similar to using Runge-Kutta instead of a symplectic integrator for orbital dynamics (assuming you have experience with those). You can use as accurate of a Runge-Kutta scheme as you'd like, but your conserved quantities wont be respected. If you're unaware of that then you can be surprised when your orbits decay. In the case I alluded to with exploding software, a few points shifting from one bin to another violated assumptions made by other code sections, which snowballed into some serious errors. This was also in the heart of a very computationally expensive section, so extra logic to repair the inconsistencies externally cost a lot more than very carefully reworking our histogram code to be explicitly aware of how it handles truncation error. Sadly I no longer have access to the code that actually watched for some of the particular edge cases. &gt; You cannot research what you find interesting. Ah, you may be limited to what is "sexy" or "promising", but at least grant committees are open to just generally expanding human knowledge. You're far less likely to get a company to sign off on something if it's not going to directly make them money in the next quarter or two...:) Luckily the recent fads with machine learning have opened up a lot more software jobs that care both about mathematics and performance computing.
&gt; I apply masking one some dimensions (cuts) and sum over others. It is efficient, but the code does not look pretty. I think `np.einsum` does not really help there, but it is cool. I think the idiomatic NumPy way to do that might be to apply the cuts and create a new ndarray with only the 'rows' that pass the cuts, then do the summation. In this case, doing it in C++ is probably sensible though. &gt; Well, I do use my histogram lib in exactly that context. My histogram is serializable in C++ and can be pickled in Python. Lucky you. As far as I can tell, this is somewhere between difficult and impossible with the ATLAS frameworks. &gt; Sorry, that's a flaw of the htmlpreview feature from github. So far I have no better solution, suggestions are welcome. You can download the documentation, and open the files in your browser to see them with correct CSS. The solution is to use Github Pages instead of the HTML preview.
ugh yes. I don't consider myself a C++ expert, however I also don't consider myself an absolute beginner. I have been working full time for about 2-3 years in a job where most of my time is spent doing C++ development. For the projects I do, we pretty much exclusively use C++14. When I started the job, I was doing a lot of passing by `const &lt;type&gt;&amp;`. However now with move semantics and RVO/copy-elision it seems like the general wisdom is to pass and return by value ([example](https://stackoverflow.com/questions/10231349/are-the-days-of-passing-const-stdstring-as-a-parameter-over)). The thing is, with C++11 and C++14, RVO is not guaranteed. It is fairly easy to tell whether RVO is being performed for user-defined types; for your test just have some kind of print/flag/whatever in your constructors that lets you know if the object is being allocated, moved, or copied. However I haven't figured out a way to do this for STL types and containers. So it feels like gambling when passing and returning large instances of STL containers, hoping that RVO will be performed. I know that C++17 has [guaranteed](https://stackoverflow.com/questions/38043319/how-does-guaranteed-copy-elision-work) [copy elision](http://en.cppreference.com/w/cpp/language/copy_elision). However C++17 is [not finalized](https://web.archive.org/web/20170430195532/https://isocpp.org/std/status), and therefore features [aren't fully implemented](https://gcc.gnu.org/projects/cxx-status.html) (without using a dev branch of a compiler, like gcc 7). Plus, the projects I am on are probably not going to arbitrarily upgrade compilers (long term version support, etc.) So for now I am stuck with what C++11/C++14 provide and, at least with RVO, it feels like a crapshoot. Am i missing something? If anyone has advice or suggestions on figuring this one out, I am open to them... (wow this turned into a little bit of a rant) edit: forgot a word 
Yeah I tend to follow a similar thought. On the one hand, working in both C and C++, I find C++ really pleasant at times. It brings a lot to the table over raw C in the bookkeeping-overhead-on-the-programmer department. However, I sometimes find C++ incredibly frustrating and annoying. RVO is a big example of that. Because now instead of having to know C++, really I need to know C++ and what exactly the compiler will decide in all of the cases where I do something that the standard says "the compiler is allowed but not required to..." And I am typically *very* understanding of some of the C++ quirks. Like I get why it is something like `std::unique_ptr&lt;MyType&gt; obj = std::make_unique&lt;MyType&gt;(args, to, MyType, constructor);` or `auto obj = std::make_unique&lt;MyType&gt;(args, to, MyType, constructor);` because pointers are pointers, and building a container on top of them is going to end up with something like this. That's the side effect of adding smart pointers 30 years after the language was implemented with raw pointers. You can't just go arbitrarily changing 30 years of syntax.
&gt; The real problem about depending on optimizations is that at the time you write it, you check that it optimizes nicely, and you are happy... but there's no guarantee that it'll continue to optimize nicely in the future. Performance regression tests. Anecdotally, I actually end up catching a lot more bugs by writing benchmarking code along with unit-tests. Maybe I'm just bad at writing tests.
I think it is my fault. I should have said explicitly that memheap isn't a malloc replacement by any means. I thought it was clear from the source. I sometimes use memheap::allocator with stl containers that could make them a few times faster (with the obvious tradeoffs) than std::allocator which calls malloc directly. The benchmarks are just to show what you could gain if you can make those tradeoffs comparing to calling malloc directly. There is nothing more to that really...
If you don't get rvo, you are still guaranteed to get a move. So returning a vector from a function will never result in extra allocations. And you should not pass by value unless you need a copy unconditionally, even then there's still a range of opinions. 
How does this differ from the C version? Do you have a diff? It appears to be just copied and renamed to .cc then move a bunch of functions inside malloc_state
I see, so the const reference static checking applies to the body and callees of the function, but not upward or other parameters.
As far as user-defined allocators go, alingof/std::align (since C++11) are really helpful, I think.
any talks you can recommend that would be of use for nonLLVM people?
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [petewarden/tensorflow_makefile/.../**map_util.h** (master → 49c08e4)](https://github.com/petewarden/tensorflow_makefile/blob/49c08e4d4ff3b6e7d99374dc2fbf8b358150ef9c/tensorflow/core/lib/gtl/map_util.h) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dgyysrr.)^.
Thanks for the answer
Not only that, when someone says 'I'm not sure what changed', responding with 'the changes are not so trivial' doesn't really help. The track record on posts like these is shaky at best. 
I read the comments and my mind just boggles. You serialize to a binary floating point representation that has same or larger exponent range and number of bits of mantissa. On IEEE-754 platforms, the serialized representation is one and the same as the platform representation. You have a choice of spitting it out big-endian or little-endian and that's pretty much it. &gt; I want to write a platform-independent binary representation of floating point numbers. It already exists. It's called IEEE-754. It so happens that all sane platforms **already use it as the platform representation**. You're done. What else do you want?? I really hate manufactured problems. If you're not on a platform that represents floating point using an IEEE-754 format, then you're imaginary anyway.
+____+
x____x
When I first learned about RVO, it made me very uneasy because of the unpredictability. In practice, it has not once been a problem for me. I have never modified code to work around RVO not happening despite writing performance-sensitive code which returns large value types. That's not to say that it has ever failed to apply in places that I expected it to, but if it has then it was in places that ended up not mattering.
In a makefile, the variable for the C++ compiler is `CXX`. Likewise, flags are put into `CXXFLAGS`. Thus, I name all my C++ files .cxx, because this makes things consistent. Note that `CPPFLAGS` refers to the C pre processor and is applied to both C and C++.
I would say TS are here to test interfaces and evolve. Especially when the library is in use already. Look at ranges TS. It didn't stop evolving at all. It also shows that it takes long years for the TS authors to bring it to the state accepted by the committee (all Eric's std proposals are so far for basic support only. No range views yet). So the sooner the process starts the better.
The reason Eric's proposals are for basic support only is that the bigger the TS, the longer it will likely take to get merged into the standard. Taking the same approach with the networking TS is probably not a terrible idea, otherwise it's just more likely to be pushed past C++20.
I wonder, why not just use "+"? It's in ASCII, surely it's just as universally usable as "X" is. 
It is nice to avoid introducing runtime cost for testability, but still not nice enough to cover the ugliness of * converting the method to a template (weaker typed, typical template error msg or link error when misused) * explicitly instantiating the template * missing the documentation purpose of interface I believe if we are ducktyping it anyway, then a solution based on `#include` or `#define` wouldn't be uglier, in fact, they would be easier to write or modify, and require no template knowledge. Include based mocking: //product.h #if !UNIT_TEST #include "real_argument.h" //real class Argument #else #include "mock_argument.h" //mock class Argument #endif void f(Argument const&amp; arg); ~~Define based mocking:~~ Edit: I apologize for posting code untested by myself, the correct code should be: //mock_argument.h #if UNIT_TEST class MockArgument {/*...*/}; #define Argument MockArgument #endif //product.h #include "real_argument.h" #include "mock_argument.h" void f(Argument const&amp; arg); //product_test.cpp #include "product.h" 
Because a # looks like four + joint together? _++_ _++_ 
A static_assert within each function would solve your first and (arguably) third points. Template code really isn't that tricky, and (in my opinion) you shouldn't be using the preprocessor to change the full meaning of your code -- besides, you now have two places you need to worry about directives.
Bingo! Today you win a hyperlink: http://stackoverflow.com/questions/1991345/origin-of-the-c-sharp-language-name
Qt Creator. Works great for Qt and equally great for other C++ work. Disclaimer: I work on that IDE:-)
Jetbrains Clion. Works better than other language aware editors I've tried. Clion uses CMakefiles for project builds. [vim is still my goto for quick edits though. Fast startup and ubiquitous on most linux distros].
As much as I like the "More feature as libraries" mindset, the compiler game really need to step up to follow. Last week I refactored out most uses of `variant` in my software by script-generated union-like class and switch/cases. The debug builds went from 800 megabytes to 55 megabytes and build times were almost halved (and I stopped hitting MS Windows's 65535 symbols max in an object file). I also won't count the number of bugs reported against various compilers due to stuff like name mangling breaking because of names being too long. So if even more thing become "library" without relying on some kind of compiler builtins that would prevent expanding kilometers of template instantiations we're gonna hit very hard walls for "big" C++ software (mine is only 200k LOC). 
Qt creator is very impressive in many ways although I ran into crazy qmake bugs. Also it seemed that out of date build scripts weren't detected so I always ran cmake (I avoided qmake after finding bugs) then ran a full build to make sure things we're up to date. It was a massive pain.
On Linux: Vanilla vim (no plugins) with ctags and screen. On Windows: Visual Studio 2015 with VsVim.
Yes, make on Windows is not ideal (it works better elsewhere with better make implementations). Watch out for Qt Creator 4.3: That will have machine better cmake support (with cmake 3.7 or later that is, the support for older versions is mostly unchanged:-).
make or qmake?
Oliver Goffart has a great article on what it would take to make Qt moc-independent https://woboq.com/blog/reflection-in-cpp-and-qt-moc.html . He also worked on a moc-free implementation Of Qt called Verdigris https://woboq.com/blog/verdigris-qt-without-moc.html Beside static reflection: * The attributes system needs to be extendable and exposed / introspect-able at compile time ( you need to tag certain methods and you need to add attributes or name mapping for serialization * We need a way to generate code that is part of C++ and sandboxed ( rather than a processor step aka macro ) - D mixin are probably the way to go * Maybe we need some kind of python-like decorator system ? * We need to do all that while improving compile times* *I tried GCC 6's concepts implementation the other day, it is slow as hell. 
Based on the example and the premise shouldn't the `Argument` class be fixed ? Smells like a case of "God object" which needs to be avoided. And ofcourse, introducing inheritance to ease testing would be bad (in some cases, but not all).
Another slide from presentation: https://twitter.com/anastasiak2512/status/858809432792338432
Windows: Visual Studio 15 Linux: Visual Studio Code Unfortunately nothing comes even close to Visual Studio on Linux. Qt Creator and CLion both aren't options for me at this point due to price and licencing - I'm still only a student.
Has anyone got examples where this would be useful?
Why no YCM and tmux instead of screen? 
&gt; I refactored out most uses of variant in my software by script-generated union-like class and switch/cases. The debug builds went from 800 megabytes to 55 megabytes and build times were almost halved (and I stopped hitting MS Windows's 65535 symbols max in an object file). That's really sad. Do you have any similar measurements for gcc and/or clang?
I use it mainly for python and as a default editor. On Windows I would not call it a full replacement for Visual Studio (as it was never meant to be one!), but it can pretty much do everything you'd expect from a good IDE. Concerning autocomplete and linting, there are many good extensions for all kind of stuff you want, including YouCompleteMe Edit: I'd suggest to give it a try. It's practically Open-Source and available also for linux.
Vi and NetBeans
Meta classes and more reflection-like functionality sound awesome. The idea of pluggable custom language extensions scares me a bit though, if it were to become widely used. Things like maintaining legacy/undocumented code are hard enough already. Imagine adding undocumented extensions that someone thought were a great idea "at the time" to the mix. Or trying to integrate pieces of code that make use of different extensions. Seems like something that could end up fragmenting the community into camps that each "speak" a different dialect. On the other hand, having a way for the standards and compiler folks themselves to prototype and implement new language features in a platform-independent manner would be pretty useful.
You can get a license for CLion for free if you go to a university or college.
Visual Studio almost full stack now that they have Linux build support. Then if I'm forced to code on Linux, then I use IntelliJ IDEA/CLion.
when I need to separate template definitions from the header (to reduce compilation time, usually), I just place them in a *.inl file and include that in any .cpp file that call the templates (ending up in a file structure that looks something like [this](https://hastebin.com/adisiqihel.cpp)). also, you have a typo in the templ files: `typename` instead of `template`.
One motivating example is that of value types. Often we have some `struct`-like type that contains various members. We will usually write setters and getters, constructors, equality operators, relational operators. It would much nicer if we could introduce (at a library level) a `value` keyword that would generate whatever we needed. Another example is that of interfaces. Often we will have conventions: all member functions must be abstract, the destructor must be virtual, there may be no member data. Again, you could introduce an `interface` keyword that enforces those constraints. There are at least 2 clear benefits (beyond the fact that there is now an unambiguous name to refer to the pattern): since it's at a library level, if your company or group has differing ideas of what these patterns are from other people, you can implement it differently in your library, and EWG don't need to spend years figuring out what the most general and acceptable approach is. The other benefit is that the definitions of these keywords (or metaclasses) can be written as testable code rather than pages and pages of verbose standardese.
Not Qt, the need for moc. It's already somewhat possible, though with much longer compile time and ugly macros. But if C++ gets powerful reflection support, then most of the boilerplate code that moc generates for you, would be unnecessary.
QtCreator is free and open source
I do most of my work on Qt Creator (both on Windows and KDE Neon, where it works much better). It is fast, light on resources and does pretty much everything I need in a base IDE with C++14 support. In the end it wins out over everything else because I do need a cross platform IDE that runs at native speeds (looking at you Eclipse CDT) It has a few bugs (mostly related to make, dependency relations and so on to the point that QBS works better than qmake across platforms) including the one that annoys me the most. The scenario is always the same I have a few headers open and when one of the open ones reference one of the other open ones and I try to save a change I get a message that I have "run out of disk space" or something similar. A quick save file is dumped into my file system and I can't save anything until I close the relevant files (having to guess which one to close) then I can save again. It happens often enough that it is annoying but not all the time either. It has led me to recommend disabling the ClangCodeModel again even though the interactions and feature set of Qt Creators C++ mode is somewhat reduced without it. If the Qt Company had the resources they should look into implementing a whole lot more of the refactoring and ease of use actions offered by Visual Studio and especially Resharper C++. There is a massive amount of small "easy" things that could be done such as automatically indenting or unindenting code based on enclosing code in {} or adding more code generation actions to the refactoring menu (such as creating implementations for all member functions in a class that has yet to get one instead of having to click on each prototype separately). 
It's not obvious from the page provided by the top 3 or 4 google results. And given that i can just apt install kdevelop, its really no contest. Qt-creator doesn't buy me anything, at least not that ive seen so far. I do like how it acts and looks but i found the 3.5.x package that comes with my distro to be old and buggy -- i actually lost work using it a few times and thus gave up on it.
emacs, emacs and emacs. nothing beats emacs. valgrind is awesome at "please just show me where my bugs are kthx" and, rarely, i pull out GDB. (i don't have too much of a use for it) once or twice a year i play with qtcreator, but only to be a step-through graphical debugger. I've got plenty of love for Qt -- I wish I still felt a need, but ever since c++11 and c++17 (or maybe i've just changed or grown as an engineer) lots of the great awesome things I loved about Qt I can do in pure c++! that being said, I still have love for Qt. ;) 
Try https://download.qt.io/official_releases/qtcreator/ Try the upcoming Qt Creator 4.3 for its cmake support -- for best results update cmake to version 3.7 or later.
sublime text 3: works on mac, windows, linux. is super customizable and awesome at editing.
Fair enough. I also do this sometimes, but don't you find that in certains cases it introduces a lot of compile-time dependencies? Because the header now #include all that the .cpp #included for implementing the bodies of the functions. And thanks for the typo, it's now corrected.
There: https://godbolt.org/g/xNg2Bn
Yeah, that kinda scares the hell out of me. What happens when you have to use two libraries, and their definitions differ? I already waste a huge amount of time, LOC, and bytes of converting between different libraries concept of a matrix/vector, because there's no standardised C++ linear algebra library. The amount of glue code I write is depressing. Getting rid of boilerplate I'm all for, but I can't help thinking the standards committee should, you know, *standardize* how that's done!
Is there a list of all the examples somewhere on godbolt? I would like to play with the experimental compiler.
The reason to immediately terminate is that an assert identifies a program logic error, which means if it fires your process is in an inconsistent state. Any further execution therefore risks doing more damage. It's the same principle as say a BSOD in Windows or kernel panic in Linux. In user space it's up to the OS to do the cleanup like closing files and terminating child processes. Of course you can roll the dice and say just because this bit of code is screwy maybe other parts of the system are ok, but that's an 'at your own risk' judgement call. Exceptions are a fundamentally different concept - neither supersedes the other, and it's nothing to do with pre vs post conditions. Exceptions are for errors that are expected to happen, albeit rarely, e.g. to do with externalties such as user input, the filesystem, networking, etc.; whereas assert says "this should never happen", ie your program's internal state has gone wrong due to a coding error.
Hi, sorry for the late reply. Cache pressure always applies - any data read consumes cache lines, and more compact data structures consume fewer of them. This leaves more cache left for other code to use. You absolutely correct that pulling "alive" flags out of large objects is a win, and using bits is more of a win than using bytes or int32, just because again more data in fewer cache lines. False sharing is definitely a thing, but you're moving the goalposts - if you have a reasonable expectation that your data structure will see high contention you might make different decisions, but to put a single bit in a 64-byte cache line seems extreme, and in that case I think the architecture and/or data structures needs to be redesigned to be more MT friendly (pipelines/work queues, data partitioning etc.). In general the cost of memory operations will always outweight ALU ops in terms of overall system performance. Doing some bit manipulations is cheap to the point of being virtually free, whereas a cache miss will cost you tens if not hundreds of cycles. Micro-benchmarks tend to hide this as they test code in isolation, so everything ends up nicely cached, and the fact that you've evicted a bunch of other data from those cache lines doesn't get measured. However in real-world scenarios, a large amount of code and data is competing for a small amount of cache, so any code which is overly greedy may see a speed-up in itself, but will be a net loss overall, as other data will be evicted and need reloading when that other code runs again. Does that make sense? You might also find this of interest: https://software.intel.com/en-us/articles/introduction-to-cache-allocation-technology
Visual Studio 2017 Enterprise on Windows and Eclipse on linux.
Recycling a thread: https://www.reddit.com/r/cpp/comments/67oh29/visual_studio_code_cc_extension_april_2017_update/ 
If you are already using vim (or I guess emacs), I highly recommend adding rtags into the mix. Despite the name, it is not Yet Anther Ctags Workalike, but actually gives you 99% of the navigation and code insight features you would expect from an IDE. It uses a background indexing server to provide whole-project lookups instantly. I combine it with YCM which handles the real-time autocomplete and red-squiggle error reporting. Rtags handles things like go-to-definition, find-all-uses, what-type-is-this-variable, and renaming. The renaming is actually powerful enough that I recently was able to use it to convert raw member access into a method call across all usages. I use a ton of other plugins as well (fugitive, gitgutter, command-t, easymotion, a.vim, and like 20 more small ones), but YCM + Rtags provides the bulk of the C++ IDE features. https://github.com/Andersbakken/rtags https://github.com/lyuts/vim-rtags (although I am using my own fork with some modifications I haven't gotten around to publishing yet). PS if you use gvim and occasionally use the mouse when navigating code, you may find this swath of my gvimrc useful https://github.com/RedBeard0531/dot_files/blob/d18aeb0/gvimrc#L75-L107
There's another moc-free modern C++ Qt fork (presented at CppCon for the last several years) - [CopperSpice](http://www.copperspice.com) 
&gt; and I stopped hitting MS Windows's 65535 symbols max in an object file The compiler is not part of Windows. It is a component of Visual Studio. 
Your situation is not uncommon, Microsoft Excel was an early adopter of std::function and they came to regret it. Proposed Boost.Outcome came about because proposed Boost.Expected caused severe binary and compile time bloat in a project several years ago, so Outcome began life as a lightweight alternative. For reference, proposed LEWG Expected is vastly slimmer than original Boost.Expected, indeed it's very comparable to Outcome now.
The more I see the direction C++ is heading, the more I think "lisp". I'm I the only one?
Is compiler.require part of the reflection proposition?
Xcode on macOS, vim on Linux. I was really enjoying VSCode on Linux but the slow load times and general latency slowly sent me back to vim.
another reflection proposal?
I have treid almost all of them, and to be honest I am obsessive about IDEs. If you doing something special related to Windows then VS is your best bet. If you doing something special related to Mac then xcode is your best bet. If you want a text editor VSCode. If you want true C++ IDE : Your *only* bet is QtCreator with Clang code model (not their own default code model).
If you don't mind Java, I recommend Eclipse with CDT.
You didn't expect someone'd write a hundred times faster malloc, did you... :) If you consider by 'arena' a contiguous chunk of memory, I'd call memheap a multi-arena allocator. It has a trivial logic to allocate additional arenas automatically if needed, and manage them. I am considering a better way to free arenas. I believe it makes this thing more generic. There is a memheap::allocator for stl on top of all of that. 
Compare it yourself
So then shouldn't your flair be Qt Creator Creator?
Why not? Just by making it thread (i.e., concurrent use) unsafe, it could be made (much?) faster.
Oh man. I'm old enough to remember C# being a new thing and I never knew that.
that's honestly quite hard to do : https://vid.me/bJ2k 
(In case you were not there) The video is going to be run past the committee first before being released, but the response from the crowd was... intense to say it mildly. :-) There is a meeting coming up soon (Toronto I think?), but hopefully they'll approve it before that time!
The amount of rebuilding from scratch needed with qmake was one of the biggest things that made me switch to CMake. +1 for QtCreator.
I tried using IDEs to write C++ but decided to use vim instead. Since I'm fairly new to C++, I have to recompile my code after small amounts of changes, and when I used CLion and some other IDEs I had the illusion that my code was fine, even though I would get many errors when I compiled my code. Also, there are a lot of distractions when my editor shows warnings and I get obsessive about fixing them. My current layout is two terminals having half the screen, one on which I write my code, and the other which I use to look up C++ functions with man.
Another cool part (IMO) is that the people working in "the backend" (I am sure every company have these people) can implement and define classes that are less prone to misuse. As an example we might be able to define metaclasses where all constructors (sans the default) have to be explicit for example. The possibilities are endless! However I doubt that the "dark matter" coders will make use of this in everyday coding, to me it seems more like a thing that the people that get down and dirty with implementations of libraries can use to produce safer and easier to use classes for the masses.
It certainly is awkward. But he's constrained by the need for absolute backwards compatibility, all existing C++ needs to continue to compile under the proposed system. Indeed, the mostly likely serious objection to this proposal is that it will permanently remove any other proposal occupying the same space in the future, and hence this proposal will need to pass a much higher (too high?) bar as a result. Finally, let me just reraise the idea that it's coming long overdue for the ability to mark a namespace as "new C++" unencumbered by backwards compatibility. To date that idea is taboo on the committee, but we need something like a Python 2.x =&gt; Python 3.x breaking change to the language most specifically to forever eliminate the "template" keyword, and templates, permanently as a most unfortunate design mistake.
I was told by a senior Visual C++ dev that over indulgence of std::function by the Excel team led to a lot of unintended memory consumption. A later refactor of the std::function implementation to use much less memory led to very significant improvements.
The standards committee ONLY approves things at meetings - so no, they won't "approve it before that time"
Yet another step on C++'s long and painful road towards becoming an incredibly poor re-implementation of Common Lisp. 
Windows: Visual Studio 2017. It just works. Linux: Visual Studio Code. With some customization and a couple addons it works pretty well for C++ development.
I was not there. Can you further describe the intense response? Was it intensely excited, intensely against, or intensely curious, controversial, etc...? What discussions did you personally hear afterwards? Thanks!
No one use Notepad? (No, me neither.)
No, it's part of this proposal, or maybe another one about metaprogramming (which in this case is considered relying OVER reflection proposal).
&gt; POSIX requires malloc, free, realloc to be thread-safe Which is only relevant if one is actually using threads. Plenty of apps that operate in a more micro-service-like fashion don't use threads at all and benefit from disabling unused thread-safe features. _Especially_ in this sort of allocator that relies on global locks for its thread-safety, rather than per-thread arenas/caches. Replacing the default `malloc` and co with a single-threaded version is a common optimization for those classes of application. Other than that, though, I agree. We have a heavily-modified C++-ified copy of dlmalloc in our engine and those sorts of cleanups are exactly the kind of thing that transforms the allocator into something the average engineer can reasonably debug and improve. :)
I have yet to see an editor that couldn't do vim keybindings, either built in or via a well supported package.
&gt; Can the class with versioning still detect that a file contains the old format without a version number? Sorry, I don't know!
ah, gotcha. VC++ needs some love on the compiler side tbh, its already got more than its fair share of problems like this it seems
Is it available yet or it's waiting for the next batch of papers?
@ your developer: Why does this link to a jsfiddle? Why do I need to mouse over it? Why don't you just post the conversion as the comment?
To be honest, it doesn't look that bad. It took me like seconds to "fully" understand the semantics based on the examples and for me that's important.
Awesome! Wasn't aware of that. I've grabbed it and it seems quite decent. While setting it up I've already noticed a couple annoyances - definitely going to send some feedback after I've used it for a little while longer.
I understand that he accomplished this mockup without introducing any new keywords. I'm just concerned that this isn't the last time we're going to see "$" for a core feature. If I start to see "$\" or whichever way it was in perl (thankfully I don't remember) I'm out. Or maybe this is some brilliant strategic ploy by Herb to so offend the committee that their honor will compel them to find a better syntax? :-p 
It already have been refused by the committee if I remember correctly, so at least for reflection syntax, it will be keywords, certainly reflexpr, somethingexpr etc. However I think Herb's work on his experimental version of compiler was done after he and Andrew Sutter wrote the proposal wher ethey wre already using this syntax, which was introduced before by one version of the reflection proposal. So basically: ignore the syntax for now, it can change to the last minute of the standardisation process.
I have /bigobj enabled.
I should have said library instead of object file : https://msdn.microsoft.com/en-us/library/at5879hx.aspx &gt; The limit of 65535 objects or members in a library has been exceeded.
Well played.
It really look great, useful, and reasonably intuitive/readable. There is a lot of similarities to D's `mixin`. That could really replace quite a lot of macro usages. And it seems indeed capable of transforming macro-heavy GUi frameworks. One thing that would be needed to make the system perfect is an ability to manipulate [[attributes]] as well as the informations attached to a type / variable
No worries about lateness - this is an awesome topic to discuss! &gt; but you're moving the goalposts Sorry, I didn't mean to! I was presenting multiple scenarios, to try and understand which one you wanted to discuss. For the sake of discussion: * Single thread, single CPU. Running in isolation, no context switches. * CPU with 1K cache lines in L1, 4K cache lines in L2. 8-way associative cache. Our scenario is a loop, where we do the following: 1. Read a single boolean from the collection. 2. Perform operations that read about 1MB from RAM (1MB = 16K cache lines). Assuming uniformity, the odds of a single cache line surviving from step 1 until after step 2 is: * In L1 - 1:16 * 1:8 = 1:128 * In L2 - 1:4 * 1:8 = 1:32 Therefore: * In a packed bits solution, up to 256 flags are stored in a single 64-byte cache. With just one evicted cache line, we lose the whole thing, forcing an access to L2, L3, or even RAM. The odds of any of the flags still being in cache are 1:128. * In a non-packed solution, spending 64-bit per flag, a single cache line only holds 8 flags. Better yet, every 8 flags have different address offsets, causing them to be associated to a different set of 8 locations in cache. This means that the odds of any of the flags still being in cache is up to eight times higher, or 1:16. Hm... I'm really doubtful I got that right. And the cache isn't uniform, so I doubt my model is 100% correct. My point is that because it's a larger target, it's more likely to stay in cache. On the other hand, 1:8 isn't great odds. The biggest weight is how much data (that isn't the flag-set) actually makes it into the L1. &gt; In general the cost of memory operations will always outweigh ALU ops in terms of overall system performance. Doing some bit manipulations is cheap to the point of being virtually free, whereas a cache miss will cost you tens if not hundreds of cycles. I think you're disregarding [port pressure](http://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-optimization-manual.html) when the CPU attempts to execute the instructions as micro-ops, and the dependency between the instructions. I whipped up a simple function for fetching a flag out of the set: * [packed into bits](https://godbolt.org/g/o9b9WK) - 9 instructions, with the first 4 having to execute in order, and the 2 following also in order. * [not packed, using uint8_t](https://godbolt.org/g/O6SLzd) - 3 instructions, only the first 2 executing in order In the packed case, we have a bunch of ALU instructions. Because they are in order, it doesn't matter if they are assigned to Port 0,1,5,6 - they are going to have to wait to execute in turn. Compare that to unpacked case which is an ALU instruction followed by a load and compare. That allows to spread the load between the ALU ports and the load ports. The CPU could be already working on the next bunch of ALU instructions before the load is done, since they are all available for use! OK, I'm tired and I'm fairly sure I'm getting this wrong. I can't help but agree with you that smaller is better. I'm just not sure that going below the size of a single 64-bit word is better. I'll see if I can do some measurements on a production server :) ---- Other stuff I wrote up while replying: &gt; Cache pressure always applies - any data read consumes cache lines, and more compact data structures consume fewer of them. This leaves more cache left for other code to use. There's a [great lecture by Scott Meyers](https://www.youtube.com/watch?v=WDIkqP4JbkE) about caches. The relevant part is in the [slide 40](http://www.aristeia.com/TalkNotes/codedive-CPUCachesHandouts.pdf) (the page with the words "Igor Ostrovsky’s demonstration of cache-associativity effects."). The graph shows that nearly regardless of the size of the data, certain stride-widths in a loop will cause significant delays. What we think of as "cache pressure" doesn't apply here. It's an artifact of the associativity of the cache. A bug, showing where the non-direct mapping used by the cache breaks down. I always fear similar issues in my codes, so I measure a lot :) 
For c++? [Cevelop!](https://www.cevelop.com/) Why? Easy of use, Linux compatibility and most of all: Automatic Coding standards checks. That among other features like template visualisation.
Ive messed around with it and it's really nice, but......ill stick with vim for now as I can get the same completion + more in vim
Less and less true nowadays - it's nearly up there with gcc and clang in VS2017.
This looks like homework
I use Clion. I think it's very good IDE for C++ with a lot of plugins. But IMHO now the best IDE for C++ is Visual Studio. I hope that in the future Clion will be a good competitor for MSVS.
If you have functions that return optionals that shouldn't be ignored, you can mark those functions as nodiscard.
If you have /bigobj enabled then the upper limit for "sections" is about 2 million and not 65535. That being said I never figured out why post C++11 we still need to provide that option explicitly. 
&gt; [...] to forever eliminate the "template" keyword, and templates, permanently as a most unfortunate design mistake. I'll bite. Why are templates a design mistake, and how do you better solve the problems that templates solve?
I've gotten compiler errors in VS (2015) when using `interface` as a variable name. I believe some of the MSVC libraries reserve it.
Herb said he wanted to show it to more people involved with standardization before the video (and I guess functioning clang fork) is opened up to a wider audience.
Can confirm. The clang-reflect repo was forked from the private repo before the Kona meeting.
This really shows the disconnect between the performance of c++ that everybody loves and the compile time required to achieve it. Can a program really be said to be fast if it took years to compile?
&gt; Can a program really be said to be fast if it took years to compile? If its fast, then yes.
§8.6, Stroustrup's [Concepts: The Future of Generic Programming](http://www.stroustrup.com/good_concepts.pdf): &gt; My initial template design did not have the prefix **template&lt;typename T&gt;** syntax. It was introduced primarily to assure “worriers.” It is now widely disliked and often ridiculed as an example of verbosity and poor design. I really want to know how does the initial design look like.
That's all good and interesting, but what would save me hours every day would be 1. modules 2. a very strict subset of C++ without nullptr, raw pointers, include, and as little undefined behavior as possible that can be enabled per-file or per-scope. 3. an official language server for autocomplete and refactoring. 4. an official build system that doesn't try to be retrocompatible I feel that the standard body is doing at the same time way too much and way too little, investing too much in language theory while the day-to-day of C++ developers is still stuck in the 90's compared to even new languages like Rust. C++ has literally the worst tools than any other successful language... I know that's not an area that the standard committee influences/cares about, but maybe that's the problem. Some shared direction there would really help.
Just a heads up, I plan to add some cppx examples to CE this week :) 
Atom, but I'm not super happy about how resource hungry it is...
My guess would be the likes of Microsoft COM. This is where you fetch some functionality, but the fetcher returns only the functions to the class that the interface exposes. Even if something is public, you can only (easily) see the interface's functions
Well I could say that's a feature :) I don't think it's impossible to solve... some combination of using `optional` and making use-after-move on the stack an error could perhaps work out? But I see what you mean... a subset of _current C++_ without nullptr is impossible, we'd need more language features before getting to that.
Programmers Notepad using samba over to the Linux box. Yes, I'm weird. 
Are you going to write an article about v2.0? Here is the link to v1.0 if anyone is interested. [click](https://www.reddit.com/r/cpp/comments/64frhb/ctai_compile_time_assembly_interpreter/)
Presumably, just having the &lt;T&gt; there should be enough for the compiler to figure it out. What could the following be, other than templates? class bla&lt;T, S&gt; { ... }; T foo&lt;T&gt; (T t) { ... }; The `template &lt;typename T&gt;` bit seems mostly irrelevant noise, and we might consider making it optional, using _only_ the &lt;T&gt; bit to tell the compiler it is in fact a template.
CLion. I tried Qt Creator, but it felt a little "weird". I need to try that again sometime.
I presume so too. But I hope to see some historical records. Plus, when I presume so, I doubt how template specialization would look like.
xcode, visual studio and code::blocks
that's clearly a fake, in the video you do not link to the video
Probably yes, but idk when. I'll try to write it in the next two weeks
Windows: Visual Studio 2015 and some times Visual Studio Code. Mac: Xcode (but do not like it).
Ah!
Sorry if my question sounds stupid, but what does it do exactly now compared to let's say inline assembler? 
Which point might that be? that C++ will allow these things to be made by programmers? 
Ok, so? some changes are for good. 
Compile-time LISP. 
Started working yesterday with Qt. The designer is infuriating, I miss tabs and some other basic behavior like move current line up/down. But other than that its quite good. I like the design. VisualStudio feels to claustrophobic for me even tough Qt wastes almost the same amount of space.
Am I the only one who uses Code::Blocks?
And we still forced to use Python 2.7. So please do not repeat the same mistake as Python did !
Just would like say "thank you" to you and your team! Great work! I am satisfied with QtCreator for 95%. My 5% wishlist: 0. Detachable bottom pane (issues/search/output/etc), so it can be moved to another monitor. 1. Optionaly hideable main menu (like main menu on Firefox which is visible only with Alt)
second version with some more tests: http://www.bfilipek.com/2017/05/packing-bools-2.html
&gt;I miss tabs AFAIK, QtCreator doesn't have tabs by intention. I also think that tab-style navigation is not good for developers in general: we are not switching to "the second" or "the third" tab, we are switching to a file with name or a function. Tabs and thier location are temporary objects, our brain should not stick to temporary objects, instead it should remember object's permanent names. The Locator in QtCreator works perfectly for this: "Ctrl+K" + "name". Also, it shouldn't be important if a file is already open or not. &gt;and some other basic behavior like move current line up/down. Ctrl + shift + up/down arrow 
Yes you are right, thank you! My typo. Correctly, a += 1; I fixed it. There is only: operator+=() and fetch_add(), but there is no operator+() : http://en.cppreference.com/w/cpp/atomic/atomic 
Using QtCreator for editing source code does not imply any kind of limitations on you, while using Qt library does.
What is a use case for running almost assembly at compile time? If I understand right, it's like you implemented a VM that runs only at compile time. Why do that?
Very fantastic TMP!
Thanks, I'll pass on your praise:-) Please use bugreports.qt.io for bugs and feature requests though: Stuff does not get lost there.
&gt;Tabs allow me to quickly switch between 3 files In QCreator "Ctrl + tab" still works as expected + it shows drop-down list of all open files, you just don't have visual tabs. &gt;I work with projects that have multiple functions with the same name. Well, it is a very typical situation in C++, and that is why you see class/namespace name before function. 
Yup
I complitly agree with this, command style navigation with "Locator" and "Follow symbol under cursor" is *the right way* to go for *developers*, IMHO.
[Neat!](http://imgur.com/gallery/LhZ6j)
Thanks for the link, it was very informative.
Make that two.
&gt; Lucky you. As far as I can tell, this is somewhere between difficult and impossible with the ATLAS frameworks. I don't understand. Why couldn't you use my histogram library for your task? &gt; The solution is to use Github Pages instead of the HTML preview. Please try again. I fixed it.
&gt; That's what I meant about kicking the can down the road. You can't choose the needs of your users. If they need this and you force them to handle this "lossy" conversion themselves, then they are far more likely to do it inconsistent with your internal machinations. I think we have a misunderstanding again. Because you can configure the library through template arguments, I don't have to force my users to do any lossy conversion. &gt; Sadly I no longer have access to the code that actually watched for some of the particular edge cases. :( That would have been interesting. &gt; You're far less likely to get a company to sign off on something if it's not going to directly make them money in the next quarter or two...:) You have a far too idealistic view of modern science funding. Trust me, it is really bad. They only want to the low hanging fruit and simple approaches.
In Perl there's both $/ and $\\. The $\ one is line end when printing and $/ is for reading input.
On Windows: - visual studio 2013 and probably 2015 soon - visual assist for the autocompletion and highlighting - incredibuild for distributed building on many processors 
Python 2.7 can be very easily asked to pretend to be Python 3 on a per source file basis. Indeed, last year or two you can write universal Python programs without much effort that run perfectly on both Python 2.7 and Python 3, and much faster on the latter to boot. I would be certain that any namespace marked as being "new C++" would work exactly the same way.
Programming: Principles and Practice by Bjarne Stroustrup.
The standard body is doing one thing. * C++ tooling sucks because macros, really. This proposal directly help tooling by removing the need for a lot of macros. * As a community, we could decide to invest heavily in clangd to be a defacto language server. It is something I would like to contribute, somehow. Because I think it has a lot of potential if a massive effort is put into it. * Build systems suck. I have become quite fatalist about that, I mean, it's the nature of build systems. * Everybody has their favorite tools. We can all use cmake and complain that it sucks, or use something better that nobody else uses. I like and use QBS but realistically, there are maybe a handful of people using it in production. There are other solutions : meson, ninja, build2, waf, etc etc. Getting a standard is impossible, because people don't agree on what the definition of a build system should be. * However, It appears to me that all build system basically output a list of commands to run the build. I have been wondering if we could partially solve the issue by using a "build system server", that would be plugged somewhere between the IDE and the language server. 
Compiler errors. However, it could have been warnings that we have turned on as errors. I don't have a Windows machine anymore so I can't easily test.
https://www.youtube.com/watch?v=XVofgKH-uu4&amp;t=615 - I'm fascinated by the smart laser pointer handling. They film the screen and map the laser dot to the slides ?
I've used wxwidgets 2 years ago. So my information might be dated. * Yes it does use the native toolkits * Don't know * I've used WxFormBuilder at the time, I needed to save a lot due to crashes. But it was okay I guess. Really taught me to apply MVC model to keep the generated file as is to allow edits in the GUI. * I don't know * I passed raw pointers to it. The memory was managed by wxwidgets internally by their own implementation of smart pointers.
I think /u/spongo2 is interested in hearing that?
No, it's a new feature with Google Slides presentation mode. It shows the mouse cursor as a simulated red dot complete with trail. My cheap air mouse presenter then moves the mouse cursor around. Apart from the severe lack of range and requiring absolute line of sight (the presenter clicker is very cheap), so long as you stay close it works quite well. And, as you noticed, makes nice videos.
I figured out what you were experiencing. See the edit in my parent comment for why.
This is great! I had never heard of it. Thanks!
Have you tried [jvi](http://jvi.sourceforge.net/ReadmeNetBeans.html)?
Interesting, is anyone hiring wxWidgets devs?
Hi. Msvc dev mgr here. Are the bugs you are discussing filed? Would love to know more about them. Thanks in advance.
2nd Edition was published in 2014.
There is also a GUI framework called nana that is all modern C++. https://github.com/cnjinhao/nana
Yes- the netbean hooks are pretty fantastic. 
I talked to someone about `expected`, and Rust's error management came out in the discussion. So, do you think `BOOST_OUTCOME_TRY` macros should/could at some point become a core language feature ? 
How about using google's protobuf? I cannot say anything concerning speed, but it is definitly a nice way to interop with different programs, even written in different languages! We use it a lot for communicating between a legacy C++ program with some modern parts written in C#. Of course the real benefit is the easy way to serialize complex object structures - something you don't have...
I think so. I've previously mentioned these bugs on reddit to some MSVC devs so I imagine they know about it. This was back when VC2015 was out and it included similar bugs. To be specific, these example programs don't all compile in visual studio 2017: https://github.com/davisking/dlib/tree/master/examples If you look in the CMakeLists.txt file there you will see that some of the examples are skipped if the compiler is MSVC. That skip was added to avoid examples that caused MSVC2015 to crash. But now that MSVC2017 is out, even more of the examples fail :( If you try to compile those programs with MSVC2017 just as the CMakeLists.txt is configured you should find that visual studio goes into an infinite loop.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [davisking/dlib/.../**examples** (master → 09b4dc8)](https://github.com/davisking/dlib/tree/09b4dc82b4e7a2fc36cf40c2391b0909a40729bc/examples) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dh1dzx5.)^.
Anyone know if `std::filesystem` is finally out of the experimental namespace?
What about parallel execution for algorithms? 
Docstrings as in standardized comments or something? I don't recall ever seeing a proposal for such a thing. I imagine it would be an extremely uphill battle, particularly because the landscape here is already fractured and major C++ users (and committee members) are using wildly differing tools for this stuff. De-fracturing is valuable IMO though. Part of the problem is deciding what you want to document. A lot of systems are built around trying to document individual parameters and return values and details of a function/class while minimizing the documentation of the entity itself, or losing the big picture in all the details. Then you get tools like [standardese](https://github.com/foonathan/standardese) that go in a completely different direction. Getting the committee to agree on an approach, avoiding feature creep of trying to cover every possible use case, and also avoiding useless least-common-denominator compromises is going to be hard.
but is a second edition of the same book, how many changes?
Does it use native widget toolkits?
They mention that stdc++ has the features of the c++17 draft in the release notes here.
Just look at [the libstdc++ docs](https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.201z)...
will follow up.
"Direct TSC usage We strongly discourage using the RDTSC or RDTSCP processor instruction to directly query the TSC because you won't get reliable results on some versions of Windows, across live migrations of virtual machines, and on hardware systems without invariant or tightly synchronized TSCs. Instead, we encourage you to use QPC to leverage the abstraction, consistency, and portability that it offers." https://msdn.microsoft.com/en-us/library/windows/desktop/dn553408(v=vs.85).aspx
as i mentioned in a parent comment further up the chain, I've got a friend working on the excel team and a family member working on the VS team... so I understand its not due to lack of care, effort, or anything. If its any consolation, every encounter I've had with an MS employee about VS/MSVC/etc in this subreddit has been positive, and VS2017 was a *stellar* update. (also my dream is still getting `boost::hana` to compile/work with MSVC, any ETA on that? It was mentioned in a dev blog mooonths ago)
lots of C++14 stuff is broken. `boost::hana` is a good way to make MSVC explode and/or hate you.
Not really related, but I love how URL's are valid lines of code: http://www.google.com 
How customizable is it?
Yeah, it's a bug. It looks like even very simple examples of trying to capture a variable created by destructuring fail: struct A { int a; }; int main() { const auto [a] = A{}; [a] {}; // error in clang trunk } 
The last time WG21 standardised a macro was a very long time ago. I think the time to get the try keyword overloaded with expression semantics will be when WG21 decides to tackle standardising monadic programming, which will be a standard towards the end of the 2020s currently. It has zero chance of getting into C++ 20. Until then, you can easily roll your own TRY() macro, or on clang or GCC you can get a proper expression try which is identical to Rust's or Swift's and let's you do if(auto x = TRY(f())) ..., see the BOOST_OUTCOME_TRYX() macro.
The time to implement docstrings will be as part of Herb's metaclasses, if they ever get standardised. They would be a perfect fit for those.
I've been using the experimental filesystem from libstdc++ for a while now in AFIO v2. It's a higher quality, less buggy implementation than Boost.Filesystem, but nowhere close to the quality of the Dinkumware one yet which is very, very solid now and by far the gold standard. In terms of showstopper bugs in libstdc++'s Filesystem TS, my single biggest blocker is that clang won't compile it. Other than that, some minor ifdef workarounds will get it working pretty well.
If they import a library. If it's not part of STD, it'll probably cause even worse confusion as they leave a class where they were given some newbie friendly library to play with.
we've made a ton of progress against Hana (especially under an update to the /permissive- switch coming in 15.3 release) but it's not working yet :(
I see. I find it unusual this never got discussed. It's been 22 years since Java introduced Javadoc, and every programming language since has featured some kind of documentation facility. Almost everyone who has ever programmed in a modern language, especially using an IDE, will testify in favor of them. Of course, there's the issue that you need a lot of discipline to keep documentation and code in sync, but I guess this is one of the cases that even standard dumb formats (like javadocs or doxygen) would be better than nothing.
Sweet :)
&gt; I think we have a misunderstanding again. Because you can configure the library through template arguments, I don't have to force my users to do any lossy conversion. If my application requires a float and you had me a rational number, then yes I'm now forced to either do a lossy conversion or eschew your library entirely. Maybe I've got performance constraints or maybe I have to interface with yet another section of code. A library can't control the design constraints of the consuming application. &gt; You have a far too idealistic view of modern science funding. That's an ...odd... assertion. I've done plenty of both grant and job applications. I guess I can't speak for your subfield in particular, but I'd be surprised if you seriously suggested the set of topics a grant committee would approve are more restrictive than those a private company would. I can say quite definitively I personally have fewer options now.
Spacemacs + rtags + YouCompleteMe.
It is unfortunate how people keep trying to use `std::mt19937` and, unsurprisingly given how hard it is to use, [how they ][0][(almost)][1][ inevitably fail][0]. Do yourself a favour and use [a randomness library that doesn't hate you](http://www.pcg-random.org/), is simple to seed [correctly](http://www.pcg-random.org/posts/cpps-random_device.html), produces [decent quality](http://www.pcg-random.org/paper.html) randomness, isn't horribly [bloated](https://cs.stackexchange.com/q/50059/16408) and has more [features](http://www.pcg-random.org/using-pcg-cpp.html#extra-features) to boot. It's 2017. Let the Mersenne Twister die. [0]: https://github.com/QuentinDuval/tiny_rand/blob/0aeb87ce84fd2062ae0364040cddc889d89fd63a/samples/main.cpp#L11 [1]: https://codereview.stackexchange.com/q/114066/40768
NIce job, and I like that finally people are talking about the brilliance of error_code and system_error!
And read them in that order. Slowly, if you need to. They will probably seem dense, coming from Java. Pass on the older books. Modern C++ doesn't just add new things, it _changes_ many Best Practices.
Check the articles I was writing for Visual Studio Magazine 4-5 years ago https://visualstudiomagazine.com/Articles/List/New-Age-C.aspx?Page=2&amp;m=1 The column was aimed for C#, Java devs who wanted to revisit C++ (by then generating some renewed interest due to its "modern" revisions C++11, C++14 and the upcoming C++17)
Technically `a` is a "name of an lvalue" and not a variable ([\[dcl.struct.bind\]/4](https://timsong-cpp.github.io/cppwp/n4659/dcl.struct.bind#4)). So it's more like a bug in the standard.
Game engine and my trace log viewer is in C++. I've done some web stuff in C++, but generally speaking it's just not really the right tool for that job. 
Christ, Meyers really needs to get that haircut sorted out.
Great talk, thanks a lot! A question, why not trying to merge into boost the actual [proposal](http://www.hyc.io/boost/expected-proposal.pdf) of Expected, that already has a [reference implementation](https://github.com/ptal/expected) in c++17 with all the improvements that you talked about (and more freedom than waiting for committee discussion) rather than calling it Outcome and make it c++14 compatible? I want to use that error handling as soon as possible, what will happen to Outcome if Expected is accepted in c++20? A little bit confusing no? No pun intended or anything, great work.
Shoveling market data about. Well, mostly the supporting services for the distribution platform over which market data is shoveled.
Where could I get the slides?
RT video processing, network streaming, transcoding, rendering (OpenGL), computer vision.
high-performance provider-level network hardware
I'm *really* happy not to see `std::exception_ptr` as the error type. Lots of `expected` examples have always used `std::exception_ptr` as the error type, and I think that is a horrid choice. It completely erases the ability to introspect the thing without re-throwing it! I think `&lt;system_error&gt;` is one of the coolest additions to C++11, but it's really under-utilized. We use an in-house implementation of `expected&lt;T, E&gt;` at my workplace and it has gone over swimmingly. As our error type we use `std::system_error` instead of a bare `std::error_code` for one primary reason: You can add *additional* context to the `std::system_error` beyond just **what** error happened, but also **where** the error happened, as well as what was trying to be accomplished when the error occurred. This is especially useful when the errant `expected` gets propagated up a call stack far from where the error happened. Along with an in-house implementation of `std::source_location`, we have a single function `make_result` (which might need a better name), which takes an `error_code`/`errc` and a context string, and constructs an `unexpected_type&lt;std::system_error&gt;` that includes the error code, the context string, and *the file and line number* where `make_result` was invoked.
In java you new basically everything. In C++ you can treat many of your classes like builtins. Like int. And the destructor is called at the end of the scope. This is C++'s biggest feature. I describe this as: Step 1: "Oh no! Pointers. :-(" (java dev worried about memory management in C++) Step 2: "Oh, no pointers. :-)" (C++ dev using value-semantics. Be like int.) 
Programming, mostly.
Thats hilarious. But, no Johnny Ramone?
Best answer by far.
Hi, I had the same issue about headers in YCM, and I thought that it was a libclang problem. Are you able to share that "normalize" fix you talked about? Thanks! 
Killing time.
`exception_pointer` is a strange under-discussed/documented beast, and I agree with you complete. Some standard library implementations also create said pointer by throwing an exception, catching it, and then calling another function. So it's every bit as slow as just throwing and catching instead of algebraic data types.
&gt; If my application requires a float and you had me a rational number, then yes I'm now forced to either do a lossy conversion or eschew your library entirely. Maybe I've got performance constraints or maybe I have to interface with yet another section of code. A library can't control the design constraints of the consuming application. That does not make sense. You wanted an assertion that LEdge(bin(x)) &lt;= x and x &lt; REdge(bin(x)). I told you that my library can guarantee these assertions if you configure the library to use the right data types *in* the library. What you outside of my library is always up to you. &gt; That's an ...odd... assertion. I've done plenty of both grant and job applications. Ok, if you are an expert then, I leave you to believe what you believe.
Ok, gotcha. You could probably rewrite that part to use other histograms, but I guess it is not worth the effort in this context. Thanks for satisfying my curiosity.
The project I was involved in uses boost.serialization. They would not switch to a different library, if it means rewriting everything. Also, they cannot convert files to a new format. Whatever they use, it has to read the old format for many years to come.
Thanks! Just to be clear, I was of course asking about a language feature, NOT about an actual macro. Lots of people argue that optional/variant/expected and ways to handle them should be part of the core language ( type matching, etc ). In this particular case, I was asking about an hypothetical syntaxic sugar for `if(!X) return error(X)`
Wow, didn't expect that someone will try that :D I'll pm you
Cross platform gamedev (iOS, Android, macOS, Windows)
Industrial, soft real time stuff. Some embedded programming.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [viboes/std-make/.../**expected** (master → 16e3878)](https://github.com/viboes/std-make/tree/16e387818f92ef431e47c2b90c1739371dd7f423/include/experimental/fundamental/v3/expected) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dh2hrl3.)^.
Most STL's make_exception_ptr() is much better optimised however. About 5k CPU cycles instead of 30k CPU cycles.
As far as I'm aware, it's a coevolution thing. Microsoft sends fixes and changes upstream. They occasionally even tag team development of a feature. As to who developed their really excellent Filesystem TS, I had been assuming it was mostly Dinkumware, after all it comes for non-Windows OSs too (QNX ships Dinkumware STL too)
Really clarifying, thanks!
Without using a precompiled header I get about 60% increase of compile time.
In [cppast](https://github.com/foonathan/cppast) - which I will use for standardese - I've added documentation comments to the AST. I think if we don't get a standardized documentation format, we should at least get documentation comments as part of the AST; this is not as complicated and can be helpful for many things.
Yes, of course, we could read/write owner_thread_id using relaxed sementic. And this would give more opportunities for optimization to the compiler and the processor to move these operations inside the critical section. But in this case it does not give a noticeable increase in performance. 
Try [here](/r/cpp_questions)
I know I can use anything. I do use doxygen. And, just like pointed by Sean, the problem is mostly on consensus on what should be documented or formatted, just like there is no consensus on a standard GUI API. But I, and I believe many others, still miss some standard documentation format in code. I really miss having documentation for standard functions and classes in my IDE, just like there is for any language created after 1995, and the main reason for that is that there is no standard for documentation of code. Yes, I know there are lots of plugins that parse doxygen and show the docs in the IDE, or fetch them from cppreference through http. I'm just complaining that I have to get a plug-in for that, and it will probably never work with some external library I need in my project JUST BECAUSE we can't agree on a standard documentation format.
* intellectual masturbation with template metaprogramming * www.i-score.org
That sounds really cool. Are you sort of following the lineage of Stepanov et al? Or mostly doing your own thing?
Vim + Clang + Python as an alternative to make for small projects I'm still a newbie When things go bigger I use CLion + Clang + Cmake it's easier when you need to use more libraries 
The horrors of copy-pasting! Really interesting article for the more significant type of bugs discovered and he wasn't even trying that hard to find them. 
What I do is outside the mainstream. [Example.](http://tamivox.org/dave/math/tern_quasi/index.html)
Clarification request: without PCH is: + time(PCH=**no**, Modules=**yes**) == 1.6 * time(PCH=yes, Modules=no) ? or + time(PCH=**no**, Modules=**no**) == 1.6 * time(PCH=yes, Modules=no) ? I'm having a hard time working out which measured times apply * PCH=**no**, Modules=**no** * PCH=**yes**, Modules=**no** (~75s full; 30s partial, shared header; 13s partial, single src) ? * PCH=**yes**, Modules=**yes** (~67.5s full; ~27s partial, shared header; ~11.5s partial, single src) ?? (-10% or x0.9) * PCH=**no**, Modules=**yes** 
The 60% I mentioned above was without modules. When I tried modules, I wasn't using a precompiled header. I don't remember if it was strictly disallowed by clang, but in any case it wouldn't make much sense to use these two features together.
The video's not coming out until much later, after there's a finalized proposal and whatnot. He'll have some committee feedback etc. incorporated into his CppCon talk, so I'll probably wait for that one.
Making games.
What!!! The header moved out of the experimental folder but I had to do gymnastics since &lt;filesystem&gt; is just #include &lt;experimental/filesystem&gt;
&gt; What you outside of my library is always up to you. Lol, then while we're at it, let me sell you schrodinger's library. It solves all problems perfectly (and instantly to boot). Though user beware, if you actually *look* at the results it provides, there is a chance the results will be correct and a chance they will light your computer on fire... The use case I've described twice now requires a float when you ask for the bin edge. It doesn't matter if you provide me an inconsistently rounded float, or if you had me a magic custom type that is perfect in every way yet I have to convert to a float myself, if I don't have a way to get my hands on a consistently rounded float, then your library is not sufficient for this use case. I must say, this has been a wonderfully useless conversation. You asked for feedback, so I described an actual real-world issue I've faced multiple times in production. You've clearly never seen nor dealt with this issue before, yet you've been oddly insistent your library fills this need. A library is definitionally an incomplete piece. It doesn't matter how beautifully it behaves internally, if the overall behaviour within a broader application is incorrect/inconsistent then the library is not a good fit. And that's fine. No library will be perfect and if you don't want to cover this use case that's your prerogative, and you can still garner an audience that doesn't need it. I wouldn't use it, but so far every time I've needed a histogram in an algorithm it's been a sensitive enough use case that I wouldn't use a third party library anyway. &gt; Ok, if you are an expert then, I leave you to believe what you believe. Lol, nice passive aggression. That pretty much sums up this whole conversation. I can literally say "Been there done that, want to hear what I learned?", and yet despite the fact that you've not experienced the same things yet, somehow you know better. That side conversation was supposed to be a friendly overture, to take the edge off things after I felt I'd had to come back and correct/explain things too much. I didn't want you to feel beat up when you're asking the commuity for feedback. Yet even here you felt you had to repeatedly come back and tell me my direct experiences are wrong, despite not having industrial experience yourself. It's made you sound like an ass. You're fun.
And what happens when you do the same on a boost function? Or a QT object? Or fmtlib? Or wxWidgets?
And if it doesn't? 
Yeah, the way we are using `std::system_error` is odd, but it's worked so far. `error_code_extended` sounds even better. We have no aversion to using Boost, so it's likely that we'll replace our in-house implementation with Outcome in the future.
Mostly to automate the boring repetitive stuff in calculus, esp. numerical integration
/u/unrealengine
[Here's my .ycm_extra_conf.py](https://gist.github.com/vector-of-bool/20bf5bab56b936f0b34e5ade9188b4a3). I haven't touched it in nearly a year, so I can't say it's perfect. It also makes some assumptions about the project layout, ie: source files beside their headers, a `build/` directory at the root of the source tree, etc. Additionally, [here](https://github.com/vector-of-bool/vscode-cmake-tools/blob/4dc3ab83f5004c93683236d3f587acefcb8703d3/src/compdb.ts#L19) is how CMake Tools normalizes source file paths, which is much more thorough.
And what if your java / python / whatever app doesn't have docstrings either ? 
Ah... This spam again.
Post-processing data for Canada weather forecast
there are lots of difference between java and c++ on functions, if you actually learned both.
system_error does have a highly non-trivial destructor thanks to the vtable. If your stack unwind is complex, you won't notice it of course.
&gt; But they won't have to chose between 10 different standards. I honestly don't even know of another documentation standard for C++ than doxygen. It is *the* de facto docstring.
There isn't anything formally standardized, but most everything uses doxygen, so I'm not sure what the real advantage would be...
There is at least another one mentioned in this thread, and one comment claiming to use it in their library.
I am curious about this. Exactly how do you C++ here? 
At the moment, we're shipping Dinkumware's Filesystem TS ("V3") implementation, with some bugfixes by me and Billy. Billy will be working on overhauling it to follow the C++17 Standard which extensively changed the spec, and to correct longstanding issues like lack of symlink support.
Thank you!
&gt; Step 1: "Oh no! Pointers. :-(" &gt; Step 2: "Oh, no pointers. :-)" This is a brilliant description.
Thank you for your suggestion, are there any benchmarks that show an increase in performance from the use of this approach? I think **"test and test and set" can not improve performance for lock() in most cases**, otherwise there would be a way to do this for std::atomic_flag which is intended for spinlock. But there is not any way to do this (test and test and set). * there are only clear() and test_and_set(): http://en.cppreference.com/w/cpp/atomic/atomic_flag * but you can't do test without set, operator= is deleted: http://en.cppreference.com/w/cpp/atomic/atomic_flag/operator%3D Also, even if we implement spinlock by using std::atomic&lt;int&gt; and will use load(relaxed) for test(), then even if load(relaxed) is free on some platform, then next CAS(acquire) will take the same large time as without previous load(relaxed). Relax reads are free on some platforms - this means that "relax reads" do not give the actual value of the variable and that they do not bring the exclusive state of the cache line that required for the CAS operation. In any cases we must wait for the exclusive state of the cache line to do CAS (or TAS - test_and_set) operation. The main cost of atomic operations is the waiting time for the actual value of the atomic variable (waiting for the some S-state of cache line for read, or waiting for the another X-state of cache line for write or CAS/TAS). On platforms with a "weak memory model", the LL / SС approach is used, in this case, it is really not necessary to wait for the exclusive state of the cache line, because even if you have a cache line in the read-only S-state, immediately after LL-load(acquire) you can continue the speculative execution of the critical section code with a temporary write ban, * and only after the successful execution of the SC-write(relaxed) - perform all Writes of the critical section * otherwise, if SC-write(relaxed) is unsuccessful, then cancel all executed operations inside the critical section I.e. can be these optimizations: * ARM v8 64 gcc 5.4: https://godbolt.org/g/r3jrLo * C++ -&gt; ASM and possible reordering: https://hsto.org/files/41e/bc2/b59/41ebc2b59de94ff0a319cd0efc6b4040.jpg * for LL-Load(acquire) used - ldaxr - Load-Acquire Exclusive Register: http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0801c/pge1427897401219.html * for SC-store(**relaxed**) used - stxr - Store Exclusive Register: http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0801c/pge1427897435711.html * for Store(release) used - stlr - Store-Release Register: http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0801c/pge1427897421621.html Programmer’s Guide for ARMv8-A: http://infocenter.arm.com/help/topic/com.arm.doc.den0024a/DEN0024A_v8_architecture_PG.pdf - **Store-Load can be reordered** - page 191 (13-1): "Reads and writes to Normal memory can be re-ordered by hardware, being subject only to data dependencies and explicit memory barrier instructions." - **cmp-branch in CAS can be speculatively executed** - page 192 (13-2): "Speculation - When the processor encounters a conditional instruction, such as a branch, it can speculatively begin to execute instructions before it knows for sure whether that particular instruction must be executed or not. The result is, therefore, available sooner if conditions resolve to show the speculation was correct." But all these optimizations https://hsto.org/files/41e/bc2/b59/41ebc2b59de94ff0a319cd0efc6b4040.jpg occur automatically on the CPU with LL/SC (Load-Linked / Store-Conditional) without your participation, and you can not improve performance more by using additional test(relaxed) - "test and test and set". Or do you mean cases where used try_lock() instead of lock()? while(...) { if(spinlock.try_lock()) // with relaxed semantic { ... critical section ...} ...other code... } 
So ACCU is waiting with releasing Herb's talk until his proposal is finalized? Is that a special request from Herb? By the way it's really awesome how fast ACCU is getting all these videos out! Huuuge thank you to them!
Considering some of the library features were voted in very late / have issues that's not necessarily a huge issue :)
It's still in the experimental namespace.
libstdc++ actually implements bidirectional iterators for path. There were a bunch of discussions about this in the standardization process -- all the other implementations used stashing iterators which technically means they only meet the input iterator requirements (even though they can be dereferenced multiple times and moved backwards). To actually have bidirectional iterators class path needs to be something like `variant&lt;vector&lt;path&gt;, path&gt;` where the first is engaged for more than one path element and the second is engaged for singular path elements. The other standard libraries emit more efficient code but their `path::iterator` can't be given to `std::reverse_iterator` since they aren't bidirectional iterators (and in practice `std::reverse_iterator::operator*` returns a reference to a destroyed temporary path).
Just rechecked my code - you're right. Seems like I got the header name and the namespace experimental prefix confused. Apologies for spreading false information.
Hi. [Bugs in Microsoft projects :)](https://www.viva64.com/en/inspections/#ID0EVHAC) What next? Propose a project for analysis by PVS-Studio.
Yes, he requested the video be delayed as far as I've heard. And I can barely keep up with all these talks. It's insane how fast they come. 
Thanks stranger. I was looking for something like this.
One of the issues with vectorization is that in a lot of circumstances using it violates the rules about floating-point reordering. IIRC `-ffast-math` among other things also implicitly enables `FP_CONTRACT`, and thus the “unsafe” optimizations that it normally prevents.
I found the most recent Casablanca analysis to be rather interesting.
/u/h-jay, I'd love to see samples of the code you're talking about. I'm sure there are bugs in our code generator but the statement "crap that fails on simple textbook-style" seems like an exaggeration. Still, if you've got bugs, we should fix them. A direct email for me is firstname.lastname@microsoft.com. Thanks! 
Follow up: http://stackoverflow.com/a/43769812/3282436 https://github.com/boostorg/build/issues/194 My issue was that I left the Python version empty in my `user-config.jam`. I think that leaving version blank is supposed to be supported, but it looks like they recently made a change to support building multiple versions of BPL that broke that behavior.
I'll try it, thanks!
projection mapping
A 3D model of Gamma radiation measurements collected using a drone. C++ and Qt3D
I like tabs too, so I split my left pane (Projects) vertically and added an Open Documents pane, which is basically the same thing.
If your concerns are customization and themes then Wx is not the proper choice. The point of Wx is it's currently the best way to write straightforward desktop application gui in C++ such as we've been making for the last 25 years. If you can imagine the thing in terms of some listboxes and trees and maybe one or two fancy animated thingies in panes, then Wx is great. If you're thinking "Minority Report" then look elsewhere.
- for work: a lims "laboratory information management system" for a high power laboratory.
Did they analyze cppcheck? (or is it too meta)
Care to compare against using operator* on a valarray instead?
libfcgi? With the c++ wrapper classes for the streams?
Controlling video processing FPGAs that drive really big (and really small) LED displays. 
Probably a more accurate title is "(Towards) a true heterogeneous container in C++" It started out as me having a bit of fun, but turned into something cool and interesting that I thought the /r/cpp community might enjoy.
Sort of but remembering to `delete` at the end is pretty easy. The real problem is remembering to `delete` on all paths (`throw`, early `return`).
&gt; Yes, he requested the video be delayed as far as I've heard I whinged about this on another thread as well, but I find this a deeply frustrating decision. (Seemingly) every other talk from the conference is being shared, and yet the one that was apparently the most exciting and potentially revolutionary is being deliberately withheld. I just don't get it. (Oh, and as an aside: I agree, kudos to the ACCU team for getting these videos up so quickly. The ones we "little people" are allowed to know about, anyway...)
&gt; Basic things like calling std::min&lt;float&gt; will break it. Which is unfortunate because `min` is a supported operation of SSE and should thus be trivial. If it had to implement a `min` using other SSE primitives that would be more understandable, but it shouldn't have to...
Awesome, I'll give them a watch, thanks!
'a' is the name of a structured-binding member, are we sure that we are allowed to capture it? According to 8.1.5.2p4, a simple capture only works with a variable of automatic storage duration declared in the reaching scope. I don't think structured binding components are considered variables, let alone with automatic storage duration. I think GCC7.1 is wrong here. That said, I DO notice that if you use init-capture, it works.
In fact naive std::function implementations are VERY costly.
I am quite unsure why Odin Holmes thinks it's a good solution to have for each (possibly) polymorphic type a wrapper with a pointer that calls the function. I understand that he suggests that non-polymorphic types can be placed in vector (and that would be a good thing). He'd do that because even non-polymorphic types could benefit somehow from the slow-down of calling a function through a pointer indirection?
The top level drawable (not a pointer, concrete type, non templated, on the stack) holds a pointer to a polymorphic type, which contains a regular T which fulfills your drawable concept/interface but not as a pointer As far as I can see, that's the exact same regular cost of regular polymorphism
cocos2d-x though I wouldn't recommend it
Why not? I find the scene system is a overkill for 2D games, but it's still pretty good.
Which one would you recommend instead? 
&gt; “Can I have a std::vector that holds more than one type?” The canonical, final, never-going-to-change answer to this question is a thorough “No” Wrong. See ```std::any```
He addresses `boost::`/`std::any` just below that question, along with `boost::`/`std::variant`. Also, technically, a `std::vector&lt;std::any&gt;` still only holds one type.
Yes, but if you have T a polymorphic type isn't that double-cost for a single feature? Otherwise it's nice that we can reinvent features that the programming language already offers, but I really feel that it's a somewhat useless thing he's doing there. But that's my feeling, feel free to ignore it.
I guess the biggest shortcoming I could see (other than things like contiguity and "when would I ever use this") is that it seems like your visitors have to advertise all of the types that they would use in advance, even if if they are fully generic. You should be able to do: c.visit([] (const auto&amp; x) { std::cerr &lt;&lt; x; }); For example.
&gt; Also headers. Lets get rid of headers. Modules can't come soon enough. Modules are not a silver bullet though. Templates would still need to be type-checked and instantiated every time on every TU probably for the same set of types over and over again. Or in other words. If you have a header only component, modules will help you a "bit" with compile times (20-30% faster which is no small feat), but not much more. That is not enough to have a pleasant edit-compile-debug cycle in big projects.
Thanks, I guess I'll look for something else then :) I really like Qt with QML, but the dependency is huge I find it. 
fast math isn't only accuracy, it breaks functionality. For example if you have to deal with inf and nan values fastmath breaks x != x, std::isnan and std::isinf. So there is no way left to detect them, would be nice if there was a way to have both optimized math and a working std::isnan. 
Use clang?
Because with Android you'll have all sorts of issues
Interesting article, but without benchmark I'm not convinced. Using std::unordered_map will cost you a lot (even if it's O(1), it's still way slower than deferencing a pointer). I don't know if it's possible to replace it with something that can be evaluated at compile time.
A couple of reasons. For example: Exceptions. (Simple) Exercise for the reader to figure out why those are relevant here. Similar to forgetting, I suppose.
Writing gamehacks, although it's mostly C I make sure to use C++ whenever possible. 
I managed to achieve a "heterogeneous container" based on [Sean Parent's talk](https://www.youtube.com/watch?v=QGcVXgEVMJg). It involves using a class with a templated constructor, which then has inheritance hidden inside as part of some private nested classes. I was playing around with it [here](https://github.com/mariobadr/clipp/blob/master/include/clipp/clipp.hpp#L118). The class is basically a type that can take on other types, and can then be stored in a vector (or any other container). I feel Sean's approach is easier to understand than yours, though I'm not advanced enough in my C++ to do a proper comparison. 
Even with `std::function` optimizations, that's still two indirect calls.
The nontrivial part is transformation of the control flow `std::min` generates into "this is a min operation" that can be vectorized as such. I'm not saying I wouldn't love the optimizer to deal with this, but I am saying any optimization that requires moving control flow around is always more complex than people think it is. ~~~~~ Update, looks like we do detect the min operation, but std::min passes by ref and the vectorizer doesn't like that: https://godbolt.org/g/h92M9J. I'll file a bug.
what kind of gamehacks if i may ask?
&gt; 5% cognitive masturbation That's part of the 5% surely ;-)
Admittedly I only skimmed it. But what I didn’t find an answer to is the question: # Why?! The only motivation I could find is that it’s often asked for on Stack Overflow. But I claim that 100% of these questions are [X–Y problems](https://meta.stackexchange.com/q/66377/1968), and that the best answer is *not* to use a heterogenous container as discussed here, but another solution. In fact, all these questions reveal glaring holes in the code’s conceptual design. There *may* be a good use-case for this container but I’m not entirely convinced. The most likely use-case, a “bag” (as used e.g. for weakly typed transport protocols such as JSON), can already be implemented in C++ without too much hassle.
Because I could :-). One assumption of my article is that the questions are not x-y questions when I said "Assuming your design isn’t totally off-base, what you really wanted to do was use a std::variant or std::any and apply the Visitor Pattern to process it." I agree that a lot of the time the solution is multiple containers. I often see someone go directly for a heterogeneous container when they've been using polymorphism for a while and suddenly they realize that they are dynamic casting all over the place, and they want to remove some of that logic. Heterogeneous containers may make sense as a refactor in this scenario, and often they may not. I've seen something like this happen when wrapping C++ up to Python clients. The Python users simply don't care about what type is inside the container (surprise surprise) so they don't want to specify which subcontainer to push back into, and if you're templating to achieve a uniform API it won't wrap well. Now, in these scenarios what I believe is supposed to happen is that you write your interface layer code in such a way that your container holding different vectors appears to Python properly as similar to a Python list as possible, but I've also seen the "holder" pattern instead that uses a variant under the hood (less like a Python list, but also perhaps less confusion from the Python user when it doesn't accept "new type X")
At some point we might want to store a collection of related but different (=polymorphic) objects. In order for this to work, typically we would * create an interface * implement the interface for each type * store pointers to interface instead of values With the concerns of resource management in modern C++, we would end up have something like `std::vector&lt;std::unique_ptr&lt;IInterface&gt;&gt;`, where manually calling `std::make_unique` and `.get()` are part of the interface usage, and more types / coupling. 
Yeah I forgot to address the use of std::unordered_map. I chose it over std::map because I didn't want the cost to access any one instance's data to grow as the total number of instances did. Re: something that could be evaluated at compile-time. I scratched my head on that one too. Maybe there is a way to do it; and we just need to experiment more. I think it's likely not possible yet. (A constexpr container would be really, really cool. Scott Schurr's conststr [best link I could find](http://stackoverflow.com/questions/33202944/convert-constexpr-compile-string-into-a-template-char-list) but you can't dynamically grow/shrink it)
well it's more serious than that, but it's not so serious you need to switch from gcc while learning C++. hopefully people raising noise about this will embarass the gcc team into fixing it
some compilers have been pretty bold in breaking programmer expectations that are not supported by the language specification. but only intel seems to optimize fp math by default.
Thanks for the reply and link mariobadr! Sean's approach is super cool (as is everything he does). Like any other heterogeneous container there are some drawbacks to it. There is a teeny bit of polymorphism going on, but the real problem is that the possible functions you can run on the held type is restricted to whatever is defined in the "concept" class hidden within the container. It works well for Sean's example because the only function he wants to use is "draw". That is, as I see it now, you can't really "visit" the container with arbitrary functionality.
&gt; typically we would What you write sounds more like a description of Java than idiomatic, modern C++ — as you’ve noted, it involves an awful lot of pointer juggling, among other things. It’s certainly not what I would do in most situations. `variant` types and similar concepts have been around for ages. **But**, point taken. There’s a *lot* of code written this way, and I see that having an easy to use, heterogeneous container would make a lot of code less awful.
That's a perfect description of what I do, too
What benefits does build2 have over modern CMake?
Haha, well you *could* pass a "token" type in to each push_back, and the result of the push back is not just void but another "token" type (that publishes types pushed back so far). Then on visit, you could pass that token again. Hell for the client, but it'd work :-)
Being actually modern?
Thanks for the response, redditsoaddicting! I like your enthusiasm! Oooh, [expression templates](https://en.wikipedia.org/wiki/Expression_templates). Those are shiny. I didn't consider them at all. I like where you're going with it. Re: "I definitely think it's possible for you to figure out which types a visitor can handle" Perhaps true in some small fashion, but definitely impossible for templated visitors.
Nice ad hominem there. ;)
&gt; C says, talking about FP_CONTACT, "The default state (‘‘on’’ or ‘‘off’’) for the pragma is implementation-defined." Damn, so why did I remember it having to be OFF by default?
I may have been somewhat derived of sleep when I wrote that. The original version was even worse. I can actually understand that a central authority on documentation would be nice. 
You should not rely solely on the compiler, try some static analysis tools.
Something being newer doesn't make it a better choice automatically. 
Note that the schedule for C++::London [has changed](https://www.meetup.com/CppLondon/events/238262489/).
Some MMOs, Counter strikes and one rhythm game. I've learned so much (that's why I did it in the first place), but it was not a pleasant ride. Mostly because everything is undocumented, you're on your own, and you depend on knowledge of certain someone from some forum. But it was worth it. Do you know that feeling when you started out programming and you managed to get something (primarily) simple to work after trying and trying for hours and hours? I felt like a kid learning all about computers again. That surge, rush you get is amazing, like your at the top of the world. Now, imagine being one of the first people discovering some amazing function to hook or something. And nothing is documented. You're on your own, a challenge. You just need to reverse, think backwards, pondering at all those sequences of x86 asm... 
Do you think the word was intentional?
The way I was imagining that working is that you have the visitor and the types you're trying to give it, but there's probably a complication in overlooking. I haven't had time to look at that in detail, but I will say that there are (arcane) workarounds for templates in some other introspective stuff, e.g., figuring out the return type of a callable object without knowing in this context what you're going to pass as arguments, under the assumption that every possible call returns the same type, which is reasonable for my eval, optimize, etc. stuff. 
they're kinda similar though
&gt; It is unclear what the future of the project will be, Qt people are torn between QBS and cmake as a qmake replacement for Qt6+ I only found statements as if they already decided they will use QBS for Qt 6 build system. https://twitter.com/jakepetroules/status/837128340108541954 http://lists.qt-project.org/pipermail/development/2017-March/028927.html Do you have examples of them still being torn?
Yes, but the link in your post still contains the rescheduled talk :)
I can see the reason for the approach. Seems interesting and useful. Does build2 for example support generating VS project files, so I could still have a nice file layout in the editor, but delegate the build process to build2?
I would recommend sqlpp11: https://github.com/rbock/sqlpp11
I asked about it in Evolution, this is likely an oversight in the wording, working on getting an issue started in Core :)
C and C++ generally don't have "standard" libraries for all sorts od things. I think that's largely because of the following: * less DB work is done with C or C++ * ORMs incur a performance penalty, that's not loved 'round here * ORMs are complex frameworks, which inevitably comes with a bunch of opinions being had; C and C++ are an opinionated bunch, that doesn't bode well with opionated ORM code :-)
It would imply that it could, but none of the optimizers (GCC, LLVM, UTC, ICC) do it.
I think in practice a desire to be DB platform independent plays a big role in ORM adoption. Rather than leverage all the features of a specific RDBMS to the full, people get an idea that they want to abstract away the specific DB and run on all of SQLite and MSSQL and Postgres. So they eschew triggers and stored procedures and views and such-like in favor of a complicated ORM to handle these things. I think this is dumb. You want to use a highly featureful DB and leverage the features as much as possible. Once you admit to yourself the code is married to a specific DB, and configuration management of the DB is part of the application code, then the point of an ORM is a lot harder to see.
&gt; I think this is dumb. Yeah loose coupling is hella stupid. /s
You can get loose coupling just by writing code against an interface. ORMs make you write tightly coupled code (just look at django's).
Correct. What an understatement!
&gt; if one of the underlying build systems can't do something then neither can CMake Can you give an example of that?
Is it possible to use this with QtCreator?
I don't like how you have to create a type for `my_visitor`. This is easy to fix. template&lt;class F, class...Types&gt; struct typed_visitor_t: visitor_base&lt;Types...&gt; { F f; template&lt;class...Args&gt; auto operator()(Args&amp;&amp;...args)const -&gt; std::result_of_t&lt;F const&amp;(Args...)&gt; { return f(std::forward&lt;Args&gt;(args)...);} }; template&lt;class...Args, class F&gt; typed_visitor_t&lt;std::decay_t&lt;F&gt;,Args...&gt; typed_visitor(F&amp;&amp; f) { return {std::forward&lt;F&gt;(f)}; } Now we can auto printer = typed_visitor&lt;int, double&gt;( [](auto&amp;&amp; x){std::cout &lt;&lt; x;} ); you do have to list the types you support. Another thing you can do is have your container optionally list the types visitors must support. Another thing you can do is have your container list the operations the types inserted must support. Then permit executing the operations. The type of a function object is one way to express "you just be able to support this operation". So auto print = [](auto&amp;&amp;x){ std::cout &lt;&lt; x; }; hetro_type&lt;decltype(print)&gt; bob; bob.insert(7); // automatically compiles how to call print on an int, and stores a pointer to it in a table bob.insert("hello"s); // automatically compiles how to call print on a std::string, and stores a pointer to it in a table. (bob-&gt;*print)(); // uses the print instance and the saved tables to execute print on each of the arguments. In short, there are a number of ways to handle dispatch. A list of supported types at either container declaration or operation use or a list of supported operations at container declaration. Ideally you'd want to support them all. --- For performance, you are erasing operations on a single element. Instead you should be erasing operations *on a vector* or a `span&lt;T&gt;` of elements. That drop the erasure overhead down to once per type per container, instead of once per element. 
Sure: VC projects/MSBuild cannot produce Clang's compilation database. Since CMake doesn't "know" the compiler command lines that will be executed underneath, it can't generate it either. Or, here is another one: in `build2` we have a limited rpath emulation on Windows so that you can actually run things like tests (that link to the DLL being tested) without any kind of DLL copying/PATH hackery. We do it using Windows side-by-side assemblies and to be able to pull something like this off you need to control the executable linking stage.
In my opinion its false loose coupling- you are just moving the pain up a layer- and introducing a new layer for bugs and performance issues to arise. Moving to a new DB is in general a huge project and not something to be taken lightly- And generally speaking, a move isn't going to just be from mysql to postgresql or oracle, usually a move involves rethinking whether to use a document oriented database or a key value store, etc. In summary, an ORM is optimizing for a scenario that just doesn't happen very often, and even if it does, the problem is likely going to look very different than the one you anticipated. I guess the other part of the argument is that SQL is the easiest language to learn that I have come across, I get that marshalling/unmarshalling objects is a bit tedious, but it shouldn't be difficult and doing it correctly is critical to system performance. 
Clang has -Wall and -Wextra flags. There might be some situations in which GCC will warn and Clang won't, and vice versa, so if you want all the warnings just use both compilers.
Sure, but most stuff is unnecessary. ORMs can be useful, though. It think I'd phrase it as in cases where ORMs are most useful, other languages than C++ are frequently much more convenient. Ruby on Rails is really cool, IMO. It solves some valid problems, and makes some aspects of persisting a website in a database really convenient. But if I need to run a web app in C++ because Rails isn't a good fit, an ORM is probably solving the wrong problems for me. If an ORM is a good fit and makes things more convenient, the Ruby probably also makes things more convenient than C++.
Clang intentionally has great compatibility with GCC flags, implementation-defined behaviour, etc. It's totally worth using both. And one of them has `-Weverything`, so if unreachable code isn't in there, it won't be in any other option. Not always the most useful thing to compile with, but definitely useful to check for the existence of a warning.
There are several, both open-source and free ones such as cppcheck and scan-build, but also commercial solutions such as pvs-studio.
Currently, I work at a CDN. I am actually more on the build side than doing a bunch of C++ development every day, but we basically have a very high performance web server application that serves a non trivial percentage of the traffic on the Internet. Previous job was in visual effects, so my background involves a lot of image/video processing and 3D rendering related stuff.
I'm currently trying to make I own neural network library on GPU, there are not a lot of deep learning libraries in C++ so... why not ? I'm learning a lot with this project. I had practically no experience (I'm 16 and started programming 2-3 years ago) and I had do restart everything from scratch like 3 times because it was not modular enough or because I didn't think about 1 small thing that ended up making everything else useless. Now I think I have the good architecture (or at least I'm pretty close). I just have a problem with shared weights, I want to make everything as simple as possible but I'm still thinking about a way to make shared weight possible without making things more complicated. 
Only true if you aren't the one paying for developer time (or don't mind paying).
https://isocpp.org/blog/category/events is one way of keeping track. Somewhat related, there's also a list of user groups at http://meetingcpp.com/index.php/user-groups.html
&gt; In my opinion its false loose coupling- you are just moving the pain up a layer- and introducing a new layer for bugs and performance issues to arise. I disagree. If your code is at all aware of what database it's running on then that's tight coupling. If your code is unaware of what database it's running on, but it just so happens the interface it relies on can't be implemented in terms of MySQL, that's a different problem. I'm not stumping for or against ORMs, I'm saying that coupling to a particular database is bad.
Same with `std::pmr::polymorphic_allocator`. I thought that made it in C++17? gcc7 still keeps it in the experimental namespace.
No, it lacks a good organizer, if there are no meetings.
Totally disagree. ORMs not only offer little value, they add to development time. You still have to learn how to use the ORM.
/u/sempuki already beat me to the punch. This is the point. &gt; It's easier to ask "why are they necessary"? I am honestly not sure what problems are solved by ORMs. Maybe I haven't worked on a sufficiently complex enough project backed by a relational database, but I have no problem working directly with SQL. I get to directly decide how the data is stored, passed around, etc. in my code. I don't have struggles that make me wish there was some tool to alleviate my suffering.
The ORMs you've tried must be pretty bad. 
The same reason coupling to anything is bad. Your code shouldn't care the exact SQL queries that are being run, it cares about a higher level conceptual operation such as "*get all employees who joined the company in 2015*" or "*save this employee object*."
ACCU just ended last week, was another great conference, even without any Morris Dancers this year. But they run regular evening talks throughout the UK very regularly, and they'll be back again next April. Try to snag the early bird tickets. Also don't forget Meeting C++ in Berlin this November. It may exceed ACCU this year in size actually.
Can you be more clear in what part you don't understand? For every template you invoke, the preprocessor will generate a copy of that template, but will substitute "T" for the actual type. Essentially doing all the copy-paste for you.
It's unfortunately a major no-go for a lot of people (or at least myself!). No VS, no fun. The "Open Folder" feature might be coming along but I need the VS debugger, VAX autocomplete, etc. The usual VS "tooling". (Except that the project does need to run on all platforms - hence CMake - but local development is done on VS. Linux is for CI and server customers.) So I'm actually not sure whether a build system that is not designed from the start to support this is a smart idea.
This is just begging the question, not really answering it. If writing a system specifically leveraging features of pl/SQL makes it better, then it's best to do that.
mmap
&gt; VS debugger, VAX autocomplete Those all work with Open Folder just perfectly fine. :) Open Folder mode has some special integration for CMake to make it easier to setup is all (otherwise the build system or user must generate a handful of simple JSON files to tell Intellisense about header paths, defines, etc.). That special integration was not available to plugin authors or anything last time I checked, but maybe if people post about it enough on [UserVoice](https://visualstudio.uservoice.com/forums/121579-visual-studio-ide) they'll open that up.
Yeah but if you're using a VS generator then you need to re-run cmake twice, with different generators, and not forgetting to have 2 different build directories (one for each generator), each time you add or delete a file ? This limitation is a real pain. Also regenerating the whole compile_commands.json each time is also stupid. We need smarter tools that just add/modify/delete the right entry in there. For large projects it's getting costy (I've seen compile_commands.json &gt; 1Go. You think twice before regenerating the whole thing).
Remember that GTKmm and libsigc++, which work very well together, use modern C++.... Where a real comparison can be made, is 3rd Party use and support. Qt has a monstrous following in desktop, mobile, scientific, automotive, and probably more. Gtk still seems focused on Desktop. That's not to say Gtk can't be used for those things, it's just probably not already done at that scale. I personally love gtkmm and find it much more pragmatic and easier to integrate into existing non-GUI large code bases. Qt is still used more and some professional people get bothered when the GUI isn't Qt cause they're ignorant.
You are correct if you want to target different architectures (32/64) with the visual studio generator you will need different build directories. You don't need different build directories for different configurations. I haven't dug into build2 to see how or if it supports these use cases. I do believe that challenges in CMake are with expressing how to find the correct library for each architecture. 
I compile with gcc for binaries, but I use clang for additional warnings. Actually I use `clang++ -Weverything -Werror`, but then I completely remove 22 "worthless" errors and convert 8 "good to know, but not critical" errors back into warnings. ~~FWIW, one of the ones I consider "worthless" is `-Wunreachable-code`. Why? Like most static analysis tools, clang reports way too many false positives when you use `if (some_boolean_constexpr)` as a poor man's `static if`.~~ ~~So I'd also like to know if there any decent (and free or inexpensive) static analysis tools that can report don't lose their minds over the `if (some_boolean_constexpr)` pattern but can still report *useful* warnings about unreachable code and always-taken branches that require a bit of inference.~~ EDIT: Added strikeout of above paragraphs. I just enabled clang's `-Wunreachable-code` again (using Clang 3.8 if that matters), and I think it's very reasonable. Thinking back, my original reason for not using it was probably a conflict with Eclipse CDT's code analysis, and I think I also recently conflated it with CLion's worthless static analysis of unreachable code. Conclusion: I recommend `clang++ -Wunreachable-code`.
b/c c++ ppl actually take responsibility for their shit maybe?
That's not how template instantiation works. It has nothing to do with the preprocessor.
Fair enough. "Preprocessor" is not really the stage where the copy-pasting happens, but it's a nice mental model to have. At least, that's what I presume your issue with my statements is. Perhaps you can be more clear?
The simplest answer is how do you write a test? With tight coupling that means you have to spin up your full production DB which can be challenging (e.g. what happens when you have multiple tests running in parallel? how long does it take to instantiate the production DB? how do you distribute your tests across machines?). Now that doesn't mean you can't implement a layer that's tied to the DB, but it's a good idea to try to not leak that detail outward unnecessarily so that you can write tests for upper layers against an alternate implementation that uses an in-memory DB or a known-to-be-correct implementation so that you can root-cause test failures more quickly). *EDIT: That doesn't mean that ORMs solve that coupling issue either as you're then just coupled to the ORM, although it can help because you can just plug-in whatever DB implementation suits you (e.g. in-memory sqlite DB for tests)
Isn't this absolutely identical to what Sean Parent suggested in his (awesome) talk "The Base Class of all Evil", or something similar? Does he acknowledge Sean who has been talking about "concept based polymorphism" for quite a while? (And Adobe publishes a library for it IIRC).
"to be held September 24-29, 2016" It seems I'm late to the party again... ;)
Why are you taking registrations when you haven't set a date?
This. We have some large code bases, yet you could count the usage of the new keyword on fingers of both hands.
Fixed
Why in the world would we want an ORM?
I don't think I understand what you mean here: what is true for `build2` too and what path forward (is CMake somehow going to figure what what MSBuild is going to do)? In `build2` we run `cl.exe`, `link.exe`, etc all ourselves (so we do use the VC toolchain). So we can generate the compilation database as we build and can do it incrementally just as we build incrementally. With the "Open Folder" feature you will be able to do all of this from the IDE.
[Scaling](http://stellar.cct.lsu.edu/files/gb17_hpx.pdf)
The best place to start is the [Introduction](https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml). Then you can dig into the hello example buildfiles, etc.
&gt; some ~~professional~~ people get bothered when the GUI isn't Qt cause ~~they're ignorant~~ Because GTK don't really care about any environment that isn't Gnome, while Qt works reasonably well, even in Gnome.
&gt; (if one of the underlying build systems can't do something then neither can CMake). Not true, cmake has a lot of build-system specific tuning and variables. For instance they recently added the possibility for ninja builds to not depend on libraries being built in the same project to start the build of depending libraries, which is not possible with its make generator.
Thanks for clarifying. &gt;I would imagine VS adds ability to generate the compilation DB as part of VS before they add build2 support. There is a third option: they will fix the remaining issues in "Open Folder". &gt; I believe the primarily purpose of the DB in the first place is for refactoring My impression is that its primary purpose is static code analysis (via clang-tidy). And I don't believe VC has anything comparable (I may be wrong, though). The bigger point, however, is this: CMake will always stay married to the horrible way of building things which is VCProj/MSBuild. There are plenty of other limitations (see my link above for details).
Yes, it does have static code analysis. The open folder technique is intractable if there are any external macros (e.g. Code for multiple platforms, optional features etc). At best they'll offer a way (if they don't already) to specify them manually but it's a hack that's not particularly maintainable. I have read through the link. It's not particularly compelling to me. In my opinion the build system should serve the developer's needs whereas build2 IMO tries to solve the wrong issues. Now the better syntax/language is a huge win. However, I'm not convinced the loss of IDE integration is worth it.
All standard containers already support this. You can easily have an allocator + pool pair, where the allocator is fed into a `std::vector` and the pool uses a bunch of memory on the stack to allocate from.
yes, but my problem is not with CMake, but with wanting both vcproj, and something incompatible with vcproj, at the same time. 
&gt; The open folder technique is intractable if there are any external macros (e.g. Code for multiple platforms, optional features etc). At best they'll offer a way (if they don't already) to specify them manually but it's a hack that's not particularly maintainable. The build system can maintain it without any problems. In fact, if you think about it, that's pretty much the same problem that the compilation database solves. So, who known, maybe Open Folder will learn to use that. 
Nice! Proteomics right here.
Tensorflow is implemented in c++ 
&gt; for example, because Open Folder is good enough and you really want source code generation maybe, but maybe at the same time glorious new features will be added to vcproj that I will really want to use. 
What use case are you considering where this would be useful?
They are nowhere near as bad as setters, and sometimes they can be the right choice (particularly the quick choice). But basically once you have a getter, you are committing that a certain piece of state will be part of your implementation, or at least producible from the implementation. A very simple example would be if you are writing a class that performs some kind of query for the user and returns it. Suppose person A analyzes the logs and notices that it's common that recent queries are repeated. He adds a fixed size cache that caches some number of queries. Perf improves. Than person 2 comes along and adds a getter for the data structure which holds the cache. It's returning a const ref, so it's harmless, right? Well, it's not harmless. The point of the structure is to do queries. Not provide a cache. Now if perf characteristics change again and you want to remove or change the container, it's a breaking change. This is what I mean by the fact that getters constrain you. Getters, used incorrectly, are basically a special case of too-wide interface. They just happen to ubiquitous because they are an obvious thing to do and certain other languages encourage them. When in doubt about interface choices, go with the narrowest that satisfies the needs of the clients of the class. Remember: widening interface is backwards compatible. Narrowing is not. 
Check out [short_alloc](https://howardhinnant.github.io/stack_alloc.html), which is an STL-compatible allocator that can used a fixed size block of static or stack memory, falling back on heap allocation when that's exhausted. 
Thank you. Definitely trying it out.
ACCU was 430 this year. So you're much bigger! But they take the full week like CppCon or C++ Now, however they are 90 min talks + 30 min corridor time and 90 min lunch breaks
They used an old Google logo for the golden sponsor. 
&gt; The simplest answer is how do you write a test? With tight coupling that means you have to spin up your full production DB which can be challenging Alternatively have an object that /only/ interfaces between the DB and other code, and write tests with a mock of that object. If you need to exercise your actual database, e.g. running integration tests, tight coupling isn't a negative; testing vs e.g. sqlite when you run on mysql is a mistake.
msbuild supports custom build steps and full custom build 'targets'. This is what CMake uses to support complex source code generation with VisualStudio.
&gt;... CMake Windows rpath emulation ... This is an interesting way to solve the problem, nicely done.
I agree ;) I tried to touch too much content in one talk. I think something like "policy based class design by example" with just that part will work better in the future.
But does it support these custom steps/targets informing the build system about discovered dependencies? Check this [use case](https://www.reddit.com/r/cpp/comments/51l0eb/build2_toolchain_040_released_adds_windows_msvc/d7dut4j/) -- can you handle this with MSBuild?
thank you daveed and louis for invalidating most of my TMP work ;) I love you for it! This is super exciting. 
I don't fully understand the example, so hopefully my understanding is correct . If you want to have your odb wrapper regenerate every-time foo.hpp is modified that is possible by making sure that the custom command that generates the odb code has marked it has a dependency on foo.hpp. This is a good starting point for custom commands ( http://stackoverflow.com/questions/2354473/cmake-add-custom-command ) . I know that more recently CMake has add support for byproducts of custom commands, which is really only a ninja issue.
&gt; If you want to have your odb wrapper regenerate every-time foo.hpp is modified [...] Not only that, but I also want it to be regenerated if any header that `foo.hpp` includes (transitively) is modified. The only way to achieve this would be for the ODB compiler to contribute this dependency information back to the build system (similar to how, say, GCC/Clang do it with the `-M*` functionality). `build2` was designed from grounds up with this in mind. 
CMake allows you to have custom commands depend lots of things including specific files, and also targets. My initial thought is that in cases like this you are better off describing the dependency at the target level ( depend on the target that foo.hpp is part of ). 
There are two things this reminds me of. One is that the container is either static or dynamic based on a template. Libraries like Eigen do this by accepting a "size" template parameter, and having a specialization for "size=0" that uses dynamic storage. The second is using static storage up to a certain size, and then dynamic beyond that. This is commonly known as the "small size" optimization or [small buffer optimization](https://akrzemi1.wordpress.com/2014/04/14/common-optimizations/), and LLVM's [SmallVector](http://llvm.org/docs/ProgrammersManual.html#llvm-adt-smallvector-h) is a good example.
WOW! This is what you call a Special episode!
&gt; It uses native widgets Are you sure about this? I see no mention of this in the README and couldn't find any traces of native APIs in the code (admittedly, I looked at it only very superficially).
come on, you know it and I know it
but it's generally used in python
ooh that's so cool :p 
Oh, wow, thanks! I knew about the "Open ... CMake" option but hadn't realized it works just for any folder, even if there's no build system there that it recognizes! I definitely need to try it again. Pretty cool.
How is that a bug?
It's perfectly in context if you read the comments on his last post.
I too went [full darth vader](https://youtu.be/WWaLxFIVX1s) when he said that. :( 
It's not. 
This is definitely not a useful case, it is more of a test and practice exercise to improve skills, the only case I think this could be of any use is if you wanted to sell an incredibly robust system to support any kind of optimization strategy without constant updates, but as you know, early optimizations most of the times are evil.
Honestly, if Qt didn't force you to use their own IDE (i think you can use it on some other ides, but i'm not sure) I'd definitely use it. It's the best toolkit we have so far.
It forces an IDE? That will be news to the half of the developers at my company who use emacs. And the ones who use vim. And the KDE developers who use kdevelop. And all of the people who use it from visual studio (which they provide a plug-in for.)
At work, in C# and Java, we use a simple QueryBuilder class. It sits right in between. It's smarter than manually and textually assembling a well formed SQL statement but dumber than any system that has a full awareness of the schema.
&gt; Gtk still seems focused on Desktop. And even then, not particularly focused on Windows or OS-X desktops, which are fairly common.
GOLD- loved every minute of it, thanks for continuing to put this together and provide a great service to the C++ community.
Why shouldn't you use a vector of shared ptrs?
It is real.
Thank you for library, but for me, it's too many words for simple HTTP request http://vinniefalco.github.io/beast/beast/example.html . Comparing to cpprestsdk https://github.com/Microsoft/cpprestsdk/wiki/Getting-Started-Tutorial#making-an-http-request-and-saving-the-results, C# HttpClient http://stackoverflow.com/a/14435574/61505 or Java HttpURLConnection http://stackoverflow.com/questions/359439/how-do-i-retrieve-a-url-from-a-web-site-using-java/360291#360291
what even is real in this crazy world?
I think the sentiment isn't to use an existing ORM but to spin one up on-demand as you build your application.
You tested on MSVC too and had the problem as well, or did I misread your blog post? Maybe I did, as it doesn't make sense :-)
&gt; At the Fall 2017 C++ standards meeting, the C++ standards committee changed the syntax for exporting a module ... Huh? Is this the future?
Thanks. I updated the post to read "November 2016". 
what language is that valid in
Is it still best to include all these modules in a PCH? Or should they be included on a file-by-file basis?
Up to and including the colon it's a label (for goto'ing to), after that it's a comment.
There must be something not right with the current 'Committee Model' when somebody inside the committee says there are too many people inside. It is a design problem if an organization doesn't want more members. Shouldn't c++ try to create another less bureaucratic structure to put all the very capable people not really needed in the committee somewhere else more productive for the language? I have the feeling that the current model of, write a proposal, defend it in the next face-to-face meeting, keep doing it for years, get approved, then wait for the implementation of it from different compilers, then wait for people to upgrade compilers... Dunno... this models seems to generate stable stuff, but would be possible to have, in parallel to this, a more flexible structure?
From earlier discussions I understood this was because there is virtually no compile-time cost involved anymore. Importing a symbol is much, much cheaper than including its header. And since having a few pages of #includes or imports is ugly and distracting, the proposal (it is not final) is to go to a coarser granularity for the standard header. I find those reasons compelling, and I do believe this also formalizes what is essentially already existing practice anyway, with most files including most of those symbols (either directly, or as part of a PCH).
We use reference-counted pointers (our own implementation that predates shared_ptr) extensively in our software. I always had a hunch this must cost a fair amount performance-wise, and felt guilty about so much atomic reference counting. Some testing I did years ago indicated it might be a 10% hit on performance. Finally, recently, I took two damn weeks to slog through a great proportion of our code, replacing copy construction of references with move construction. This slashed the number of atomic AddRefs and Releases by 82%. During a transfer of 4 GB, the number of atomic operations dropped from around 20 million, to around 3 million. It had *zero* impact on performance. *Zero.* In fact... it made performance slightly worse. Then I launched the profiler, and made a few tweaks to our byte vector, which was initializing memory in a loop that I expected would be vectorized, but wasn't. I changed that to explicitly call memset. Boom, 50% improved performance.
Is anyone able to comment on how using this feature impacts compile times?
Got it, thanks for the links.
 export module std.random; seems much nicer and logical to read than: export import std.random; Does the second both export and import `std.random`? Is there any reason for not also allowing `module` keyword to be used?
With those results, I assume your test code was single threaded.
That `_request` routine is over 500 lines of code. That is bothering me for no reason.
I am not the author, but I have used Beast in the past. I think an analogy can be made to the STL. Prior to the STL, other languages and even containers in C++ would have a sort method. To sort the container you would just call c.sort(), with maybe an enum for ascending or descending. Then then the STL came, and suddenly to sort, you had to std::sort(c.begin(),c.end()) which was more complicated. Asio, is kind of like the STL for asynchronous programming. The genius of asio, is not so much the functionality it provides, but the way it decomposes asynchronous programming into orthogonal components that you can compose to do all kinds of asynchronous programming from networking to signals. Just like the STL, asio is on its way to being standardized by the C++ committee as the way to do network programming. However, asio does not have a built in way to handle http. Now rolling your own http is a pain and you are likely to get the edge cases wrong. What Beast provides is a way to process the http in a way that is "native" to asio. So why would you be interested in asio and Beast. 1) The networking TS is based on asio, so learning asio will be a great investment 2) Once you learn asio, Beast feels pretty natural 3) You get great flexibility in combining libraries. For example, if you were writing a web server where you wanted to read a file and serve it, you could use Beast for the http part, and AFIO for the async file read part and combine them with asio to get a non-blocking web-server. 4) Once we get the low-level, flexible portions of http processing right, we can build better abstractions on that foundations. In fact, a lot of different people can build abstractions, and because they use asio, we can use them together. 
Came here to say the same thing. Not only that but the code is plain ugly. You could actually use functions to tell what you want to do. As of now every reader of this function has to decipher the meaning of all the statements again and again. And a nesting level of 11? WTF! Also why no range for, why auto_ptr, ... the Json library you use uses C++11. And the parse rule function. OMG! Countless if-else with string comparisons. You know you could have a map or unordered_map to map the strings to enums and then have a switch statement. Nor re-arranging ifs to improve performance needed anymore :P The whole tag is true could then be handled by a fall through. Further you would need just one return true then at the end of the function. Return false if the string could not be mapped to an enum. Also you could adapt rule.t just once. And the same magic numbers over and over again. There is so much duplication it is crazy. The code could easily be made cleaner, shorter, faster and easier to modify. ...
 What is the /DSTD_MIN flag ?
I feel like it should be pointed out that the standard library version they used was at least 14 years old: ~/src/gcc$ git show -s 9f815d0eb2930b13f0d5d5f28f9fa43987ae0ce0 commit 9f815d0eb2930b13f0d5d5f28f9fa43987ae0ce0 Author: redi &lt;redi@138bc75d-0d04-0410-961f-82ee72b054a4&gt; Date: Tue Aug 12 08:46:43 2003 +0000 2003-08-11 John Levon * docs/html/ext/howto/guide.html (GLIBCXX_FORCE_NEW): Update remaining places for the name change from GLIBCPP_FORCE_NEW to GLIBCXX_FORCE_NEW git-svn-id: svn+ssh://gcc.gnu.org/svn/gcc/trunk@70363 138bc75d-0d04-0410-961f-82ee72b054a4 Sadly, they didn't actually figure out what was causing the leak, so it's not possible to tell if it's still present.
Why not the simple export std.random; ?
Qt has QGtkStyle and the Gnome platform theme, so if you run a Qt application under a GTK desktop, it looks and feels native. If you run a GTK application on a Qt desktop, there is no such attempt to fit in. This problem exists to some extent with GTK2, but with GTK3 (with the header bar and client side decoration) it's much worse.
no, it should be 'art vandeley' or 'vandeley art'
relevant user tag
&gt;You need to add the compiler switch /MD when compiling a source file that consumes the standard library modules. The /MD switch brings in the dynamic library for the CRT. In a debug build, you need to use /MDd instead of /MD. So using a static CRT is not supported for modules? Or is this just a limitation of the current implementation?
 struct xyz {}; const xyz = foo(); Did I forget the variable name or do I want `const auto xyz = foo();`?
And this is faster than `std::vector&lt;std::any&gt;`?
I prefer gtkmm over qt. Qt is basically a Java-like library grafted onto C++98/C++03, and forces you to do stuff in a pre-C++11 way. (Maybe that's changed in recent versions of Qt?) GTKmm integrates much better into modern code.
In their case they have more than just 5 tokens and of course it depends on their distribution. Yet judging from what their code looks like I doubt they ran proper benchmarks to use the ifs over something else ...
Isn't the variable name xyz in both cases?
This case might be more interesting: struct xyz {} const abc = foo(); Did I forget a semicolon or do I want `const struct xyz abc = foo();`?
So apparently including some C headers (from SDL headers I believe) includes vadefs.h which conflicts with modules via: 1&gt;c:\program files (x86)\microsoft visual studio\2017\community\vc\tools\msvc\14.10.25017\include\vadefs.h(128): error C2953: '__vcrt_va_list_is_reference': class template has already been defined 1&gt;c:\program files (x86)\microsoft visual studio\2017\community\vc\tools\msvc\14.10.25017\include\vadefs.h(125): note: see declaration of '__vcrt_va_list_is_reference' I added _CRT_NO_VA_START_VALIDATION to defines, but that just gives: 1&gt;f:\dd\vctools\compiler\cxxfe\sl\p1\c\modulereader.cpp:4536: sorry: not yet implemented 1&gt;e:\code\native\ghlib\include\ghlib\reflection.h(105): fatal error C1001: An internal error has occurred in the compiler. 1&gt;(compiler file 'f:\dd\vctools\compiler\cxxfe\sl\p1\c\moduleutilities.h', line 21) 1&gt; To work around this problem, try simplifying or changing the program near the locations listed above. 1&gt;Please choose the Technical Support command on the Visual C++ 1&gt; Help menu, or open the Technical Support help file for more information So I'm stuck there :) I think I'll wait some more until modules have better support.
&gt; Don't forget that C++ may be used by people with little experience, it needs to be taught in school. Fully agreed.
C++
We are working on providing more official numbers, externally verifiable. But like anything else C++, it is taking time because of all the other stuff to attend to. Anyone willing to try the newer compiler bits on their favorite projects and report numbers, please drop me a line
The current C++ standard headers are a mess. In future releases, the modules will be tracking the [Standard Library Modules](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0581r0.pdf) proposal.
Not yet in this preview implementation of the Standard Library Modules. This is an experiment the VC++ team is conducting, so it is deliberately fixing some variables. Of course, once the design is locked (or close to), the team will move to provide full support for all scenarios of interests.
Modules are a better replacement of PCHs, so normally you wouldn't want to include them to build another PCH. Modules aren't header files. You don't include them; you import them. It is cheap to import a module. Declarations are resolved on demand, so you don't pay for what you don't use.
I know. It is a deficiency in C++11/14 standards :) First of all this "rule" is in-place only in non-existing-yet C++17 standard. If compilers were to follow pre-17 standards -- they should not automatically call dtor at all. Ok, most compiler writers decided to implement auto-dtor call for anonymous union members in this specific situation (where it get's constructed in parent class ctor initializer list). But the thing is -- in ctor body I can "manually destroy the union member subobject"... auto-destruction should be switched off once we enter ctor body. I didn't check if it is a deficiency in C++17 standard or in those compilers I checked, but it was certainly not a pleasant surprise to discover. Edit: if you think it is a non-issue, consider a case when your union has two members and in ctor you decided to "switch" to another (for whatever reason).
&gt; Allow “export import M;” and “export { import M; }”, with the semantics of “export module M;” in the current draft, and remove syntactic support for “export module M;”. Does that qualify as a rationale ? In any case, the Blog post describe the change as follow &gt; At the November 2016 C++ standards meeting, the C++ standards committee changed the syntax for exporting a module. So, even if there are subtle differences and the underlying behavior needed a fix, at the end of the day, for a regular developer, the behavior is similar enough that s/module/import/ do not change the meaning of the program. Therefore, I argue that the `export module` syntax should be kept, even though the behavior may have change slightly. I would also like to add that "`std::move` do not move" and carries an *intent* rather than an implementation detail, and, using the same logic, `export module` is a sane, easy to understand manner to carry the intent of the developer. There is no denying that to someone reading the standard, `export import` has a semantic rational behind in, and I'm sure `requires requires` is also logical as far as the compiler writer is concerned. However, they are neither elegant nor useful as far as program readability is concerned. And once again, it makes teaching tedious enough that you wonder why you didn't stick to python. &gt; -"If your module depends on another one, you need to make it visible by using the `export module Foo`" &gt; -"Hum, ok" Versus &gt; -"If your module depends on another one, you need to make it visible by using the `export import Foo`" &gt; -"??? Why does it say `export import` ? Maybe it should be just export ? Maybe it should just be just import? Are all languages as confusing? This is so dumb, everybody uses javascript anyway, I shouldn't have taken this class." ( I'm caricaturing slightly, but you get my point ) It's the little things. 
Indeed. I'm interested in seeing some benchmarks and am a bit surprised there's none on the blog post since, as you say, reduced compile times is one of the main purposes!
If my memory serves me correctly, I think I heard "uniformity" and no redundancy, i.e. not having `export import M;` and `export module M;`.
Have you tried this recently ? The KDE distro (can't remember the name) made by the KDE folks makes GTK apps look fine. There is a Gtk oxygen theme of course. There are efforts in that space. But more importantly is programming model and maintaining code. Pick your poison at that point since your back end should be different from front end and GUIs should be able to be ported easily. I go with GTK for that ... 
Yes, cpprestsdk certainly allows you to accomplish some specific goals more quickly and easily than Beast. But it also comes with some baggage - you are tied to their asynchronous model and their method of processing tasks, e.g. `pplx::task`. Beast does not tie you as closely, it operates on concepts. And it relies on Asio which is eventually going to become part of the C++ standard, currently under consideration with the name "Networking-TS". Solutions which rely on standards are going to have greater longevity and support than solutions such as cpprestsdk which mix together cross-cutting concerns.
&gt; Would you be able and so kind to share our concern with the committee concerning this issue ( and more generally, the importance of sane syntactic constructs ) ? Of course, I will; however, I cannot guarantee the result. It helps too if there are paper trails in committee documents. Would you be able to write a short note (and rationale) to be included in the Toronto pre-mailing? That way, one may avoid (not sure) "Gaby is complaining about WG21 not liking his syntax." What we are doing is important, and it does not have to be ugly because C++. 
I jumped into C++ by learning to program graphics APIs (OpenGL, Direct3D, Vulcan, etc). Even thought most languages have bindings to use them, the native interfaces are in C++, and you can find tons of video tutorials and guides. Good way of getting your feet wet in some heavy C++ while also learning some highly valuable stuff. Hope you have a good grasp of linear algebra and matrix math though
ES6 people will already be confused because in ES6 const isn't immutable
No. In the first case, xyz is a type name.
I still don't understand why MS cannot just go ahead and add yet another flag in the VC++ property pages, something like **Use modules**. Is it really so hard? Sure, it's experimental, so okay, put **Use modules (EXPERIMENTAL USE AT YOUR OWN RISK MS OFFERS NO SUPPORT FOR THIS)** if you must but don't force developers to compile from the command line. It's 2017 for crying out loud, no need to be so sadistic.
Quant finance related stuff. Analysis, trading, console-based UI.
I don't recall the exact details, I was combining multiple tables with references between them and lazy weak and non weak pointers. I recall an instance where I failed to have the lazy weaks to be loaded when needed although following the instructions in the user guide. I also had some "surprises" when expecting that I get the same shared pointer for the same "record". I've read about sections but if I've multiple different parts that can updated independently it then requires as many sections as parts that can be updated but I also always need all the sections to be loaded. As I said my choice of using sqlpp11 is that I wanted to have direct control on the SQL through a DAO (which I also used with ODB to abstract away the database logic). Another item was the heavy dependency on boost, although I noticed that ODB supports std features when they appear, e.g. shared &amp; weak ptr and the choices are usually right (e.g. optional). So all in all, both odb and sqlpp11 are good options. As said above, ODB is easier to start with and a good choice if ORM is needed. sqlpp11 on the other hand requires good understanding of advanced template programming.
No problem :) I am a big fan of both VS and modules, so I am super excited that work on them is progressing as well as it is, even though they didn't manage to get into C++17.
My guess would be lack of resources. They are hardly done with the feature and seen from the outside of MS the VC++ team seems to get the short end of the resource stick. But I am guessing that much like for places like Google Microsoft needs to get their compile times of C++ down and that means modules. They are actually able to dogfood this feature and I am pretty certain it is going to be rather well supported quickly because of this need.
And `constexpr const`.
Wow. First `requires requires`, and now `export import`. If we're going to to have ridiculous syntax, how about import std.random &lt;= and export this module; It makes about as much sense as `export import`, and is made up entirely of valid C++ tokens...
Wait what?
I haven't written any Java in years so I can't comment on that.
Makes sense that you need it, I make C++ code for electronics our systems are magnitudes smaller than anything Microsoft releases but we need to reduce compile times (and test execution times but that is more of having to move away from LabView/TestStand) too.
Really bad naming, this const behaves like final in Java what means that you cannot reassign variable/field, but they used keyword from C that makes variable immutable. They could use let/final instead of making this ...
I like https://www.youtube.com/user/lefticus1/videos
Actually I thought the additional `const` was redundant (in some cases at least).
It would be nice to we non meta-programming use cases like this as well. The most fun is to use reflection to access hidden methods/vars in libraries
the article author did attempt to file one, but the issue has been resolved now in the latest stdc++ implementation. Though for those using older implementations it is still an issue.
 template &lt;typename T&gt; bool equal(const T&amp; a, const T&amp; b) { for... (auto member : $T.variables()) { printf("var: %s\n", member.name()); if ((a.*member.pointer()) != (b.*member.pointer())) { return false; } } return true; } Demo: https://godbolt.org/g/maV08o
This code is wrong on so many levels 
I guess the best advise is to just constantly work on private projects. Personally, I prefer games or game engines in general as they cover a large spectrum of different coding practices. Also you may use codereview stackexchange to get valuable feedback from experienced developers.
Sorry! I've never thought to do what he asked about. I just shared my initial two cents on the issue. Thanks for correcting me :)
I would be interested in comparing to a struct holding a std::type_index, void *, and a std::function to run delete and hold that in the container. Maybe, if it matters, throw in some small value optimization but that adds more complexity. class any { std::type_index m_type; void * m_data; std::function&lt;void( void * )&gt; m_destructor; public: any( ): m_type{ typeid( std::nullptr_t ) }, m_data{ nullptr }, m_destructor{ []( void * ) { } } { } template&lt;typename T&gt; any( T &amp;&amp; value ): m_type{ typeid( T ) }, m_data{ static_cast&lt;void *&gt;( new T( std::forward&lt;T&gt;( value ) ) ) }, m_destructor{ []( void * ptr ) { delete static_cast&lt;T*&gt;( ptr ); } { } ~any( ) { auto tmp = std::exchange( m_data, nullptr ); if( tmp ) { m_destructor( tmp ); } } ... template&lt;typename T&gt; T &amp; get( ) { assert( std::type_index{ typeid( T ) } == m_type &amp;&amp; m_data ); return *static_cast&lt;T*&gt;( m_data ); } template&lt;typename T&gt; T const &amp; get( ) const { assert( std::type_index{ typeid( T ) } == m_type &amp;&amp; m_data ); return *static_cast&lt;T*&gt;( m_data ); } };
If there is near zero abstraction overhead, why isn't the entire standard library just a single module?
I wouldn't be that worried, after all concepts and modules were on his list for 17 and that didn't influence much.
&gt; Even so, no compiler actually removes it to maintain backward compatibility. Wrong: VS2017 removes `auto_ptr` (and all other features that are removed in the upcoming C++17 standard) when compiler option `/std:c++latest` is in effect.
True! I consider this separation somewhat artifical, too. If consumption of modules is really such a no-brainer, then why not just going all-in with a single module `std` and another (conceptified and rangeified) module `std2`?
The organization of the Standard Library in terms of modules isn't just driven by how fast it is to import module. As I said in earlier post, we would like an organization around a cohesive, logical topical facilities.
When bootstrapping, you should always start with clean toolchain source by unpacking from the archives. That script is written in POSIX shell and we try to keep it as simple as possible. Plus the equivalents for windows are batch files. 
Don't tell it Marla.
So awesome! I'm a big fan and follower of the beast library, and I hope that the new http interface will ease up chunked body read. Can't wait to get my hands on it. Thx for your great work!
How does that mesh with privacy? It would be pretty bad if reflection bypassed access checks; as this would simply mean that everything is public and all invariants are out of the window. On the other hand; if it is supposed to respect access checks, how does a class grants access to a particular function? (See: `make_shared` fiasco with respect to private constructors)
Yes. They're tags.
The StrongRectangle is a very bad example of how to use strong types. You are not supposed to unpack them in the ctor just to safe them as doubles. The correct way of doing it would be this: class strong_rectangle { public: strong_rectangle(width w, height h): m_width{w}, m_height{h} {} width get_width() const {return m_width} height get_height() const {return m_height;} private: width m_width; height m_height; }; In order to make width and height usefull you provide the meaningful functionality that they need directly; this is the only place where you should touch the doubles in them: width operator+(width lhs, width rhs) {return width{lhs.get_value() + rhs.get_value()};} width operator*(width lhs, double rhs) {return width{lhs.get_value() * rhs};} width operator*(double lhs, width rhs) {return rhs*lhs;} The reason for this can easily seen from the following code: auto height_sum = rect1.get_height() + rect2.get_height(); auto width_sum = rect1.get_width() + rect2.get_height(); // OOPS: C&amp;P-error The version in the article will do wrong things at runtime; the version that *really* uses strong typing will fail during compilation, which is what we want. Another advantage is the following: strong_rectangle operator*(width w, height h) { return {w, h}; } If you are talking about width and height it makes some sense to get a rectangle when you multiply them. And since you are strongly typed, it is a somewhat reasonable to overload the operator. You cannot do this if you just use your types as annoying wrappers to make function-calls harder.
When /u/foonathan posted about [strong typedefs](http://foonathan.net/blog/2016/10/19/strong-typedefs.html) he came to a similar conclusion. However, in his type safe library, [strong typedefs](https://github.com/foonathan/type_safe/blob/master/include/type_safe/strong_typedef.hpp#L49) constructors and several member functions are prefixed with `constexpr`. Is the `constexpr` keyword necessary for zero-overhead in more complicated examples not presented by the OP? If not, why would I use them?
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [foonathan/type_safe/.../**strong_typedef.hpp#L49** (master → b576bf3)](https://github.com/foonathan/type_safe/blob/b576bf311254952736c3abd6823c397e247b4ea4/include/type_safe/strong_typedef.hpp#L49) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dh8oem2.)^.
One of the common names I have seen for this is *phantom types*.
Look, I don't care about your toolkit or even mine. You're obviously focused on a catch-all solution here. OP sounds new at this (GUIs) so I'm glad we're both venting. I fired up the KDE distro (Neon) and ran `gtk-demo` and the "header bar" worked fine.... You seem to not consider Linux desktops as being mixed between GTK and Qt. It's just not realistic. You run no GTK apps? You think they're all made poorly? Or just plain look bad? I've seen some of the worse code and worse design (look) in Qt apps than I've ever seen with Gtk. We can all agree that Qt, GTK, and Wx are seriously viable options. Who really cares about "native look and feel" when it's simply a game of matching themes - seriously Qt and Gtk look fine together. Maybe your plasma desktop is fucked up? Im not sure. Side note, I think QGtkStyle is old now, doesn't work with Qt &gt; 5.6 or something. So have fun making Qt apps "just work" with non-plasma (KDE)... 
It's not available yet. Well, perhaps /u/andrewsutton could give us more details :).
It's not convenient when the script fails to install because of permission reasons and it has to recompile everything again. Which leads me to another question: you don't provide binaries on build2.org, why?
All that's really necessary is that the type only have the members that the alternative would have (e.g. if width is like a double only have a double as a member, so the size is the same) and make the methods in it all inline (they are implicitly if defined inside the class body). constexpr is just icing -- it additionally lets you do calculations at compile time so there is no cost at runtime.
You can serialize only the public members of an object and keep the implementation details private. As I said in my previous post, you can choose to reflect over only the public data members of a struct. Then as long you only change the private members of the struct in code, the serialization format remains compatible because the public members are unchanged. I still don't see where the serious, unavoidable issue is for this use case.
https://xkcd.com/1172/
The difference is that now you actually need to implement a class width. The article uses just a phantom type (widthTag) and a using declaration to create a new type. And maybe now I want to calculate the circumference of the rectangle, which requires adding a height and a width? But this operator is nit implemented. This is *too* strong typing. You could be this strict with units, maybe.
constexpr enforces that the calculation _can_ be done at compile time so that the resulting expression is at all times a constant expression and can be used where constant expression is required. int array[foo(42)]; The foo() must be a constant expression. This is a classic example why the compiler enforcement is required. Any deviation from constant expression will be reported by the compiler. It does not guarantee that the computation is done at compile time, for example, if the parameter to foo is not a constant then the result is not a constant expression - it just means that the code must be written in a way that when all arguments are constants the result will be a constant (expression). 
I think you're trying to write a version of std::any that doesn't use any polymorphism? That's a fair thing to attempt, and an interesting approach. It puts all of the book keeping on the client, though doesn't it? Else we violate strict aliasing with the `get` function and enter UB territory. It needs something like `std::any_cast` to check the typeid under the hood and throw. This whole try...catch pattern in the client becomes tedious as the number of types grows, and additionally really slows things down, whereas a visitor on an andyg::heterogeneous_container will iterate over the appropriate vector that stores each type. Effectively, the heterogeneous container is much better optimized for reads. As (small) aside the impl you've provided still needs to address copying, else a normal push_back won't work (basically it's a move-only type right now). 
&gt; OP sounds new at this (GUIs) so I'm glad we're both venting. OP wants to know why GTK's API is so terrible. Given it was invented by people who used C because they were philosophically opposed to C++, then reinvented half of C++ with GObject, I'm not really surprised about this. &gt; I fired up the KDE distro (Neon) and ran `gtk-demo` and the "header bar" worked fine.... It "works" fine. It just makes no sense whatsoever on a platform where everyone else uses menus and toolbars like sane people. Even worse, it hides the default window decorations and draws them itself (badly) because who cares about the users preferences. &gt; You run no GTK apps I use Emacs, with the menu and toolbar hidden. Thankfully, while using GTK3, it hasn't fallen victim to this header bar nonsense. I also use Inkscape, which still uses GTK2 and therefore works a lot better. &gt; Who really cares about "native look and feel" when it's simply a game of matching themes - seriously Qt and Gtk look fine together With GTK 3 it really isn't just a game of "matching themes" because the theming system is inadequate (compared to Qt or GTK 2), so you don't, for instance, have a GTK 3 version of QtCurve (my preferred theme). &gt; Side note, I think QGtkStyle is old now, doesn't work with Qt &gt; 5.6 or something It still works, it's part of Qt now. See [here](https://news.ycombinator.com/item?id=11898861) for example, to see why I think the GTK developers genuinely don't care about anyone but Gnome. GTK 3 really isn't an option anymore unless you're developing specifically for Gnome.
Repeating a comment I just made on the blog post: &gt;&gt; We are working on getting numbers that can be shared publicly and reproduced by the community. Internally we have seen reduced compile times from less recompilation. Honestly, though, the improved code cleanliness has been the biggest benefit. C++ Modules are kind of like a type system for your code organization in that they help to provide abstractions and relationships, and especially enforcement of these. Before we started using modules in Windows we absolutely thought compile time was the biggest motivation. Our opinion changed quickly based on our experience. Having tools to enforce architectural boundaries is critical when you're working on a project with a lot of devs of different experience levels and design philosophies. It's especially good when these tools are part of the compiler, rather than some modeling tool in the IDE (no offense intended, VS!)
If anyone's interested I have a [phantom type implementation](https://github.com/Enhex/phantom_type) that you use just like the underlying type.
This library still uses "goto" statements.
Whom should I ping to get a nasty bug in coroutines fixed faster? Maybe, Gor Nishanov? :) https://developercommunity.visualstudio.com/content/problem/23949/stack-overflow-in-generated-coroutine-code.html
I'll take a note and check on it on Monday. (And gor has the office next to mine :-) )
I get your points here. Choices are good. But it is a little digressed here. For the original question by /u/sphere991, it is harder for C++ to be too experimental because of its wide spread usage. People get upset when their code is broken. Still, balancing evolution and stability is a tricky business.
Is the idea that you would want to force just one module on everybody, or that you would want to see one single module in addition to the decomposition exposed in that paper? C++ has at the very minimum two sorts of implementations: freestanding and hosted. The freestanding implementation is not required to provide all the goodies in a hosted implementation. So, you get that dichotomy going on. Next, from a cohesive presentation point of view, there are certain topics you would just want most people to stay away from -- some are in the `std.memory` modules. You start getting the gist of it. I personally think that a decomposition around 5 or 6 modules of the entire standard library isn't too bad.
That is an allowed redundancy (which I don't recommend in code reviews), but not compulsory as `export import`.
Indeed. You can't have appreciable compile-time you can write home about if you keep the current mess, without code hygiene. We need to have better code hygiene, so that the tools (the entire toolchain, not just the parser/type checker, but especially the linker) can make good assumptions to provide better and faster support. I've consistently presented the goals of modules as: (1) support better architecture; (2) isolation; (3) compile-time improvement; (4) better semantics-aware tools. It is nearly impossible to get (3) if you don't have (1) and (2). I've seen this over and over. [Manuel Klimek's CppCon 2016 talk](https://www.youtube.com/watch?v=dHFNpBfemDI) is another independent experimental concurrence of this basic observation. Point (4) is essential for productivity and increased safety.
Shouldn't be any UB as the asserts guarantee that the retrieved type is the stored type. The ... was the stuff like copy/move... but here is a small impl https://godbolt.org/g/3WM16V that optimizes well(at least in the small case)
That would be very great. Thank you! Everything worked like a charm and then unexpectedly broke in latest RC.
The first one makes no sense. You're not exporting a new module called `std.random`, you're re-exporting something you've imported. You are importing `std.random` and then exporting that thing you imported. it reads like `export (import std.random)`. 
Never heard of `requires requires`, but `noexcept(noexcept(x))` makes perfect sense: the `noexcept` of this is conditional on a value, and the value is `noexcept(x)`. 
&gt;If export import is the way to export a module It's not. `export` is the way to export something. `export import X` means 'import X and export it'. You are exporting the result of importing X. It makes perfect sense. &gt; should be imported with import export. It's imported with `import`. What would `import export X` mean? Export `x` then import it? That's retarded.
It baffles me that people would be confused by this very obvious and simple feature.
&gt;Would you be able and so kind to share our concern with the committee concerning this issue ( and more generally, the importance of sane syntactic constructs ) ? If you don't like it, write `export { import X; }` which is more verbose but does make it clear what is going on. `export import X` means precisely `export { import X; }` i.e. import X and then export that namespace.
There's nothing compulsory about `export import`. You are exporting the thing you're importing. It's only 'compulsory' in the sense that writing `=` is compulsory in an assignment statement: you're doing something, you're writing the most obvious code to do that thing.
Are you being sarcastic?
Here's a few that come to mind: 1. Call a free function; 2. Call a static function of `derived`; 3. Call a member function of `derived`, but make sure you don't use uninitialized members or virtual functions; 4. Do the work before constructing `derived`. I'd personally prefer any of the above over your lambda. Use a regular construct that allows you to use as much space and intermediary variables as needed. Right now, you code is indented by 4 tabs, is not reusable and is bunched up in an unusual place. Don't try to cram stuff like that. By the way, your lambda has an unnecessary `()` (implied) and return type (inferred). And don't pass objects by const reference if you're going to copy them. struct base { std::string s_; explicit base(std::string s) : s_(std::move(s)) { } }; template&lt;typename T&gt; struct derived : base { explicit derived(const T&amp; v) : base(fix(v)) { } private: template &lt;class T&gt; static std::string fix(const T&amp; v) { std::ostringstream ss; ss &lt;&lt; v; return ss.str(); } };
Passing objects by const reference to end up making a copy is fine, so is passing by value and calling `std::move`. They have different pros and cons. In constructors specifically the latter is probably preferable but it's almost certainly a totally pointless optimization for most classes.
It depends what you are doing but you can see a substantial performance hit, mostly from the simple fact that shared pointers are twice the size (typically) of raw pointers, reference wrapper, or unique_ptr. So you tend to get more cache misses/use more cache (causing more misses elsewhere).
Its proper english as far as I can tell, but the phrasing is off. Its like a massive active vs passive voice problem.
&gt; Moving the parameter is always either the same or better than copying a const reference. I see no reason for the latter, whether in constructors That's false. This approach is slower for almost all types, on lvalues. It's copying a reference + copy construction, vs copy construction + move construction. `unordered_map` shows up as 56 bytes in my standard library. Even assuming it would simply be optimized to copying those bytes over (not sure if that's even very likely), 56 is still a lot more than 8. Not to mention the moved-from object has to be destructed, technically. &gt; or elsewhere. Even more false. If you are in a member that's not the constructor, you may well be doing copy assignment. So now we are compare copy constructor + move assignment, vs reference + copy assignment. Copy assignment doesn't always trigger a heap allocation, a copy constructor does. On random data, your approach will trigger N heap allocations, vs Olog(N) for passing a const reference. const &amp; + &amp;&amp; overloads are strictly faster than passing by value (at least for non-primitive types). However, value passing is not strictly faster than only const &amp;. It gives you slightly worse performance characteristics in both cases but effectively gives you both overloads at once in this situation. Anyway hopefully you see the issue is more complex than what you made out and there is room for a diversity of opinions, so there is no reason to state it as fact.
I like the idea of the 'standard C++ library' being a single import so that new users (and probably experienced ones) don't have to spend any thought on what to import. If it's just 5 or 6 modules for the entire standard library then the problem is pretty much solved. I haven't read the whole spec, but I assume a module can export other modules, so it would still be possible to have an 'import std.all' feature in the future. Thank you for your work on this, I really look forward to the whole header file mess going away!
Since move-semantics were introduced, passing by const-reference is more expensive than passing by value, for cases where the argument can be moved into the function. You can update your "rule of thumb" to include: if the function copies the parameter, pass by value instead of const-reference and move the parameter. 
&gt;&gt; Moving the parameter is always either the same or better than copying a const reference &gt; That's false I don't believe it is. If the original value was moved, then there are no copies at all. As for the case where the original value _was_ copied, the difference between copying a reference and a move constructor is, to me, irrelevant compared to the savings that are made possible by allowing a move. 56 bytes over 8 is trivial. &gt;&gt; or elsewhere. &gt; Even more false Again, you are ignoring the case where the original value has been moved. I would agree, however, that the consequences of not moving the original value are more severe when assigning. I've found over time that most values _can_ be moved around, which is why I recommended value+move instead of ref+copy in this case. Obviously, `const&amp;` and `&amp;&amp;` overloads are preferred since they handle both cases optimally. &gt; issue is more complex than what you made out Indeed, I will modify my post to explain it.
To be fair, .NET has always had this so C++/CLI picked it up by default. 
Error messages can always be improved. &gt;Also from what I can tell, 'for...' seems to be more intuitive and flexible than using the pack expansion operator Then why add them?
Wow, that sounds great. Thanks for sharing that. And it makes so much sense.
Lambda is a quick way to write an anonymous function. If it's short and obvious enough, sure. Otherwise, consider giving a name (that is, write a function), e.g. in an implementation file derived::derived(params) : base(prepare_stuff(params)), ... {} namespace { retval prepare_stuff(params) { ... } } I would *not* make `prepare_stuff` a member of `derived`, because that creates a superfluous compile-time dependency. I don't know what's the status with lambdas, but with a normal function it's not too hard to force inlining (in nonstandard way, mind), in case the complier fails to do so and measurement shows inl9ning relevant :-).
If you (like me) feel impatient for stackless coroutines - take a look at https://github.com/jbandela/stackless_coroutine which uses C++14 lambdas to get a lot of the benefits of coroutines. Example for those who are familiar with ASIO. http://stackless-coroutine.readthedocs.io/en/latest/Tutorial.html#complete-example-cpp
It is possible to make strong type forward operator calls from the type it wraps using a bunch SFINAE tricks. Then you wouldn't need a specific width class. Now, in general case where you might want specific functions then unfortunately you are back to square one. Then again - do you really need a strong type wrapper for such cases?
One of the reasons for using strong types is to prevent the type to decay into a built-in type accidentally. If you need to access the underlying value, it should be painfully obvious that you are doing so. You got the "int get" part right though. The same logic applies there, you shouldn't be able to stuff a new int in an existing strong type value without explicitly creating a new strong type value and copy it into the old value.
&gt; C++14 :(
The about page says he's Austrian, which explains why you don't find it so hard to understand.
These "old" series by /u/STL are still really good: [Core C++](https://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Core-C-) [Standard Template Library](https://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Standard-Template-Library-STL-/C9-Lectures-Introduction-to-STL-with-Stephan-T-Lavavej) [Advanced STL](https://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Advanced-STL) They are actually on Channel9, not Youtube.
Your "new" rule puts additional burden on the type being passed in: it needs to support the move, whereas with a const ref, it only needs a copy construction. Also what quicknir argues else-thread:-)
This is kind of silly. He answers the question with "no" and then motivates it by referring to drafts that may never make it into the standard. Of course the answer can be no if you are allowed to make up imaginary features.
Movable types are the norm now. In the unusual case of non-movable types you can use a const ref, sure. It's hard to argue that copy-construction instead of move-construction is a good "default" case. Imagine if the copy takes 10 seconds, that would be a devastating impact on performance. 
But it in this sub-thread, we're discussing the case of not changing the object that was passed in. A copy has to happen.
I'd love to make it more interesting, but frankly, C++ features aren't there yet. I must say: I'm not very happy with this blog post either, it was finished a while back, before I finally decided to publish it.
&gt; It is not just hard for humans to reason about those pointer, also static code analyser have their problems which such variables. I found `clang --analyze` to be quite reliable to find such memleaks.
The code in the question wants to hold onto the object passed in ; this is a perfect use case for move-construction. For example `base b("supercalifragislitic");` creates and destroys a temporary parameter which is copied into `b.s` before it is destroyed, whereas if move-construction had been used then a temporary is created and moved. One dynamic allocation (inside the string) instead of two.
Lack of contractions makes it awkward, a couple extra "a"s and such make it foreign, and a lack of commas breaks flow. Pretty tale-tell signs of a non-native speaker.
Of course there is no instance for a c'tor... you missed my point... and they are not.
My understanding is that if you "import std;" you get all the submodules too. So basically whatever the module organisation, you can still do this if you want. Not sure what the consequences are supposed to be.
I'm ambivalent about the syntax, it's either going to be too verbose for some people or too cryptic for others, and they're going to bikeshed that in the committee anyway. I just want a reflection operator and a heterogenous constexpr for loop.
I would not call "Calling static functions from a constructor" an idiom... :) Yeah, I would not use a free function for that, and definitely not "doing the work beforehand", not worth it IMO. 
Interestingly I can second this (I'm German as well). I wouldn't have thought that the familiarity with the native language of the author makes his apparently not so great English pretty normal sounding.
Might as well just do `using Type = int;` at that point...
I generally don't like it, so I ditch it when I can. (I'm ignoring `#include` of course.) Mostly, for my practical purposes, with a bit of refactoring you can often ditch the preprocessor. About the only thing I keep it for now is selecting between build configurations, which is the only bit of `#ifdef` in the code... #if defined(BUILD_TYPE_A) using BUILD_TYPE = BuildConfigurationA; #elif defined(BUILT_TYPE_B) using BUILD_TYPE = BuildConfigurationB; #endif I think you can ditch most of it if you're so inclined.
Are we still saying phrasing?
Really enjoyed this talk
I forgot to mention this was for a commercial product and I don't want to deal with license costs. 
I don't understand your whining. The syntax is honestly fine and doesn't resemble Perl at all. **"`$`" != "Perl".** &gt; for... is presumably some awful way to iterate over a parameter pack? What the hell though. You don't know what you're talking about. It's a "compile-time loop" over an heterogeneous container like `std::tuple`. This works: for... (auto x : std::make_tuple(1, 'a')) std::cout &lt;&lt; x; There's [a proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0589r0.pdf) for this. I also assume that the `...` syntax is not final and probably a quick hack to make the experimental implementation work. What really bothers me about your comments is that you claim that the syntax is "awful" without an objective argument and that you don't propose any alternative. You don't like the syntax? Either explain why instead of bashing it, in order to start a discussion, or submit a proposal. Note that without `for...` you would need something like for_each_tuple(std::make_tuple(1, 'a'), [](auto x){ std::cout &lt;&lt; x; }); How is that better? 
you can use the LGPL version of Qt
How to solve this issue for libraries which can be build as dynamic as well as static libs? And choice is depended on the environment. 
Any idea about how well does it work on Linux? Last time I checked, it didn't at all, but now I see on the website Linux is supported, and apparently you just need to build from source.
Yeah it's (almost?) a first class citizen now. I develop on mac and deploy on windows so I can't speak from personal experience, but I know a bunch of successful projects have been deployed on linux and there's lot of talk about it on the forum. 0.9.1 was just released a few weeks ago
That's not ugly C++ code. It's only 500 lines and doesn't even use boost. I counted max three nested templates. I bet that code takes less than 10 minutes to compile and uses less than a gig of RAM on startup. "I've seen things you people wouldn't believe..."
eh, your example does *not* hold the object in question. If it did, there would have been two allocations, move or not. No?
Try to make only one post when you answer, it's easier for others to respond to. &gt;&gt; Namespace pollution is a real problem, but it's irrelevant at this level. &gt; &gt; Why isn't it relevant at this level exactly? Because the scope is small and well-defined. Namespace pollution is a problem at namespace scope. It used to be a much bigger problem in C. Now that most people use namespaces in C++, it's mostly an esthetics thing as long as you don't have `using namespace` all over the place. The point is, the chances of this new static function interfering with anything are negligible. If it does, the scope is small enough so that it's easy to fix and won't have an impact on anything else. The advantages of moving code to its own unit (readability, easier to maintain, reusable, etc.) far outweigh the impact of introducing a new name in the private section of a class. &gt; I would not call "Calling static functions from a constructor" an idiom... :) By "idiom", I mean something that is widely recognized and understood. Nobody will be surprised to see it and everybody will figure out "oh, you need to do more work before passing something on to the base class". That's a good thing. Use practices that are well-known and understood. &gt; Yeah, I would not use a free function for that, and definitely not "doing the work beforehand", not worth it IMO. Fair enough. You seem to have had eliminated all alternatives even before asking the question. I would still insist that using a lambda to create a temporary "artificial scope" just so you can have statements instead of one expression is a misuse of the language. It's cute and brittle. It's hard to read. It's unusual. &gt; But I agree... I should be careful with the C++ terminology... my bad You should. Wars were started this way ;)
&gt; Of course there is no instance for a c'tor... I'm not talking about for a constructor, I'm talking about to invoke a static member function on. I.e., the direct portion I quoted... &gt; and they are not. [They have _always_ been](https://wandbox.org/permlink/l3uJsX6pTCMp64gl).
No offense, but you not calling it an idiom doesn't change the fact that it's been idiomatic since C++98. You not having seen that idiom is not the same thing.
So, the module `std.core` already provides for "all the STL stuff". You can just use that directly. What you might consider doing is replace that PCH with a module that exports the functionality that you need.
People have preferences. Now--while the feature is in TS--is the time to give feedback to the committee. Sure, if in fact `export import` makes it to the Standard, I'll write `export { import X; }` as I think it makes a silly syntax a little more sensible. But now--before the feature is standardized--is the time to express preferences, even about the silly things. 
I kind of wish Qt provided a tool to instrument an app and then, at run time, visualize (or analyze in some way) the parent graph as a program runs to catch issues like this.
I usually watch Handmade Hero at 2x speed, to see how certain things are designed/implemented, but otherwise I don't scrutinize his code.
I hope not. Rust's macros appear to be a shameless copy of Racket's macros. D metaprogramming appears to be more in the line of C++, and is also extremely powerful (much more powerful than Rust macros as well). That's where C++ should be looking for inspiration, IMHO.
But it doesn't, so I have no idea what point you're trying to make...
I agree, but the problem is with class templates.
You are quite the diplomat, aren't you? :D
Just trying to be unbiased towards anything :P Having an open mind allows for greater advances.
You really liked my 4 tabs ). Sorry, I have no idea how it happened something got screwed up in my vim settings. unnamed namespaces in headers isn't a good idea. I think for simple stuff lambda is fine, nothing much to parse there. As for more complex stuff, one can add polices to all you alternatives to keep the core 'derived' semantic clean. There are obvious pros/cons. template&lt;typename T&gt; struct blahpolicy { ... fix... }; template&lt;typename T, typename P=blahpolicy&lt;T&gt;&gt; struct derived { derived... : base { P:fix } {} }; 
I count 24 [feature test macros](http://en.cppreference.com/w/User:D41D8CD98F/feature_testing_macros) added in c++17.
Why not delete the orphaned pointer instead of asserting? I can see that sometimes it is a bug, but sometimes it is normal to have orphaned pointers. A wrapper that would always "do the right thing" would be useful (and I've used one exactly like this in the past)
Yeah you can do that, but it still won't give you GCC-7
There is an early April gcc-7 snapshot for Ubuntu 17.04 in this PPA. Just wait a few days/weeks: usually there is a backport from the latest Ubuntu to the long-term-release after a new gcc version is released.
[GammaRay](https://www.kdab.com/development-resources/qt-tools/gammaray/) is a tool for examining and manipulating the internals of a Qt application at runtime
Is it not the intention here that something may be or likely to be wrong in code for an orphaned pointer on an embedded device? So, therefore it may be sufficient to just trap design or refactoring errors rather than adding functionality automatically.
And hasn't been since 2005. https://gcc.gnu.org/r106665
What is the point of this article? What is Windows specific about these instructions? I thought this would be a valuable article that would mention weird exceptions since it's building in a nonstandard environment, but it essentially tells you how to run make, with directions that are standard for anyone who has used anything *NIX-like...
&gt;reflection is better No it's not. Reflection has a huge runtime cost, whereas macros are compile time. That's why C++ has gone the way of TMP and constexpr. Also, most of the time you need to manipulate the AST it's to avoid *repeating code*, not necessarily to make things *type independent*.
All the discussions about reflection in C++ are about compile time reflection. And like I said, macros will not let you avoid repeating code unless you know your needs at the time you write the first bit of code. You can use macros to write a struct that knows how to serialize itself without repeating anything, but you can't use macros to serialize an already-declared struct without repetition. (I don't really understand what you mean by type independent at all).
You are thinking C preprocessor macros. When I say macros I mean lisp style compiler executed macros. Those are much more powerful then reflection because you can manipule the AST directly, it's like extending the language/compiler by yourself for your specific problem. Obviously, in C++ it's much harder to do it because of the syntax, but have you seen any moderate use of templates? Not the STD collections stuff, real template metaprogramming? It's **really** hard to understand what's going on. 
Rad
Or something akin to nim's templates would be better. They even work with overload rules, so you can match an ast transform against a pattern to create custom compile time optimizations.
Hey hello, could you give some beginner-friendly examples of all this ? what i find online on homoiconicity is really either theorical (and without demo) or not made for understanding at all. 
There is no decent package for libc++ on Ubuntu :-( The one in the official repositories is archaic, and the LLVM apt repositories don't contain libc++. EDIT: But it only takes a minute to build libc++ from source once you've installed Clang 4.0 http://libcxx.llvm.org/docs/BuildingLibcxx.html#getting-started
I would assume it's allowed to return a non-null pointer, you're just not allowed to dereference it.
Imgui is nice, but I think it's vastly underpowered for a CAD application. YMMV, but I'd use Qt in this situation.
It doesn't matter whether you have preferences. `export module` makes no sense, `export import` makes sense.
If `size()` returns `0`, why does it matter if `data()` is not `nullptr`? `memcpy` still works (by copying nothing), so does other function with similar semantics. **EDIT:** actually the [the doc](http://en.cppreference.com/w/cpp/string/byte/memcpy) says both src &amp; dst should not be nullptr for memcpy.
I wrote USSG for this purposes https://github.com/FictionIO/USSG, I used in http://fiction.io/projects/engageworks_works/ . Wasn't able to maintain and continue to development. 
[removed]
&gt;constexpr const std::pair&lt;int, double&gt; z { }; is tolerated but the const in that declaration is redundant, but constexpr is required if z was to be used on contexts that required constants. Good. That's how it should be. &gt;The pre-Issaquah Module TS draft grammatically allowed import M; in an export-fragment, but that wasn't the required form for exporting a module. The post-Issaquah Module TS draft made that form the only one, and therefore compulsory. `export module M` is retarded syntax that makes no sense.
[removed]
I have also seen that name. But it tells you nothing about what these "phantom types" really do. I've also seen "tag types" used - you "tag" one type with another. That's, well, less bad. I think this concept really needs a good name...
It's not an issue outside of shitty platforms like Windows.
&gt;I don't understand your whining. The syntax is honestly fine and doesn't resemble Perl at all. "$" != "Perl". Disagreeing with shitty syntax isn't whining. $ does equal Perl. 
[removed]
&gt; since for obvious reason it would be much more safe to have a well-defined null pointer instead of a "not dereferenceable type" Not obvious at all. At least I can't see any reason. If your code dereferences the pointer when `size()` is `0`, but `data()` is not `nulltptr`, you have an out of bounds bug. It is probably still there when size is non-zero.
What OS do most car's use and do they even allow third party applications?
LISP ain't Clojure. In fact, LISP ain't even Lisp!
AFAIK Linux, but a lot of people install Windows PCs in their cars. It is technically possible to install custom software on Car PC. For example the Android Auto part is forked from a project which aims to add Android Auto to the stock Mazda head unit.
I didn't know till today that function arguments aren't required to be evaluated in order - I doubt it's a rare misconception.
 This part of the page is confusing: &gt; `a ? b : c` is required to evaluate a before b and c. But the relative order of b and c is unspecified. In the conditional operator, only one of `b` and `c` is evaluated. It doesn't make any sense to talk about their relative order. 
But you're moving out of a variable and using it in the same expression. Regardless of order of evaluation, that seems obviously bad.
&gt;A std::move is just a move_cast and the data may, or may not, be moved. The function parameter is `std::unique_ptr&lt;Data&gt;`, so evaluating the function parameter (which happens before the function is entered) does in fact move out of `data`. Something this blog didn't mention was that passing `unique_ptr` by value is somewhat fishy; I believe the normal recommendation is to pass them by reference (either lvalue or rvalue). In this case your point would be relevant; the function call would be valid, although the onus remains on the function implementation to be aware of the case where its different parameters alias each other.
&gt; &gt; "And move(data) empties out the smart pointer" &gt; is not precise. A std::move is just a move_cast and the data may, or may not, be moved. EDIT: This is true.
For anyone who cares, I updated the program options example presented in this post to not use any macros. Instead of providing metadata, the command line flags are generated directly from the names of struct identifiers. I think this is a stronger demonstration of how reflection could be useful. For example, originally the program options struct looked like this: struct ProgramOptions { REFLOPT_OPTION(std::string, filename, "--filename"); REFLOPT_OPTION(int, iterations, "--iterations", "-i", "Number of times to run the algorithm.") REFLOPT_OPTION(bool, help, "--help", "-h", "Print help and exit.") }; and now it can look like this: struct ProgramOptions { std::string filename; // --filename, -f int iterations = 100; // --iterations, -i bool help = false; // --help, -h }; The updated code is on the example repository linked to in the article, but I haven't changed the blog post yet. I'd be interested in hearing your feedback on this change. I think this is a good interface by default but if this were an actual library I'd like to provide a way to override this behavior to customize the command line flags.
At least it fixes some subtle bugs due to the fact that they were unsequenced. Now you're at least guaranteed that nothing happens while an argument is being evaluated.
It's not required to be a null pointer. For example it might point to space that has been allocated but does not correspond to a vector element (especially if the vector had previous had elements in it and then been resized to zero).
&gt; `export module M` is a retarded syntax that makes no sense. I understand that is how you feel. It does not give me much technical content to work with. 
I can't honestly think your use case justifies learning a whole other language for, if that's the only reason. How often are you going to want to run a MultuiUserDungeon on an embedded device?
[removed]
As a Java developer learning C++, I'm really enjoying the book Accelerated C++. My biggest difficulty was figuring how and when to use pointers, copy constructors, reference counting, and what the heck lvalues and rvalues are. This book helped me understand all of it. I'm on the last chapter and I'm going to continue on to Scott Meyers effective C++ and modern effective C++. I've never seen template meta programming before, but today when I was looking at it was already clear on how it works (in simple cases, I'm sure there's advanced examples that will confuse me haha), because Accelerated C++ has given me a good base. 
Sorry could you elaborate on this? Do you mean that: foo(f(g()), p(q())) It is guaranteed that f evaluate immediately after g, and p evaluate immediately after q? If that's not what you mean then I don't think I follow.
Not sure what you mean by default for everything, there are many many situations where ordering is guaranteed. Almost all if not all of the ordering of everything to do with object contents is guaranteed, initializer lists are guaranteed.
Post a comment on his page, so he can fix or remove it.
vector is NOT doing this, but here's another way to have a valid but not dereferenceable pointer char * ptr = malloc(0); 
Link time can be reduced when symbols carry knowledge of their owning modules -- and my hope is that implementers don't just settle on mangling the module name into the symbol (a good trick to get the system up and running, but not necessarily a long-term implementation strategy). The same is true for the dynamic linker. See the 2-level namespace implementation on macOS platforms. Unfortunately, the current spec only provides a weaker form of module ownership semantics. Link time code generation is already permitted under the existing C++ model -- and indeed practiced in production environments.
See this answer: http://stackoverflow.com/a/19472607/1364752 Sure it would be fixed using `std::make_unique` twice, but it shows the case. With your example, the compiler was indeed allowed to call `q()`, then `g()`, then `f()`, then `p()`. If I'm not mistaken, the problem illustrated in the linked answer shouldn't appear in C++17, because function arguments evaluation is indeterminately sequenced instead of unsequenced as it used to be.
The other guy's point is that `std::move()` doesn't actually do any moving - it just casts the argument to an rvalue reference, which allows the move constructor or move assignment operator to be used. Without the cast only the copy constructor / copy assignment operator can be used. 
Looks interesting, but seems unfortunately to have a few dependencies like java, apache ant, python...
So... GNU/NT still has a long way to go.
&gt; Not sure what you mean by default "default: a preset value that a computer system assumes or an action that it takes unless otherwise instructed." "Order of evaluation of the operands of almost all C++ operators (including the order of evaluation of function arguments in a function-call expression and the order of evaluation of the subexpressions within any expression) is unspecified. The compiler can evaluate operands in any order, and may choose another order when the same expression is evaluated again."
&gt; If Microsoft ever does applications for Linux it means I've won. But hey, at least Linus Torvalds is happy, right?
Are you sure that you need a vector? (Do you need to change the size of the buffer?)
Holy hell is that true? 
Yes I realized this part brings more confusion that anything else, I reformulated. Thanks for pointing in out.
Look at the getting started page and the Prerequisites section: https://buckbuild.com/setup/getting_started.html
Nice $bait
The same fuckups can be done with C, some function calls and raw pointers. Gotta know your C regardless. Quite awful code though...
I would err on the side of caution and not presume nullptr for empty. E.g. imagine a vector that had elements, and then was emptied. It's not a bad idea not to free storage for futher inserting into a vector (performance). It's not a bad idea to just return the pointer from data, no checks at all (performance again). So... Don't do `T* p = vec.data(); if (p) use(p, v.size());` :-)
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6a6gr8/hey_im_looking_for_a_bit_of_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
While I always wonder what is wrong with writing a C++ build toolchain actually in C++, Java seems like a really poor choice. While the startup cost doesn't matter if you are rebuilding the entire project, during development, when you need to recompile a single file I wonder if the Java overhead will actually be greater than the compilation.
The visualization has an option to filter nodes by their degree. Setting the threshold higher leaves only the most "important" nodes (included most often). So that mitigates the issue, I'd say. But your suggestions sound interesting as well.
Buck solves the startup time problem with Nailgun, which keeps a JVM warm for the build. Incremental builds is actually where Buck excels. Because Buck requires a strict dependency graph, most things can be cached. There is some discussion here: http://zserge.com/blog/buck-build-system.html 
Must concur. A large part of curating good presenters is to actually look at past presentations they've done. Some big conferences even require links to videos or slides from previous talks as part of submitting a new talk so that they can judge the quality of the presenter. This might not be used purely for inclusion of the talk, but helps with scheduling and balance. e.g., the conference might want to fill up 70% of its slots with established good speakers, leave 10% open purely to new speakers, and also guarantee that they never invite back certain other speakers.
You shouldn't be writing your code for ease of debugging! Heck, worst case you can edit it to be easier, but the tool will let you step into it... I mean, look at the alternatives f(a(), b(), c(), d()); or { auto aa = a(); auto bb = b(); auto cc = c(); auto dd = d(); f(std::move(aa), std::move(bb), std::move(cc), std::move(dd)); } (You need the extra level of indentation to make sure that `aa`, etc, are fully out of scope and destroyed.)
if `ostream::operator&lt;&lt;` accepted any Callable and automatically treated it as a manipulator, how would you print out those Callables that also happen to be Streamable? There are examples of such even in the standard library: every random number generator from &lt;random&gt;. although i suppose restricting it to those that are invocable with ostream argument could work.. although doubtful that proposal would get far.
Perhaps, just std::function&lt;&gt; explicitly?
F# programmers won't be confused though.
Why std::function? "streams are already rumored to have overhead, let's throw more overhead on top of that"? If you're writing a proposal, allow lambdas as manipulators std::cout &lt;&lt; [](ios_base&amp; os) { if (os.pword(myidx) == &amp;os) os.iword(myidx) = 7; // or whatever sensible manipulators do return os; } &lt;&lt; myObj &lt;&lt; '\n'; 
&gt; Why std::function? Because I want to bind to manipulators. Sure, lambdas are fine too but for different reasons. 
Ugly only depends on your standards. And of course worse code is always possible.
There is some arguments/opposition to an anonymous review system for C++Now or CppCon. The submission review happens through a platform called http://easychair.org/ Meeting C++ had for a few years now an anonymous system, since last year past speakers can see speaker name and bio too. It works too, in both ways you need a group of people to do the final selection. Or you end up with 10 similar talks on TMP/Functional Programming/popular thing x. ;) But, as far as I see it, both systems have yielded similar results. But I have seen (IMHO) qualified speakers being rejected for CppCon, with really silly and stupid reviews. Focus should be more on helping to improve the talk rather then rejecting because thing x wasn't mentioned. Both for people not researching a person well enough, and its a topic under speakers which the most ridiculous review is. 
Or go to definition and put a breakpoint. 
Yep, makes sense now. A few advantages of operator int() kind of stuff are: * easy go back to the underlying type (if for whatever reason you ever have to) * no need to add a bunch of operators to be able to use standard algorithms (think of std::max) and other templates dependent on standard type concepts.
Thx! I've heard _ is not recommended (even though I love using it). Would you elaborate why? __ is reserved by the library IIRC, I'm not sure about single underscore rules/best practices though. Anyhow, good catch :)
Thank you for the ping. We will try to squeeze the fix in 15.3. Workaround is to wrap the surrounding fragment with pragma optimize off. #pragma optimize (“”, off) before send_command_with_reply and #pragma optimize (“”, on) after the “};” around line 894. 
In the global namespace it is: [reserved identifiers in declarations](http://en.cppreference.com/w/cpp/language/identifiers#In_declarations)
[@gameloft's latest tweet](http://i.imgur.com/vMYHvuh.jpg) [@gameloft on Twitter](https://twitter.com/gameloft) - ^i ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Thanks so much for this article - I haven't done much of this stuff and always found it a bit confusing (+ I've struggled to find legit uses for it in the context of games). I'd definitely be interested in seeing how this looks with C++17 features. 
I added my take on it in another reply if you're interested in taking a look.
Didn't realize how much c++17 would simplify type traits code. std::is_detected_v... [drools]
Unfortunately std::regex implementations in ALL standard libraries are quite bad (as of December of 2016). If you want to use a regex in something more or less performance/security sensitive then use boost::regex, or even better - PCRE. 
&gt; gorgeous ... template &lt;typename T&gt; \ class has_##func##_method { \ typedef char one; typedef long two; \ template &lt;typename C&gt; static one test(decltype(&amp;C::func)); \ template &lt;typename C&gt; static two test(...); \ public: \ static constexpr bool value = sizeof(test&lt;T&gt;(0)) == sizeof(char); \ }; \ \ template&lt;typename T&gt; \ constexpr bool has_##func##_method_v = has_##func##_method&lt;T&gt;::value; \ \ ... template&lt;size_t N = 0, typename... Ts, typename... Args&gt; \ inline typename std::enable_if_t&lt;N == sizeof...(Ts), void&gt; \ func##_managers(std::tuple&lt;Ts...&gt;&amp; t, Args... args) {} \ template&lt;size_t N = 0, typename... Ts, typename... Args&gt; \ inline typename std::enable_if_t&lt;N &lt; sizeof...(Ts), void&gt; \ func##_managers(std::tuple&lt;Ts...&gt;&amp; t, Args... args) { \ _do_##func##_if_has_method(std::get&lt;N&gt;(t), args...); \ func##_managers&lt;N + 1, Ts...&gt;(t, args...); \ I kid, I kid
This might be a daft question. But how are macros powerful tools for AST generation? What can they do in that regard that normal code cannot?
C++ inherits the relevant rules from C99, which has in "Sizes of integer types &lt;limits.h&gt;" (§5.2.4.2.1) values for `CHAR_MAX` and `LONG_MIN` that make it ~~impossible~~ _technically_ possible (but highly unlikely).
I don't want to put you off! Learning c++ and running on the Pi is a great aspiration!
SO "documentation" is more like a cookbook, of highly questionable quality due to low participation among the regulars, rampant plagiarism and an utterly inadequate review process. Stay away.
So this is like 'public import' in D, just made ugly to fit into C++? Also why not use private/public keywords to "export" symbols?
Under what circumstances would `f(std::move(smartPtr));` _not_ result in `smartPtr` being cleared?