The choice that was made a long time ago was to only give containers that can have a more efficient find than the one in &lt;algorithm&gt; their 'own' find. 
or [std::binary_search](https://en.cppreference.com/w/cpp/algorithm/binary_search).
The library has std::search, which you can (should?) also use with std::string. Having a find in std::string is a design error.
Or not necessarily specific knowledge on containers, but some optimization technique that could make search faster if it's specific (as opposed to generic), or do search somehow differently. I might be wrong on both regards, but i think this question was covered in Meyers' "Effective STL" which i would definitely recommend regardless.
What is wrong with Qt? how does it not cover your needs?
Not sure if you imply that I might blow up the amount of generated code or just sharing a fun story what may happen with templates.. here's what happens with the technique I advertised as "light-weight", just in case: The object files for math/ are 92K .. compiling and linking this example: #include &lt;mango/mango.hpp&gt; using namespace mango; int main() { float32x4 a(1.0f, 2.0f, 2.0f, 1.0f); float32x4 b(0.0f, 1.0f, 0.5f, 1.0f); float32x4 c = a.xxyy + b.zwxx * 2.0f; printf("%f %f %f %f \n", float(c.x), float(c.y), float(c.z), float(c.w)); } ~/work/code/simdtest $ ls -lah drwxr-xr-x 4 t0rakka staff 128B Mar 22 11:39 . drwxr-xr-x 12 t0rakka staff 384B Mar 22 11:37 .. -rwxr-xr-x 1 t0rakka staff 8.2K Mar 22 11:39 a.out -rw-r--r-- 1 t0rakka staff 270B Mar 22 11:39 test.cpp Compresses to 2.2 KB with UPX, but I wouldn't write 4 KB intros with this code (too much bloat for that). The code size is at least within tolerances for my uses. ;) 
Span and unique/shared_ptr provide functionality beyond that of a raw pointer and in particular, they solve common problems. Shared_ptr migh solve a less common problem, but at least it is non-trivial to implement, so it makes absolute sense to put them into the standard. Observer_ptr however brings nothing to the table functionality wise, I don't think it solves any common problem and if you want it, it can be implemented in a few lines of code. So I think there is a much smaller incentive to put it into the standard. &gt; For most of the community those small costs are well worth paying in exchange for increased correctness. Is there any empirical evidence that the introduction of observer_ptr into a codebase has yielded significant benefits (i.e. found bugs, higher programmer productivity, easier to understand code) that justified the refactoring effort? I'd really first like to see that observer_ptr proves it's usefulness in practice, before it gets into the standard. And while you are mentioning backwards compatibility: std::observer_ptr is not backwards compatible, as it requires explicit casts from and to raw pointers. So you can't just replace a raw pointer in your interface without also upgrading the callers. Which either means you are in control of both sides, in which case it offers little additional benefit compared to just enforcing that raw pointers are never owners or you have to introduce a dual interface - at least for a transition period. &gt; Use observer_ptr if compiled in 20 and something else otherwise, is no argument. Types are constantly being added in new standards. Usually the way this is handled (pretty obviously) is simply to get an implementation that works with the older version, and have a conditional type alias (this is what I do for variant, optional, any, ...). What you're suggesting by comparison makes little sense. Yes, new types get added, but you want to replace existing "types" ,(raw pointers) with something that has an incompatible interface and imho observer_ptr just doesn't provide enough benefit to do that. I actually know very few c++ libraries that conditionlly use polyfills in their interfaces (Abseil being a recent - annoying - example). Usually it is more of an implementation detail. But in any case. The fact that the ifdef is at a central location doesn't change the fact that that it introduces ABI and potentially API incompatibilities. Again, if I could see a significant benefit from it, I wouldn't complain, but I don't see it. I believe that it is much more important and useful to have a tool like clang tidy in place that can run on an unaltered code base (maybe with a few `gsl::owning` annotations in it) and can check that raw pointers are non-owning than trying to enforce that through the type system and paying the (small ) price for that every single time the code gets compiled. I would probably be fine with standardized `std::owning` and `std::non_owning` type aliases to annotate interfaces during a transition phase, but a full-fledged class just for annotation purposes is imho overkill. Sorry for the long post. I hope I've made my view clear but in the end it is if no consequence, because I have no influence on what the committee will do or will not, so I'll stop here and just see what the future brings. 
Because it is not necessary, there is an algorithm (`std::find`) for that. In fact, `string`'s interface is considered bloated by many and there were proposals to remove a bunch of functions from string in favor of free functions.
Thing is, libuv has pretty poor performance. Probably similar to ASIO in out-of-the-box configuration, but ASIO can be tweaked to make it go much quicker, whereas libuv cannot. I'll accept that the libuv API is much easier for most programmers. Though, personally speaking, at that point just choose the raw socket API, as it's really not that bad, and if you don't care about performance then Windows provides a pretty decent semi-POSIX API that mostly works.
Fair, didn't think about that!
Oh, yeah, if you don't want that I guess that makes a lot of sense. I'd personally want it to be exactly what i put it, so I want the full qualified name or whatever its called
I think even the committee acknowledges that was a mistake now.
Sockets don't implement (efficiently) timeouts at the BSD sockets API layer. Therefore it's very reasonable to not offer timeouts at the high level layer, as it would encourage hidden inefficiency by people using timeouts willy-nilly, and causing a hidden conversion of apparently blocking i/o into non-blocking i/o and an async reactor. By making them explicitly program timeouts, it forces them to realise what inefficiency they are actually paying. It's a reasonable opinion to hold, in my opinion. I get it, and I think so do most of the committee. The alternative is to do as LLFIO does, which is that all APIs offer timeouts, but if your handle implementation is a blocking one, timeout i/o will fail with an unsupported failure. In other words, timeouts are only implemented on async or non-blocking handle implementations. This is probably too surprising for end users for a mid-level API like ASIO, but is probably acceptable for low level APIs like LLFIO. We'll see what the committee thinks come Cologne.
Nice, a kind of statically checked version of https://github.com/zajo/leaf. FYI I did consider this design for Outcome, but I ruled it out due to compile time impact in large codebases. Still, for .cpp only usage, it could be a nice handling pattern.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [The suggested solutions to this 'problem' are painful. I'm so glad Rust has traits.](https://www.reddit.com/r/rustjerk/comments/b43jqz/the_suggested_solutions_to_this_problem_are/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I think this tutorial is a bit too short in that it would be much simpler to achieve the same functionality shown here by just calling the compiler directly. It also doesn't provide enough information to be able to read common real- world make files. &gt; You can make use of it and ease your compiling process by using makefile variables for complex projects. Why on earth would I use make for complex projects unless I'm already a make guru?
IIRC, string was developed separately from the standard algorithms and containers. Most (not all) differences in the interface are historical. That being said: I generally consider std::string to represent a single value not a container holding multiple char values(just consider how often you check two strings for equality compared to checking two vectors for equality).
&gt;what's not to like UWP
Brings memories of Perl coding times...
(Tangentially related) This is the first time I've come across `std::any` and I'm surprised its interface is so bad. I would have expected a non-throwing test for the value that also optionally returns the value, so that you could test and get the value at once in an if statement, like this: std::any example = 33; if (int* i = example.as_ptr&lt;int&gt;()) { useInt(*i); } else if (std::string* s = example.as_ptr&lt;std::string&gt;()) { useString(*s); } 
Yes, but that only returns a `bool`, saying whether the element was found or not. It doesn't tell you where the element actually was. It could be implemented: template &lt;typename FwdIt, typename T, typename Comp&gt; bool std::binary_search(FwdIt first, FwdIt last, const T&amp; value, Comp comp) { return std::lower_bound(first,last,value,comp) != last; }
Ah, yes, you're correct. Good catch! cppreference's possible implementation is similar to yours, but handles the case of `value` being out of bounds.
Thanks, you are right.
Very nice work; the usage examples are concise and declarative. Looks like a lot of fun to play with!
I'd really prefer if articles like this wouldn't talk about error handling when they are actually about error reporting. &amp;#x200B; I've seen far too much discussion about the low level details of different error reporting strategies and far too little about the question how to actually handle an error. This is important because depending on how you want to handle an error, different reporting strategies might be preferable.
Rather than add find to vector, it should arguably be removed from string. Here’s Herb Sutter on the topic: [Monoliths "Unstrung"](http://www.gotw.ca/gotw/084.htm)
My condolences
std::string is much more specialized, it's not even templated, it also had to implement the usable concept of a string, if it didn't have things like find it would have to be wrappered for many common uses. std::vector on the other hand is much closer to being a pure container it is highly uniform with the other generic containers. if you write your own complete library (as i (very-slowly) have) you could certainly create a find for your list implementation (assuming your list's templated to a type which defines equality ofcoarse, you could also emit a compile time error (using sfinae) in case someone does try to find() thru a list of incomparable types ). Cool Question.
Finding a substring is a very common and well defined procedure. Finding an element or sequence of elements in a vector is much less defined. Is the vector sorted? Can the elements even be compared at all? It turns out that performing an operation on each element in sequence is the common thread of vector operations and search is just one of a large number of applications of that. The std:find_if() and related algorithms are probably the closest thing to what you will find in the stl.
Not to bash the hard work of that team, but cppwinrt and XAML seriously suck together. The VS extension tries to help you but it forces you in its architectural file layout and one slight deviation from that and everything blows up. It’s very unforgiving and I would only use it as a quick and dirty way to build UI if you must. For non UI the platform is great and they really thought through a lot of the nuances of COM and c++17 interopt. c++/cx for the xaml bits and cppwinrt for everything else.
&gt; it's not even templated https://en.cppreference.com/w/cpp/string/basic_string std::string is a specialization of std::basic_string.
Very nice, 
&gt;it's not even templated Uh, yes it is. You can specify the char type and allocator for starters.
&gt; dependency inversion Obviously, Swing has been implemented in terms of the Windows API, and it uses factories based on abstract interfaces, so there's a concrete proof that dependency on the details, even some of the main control structure such as use of a message loop, can be abstracted away. At least that's what I associate the term *dependency inversion* with. However, doing that can be a lot of work, IMO only defensible if the code is going to be reused as a new framework. --- &gt; template patterns Not sure if the meaning I'm familiar with is the one you intend. I think of the *template pattern* as a procedure for doing something implemented as calls of virtual methods, where those can be overridden to customize the behavior. The only time I've used that technique in C++ was to express an idea for new Eiffel-like exception handling (essentially, it would repeatably retry a piece of code and eventually bail out, which was the customizable procedure), so I believe, even though the GoF patterns were described as language independent, that it's less practically useful in C++, that in C++ one typically uses other techniques. I see no obvious connection to using the Windows API, but there may well be opportunities to use that pattern. :) 
Yep, you were on point on both patterns. As I feared, DI with "platform-specific" framework would be a hassle. Thank you kind sir!
I believe std::stiring predates the collections and algorithm. You'll see std::find is slightly faster...if i could find the link...
you need to propose that for c++26 or convince Herb Sutter that this is the next needed feature after c++ gets meta classes - so he can do it for you :) &amp;#x200B; thanks for creating this fork - even the existence of such projects help to convince other that runtime-compiliation is doable and worthy
Quotes don't work that way in macros. To Stringify the name of parameter x, you do this: #define name of(x) #x The whole point of OPs library is to parse out extra info like namespace qualifiers at compile time. Also, your simple case can't do things like give you the string name of an enum value in a variable.
How does the pointer version of any_cast fail to achieve that?
I couldn't resist taking the challenge and eventually came up with this: #include &lt;iostream&gt; template &lt;unsigned long long Base = 10&gt; unsigned long long per(unsigned long long num) { unsigned long long new_num = 1ull; for (; num != 0; num /= Base) { const auto digit = num % Base; new_num *= digit; } return new_num; } int main() { unsigned long long num = 0; std::cin &gt;&gt; num; int number_of_iterations = 0; while (num &gt;= 10) { num = per(num); number_of_iterations += 1; std::cout &lt;&lt; "Iteration " &lt;&lt; number_of_iterations &lt;&lt; ": " &lt;&lt; num &lt;&lt; '\n'; } } Run it live: http://coliru.stacked-crooked.com/a/9d38aa275eba58a9 Assembly listing: https://godbolt.org/z/j_5ORA
You're right, sorry. I didn't look at the documentation properly (I promise I did look at it a bit!) and didn't see the pointer version. For the benefit of any other readers, here's the fixed version of my snippet: std::any example = 33; if (int* i = std::any_cast&lt;int&gt;(&amp;example)) { useInt(*i); } else if (std::string* s = std::any_cast&lt;std::string&gt;(&amp;example)) { useString(*s); } 
Regarding raw pointers, I can only speak for myself, but the worst kind of bugs often come from accessing disposed pointers. The last person at my workplace who said unique\_ptr was more trouble than it was worth (all the while being unable to cite specific problem cases..), within that same week had managed to call delete twice on the same pointer. Pretty infuriating stuff, and 100% would have been avoided with simple use of unique\_ptr.
The benefit of using `std::filesystem` is not that it is a bit neater; it's that there is no existing standard library function at all for getting that information. For example, `stat` only works on Posix systems (e.g. not Windows).
I can recommend [Boost.QVM](http://boostorg.github.io/qvm/).
Absolutely nothing. `(type)var` is a "C-style cast", `type(var)` is C++ constructor syntax. For primitive types there is no difference in their effect.
&gt; what’s not to like? [Deployment](https://docs.microsoft.com/en-us/windows/uwp/packaging/packaging-uwp-apps#sideload-your-app-package). No such thing as a portable UWP application.
First one invokes cast, second one creates temporary object through the constructor. In this context, they will do the same. &amp;#x200B; But, you really should be using static\_cast to do the casts. It's more obvious what you meant when you use it and you will get better errors when you make mistake. It's much safer. &amp;#x200B;
Sure, they are a tool just like any other and can be misused easier than most. Smart pointers are usually indeed better for most use cases, but there's a sentiment in parts of the C++ community that raw pointers should be avoided altogether, at almost any cost. I totally disagree with that - there are plenty of good use cases for raw pointers. 
Not just primitive types
/r/cpp_questions/
I mean, `vector&lt;bool&gt;` specialization is a mistake, everyone acknowledges it. But it's frustrating that people always point to it, when it's an aberration. Python bit the bullet and fixed their mistakes in the (decades long) 2-to-3 conversion. No one harps on them for `print` as a keyword. 
Very flexible and easy with [Qt Style Sheets](https://docs.microsoft.com/en-us/windows/uwp/packaging/packaging-uwp-apps#sideload-your-app-package). With Qt Widgets you can also use custom painting and “proxy styles” for more advanced customization and to avoid the small performance hit from loading stylesheets. QML is another approach, but I’m old-fashioned and still use Widgets. Take a look at Autodesk ReCap and Infraworks for some examples of extensive custom styling.
There are multiple small syntax errors in the code, but fluentcpp.com says that they review posts. Hmm.
Neat, but in practice I think it doesn't necessarily make sense to expose every possible error type in a variant like this, not just for the reasons cited (although they are all good, and the self-criticism is super) but because I think most error handling code explicitly does not *aim* to be exhaustive like an `std::visit`. In descending order of my subjective guess of the frequency (YMMV) of what error handlers actually do: 1. Optionally do some logging, cleanup or rollback action (although the latter absolutely ought to be RAII if possible) then return the error to the caller 2. Do (2) and wrap the error in another error (perhaps giving local context) and then return it to the caller 3. Look for a small number of specific error types and take some action (e.g. `if error.isTimeout() &amp;&amp; retryCount++ &lt; something`), otherwise return the error to the caller 4. Exhaustively handle every possible error type like a visitor This really leads me to believe that the most useful composable error is something like an ABC with an additional shared_ptr to it's own type for chaining. Specifically, this privileges case (2) over (4) -- and I'll fully admit that it makes (4) much harder without the compiler giving you a type-safe variant visitor exhaustion pattern. Specifically, I really think that it's valuable to have almost call-stack like error chains because it allows for the right context to be added at each layer. For instance, ... --&gt; ErrorParsingPackage(package) --&gt; ErrorParsingFile(filename) --&gt; ErrorUnexpectedEOF(details) So you can write something like (without a ton of the boilerplate included) ``` class ErrorBase { virtual [[nodiscard]] std::string describe(void) const = 0; virtual ~ErrorBase(); // Please committee, make this automatic whenever there is a pure virtual function kthx std::shared_ptr&lt;ErrorBase&gt; wrappedError; .... lots more boilerplate because C++ ... }; using Error = std::shared_ptr&lt;Error&gt;; class ErrorType1 : public ErrorBase ... class ErrorType2 : public ErrorBase ... std::expected&lt;Foo,Error&gt; GetFoo() { return UnexecptedWrapper&lt;ErrorType1&gt;(...); // &lt;-- forwards to make_shared which forwards constructor of ErrorType1 } std::Expected&lt;Bar,Error&gt; GetBar() { auto maybeFoo = GetFoo(); if ( ! maybeFoo ) { return maybeFoo.error().Wrap&lt;ErrorType2&gt;(...); // forwards to make shared to constructor of ErrorType2, also takes the ErrorType1 and embeds it as the next in the chain so it can later be iterated through } return Bar(maybeFoo-&gt;...); } ``` 
And this is getting downvoted why?
Yeah, I tried above to create a hierarchy of which error handling *actions* are most likely. I have my own opinionated opinion on what kind of reporting is most ergonomic based on that too :-)
If you do something like `std::max(vec.x, vec.y)`, then you have big problems because you do not have `operator&lt;` for `Accessor`. 
Oh I totally agree, it was created way at the beginning of the STL and templating in C++, it probably seemed like a good idea at the time. Now our learned experience shows us that it was not, and that having a special container like `std::bitset` is preferable in most cases. I do wish sites like [cppreference.com](https://cppreference.com) were more proactive in pointing out things that are no longer best practices. There's just a [couple of notes](https://en.cppreference.com/w/cpp/container/vector_bool) at the bottom of the page that don't really make much of an argument. 
A great way to write unmaintainable code for little benefit.
The allergy is developed over years of misuse because a raw pointer does not describe the ownership semantics of the pointed object, let alone enforce them. As with anything in C++, there are good and bad uses of a language feature. Almost no one would complain about using a raw pointer inside function scope, or as a private member of class where you can guarantee invariants (e.g. in a circular buffer class, to hold the last pointer from the end to the start). But many of the uses are just plain bad. std::non_owning&lt;T&gt; is a nearly-free abstraction that just says "Hey, you don't own this, don't delete it, be careful about its lifetime and most importantly, *tell anyone you give this pointer about the previous two points*. 
I think the whole point of `non_owning&lt;T&gt;` is that you don't have to be a smart pointer purist in order to get the useful function signatures :-)
Well, before there was a `non_owning&lt;T&gt;` wrapper, those people had a good point. Now that we have it, what are the use cases for `T*` over `non_owning&lt;T&gt;`?
Awesome, just learned something! Thank you!
&gt; The languages is broken beyond repair The language is bound to be a compatible superset of C11, which is targeted differently. This means there are constructs we must support but are not optimal. If we can provide a low (or zero) cost abstraction over it in the STL, why not? 
Just FYI, I've written modern C++ targeting an embedded platform where 0 is a valid address. YMMV.
I just don't know what to think. It's so brilliant and confusing at the same time. Should I use it?
Fair point, but it also seems kinda redundant to me. 🤷‍♂️
You should have added a question "Do you already use this feature", because someone who didn't code with it may not know the caveat.
Right. And `std::string` has it for two reasons: - `std::char_traits&lt;char&gt;` can use `memchr` which is usually written in highly optimised assembly, and - `std::string` has the most bloated interface in the entire standard library.
Thats not the point. The problem is that you can assign or compare an integral value to a pointer without any explicit cast. This special dispensation for the litteral 0 (And I believe generally compile time constants of value 0) is completely useless (and actually has always been since the standardization of the NULL macro). 
I have program that uses a lot of standard library, Boost, nhlohmann JSON and few other libraries and the sole thinking of Qt in this project scares me ... it would break an entirely consistent RAII stuff, entirely consistent purely snake_case code and likely significantly complicate the build system.
std::string was not part of the original STL, neither was IOStreams. 
&gt; `std::string` has the most bloated interface in the entire standard library. Still no replace("foo", "bar"), efficient formatting and many more 
For non-debug purpose, there is 0 reason to do it, since you should always initialize your variable with **meaningful** value. No default value can be meaningful.
No, better use `boost::small_vector` instead which is dedicated for SBO and does not null-terminate arbitrary `T`
/r/cpp_questions
I said it was bloated, not useful.
Yes. That doesn't mean creating these builds magically happens, somebody still has to set things up.
You keep saying this, but it's nonsense. `std::array` doesn't have `find`, `std::deque` doesn't have `find`, `std::forward_list` and `std::list` don't have `find`. Apart from `std::string`, which is different from the other containers in **many** ways, only the maps and sets have a `find` member. And that's because those containers can find an element more efficiently than a simple loop. The ordered associative containers can walk the binary tree to find an element, and the unordered maps and sets use the element's hash value to locate it in the right bucket. Apart from `std::string`, which is different from the other containers in **many** ways, none of the containers that would implement `find` with a simple loop have a `find` member. Because you can implement it with a simple loop, or using `std::find`.
Can't you use std::find or std::find\_if on a vector? STL algorithms are pretty nice in certain situations.
Thank you I think enough people have filled in. 
Since that would immediately imply that T has an equality comparison operator overload. Why limit the class of acceptable types for no benefit apart from consistency?
So should &lt;algorithm&gt; functions be preferred over member functions for vector and string when traversing and searching?
The first part of this is \`rbegin\` and \`rend\`: \`rbegin()\` and \`rend()\` give "reverse iterators" - that is little objects which implement \`operator \*\` (get value), and \`operator ++\` (move to next value). Being "reverse" iterators, \`rbegin\` actually gives you an iterator to the \_last\_ character of the string, and it's \`++\` actually goes \_backwards\_ through the string. The second part is the string constructor that you're passing \`rbegin()\` and \`rend()\` into (\`string(name.rbegin(), name.rend())\`): This constructor takes the "begin" iterator, reads its characters one by one until it gets to the "end" iterator, and builds a new string from the characters it gets. By giving it a \_reverse\_ iterator pair, the first character it reads, and which it puts at the start of the new string, is the \_last\_ one from the original string. Followed by the 2nd last, then the 3rd last, until it gets to the "end" - which for a reverse iterator, as it's going backwards, is the start of the original string, which it puts at the end of the new string. Voila! The string, but backwards!
Agree with you that it is short. I found it good for introduction.
Introduction to make: Step 1: Don't use make. Kidding aside, make is a pain to use compared to some of the newer build systems out there. I've often joked that only one makefile has ever been written and everyone else just copied and modified it to suit their purposes. I suppose makefiles aren't a bad format when being output by a tool like CMake or whatever, but the idea of writing them by hand for anything but the simplest projects (and as I said, I just copy and modify existing ones if I'm going to do that) frankly turns my stomach.
By "some" you mean "`void` only"?
Yeah. I believe the same as in my projects i reused same old makefiles and just do make on my projects. I rarely looked at makefile but while looking at it i realize that i don't exactly remember the basic syntax of makefile. So read the intro and shared here too.
Try `long double`
This looks like an amazing library. I've been sort of meaning to do this for a while but "never got round to it". Now I don't have to! This way more complete than I'd ever have done. 
the second gets rid of a bunch of c-cast warning with many c++ ides though..
Thanks. And that's right, I totally forgot the `\0` at the end.
Yeah you can’t deploy it on *NIX but OP was interested in Windows only. 
First, you realize that this is primarily meant as a mitigation feature right? So unless, you are one of the few gifted people that always write bugfree code, it this can absolutely be meaningful. Second, it is not that rare to give an initial value of zero to a variable (e.g. think about the counter in a for loop). &amp;#x200B;
Got a new listener in me 
While on the subject of using VSCode for C++ I was wondering if anyone here uses VSCode on a Mac and if so would you mind sharing your tasks and launch json files that you use as a base? I keep meaning to look into setting it up but never get around to it as I am lazy :P Bonus would be options for both Apple Clang and Clang via Homebrew but that is asking a lot I know ;) If you can share your setup I would be very grateful! Cheers!
Thats a good idea, have added the question.
reminds me of Manu's [ctti library](https://github.com/Manu343726/ctti)
If you think `std::string`'s interface is bloated, what would you remove from it? I would personally love to see more methods..
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b472r5/a_simple_question/ej4w6lj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Why does &lt;T&gt; in vector need an == operator? Maybe it can be implemented in such a way that find gets sfinae'd away, but that may just create more problems somewhere else.
&gt;But, you really should be using static_cast to do the casts. It's more obvious what you meant when you use it and you will get better errors when you make mistake. It's much safer. Is there any difference "under the hood" between a C-style cast and the C++ casts (i.e. static_cast, dynamic_cast, const_cast, ...)? Or do they all compile to the same assembly/machine code?
You have to be careful if you want to do this. To quote [my comment from a while ago](https://www.reddit.com/r/cpp/comments/9zg5tc/_/eagenm5): &gt; `std::basic_string&lt;T&gt;` seems to only be well defined if `T` is a trivial standard layout type ( http://eel.is/c++draft/strings#general-1 ). Unfortunately, this makes `std::basic_string` rather hard to use as a container. For instance, the example of `std::basic_string&lt;some_struct&gt;` where `some_struct` has a `std::string` member is invalid because `some_struct` is not trivial because `std::string` is not trivial
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b45d5i/what_is_the_difference_between_double_number_and/ej4yjgn/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Do you know why it's inefficient? Are you saying having to call setsockopt is inefficient?
I would remove mostly everything (the ideal interface should be more-or-less similar to \`std::vector\`), and have free functions instead. See the points made in the other comments (n containers with m functions should require n+m implementations), and \[this\]([https://stackoverflow.com/questions/5989734/effective-c-item-23-prefer-non-member-non-friend-functions-to-member-functions](https://stackoverflow.com/questions/5989734/effective-c-item-23-prefer-non-member-non-friend-functions-to-member-functions)) SO question
Note that we have `string_view` having multiple overloads of find, replace, insert, append etc to handle every combination of `char*`, `char*` and length, single `char` etc is unnecessary. The `string_view` function is the only one you need, and construct a string view from the `char*` etc. I'm not saying it shouldn't have more functionality, I'm saying that 14 versions of `operator+=` and `append`, and 10 versions of `assign`, and 11 versions of `insert` etc is confusing, hard to learn, and bloated, while still only providing quite basic functionality.
Why are you not a moderator already?
As someone who uses Asio + Beast, what type of tweaks are you speaking about?
Having this feature is definitively great for debugging, but I was replying specifically to your comment that implies that you would like to use on release builds. Having a default value, is like specifying that signed integer should wrap like unsigned when overflowing. It will not magically solve bugs.
The article has been removed.
It seems weird to suffer from boostophobia, yet not minding all these dependencies (and a bunch of transitive ones) of Tokio: `Dependencies` `bytes ^0.4` `futures ^0.1.21` `iovec ^0.1` `log ^0.4` `mio ^0.6.12` `scoped-tls ^0.1.0` `tokio ^0.1.5` `tokio-executor ^0.1.2` `tokio-io ^0.1` `tokio-reactor ^0.1.1` `tokio-timer ^0.2.1` `env_logger ^0.4` `flate2 ^1` `futures-cpupool ^0.1` `http ^0.1` `httparse ^1.0` `libc ^0.2` `num_cpus ^1.0` `serde ^1.0` `serde_derive ^1.0` `serde_json ^1.0` `time ^0.1` 
So that delayed part should run in parallel with the rest of the program? You should use std::thread or std::async. 
/r/cpp_questions
Who says my boost preferences have anything to do with dependencies?
you asked, I delivered :) [https://github.com/dkormalev/asynqro/commit/55934c3c73e50f47c8d24a1336458018c5a9659d](https://github.com/dkormalev/asynqro/commit/55934c3c73e50f47c8d24a1336458018c5a9659d) 
Desktop apps can host UWP controls in recent Win10 builds; so one doesn't need to actually buy into the whole Platform any more.
Nice :-) I'll probably give it a try the next time I'm annoyed by QNetworkReply's signal interface.
Possible but it is going to take lots of work for little benefits. If you wanna build a lightweight GUI that is not cross-platform and not portable, C# WPF is a good choice, another one is the Free-Pascal + Lazarus IDE that allows to build GUIs like in Visual Basic 6 by picking and placing components and clicking at the component to insert the event handler code. The Lazarus IDE can also generate standalone static-linked executable without any dependency. The IDE is cross-platform, so you can build your application on Linux and MacOSX. The IDE and Free Pascal also supports lots of Delphi components and codes. Here is a full list of apps built with Lazarus IDE: [http://wiki.freepascal.org/Lazarus\_Application\_Gallery](http://wiki.freepascal.org/Lazarus_Application_Gallery) &amp;#x200B; &amp;#x200B;
In fact, if you are looking for something to replace QNAM with, you can try to adopt the same idea as we did in our in-house framework (I'm not proposing using the whole framework because it could be too much, but it is BSD3 so you can do almost everything you want with it). We work with a lot of different web services and need to support their massive APIs. To achieve it we made a wrapper on top of QNAM that uses Futures from asynqro and allows us to add support for new APIs pretty fast. Base point is RestClient class ([https://github.com/opensoft/proofbase/blob/develop/include/proofnetwork/restclient.h](https://github.com/opensoft/proofbase/blob/develop/include/proofnetwork/restclient.h)). It is designed as low-level access point that schedules network requests, times them out, works with auth and so on. It is used in so-called API-classes, all of them are inherited from BaseRestApi ([https://github.com/opensoft/proofbase/blob/develop/include/proofnetwork/baserestapi.h](https://github.com/opensoft/proofbase/blob/develop/include/proofnetwork/baserestapi.h)). This class has the same post()/get()/put()/etc. methods as RestClient, but instead of returning raw QNetworkReply it returns its contents (wrapped with CancelableFuture of course). In derived classes we unmarshal raw response from services with various marshallers in the way you can see here - [https://github.com/opensoft/proofutils/blob/develop/src/proofnetwork/ums/tokensapi.cpp](https://github.com/opensoft/proofutils/blob/develop/src/proofnetwork/ums/tokensapi.cpp) and return CancelableFuture of proper DTO class.
That's a nice way of doing it. I tried changing it in my raytracer but a nasty bug emerged. Vec3f v, u; v.x = u.x; this doesn't assign the x component but all 4 components, because the ScalarAccessor(const ScalarAccessor&amp;) is called how do you deal with it? It has to be defaulted to work nicely in a union.
Oh, that looks really useful. Not sure how much of it I will use, but I will definitely keep it in mind in the future (no pun intended).
Yes. IMO one should look at string as a container more than as a string class.
Your `String` class is missing a defaulted `operator&lt;=&gt;` for that feature by the way.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Yeah I know, but if you add it, the GCC build on godbolt refuses to compile it.
Haha, actually it doesn't compile at all now. Would be nice if godbolt had a few "stable" trunk builds.
It seems to be having issues with it already.
Yes that's what I'm saying. It worked earlier in the week.
Oh, I thought I was replying to your first comment. I didn't even see the second. I'd say godbolt couldn't really do any better, though. The actual releases are probably the ideal measure of stable. I do get your sentiment, though. My local GCC build would probably accept your example.
Makes sense, thanks!
I was referring to LeeHide's macro, because yours has this clear advantage.
&gt; CMake pollutes source tree with build artifacts by default. Only if you build-in-source, which is an asinine thing to do. $ cd myproject-1.0 $ ls CMakeLists.txt src $ mkdir build $ cd build $ cmake .. $ make -j At that point, "make" will invoke cmake to update build files, if you have changed any CMakeLists.txt. Need a clean tree? Just run "cd .. ; rm -rf build". No picking through your sources to remove cmake artifacts. &amp;#x200B;
Direct2d is a very nice api. If you use it with MFC you just literally call something stupid like EnableD2D() and it does all the ugly boiler plate stuff automatically. If you get access to modern hardware accelerated DPI aware api. I used it in one of my last projects.
That's an incorrect implementation. The way to remember `lower_bound()` is that it tells you the first place that the value *could* be inserted without violating the ordering, following the STL's insert-before conventions. That is, given 100,200,300,400 and the value 250, you'll get an iterator pointing to the element 300. Therefore, you can get a non-last iterator without the element actually being present in the sequence. An implementation of binary_search has to handle both cases: last returned, or non-last returned but the iterator points to a non-equivalent element.
That is actually a non-issue due to how templates work. (In the following explanation I will use ordinary programmer terminology, not hyper-pedantic Standard terminology, for clarity.) When instantiating a class template, the signatures *but not the bodies* of its member functions are instantiated. Those bodies are instantiated only on demand (i.e. if they are actually called). This isn't just a compiler throughput savings - it makes code more usable. The way to remember this is that `list&lt;T&gt;` has a `sort()` member function. However, `list&lt;T&gt;` doesn't require `T` to have `operator&lt;`, unless and until `.sort()` is actually called.
To expand on this, the STL is built upon algorithm on iterators of elements from containers. So it's more natural to use algorithms in namespace std than using member functions, though specific member functions have important optimization based on the type of container. Note some optimization could be possible based on container type, such as std::advance could be O(1) on std::vector but not done yet possibly to to avoid bloating the interface, and in C++20 we have a better tool for this: Concepts. As for string, it is designed to have a compatible design as a sequential container so that on can apply std algorithm to it as well, for example, converting string to uppercase may be done in a std::for_each. However its generic interface has caused more damage than good and is not considered a good design.
I must be responsible and add the caveat warnings into the post, thanks for the warning. :) 
What optimization level was that? I like the swizzle syntax, and I especially like that you found a language-lawyer compliant way to do it, but I also like fast compile times and debug perf.
The SA converts to S nicely, but the problem is indeed when you have something that takes template parameters, the list of those things is "endless" (clamp, min, max, sin, cos). Then it's a bit annoying with printf, if you like that.. I usually just cast. The annoying part is that the C++ error messages are misleading (and long!), it says that cannot convert into vector of doubles etc.. which is totally wrong and misleading. That's the downside, but the upside is too much for me to ignore (I am dealing with SIMD backend and this just destroys the alternative code paths..) *sigh* :) 
The operator &lt; isn't the problem, the problem is deduction of the template parameters types. The workaround is to make the accessor look like a scalar with a cast, which is not very convenient. Alternative is to enforce the type and then let the signatures match: std::max&lt;float&gt;(a.x, a.y); That works as the compiler can deduce the type (as it is forced) to be a scalar. Annoying.. the workaround is to add more overloads for most commonly used functions (as a convenience). This does require a comparison operator if we don't want to cast (works for everything ;): if (a.x &gt; a.y) I'll most likely make the API more user-friendly by adding more overloads in the near future. I just been so used to the way it works that it never bothered me.. but you do have a point now that I look back. :) 
... p.s. my rationale has been that if I start patching things, that work never ends as there are endless number of templates and functions to handle. That's what been keeping me away from that path... but as you made me think about it once again, supporting common stuff like min, max, clamp, &lt;, ==, &gt;=, etc. wouldn't be that much hassle and would improve the coding experience a bit, so why not. :) 
So what did you try?
I've already had to submit task 1 but as it says it needs to be rewrote, I used a string within a vector that passes by reference. However, for me to get above 70% I need a better way to program the AI functionality so that works will be associated. He suggested using a shared library but I'm not really familiar with this concept. 
This is off-topic here, try /r/cpp_questions. But please, show some effort by providing some of the code you have so far and by indicating where you're having problems. Don't just dump a picture of text on people.
Apologies, I did write what I had currently worked on within the optional text section but it hasn't appear :(
It's compiled to machine code by default, and it doesn't have a GC.
[Unlimited Power](https://www.youtube.com/watch?v=Sg14jNbBb-8)!
because I hate myself
LMFAO
I don't choose C++ ~~over~~ other languages. I choose the right tool for proper tasks. But when I want to do some hobby projects, I may choose C++ because it's quite challenging when going deeper. I like to do challenging stuff than repeating boring code. 
I write software for other people and other people don't want bloated slow bullshit. 
We had a C++ class in high school, but it was god-awful. Code printed out, code on the blackboard and the teacher barely knew what he was doing. I did realize how powerful a language like C/C++ was though. Learned C first, then moved over to C++ when I was confident enough (at that time I believed that C was a requirement for C++).
wanted to get a bit closer to the metal out of curiosity mostly.
speed
I dunno, seems like people's tolerance for slowness is. gradually increasing nowadays. 
I didn't. I work on compilers and toolchains and those projects chose C++ and, so, here I am. 
Zero-cost (and low-cost) abstractions.
/O2 (MSVC) -O2, -O3 (clang++, g++) -Ofast (clang++) The debug binaries are also "the usual size", -O1 bloats quite a lot with clang as it does not optimize away the temporary assignments and what not. The g++ makes tighter code with -O1 but even clang will not result anything like code explosion you witnessed, just the usual O1 bloat since most code is kept for easier stepping with a debugger. Let's put it this way: enabling the code did not result in visible changes to compilation times or resulting code size. Especially O2 and above, all of the abstraction is optimized away (The C++ way of "Zero Cost Abstractions" that mostly code in compilation time explosions). A bit of a rant that it is indeed super easy to write code that compiles super slowly with C++ ... I been drifting towards more functional style in past years; the code is easier to understand and it runs pretty nicely. On the other side of the coin, I really do dig templates for containers and stuff like that. If I were to write the math code now (I might upgrade it in a year or two) I probably wouldn't use templates at all with it; all of the vector types are pretty explicit.. the template variants for fully generic scalar type and dimensions have not been used ONE SINGLE TIME in the past 10 years!!! I could write arbitrary precision Float class to have trillion bits of mantissa and billion bits of exponent, but WHY!??! In such scenario the templates would come in handy as I could save a couple of hundreds of lines of boiler plate code repetition. The SIMD specializations already mostly repeat the code ANYWAY so.. the templates should probably just take a hike. xD 
Being able to use const on runtime variables to enforce correct usage. C++ isn't exclusive in that regard, but popular languages like C# reserve const to compile-time. Being able to stack allocate or heap allocate a given type as I see fit. I hate the class / struct distinction other languages make, or even worse, languages like Pony that just say "Just embrace your inner C!" Yeah no, I'm not going to sacrifice type safety just to reduce my number of allocations. Phantom Types + Type Traits allowing me to make static guarantees about domain-specific problems such as coordinate frame conversions. Probably possible in other languages, but it was really easy in C++. Template specialization. I can swap out entire implementations for containers based on the underlying type, and the user is none the wiser. Zero cost exceptions (on non-exceptional paths). Rust users love to circlejerk about their explicit error handling, but I'd rather not pollute all my callchains and experience refactor hell when a function that used to not errors all of a sudden does.
Compatibility, efficiency, and ease of use in IoT environments.
I started my programming journey with Java. I was impressed with how much C/C++ was giving me freedom over everything, I could write my program exactly how I wanted to. It seemed more professional and appealing. Slowly I was using C++ more and more. Now that I got to somewhat advanced level I hate myself and hate this language, and I wish I never had abandoned Java for it. I tried to come back to Java many times but now I just can't... So I guess I'm gonna stay with C++ and keep bringing hell to myself, it's quite a rabbit hole
I looked into the overloading quickly.. I think I'll pass mostly and just keep casting. T min(const SA&lt;S,T0,I0&gt;&amp; a, const SA&lt;S,T1,I1&gt;&amp; b) T min(const SA&lt;S,T,I&gt;&amp; a, S b) T min(S a, const SA&lt;S,T,I&gt;&amp; b) ... for everything ... outch-outch. If only the C++ could be told that SA -is- S, not just can-convert-into-S so that the type deduction could get a bit of a helping hand. How did you do your custom overloads? Something more scalable than above abomination? 
Not being a pile of shit.
&gt; seems like people's tolerance for slowness is gradually increasing nowadays. It's not.
&gt; I hate the class / struct distinction other languages make Are there non-.Net languages that make that distinction?
Speed, easy resource management, generics, and incredible flexibility. I don’t disagree that it’s a beast and the minutiae/intricacies are almost endless, but I think most (not all) make sense. I mean, C++17 almost feels like writing really fast python.
D Lang, although they provide stackalloc!, still feels a bit messy though. A lot of other languages don't even provide value types, which is even worse.
On the bright side, C++20 should make things a lot cleaner and easier 😊
So what if people still didn't even get past 11
Think of it like learning a new language, except everything you already know how to do still works.
I use C++ when I believe it's the best tool for the job. I didn't choose C++ specifically over other languages in general, in fact I use other languages all the time.
I learned C first and loved it. C++ built on it in ways that were clearly useful (classes, overloading, containers, auto_ptrs) without forcing a shift to a completely different programming model (untyped/ gc / interpreted ).
As someone who started in JS, and now does mostly c and Rust, your mental models can change. 
When I learnt C++, it was basically _the_ language. There was C, and C++, and a bunch of niche languages such as FORTRAN. ... So that's why. These days the main thing I like about C++ is that has flexibility to be highly abstract as well as very low-level.
Shush you're not supposed to tell them that!
Templates, the optimizing compiler (guilt-free abstractions etc...) and RAII.
It’s what I learned in high school when I decided I was too cool for Pascal.
Is rust hard to learn
We have an old platform that customers want to handle a much higher volume of messages and complex data than it does now. We already have high-value commitments from customers. I would say your average desktop user who is getting his software for free is getting a little more tolerant of slowness in the web age. But the people _paying_ for software are not, and in fact are growing _less_ tolerant. They want _more_ speed, not less.
&gt;There's an abundance of software that runs slow as hell but is popular anyway. Not all code has to run fast and be optimized to the max, but developer time is expensive - especially ones from the "no bullshit" languages. I like C++ a lot, but using it for every single project would be like using a hammer to fix everything in your house.
Because it was the first language I learned in high school and college and used professionally, and I stuck with it and I didn’t really alter my course. 
I use C++ because my employer uses C++. I don't choose my jobs based on what language they use, I work on interesting stuff and use the language the people working on that thing use.
At the time, it as the only object orientated language I knew of.
The paycheck
I'm still waiting for the perfect language to come along, so until then I have to settle for a language that doesn't pretend to be one. A messy hodgepodge of a language that can model a messy hodgepodge world; because the universe doesn't care about our neat and tidy theories.
Because that's what MFC is built on. Why else?
Swift works that way– classes are reference types &amp; structs/enums are value types.
Was looking for "job". This seems to be the appropriate answer
tl;dr: Cool jobs drew me to C++. I started learning C++ a couple years ago because I wanted to work in the games industry (managed to get a couple onsites but no offers last summer). Compared to other languages I know, C++ is probably in the middle of the pack as far as how much I like the language itself. What I *do* like about C++ is that jobs I find interesting tend to use C++. Jobs in graphics, audio processing, high performance computing, etc. I'm interested in more performance sensitive work that requires deep technical knowledge, but after college it was hard even finding jobs that aren't pure CRUD and business logic, let alone get an interview for them. CRUD didn't interest me and isn't why I got into programming, but until recently I didn't know what my options were, so CRUD is where I wound up when I graduated with a non-CS degree. I broadened my search beyond the games industry just by searching for 'C++ programmer' on Indeed and I just got offered a job making almost twice as much money at a scientific computing company that focuses on image processing and computer vision. They only cared about my C++ and general programming skills. So hopefully I'll be making a lot more money at a job I like more than my current CRUD/systems admin-ish job while getting experience that'll lead me to other interesting jobs.
They need to turn it up.
To be fair I think that depends on the programmer. If you can do the same thing in C++ or Python but the programmer in question just vastly prefers C++ for whatever reason then what's the harm?
Very on the nose, I completely agree (and have seen the same stuff myself). As you say - this comes out strongly in data processing. Users have more and more data every day that they want to do crazy things with; data is growing faster than computer power, so it's natural that they look to the software to provide solutions. Basically all I've done for the last 6 months is make small memory optimizations (along with refactoring). But the impact is there, and it matters to the end user.
Hard constraints on memory and cpu consumption. Frankly, I don’t think there are any other good reasons.
The same thing came to mind when I read the question.
I feel weird writing this (considering the consesus of hating this language) but I fucking love all these C++ features Coming from a long Java background, it's so mesmerizing. You can basically make up shit on the spot and it turns out to be a supported language feature. The one thing I dislike about C++ is missing standardized reflection. This would be really useful for visualization, user interfaces and even debugging. 
One more plus
Game development. For decades, at has really been the only tool for the job, Unity3D notwithstanding.
High level of control on the software, while also having a pretty high level language.
Ditto++; // Though some of us transitioned from assembly, to C, to C++ &amp;&amp; sometimes to C#
The reasons for this are historical. Up until C++98, C++ did not even have a string class, instead everybody wrote their own implementation. For example on Windows MFC, you had CString. Borland had TString and so on. As part of the standardization efforts in the mid 90's, the committee specified string. The way people implemented strings and other collections was to have algorithms as member functions. In that model, the string class would have a find member function that returned an int. An example is CString::Find [https://docs.microsoft.com/en-us/cpp/atl-mfc-shared/reference/cstringt-class?view=vs-2017#find](https://docs.microsoft.com/en-us/cpp/atl-mfc-shared/reference/cstringt-class?view=vs-2017#find) . &amp;#x200B; Then Andrew Koenig met Alex Stepanov. Stepanov, had come up with this really neat abstraction of iterators, containers, algorithms where could implement an algorithm once and have it work for all containers instead of having to write for each container. This was presented to the C++ committee, and in a matter of months, the STL was voted into the C++ standard. std::vector, deque, list were part of the big STL import. Now what to do with string? Basically, the old interface was kept, and the STL was grafted on. This is why string has such a huge interface. While most algorithms return iterators and end iterators for invalid values, string member functions such as find, return integers and std::npos for invalid values. &amp;#x200B; In the STL world, the main reason a collection implements an algorithm as a member function is if it can provide a special purpose one that has better complexity. An example is list::sort which takes advantage of list's internal structure to provide a n lg n sort. So string is kind of like a weird hybrid of the C++ world pre and post STL. std::vector is from the post-STL world. &amp;#x200B;
When I started, there wasn't a choice.
Can you explain a bit more about how you use phantom types and type traits? That sounds interesting.
Well what choices do you have if you want performance? Fortran, C, C++, Java and maybe one of the new player Rust? * Fortran isn't bad it's just old and not very popular, learning it would have limited my job choices compared to C++ * C i actually really like it because it isn't as bloated as C++. It was the first language i learned and i still never use it. Just lacks object orientation, which is nice to have once in a while. * Java is nice, but i hate that the code needs the java vm to work. That means for most micro controllers and integrated chips it is not a valid choice. And i was always interested in hardware and how my code interacts with the machine. One of the reasons i learned programming is because i wanted to understand computers, java just adds an layer of abstraction that i don't appreciate. But to be honest probably a great language for many things. * Rust, actually looks great and people love it. At this point i just don't think it's popular enough for me to spend the time and effort switching to it. And i am not sure if it will ever get there. C and C++ are very established and it is going to be difficult to bring in a new player. So yeah, C++ it is. It's established, it's popular, it's fast and it runs on almost everything. Other languages don't give me those things. That's why i just accept the fact that it is ugly and sometimes hard to use. 
So in the industry I work in, we commonly use various reference frames to represent where things are in relation to each other. An example would be Earth Centered Earth Fixed (ECEF). This is often the go-to frame of reference, so all positions of things in the environment is stored in this reference frame. Sometimes, it's easier to write a certain piece of functionality by using positions in relation to a given object (known as body frame). To achieve this, we need to convert positions of objects from ECEF to body frame in relation to a particular object. To do this, we apply a rotation matrix that will convert from ECEF to body. Often times, people tend to just store positions as a 3D vector, and in some cases, even go so far as just storing it in a float Position[3]; This sucks, because you're basically relying on the variable naming conventions to ensure you're using a value the correct way. Instead, we can wrap that vector in a class Position&lt;T&gt;, where T is a phantom type, aka T is not actually instantiated anywhere within Position, it is merely exploiting the fact that two different values of T result in two non-compatible types, so attempting to assign those types to each other results in a compilation error. Something along the lines of: template&lt;typename T&gt; class Position final { public: // ... Some interface private: Vec3f mValue; // Note T is not actually used anywhere here. }; Position&lt;Ecef&gt; foo; Position&lt;Body&gt; bar = foo; // Won't compile! With that in mind, we can store the positions of all our objects using Position&lt;Ecef&gt;, where Ecef is just "struct Ecef;" that got forward declared in a header somewhere. So we have a Position&lt;Ecef&gt; stored in our entity, but a function we want to call only accepts Position&lt;Body&gt; because the algorithm being used is easier to implement with that frame of reference. So in order to convert From Position&lt;Ecef&gt; to Position&lt;Body&gt; we need a rotation matrix (not the only way, but that's what we're using in this example). With a Rotation Matrix, we can also utilize phantom types to ensure we're doing things correctly: template&lt;typename OriginatingFrame, typename ResultingFrame&gt; class RotationMatrix final { // Implementation. }; Thus we need some way to create an instance of RotationMatrix&lt;Ecef, Body&gt; and apply it to our Ecef position, resulting in a Body position that we can pass to the function. To create an Ecef To Body rotation matrix, you need three rotation values: Psi, Theta, and Phi. So in addition to storing Position&lt;Ecef&gt; for a given object, we now also store Orientation&lt;PsiThetaPhi&gt; (another phantom-wrapped 3D vector) for the object, as well. Now we need a way to take that orientation and create the matrix. We can define a constructor that takes an Orientation&lt;PsiThetaPhi&gt; as a parameter, but we only want that to work for a rotation matrix that translates from ECEF to body, as it wouldn't make sense for any other combination of reference frames. This is where type traits comes in. We can define the constructor as such: template&lt;typename T = OriginatingFrame, typename U = ResultingFrame&gt; RotationMatrix(std::enable_if&lt;std::is_same&lt;T, Ecef&gt;::value &amp;&amp; std::is_same&lt;U, Body&gt;::value&gt; = 0) { // Populate the matrix } Thus, this constructor is only exposed when creating an instance of RotationMatrix&lt;Ecef, Body&gt;, allowing us to perform the rotation and use the function. This could also just be done with a standalone function, but we opted for type traits to allow us to use constructor syntax. When you dive deeper into it, you end up using type traits more heavily for various things, like converting from NED (North-East-Down) to geodetic for a given Position&lt;Ned&gt;, for example. It ends up being a very powerful toolset, because nearly all your math logic now gets statically checked by the compiler, instead of having to hunt down runtime errors. 
Because that's what all the cool stuff is written in.
Freedom! Want classes ? Ok here ! Don't want classes ? Ok here ! Want me to manage this object's memory ? Ok here ! Want to manage it yourself ? Ok Here. Have the freedom to do what you want but be ready to face the consequences. 
I mean, if you can do the same thing in either C++ or Python you'd probably want C++ purely for speed over Python.
What if speed isn't an issue? I can make a roguelike in a linux terminal using C, C++, or Python and the end user won't be able to tell the difference. So it comes down to which language I prefer to work in, right? 
The harm is more development overhead. Pythons huge standard library and the simple syntax gets you going very very quickly. When speed is not that critical, you just get more done quicker and with less boilerplate, imo. And if you need the speed for numerics, you're not even that much slower with mindfull NumPy usage.
If it's a solo job or a team of people who prefer C++ for whatever reason then the overhead might be worth it. Especially if it's a solo job some people might just be more comfortable with a language they really like rather than one which has less overhead but appeals to them less. Some people actually like writing all the little boilerplate parts of a project. I don't think there is a right answer for every situation. It's totally case by case.
Its a good way to get a better intuition how computers work (which isn't always apparent in higher level languages). C is probably better just for that but C++ let's you tune the level of abstraction up and down pretty freely - you can try the standard library's linked list and then try and write our own implementation or the other way around. 
That's a good question! I think in the early days, I tried to allow the simplest possible syntax C++ allows to work with JSON. Then I tried to mimic the interfaces and names of the STL to let the library blend in nicely when used with other containers. Eventually, the API got stable, so any new feature request needs to answer the question "Is this something that a lot of users of the library may use?". It's hard to resist adding new features just because someone may need them or even create a PR for you, but in the end, you have to test and maintain that code, and semantic versioning makes it so hard to get rid of code after the fact.
Quite apt, coming from a KingSlayer.
No, MFC is built on orphans' tears .
It was the only real choice in 1996.
- Not gabaje collected - Manuèl memory management - C syntax - close to HW - great history behind it and useable on linux What makes me hate C++? Bloated with features!! I understand the decision behind supporting 20yo code... But deyum! Learning C++ is an infinite journey 😰 In fact, for the same reason, I'm interested in rust now 😅
It's best that you learn from a book that teaches "modern C++," i.e. the idioms and practices introduced in C++11, the C++ standard published in 2011. See https://stackoverflow.com/q/388242/8887578 for book recommendations. 
That is fantastic feedback. It’s detailed, kind and helpful :-) +1.
Thank you!
Your story reminds me a talk titled [(Not Your Father’s) C++](https://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2012/-Not-Your-Father-s-C-) by Herb Sutter. You may take a look at the [Get Started! page](https://isocpp.org/get-started) and [Tour page](https://isocpp.org/tour) of Standard C++ Foundation.
I found rust very easy to learn. There is some friction if you're trying to use patterns from other languages but if you approach it fresh it's pretty easy as far as compiled languages go.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b4gc74/who_wants_to_help_json_for_modern_c_get_into/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks! I think I'll be starting through here &amp;#x200B;
The power to command the machine's status down to bit level combined with the ability to right powerful abstractions combined with the ability to not pay for what I don't use. It's a unique combination that allows the best performance both for the computer and the developer. 
Could you please explain what does it mean "Forward to LWG for Fundamentals TS 3"? Does it mean that expected feature is dropped from C++20?
I started working in computer vision in early days of opencv (about 12 years ago) it was only available in C++ and therefore I learned it. Now even when it's available in Python and Java I cannot think of letting C++ go, I'm addicted to its performance.
dunno new stuff every ~3 years is easily manageable and there is literally no one out there who wants rust devs
 Yes and no. It can be a lot all up front, but once you get through that first chunk, it’s relatively smooth sailing. There are a few concepts in rust, namely the borrowing rules, that can be subtle and difficult to get at first. Though with persistence, they eventually click. New complexity rather tapers off after that. In my experience, c++’s complexity takes long to reveal itself, but is perhaps more complex than rust. in the long term, I believe rust to be easier than c++ (and certainly more ergonomic). the compiler has really good error messages that explain in real sentences what you’re doing that’s not allowed. But more importantly, the language was designed to make the trickiest errors in c/c++ impossible (without a runtime sacrifice). Rust is also good at making would-be hidden costs, visible. To top it off, the rust community is very welcoming and not at all elitist. There seem to always be those happy to answer your questions. All in all, rust is an endeavor, but is a hill you can climb. 
performance and you can develop for anything from microcontrollers to large applications or games.
It’s powerful and expressive. 
This is really interesting thanks for the detailed explanation!
I was not going to respond to this, but what the heck... #define macro(x) template&lt;typename X&gt;(X&amp;&amp; x) &lt;rant&gt; We see articles once a month or so complaining about preprocessor macros, saying how they're evil, and espousing some other solution. Yet as much as I've tried to be open-minded, I never seem to agree with them. Personally I think macros are GREAT! They're a very powerful tool - and like any tool, they can be abused. Here's your list: 1. Code with Macros Attracts Bugs 2. Complicated Code Reading 3. It’s Difficult to Write Macros 4. Complicated Debugging 5. False Positives of Static Analyzers I don't know how to respond to \#1. It's simply not been true in my experience. Apparently yours is different. I will say what I find often lacking are unit tests _for_ macros - i.e., people don't often write tests to actually check their new macros in various use-cases. \#2, \#3, \#4: replace the word "macro" with "templates", and you have the same exact results. Complicated things are complicated. If you write complicated macros, they're usually complicated to read, write, and debug. Same with templates. Same with code in general. (For some weird reason, however, I and most everyone I know has always found templates to be harder to read, write, and debug; but I like them too) \#5 is an interesting claim. But the only evidence you cited was for the `DCHECK()` macro, and as far as I know it's not the fact it's a _macro_ that causes a false positive... it's what the actual code _does_. By that I mean had the same logic been written in the source code directly, without any macro, it would still be a false positive. It's just in a macro for some of the same reasons the standard `assert()` is a macro. And it _should_ be a macro. We don't have the language tools available in C++ to truly replace many macro use-cases. (e.g., `std::source_location` is not supported by many compilers yet, nor do we have lazy evalutation, nor reflection, nor stringification, etc.) This isn't to say macros don't have problems. They have specific issues with certain argument syntax (e.g., the comma parsing problem); and variadic macro support is not universal across compilers. They are essentially a different language with different rules, and as such it takes time and effort to become proficient at writing them well; and few people have the time or desire to do so. But again, one could argue the same for templates, or regular expressions (regex), or SQL queries, or whatever. It takes time and a lot of reading and experience, etc. Copying stackoverflow snippets doesn't count. The one really hard and unique issue with macros is the name collision problem, imo. But I think they're incredibly useful, and for me their benefits _far_ outweigh their negatives. &lt;/rant&gt;
I didn't do them yet, and I probably won't
Although we all love and appreciate your library, I don't think this post is appropriate for this subreddit. Perhaps post this in the jobs sticky?
Initially? Ease of use. If you think I'm joking, go back in time 25 years and try to handle string data with more than 255 characters per string in f'ing pascal. Now it is the guarantee that the code I write today won't have to be rewritten tomorrow. Will toy-language-du-jour still be around in a few years? Will your code still compile, or will the syntax have changed completely? Who knows... The performance benefits and the mature ecosystem are nice too.
Perfectly correct! 
And because it's widely used. Some obscure functional programming languages might pay incredibly well, but there's not going to many employers to choose from. 
Probably the biggest factor is back when I started C++ (using it for gamedev), there weren't as many options. I knew it was fast and that pros were using it. I kept with it because the types of things I wanted to build were games, audio applications, and things that needed to be fast and realtime. I didn't want to have to rewrite something because it was too slow. I also looked at examples of things built with different languages and it seemed like the most impressive stuff was C and C++ back then and that Java and python stuff was slower.
Does it support value template parameters for things other than integral types?
I'm not sure I understand. It looks to me as if you'd like to apply as a mentoring organization?
Embedded programming. Started with C, then as systems become more powerful, C++ became available for me. Now I use C, C++, but also Python for things that are not time critical.
 If you need raw fully-qualified name, use NAMEOF_RAW. ``` NAMEOF_RAW(somevar.somefield) -&gt; "somevar.somefield" NAMEOF_RAW(&amp;SomeStruct::SomeMethod) -&gt; "&amp;SomeStruct::SomeMethod" NAMEOF_RAW(std::string) -&gt; "std::string" ```
Well, I might not be all that interested in perf, but my manager told me to work on this huge 30 year old application;). Let's not kid ourselves in believing a programming language is only used, because it is the best tool for the job.
I’ve been introduced into C++ back in university while studying mechanical engineering. C++ was successor of FORTRAN that time. I’m also writing sometimes in java/spring if necessary. But my profession is still C++/Qt based desktop applications, and I think will always be. I simply learned to love C++, regardless what others say, it’s not dead.
Believe me, I'm well aware of what UB can do to a program. But bugs in the compiler aside, I've never heard of a case, where it would allow an ill-formed program (again, not "ill-formed no diagnostics required") to pass compilation. Not saying it never happens but unless I see any counter example I see no reason to assume it does. 
A lot of control over exactly how I want the program to work.
Just because you can do it in both languages doesn't mean it has the same quality/ amount of features after a given amount of development time. And in particular for small projects, existing libraries and frameworks can be much more important for performance than the programming language. 
I love OOP programming. At school I learned Python, then Java. But Java couldn't give me that sense of "efficient programming" (Yes garbage collector, I'm talking to you) and other things. My other choices were C or C++, and I chose the latter because of the OOP. After a looong time I finally learned it (At least, a VERY big part of it, C++ libraries are immense), and now that I'm starting to learn Vulkan, it seems so easy to implement.
Especially as processor cores arent getting faster, and havent been for some time.
Being able to use OO programming and finally having access to an optimizing 32-bit compiler. The year was 1996.
Same. But I was so naive then,with the things I was trying to,do with it.
&gt; when I graduated with a non-CS degree Out of interest, what *was* your degree?
I knew C and I started developing games for fun using Unreal Engine with C++. C++ can be anything these days. Classes, templates, lambdas, operator overloading and many other features make C++ a high level language almost as expressive and easy to use as Python and the likes imo. Yet you can still mess around with memory, assembly and all sorts of low-level stuff, trying to make your code as fast as it can. That's what I like about C++.
I was programming mostly Java and it didn't feel real because the language was so cut of from the actual computer. In C++ you were allowed to do things like accessing arrays out of bounds and the language didn't stop you. I liked that C++ forces fewer decisions on me and if I don't want to pay for the overhead of bounds checking or garbage collection I don't have to. It has made programming fun again and I'm still enjoying C++ more than 10 years later.
I also like the idea of being able to provide a single 10 KB executable instead of 35MB thousand+ files of dependencies.
I call BS. If you really cared about performance, *and nothing else*, you'd be writing assembly code. Instead what people generally care about is a combination of performance and other factors, of which development effort is probably the most important. We really should stop chasing people who don't have performance as their one and only goal in life away from the C++ community. I cringe whenever someone says "I want to write a program to do x" and people respond with "well, x is not performance sensitive, so you should not be using C++". As if performance were the only reason to use the language, and for the rest it is so horrid, so nasty, so difficult, so unpleasant, and so weird that only a self-loathing idiot would use it. 
Masochism.
I also think like this sometimes but the truth is that I don't really like languages like Python. I want statically typed languages. I don't really know a lot about Python but I always struggle to write good code in languages such as PHP or JavaScript.
I'm inclined to agree. For my team being able to write high level and low level cross platform code is easily on par with performance in terms of reasons for going with C++.
Lol
C++ was the only actual serious language when I finished my CS degree(2005). I did most of my scripting in Ruby (still do) but the heavy lifting is always done in C++. I have learned and worked with other languages C#, Javascript, Java and Haskell but due to my current work (Machine Learning Research) my main language is C++
&gt;you'd be writing assembly code. Um, what decade are you living in? We know for a fact that modern compilers can produce much better assembly than most humans except in very few, very specific cases.
Any tips from someone who wants to enter that field after college?
Low level, embedded systems, and real-time systems. Not many options beyond C and C++ out there. Rust is kind of getting there, but will probably take another decade to be adopted by industry given how slow companies that make embedded systems are.
Nonsense. Humans can write the exact same code that compilers write, _and more_. The only reason compilers generally outperform humans is because humans don't want to put in the effort. 
Word on the street is that Python actually does come with a lot of development overhead in terms of technical debt related to runtime type checking and baseline performance.
Speed, more control over memory etc... As someone that likes things like Cyber Security a lot, stuff like DDL injections, Hooks, shellcode Injection are very interesting to me and C++ help me with that and with OS programming. And ofc I want to do a game with Unreal Engine just for the fun of it.
Speed is always an issue. If speed isn't an issue because you can throw hardware at it, then your speed issue becomes a money issue. And when you can't spare any more money for hardware, then you've got a money and speed issue. &amp;#x200B; Most useful software are more complex than a terminal roguelike, and evolves in complexity over time. And speed vs complexity isn't a linear relationship. A little bit of extra complexity can blow out your speed requirements by quite a lot.
Again, what decade are you living in?
What would be a simple example of a pattern that requires a different way of thinking than C++? 
&gt;Again, what decade are you living in? Wow, lacking social skills much? Do you talk to people like that in real life as well?
It's fast. It doesn't need an interpreter like Python.....hiss
Oh, so you can come out and say "Nonsense" and that's apparently good social skills. To top it off, you didn't even give a good counter argument and yet you judged someone as having said nonsense. &amp;#x200B; Don't whine about social skills when you don't have any. &amp;#x200B; And yes, I do talk to people like that in real life. It's a common phrase, used for humorous affect. People say that phrase in real life to each other all the time. If you'd had any social skills, you'd have known that.
It's fun to learn and I'm constantly learning something new with C++.
Why not build tensorflow with bazel, and manually link to resulting binaries with cmake? You can even automate it with cmake's add_custom_command.
This is what I tried to do for a while, but tensorflow needs Eigen and Protobuff as dependencies apparently and I could not figure out how to get that to work with CMake. Sorry, I'm not very good with CMake, do you mind expanding a bit with what you mean?
Be careful not to jump the gun. TDD isn't merely about writing unit tests or the tools to automate unit tests. You have to learn/experiment with designing a program to be able to be tested in units. Otherwise, you can end up with tests that have unfortunate dependencies on runtime uncertainties, or nasty backdoor hacks to make something testable.
&gt; std::advance could be O(1) on std::vector but not done yet possibly to to avoid bloating the interface `std::advance` *is* O(1) on std::vector&lt;T&gt;::iterator. std::advance dispatches on the iterator category of it's argument. In other words, if a container provides a random access iterator (which by definition provides a `+=` operator), then the `+= operator will be used.
Find open source projects to contribute to or start own. Demonstrate that you have the skill and understanding to merit a job offer. Set high standards for yourself. Polish up that CV and hustle. Good luck, soldier. 
Also, there is no substitute for learning by writing code. So to that end: [https://wandbox.org/](https://wandbox.org/) &amp;#x200B; &amp;#x200B;
It's a vendor-neutral scalpel with excellent structure and excellent abstractions that can bang bits as well as it can build huge software systems.
If you're OK with ~1/3 performance and you like types you should consider Haskell.
In Australia, every 3rd or 4th job ad I came across was using Rust. Probably startups with ideological developers, but they're there.
Some of the high-profile projects using ASIO: * MongoDB - a popular NoSQL database * [libtorrent](https://libtorrent.org/) - a library in the heart of many BitTotrrent clients * [libbitcoin](https://libbitcoin.org/) - a library upon many Bitcoin clients are based * [Ripple](https://en.wikipedia.org/wiki/Ripple_(payment_protocol)) - an enterprise blockchain payment system.
Thank you, but I'm specifically interested in working with compiler technologies. These tips although valid apply to any SE out there.
&gt; We know for a fact that modern compilers can produce much better assembly than most humans except in very few, very specific cases. This still does not erase this guys point at all: &gt; most humans Yeah, that’s because most humans don’t master assembly languages. That’s like saying that google translate will produce better Chichewa than most Americans. That’s obvious, but if you know your Chichewa really well you can probably produce better texts than GT, or at least same quality. &gt; very few, very specific cases. Wouldn’t say that it’s very specific cases. Not really. If you know your way around assembly, and you know what you want to do, I’m pretty sure you can write some task specific assembly that is better than optimized generic assembly. It will demand perhaps more time to write than C, but if performance is all you care about...
I still prefer higher level languages like Haskell for some things, but after reading Elements of Programming by Stepanov and McJones I discovered that C++ can be beautiful. Before that book my opinion was that C++ was a nessecary evil for low level software. EoP changed all of that.
Nowadays, Python has opt-in static typings with the caveat that it is enforced by a tool (mypy), not the compiler itself.
How easy it is to use, how many great courses are there and how many things you can do. 
just write tests for all the functions you are programming, you don't need frameworks to do it - it is really simple. The only thing changes with TDD is that you write the test before you write the function. Simple. Is it important? testing yes, but TDD? It's more of an philosophy, some love it some hate it and many just don't care about it. I personally write my code, than i write my tests and then i tell everyone else i did it the other way round so i don't anger the TDD fanboys. Gtest (and other testing frameworks) are usually huge and i wouldn't recommend adding them to smaller projects. They really start to shine when you are working in bigger teams and you need a standardized testing procedure. 
I didn’t realize it until now, but “runtime type checking” is most of my problem with python and I could never really clearly explain why to others. Thanks for the combination of words 
&gt;Yeah, that’s because most humans don’t master assembly languages. That's irrelevant. His point is irrelevant, so I don't need to "erase" it. Compilers are better at it, end of story. &gt;If you know your way around assembly, and you know what you want to do, I’m pretty sure you can write some task specific assembly that is better than optimized generic assembly. No. Hasn't been true for some time. CPUs do a lot of things under the hood that assembly does not give any sort of guarantee. It's all about caches and data latency these days. And compilers do more than "optimized generic assembly". You do know that compilers can generate target specific assembly, right? The cases where humans still have an "edge" is choosing specific instructions for doing high level algorithms that have not yet been embedded into compiler consideration, such as using SIMD instructions for UTF-8 text processing. And that edge will soon disappear as that makes its way into compilers and libraries.
I would recommend [doctest](https://github.com/onqtam/doctest) - it is the lightest in terms of compile times (see the [benchmarks]( https://github.com/onqtam/doctest/blob/master/doc/markdown/benchmarks.md) - by orders of magnitude) and is super easy to use (just like [Catch2](https://github.com/catchorg/Catch2)) because it is just a single header! doctest is so light and unintrusive you can write your tests right next to your production code - imagine writing the tests for a class at the bottom of the .cpp which implements it! The framework produces 0 warnings and all tests can be removed from the build by defining [```DOCTEST_CONFIG_DISABLE```](https://github.com/onqtam/doctest/blob/master/doc/markdown/configuration.md#doctest_config_disable) globally. This is what sets doctest apart from the rest - it is truly practical to include it in the production code and write unit tests along your code (and TDD becomes straightforward) - other programming languages such as D, Rust and Nim have this capability out-of-the-box.
It's hard to find the right terms when there's a lot of mixed usage and obfuscation. I always get frustrated when people say X is strongly typed, but they neglect to mention that X doesn't do the checking at compile time. So the system I use is: runtime vs compile time, and strong vs weak vs none. Duck typing is an interesting one. Python is duck typing at runtime, but is duck typing in itself weak, or only when it's at runtime? C++ template typenames are duck typed, but at compile time, so it is strongly typed in effect.
I like to joke that I know two kinds of environments: The ones where a few dozen MB overhead don't matter and the ones where a few dozen KB are too much. It's not quite true but also not too far from the truth either.
&gt; that's the end of the argument No. /u/johannes1971 clearly gave a very specific case "If you really cared about performance, and nothing else." Thus the argument isn't about the general case, it doesn't matter that compilers *generally* outperform humans. With enough time and effort, humans can craft assembly superior to that of compilers (if by no other means, we take what the compilers generate and tweak it). The thing is, that takes effort, which is clearly what johannes is stating (because that's literally what he states).
Writing your tests in the same file as the thing you're testing is not what I would call unintrusive. I'd much rather keep my tests separate from the rest of the code and simply define a separate build target for them. Though I guess that's mostly a matter of taste and I'd assume you could do it either way with both doctest and Catch2.
&gt; Oh, so you can come out and say "Nonsense" and that's apparently good social skills Don't play the victim here. You made what could be construed as an antagonistic comment by saying "what decade are you living in?"
When i started practicing leetcode, i switched from C, as it CPP with its STL is far faster to code than C. 
Other than web frameworks, is there some other "sector" of development that C++ is totally ill suited towards?
Wasn't playing the victim. Just pointing out double standards.
Might be a silly idea but have you thought about doing it the other way round? Export your graphics engine as a python module (via pybind11 or such) and use it with your regular Python tf/keras workflow. From the looks of it, the deep learning part is the one where you'll be doing most of the work, so doing it in Python will be much more fruitfull since it'll leave you free to focus on research and experiments and prototyping, which is where Python excels over C++.
Because the first thing i programmed was a very bad chess computer and since then i only made other miserable chess computers and (almost all) chess engines are in c or c++.
&gt;If you really cared about performance, and nothing else." Thus the argument isn't about the general case, it doesn't matter that compilers *generally* outperform humans. &gt; &gt; &gt; &gt;With enough time and effort, humans can craft assembly superior to that of compilers (if by no other means, we take what the compilers generate and tweak it). Wrong, as I've replied to another person in another comment. CPUs do a lot of things under the hood that makes any assumptions humans have about performance become misguided, at best. And that would only be compounded by tweaking compiler output that may end up being worse. No amount of time and effort is relevant.
Bjarne Stroustrup is cool and his ideas about how C++ and programs in general should be built was very inspirational. There’s an idea of standards and rigor and ideals of longevity and safety that are stressed very early on by him in his programming book and he explains a lot of cool real world applications of C++. I have found that I enjoy learning it more because you simultaneously learn about memory and how programs work and how the OS handles certain things and you feel like you’re actually gaining expertise which didn’t really seem to happen with a scrutiny language tutorial as much. I tried Python a few times and never got far, but C++ just seemed so versatile and capable and cool and most people’s complaints seemed to be about badly written C++ and not well written C++.
My personal opinion, it is completely appropriate. nlohmann's JSON is a highly popular JSON library, and it is written in C++.
What compiler? I noticed the __fastcall/__stdcall are dropping things out of registers more than UNIX-like System V ABI the clang/gcc use. You can remedy this to a degree with __vectorcall, but it's annoying and I don't do it myself (I just live with it). Suspicion is that the constructors force more expensive parameter passing. I used to have a "nice" godbolt everything-in-one-source test framework with outputs for msvc, clang, gcc and icc and used that to tune the code. It's out-of-date as it has to be kept in sync manually.. :_( Next: upgrade the test to latest code and see if we had (performance) regressions. 
Well in C/++ it's very common for people to end up with multiple references to the same pointer at once. A lot of people like that looseness and choose to trust themselves to not invalidate that reference. Rust will prevent this at compile time unless you further wrap your pointer in a ref count. This is similar to what you should be doing in c++ with a shared_ptr but rust doesn't let you make that mistake in the first place. Coming from C/++ , some people often find it restrictive at first but imho its stuff like this that means I have to think less about safety in rust and worry less about runtime crashes. Another thing people often do when starting a new language is try to implement a linked list. Well a linked list is problematic by default in rust because it violates those safety rules. Again, people think this means rust cannot express simple data structures and pass on it, but rust offers a few extra bits that you can use inside an explicitly marked unsafe block, and there are ways to create that structure still. All in all, imho it comes down to trust. I don't trust myself to not have made a safety error in my code. I know I usually don't, and sure I can hopefully quickly fix the few things that make it through to production, but with rust I don't worry about that. It handles that for me and if it compiled I have peace of mind and can just focus on other aspects of my code. Also Rust has the best build and dependency management system of any language I've tried. In most cases I don't have to think about it and am no longer spending time setting up my CMake etc... ----- For reference, I mostly use c++, python, swift and objc in my daily job. I use Rust at home and hopefully with time, at work, but it's difficult to introduce a new language in to a preexisting stack. I mention this just so people know where my opinions are coming from in terms of language. I find rust is very similar to Swift (I call them sister languages if anything) and would describe it as being as low level and performant as C++ with the ergonomics of Python.
Thanks, I'll definitely look it it
Does TF produce artifacts in an install tree or an archive? (I guess it'd be just one extra command to consume it.)
Uh absolutely it isn't
Well yeah obviously. You should be a well rounded engineer. Too many c++ devs know nothing else. But it's just one tool in the belt
I like that I can write cross platform code that can run on mac win linux Android iOS and web. And that it can be high performance on each platform as well. I also actually like explicit pointers and references compared to writing in, say, Java. We've been burned in an Android project at work because we were passing around implicit references all over the place and not realizing it, polluting source data structures when we should have been passing by value. C++ puts ownership in your face and makes you design around it, while some other languages don't give you ad much visibility into what you're actually doing and you make mistakes you didn't realize you were making.
I am able to express the problems in a way that mimics the problem, to the handcuffs of the language designer. C++ being multi-paradigm lets me do this. I have work at both a high and level level and express the abstraction levels necessary. Also, it makes fast code :)
&gt; Speed is always an issue. If speed isn't an issue because you can throw hardware at it, then your speed issue becomes a money issue. &gt; Most useful software are more complex than a terminal roguelike I don't think you're right about this. Running chrome is usually the most computationally intensive thing most people do on their laptops. Modern hardware outstrips the vast majority of computing problems. I work with a C++ code that has to run in parallel on large clusters often for days or weeks at a time to solve engineering problems. For such an application the kind of optimizations that C++ provides are obviously beneficial. But for 95% of the coding projects I work on, even dirty, inefficient Python code will run in milliseconds on my laptop. The speed with which I can bang out and debug a program is what matters, not the program run time.
I love assembly and work with it quite a bit so I feel confident in saying this is entirely inaccurate. Sometimes, yes, I find odd corner cases where you can optimize specific routines, but more often than not the compiler will outperform me. Reasoning about memory and execution dependencies to do proper latency hiding by hand is untenable. Maximizing occupancy at every stage by hand is untenable. Inlining assembly routines is also highly impractical as you have to rewrite registers often at the callsites to make routines “fit.” It really comes down to a losing value proposition wherein the time it takes me to get something right in assembly is greater than the time it would take me to write a new performant abstraction in C++.
Cool work but a terrible library name
No nonono.. that's the naive view of the situation ("Compilers are better at it, end of story." The thing compilers really are good for is consistency; they take the source code in, and consistently, without tiring or discrimination optimize any and all code that the programmer has written. You change one thing and the cascade effects to surrounding code are always, without exceptions, taken tirelessly into consideration. The problem the assembler code has is not that it is hard to write, or that it isn't expressive, but that it has so many steps that the programmer has to do manually. Juggling parameters in registers and in stack, allocating registers and choosing the least expensive instruction sequence to evaluate the programmers intent (="the expression"). Modifying assembler code -and- at the same time optimizing it to the last clock cycle possible is a lot of manual labour. It can be done better than the compiler but it is insanely expensive and to make the situation even worse (or better, actually) is that the compilers are getting pretty good at what they do. They still don't replace good source code; if you write crap you get crap out. If you instruct compiler to do stupid shit, it will do stupid shit. If you have a crappy layout for your data, the compiler can't help you with it.. it will work with it, generate shit code and you won't know if you don't have the skills for it. It's still up to the programmer to know what he is doing. Give a human enough time and he will out-perform the compiler in runtime every time (when possible, some times the workload can be just too trivial to bother). But is it worth it? Most certain not; it will be massive waste of time (until the .001% of situations where it isn't but that is edge case and we're not debating those). 
Python's type system is still not as weak say for example JavaScript . However it doesn't scale very well when we something more than trivial as you've mentioned of the time even if set performance aside type checking is biggest issue
I was in education and I'd learned C because I wanted to and C++ seemed the next logical step. 
And data center energy efficiency gets more important, and the growth in portable, embedded and IOT devices. These all point to c++ continuing to be relevant for a long time. 
&gt;that's the naive view of the situation It's not naive, it's realistic. &gt;Give a human enough time and he will out-perform the compiler in runtime every time If compilers improves at a rate faster than a human can write their best assembly code, then the human will always be playing catch up. Meaning the human can never out-perform compilers.
I was testing on godbolt with newest clang, gcc, mcsv. All have problems with various approaches.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [doctest - "The Lightest C++ Testing Framework" - version 2.3 released! With reporters support (including XML - for CI)](https://www.reddit.com/r/programming/comments/b4jzsg/doctest_the_lightest_c_testing_framework_version/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Hi. I've been working with C++ for a long time. I enjoy the Cpp chat video/audio podcasts: [https://cppchat.fireside.fm/](https://cppchat.fireside.fm/) Also I encourage you to consider "east const": [http://slashslash.info/eastconst/](http://slashslash.info/eastconst/) [http://slashslash.info/petition/](http://slashslash.info/petition/) I think the links that you've been given omit this.
Ditto. The only two portable programming languages are C and (slightly lesser) C++. I work in Linux on x86, ARM, ARM64, MIPS. I also dabble in microcontrollers. The only two portable languages that are fully supported across all those platforms are C and C++. The C compiler bootstraps first on any new platform. Usually the C++ compiler follows long after. The C++ version might be a little behind on some platforms, but I can still write higher level code that malloc/free.
&gt;But for 95% of the coding projects I work on, even dirty, inefficient Python code will run in milliseconds on my laptop. But they don't represent the 95% of programs that most people run. Browsers, browser based programs, word processors and such. And people aren't exactly raving about their performance.
&gt; Rust will prevent this at compile time unless you further wrap your pointer in a ref count So essentially it comes down to forcing these types of "best practices" at compile time and as a language feature instead of leaving it up to the developer to deal with (or trusting 3rd party libs aren't doing anything sketchy). &gt; few extra bits that you can use inside an explicitly marked unsafe block How often would you say you have to use this escape hatch? Or is it the sign of bad code smell to be doing it in Rust in the first place? I'm actually very interested in checking Rust out only because of the package system. I mainly use javascript and python in my day job (and love tinkering with c++ stuff during my free time). npm and pip might have their flaws but they mostly just work as you'd expect when you want to pull anything in. Thanks for the overview
Why does the libjeg-turbo (fastest software JPEG decoder on the planet) have so much assembler code in it? https://github.com/libjpeg-turbo/libjpeg-turbo/tree/master/simd/i386 Are the developers of the fastest library so stupid that they don't know the compiler is much better than them? They should quickly rewrite all of the time-critical loops in C to get speedups? :D Quote from their webpage: "libjpeg-turbo is generally 2-6x as fast as libjpeg, all else being equal." libjpeg is written in C, shouldn't it be faster as the compiler should be able to generate faster code than a human programmer? 
Looking forward to. :)
Didn't know about that one. Thanks!
&gt; Yeah, that’s because most humans don’t master assembly languages It's not just about mastering the assembly language, but also about knowing how the cpus you are targeting work. You could know the assembly language you wrote in perfectly and still write horribly inefficient code due to not knowing the latencies and throughputs of instructions, which instructions can be executed in parallel and which can't, or how the caches work. 
Wrong. As of today, compilers can only do what humans have programmed them to do. As such, a human can do anything a compiler can do with enough time and knowledge. Now I'm not saying humans SHOULD attempt to do the job of the optimizer, just that they can. 99.9999999% of the time, a human trying to tweak what a compiler has done is incorrect. However, the argument isn't about what "should" be done, but what is possible. It is *possible*, given enough time and resources, that a human can out perform the optimizer.
It's officially called 'Student Integrated Studies' but it's basically a general studies degree I got after I couldn't decide on a major. I started in CS for a couple semesters but I didn't feel like I was learning anything I couldn't teach myself so I wanted to major in something I wouldn't study on my own. I tried out majors in math, biology, English, comparative religion, and economics before I decided I just wanted to graduate. They bundled up 3 subjects I had the most credits in as my "concentrations" - biology, math and CS, even though I only took 4 CS courses - and I just had to take some fluff leadership class for the advanced writing requirement to get the degree. If I had to do it again I probably wouldn't drop the CS major since it's what I'm most interested in and upper-level classes in other subjects are a huge pain if you're only kinda interested in the subject.
Yes it essentially has put all the best practices into its type system. This also applies to multithreaded where you can't share things across threads without using a thread safe type or wrapper. The use of unsafe isn't necessarily code smell. It crucially doesn't disable the safety checks, it just allows a few extra things like dealing with raw pointers directly. It's necessary if you're doing any interfacing with another language/system via the CFFI because rust cannot know what it's doing on the other end. But the nice thing is that because these blocks are marked unsafe explicitly, you know exactly where they are.
Why do you think compilers need improvement? Are you suggesting that there are still things to improve? How do you claim that a human programmer cannot identify these optimization opportunities? :D Can you tell me why a compiler might want to use dynamic programming when evaluating AST generated from expression? Any argument why you might want to use some other technique instead, if so, why? 
&gt; It's not naive, it's realistic I'm not sure if you're intentionally misunderstanding the argument. Everyone in this thread has been clear with you, the argument isn't about what is realistic, but what is theoretically possible. We clearly agree with you that compilers are far better than humans given normal (and even abnormal) circumstances. But the argument is about how to get the most computation out of the least amount of electricity ONLY, where nothing else matters. Given that argument, Assembly would be the programming language of choice.
Are you coding in C++ for work?
Gotta go fast
Ive been working with hunter.sh to see about fixing the library linkage issue. Needs some more maintainers, but I think its better than being, to be honest. Android ndk support definitely needs a toolchain update. Google broke stuff somewhere marshmallow. But im working on a hobby project trying to get beast and graphql working together. 
Then I do not understand the different roles... Maybe it becomes clearer once the registration opens.
I tried to make this clear here: https://github.com/nlohmann/json#design-goals
That is correct! That's why I would only use it for smaller projects, not for anything too complex.
For my current project, I needed a system's language that would allow me to write high-performance code. I never had much love for C++ as I was always weirded out by the overly complicated semantics and the immature type system. I also don't care much for OOP design paradigm which is still very prevalent in the C++ world. S So I was seriously considering Rust (mainly for their clean division between data and behaviour, something that C++ still lacks), but it has its own share of issues. What finally convinced me to adopt C++ is the work on the C++20 standard. We finally get a usable type system (concepts), proper modules, coroutines and fixes to lifetime (std::bless). Also, C++ has a great compile-time transformation facility with constexpr and parameter packs, and it gets even better with consteval functions. Now, if I could also have proper pattern matching and protocol-based programming, and I'd be very happy indeed. &amp;#x200B;
I know the way I put it wasn’t good, but that’s what I meant by mastering the assembly language: knowing what to use and how in specific situations. 
I'd rather try a nixpkg repo than a disk-filling docker download.
Pytorch has a newly released c++ front end which you can easily integrate into c++ applications without having to bind into python. It has been used for the AI on some recently released games written in c++. I would look into pytorch and see if it has everything you need before going between python and c++ with Keras 
Every other language I've tried or looked into makes me feel like it's trying to control how I write code, or hide its workings from me.
Perhaps time to production and life cycle of the app are major factors.
Coool
It's fast compared to other languages (I'm looking at you, Java) while it also contains useful library functions and I don't have to create everything from scratch every time I use it (I'm looking at you, C) To be honest though, I'm starting to switch over to C after looking at the path C++ is going down. Adding new bullshit like "variants" and "modules" makes me want to puke.
I did a really quick hack (pasted, pasted, edited stuff out that is not relevant, etc..). https://www.godbolt.org/z/OXcnz8 Notice the line 9305!!! When you comment it back on, the parameters are passed in stack!!! The DESTRUCTOR is the culprit…! (at least, for me) OK; why the destructor.. because of the DeAggregate to work around ancient compiler warning (the array of components used that). I had to rewrite the data() member function and [] array indexing of the components. Those are not strictly necessary, really.. but some times you just want the convenience. The data() member function is mostly for interop with OpenGL and other APIs. To top this off, this is HARD to detect in regression test.. I only validate outputs and that expressions I have in the test compile. OK; so the destructor was needed for other feature, but it MUST go.. I can't stand the stack parameter passing for this trivial workloads; unacceptable! :) 
It’s not C++ specific, but I found [this book](http://www.obeythetestinggoat.com/pages/book.html#toc) a good introduction to the TDD philosophy. I’m don’t do rigorous TDD in practice, but it’s good to understand the ideas. Catch2 is a great framework in addition to GoogleTest and Doctest. 
https://github.com/t0rakka/mango/commit/8116f9dafaaddc33bb851842bb72a0c1c8ba388c 
OK. Feel free to file an MR to add a Nixpkg recipe to the repository (please file it to the `docker` branch since this is really the "preview deployment" branch). This has all of the build instructions in there and just need ported over to a Nix recipe.
MSVC implements Annex K, including memset_s
Is this some random twitter user quote lol. Fucking ouch.
I once suggested a similar approach at work to replace our system of C-style unions for kinematics and typedef'd doubles for units and had it shot down because we're so deeply invested in legacy code. People make mistakes all the time and if there's not a visual output directly tied to the computation they can go undetected for years.
This got longer than I wanted but I'll go with it. I have a pretty strong math background compared to most of the CS majors I went to school with and work with now who talk about how much they hate math whenever it comes up. I've noticed what you're talking about too and I think it's a personality type that makes C++/math/engineering appealing and tolerable more than the subject knowledge itself being important. I don't know if you'd need any special background to learn C++, but I think I'm more interested in conceptual knowledge than other programmers I know. I learned C++ by alternating between reading C++ books and working on projects. A surprising number of web developers I know have a more ad-hoc style of learning new things where they immediately try things and Google individual problems until things seem to work, then they just move on since they're only interested in the end product. They often don't seek out conceptual knowledge so they learn the 'why' behind things through happenstance. While you need to experiment sometimes, I think using only that style of learning is inefficient for C++ and the fields it's used for since you'd miss a lot of subtle problems that'd be hard to diagnose if you have weak conceptual knowledge of why things work the way they do. I can't imagine learning concurrent programming in a totally ad-hoc way. Not all web developers are like that, but a ton of people in my college's CS major really only cared about the end product whenever they programmed and weren't all that interested in CS itself. The couple people I remember who were interested in CS itself had natural science minors, never complained about math and mostly programmed in C or C++ and Rust. But maybe I'm biased towards that view.
catch2 was great for me but it has definitely grown into a very bloated mess as of recent and now it looks like it won't be a header-only library which will basically make it as painful to use as our previous unit testing framework CppUnit. I'll give your library a try and hopefully it will stick to being a very lightweight header-only library.
here is [an insightful comment thread](https://www.reddit.com/r/programming/comments/b4jzsg/doctest_the_lightest_c_testing_framework_version/ej7ffpr?utm_source=share&amp;utm_medium=web2x) on the implementation differences between Catch2 and doctest.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b4lysi/what_to_learn_after_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I want to make games and its the industry standard
It will stick to being header-only and light. One thing that might happen is the development an extension header which is free to include STL headers and provide useful functionality (not allowed in the main header).
I think the mentors are people familiar with the code base who are responsible for guiding the Technical writers through it?
With WebAssembly you can use C++ for web frameworks. WebAssembly is still pretty new, but as it matures and there’s a better ecosystem for it this will become more widespread. 
You should read modern c++ programming with test driven development (https://www.amazon.fr/Modern-C-Programming-Test-Driven-Development/dp/1937785483) it’s a nice book that takes you step by step into TDD’s philosophy with concrete C++ codes
so looks like the copy constructor is the problem https://godbolt.org/z/1iKjd7
Try starting with Catch2 (https://github.com/catchorg/Catch2). It’s a header-only library, so it’s easy to get going with. Whichever test framework you choose, put the test headers in a precompiled header, if you can. You get a much faster turnaround. And then pick a problem! Try googling for code katas. There are loads of interesting ones. For TDD itself, write a simple failing test, then write a simple bit of code to make it pass. Then add another test, and repeat. TDD is a code and design practice, rather than a testing process, and it can take years to get good at it. But it’s easy to get started. Good luck!
Yea that could potentially be it (or a part of it). The left side of one of the docs pages linked above says \&gt; Apply to be a mentor organization and help bring experienced, excited technical writers to your open source community! So it seems like part of (or the main part of?) being a mentor organization is that technical writes will get "assigned" (?) to your project/organization and they subsequently improve the documentation of your project, with your (the mentor's) help? But oh well, totally agree it's not too clear at all... :-)
I know, oh man.. I have the low-level API to pass the rows as individual arguments: static inline float4x4 transpose(float32x4 m0, float32x4 m1, float32x4 m2, float32x4 m3) Then wrap this with convenience: static inline float4x4 transpose(const float4x4&amp; m) { return transpose(m[0], m[1], m[2], m[3]); } Compilers can be evil. I been thinking: if Rust, or whatever, can pull this off w/o all these hoops I might be tempted.. On the bright side, compilers are getting there.. at least we can get good results with right amount of vigilante.. :D 
wxWidgets, especially if you want small, self-contained, statically linked executable (impossible with Qt unless you by the commercial license).
Forever.
The conversion to function pointer is a special case that only works for lambdas that do not capture anything. 
yes I know. I was unaware that the converts function pointer is valid for the life of the program.
That's because the compiler decides to not create a functor object out of the lambda and instead made it a regular function which can be passed as a function pointer: https://godbolt.org/z/MjaIOF
Nice. Does it also produce code coverage output that can be integrated into SonarQube?
&gt; it matters to the end user. It definitely matters enough for them to pay out the nose for it. &gt; data is growing faster than computer power Another interesting side of this is deployment. If you're in any kind of safety-critical or minimal downtime environment, replacing hardware is an absolute _bear_. It requires technicians, backup units, and measures and topology considerations to reduce downtime. The expense is immense. Many software deployments can be the work of a small team, with less specialization and without disturbing the networking.. So because the returns are diminishing and the expense is so high, many customers will do almost anything to avoid having to purchase new hardware. This is where I think C++ wins out in comparison to newer things like Rust - platform support. Rust is great - if you're on x86 or newer ARMs. Everyone else is in a bind, because these new languages are tied to compilers that don't seem to really care about adding support for old hardware. Our hardware is over a decade old and we've been able to follow along from C++98-&gt;C++11-&gt;C++14 and 17 is on the horizon. The larger C++ community seems to really care about keeping code written for older platforms working. Which to me is exceptionally ironic for some of these newer languages stated goal. The old embedded platforms are usually in places that need far more safety guarantees than many of your your new systems. 
I learned in 1993. So, providing language features that would allow me to keep using features that I was used from Turbo Pascal 4 - 7 / TPW 1.5, having the means to put a safety jacket on C, while being portable to the same platforms. Personally I don't care about zero cost abstractions, yes they are welcome, however for me safety trumps performance. Nowadays for me it has been downgraded to the Java/.NET/Node companion, as I no longer do complete applications 100% in C++.
My solution is not hierarchy at all. One exception class serves me perfectly well, and there's none of the silliness that comes when you have to catch a bunch of different things separately. My scheme is that each library/executable has its own errors, and it throws them along with its own identity, via a single exception class that knows how to load loadable text from the throwing module (so it can auto-load the text and do token replacement all in the context of the throw command.) If you really need to check for a specific error, there's a method on the exception class that lets you check, is this error X from module Y. It also includes an error level (warning, fail, etc...) and an error class that allows you to often not have to bother checking the specific error, .e.g. is it a lost connection error is good enough to check for the socket to have lost connection. And it includes a simple stack trace. Each catcher can add his own file/line to it and re-throw. That's inherently platform independent and light weight and doesn't depend on any symbolic information being available in the field. &amp;#x200B;
It's rough. You have to get a job at a company big enough to have compiler teams. And from there you have to have the requisite knowledge to work on these teams. Take a few systems engineering courses and a compiler course and then download clang + llvm. Find something to start looking into. e.g. `clang -g test.c -emit-llvm -S -o test.ll` and maybe try to find what chunk of code is responsible for creating this. e.g. just find the class and the properties that correspond to the text emitted here. !8 = distinct !DISubprogram(name: "main", scope: !1, file: !1, line: 1, type: !9, isLocal: false, isDefinition: true, scopeLine: 1, isOptimized: false, unit: !0, retainedNodes: !2) Also, look at the Kaleidoscope tutorial series in `llvm/examples/Kaleidoscope/`. Go through it a few times. Figure out some ways to add features or improve it. That being said, it boils down to luck. I joined a team as a general purpose systems engineer and some months in they ended up needing help with toolchain related stuff. I got pulled into working on a few things that were close to the compiler and over time ended up working on the compiler proper. So my path was raw luck. It wasn't my goal, I just had the right skills combined with the right opportunities and was on a team with the right needs. Eventually find some chunk of code you find fascinating and ask one of the guys on the git blame if they can point you to some beginner's tasks related to it. Many of the people who work on these projects are super friendly and enjoy helping others. 
compilation times are specifically why I use doctest, and also why I dislike header-only libraries in general. I'll use them, but 9 times out of 10 I'll take the library that's not header only.
Templates and metaprogramming. You can make your programs do stuff before they even ran! 
in reality doctest isn't header-only - it's composed of [these 2 files](https://github.com/onqtam/doctest/tree/master/doctest/parts) but it is an exception for "header-only" libraries indeed.
&gt; and now it looks like it won't be a header-only Where did you get this from?
I'm left with the impression that code coverage is generated with other tools such as gcov or OpenCppCoverage and that is orthogonal to what a testing framework is supposed to do. doctest is just a library - it does not deal with build systems and toolchains. But if any of the coverage tools integrates nicely with SonarQube - then there should be no problem using doctest as the testing framework.
https://codingnest.com/the-future-of-catch2/
I use this all the time for small projects controlling instrumentation. I can create a working app in 5 days. The new compiler is slower than previous c11 compiler, but still beats Qt imho. I am not sure how well it would work on a large codebase. 
No, but it does help mitigate vulnerabilities caused by those bugs (data leakage, etc.).
Can we ban image-only posts?
&gt; That's irrelevant. His point is irrelevant, so I don't need to "erase" it. Compilers are better at it, end of story. False. People that really know their way around assembly can provide better performance than an optimizer, the same way special optimizers can. Whether we do care about that delta, is another question. &gt; The cases where humans still have an "edge" is choosing specific instructions for doing high level algorithms that have not yet been embedded into compiler consideration, such as using SIMD instructions for UTF-8 text processing. And that edge will soon disappear as that makes its way into compilers and libraries. That implies we will get algorithms that do so. For non-trivial problems/loops/etc., it isn't an easy task at all. That is the same promise as Itanium, and see where we are. Then there is the fact that it is extremely hard to predict what is the best approach for a particular architecture/model/load until you actually measure it, and the manufacturer won't give you details either; so an optimizers cannot do an optimal job to begin with. So, no: if you are desperate for performance, an optimizer isn't what you should be looking for.
&gt; No one cares why compilers outperform humans. All that matters is that they do. Except the hundreds and hundreds of people in CS research, supercomputers, compiler writers, ...?
&gt; It definitely matters enough for them to pay out the nose for it. Which, I have to say, is *quite convenient* for us... More fun writing performant code, anyways. I'll admit what I've been dong isn't super critical, at least in most applications I'd imagine, so I haven't really felt the same pressure. &gt;This is where I think C++ wins out in comparison to newer things like Rust - platform support. Rust is great - if you're on x86 or newer ARMs. This is definitely a bit funny. Backwards compatibility is *so huge*. Although it manifests differently for us - our application is still compatible with custom 'workspace files' that users were creating in the mid 90s. I couldn't agree more with your analysis. C++ is in this magical world of somehow still working like it used to (mostly backwards compatible) but also having the features, usability and support of a modern-ish language (unlike other languages that are still around like COBOL... or so I would imagine, can't say I know COBOL so...) The fact that it can compete with Rust in a lot of ways is remarkable given how old the language is and how much it does, and its history. Can't say I see C++ going anywhere anytime soon. And I guess worst case scenario it will always hold a place in our hearts &lt;3
He/she did write "*and nothing else*", though. If the time invested is not important enough compared to the rest, it does make sense to optimize further by rewriting in assembly. Of course, that does not mean it is the right choice for the vast majority of the code that gets written.
Don't you just hate that? :p I've had many a "brilliant, innovative idea" shown up by someone else.
Being not header only is a change I welcome for most header-only libraries out there. Header only and “lightweight” are absolutely not synonyms. 
is that guaranteed by the standard?
I agree sometimes I do want performance, but to me most of the reason I use C++ is correctness. If you take a look out there there really is no other top tier (in usage) language with a static type system that provides the the encapsulation tools that C++ does. There are better type systems out there (Haskell), but no one uses those languages.
I wanted to contribute to KDE, so I had to learn C++. It was totally worth it, 10/10 - would do again!
When people giving advice say never they mean almost never. It is just something you have to get used to, if not you're going to have a rough time at life...
Effectively yes. The standard says that the conversion operator returns the address of an invented function that does the same thing as the call operator if the lambda. (http://eel.is/c++draft/expr.prim.lambda.closure#7.sentence-3)
You can read the actual (draft) wording in \[expr.prim.lambda.closure\] here: http://eel.is/c++draft/expr.prim.lambda.closure#7
It means the feature will first be published as part of the the Library Fundamentals Technical Specification version 3, and subsequently merged into a revision of the C++ Standard. Given the timing, that revision will almost certainly not be C++20, but more likely C++23.
I’m on mobile so I can’t go standard-spelunking to be sure, but I would expect a 0-sized lambda (with no captures) to be safe to invoke via function pointer with no regard for lifetime concerns. I’m curious: say your lambda did have captures, but the code segment doesn’t refer to those objects, I think it would still be safe to invoke a function pointer to it. Speculation: I don’t think code segments have a lifetime, so a function pointer would always be valid, assuming you’re not dealing with DLLs etc. If I’m way off someone please correct me.
&gt;At some point in your curve/surface, the right decision is to optimize it further by rewriting in assembly. &amp;#x200B; I'd rather massage/coax the compiler into giving me nicer assembly. Rewriting things in assembly should be really a last resort.
[https://www.vim.org/scripts/script.php?script\_id=3302](https://www.vim.org/scripts/script.php?script_id=3302)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b4g6b3/new_to_c/ej89p2n/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm inclined to let this one stand as it's generated some interesting discussion, but future examples won't be looked upon kindly.
Nice job taking a sentence out of context and arguing something completely irrelevant.
My professor made us use C++
I went with GTKMM because I wanted to write my UI in c++ not qml.. fun choice, the entire documentation portal broke over 8 months ago and people have been BEGGING on the mailing list to have access SO THEY CAN FIX IT THEMSELVES, just being totally ignored gnome doesn't give a shit about GTKMM, probably don't go there. 
I am also inclined to permit this - an occasional request for volunteers, for a popular project, with some time-sensitivity, merits a standalone post. If the subreddit were drowning in this stuff then we'd need to do something else.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b4mzco/lifetime_of_lambda_cast_to_function_pointer/ej8a8tl/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I mentioned SIMD as one of the exceptions in my other replies. Read.
If you develop on a fixed or small set of similar platforms then sure adding a build step for every library isn't a big issue. When you need to write libraries that can be built or cross-compiled to/from Windows, Cygwin, Linux, Mac, mobile platforms, game consoles, then you basically have little choice but to use header-only libraries. The only C++ libraries I've ever used that made a conscious and successful effort to build on pretty much most platforms including mobile are Qt and boost, and most of boost is header-only anyways and Qt is still a huge pain to get working on many platforms. I can't name a single other widely used C++ library that actually bothers to ensure it will work on a variety of platforms.
coc.nvim + ccls is as good as any IDE out there. 
&gt;But the argument is about how to get the most computation out of the least amount of electricity ONLY, where nothing else matters. Given that argument, Assembly would be the programming language of choice. Then the argument is stupid, because there is no case where "nothing else matters". Because even if you only care about performance and nothing else, you still have to care about at least one more thing: correctness. So you can keep trying argue that ridiculous simplification just to win debate points, or try to understand that even theoretically, you can't have only one thing matter. I won't be surprised if you come back and try to argue that in your theoretical argument, not even correctness matters. &gt;but what is theoretically possible. Ah, the classic nerd tactic. When you have no argument, be as ultra-literal as you can and try to win on a stupid technicality. Okay, you want "theoretically"? Okay. Compilers are improving at great rates. We may even get some kind of AI to do it well. We know that some of these evolutionary techniques are capable of finding flaws in a CPU and generate ridiculous code that happens to exploit those flaws which confound humans but does the job faster than the "correct" assembler. What's a reasonably sized program for a human to conceivably write in assembler? A compiler. Okay. Let's race, in your theoretical world. We get a team of humans competing against a team of compiler writers. The humans have to write a compiler that beats a compiler. Who will win? How fast does a compiler improve? How fast can humans improve? By the time the humans improve, and improve their assembly, the compiler writers would have also improved the compiler, and used the compiler to compile an improved compiler. How fast can humans play catch up? How long can your theoretical humans live? Let's play your game. Infinite time, infinite energy, infinite lifetime. This is all theoretical, after all. A compiler written in a compiled language improves exponentially. A compiler in assembly improves linearly. And improvements discovered by the assembly writers would make its way to the language compiler. How long, given infinite time, energy and lifetime, does it take the human linear curve catch up to the exponential compiler curve? Do you want to argue against mathematics? You wanted to argue theoretically. Can't get more theoretical than comparing a linear function to an exponential one. I'd love for you to argue that a linear function intersects an exponential one for a reasonably large x, given an inifinite x-axis. &amp;#x200B; Theoretical. Pfft.
I couldn't find it in VS 2017 or on docs.microsoft.com. I was surprised when I first tried looking it up. I suppose 2019 RC might have added support but I don't have that on this machine to check.
I develop for linux, windows, mobile, and every game console out there (except the handheld ones). Platform independence is completely orthogonal to header-only, and is a conscious effort by the original developer. Many of them still need to juggle platform specific includes and all that jazz; nothing about being header only vanquishes those problems. As for compile times, even if templates are heavy, why do I want it to be worse. Even catch2’s header conditionally defines a translation unit already. Why not just make that unit a file as god intended instead of needing to include it with a special define. Setting the library up right makes the source code easier to understand, promotes more logical separation of declaration from definition, and gets rid of needless parsing, not just for the machine, but for the human as well. People that embrace header only are, in my opinion, the vocal minority that found a local maximum, and really just need to suck it up and learn how to work with actual cross platform build systems (aka cmake) and move on with their lives. 
&gt;That implies we will get algorithms that do so. For non-trivial problems/loops/etc., it isn't an easy task at all. That is the same promise as Itanium, and see where we are. Compilers can make the SIMD instructions accessible as builtin functions. From then on, the human programmer only needs to call these functions, without ever having to dive into assembly. So, not very trivial. In fact, we already have it: OpenCL, CUDA. &gt;Then there is the fact that it is extremely hard to predict what is the best approach for a particular architecture/model/load until you actually measure it, and the manufacturer won't give you details either; so an optimizers cannot do an optimal job to begin with. So an optimizer cannot do an optimal job because they don't have enough information, so a human can do a better job without that information either? Right...
Wrong. A compiler improves at a much faster rate than humans. Given infinite time, energy and lifetime, humans still can't catch up to it. By the time humans can write a reasonably complex program in assembler that beats a modern compiler at some version, the compiler would have already gone through multiple versions and generate much better code again. In no universe does a linear function catches up to an exponential function for reasonably non-small x.
Fair enough, name some C++ libraries that you feel cross-compile to/from Windows both 32-bit and 64-bit and using either dynamic or static runtime libaries, MacOS, Linux, Android/iOS and I'll give it a shot right now. &gt;People that embrace header only are, in my opinion, the vocal minority that found a local maximum, and really just need to suck it up and learn how to work with actual cross platform build systems (aka cmake) and move on with their lives. You claimed you develop for mobile but then you mention using CMake... CMake doesn't work for iOS, someone tried to add a toolchain to give it iOS compatibility but that hasn't been maintained and is no longer supported.
The ios toolchain is now built in but we rolled our own. As for libraries... where do I start. What domain are you in? I feel like most libraries I need to integrate don’t require any additional whiteboxing. 32-bit and 64-bit is also rarely an issue and again orthogonal to the notion of “header only.” The burden of proof is for you to explain first how header only correlates to literally any of the concerns you’ve brought up regarding cross platform deployment. 
&gt;How do you claim that a human programmer cannot identify these optimization opportunities? And they'll implement those optimization opportunities... *in the high level language that the compiler is written in!* You seem to have misunderstood the argument. We're not talking about humans vs computer at programming. We're talking about humans writing assembly vs humans writing in a compiled language to generate assembly. &gt;Can you tell me why a compiler might want to use dynamic programming when evaluating AST generated from expression? Any argument why you might want to use some other technique instead, if so, why? I don't understand the point of these questions.
Ha nice
That's a damn shame. It only ended up getting implemented where I work because for about a year I had more or less free reign to overhaul our APIs as I saw fit. People don't appreciate how much cognitive load it removes from development until they've actually experienced it first-hand, it seems.
&gt;As for libraries... where do I start. By naming them.
Didn't the current maintainer of Catch2 recently put up a blog post indicating that they'd also have a non header only mode?
https://en.cppreference.com/w/cpp/container/vector/push_back Doc says iterators are invalidated if memory reallocation happens (and that past-the-end iterator is always invalidated). What you're doing is implementation dependant and a bad idea™. Why don't you just keep track of vectors size instead?
It’s not implementation dependant. I’m not talking about std vector’s iterator, I’m talking about my custom ‘safe’ iterator.
Thanks. I'm a bit new to vim: how do I get this setup?
Is there an easy guide on how to get this configured?
I love when people vote me down because they can't argue against mathematics.
Since it's your own implementation, it's fine for both. But I suggest keep the `end` iterator still the `end` after the push back, since you want the iterator validated after the insertion.
&gt;C++17 almost feels like writing really fast python. Would C++20 make this experience better? 
Don't mislead C++ newbies that C++ is only about performance, and that's not the excuse not to make C++ easier to use. Also, performance heavily depends on the algorithm than the languages. A bubble sort in C++ may be slower than quick sort in Python (just an example, no data). 
I’m fine with both behaviors, my question is more about the correctness of the current behavior. When most people think of a past-the-end iterator, do they expect it to always be a past the end iterator even after insertion? Would my current implementation be perceived as bad by other programmers? That’s what I’m worried about.
Assuming the `Foo` your iterator has is of type std::vector&lt;T&gt;*, then your implementation sounds fine to me. For a vector, I would not expect std::vector::end to remain the same after an insertion, so I think its fine if an old "end" iterator is no longer the actual end. Just note that your iterator only really works with sequential containers (see https://en.cppreference.com/w/cpp/named_req/SequenceContainer). Other containers (like std::list) are expected to have their "end" iterator remain the same after an insertion.
Thank you for your answer!
&gt; Compilers can make the SIMD instructions accessible as builtin functions. From then on, the human programmer only needs to call these functions, without ever having to dive into assembly. So, not very trivial. That is exactly the same as programming in assembly. So, no. &gt; In fact, we already have it: OpenCL, CUDA. Not at all. Accessing individual instructions has nothing to do with OpenCL and CUDA. They are way higher abstractions. &gt; So an optimizer cannot do an optimal job because they don't have enough information, so a human can do a better job without that information either? Right... You are the one that claimed that we don't need humans anymore writing assembly because we have "compilers that are better at it, end of story.", not me. :)
&gt;That is exactly the same as programming in assembly. What are you talking about? Yeah. Just like writing std::copy is the same as writing memcpy is the same as writing assembly. &gt;Not at all. The former has nothing to do with OpenCL and CUDA. They are way higher abstractions. Yes, the are higher abstractions. That's the point. &gt;You are the one that claimed that we don't need humans anymore writing assembly I did not make that claim. Quote me where I made that exact claim. &amp;#x200B;
coc.nvim in Vim 8.1 blocked input for me when I tried editing a large-ish CPP file (~12k lines). Cursor was blinking, but no keys could get through. This is without any language server set up, just basic completion from text in the current file. In smaller files, it didn't do this, but I recall it feeling a bit slow, and that the completions offered weren't great (possibly, it needs a language server to really shine, idk). I use YouCompleteMe without C++ semantic completion these days. In contrast I find it's very fast and the completions offered are good. I tried getting C++ semantic completion set up, but libclang or whatever wasn't able to compile my project. I think the switches I provided were all correct, but idk. It's an old codebase built with MSVC which has quite a bit of non-standard behaviour.
If a library compiles on a given platform has absolutely nothing to do with it being header only or not.
I am not trying to argue that a library has to be header-only to compile on a "given platform". That's absurd and I have no idea how you came to that conclusion based on anything I said. I could absolutely pick an arbitrary platform and write a library to compile on that specific platform. The argument is that in order to compile on **every** platform, being header-only is a hard prerequisite. There is absolutely no way to write a C++ library that can work on every single platform that has a standard conforming C++ compiler if that library requires a build step. That is an objective and unavoidable fact that is fairly unique to C and C++.
I would imagine so, but I haven’t really played with the new C++20 features that much yet. But all of the automatic template deduction stuff in C++17 makes it feel almost a little strange how easy stuff can be.
&gt;The argument is that in order to compile on every platform, being header-only is a hard prerequisite. No it is not and I was not talking about a single platform. The general question if code A will compile on any platform X is completely unrelated to the question if that code is put only into headers or split between headers and source files. I can write a header only libray that will only compile on a single platform just as easily as I can write a classic library that compiles on any platform with a conforming c++ compiler.
I use it daily on a project with &gt; 3 million lines. It takes quite some time to index the entire project but after that it is very performant. 
I assume you are writing an application consisting of multiple source files for multiple different target platforms correct? Why would it make any difference if you had to add a few 3rd party source files from a library foo to your buildscript?
You are making a basic fallacy. I am not saying header-only libraries is a guarantee that it will work on all platforms, I am saying it's a necessary but insufficient condition. If your library requires a build step, you have already limited your library to a fixed set of platforms. But of course I can write a header-only library that works only on Windows or for a specific compiler, that's trivial and at no point did I make any such claim... Without knowing specifically what argument you're trying to advance I'm not sure this discussion will be particularly productive as it seems based on the lack of specifics you're only arguing for the sake of arguing.
You seem to be keen on misinterpreting my posts: All I'm saying is that header only is NOT a necessary condition. 
&gt;Why would it make any difference if you had to add a few 3rd party source files from a library foo to your buildscript? Because they don't exist. I asked the other guy to name some libraries that will build on Android, macOS, iOS, Windows 32/64, etc... and his answer was basically to tell me to go fuck myself.
Then we'll continue misinterpreting one another. You say it's possible to distribute a library that's cross platform that involves a build step, I say it isn't... If you have an example of a widely used C++ library that I can go ahead right now and build on the platforms I mentioned I'd love to give it a try.
You are aware that e.g. catch2 is nothing more but a classic library, where the source and the header file are merged together and depending on the preprocessor macros you put in front of it, you are getting one or the other? There would be absolutely no difference if it would ship in two separate files. 
Interesting. Do you use neovim? Linux? Since I'm running vim on Windows, I was thinking that either of those things might have been the issue. I might give it another try in the future, but YCM works for me right now.
I work on all of Linux, Windows and macOS using neovim + coc.nvim + ccls. It works everywhere just fine. 
my condolences.
Lol, your comment above says that your application uses electron. Developers use it for a reason.
I use youcompleteme and I've been happy with it 
YouCompleteMe is great but installation of it is a complete pain in the ass. The official instructions don't work, so Google around for other people who figured it out. 
What is your prior experience in programming?
I'v taken intro to programming and object oriented deisgn in school but got D's in both because at the time I was a slacker and didn't care. I have very BASIC knowledge of programming, but I basically dont know any syntax, and id have to google everything to write any lines of code. 
Well, Bjarne Stroustrup's *Programming: Principles and Practice Using C++* is supposed to teach beginners how to program with c++, so maybe you'd have luck with that? Personally, I've just picked up c++ as I go for the most part and also used to watch some podcasts on modern c++ features.
I'm interested to learn audio programming. My first stop was Rust because at that time, C++ looks scary. But later I found that the community is more driven towards cli, web, and game development (in that particular order); none that I actually care about. There's not a single mature desktop UI and audio-related crates. 6 months gone for nothing. Then I found Qt, JUCE, and C++ Primer. C++ reminds me of Java; everyone seem to hate it but it gets the work done. To sum up, I like C++ because it does what it promises without too much gimmick. I have a lot to catch up but again I'm still young so its not too late. 
r/gatekeeping
I'm loving Qt so far. It's just such a speedy and robust UI framework.
You could use `myCustomObject.size()` instead for this purpose: auto oldSize = myCustomObject.size(); auto theResult = doSomething(); if(oldSize == myCustomObject.size()) /*doSomething() didn't insert anything in myCustomObject*/ else /*doSomething() inserted something in myCustomObject*/ If there are no other specific requirements for this design, it would be more intuitive for properties of `end()` to be similar with those of `vector::end()`. *This would be better in my opinion*. This is your custom container, so it wouldn't be incorrect either way as long as it delivers what it promises.
Yup! It feels like JavaFX without JVM bloat.
You can implement it like that. make a template class for iterator, make member a pointer to container (const or non-const depend of iterator type) also hold size\_t for current index , then you make that check safe. So current size of end will be container size, after you insert / delete operator == will check that size is same. Also when you insert / delete to container you can easy obtain stl iterator under-the-hood and perform operation also to update current index as well. &amp;#x200B;
I know the reasons, I just hate it. Right now, between CEF and Electron, on my *home* machine, which I also use for work from home, I run the following copies of Chromium: * Opera * Spotify * Slack * Microsoft Teams (can you smell the corporate hell I am in?) * Steam * Battle.net * Epic Launcher (I am lucky I do not play EA and Ubisoft games, as I am sure they have their own Electron based launchers) * Viber * Skype (but I run this shit on demand) Each copy is at different version of the framework, each spans gazillion processes (which is ridiculously expensive on Windows), each takes ridiculous space on my SSD (even today, buying an SSD is expensive), and each starts its memory usage from 200 MB. I know the stupid adage "if you have unused memory, you have paid for something you are not using). The problems is, I want this memory to go to whatever I need on the **foreground**, like the game I play, and not on background utility programs. However, there are more *nefarious* issues. All these programs (even the ones made by Microsoft): - have own UI and UX. Knowing how to use Steam does not automatically grants me muscle memory how to use Spotify. This is shit on Web already, but for desktop app is abomination. - Breaks subtle flows because they have to reinvent every UI component. Menus on Spotify and menus on Steam work differently. Really? - Some of these programs are not even cross-platform, to begin with - Their integration with the rest of the ecosystem on my desktop is abysmal. They are isolated islands amids all other programs which work cohesively together All in all, total shit :) 
&gt;in order to compile on every platform for which a standard conforming C++ compiler is available, being header-only is a hard prerequisite. That is an objective and unavoidable fact that is fairly unique to C and C++. This is such a patently false statement, I don't even know where to begin. Being header-only is clearly *not* a prerequisite for being cross-platform. These two concepts have absolutely nothing to do with each other at all. How to *build* a library has nothing to do with its code being cross-platform or not. If library authors don't include build instructions for 'really obscure platform X', well, then this is usually very easy to add by whoever needs to compile for 'really obscure plaform X', especially if there's a well written CMake file. For everything else, there's CMake already solving your problem. Besides, header-only libraries are a terrible antipattern, while cross-platform code is highly desirable.
It's Scott Meyers. So, no, not a random Twitter user.
I agree that single-header-ness has nothing to do with the ability to build code on multiple platforms. If a library is only 1 .cpp file and 1 .h then it is still extremely easy to use (as long as it doesn't come with complex cmake/build-system code which prohibits multi-platform compilation). A single-header library just makes it A LOT easier in terms of integration (just copy the file - and probably there are no build instructions) but says nothing of the constructs/headers/compiler dialects &amp; extensions used in the code itself.
This looked cool until I saw the overloaded the &amp; operator in com::ptr. Noooooo.
"Given enough time", might be longer than the lifetime of a human and longer than it takes to implement those strategies into a compiler, those are at least two reasons, why an argument based on arbitrary long dev time isn't useful
You learn by doing. You clearly don’t work well with a curriculum. Buy a webcam and learn cv; do some simple projects. Write a calibration pipeline from scratch; implement a monocular vio algorithm. 
&gt; then you basically have little choice but to use header-only libraries. That's incorrect. To support any given platform, a code must be able to compile on such platforms. It has nothing to do with header-onlyness or bundled build scripts. If the bundled build script doesn't support your exotic platform - you're required to embed the third party into your build process. It's highly unpractical to burden the majority of users with bloated and outdated build scripts for the sake of business that wants to get full support for free. It's also highly unpractical to burden the majority of users with bloated header-only libraries when one can use a bit of CMake to remove the overhead. Header-only is by no means a long term solution to our problems. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b4sw7v/learning_c_for_robotics/ej97jzc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It is not only about performance, there are some other good reasons for using C++. Among other things, obfuscation of proprietary algorithms or commercial library; one the few choices available for embedded or real time systems and direct access to the operating system C-API. 
I can do that, but I also often need to call a erase method on my object , and it takes iterators as parameters. So, using iterators often gives me more concise code.
I think `end` should remain `end` or be invalidated. This article https://en.cppreference.com/w/cpp/container mentions what happens to different `end` iterators from standard containers after insertion.
&gt; Yeah. Just like writing std::copy is the same as writing memcpy is the same as writing assembly. You are mixing apples and oranges. &gt; Yes, the are higher abstractions. That's the point. Your original point was that OpenCL and CUDA were similar to using builtin functions. It is the opposite point. &gt; I did not make that claim. Quote me where I made that exact claim. I actually *quoted* you.
Yes.
Yes.
It looked to me like you think the final compiler has been written and that they cannot be improved anymore at all. Now what would be the point to improve a compiler that is already perfect? Now; my premise is that if the compiler is NOT yet perfect then there is room for improvement and so there is room for a human to make a better result than a compiler. I was merely probing what you know about compilers to begin with so that we could have had a more in-depth discussion about the techniques compilers use to transform the user-written expressions into binary code and what trade-offs they have to make to be able to do the work in reasonable time. I have some compiler related work experience from shader compilers at ATI Technologies (before they were AMD) and from Qualcomm Adreno GPUs writing microcode by hand and working with the compiler to generate microcode for the GPU to execute (I was the owner of the OpenGL 1.1 driver for Adreno and it's shader generator). I know where my experiences and opinions related to the experiences come from, so I was just curious where yours came from as they are radically different from mine. You have your reasons to think the way you do so maybe you could explain why you think the way you do, or we can leave it at that if you're not interested, it's up to you. 
tysm also if you have additional information about that i would really appreciate that. and i am using codeblocks i know it wont create a game that's why i am asking you please if you know a software like codeblocks that can help me to create a c++ game tell me, Thanks. regards
tysm also if you have additional information about that i would really appreciate that. and i am using codeblocks i know it wont create a game that's why i am asking you please if you know a software like codeblocks that can help me to create a c++ game tell me, Thanks. regards
Since it's clear from the vagueness of your question that you have literally zero idea how hard it is to make a game... I'd suggest you look into a pre-made engine. Unreal Engine can be worked on in C++, and the slightest bit of tinkering will show you how incredibly out of your depth you are :P
No. But it's not C++s fault, I'm saying _you_ specifically can't. For one, the way you phrased the question implies that you do not have the skillset required to even get started on this, and for two - look at GTA Vs credits. Look how many names there are on that list. If you want to create something "like GTA V" on your own you'll have to do the work of _all_ of those people, and I rather suspect every single one of them is more proficient in their field of expertise than you are at the moment. Your own lack of skills can be remedied by practice - but even if you become the greatest at all game related skills there is, you'll still not have enough time in your life to actually finish something of the size of GTA V. Again - that has nothing to do with C++. I'd bet money that a significant portion of Rockstar's engine is written in C++, but again this doesn't really help _you_ personally do it. If you want to look at what's possible for single developers, games like Stardew Valley or Cave Story are critically acclaimed games made by single developers over several years - if you get _really_ good at a variety of skillsets, that's roughly the ballpark of what you're aiming at if you got at it on your own. (Note that I'm not saying you should get a team together to do it either - managing a team like that _also_ requires skills that you _do not_ have at the moment) 
&gt; "Compilers are better at it, end of story." So it's not end of story after all. Thanks for your time, cya later, dude.
No. If you want to create AAA game, you need tens of millions dollars and not C++.
I know i am fuckin' stupid. But, also i know that it's hard af to make a game with C++. I am a beginner with C++, i did alot of researches to know if it's worthy cus i wanna create alot of stuff with it. I know LUA but lua is kinda limited if you used it before you'll know how limitness is it. Anyway, so I know Unreal engine btw but idk why now it's not working on my computer but i mean a source to test software like ummmm, no one can drag and drop an object in Code::blocks, you can just write and then test. u got it? Also thanks for helping me.
I know it would take alot of effort but:- 1. I can do voice impressions 2. I got millions of sound effects 3. I am already a pro-sound editor 4. I can model/rig objects and stuff also i can animate 5. I know LUA/HTML/CSS3/Markdown/Lil bit of JS/PY and more
Guys i didn't made the goddamn post to make fun of me, i know i am still beginner
Thanks for the tips. Also thanks for givin me depression bro i really appreciate it.
No need to get depressed. Just scale down your expectations by a lot. Before thinking about something on the scale of GTA V, try writing something like Tetris or Asteroids. That is, for now, a much more realistic goal to aim at for you.
alright ty also with the question of the post i didnt mean that i am gonna create GTA v or i wanna create it i just wanted if it's just possible to do it with c++ and i am thinking to start with a game like counter strike 1.6 i guess
Tetris. I'm serious. Try that first.
&gt;I had already quoted you in my previous message. You quoted me. None of those came close to what you're claiming I said. &gt;Your original point was that OpenCL/CUDA were somehow similar to using builtin functions and/or that OpenCL/CUDA are similar to the Itanium promises (not sure which one; but it doesn't matter, both are wrong). No, that's not my original point at all. I'm saying access to special instructions do not, as you claim, require special knowhow for the compiler to optimize for, because they don't need to. All they need to do is to expose those instructions in some sort of higher level API. OpenCL and CUDA being the most apt example, but std::copy using memcpy underneath the covers is the same thing in regards to the compiler opening up the ability for users to specify dedicated algorithms instead of trying to infer from the source.
Another question sorry, should i learn c++ in a specefic way to develop a game ? or it's normal if i learned the basics and the advances of it? like I mean is the basics of C++ \[Game development\] is different than the basics of C++ \[e.g. Printing Text , Variables , If , Functions, Do- while loop, etc..\]
i mean should i learn in a different way if i want c++ to develope a game?
Look for godot engine on google and see if that looks interesting, it uses C++.
It is the end of the story. Because people end up using the jpeg library instead of writing their own assembler for it. You argued my point. Thanks for trying.
alright tnx
alright
Seriously, big projects are always teamwork. Do you have an idea, how many man-hours GTA V took? So it is like - OK, you surely can, it'll take about 50 years judging by man-hours. The tech will not stand still those days, however, so if you want today's GTA V level after 20 years, well, probably you'll be able to make it, albeit still problematic, imo. Practically - forget about AAA. Do something easier, you can cut many corners here and there. Take Unreal Engine, many games with excellent graphics use it. But it goes way beyond your question, better specify more precisely what do you need. But you really cannot do AAA single handed.
&gt; godot engine alright thank you so much
umm alright i already gotcho man , tysm for the tips
The C++ you use to develop games isn't fundamentally different from what you're describing, just that you need to know a couple things in _addition_ for game development. Learn the basics first.
No, basics aren't different for gamedev. Hop onto a game engine of your choice as fast as you can, but be ready to return to some basics setup for learning and testing a lot.
I think it's cute that you have a blind faith in the compilers and am a bit jealous that good enough suffices for you. I tell you what to expect in the future: the more you know, the harder programming will get. You will become increasingly more critical of your and other's work, and saturated by design choices you didn't know even existed before. You're lucky.
alright tysm
What a plot-twist, LOL, assembly code is faster.. thus.. C code is faster.. you should go into Hollywood and write movies. :) 
alright tnx
By your logic, someone writing in C++ is writing in assembler, because all it does, in the end, is call some code that someone else has written in assembler. After all, something like std::copy calls memcpy in reasonable circumstances, which is just nothing more than a compiler builtin that calls the correct optimal assembly. The point of libraries, just as with the point of a high level language, is that the assembly doesn't have to be written from scratch after the first time. At this point, you're just forgetting what the original argument was about in the first place.
&gt;I think it's cute that you have a blind faith in the compilers Nothing about what I just said suggests anything close to blind faith. You lose the argument. Goodbye.
this question is like "can I make a skyscraper with steel? but a really big one, like Shanghai Tower?"
Take Unity and make a Tetris or a Super Mario Bro clone. Then you will know more. Judging from this post, you don't have the knowledge to do a game yet. Take small steps and you will eventually get there. One hint: tools or programming languages are not importanr. You can do everything with everything. But you need knowledge and understanding what you need, and that only comes with experience. And Unity is a brilliant way to start gamedev.
You seem to have forgotten it as well, here's a reminder to keep us on track: "Compilers are better at it, end of story." Here's a revised edition: "Compilers are better at it, until they aren't." and I can guarantee that this is a lot closer to the reality. 
Uh, no. Do you know how threads work? Someone starts a thread, and people replying on that thread is addressing, directly or indirectly, the original post of the thread. The original comment is the argument. By trying to claim that my comment is the initial argument, then you are admitting you are lifting my comment out of the context of the ACTUAL ORIGINAL argument that started this thread. Good job on admitting to dirty debate tactics.
Clangd 8 will be a big update in YCM.
You're years away from being able to write a game in C++. If you're asking questions like this, you have a whole life journey ahead of you. Codeblocks is an IDE, then you need a game engine - some peope write their own, some use off the shelf engines. Then you need to write the game itself. To write the game you need to design it on paper and that's a whole 'nother thing. As I said, given the question you asked I'd say you're years away.
You have repeated your ideological view of the situation, where compilers are at the pinnacle of human knowledge while the ground truth is that it is very HARD to write high level code that compiles well on all compilers for all platforms. This is something I witness on a weekly, if not daily basis. Your views have very x86-centric smell to them; "hardware will run the binary fast no matter what" ; as we both seem to know the fact that the x86 does indeed have abundance of computational resources at its disposal. How many execution ports the latest i9 has? 7? The CPU can theoretically run 7 instructions per clock cycle, one cache miss at 100+ clock cycles means over 700 potential instructions missed if the thread of execution cannot proceed until the memory transaction is visible to the core. In a scenario like this I can see how the compiler can most of the time do "perfect job" as there is very little it could improve by re-arranging or selecting different instructions because the hardware already does rename registers, out-of-order execute instructions, pipelines the execution and so on and on, where the actual bottleneck is dependencies to external I/O, especially memory. I am not disagreeing in this scenario and you make a lot of sense when looking at it from this angle. This is why I know why you think you are "right" and it's the end of the story. But as I said multiple times, this is the naive view. You know enough to be confident that you are 100% correct and there is nothing else. This is amazingly comfortable place to be, because everything is perfect and you know everything. Then you learn more and find yourself in a hard place: you have to make design trade-offs, the more you know, the more trade-offs you have to make as you even know you have these choices to make. You probably have a cell phone. It has a battery. The code you write for such thing should be energy-efficient, something you didn't think about too much in the x86 scene. App developers don't think about it too much, they don't have to. The work I do requires such thinking because the customers actually measure power and have criteria which has to be passed. I worked 10 years at ATI Technologies / Qualcomm as GPU driver engineer and maintained / owned the Adreno OpenGL 1.1 driver writing microcode and microcode compiler related optimizations for it. Compilers were literally my day job for 10 years.. the reason I asked the compiler related question earlier was to probe what level of proficiency you have to talk about compilers. You didn't understand the question, fair enough. The reason I was going to talk about compilers was to establish that they use pre-defined algorithms to transform the expression tree and do instruction selection, and how that works, any why it cannot be perfect. It can be really good but the problem is NP-hard so there is no definite guarantees that you can get a perfect answer in finite time. This is the reason there always will be room for human improvement, it is a mathematical irrefutable fact. I am sorry you got your feelings hurt but you left me very little room for intelligent discourse with your stubborn attitude. I was offering reasonable explanations and all you had to do was to have an open mind. I can't open your mind for you.. years down the road, you will know what I meant with all this. Take care. 
&gt;You have repeated your ideological view of the situation, where compilers are at the pinnacle of human knowledge Is this how you try to win arguments? By putting words into people's mouths? You demonstrate a notable inability to read what I actually wrote and try very hard to twist my words so you can argue a strawman. &gt;Take care. Good riddance. Can't stand people who use dirty debate tactics.
Will the end user see any noticeable changes?
You could tell me what your background is and what experience you have because the way you stubbornly keep claiming "compilers are best, end of story" is not evidence to enforce your opinion; it literally IS your opinion. 
I don't think this is on-topic at all.. :D 
Have you been convicted of sexual assault, because you seem really intent on forcing things into people's mouths?
No, seriously, do you not understand that in internet discus?ion forums, people reply to things in threads? I was not the person that started this thread, so in no way was my comment the original argument. YOU forgot the original argument, which is the comment that started this thread. It's on-topic at the moment because you are obviously incapable of understanding how internet discussion threads work, and that comments do not stand alone. If you want to argue something I wrote, you HAVE to do it in the context of the original comment that started the thread. I really can't believe I have to explain this.
&gt; Have you been convicted of sexual assault, because you seem really intent on forcing things into people's mouths? I didn't force you to write above.. 
Yes and yes. 
Meanwhile, here's some interesting reading on the topic. https://github.com/gergo-/missed-optimizations 
Yeah, and compilers will be stuck that way forever. Whatever will we do?! The sky is falling!!!!
Your claim that the compiler is always better wasn't the end of the story after all. That was the statement you stood behind and it crumbled. I'm OK, thanks for asking. :) 
If you erase much, did you consider using std::list&lt; &gt; ? &amp;#x200B; You could also call vect. reserve( vect. size( ) + 1 ). It guarantees that there will be no reallocation as long as a single element is added. &amp;#x200B; What is returned by doSomething( )? &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
That's what everyone was talking about; compilers aren't perfect and one can find opportunities to improve over their work. Of course it also makes sense to improve the compilers, because we are more productive in higher level languages. We don't write assembler directly; we work on the code generators and try to make them generate as good result as possible. The difference is that I am not absolutist; I don't believe in absolute statements like "compilers are always better", because they are not. 
&gt;compilers aren't perfect I NEVER FUCKING SAID COMPILERS ARE PERFECT. &gt;I don't believe in absolute statements like "compilers are always better", I NEVER FUCKING SAID THAT EITHER, YOU ILLITERATE FOOL. QUOTE ME ONE FUCKING PLACE I SAID "ALWAYS BETTER". STOP PUTTING FUCKING WORDS IN MY MOUTH. I'VE HAD IT WITH YOUR CONSTANT ARGUING OF THINGS I NEVER FUCKING SAID. LEARN TO FUCKING READ AND PISS OFF.
&gt; If you erase much, did you consider using std::list&lt; &gt; ? Iterators will remain valid when you insert. I know, it was my initial choice, but in this case data contiguity is absolutely crucial. (This is a bytecode generator for a virtual machine) So a list, queue or anything like that is out of the question. I don't erase much, and when I do it's only rollback (removing the last N entries, or all entries after a certain point). &gt; You could also call vect. reserve( vect. size( ) + 1 ). It guarantees that there will be no reallocation as long as a single element is added. Not really viable in this case, I don't know how many instructions (vector entries) will be created by a call so I can't estimate that number accurately since it depends on a ton of things (context, values, on-the-fly optimizations, etc). &gt; What is returned by doSomething( )? It's just an example method. In real code, this would be a call to a `gen` function of my bytecode generator (a function that generates VM instructions for a given node). I don't want to make these functions return true/false depending on if instructions were inserted because most callers don't need that information (it's only needed in a few specific cases) and because it would bloat my code uselessly. Also, some of my `gen` functions *need* to return something (such as the register address of the result) so it's simply not possible in some of my `gen` functions. If you want the full story: I needed these features (stable iterators + an erase method) for my "if-then-else" statement bytecode generator. I wanted to know if the body of the else/if generated any instructions (= if `genStmt(stmt-&gt;getThen())` inserted something in the bytecode buffer) so I can remove/recalculate jumps accordingly. (to avoid generating useless instructions) 
Check the "getting started"-guide here: https://old.reddit.com/r/gamedev/wiki/getting_started and also this FAQ: https://old.reddit.com/r/gamedev/wiki/faq Might be helpful. 
You wrote, quote: "That's irrelevant. His point is irrelevant, so I don't need to "erase" it. Compilers are better at it, end of story." Those were your words. However, the latest evidence seems to prove my point that it wasn't end of story after all.
&gt; If your library requires a build step, you have already limited your library to a fixed set of platforms. I am going to tell you a secret that WILL SHOCK YOU! You can provide build steps for third-party libraries using the build system of your choice 😱
It's still considered experimental, so it's an opt-in, but clangd 8 has the ability to index your project, so `GoToReferences` and `GoToDefinition` work across transaltion units. The index is off by default and can be switched on by adding `let g:ycm_clangd_args = [ '-background-index' ]`
I spent quite a lot of time setting up Vim ALE + clangd + bear (to produce compile_commands.json). In general - I see a future in LSP to turn any reasonably advanced text editor into IDE. However, there are few pain points to take into account: - if you think of using LSP-powered setup, there are not that many LSP daemons for c++ currently available. The most feature-full seems to be clangd as of yet. - its pretty hard to setup proper machinery to get good compile_commands.json generated, especially if your native tools do not support that (I have GCC toolchain which don’t), and I used bear tool to generate that for me - Even if you have compile_commands.json generated, complex project structure might still get into your way. My setup includes around 400 repos, non-trivial CFLAGS resolution, etc., you get a picture. I ended up switching back to good old ctags. But I must say, we need a little better tooling support and LSP setup will be really sweet!
Well you never forget your first love ;) 
The installation is actually very simple. The official doc is confusing because it includes two much information without proper organization. This is what I did every time in my Linux installation. 1. Clone repo to `.vim/bundle/YouCompleteMe`. 2. Install build dependencies. 3. Run `python3 install.py --clang-completer` in `.vim/bundle/YouCompleteMe`.
Any reason you can't use a `deque`?
Sounds fine to me. If you have: std::vector&lt;int&gt; vec = { 1, 2, 3 }; vec.reserve(20); std::vector&lt;int&gt;::iterator end = vec.end(); vec.push_back(4); assert(end != vec.end()); assert(*end == 4); the asserts will likely pass on most implementations. Technically it is undefined behaviour, because `end` is at or after the insertion point, but in practice in an unoptimised build the behaviour will be the same as yours. It's hard to make it do anything else if `iterator` is allowed to be a `(char *)`. Since the behaviour is not defined by the standard, you can make your implementation do whatever you want and still be conforming. As you say, the main thing is to document that it is not like `std::list::end()`.
https://en.cppreference.com/w/cpp/container/deque &gt; As opposed to std::vector, the elements of a deque are not stored contiguously Not contiguous.
&gt; &gt; did you consider using std::list&lt; &gt; ? Iterators will remain valid when you insert. &gt; I know, it was my initial choice, but in this case data contiguity is absolutely crucial. I'm not sure I quite understand your use case, but if you want a (contiguous) vector with stable iterators that behave like list iterators (i.e. iterators remain pointing to the same item, not necessarily the same position), there's an implementation of one [here](https://github.com/duneroadrunner/SaferCPlusPlus#msevector). Because it's a vector, `std::distance()` is fast if you want to use it to check whether elements have been inserted/removed in between two specific elements. 
My implementation is similar, except that it's more suited to my use case and my objects. I also have my custom `distance` function that takes advantage of the implementation, so distance is also easy to calculate in my case.
 beautiful ugliness
I would expect the end to stay as end, is weird the think I can store an end iterator and suddenly it's valid. What happens if I have an iterator to position x and insert an element before x?
We'd gladly accept a PR to simplify the instructions. By the way, you can try clangd with YCM - `--clangd-completer` and `let g:ycm_use_clangd=1`
s/tens/hundreds/
Currently I don't insert anything in-between, it's always appending to the data structure. But if that were to happen, the iterators after the insertion point would still point to the same *position*, but not the same *data*. (So an iterator pointing to the 5th element would still point to the 5th element, but the 5th element might have changed)
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b4xf4i/i_have_project_due_tomorrow_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I have electrical engineering background so my first programming language was c, then What I really liked about c++ were the concepts of templates and constructors and destructors.
Every single AAA game you have ever played was written in C++, fwiw (unless you've played really old AAA games, in which case they were written in C and assembler). Remember, AAA is defined in terms of _budget_. GTA V for example cost somewhere north of $250 million, iirc. But let's set that aside, and assume you're asking how to make a low-budget indie game that's similar-ish to GTA and are just curious if C++ is the right tool. The hard part of making a big game has nothing to do with that, though. It has to do with the large amount of very complex code that has to be written, and the complexity is independent of the language itself (you have to write gameplay, physics, audio, AI, graphics, UI, networking, editors, pipelines, packaging, distribution, online services backends, anti-cheat, QA tools, GM tools, developer tools, etc. etc. etc.). And that's just the _code_ - most of the cost of making a big game is in the \_content\_ with all the models, animations, textures, VFX, sounds, music, mocap, VO, UI, and so on. The reason you're getting bad answers to your question is that you asked how to build the hardest thing possible before you've learned how to build simple things. Do you know how to write a Tetris clone in C++? If not, start _there_. Then move on. Make a Breakout clone, then a Pacman clone. Do a top-down bullet hell game. Build up until you can do an old-school Mario or Zelda clone. Then start doing some very simple 3D games (even simpler than Nintendo 64-era games; like, make Tetris again, but where the blocks are rendered in 3D). Build up again. Add sounds and UI to the games you make. At that point, you'll be a well-rounded junior game developer. You'll have the skills and portfolio built up to get a job at a AAA game development company. Which is literally the only way you can possibly ever write a AAA game - with a couple hundred other coworkers all being financed together by a AAA company. :) You might find you don't want to do that, though, and want to stick to smaller-budget games, maybe even stay indie. There's a reason so many ex-AAA game devs go and do that. Now, so far as tools, you don't need much. To make some of those first games - Tetris and the like - you just need an editor and a C++ compiler and nothing else. When it comes time to start using art or sound assets, I'd recommend you start by downloading free assets (or cheaper non-free ones) and just use those. For making bigger games, you probably want an engine of some kind (that already has all the hard rendering, physics, sound, pipeline, etc. bits built for you). If you're set on C++, Unreal or Godot or one of those are good choices (just Google "C++ game engine free"). For simpler games, you probably want a framework like SDL2 or SFML or Allegro or the like to handle all the bits like keyboard input and such. The key thing though is that as you start building these simple games, you'll start learning what you don't know. You'll be able to ask better questions with definitive answers that will help you grow, rather than asking broad questions with simple answers that don't actually help you in any way. (And I'd recommend asking on /r/gamedev, or gamedev.net, or gamedev.stackexchange.com, rather than /r/cpp - especially as this question was off-topic and belonged on /r/cpp_questions anyway!)
I was writing a review for your code, but after seeing it better I've opted for this answer. You're entire project needs to be rewritten from scratch as it has a lot of errors and misconceptions. I highly suggest you to read a good book on C++ and Programming in general. For **C++** I suggest [The C++ Programming Language (4th Edition)](http://www.stroustrup.com/4th.html) I don't know books for programming as I've never read them due to my education in Computer Science.
The behaviour you outlined is exactly what will happen with `std::vector` in the case that the iterators aren't invalidated (e.g., pushing into a vector with enough reserved capacity).
Thanks, I'm glad to know that. I learned from an edx intermediate course and like I said, I've been away for a while. I'll be sure to use that book as a way to learn going forward. I appreciate your response
Newsflash: you are off-topic yourself. 
&gt;https://codingnest.com/the-future-of-catch2/ Note that a single header version will continue to be available. It may have some parts removed (so you might have to include two or three headers in some cases). The world of C++ has moved on since Catch was originally released - and single-header-only doesn't work as well with package managers. We're a way off modules in wide use - but that's also a direction that, along with package management, makes a single-header \_only\_ approach less and less defensible
&gt;goto No.
Lol, yeah I've heard that. I'll avoid using it in the future
If each parser can produce 0,1 or many work items that the main event loop must process, then you probably want a response queue rather than a promise. Depending on the constraints, the main loop can have one queue shared among all (perhaps a priority queue) or there can be one queue per parser (if it’s known at compile time). The latter is nice because single producer single consumer concurrent queues can be implemented lock free.
I don't really understand it, but it looks like you have a lot of comments you should remove: //Add donation CLEANER::ConsoleClear(); AddDonation(); &amp;#x200B;
Correct me if I'm not understanding correctly, but it seems like fundamentally flawed design. A promise should only be set once, so if it can be set twice, there's a problem. You shouldn't try to find a loophole for that, but rather restructure the design. I don't know if promises are really the best choice in this case. As far as I understand, promise/futures should be used to represent a specific calculation that will take some time to complete. I don't think a continuous real-time analyzer should be using promises, but rather it should be using queues. Queues can be used mutliple times, and can still provide thread safety through mutexes. If a given parser can only be used once because it fulfills a promise, and you want to use it multiple times, then that just won't work. In the end, if you're not using promises for their intended purpose, you're going to have to create some spaghetti code and workarounds in order to finagle it the way you want. This will add complexity down the road, and make it harder to maintain and expand the code. Certainly promises/futures are nice and easy to use, but only for their intended purposes. Queues with mutexes seem to get the job done more directly.
You can hardly make it any easier imo... Getting started with the ycm_extra_conf can be a bit tricky I reckon. Is that what you are talking about? 
Only one that actually works. Generating the compile_commands.json with clang as a cmake compiler is a must though 
Just few things more: * find or create a coding style that you like and stick with it * don't use uppercase for anything but macro * goto is not bad, but it's like an "expert" tool, try to not use it if you can * you completely misunderstood exceptions Learning is a long journey, enjoy the ride :) 
I just figured out that was a thing a few weeks back and it's a game changer 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b4uxl9/can_i_create_3d_game_with_c_but_a_really_good/ej9zmz9/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b4xbv5/something_i_made_about_6_months_ago/eja3r48/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What you say here doesn't really make sense. What's suggested here is: 1. Build TF with Bazel. No cmake. 2. Just add the built TF library to your cmake build. If needed, use \`find\_package\` for Eigen/Protobuf. &amp;#x200B;
This is unacceptable. Stop or you will be banned.
Oh nice!! Will use it from now on. Thanks. 
Thanks so much
All iterators at or past the point of insertion are still invalidated even if there is no reallocation.
This sounds good --- do you have any sort of a short guide on how you set this up? Any step by step scripts or lists?
I did this but got an error at step 3, unfortunately. Videos I saw were of people who encountered the same issue. Any sort of a helpful video or guide that you can suggest?
Not really, when I try to create a ycm script to run the build flags that's where I get errors. I'm not sure how to get over this hurdle.
Do you think deoplete would be a good replacement for YCM?
Start with Vim ALE manual here https://github.com/w0rp/ale/blob/master/README.md#installation I used Nix to get clangd running quickly, but you can use any pkg manager for that. Or you can compile it from source, in case you feel particulary adventurous :) In case build tools you are currently using are not supporting compile_commands.json generation (this is requirer for clangd to find include paths), you can use bear (https://github.com/rizsotto/Bear) Thats basically all. There are lots configuration options in ALE to fine-tune for your own taste. Here’s my setup in case you are interested https://github.com/ingarsjekabsons/dotfiles . 
Thanks. I came across this quote and just wanted to know what other people thought about it. Especially given that it is from Scott Meyers. Maybe I could have just framed it as a question I suppose. 
I've never had to do anything more than run `python install.py - - clang-completer`. Have you tried to get help on the issue tracker? 
Man wtf is all of that hh i really appreciate that you took time to write this, i will start to read it now thanks so much man ♥
thanks
alright thanks for the tips
alright thanks for the tips
can you answer my question please?
with just yes or no
?
alright i read all of that, i actually can't thank you enough man ♥ i really appreciate that you understood what i mean and understood that i am beginner and i don't literally mean GTA V, i really appreciate that, again thank you so much man hope you have a good day ♥
&gt; Technically it is undefined behaviour Iterator debugging will catch this: C:\Users\bion\Desktop&gt;type test.cpp #include &lt;crtdbg.h&gt; #include &lt;assert.h&gt; #include &lt;vector&gt; int main() { // The next 3 lines cause assertion failures to go to stdout instead of popping a dialog: _set_abort_behavior(0, _WRITE_ABORT_MSG); _CrtSetReportMode(_CRT_ASSERT, _CRTDBG_MODE_FILE); _CrtSetReportFile(_CRT_ASSERT, _CRTDBG_FILE_STDOUT); std::vector&lt;int&gt; vec = { 1, 2, 3 }; vec.reserve(20); std::vector&lt;int&gt;::iterator end = vec.end(); vec.push_back(4); assert(end != vec.end()); assert(*end == 4); } C:\Users\bion\Desktop&gt;cl /EHsc /W4 /WX /MTd .\test.cpp Microsoft (R) C/C++ Optimizing Compiler Version 19.16.27027.1 for x64 Copyright (C) Microsoft Corporation. All rights reserved. test.cpp Microsoft (R) Incremental Linker Version 14.16.27027.1 Copyright (C) Microsoft Corporation. All rights reserved. /out:test.exe test.obj C:\Users\bion\Desktop&gt;.\test.exe C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\VC\Tools\MSVC\14.16.27023\include\vector(199) : Assertion failed: vector iterators incompatible C:\Users\bion\Desktop&gt; &amp;#x200B;
Fair, very true. Realistically the OP's use of end iterators should be fine in an ideal world, but it's entirely possible a standard implementation's checked iterators might flag and error on comparison of a by-the-standard invalidated iterator, so one shouldn't assume the obvious.
Learn how to write mock objects that stand in for what you would see as a runtime dependencies. Learn how to structure your code so that these dependencies can be injected at runtime. 
Thanks! That's a great help, I'll try again!
Have you tried vscode with vim-plugin?
&gt; A surprising number of web developers I know have a more ad-hoc style of learning new things where they immediately try things and Google individual problems until things seem to work, then they just move on since they're only interested in the end product. They often don't seek out conceptual knowledge so they learn the 'why' behind things through happenstance. This is why there's so much shit software out there. I could go on a multi-day rant about the things I've seen. But it's not just web. There Coldfusion installer currently has a bug in it where the installer just won't put specific DLL's in the correct folder. This bug was introduced when they updated the installer to support windows 2019 (but the bug is confirmed on 2016 as well). I know this because one of the systems I developed and maintain is an automated VPS solution that also offers to install various pieces of software. And they've flat out stated they're not going to fix the bug until the next scheduled release, so no hotpatches, or updated installers for who knows how long. I didn't used to be so bearish on software in general until I wrote that system. The amount of shit I've seen from 3rd parties is ridiculous. &gt; While you need to experiment sometimes, I think using only that style of learning is inefficient for C++ and the fields it's used for since you'd miss a lot of subtle problems that'd be hard to diagnose if you have weak conceptual knowledge of why things work the way they do. I can't imagine learning concurrent programming in a totally ad-hoc way. There's a truism that you need to be able to understand 1 layer of abstraction below what you're working on. Otherwise it's just a magic black box. C/C++ developers tend to have a lower level understanding, which is why they tend to be higher quality developers. &gt; Not all web developers are like that, but a ton of people in my college's CS major really only cared about the end product whenever they programmed and weren't all that interested in CS itself. The couple people I remember who were interested in CS itself had natural science minors, never complained about math and mostly programmed in C or C++ and Rust. &gt; But maybe I'm biased towards that view. this is going to make me sound like an arrogant asshole, but whatever. i think the top web developers are smart and could generally do anything they wanted to. I think the average web developer is less intelligent than the average systems developer. Many of them flat couldn't do the work, even with education. But they're able to get by because of how abstracted everything on the web has become. 
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b4dmgr/what_was_it_that_drew_you_to_c_specifically_over/ejau5pc/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I wouldn't buy into the safety of rust vs C++, that hasn't been proven out yet. A lot of what rust does is more strongly codify what's considered good practice in C++ (but not enforced). for example, you'll see a lot of talk about the unsafe keyword in rust and how as long as you don't use it you're safe. That's not entirely true, because safe code can mutate state that unsafe code uses. For example, imagine a class where you're accessing an array element based upon an index. safe code can change that index to be 1 past the array end, then the unsafe code will blow up. In rust you cover that unsafe part with a module and that module protects the unsafe section with it's life. That's exactly what a good C++ developer will do. It's just that in rust, many times the program just won't compile if you DON'T do the thing you probably should be doing. In C++ it's just something you learn to do over time as you're taught/trained/get experience. Rust has a lot more up front friction in terms of getting the compiler to let you do the things you want to do and it has a build/package system that's miles ahead of C++. But in C++ it's much easier to express your intent. And the while the Rust compiler will often times disallow you from doing things that are perfectly safe (because it can't prove that), C++ rarely if ever has that downside. The biggest benefit of rust in terms of safety is that when something unsafe is blowing up you can generally go right to the source because of the unsafe keyward. And since these unsafe areas should be covered and protected by modules, even if the actual error is in safe code, it's generally going to near the unsafe area. And there's a lot of value in that discoverability. But whatever you do, don't buy into the claims that rust is safer than C++. That may end being true, but rust needs more time and projects before that can be reliably stated.
I have some prototype-quality improvements to the optimizer that fix the performance for these examples, and hopefully for a lot of other cases. There are a few issues caused by some struct variables passed by reference to (inlined) functions, which prevent the optimizer to do proper redundant load/store elimination and dead-code elimination, eliminating those structs and avoiding the heavy stack usage. When will these opts. be released? It's too late now for the 16.1 update, feature complete is this week, so I hope 16.2. There are a few other known weaknesses when dealing with more complex C++ code that will be fixed by new/better optimizations in future updates.
Jesus did that GUI looked horrible :D
If you really care about performance you look for the best performing algorithms for you specific use case, data sizes, and hardware, all of that while running a profiler to make sure you are not fooling yourself. 
You can start by stating what error you got.
&gt; This is why I do not use the package tasks, as I am not guaranteed to produce a return value and this is not an exception. Don't over complicate things. Sounds like you might want to return an `std::optional` type instead, which is the intended purpose for the scenario you described. &gt; Now the problem is that a given parser may be ran twice and thus fulfil a promise twice. This doesn't make sense... why would the parse run twice and set the promise twice? Sounds like you are rolling your own future/promise mechanism which is quite easy to screw up. Just use a package task that returns optional. The main tread waiting for the future then checks the optional, and then gets the value if there is one. Done and dusted.
[Here's](https://github.com/mbise1993/riffbox/tree/master/.vscode) the .vscode folder for a project I've recently been working on (started on Windows then got a Mac so I've moved to that). There might be better ways of doing certain things, but its been working well for me so maybe it'll help you out.
Cheers! Will look tomorrow :)
Performance. Most of interesting high performance tools for data parallel computing are targeting or extending C++. There is really no substitute. It doesn't mean that I like C++. I dislike it a bit less with each improvement and it helps that C++ does get better almost every year. I would love to see that "smaller and cleaner language struggling to get out" Bjarne Stroustrup spoke about. I don't really care about backward compatibility, since most of my work is a research code.
I also have been waiting, for a few decades already. I have high hopes for Julia, but it needs more mature ecosystem.
&gt; Is this a correct behavior for my custom iterator, or should the .end() iterator of a data structure always stay equal to .end() even after insertion? Or maybe it is fine as long as it is documented? Your custom container should document when its iterators are invalidated. The value of .end() should only change when an operation that is documented to invalidate the end iterator occurs.
To be honest I've never heard of deoplete but I'll look into it 
[CNTK](https://github.com/Microsoft/CNTK) is quite usable from C++. It support your requirements of cmake and CUDA.
You want something a bit different than a promise. Wire up a condition variable, mutex, and package. template&lt;class T&gt; struct package { bool ready() const { return has_data; } T get() { auto l = lock(); cv.wait( l, []()-&gt;bool{ return has_data; } ); if (package) { auto retval = std::move(*package); package = std::nullopt; exception = nullptr; has_data = false; return retval; } assert(exception); std::rethrow_exception(exception); } template&lt;class...Args&gt; bool emplace(Args&amp;&amp;...args) { auto l = lock(); try { package.emplace( std::forward&lt;Args&gt;(args)... ); exception = CrlUtils::nullopt; // don't be double-engaged } catch(...) { exception = std::current_exception(); } has_data = true; cv.notify_one(); return (bool)package; } void except( std::exception_ptr eptr ) { auto l = lock(); exception = eptr; package = CrlUtils::nullopt; // don't be double-engaged has_data = true; cv.notify_one(); } private: auto lock() { return std::unique_lock&lt;std::mutex&gt;(m); } std::mutex m; std::atomic&lt;bool&gt; has_data = false; std::exception_ptr exception; std::optional&lt;T&gt; package; std::condition_variable cv; }; I think this is what you want. A `package&lt;int&gt;` is a thread safe depth-1 queue. You can non-blockingly poll `ready()`. It can be extended with `wait`, `wait_for` or `wait_until` if you want. `get` will either return the `T` (and empty the state) or an exception will be thrown. 
What's the easiest way to generate these compile\_commands.json files when creating lots of projects quickly?
I haven't -- due to concerns for privacy, I really don't trust vscode yet, even using vscodium, because I'm not able to tell definitely whether a plugin is using telemetry, even with the global telemetry settings turned off. Is it at least equal to or better than using vim or neovim?
&gt; ycm\_extra\_conf I was able to figure this out and get it to work. I had to completely redo how .vimrc and all the other plugins were structured with a custom script so that there were no conflicts. Now I'm just not just able to get the extra plugin YCM\_Generator to work to generate any ycm\_extra\_conf.py files. I'm not sure how to do that properly. I got it to work by creating one by hand but when creating lots of projects all at once this can be quite cumbersome.
Thanks, I was actually able to get it to work properly. Now I keep erroring out on the ycm\_extra\_conf.py generating step using the YCM-Generator plugin: [https://github.com/rdnetto/YCM-Generator](https://github.com/rdnetto/YCM-Generator)
I was able to get it to install. Now, for the [YCM-Generator](https://github.com/rdnetto/YCM-Generator), here is the error: 'config\_gen.py: error: too few arguments' The documentation isn't really that great -- what would be the proper command? I'm using: YcmGenerateConfig --make make --build-system make --compiler /usr/bin/clang --language c++ --configure\_opts="-Wall" My compiler options are simple: CXXFLAGS := -std=c++14 -Wall -g -O0 -Wall &amp;#x200B;
https://www.reddit.com/r/cpp_questions/
/r/cpp_questions/
Speed and freedom 
Still seems to struggle indexing any of my files that include range-v3. Cquery handles it but the vscode plugin periodically freaks out and causes clang-format to completely butcher my code
\&gt; In real code, this would be a call to a gen function of my bytecode generator (a function that generates VM instructions for a given node) &amp;#x200B; So, this function returns the generated bytecode, and appends it to the vector? If that is correct, you could only add to the vector, and return the number of instructions added. &amp;#x200B; I would use vect. size( ) instead of .end( ). You can check if something was added when the size changes. 
&gt; If that is correct, you could only add to the vector, and return the number of instructions added. No, some instructions (like Jumps) have to be adjusted later, so I need to be able to modify inserted instructions. This is the purpose of the iterator. My builder class creates instructions, appends them to the vector and returns an iterator to the appended instruction. &gt; If that is correct, you could only add to the vector, and return the number of instructions added. Nope, like I said, some of my functions already return something. &gt; Why do you need to check if something was added anyway? To adjust code generation depending on the context: sometimes, even if a tree is not null, it still doesn’t produce any bytecode. (Discarded expressions without side effects, empty compound statements, etc.). Example: Some instructions are emitted before visiting a subtree because they assume that the subtree will generate bytecode (conditional jumps for instance) but if the subtree doesn’t emit anything, they can be removed or replaced by more efficient instructions. &gt; There is something wrong with your code, this usually comes from an earlier conceptual error. Really? How can you be so sure that my code is bad? 
const_await
Set CMAKE_EXPORT_COMPILE_COMMANDS if you’re using cmake.
Can you link to the relevant discussion? I'm considering using gtkmm myself.
I took a class in Visual Basic, then took two classes in C++ and was annoyed that the compiler kept complaining about all the code that wasn't working yet that I planned to get back to, now let me just run the code I want to test, thank you very much. By the end of the C++ classes, I got used to getting code in a working state first, and when I looked at Visual Basic again, I was immediately annoyed that I was no longer getting support from a compiler that could tell me my dumb mistakes before I even ran the code. I was hooked ever since.
Could you maybe explain what the conceptual difference between using the promise/future mechanism and this package is and when/why you should prefer it?
&gt; No, some instructions (like Jumps) have to be adjusted later, so I need to be able to modify inserted instructions. This is the purpose of the iterator. &gt; To adjust code generation depending on the context: sometimes, even if a tree is not null, it still doesn’t produce any bytecode. What is the difference between no byte code, and a bytec ode segment of zero length. Why is special treatment needed? &gt; Really? How can you be so sure that my code is bad? There are inconsistencies in the way of thinking (appending a value to a vector, and returning an iterator to the appended object). I believe that you need symbolic labels. Did you consider using [https://llvm.org/docs/tutorial/](Kaleidoscope)? 
&gt; What is the difference between no byte code, and a bytec ode segment of zero length. Why is special treatment needed? I don't understand what you mean. You're making assumptions about my VM's instruction set and architecture. &gt; There are inconsistencies in the way of thinking (appending a value to a vector, and returning an iterator to the appended object). Why would you consider this inconsistent? I don't see anything wrong with that. It just seems to be a matter of taste. &gt; I believe that you need symbolic labels. Jump to a label, and put labels in the code. Later, the labels can be replaced by true addresses. This would need 2 passes. Why should I do something in 2 passes when 1 pass is more than enough? My solution is fine (for now). &gt; B.t.w. Did you consider using Kaleidoscope. Kaleidoscope is a tutorial. Do you mean, did I consider following that tutorial to build my language using LLVM? Yes, I read it a bit when I started to get into compilers. LLVM is not suited to my use case (but I use a subset of their libraries), it's designed for AOT languages, not for small embeddable interpreted languages. It just seems like you're making a ton of assumptions about the rest of my code and about my whole language, and that you're judging my whole code based on that.
https://mail.gnome.org/archives/gtkmm-list/2018-November/msg00013.html follow this discussion 
My experience with teaching programming to students, is that one must always try to find the reasoning behind the code. If the student cannot answer questions about the design, it usually means that there is no design. 
Thanks. I see that documentation of 3.93.0 (development version) is still broken: https://developer.gnome.org/gtkmm/3.93/
Right now I just feel like you're being condescending, directly assuming that I'm a beginner (I'm far from a beginner) and asking questions not related to my original post. Of course there's no hard feelings! :) If you want more detailed answers, then please ask me structured questions so I can write the answer you're looking for. Maybe I'll find flaws in my current design if you ask the right questions! Also, note that this a +- 12K Sloc project that I've been working on for more than a year, so I can't really explain the whole design just like that.
What is the language that you wish to interpret?
&gt; What is the language that you want to interpret? A language I created, it's called 'Fox'. &gt; To answer your original question: I would give up about using iterators, and use index everywhere. My advice is to write a small index class that wraps size_t. Can be done, but it'd just make code longer and less concise in my opinion. To change an instruction at index `n` it'd have to do `module.getInstrAt(n).Jump.offset = /*...*/` instead of just `it-&gt;Jump.offset = /*...*/`. I don't see why it indexes would be better in this scenario. 
&gt; don't see why it indexes would be better in this scenario. Because they are robust against resizings. What is special about 'Fox'?
&gt; Because they are robust against resizings. I can make my iterator to be robust against resizings if needed, too. My iterator just packs an index + a pointer to the buffer. IMHO the iterator makes code more concise and clearer, and abstracts away the implementation which is always a good thing in case I want to change the underlying container someday. &gt; What is special about 'Fox'? (Note: Fox is *mostly* a learning project, so I'm not making Fox with the idea of making the next big thing in mind. Yet, I'm still developing it as seriously as possible in case it ever takes off or finds a niche). Fox would be a small, statically typed embeddable language. My end goal is to have a powerful FFI and to make integrating Fox in other projects as painless as possible.
&gt; A bubble sort in C++ may be slower than quick sort in Python (just an example, no data). Yes, and a quicksort in C++ may be slower than bubble sort in Python if the container is a vector, the elements are not moveable, and elements have a copy constructor that const references their own container and is n^2 on container.size(). When we talk about performance differences in languages, we're assuming there's a baseline of good data and algorithms.
Have a look at [Armadillo](http://arma.sourceforge.net/)
good luck with your project.
Can you explain why they use `unsigned long` literals in their examples: ``` StaticVector&lt;int,3UL&gt; a{ 4, -2, 5 }; ```
Wouldn't you be better off using a firewall than having to trust any individual app?
I also like for-loops.
And the fact that most programmers (around me) only write "C with classes." Throw a "template" or "const method" in a job interview and you're instantly at the top of the list to hire.
&gt; every ~3 years I'd say 6 years since C++14 is a bunch of bug fixes of C++11, and you can slowly learn C++17/20 at the same time.
&gt;besttopnewcontroversialoldq&amp;a Unfortunately these don't generally have a low or zero mental cost!
how do you decide the size if there are several different types throwed underneath (or in a different compile unit/lib?) in your catch place, all based on a base exception &amp;#x200B; a: base 100 bytes b: base 300 bytes c: base 100.000 bytes &amp;#x200B; lib 1 if(x) throw a if(y) throw b if(z) throw c &amp;#x200B; lib 2 try { lib1 stuff }catch(base&amp; b) 1. you can't know every exception type-size at lib2 2. even if you would know them - it wouldn't be correct to allocated just the biggest exception size (because of size constraints) &amp;#x200B;
If all people cared was performance, they'd pick C.
Or... you know... [ranges::view::enumerate](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/enumerate.hpp)
What I was talking about is that you don't catch by reference but by value, and that you CONVERT (not SLICE) the thrown object to the caught object. That way the catch block already determines the upper limit of what you need: if you catch something that requires 20 bytes to store, you need 20 bytes, and nothing else. If you throw something that is larger, the CONVERSION FUNCTION will need to fold the additional information into the space it has. For example, let's say I throw something like this: class myexception: public std::exception { int linenr; std::string source_file; }; but I catch std::exception. The conversion function could either leave out the linenr and source\_file, or it could add it to the message (for which there is space in std::exception). Either way, we end up with a different exception than the one that was thrown, but since that is the type of exception we are able and willing to handle, that's fine. 
Saying that a programming language is unsecure makes no sense, if you write good code all languages are secure. It's bad programmers that make programs insecure
IMO, I highly prefer to use a sharp knife, I can avoid to cut my hand.
If you want a 1 element queue like the OP does, use a one-element queue like I wrote. If you want a promise/future delivery of a single piece of data ever, use a promise/future. I'm uncertain how to answer your question, other than to define what a one element queue is, and what a single piece of data ever is. 
&gt; These coding languages have the most open source vulnerabilities, according to a WhiteSource report. This is at least well defined even if it isn't an even playing field.
I was working for a commercial RTOS vendor (written in C), and all the best bug reports came from users whose applications were written in C++. I saw programs that really pushed the boundaries, while doing critical jobs in telecom and defense. Nothing else came close.
I agree in principle but there's some things to consider. For example I would consider C (or old C++) a much more insecure language than modern C++ (by some definition of "insecure"). For example it's very easy in C to create memory leaks, write past allocated memory, etc. - you see pointers and "untyped stuff" (e.g. \`void\*\`) much more often than in modern C++, and this is exactly where mistakes and security problems happen. Compare that to \`std::array\`, \`std::string\` or \`std::unique\_ptr\`.
for sure that's true, but a skilled programmer would be able to make a very secure program in C. If someone makes a program with security issues in C, they cant 't go blaming the language for that.
came for overloadable operators and stayed for TMP
I'm surprised that Java is rated so low. Maybe it's just used more often.
We need to put that in C++23 ! ( we couldn't in 20 because it requires modifications to std::pair )
&gt; You say it's possible to distribute a library that's cross platform that involves a build step Of course you can. If you are writing an c++ application from which you could use a header only library then you obviously know how to build a couple of c++ files and link them together. Why should it be a problem to add a couple more source files (comprising the library) to your application's build script (or if you don't use one, just put the additional files on the command line that invokes the compiler? I think what you are mixing is compiled vs header-only libraries and separate compilation (with a custom build logic/custom build system) vs compilation as part of the consuming project. Maybe you are also mixing causality and correlation. And maybe what you are actually complaining about is that there is no true cross-platform build system that works for every host/target combination for which a c++ compiler exists. On that we can agree (Although cmake does a pretty good job there - it just doesn't work everywhere out of the box). However, a header-only library also can't be used on a platform for which you don't know how to compile a c++ source file and if you know how to compile one, then you also know how to add source files from an external library to your project. &gt; If you have an example of a widely used C++ library that I can go ahead right now and build on the platforms I mentioned I'd love to give it a try. Why does it have to be widely used? If your claim is that header only is a hard requirement for being corss-platform, then that claim can be refuted with a single counterexample, so it should be enough, if I just whip up a small dummy library that prints "Hello World" no? But how about fmt: https://github.com/fmtlib/fmt If you don't want to use cmake, you can just: - Add `&lt;FMT_ROOT&gt;/include` to your list of include directories - Add `&lt;FMT_ROOT&gt;/src/posix.cc` and `&lt;FMT_ROOT&gt;/src/format.cc` to the list of source files of your project - Build your project on/for any platform you want. Another example that comes to mind is Boost.Signals (which IIRC has been removed from the last boost distribution) In the end, it is inconseuquentail. If you only want to use header-only libraries in your ross-platform projects, that's fine with me and I'll just go on and use any library that works on the targets I'm interested for my cross-platform projects (internally we have a few utility libraries that are not header-only and are used on microcontrollers as well as on windows machines). 
That and `view::zip`!
Oh sorry, I should have read the post more carefully. I missed that he exactly describes the need for a depth-1 queue. 
And yet just about every significant C/C++ project of scale has security issues, so I guess the majority of C/C++ programmers must be unskilled by that metric. Including those working on Linux, Windows, web browsers, device drivers, even space systems. Other languages prevent the programmer creating programs with memory leaks. These are inherently more secure, as they prevent the creation of programs with whole classes of bugs.
Calling setsockopt is racy because it affects all users of that socket handle. So, in "real world code (TM)" it's virtually useless. I know I've never used it except in toy use cases. What I have done - and I apologise now in advance - is `pthread_signal()` the thread blocked on a socket i/o to break it out of its sleep after a time out. Which is extremely nasty, and still racy in the sense of global signal handlers installation, but that technique actually scales to code complexity and real world code in a way per-socket timeouts cannot. (i.e. what everybody needs is *per-i/o* timeouts, not *per-socket* timeouts. POSIX API is broken here, but that's not uncommon)
{ { { { this scope can thow a 100_byte_exception or 500_byte_exception } } catch(100_byte_exception) } catch(500_byte_exception) } how do you transport the 500_byte_execption without using heap if you do not have convert-places in between? how do you even know what storage is needed for non-catched exceptions? i also get the feeling that you just ignoring the fact why current exception handling needs heap
Memory leaks are rarely security issues though.
Humans write bugs period. However, some programming languages inherently prevent certain classes of bugs and may limit the impact other bugs have (e.g., if every array access is bounds checked, then a miscalculated index may crash the application, but it can't be used to read data from random memory locations).
The usual: replace the dynamic memory allocator, replace the i/o service mutexes etc. To be honest, if you're using Beast then ASIO or libuv is probably not going to be your bottleneck. Parsing potentially malicious text is much more likely a bottleneck for anything but a trivially simple HTTP application. I'll put this another way: I've written a good few high performing, very scalable HTTP applications in Python. Perhaps it's my lack of domain experience, but I've never found a need to parse non-fixed-form HTTP in C++ i.e. Where HTTP comes from sources I don't control, I reach for Python because it saves on all the extensive input fuzzing testing I'd otherwise need to do. So use the dev and test costs saved on more servers instead. Where HTTP does come from sources I control, I either use a fixed-offset parser or I replace HTTP with a binary protocol so I don't need to parse text. I have yet to *personally* see a strong use case for C++ parsing of HTTP over using a different language ecosystem with far more mature support. But it's totally possible it's my relative lack of experience talking here. For example, I've *personally* found cherrypy in Python scales very well if you program it right, it can deliver as many requests per second as SSL handshakes can be performed, so using a faster language than Python makes no sense when HTTPS connection overheads dominate all. So in my opinion ASIO or libuv's performance only matters when you're getting into the hundreds of thousands of requests served per core per instance territory. I am sure there are some people doing that with HTTP, but probably most in that territory are using an all-binary wire format, without possibility of malformed input attacks.
Why would you need std::pair for that instead of using a dedicated struct with meaningful names?
&gt; Why does the libjeg-turbo (fastest software JPEG decoder on the planet) have so much assembler code in it? The history is lost, but I'd guess part of it is that it's old code. I have written SIMD assembly code. Back in the day, GCC (3 era) was terrible at optimizing the code, and did a shockingly bad job of optimization and register allocation, and it was very easy to beat it with assembly language. Also it was even worse at MMX probably because of the weird shared state thing. The other thing is that C/C++ (yay a legitimate use!) have to use the language rules to infer information about aliasing, where as with asm, you presumably know that and don't have to guess.
No corporate ties with any major industry (as C#, Java JDK (ugh)). Performant yet practical in day to day use. Major implementer of GP style. Metaprogramming facilities yet the C abstract memory model at hand.
/r/cpp_questions
&gt; C has the highest number of vulnerabilities out of these seven languages, accounting for nearly 50% of all reported vulnerabilities over the last 10 years, according to the report. However, this does not mean that C is an inherently more vulnerable language, the report noted: Developers have to keep in mind that C has been in use for much longer than most other languages and has the highest volume of written code, making it natural that it would have more known vulnerabilities than the rest. Not normalized per LOC making it a) impossible to conclude anything from that data, and b) impossible to take the article (or the report) seriously.
&gt;I’m struggling with a ~~few~~ all concepts. &amp;#x200B;
I was writing a large HPC simulation in C, when I realized that in order to handle run-time dynamic behavior, I was basically reimplementing vtables in C. I was like, shoot - there's a bunch of much smarter people than me who have worked a ton to solve this problem, and they called it C++. It is so much faster for development in this case - C++ is straight luxurious compared to C. Plus the performance hit is not bad if I don't use all of the features of C++. Plus atomics are great, the CRTP and templates can be useful, and the standard library is wonderful. &amp;#x200B; To be fair, I do use Python to deal with the file output and to generate interesting data, because of the amazing data analysis libs, but damn c++ makes things so much better! It was scary though, having functions return structs that I thought were allocated on the stack... it took me a bit to figure out copy/move nuances. And there's mutable strings if i want! Built in! And mutable arrays (if I want!). Iterators and Auto are just icing on the cake. &amp;#x200B; Code like this still makes me nervous haha - sometimes I miss having to manually manage memory: `MyStruct create_value(int x){` `return MyStruct{x};` `}` &amp;#x200B; TLDR: It's significantly easier to write more maintainable and extensible code in C++ over C. 
These are pretty close to the core concepts of programming. you are going to need to provide more detail about where you are having problems. maybe provide a brief summary of what you think these are and then ask about the parts you are not sure you have right. r/learncpp and r/cpp_questions are probably better places to ask these.
heartbleed \*cough\* :D
I like the complexity and working on projects that use it. And for some reason it doesn't seem to be very well liked, so better for me since I'll take jobs that require using it.
I guess because it's implemented in terms of `zip` which uses `pair`. But good point! I think that if you already want a special case for zipping index and some range, you should provide meaningful names for the fields as well (like `.index` and `.element`). I hope this gets changed!
&gt;I have yet to &gt; &gt;personally &gt; &gt; see a strong use case for C++ parsing of HTTP over using a different language ecosystem with far more mature support Well, any C++ WebSocket implementation (like Beast) has to read and write HTTP.
You mean besides setting the cmake flag? 
&gt;As someone who uses Asio + Beast, what type of tweaks are you speaking about? It is mostly what Niall said. Have a look at this example for a guide: [https://github.com/boostorg/beast/blob/2c141cd4ad55da087061e05206d9ff849aca0f63/example/http/server/fast/http\_server\_fast.cpp](https://github.com/boostorg/beast/blob/2c141cd4ad55da087061e05206d9ff849aca0f63/example/http/server/fast/http_server_fast.cpp)
&gt;using Boost in general is a big no thank you Irrational fear of Boost is indicative of a non-scientific approach to engineering.
`for(auto &amp;&amp; [index, elem] : enumerate(range))` is basically the only way i would use that thing - do we really need names ?
Sure, but implementing WebSockets is definitely something I've never done, nor needed to do. There are lots of mature existing implementations for me to reuse. I do want to be super clear that I don't have oodles of web programming experience. I have more than most C++ developers, and I've delivered a good number of surprisingly scalable, public facing, web services written in Python, and occasionally .NET. But my experience is shallow, I've either come in from the very high level, or from the very bottom level. I am weak on "deep HTTP" of the kind say Facebook rolls out. To be honest, it's not an area where contractors get hired in Europe, so I had no reason to specialise into that, no money in it without relocating to the US.
I don’t believe that’s required (at least it’s not in MSVC), but it’s more “correct”. The second template parameter is the size of the vector, which is a std::size_t. However, there’s no literal suffix for that (yet) so they’re using the fact that size_t is an unsigned long on most 64bit machines to avoid a narrowing conversion. In general, I believe C++ disallows narrowing conversions for non-type template parameters, but you can get away with using a constant literal int as long as it can be represented by size_t (ie &gt;=0). 
Typically yes, the simplest way to do it would be to add it to your CmakeLists.txt in the root of your project. cmake_minimum_required(......) project(....) # Somewhere around here option(CMAKE_EXPORT_COMPILE_COMMANDS "Generate compile_commands.json in build directory" ON) ...
Sure, I totally get that, but there are plenty of uses for doing HTTP reads and writes in C++. Another example, an .exe which visits a URL on launch to see if a newer version is available. You wouldn't want an .exe compiled from portable C++ to delegate that to some external script.
CONFIRMED. If you're on Windows, C++/WinRT is the only game in town. Do I need to repeat "if you're on Windows"? Do not expect any cross platform ability like you have with Qt. If you design carefully, you can end up with some parts that you can isolate as pure C++, these of course can be portable, but the UI "layer", which will be extensive, is not portable at all. My recommendation with C++/WinRT is to get on the SDK that came out with Windows build 1809 (yes, *that* one). I think it's 17763 if memory serves. The tooling is not quite there yet, but it is workable once you discover the quirks. I hope it will get better with VS2019 and the next SDK. I desperately hope Microsoft stays with C++/WinRT, focuses on the tooling and documentation, and doesn't shift yet again to some other C++ story on Windows. **I WANT TO BELIEVE** 
One reason that I still find myself having to use some macros, that are commonly used anyway, is because templates cannot accept a namespace or enum space as a type parameter. Without that, there's a family of things that you can't do with templates because you cannot generically access some common functionality that would be in any of the enums (at least the ones you pass to that template) or namespace. &amp;#x200B;
If anything, we can learn from the article that there is no language called "C/C++". There is C, which attracts a high defect rate, and C++, which attracts a ten times lower defect rate. If languages with memory safety are inherently more secure, why is Java sitting there at 11%, more than twice as high as C++? 
&gt;Throw a "template" or "const method" in a job interview and you're instantly at the top of the list to hire Do you work at the same place as me?
Some things need to go through in order for things to work properly. When letting something go through, one can inadvertently let telemetry through also. It's a deterrent strategy. You can't firewall and sandbox everything all the time. 
If you look at a container that doesn't invalidate references on insertions, say \`std::list\`, the \`end()\` iterator always points to the end even after insertion. But ultimately, this is your choice.
You don't need to add `-Wall` and `-Wextra` manually. It is already taken care of by the project function setting the warning level to 3.
Neither do the alternatives.
I am going make sure to remove "-Wall" and "Wextra" for the next update. But as for removing warning level I thought that was set to one by default not three.
&gt; Not normalized per LOC (or anything) making it a) impossible to conclude anything from that data, and b) impossible to take the article (or the report) seriously. And beyond LOC, there's also usage. C libraries are *everywhere*, so they get stress-tested much more.
 [https://stackoverflow.com/questions/11328264/python-like-loop-enumeration-in-c](https://stackoverflow.com/questions/11328264/python-like-loop-enumeration-in-c) &amp;#x200B; or &amp;#x200B; [http://reedbeta.com/blog/python-like-enumerate-in-cpp17/](http://reedbeta.com/blog/python-like-enumerate-in-cpp17/) 
Sort of correct, but programming talent is not binary good/bad. Sometimes it's variable even among the same programmer across time (come on, we've all done dumb things!). And good code is not binary either, there's great code, and good code and ok-it-works code and burn-it-with-fire code on TDWTF. So it's meaningful to say ask: how good of a programmer do you have to be in order to never cause a critical security bug in language X? Which languages are more likely to have bad code result in safer behavior (crashing the program, invoking a termination handler) and might have catastrophic failure mode (all your business data are held for ransom by a dude in Kerbleckistan)?
No matter how many words I write here, I cannot get the point across that the type of exception that is thrown, DOES NOT have to be the type of exception that is caught (and note that throughout all this time we have been talking about a possible language evolution, not about how C++ works today). I can throw a 500-byte exception, but if that exception is convertible to a 100-byte exception it can be caught by the 100-byte exception handler. How can this work? Let's say you throw the 500-byte exception. It is created on the stack. The exception handling mechanism now looks for a matching catch handler, and comes across the 100-byte exception handler. If the type of the 500-byte exception is convertible to a 100-byte exception, it is converted, and that smaller exception fits nicely in the space we had reserved on the stack. At this point the original 500-byte exception is discarded, and the stack is unwound as normal, with execution continuing in the catch handler for the 100-byte exception. Would this be exactly identical to how it works today? No, but it would be plenty good enough for the vast majority of use cases. In my opinion exception handling is vastly over-engineered anyway. I'd be perfectly happy to have restrictions like only being able to throw std::exception and any classes derived thereof, not being able to lifetime-extend exception objects, having a restricted and faster mechanism to replace the dynamic\_cast, etc. 
Availability is absolutely part of the principles of information security. So it depends on the details of the leak and service -- can an adversary trigger the leak, how critical is availability of the system (are we talking about flight-radar or candy-crush) and so forth.
Yes we do. This may be the common usage, but not the only one. And in particular, if I'm iterating over a set of numbers, I welcome if I don't have to remember which comes first. 
What really surprised me is that enumerate was only a very recent addition to ranges-v3
Sure &amp;#x200B; } &amp;#x200B; this is most useful part of C++
Because, behind it's gruff exterior, modern C++ is actually a memory safe language :-) It's much harder to write an off-by-one using `std::foreach` or to mess up a lifetime issue using `{unique, shared,weak}_ptr`. It's really hard to call an `std::function` using the wrong parameters. You can't have printf bugs without printf :-) [ Also, for historical reasons, Java and SQL go hand in hand, and securing SQL against injection is much harder "logical level" security than UAF-type-stuff. ] 
[KDE community](https://kde.org/) has Lots of cool stuff to work on.
We'd love your help over at yuzu! We are currently writing a nintendo switch emulator. [https://yuzu-emu.org/](https://yuzu-emu.org/) 
auto tiddy
&gt;hey, i like to think i'm an above-average c++ programmer That's actually an extremely good sign you are not. Well, one has to define the "average c++ programmer" but the more you know the higher the bar is. &gt;and have been trying to find cool open source projects to join Find some popular C++ libraries or projects. A good one is [`nlohmann/json`](https://github.com/nlohmann/json)\]. You can also contribute to your favorite code editor, I've contributed to [KDevelop](https://www.kdevelop.org/) a couple of times. Using a DE on linux? Pick some bugs that bothers you and fix them. GNOME, KDE, LXQt, Mate all need help (not all of them is c++ though). You can also create something cool on your own. At one time you *will* need libraries, and all of those can be contributed to (if they are open source of course). (shameless plug here) I also have a library and I accept patches : [`gracicot/kangaru`](https://github.com/gracicot/kangaru)
There's a great book on the topic of (re)designing code for unit tests "Working Effectively with Legacy Code" by Michael Feathers. 
Sure, but that's what libcurl etc is for. Dunno, still think Beast et al is for problems I'll never encounter in my career.
Why not a standard library (either libstdc++ or libc++)? You could start by looking at the coverage data and writing tests until you get familiar with the codebase.
Write some sort algorithm on your own or A* pathfinding and You realize how good You are. Good luck :D 
Not to mention that views/span allow you to avoid working with objects directly so you're less likely to misuse them.
This one is interesting: [https://github.com/wheybags/freeablo](https://github.com/wheybags/freeablo) 
&gt; hey, i like to think i'm an above-average c++ programmer Ok good &gt; have taken data structures and several courses in c++ uh oh - if those are your credentials I'd say it's much more likely you barely classify as a beginner - above average only if you compare yourself to people who don't know C++ at all.
the same can be said for SQL .. using a prepared statement and good luck trying to get an injection working.
A*, really
Kind of ridiculous to ask for help on your project after slamming someone you don't know for perceived lack of abilities you've never observed.
[removed]
"above average" is highly relative. Bitcoin is a fantastic C++ project, they have a few "good first issue" tasks in their github. 
Slamming? I'm pointing out to OP that's it's easy to overestimate ourselves. I've been victim of that, and maybe still am. Taking several courses is not enough. I assume most C++ programmer has at least some years on one or multiple projects and already has contributed to open source projects. The kind of thing OP asked help to start doing.
It's amazing to me how often people would rather repeat an idiom 20 times with the constant cognitive overhead, than to spend a little more time to learn (and gain trust for) an abstraction. Computers are amazing at doing purely mechanical, repetitive work, and still so often programmers don't seem to want to use them that way if it means they don't get to stay with the abstractions they're already comfortable with.
I'm preferring a builder pattern. It's much simpler and better maintainable. I've personally used this syntax, which I quite like: auto car = *vehicle().wheels(4).color(0x335577).horsepower(120); `vehicle()` creates the builder and each setter returns the builder again, and the `operator*` actually creates the object based on all the settings.
&gt;(have taken data structures and several courses in c++) OP even admits he's not what he says he is. And this person can ask for help on their project in a general sense, as other readers here will also be likely to look for projects to help out.
MS paint flood-fill. Fun to do it with bitmaps. 
https://NavCoin.org
I did A\* in 3 hours (hex based tile game), but not before reading about how it works. So it's not that difficult to implement.
Please join us over at [LibreOffice](https://wiki.documentfoundation.org/Development/GetInvolved). Begin by doing easy hacks to get comfortable with the patch review process.
Maybe you could have a look at algorithm-archive.com
If you are interested on cryptocurrencies, contact me
For C++ I cannot agree more, but for C? Meh. In my estimation C99 is the "modern C". What does C11 brings that's so relevant?
Things that always need more love https://openmw.org/en/ https://rada.re/r/ 
Code that doesn't compile with Microsoft Visual Studio on Windows?
Envoy Proxy, written in C++14: [https://github.com/envoyproxy/envoy](https://github.com/envoyproxy/envoy)
I'm in this boat. I'll help someone on their project if we use my messaging/serialization software as part of the project. 
You created a new name just to say this?
I'm the main developer on https://github.com/libfive/libfive/ We've got something for everyone: * Solid modeling + algorithms, including some exciting N-dimensional template madness * Bindings to dynamic languages, with all of the fun API design that this entails * A Qt GUI using OpenGL for graphics
In this case, though, the result of `new` is not discarded, so `[[nodiscard]]` should not catch it
Amit's tutorials are great. I was able to implement A* after reading. https://www.redblobgames.com/pathfinding/a-star/introduction.html His old site has good information too. http://theory.stanford.edu/~amitp/GameProgramming/
Off-topic. Please don't waste our time.
Very good point, I got caught with this in debug while it worked fine in release. So I'm not using `end` instead of `rbegin`.
&gt; Running chrome is usually the most computationally intensive thing most people do on their laptops. Who's to blame for this? Shitty web devs that make sites full of bloated JS.
Static assertions Anonymous structs and unions "alignas" and "alignof" Closer to C++11 Not 20 years old (20+ years is very good for scotch, not so good for programming language specs.) Possibly already using it anyway ("gnu11" became the default C dialect for GCC as of GCC 5.5) A crotchety old coder says it's better (don't make me put in my arguin' teeth, you young whippersnapper!)
(Damn, now I need my readin' glasses to see these dinky light-grey comment action links) Static assertions Anonymous structs and unions "alignas" and "alignof" Closer to C++11 Not 20 years old (20+ years is very good for scotch, not so good for programming language specs.) Possibly already using it anyway ("gnu11" became the default C dialect for GCC as of GCC 5.5) A crotchety old coder says it's better (don't make me put in my arguin' teeth, you young whippersnapper!)
I feel like bash would be in the top 3 on there if the metrics weren't what they were.
&gt; But how about fmt: https://github.com/fmtlib/fmt If you don't want to use cmake, you can just: You can just use the header-only configuration via the FMT_HEADER_ONLY directive which was made available because it doesn't build on all platforms, such as Cygwin. I look at this as a business owner more than a language lawyer trying to win an argument. I would be incredibly happy if C++ had a way to distribute dependencies using a build process that wasn't error prone such as subtle ODR violations, subtle binary compatibility issues that come up when your library makes use of the STL or even worse, depends on yet another library and causes crashes that are hard to diagnose, and a host of factors that make it simply impractical to distribute C++ libraries. Honestly if I were wrong about this issue, I'd be very happy to know it but with everyone just providing very long paragraphs expressing their opinions when examples would suffice showing a practical C++ distribution model that just works... I have no choice but to conclude that the only cross-platform way of distributing C++ libraries that takes full advantage of the language and has the highest chance of just working... is the header-only distribution model. That said... if you have a distribution model that works well for you and you are happy with it, honestly that's great and you do what's best for you. I have paying customers who depend on the C++ libraries I write and I have no choice but to evaluate this situation from a business point of view... and for my customers who use my work on a variety of platforms and in ways I just can't anticipate, the only solution I have found that works for me and works for them is header-only distribution.
Do you speak template?
&gt; uh oh - if those are your credentials I'd say it's much more likely you barely classify as a beginner - above average only if you compare yourself to people who don't know C++ at all. I knew the top response was going to insult OP as soon as I started reading. It wouldn't be the C++ community if they weren't insulting for no reason. 
thank you to everyone who gave me advice and suggestions! i rlly appreciate it. 
It's more of a reality check than an insult. It's bad news, delivered with care, not anger.
I'm fine with it, although obviously not everyone agrees with this opinion :)
https://github.com/Themperror/Dungeon-Keeper-Remake
"Insult" is absolutely not the correct word.
Oh well.
How to *become* good at speaking template? Working on small-medium sized code all this time and I've never gotten around learning about templates and don't know anything of the power they yield. 
Abrahams and Gurtovoy's book C++ Template Metaprogramming. It may be 15 years old but you will thoroughly understand what is going on.
capnproto! If it keeps improving I will be very happy. It is very good already, but, for example, capnproto does not support hashtables directly in their language. It would be nice to have those. Of course, this is my wishlist. It would not hurt to get some more documentation on how to run multithreaded RPC servers either.
The "Ok" kinda forshadowed it...
Can we agree on "a reality check worded indistinguishable from an insult"? There are other ways to convey the same message. 
&gt; Can we agree on "a reality check worded indistinguishable from an insult"? I'm afraid I can't agree on that, no, because I personally don't see an insult there. &gt; There are other ways to convey the same message. Out of curiosity, how would you word it?
Haskell does have for loops: ``` numbers &lt;- for [1..4] $ \i -&gt; do putStrLn "Give me a number" line &lt;- getLine return (read line) print (sum numbers) ``` Though unlike most languages that "have" for loops, `for` is just a regular function in Haskell, so the same can also be written as: ``` print =&lt;&lt; sum &lt;$&gt; for [1..4] (putStrLn "Give me a number" &gt;&gt; read &lt;$&gt; getLine) ```
 [https://github.com/onqtam/doctest](https://github.com/onqtam/doctest) [https://github.com/onqtam/doctest/blob/master/doc/markdown/roadmap.md](https://github.com/onqtam/doctest/blob/master/doc/markdown/roadmap.md) 
That is fairly uncharitable and perhaps the tone of my comment warranted it. I get that you personally are all-in on boost and I also appreciate (and have used in production) beast. But there are lots of reasons why boost might not be a fit for a project and that really shouldn't be controversial. I've used boost for a while and respect the project in general. Boost was absolutely required for enjoying c++ until a few years ago. All that said in my current project it is indeed a big no thank you and the general tone of the boost police calling people unscientific or irrational is a huge red flag for me in terms of community and it's advocates.
Yeah, thats for sure, claiming to be above average in c++ is a tall order, when you see those amazing talks and look at the cool things people doing with c++, for me i personally feel like an idiot
You may find that there are many tough challenges ahead. 
[qTox](https://github.com/qTox/qTox) is a fully distributed chat/voice/video cross platform program, using the Qt framework. We could use your help and have a small helpful group of maintainers. If you want to test it out you can contact me at tox:AC18841E56CCDEE16E93E10E6AB2765BE54277D67F1372921B5B418A6B330D3D3FAFA60B0931
[qTox](https://github.com/qTox/qTox) is a fully distributed chat/voice/video cross platform C++ program, using the Qt framework. We could use your help and have a small helpful group of maintainers. &amp;#x200B; If you want to test it out you can contact me at tox:AC18841E56CCDEE16E93E10E6AB2765BE54277D67F1372921B5B418A6B330D3D3FAFA60B0931
You can use this website to search for projects on github based on tags and languages. [http://github-help-wanted.com/](http://github-help-wanted.com/) There is also a good first issue tag for beginners. 
Exactly!
How are you with AI? &amp;#x200B; [https://sc2ai.net](https://sc2ai.net/) has some fun projects, we make bots to play against each other. Lots of projects to get involved in, and the main ladder server has an active community working on it : [https://github.com/Cryptyc/Sc2LadderServer](https://github.com/Cryptyc/Sc2LadderServer) 
That is a great book indeed. I also find that Peter Dimov's articles ([part1](http://www.pdimov.com/cpp2/simple_cxx11_metaprogramming.html) and [part2](http://www.pdimov.com/cpp2/simple_cxx11_metaprogramming_2.html)) are very clear on how to simplify most of MPL functionality using C++11 constructs (e.g. variadic templates and alias templates).
 If you consider that an insult you must be sensitive as fuck. Good luck with that.
 Interesting. Never thought about actually contributing to the standard library before. I guess I've always been pretty afraid to do that.
You have the same problem with all other iterators after the insertion point. my_vec v = {0, 1, 2, 3, 4}; auto it = v.begin() + 3; // Contains it.index == 3, *it == 3 v.insert(v.begin() + 1, 9); // v == {0, 1, 9, 2, 3, 4} std::cout &lt;&lt; *it &lt;&lt; "\n"; // prints 2 It is feasible to avoid this (for `end()` iterators and non-`end()` iterators like above) but you'll need some sort of extra trick. For example: * Each vector could keep a container pointing back to all iterators that exist. When you insert an element (including with `push_back()`) you could increment the index in all iterators pointing at or after that point (and if you remove an element you could update all iterators after that point by decrementing their index). This would be a bit fiddly (e.g. destroying the iterator needs to reach back into the vector and remove itself from the iterator container) and if you are using threads then you would need to be especially careful about what operations can modify the vector's internal iterator container. It would also potentially be very expensive if you have a large number of outstanding iterators. * You could use some sort of secondary structure e.g. a `std::list`. Put indices in the second structure (so use `std::list&lt;size_t&gt;`) and make your iterators contain iterators of that secondary structure. When you insert/erase, you only need to update the indices in this secondard structure, not all iterators. This description is just an idea, not a complete design, and in fact I think you would need a *third* container that has a mappinng back from index to the secondary container. I'm going to stop going down this rabbit hole now, but I think with some more thought it would be feasible. * Thinking about it more, the best thing I can think of is a hybrid of these two approaches. For each instance of your container, have a `std::vector&lt;T&gt;` (of course) and a parallel `std::vector&lt;std::shared_ptr&lt;size_t&gt;&gt;`. Your class could maintain the invariant that element `i` in this vector points to the number `i`. Obviously insertions/erasures in the main vector must happen at the same location in the index vector. Your container's iterators can take a copy of the `std::shared_ptr&lt;size_t&gt;`, and it can rest assured that it will always point to the updated index of the element it started with (or to `v.size() + 1` for the `end()` iterator). I suspect the real solution is to consider whether you *really* need contiguous elements. If your concern is performance (rather than some API that takes a pointer to an array) then try out `std::deque` and see if it is really the bottleneck in your application/library. 
Your GitHub search is not entirely correct, it seems to search for C++ in repository description also. But to be honest it's not straightforward how to search for most popular repos in a certain language on GitHub, I came up with this hacky solution for now: [https://github.com/search?l=C%2B%2B&amp;p=1&amp;q=stars%3A%3E0&amp;type=Repositories](https://github.com/search?l=C%2B%2B&amp;p=1&amp;q=stars%3A%3E0&amp;type=Repositories)
This is a ridiculous comparison. If you go through the tools in your shed, you could determine which one causes the most injuries, and decide to get rid of it. Now you have no saw, then what? 
We work on a Final Fantasy XIV emulator and would love help from anyone interested: https://github.com/SapphireServer/Sapphire Feel free to chuck me a PM or join the discord if you have any questions
OK, last post on this, after that I just have to accept that you disagree with me. &gt; You can just use the header-only configuration via the FMT_HEADER_ONLY directive which was made available because it doesn't build on all platforms such as as Cygwin or using the Intel compiler but it will work on those platforms if you use the header-only configuration. Sure you can use it in header-only mode. But the question was if it is necessary. I don't have an intel compiler but I can use it quite fine with msvc, cygwin, msys on windows and clang, gcc and mingw (cross compiled to windows) on linux. Do you know what exactly is supposed to be the problem? &gt; I look at this as a business owner more than a language lawyer trying to win an argument. Well, I'm also not a language laywer. I'm just an application developer that tries to convince people to not make their libraries header-only needlessly (of course many "modern" utility libraries are often so heavily templated that you have to have the whole code in the headers anyway), because I - the user of those libraries - feel the pain in terms of compilation time or - worst case - because someone thought it would be a good idea to include `windows.h` and pollute my code with all kinds of macros [1]. &gt; I would be incredibly happy if C++ had a way to distribute dependencies using a build process Again, you are mixing two related but separate problems: How to distribute your library and header only vs header+source split. I agree whole hartedly that a) Libraries need to be distributed as source code b) Unless the author is extremely careful about ABI and ODR under different build configurations, they need to be compiled as part of the final application with exactly the same toolchain and settings as the final application and not separately. Header only libraries can - by definition - only be used in that way, but the same is possible with libraries containing source files. The problem I see in practice is that most library build scripts try to do too much, like setting various compilations flags (maybe dependent on the toolchain and target platform) or searching for various dependencies (and again doing some configuration based on the result of that search). That is whats making many libraries difficult to use in environments not anticipated by the author, but none of that is actually necessary. &gt; that wasn't error prone such as subtle ODR violations, subtle binary compatibility issues that come up when your library makes use of the STL (huge problems on Windows) None of that is an issue if your library is compiled as part of your parent project, with the same settings. &gt; or even worse, depends on yet another library and causes crashes that are hard to diagnose What does dependency on a different library have to do with header-only vs compiled? &gt; Honestly if I were wrong about this issue, I'd be very happy to know it but with everyone just providing very long paragraphs expressing their opinions when examples would suffice showing a practical C++ distribution model that just works... I'm not just stating my opinion, I'm telling you that my experience runs counter to your claim and I gave you two examples that work on all platforms I can test right now and I have many more examples internally. I can't point you to those internal ones but I can give you a trivial example that you can make arbitrarily complex as long as you stick to standard c++ features [1]. All that being said: I'm discussing what is possible and what isn't and what I as a application developer prefer to use. I'm not arguing that many many non header-only libraries are very difficult to use outside of common platforms (as I said, I'm developing for embedded systems so I do feel the pain). I'm also not disputing that there might be other valid reasons to make your library header-only and if it is easier for you to sell header-only libraries, e.g. simply because that is what your customer expects and is familiar with, then sure - go on. But I stand by my point that is not an inherent limitation of non header-only libraries, but rather a QoI issue in their design. [1]: I'm not talking about "fake" header-only libraries like catch2, where the definitions are hidden behind a preprocessor branch, which requires me to include the header once in a separate cpp file with a special define in front of it. Effectively those libraries are doing exactly what I'm proposing and just merge the source and the header file into a single file that I - the user - have to separate out again. [2]: Here is an example of a minimal non header-only library that will work on any platform with a c++ compiler. // hello.hpp const char* hello(); // hello.cpp const char* hello(){ "Hello World"; } 
Not so modern anymore, but "Modern C++ Design" by Alexei Alexandrescu got me started...
For a virtual machine it’s better to have a contiguous bytecode buffer for maximum speed. (Data locality is important). Deque isn’t contiguous so I can’t really use it.
Shameless self-plug (it could hurt for templates haters btw): [https://github.com/skypjack/entt](https://github.com/skypjack/entt)
I'm sitting in an Algorithms lecture, doing amortized analysis on vector insertion and deletion. Suddenly reddit is relevant.
Shameless suggestion. If you are comfortable with templates and want to try something in the gaming field, you can help me with EnTT: https://github.com/skypjack/entt I've a TODO list that is quite long and in the worst case (that is where contributions don't reach the standards of the project and full coverage isn't respected) it will be funny at least.
I would say the amortized cost of an append is constant but linear for an insert. Maybe I've been misusing the word insert for the last 20 years though...
*when inserting at the end of the vector*, i.e., a push_back().
Proposal ongoing, we might get it in 2023/2026 timeframe.
I hope you did not meant other languages implementations.
You are absolutely right :) 
Only read the words, didn't watch the video but ten years is a long time, particularly in the world or tooling. They say there was a bump in 2017 is it now rapidly descending? I would like to see graphs on number of bugs found against year for each language. Are security problems found in new code more than old code? &amp;#x200B; I suppose I would like to know if, even though many still code in C, are we wining? Is increased awareness and better tooling doing its job?
&gt;All that said in my current project it is indeed a big no thank you But you said "using Boost in general is a big no" so we aren't talking about just one project now, are we? You're saying that Boost is not a good fit for \*any\* project. Or perhaps I misunderstood you?
The amortized cost does not actually have a limit. The limit infimum is 2 and the limit supremum is 3. The best case is when you fully utilize the underlying buffer (when you finish with len=cap). In that case, each resize incurs 2^(n) (plus 1) copies, and then the next 2^(n) pushes incur only 1 copy, so amortizing the cost of the resize over the next 2^(n) pushes gives each one 1 extra copy, so 2 copies on average. The worst case, which is what the article analyzes, is when you minimally utilize the buffer (when you finish just after a resize so len is about cap/2). In that case, there are not a further 2^(n) pushes to amortize the final resize over, so you need to amortize it over all the previous pushes, giving an additional 1 copy per push, or 3 copies on average. You can write a program to test this: measure the amortized number of copies when doing n pushes. You'll see it varies from about 2 when n is just below a power of 2 to 3 when it is just above one.
I repeat my assertion that you should try it out with deque and see if it is really the bottleneck, using evidence rather than intuition. But failing that, my idea of a data structure based on dual `std::vector&lt;T&gt;` / `std::vector&lt;std::shared_ptr&lt;size_t&gt;&gt;` may be what you want.
I don’t need another data structure. My current solution works just fine (for now). You’re right that it breaks when erasing/inserting before iterators, I can just document that the iterator may be invalidated by insertion/erasure before the position of the iterator. After all, I just need iterators that stay valid after a push_back, not anything else (for now) I mean, why overcomplicate it when this simple solution works just fine? My initial question was simply about how .end() should behave, not about why I should do X or Y or Z instead of using a vector. If this solution breaks in the future due to added constraints or unforeseen complications, I’ll look into deque and others.
Every so often, an append has to make `N` copies when the vector resizes. 
This programming language has infinite amount of features that I haven't realized yet that they exist 
Are you responding to me...? I mean yeah, that's why we're talking about amortized cost. My point is that the title is misleading. An insert doesn't have a constant time, even amortized. The article is about appending
Whoops, that went off to the wrong post. 
What is this supposed to be saying? You can use a + in front of a lambda function to cast it to a function pointer even though it will be done for you by the compiler? What is the point here?
Note that e.g. the folly vector uses a growth factor of 1.5 whilst gcc uses 2, discussion [here](https://github.com/facebook/folly/blob/master/folly/docs/FBVector.md#memory-handling).
&gt; 1. Detachment, the reinterpretation of a live object into an array of bytes representing that object. &gt; 2. Attachment, the reinterpretation of a previously detached object representation into a live object. Without having thought too much about the details yet: Yes Please!
It is indeed surprising that you can't currently do this without involving UB in C++, except for trivially copyable types. Where we need to get to as a language ecosystem - for both C and C++ - is that 99% of C and C++ programming does not require reinterpret casting because the language has sufficient facilities to avoid the requirement. Reinterpret casting is bad, it ruins optimisation and it ruins proveability of code correctness. We need it to go away as much as possible. Thankfully, constexpr-capable code hard disallows UB. I look forward to the day where all the C++ you write is by default checked and errored out as if it were constexpr (with escape hatches for backwards compatibility of course). 
&gt; Dependency Injection - a 25-dollar term for a 5-cent concept &gt; Rise of the State Machines I don't know who Kris Jusiak is, but the dude can sure name presentations! (well... I actually have heard him speak before, on a [cppcast](http://cppcast.com/2019/01/kris-jusiak/) episode)
AFAIK, 2 is the absolute worst factor [it will always fail]. Theoretically [don't ignore what I wrote, please, theoretically], the Golden Ratio would be the optimal ratio: 1.6180... In practice the difference between 1.680... (and the cost of calculating that, we need float math now) and 1.5 (which can use integer math) is negligible (or negative). So, 1.5 is the way to go.
Posted by author. Comments are welcome. 
The author 'misuses' the word insert in the title. He means 'insert at the end' or 'append' or `push_back`.
I still did not understand what the `+` is actually [supposed to be] doing, can someone explain?
xpost to /r/C_Programming
wtf why would you use 2, this should not be a discussion. Where is the bug report for this??
I just had this issue the other day because I wanted to register an atexit(3) function. You can’t do that with lambdas unless you have this. I think it’s super cool.
* Use target-based CMake commands. Don't use `include_directories` and equivalents. * I really wouldn't execute vcpkg commands from CMakeLists, or even clone vcpkg there. * As of the latest VS 2017 (or possibly 2019), I also think once you have done `vcpkg integrate install`, you don't need to set the cmake toolchain variable (or anything else for that matter) anymore, do you? I think VS now handles this all for the user.
What had to use a + in front of a lambda function?
Why don't you come to Aspen and meet him (and the rest of us)?
The conversion to function pointers is useful, but I'm with the other people in being confused at why you would put a `+` in there. It's [not needed](https://godbolt.org/z/htI-kt). Incidentally, I once made a little library that used `libffi` to dynamically allocate thunks that would give you a C function pointer to call lambdas even that *contained* bindings. Never used it, but fun little exercise. :-)
After reading some answers and looking at my problem I think you are right that setting a one queue per parser is probably the right way. The lock free part though is where I am a bit out of depth, even with the std::atomic (memory order) and I feel conceptually more comfy with the mutex/lock system. The problem is that the mutex/lock system has it's own pitfalls specially if the parsers are provided by external code. (deadlocks. &amp;#x200B;
It forces a cast to scalar type, which in this case forces it to be a pointer. There are a few cases involving templates or overload sets where a "bare" lambda causes compile errors or other problems, so the `+` can fix those. It's not always or even often needed, though.
Does your library assume everything given to it has a unique type, or can it be used with old-style C++ functors as well?
Unary + is defined for a handful of built-in types. One of those is function pointers. Part of calling unary + means trying to convert the argument if necessary, and captureless lambdas can convert to function pointers. Thus, it essentially forces the conversion. In the article, however, it doesn't actually accomplish anything because the code is already unambiguous without it.
Truth be told, the way I actually wrote it originally it took a `std::function` as the constructor parameter, and that's what it actually stored internally. This was laziness on my part so I didn't have to handle the type erasure myself, but it means there are a couple different indirections before it actually makes the final call. But yeah, that means you can give it any callable. I can do a little clean up to it to remove some bit rot (it was written many years ago in C++98) if there's interest in me posting it; though do remember that it was basically a "hmm, I wonder if I can do this" thing. :-)
Just quickly skimming the contents of the draft. This would be huge for me. I’m coding a custom financial equities library and I’m trying to create a shared memory module where I can launch program 1 with all the raw stock data and program 2 (the backtester) can consume the data. I’m using shared memory right now but it feels very hacky.
Maybe I should! I've even got a good name for a talk: &gt; Beware of future promises ...to talk about the problems of not only _where_ future/promise continuations execute, but _when_. Sadly, I've got a day job at a startup and we're in crunch mode, so I doubt I'll have time. :(
Please please please don't implement your own concurrent data structures before looking into the bog-standard ones: Facebook's folly (ProducerConsumerQueue), Boost (Boost.Lockfree), Intel (TBB), Microsoft (TPP) and so forth all have off-the-shelf options that you can use. [ Note: lockfree is a nice-to-have. If your queues are lightly contended, then locks are fine. The queue performance itself only matters when the parser time is comparable to the overhead. ] 
Are you not supposed to use push_back?
I too work in financial services, and we are facing a growing problem of heterogeneous compute being non-optimisable under the current C and C++ memory model. Basically right now the compiler must be made to completely give up on optimisation when working with potentially shared memory, which forces expensive developer time to go into hand tuning that sort of code. What we'd all much prefer is that the compiler knows about shared memory, can be told what kind of cache coherency it has, and generates reasonably not awful optimised code for each use case. Our colleagues in the self driving car industry have very similar needs, as do our colleagues in the HPC field. Even our colleagues in high end storage are increasingly bumping into the same problem, because there is no hardware cache coherency between CPUs and storage devices which can push 12Gb/sec upwards nowadays, so software has to coordinate the coherency manually. All that said, there are good reasons that nobody has seriously proposed adding shared memory understanding to C++ before. And everybody reading should assume that this proposal will be rejected, it is by far the least likely of my extant WG21 proposals to make it into the standard.
well, I remember he has many talks about di
Use `push_back` whenever you want to put^ something at the end of the list (append). As the article says, the amortized time complexity is **constant**. You can also `insert` an item anywhere into a `vector`, but this moves everything after the insert point down one memory space. This takes **linear** time. The title is confusing because he says "insert" is constant time, but the function literally named `insert` on a vector does take linear time and the article only talks about the `push_back` (append) function.
Agreed with point #2. You should allow users to supply the CMAKE_TOOLCHAIN_FILE location. I wouldn't want to have a new boost installation per repo.
eh... least secure languages or languages with the most people writing poor code for them? is there a difference?
Why 1.5=3/2 and not, say 1.6...=5/3 or another more precise rational approximation of φ?
I think it's about : &gt; This works because the compiler converts **non-capturing** lambdas to actual functions Which not many people are aware about. (The other thingy is the `+`). 
I think it's about : &gt; This works because the compiler converts **non-capturing** lambdas to actual functions Which not many people are aware about. (The other thingy is the `+`). 
How did you actually produce the function pointer? To give the right type to `std::function::target`, you need the original type given to the constructor, but storing a method of doing that requires access to the `std::function` and thus `this`, preventing such a method from being or returning a C pointer of the appropriate signature. You run into the same problem trying to store a known type. I'm aware there are workarounds that use static storage with the limitation of working with up to a maximum of N conversions from the same type (for N = 100 or so before compilation starts really suffering). If you managed to do this without such workarounds, I'd be extremely interested in seeing how or seeing where I misunderstood. I've made [my own little black magic utility](https://wandbox.org/permlink/6IXj4hiLJUvcJERE) for this just for fun, but it does come with that limit and runtime-asserts when the limit is reached.
Maybe because it causes fewer reallocations than 1.5, or it aligns better with what malloc does, I don't know.
Multiplying by 1.5 can be done x+(x&gt;&gt;1).
You know: Even if the only thing that comes out of it is a clearly defined way in which I can tell the compiler: "Treat this array of bytes as an object of type X", I would be already very happy.
Why is 2 a worse factor than 3? And why is the Golden Ratio optimal? I don't even agree with saying "theoretically optimal" in this context as there are simply tons of different costs and considerations, but I'm curious to know what your reasoning is. If it's what I think it is, then it's not correct.
&gt; What this proposal does not cover: &gt; [...] The same source code compiled for more than one architecture, or settings, or configuration. [...] &gt; [...] &gt; A ‘reachable C++ program’ can be defined by the implementation as one of the following options: &gt; [...] &gt; Concurrent executions of many instances of the current C++ program, where modified storage instances can be passed between those concurrently executing instances, including across heterogeneous compute Is this consistent?
The reasoning I've always seen were about the ability to reuse previous allocations, which the golden ratio allows. It's possibly valuable for large sizes, however at small sizes it doesn't hold since memory allocators use slabs anyway; and many collections are small anyway... *Note: I personally would argue that both factors are bogus, the optimal thing to do would be to ask your memory allocator, but there's no interface for that so people endlessly toy around with made-up factors.*
13/8=1.625, and `x * 13 / 8 == x + ((x + (x &lt;&lt; 2)) &gt;&gt; 3)`. Surely is is not _that_ much more expensive?
I had to read this a few times before I think I got what you're trying to say, but I *think* I understand. The short answer is [libffi provides the ability to dynamically generate thunks](http://www.chiark.greenend.org.uk/doc/libffi-dev/html/The-Closure-API.html). Perhaps this (lightly-edited) GDB session will be enlightening: (gdb) b main Breakpoint 1 at 0x401406: file test.cc, line 16. (gdb) r Starting program: /home/evan/fun/libcppclosure/a.out (gdb) checkpoint checkpoint 1: fork returned pid 24457. (gdb) b invoke Breakpoint 2 at 0x4013d2: file test.cc, line 12. (gdb) c Continuing. Breakpoint 2, invoke (f=0x7ffff7ff5010, x=5) at test.cc:12 (gdb) p f $1 = (int (*)(int)) 0x7ffff7ff5010 (gdb) restart 1 Switching to process 24457 (gdb) disass 0x7ffff7ff5010,+27 Dump of assembler code from 0x7ffff7ff5010 to 0x7ffff7ff502b: 0x00007ffff7ff5010: Cannot access memory at address 0x7ffff7ff5010 (gdb) c Continuing. Breakpoint 2, invoke (f=0x7ffff7ff5010, x=5) at test.cc:12 (gdb) disass 0x7ffff7ff5010,+27 Dump of assembler code from 0x7ffff7ff5010 to 0x7ffff7ff502b: 0x00007ffff7ff5010: movabs $0x7ffff7bd4f62,%r11 0x00007ffff7ff501a: movabs $0x7ffff7ff5010,%r10 0x00007ffff7ff5024: clc 0x00007ffff7ff5025: rex.WB jmpq *%r11 0x00007ffff7ff5028: js 0x7ffff7ff500a 0x00007ffff7ff502a: (bad) End of assembler dump. 
Oh, I completely missed that bit in the original comment, sorry. That makes a lot of sense.
[This guy gets it](https://github.com/UnruffledST/Scroda/commit/9a07350c9aaffb93bfbda885784277e8ca253ce5)
This is exactly the point, I think my design is fundamentally flawed. The problem is that contrary to the assertion it is quite elegant and code that handles the parsers insertion and management is very small and is contained in 30 lines of code with template support. I think after we make the release for the customer and I add the new tests cases that we created for the new release I am going to give a try to the queue. My problem is about the size of the queue. I am afraid of getting OOM. This is for an embedded system so it is a real concern. With a queue I will need to be able to prune it in a controlled way.
Yeah, basically agree. However if that's going to be the reasoning then it makes more sense to just use the fibonacci numbers directly than to multiply by the golden ratio.
It's actually non-standard to pass a function pointer with C++ linkage (e.g. a lambda's `operator()`) to a function expecting a function pointer with C linkage. Nearly every compiler lets this compile though.
&gt;ProducerConsumerQueue Thanks for the tip on the data structures. The thing is if boost has it why does the std library not have it? Boost is huge and overlaps a lot with the modern stdc++ lib. The others I will check them out, as as long as they are portable they are candidates. This is for an embedded projects
Boost is a proving ground for the standard library. Most of these are suitable for embedded use (they can be done no-throw, for instance when using fixed sizes). 
Im wondering if its possible to use SAFE qualifiers like on D or C# in the future to achieve something like Rust.
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b5tdlg/looking_for_open_source_contributors/ejfxyek/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's a very limited use scenario, basically HPC, lots of the same CPU connected by a fabric. But if we don't draw that line, we have to deal with specifyingportable ABI, and *nobody* wants to touch that with a barge pole!
JUCE! www.juce.com
WIP EnumToString /StringToEnum [https://github.com/Neargye/magic\_enum](https://github.com/Neargye/magic_enum) 
You can already do that via reinterpret cast. What this proposal does is "turn this array of bytes into a well defined, legal, live object". Which turns out to have lots of surprising side effects, like profoundly changing what moves are and can be.
JUCE is an example: https://github.com/WeAreROLI/JUCE In fact, I think JUCE's approach to this problem is genius. They rolled out their own "Module" system (different from recent C++ modules, more like a unity build system). That has made the most sense. That, combined with the PIMPL paradigm (private implementations for separate platforms, shared common interface), solves this issue in a very satisfying way. It's not header only, though the project is structured such that you only ultimately need to include a single .cpp file per "module".
I think it might be easier with https://github.com/vector-of-bool/pmm. It handles the bootstrapping and downloading the dependencies for you. The only requirement include one cmake file. 
Because the GCC team tested this issue extensively and found absolutely no evidence that a factor of 2 performs better, but did find situations where it performs worse. Yes, there is a good theoretical argument for why a value closer to the golden ratio is optimal... but real world performance benchmarks show that based on actual use cases, it's faster to perform fewer reallocations rather than try to conserve memory.
I think that's being generous, but the plus is still nonsense. 
tbh in this I would clearly favor the lesser memory usage. Is there an email exchange, ticket or someting where this was discussed? Also totally unrelated, do you know whether implementations irl guard against 'vector.reserve(10)' but then inserting 11 elements? Or does this end up wasting large amounts of memory, assuming i dont ever append more data.
&gt; tbh in this I would clearly favor the lesser memory usage. Sure it's preferable in some circumstances especially on memory constrained systems, but that was considered a niche use case where people already roll their own solutions anyways. For most platforms the amount of memory you allocate is not the same as the amount of memory you commit from the OS... on the most common platforms used by GCC, ie. Linux... you could literally write the following snippet of code and not really have to worry about it: auto v = std::vector&lt;char&gt;(); v.reserve(1024 * 1024 * 1024 * 1024); // Reserve 1 GB of RAM. Behind the scenes ```vector``` will ```malloc``` 1 GB of RAM! And yet... it's no big deal for most use-cases since the OS doesn't actually allocate anything until you write to that memory. Similarly ```vector``` can use a factor of 2 and it won't make much of a big deal because that memory doesn't actually get committed by the OS until you write to it. As for whether there are e-mails/tickets etc... yeah there are several but I don't have links off the top of my head. There's the GCC mailing list where people investigating using a factor of 1.5 for ```std::string```, there's multiple bug reports where people suggest using a factor of 1.5 instead of 2... in each case the people in favor of 1.5 have strong theoretical arguments for why it's better, but have not yet produced any actual benchmarks to justify that argument, so the proposal continues to get rejected in favor of performing fewer allocations.
&gt;you don't need to set the cmake toolchain variable (or anything else for that matter) anymore, do you? Correct. The toolchain file is still needed for CMake.exe, but VS will detect the vcpkg integration and automatically pass the toolchain to CMake when running the configure step. Here's the blogpost you mentioned: [https://devblogs.microsoft.com/cppblog/whats-new-in-cmake-visual-studio-2019-preview-2/](https://devblogs.microsoft.com/cppblog/whats-new-in-cmake-visual-studio-2019-preview-2/)
I am very happy to see initiatives like these. I was very surprised that a system's programming language such as C++ is so lacking in tools for manipulating object storage and lifetime. It's something that I've been bumping into over and over again when trying to developer some high-performance algorithms. Patterns like copying live object storage or reusing object storage (luckily, the last is already covered by std::launder) can be very useful, but one has to move on their toes in order to avoid UB... 
&gt;You can already do that via reinterpret cast. As you point out, not in a legal way. 
It is not 1990 anymore. mov eax, edx add eax, eax add eax, edx shr eax vs mov eax, edx add eax, eax add eax, edx sal eax, 2 add eax, edx shr eax, 3 So, identical.
bit_cast too
Inheritance is incredibly powerful, if you know how to use it. There are a lot of folks around today who will try to convince you it's something to be avoided, but they clearly don't know how to use it to optimal effect. &amp;#x200B;
Care to elaborate on how you use it and where I'm going wrong?
I added a stream concept into my library before i added vector. This proposal seems to amount to taking functionality which today requires templating and generic programming techniques, and instead incorporating them into the core language. I'm not hating that sounds good, just trying to correctly frame the proposition.
\2. Prefer free function operator overloads to members/methods. Only a few operators are method-only. Use `friend` to implement non-member definitions as if they were members.
Without a solid example from your code, it's hard to know where (or if) things went wrong. Obviously if you have to keep re-reading a base class implementation, it's not a very good base class.
$.02 of mimic using of Go's interface, [http://coliru.stacked-crooked.com/a/88ac03db60bf4f85](http://coliru.stacked-crooked.com/a/88ac03db60bf4f85) 've to say, coding in C++ is really fun :-)
1. Inheritance is not a very good method to prevent code duplication (the reason is tight coupling). Inheritance is for defining polymorphic interfaces. If you have a bunch of functions that act on some data that you want in some number of classes then you should be using an "has a" rather than an "is a" relationship. If your project is using inheritance as a means it prevent code duplication then they are doing it wrong. It sounds like you are just dealing with crappy code. I would suggest getting out of there. 2. Operators in C++ are not special. An operator over load is just a matter of infix vs prefix notation. It honestly does not matter. It may be that this was a bad choice, but there is zero chance that if you work in C++ for very long you will not get used to it. 3. Friendship in C++ is generally discouraged. It is the most tightly coupled relationship in the language if your team is using it often they are doing it wrong. If your team is using protected data in C++ they are doing it wrong (there is almost no reasonable use case for this). Protected member functions should be rare. Inheritance should be rare. It is only there for the cases where you need runtime polymorphism. The thing to realize about the relationship between Rust and modern C++, and this will probably irritate the Rust fans, but Rust is essentially a language that was designed with the intention that it would let you do "Modern C++" while making it impossible for you to do "old school" C++ or C. There is some addition and removal of syntactic sugar, but that is inherently what Rust is. Likewise, there are some bells and whistles that have been added to C++ since Rust was designed (like rvalue references), but mostly the additions to C++ are to support the same programming paradigm that Rust is trying to support. If you know Rust and try to write you C++ to be Rust-like, then you are already doing "Modern C++". The problem you are dealing with is that there are a ton of programmers that know C and some object oriented language like Java or Python and think that means that they already know C++. It is hard to convince these people that Java is nothing like C++, Python is nothing like C++, C is nothing like C++, Go is nothing like C++. The syntax is very familiar, but the set of programming idioms is completely different. I have spent much of my adult life engaged in this task. I cannot recommend it as a recipe for a happy life. If you like Rust, then the best case would be finding a Rust job. If you have been using Rust for a fair amount of time and you are still not irritated every time you have to write C or Go then find work in C or Go. With your background it is only if Rust ruined you for C and you cannot find a Rust job that I would recommend you going through the arduous process of learning to use C++.
Assuming you are right about the new codebase you work on being one of those who abuses OO where composition would have been better, then you have to plan on the long term : * Master the existing codebase; companies don't usually employ new developers with the aim of refactoring what already works * Accumulate examples of design issues and alternatives you identify along the way * Improve in small increments * Reduce complexity at every opportunity * Simplify lifetime management by applying modern idioms (correct by construction) * Refactor from the inside, create new subobjects to isolate smaller behaviors and reduce the amount of moving parts * Gain technical credibility and/or codebase knowledge in the team * Identify encapsulation leaks * Seize the opportunities brought by new development projects to suggest any important refactoring previously accumulated that will benefit the new project (demonstrate the immediate benefit) There are probably a lot of other things that can be done. This isn't meant as an exhaustive list. The interesting is that it can be much more satisfying to improve a codebase like this rather than being stuck doing boring work because all the interesting challenges have already been properly solved and there's not much left to think about.
The article says it automatically casts it to a function pointer
I really like my job so I'm committed to learning how to use C++. :) I'm interested in finding a way for me to \*enjoy\* writing C++ rather than trying to write C in C++ (tempting) or do other things that would cause my team mates to accuse me of writing "nonidiomatic" C++ code for the sake of avoiding features I don't like. 1. Is there a good way to learn about the rvalue v lvalue etc stuff? The cpp docs I usually read are \*dense\* and there is always a lot of special cases. 2. This code base is using inheritance as part of a framework to create phases in a pipeline. The pipeline class works on the phase classes, which are part of a complex hierarchy of input/output classes and context classes for per thread values. My biggest issue is I constantly have to go through the whole code base of the framework to figure out what my class is implementing and what the relationships are. The inputs and outputs of each phase are also templated, but whether all the phases have compatible input and outputs isn't known until run time which makes errors super hard to debug. 3. Is it ok to just use structs instead of classes? Is that incorrect?
A non capturing lambda should do that already.
&gt; Inheritance that is only used to implement a purely virtual interface with no data is fine. When I am inheriting data and implementations, however, I pretty much have to crack open the parent class's implementation. In short, it's basically a method of copy and pasting code without the locality; it's not an abstraction that lets me reason about just behavior. There is also always the question of whether it's better to use inheritance or use composition/a library for would be static methods. Sorry, implemention inheritance has its issues but this argument doesn't make any sense. How is it different from applying your arguments to functions that call other function? You have to crack open the called function to see what it does, it's just a way of copy-pasting code without locality, etc? The same way that a function has an API that documents what it does, that in theory means you should not need to see its implementation, the same is true for a class. And that is true whether the class is being used via inheritance or composition. Where it does start to break down a bit is the fragile base problem, which you should specifically reference if that's what you mean. This sort of thing mostly occurs when you mix implementation and interface inheritance, and I'd agree in general this is a bad idea. In C++ functions are not virtual by default so you can exert more control over this sort of thing and try to be more precise. Generally speaking these problems are caused by virtual functions calling one another. Keep in mind that C++ style inheritance can do very powerful things like CRTP and policy based design, which AFAIK are not possible in the Rust type system (maybe with macros). It is true that there are more opportunities to misuse it as well though. Mostly it's good to focus on using inheritance in conjunction with specific techniques (for me, usually just pure interface inheritance, and pure implementation inheritance via CRTP) and not let things get out of control with deep hierarchies and tons of ad hoc features being used. &gt; Operator overloading via class methods is just weird in terms of how concrete it feels compared to traits. You have a limited selection of magic names that are baked into the class rather than having the class implement a set of interfaces. This also makes it impossible to constrain type parameters, as far as I am aware, to just focus on writing to behavior. In that sense, this also makes it a weak/not an abstraction just like parent classes. Well, in Rust you implement some interface called `Add`, which then "magically" gets called when + happens. It's not very different? I also don't understand what you mean by "impossible to constrain type parameters". Can you show an example of what you'd want to achieve that you think is impossible? &gt; Visibility is fine up until you get to friendship, protected, and just dealing with inheritance. I haven't used protected... ever. There's really almost no use cases for it, in good code, that does not overuse inheritance. Sometimes *maybe* protected member functions, in classes designed specifically to be inherited from (like CRTP mixins). Even then I just don't bother. Protected data not so much: http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rh-protected (you might find the core guidelines generally a good read when it comes to modern C++ style). Friendship is pretty simple. It's not something you should use too often to start with. I agree it can interact a bit confusingly with inheritance. This is just something you get used to. If you don't overuse either friendship or inheritance though, you're much less likely to encounter confusing corner cases with both. &gt; Most of my time writing C++ is spent using a framework that is very object oriented. Mostly what I can say to you is that your biggest issue here is not C++ but the design of the framework. People wrote code a lot like this in the past. It's unfortunate but you can do it with any language. 
The compiler is (probably) smarter than you * 3 / 2 lea eax, [rdi+rdi*2] shr eax, 3 * 13 / 8 lea eax, [rdi+rdi*2] lea eax, [rdi+rax*4] shr eax, 3
I wouldn't call Linux overcommit behavior that exists only on Linux "most platforms". malloc actually means malloc on BSDs, MacOS, Windows, and even Linux with overcommit turned off.
I wish the GCC team had published such a finding; we would consider changing our factor to 2; Gaby said 2 was better in real world cases citing this but didn't provide the actual benchmark data either :/
I would like to see some code that demonstrate your issues. With code, the community is more able to help making these particular uses of C++ right. I think the faster way to learn ownership in C++ is to forget ownership in other languages temporarily. I think these talks are good: - [CppCon 2015: Herb Sutter "Writing Good C++14... By Default"](https://www.youtube.com/watch?v=hEx5DNLWGgA) - [CppCon 2016: Herb Sutter “Leak-Freedom in C++... By Default.”](https://www.youtube.com/watch?v=JfmTagWcqoE) About value category (lvalue and rvalue) - [Value categories - cppreference.com](https://en.cppreference.com/w/cpp/language/value_category)
Right. I didn’t even bother to use -O3 in godbolt.
I could be wrong as I'm not an expert, but a Google search seems fairly definitive that MacOS and FreeBSD have overcommit by default. It's Windows that's the odd-one out. Once again, happy to be wrong about this.
I only used `-O1` and the source wasn't even fancy bitshifting, it was literally `13 * n / 8`
This reads like propaganda
It genuinely isn’t meant to be propaganda. It’s my personal perspective and I’ve come here to ask questions and get feedback. 
I’m using this framework https://github.com/facebook/wangle so maybe some help in how to use it correctly would be valuable. I mostly find the dense hierarchy of classes and templates to be overwhelming and it seems rather unnecessary. 
If overcommit allows you to stop caring about how much you allocate, why not go even further with a factor of 4 or even more? You wouldn't be wasting memory and perform even fewer allocations.
Friendship isn't the most tightly coupled relationship. Nesting is. This misconception leads people to prefer nesting.
&gt;There is also always the question of whether it's better to use inheritance or use composition/a library for would be static methods. Unfortunately a lot of inheritance in code is for reuse, where composition should have been the preferred way; and a lot of programming courses incorrectly teach reuse as a reason for inheritance. There is one or two cases in C++ where inheritance is necessary for reuse, and that would be to take advantage of the empty base optimization. One other case I can think of is for metaprogramming where you can encode some information as an inheritance relationship so that you can use stuff like `std::is_base_of` . &gt;This also makes it impossible to constrain type parameters, as far as I am aware, to just focus on writing to behavior. There are a few techniques to constrain type parameters. The newest way is `if constexpr` to choose the behaviour given the properties of some type, but that's only available in C++17. The old way was to use SFINAE, which still has some use post-C++14. You use them in conjunction with `type_traits` or other traits classes, or with the newer detection idiom. &gt;Also, is there a good reference document for lvalue/rvalue and ownership in C++? Potentially for someone who already knows Rust? Ownership is easier than in Rust, as ownership semantics is just defined per type rather than enforced by language. lvalue/rvalue won't tell you much about ownership since types are free to not take ownership even if given the chance. About the only thing that will tell you about a type's ownership semantics is if it has move constructor or assignment and no copy equivalents.
&gt; MacOS: [link] Even the post there indicates memory compression may be playing a role in those results. &gt; FreeBSD: [link] Everything there appears to be talking about Linux. (There's a digression about stack space being reserved with a guard page and only committed when the guard page is touched; everyone does that) If Windows is indeed the only platform that implements malloc() correctly maybe that helps make up for being unable to implement C11 aligned_alloc ever.
By non standard do you mean it may result in undefined behavior? Or that it is an atypical design? 
Dividing 2 consecutive Fibonacci numbers, gives you the GR, the bigger the numbers, the better the approximation. using golden_ratio_64 = std::ratio&lt;7540113804746346429, 4660046610375530309&gt;; // 64 bit using golden_ratio_32 = std::ratio&lt; 1836311903, 1134903170&gt;; // 32 bit
[Like this one](https://www.reddit.com/r/cpp/comments/b5omnv/the_amortized_cost_of_vector_insert_is_3/ejgu3rw/). 
&gt; ... in this context as there are simply tons of different costs and considerations ... That's what I mean with "... but in practice ...", it doesn't make any noticeable difference, whatsoever.
I think there could be a benefit in being a bit more aggressive at smaller sizes. Going 0 &gt; 1 &gt; 2 &gt; 3 &gt; 4 &gt; 6 &gt; 9, is a lot of "re-allocations", just to arrive at 9. I guess the system-allocator has a role in this as well, so maybe it doesn't matter.
&gt;you don't need to set the cmake toolchain variable (or anything else for that matter) anymore, do you This is true when you run 
Well, prefer nesting if one class is purely an implementation detail of the other, sure. Realistically though when people think of using nesting it's usually because the classes in question are very tightly coupled so it doesn't strike me as something that's misused a lot.
are they just creating wrappers around the current socket interface in C? And there will be no "new exciting" abilities I imagine? (since all this must be mediated through the same operating system networking api)
Yeah, the requirement for swap to be no fail and not invalidate iterators or references effectively kills the small vector optimization :/.
1. Roughly speaking, lvalues have *names*, rvalues do not. There are exceptions to the rule but it's a pretty good rule-of-thumb. In the statement `xyz = 0;`, the variable `xyz` is an lvalue. For a function `Thing makeThing() { return Thing{}; }`, the value constructed by the expression `Thing{}` is an rvalue. If it has a name, it is almost always an lvalue. In 99% of "normal" code, you don't need to worry about the difference. 2. Yeah, large OO designs can be overwhelming. Combined with poor documentation, it can also be a mess. 3. Yes. I use structs all of the time. `struct` and `class` are effectively interchangeable. Very little would've been lost if Bjarne had decided to drop the `class` keyword from the language. Don't conflate C++ and OOP. Unlike languages like Java, OOP is just an option available in C++. To the extent I use it at all, I limit my OOP designs to small tightly-scoped problems rather than grand overarching hierarchies. RAII and templates are the biggest value-adds for C++. If you understand those two concepts well, they will take you a long ways.
Very helpful! Do you have a methodology when you aren't using OO? Do you just use free functions?
Because you then need to balance overcommitting memory against physical spatial locality. By allocating way more than you need you end up risking a loss of physical spatial locality even though your data is spatially local in virtual memory. This can degrade the performance of your entire application as a whole as it throws off various heuristics and strategies that the kernel uses to ensure that memory that is spatially local virtually is also spatially local physically. You can gain additional insight about this phenomenon from here: https://en.wikipedia.org/wiki/Cache_coloring
Interesting, so there is a drawback to overcommitting.
Why are modifications needed? Doesn't range-v3 use std::pair?
\*You\* are the one misleading beginners. If one doesn't need performance, one shouldn't use c++. \*You\* want to grow this community for your own personal reasons, whichever they are, without consideration for the hell that awaits programmers learning c++. One of the most complex language out there, due to performance considerations.
Its toxic and circlejerk community. Just like Dota. Home sweet home.
json for modern c++ sucks
It shouldn't compile because the functions are supposed to have different types.
Where is the pricing information?
You can do full-blown functional programming in C++, complete with monads and higher-order functions. However, don’t think of a function of the basic unit of your design. Think in terms of overload sets. An overload set is all the different overloads of a particular function name. Thinking in terms of overload sets is really useful because it makes it easy to write templated code. And templates are the *best* way to avoid code duplication. TL;DR overload sets are useful because they allow you to create a uniform interface for otherwise incompatible types. Also! Here’s an example of writing lazy evaluation in c++ using iterators: https://bartoszmilewski.com/2014/04/21/getting-lazy-with-c/
Can you elaborate?
Homework assignments do not belong here. Suck it up and do it yourself - you might learn something along the way.
No. 
[I think, here you can get your answer.](https://www.reddit.com/r/cpp/comments/b61c74/c11_what_is_possible_to_do_with_movedfrom_object/)
bit_cast returns by value no?
that depends entirely on the object, everything is different. Basically anything which involves making horrible mistakes, because moving is supposed to transfer ownership of allocated memory. So it really depends on how the object and the move operation itself is implemented.
You will have gained nothing. Either do it and learn something or dont do it, but at least be a man about it and stop cheating yourself. 
I don't think you can achieve what this proposal suggests with any amount of template programming. 
Could you double check your link?
You can always destroy it. Anything else is up to the implementor of the class. 
&gt; Operator overloading via class methods is just weird in terms of how concrete it feels compared to traits. You have a limited selection of magic names that are baked into the class rather than having the class implement a set of interfaces. This also makes it impossible to constrain type parameters, as far as I am aware, to just focus on writing to behavior. In that sense, this also makes it a weak/not an abstraction just like parent classes. Are you aware that you can implement most operator overloads as free function (templates)? 
After moving an object, it's still in a valid state, but you don't know what state. That means you can call any function on it that doesn't have preconditions. One of the most useful things to do is to call a function like `std::vector::clear`, which has no preconditions and leaves the object in a well-defined state. (In practice calling `.clear()` on a moved-from vector isn't needed, but it's necessary to be correct according to the standard.)
Ah the good ol' reddit switcharoo
Not downvoter, but c++ can actually provide some opportunties for better performance AFAIK
Protected can make a lot of sense for copy /move constructors and assignment operators if you use implementation inheritance (which I find much more useful than many others I have to admit).
&gt;Also, I keep hearing about "modern" C++. Is there a guide or book on how to code in "modern" C++? The resources I have found so far only go over features, but not style. I think a good resource on how to use modern C++ is the [C++ Core Guideline](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md). Modern C++ most of the time means that: * You should use `std::unique_ptr` for pointers with a unique owner. `std::unique_ptr` is basically Rust's `Box`. * Use `std::shared_ptr` and `std::weak_ptr` if your pointer is owned by multiple object. `std::shared_ptr` is basically Rust's `Arc`. But there are some cases when `std::shared_ptr` is [not atomic](https://snf.github.io/2019/02/13/shared-ptr-optimization/). There are no equivalent to `Rc` though. * Use `std::move` to pass ownership. This is equivalent to Rust's default ownership behavior (Rust is move by default, C++ is copy by default). BUT! Unlike in Rust, in C++ nothing guarantees that you can't use a moved object. If you move your pointer out of an `std::unique_ptr` and then dereference that `std::unique_ptr` you get a null pointer exception. So you should use `std::move` with care. So, Modern C++ is basically a worse Rust. It requires a lot more attention from the programmer, since there are no compiler checks, but you can easily apply your knowledge of Rust of write good Modern C++ Off-topic: Lol at this subreddit for downvoting anything that has "Rust" in it's title. Rust is good for the development of C++, just accept it.
&gt; Keep in mind that C++ style inheritance can do very powerful things like CRTP and policy based design, which AFAIK are not possible in the Rust type system (maybe with macros) Can you think of an example? I tend not to reach for CRTP and I tend to think of "policy based design" as just using more template parameters to increase genericity. The only place where I used CRTP is for implementing expression templates to save some code duplication. But in Rust this could probably be done via "default trait methods". &gt; I also don't understand what you mean by "impossible to constrain type parameters". I think they mean the ability to express requirements for template parameters to constrain a template. In Rust this is done via traits and in C++20 we would do this using concepts. For now, we do this by exploiting "SFINAE" which is kind of a hack but "works" in a lot of cases.
I just read the part of Stroustup's Tour book that explained this. IIRC, apart from what others have said, you're allowed to assign to a moved-from object as well.
Yep, fancy bitshifting is completely useless on modern compilers. My favorite example is when you write: return m*65534; clang outputs: mov eax, edi shl eax, 16 sub eax, edi sub eax, edi but if you do: return (m&lt;&lt;16)-(m&lt;&lt;1)-m; clang outputs: imul eax, edi, 65533 
&gt; I don't think you're right about this. Running chrome is usually the most computationally intensive thing most people do on their laptops You mention laptops. Laptops have batteries. Doing more computations will always drain the battery faster, even if the program is "fast enough". This was especially glaring with Atom, it might have improved since I tested it, but at some point it drained my battery noticeably faster than Notpad++ or Sublime. Performance still clearly matters, even for very basic things like editing text. 
Hard coding a dependency on and automatically running vcpkg from a project's cmake file is imho a very, very bad idea.
VS2019 is the one that automatically uses vcpkg.
Re: 3, the *only* difference between a class and a struct is that members in classes are private by default, and members in structs are public by default. Because I prefer to write the public interface at the top of the file, and I am lazy and never know how `public`/`private` should be indented, I generally use structs. As others have mentioned, nothing would be lost from the language if the `class` keyword had never been added.
As for programming in C++ using a functional style you might want to check out this book here: [https://www.manning.com/books/functional-programming-in-c-plus-plus](https://www.manning.com/books/functional-programming-in-c-plus-plus) &amp;#x200B;
Said that, I tried to convince ppl in my project of a Rust rewrite because I start to feel pure C++ is getting more and more complex without actually making my job easier.. No luck so far but I keep trying. Do you have any experience with exporting a C interface from Rust so that e.g. a C++ frontend can use it?
bit casting only works on trivially copyable types. It will fail to compile with anything else. As the types being cast are trivially copyable, the compiler can elide the value copy entirely, and perform no work.
There has been enormous progress in recent years on improving the formality of the object model in C++. Less so in C, but even there, it could be that the time is finally right. Historically it wasn't possible because of the huge variation in hardware e.g. some C implementing architectures implemented all pointers as a key value store. In recent decades hardware has become far more homogeneous, and thus more can be standardised than before.
Currently it is UB to serialise or deserialise anything but trivially copyable types. Thus, serialisation and deserialisation must convert objects into a trivially copyable type i.e. an array of byte. This is expensive and often unnecessary. This proposal seeks to enable more types than just trivially copyable to be persisted without involving an unavoidable memory transformation.
Generally, it can be destroyed or assigned to. That’s it. Use it in any other capacity and you’re playing with fire.
FYI, I just added property::packs which removes any usage of strings, and it uses relative paths. This basically allows properties to be near 1 lookup per property which is the fastest it can be. This was done without sacrificing any of the features. So at this point I would say yes this is a bad ass property system which is fast. However depends of what you are doing you may still want to stick with strings. Strings are much easier to deal with when you have different versions of data / backwards compatibility. &amp;#x200B; Cheers.
As for value categories: There are basically two axes involved that matter semantically: 1. L versus R. 2. GL versus PR. There are three legal combinations of these two dimensions: L, X and PR where X is this funky intersection of R-values and GL-values: \ L R ---+------------ GL | L X | PR | - PR L versus R: This affects overload resolution. Depending on the value category of a function parameter, the compiler might pick a different function from the overload set. This is useful for distinguishing between objects that can be moved from and objects that the caller might still want to use after the function call. void function(MyClass const &amp; x); // prefers L-values void function(MyClass &amp;&amp; y); // only for R-values As a general rule, you are allowed to mutate the object `y` refers to in the 2nd overload. `y` refers to an object that was the result of a PR-value or X-value expression. In the first case (PR) the object had no name in the scope of the calling function which makes it impossible for the caller to access it again. So, it's OK to mutate it. The second case (X) is usually the result of the caller explicitly stating "I'm not interested in this anymore" via `std::move` or `std::forward`. So, it's *also* OK to mutate the object without causing surprizes. The ability to mutate it allows for some performance optimizations. This is usually done for more complex types in a "move constructor" as an optimization for a copy. GL versus PR: GL is short for "generalized L-value" and PR is short for "pure R-value". This axis is about identity. Generalized L-values are expressions that refer to a piece of memory. And usually, we can refer to it multiple times (using the same name or expression). You can have GL-values of an abstract type as the result of dereferencing a pointer or using a reference. PR-values are either values (for types like `int`) or "real" temporary objects with no indirection. Examples: int variable; variable = 3; // ^ ^ // L PR // This is where the L and R categories have their names // from originally. L = Left, R = Right (in assignment) Producing all kinds of values using functions: int pr_value(); int&amp; l_value(); int&amp;&amp; x_value(); For rvalue references it really makes a big difference whether it is named or not. The expression `x_value()` is an x-value because the function returns an *unnamed* rvalue reference. But in a function like this void foo(int&amp;&amp; rvref) { // the rvalue reference `rvref` is actually an // L-value expression because it has a *name*. } Finally, I'd like to mention that there is some exceptional template parameter deduction rule for rvalue references which you might trip over if unaware: template&lt;class T&gt; void i_eat_anything(T&amp;&amp; r); int main() { int i = 23; i_eat_anything(i); // T=int&amp;, T&amp;&amp;=int&amp; i_eat_anything(9); // T=int, T&amp;&amp;=int&amp;&amp; } This deduction rule together with "reference collapsing" (&amp; + &amp;&amp; = &amp;) allows "perfect forwarding": Accepting (almost) anything and being able to forward such parameters with their original value category (w.r.t. L versus R) to other possibly overloaded functions.
1. The was a pretty good basic explanation about it so I'd just add two cents. First, the value category is a property of \_expressions\_, not objects. Second, the most important part is to distinguish prvalues from others. 2. The problem of the framework, not the C++. C++ is multiparadigm, people often mess up tools. 3. Many people distiguish them semantically. Classes for invariants and structs for aggregates. Per Core Guidelines.
This is incorrect. After a move, std::vector is guaranteed to be empty.
rust is basically an amputated modern c++.
I am confused - what is not true, and what is your citation? As far as Standard Library objects are concerned, moved-from objects are in a "valid but unspecified" state regardless of whether they were the source of a move construction or a move assignment (unless otherwise specified, e.g. shared_ptr/unique_ptr guarantee that moved-from is empty).
According to cppreference (see [here](https://en.cppreference.com/w/cpp/container/vector/vector)) move-constructing without providing an allocator or by providing the same allocator as `other` results in `other` being empty. Otherwise an element-wise move is performed which does not guarantee `other`'s emptiness. When move-assigning, however, `other` is put into an unspecified state (see [here](https://en.cppreference.com/w/cpp/container/vector/operator%3D)).
Isn't auto_ptr horribly broken? I've read that somewhere, is that true?
did you just use an and &amp;&amp; in a comment 
Implementing the iterator interface is one example, where you can use CRTP (consider boost::iterator_facade)
And then you get people doing crazy things like using `std::basic_string&lt;T&gt;` as a vector.
Did you mean: *recursion*?
rm -rf $1 # What could go wrong?
https://www.manning.com/books/functional-programming-in-c-plus-plus I haven't read the book, yet, but the author's blog has taught me some interesting techniques.
It's important to note `std::move` in C++ actually doesn't move anything, it only makes moving possible by casting to rvalue. Passing such a construct to a function can actually end it three ways: - object is moved, or - object is not moved, or - object is copied 
Exactly.
Assign or destroy.
There are other ways to program in C++, using generic or template metaprogramming that works just like Python duck-typing. The advantage of generic programming is that it does not have the runtime overhead of inheritance and a templated function works with any class that matches the type requirement regardless of the inheritance hierarchy. The only problem of templates is the loss of runtime polymorphism and the slower compiler time. &amp;#x200B; For instance, the function showType&lt;T&gt; works with any class implementing the methods .Name() and .Size(), the template in this case generates overloading functions for every type instantiated. &amp;#x200B; template&lt;typename TShape&gt; void showShape(TShape&amp;&amp; sh){ std::cout &lt;&lt; "Shape name = " &lt;&lt; sh.Name() &lt;&lt; "\n"; std::cout &lt;&lt; "Shape size = " &lt;&lt; sh.Size() &lt;&lt; "\n"; } &amp;#x200B;
Moved-from state is merely a convention, the language itself does not have this concept. At the very least, it is reasonable to assume that its destructor can be called.
Rust is what modern c++ tries to be ;)
I can find no support for this in C++17. In 26.2.1/4, it says that for `X u(rv);` (where `rv` is a non-const rvalue), the postcondition is &gt; `u` shall be equal to the value that `rv` had before this construction In 26.2.1/16, it says that for `X u(rv, m)` (where `m` is an allocator), the postcondition is: &gt; `u` shall have the same elements, or copies of the elements, that `rv` had before this construction I would _guess_ that the intent of cppreference was to say that using a different allocator will copy elements, and therefore will have linear complexity and probably leave the original elements in `rv`. However, writing that the moved-from object is "guaranteed to be `empty()`" sounds incorrect to me.
Combining c++ and rust through a c interface is imho the worst you can do, because you are loosing any guarantees AND power the c++ or rust world can give you if you stay in one of the two languages (you can'tuse templates, raii, rusts borrow checker etc. . At the same time, you now need a hybrid toolchain, package management....
I don't know where you work, but if you refuse to work at places with crappy code I feel like there is nowhere to go. Problem areas are opportunities to improve. Companies can't rewrite all their code at the drop of a hat whenever Herb Sutter makes a blog post.
I'd recommend reading "Effective C++" by Scott Meyers. He goes over a few things from your OP and questions in this thread. Like how there is really no reason to use protected.
What language standard are you guys using?
After going through the draft and the relevant cppreference [discussion page](https://en.cppreference.com/w/Template_talk:cpp/container/constructor) it seems it is not directly stated in the standard. However, it is argued that it is the only possible way to offer the complexity guarantees of the std::vector operations. Howard Hinnant, who I believe is a member of the standards committee and directly involved in designing rvalue references for the standard explains it in detail [here](https://stackoverflow.com/a/17735913/4341534).
That is both true and very unfortunate... Lambda would be an ideal choice as glue for C++ callbacks from C libraries if they were convertible to function pointers with C linkage. Instead one has to write meaningless one-liner functions. Free functions! One cannot even hide it using static member function as those can't have C linkage either
I actually actively dislike this type of template programming, because it's essentially write-only. You can't meaningfully answer the question of "what other methods do valid inputs to this function have?" I much prefer C# interfaces and generics, because the language will outright tell you that this interface doesn't support .Count(), without finding all callsites. To make it worse, there's no location anywhere that can tell you the expected semantics of .Name() as it relates to this function. I think it's absolutely atrocious that this style of programming is regarded as the future for a statically-typed language, and it demonstrates some pretty poor judgement on behalf of everyone involved. And yes, we're adding concepts and contracts to deal with it, but it's pretty fucking late now.
Right. In Rust that use case that is covered by traits + default methods.
Member functions don't imply i OOP. Class hierarchy, interfaces and the layout of the code can indicate OOP style. For example, you can use data oriented design but using handles with an OOP style API.
&gt; if you refuse to work at places with crappy code I feel like there is nowhere to go. Pretty much this.
Side point since you mentioned free functions: If you're using the standard library, many functions have received overloads which allow you to provide your own allocators and destructors. These can be used when interfacing with C libraries or libraries that use "init" and "free" functions instead of classes.
&gt; this style of programming is regarded as the future for a statically-typed language by whom? :) Stroustrup apologized in [D&amp;E](http://www.stroustrup.com/dne.html) for it saying--and I'm paraphrazing from memory here--he didn't know how to solve this problem. This "compile-time duck typing" is a double-edged sword. I agree with you that it can be very difficult to read. When I look at Python code, I have the same problem. What are all these parameters supposed to be? The code is not self-documenting. But I could imagine that conceptifying these kinds of templates may end up being nontrivial in at least some cases. We need to come up with *good* concepts to make this easy and terse and avoid enumerating a concept for every tiny bit of functionality we'd like to use. I'm looking forward to concepts in C++20. Have been waiting for too long.
No, it has not influenced C++. Partly, because most of Rust ownership comes from modern C++.
&gt; Use it in any other capacity and you’re playing with fire. There are objects for which this is explicitly not the case. `std::thread` and `std::unique_ptr` for example have post-conditions on being moved from.
Where do you get that this implementation is wrong? Everything in standard C++ you can do to check whether the objects are allocated will actually allocate the memory. So after the as-if rule it complies with the standard.
Far too slow compared to other solutions is one of the reasons. In many projects We spend now time replacing it... By far too many allocations as well, causing too much pressure in multi-threading apps. As soon as you want to deal with error properly, it is getting annoying very quickly. Otherwise, yes it does the job. That said It has tho a few side featuresregarding merging and other, that can be handy in some particular cases
After moving from an object, it is left in a valid but unspecified state. (i.e. you dont know the state, but the destructor must work properly, and any operations that have no preconditions and leave the object in a predictable states can be used to keep using that object) vector&lt;int&gt; a (10, 5); vector&lt;int&gt; b (move(a)); a.assign(10, 5); assert(a == b); // should never fire
This style of programming is in all over STL and lots of other template header-only libraries. &amp;#x200B; \&gt; You can't meaningfully answer the question of "what other methods do valid inputs to this function have?" I agree with that and this a of the biggest problems of template meta-programming as it is hard to restrict type parameters and figure out what kind of type parameters the function accepts. However, it is a price to pay when heap-allocation is not acceptable or in high-performance code. &amp;#x200B; \&gt; And yes, we're adding concepts and contracts to deal with it, but it's pretty fucking late now. Exactly, that is why they are adding concepts language feature and contracts. To provide better templates error messages and make the type parameters specification explicit to the reader. &amp;#x200B; \&gt; I much prefer C# interfaces and generics, because the language will outright tell you that this interface doesn't support .Count(), without finding all callsites. T As far as I known, C# generics does not support this type of template meta-programming of C++ that is quasi statically typed duck-typing. C# generics also erases the type information, the C++ generics generates code or object-code overloading functions that makes the code faster. Another benefit is that it does not depend on any class hierarchy and has no runtime overhead. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; this will probably irritate the Rust fans, For what it's worth, I don't think it will. I've used an analogy like this myself, at times. I think it's \*slightly\* reductive but a good starting point. What analogy isn't a little reductive, eh? That's kind of the point.
"Effective _Modern_ C++" (also by Meyers) is a better answer to OP's 'edit' question. The first one would help more with OP's original 3 issues.
I feel like it has been regarded as the future, despite being nigh-on unusable, because no one has wanted to introduce the interface keyword. Even concepts feel like an active refusal to just do interfaces properly by trying to describe the shape of the thing rather than the type.
Isn't `std::basic_string&lt;T&gt;` contiguous nowadays, i.e. isn't it just a vector of (wide-)chars?
Re 1), the "Effective ..." series by Scott Meyer mentioned also in another answer is a pretty readable series of books on the foibles and best practices of C++. You might want to grab "Effective Modern C++" for the lvalue and rvalue stuff, and "Effective C++" for most of the questions regarding inheritance, though I'm afraid the general answer for the second topic will be "C++ uses inheritance like a scalpel, in selected places, not like a foundation to everything it does, as Java does". 
Even if that were true, it doesn't contradict my statement. I never said rust had influenced c++, I said it is what c++ aspires to be. However, realistically I do believe that the competition in form of rust does have some influence on the language development.
As someone who's trying to get a grasp on modern C++ after not touching it since early 2000s (and using mostly the pre '98 version of C++ from visual studio) I found both to be incredibly enlightening. Obviously some things in EMC++ invalidates things in EC++, but going through both seems more complete in terms of trying to get your head around what the hell to do while writing C++ code.
Yes, it can but these two languages are somewhat same, given the proper implementation. I am not sure why people have downvoted me for stating facts. Anyway, as I said, if all people wanted was speed. C is a cheaper alternative. You get C++ performance, or something quite close to it, without all the hassle of learning C++ in and out. C++ has tools to write code in a less error-prone way without sacrificing speed. This is why people pick C++ over C. Speed isn't the factor. I am yet to see someone ditching C for C++ with speed concerns.