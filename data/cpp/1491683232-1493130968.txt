&gt; As for now, every function returns a boolean if it succeeded or false if it didn't. [wat](https://s-media-cache-ak0.pinimg.com/originals/66/74/75/6674754b6b4502ce0d22928dceba3ec4.gif)
have you tried clang's [include-what-you-use](https://include-what-you-use.org/)?
Am I the only person who thinks that syntax is getting progressively uglier and less intuitive? * An open paren with a closed paren you have to hunt to find * A square bracket and comma that seem wildly out of context * An equals sign which isn't forming part of any obvious assignment * The keyword 'this' out of nowhere, like that's somehow supposed to illuminate anything I've kept up with most of the changes to C++ over the years, even when the language nearly disappeared up its own most-vexing-parse in the template metaprogramming days, but damn if that line doesn't look like someone threw up some perl into the middle of a line of javascript.
I would really really like to see you add support for translation of r-value references to C++98. ;)
It's ugly. It's a challenge to propose a better grammar that isn't ambiguous or backwards incompatible though.
The final results of your constexpr code needs to be made seperate from the intermediate data produced by it. if you have a constexpr object with multiple members but only one which is needed at runtime, create an immutable copy of that single member. Otherwise you will have enormous code bloat. And always check the assembly when dealing with constexpr to ensure you're not accidentally keeping some data around. With the right methodology constexpr can actually eliminate code bloat massively
Oh nooo not GCJ! It will be sorely missed.
have you not used lambda? This looks like normal C++ lambda code to me(aside from the *this which is new)
&gt; Having multiple closing parens on the same line Did the person who wrote the style guidelines you use get started with lisp?
Point taken. I have removed some "crap", completely erased some sections and fixed the grammar a little when not tired. As a result everything is simpler now. 
One way of fixing "unclear ownership" is to make copies of what you need.
I believe fPIC tells the compiler to emit position independent code, that means the code can be placed anywhere in memory. This is required for dynamic loading as you cannot know before loading the library where it will be placed in memory. However it doesn't imply a dynamic library. 
Modern ELF implementations require that dynamic shared objects are fully relocatable without run-time code modification, that is, they must only contain position-independent code (PIC). Not all constructs the compiler by default uses result in such position-independent code, and `-fPIC` tells the compiler to avoid problematic constructs. `-shared` just tells the static linker to produce a dynamic shared object as its output, and not a regular program. But at that point, the compiler has already run, and if any of the object files contains position-dependent code, the link will fail.
You mean that one header won't be included twice if it has `#pragma once`, or something else? Anyway, I think those compilation problems occur, because general-purpose libraries tend to be a) template-heavy, b) used in many .cc files (= compilation units).
What bothered me a few years ago, was that you'd need `-fPIC` on x86_64, but not on regular x86. It's still a mistery to me why 1) 32 bit doesn't need to be relocatable, 2) It's not default on 64 bit, while you obviously (always?) need it.
Uninitialised data would be my guess. Debug will default initialise everything; Release will only do so if the standard mandates and otherwise it's free to leave whatever garbage was already there. Check whether all pointers are initialised to nullptr; all ints to 0 or immediately to their proper value; all floats to 0.0; etc. Unfortunately, last time I checked there I didn't see a good way in VS to detect uninitialised data at either compile or run time but hopefully someone who knows better can chime in. Edit: spelling
On Linux, Valgrind (memcheck) can detect usage of uninitialized memory. I don't know of an equivalent for Windows, but I found [this stackoverflow question](http://stackoverflow.com/q/413477/).
When ELF was introduced for i386 on Linux, there was quite a bit of a body of position-dependent code, including hand-written assembly code. The i386 has only somewhat limited facilities for position-independent code, so the performance overhead was quite noticeable. I assume that `DT_TEXTREL` support was kept in the toolchain as some sort of compromise. You don't need PIC for the main executable (unless you want the extra security hardening load address randomization brings).
The distinction is not shared/static but position-independent/position-dependent. Some static libraries are compiled as PIC to permit linking into dynamic shared objects. “Static” linking against shared objects would theoretically be possible if the toolchain supported it, but it does not. You need the individual object files before the DSO is created, then it will work in almost all cases. The reason why static linking of pre-existing DSOs is hard on i386 and x86-64 is that even position-independent code must have a fixed offset to its data segment. This means that each such DSO would need its own data segment, but the glibc dynamic linker only supports one data segment. That's why everyone (but the distributions) copies `.so` files around and bundles them with their applications.
You need to provide a LOT more information on what you're doing. Different behavior is usually linked to optimizations the compiler does. Run it through a static analyzer and address any issues . If you're using interrupts or threads you may have a synconization or data caching issue.
It's not really funny actually for people who *are* really autistic - it's not like these people can just switch on or off "being autistic". It's so to speak a life-long illness.
Wow, there is a Windows version Valgrind eventually. That's really cool. Did you have experience on it? Is there any difference with the Linux version? (The Windows version is still prealpha) Recently I found Dr.Memory for Windows and it's quite useful, but it crashed on a larger project.
You need at least tell what's the "wrong result" to get better help. As others pointed out, uninitialized data may most likely be the reason. For more specified, check if your any class member not in the initialize list. 
Using `-fPIC` on i386 comes with a runtime cost. There is a nice article about it [here](http://ewontfix.com/18/). Things are better on x64, because it offers instruction pointer relative addressing. Edit: This was meant to be an answer to rubdos.
I believe dynamic library can know where it will be loaded. It can be created non-relocatable, but then there is a problem when 2 libraries want to be loaded at the same address (plus lack of this false-safety of loading stuff at random addresses).
Nope, no experience at all - I gave up on Valgrind when I swapped to Windows and only just googled now but was very glad to see it :) I imagine you may have to build with gcc to use it, which might be problematic for anyone using MS-specific calls, but I'll see; I've got a project I've been working on in MSVC today actually. I've never used Dr Memory -- a colleague had similar experience to you while trying to track down some uninitialised data; it couldn't cope with the sheer size and/or aged clunkiness of the codebase -- and I'm currently reliant on VLD to find memory leaks and tedious hunting to find uninitialised data...
don't put optimisation level too high if you depend on float special values like nan, infinity, etc..
Unfortunately, I didn't use assert.
thanks you, im working on it!
First thing to try might be to make sure the warning for unitialised variables is enabled: https://msdn.microsoft.com/en-us/library/1wea5zwe.aspx If the project wasn't yours to begin with, also search your entire solution for 4701 and C4701 to make sure no-one's done #pragma warning(disable: 4701) somewhere which would suppress it. You might ask why anyone would suppress such a useful warning but we've all seen some impressively silly things done in large codebases.
If the code is not relocatable, you probably have to patch it at load time to take into account the address where it has really been loaded. However, it means it needs to always be loaded at the same address to be shared between processes (and I don't know if any sharing is even done if it is really patched). I don't know the details, but there is also a PIE for position independent executable (which seems to subtly differ in the mechanisms and the micro performance profile of various items), so you might want to use the option corresponding to what you are compiling a translation unit for (.so you will 99.99% of the time want fPIC, executable you probably want fPIE in most cases, but for some exotic builds you can very well want to build a non relocatable static program) Probably when the x64 ABI was defined, building .so without PIC has been considered an unimportant thing to support (or even dangerous!), and actually you should probably view it as a legacy thing for x86. 
Thank you so much, I have solved my problem!
&gt; you should consider typeid hashes. this may break horribly with DLLs
Only if you also do a default capture, and using default capture when doing anything nontrivial is a bad idea. I generally have no problem with `[=]` or `[&amp;]`, but once you're manually setting capture rules for some of your variables just go ahead and explicitly list them all.
Note that `dlclose` and C++ is quite complicated. If you use certain language features, the toolchain will mark the shared object as undeleteable, which means that you can call `dlclose`, but it will not actually unload the object (so you can't reload a new version of the library). You also need to consider the impact of smart pointers (and other sources of callbacks). If you keep a smart pointer around after the `dlclose` call, and the type of the object was defined in the unloaded shared object, eventually, object destruction will cause a crash because the destructor is no longer around.
It should be called "Understanding dynamic linking on Linux"
What language features would cause a shared library to not be unloaded?
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/64d0ci/why_i_have_different_results_in_release_build_and/dg1pszs/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Let's say you're on a microcontroller that lacks branch prediction, and you have a switch statement which is controlled by an enum. The switch simply returns another value based on the input value. You could simply use a lookup table, but that would increase the size of the executable. So instead you could use a constexpr function which analyzes the bitwise relationship between all of the ouput values. More likely than not, all of them will possess a set of common bits or be based from a common lower bound. You could use another constexpr function which uses this lower bound or common bitmask to determine the number of bits required to encode the range of values. You could reduce the range of values to simply one or two 32 bit constants that are unpacked using a mask generated from what was originally the controlling expression of the switch statement. Additionally the compiler will be able to reorder the unpacking to better utilize out of order execution. Compressing data and generating branchless code is very easy with constexpr. Note that this will not always give a performance benefit, especially if one of the output values is far more likely than the others, but for cases where all are equally likely branchless code will be faster and smaller. 
A few warnings, too: Constexpr means inline. Don't call constexpr functions at runtime. You will definitely experience code bloat from that. Always assign constexpr results that are created within a scope intended to be evaluated at runtime to constrexpr variables, as this will assure that the code is evaluated at runtime. And if you're using GCC make sure you have all warnings on. If the address of a local variable persists outside of a constexpr functions scope, the value will automatically be set to nullptr, which can be very bad if 0 is actually a valid address on the platform your code is running on. And always check the assembly until you become more acquainted with constexpr
Looks like you can write x86 assembly and integrate it directly with your C++ code. 
ctai is kind of small framework, that can interpret very simplified x86 assembly code in a complie-time. As the result it returns value from the eax register. It's written as a template metaprogram. And if you wonder if it can be useful in daily programming, the answer is no. ctai is completely useless (:
it appears the result is constexpr
However you seem to have actual control flow handling, which is pretty impressive
Perhaps you're right. Haven't done c++ in windows for some time. Lots of C#.
Yes, ctai::execute_code is a template constexpr int32_t value, so of course it can be used as a template parameter. In fact, everything here is a type or a single constexpr value. ctai::execute_code takes the code as a template parameter. Even actual asm code is an alias to ctai::string struct.
Anything that causes a `GNU_UNIQUE` symbol to be emitted. Typically, this happens when a template instantiation references a variable or constant which has to have a unique address within the program, like this: template &lt;int i&gt; class C { static int v; public: static int *value(); }; template &lt;int i&gt; int C&lt;i&gt;::v = i; template &lt;int i&gt; int * C&lt;i&gt;::value() { return &amp;v; } int * f () { return C&lt;17&gt;::value(); } The assembly contains: .section .data._ZN1CILi17EE1vE,"awG",@progbits,_ZN1CILi17EE1vE,comdat .align 4 .type _ZN1CILi17EE1vE, @gnu_unique_object .size _ZN1CILi17EE1vE, 4 _ZN1CILi17EE1vE: .long 17 
I wasn't interested until you told me that it's essentially useless, and now it sounds fun to me, for some reason. Maybe I'm just overinundated with over-the-top frameworks and super-enterprise libraries that my eyes glaze over a bit for things that aren't toy projects.
Can you add a comparison to reckless? https://github.com/mattiasflodin/reckless
In High Energy Physics [ROOT](https://root.cern.ch) is used for storing, accessing and analyzing data (among a host of other things). While as with any framework ROOT's approach regularly sparks discussions, I'd argue that its columnar data structures and their I/O is one of ROOT's strongest points. In particular, you'd likely want to look into the [`TNtuple`class](https://root.cern.ch/doc/master/classTNtuple.html) which is a simple cases of a ROOT [TTree](https://root.cern.ch/how/how-read-tree).
Obviously I have to ask if it is available with the AT&amp;T syntax ... :)
+1, this does indeed look great. With the move to modern C++ there's also a move inside ROOT to add safer and more high-level abstractions (which also use more idiomatic C++).
"misunderstood"
There is basically no real information here, just an unsubstantiated rant that goes nowhere and says nothing. &gt; So yes, you can write rather relatively efficient code in C++; and no, it is not designed for performance. Seems like a strange claim and isn't backed up by anything other than 'fortran IS designed for performance' &gt; But honestly, if you want performance, you should think about programming hardware directly. Then HDL and Verilog will be your languages of choice. I haven't taken a survey of how many of my customers have fpgas in their windows PCs, but I've been assuming the numbers are low. Now I feel silly.
Pinging /u/STL to let him know we all want to see it implemented in MSVC!
Y'all know I'm a library dev, right? I'm currently ranting at the compiler team, "I WILL BURN THE WORLD TO GET `if constexpr` IMPLEMENTED ONE MINUTE SOONER". Everyone else needs to get in line behind me :-P
It would be nice to have some simple usage examples in the readme.
I'm also an AT&amp;T syntax guy :(
Wow, you guys are taking it to a new level. 😀 I'm only a beginner, most of what I know of c++ is included in a simple "hello world". 😂 Pretty clueless about higher maths too, integers and such, I'm not attending a college, but a vocational school :(
IIRC, you need std::ref(*this) unless you want a copy.
You might be interested in Apache Arrow.
This would not be considered a new level, but very entry level for programming and math in general. There is resources for learning c++ and maths in just about every form of media you could think of. I suggest you take a look at khan academy online for learning math, even learning some basic c# through code academy could go a long way to helping you think like a programmer. If you are struggling with the foundations of c++ now, you'll want to kill yourself once you get to memory management and pointers.
[removed]
The first C++ compiler was not written in C++. It was written with "C with Classes". The preprocessor for that was written in C (turns "C with Classes" into C code). **Then** with C++ a more efficient/complete C++ compiler was written (using the compiler that was written with "C with Classes"). http://softwareengineering.stackexchange.com/questions/105313/how-could-the-first-c-compiler-be-written-in-c
You know about integers. You probably just don't know that you do. Integers are whole numbers. I.e. 5, 248, 70000 are integers, while 5.7 or 0.888 aren't What I meant by integer division is that you don't use a point for the result but only take the whole number and drop the remainder. Or with modulus you drop the whole number result and only take the remainder. Example: 7 and 5. Normal maths: 7 / 5 = 1.4 (because 5 * 1.4 = 7) ("real number") Integer division: 7 / 5 = 1 (because 1 * 5 + remainder of 2 = 7) ("whole number"/"integer") Modulus: 7 % 5 = 2 (remainder of 7 / 5) ("whole number"/"integer")
Is this something on the same track what Alexandrescu was presenting at CppCon 2015? [Declarative Control Flow](https://www.youtube.com/watch?v=WjTrfoiB0MQ)
There is actually something to it here: for consumers, performance comes from the graphics card, which hasn't been programmable in C++ until just recently (and even then, only a restricted subset). The other guys that are interested in performance (by which I mean "speed" and not "reliability", which is the real-time crowd) are the financial traders, and they _do_ write FPGAs.
If your C++ book introduces `new` and `delete` very early on you should consider it outdated. _Modern_ C++ (which dates from 2011) prefers using `make_*` for dynamic allocation. It doesn't matter if you don't understand what I just wrote, but there are a lot of older books (or newer books in the older style) around and it's important to be up-to-date or you'll be wasting your time.
By the way, there is a typo in the title, the library is called [GSL (guidelines support library)](https://github.com/Microsoft/GSL).
I know, I am embarrassed I put it in there. I should have used a smart pointer. 
&gt; in my personal experience it is easier to work with independent repos for different generations of a project Please learn how to use git. Switching branches in git is trivial. The way you use git is pretty much broken. Your personal experience mirrors this brokenness: garbage in so garbage out. Do it right and your experience will be better. Use smartgit, the de-facto GUI for git IMHO to learn git-ese by example. Even svn repositories are much easier to use via git, especially when using smartgit's extra sauce for that.
You cannot change the license without getting written permission from **all** contributors. The license is a big deal. Choose wrong and you're stuck with it with no way to change it. 
The license make the code useless for many. It has to be discussed because you insist on the code being useful. The licensing bug makes the code just as useless as any other major bug or design issue would and you can't artificially separate these concerns. 
Go doesn't have exceptions, you can recover from panics but it's ugly. I am only showing how clean closest equivalents look like, I am not claiming they are/work exactly the same.
yeah, the noexcept destructor was a red flag for me, because it forbids these finally() blocks from throwing exceptions. that makes the interface a lot more restrictive than it should be
No it is not. I'm working on the next version, which will be more dev-friendly and maybe someone will contribute and implement it (: For now I think I will focus on the Intel syntax only.
&gt; You cannot change licensing without dealing with every contributor. We know. If there will be any contribution then we will work with every contributor on the topic of license of contributed code. But we don't think there will be any contribution at all. Mainly because we are working on next version which, probably, will be different than v.0.1 presented here.
Somewhat lower level (designed as being comparable to NumPy -- whereas Pandas itself builds upon NumPy) but perhaps also useful in your context: https://github.com/QuantStack/xtensor/ Syntax cheat sheet: https://xtensor.readthedocs.io/en/latest/numpy.html
I've always disliked those, honestly, and many of the (ab)uses of RAII as well. Not that RAII should be avoided - far from it! - but I don't like using it to implicitly wrap blocks. I really prefer things like `using` from C# which make it clear that a particular value's lifetime encloses a clearly delineated scope. I just feel that if a variable or class's whole purpose is to enclose a scope, it should visually and explicitly do exactly that, and not masquerade as a local value. Such syntax could also address the never-ending requests for unnamed locals that such uses of RAII encourage. `{ std::scoped_lock _blah(my_lock); do_stuff(); }` vs `using (std::scoped_lock(my_lock)) { do_stuff(); }` I find the intent and lifetime of the second much clearer, even though I can obviously decode the first one without much effort. &lt;/two-cents&gt;
Well, if you push a bunch of things into a stack, and then you pop them, they came out in reverse order. If you push a bunch of things into stack 1, then you pop them all and push them into stack 2, and then you pop everything from stack 2, it will come out in the order you pushed them in. Which is the same behavior as a queue. There are some details to work out but that's the basic reason why building a queue from two stacks is easier than the reverse.
In my own experiments writing projects like this, compilers(especially gcc) don't like variadic templates with value parameters. A very simple optimization in both compile-time and compiler memory usage is to wrap all characters in a simple type and then working with that instead(eg: template&lt;char C&gt; struct my_char;). Source: https://github.com/J-Gamer/brainfuck-string-literal/issues/1
I'll pass point (1), "Good"/"Bad" is too subjective to be worth arguing. I'm ambivalent on point (2), while C++ certainly attempts to strive for performance, I regularly think there are *missed opportunities*. This seems a staple of design by committee or maybe the willingness to embrace as many use cases as possible. This is usually more apparent in the standard library: streams, mandatory memory stability in maps/sets, ... but there are a few instances where the language took a conservative approach at the cost of performance: run-time tracked moves and `noexcept` terminating on exception (instead of being undefined) are such instances where overhead is paid. Finally, I fully agree with point (3). C++ is not easy, and while the right set of guidelines may make it less complicated, they do not make even moderately easy. Still won't make me abandon the language, I derive too much utility from it, but I've seen (and still see) enough juniors struggling with its corner cases, and get caught myself regularly enough, that I'm at no risk to believe I've "mastered" it.
I think this is one of the unfortunate things about getting into C++ as a beginner, its so easy to run into bad reference material that ingrains bad habits early on (as I mention in my reply to OP). C++ Primer is at least new enough to avoid most of the nasty stuff.
Then you wrap it up, and a class like this might be useful to enable such wrappers. But its design perhaps suggests otherwise.
This was already posted above. You can have that in C++ https://youtu.be/WjTrfoiB0MQ
Plus, if your system is using `musl` libc library (such as Alpine Linux does), `dlclose` is just a noop, it doesn't support unloading. Reasons are explained by musl developers, mainly because great complexity and bugs experienced in GNU libc and all the "hacks" related to it.
Note that that example (using unordered_Xxx equality) is powered by is_permutation, so I don't see what you're saving there. Why make a container just to throw it away?
Ok, sure, there are also real-time signal analysis applications and the like, which also use specialized hardware. It does seem to be the trend for where real specialized performance is needed - get off of the cpu. And that frequently means a language other than C++. I really don't get what your beef is with what I said?
This is great post
I'm going to be the heretic here but why don't you try Rcpp: http://www.rcpp.org This wouldn't work so well with a pure C++ project but if you're after high performance data analysis it might just work and you get the advantage of the whole R ecosystem. Late edit: I didn't even know about this, but apparently you can even embed R in a C++ application: http://dirk.eddelbuettel.com/code/rinside.html
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/64lur5/new_to_coding_and_need_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
We get this question a lot. Please see [this page](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list).
Crazily enough there are places where performance matters other than highly parallel computations.
&gt; I think among other things one of the hardest things to reproduce is the clean syntax of slicing[:] I don't know anything about the Python library in question, but Eric Niebler came up with a [really neat way](http://ericniebler.com/2014/12/07/a-slice-of-python-in-c/) of replicating Python's slicing syntax in C++ for Range-V3.
Udemy was offering C++ for the unreal engine discounted for $15-20. If you can get it for that much, I'd say it's a worthy course.
at least for `noexcept` there is no overhead (by design. undefined behaviour was discussed until implementers reported that terminate can be implemented without overhead). The crucial thing is that the compiler can call terminate as soon as an exception is raised, no need for stack unwinding. Have a look at [this code](https://godbolt.org/g/Hf1WBC), you will see that there is no checking code involved (even at -O0). It does not even impede further optimisations. Compare to how that changes when you change the `noexcept` to `throw()` and use `-std=c++14`
You're incorrect and you need to stop misleading others. N4659 26.2.7 [unord.req]/12: "Two unordered containers a and b compare equal if a.size() == b.size() and, for every equivalent-key group [Ea1, Ea2) obtained from a.equal_range(Ea1), there exists an equivalent-key group [Eb1, Eb2) obtained from b.equal_range(Ea1), such that is_permutation(Ea1, Ea2, Eb1, Eb2) returns true. For unordered_set and unordered_map, the complexity of operator== (i.e., the number of calls to the == operator of the value_type, to the predicate returned by key_eq(), and to the hasher returned by hash_function()) is proportional to N in the average case and to N^2 in the worst case, where N is a.size(). **For unordered_multiset and unordered_multimap, the complexity of operator== is proportional to Sigma(Ei^2 ) in the average case** and to N^2 in the worst case, where N is a.size(), and Ei is the size of the ith equivalent-key group in a." "However, if the respective elements of each corresponding pair of equivalent-key groups Eai and Ebi are arranged in the same order (as is commonly the case, e.g., if a and b are unmodified copies of the same container), then the average-case complexity for unordered_multiset and unordered_multimap becomes proportional to N (but worst-case complexity remains O(N^2 ), e.g., for a pathologically bad hash function)." Emphasis mine. The multi containers must behave as if they use is_permutation, which can have quadratic behavior. (This can happen when all of the elements are considered equivalent according to the predicate, but they're jumbled up, so the "However" doesn't apply, and you're left with the Sigma expression.)
Sure but the boolean is not necessary. The implementation should define the move constructor and make it call an undefined function. If a move happens and it is not elided you will get a linker error. The move constructor is only useful for the above construct which will always elide.
So, it is mandated to call `==` not use the equals operator in the unordered set.
That's what I said. Each C++ update is made with the previous version of it. Every so often they made marketing refreshes of the product name, but nothing else changed. Each iteration was just as efficient as ever, since not losing efficiency was a core concept all along (the zero overhead rule).
There's some runtime overhead with sjlj exceptions (or at least there was with clang targeting 32-bit ios a year or two ago), but thankfully sjlj platforms are becoming increasing rare.
You're right, I was having a brain fart. I was thinking about using them within smart pointers. [http://stackoverflow.com/a/5030687](http://stackoverflow.com/a/5030687) But you're right, it would be fairly easy to create a generic class that wrapped COM object pointers and called the -&gt;Release functions in the destructor.
Wasn't thinking clearly. Updated my response. Maybe just hate the COM interface and want to find stuff wrong with it
Correct me if I'm wrong, but can't you "pretend" a shared library is static by linking in the whole thing via something like "-Wl,--whole-archive $(WHOLE_LIBS) -Wl,--no-whole-archive" (using g++, for example)?
As someone who has mostly just dabbled in C++, I find it intriguing the things that are made possible by constexpr and variadic templates.
In my limited experience, I never had a big benefit from specific game programming books. If you use a good engine most of the work is like connecting the right blocks and not a big engineering challenge. Just start by getting some experience using the online resources, reference manuals, examples and after that you can check again.
I kind of figured this was the case, just wasn't so sure. I thought maybe you'd need the basic coding knowledge then minor tweaks specific for game design. So that's good I'll just keep playing with the available information online then eventually grab a book.
I have been playing around with UE4 mainly the node editor seeing as how I only know the very basics of c++
So you wouldn't recommend even a regular c++ book?
What titles would you recommend?
What kind of game do you have in mind and what tools do you want to use? Keep in mind that most people bite off WAAAAAAY more than they can chew on their first project and end up getting stuck and frustrated and giving up. So, what kind of project do you hope to accomplish and what kind of timeframe do you have in mind?
It's a very good course. Ben is a great teacher. 
That's a good place to start, actually. It'll teach you the principles of coding and game programming with a pretty low barrier to entry.
A c++ book is probably a good idea. C++ can be a bit overwhelming without a good learning concept. Unfortunately I do not know which one would be good for you. Just keep in mind that modern c++ 11/14/17 is the way to go: some of the books teach error-prone and unnecessary complex C++98 styles. Or worse: they start as C introduction
well, doing anything with 3d graphics is incredibly complicated - both from a programming and a math perspective. A simple 2d puzzle game with sprites using some sort of toolkit (SDL would work), is a good start. For that, you don't need anything more than a basic grasp of C++, so any book will do. Doing 3d work with an established engine is somewhat more manageable for an intermediate project. 
Re &gt; **"** We're not calling is_permutation on the whole container, just on the resulting equal_range for each key. That's fine but the context here, what we're discussing, is a claim that there was no point in creating the container instances since they used `is_permutation` internally, and that claim is only meaningful if there's no difference in complexity. Context can be pretty important. --- Re &gt; **”** Condescend less, please. There's no need to for the personal characterization. --- I'm interested in learning. With both Visual C++ and g++ the code below seems to disprove your assertion that &gt; Your trivial algorithm is wrong, counting elements is insufficient Is the below code in error, or are both these compilers wrong, or are you wrong, perhaps? #include &lt;iostream&gt; #include &lt;unordered_set&gt; #include &lt;string&gt; using namespace std; struct Special_string { string value; friend auto operator==( Special_string const&amp; a, Special_string const&amp; b ) -&gt; bool { return a.value.substr( 0, 1 ) == b.value.substr( 0, 1 );} Special_string( char const* const s ) : value( s ) {} }; namespace std{ template&lt;&gt; struct hash&lt;Special_string&gt; { using argument_type = Special_string; using result_type = std::size_t; auto operator()( Special_string const&amp; s ) const -&gt; result_type #ifdef SIMPLE_BUT_WRONG { return hash&lt;string&gt;{}( s.value ); } #else { return hash&lt;string&gt;{}( s.value.substr( 0, 1 ) ); } #endif }; } // namespace std using M = unordered_multiset&lt;Special_string&gt;; auto are_equal( M const&amp; a, M const&amp; b ) -&gt; bool { if( a.size() != b.size() ) { return false; } for( auto const&amp; s : a ) { if( a.count( s ) != b.count( s ) ) { return false; } } return true; } auto main() -&gt; int { M const a{ "c", "c" }; M const b{ "c", "c++" }; M const c{ "c", "c" }; M const d{ "bcpl", "c", "c" }; { bool const a_eq_b = (a == b); bool const a_eq_c = (a == c); bool const a_eq_d = (a == d); cout &lt;&lt; boolalpha &lt;&lt; a_eq_b &lt;&lt; " " &lt;&lt; a_eq_c &lt;&lt; " " &lt;&lt; a_eq_d &lt;&lt; endl; } { bool const a_eq_b = are_equal( a, b ); bool const a_eq_c = are_equal( a, c ); bool const a_eq_d = are_equal( a, d ); cout &lt;&lt; boolalpha &lt;&lt; a_eq_b &lt;&lt; " " &lt;&lt; a_eq_c &lt;&lt; " " &lt;&lt; a_eq_d &lt;&lt; endl; } cout &lt;&lt; endl; // Simple: Right: cout &lt;&lt; a.count( "c" ) &lt;&lt; endl; // 2 2 cout &lt;&lt; b.count( "c" ) &lt;&lt; endl; // 1 2 cout &lt;&lt; c.count( "c" ) &lt;&lt; endl; // 2 2 cout &lt;&lt; d.count( "c" ) &lt;&lt; endl; // 2 2 cout &lt;&lt; endl; } Output: [H:\forums\reddit\009 is_permutation] &gt; g++ equality.cpp &amp;&amp; a true true false true true false 2 2 2 2 [H:\forums\reddit\009 is_permutation] &gt; g++ equality.cpp -D SIMPLE_BUT_WRONG &amp;&amp; a false true false false true false 2 1 2 2 [H:\forums\reddit\009 is_permutation] &gt; _ I had a bug in the code when I first posted (hashes must be equal for values that compare equal!), which you can reproduce with the `SIMPLE_BUT_WRONG` macro symbol. But even in that case simply counting, the O(*n*) algorithm, produced the same result as `==`. 
Link please, can't find it.
Ok thank for the heads up, I may just learn more about c++ through some books then try a galaga style game with sprites
&gt; You don't need PIC for the main executable (unless you want the extra security hardening load address randomization brings) So I would say that today you absolutely wants PIC/PIE for the main executable, unless you have extremely good reasons to decrease the security of the software you are building...
Yes I looked at them and c++ primer was one of them.
No one has said anything about the C++ Primer, but it's a very good book. It's not game related but it will definitely get you up to speed and comfortable with C++ if you stick with it. I highly recommend it but know that it can move quickly through topics (it is a primer after all, and makes assumptions about what you know about programming in general). Bjarne Stroustrup also has a book, "[Programming - Principles and Practice Using C++](http://www.stroustrup.com/programming.html)." If you are looking more for a book that teaches programming *as well as* C++, I'd probably go with that one over the C++ Primer.
Elision in the auto x = finally(...) case is only guarantueed in C++17, and the GSL is supposed to work on C++14 compilers. So, move support is in fact needed.
You're still wrong. unordered containers don't have access to any operations that let them do better than is_permutation. Even ints can be considered equivalent but not equal (e.g. a predicate that inspects parity). I want to go play Hearthstone, so I'm not going to bother anymore if you aren't going to listen and think when multiple STL maintainers tell you that you're wrong.
Yeah, it's a good intro to both C++ and game dev.
That sounds like a good plan. I'd start with space invaders though. Galaga pathing is non trivial. Random piece of advice: learn how to use a debugger immediately when you start leaning c++. So many peoe try to debug hard problems with print statements and they waste so much time. Force yourself to use the debugger. 
Okay
I've never read that title, but Lippman is a credible author.
I will add it the next time I set up a night run of the benchmarks. nanolog's benchmarks seem to imply reckless is slower than nanolog. https://github.com/Iyengar111/NanoLog
How have I not come across this before? Many thanks
Holy smokes, clang just [really impressed me](https://media.tumblr.com/tumblr_m6odkq8jNo1qbolbn.gif). When I looked at gcc generating all the SIMD code I thought to myself there was no way that clang would beat it with its ordinary assembly code... but it did, by recognizing Gauss' formula in code. Do you know if this is a hardcoded thing it recognizes or are there a larger capability in clang to recognize series and replace with algebraic substitutions?
Awesome. I'm really looking forward to the discussion/progress that these keynotes will start - this was a very good idea! 
See also https://www.reddit.com/r/cpp/comments/637a7p/c_weekly_ep_57_dissecting_an_optimization/
Damn, that's nice 
&gt; The GTX 1080, for example, has 2560 CUDA cores which can be harnessed for any parallelized computation. That will do you a lot of good. Sitting there, doing nothing while your CPU language of choice struggles to feed it work through 10 layers of abstraction. I own a GTX 1080, Minecraft still doesn't manage a stable frame rate. 
&gt; Constexpr means inline. You will definitely experience code bloat from that. Do you mean "inline" in the sense of "this function body must be inlined wherever it is called" rather than in the C++ sense of "this function may violate the ODR"? [Something I hacked together](https://godbolt.org/g/0RwM1W) suggests to me that neither `clang++` at `-O1` nor `g++` at `-O0` is inlining constexpr functions called at run time. They do inline them at higher optimization levels, so presumably they are still doing their inline analysis to determine if it's worth it. (In this trivial case, absolutely.) But I am not really an expert so I defer to your explanation.
why not wait til there's content to post this. Is this really an appropriate place for an ad? 
EDIT: I was completely wrong, thx for explanations. I sincerely think that you based you code on an UB. Correct me if I'm wrong. First of all, you have done copy capturing with your lamdba (and not reference capturing), so the value of `this-&gt;done` will always be `false`. Let's assume, that you have made reference capturing for the rest of my comment. In insurance, you test the value of `this-&gt;done`, but if the desctructor of TimeoutInsurance have been called, then `this` and `this-&gt;done` are no longer valid. You should have put the boolean `done` in a `shared_ptr&lt;bool&gt;` to solve this problem.
This is to let people who may want to attend C++Now know about the program. We announce things (keynotes, program) as soon as they become confirmed.
At work we just started using IncrediBuild (network compile spreader plugin for visual studio/c++). Compile times went from 30mins to 4-6mins
**Company:** [Sharp Reflections GmbH](http://sharpreflections.com) **Type:** Full time **Description:** Sharp Reflections is a fast-growing technology provider to the oil and gas industry. We are the first commercial provider of Big Data technology for seismic analytics. Our tools dramatically reduce the time required to process and analyze huge datasets, and improve the quality of the pre-drill reservoir predictions. We’re building a world class technology company to meet the needs of a growing global client base that includes several leading international energy companies. Pre-Stack Pro, our flagship software product, leverages HPC compute technologies to process and analyze huge 3D seismic datasets used to target oil and gas wells. The developer will work in the core team that develops both the front and back end software components. We offer competitive salary and a great work environment, where your contribution will have an immediate impact on business results. You will join a young and highly motivated team working in an agile development process. Flexible working conditions and a self-driven team await. Specific tasks include user interface design and implementation, scientific data visualization, integration of geophysical algorithms in close cooperation with domain experts and system administration. **Location:** Kaiserslautern, Germany **Remote:** No **Visa Sponsorship:** No **Technologies:** Required: C++98, move to C++11 or 14 soon, using the Intel compiler and building using CMake. Platform is Linux. Experience with at least one of the following: Linux/UNIX system programming, multithreaded programming, HPC technologies like MPI, GPI, etc., scientific visualization e.g. using OpenGL, last but not least Qt. Experience with UNIX system administration. **Contact:** Please send your application to matthias.decker@sharpreflections.com
&gt; Is the below code in error, or are both these compilers wrong, or are you wrong, perhaps? Your example doesn't meet the criteria I laid out - you don't differentiate between keys that are *equal* and keys that are *equivalent*. Change your example so that `Special_string`'s equality check does a full equality comparison, and separately provide a template argument for `KeyEqual` that only checks the 1st characters. You'll find that your `are_equal()` would return `true` (since you're only counting *equivalent* keys), but real `==` correctly returns `false` (since it must count *equal* keys). 
this is a pointer, not a value, so your first concern isn't valid. I'm not sure the second issue is valid either, there is no code path where the lambda can be executed after the TimeoutInsurance instances is destroyed.
That is pretty cool. Getting compile times down that much makes a huge difference! 
less time for legit reddit reading now :/
&gt; run-time tracked moves I don't see anywhere in c++ 'run-time tracked moves'. Perhaps you care to elaborate on this? &gt; and noexcept terminating on exception (instead of being undefined) are such instances where overhead is paid. What overhead? &gt; C++ is not easy I find it very easy. 
How does Ali's book (on D) compare to Andrei's one?
I was completely wrong, thx for the explanations, however: &gt; copy the code and play with it, set some break points, and you will see You cannot play with gdb to test UD, you can only play with gdb to test why something is failing, eg. if a UD leads to something strange (like deferencing a non-valid pointer). UD can create valid machine code and UD source code can be compiled during many years until your compiler make some change that exploit that UD to make some better optimizations.
Despite being good friends with Walter Bright's son and having him constantly say "hey try D" I still haven't tried D. Despite the many great advantages of D, it still doesn't have the ecosystem of third party libraries and tools that C++ has and that severely neuters it's effectiveness. That's not D's fault, but its the reality.
This is a nice article. Thanks for posting. I'd change one thing. "Trie" is an awful name. It's actually short for "reTRIEval", so I guess it's supposed to sound exactly like "tree". A better name, which I also find easy to remember, is "Prefix Tree". So I'd say "Prefix Tree (which some people call a *Trie*)". In any case, Prefix Trees are great. They have nice efficiency characteristics, a reg'lar ol' programmer can write a decent one, and the idea leads to other interesting and useful data structures: Hash Trees, HAMTs, etc.
&gt; I don't see anywhere in c++ 'run-time tracked moves'. Perhaps you care to elaborate on this? In C++, when you move from a variable, you *must* leave it in a state which allows destruction or assignment. This requires your assignment operator and destructor to handle the case of an "empty shell". An affine/linear type system would track the move at compile time, and the destructor would never get invoked to start with. &gt; &gt; and noexcept terminating on exception (instead of being undefined) are such instances where overhead is paid. &gt; What overhead? There is an overhead induced by having to place an exception handler at the boundary of the method, to trap the exception and call `std::terminate`. If this were undefined behavior this would not be necessary. More importantly, though, the presence of exceptions regularly trip up optimizers (they complicate the control-flow), which in turn means that code-path where it is provable that no exception occurs can be better optimized that those where such a proof is not available. &gt; &gt; C++ is not easy &gt; I find it very easy. Lucky you. Would you happen to know why: std::unique_lock&lt;std::mutex&gt;(lk); compile and creates a default constructed `lk` variable of type `std::unique_lock&lt;std::mutex&gt;`? I just hit this issue at the end of the day and I am still not sure why this is interpreted as a variable declaration (the grammar never ceases to astonish me).
Ali's book is targeted more at the beginner programmer, and is concise enough to be finished over a weekend or so - good to pick up the basics of the language quickly. Andrei's book is a more comprehensive overview of the language (more like Stroustrup's "The C++ Programming Language"), and some code snippets don't work directly (some changes to the compiler and some changes in the APIs since the book was published). That being said, the book is filled with very interesting (and small-enough) problems demonstrating D's features. So take your pick!
Between Rust and D (more experienced in Rust than in D), D is no doubt much more comfortable for people coming in from C and C++. It is also a remarkably clean and intuitive language. The one big thing I miss from Rust though is pattern matching. Rust's pattern matching is very powerful indeed.
Or use Microsoft's build-in crypto (inside advapi32.dll). Start with [CryptAcquireContext](https://msdn.microsoft.com/en-us/library/windows/desktop/aa379886.aspx).
You are saying this because you didn't try it. It works on C++11 and C++14 fine because the move is elided even if not guaranteed.
&gt; C did not have a linear type system. When C++ was conceived, it was thought as an extension to C. Sure; that's a trade-off. Compatibility over performance. It's not necessarily a *bad* trade-off, C++ is after all very successful probably because it integrated so painlessly with se. However, it does mean that there is a cost that could have been avoided. &gt; In this case, if it was undefined behaviour, it could seriously hurt correctness. &gt; I think the comittee was correct to choose this over the alternative. I agree too; there's already way too much undefined behavior in the standard and one less foot-gun is welcome. Once again, though, it's a trade-off away from "raw performance". &gt; If it quacks like a duck, it is probably a duck. &gt; If it looks like a variable declaration, then it is a variable declaration! &gt; What else could it be, since you are instantiating a template type? I was expecting something akin to a "most vexing parse". Anyway, I find the following code thoroughly confusing: int main() { int(lk); foo(lk); } seems to be valid C++ which declares an `int` called `lk` and calls `foo` with `lk` as its argument, as you can tell from syntax...
Could you elaborate on what you mean by 'run-time tracked moves'?
Hahaha!
is_permutation() is mandated to be equally smart, being guaranteed linear time when the sequences are equal(). N4659 28.5.12 [alg.is_permutation]/4, emphasis mine: "Complexity: No applications of the corresponding predicate if ForwardIterator1 and ForwardIterator2 meet the requirements of random access iterators and last1 - first1 != last2 - first2. Otherwise, **exactly last1 - first1 applications of the corresponding predicate if equal(first1, last1, first2, last2) would return true if pred was not given in the argument list or equal(first1, last1, first2, last2, pred) would return true if pred was given in the argument list**; otherwise, at worst O(N^2 ), where N has the value last1 - first1."
Checkout Accelerated C++ by Andre Koenig and Barbara Moo. It jumps right into programming examples and teaches concepts along the way!
When I was taught about them in school, they made a fuss about how it's pronounced tree :P
The fact that you moved from a variable is not tracked at compile-time, forcing you to handle the fact that some of a type's methods may be called on a moved from object (at the very least, the destructor!). For example, imagine that I write a `ptr&lt;T&gt;` class which is guaranteed never to be null... unless you moved away from it (in which case it's an invalid state). If the type system enforced that no method is called on a moved-from variable, then that would be it. However in C++ I must *at least* handle the case in the destructor (pointer may be null), and if I want to be able to store the type in a STL container, I must *also* handle it in the assignment operator. Thus, moves are tracked at run time.
I disagree, it's an article that reviews a static analysis of the C and C++ code of TensorFlow, revealing mistakes found in the code. 
Yea thing was wierd. Tried opening it in Firefox and the price was $20. It was discounted to $10 on my brother's computer. So something was up
Linus?
What happens if you have a collision though?
I'm not familiar with details of cryptography, but [this](https://msdn.microsoft.com/en-us/library/windows/desktop/bb204776\(v=vs.85\).aspx) is certified. 
As a game programmer I appreciate the game designers that understand how to code. Their ideas are more reasonable because they're aware of what i can/can't do. Also being able to tweak things in code without me all the time makes the iteration much smoother.
What if your incoming string collides with one of the cases?
He might be able to but won't because he does not care. (his words, not mine)
We've defined racism such that a neutral intelligence with pattern-noticing abilities will naturally be racist as well. That's evidence that our definition is really the problem.
Obvious solution would be to tweak hash-function a bit.
D has had a huge effect on C++, from `auto` to `if constexpr` to the range library. D and Rust have a great ability to experiment without the crust that is backwards compatibility, and C++ gets to benefit hugely from these. *This* is what makes C++ a better language, not sticking your head in the sand and humming the same old tune. Learning what can be learned from Rust and D allow C++ grow and get better. (as a side note, the [D conference](http://dconf.org/2017/index.html) has Scott Meyers as a speaker... so there is that)
&gt;Most attendees aren't designing the language. We're coming to learn new techniques and ideas we can use in C++, because we have jobs and things to do. Rust and D are similar enough to C++ that you can get ideas for C++ techniques. Many language and library features come from different languages, there's no harm in looking at them. 
No, just change the salt of the hash function to another value, which doesn't produce collisions on enum strings.
Have you thought about making impl4 based on a variant? :) You'd avoid an extra allocation and indirection per node (they are stored in a map anyway) and the visitation code would probably be simpler just because it'd be implemented by the library (boost or STL or eggs or ...). Would be interesting to see if this gives even better performance. 
Please make the graphs using log scale. Right now, &gt;50% of the graphs are completely useless and unreadable.
This is offtopic, so I'll only make one post about it, but since I'm familiar with this line of argument... Basically, a different way of putting this is "people like to think that computers are somehow amoral or objective, but humans still code them, and so many algorithms, especially ones in the AI/ML space, contain the biases of the humans who make them. As such, AIs can have bias, including racial bias."
Thanks, wait for v2.0 
There have been quite a few posts about it lately, even on "mainstream" computer news sites. It kind of began with Tal or whatever Microsoft's Twitter chat bot was called, then there's the problem that we humans are massively biased and feed all this biased info into AI's. It is actually a really serious problem, and it is a fact that it is happening, now. Sorry I don't have a link handy for you but Google a bit and you should find a few good articles about it. Also see /u/steveklabnik1's post below.
huh?
Well the scriptable IDE by excellence is emacs, but coming from Visual Basic I doubt you'll like it....
Both emacs and vim are provide the infrastructure for that kind of analysis, and if you can't find a plugin to do what you want there are plenty of resources available to help you write your own.
Trie is great to write an article about but you are doing benchmarking wrong for enum to string, or string to enum. Unless you have 100, 1000, 10000 enum elements this benchmark is wrong for this use case. I suspect your enum is much smaller. If your benchmarking besure to use real world data, you might find with the 3-20 elements the difference is negliable so using the other structures should depend readability and maintainability (if this is your only trie use case then you have just added a maintainability nightmare)
That is only true to a point. If this method takes a significant amount of CPU times or is part of a hot code path, it may be worth it. You just have to put a bunch of comments. And the less experienced developers should not mess with the hot paths anyway. It is also valuable as an academic exercice.
Sounds to me like you need to learn AutoHotKey. You won't regret it. It revolutionizes the way you use your computer. Imagine being able to add virtually any feature to your computer or any program etc .
That trie picture is wrong. It's wasting memory storing a single letter on a node. Originally when it doesn't need to branch anymore it just stores the full data in it. So in a trie all nodes either have 0 children or 2+ children. Nodes with 1 children are bad design. Also, no mention of Patricia tries? They're like tries but with even better memory management.
I am not on windows, and autohotkey isnt capable of parsing C++ code for type information
&gt; Would you happen to know why: #define ADD_LOL(x) ((((((((x##_lol)))))))) #define DONT_ADD_LOL int ADD_LOL(lol); int DONT_ADD_LOL(lol);
You seem to have logged into the wrong account, I think you we going for "hyperdefensiveinstinct". All those two repliers were saying is that the C++ community doesn't mind hosting content of other languages because, in the end, discussions of even the deficiencies of our language can only lead us to solutions to those deficiencies. If we closed our community off and said "we're the best language already", we wouldn't have all these amazing modernizations we do or soon will have to make our lives even better. The discussions being hosted may also be relevant algorithmically or just interesting topics of our generic field, that we can all take something from or enjoy. 
1. That's DPAPI which has absolutely nothing to do with using AES. 2. That's... not a thing you can use in C++. DPAPI is a thing that helps make memory dumps / telemetry safe, but if someone has access to your memory they also have access to the DPAPI key, so this really doesn't gain you much. It's a bigger deal on the CLR because you can't scrub System.Strings when you're done with them because System.String is immutable.
I think most standard library implementations uses tag-dispatching on `std::iterator_traits&lt;Iterator&gt;::iterator_category`, so if you provide it a random-access iterator, it will take advantage of that. I think /u/foonathan's comment about redundant writes is the more likely explanation.
&gt; Since a moderator posted it, it is by definition appropriate. That's not an interesting argument to me. If I don't feel it's appropriate, it's is something I take into consideration when deciding if I want to be a part of the community. If community growth is interesting to the mods, then they should welcome feedback. &gt; Does that make it more news than ad? The actual content linked to doesn't matter, it's the lack of transparency in the title to someone who doesn't have all this information ahead of time. That's what makes it clickbait.
Respectfully disagree with your comparison. It's more like going to a C++ convention and seeing a talk about a C++ dialect with experimental features that might be of interest to the general C++ community. D is special in this regard due to its very close history with C++ and who its designers are.
I think you're looking for r/cpp_questions
That reminds me, is there an article/guide out there somewhere that deals with how to correctly benchmark code and analyse/visualize the results?
Couldn't we generate the enum_to_string and string_to_enum fonctions with macros, for example: https://godbolt.org/g/o5ZcTX ?
Performance is important maybe? I am guessing. Just know Phobos but it uses a lot of compile-time polymorphism. Just as C++. You know what happens when you start to over-object orient your code right? D is supposed to be systems programming, not Java or C#.
Sure. While I'm happy with mine for now, it's always good to have the official one around. Just in case ;-)
I'm maintaining a plugin for related to C and C++ development for Vim: [lh-cpp](http://github.com/LucHermitte/lh-cpp). Somewhere in it I have a (vim) function able to extract information from the enum under the cursor (type or variable). I use it to automate the generation of `swith` statement. It relies on ctags (I highly recommand using the maintained fork: Universal Ctags ), which implies it won't work with C++11 `auto` variables: I need to take time to eventually integrate libclang. If you're not already familiar with Vim, it'll be quite a challenging path to take.
The last one wasn't much C++ oriented as well, I think most of C++ content was shared between you and Rob and everything else was highly popular now "women in tech" topic.
Guide to rant on C++: 1. Show an obscure snippet of code or feature 2. Say C++ is a giant beast of unnecessary complexity 3. Show how it's done the right way in a cool language Yet C++ has only two rules to be follow: 1. Don't use what you don't master 2. Master what you don't know
You can also check the Definitive C++ Book Guide and List at Stack Overflow. http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
But why does it need a clickbait title?
I don't see it as click bait as I know that this is an upcoming conference. It probably wasn't intended to be click-baity.
&gt; as I know that this is an upcoming conference clickbait isn't clickbait if you've "already clicked" - meaning you know the content of the link already. That's why I gave an example of a non click baity title.
&gt; it's not like some company is trying to sell it's product yes it is. It's exactly like that.
Do you have any internship positions?
People just use clang now.
No, I - and many other people here - now that C++Now is each year in May. Thus, when I read something about this year's keynote in April, I know it's upcoming.
&gt; it's a non-profit organization] That's not actually relevant to what you said. It may be appropriate content but it's not an appropriate title.
Yes, I agree
Was the title originally "you won't believe who is keynoting C++Now. The second one is shocking", and then changed to the "just the facts" one we have now?
Nice article! I'd say though that you don't need to separately "add std::hash for associative containers" as those can be seen as sequential containers of tuples, so the first 2 points automatically give you the third. Further, if you look at a tuple as a heterogeneous sequence, then if you have a way to hash any sequence, then only one thing is required - hashing any sequence. I'm not quite sure if the range proposal currently handles heterogeneous sequences in a uniform manner, but if it does - then all you need is a hash function for an arbitrary range of hashable entities (recursively defined for ranges of ranges).
`int _avx_unique_store(__m256i ov, __m256i nv, __m256i *o)` I assume this is a function that is defined by the author's C++ implementation (because the name starts with an underscore). Any idea which header it is in?
[there you go](https://pastebin.com/iAuKKwLm) I wouldn't call that official or any such thing tho. I just unwound a template recursive implementation I found somewhere on the internet. It's still in there as well.
Specifically, a log-log plot https://en.wikipedia.org/wiki/Log%E2%80%93log_plot Right now the size axis is logarithmic, but the time taken axis should be too.
Yeah I was meaning to do this last night. Work, unfortunately took precedence. I'll see if I can get to it tonight!
https://dlang.org/spec/cpp_interface.html it does * matching C++ name mangling conventions * matching C++ function calling conventions * matching C++ virtual function table layout for single inheritance 
That doesn't help people who need portability
Personally, when I needed properties in a project of mine, I introduced the following class (showing only signatures to keep the example short): template &lt;class T&gt; class Property { public: Signal&lt;void(const T &amp;)&gt; changed; Property(const PropertyOwner *owner, const char *name, const T &amp;value = T()); operator const T &amp;() const; Property&lt;T&gt; &amp;operator = (const T &amp;value); }; This, coupled with List&lt;T&gt; with similar reflective capabilities, allowed me to quickly made object models, like this: class Scenario : public PropertyOwner { public: Property&lt;std::string&gt; name; Property&lt;size_t&gt; duration; ... List&lt;Entity&gt; entities; Scenario() : name(this), duration(this) { } }; This allowed me to automate UI creation. Forms for each object could be automatically generated by looking at properties at runtime and constructing the appropriate forms. It was also helpful in automating persistence. Objects could be saved to/loaded from XML automatically. While the above seems incredibly useful for building applications, properties like the ones requested here don't offer actually anything. Even the advantage of syntax is not really an advantage. I've worked with ActionScript, which has properties like this, and very often there was confusion between variables and properties. In some cases, instead of changing variables, properties were changed, and in some other cases where variable declarations were removed, the corresponding code was not because it was valid, but was referring to properties instead of the missing variables. 
https://www.sololearn.com By far one of the best free online resources you can get for c++ you get the basics pretty much instantly. Before the tutorials get gradually more complex
Which hash though? You could do something like a CRC hash, or you could try to be cute and make one up that's "good enough" for your purpose, like summing the letters in the string and maybe multiplying them by position or something so that scrambling the letters doesn't cause a collision. The two would perform quite differently so this can quickly get into benchmarking different hash functions, which TBH, you could just do that and tell us what you find.
Is this some kind of joke? This so called pattern uses inheritance, polymorphism, heap allocation, and it is not even thread safe! And it is not even extendable! if concept_t is private to document_t, how would an external module provide new types??? 
this happens in async programming. The callback can be called much much later. So use a weak_ptr and try locking it.
I would expect the code to look like: case hash("xxx"): if (input == "xxx") { return xxx; } break; At least I hope it does.
AAA? C++ Indie/Mobile Unity dev? C# Why C++? Performance issues around memory management. With C# it is very difficult to control garbage collection and very difficult to control memory layout cache locality. Doing this in C# requires fighting against it's design and you end up doing more/uglier work than if you just did everything manually in C++. That's on top of the general perf/memory overhead of C#. C# runtimes are getting better. But, the overhead for real-work (not microbenchmark), large-scale systems is still quite large. Meanwhile, modern C++ is catching up to C# in terms of expressiveness, but is doing so with zero-overhead abstractions. And, that's even ignoring the past 20+ years of legacy code and experience in C/C++ old-timers in AAA have built up. It's very expensive to rework that into C#.
I'm guessing you're talking about 'games' as you say 'AAA'. Ignore everything below if that's not the case. Most big game engines are going to be C++. Basically anything outside of Unity. This is mostly for performance (deterministic; no GC), raw stead-state speed (it's still quicker than JIT'd C# usually), and integration with 3rd party library which are near universally also c++. However, don't fret this change! Modern engines like UE4 are c++11/14/17 and that's exactly what you should look for and learn. On top of that, they will provide everything the raw c++ standard libraries do not. XML? JSON? Bond+Protobuf serialization? Networking and replication? Filesystem stuff? Other high-level abstractions? Yup, you'll get it there as part of the engine too. The engine will provide a comfortable set of high-level APIs that should be very friendly to a C# developer.
C++ is a more versatile language because of memory control. Also having a solid grasp of C++ makes it easier to move into other languages, but that's just my experience. 
Okay. Thanks for clearing this all up for me. Really appreciate it. Im moving to C++ from now then. :)
C++ is the way for the videogames industry as a programmer EA and it dice engine are C++
Thanks. But just for curiosity. As people say that C# is improving alot there isn't anyway that developers will switch to C# and update their engines? 
Yeah, but what C# and Java both did is they exposed algorithms as container members. You have a `List`, you write `mylist.` and all of a sudden, your IDE gives a code completion item for things like `.Sort()` and that sort of thing. This is priceless. And it's precisely what C++ misses having global, general-purpose, any-container-will-do functions. I understand the motivation, but usability suffers greatly because of this.
That's an already solved problem - https://msdn.microsoft.com/en-us/library/ezzw7k98.aspx
I had no idea this was the case, and the person I mentioned has never mentioned this somehow despite numerous discussions about D and programming in general. Good to know - I'm going to have to take more of a look, now.
It also depends on what you want to do. AAA games have dozens or even over a hundred engineers and scripters and such. A C++ game engine might still use C# for all tooling, for instance, and C# may even be the game "scripting" language in use. There's a difference in skill sets and tools used by engine developers, tools developers, content developers, devops, platform developers, and so on. Many games even it's entirely different languages for their servers, and C# is a popular choice there. Learning C++ - or _any_ new language/tool - will never hurt and can only help your career. 
I've used Armadillo quite a bit, and it works quite well. I think it's generally the fastest. Although, of course it depends precisely on what you are looking at. It natively supports parallelism, but GPU. You could use nvblas to use a GPU for some computations, but I found setting up Cuda quite painful, which you must do to use nvblas. 
Fair enough. I guess that's a reminder not to assume. Though looking at the article again, I realize that it's only in the second version that he makes use of the properties of a random access container, so there's no reason to assume the standard library would use that algorithm (especially since, as you point out, that version makes several not-strictly-necessary copies)
You don't need to switch to C++. You can become both a C++ and C# developer, they are not exclusive.
Yeah, usually you get blas and lapack from the package manager in linux, which is great. But the performance is usually not the best. I installed ATLAS (optimized BLAS) from the [AUR in Archlinux](https://aur.archlinux.org/packages/atlas-lapack/), and still had to deal with disabling cpu frequency scaling for the installation. Good [guide here.](http://www.astr.tohoku.ac.jp/~akhlaghi/ATLAS_install.html) But well, makes sense to decouple this from the library, and let the user tweak it.
A bit. The boost dependency was recently removed i believe (edit: or made optionnal? it's only for the multithreading i think.). The blas and lapack are required for optimal performence, but the library will work without it.
Wow, not a single comment how pathetic STL implementation is? Not a single thank you to Lemire? From what I see his first implementation does not break a single requirement for std::unique and is 3x faster when branches are hard to predict. I would hope this to be fixed soon in the gcc and clang, but I know it will not be.
Do you need to solve/manipulate really large systems or small systems many times? Big difference. I've been using Eigen via RcppEigen along with RcppParallel. The parallelization is at a level above Eigen (solving many small systems in parallel) so I expect it would slow things down if the solver in each thread was spawning yet more threads. I like Eigen. I would prefer something more stylistically aligned with the direction of Boost/STL. I get a bit of whiplash integrating so many libraries. The docs could be a bit better organized but its fairly easy to figure things out. For very (very!) large systems, my guess is PETSc is likely the way to go. At least its quite mature. Eigen is optimized for small systems with dimensions known at compile time.
I am working right now in signal processing. The point is that I would like to leave the door open to any scale. Not very very large for sure, but I cannot say if the user would need really fast analysis, or really big system/images. Have you used PETSc (and Trillinos?)? I have seen libraries that rely on them for MPI features, but never had a look on them.
Have you looked at [ViennaCL](http://viennacl.sourceforge.net/)?
No because the AI could just be reflecting the biases of the test data.
!removehelp
What operations do you need support for?
well continue using C++ then most game dev places seem to believe C++ is the only way to make performant games and knowing how to handle lower level should be enough to help work your way to high-level languages when needed 
Maybe have a look at Rust, too. Depending on how much you know about C++ you will find a lot of common concepts. It's never a bad idea to know some other languages.
Doesn't answer the question much, but puts forward some other language. No need to guess which :-)
Inverse matrix and full eigensystem spectrum.
It depends hugely on your application. In mine I make heavy use of both eigen and petsc in a finite element context. Eigen for the thousands or millions of small (N&lt;100) matrix multiplications that happen each iteration (totally local) with petsc to handle distributed memory parallelism for global operations (krylov solvers running across thousands of processors, etc). Eigen is nice for having a clean API and making simple things simple. Petsc has a very messy C API but it can do literally anything in the world of linear and nonlinear algebra. It's more a framework than a library. 
Rust competes with C++ in the same domains, knowing it might be a good thing in the future and therefor maybe it would be good to learn it today. I don't see why that would be not relevant. PS: I'm not a Rust zealot.
**Company:** [Hawk-Eye Innovations]( http://www.hawkeyeinnovations.co.uk/careers) **Type:** Full Time, Permanent. **Description:** Our computer vision team develop highly optimized, real-time, computer vision algorithms to build systems which process billions of pixels per second. The graphics team work on 3D rendering and augmented reality in the challenging environment of broadcast TV. **Location:** UK – London / Basingstoke **Remote:** No **Visa Sponsorship:** No **Technologies:** We use the latest C++ features supported by Visual Studio. QT and Boost are used throughout the organisation. Computer vision teams use CUDA, OpenCV and occasionally SSE/AVX. The graphics team are looking for skills in DirectX and OpenGL. **Contact:** Check out our [careers page]( http://www.hawkeyeinnovations.co.uk/careers)
In general, my rule is that you use auto if a) The type is irrelevant and/or b) The type can be made obvious from the RHS and the variable name
Well, the graphics rendering is going to be a similar sort of hassle regardless of the platform/language. In the end you're going through your game objects and painting them to the screen every frame. If you're set on C++ then SFML is a fine option, since it's multiplatform and has all of the low level details abstracted to a simple interface. Also it has got a module for your standard graphics primitives, sprites etc. so you don't need to get your hands too dirty when starting out. As for GUI (the user interface, not the graphics rendering), have a look at ["dear imgui"](https://github.com/ocornut/imgui) (yes, that's the real name), especially since it has got [SFML bindings](https://github.com/eliasdaler/imgui-sfml). If you're working on different platforms then you need to agree on a build system, [CMake](https://cmake.org/) is a good option (but there are others, of course) since it can spit out Makefiles for Linux and VS projects for Windows (also SFML is built with CMake and it has a handy [tutorial](https://www.sfml-dev.org/tutorials/2.4/compile-with-cmake.php for it as well).) You can then work against the same source tree. Oh, and it might be worthwhile to look at [component based modelling](http://gameprogrammingpatterns.com/component.html) for your game data. Have fun!
Thank you very much ! 
I think it's important to use the right tool for the right job. I like programming in C++, but I regularly use a wide variety of other programming languages and tools. C++ is a good hammer, but not everything is a nail. If you think about problems carefully and choose the correct tool, then you will be able to produce high quality solutions. Sometimes C++ will be the right thing; often it won't. I recommend seizing the chance to learn as many different programming languages, tools and methodologies as you can. Not only will it give you a large and flexible array of skills, but it will make you a better C++ programmer by helping you see problems from other points of view.
Here's bjarne's thoughts (summarized as "no.") https://youtu.be/NvWTnIoQZj4
Since CLion is now (usually, if not always?) able to infer the type when auto is in use, might we see a future feature which allows the inferred type to be displayed in-line? Then I could maximize flexibility of my code through use of auto and it would still be 'self-documented', provided that I am viewing my code in an intelligent IDE. If such a feature will exist in the future, it would be in JetBrains' (and other vendors of powerful IDE's) strategic best interest to advocate for use of auto :)
This is a great suggestion, moreover, it's already implemented. Inferred type is shown in the Quick Documentation pop-up.
Hold ctrl and hover over the variable name, it's already a feature. It's disappointing how frequently the indexer fails to be able to infer the type, but it often works. 
We also plan the reverse intention to substitute auto with type: https://youtrack.jetbrains.com/issue/CPP-8555
Could you share the code when it fails? Would be great to investigate.
Getting into the game industry is a bad move. This is just a small part of the entire programming industry with its own specific requirements. The game industry locks the programmer much harder than the C++ language. To develop within this industry, one has to develop very special skills that are not needed in other parts of the industry and, accordingly, will not be paid by anyone. In fact, starting a career as a game programmer is like joining a mafia. There is no way to get out.
I regularly submit very detailed reports to your issue tracker, and I will continue to do so. 
That's great. I haven't been using C++ much recently, and so I have only tried an early version of CLion - so I was unaware. Thanks. I suspect that I'd probably be interested in having a more aggressive in-line feature that simply displays the inferred type when available (with appropriate highlighting to indicate that it is augmented/inferred information), but reveals the true 'auto' text when I click it so that I can still edit the code properly, and I would be able to read code that truly uses auto in exactly the same way as code with hardcoded types (obviously, some careful UX design would be necessary here - but I have a couple ideas in mind that seem decent). That way, I wouldn't have to avert my eyes to a different place regularly while browsing code -- Seeing the type of everything is something I'm absorbing from all code all the time, and so I'll continue reducing 'auto' use until I can painlessly see the types.
Thanks a lot!
Ah I see, so args_t creates a tuple of the argument types of foo. I missed that. 
Interesting post! I recently got a job as a software developer after learning C++ in my own time. The one thing I never learned will are threads. Do you have any good resources on concurrencies? 
I definitely remember Rust being mentioned and discussed at CppCon when the guidelines ownership checker was announced. Also Alexandrescu talked about "how they managed it in D" at different occasions. Moreover, at the upcoming CppNow 2017 conference there are 2 keynotes(!) about other languages, and you can imagine it is D and Rust again (however, not everyone in C++ community is happy about that, see [reddit discussion here](https://www.reddit.com/r/cpp/comments/64pc3a/cnow_2017_keynote_ali_%C3%A7ehreli_competitive/)). As of Bjarne, [here in the comments](https://www.reddit.com/r/cpp/comments/654ff3/is_it_smart_to_stick_to_only_cpp/dg7kp03/) there is a video where he commends knowing about 5 different languages, including Java, Python and one of functional languages. 
Ok, I see. Thanks. This definitely needs some deeper thoughts and discussions inside the team. And thank you for your support!
If you're programming for POSIX environments, [this book](https://www.amazon.com/Programming-POSIX-Threads-David-Butenhof/dp/0201633922) is an absolute reference. It's as old as pthreads, but still relevant, especially the explanation of various multi-threading paradigms, such as pipeline and worker group. Plus it's much better than [OReilly's book on pthreads](https://www.amazon.com/PThreads-Programming-Standard-Multiprocessing-Nutshell/dp/1565921151). If you're developing for multiple platforms and want to stay 100% C++ /u/Meowiavelli 's recommendation is def. top notch.
Dispatching through delegating constructors allows you to control mem-init-lists. `if constexpr` can't do that, because it happens after the constructor's opening brace.
I would recommend "A Tour of C++" by Bjarne Stroustrup. It is intended as an introduction to c++ for programmers. "Effective modern c++" has a lot of good best practices stuff. The cppcon videos are generally great. Jason Turner's "c++ weekly" video series can be pretty educational, but it isn't necessarily the best starting point.
This isn't C++. Try contacting Microsoft directly.
Fantastic write up. Im currently working as a LED Test Engineer and have been wanting to program for a living. I have started using raspberry pi's for various projects which include talking to slave arduinos which switch relays, monitoring ambient conditions, broadcasting data to an internal website, slots for communicating between pi's, and more. I made the choice to go 100% C++ and pre c++ 11 to learn all the basics and have had a blast doing. If anyone wants to learn c++ for interacting with the real world i strongly suggest you get a raspberry pi 3 and an microcontroller dev board today.
Don't get me wrong I certainty use other language and not opposed to just throwing them aside. In face I know the basics of quite a few languages. The thing is I want to master one so that I am truly useful if you understand what I am trying to get at. I just feel like it's impossible to be amazing in many different languages since there is so much to learn. 
Yea that's about what I know, thanks for detailing this. Do you (or anybody else) know anything more? Is it just one person working on it, or multiple? What's the overall plan for the future? Etc.
They will most likely never (or not in the next 5 years) switch to clang for code completion. At least that's the gist from their tickets. They have put a lot of money into their own code completion, which is tailored to their IDEs.
Really? I thought it was just the packages that were incompatible.
Hi - I'm an employee of Codeplay, and have recently been helping out my colleagues with their work on Eigen (and Tensorflow). Our efforts are focussed on porting Eigen's operations to OpenCL (by way of the SYCL programming standard), as CUDA ports of much of Eigen's functionality already exist. The stuff we're doing is designed to work with Tensorflow, indeed. It's early days yet but we've managed to get a decent amount of code ported. /u/lightcatcher is correct, the documentation could be improved. We'll get there but at the moment we're still making regular changes. /u/sumo952 you might also be interested in [this Eigen starter repository](https://github.com/ville-k/sycl_starter). It has a small sample demonstrating how you can do linear algebra with Eigen's OpenCL port (as well as a comparison with the equivalent SYCL code). I notice you mentioned you were looking for dependency-free library - while Eigen certainly fits that description for pure CPU, adding either CUDA or OpenCL support requires the use of more external libraries, so that might be a dealbreaker. If you'd like more information, please drop me a message, I'd be happy to send you some more instructions if you decide to give it a try.
&gt; At CPPCon I never once heard anyone mention another language Yeah, you've had a different experience than myself. :) I don't think a lot of _talks_ have delved into other languages (though some certainly have), but in the hallways you get a lot of stuff about D, C#, Rust, Go, Swift, and the other would-be C++ competitors. With a dash of Erlang, Python, Haskell, and so on if you hang out in the right crevices of the conference hall. :p 
&gt; Most attendees aren't designing the language. This is actually probably inaccurate. I get where you're coming from, but I think you're misinterpreting the content I expect Ali will present. This is not a talk for language designers. &gt; You're wasting everyone's time with crap like this. Don't post it and don't host it. Attendees have repeatedly said they have enjoyed talks that are controversial and challenge the existing status quo in the community. And people have been asking for a Haskell keynote for years.
Because that's what we went out of our way to do this year.
&gt; The obvious hipster choice is Haskell. But of course :) &gt; The obvious one is Go. I actually think this is the hipster choice. &gt; For extra challenge: plain C /u/tvaneerd would crucify me :)
Yes. This is not normative or discussed with the other mods, but in my book: * Announcements for C++ events. * Announcements for C++ tools (compilers, IDEs, etc). * Announcements for C++ libraries, especially those with crosscutting usage among different types of C++ programmers. * Frequent announcements for libraries that do not have wide adoption and are only of interest to a very specific domain would probably warrant a conversation.
We have had him in the past, IIRC. I think I was the one who invited him the last time.
In this particular case, low pay is not the reason at all. A huge number of programmers starting a career strive to develop games, and this is what makes the pay low. (As Churchill said: "If you're not dreaming about developing games when you're 25, you have no heart. If you're still dreaming about it by the time you're 35, you have no brain.") Because the topic starter is the one of those due to whom others in game industry have low pay, it's unlikely that it will scare him.
A C++ IDE, the best for C++ in my opinion
So are things like libc or Qt libraries different for every distro even when version numbers are the same? Or are you talking about how distros like Debian hold the same packages for a long time while distros like Arch always have the latest software?
No problem! I saw that the three of you had good points and questions, but didn't want to spam the thread, so tagged you as well. I'm happy to answer! In terms of dependencies, unfortunately it's not possible to target most OpenCL hardware with a header-only library. Even most CPU implementations have some kind of shared object, like [pocl](http://portablecl.org/) or [Oclgrind](https://github.com/jrprice/Oclgrind). Partly this is to work with the [OpenCL ICD loader](https://github.com/KhronosGroup/OpenCL-ICD-Loader) mechanism so that you can target multiple OpenCL implementations more easily, but I imagine that implementing a header-only OpenCL implementation would be quite tricky to achieve. Benoit is working on (among other things I imagine) adding GPU support to Tensorflow. CUDA is well supported, OpenCL less so, and one avenue (that we're most interested in!) is to add OpenCL support to Eigen which is then used for Tensorflow's computations.
Good to know, thanks!
But TDD usefulness goes down as complexity and domain increase. Sure, you can continue to use TDD and write code that passes all of the tests that you've written, but that doesn't aid in the design of a larger system whatsoever.
Paul E. McKenney's "Is Parallel Programming Hard, And, If So, What Can You Do About It?" is also an excellent read: https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html
Actually, I think C is perfect, in the sense of completely hitting the target of what it set out to accomplish: be a better / highlevel assembly. C++ tries to do more. Maybe I'll give a talk sometime "What C++ devs could learn from C". 
/u/jpakkane, can you give me next week's lotto numbers? https://www.reddit.com/r/cpp/comments/64pc3a/cnow_2017_keynote_ali_%C3%A7ehreli_competitive/dg4d79m/ 
C++ Primer 5th edition will get you going on C++11, and act as a decent refresher at the same time.
There might be distro-specific patches for each library. Some distros (Arch) are usually more vanilla than others (Ubuntu.) But usually the differences are small enough to not break a binary on Arch that works on Ubuntu, given the same libc version.
Effective Modern C++ is probably all you need. It's short, highly relevant, and actually an interesting read - cover-to-cover. 
It's a commercial (but free for open source work) multiplatform C++ IDE. It has a LOT of support for C++ best practices.
I use cmake and imgui in a multiplatform project and it works well. 
well, at least use a modern/good book if you do intend to learn Haskell: www.haskellbook.com Haskell is *extremely* attractive if you're coming from Ruby/PHP/JavaScript, because you buy a ton of safety and performance without sacrificing expressiveness. Haskell is very attractive if you're coming from Java/C#, since your performance is in the same ballpark (sometimes faster, sometimes slower) and you gain a ton of expressiveness, safety, and power. I imagine that the C++ problem space is so different from the Haskell problem space that there isn't going to be much overlap where you could select one or the other reasonably.
I see regarding header-only! Cool. So Eigen is the linear algebra backend for all of Tensorflow? Or not yet and currently they have a different one, but plan to switch to Eigen once its Tensor module is "ready"? And basically you (or Codeplay) is adding OpenCL to Eigen's Tensor module (which will then be used in Tensorflow), and Benoit is adding GPU/CUDA to Eigen's Tensor module? Thanks, your answers are very much appreciated :-) To be honest it feels like the (outside) communication about all this work (Eigen/Tensor-module/Tensorflow/OpenCL/CUDA) is not very good and it's quite hard to find out what exactly is going on, who is working with whom (and that they coordinate with each other), and how serious these efforts are (or whether it's just "playing around").
It looks strange because modern C++ leverages the STL heavily and it has got some new features in the last few years. Modern C++ is effectively a different language. Nowadays, there is a dichotomy between modern C++ and C. I don't have any C++ books that I really love, so I can' recommend any to you. I do highly recommend cppreference. I have it open in a tab at all times while at my day job. 
As someone who's been hiring programmers for many years, I'll say that this is very good advice.
I initially learned by reading "Programming with POSIX Threads" by David R. Butenhof, which is the book /u/eeeple recommended for POSIX environments. It is a great book, and I highly recommend it. That said, if I had to start learning now, I would probably start with C++. I haven’t read the book /u/Meowiavelli recommended, but the reviews are good. I’ve put it in my queue.
Why was clang complete picked over youcompleateme? I'm not fully aware of the former's features, but the later also supports python. Does clang complete have some killer features I'm not aware of? 
No, AFAIK it performs worse and doesn't have the ability to configure it as well as I'd like.
Don't forget build systems. Drop some CMake knowledge there.
I think it will be more helpful if you explain how to develop a game in rust, and compare it with doing the same in C++.
There has never been confusion regarding this in the past five years of announcing it on reddit, so I have never thought about it.
Any real use case of this you shipped in VS2017 that I can look at? I understand different ctors based on some runtime information(like if the string constructed from other strings will need to heap allocate) but I am not sure if I can think of some case for compile time dispatching. 
PyCharm does, but I'm pretty sure it's just those two. They may make a community edition of they want to convince FOSS devs to switch.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/64t2bu/resources_for_getting_started_with_c/dg8svbv/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It depends. You may need higher level languages for fast prototyping.
Disassembly viewing support was so much anticipated and a great letdown. Whole point of it is for us to be able to see disassembly anywhere we step through, you know so we could check what code compiler generates. Now we can just see disassembly when stepping into code with no source available. I am sure it has it's uses but I never needed that personally​. No way to switch to Intel flavor is also disappointing because AT&amp;T flavor is more complicated than it needs to be with no practical gains. Maybe on next version then. Awesome release anyway :)
My feeling is that these languages quickly become popular because they aren't particularly different from other languages people are already familiar with. Haskell is very different, even if the ideas are available elsewhere, other ideas are no longer available for you to fall back on, you have to go all in and actually learn how to think and program functionally. I say that the ideas in Haskell are available elsewhere, but the exception, and the killer feature, is the type system, which is so powerful and expressive it allows you to do incredible things you just can't do in other languages, while not being incredibly difficult to think about like (I find) most dependently typed languages.
What advantages does it have over Qt Creator, which already supports a lot of Clang tools including a Clang code model?
Wait, so this is based on vim?
As a game programmer, I am glad that my fellow designers are good at their job and trust me to do mine. I agree that some high level programming knowledge can help the design process, but, for God's sake, don't let them write, nor read, C++ code.
Note that you can get it for free if you're a student.
Awesome, now we are talking. CLang is the only tools I have ever seen can do almost complete parse of C++. I have experience with VS, Clion. Both are bad. But I do set QtCreator to CLang Code Model becomes awesome.
Probably works over SSH.
First of all , that is not true most of the time. Unless your are including huge amount of code. In that case CLion parser is broken most of the time. So slowness is better than being broken. But they had option to contribute to CLang upstream and make it faster for everyone. BTW CLang auto complete is only a little bit slow on Windows (a little bit, I include almost 200+ package and only get a little bit of lag when I trying to something it is not in its cache). It works perfectly as far as I know in macOS and Linux. 
This is a great article, but it leaves me with a twinge of sadness because reflection is my #1 long-term want for C++. Especially since I think a lot of what some people might describe as 'toxic polymorphism' arises from a lack of reflection. Ex: when, for expedience or commercial realities, you add extra virtual functions to some base class because in your client code you can't easily test if an object has a particular field. IMHO, things like concepts ( which will be cool and useful ) have arisen at least in part because C++ classes are basically 'raw' structs at the end of the day. It would be amazing if reflection were a first class feature of the language, and if it could somehow be implemented while maintaining backwards compatibility, and while adhering to the 'only pay for what you use' ideology. I am aware that this is not the least bit practical, but I can dream! I'm definitely not the type of programmer who thinks the preprocessor is evil, but it's a bit crazy to think that 30+ years have gone by and reflection is still not there unless you're willing / able to use the preprocessor, which is an even older ( but totally valid ) technology. I use templates fairly often, but not as often as some here. Does anyone think that templates would be easier with reflection or with richer descriptions of C++ classes? It seems to me that concepts feel bolted on rather than first class. Concepts feel as if they're yet-another-feature designed to address the underlying problem - there is simply not enough meta data about C++ classes and no easy way to put it in. This really bothers me when it comes to spurious operator overloads - you know, when you add a dummy operator overload just so a class will compile when used in some template strategy.
Not based on vim - it is vim with a bunch of already existing plugins. The title is deceptive.
Well, TL;DR: at the end of the post there is a hint on part 2. Covering something like reflection in depth is difficult. Any hint of Qt in this article is missing, Qt has had lots of reflection features for as long as its had the moc. A few weeks ago I gave an overview on current proposals for reflection: http://meetingcpp.com/index.php/br/items/reflections-on-the-reflection-proposals.html But, we don't want to fast track this into the standard. The standard *is* written in stone, lots of effort to select carefully what it should look like. So, for C++20, what we should want is a TS, which is implemented widely in compilers, so that reflection support ships to all of us, before its set in stone.
That's an "okay" article! ;-) I wanted to correct just a tiny quibble: &gt; The Java reflection API is highly structured (unlike Python) Actually, Python has the informal reflection that's mentioned in the article, but it also has full introspection with the [`inspect`](https://docs.python.org/3/library/inspect.html) module.
I use reckless as-is. It's a copy-pasted code from the example. You can look at the sources. https://github.com/RafaGago/mini-async-log/blob/master/example/benchmark/main.cpp#L814 I log to disk because IMO the common use case of this type of logger should be to log to persistent storage (/var/log?). Logging to memory is a problem that a memory logger should solve IMO. Logging to memory would only change the consumer rate, but the same destination (disk) is used for all loggers, so the consumer rate is equal both for "spdlog" and for "reckless": the SSD speed. There is no inherent advantage for any of them. spdlog is using a bounded queue logger so it should be detrimental for spdlog because its bounded queues get full. If reckless uses a bounded queue, is there a way to set its size? that could be a very obvious unfairness source. How many messages were your tests logging? Testing with too little messages tests the fast-path only. These benchmark throw a very big load in a very short time to see how the loggers behave when in a brutal load (contention, full-queue backoff strategy, etc). Were you using a CPU clock that counts cycles for logging or "real" time? Counting cycles just tells half the story. There must be an explanation. The own reckless benchmarks contradict my results __a lot__.
There is work that shows that the MOC does not depend on macros it self. Its a common error to be blind and ignorant when it comes to the features the moc offers. Implementation doesn't matter, its the use cases which it enables today across so many platforms. Thats what matters, that the moc and Qt can provide every day, industry standard use cases of what people would like to do with reflection. Boost fusion has by the way also their own reflection macros, just build in a different way, also giving us lots of useful usecases. At the end, we don't want either in the standard, but should achieve to be able to replace both with the standard.
Let me try and answer here. There were reasons to avoid clang parser from the very beginning (including symbol caching and other necessary optimizations - you can check some info in this presentation: https://www.dropbox.com/s/tqed22izc4wd5es/spbusergroup.pdf?dl=0, architectural reasons (CLion is based on IntelliJ platform and it was easier to fit our own solution there), and some historical). Also while we agree, that clang solution is better in terms of correctness, in terms of performance for the IDE goals it's not ideal. We were considering clang integration into CLion a couple of times already and the best solution we see for now is to continue with improving our own parser, looking at clang as a source of useful information. So we are not using it directly, but follow it anyway. Talking about false-positives in CLion, we do appreciate when users report the problems they meet in the product. And we follow the tickets, grouping them and improve the product with each release.
Thanks for your support. When deciding on the exact implementation and after chatting to the users who requested the feature, we selected this direction as a first step. So we do plan to implement disassemble on demand (you are talking about here), most likely in 2017.2.
Thanks for pointing it out, it's great you took your time to follow the article. I narrowed mentioned statement to system_clock.
I think I might use that second one. Me: How is the base stack type implemented? Interviewee: What do you mean by 'base stack type'? Me: Correct! Exactly the response I was hoping for. Next question... 
&gt;Almost every other "reflection" feature of languages has been rhntime reflection. C++ is blessed in that it has a very similar language to pillage for ideas that have been proven to work ­— D. C++ could basically just lift it directly from D as is. Basically every metaprogramming-related proposal for C++ already exists in D.
Integration is done for Vim but once I'm fully done with refactoring stage (moving the editor-agnostic framework to a separate repo) it will be possible to integrate it in environment (editor) of your choice. I'm currently working on indexer implementation which took me more than I expected and therefore refactoring step will be put on hold until I'm finished with that completely. I also need to stabilize the API before publishing it.
Ignorance is a bliss. You could have had a look at work that had been done before making such underestimating judgments. It is not about plugins per se ...
At the time I was deciding for one or another, clang_complete was much easier to setup (automate) but it also had one feature that I really missed from YCM - function parameters autocompletion. Replacing one plugin with another is just matter of installing it and disabling the other one. Nothing more than that.
There are multiple backends available in TensorFlow, though Eigen is the one we're most interested in! I think the idea is to have multiple so that it remains adaptable to a large number of systems, though you'd need to check with a TensorFlow maintainer for their long-term plans. Yes, we're adding OpenCL to Eigen's Tensor module, which then allows TensorFlow to run on OpenCL devices. It's true that there's not a lot of information out there at the moment about our work, this is partly because it's still so new. That said we're submitting a paper to [IWOCL 17](http://www.iwocl.org/iwocl-2017/conference-program/) which will hopefully explain some of what we've done, so the situation will improve.
Good question, I meant vertices.
Cartesian coordinates, yes.
Call the vertices A, B, and C. It's not hard to find these three [Euclidean distances](https://en.wikipedia.org/wiki/Euclidean_distance): * between A and B; * between A and C; * between B and C. Is that what you want?
&gt; 12 different operations Can you show us what operations those are? 
NM actually it's 6 or 3. Some of the distance measurements would be redundant! 
I can't figure out what redundancy you speak of. Post some code; show us how you're trying to do this.
&gt; Using `$` has been argued out of favor because it is common in legacy code, particularly in code generation and template systems which are not necessarily valid C++ but produce C++ sources. Nitpick: `$` in identifiers is valid C++. The following program: #include &lt;iostream&gt; int main() { int my$ = 3; int $my = 4; std::cout &lt;&lt; my$ &lt;&lt; " " &lt;&lt; $my &lt;&lt; "\n"; return 0; } compiles and prints "3 4" as expected. *Ironically, I discovered this when working on a macro-based reflection utility with a colleague, specifically when implementing automatic json-deserialization as `$` was used in some json-schema names I think; I am not sure whether he discovered it by accident or not.*
gcc and clang and some other compilers allow it as an extension. (VMS made heavy use of it). GCC has a `-f[no-]dollars-in-identifiers` flag and clang has a `-W[no-]dollar-in-identifier-extension` flag which default to allow them but you won't find it in the c++ language spec.
Doesn't youcompleteme use libclang?
libclang != [clang_complete](https://github.com/Rip-Rip/clang_complete).
Pretty sure the C++ logo is a footgun. Or at least, should be. 
Have you looked at Cereal for C++11 serialization ?
Hah, thanks. This is cool, is this Python 3 only? Just goes to show how much I have to learn in Pythonland :)
I've seen it mentioned elsewhere that attributes aren't intended to change the runtime behavior of a program, at least as far as C++'s attributes are concerned. I mean, we have things like function multiversioning in g++, but it's hardly standard. From what I can tell, they don't think attributes should have any runtime cost associated with them.
First of all intellisense of Visual Studio can be more stupid while the smart feature of CLion is it really smart and helps you while codding, one is an autocomplete and the other the help you always wanted Debug with VS is a pain in the ass, any tipedef shows as it was originally typed, while debuging in VS you will never see std::string and you will see basic_unit&lt;...&lt;...&lt;basicString&gt;&gt;&gt; and in general the debugger of CLion is smother than the VS Compile, the Visual C++ compiler sucks, the performance of the code it poor if you compared it to clang or GCC For me works better and i like it more, it allows me to work with linux and doesnt need 20GB of data plus installing tons of stuff i dont want, it is quick, productive, easy to use and my favorite IDE, it is not perfect but in my opinion is better than anyone else
fixed
I don't know if it would be possible for this to not add any runtime overhead. That's really the point. C++, so far as I can tell, only accepts convenience functionality when it doesn't add too much of a runtime cost. That statement is likely far too strong to actually be reality, but we can turn off RTTI, and often this is done for some reason or another... It actually looks like you *might* be able to do this at compile time if [this](http://stackoverflow.com/a/13787502/1262557) stackover question works to your satisfaction. Of course, that's static polymorphism, so it's not really your usecase. You might be able to use RTTI if you use mixins/interfaces if [this](http://stackoverflow.com/questions/3496561/polymorphism-and-checking-if-an-object-has-a-certain-member-method) is accurate. However, that looks like it might be *exactly* what you wanted to avoid.
It's just the project I have to do for class right now, but writing a reliable data transfer protocol that works over UDP is checking quite a few boxes...
Well, "prefix tree" exists, too, and is taught in at least one school: the one I teach at.
No, it's foolish to only learn one language. Never stop learning C++ but start learning other languages. In my experience, every language that isn't C++ is basically easy-mode C++. Except Haskell.
C# doesn't really have mixins in the classical sense, since in C# a class cannot inherit from a type parameter and there's no multiple inheritance. Rust's traits are way more powerful: for example, in Rust you can define an algorithm that works on numeric types that have certain features (such as the + operator) - you cannot do this in either C# or C++. And forcing people to use global functions, like in C/C++ or D's Phobos is still a terrible idea: much better to provide simple APIs like `List.Sort()` that IDEs can support and people can use.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/65hrv8/if_you_want_fresh_c_tutorial_checkout_this/dgafeah/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!remove
I'm curious to try this out, but I have only a windows machine. Is it possible to run this on windows 10 subsystem for [Linux](https://msdn.microsoft.com/en-us/commandline/wsl/about)? 
`inspect` was actually introduced in Python 2.1 - [source](https://docs.python.org/2/library/inspect.html).
I haven't tried that out. Give it a try if you feel so but it might be easier to set it up inside the virtual machine.
Would be amazing if you added catch support! :)
Personally I don't know much about the backends to TensorFlow, just that Eigen is one and XLA is another. We're not involved with XLA. I can only really talk about what we've done as I'm rather new to all this. Other folks might know more but for sure this is a coordinated effort.
Thanks for your comment! I am not a user of catch but as I understand it, it is more powerfull than XCTest and VSTest so I fear it may not be practical to use. Nonetheless I will take a look at it in the hope of not needing a shoehorn.
I'd love explained: How targets interact with each other: * If i create a library target, what does that expose to any executable targets i have in the same project? How to practically run tests: * If i have several subdirectories declaring their own tests, is there an easy way to run all the tests in all the subdirectories? I think it's always difficult understanding implicit configuration Vs explicit configuration. I look forward to your talk.
The worst is the indian students still learning on some medieval Borland Turbo C++.
Sounds like a scenario that could be better approached with a data-driven design, though.
... What would be the difference ? It's not like IDEs take more than 1/50th of a second to load anyway
You have to create a project, it creates lots of boilerplate files, etc. So currently I'm just using vim.
The article on unity builds is a good introduction. Anyone using cmake can drop in [ucm](https://github.com/onqtam/ucm) (no affiliation) and turn on the UCM unity build option. UE4 is a good example if it being used - our project in work takes about 45 minutes to compile and link normally, but with unity builds takes about 12. One of the down sides to unity builds is that it increases speeds up the full rebuild time at the cost of incremental builds. Unreal has a feature to do "adaptive" unity builds, where it puts frequently changed files together so you only need to rebuild one module most of the time.. 
Their screenshot actually shows [Orwell Dev-C++](http://orwelldevcpp.blogspot.de/). 
Just read the second article in the series talking about std::hash over tuple and other composite types. One of the "problem" is whether boost::hash_combine or something similar preserves the "hashness" of the hashing algorithm. Howard Hinnant hasa fantastic talk on this subject: https://www.youtube.com/watch?v=Njjp_MJsgt8&amp;t Personally, I think as long as there is a customisation point to override the default, this should be done. 
Say I have library that is added as a submodule to my project (so I can control the exact version of the library). Both use CMake. How would I go about having my project correctly compile the library and then get its include directory(ies) and link to it? This is something I have a hard time figuring out how to nicely do in modern CMake.
Yeah, this continues to confuse me. What advantages could it possibly offer?
Yeah, even just a basic test runner with a list of all tests would be amazing. Nice work!
That library has to have proper build scripts. Do not use: * include_directories() * add_definitions() Use: * target_include_directories() * target_compile_definitions() * target_link_libraries() * target_compile_options() If build scripts of the library follow advice above then you can just have a library in a subdirectory of your project, add it to the build using `add_subdirectory()` and consume it with `target_link_libraries()`. Then your own target will automatically inherit include directories, definitions and compiler flags that were defined as `PUBLIC` or `INTERFACE`. It is amazing how many people get this one wrong. And this by the way is not a "modern cmake". These functions exist in 2.8 too. cmake should really remove `add_definitions()` and `include_directories()`, they are the cancer.
You might want to consider "neoGFX" which seems to meet all your requirements! :D
Generating project files for modern IDE. With correct settings. Optimization flags (including LTO) - properly setting them for clang/gcc/vs - is there any sane way to set them at once? Linking static and dynamic libraries - including the ones I found inside some obscure git repo. Building them. Working with header only libraries. Multiproject builds. 
Maybe this is out of scope. Better, maybe it's answerable in a comment. I'm on a project that's built up out of a bunch of different got repos, each of which builds a small artifact that gets pushed to an artifact server and then pulled down by the cmake build startup of the next build in the dependency tree. This process adds a lot of time to the build spent pulling down dependencies, and makes it hard to figure out exactly which dependencies make up the tree deeper than the first level, whether we've got version conflicts, etc. Are there tools, something in cmake itself, best practices that could help us out here?
IIRC target_include_directories() is in 2.8.10 and compile definitions from 11, compile options from 12. Then compiler requirements (to select C++11 / 14 or C99) is from 3.1. In general, it's not just new commands in newer versions that are great, it's also all the bugfixes you don't have to work around because you have a recent version.
Haha, it's like you read the draft of my presentation already!
The question was inspired by [yaml-cpp](https://github.com/jbeder/yaml-cpp), which while usable is not very amazing. It aims to support CMake 2.6, unfortunately, [due to some guys at CERN using it](https://github.com/jbeder/yaml-cpp/issues/361).
I really like the new one that's on the official site. Can't seem to find a SVG version though. Also noticed that their Twitter account (@isocpp) still seems to use the old one.
No KDevelop?
I looked it up, you're right. It doesn't, but it surprised me that you were right because the mixins that I've used like the linq stuff worked really well.
I am currently writing a book on this topic which will be called *Effective CMake*, since CMake is still lacking a good book which takes any (new) users by the hand and guide them through the proper setup of a project using a modern and clean approach. Depending on the length of your talk, I'd focus (as I'll be doing in my book) on project dependencies, how to layout a build system which works nicely with several architectures (for instance using a common C++ base and Android, iOS, Desktop ans Frontends), working effectively with CPack-based installer, how to implement support for own toolchains and own compilers and best practices with tooling such as clang-tidy, clang-format, iwyu etc.
Modern CMake is a build system based on targets. Each targets have their options, dependencies, include directory and CMake resolve everything based on those properties. I managed to port a project to modern CMake with this page https://cmake.org/cmake/help/v3.0/manual/cmake-buildsystem.7.html
I wrote a [post](http://mariobadr.com/creating-a-header-only-library-with-cmake.html) on how to configure CMake for header-only libraries. You can also check out this [pull request](https://github.com/jarro2783/cxxopts/pull/33) that was accepted.
This image was developed for use with the original isocpp.org website, so it is owned by the Standard C++ Foundation. But (originally) they opted to use the image from Bjarne's book (with permission), so I asked for permission to use it. My intent is that it should be the (default) logo for any new group that wants to startup.
After getting autocompletion of a function name, I want to get function parameters (for all function overloads) as well.
So when can we sample/purchase the pre-release?
Nice blog post. However, it only covers the very basics, and not the caveats. `target_sources` is unfortunately not the solution to make headers show up in IDEs. It makes the headers show up only if a target actually consumes the INTERFACE target, and then the headers show up in that target, not in the interface library target. On top of that, the headers show up in *every* target, and completely unordered, losing all its folder structure. It's basically useless. So no, unfortunately it is not that easy.
Hi, thanks for your reply. I'm aware of the basics, but there are many caveats, if you try to do this stuff in real-world projects, it doesn't just work satisfactory this easily. &gt; See bottom of this post - use an interface. See my other reply here: &gt; `target_sources` is unfortunately not the solution to make headers show up in IDEs. It makes the headers show up only if a target actually consumes the INTERFACE target, and then the headers show up in that target, not in the interface library target. On top of that, the headers show up in *every* target, and completely unordered, losing all its folder structure. It's basically useless. So no, unfortunately it is not that easy (when I completely agree that it _should_ be). Thanks for your pointer regarding static/dynamic.
Personally, the only acceptable way I found was to make a static library with a dummy .c file and all the headers. Dirty but it works well enough :(
It's sad, because it's always possible to have another CMake binary on the side (without overriding the system one) tracking the latest release. 
CMake master is working on getting an easy IPO setup. But in general, you can either add -flto for GCC and Clang or /LTCG for MSVC.
You should get together with Daniel Pfeiffer https://cppnow2017.sched.com/event/A8J6/effective-cmake and make complementary presentations on aspects of modern cmake. Bring in Jonathan Muller http://foonathan.net and my three favourite cmake teachers would make a dream team. I'd say tackling cross platform and multi module composable building coupled with good automatic use of static and dynamic analysis and supporting tooling such as clang format. Rather than talk theoretically I'd love to see a practical implementation for a reasonably sized project.
I'd assume it's more of a bureocratic problem of getting it approved and then getting it out to every computer that needs it (and having it on the side). Of course the best solution would probably be for them to bite the bullet and upgrade along with all their projects.
Well the best workaround I am aware of is adding a custom target... `add_custom_target(mylib-headers SOURCES ${HDRS})`... works well, not too ugly, but still very unsatisfactory, I really hope the CMake people manage to find a proper solution to this in 2017. PS: Not to be rude but have you not tested your code before writing the blog post about it? Or did you test it, and it worked properly in your IDE? In that case, I'm curious what your IDE is? (Maybe it's a VS specific issue and works in some other IDEs?) It's kind of misleading for people that read it otherwise.
Iiiek. That's really too dirty for me. :-) As mentioned above I used a custom target. (I'm curious btw, did you consider a custom target? Why go for the static library with dummy .c file?) But neither of the two solutions is satisfactory and feels very far from "modern CMake". There should be proper header-only library support in this age :\
I have tested it, but more in the context of making sure things compile with the correct flags thanks to propagating flags/properties via INTERFACE. Pretty sure I also tested it in CLion - don't have access to my work computer at the moment but I'll try it again on Tuesday and see what I get.
How to find a library (both optimized for cmake and not) using cmake and how to write your own library to make using it from cmake easier. I still struggle with these things and probably don't do them right unless someone else has already written something I can just grab. Also, how to tell what variables you should use from another cmake "module" that you "include". Lots of finger quotes because I'm not entirely sure what the right terms are.
Yeah, Microsoft really obfuscated that one: instead of adding in the options to the Property Sheets for the project, they decided to only offer the functionality as a compiler switch.
No news since **December 2015**?
Don't use `BOOST_INCLUDE_DIRS`, use the imported target `Boost::boost` or the specific libraries like `Boost::filesystem`. These pull in the include path as a side effect. Imported targets are definitely part of "modern" cmake; using `FOO_INCLUDE_DIRS` and `FOO_LIBRARIES` is the old way.
I'd really like to understand what CMake is doing under the hood with targets, hierarchically, and how that maps to current best practices. Also, why do some Find module pollute the graphical menus and why do some do not? Finally, why does CMake not ship a Qt5 Find module? I have to tell my users to append Qt5's path to PATH, which seems like a big step back from Qt4 (actually, Qt5 best practices with CMake would be great, there are at least three ways to find Qt5!).
He probably did, its like you set this up. :/
what we need is module support in CMake and in (lib)clang, and I guess EDG's compiler. What I'm saying is that modules should be a huge win once IDEs can exploit them for better/faster completions and stuff. AFAIK VS2017 does not have full module support in it's version of EDG.
Not every value needs to be read from file, that would be excessive. Especially when the value is used once in an entire project, and once finalised will never change again. Unnecessary overhead to repeatedly retrieve the same constant. And what would be the point if the value is easily accessible anyway, it would achieve nothing. Data driven design is best left to things that are required to be configurable on the fly, or to define several instances of a thing.
You can shoot while running away... neat!
From knowing C++ it is very easy to expand into C# or Java whenever you might find it necessary. It would be a good idea to also pick up Python on the side. There are many things that are much faster, easier and more convenient to do with a little Python than with a lot of C++. C++ and Python are great complements to each other. And, knowing Python makes it easy to expand into other dynamic languages like JavaScript and Ruby if necessary. For pure education and mind expansion. It would be a very good idea to read through the two "Seven Languages in Seven Weeks" books. You don't need to become and expert in those fourteen languages. But, exposure to the very different concepts they use will make you a better programmer in any language.
So your suggestion is to store thousands of values and strings into a global memory space, to define variables that are meaningless outside of a single scope/context, for no other reason other than to prevent someone from changing the exact same value in a header file instead? When you could just have the value set once in an easy to manage space and have it compiled efficiently with literally zero overhead?
This sounds super cool - can you point me to a find module that does this?
An excellent article, thank you Jackie! BTW I've also liked the cppcast episode you did back in October. Just wanted to add that there's another option for reflection - reading symbol files during runtime. While this isn't a real alternative to what was presented in the article, it does the job, and it's an option I've used myself for an in-house development at my job. I've only used it on Windows for reading PDB files produced by VC, but I think something analoguous can be done with the DWARF format produced by POSIX-y toolchains (GCC). By using a combination of this with RTTI, I was able to produce a pretty complete proof of concept after just 3 days of work. This included code which reflected over arbitrarily nested structs, containing C arrays and enums, with 0 changes to the existing (legacy) code, and without any need to switch compilers. Pros: - It worked on legacy code with zero changes to the struct definitions, instantiations or uses - It works with any legacy compiler (even VC6 on Windows XP - those are still used internally here and there in my company, and I imagine in many others). - Relatively easy to understand and maintain even for junior developers - Relatively fast - Short compilation times - no templates - Can be used to get the offset in memory of struct members - Could be used to reflect on arbitrary C++ classes as well Cons: - Requires having the debugging symbols available near the execuable / library. This is problematic for an out-facing product, but for an internal application this was perfectly acceptable. It can also be ok for a backend service of a website. It also makes the size of the distributed binaries larger. However for in-house application(s) this wasn't an issue. - Runtime only (of course). While I had realtime constraints, this "reflection" was done during application startup, pointers to the interesting bits were acquired then and used during runtime. - Could become tricky for anything more than simple structs (although usually these are the problematic ones) - Isn't cross platform at all (although writing a cross platform wrapper for reading PDB or DWARF is doable I guess, it's not a full debugger, just reading structure info metadata). - On MSVC I used the non-standard RTTI function raw_name() to get the mangled name which the debugging API requires, since the name() function returns a human-readable name. But I think the name() function on GCC behaves essentially the same as raw_name(), that is, it returns the mangled name, so that's ok. If you squint at it, that's essentially that's what the Java and C# reflection do - they access metadata added by the compiler to the binary. In the case of the debugging info this metadata isn't there for reflection of course, rather for the debugger, but we can use it for reflection. For reading PDBs on Windows I've used the DbgHelp API. The recommended API is usually the DIA SDK, but I found the DbgHelp API easier to work with. It's documented [here](https://msdn.microsoft.com/en-us/library/windows/desktop/ms679309(v=vs.85\).aspx). It also has the following advantages: 1) Pure C API Okay, this is a personal preference, since the DIA API is COM based. And I don't like working with COM in C++. Even with all the wrapper classes it's still a pain. The DbgHelp C API is what you might call a bit old-fashioned, but it's simple. 2) The dbghelp.dll is distributed with Windows. While the DIA SDK requires distributing and registering the msdiaXX COM dll, which is a pain. So with dbghelp.dll there's no need to distribute any DLLs with the application. And for reading type information there's no need to use the latest version, the basic functionality of reading struct metadata has always been there as far as I can tell. The one disadvantage was that it's somewhat poorly documented on MSDN. However, a combination of looking at examples (e.g. [here] (http://www.debuginfo.com/examples/dbghelpexamples.html)) and some exploration with sample structs was enough to get me what I wanted. 
Generator expressions are so confusing that you could do your whole presentation on them alone.
Whatever you do don't call it "Modern CMake". A simple google search shows many articles talking about 'Modern CMake' and some of these are showing what is now considered old out of date cmake style. Hahaha. 
If you really want a PC to fly, load up an old version of DOS five or six and use Borland turbo c version two or perhaps write it in assembler. Or, get a nice pic32 from microchip.com maybe and rewrite your algo in straight machine language, and your code will be faster than any thing in the entire universe. The pic32 also has a c compiler.
Have a look at the sources! It's also in the module documentation and patch notes will mention when a new one is added to a common Find module: https://github.com/Kitware/CMake/search?l=CMake&amp;p=6&amp;q=imported&amp;type=&amp;utf8=✓
So many things to do but so little time...
I'd say that most people assume you can't have any software if it doesn't come from the vendor. There will certainly be issues for distributing it to all the machines, but they must have something already to make it work for custom software they internally use, so it's not impossible. Just no one really tried it. I understand the business reasons behind it, but as an engineer, I find it unacceptable not to fix that, it's just hard tech debt at this point.
Just have a super-build setup where you have one huge pure CMake project and integrate all the various libraries with "add_subdirectory()". With the proper amount of caching, it should be fine! The pros for doing that is that you can rebuild everything with a new compiler without going through recompiling every dependency, uploading it with a unique identifier. Same applies if you change compilation options such as adding a code sanitizer. It just works.
A comparison against Bazel would be useful because my coworker is obsessed with it.
Yea exactly - one custom target just for showing the headers, and then the actual INTERFACE library target (without target_sources). Anyway /u/mariobadr mentioned below that target_sources now may actually work so I'm going to try it again... :-) But I'm not celebrating until I've seen it working by myself ;) Good points by the way on the targets in the IDEs!
Would doing an additional full check inside of the case statement be reasonable?
why be mediocre in 2 things, when you can be good in 1 (if you ask me)
&gt; target_sources Wait, can you can use target_sources to add files to a target made in a parent directory? This might be the best feature I didn't know about.
&gt; Products built with C++ cannot be considered as finished products. Um, okay... Flamebait horseshit.
very true.
I can't agree. It was an *attempt* at flamebait, but a third-rate attempt at best. To qualify as first rate flamebait, you can draw ridiculous *conclusions*, but when you base them on outright falsehoods (e.g., claiming that Windows is written in C++ when it's actually almost entirely in C, using C++ solely in the graphics subsystem), that weakens your argument to the point that you're likely to receive more pity than flames. 
&gt; when it's actually almost entirely in C I don't work in Windows, but I believe that this is mostly false. *Kernel mode* is almost exclusively C. As I understand it, user mode is generally C++. (I see Windows devs submitting bug reports against the compiler and libraries, and they do care about C++ a whole lot - to the point where the Visual C++ team was internally named Windows C++ several years back).
&gt; Although being a hardware-oriented language, C++ completely ignores efficiency. Claim without evidence. &gt; A language construct that has uncertain translation to assembly cannot be part of C. Genuine question: Is that a standardization guideline set and applied by WG14? &gt; Thus, C++ is completely unusable for C programmers. Isn't there a sentence like "C++ has C at its core" one paragraph ago? &gt; It makes them lose control over hardware, and in terms of systems programming, software produced with C++ is unacceptably inefficient. - Totally false. - Violates common sense. - Claim without evidence. &gt; It is very intriguing to see C++ actually being used in the industry, and there must be a reason. Nothing to feel intriguing. All premises so far are wrong. &gt; Some say that Linux shows 1200% higher performance than Windows. Citation? Who is "some"? I'm not saying this is definitely wrong, even though the 1200% claim is suspicious enough. But it totally lacks the decency of writing. &gt; Windows is a prototype operating system. Not saying Windows is anything good. But, huh? "prototype operating system"? &gt; Products built with C++ cannot be considered as finished products. Interesting. That would make a GCC and LLVM unfinished. - https://lwn.net/Articles/542457/ - http://llvm.org/docs/FAQ.html#in-what-language-is-llvm-written &gt; If a project is implemented in C++ and is going to be used in production, it needs to be ported to C first. - Totally false. - Violates common sense. &gt; If a project is implemented in C++ and is going to be used in production, it needs to be ported to C first. It shouldn’t be a very difficult task: Wait. If it is not very difficult to port C++ code into C, doesn't that mean: - The programmer is basically trans-compiling C++ into C manually. - The programmer will learn what the corresponding C code is given the C++ code. - Given the programmer is proficient in writing efficient C code, they will learn how to write C++ code too. - The programmer will start to feel certain about how the C++ code is translated into assembly. - With these knowledge, the programmer will become aware of how to control hardware using C++ and also regain the feeling of control. - Soon, the programmer will understand how to make *finished product* using C++. Wow! The final sentence destroys the entire post!
Developers can start testing integration today. The code has been shipping in MSVC for over a year. Grab the latest copy of VS 2017 and it should work for most scenarios. If you do run into an issue, let us know. 
Alas, I'm only a student, but if you give me people to email while I'm interning with MSIT this summer, I'll be sure to do so! (And I'll be sure to tweet Dona)
See my response above--compiler features start off in the command line and don't make it to the IDE until they're ready for everyone and their sister. The average C++ developer would be scared by a TS :) So no desire to obfuscate. We just really don't want to push them until the end-to-end story is complete.
"Only a student" is a fallacious statement. You're the future, right? It's great to have students using C++. Shoot me a mail when you start this summer! My email is my first initial and my last name (though it's not hard to find me if you have access to our internal Active Directory services.)
We've tested modules in VC14 U2 and U3 and things were barely usable on trivial examples. Here are a couple of issues (we haven't re-tested this with VC15): * Using `std::string` in a struct results in VC14 U2 with linker's inability to resolve string symbols while linking `foo.exe.obj`. VC14 U3 compiler in this case fails with internal error while compiling `driver.cxx`. * How to only produce `.ifc` file without the object file? /module:export? Looks like compiling the header (with /TP) is the best options so far: it produces `.obj` but a small one. cl /c /EHsc /experimental:module /module:interface /TP foo [More information on our tests](https://git.build2.org/cgit/change/tree/build2/cxx-modules).
Most of the issues we're chasing down now have to do with the standard library. I'll follow up on the `std::string` issue. Feel free to send me mail and we can work on the rest of your issues. 
Old cmake : `add_definitions("-DUNICODE")` Modern cmake: `target_compile_definitions(myApp PRIVATE "UNICODE")`
You are clearly missing my point. I'm not going to convince you, then. Have a nice day.
I feel like half of my brain cells just commited suicide
How would the abbreviated syntax help with the complexity in this article?
Find modules primer would be great! 
&gt;What would you like to get from such a talk? I have been using cmake essentially the same as I was when I first started using it, circa 2009 maybe. I have never even heard the term "modern cmake" so from such a talk I'd like to hear what you actually mean. I'd also like some info on how best to handle external dependencies. Right now in a project I'm linking to about 5 different libraries, deployed on a few different linux systems. I basically set environment variables to specify library locations, but this is certainly suboptimal.
Hm that's exactly what I said below but then /u/mariobadr replied: &gt; I just tested it with the latest VS on my laptop (the one with CMake support built-in) and it seems to be working fine So I guess I was right and it's still useless/messy. Too bad. Good I didn't get my hopes up.
You can use generator expressions to accomplish that: target_compile_options(YOUR_TARGET PRIVATE $&lt;$&lt;CONFIG:Debug&gt;:-some_debug_option&gt; $$&lt;NOT:&lt;$&lt;CONFIG:Debug&gt;&gt;:-some_release_option&gt; ) Also, if another target links to the target, you can also have it have some of the same compile options using either `PUBLIC` or `INTERFACE` for the scope. **EDIT:** Fixed to show proper way to set release options.
The default Qt5 modules do this.
Ah, thanks. ... and is that seriously the syntax? $&lt;$&lt;CONFIG:DEBUG\&gt;: that is not pretty.
That's the syntax for [generator expressions](https://cmake.org/cmake/help/v3.8/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions\(7\)), which are supported by almost all newer ("modern") keywords and are more useful than they look. ~~You could ofcourse do something like this:~~ Doesn't work actually... if($&lt;$&lt;CONFIG:DEBUG&gt;:TRUE&gt;) { target_compile_options(YOUR_TARGET PRIVATE -debug_option -debug_option2) } 
Intuitive syntax was not part of the required requirements for this proposal. 
Agreed. POSIX threads are really bare metal and require extreme caution when used (particularly in C++). I'm not familiar enough with the STL or boost thread libs, but I know Qt multithreading implementation is really simple (if you're willing to use Qt).
The syntax didn't change. 
Can we please all ignore this piece of offal and not post anything like it on this subreddit in the future?
&gt; they do care about C++ a whole lot Isn't that because of the MSVC compiler that doesn't care about C? :)
Good point. Maybe "Fluent CMake", though perhaps that's better suited to a book and if it actually demonstrates tested and thorough patterns. A longer and more specific title is probably best for a presentation. This would also help focus the talk and find references to it.
The funny thing is that if my module above is possible (i.e. if you can re-export symbols from a header file like that), you pretty much don't even need Microsoft to do this for you. The number of Windows API calls in my 307,000 lines of code is in the low dozens, and the number of types and constants used isn't that much greater. I can stick them in a module file like this myself, no problem... 
But then that doesn't work with your "functions returning `bool` should be fine" part.
Thanks again. Hopefully the new wording gets across the point better? Btw, are you T.C. on SO?
Yes, find modules (like FindFoo.cmake) do not impose many restrictions on what variables or named IMPORTED targets are provided. There are conventions, but those a bit weak, so there is no generic answer to your question. Config modules solve many of these problems, but require upstream to provide them. A good Find module will document IMPORTED targets which are available after a successful find. This is also true of Config modules anyway.
Thank you very much. It solves the last issue I had with my new CMake build.
&gt; If i create a library target, what does that expose to any executable targets i have in the same project? That is up to how you define the library target. If you write add_library(mylib mylib.cpp) add_executable(myexe myexe.cpp) target_link_libraries(myexe mylib) then the relationship is that CMake will ensure that mylib is built before myexe, and it will add mylib to the myexe command line. If you use other `target_` commands you can have more control over how myexe sources are compiled, as they depend on mylib. This typically means setting include directories or compile definitions. See https://cmake.org/cmake/help/v3.8/manual/cmake-buildsystem.7.html for more. I'm not sure what the difficulty with tests is. Can you be more specific? I don't know what you mean by implicit versus explicit configuration. 
Great, I didn't know that Daniel is presenting there. It looks like there shouldn't be too much overlap between our talks, except perhaps regarding finding dependencies. These topics are large and everyone seems to have a different difficulty with them, so explaining principles can often go further than trying to find the answer for everyone. For the topics you mentioned, https://cmake.org/cmake/help/v3.8/manual/cmake-buildsystem.7.html, https://cmake.org/cmake/help/v3.8/manual/cmake-packages.7.html and https://cmake.org/cmake/help/v3.8/manual/cmake-toolchains.7.html are a good starting point. There is no such 'high level' manual for integration of tooling, but I think that would be useful to have. I have kept the buildsystem of https://github.com/steveire/grantlee fairly modern, at least as far as porting it away from old-style commands (but not as far as integrating tooling like you describe), so you could have a look at that. It has dependencies, tests, cpack etc.
Well, it is still unusable on linux. Just too much bugs, like the bottom of text is just cut off, this is due to text being aligned to the bottom of elements, i.e. buttons, and i just cant look at that mess... Or like, if i want to rename file, i can barely see the name of file in text field, i can only see the top of text.....
Indeed, I think it should be fine from a coverage point of view to select a comparison based on the first member of a pair, and use the second element as a unique ID inside the context (like the index). It should work fine as you said. It is quite clever :) I will have a try at it after my vacation leave.
Makes total sense. There's not even consensus yet among implementations, is there? It's good to have "pro users" use it and gain experience with it but working on IDE integration is a bit pointless at this point.
https://github.com/Kitware/CMake/blob/master/Modules/FindPNG.cmake is a good example, because it also depends on the zlib library, and so adds it to its own `INTERFACE_LINK_LIBRARIES` target property.
&gt; Modern CMake is a build system based on targets This for me is the most-core principle. Almost everything else follows from this.
Hi there, Gabriel Dos Reis here. I would agree with you if this Gabriel dos rios you speak of has done this outrageous thing you are saying. I don't know if he works for Microsoft, but he definitely does not work in the C++ team - I would have bumped into him otherwise. If you meant to refer to me, I am afraid the name isn't the only thing that is inaccurate in the accusations. Below I offered a few reasons for why and point to materials. I also seize the opportunities to address a few misstatements elsewhere in this thread - not necessarily yours. The title mentions "concept and module TS", but the body of your statement talks only about modules. I [announced](https://www.youtube.com/watch?v=RwdQA0pGWa4) that "C++ modules" will be available in VC++ in the VS2015 timeframe, and they were available in [VS2015 Update 1](https://blogs.msdn.microsoft.com/vcblog/2015/12/03/c-modules-in-vs-2015-update-1/). Ever since, the VC++ team has been busy improving the quality, in addition to implementing standard features. In the Spring 2016, I gave a ["Spring 2016 update"](https://www.youtube.com/watch?v=mbhAQIZuI5k) about the state of modules to the C++ folks in the Pacific Northwest and they graciously made it available online - which was also debated on this very forum, if my memory serves me correctly. There is also a [GoingNative video](https://channel9.msdn.com/Shows/C9-GoingNative/GoingNative-46-Why-you-should-be-Using-Cpp-Modules) showing how you can use and build modules, including building IFC metadata out of existing headers so you can consume them as if they were modules. Kenny Kerr has written numerous tutorial materials about how to build and consume modules: [here](https://kennykerr.ca/2015/12/03/getting-started-with-modules-in-c/) and [here](https://msdn.microsoft.com/en-us/magazine/mt694085.aspx) some samples. Additionally, I've been working with standard library providers to define what the Standard Library should look like when consumed as modules. It is a work in progress but the result is [public](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0581r0.pdf). As you can see, there is no basis for "online hide-n-seek" claim. Somewhere else, you expressed surprise that there hasn't been any news since December 2015. There has been, as the materials I point to above show. However, it is also true that most of the syntax has not changed in anyway way that impacts usage. That is why the VS2015 Update 1 blog post remains a good reference -- in fact /u/AndrewPardoe had made a few minor updates to it. This also reflects the fact, from usage perspective, the specification is mature. Now, we need action from WG21 to enable the next stages of bringing this long-awaited functionality to the masses. Some compiler writers have been busy at work with the module TS. You routinely hear about VC++ and Clang. But you will be pleased to learn that GCC has started an implementation. You can follow progress on the [GCC cxx-modules wiki](https://gcc.gnu.org/wiki/cxx-modules) page, which also gives you directions about how to get the compiler source and build it. Regarding concepts TS, both Andrew Sutton and Bjarne Stroustrup have published numerous tutorial materials -- just do a little web search of their names and "concepts", I'm sure you will get hits. Bjarne's most recent is [this paper](http://www.stroustrup.com/good_concepts.pdf). It is a good read. Try it. Now, having said that, is there room for improvement? Absolutely! The Visual C++ team is working on IntelliSense integration -- here again, caution needs to be exercised about how an "unofficial", subject-to-change-any-moment, experimental feature is aggressively pushed to millions of developers. The team has to square the circle of keeping on top of experimental features while also not breaking customers' code. I would like to see more done on the build system side. However you don't change build definitions every time you change or upgrade a compiler. So, a good chunk of the work here is predicated on the stability of the design and how much it is close to being standardized. Positive actions from WG21 here can be a tremendous boost. Lastly, this isn't about "Microsoft Modules". This is "modules for C++" and all C++ programmers. It is a community effort. The recommendations I've made would have been the same if my employer had been Google, or Red Hat, or Facebook, or you name it. 
We are trying hard to closely follow WG21 directions here. At the last standards meeting (Feb 2017), the standard library modules paper was scheduled for discussion but we never got to it largely because I was in CWG trying to advance the main TS, and also because the overall schedule was packed. I do hope we will make more progress at the Toronto meeting (Jul 2017). I understand you reported some issues; my understanding is that they have been fixed. If you're willing to try the nightly builds, please give them another try and let us know. 
I think the most-recent design thinking about this is here: https://cmake.org/pipermail/cmake-developers/2015-July/025680.html
&gt; The code you wrote doesn't seem to actually do what you said? Oops, thanks. Fixed now. &gt; This isn't explicit and has some useful benefits Oh, I see what you mean by explicit now. There is explicitly a target_link_libraries(myexe mylib) and during the design of all of this, we decided that that was enough of a link between the two, though that was not uncontroversial. &gt; figure out why this works and `include_directories` does not (when used in place of `target_include_directories`). Not sure what to say there. This is why the recommendation is to use the latter instead of the former. There are many wrong or suboptimal ways to use CMake, but the manuals such as https://cmake.org/cmake/help/v3.8/manual/cmake-buildsystem.7.html focus on the correct and optimal ways.
Thanks, I understand it now. I still think it looks horrible and should be simplified. 
I hope concepts don't end up as an extreme template metaprogramming style feature for library authors only, but you're right this is... A bit of a clustertruck
I think you get an official +1 to being awesome. I don't know what happened to the msvc team but you all seem like ~~ly~~ extremely nice people
Probably not what you're looking for but I ended up using python scripts to manage third-party non-cmake dependencies on our last major cmake-based project.
This declaration doesn't seem right: template&lt;Forward_iterator Iter, Number&lt;Value_type&lt;Iter&gt;&gt; Val&gt; Val sum(Iter first, Iter last, Val acc); Should it be something like: template&lt;Forward_iterator Iter, Number Val&gt; requires Number&lt;Value_type&lt;Iter&gt;&gt; Val sum(Iter first, Iter last, Val acc) ?
You're right. Pinging /u/bstroustrup 
This is the recording of my last session in german. https://www.youtube.com/watch?v=DovEf7x4xvI The setup is not part of this video. It's kind of hard to show a making of a live coding presentation, to show off this tool. I think the benefit is more to show how to use C++14 including std::thread effectively with Windows APIs (win32, IOCP) and Com APIs (DirectX &amp; DXGI).
In this case, you may want to set it globally or you may end up in mismatched libraries. Careful!
Thanks, my bad. It's old stuff anyways, we should all be using a much more recent version!
Those were only **bare essentials**? I am a long way from entry level position then :(
At the end of the day what people want are fast, reliable, portable builds. Bazel and CMake are absolutely competing in that space. That CMake happens to generate builds to do it is an implementation detail from the perspective of, "Which should I use for my next project?"
Calling `sum()` *more flexible* in the paper is odd (edit: I guess the intent was actually flexibility in terms of implementing `sum`, not using it). It's now limited to only numbers. Concatenating `std::string`s is a pretty reasonable operation, that we would then have to "deliberately" write again in the same way. Which, best guess, would look something like this: template &lt;Range R, Copyable T, BinaryOperation&lt;T, T const&amp;, Value_type&lt;R&gt;&gt; Op&gt; T foldl(R&amp;&amp; range, T init, Op op) { for (auto&amp;&amp; elem : range) { init = std::invoke(op, init, elem); // sigh } return init; } Where `BinaryOperation` is something like: template &lt;class F, class R, class X, class Y&gt; concept bool BinaryOperation = requires(F f, X x, Y y) { { std::invoke(f, std::forward&lt;X&gt;(x), std::forward&lt;Y&gt;(y)) } -&gt; R; }; I don't see anything in the Ranges TS like this... would I have to do `Invocable&lt;T const&amp;, Value_type&lt;R&gt;&gt; F` and then a separate `requires` clause on the result? 
Speaking of the latest copy of MSVC, what happened to the nuget packages? I'm getting timeout errors whenever i try to update.
&gt; Can I spread a module interface over multiple files? As part of an experiment, VC++ supports spreading module interface definition over several interface source files. It is an ongoing experiment, so there are still some rough edges. Try `cl -experimental:module -module:merge: MyModule 1.ixx 2.ixx 3.ixx` where `MyModule` is the name of the module that all of `1.ixx`, `2.ixx`, `3.ixx` collectively define the interface of. This is an undocumented switch because we are still working on it. Eventually, I would like to see something along those lines without added syntactic ceremony or syntax overhead. The spread of interface over multiple source files can be worked out at any time. Ideally, I would like to see it done after the Module TS advances to the next stages, giving enough stability for tool vendors to work out support for feedback from larger and more diverse pool of users. 
Don't give away all my secrets... that was going to be revealed in the big "SCarroll's Secrets of Technical Management" consulting class I was gonna charge big bucks for!!
This must be a troll.
cppreference has all the info you need for concepts. I've been using them for months, and I've never looked at the actual spec. (Much like yourself, I'm way too lazy for that shit). They have docs for other experimental extensions, too. http://en.cppreference.com/w/cpp/experimental
Is there any FOSS project suing modern C++? I always try to find something, but it's usually C++89, C++ without templates etc. Basically C with Classes.
Great, I will try them out, and if they work our entire main solution as soon as the dogfood server is back to life. BTW I thought P0581R0 was spot on. Was there any thought about providing a few header files alongside the ifcs containing legacy macros to make it easier to port? We found things like NAN and M_PI were used quite a lot in our code and ended up writing a macro_cmath.h
Thanks (: Briefly looked at the repo and it looks interesting. Added to my TODO to check it deeper
Nice, added to the TODO too
I decided to postpone optimizations and get back to it when it'll be a real issue. Anyway thanks, I'll bare it in mind
Bazel AFAICT can use ccache and distcc, that's how we're trying to use it. I'd also be surprised if it can't generate project files for visual studio because Google still does a ton of Windows development.
You can write KMDF drivers in C++ but you just can't use the standard library, use exceptions, or a few other things. 
Right... reading symbol tables is ACTUALLY black magic. A library I was going to cover in this post but didn't have time (would like to cover it in a future post if possible) is HippoMocks, which uses knowledge of the Itanium ABI to implement function reflection, as I understand it. https://github.com/dascandy/hippomocks
From the C++ Standard: A program may add a template specialization for any standard library template to namespace std only if the declaration depends on a user-defined type and the specialization meets the standard library requirements for the original template and is not explicitly prohibited. I don't think Optional prevents it, so as long as you don't specialize anything in namespace std, you're likely good to go.
&gt; BTW, another question is whether we can specify multiple `/module:search` options to provide several module search directories? Yes, you can; that is supported. Just as you can supply as many `module:reference` options. Regarding your scenarios: it sounds to me as if you would like to extract the dependencies of a translation unit. That is something we are planning to implement in `CL.exe`. Because VC++ has to support myriads of build systems, it can't just dump the dependencies in the form of `gcc -MM`. I would like to ensure that whatever is emitted correctly covers your scenario. Could you shoot me an email? I can be reached at my initials at Microsoft dot com.
Hmmm... The limitation for it to be user defined type is logical, yet makes my idea far less​ useful. Thanks for clarifying the rule for me.
Well for starters it lets you create templates that deal in `optional` without caring what the inner type is. With the current state of affairs if you want to traffic in `optional` objects you have to do a bunch of tag dispatch magic to handle references differently and coalesce them to pointers rather than `optional&lt;T&gt;`.
[`boost::optional`](http://www.boost.org/doc/libs/1_63_0/libs/optional/doc/html/boost_optional/tutorial/optional_references.html) already supports references.
errr WAT? C++17 is pretty much sealed. Moreover, databases come and go, I doubt any of them will ever make to c++ standard
ImageMagick springs to mind. Good luck!
I was thinking providing multiple implementation. I'd only allow the inclusion of one of the headers. The goal of that would be to let users experiment with these implementations and see the pitfalls and advantages of one over another.
I don't think you want sum() to work on strings. Even though concepts are syntactic duck typing, we want to use them as representing semantics, not just syntax.
Very good point. When I learned CMake I was confused about the names of some variables (eg, is it relevant/required that sources are listed in foo_SRCS first before being passed to add_executable, etc). I have some code to adjust :).
Semantics. A pointer is an address, an optional reference is either an object or none. Also an optional could have higher level access like map() and stuff.
A naked pointer doesn't communicate ownership semantics, for starts. Second, accessing an empty optional is a detectable program error that (if you subject yourself to such things) throws an exception on attempted access. As others mentioned, supporting optional references is also better for generic code that works with optionals.
Yeah, that makes sense to me. It's difficult to actually represent semantics though. 
You would probably find it useful to read https://cmake.org/cmake/help/v3.8/manual/cmake-buildsystem.7.html#transitive-usage-requirements . You can define 'imported' targets in Find modules so that usage is convenient and simple.
&gt; Also an optional could have higher level access like map() and stuff. After doing a project using `boost::expected` I want everything to have `map` and `bind` it makes code so slick.
Yes, and `int` may also be 64 bits. So for storing data I would use `int16_t` (more terse) or `int_least16_t` (more portable).
`int16_t` is not guaranteed to be implemented. It's marked as optional. Only `fast` and `least` variants are guaranteed to be implemented. See http://en.cppreference.com/w/cpp/types/integer
Clearly, the one that's correct. Everybody knows which one that is. ... I'll see myself out.
I agree, `int_least16_t` is more portable than `int16_t`.
Ownership: Well, surely if the optional holds a reference, it would be non-owning? Unless it's extending the life of a temporary... Which feels ambiguous... Although not as bad as a pointer? Detectable program error: As long as you don't end up with a dangling reference, which you'd presumably avoid by clearing the optional when the referred to object distructs.
This is very cool. I haven't looked at the code at all yet: I just cloned the project, opened the solution in VS, built and ran. Boom, my VS instance is copied to another window. Thank you for this tool!
And part of the requirements for the original template is "a program that necessitates the instantiation of template `optional` for a reference type [...] is ill-formed." I'm not sure how you can have a useful specialization while meeting that requirement.
Personally I'm quite happy with Pango. Simple text is simple (when used with Cairo, at least). And if you happen to need lots of formatting through embedded HTML, it can do that too. 
because in practive nobody gives a crap. when you work on a codebase of 100,000+ lines of code your bottleneck in performance is not going to be integer math. If you have a specific use case where integermath is actually going to impact you performance in a significant way, you can still choose to actually look up to compiler behaviour for every operating system you want to support, to see if replacing int with int_fastX_t is actually going to make a dent in you implementation. This however should account for 0.01% for you codebase. My money is on whenever you activate -o3 -fast-math it is fair game for most compilers to optimize your integer calculations in any way they think it's right and int_fastX is not going to make much of a difference. 
Would love to see that talk in English if that's possible. Also the scripting talk looks cool! I'll just have to learn German!
I would use size_t for counting things that come in containers. I don't generally use 16-bit types for counting anything; that's a limit you reach entirely too easily. For the rest, int is easy to type, and easy to deduce from literal numbers if you feel so inclined. And maybe it's just me, but those intxx_least/fast_t types are a bit of an eyesore, aren't they? And, maybe also just me, but somehow I cannot bring myself to worry about machines that don't have int16_t. 
 std::optional&lt;std::reference_wrapper&lt;std::shared_ptr&lt;int&gt;&gt;&gt; opt; opt-&gt;reset(); // Compile error So no.
&gt; the fact that we don't care about such trivialities. That's what I was afraid of. Why not? I think a logo gives spirit to whatever it is representing. The current logo is dull and dead, while the language is not. 
Propose, or propose not. There is no complain.
It does work but in a classically CMake'ish less-useful-than-it-should-be kind of way. The files added will assume their directory is that in which the _target_ was added, not the directory in which the `target_sources` was called. You thus effectively have to toss `${CMAKE_CURRENT_SOURCE_DIR}/` in front of every file listed, assuming you're good with absolute paths in your generated build files. Otherwise, you have to construct the path relative to the target manually (so moving sub-directories around won't work), or use some ugly CMake snippets to generate the relative path from the target and toss that in front of all the source files. In any of those cases, it's then that much more painful to set properties on source files after they're added, too. You'll see the same path problem with any other option set from your child directory, like include paths, source properties for things like PCHes, and so on.
Wow. I could quote some stuff that has me cracking up... but that'd amount to the whole damn article. Thanks for that link, i needed some giggles. (ETA: not to say the OP article didn't have me chuckling but somehow this one takes the cake imo.)
C++ has a logo now? Is that part of C++17? 
Not enough stickers on your MacBook to set you apart from the Node.js crowd at Starbucks huh? Call me old-fashioned, but I'd say the operative word in "programming language" is *programming*.
Dunno, "language" is pretty important too. What definitely isn't is "logo". It isn't even part of the term :)
&gt; I think a logo gives spirit to whatever it is representing. Then let C/C++ not having a logo proudly represent actually doing some programming :) Bonus points if it said something like "Sorry, we were too busy writing the software you're using to view or print this to make a logo." where the logo would be.
I didn't even know C++ had a logo.
Unless you're writing logo, of course.
I think the best result would be to use a logo design that matches the era in which C++ first made its mark on the world. Something classic. Tasteful. Timeless. http://imgur.com/TPfbc6l
There's no guarantee that `std::vector&lt;T&gt;::size_type` is `std::size_t`, although /u/STL has said at least once that for at least MS' STL it always is.
Proposed Boost.Outcome has a option&lt;T&gt; which can optionally have map and bind available on it. As does its expected&lt;T, E&gt; implementation. https://ned14.github.io/boost.outcome/index.html
Hi there - the logo source files (including SVG) are available on GitHub: [https://github.com/jwkratz/cpp_logo](https://github.com/jwkratz/cpp_logo) We'll make this available on [https://isocpp.org/](https://isocpp.org/) so users can find the source files more easily. Thanks!
Yeah I totally left off T&amp; support in proposed Boost.Outcome. People have queried that choice, I tell them when the committee decides on Expected's T&amp; formulation, I'll adopt their choice then.
Edit/correction: Source files are available here: [https://github.com/jwkratz/cpp_logo](https://github.com/jwkratz/cpp_logo) License details are available here: [https://isocpp.org/home/terms-of-use](https://isocpp.org/home/terms-of-use)
&gt; As does its expected&lt;T, E&gt; implementation. Yeah I know, that's what I'm using, and is why I'm addicted to it now. :)
It's not rotating around itself.
`std::vector&lt;T&gt;` is short for `std::vector&lt;T, std::allocator&lt;T&gt;&gt;`, and `std::allocator&lt;T&gt;::size_type` _is_ guaranteed to be `std::size_t`. There's no guarantee that `std::vector&lt;T, A&gt;::size_type` is `std::size_t`. ;-]
Me either. I like the logo. At first I thought it was the "cool" logo that the OP was proposing. I wish that logo was published more. 
PascalCase MasterRace. Represent. 
Apparently that's not the C++ standard logo, it's just a logo on that webpage, nothing standard at all. A shame though in my opinion, they should make it the standard logo! (or a better one, but the community or committee would never be able to agree on one ;-) )
Yeah, [I just learned that](https://www.reddit.com/r/cpp/comments/65yaik/are_there_any_proposals_to_change_the_c_logo/dgeacjo/). Apparently it was discussed recently [here](https://www.reddit.com/r/cpp/comments/65eqn2/c_has_official_logo/). I don't know how I missed that thread. Nonetheless, it is a shame. 
Thanks for that link, I've actually read it before - always comes up when you search for how to fix CMake header-only targets. &gt; We could consider lifting this restriction for sources that do not compile (but make it an error to add a compiling source). So this was never done, right? And if I follow that email posting, there's no particular reason why it shouldn't be done - in fact people seem to agree it would be a good idea to do it? It was just not done? (yet?)
Well, even thats not happening in c++17..
thread safety notes on all functions.
Or thread safety features in general. Just came across a talk by Herb Sutter on how const implies thread safety in C++1x
&gt; const implies thread safety in C++1x Only in the standard library, _not_ in the language. Libraries _should_ document their thread safety requirements and guarantees; why wouldn't they?
[source](http://www.informit.com/articles/article.aspx?p=1235624&amp;seqNum=3)
Perhaps feature-not-bug that makes you LOL?
If nothing else there is at least the guarantee that std::size_t will be big enough.
Will we ever be free of this argument?
Unlikely. It's just a dorky version of bikeshedding. Both sides have valid reasons, and everyone is free to choose their preference. Except my juniors, where it's [my way](http://i.imgur.com/WXGOIsA.png) or the highway. ;)
Haha, well at least it's not this: https://twitter.com/UdellGames/status/788690145822306304
It can but that's not the route that Google is taking (or anywhere close to the internal version they use). They want to have proper distributed caching and workers with the knowledge in Bazel in order to do more optimizations. See: https://github.com/bazelbuild/bazel/blob/8ff0d0d436b4fd9fd4199d313f708377c7a668af/src/main/java/com/google/devtools/build/lib/remote/README.md
Make sure you use canonical links when linking to a file/directory on GitHub. On GitHub, you can press the "y" key to update the URL to a permalink to the exact version of the file/directory you see -- [source](https://help.github.com/articles/getting-permanent-links-to-files/). I've tried to fix your links: Relative | Canonical -|- https://github.com/bazelbuild/bazel/blob/master/src/main/java/com/google/devtools/build/lib/remote/README.md | https://github.com/bazelbuild/bazel/blob/8ff0d0d436b4fd9fd4199d313f708377c7a668af/src/main/java/com/google/devtools/build/lib/remote/README.md Shoot me a PM if you think I'm doing something wrong.
Last time I have seen a panel of cpp gurus, they said, use int (and vector). I recommend you use int, and static_assert() about situations where you are in doubt.
Can't you reserve memory ahead?
CMake has a great policies system for fixing stuff. I would really like to know if there are plans to use it fix some of the really crazy things in CMake. For example: * Lists are really just semicolon-separated strings. * In fact everything is stringly typed. * Variables are case-sensitive but functions aren't. * The function declaration syntax is weird. It would be nice to have a more normal one. * There's no distinction between undefined variables and variables set to "". For example there's no way to detect typos like this: `set(CMAKE_BUILD_TYPE ${CUSTOM_BULD})` or `set(CMAKE_BULD_TYPE "Release")`. * It's often very difficult to tell where you should use the contents of a variable, and where you should use the *name* of a variable. Again due to everything being stringly typed, but really variable names should be distinct from strings at the very least. Even PHP does this. 
So I tried v14.0.25214-Pre from dogfood and it definitely exhibited different behavior. Sadly that behavior was "error C2025: invalid or corrupted binary module interface file: 'std.core'". I couldn't find any other std.core.ifc files after package install, I was sort of expecting an MSVC/14.0.25214-Pre/ifc
Exactly. Everyone should only do whatever you do. 
I had thought that std::vector was guaranteed to use a capacity doubling algorithm at least since C++ 11? If so, then you will know exactly what it will do, and when to use .reserve() to avoid that where that makes no sense.
But why? Why not use a type with an appropriate range to reduce the risk of incorrect code? Do you *int* people disable compiler warnings or do you put casts everywhere to silence them (comparison with *.size()* for example)?
Also, the part where your initials, username, and the thing you work on are all STL.
No, i'm using default oracle jdk 8u121.
0x13 graphics mode give me so much nice memories.
&gt;Basically such bugs should be found with unit testing. Really? Would anyone bother to write tests with this granularity? Especially when the bug is caused by a bit of arrogance in the first place (i.e omitting the `override` keyword)?
It must be exponential. Doubling turns out to be a bad plan thanks to the walking vector reallocation problem.
Why so? 
I like the actual logo, it is fine, clear and nice
I agree that `override` should be used, I just can't see anyone writing a test that would catch the condition in the article, that's all.
Probably because any problem solved by using [a special allocator for node-based containers](https://docs.microsoft.com/en-us/cpp/standard-library/allocators-header) is better solved by just using a better data structure. But I'm only guessing...
Even then this is the bug that should be caught with compiler warnings/other static analysis or like you said the `override`-keyword. Writing unit tests for this is a waste of time that could be better spent writing tests for something else or rolling your thumbs.
https://github.com/facebook/folly/blob/f258ec23413c8b75680291ce3bb01fc9fed72fc5/folly/docs/FBVector.md#memory-handling
1. - 2. I remember no way to see the type deduced from `auto`, QuickDoc on variable simply gave me `auto var;` 3. I am pretty sure it was, but nevermind, it's good enough for me to hear that all then are present now! 4. I tried to look for any screenshots left, but alas( I remember it was about some 3rd-party library related to OpenGL, that had tremendously long Doxygen commentaries for functions (like, 40-100 lines of description + detailed descriptions of parameters and stuff). When invoking help, the QuickDoc window occasionally went from top to bottom of the screen trying to display it whole, instead of providing a preview. That could be already fixed though, or on contrary be a very rare kind of heisenbug - since I tend to get myself into various crazy stuff no other people ever encounter :)
What granularity are you talking about? I imagine the author meant a test that exercises the methods of the derived class (which you'd obviously have if you were writing a unit test) _via_ a pointer to a base class. That doesn't sound so far-fetched as a unit test, and definitely seems plausible for a higher-level test. Like: class Shape { public: virtual int area() const = 0; // or maybe: virtual int area() const { return 0; } }; class Square { public: Square(int side) : side_(side) {} virtual int area() { return side_ * side_; } private: int side_; }; unique_ptr&lt;Shape&gt; s = make_unique&lt;Square&gt;(5); ASSERT_EQ(25, s-&gt;area());
"The problem will occur if we raise an exception from the move/copy constructor. As I see this, it can happen only with custom move code that we have for the callable object. We should be safe when we use only lambdas" - this is wrong in so many ways. Please look at this code #include &lt;gsl/gsl_util&gt; struct foo { foo() = default; foo(foo const &amp;) { static unsigned u = 0; if (u++ == 2) { throw std::runtime_error("copy-constructor failed"); } } }; int main() try { auto _1 = gsl::finally([f = foo{}](){}); auto _2 = std::move(_1); } catch (std::exception const &amp; e) { } It crashes in gsl_util:59 (or gsl_util:57 if constant is 1): &gt; 4 0x00007fffff0fd701 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 &gt; 6 0x0000000000400b8b in gsl::final_act&lt;main::$_0&gt;::final_act (this=0x7ffffffde2d8, f=...) at ./gsl/include/gsl/gsl_util:57 or &gt; 4 0x00007fffff0fd701 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 &gt; 6 0x0000000000400aad in gsl::final_act&lt;main::$_0&gt;::final_act(gsl::final_act&lt;main::$_0&gt;&amp;&amp;) at ./gsl/include/gsl/gsl_util:59 This happens because std::move does not actually move anything. std::move does not give you [no-throw guarantee](https://en.wikipedia.org/wiki/Exception_safety). 
In accordance to [this SO question](http://stackoverflow.com/questions/4384765/whats-the-difference-between-pretty-function-function-func) &gt; __PRETTY_FUNCTION__ is a gcc extension that is mostly the same as __FUNCTION__, except that for C++ functions it contains the "pretty" name of the function including the signature of the function. Visual C++ has a similar (but not quite identical) extension, __FUNCSIG__.
&gt;https://gcc.gnu.org/ml/libstdc++/2013-03/msg00059.html
Why in the world would you put "The output is below" followed by totally the wrong output, with no indication that it's wrong until later?
The favorite obscure library feature would be a more entertaining question. As far as undocumented (or, in standard's terms, unspecified), I vote for `std::random_device`: it is unspecified if it is random at all, and while MSVC and LLVM libc++ and GNU libstdc++ (where RDRND or /dev/urandom is available) all do the sensible thing and fetch a non-deterministic random number, the MinGW implementation of the standard library does not, and has every right to do so.
documented [on cppreference](http://en.cppreference.com/w/cpp/error/runtime_error#Member_functions)!
/u/Brigapes, it seems a bit overwhelming, but it is not as bad as it seems. It took me years to get there, but I didn’t know how or what to learn. Now that I’ve done it and that I’ve been in the field for years, I know how and what. That is what motivated me to write this post. For some of the things, like the algorithms that I mentioned, you don’t need to know all of the different variations, implementations, and the math behind them. You need a simple overview of the general concepts, enough to understand that it is an option when you are trying to solve a problem. Then, when you need to use it, you can go back and look deeper at the few options that may be appropriate, and you select the best. This overview would not take too long to learn. The challenge is that you can’t get this type of overview very efficiently from algorithm text books, many of which assume you are taking a CS class, and they can be difficult/time consuming to read because they go deep into the algorithms, the data structures, and the math behind it, as well as different implementations and their pros and cons. What you need is more of a summary of part, not all, of that. Anyway, don’t get discouraged; keep at it.
I haven't read it either, but I will. Thanks for mentioning it.
You are right. I asked about it on [SO](http://stackoverflow.com/questions/43466863/isnt-virtual-keyword-redundant-when-override-or-final-specifiers-are-used).
There seems to be other implementations for node allocators that provide out-of-the-box better performance: https://probablydance.com/2014/11/09/plalloc-a-simple-stateful-allocator-for-node-based-containers/
Personally I recommend not ever using int but rather some type which specifies the number of bits. The valid range of int varies from machine to machine so using it creates non-portable program by definition. Moving one's 100,000 line program from one platform to another and trying to chase down a bug resulting from a change in size of short, int or long, etc. would be a huge time waster. Who has time for that.
I don't hate allocators, I hate `&lt;allocators&gt;`.
I use `__PRETTY_FUNCTION__` and `__LINE__` in my log messages all the time.
There is no such data structure. You either pay in locality by not allocating contiguous blocks or you pay in moving elements around into contiguous blocks.
It's specified that way because not all hardware (think DSPs) has access to a true random device or a way to mimic one. Since Windows *does* have easy ways to do that (`CryptGenRandom(NULL, bytesYouWant, pointerToBufferInWhichRandomBytesWillBePlaced)`) I'd call MinGW an incredibly bad kitty here, and not that it "has every right to do so."
Thank you for encouraging me. I will try to promote those topics for international conferences.
The only undocumented thing here is the growth factor. That is literally it. `push_back` reallocates when `size() == capacity()`, how much it reallocates by is up the implementation but when do you care? `insert` is the same for the value variant, and the iterator variant allocates whenever `size()+distance(first,last)&gt;capacity()` as you would expect. The rule is literally if the `size()` after the `push_back`/`insert` exceeds the current `capacity()` then it allocates more memory, what else would you expect?
In this regard, I would say that Stepanov's books and video lectures are the most authoritative sources for understanding the design principles behind the STL. 
I wish that discussion provided an explanation for why it was empirically worse like the folly page does. Paging /u/GabrielDosReis
You are welcome /u/Brigapes. Unfortunately, I took down that website long ago. As for books, yes, I used books. I bought my first C++ book in 1993 before the resources that we now have with the internet were available, so I mainly learned by reading and doing. I have a large collection of books on many software subjects, but I’m not sure that a list of my books would be that useful or encouraging. Maybe I’ll write about some of these subjects separately instead. Divide and conquer…
From what I understand: `.d` files don't work with modules because unlike `#include`, a module `import` statement says nothing about where to find the module being imported. So if you're processing dependencies for `main.cpp` and see an `import M`, what goes in the dependency file? `module M` might be declared in `subdirectory/O.cppm` but there's no way of knowing that while processing `main.cpp`.
I don't know. All I know is that OpenCV's text rendering is even worse than OpenCV itself. And when I was looking for a decent alternative, using Cairo seemed reasonable, even at the cost of two additional image transformations (since libcairo can only deal with one specific internal representation).
Do any of the compilers offer a compile switch that will fail to compile if you forget to add override? That would be extremely useful and helpful.
gcc has `-Wsuggest-override` as of 5.1
clang/llvm
Well done! I too had the habit of putting "virtual" on all the declarations in all the subclasses, then I read the C++ Core Guidelines which as the rule: &gt; [Virtual functions should specify exactly one of virtual, override, or final](https://github.com/isocpp/CppCoreGuidelines/blob/04537cdb111458254f321c7e7f4fcbea3736a5a2/CppCoreGuidelines.md#Rh-override) Now, if only I could switch away from GCC 4.4.7 and MSVC 2010, I'd be much happier to oblige. As it is, I've been forced to use macros to enable the C++11 features on GCC 4.9 and Clang, and disable it everywhere else. Le sigh. EDIT: TIL there's a GitHubPermalink bot :)
C and C++ deserve to be considered separately about their logos.
I'm pretty sure I've never used override on the destructor &amp; GCC and clang have both had warnings about the base destructor not being declared virtual at -Wall (which is a compile error with -Werror). YMMV.
[This](https://github.com/aserebryakov/lia-examples/blob/master/01-override/02-destructor/01_not_virtual_destructor.cpp) file is compiled with no error under cygwin: &gt; g++ -Werror -std=c++14 01_not_virtual_destructor.cpp &gt; $ g++ --version &gt; g++ (GCC) 5.4.0 Did I wrote the command line wrong?
Make sure you use canonical links when linking to a file/directory on GitHub. On GitHub, you can press the "y" key to update the URL to a permalink to the exact version of the file/directory you see -- [source](https://help.github.com/articles/getting-permanent-links-to-files/). I've tried to fix your links: Relative | Canonical -|- https://github.com/aserebryakov/lia-examples/blob/master/01-override/02-destructor/01_not_virtual_destructor.cpp | https://github.com/aserebryakov/lia-examples/blob/b9da9cf5f2ddacefdca858e908fb115b7fc75dd7/01-override/02-destructor/01_not_virtual_destructor.cpp Shoot me a PM if you think I'm doing something wrong.
Obviously English should have a logo too
Those languages also have cool names that you can incorporate into the logo design. Python has the obvious snakes, lambda looks like an "h", a bird is "swift", "Gopher" contains "Go", and metal cogs can "rust". What cool thing can we do with the name "C++"?
Every few days I consider applying to your team...
So this guy wants to "expose" his "pointer" - no thanks!
I wouldn't change it, just own it heh. At least you didn't prattle on about `back_inserter` like the other guy.
&gt; [`override` ensures that the function is virtual and is overriding a virtual function from the base class. The program is ill-formed (a compile-time error is generated) if this is not true.](http://en.cppreference.com/w/cpp/language/override)
'override' is only a hint to compiler that you intend to rewrite the base class method. If method with such signature isn't found code will not be compiled.
Hard to know what you meant. :) "beginner C++" in my alma matter could mean anything from Hello World to a playable game and from-scratch engine. :p In any case, I think I answered you best I can. You'll need to supply a lot more details (e.g. source) about your program to have any idea what else you'd need help porting. The gist is probably just going to be to write a Makefile or something to get your code compiling with GCC and then fix up any errors.
http://kl1p.com/swardhan/2 Here is the source
Thanks for the introduction. I had to do something with time a while ago and couldn't get anywhere with cppreference.com
We're hiring! Check the jobs thread.
As long as he's not exposing his "private member"...
libc++ does that https://github.com/llvm-mirror/libcxx/blob/21d02bea5818ecd0210dd6f08d9523dc9c010890/include/exception#L164 libstdc++ does that under some preprocessor conditions https://github.com/gcc-mirror/gcc/blob/5a51c124b27b894f19ad487f523470fbfabe3123/libstdc%2B%2B-v3/libsupc%2B%2B/exception_ptr.h#L179
Any particular reason to use `reference_wrapper` over raw pointers here? 
Would you point to it please? Cheers!
it does use libstdc++, libstdc++ does not use WinAPI. bug report here: https://sourceforge.net/p/mingw-w64/bugs/338/ I am mostly griping about the failure of the specification here.
It's stickied on the subreddit, so it will be the first thing listed on /r/cpp.
👍
To learn about smart pointers I was implementing a tree with each node containing a vector of unique_ptrs to its children and I ran into this exact problem when I wanted to iterate over a node's children. I think I'll give this a try. Thanks.
LIKE!
Exactly, a trade-off of locality for not shifting as many elements. There is no free lunch.
On the main page, under "IDE++" section: &gt; And it's free! 
Has anyone here used Mockator (which is packaged with Cevelop) and have an opinion on how it compares to Google Mock or CppUMock?
Check out some of the new cross platform features for C++ in visual studio 2017!
I prefer `ptr_vector` to `vector&lt;unique_ptr&lt;T&gt;&gt;`, because: 1. Sometimes we need pass `T* []` to underlying API, such as `WaitForMultipleObjects`. With `ptr_vector`, we could simply pass `.data()`. 2. Performance. `ptr_vector` is `vector&lt;POD&gt;`. POD could be memcpied, which `unique_ptr&lt;T&gt;` couldn't be.
&gt; C++ has official logo!? sure - goatse.cx always was, always will be, don't show it to little children... 
These macros aren't defined by the C or C++ standards. The `&lt;math.h&gt;` header (like many C headers) is hijacked by other standards outside WG14 and WG21 that make conflicting demands. It is bad taste and bad practice, but that is what we have. That is why P0581R0 recommends to let those headers alone. In practice, I expect implementers to do something along the lines of what you say, as the functionality matures and get wider uses. (For example, as you know, the header `&lt;stdio.h&gt;` that ships with VC++ actually takes advantage of C++ templates to provide safer and faster C IO facilities.)
Sorry if it's a stupid question, but wouldn't that best be handled by using a shared pointer and handing out weak pointers? Trying to hand out pointers to the contents of a unique pointer sounds counter to it's purpose and offers nothing over raw pointers as far as I can tell.
This is the first time I've heard of this IDE.
You (Microsoft) use 1.5 because Dinkumware did some testing, and found that it worked well. I'm not at all sure Google's groups search works well enough to find it any more but either PJ or Pete Becker (who worked for Dinkum at the time) posted to this effect on Usenet (probably on comp.std.c++ or comp.lang.c++.moderated). If you really want to search for it, I believe it was in a thread related to a post by Andrew Koenig about the growth factor and the golden mean (about which, see below). There is, however, a pretty decent theoretical argument for using a growth factor less than or equal to the golden mean (1.61803...). A smaller growth factor means that if the discarded blocks are contiguous, they'll (eventually) add up to enough to space to fulfill the next allocation request (and, conversely, if your growth factor is larger than the golden mean, that can *never* happen). So, 1.5 is a value that's fairly easy to compute (even using only integer arithmetic, as in `n * 3 / 2`) that's a bit less than the golden mean, so you get the nice property of eventually being able to reuse your discarded blocks (assuming they're contiguous, of course).
Why not just use Foo&amp;?
You probably know this already, but `-Werror` simply turns warnings that are already switched on into errors. You may want something like `-Wall -Wextra -pedantic` which enables most warnings for g++ and clang++.
You can't store references into standard vectors
In my code base, I basically used the same technique. At some point, I realised that std::unique_ptr wasn't going to cut it (essentially due to copy-and-paste holding references to the objects held in the vector) -- I was going to need to std::shared_ptr's. At that point, I had to roll back all the neat reference wrapper stuff. Just a word of warning: don't do this unless you're utterly sure that you will never need to share the objects being held.
Apparently you need to familiarize yourself with the LaTeX lion.
If your unit test uses a pointer to the implementing class instead of a pointer to base it might still call the expected method. I think that is something easy to miss. 
[C++17: The Library Features - Nicolai Josuttis](https://vimeo.com/213564917)
In my mind I say "sevelop" 
Good points. I got another one: * This container's iterators already dereference to the `Foo` objects, not pointers too `Foo`s -- making an iterator adapter unnecessary.
Surely, the font has to be monospaced
For the latter one just read his twitter.
Haven't seen this before - trying it out now. What's up with the "tor"-suffix for almost every plugin name, though? Edit: no support for CMake, exited.
I'm not proposing it, it's likely to make it in. Look below for more info on benefit. 
This is from the abbreviated lambdas paper, where the first part seemed mostly desirable as far as I can tell. The idea here is that it also removes the need for decltype, but I'm not sure how that will play out with the proposal. In any case, even that level of terseness would be great because these range operations are really common and the lambda boilerplate really distracts from what it's doing. I didn't even include the other parts of the paper. 
We'll have concepts, so you could return it as a view. 
Any examples on how that would work? Would I be able to implement the function in a cpp file instead of a header?
Template visualisation looks neat :P
I'm currently less than 2 minutes in to this video, and not sure I watn to go any farther. It's targetting version 3.1 ([released in 2014](https://cmake.org/pipermail/cmake/2014-December/059418.html) ) which supports modern cmake functionality. yet it's still using `include_directories`, and `link_libraries` instead of targets.
This seems cool but umm... The one on temporary iterators in loops, do people actually do that? 
I would still call it an issue with the standard. If the platform doesn't support a true random device then `random_device` just shouldn't be available just as with `(u)intN_t`, and possible provide a type alias that will be `random_device` if it is available and some other generator if it isn't (ie `pray_to_god_i_am_random_device`).
Ranges for demand :p
Conflicted whether i want to have JRE on my system for this :/
To add to these resources: https://community.kde.org/Policies/CMake_Coding_Style https://www.slideshare.net/DanielPfeifer1/cmake-48475415 http://fujii.github.io/2015/10/10/cmake-best-practice/
It's a jungle out there ! :D
Close, but some issues are: - we're using `vector` for the ownership semantic, which you lose using `ptr_vector`. That can be improved with a `ref_vector`(which is a `vector&lt;T&gt;`&amp; or rather a `reference_wrapper&lt;vector&lt;T&gt;&gt;`. - `vector&lt;unique_ptr&lt;T&gt;&gt;` supports "nullability" and polymorphism, `vector&lt;POD&gt;` doesn't (nullabilty can be solved using `optional` though)
You couldn't go wrong with [SQLite](http://sqlite.org/) for your database needs.
TIL CMAKE_CFG_INTDIR is a thing, time to move all of my export headers https://cmake.org/cmake/help/v3.0/variable/CMAKE_CFG_INTDIR.html
Thanks for the comments, /u/donalmacc &amp; /u/ojd5! Not the author, but exactly the review &amp; discussion I was hoping for when submitting, with quite useful links!
Do you actually need a database with a queryable language? The file system works surprisingly well in this regard, provided you can use it to organize your data.
Make me think that it could be useful to add a custom C++ attribute to flag all methods in Qt that could cause the object to be detached 
Thank you. I was about to ask.
Regarding your second point, how do you then group stuff for IDEs (with source_group())? 
i dont understand why the cmake guys aren't capable of making good docs and examples
Super late reply to /lluad and /c0r3ntin, but [the website says](https://www.zapcc.com/buy-zapcc/): &gt; Zapcc is free for non-commercial entities (e.g academic and open source developers)
That would have also been a nice way to do it. Too late :/
This is sometimes useful for quick programs when you don't want to bother implementing/searching a correct version yourself (and know that you're using libstdc++): #include &lt;algorithm&gt; // ... int gcd = std::__gcd(25,15); 
Deque is normally implemented as an array of pointers to blocks, each of which holds some (more or less arbitrary) number of data items. When you need to reallocate, you only reallocate the array of pointers. That's entirely different from what I'm discussing though. I'm talking about a vector that works like a current vector but for *one* exception: when it reallocates, and needs to copy data from an old block to a new one, it does *not* copy it all at once. Instead, it distributes that copying (about evenly) among calls to `push_back` (or `emplace_back`, etc.) 
Ah, yes, indeed.
A range that contains a small buffer for a few items and fetches them in batches using a type erased method, while the iterators walk using visible-to-compiler semantics, could work. Make the range non-copy/moveable in C++17 and you can even avoid allocations. The type erasure overhead is reduced to once every N elements. 
In my opinion GLUT is a rather bad example. I'd use a library that uses the target-based approach for including it. Or just any library that doesn't require that "Hack" code for GLUT. Very confusing for beginners. Also why are you not using target_include_directories and target_link_libraries in the first 5mins? Quite bad style I think?
I used that rix0r link before. That is good stuff.
Please read the sidebar.
Here's an example: https://pastebin.com/vx5uYLwW I pasted the output at the bottom. Edit: My first year programming c++ at university. How would an experienced programmer implement this differently?
Ah, now I understand what you're getting at. Yes, quite true (only it's really quite a bit uglier than a deque, because the new block will have some old data that's been copied in at the beginning, then an empty "hole", then the new data that's been inserted). Just in case it wasn't obvious from the original post, I'm certainly *not* advocating this as being even close to a practical or useful data structure (more of a thought experiment about something you could theoretically do if constant-complexity insertion was *really* an overriding concern).
I'm having issues building Boost.Python on Windows with VS2017. Specifically, I am building everything, but the python libraries are missing. b2 finds my python install just fine, and it lists the python module as "building" in the section at the beginning that lists all the libraries. But the resulting libs directory does not have any libs with "python" in the name. Searching the build output for the string "python" only has results at the beginning of the build during the initial configuration; there are no warnings or errors about python except for the fact that it fails to find numpy (because I don't have it installed). Building like this: b2 --prefix=c:\boost --build-dir=boost_build --stage-dir=stage --layout=versioned --without-mpi --build-type=complete toolset=msvc-14.1 address-model=64 -j4 --debug-configuration -d2 stage &gt;build.log 2&gt;&amp;1 Has anyone run into anything like this?
still waiting vcpkg update
It doesn't really make any sense to unpack the value before you test it for truthiness, because it's only valid to unpack if it's not empty. 
It makes sense for me because I'm willing to trade clean unpacking for syntax sugar with dirty unpack.
But this is just one point. The other is noticing structured bindings initialization form can't be used on the same place a normal declaration can, generally, hence I've hit that snippet.
Rust's `match`, Haskell's pattern match, or any other barely useful form of pattern matching and my "problem" goes away. You're right. In C++ I'm sticking with member access, it's what it's able to do, not its half-baked solutions.
what's wrong with: if (auto bar = foo()) { auto [baz] = bar; std::cout &lt;&lt; baz &lt;&lt; std::endl; } else { std::cout &lt;&lt; "empty" &lt;&lt; std::endl; } ? It's equally as terse as the conventional solution, and far more expressive than some weird "check the condition prior to unpacking, but also unpack in the condition block" solution you desire.
Yes, integrating the clazy functionality into clang-tidy is something we're investigating.
TIL about boost fiber. Since digging into go and playing around with its channels this looks like a cool lib to experiment with for multi-threading.
`sudo apt install build-essential`
That's why I have made this: https://github.com/Orphis/boost-cmake Try it by changing the URL to point to a tar.bz2 release, fix the SHA256 hash to match the release tarball and it should work. I tried it with beta 2 and it was fine for my projects!
&gt; As most files required to parse the tokens, most files needed Boost.Wave which included Boost.Spirit, which takes ages to compile. To be fair, Wave uses Spirit.Classic (Spirit v1); Spirit.X3 (Spirit v3) compiles very quickly.
First of all, the "old" version is totally fine. But secondly, this is what `fmap` is for: foo().fmap([](int baz){ std::cout &lt;&lt; baz &lt;&lt; std::endl; }); Hide the if/dereference logic and just focus on the functionality. 
I've been stuck on this problem since the first beta came out, and `-d2` is one of the first things I added. The only helpful information that has given me is the fact that there is NO debug output for the python libraries, which would imply that it is not even trying to build them. But as far as actually tracking down the reason for that, I've got nothing. All of the output I *do* have indicates that everything is set up correctly and that it *should* be building. I am still relatively unfamiliar with b2; what is the normal sort of process for debugging issues like this? 
Yeah that sounds about right. I have tried messing with user-config.jam to make sure either finds the right python (that's why I have been including the `--debug-configuration` flag) but I haven't touched that ever since the debug messages started to indicate that it was finding the right executable. But it's becoming increasingly clear that I should be a little skeptical of the debug output. I'll have to mess with that some more and see it is changes anything. 
The digit following `-d` can be between 0 and 13 (inclusive), each one enabling an increasing set of diagnostic outputs. `-d2` only displays actions as they're executed; `-d3` enables dependency analysis, which sounds like might be what you need, but if it's not then just increase the number until you start seeing useful info (see [here](http://www.boost.org/build/doc/html/bbv2/overview/invocation.html) for the full list). I don't use Boost.Python so I'm not sure how involved its jamfile is, but I have spent many hours with Boost.Build over the years so I know firsthand that it has no shortage of useful data to help sort out issues like this. N.b. just `--without-mpi` is going to produce a lot of data to sift through; `--with-python` would be better for getting this figured out. EDIT: grammar
How to install all the plugins into my existing Eclipse installation? Cant find update site for that.
Yep. It's possible in theory, using the libclang integration in QtCreator via the Clang code model. We've made it work in KDevelop using a self-built LLVM/Clang some time ago (cf. http://wstaw.org/m/2015/12/23/kdevelop-clazy.png ) -- note that both IDEs make use of libclang thus could both share work on this feature. Upstream ticket for QtCreator is here, in case you want to get notified about this matter: https://bugreports.qt.io/browse/QTCREATORBUG-15157
 template &lt;class T&gt; struct tuple_size&lt;maybe&lt;T&gt;&gt; : integral_constant&lt;size_t, 1&gt; {}; This is so _so_ wrong! `std::optional`, `std::any`, your `maybe` type, ... do not satisfy `tuple_size&lt;T&gt;() == 1`! They are actually `Range`s (in the Ranges TS sense) of zero or one elements, so this is what you want: for (auto&amp;&amp; v : foo()) std::cout &lt;&lt; v &lt;&lt; std::endl;
This great! It initially reminded me of the interface of professor Melissa O'Neill's randutils library, except this is such an aggressively functional composition it is another level entirely.
Note that this post is over a year old, and we [discussed it at the time](https://www.reddit.com/r/cpp/comments/49ixds/sigc_ported_to_c14_sheds_73_of_code/)
Was there any specific reason you wouldn't just use [libTooling](https://clang.llvm.org/docs/LibTooling.html)? Thing is, libclang is built so, that it could be reliable in terms of an interface, i.e. it doesn't change like... for a long time and ensures backwards compatibility, so that tools like YCM can rely on that interface being pushed as the new versions of LLVM come out and improve performance. libTooling, on the other hand, doens't have to satisfy these restrictions and hence is much more powerful. It exposes an interface to parsing and Clang AST, which is everything one would ever dream, especially when having tasks like "just loop over the function tokens and see if you can find noexcept". The [AST Matchers](http://clang.llvm.org/docs/LibASTMatchersReference.html) are great and easy-to-use, just see [clang-tidy](http://clang.llvm.org/extra/clang-tidy/) checks (and clang-tidy itself as it uses libTooling) for the reference. If I am correct what cppast does is implementing its own kind of AST, not sure why Clang AST isn't used there, either. I mean, it's truly interesting and very educational, but I'm just wondering why libTooling, Clang AST and AST Matchers aren't enough and what is the task, which they are struggling with. I mean, they can be improved, too, if there is one.
Nice!
Using "date.h" from here https://github.com/HowardHinnant/date/blob/master/date.h just to get easy printing of `chrono::duration`, and using: int main() { using namespace date; using namespace std::chrono; std::cout &lt;&lt; time([]{std::this_thread::sleep_for(100ms);}) &lt;&lt; '\n'; } My system outputs: 240373050s
Not what I want, ranging over maybe/optional because pattern matching doesn't work.
 auto fmap (auto v, auto&amp;&amp; fun) -&gt; std::optional&lt;decltype(fun(*v))&gt; { if (v) { return fun (*v); } else { return std::none } } 
&gt; I would love fast type-erased ranges if such a thing can exist in C++. I've not tried it, but Range-V3 has a type-erased [`any_view`](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/any_view.hpp) which sounds like what you want.
Make sure you use canonical links when linking to a file/directory. On GitHub, you can press the "y" key to update the URL to a permalink to the exact version of the file/directory you see -- [source](https://help.github.com/articles/getting-permanent-links-to-files/). I've tried to fix your links: Relative | Canonical -|- https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/any_view.hpp | https://github.com/ericniebler/range-v3/blob/300dbd19e2fd9f98258236e093c54ad42241f24f/include/range/v3/view/any_view.hpp Shoot me a PM if you think I'm doing something wrong. To delete this, click [here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dgit9h1.)
Nice snippet, looking forward for these plumbing tools in the stdlib.
&gt; pattern matching doesn't work. Which pattern matching? C++ has no such thing. That's different from it "not working". Structured bindings is just syntax sugar for `std::tie`. Your code declares that optional has a `std::tuple_size == 1` introducing undefined behavior for empty optionals. That's way worse than C++ lacking pattern matching.
Passing pointers or references over a named pipe to a DIFFERENT process should not work. If it's the same process, than the object is in the same address space and using the pointer would work (as long as it's still alive, something which may not be guaranteed if the object was allocated on the stack). If it's on a different process, the pointer does not refer to the same memory as in the original process (or it may not be a valid pointer), so it shouldn't work.
You don't include &lt;algorithm&gt; for sort in stopwatch.h This shouldn't be used by people unless they're aware of the limitations of this timing method. Your examples are misleading because RDTSCP with an invariant TSC implies that the "cycles" you present in your example are not true processor cycles. For a bit of history, see [here](http://stackoverflow.com/a/19942784): &gt; When Intel first invented the TSC it measured CPU cycles. Due to various power management features "cycles per second" is not constant; so TSC was originally good for measuring the performance of code (and bad for measuring time passed). &gt; &gt; For better or worse; back then CPUs didn't really have too much power management, often CPUs ran at a fixed "cycles per second" anyway. Some programmers got the wrong idea and misused the TSC for measuring time and not cycles. Later (when the use of power management features became more common) these people misusing TSC to measure time whined about all the problems that their misuse caused. CPU manufacturers (starting with AMD) changed TSC so it measures time and not cycles (making it broken for measuring the performance of code, but correct for measuring time passed). This caused confusion (it was hard for software to determine what TSC actually measured), so a little later on AMD added the "TSC Invariant" flag to CPUID, so that if this flag is set programmers know that the TSC is broken (for measuring cycles) or fixed (for measuring time). &gt; &gt; Intel followed AMD and changed the behaviour of their TSC to also measure time, and also adopted AMD's "TSC Invariant" flag. &gt; &gt; This gives 4 different cases: &gt; &gt; * TSC measures both time and performance (cycles per second is constant) &gt; * TSC measures performance not time &gt; * TSC measures time and not performance but doesn't use the "TSC Invariant" flag to say so &gt; * TSC measures time and not performance and does use the "TSC Invariant" flag to say so (most modern CPUs) Another issue is that each core has their own TSC with possibly different values, so if your application does not pin its processes your process may migrate to a different core and you will suddenly see jumps in time. These are just a couple things people should be aware about when trying to use this code (and it should be mentioned in the README!).
Thank you so much! :D
The thing is that transform, remove_if and similar operations on temporary vectors are surprisingly fast, usually on par with the range library. I got the temporary vector method to be a bit slower only by doing lots of operations on very small containers, like with 10 elements. That's why coming up with a type-erased view that's faster than temporary vectors is so hard.
I hate being obligated to name useless temporaries... C++ is full of this.
Thanks! I expect it would take me much longer than 1 hour to implement something like that and much closer to a week or more of just researching what people want :). I'm not so familiar with what people want from IDEs and header-only libraries.
"new API: call/cc" is quite an understated changelog entry.
Right, this post naturally doesn't claim to cover the whole STL which is so rich. I am trying to get a wider coverage via the [STL Learning Resource](http://www.fluentcpp.com/STL) though, of which this post is just an episode. Happy to get your feedback on it.
v1.64 is now available in vcpkg. edit: "now" not "not"
Most of the issues you list are about difficulties with the language. No one likes the language, but no one is putting time/effort into replacing it (though I've put some design work and a year of refactoring CMake to make it possible, there's more to do). Regarding variables and debugging cmake scripts when something is wrong with them, I hope this will eventually help: https://steveire.wordpress.com/2016/01/24/cmake-daemon-for-user-tools/ &gt; set(CMAKE_BUILD_TYPE ${CUSTOM_BULD}) Don't set this (or test it in an `if()` ) in cmake code. Doing so makes your build unportable to IDEs. That said: set(Foo ${NOT_SET}) if (Foo) message("Foo is Truish") else() message("Foo is Falsey") endif() if (DEFINED Foo) message("Foo is defined") else() message("Foo is not defined") endif() set(Foo "${NOT_SET}") if (Foo) message("Foo is Truish") else() message("Foo is Falsey") endif() if (DEFINED Foo) message("Foo is defined") else() message("Foo is not defined") endif() Output: Foo is Falsey Foo is not defined Foo is Falsey Foo is defined 
Thanks for proposing this. I'll have a look into it
Interesting, will clang-tidy integration work if the codebase flat out _does not compile_ under clang? (lots of ambiguity resulting from *namespace X { class X; }* and *using namespace X*)
&gt; Dangit, I hate that I missed this post. You didn't really :). &gt; What I felt like did not go well was simply how to deal with repo A depends on repo B and so forth The way I think of this is to consider some C++: struct Buildsystem { std::string globalSettings; std::vector&lt;std::string&gt; libraries; // ... void consume(Buildsystem const&amp; other) { // Oops, overwriting things! globalSettings = other.globalSettings; // Oops, libraries is not unique anymore! libraries.insert(libraries.end(), other.libraries.begin(), other.libraries.end()); } }; The `consume` method will wreak havok on your data because it doesn't know any better. That's what happens when you `add_subdirectory()` random projects and I'm very against doing so. In my opinion you have 3 options: 1. Build your dependencies separately, install them to a prefix and consume them as external things from there. This is what we do with KDE Frameworks. I think this approach works well. If you are in an organization with many engineers, and the dependencies don't change often, you can set up a system of distributing binary packages of the dependencies. 1. Take ownership of the dependency buildsystem and modify it to your needs. Ensure that it uses your compiler settings, doesn't trash your `CMAKE_CXX_FLAGS` or other 'global' settings (instead either ensure that it uses 'your' compile flags or assimilate its uniqueness into your own buildsystem settings), has target/test names which are globally unique etc. 1. Use ExternalProject to keep everything together under an 'umbrella'. This is hard to get right and has significant disadvantages. Depending on how you use it, you might clone the source of the dependency to the build dir during the build, making a `rm -rf` on the build dir more expensive. Also, source changes in the external project won't be re-built if you just build the top-level project. I recommend 1) or 2). 
&gt; timing function calls in a high precision manner Doesn't Chrono do this? I know Microsoft's stdlib used to have some precision troubles, but that got fixed. What problems remain, unless the issue is people using an older stdlib?
Man that's new I always thought it was a link list of two nodes internally. I am using read and write functions of c. And sending it as write (FD, &amp;pairname, sizeof(pairname)); Same for read.
No. `std::shared_ptr&lt;T&gt;` is meant for shared ownership and its implementation incurs overhead which you don't want when you don't need shared ownership. When using modern smart pointers, raw pointers are considered as non-owners. A good reference on this topic is the following talk : https://www.youtube.com/watch?v=JfmTagWcqoE
Boost.fiber is extremely cool. It's almost a work of art in my opinion. Performance could use some improvement, but I'm sure it'll get there. 
`fmap` works for both ranges and optionals, since both of them are monads. Hence, if `transform` works for ranges, it should also work for `optional` (which would be the case if `optional` would model the `Range` concept).
What happened with Boost.SIMD ? Wasn't it under review for this release?
I highly doubt that Nintendo has their own compiler. So I'd say they likely use something already available (likely GCC). You could probably use a more recent version of the compiler though, barring any custom non-public patches by Nintendo to the compiler or ABI incompatibilities.
Is there any feature not supported then? (threads, lambdas?) It took a while for the MSVC to fully support C++11
Don't worry. Clang had all the C++11 features. I don't know what happened to MSVC and why people thought it was acceptable to not be **fully** C++11 compatible. 
Was it [that](https://arobenko.gitbooks.io/bare_metal_cpp/content/) one?
Yes! Thank you!!
Why dont you use QueryPerformanceCounter? Rdtscp is unsafe...
Seems extremely promising, it just needs `XML`, `LLVM` and `WinZip` somewhere in your pipeline and it shall be just perfect.
Undefined behavior. I just love it.
None of that makes any sense. `fmap` is a Functor operation, it has nothing to do with Monads. And every Functor has its own implementation of `fmap` that does something unique to that Functor. `transform` at best would give you back a range, not an `optional`.
Fair enough :)
... implement it in C++.
There is a msft-specific thing __if_exists which might help, if it wraps a pragma warning. Cross platform, not much beyond the deprecated attribute
Novice programmers aren't aware of indentation.
Hmm Sony messed with clang I had thought but also presented a lot of their stuff not too long ago. Both Sony and Nintendo use FreeBSD these days. C++11 works well on that platform. I also target FreeBSD with clang in my day job but our toolchain is pretty much just upstream's.
Can anyone explain to me why every beginners guide bring examples for calculating radius, prime number, and Fibonacci, when I was learning C++, these examples were just awful, and completely useless.
Many compilers supported this feature as a nonstandard extension for many years before it made its way into C++14. For example if you're using gcc or clang you can use `__attribute__((deprecated("woof")))`. 
From my perspective I lost interest in 'D' a long time ago. While Rust is certainly not ready for prime time yet on the surface it seems to be far more interesting to me at least. I still need to look into Rust to see if they have made the same (IMHO) mistakes that D has made with their language.
&gt; Thanks but I'm not serious at brute-forcing non-native features in C++ Why ? In my book, a feature implementable purely as a library solution is better than a library that requires language support.
&gt; I believe Standardese is stepping on the same rake Doxygen did -- it has the core of its output generation hardcoded into C++ executable. While this is true, I originally planned to provide both a library and a tool. The tool merely drives the library, so you could write your own tool and customize the output generation. For various reasons during development, this goal was put back. But I'm right now working on making that possible again: you can then create your own output specification which is then rendered into HTML etc. While the rendering process itself is hardcoded, you can, for example, stylize the HTML. &gt; There is also a string template engine, yes -- but it seems to be just an addition, for generating extra pages. Yes, that is true. &gt; Also, it would be nice to see some examples of Standardese-generated documentation -- strangely enough, README doesn't give any such links You're right, that's an oversight.
In my book a feature that requires all kind of hacks to be implemented as a library and still falls short compared to the native alternative it tries to attain (including cornes cases here and there), is a waste of time and a headache to adopt.
Standards.
I would think the easier thing to do though would be to make a reStructured Text output generator. You've got the whole parse tree there and it is fairly easy to work with. Using the XML output as an IL, as this tool does, is the other way to go, but it feels like this is a fairly bulky build pipeline for documentation.
While `hana::string` is cute, I do wish it was possible to use `std::string`/`std::vector`/... at compile-time (in `constexpr` functions). I know that memory allocation is currently unsupported, are there other roadblocks?
&gt; in all the projects that I'm currently working warnings are turned into errors That sounds like a good thing
If you are looking for help, you've already posted to the right place - stackoverflow. If you want a post on reddit, try /r/cpp_questions. This sub isn't for questions.
I already said this in a comment above -- I'm afraid only being able to stylize the HTML with CSS is not enough. To be truly in control of the output, one needs to be able to tweak the HTML/MD/RST generator. Therefore, this generator should be *easily* tweakable -- which contradicts with hardcoding it into a C++ executable (even if it's just a tool based on your library). If the generator is inside a compiled executable, you simply can't tweak it on a per-project basis (for instance, to format declarations according to the coding style of the library being documented). And with string templates, you can. Since you already have a string template engine, why not use it for generating ALL the output? 
You said it would be useful, but didn't provide any examples. What would be your use case?
I'm planning to use exhaustive semantic HTML tags and ids, for example, so I think it could be flexible enough. Could you show me an example of the kind of flexibility your tool gives? &gt; Since you already have a string template engine, why not use it for generating ALL the output? This could be implemented, yes.
I tried to put this in a nice to use macro and came up with this: template&lt;bool condition&gt; struct warn_if{}; template&lt;&gt; struct [[deprecated]] warn_if&lt;false&gt;{constexpr warn_if() = default;}; #define static_warn(x, ...) ((void) warn_if&lt;x&gt;()) int main() { static_warn(false, "This is bad"); } This works on clang and gcc. MSVC, however, does not tell where `warn_if&lt;false&gt;` is instantiated, which makes this kind of useless. Is there a workaround for this? That explicit default constructor was required because MSVC does not seem to emit a deprecated warning when constructing a temporary of a specialized empty struct and marking it explicitly as unused via `(void)` ([Compiler Explorer](https://godbolt.org/g/PhcCI8)). I don't think this is supposed to be that way. 
I haven't done anything yet in rust. It only recently crept back on my radar after a couple of years of ignoring it. Sadly I have an almost 10 year old mature code base of almost a million LOC to work on...highly threaded HTCP physics related.
They did up until the Switch. It wasn't "their own" but it was a fork of an ancient crufty compiler. It was kind of hilarious in a sad way. I don't know offhand what version of Clang the Switch DevKit uses, but I'd imagine it's new enough to support both all of C++11 and C++14, if not parts of C++17. Whether it's kept up to date or suffers from Nintendo's usual fire-and-forget mentality is to be seen.
Sony's definitely on Clang/LLVM. The Sony devs have been fairly active in the C++ committee and SG14 group.
Aside from C++98 two-phase lookup, what are they lacking? http://en.cppreference.com/w/cpp/compiler_support indicates they're fully caught up with the C++11 additions and the C++14 additions too.
&gt; is in no way best in class (literally) for anything it's marketed for I disagree. There's not a single other build tool out there that can as flexibly generate build systems in a cross-platform way. Nothing offers the same breadth of features and compatibility. Does that mean it's not a giant ball of mud? Absolutely not; it practically guarantees it.
&gt; They did up until the Switch. It wasn't "their own" but it was a fork of an ancient crufty compiler. How did the developers put up with that? I'd have a hard time imagining working with any old (and buggy) compiler. Though I guess in a way they might not have put up with that considering the lack of 3rdparty games on the system.
How about using it to document a library in another language with a different syntax? http://vovkos.github.io/jancy/stdlib I believe it's a good demonstration of flexibility. Also, being able to simply make a copy of the frame directory and update it to your liking allows you to: - have footnotes - set indentation rules according to the coding standard - merge all declarations into a single code-snippet overview -- or split them between multiple sections (Functions/Variables/Properties/...) - change order of sections Functions/Variables/Properties/... - change section names (Functions -&gt; Methods -&gt; Member Functions...) - place enum descriptions in separate files or inject them all into the parent namespace file - choose whether to place parameter descriptions to tables or lists - etc, etc, etc I highly doubt merely stylizing the HTML could give this level of flexibility. String templates FTW :) 
&gt;How about using it to document a library in another language with a different syntax? http://vovkos.github.io/jancy/stdlib I'm not sure what you mean. &gt;- set indentation rules according to the coding standard I was toying with `clang-format` integration, that could achieve that. &gt;- merge all declarations into a single code-snippet overview -- or split them between multiple sections (Functions/Variables/Properties/...) &gt;- change order of sections Functions/Variables/Properties/... &gt;- change section names (Functions -&gt; Methods -&gt; Member Functions...) Those are not applicable to standardese, it does not have such a distinction in the output. &gt;- place enum descriptions in separate files or inject them all into the parent namespace file That can be done with a command line option. &gt;- choose whether to place parameter descriptions to tables or lists I think you can do that with CSS hacks :D &gt;I highly doubt merely stylizing the HTML could give this level of flexibility. String templates FTW :) Could you show me a sample string template? 
Also the point is _mostly_ on compound declaration location limitations.
People are getting into code younger and younger I reckon. Examples of problems that are relevant and understandable to them are much more useful to them.
If you want examples of some C++11 features that MSVC does not correctly support yet: Two that come to mind immediately are: constexpr and SFINAE (the latter to the extent that the detection idiom works correctly, for example, for private members).
Neat. I have something similar for markdown conversion (although very specific to my project and not suitable for general use). Source here: https://github.com/rpclib/rpclib/blob/master/utils/markygen.py and https://github.com/rpclib/rpclib/blob/master/doc/reference.md.mako
Make sure you use canonical links when linking to a file/directory. On GitHub, you can press the "y" key to update the URL to a permalink to the exact version of the file/directory you see -- [source](https://help.github.com/articles/getting-permanent-links-to-files/). I've tried to fix your links: Relative | Canonical -|- https://github.com/rpclib/rpclib/blob/master/utils/markygen.py | https://github.com/rpclib/rpclib/blob/3c0a23da7356bd31ed8a81a76771dade0f8a7b72/utils/markygen.py https://github.com/rpclib/rpclib/blob/master/doc/reference.md.mako | https://github.com/rpclib/rpclib/blob/3c0a23da7356bd31ed8a81a76771dade0f8a7b72/doc/reference.md.mako Shoot me a PM if you think I'm doing something wrong. To delete this, click [here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dgkmdee.)
Example of C++11 constexpr that MSVC will not compile: #include &lt;type_traits&gt; template&lt;int I&gt; struct X { }; template&lt;class... T&gt; constexpr int f(T... t) { return 1; } template&lt;class... T&gt; struct Y : X&lt;f(std::is_same&lt;T, void&gt;::value...)&gt; { }; Y&lt;void, void, void&gt; y; 
I am not a big fun of stuff like that (in C++1x), void addFoo(std::unique_ptr&lt;Foo&gt; foo); Sometimes it is the best solutions but it is forcing a dynamic allocation from the caller, and creates a strong semantical coupling with the API's storage details. In general, I'd prefer (with a movable Foo of course). void addFoo(Foo f) { foos.push_back(std::move(f)); } The client is to decide about the local copy: Foo f; ... addFoo(f); //keep it or { Foo f; ... addFoo(std::move(f)); //or not } 
Example of C++11 SFINAE that MSVC will not compile: [Source](https://github.com/boostorg/config/blob/develop/test/boost_no_cxx11_sfinae_expr.ipp) template&lt;class&gt; struct ignore { typedef void type; }; template&lt;class T&gt; T&amp; object(); template&lt;class T, class E = void&gt; struct trait { static const int value = 0; }; template&lt;class T&gt; struct trait&lt;T, typename ignore&lt;decltype(&amp;object&lt;T&gt;())&gt;::type&gt; { }; template&lt;class T&gt; struct result { static const int value = T::value; }; class type { void operator&amp;() const { } }; int test() { return result&lt;trait&lt;type&gt; &gt;::value; } 
It's a hideous, incredibly buggy hack in the compiler codebase.
At least from a game dev perspective, it's way better than some other compilers... But it certainly needs work, it's not like MSVC users don't know it's trailing GCC and clang (And Intel, for some stuff?).
I'll also confirm Sony is using clang, I have a buddy who interned with their compiler team, and is starting full time soon.
Any C++14 support?
That's not a feature that actually exists at this point in time.
Shows that they're at least working on things then &amp;ndash; I just get warnings for unused arguments. ;-]
Msvc is better compiler then clang for game dev? Can you give examples? I use both and i prefer clang any day.
What? I'm talking about compilers other than the main 3 or 4 (GCC, Clang, MSVC, Intel), such as the Wii U and 3DS compilers. I also generally prefer Clang, though I use MSVC on Windows as I prefer the tooling. 
^ This bot has a point. More people need to know about this.
 if (!name) return fws::http_response(); return spells::view(*name, partial); Gah... Since we're in a picky mood: return ( !name ? fws::http_response{} : spells::view(*name, partial) );
I have used crow in a couple of personal projects. I wouldn't recommend it to anyone. * Either the developers have died or they have abandoned the project * There are some outstanding bugs waiting to be resolved (see above) * The code quality of the library is extremely low * Due to the reasons above, I cannot recommend that thing to people. For very small projects, it's probably fine, don't have to worry about it. For anything more involved (10+ HTTP calls + websockets) no thanks. CPPCMS is/was awesome. I have used it in production (at work) several times. Problem is ... seems to be abandoned as well. 
I was subscribed to CPPCMS mailing list for a while, there was definitely activity. It isn't up on any git pages, it's all done on sourceforge, though.
Do you still have the source code?
Sometimes you need to build an external 3rd party library (like an opensource one).
Done.
 opt-&gt;get().reset();
I think I will hold off on changing the architecture of my software so that it compiles faster, thanks.
Does Beast support WebSockets with SSL/TLS? 
That doesn't do what you think it does. It supersedes tag dispatch almost completely, but it doesn't let you sense whether you're being invoked for compiletime or runtime evaluation.
Agreed, changing your architecture is not something that should be taken lightly and if your build times are already short, no worries. But I have worked on C++ projects that take a couple of hours to build, we were always thinking of ways to decrease build times. Another example, Ales Holecek, vice president for development for Windows said that it take 16 hours to build windows 10: https://twitter.com/DawidFerenczy/status/543171331328864257
There's also a simple c++ wrapper for papi here: https://github.com/bcumming/papi-wrap
Ah, I got ahead of myself. I was thinking I had seen confirmation on the `if (constexpr())` proposal. Double checked and indeed, nothing like [P0595](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0595r0.html) is in C++17, which in hindsight should be obvious since it was proposed in 2017. :) Thanks Stephen! So back to the question from /u/James20k: no, still out of luck. :)
For a library solution, Boost.Serialization has [`BOOST_STATIC_WARNING`](http://www.boost.org/doc/libs/release/libs/serialization/doc/static_warning.html).
I'll wait for modules. Better build time, better semantics and better syntax. There are only a small amount of issue in order to be ready. 
okay.. may be other thing is wrong.. :( ty for the help
and ty for /r/cpp_questions , I did not know that exists
[removed]
Output: [^source](http://ideone.com/jee2KL) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20https%3A//www.reddit.com/r/cpp/comments/66ucn4/how_to_delete_dynamically_allocated_pair/dglepa0%20Include%20your%20reason%20for%20reporting%20here.) 
I have been thinking about C++ tooling recently ( mostly regarding clangd ), there is still so much that can be done. In this case * Index all the symbols from the whole project + include path. You don't need much data beside a fully qualified name &amp; the corresponding header. Of course you may want rules to include &lt;QString&gt; instead of qstring.h, etc. Template specializations &amp; macros make things complicated. Macro themselves should™ ideally be indexed* * Auto includes headers from the IDE * Support renaming headers * Support renaming a source file corresponding to a header * Support renaming include guards * Header sorting, ideally group by library. * Warn of unused headers - Easy to do in sources files, but not so much in headers themselves, because you need to fix everything transitively, and you don't always want to. *Somehow - I just realized the issue with c++ macros is that they can't be part of the AST. which is obvious but I never thought about it in these terms before - Though maybe there are ways tools could work around that. But the point is that an IDE should be able to see and modify all possible branches. 
&gt; Well, my point was that doxyrest approach allows producing documentation for different languages, not C/C++ only I see. standardese will not support that by design: It is build specifically for C++, it detects common C++ idioms etc. &gt; String templates for C-family languages are here: This looks interesting. Maybe I find a way to support your project.
Since I usually compile in "treat warnings as errors" mode, `static_assert` is good enough for me.
std::map::count function can return more than 1 because operator == could return true for 2 different keys to some value. There is also a templated version: template&lt; class K &gt; size_type count( const K&amp; x ) const; 
"Increase memory fragmentation with the Pimpl idiom".
While agree that there are downsides of PIMPL, there are downsides to most approaches (it looks like there will be downsides to modules as well: http://stackoverflow.com/questions/34652029/how-should-i-write-my-c-to-be-prepared-for-c-modules). I think that it is a useful idiom in certain situations (which you can also combine with other techniques to reduce compile time). 
Yes, I hope that modules help with better built time, better semantics and better syntax. But I am always worried at what cost? Nothing in this world is free :)
Yes, ccache is great! The pros definitely outweigh the cons. The only problems are self-inflicted (my Makefile is buggy and doesn't run a compilation command). 
True that is a downside. 
Well contribute to the project and do it yourself instead of just asking.
The optimist in me is pretty excited for modules. I agree I think it will be faster compile time. But the pessimist in me is wondering what I will lose. :)
PR: support winrar
I think as in see : see-vel-up
[include-what-you-use](https://github.com/include-what-you-use/include-what-you-use/blob/master/README.md) seems more useful.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [include-what-you-use/include-what-you-use/.../**README.md**](https://github.com/include-what-you-use/include-what-you-use/blob/953970c487b004050d44925bfcc5133be9fa0d7f/README.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dglrk5y.).
So? If they support the compiler then just build it.
I think it will work with most of the types, but I did not try
Unfortunately you’re just not going to be able to fully index preprocessed code without imposing some pretty hefty restrictions and assumptions. Real basic stuff that’s used 90% of the time will be sorta-fine, but that last 10% is awful to handle and the best you can do is handwavy heuristics. Basically, the problem of figuring out what text the compiler actually sees requires execution of a not-quite-Turing-complete language, almost on par with the (theoretically Turing-complete) complexity you can bludgeon out of templates. You can do recursive includes, you can do arbitrary arithmetic during `#if`/`#elif` and macro expansions (←exercise left for reader). As a simple example, suppose you have a header that does #if N &lt; 1 # undef N # define N 2 #elif N &lt; 2 # undef N # define N 3 #elif N &lt; 3 # undef N # define N 4 #endif and is included by multiple files with different `N` values. Without reference to inclusion context, you can’t tell what value `N` will have afterwards, which means you can’t just mark “header foo.h defines `N` to be 3” in your index after checking one path and move on. You can even mix recursion in, since headers can include themselves up to ~some~ depth whose minimum is defined per standard and maximum is defined per preprocessor and command line. But at least the preprocessor stuff parses ~easily and in a few steps. If you mix in compiler stuff that happens post-preprocessing, you’re gonna have a bad time: #define MAKE_NAME(a, b)MAKE_NAME_0_((a,b)) #define MAKE_NAME_0_(x)MAKE_NAME_1_(MAKE_NAME_2_)x #define MAKE_NAME_1_(x)x #define MAKE_NAME_2_(a, b)prefix##_##a##_##b void MAKE_NAME(NAME_PART_1, NAME_PART_2)(); #if FUNCTION_BODY void MAKE_NAME(NAME_PART_1, NAME_PART_2)() {...} #endif Again, without knowing what the context is, you can’t determine what “function” is declared, whether it’s defined as well, or even whether the code is remotely valid. And of course without evaluating the macro expansion fully, your parser can’t tell what kind of AST structures should be used for this. Maybe it’ll come out as void prefix_NAME_PART_1_NAME_PART_2(); …or maybe void prefix_np1contents_np2contents(); …or maybe even void prefix_foo(); struct {...} x_baz(); since the arguments to `MAKE_NAME` can involve any old sequence of tokens except unbound `,` `(` `)`. More fundamentally, in terms of what macros are defined initially or even what the exact preprocessor behavior might be, your indexing environment/behavior may be completely different from your build environment/behavior. E.g. Clangwise, if your indexer doesn’t support `__has_extension` (it probably shouldn’t attempt to) and know exactly what extensions are supported by the target compiler, then you can’t tell how an `#if __has_extension(__foo)` will actually come out, and any code that relies on that outcome becomes opaque. Ditto stuff like the MSVC `#@` operator, or the GCC `x...` parameter form and `,##` comma elimination. There’s also a huge number of pragmata supported by different versions of different compilers, some of which (e.g., `#pragma GCC poison`) can affect preprocessor operation, and all of which can (post-C99) be emitted via `_Pragma` or `__pragma` as the result of a macro expansion.
You can check "c:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Xml\Schemas\1033\natvis.xsd" CustomListItems expansion - https://docs.microsoft.com/en-us/visualstudio/debugger/create-custom-views-of-native-objects Intrinsic tag - Describes a custom intrinsic function that can be called from an expression SmartPointer tag - Indicates that the given type is a smart pointer. The text inside this element specifies the expression to evaluate the underlying pointer. Attribute "Optional" for some tags: Item, ExpandedItem, DisplayString ... and they now support variadic templates (this broke few my old visualizers :) )
Yes, but once that module is built, parallelism really should get going. Source: experience with some current parallel build systems. In fact, I don't see how modules could change the current situation in any way?
What do you mean by COM?
Another powerful approach can be to generate a XML Document which you can then translate to some specific HTML style using a XSLT stylesheet.
Would you mind reading through my current outline (basically chapter headlines, I won't bother you with everything I've already written) so that you may be able to suggest topics which should definitely be covered?
std::chrono::microseconds and std::chrono::nanoseconds still didn't work properly in MSVC 2015, not sure about 2017 but I've had to resort to using this solution that uses Windows OS specific code many times: http://stackoverflow.com/questions/16299029/resolution-of-stdchronohigh-resolution-clock-doesnt-correspond-to-measureme
Isn't the Pimpl idiom getting rid of gratuitous compile-time dependencies? I agree with modularization. That is good advice is most situations.
It is not. 
Oh. I was pretty sure it was. Thanks for the info.
Constexpr if is independent of templates. I suspect it compiles for you only if you never try to instantiate the template. The condition for constexpr if must resolve to a compile-time constant bool (constexpr variable, global const, const variable that evaluates to a literal, etc), the result of invoking a constexpr function, or examining the value of a template value (e.g. `template &lt;size_t N&gt;`). I suspect use_logger in your example simply isn't a compile-time constant. The reason it needs to be constant should be self-explanatory.
Yea, I just meant in a lot of cases people post link to latest code and when you go see it months/years after you can't find what you were looking for (specially if a line is linked).
Eclipse CDT too.
&gt; I believe we've all had the case where something was compiled, while it shouldn't have been, due to accidentally creating/including a #define of the same name or defining it to 0 while checking with #ifdef. mmhhh... no.
I totally agree with stopping usage of `#ifdef`. I generally do this: #ifndef DEBUG #define DEBUG 0 #endif #if DEBUG /* Do something in debug. */ #else /* Do something in production. */ #endif Of course, instead of writing a `#define` if its not undefined, I could use something like this: #define PRIMITIVE_CAT(a, ...) a ## __VA_ARGS__ #define COMPL(b) PRIMITIVE_CAT(COMPL_, b) #define COMPL_0 1 #define COMPL_1 0 #define CHECK_N(x, n, ...) n #define CHECK(...) CHECK_N(__VA_ARGS__, 0,) #define PROBE(x) x, 1, #define NOT(x) CHECK(PRIMITIVE_CAT(NOT_, x)) #define NOT_0 PROBE(~) #define BOOL(x) COMPL(NOT(x)) #if BOOL(DEBUG) /* Do something in debug. */ #else /* Do something in production. */ #endif This is much better than defining macros to `ON`or `OFF`, however, if its undefined it results to true instead of false, as anything that is not `0` is true. Of course, it could be extended to match numbers and then if its not a recognizable number it becomes false: #define PRIMITIVE_CAT(a, ...) a ## __VA_ARGS__ #define CHECK_N(x, n, ...) n #define CHECK(...) CHECK_N(__VA_ARGS__, 0,) #define PROBE(x) x, 1, #define IS_NUMBER(x) CHECK(PRIMITIVE_CAT(IS_NUMBER_, x)) #define IS_NUMBER_0 PROBE(~) #define IS_NUMBER_1 PROBE(~) #define IS_NUMBER_2 PROBE(~) #define IS_NUMBER_3 PROBE(~) #define IS_NUMBER_4 PROBE(~) #define IS_NUMBER_5 PROBE(~) #define IS_NUMBER_6 PROBE(~) #define IS_NUMBER_7 PROBE(~) #define EXPAND(...) __VA_ARGS__ #define FALSE(...) 0 #define IIF(c) PRIMITIVE_CAT(IIF_, c) #define IIF_0(t, ...) __VA_ARGS__ #define IIF_1(t, ...) t #define USING(x) IIF(IS_NUMBER(x))(EXPAND, FALSE)(x) #if USING(DEBUG) /* Do something in debug. */ #else /* Do something in production. */ #endif You could even extend `IS_NUMBER` to recognize `ON` and `OFF` as well, so both forms can be done. 
I recently still got an error about `&gt;&gt;` being recognized as the bit shift operator. Just throw decltype, variadic template, template template parameters, declval and ADL in the same statement and the compiler breaks down. I think it has been fixed in MSVC 2017 though.
Cool thank you very much!
&gt; Have you had any code where T&amp; would have been helpful, and if so, which behaviour? This is a really interesting question. On a number of occasions I **thought** an expected&lt;T&amp;&gt; would be helpful. And then I thought to myself "oh I can't do that" followed by "actually, that's a really bad idea altogether, it's a design mistake to have Maybe borrowed references to stuff". So, despite over two years of using Outcome now, I have never yet once encountered a situation where expected&lt;T&amp;&gt; was the right design choice. But then I'm also the kind of programmer who thinks that T* is a perfectly fine substitute for optional&lt;T&gt; almost all of the time. Other programmers would strongly disagree. I'm not saying there isn't a good use case for expected&lt;T&amp;&gt;, just I haven't seen it yet in my programming using these things to date. And I have probably as much use experience with these as anybody on WG21. I'd personally ship Expected without T&amp; support, and add it later if it becomes an obvious hole. I suspect it will never become an obvious hole. And better to leave it undefined than fill in something out of disliking holes for the sake of them. 
Since `ON`/`OFF` are only used in the context of the feature macros, you can completely skip their definition and simply use `+`/`-` directly. Especially considering that most configurations are declared somewhere in the build systems.
That's the rub though, they are *similar* concepts, not the same. Each have different constraints and different behavior with different inputs. This is a LCD API. It doesn't fit the semantics for any of them particularly well, but it works ok as a generalization over all of them. 
Almost expected something about header guards lol
This code is Enterprise-Ready™
If you can get away with it, websocket chat is one of the few things Node does well. It's low-compute intensity and network I/O-bound so Node's up to the task and several frameworks are already available.
&gt; Index all the symbols from the whole project + include path. You don't need much data beside a fully qualified name &amp; the corresponding header. Of course you may want rules to include &lt;QString&gt; instead of qstring.h, etc. Template specializations &amp; macros make things complicated. Macro themselves should™ ideally be indexed* I mean, doesn't every IDE do this, or try? Eclipse did this reasonably well for me. Now I use rtags (with emacs/spacemacs) and it does it fine. Macros aren't part of the AST per se but I can go to definition on a macro (Eclipse can too, and can even do step-by-step macro expansion... pretty amazing on occasion). Eclipse also renames the .cpp and .h file when you rename the class, though it was a bit buggy when I tried. clang-format does some sorting of includes, and most IDEs can do certain things too. Btw, macros also make it staggeringly hard to implement include-what-you-use exactly correctly. A header can change the definition of a macro that changes subsequent includes meaning, even if no symbols from it are used.
&gt; At runtime, this translates to an additional level of indirection for every method invocation, which you wouldn't necessarily have to pay for otherwise. That's pretty unlikely. It will prevent the function from getting fully inlined at compile time, that is true. It can still get fully inlined from LTO. If the function wasn't getting inlined though, it's probably the same, as the implementation class methods are almost certainly going to get inlined into the interface class (because they are only called from one place). So it's one function call either way. I also wouldn't use the term "indirection" as I would reserve that for a situation where the callee is not fully determined at compile time (e.g. a function pointer or virtual function) but maybe that's on me. But yeah I agree with the general sentiment of your post. In particular the data indirection is a lot more significant performance wise. A vector of pimpled classes will behave abominably compared to a vector of normal classes. But sometimes you don't have a vector. I don't think I've ever used a pimpled class.
My coworkers already say my code is too complicated when I use a basic ternary (only variables, no function call or operators), this would fuck with their brains.
I quoted it above. I'm fully aware of the fact that you can use any mathematical operation.
Ah it's way down there I'm sorry.
I think the mistake was going down the rabbit hole to begin with - the syntax and implement details (writing a specialised comparison operator for some STL type, really?) quickly got out of hand for something that just required a nullptr check.
Resharper C++ too.
Similarly it could detect nullptr dereference, I think. It's probably over engineering for a game engine to play with references like that. But as a C++ case study it's a cool article.
Not really, I just need to do try?, add in the missing if-check, and the Swift code becomes almost verbatim to the C++ example at the end. 
Not sure but it well could be that the feature in qtcreator is made possible with clang. Atleast the code completion is. 
no, it was here since way before the clang code model. Same for the completion, it does not necessarily use clang's (I disable it on my projects because its memory usage can climb past 20 gigabytes then).
&gt; That's pretty unlikely. It will prevent the function from getting fully inlined at compile time, that is true Yes, well it depends entirely on the compiler and linker being smart. And not all of them are, all of the time. &gt; the data indirection is a lot more significant performance wise. A vector of pimpled classes will behave abominably compared to a vector of normal classes. Yes, excellent point - I forgot about that aspect. every data access goes through the smart pointer, and your cache locality gets screwed by the access patterns. &gt; I don't think I've ever used a pimpled class. I have, and it was quite simply a PITA.
Yes, I'm referring to COM, the [Component Object Model](https://en.wikipedia.org/wiki/Component_Object_Model). It originated on Windows, but it is not Windows specific nor limited to Windows. It is part of macOS in CoreFoundation as the NSPlugin API, for example. IIRC some browsers use it for plugins and interop, and various frameworks and libraries use it. COM is specifically aimed at providing a stable ABI, and it supports that very well. The overhead is significantly lower than PIMPL, as once you have an instance via `QueryInterface`, you're basically dealing with a regular object with virtual methods.
in component systems like this, it's common for the RenderSystem to have a vector&lt;RenderComponent&gt;, and process the components sequentially. this is the 'primary index' that needs to be optimized for cached coherency. the article describes a 'secondary index', which is why it's appropriate to operate on pointers/references instead
You could just use Handle-Body and just store the handles by copy if you're that worked up about it. I'm considering rewriting an XML parser that I wrote and still use from time to time, and am considering doing that for the document tree structure. I might just shove 'em all into a shared_ptr and call it good, though. I've taken to putting a "typedef std::shared_ptr&lt;myclass&gt; pointer;" in many of my class definitions anyway.
Well, maybe "gratuitous" is not the right word. In theory, Pimpl sounds like a pretty cool idea, but I agree there are definitely drawbacks. 
It looks like a heavy pattern, how fast is it in runtime compared to Pimpl? 
I love this tool but it's hard to install. I want it to be part of the official clang tooling.
It is, right up until you upgrade your compiler.
C++ is more powerful, has more complexity and you can f××× sh1t up really hard compared to python in which you can just add an Elephant to the calculation of Pi and still get something to work with. I like python for the fact that beginners learn to code in a clean way but not for the fact that everything somehow just works. People learn less through Python compared to languages like C. It's the error that teaches, not the completed project.
Sure, learn both. But what would you like to use day to day for getting things done? If its smallish I'll start in python and switch to C++ if it's not fast enough, if it's large I'll tend to start in C++ for that type checking alone. I feel though that if there was a standard way of handling numerics in C++ with library interfaces around it, then I would probably reach for C++ first every time. I kind of hope Julia continues growing as it's got many of the benefits of both worlds.
&gt; if maybe more so. But if you're a guru at it, you can write Python which actually matches or beats C++ with its STL (and I'm talking CPython here, no fancy JIT) Be interested to see a real world example of this, as far as I know python is the slowest language around Number crunching in external modules may be fast, but the C++ STL is generally designed to be the lowest overhead possible (eg move semantics were essentially introduced purely to optimise vector&lt;&gt;). In python generics are expensive, C++ templates are free, python has no concept of stack vs heap and is reference counted, in c++ you abuse the crap out of the stack and RAII is literally free vs reference counting garbage collecting etc etc
I also use the compiler as a refactoring tool. It makes things so easier. Just change the thing you want to change, press build, fix the first error on the list, rinse, repeat. Then, one by one, all those little translation units slowly become green, up to the last. Satisfying.
I don't mean to be a dick, but someone really should have edited Hartmut's press release. &gt;While we call it version one, it is in fact the fifteen~~s~~th official release of our library. &gt;HPX is the C++ Standard~~s~~ library for parallelism and concurrency. &gt;The new C++ Standard~~s~~ facilities listed ~~m~~lend themselves perfectly ~~with~~to some of our extensions targeting asynchronous operation**s**, such as asynchronous parallel algorithms, asynchronous task blocks, or dataflow constructs. &gt;We have refactored our thread-scheduling subsystem for improved performance and less~~er~~ overheads. *** &gt;We now support transparently migrating objects across compute-node boundaries, which is a major feature supporting dynamic load balancing in large distributed applications. Yay! I work mostly with Charm++ which has had this functionality for a long time, and it's been hard for me to move toward using HPX's tasking model (which I like better) because it hasn't supported the some level of migration that Charm++ does.
Yes, absolutely. Standardese can definitely be used together with Doxyrest as the front end instead of Doxygen -- to properly support the modern C++. What needs to be done on your side is to emit XML according to the Doxygen schema. No need to implement it all, BTW -- most of it is never really used, so you can extend it on as-needed basis. On my side, Doxyrest string template frames need to be updated for the modern C++. 
As a novice to groovy and fairly versed in python, what does groovy have that python doesn't? What specifically do you see groovy excelling at over python?
Python is not an improvement over Perl at all and I do not understand how it came to take the crown of most common scripting language. The scoping is bad, the lack of strict declarations is bad, and the runtime also happens to be kinda garbage. It is one of the worst languages possible for embedding yet you see it used for that all the time. One would think that by now there'd be a new generation scripting language that bests all this crap from the 80s. It may exist, I don't know. I suppose Perl 6 is an attempt in that direction, but I gather it's impossible to write a performant run-time for it.
I didn't mention Perl? I personally wouldn't recommend actually using python as an embedded language. Something lightweight like Lua is usually much better anyway, but I can see why people would want python: the ecosystem of packages is great and the language is well-suited for prototyping, especially because it's easy to write in.
It's not really that heavyweight actually. Each class implements a common base, [`IUnknown`](https://en.wikipedia.org/wiki/IUnknown) which just provides reference counting (`AddRef`, `Release`) and the magical `QueryInterface`. This allows a single object to implement multiple interfaces, and gives you all sorts of flexibility (such as composition, facades, etc). At runtime, once you call `QueryInterface` up front to get an object to work with, you're simply dealing with a concrete object that implements an interface defined by an abstract base. The overhead is just a VMT lookup as usual in C++, and there's no impact on data or layout. IOW definitely faster than PIMPL.
You might want to consider something like Visual Assist as it would significantly speed up that process. That is, unless you do it this way as some sort of cathartic release, then don't let me stop you. 
The ideal is to use Python by default, and write performance critical code in c++. The problem is how you interface the two, either call it in a shell, or write a python module in c++.
Octave is more a poor man's Matlab.
I do have a refactoring tool other than the compiler that's for sure, I tend to use them when it's something simple such as renaming things. When the way a class is used is changed, and it's interface had been broken, I don't think I'd let a tool do these change for me.
I always used to argue it was a valid implementation defined behavior: http://stackoverflow.com/a/26302259/1708801 but considering this defect report: http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1963 it may not be. Although moot since all the major compiler support it as an extension anyway.
take the first range as input and the other ones as parameters similar to how linq does it with SelectMany for instance.
&gt; transform at best would give you back a range, not an optional optional _is_ a range
The release notes page is down, anyone have another link or can copypasta?
I was hoping it would be something like [hunter](https://github.com/ruslo/hunter), but *better*. Edit: word
&gt; but it doesn't let you sense whether you're being invoked for compiletime or runtime evaluation. That would be extremely useful! My compiler does not allow using SIMD intrinsics inside constexpr functions so I have to often implement two different sets of types and algorithms for constexpr and non-constexpr contexts :/
Yeah, this is pretty much what Sean Barrett said with his STB libraries. They made it possible for him to make small C programs that do those sorts of things without having to go to python or some other language.
All Projects * Fixed available kits after selecting Qt 5.8 as minimal required version in wizard (QTCREATORBUG-17574) * Fixed that `Run in terminal` was sometimes ignored (QTCREATORBUG-17608) * Fixed that `This file is not part of any project` was shown in editor after adding new file to project (QTCREATORBUG-17743) Qt Support * Fixed ABI detection of static Qt builds Qbs Projects * Fixed duplicate include paths (QTCREATORBUG-17381) * Fixed that generated object files where shown in Locator and Advanced Search (QTCREATORBUG-17382) C++ Support * Fixed that inline namespaces were used in generated code (QTCREATORBUG-16086) Debugging * GDB * Fixed performance regression when resolving enum names (QTCREATORBUG-17598) Version Control Systems * Git * Fixed crash when committing and pushing to Gerrit (QTCREATORBUG-17634) * Fixed searching for patterns starting with dash in `Files in File System` when using `git grep` * Fixed discarding changes before performing other actions (such as Pull) (QTCREATORBUG-17156) Platform Specific Android * Fixed that installing package with lower version number than already installed package silently failed (QTCREATORBUG-17789) * Fixed crash when re-running application after stopping it (QTCREATORBUG-17691) iOS * Fixed running applications on devices with iOS 10.1 and later (QTCREATORBUG-17818) BareMetal * Fixed debugging with OpenOCD in TCP/IP mode on Windows (QTCREATORBUG-17765)
RAII = one of the most kick-ass concepts!
If I'm reading this correctly, this does not integrate with the package manager for the system? I'm still looking for a good all-in-one solution. Right now, I need my dependencies in 3 places. First, I need to have them in my CMake code in the form of find_* functions, so that I can build my code. Second, I need them in whatever tool I use to install the dependencies (in my case puppet). Third, I need to list them when I'm packaging my code (in my case in the dependency fields of an RPM). I'd really like something in CMake that could cut out the second piece.
Seems the bandwidth limit on the host has been exceeded. Is there a mirror by any chance?
simpler by design and almost no macros. see http://mockator.com/ for user guide videos and http://eprints.hsr.ch/327/1/mockator_mrueegg_thesis.pdf for text.
How does this compare to the author's own [cget](https://github.com/pfultz2/cget)?
In context of asynchronous programming, I usuary use shared_ptr to ensure whatever object to outlive. Isn't this similar problem?
Tracy is a tool that gives you a slick interface for error propagation for code that doesn't use exceptions. It's a part of a bigger infrastructure we had at work, and decided to take it out for everyone to use. IMO, it's extremely comfortable. I'd like to hear opinions and ideas about it.
TL;DR: You don't understand the C++ standard library design and you whine about your lack of understanding. Iterators are there so that you can avoid the braindamage almost enforced by many other frameworks that have you do `if (container.contains(foo)) then doSomethingWith(container[foo])`. This will perform the lookup twice, and there's no way around it unless you use an iterator. No, having the container cache the lookup's results is not a clever thing to do. I've run into that sort of a "paradigm" once and it was so hard to get to work right *and* perform well that it was simpler to just ditch it. If the default insert action is OK to you, you could use an API returning the reference. Some of the nicer APIs will accept a functor that creates the object in some non-default way, but C++ library doesn't do that.
This lets you install the same packages from `cget` directly in cmake. However, `cmake-get` doesn't support the package manager like features in `cget`, so you can't list the packages that are installed or remove a package. Also, `cmake-get` doesn't cache downloads. Since its written in cmake, I can easily provide a script that installs the dependencies for the user or do it during cmake time as well, which is nice as some users don't like to install another third-party tool to install the dependencies. 
I think this is a useful tool for C programmers. This is something that I have been scratching my head over in C and figured macros must be the way to accomplish this. I made a similar thing for my C projects and it's been working out well for me. This is good if you're stubborn and want to avoid C++ exceptions at all cost.
&gt; poor man's Matlab Any good reasons why a rich man would choose matlab over python?
Various toolboxes. Some of the Python equivalents of functionality are also less reliable (looking at you, TransferFunction). Also if you have a lot of infrastructure and utility code already there for Matlab, why reinvent the wheel? For my purposes, 98% of the time Python is good enough (if maybe a bit less convenient occasionally). And the remaining 2% of the time I can jump on a floating license for a few hours.
I suppose it's possible that I opened an old project and it was using an older toolset or something like that.
Yup. We did not use exceptions at all in my team (RT embedded), so it was pretty handy. You're more than welcome to propose and submit PRs with ideas you think are worth having in this!
I can't speak to your specific needs, but in my experience (years old at this point), if you've got the licenses and server setup, spinning up a cluster is relatively easy in Matlab. Of course, it's going to cost you something ridiculous between the license cost of the toolboxes and the Matlab itself. Hence my calling Python poor-man's Matlab.
This would be more interesting if there was also a version that didn't store individual bits, just to see the effects of packing/unpacking overhead. 
&gt; how it came to take the crown of most common scripting language The perl6 debacle sucked all its energy out of the room. (And I'll disagree about python not being an improvement; for starters, you can build complex types in python without wanting to die) (I'm led to believe that perl got better in this respect, but these days the only thing I want to use perl for is a better awk and / or a better sed) 
&gt;Macros No thanks.
MSVC is committed to C++ conformance. Yes, we've had a few rough years but it's clear from even this thread that we're improving rapidly. At this point, it's pretty much just two features that we lack: two-phase name lookup (that work has started) and a conforming preprocessor. Once those two features are implemented MSVC will conform to C++98/11/14. You can read more about [standards conformance in MSVC in this blog post](https://blogs.msdn.microsoft.com/vcblog/2017/03/07/c-standards-conformance-from-microsoft). It talks about our status, our plans for C++17 conformance (planned to be done before the Standard is published), and how we're doing with Technical Specifications (not too badly at all, if I do say so myself.) There are bugs--as there are in any compiler. Ironically, as we get closer to conforming, especially on the hard-to-implement features like extended `constexpr` and expression SFINAE, we're finding bugs in other compilers. We use other compilers frequently to verify that we're reading the Standard correctly, and sometimes we find that they've read the Standard incorrectly : ) You'll find the most bugs in these two features but they are close enough that we're considering the features done (and of course we'll fix bugs as we encounter them!) As for C vs. C++, MSVC is intended to work for both. We had a huge conformance gap with both languages and we chose to fix our C++ conformance issues first. Frankly, the number of C++ developers using MSVC dwarfs the number of C developers. Also, the C Standards have been a bit, um, interesting as of late. We have done C99 conformance work, most notably [C99 _Bool, compound literals, C99 designated initializers, and variable declaration](https://blogs.msdn.microsoft.com/vcblog/2013/06/28/c1114-stl-features-fixes-and-breaking-changes-in-vs-2013) a couple of years back. Implementing a conforming preprocessor is a huge benefit for both C++ and C conformance. We hope to start that work any day now. After we tackle C++ conformance we'll turn our attention to C conformance. We know it's been a long journey to get to the place where MSVC is standards-conforming, but we're almost at the end of the journey. We appreciate all of those developers--like /u/dodheim --who have been there along with us, eagerly trying out our [conformance mode](https://blogs.msdn.microsoft.com/vcblog/2016/11/16/permissive-switch), new toolsets, and all the rest. We know it's painful to fix MSVC-specialized code to work in a standards-conforming manner but we're doing our best to make this work for all MSVC developers. And, as always, you're welcome to mail me about any MSVC related issues, either at firstname.lastname@microsoft.com or visualcpp@. 
We respectfully disagree : ) Why C99 instead of C11? C++ and C are different languages. That's ok. MSVC will get to C conformance soon. [See my comment above for details](https://www.reddit.com/r/cpp/comments/66no4v/question_about_c_version_on_nintendo_switch/dgoxaho).
Yes, this compiles correctly with our latest compiler. Thanks, /u/dodheim!
I think there is a bit of misconception at play here (most likely caused by some lack of documentation). HPX has never required for you to have a 'custom main' function in the sense that you had to make the std library invoke something else but the predefined `main()` entry point. What HPX requires however is that for it to work you have to explicitly launch the scheduling system (the runtime itself). After that only threads (tasks) run in the context of this runtime can take advantage of all of HPX's functionality. IIRC, we have discussed exactly this problem over on the cppchat slack channel a while back. As said there, I'm sure that we can find a way to make it work for your use case. The easiest might be for you to come over to our IRC channel (#ste||ar at freenode) where the other developers can chime in if I'm not available.
With that being said, would it help for your use case if, when hpx::init returns the function was lifted to an hpx thread automatically? I'm pondering with that idea for a while now, but I'm not sure if it wouldn't create more confusion...
Have you tried the CMake integration in Visual Studio 2017? With the addition of one extra .json file, you can get it to generate and build msbuild-based projects with the same location and parameters you'd otherwise use, and then get VS's native support for Intellisense, debugging, etc. no need to even look at a command prompt. There's similar support for VSCode if you want a lighter experience with a more terminal/*nix-y experience. Install the cmake-tools and cpptools plugins, set a couple .json files, and you can generate, build, and debug, and use CMake/Ninja-based builds if that's your bent.
I know you are asking about CMAKE, but gn is the tool that does this in a perfect way. I use it daily and it will build your project for windows, with or without VS projects, with ninja, based on clang or MSVC... it doesn't matter. I use it daily, I can my projects on mac/linux/windows... and it is really flexible.
The range-based for example is kind of a bigger issue. The ranges spec has run into the same problem: the temporaries in the init-expression don't live long enough and hilarity ensues. There's no defect report for this yet that I'm aware of; might need a paper to the committee outlining this problem specifically and why it needs to be solved. The likely long-term fix is to make range-based for less surprising (e.g., make all temporaries in the init-expression live throughout the loop's body, rather than being specified as the naive source transformation in the spec currently) and not changes to coroutines or ranges.
[This works for me.](http://stackoverflow.com/questions/38171878/how-do-i-tell-cmake-to-use-clang-on-windows) Make sure you use the correct tool chain name though, as I believe it has changed since that stack overflow question was answered. The easiest way to get the name is to open visual studio and look at the name assigned to the toolchain name in the drop down. EDIT: n/m this isn't what you were asking for.
for now I'm limited to VS 2017, so we'll see.
so you mean to set all zeros for bytes? (or some predefined value)? so that could be equal to memset...
I am the author of the https://github.com/paceholder/nodeeditor repo. Let me know if I can improve the code or add some lacking features.
What's a hat trie?
I wrote a post that may address some of your issues: https://bitsmaker.gitlab.io/post/clang-tidy-from-vs2015/
You're welcome (Thank Boost).
Why?
&gt;&gt; The single biggest design flaw in STL containers is their overuse and unavoidable use of malloc. That's not Stepanov's fault, back at that time malloc was very quick. It only became a bottleneck from about Pentium 4 onwards. &gt; I'm not sure I get you. When does the STL excessively allocate when it can be avoided? Some containers (eg maps) are forced to be node based due to the spec, but we have eg unordered maps. Oh where does one begin? :) If we were to start the STL today, you would never, ever allocate memory unless the caller explicitly says "you can allocate memory" in the call. You would also use a Boost.Intrusive type design for a lower layer, and a less intrusive, more convenient upper layer. But none of this is me saying this. Committee members such as Chandler Carruth, Howard Hinnant and Eric Niebler have been saying this for years, and much more importantly, have put significant input on how to do much better design into a STL2. Last time I was having dinner where Bjarne was present, the topic of STL container's unfortunate inefficiencies came up, and we got into a lively discussion about John Lakos' allocator improvements coming in C++ 17 and later. I just dropped a ton of names there, but I wanted to illustrate that this stuff is not coming from me, but from the C++ thought leadership. I'm just a disciple who listens, and mostly agrees. &gt; I don't think its possible to implement most of the containers without allocing off the heap, and in python you can't use the stack (which is cheap) Oh there's a ton of better ways than the STL does it. Howard has done lots of work to let you preallocate the nodes in a cold path, and then feed them sans malloc to many STL containers in the hot path. That's coming in C++ 17 I think. Should be a big win, and doesn't break backwards compatibility. &gt; &gt; The key part to Python high performance, same as in C++, is avoiding all malloc in your hot path &gt; I mean.. python is just inherently slow due to language design though, not due to having to allocate heap memory &gt; https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/ For small ranges of stuff, yes Python will always be slower than C++ simply due to cache locality (interpreted languages with dynamic dispatch inevitably make mostly useless your L1 cache). But well written Python *scales* amazingly, and better than most C++ you see out there. That's because - and I credit mostly Guido himself personally here - the Python leadership have generally chosen in the standard library and in CPython the *right* algorithms and implementations. C++, being older and having a very, very different standardisation process, has not done as well. For example, the upcoming Networking TS (ASIO) is clearly suboptimal on current hardware. It was designed for a world fifteen years ago. The way C++ is standardised means you're going to get ASIO's design (and rightly so, WG21 already invents too much stuff instead of fulfilling its remit of standardising *existing practice*). The way Python is standardised means Guido **will** veto suboptimal design if he feels strongly it won't have longevity, even if that veto is enormously unpopular. The lack of a singular authority in C++ like Guido is for Python, and the very, very different systems of authority and planning both have, and the historical context from where their cultures stemmed, has us end up with the outcomes there are. Don't get me wrong, C++ has strengths Python doesn't have, but as a personal opinion, I think the Python culture and ecosystem is superior to that of C++. They have more "legs" over there, at least until Guido leaves/retires/something else shifts.
The way we've solved this in the past is a ninja to .vcxproj wrapper, so your build system is ninja, and VS invokes ninja to do everything. I threw one of these together in less than a day for a past contract with a bit of Python. Worked very well. I'd suggest that a very viable solution for you.
Is this an alternative to a Rope?
I'd suggest reading the MS blog articles. Basically, you can open a "folder" containing a CMakeLists.txt and have a fully building, debuggable, Intellisense-ready product with no extra step. Also gives you a platform choice which is normally lacking from CMake projects because CMake is goofy and treats platform as a generation-time option.
&gt; At least in Clangs documentation the only way to generate the files required by Clangs tooling is to actually use CMake If you're talking about `compile_commands.json`, you can use `intercept-build` with whatever build system you like.
When will this long-standing bug be fixed?
I'll pose this question then: Why is Catch an exception? Sure making macros for `min` and `max` and `GetObject` (looking at you `windows.h`) and so is making `None` a macro (looking at you `X11/Xlib.h`) is retarded because they clash with names that might very well be used by user-code (OR THE FUCKING STANDARD LIBRARY!) but that can be resolved by using `CAPITAL_NAMES` as this library does. Is `MY_MACRO(i++)` ok? I would answer yes. My rule is a function style macros should behave like functions (have a return value, run the arguments once etc.) as much as possible^1 , and other macros should generally only be used for configuration but when you follow those rules macros actually behave nicely and to me it seems like this library mostly follows these rules^2 . Getting back to the first question: I would say the reason Catch gets a pass is because the macros solve a problem that other features can't. They make writing and reading test cases easy, they allow capturing expressions etc. and I would say this library does the same. 1: Irrelevant to this library but I thought I should mention that one of my most common uses of macros is to spam out function definitions that have a similar body but can't be templates (overloading multiple operators for example). In this case the macro results in duplicating less code and as a result making errors less likely. 2: The macros behave like statements which seems necessary in this case (they may return from the function) and gives a clear error when used incorrectly and some of the macros conditionally execute the parameters (this does not lead to issues with modifying expressions though). **tl;dr:** Macros have a place and a purpose, and being scared of all their uses, because some of their uses are bad, does more harm than good.
... Which is hard if the compiler refuses to be a C compiler and you have an external library that uses C99.
You’re not contradicting me. You’re talking about analyzing post-preprocessed code and a specific indexer of preprocessed code being “good enough”—and I agree, for most day-to-day usage there are plenty of suitable options; Eclipse does fine for me in that regard. However, again, you’re not going to be able to **fully** analyze the entire codebase, and if you do analyze it you’ll have to cut semantic/syntactic corners somewhere. If a symbol only gets defined on a particular target platform, it’s not going to show up in your index if you preprocess/index w.r.t. some other target platform. If you don’t need to include a header on this architecture but would on another, then nothing in it will get indexed. If you use a header in two different ways or for two different languages (e.g., C and C++, or taking two separate paths through the header), there’s no telling what will actually get indexed. If two different definitions for a function are split around an `#else`, then only one of those definitions is going to show up. It’s great that people have written tools that basically work well enough, but that’s not at all what I’m talking about, and /u/c0r3ntin was talking about indexing all symbols andsoforth, which (again) is greatly constrained by the preprocessing stage.
 **Company:** [Avalanche Studios](http://avalanchestudios.com/careers/) **Type:** Full Time **Description:** PC/Console game developer. Makers of Just Cause, Mad Max, and theHunter games. We're hiring for many different positions with different seniority requirements, check [here](http://avalanchestudios.com/careers/) for more details. **Location:** NYC, Stockholm **Remote:** No **Visa Sponsorship:** Easiest if you are Swedish **Technologies:** C++11, Python and Perforce are used for all roles. Depending on the position you may also use Qt, Havok, FMOD, or other 3rd party software. **Contact:** http://avalanchestudios.com/careers/ 
I'm relatively new to Windows development and originally wanted to set up something like you suggest. I got pretty much nowhere. Decided to just use MSVC from the command line and fix the few compatibility problems I had. Now I have the fun of maintaining compatibility on new releases, so I can definitely see the motivation (though I'm using gcc on the Linux/android side). I remember installing VS 2017 there was an option to install clang support. I tried it but just couldn't figure out for the life of me what it actually did. Couldn't find a whole lot of help searching either. Maybe when I get some time I'll give it another go using your experience and the advice of others here. Thanks for sharing.
Resharper++ is so unbearably slow that it is more of a crux then a help. My laptop is almost 4 years old but still has 8gb of ram a nice SSD and a dual code processer with hyperthreading. Far above the minimal spec. 
If you don't care about all the clang stuff it's actually not that hard. I don't mind using the command line to do the setup. Steps usually are: * Create a project folder with a simple CMakeLists.txt. * Create a folder named build and cd into it. * Run `cmake -G "Visual Studio 14 2015 Win64" ..` or similar. * Move up one folder. * Run `cmake --build build --target INSTALL --config Release` if you want to compile from the command line. You can also just open the solution that is now in build. However you probably need to set the start project and target. However CMake doesn't recreate the solution automatically if something changed, while building through the CMake build command does. I guess in Visual Studio 15 2017 most of these steps aren't necessary anymore.
Right on, yeah I have a VisualC++/CMake command line build set up now. I meant I might try out the clang stuff at some point. I've run into a few issues with code compiling in VisualC++ and not in gcc and vice versa
Dynamic typing can be uncomfortable for people who are used to static typing. Since Python 3.5/3.6, you could actually do type/variable hinting such as `variable: int = 5`. It's still possible to change it to a `str` etc. at runtime but mypy points out the mistake like this function expects an `int` but you passed a `str`. For example: def some_method(a: int, b: int) -&gt; Optional[int]: result: int = a + b if result &lt; 4: return None return result I have never seen a Python project where a variable's type suddenly gets changed to something else elsewhere in the code base or maybe I was just lucky. I enjoy C++ companionship with Python though. They work well together.
In most code I write it's extremely rare to care about variable implementations when it comes to speed, it's more important to have reliable behaviour, which means things must be defined based on intended use. If I'm reading an integer from disk or network the size has to remain constant. Fast_uint32 doesn't guarantee that. I could load a uint32_t into a fast version for math reasons but that is it. You shouldn't use the fast versions as members or anything stored on the heap. If you really care about performance you have to hand tune it to a particular machine and worry mostly about memory access. Then you definitely need control over your data sizes.
&gt; If I'm reading an integer from disk or network the size has to remain constant. Fast_uint32 doesn't guarantee that. Why would you use a "fast" integer type when you're I/O bound?
Any junior remote position available??
How would you do this?
It's actually fairly simple (although I am not sure if we are wading deeper and deeper in UB country here). When you do a context switch to a user level thread, you always have a context to jump back, for the sake of simplicity, your main function. You can use that context, add it to your task queue, and call it a day. I have a toy implementation which seems to work.
Yes, it would be all about simplifying application startup boilerplate. There will always be use cases which require a more elaborate/verbose setup for sure. However, for most scientific applications, this mode would probably be the default mode which just works (tm).
Wouldn't having separate directories for non-VS projects with post-build actions that copy the source files for those projects work? 
You can use Visual Studio's debugger without a project of any kind (assuming you have a PDB for the thing you want to debug) with: devenv .\path\to\exe.exe .\path\to\src.cpp 
Our daily struggle summarised: assume this, BUT... 
I don't think that is the intended message. If written correctly, move constructors are very cheap. The point of the warning is that move constructors may not have been written, and if they have been written, may not have been written correctly. Since `T&amp;&amp;` is implicitly convertible to `const T&amp;`, the absence of a move constructor may make your code accidentally call an expensive copy constructor instead. The second point clarifies this. If you know that efficient move constructors are present, you do not need to make any assumptions about them, because you know that they are present and well-written.
The author just emphasizes that it's not self-evident for move constructor to exist and be substantially faster than copy ctors. That said the standard library was completely refurbished with c++11 to provide move constructor wherever possible/needed. So this statement mainly applies to "third-party" code.
Unfortunately the original article does not show a sufficiently complete or realistic example to illustrate some of the problems that you run into in real applications. Now I had started writing a whole discussion about the relative merits and why I thought PIMPL was slower, and realised I was actually thinking of the performance of regular classes vs PIMPL, not PIMPL vs COM. So after reflecting on your comments and looking at it more deeply, I agree now with your analysis. PIMPL may be faster in the simplest case, and they should be approximately the same performance in the common case. &gt; so you pay the cost of a cache miss and that's it In its simplest incarnation (and trivial sample code), yes. But in real apps, you frequently need to do things like implement observer interfaces and have other virtual methods. This can all become quite unwieldy with PIMPL, and at least adds overhead to the simple case. &gt; If the implementation class needs to be virtual, it shouldn't have any additional overhead over COM This is the more likely case in a real application, which means performance-wise they should be about the same. &gt; COM exposes a pointer with a bunch of virtual methods, so you pay for the cache miss on the pointer and the vtable lookup. Agreed, so it's equivalent to the common case of having a pointer or smart pointer with virtual methods. So while the performance should be comparable, maintenance is still an issue. And because you have two classes involved, managing inheritance etc becomes a problem. We had so many problems with the PIMPL code in one project that we just never would have had in regular code.
Never tried it but CLion has MSVC support now and uses Cmake, might be the path of least resistance for you.
Doesn't unique_ptr&lt;T&gt;'s destructor require visibility of the destructor of T? I don't think the code presented in the site works.
In the past, I've worked in control systems, as an integrator, but for the last seventeen years, I've been in Telecom, developing real-time databases and other systems for subscriber data. C++ is my favorite programming language, but I'm a bit biased since I know it so well, and I've been lucky to work on some really cool projects, on many of them I've been involved from product design, development, all the way through launch. It isn't often that you get to create a new product from scratch! Anyway, I'm playing witht the idea of starting a blog on C++/software development. If you are interested, send me a PM, and I'll add you to my email list. All the best.
Yes, of course! It would be incredibly rude of us not to, especially given how much we ask the community to send us your bugs. Usually when there's a disagreement between compilers and the Standard is ambiguous, we're already discussing the issue with the maintainers of the other compilers. If there's actually a bug in Clang, we've almost certainly got a Clang maintainer on the mail thread. And a few months ago a GCC developer helped us chase down incorrect behavior in our compiler. We are a pretty tight community and we all respect each other greatly. We also tend to find a lot of bugs in OSS library code. Most of those are places where the library depended on MSVC-specific behavior that's now fixed, but we've run into many situations where either other compilers was getting it wrong or, more commonly, other compilers disallow a behavior that the Standard allows. And yes, our devs submit PRs directly to fix these issues. C++ is hard, apparently : ) But we're all in this game together. 
Stroustrup is a good author. I read “THE C++ PROGRAMMING LANGUAGE” many years ago, and I used it as one of my main references for a long time. The language (and the internet) has changed a lot since, and now, I find my self using the internet as a reference a lot more often. However, when it comes down to “when" and “why” to use some features, I still refer to it. Scott Meyers has several really good books that you may consider after you finish with Stroustrup’s book. Also, remember to start programming as soon as you learn the basics. If you don’t understand how something works, use it in a small program; play with it until you understand it. It works for me.
Is that a type of lexer?
Restated: Unless the move operation has already been defined by the ISO C++ committee, don't move anything? ...