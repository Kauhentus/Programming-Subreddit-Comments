Except in the places where it is. Like here.
Use [QProcess](https://doc.qt.io/qt-5/qprocess.html)
I had a feeling it would be. Could you share anything more specific on why?
Take a look at [this](https://docs.python.org/2/extending/embedding.html) page. The very first example should suffice and is really, really easy. All you would really have to do in read in the script and feed it to the python interpreter rather than the example script that the example shows.
Compiler Explorer is open source: we welcome any help. There's an issue for this and some progress has been made (especially with recent changes): [https://github.com/mattgodbolt/compiler-explorer/issues/550](https://github.com/mattgodbolt/compiler-explorer/issues/550) &amp;#x200B; My personal take is that any IDE or editor that has a "vi" or "vim" mode always disappoints - it's never as good as straight \`vim\`.
Treat the disease, not the symptom.
Boost Python allows you to both wrap C++ to expose to Python and embed and invoke Python from C++. Been quite a while since I've used it, but it's awesome. Learning curve is quite steep. Get ready for 30+ screenfuls of template errors if you get the smallest thing wrong.
Otoh, having tests right next to this new piece of code you're looking at would really help understand it. When they're separate you first have to know/assume that tests exist, and then know where to find them.
and the modern way to do just that would be to just build windows.h as a header-unit, so it is treated as a module by the system. That would be the whole of Windows.h, exporting the lot, which is what the question was trying to avoid here.
Some of the things on my list don't have papers yet, or papers that I'm not sure are the right paper, so it's a little hard. Those include Unicode text types and facilities (Sg16 work), coroutine library types like generators and tasks, and persistent/immutable data structures. Still thinking about the ones I want from the list.
But in any reasonably well ordered system, it should be fairly straightforward to associate tests with what's being tested. If not, there are bigger issues to worry about.
The compiler has a cool mechanism to achieve this: it uses STL containers with custom allocators, storing everything within a chunk of memory beginning at a specific virtual address. That way the data structures, pointers and all, can be blasted to disk without a real serialization step, and later directly read from disk.
I feel like it is more like a luxury feature, it makes the whole experience a bit more enjoyable for small number of people. Nevertheless I have nothing but profound respect for everyone contributing to Compiler Explorer, I have come to enjoy it more and more.
If putting test code and production code together didn't have any merit, contracts would not be a thing.
I dont understand why aren't these modules implicitly tied to namespaces. Why not make me access the content of a "foo" module i imported through "foo::" unless i'm typing "using namespace foo"? By the currently described implementation i feel like i'm going to mechanically add a namespace declaration in each module anyway.
Lack of TDD does not imply lack of automated testing. TDD is the practice of writing failing tests before writing code. It is still perfectly valid to write the test suite after writing the code, but that isn't TDD.
I was hoping there would be a way to somehow keep using the same name for exported symbols. Gratuitous renaming doesn't help readability, and the rest of the Windows community is already used to WM\_LBUTTONDOWN. I don't suppose there is any cool precompiler trick that will somehow let me reuse the name WM\_LBUTTONDOWN for a symbol name of my own?
I ran across this back in February, /u/onqtam nicely done, I'm using it regularly. `Tests &gt; No Tests` and inline tests near the code make it easy and obvious.
I don't think it's useful to obsess about things being standardized. I mean all these newfangled languages with package managers are not standardised. Both Conan and vcpkg both work fine and are improving
Modules won't solve package managing. Won't even make it easier, modules are completely unrelated to package management.
Big in terms of standardization effort - we are talking about the standardization process after all. I'm no expert, but I would guess that generic lambdas and fold expressions were easy to specify. Generalized constexpr and ctad were probably more difficult. But I don't think any of those features had the same complexity as the c++11 memory model, move semantics, the initial constexpr version and now coroutines, concepts or modules. But then: I'm not involved in the standardization process at all, so I could be completely wrong.
Except that in the real world you often can't. (Precompiled headers go in a single one for a whole project, so you need to reorganize existing code base rather than just enable a pre-compiled header option, which can be done for particular projects but is a no-go in the general case)
Because this is C++ and new inventions are systematically subtly different from existing things.
Da t
taking a couple minutes to sort out your dependencies and write a couple adapters for their build systems really is not the end of the world
I go back and forth on this but I've settled on a mirror hierarchy for tests related to a file or the test file beside the source with a test_ prefix.
I'm hoping we won't be needing precompiled headers anymore once we have modules, otherwise I would have added "size of precompiled header files" to my list of things I hope gets smaller.
&gt; Precompiled headers go in a single one for a whole project This makes no sense at all.
Adding modules support to package managers should be very easy, but in the end, your project will compile faster (one ifc instead of billions of headers) and some internal things of libraries will be properly hidden.
Can it also detect uninitialized struct members? These are much harder to spot sometimes. struct Foo { Foo(int); Foo(); int x, y; }; Foo::Foo(int x) : x(x) {} Foo::Foo() : x(0) {}
https://isocpp.org/std/the-committee &gt; There are four major subgroups: &gt; &gt; - **Core, aka CWG**: Mike Miller (Edison Design Group). &gt; - Evolution, aka EWG: Ville Voutilainen (Qt). &gt; - Library, aka LWG: Marshall Clow (C++ Alliance). &gt; - Library Evolution, aka LEWG: Titus Winters (Google).
It does not do that because [there already exists a check for that](https://clang.llvm.org/extra/clang-tidy/checks/cppcoreguidelines-pro-type-member-init.html). Dunno if it covers this exact case, but it could be extended if not.
One notable aspect: &gt; Many solutions have been developed to leverage warm machines in a local cluster or cloud datacenter (e.g., distcc or icecc). We developed such an application on top of gg. &gt; Using model substitution, we implemented models for seven popular stages of a C or C++ software build pipeline: the preprocessor, compiler, assembler, linker, archiver, indexer, and strip. These allow us to automatically transform some software build processes (e.g., a Makefile or build.ninja file) into an expression in gg IR, which can then be executed with thousands-way parallelism on cloud-functions platforms to obtain the same results as if the build system had been executed locally. &gt; These models are sufficient to capture the build process of some major open-source applications, including OpenSSH [29], Python interpreter [32], the Protobuf library [31], the FFmpeg video system [14], the GIMP image editor [16], the Inkscape vector graphics editor [21], and the Chromium browser [6]. Build systems often include scripts that run in addition to these standard tools, such as a tool to generate configuration header files, but typically such scripts run upstream of the pre-processor, compiler, etc. Therefore, gg captures these script outputs by a model as dependencies &gt; gg is about 2–5× faster than a conventional tool (icecc) in building medium- and large-sized software packages. For example, gg compiles Inkscape in 87 seconds on AWS Lambda, compared with 7 minutes when outsourced with icecc to a warm 384-core cluster. This is a 4.8× speedup. Chromium, one of the largest open-source projects available, compiles in under 20 minutes using gg on AWS Lambda, which is 2.2× faster than icecc (384). We do not think gg’s performance improvements on AWS Lambda can be explained simply by the availability of more cores than our 384-core cluster; icecc improved only modestly between the 48-core and 384-core case and doesn’t appear to effectively use higher degrees of parallelism. This is largely because icecc, in order to simplify dependency tracking, runs the preprocessor locally, which becomes a major bottleneck. gg’s fine-grained dependency tracking allows the system to efficiently outsource this step to the cloud and minimize the work done on the local machine. Source: "From Laptop to Lambda: Outsourcing Everyday Jobs to Thousands of Transient Functional Containers." S. Fouladi, F. Romero, D. Iter, Q. Li, S. Chatterjee, C. Kozyrakis, M. Zaharia, and K. Winstein. USENIX ATC 2019. https://www.usenix.org/conference/atc19/presentation/fouladi
And in one comment you have removed any consideration I had to use doctest
Wait, what? Uninitalized struct variables? Structs are allocated in one big swoop, how could anything not be initalized?
The post you replied to shows such an example. ‘y’ is left uninitialized
Some reasons I can think of are: - This is inefficient, specially on non-forking systems (aka Windows). Opening process is relatively cheap on POSIX systems, but on Windows it is not. - You need the python interpreter installed on your system - And you need `python` in your `PATH`. It also has to be the right version (2.7 vs 3). - You will restrict yourself to passing data via stdin/stdout (`system` won't do that, you will probably need platform specific APIs -- even less portable) - If you want to allow the user to give the python script from command line, you are creating an exploit. If you give a file named `null.py &amp;&amp; sudo rm -rf /` your call will be `system("python null.py &amp;&amp; sudo rm -rf /")`. Depending if `system` is executed using a shell, you got yourself an non working system now.
But C++ doesn't have designated initalizers?
fwiw I found porting the catch TeamCity reporter to doctest was pretty trivial for the bits I needed
These are very good points. Thank you!
Yes. But: 1) pretty certain you can’t use them when you have a user defined constructor 2) either way definitely has no bearing on what happens when the user invokes the constructor which is what the parent post was clearly talking about
It's not even clear that modules will improve compile times. In some cases it makes things worse since modules inhibit parallel builds to a non-trivial degree.
K I don't use C++ like this so chill with the attitude.
It will in C++20
This throws up lots of questions in my mind: what is the fiscal cost of using it (you need a subscription to *AWS Lambda* and *S3* storage), how much bandwidth does it use, how secure is my company's secret source code (am I giving it away to evil *Amazon*)? It is clearly very early days; the package seems to have no web page other than *github*'s *readme.md*, no documentation other than the quite cursory and pointedly selectively incomplete *readme.md*, and no technical documents to indicate what the thing actually does (I haven't read the conference presentation the OP alludes to, but assume it provides only a high-level overview). The comparison with running some build system on a local hot-rack seems suspicious. Why would it run 5x faster on *AWS lambda* than a system on a well-stocked local rack? Can it run on a local rack itself (if not, why not?) This would be the use case in which I am most interested. On the whole I can only say there seems to be a bad smell about this at the moment. I will watch with interest, but more than anything the best it has done is to bring my attention to other ways of doing the same thing (```distcc``` or ```icecc```), thanks for that!
Only took em 21 years.
This is actually a surprisingly apt question. I'm sure that templates are used far too much in concrete application code where they serve mostly only to accentuate compile times. Looking retrospectively at my work, I see most templates have one concrete realization and then one half-assed one which would ultimately have been better just as two distinct concrete classes. But then you have the feeling that if you don't use them, you lose the practice and ultimately the ability to leverage them where they are good (algorithms!). This is even more acute with the introduction of concepts, where one starts to feel that a part of the language will slip from your grasp if you don't use it.
the description "This is even more acute with the introduction of concepts, where one starts to feel that a part of the language will slip from your grasp if you don't use it " is what I'm thinking when I use templates.
You can, but do not have to. Think of modules as replacing `#include`. Instead of textual inclusion, you get a bunch of newly visible names injected. How you choose to use or abuse this power is up to you and the libraries you depend on.
Most of the time, you probably don't need a template, but they give a lot of power when doing things at compile time and generic programming. I would recommend templates for defining control flow patterns like in &lt;algorithm&gt;, making containers, and when switching on an enum value, e.g foo&lt;myenum::bar&gt;(); People would expect or understand templates in those three use cases above. Other cases depend on your problem, but I wouldn't be too concerned with overusing templates.
Isn't that called clang and gcc trunk? Or go look at their branches.
You need them to make highly generic libraries. Which isn't a thing I really ever do, but I'm glad other people have made the ones I use all template-y.
I tried getting into writing clang-tidy checks but the documentation for it is fairly unhelpful. I'll look through your code and see if I can get it to build on my relatively low powered Linux box
Where is sz initialized? Also, valgrind is very verbose. Not every message means there is an issue. The serious ones are the memory leaks and even then I've had to suppress some of those warnings because they are not actually issues.
Learn to type.
Learn to program.
I can do that already
This is more suited for /r/cpp_questions Pictures of code are a horrible way to debug code. Post actual code instead of screenshots. Take your first screenshot for example - there's 16 lines displayed, out of which 11 convey no useful information. My best guess is that `master` at some point has not been initialized when passed to `ORDERED_PRINT()` and it just happened to be `NULL`, so it didn't blow up. &amp;nbsp; Valgrind is a very powerful tool with switches like `--track-origin`. It's output isn't *just* `Conditional jump or move blahblahblah...`, it displays a full backtrace telling you exactly how the uninitialized variable access came to be. It also can be combined with `gdb`, so that, when valgrind finds an error, your debugger opens that piece of code with the exact backtrace. I have no idea if Qt Creator has all these capabilities, but if it doesn't, you need a better IDE. &amp;nbsp; In conclusion: - Learn to use your tools. Understanding valgrind better would have helped you here. - Post enough data for others to help you. Besides posting code instead of pictures, hey, your code seems to be on gitlab, so give us a link and maybe someone will clone it and run valgrind for you.
A lot of times they are asking about corner cases that don’t really come up in practice but were put int the standard for completeness and to have same behavior in those corner cases. Because of that, people might not be familiar with specifics. The only time you’d need to know that may be if you are the compiler or library implementer. In general, you are right that no one person knows everything. It’s simply too large of a language. However there are domain experts who are knowledgeable in particular areas. This isn’t different than any other complex system. Someone else can she more light on the committee process, however.
Learn linear algebra
&gt; a link and maybe someone will clone it and run valgrind for you. [https://gitlab.estig.ipb.pt/algorithms-and-data-structures/univerza-v-mariboru/assignments](https://gitlab.estig.ipb.pt/algorithms-and-data-structures/univerza-v-mariboru/assignments) &amp;#x200B; Do you want me to post the code here? How do I change the post from cpp to cpp\_questions?
sz is initialized in the constructor &gt; `benchmark::benchmark(int capacity) {` &gt; &gt;`sz = capacity;` &gt; &gt;`arr = new int[capacity];` &gt; &gt;`sum_DLL=0;` &gt; &gt;`sum_Array=0;` &gt; &gt;`}`
Shouldn't this be in Opengl sub ?
Thanks for the link, but it is asking me for a "LDAP username". Is it privately hosted? You can't move your question to another subreddit, but you can edit the question and show us more of your code. /u/skymeson asked about `sz`, so maybe you should post the whole class with member function implementations.
Here is where you are wrong, the standard is not as well defined as you think it is. For instance, if going off the text along, there is no normative text specifying if a dereference of a null pointer is well defined behavior. Nor does it specify what happens when you dereference a pointer past the end of an object. Temporary objects have no defined storage duration. Another example would be \[dcl.ref\] p5 sentence 3: &gt; A reference shall be initialized to refer to a valid object or function[.](http://eel.is/c++draft/dcl.ref#5.sentence-3) What is a valid reference or function? This is not defined anywhere (although I believe this may be fixed soon by some paper, I don't know the specifics). We just don't know, so interpreting the standard is not all black and white. The standard also likes to define things by omission, such as what a core constant expression is. It states what a core constant expression isn't, so determining if an expression is a core constant expression requires one to go through step by step through the 20+ conditions, some of which include exceptions, to figure it out. Another example would be what kind of declarations are defining declarations. Long laundry lists are hard to interpret, and no one will know exact specifics.
1. There are people who ask questions to learn something. And there are people who ask questions to demonstrate just how darn amazing they are and they should be giving the talk and who is this guy on stage and omg I'm so darn intelligent. 2. Ask a good lawyer if XYZ also defines case ABC or not. 20'000 dollars later you probably won't have an answer, simply because things aren't that simple.
Do you think we would need lawyers if laws are so well defined?
It should be public now
[Game Engine Black Book: Doom](http://fabiensanglard.net/gebbdoom/) This will tell you how Doom works. It won't exactly tell you how to make a modern rendering engine since you probably aren't coding for DOS and VGA cards, but it'll definitely tell you about Doom. (Also Doom doesn't use a ray caster, Wofl3D does)
Thank you! Much appreciated
https://lodev.org/cgtutor/raycasting.html Maybe also brush up on linear algebra and trig. Doom was sort like a ray caster, but did some more stuff beyond a basic ray casting. This will tell you how to make a wolf3D thing.
Much appreciated. Thanks!
IMO the reason to do a 2.5D-style engine would be for the fun of doing all the problem solving yourself. If you're choosing a project for the sake of ease, I wouldn't be surprised if utilizing the full 3D pipeline of opengl/d3d would be far easier because of the wealth of tutorials and libraries built for that. That said, these are probably good sources before you dip your toes: http://fabiensanglard.net/doomIphone/doomClassicRenderer.php http://fabiensanglard.net/duke3d/index.php
Yeah but that's just a shitty way for it to work. Python and lots of other languages work the way they are suggesting and it's fantastic. You can tell what to import based on how it's used. if that relationship doesn't exist then you're back to wondering what magical include file you need to pull in function foo.
How can you know that virtual address will be available and always have enough free memory after it to deal with all the allocations the compiler will make? Like is it a hardcoded address, and is it just put far away from where the normal heap and stack would grow?
Compiling with optimisation increases the likelihood of spurious issues, in my experience.
Their compiler sources are public. You can get them via svn, but you need an account. Just seach for foundry27
Thanks!
Even if the standard was completely defined, it wouldn't always be "easy to spot" what a certain case does. Standard provides general descriptions of each part of the language and it's not that easy to draw parallels between them. You also need to know your way around the standard and its terminology, which most people don't encounter ever.
If court rulings ran offline, faster than real-time on any one person's laptop (i.e. gcc) then lawyers ought to be redundant. ¯\_(ツ)_/¯
That depends on what you're writing. If it's a program for a user, you probably only implement specific cases so you may not use a single template. If it's some backend stuff, you might need a few to cover more cases with single code. If it's a library, you might need a lot of them, because you don't know all the classes that might be using your code. If that's a "core" library, your code may have only templates all the way down :) &amp;#x200B; The more you know about the way it's going to be used, the fewer templates you'll need.
malloc will not throw bad_alloc, youre thinking of new. malloc could return NULL and even that isnt guaranteed (overcommit)
**this** not **the** is the word used in the actual title. This is just click bait.
Well, I won't let you play that bullshit with me. You're blocked.
I'll do it, thanks for sharing your thoughts!
Okay, yes, I should have used `new`. The point is that you can construct a test that will be a erroneously pass if the function is inlined.
1. Because that makes it much harder to use modules to replace headers. All of a sudden you have to add namespaces throughout your source. 2. Because modules do not have a 1-1 relationship with namespaces. A namespace can contain many modules. A module can contain many namespaces. They are just not the same thing. 3. Because there will be fewer namespaces in a module world anyway. Right now my source is littered with namespaces that have no other purpose than to hide names from other parts of the source. That won't be necessary in a modules world anymore. You won't need 'detail' namespaces anymore either, as modules do a much better job of hiding symbols you don't want exported. 4. Because namespaces solve the wrong problem to begin with. What I mean with (4)... Namespaces, as used by C++, are primarily intended to make sure that symbols from library A don't clash with symbols from library B. So if you write a library, you choose a namespace, and then everybody else must magically know that this is "your" namespace, and respect that, because if there is a clash, you are back to square one. A far better design would be if the importing application provided the namespace. The importing application knows which libraries it imports, so it can assign a unique and convenient namespace to each one. E.g. import qt as namespace qt; // qt::window, qt::qmlview, etc. import std as namespace stl; // stl::vector, stl::sort, etc. etc. This solves the correct problem: the importing application knows precisely which names it uses, so it can make sure they don't clash. Well, maybe for C++23?
I love it, I just want much more of it! I estimate we are using maybe 200-400 symbols from that file. As for how many it declares... Tens of thousands? Hundreds of thousands? Who knows...
C++ is ridiculously complicated, so I don’t find this surprising. This is what happens when you try to design a language For the modern world but have to adhere to years and years of legacy stuff.
What does that have to do with the question if a variable doesn't get initialized or not? Are you confusing allocation and initialization?
That C++ is a design tool that we use in the absence of a greater theory.
You use templates when you need to abstract over sets of types. Personally, I use them literally everywhere.
Hmm, looks like FoundationIO is about to receive an update where lots of struct members have their initialisation revised... Maybe in C++23 we can change those rules? int a; // zero-initialised! int b = std::uninitialised; // for people who think initialisation is unacceptable overhead It would make the language a lot safer...
Also the fact that most other languages don't have a written standard at all, just reference implementations That's a world of difference
Ahem. It's not about overhead, it's about clarity and safety. Which is more correct: int a; if (...) { ... a = 99; } else { ... a = 100; } or: int a = 0; if (...) { ... a = 99; } else { ... a = 100; } In the first case, if you forget to set `a` in one branch the compiler will tell you about it (with `-Werror=uninitialized`); in the second case it can't so you have to pick a "safe" default or one that will crash at runtime.
They have AI that does bankruptcy law now. No joke.
[Cologne, Germany](https://wg21.link/n4783)
Just a quick note -- there's a paper, too: https://www.usenix.org/system/files/atc19-fouladi.pdf
It's about safety indeed. Except I think the safer version is the one where it has a guaranteed value so you can be sure your test cases always run deterministically, rather than relying on whatever happens to be on the stack at the time. If you want the warning, by all means use `std::uninitialized`, or even better, a lambda: const auto a = [] if (...) { ... return 99; } else { ... return 100; } ();
We need legislative metaprogramming first
I often give my classes their own pair of header and source file, and if each of those were turned into a module with its own namespace I would end up with repeated clutter in front of each class name (e.g. foo::foo = class foo in module namespace foo). A class is already a kind of namespace so I don't need an extra one.
I am very much interested to work on this, but I don't have a necessary skills that relates to technologies, since \`seastar\` and \`scylladb\` are both open source, will I be able to be a full time contributor and hopefully have a full time role in ScyllaDB if I perform greatly? I see there is a slack group for users, is that also a place for dev contributors to collaborate?
*Our* test cases run with ubsan, so reading an uninitialized value is a hard failure. In my book, that's better than running deterministically and spuriously passing. If you haven't enabled ubsan (and asan, etc) for your unit tests yet you really should try it! Refactoring into SSA style isn't always an option for more complex code with multiple variables getting initialized at different times. I agree that it is preferable though - and increasingly more of an option with IIFEs and now structured binding.
Very true.
Ask on boost's users mailing list: https://www.boost.org/community/groups.html
No, it's not click bait. You do need to calm down, though. I don't appreciate you very fast jumping to conclusions and post comments suggesting that I am fraudulent. I have posted this as a link post. Reddit captures the title and preview of the post when the post is first made. Some people were bothered by the *the* word, so I then changed it to *this* in the Medium post. I am not able to change it here though.
Come grab a Kolsch with us! Or, if you're feeling particularly hostile, a Pilsner instead (shots fired).
I'm curious and haven't used it for a while, what improvements for vcpkg did you see over the past year or so?
I get where does this question come from : no you cannot distribute modules in the same way as libraries, the format in which your modules are precompiled is not standardized in any way and may well vary between minor version of your compiler. Package everything into a classic static/dynamic library, or distribute the code and let your user build locally your module, you'll be better off avoiding weird linking errors.
I don't think headers are terrible. They have been used for a long time and have been very useful to people. Modules might provide a better alternative in many aspects but that doesn't make headers terrible.
So did I. You've got to ab-use something in order to know to *use* it properly.
Just to be clear: I'm not trying to take away your uninitialized variables, I'm just asking for the default to be zero-initialized, with specific language support if you are sure you are a big boy who can handle uninitialized.
`std::string std::generate_legal_speak()` is your friend!
I know android needs `-latomic` to link correctly. You can try that.
Everything you said equally applies to any large codebase, so this shouldn’t be too alien, surely. Have you ever been asked to provide details about how your own code operates in some corner case and had to say “hmmm, I need to check on that and get back to you”?
**Company:** [SoundCloud](https://soundcloud.com/) **Type:** Full time **Description:** As the world’s largest open audio platform, SoundCloud is powered by a connected community of creators, listeners, and curators who share, discover and influence what’s new, now and next in music and audio. Our team builds, integrates, and maintains the playback stack in all our clients. The team controls playback end-to-end with our custom C++14 embedded player in our native applications. We handle millions of plays and strive to provide a blazing fast playback experience to our users. We are looking for an engineer with solid experience in C++, and a strong interest in learning mobile development in Kotlin and Swift. You can check out this blog post for more info on our player's internals on Android: [SoundCloud is playing the Oboe](https://developers.soundcloud.com/blog/soundcloud-is-playing-the-oboe). **Location:** Berlin, Germany **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++14, Kotlin/Java, Swift/Objective-C **Contact:** PM me on Reddit or apply directly [here](https://jobs.soundcloud.com/job?gh_jid=4352885002).
Fully agree, this is one of the classic cases in C++ where the default is wrong. Simply switching the default would be a huge improvement in my book.
Isn't it funny that [GO lang](https://en.wikipedia.org/wiki/Go_(programming_language)) spec any C++ programer reads like an easy story?
What would you think about making variables without an initializer ill-formed? That is, all of the following should refuse to compile: int i; struct X { int a; } x; struct S { int a; S() {} };
C++ has been around for ... thirty years? ish? And during that time a collection of excellent people did their very best, given what they had. Basically. They never broke it (AFAIK), it's always been fast, it's reasonable memory efficient. Has excellent CFFI :)
I've packaged boost.hana for fun, and modules yield ~10x compilation performance improvement from headers
The standard is 20 years old. Dozens of people have written words that are in the standard, if not 100s. Each word and phrase had a reason to go in there. Usually that reason was not recorded; and even if you wrote it, you might not remember 20 years later. You can easily remember "oh, using a null pointer is UB due to something in the standard" without remembering what lines. Maybe you had that discussion before. You didn't write the lines that make it UB, and the person who did wrote it 20 years ago, and the last time their meaning was changed was 10 years ago by an editorial rewite to bring r/l value nouns into uniform compliance with a new way to word them. And it turns out that if you read the rules one way, dereferencing a null pointer is never stated as UB. But read another it is. Huh. So now it takes acheological examination of standard versions (git blame is just the start) to work out if that was always true and nobody noticed, of if it changed, or was it always true and intended that way? Then someone puts forward a paper to fill that hole, and other text changes in subtle ways around it.
Fun fact : Rice's theorem states that any non trivial semantic property of a given piece of code is undecidable. So it is little wonder even experienced programmers cannot easily decide how a given piece of code would behave
"If you're the smartest person in the room, perhaps you are in the wrong room"
Not that I necessarily disagree, just playing devils advocate: - if I had a function that called std::async and returned a future like object is it not equally concerning? Why don’t I need to annotate that declaration that it does funk stuff with threads/lifetimes? - so then we annotate. But I wrap the function with a convince function. Now there’s no annotation. So what did I gain from the annotation?
I never fully understood this argument. After all, current builds already have ordered dependencies. Sure, modules are a bit tricky because of the module to file mapping, but I don't really see a big practical problem here? Maybe I am missing something, but doesn't one just need to parse the first line of every source file to see whether its a module declaration (can be done in parallel) and then do a topological sort (which is very fast for even for largest real projects). Not to mention that the results can be cached and only redone for files that have changed. With a modern SSD and low-latency filesystem, the cost of this should be close to zero.
Try /r/cppquestions
Hi - this doesnt seem to be a valid url
In this video, One Lone Coder youtube walks you through the 2.5D rendering. [https://www.youtube.com/watch?v=xW8skO7MFYw&amp;t=1s](https://www.youtube.com/watch?v=xW8skO7MFYw&amp;t=1s) His code conventions are terrible (IMHO) but the explanations are great.
I think the language should have required a default from the beginning, but adding that rule now would cause massive breakage. Defaulting to zero-initialization would not cause any breakage (since zero is a legal value for an uninitialized variable). I see some advantages: 1. The language becomes more regular. If you declare something, it is always automatically initialized, whether it is a class with a constructor, or a primitive type. 2. The current forest of initialization rules would be pruned of its most poisonous branches. 3. Software that mistakenly relies on uninitialized variables and works most of the time becomes more deterministic in its behavior. 4. The choice to leave something uninitialized would be clearly telegraphed to the reader of the source. "I _wanted_ this to be uninitialized, I didn't simply forget to initialize it."
Me every time: ¯\\_(ツ)_/¯
There's no legal template for such a thing.
I just used this as part of a maze game I'm making, and it was an excellent tutorial. Why are his code conventions terrible, in your opinion?
Is there such a thing as weakly defined behavior or poorly defined? I know there is well defined and undefined
https://www.reddit.com/r/cpp_questions/ that's on the side bar
Because they're more interested in honing their LaTeX skills.
Please read this first [https://matt.sh/howto-c](https://matt.sh/howto-c) ... Very sobering.
AI is actually chipping away at the profession, so that's not an impossible future. https://www.forbes.com/sites/cognitiveworld/2019/02/09/will-a-i-put-lawyers-out-of-business/#90d733b31f00
&gt; Take your first screenshot for example - there's 16 lines displayed, out of which 9 convey no useful information Even worse: the opened valgrind issue in the bottom of the screen is for line 159, while the code source shows the unopened issue at line 277.
Just glancing on your code, with the first valgrind error, there seem to be a lot of issues: [Here](https://gitlab.estig.ipb.pt/algorithms-and-data-structures/univerza-v-mariboru/assignments/blob/master/Assignment4/binarysearchtree.cpp#L159) valigrind complains the there is a jump based on initialized value. We see that setPoint is initialized to root (which is nullptr by default), and then is changed to either [left](https://gitlab.estig.ipb.pt/algorithms-and-data-structures/univerza-v-mariboru/assignments/blob/master/Assignment4/binarysearchtree.cpp#L162) or [right](https://gitlab.estig.ipb.pt/algorithms-and-data-structures/univerza-v-mariboru/assignments/blob/master/Assignment4/binarysearchtree.cpp#L164). Looking at how left and right are initialized, we can see that the Node [is created here](https://gitlab.estig.ipb.pt/algorithms-and-data-structures/univerza-v-mariboru/assignments/blob/master/Assignment4/binarysearchtree.cpp#L170), but it left and right members ar not assigned nullptr by default, hence the test with undefined value. (That said, the code is very ugly, you [leak a Node pointer each time you call insert](https://gitlab.estig.ipb.pt/algorithms-and-data-structures/univerza-v-mariboru/assignments/blob/master/Assignment4/binarysearchtree.cpp#L149), among a lot of other horrors ).
Tag dispatch, crtp, variadic expansions &amp;nbsp; Very powerful
[Here is my submission.](https://godbolt.org/z/XD-7QI) I didn't take time to make an unique name generator so it will error if you use it twice in the same scope, but that's easily fixable.
[Here is my submission.](https://godbolt.org/z/XD-7QI) Sadly it doesn't work I didn't take time to make an unique name generator so it will error if you use it twice in the same scope, but that's easily fixable.
In the sense of ISO, sure, but they are in the sense that there is one blessed method of package management that everyone uses.
https://godbolt.org/z/uoSTBm Here's my solution from the other thread - it uses a user-defined literal to guarantee that you can only construct a string_literal with an actual literal, because that's the only thing the UDL will accept.
All the same advantages apply to making failure to specify an initializer ill-formed, with the additional advantages that: 1. It is impossible for software to mistakenly rely on uninitialized (non-explicitly initialized) values, since it won't compile; 2. The class of mistakes where an initializer should have been provided is eliminated entirely; a zero default is not always appropriate or safe. As for breakage, I don't think there can be that much C++ code (excluding C-compiled-as-C++) that would need changing, especially if a deprecation cycle were provided.
\&gt;This even happens in talks where actors like Herb Sutter or other famous people sit in and I ask myself, how can it be that there is a room full proficient C++ software engineers and no one can say if phrase XYZ also defines case ABC or not. It's not like physics where we have to find out what the answer is. Not an expert here, but programming languages follow the rules of formal languages. They define grammars, syntaxes, and tokens, but not implementation details or every specific case or scenario. Then there can be debate over whether according to the rules of the formal language, XYZ also defines ABC.
&gt;P0323 std::expected &gt; &gt;One doubt: we have several ways of reporting errors. Is having another method good or will just make our code more complicated and confusing to use? It will be perfectly fine with a throwing expected::operator\*, otherwise it's just another way to the UB land. &amp;#x200B; &gt;P0881R5 - A Proposal to add stacktrace library &gt; &gt;This might be helpful in environments where setting up debuggers is hard This will be helpful literally everywhere - it's incomparably more useful to see a Python-like stacktrace right on the spot than just a string from assert() or exception.what().
If we take Python as an example we have easy_install vs pip, and then virtualenv vs venv vs pyvenv vs pipenv etc What's considered "blessed" keeps changing and there is far from "one way" to do things
Reddit isn't a forum. You're currently replying to yourself. Reddit is threaded. Click the "reply" button on comments. You may want to use [Old Reddit](old.reddit.com) instead, which you can permanently enable in settings.
Unfortunately one can also write an explicit call: `operator""_literal(new char[42])`.
`std::legal::writ&lt;&gt;` is a PITA.
You seem to be saying that 'programming languages' as a category define syntax, but not semantics, and that their definitions are in general not complete. Neither of those is true. Any programming language that actually runs has some sort of definition of its semantics, which is necessarily complete for programs that the C++ standard would call 'conforming'. That semantic definition may be "what result does the reference implementation give?", or it may be the text of an implementation-independent standard. Note that in either case, a program that is 'in the language' in the formal sense but whose semantics can't be evaluated is inherently a bug in the semantics. There can be debate over how to fix the bug, but that's premised on the notion that everyone agrees that the program \*is\* a program with the semantics as given.
Thanks I will definitely check that out, but I am hitting the reply button on the comments, or trying to anyways I’m not sure if it’s fat fingers or this crappy phone, sometimes it works other times it doesn’t.
Terrifying.
Code review of your entry: 1. Following does not trigger the assertion, despite `array` not being a string literal: char const array[] = {'a', '\0'}; ASSERT_IS_STRING_LITERAL(array); 2. Using percentage character anywhere in the string literal triggers a warning: ASSERT_IS_STRING_LITERAL("%"); 3. `__attribute__` is non-standard and will fail with compilers that don't support it.
&gt; For instance, if going off the text along, there is no normative text specifying if a dereference of a null pointer is well defined behavior. Dereferencing a null value pointer is well defined behavior. What's undefined behavior is the l-value to r-value conversion. In other words this is well defined: int* x = nullptr; *x; // no l-value to r-value conversion is performed. This is undefined: int* x = nullptr; int y = *x; // There is an l-value to r-value conversion, this is undefined behavior.
&gt;After all, current builds already have ordered dependencies. As C++ works today, every translation unit is entirely independent of every other translation unit. This property allows for all translation units to be built in parallel. &gt;Maybe I am missing something, but doesn't one just need to parse the first line of every source file to see whether its a module declaration (can be done in parallel) and then do a topological sort (which is very fast for even for largest real projects). No, with modules before you can build a module you must first build all of its dependencies. It's not the construction of the DAG itself that slows things down, it's that once you have the DAG of dependencies, you must now build those dependencies in the order specified by the DAG. If your DAG is linear, then you can not parallelize any of the builds and must build every single module one by one. That's not the case with how translation units currently work, where as I mentioned before, every single translation unit is entirely independent of every other translation unit and hence they can all be built in parallel.
No, you didn't discover it. You wrote this garbage advertisement disguised as tutorial.
And he didn't even try to go by a different name on reddit lol
Here is something a bit shorter doing the same thing (I think): #define ASSERT_IS_STRING_LITERAL(x) static_assert(true, x);
Following triggers no warnings, despite `array` being a non-static local (and furthermore not a string literal). constexpr char const array[] = {'a', '\0'}; ASSERT_STATIC_LIFETIME(array); Except on clang, which produces: error: reference to local variable 'array' declared in enclosing function
&gt;It will be perfectly fine with a throwing expected::operator*, otherwise it's just another way to the UB land. What wrong with it having UB `operator*` and throwing `.value()` like `std::optional` does?
Correct, this was clarified in a core langauge (CWG 2xx, I don't recall from memory), which is why I said *from text alone*. The wording says that it is "an lvalue that denotes the object or function the pointer points to" or something to that effect, but the issue with that is with a null pointer value, it does not point to an object or function, therefore from just reading the standard one might think that it is UB.
The C hacker in me wants to just check the pointer to see if it points to the data segment rather than stack or heap, something that should be easy (and non-portable) enough if you know what platform you're targeting. It's probably no different from checking if it's `static` (or perhaps `constexpr`) however, something I've seen others here try using more elegant methods. :-/
Oh shoot, really? I had no idea that you could call a UDL operator directly, TIL!
No, but I think the closest thing to that would be unspecified behavior, but unspecified is still well defined. https://en.cppreference.com/w/cpp/language/ub
Nice catch! /u/skreef 's version seems to hold.
Yeah. When I read the OP, I was really doubtful that it would be possible. Since there is nothing special about literals, they cannot be detected through inspecting arbitrary expressions. But that solution expands into syntax where the grammar specifies string literal specifically, so it seems solid.
Love a bit of PVS-Studio - it’s exceptionally useful in the editor compared to clang-tidy and cppcheck extensions. I’m quite fond of an install where the license limits the number of clicks rather than the validity period. But only I use it here (199 clicks!). It’s seen as hindering development, and some even prefer writing manual code checks rather than suggested (and standard compliant!) corrections. Weird.
Oh I didn't know that this was not part of the normative text. I see your point then.
&gt;What's wrong with it having UB ["apparently there's not enough of it in the C++ language"](https://youtu.be/PH4WBuE1BHI?t=1881)
[removed]
kek
**Company:** [Improbable](https://improbable.io/), London **Type:** Full time **Description:** Help us build a new simulation runtime optimised for deterministic and faster than real-time simulation execution, which forms the core of our military simulation platform. This is a completely new approach, optimised for operational planning and wargaming in complex probabilistic simulated environments. You will join a small, experienced team, central to our product offering with significant scope for impact and ownership. The work that you do will allow tacticians to execute large numbers of simulations concurrently; something that will radically improve the status quo. Our core engineering teams are focussed on building complete product solutions to tough engineering problems. Overview of our division: [bit.ly/2lt8DnI](http://bit.ly/2lt8DnI) **Location:** London, UK **Remote:** No **Visa Sponsorship:** Dependent on Location. **Technologies:** Mainly C++14, with some Go, Bazel, gRPC and Protobuf thrown in. **Contact:** PM me on Reddit or apply directly [here](https://improbable.io/careers/opportunities/software-engineer-distributed-simulation-enterprise).
Is there any reason to have concerns about the future adoption of [P0709 (Herb Sutter's exceptions proposal)](https://github.com/cplusplus/papers/issues/310) if `std::expected` is accepted into C++20? Given a choice between the two I'd much prefer the former.
Unfortunately `-Wuninitialized` [is not very reliable](https://gcc.godbolt.org/z/sZI4gB).
\+1
That is not answer i looked for, but thanks anyway. I feel like only me is using boost of 1k members currently online on subredit.
Eh, that's a good reason to use more than one compiler in development and testing.
Looking at it this way is missing the point: Even in today's translation model, the compilation of the code in foo.cpp depends on the compilation of other source files: Headers. The two difference are: 1) The compilation happens in the same process and 2) The compilation happens again in each translation unit that uses that header directly or indirectly. Now, 1) is usually more efficient, than compiling each "header" (or module interface unit) separately and communicating the information between the compilation via build artifacts in the filesystem, but the fundamental ordering doesn't change and in fact, it would be a totally valid implementation of modules (albeit not avery sensible one), if `import foo` would cause a separate compilation of the module foo for each translation unit, just as an `#include "foo.h"` causes the code in "foo.h" to be recompiled.
Google some features you learned and check when they were introduced.
If you took an intro class, there's no student-relevant difference between 11, 14, and 17.
[here is a comprehensive overview of when which feature was introduced](https://github.com/AnthonyCalandra/modern-cpp-features)
It doesn't need to be language fundamental. Broadly useful is enough. As far as I know this proposal comes from the new machine learning study group.
I prefer that method, I don't like to take risks just because some "elegant" method is going to fail silently just because the compiler flags changed.
id like to participate, if something like this happens
I took an intro class and an 'advanced programming techniques' class which taught us how to use structures, classes, some sorting algorithms, overloaded operators, mix/max templates and a couple other things.. that's the furthest the school taught
Well... then Python is not a newfangled language with package manager :)
To be honest, I am also concerned about the idea of `flat_set`. A naive sorted vector has linear insertion/deletion performance -- O(log N) comparisons, but O(N) moves. This seems like it could easily trip up people. Furthermore, even if its `find` function has O(log N) complexity, it manages to touch log(N) cache lines in the process, whereas a different layout (Eytzinger, for example) will have better cache behavior... at the cost of contiguity. In the end, I am not sure of the "niche" that `flat_map` and `flat_set` intend to cover; and whether they warrant inclusion in the standard.
probably 98 or something.
Fair, `flat_set` may not be the answer to the problem. It's still a major sticking point that `std::unordered_map` is essentially hamstrung by the standard to make performance sacrifices for what I believe to be the wrong reasons, or benefits that aren't terribly important to many of its potential users.
Even in these topics there is not that much of a difference between c++98 and c++17, but if you want to know i would recommend just emailing your teacher.
i tried, he doesnt work there anymore. The book we used was "Starting out with C++: From Control Structures through Objects, seventh edition" by Tony Gaddis. Can't even find in the book which ISO it is.
Given it was published in early 2011, it's safe to assume that it taught C++98.
damn. i got some catching up to do
Did you ever use the syntax: for (Thing thing : things) { // loop over things... } (as opposed to an index or iterator for-loop)? If so, then you learned at least C++11. Same if you ever used something called a 'lambda', or learned anything about 'move semantics', or `constexpr`. As a beginner, you won't know the difference between C++11 and C++14, so don't worry about that. You probably didn't learn C++17. Still: did you use types such as `std::optional` or `std::variant`?
I would just look through what you know and compare it to each c++ version’s “patch notes.” For example, the “auto” keyword came out in c++11 so if you have used that, then you have been coding in at least c++11. This following link lists some things you might find useful. https://smartbear.com/blog/develop/the-biggest-changes-in-c11-and-why-you-should-care/
another user pointed out i likely learned on the 98 standard. I haven't done any std:optional or std:variant but I do remember using constexpr so that a value could be evaluated at compile time and reused as const in other functions (i think?) &amp;#x200B; never used that style of for loop either, there was always an iterator
Another test: - take some code you wrote for the class - do some googling and figure out how to modify which C++ version you are compiling in your build script - try compiling with no flag/option, with a `-std=c++11` flag/option, with `-std=c++14`, etc. If it works with all standards, then you probably learned an old C++. If it only starts working with a certain recent standard, then that's what you learned. This method isn't foolproof though, since you may not exercise modern code in the snippet you choose
All C++ language iterations have been built on previous versions and in general, backwards compatible. C++11 and beyond introduce new ways to do for loops, but the basic for loop hasn't changed. A few thing introduced in stdlib, and were later deprecated (auto\_ptr was deprecated, and unique\_ptr replaced it with better functionality). Let me turn it around for you and state the major functional changes that divide the pre and post C\_++ world: \- Move semantics. \- Smart Pointers (shared\_ptr/unique\_ptr). \- Anynomouse Functions/Lambdas \- Threading Model in the language. \- Auto type deduction. \- Increasing set of algorithms that operate on stdlib container classes. As would be expected with an intro level course, it likely didn't delve deep enough to make a meaningful differential on what version you've used.
VS's intellisense is stored in a SQL Compact database – I've not tried, but you could probably query it directly for such things fairly easily.
https://gist.github.com/MattPD/9b55db49537a90545a90447392ad3aeb
Ah, probably C++11 then; `constexpr` didn't exist before that. Also, your summary of what is does is basically correct. Pretty good for someone who's learning. A lot of people struggle with the concept.
Incrementing gang stand up!
I've never fiddled with the compiler settings in Dev-C++. Professor said it easily breaks on \[this specific version we use\]( https://imgur.com/yB79fPQ )
Thanks
That's programming for you: you must learn to Google and figure out how to change stuff. People on the web are happy to tell you what to look for, or what your problem *might* be, but we generally appreciate if you're willing to do the legwork. We're busy people after all, and I haven't personally used Dev C++ for about 9 years I think
[Maritim Hotel Köln, Cologne, Germany](https://maps.app.goo.gl/NkYQgmho52mBrxj19).
Great, the [Coroutines TS Customization Points](https://hackmd.io/@b2TYiDA_TdSl8aW3--X10w/S1H_loeA7?type=view) makes things much clearer.
Given that the 9th edition talks about introducing C++11, I would say you definitely learned C++98. &amp;#x200B; [https://www.abebooks.com/9780134400242/Starting-Out-Early-Objects-9th-0134400240/plp](https://www.abebooks.com/9780134400242/Starting-Out-Early-Objects-9th-0134400240/plp) &amp;#x200B; "Building on the popularity of previous editions, the **Ninth Edition** has been updated and enhanced with new material, including C++11 topics and recent changes in technology."
&gt; otherwise, the page would have been titled "What I would like to share about my compile-time reflection library for C++ - refl-cpp" and it wouldn't be very tempting to click I'm not sure why you think this way, but FWIW I would be far more likely to click on that \[honest/relatable\] title. Decades of internet use has resulted in reflexively avoiding anything that sounds like spam/bullshit, zero thought involved. That said, I didn't interpret your title that way at all. It starts with the name of a library, then refers to it as "the library" – this is just how articles work...
&gt; otherwise, the page would have been titled "What I would like to share about my compile-time reflection library for C++ - refl-cpp" and it wouldn't be very tempting to click I'm not sure why you think this way, but FWIW I would be far more likely to click on that \[honest/relatable\] title. Decades of internet use has resulted in reflexively avoiding anything that sounds like spam/bullshit, zero thought involved. That said, I didn't interpret your title that way at all. It starts with the name of a library, then refers to it as "the library" – this is just how articles work...
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
My understanding is that it's just hardcoded, and we hope that no DLLs will attempt to inject themselves there. (I believe they have to disable ASLR for this.) This is one of the reasons that the /Zm option was added. I also believe they added a "chained PCH" feature later, to use non-contiguous memory, but I'm not 100% sure. (Not a compiler dev.)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I've manually approved your comment. In the future, please follow the instructions and don't use URL shorteners, to avoid triggering the spam filter.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/cdcg07/valgrind_problem_solving_issues/etumy9m/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/cd5ahj/is_there_a_way_to_call_a_python_script_from_c_code/etumzae/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Oh I fully agree. It's always been my understanding that `std::map`'s memory stability were just an implementation detail that leaked into the standard, and then `std::unordered_map` kinda inherited them (though only partly) so as to be as "drop-in" as possible. The end result, unfortunately, is sub-par performance (and high memory overhead) for both of them for a niche feature that is rarely used, which seems quite backward :/
Thanks
https://github.com/luncliff/coroutine/wiki#deveoper-notes
See https://www.scylladb.com/open-source/ for communication channels
Ah, that is what you mean. I don't see much of an issue here to be honest. These kind of dependencies exist today and they are called header files. If you rely on any kind of generic programming, be it the standard library or any of the template-heavy dependencies out there, you are already throwing most of parallelism out of the window, since you have to parse and process all this humongous amount of stuff for every single translation unit you are building. I just don't see how modules will be inferior to this model (of course, after the initial kinks are worked out and the implementations are more optimised). If your codebase is such that you can build units in parallel, you will still be able to do so with modules. If you code is like mine, where there is just a huge load of template-based header "libraries" and you end up amalgamating everything into one big source file anyway, you'd at least get extra benefit from caching the pre-parsed AST. And finally, we live in the age of whole-program optimisation. I believe that in face of LTO and other goodies, the concept of translation unit is starting to lose its purpose. One should explore the ways of parallelising the compiler itself and not relying on single-threaded compilation of independent files for parallelism.
Link to slides?
If you used gcc and you know the compiler version, you can find its feature list here by C++ version [gcc cxx status] (https://gcc.gnu.org/projects/cxx-status.html)
No worries, I just meant to point to you the right place to ask this question, so that you can get a good answer. Here is not the right place. Also in my experience I never had problems with Boost.Process (async)streams.
Designated initializers. Finally.
Thanks, I'll keep you in mind when next I'm available to that degree.
Well, last part is what I expected. Members who has experience with Boost.Process (async) streams to comment about the code. Extra comments about boost is just mu disappointing about lack or poor documentation about library. This is basic example of how should work but I can not see what am I missing. I am not beginner in c++ but lack of documentation introduced me as a beginner.
Well it's the same in JavaScript. All major languages share the same problem. Only some of the smaller ones manage to keep a coherent ecosystem, and that's just because they're still small.
I (the author) would love to hear your thoughts on it. What is the use case that you would consider refl-cpp for and why? Would you like to see more examples/documentation? Also, I would be happy to answer any questions about the implementation and/or the reasoning behind it.
Thanks, same story with other subredits or StackOverflow, topic does not matter. Because there are too much experts, internet become place where you do not have space to share experience or read about. I have seen at least 10 posts in r/cpp that can be sorted in same category as mine. But hay, they probably know some of your colleagues or have good karma. So, they have no worry to posting any kind of post.
&gt; I have seen at least 10 posts in r/cpp that can be sorted in same category as mine. Feel free to link to them. Or, instead of coming up with nonsense conspiracy theories, you could just admit this doesn't belong here and we have another subreddit where people are more than eager to help you with your problem.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The problem with that view is that there is no package management solution that fits all and thinking that yours is the total winner is a bit naive (same with build systems). Having the ability to progress things is a crucial trait for the ecosystem. Standardizing the implementation is really a pointless endeavour, not even considering making people in the committee agree on something. On the other hand, standardizing the common language for these tools to speak with each other would make a real difference. Allowing people in different domains to move their projects from one build system/dependency/package manager to another depending on the requirements. Like, take for example system package management on Linux distributions. A great thing for stability, security. Is it a great thing for development? Not really, people are trying to hack things into the system all the time because they need new stuff. So we need some other solution, but again, who is to decide which should be the standard? It's just better to make it easier to pass projects around ecosystems, honestly.
I have probably spent more years in programing then you are years old. Just not familiar with boost.process doe to a lack/poverty of documentation about newer releases of boost. So I used r/cpp to find peoples who has experience with it. In r/cpp_questions and similar you can not find such answer. There you can find answers about syntax.. etc... but not about changes or new features of library. You should first ask your self if post can get response on subreddit you recommend before you recommend over if post is suitable for your subreddit. Back then, anyone was able to learn programming by self and experience sharing was on decent level. Today, everything is censured so this subbredit should not be an exception.
I learned Visual Studio 1.52c
Generic lambdas? Structured binding? CTAD? `to_string`? `from_chars`? `optional`? `variant`? `any`?
IMHO, linear algebra in the standard is pretty important. Not because we need a standardized replacement for eigen or glm, but because there are so man libraries that deal with 2d or 3d coordinate systems and each one having their own, incompatible MathVec class. I'm with you that we don't need statistics functions in the standard, but on the other hand, they are a nice to have, low-effort addition (I mean quite a lot of the standard algorithms are not really that important, but they are still nice top have)
If only you spent 1% of the time you learned programming in social skills... You have decades of programming but still can't differentiate between then and than? We're all programmers here and we all face problems in our projects on a daily basis. You don't see us posting them in r/cpp because that's simply not the place for it. &gt; You should first ask your self if post can get response on subreddit you recommend before you recommend over if post is suitable for your subreddit. Yea, that's not how this works. Not being suitable for /r/cpp_questions doesn't make it suitable for r/cpp.
There is pretty good way to tell if you were taught pre-C++11 or past, but other than that, asking if you've learned C++11 or C++14 or C++17 is akin to asking if you've learned Python 3.3 vs 3.4 vs 3.5. It doesn't make much sense. Something like "were you taught any feature introduced in C++XYZ standard?" is a better question that can usually be easily answered.
The nice that they are supposed to cover are primarily small datasets. I can think of many applications, where I only have a dozen or so entries in my map and flat set/map are quite useful in such situations. Also iteration is very efficient. Let's face it: In the end, standard consumers are not designed top give you optimal performance in specific scenarios. They try to be a compromise between ease of use, safety, flexibility and performance. If you need absolute best performance under a specific workload with a specific subset of types, you will most likely use a custom datastructure anyway.
Smart guy but I don't see his audio proposal going anywhere.
&gt;If only you spent 1% of the time you learned programming in social skills... I am not trying to skill you. Just saying that there is no place where self learned programmer can share or read about experience on the internet anymore. In my environment I do not have peoples with which I can talk about programing or any related, so internet is my only place where I can try to get information. Over the years, learning on the internet become difficult since you are limited to only searching for shared experience by others and not share yours. And shared experience these days is more/less about announcement what is new and what it old but most important that they feel like heroes when they do it because they are announces "free" code, but it all efforts are useless without proper documentation. It just expose tons of security risks for people who trying to make things work. I do not share much because of this specific reason. I get blown on first loop when I trying to make a point because I shows up from nowhere as anonymous.
I think it's because you're specializing the class without an actual class specialization.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
From the VC++ cross-platform team chiming in. Appreciate the feedback. I agree that parallel compilation support is needed (and probably from msbuild aka the toolchain, as you mentioned!). Thank you for checking it out! /u/soldieroflight /u/itsarabbit
The most relevant things to focus on are in C++11. Remember that it took from 2003 to 2011 for that version to be released. The next version with as much impact may be C++20. Not to say that the versions between don't have amazingly important additions, but none of them impact the fundamentals of the language as much as the additions we got in 11 like move semantics and smart pointers.
Do you think it will have the same fate as the Graphics proposal?
&gt; I think that's OK - people putting things in a certain way for them to get more publicity You mean click bait, you are in favor of click-bait. Many people (including myself) deeply frown upon that because it is dis-honest and treats the consumer as something to toy with. Which is a shame, because your write-up seems pretty good and the material is of interest, but I have to echo what /u/Xaxxon said (in a much less needlessly abrasive tone).
And for the people stuck on previous versions; a simple C++11 macro: #define instantiate(T, ...) ([&amp;]{ T ${}; __VA_ARGS__; return $; }()) struct S { int a, b, c; }; S myS = instantiate(S, $.c = 42);
Why can't we have C ones, though? The C++ ones are more constrained.
Even closer to the real thing: https://godbolt.org/z/KakWtO #define INIT_IMPL(r, data, elem) $ elem ; #define init(T, ...) ([&amp;] { T ${}; \ BOOST_PP_SEQ_FOR_EACH(INIT_IMPL, , \ BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__) return $; }()) struct S { int a, b, c; }; S myS = init(S, .a = 3, .c = 42);
Does anyone have a good summary of "the big things" to recommend?
Don't look at me. I just started learning C++ a couple of weeks ago. So technically, I'm still on C++03!
How does new/delete in constexpr work? I mean usually they have side effects in their underlaying implementation? Special implementation with is_costexpr_evaluated in new operator?
That’s basically an implementation detail of the compiler I think. It probably allocates memory in its heap and sends the pointer back to the constexpr context, but that’s just a guess
Why add the extra lines (there will be two) instead of making the combination keyword "enum switch"? Perhaps with the latter, compiler implementations can find it easier to not tell me my function can reach a non-returning state?
False and false.
I want: int x=0; int y=0; to be the non-error option. Ctor can override it. Maybe an attribute for explicitly uninitialized.
I guess I missed the point that new/delete behaviour is defined in the standard. So if I p.e. Preload a malloc implementation there is no guarantee that it will be actually used.
I assume you mean preload into the compiler call? Yeah, I wouldn’t make any assumptions there even as there’s no guarantee the compiler even uses malloc in the first place. Also as an aside while operator new is constexpr malloc is *NOT* since the compiler can’t guarantee no undefined behavior when malloc is used in your code. That’s because unlike with operator new malloc doesn’t know what type of object the memory is being allocated for and thus the compiler can’t guarantee what the memory is being used for.
Initialization order matters in cpp, while in c such things don't exist. He mentions that
`new`/`delete` in constexpr code does not call any overload operators nor does it call any standard runtime implementation. These are internally allocated in the compiler and then emitted into the static data section of the final executable.
I am certain that there are ways to make that work, and it isn't particularly hard for the compiler to know if the order matters or not.
I will definitely check out. The actual cpp I rarely code at work is ancient shit with qt. But the new stuff and the ideas those guys have always keeps me faszinated.
This has to be done at runtime, no static/compiletime assert would work reliably. In your entry i don't see why \`input\` argument can't point to a string literal, but \`test("Hello")\` has to be called at runtime to assert this simply because there could be condition as in \`test(some\_bool ? "Hello" : heap\_pointer)\`. However you can possibly create your own memory allocator(s) and track allocations there, or instrument your binary with your own replacements to standard allocators/deallocators. If it's in allocated memory then it's not static, this is what this kind of assert has to check. This is not going to be an easy solution like in three lines of code of course and i'm not sure how portable that would be or if this would cover all corner cases.
Is he correct at 16:28, when he mentions that such usage is UB? It sounds strange. Shouldn't the lifetime be extended in that scenario?
Could be any version of C++ from the 90s on really.
Expansion statements - yes, that is awesome!
He is wrong. `getUsers` returns an lvalue reference, otherwise his C++17 solution wouldn't work. Range-based `for` handles that perfectly fine. Even if `getUsers` returned a temporary, range-based `for` uses `auto&amp;&amp;` to capture the right hand side expression, and the lifetime is extended, exactly as you would expect.
**Type:** Full time **Description:** 3 years of experience at a large cloud services provider. Experience in developing distributed systems, network protocol design and real-time software. Hoping to work with high-performance or constrained systems (devices, video games etc). Worked on multiple projects for the open source game SuperTuxKart, wrote a personal game engine for a multi-semester long Masters project, internships at two game studios. Have a Masters in Games Engineering and Bachelors in Computer Science. Also experienced with robotics, ML and computer vision (hobby projects). **Location:** Seattle, WA. Will consider remote work. **Visa:** H1-B (already have but you must be able to transfer) **Languages:** C++, Python, C#, Golang, Ruby, Java **Contact:** PM
&gt; **”** method to assert that a pointer to a character array refers to a string literal On the surface of it it is a self-contradictory requirement, since where you have only a pointer, the information about original type and token kind is lost. Some creative interpretation of what the goal is, is IMO therefore necessary. I see two possibilities: * *Asserting* via a macro that the argument is a string literal. This is trivial to do, but is only useful in macros. * *Detecting* in ordinary portable C++ code that smt is a string literal. As far as I know this is impossible. --- One trivial solution to the asserting-in-macro is to concatenate string literals at compile time. #define ASSERT_IS_STRING_LITERAL( s ) (!!s "") auto main() -&gt; int { ASSERT_IS_STRING_LITERAL( "Blah" ); ASSERT_IS_STRING_LITERAL( L"Blah" ); ASSERT_IS_STRING_LITERAL( u8"Blah" ); ASSERT_IS_STRING_LITERAL( u"Blah" ); ASSERT_IS_STRING_LITERAL( U"Blah" ); #if defined TRY_INT ASSERT_IS_STRING_LITERAL( 42 ); #elif defined TRY_POINTER const char* const p = "Blah"; ASSERT_IS_STRING_LITERAL( p ); #elif defined TRY_ARRAY const char a[] = "Blah"; ASSERT_IS_STRING_LITERAL( a ); #endif } This generates a syntax error for a non-literal. One may use it e.g. in a macro that generates an instance of something that *represents* a string literal, so that this macro can be used as a kind of literal notation for arguments to functions requiring string literals as arguments. --- For the case/interpretation of a non-macro string literal detection: After syntax checking a string literal is an lvalue expression of type *Char* `const[`*n*`]`, where *Char* is one of the built-in character types. I see no portable way to detect the original literal-ness of that. In particular rvalue references don't help.
C++11-98...so, C-87?
It depends on what the methods involved return. [These quick examples](https://godbolt.org/z/5tdZh1) show how returning a temporary probably wouldn't result in the behavior that you want.
So, 14/17, without the 20 bits, are minor releases feature-wise.
It is NOT clickbait. Clickbait is meant to be deceptive - my post is not deceptive. The structure of the sentence is the following - I mention "refl-cpp" (the name of the library), then I say "a deep dive", and then, since I have already mentioned the name of the library, I use "to" to refer to it. Lego - The Movie - is it clickbait? Are they saying this is the ONLY movie? #relatable I do not endorse clickbait in any shape or form. I do not endorse people who have no other job than to participate in a meaningless discussion rather than staying on point. That is why I have reposted this post in another thread - to stay on point. Anyhow, I changed the title of the post in Medium almost immediately, because I would hate for my article to get bad publicity for any single thing, even if someone has simply decided that he doesn't like the article used in it. What has happened though, is that people find it more interesting to discuss a hypothetical (and nonexistent) error in the title of the link of the post only, than the contents of the article, or god forbid, the main subject of the article.
much better title.
The title would be too long. People scrolling all day on the web these days..., it makes some of them scan only the first few words of the sentence. That is why I started with "refl-cpp", then added "- a deep dive", and later on referred to the library with "the". Spam filters are sometimes wrong. The only reason this comment thread exists is that somebody used the word "click-bait" and everyone who thought they have something to say about clickbait decided to do it without thinking about whether it is or it is not. I have reposted and really, really wouldn't want to ever be involved in such a discussion about grammar and opinion about clickbaity-sounding things ever again (esp. on reddit). &gt; That said, I didn't interpret your title that way at all. It starts with the name of a library, then refers to it as "the library" – this is just how articles work... Thanks for that.
If `getUsers` returns an lvalue reference to a temporary, `auto&amp;&amp;` [will not help whatsoever](https://en.cppreference.com/w/cpp/language/reference_initialization#Lifetime_of_a_temporary): &gt; a temporary bound to a reference parameter in a function call exists until the end of the full expression containing that function call: if the function returns a reference, which outlives the full expression, it becomes a dangling reference.
They aren't emitted into three final executable assay all. All memory that it's "allocated" during compiletime also has top be reallocated during compiletime.
Again this topic, implemented with macros. If macros are allowed there is no need for C++17.
It would have been much better if you would have covered map, multi map and set. &amp;#x200B; Both range-v3 and boost range are compile time wrappers around standard iterators. So, performance will always be same.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/cdt8ab/looking_for_some_help_with_file_transfer_via_qt/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Please, explain yourself. How does the C++17 standard directly involve any changes to preprocessor macros? What refl-cpp provides is not implementable without them. Please, see the deep dive post for information on the implementation details.
It looks good. However, I think it is unfortunate that a custom preprocessing tool is introduced into the build chain, and this would be a reason for me to avoid this solution. The reason is that custom build steps, particularly ones that have complex dependencies like LLVM / libclang, are one of the foremost obstacles to the portability of C++ codebases. It's usually easy if you are targeting only Linux or macOS, but significantly harder if you also want to support Windows. You now have an additional compiler version dependency, another set of flags, etc. If you want to do cross-compilation, that has now become even harder than it already is. Very mature preprocessors, like Qt's \`moc\`, go through a lot of trouble to mostly solve the problems above, including that it provides its own build tool (\`qmake\`) to simplify the process. That seems way out of scope for this project. Side note: In the Rust ecosystem, this problem has been solved by formalizing a way to inject code into the compilation pipeline (\`proc\_macro\`), allowing libraries to define "plugins" that can modify the AST arbitrarily. Standardizing something like that for C++ would be a tremendous undertaking. Maybe in C++30.
Is this in building boost.hana or using it from another project? I assume this is using clang modules (implicit builds) rather than an explicit module build (since I know of no build system reliably doing header units properly in explicit mode)?
The C++17 does not change preprocessor macros. My point was that if you are using macros, you might as well implement the reflection as C++03 or 11 for wider adoption. This might be an unpopular opinion, but from my PoV, using macros kind of waters down the "reflection" part, as you are essentially describing the contents of your types semi-manually to the system. In languages where reflection is actually possible, one can reflect types without any pre-written boilerplate.
The preprocessor's usage is **optional**. It was added later on as a complementary tool due to user demand. I am aware that it might impact the portability of the codebase by a tiny fraction. I would like to mention that, of course, the preprocessor is only needed on a dev's machine and *only* depends on libclang. refl-cpp targets C++17 and up and it is very unlikely that somebody who has access to a C++17 compiler has trouble building a tool that depends on clang. But if you don't have support for recent C++ standard revisions I would obviously recommend that you seek a different solution. And yes, Rust's proc_macro is amazing.
&gt; to topologically sort a random DAG of 10000 nodes and 124543 edges) It's not the DAG sort that's the bottleneck. It's gathering the information to do the DAG sort that is the bottleneck. With headers, you just need to compile and get "what files were read?" from the compiler. With modules, you can't *start* compilation until required modules are available. Discovering where those modules come requires scanning source code. That's where the DAG contention comes from and the "new feature" required of build tools (build-time DAG sorting by adding build-time discovered edges).
That would not be possible. Refl-cpp depends on the wider constexpr availability in C++17 for some of it's compile-time features. I would have to severely reduce the usability and feature-set of the library in order to provide support for these older versions. Besides, with the new schedule of the C++ committee (rolling out new standard versions every 3 years), everyone is going to be on the C++17 bandwagon sooner or later. For those that don't have access to recent C++ versions, I would obviously recommend looking elsewhere.
( cc /u/suthernfriend ) &gt; I am certain that there are ways to make that work I agree! Or rather I don't think the usual concerns stated are, uh, worth being concerned about. I laid out my reasoning here: https://www.reddit.com/r/cpp/comments/c429ta/cnow_2019_michael_park_pattern_matching_match_me/es2e9r5/?context=3 tl;dr the language rules are currently backwards. Member init lists should be a hard compiler error if out-of-order, designated initializers should reorder, optionally with a warning (ideally the warning would be smart, like not complaining if all the types are initialized with constants or other expressions determined to not be order-dependent). The committee can't fix member init lists, but it can fix designated initializers.
Why would parsing the first line of the source file be such a bottleneck? Not to mention that you can cache the information and just update the changes the next time you build? I understand that the process is more complicated and that it requires support from build tools, but again, I fail to see the big problem.
Ok. I admit not reading the full article. I'm definitely one of those people who saw the first example littered with macros and closed the article. I have seen tens of projects doing something similar and my synapses fired - before I knew it, the tab was gone.
Another important point that I need to address for anyone who has \*\*portability concerns\*\*. If a project decides to use refl-ht, and later wants to stop using it due to incompatibilities or whatnot, that is fully supported. refl-ht generates metadata files that are compilable with any compiler supporting refl-cpp (it generates the macros that a user would otherwise have to manually type out). The generated metadata files can then be used without the preprocessor. So one can go from manually typing out the list of members (refl-cpp only way) to refl-cpp + refl-ht to refl-cpp only again.
That's totally understandable :)
Generic lambdas seem really nice :)
Yes, it isn't hard, it's impossible, given the current compilation model. The only thing you can do is make the compiler very conservative and only allow reorder for trivial members. This means that a member becoming non trivial would be a huge breaking change which is worse than the current situation.
It depends on what getDatabase() and getUsers() return. If getDatabase() returns a value and getUsers() returns something which is referencing into the database value, then its UB. If getDatabase() returns a reference to an object living somewhere else, getUser may reference into it perfecly fine and no UB is involved. Or getUsers() can just return something by value. Then its also fine, because we get lifetime extension
have you already seen cppcoro?
I took a look at cpproro, but had hard a time understanding something like: co_yield co_await std::forward&lt;AWAITABLE&gt;(awaitable);
I've now reverted the code of llvm2019 to the code of LLVM Compiler Toolchain, since the llvm2019 extension removed llvm-lib.exe from the toolchain [I gues one of the slight modifications], which is required to use LTO for static libraries. The code is [here](https://github.com/degski/llvm2019).
In my opinion, audio needs an API like Vulkan is to graphics. A cross-platform low-level API with modern hardware in mind that plays nicely with C++. As to why the audio proposal still has a long way to go read the feedback by Apple P1746R0): ..."The design in P1386R2 does not address several important areas." ... "An audio interface design that does not take into consideration audio routing and policies will not be an interface upon which large scale portable systems can be created." ... "Is the proposed API failing to be a general and portable interface? Does it leak too much of the underlying platform specifics?" ...
Each of "the big things" requires its own talk (or several). If you'd like an overview, take a look at [C++20 in Breadth](https://www.youtube.com/watch?v=tczJe5YGHuc) by Alisdair Meredith.
You don't need a package manager that can be a 100% solution for everyone you just need to make a standard for 99.9% of people. If i want to do something that's non standard then I can go back to writing makefiles. I have spent the past day getting something to compile on windows that works perfectly on Linux because of either a bug in cmake or because of changes in the latest visual studio c++ compiler. Not sure which and sick of trying to find out so wont be using that library. while in rust land I can just add 'actix-web = "1.0"' to Cargo.toml and I will get all the dependencies exactly as the developers wanted for a fully working cross platform webserver with ssl, http2 and websocket support. Can anyone point me at something that does the same in C++ land ?
IMO, should be something like: class Foo default { ... }; template&lt;class T&gt; class Foo default(condition) { ... }; ...and then support "using default(condition)" to set a default for types defined in a namespace. Could also support "void Foo() default { ... }" for function locals.
First line? You need to scan for all `import` lines too.
There is a paper in flight that will add an annex to the standard with all points of undefined behavior referenced in the standard. It's in the latest mailing.
Note that you can have some free memory after deallocation but still got allocation failures due to memory fragmentation. Also there is no guarantees for 3rd-party code in low memory condition.
You most likely have never seen a big codebase in your life if you can say this ? File IO, especially small reads such as "read the 1st line" is expensive. Very expensive. Also you need to look for imports, not just exports. And yes you can cache the results. But time to first run is very important too. Consider the compilation time of your CI.
You are right. I must have had a particularly bad brain fart. I didn't think about imports.
He is right, but the “fix” in the new standard seems odd. Instead of introducing new syntax, why not just extend the lifetime of the temporary for the scope of the \`for\` loop? This would prevent a lot of accidental UB, be completely consistent, and 99.999% of the time it’s what the user wants (scratch that — *100%* of the time). Introducing a new syntax (`for (init; loop head) …`), while now consistent with `if (init; condition)`, seems completely unnecessary and, as mentioned by somebody in the audience, gratuitously verbose.
Ugh, the section you cite reveals another ugliness: Even in C++20, there’s a different between direct-initialisation and list-initialisation of aggregates. After Timur went on about how unified these two will be in C++20 that’s a disappointment (and it’s completely unclear what purpose this distinction would have).
&gt; compiler implementations can find it easier to not tell me my function can reach a non-returning state Unfortunately, variables of an enumeration type can contain integer values that don't correspond to any value inside that enumeration, so there's no really no way around having to add a default return after your switch.
On my machine (MacBook Pro) concatenating all the files in the LLVM monorepo (100k files, 2.3 GB of data) takes 13 seconds. Running grep for \^import on all these files takes 19 seconds. True, I completely forgot about imports (me being dumb), but we are talking about what, 20-30 seconds overhead here on a 2GB codebase? In comparison, the initial make run takes well over a minute.
It's hard to figure out what 99.9% people need, really. No one knows what all C++ programmers do and their requirements and risking all (since you can't just pull your solution out of the standard just like that) to follow a blind guess sounds very much like a wasted effort. Even the notion of standardizing something that none people in the committee have experience with is funny, though we have examples of such fiascos. The committee are not magicians, they are the same programmers like you and me, they can't just pull the perfect solution out of the box, even though many people in the community have been trying to work out some solution. But there are much more problems aside from existing solutions being non-standard. A lot of existing languages live happily with community-driven package managers and are free to move to a different one if the are problems with the existing one (npm). As you noted, a lot of existing C++ projects are written only for the set of platforms their authors were bothered with. The ecosystem is very fractured and the fashion of building cross-platform libraries is a fairly new one. Vcpkg and Conan are trying to work out a solution, they are not perfect, but are improving very fast. You can check them out (you can start with vcpkg, it's fairly easy to bootstrap, Conan requires more time to start). But again, I would laugh at anyone who would think that non-domain experts in the committee could figure out something better than experts who have actual experience with the ecosystem for many years. Anything somewhat good requires an actual user experience, not just a few toy projects on github.
vcpkg only has the latest versions of some dependencies. I'm not on boost 1.70 for my project yet which is all vcpkg has so i'm stuck. its not a great solution for this. Its cant be that hard to get conan, vcpkg, cmake and others to talk about what a standard c++ project should look like and how it should be built. Currently wasting my time getting Clucene to build on windows instead of writing business logic which I'm paid for. vcpkg is no use here. `PS D:\vcpkg&gt; .\vcpkg.exe search clucene` &amp;#x200B; `If your library is not listed, please open an issue at and/or consider making a pull request:` [`https://github.com/Microsoft/vcpkg/issues`](https://github.com/Microsoft/vcpkg/issues)
I'll admit I've read nothing but the graphic at the top of this page, but it looks incredibly intrusive and completely changes the pass-by-value paradigm the standard is erring towards; a simple data structure becomes in essence an object full of setters and getters? It feels like the programmer losing their free will somewhat.
&gt;No. Nothing close to that is happening. I would really advise you to read both articles (esp. the last one). The screeshot shows a feature of refl-cpp known a proxies. Proxies allow for a custom type to mimmic the interface of another type without writing glue code. myns::value\_proxy is supposedly a user-defined proxy class that extends refl::runtime::proxy&lt;myns::value\_proxy&lt;T&gt;, T&gt; (the CRTP pattern is used). The myns::value\_proxy then only has to define a single invoke\_impl template function that implements all members of the target type of the proxy. Best of all, all of the function call resolution happens at compile-time! But, obviously, in C++ fields cannot have code run on access, so refl-cpp resorts to using functions that have the same name as that of the reflected member.
Also, this has nothing to do with the pass-by-value paradigm. The whole point of custom proxies is that the user that creates the proxy can specify the backing storage for the value (if any!). refl-cpp only provides the highly flexible tooling so that value\_proxy, shared\_proxy, unique\_proxy, etc. can be created. Please, refer to this example as well: [https://github.com/veselink1/refl-cpp/blob/master/examples/example-proxy.cpp](https://github.com/veselink1/refl-cpp/blob/master/examples/example-proxy.cpp)
I fully understand the frustration about the current state of things, but the important thing is that people are working to make it better and it very much does. "It can't be that hard" is incorrect and ignores all the problems, of which most are not even purely technical. All is about people (opinions) and money (time is money, requirements are money). These problems are magnified if things are discussed in the committee context. Vcpkg is a git project that fixes the ecosystem to make it compatible and eliminate a lot of problems by design. You need to pick the commit with the version of boost you need and, optionally, port non-vcpkg projects into it. Also, you can fork the repo and customize the default ones too. And yes, the current state of things is that if you want some external dependency - you need to figure out how to integrate it, even top experts are struggling with it which is absurd. But the situation is improving. But it requires the community effort, at least making libraries easier to package.
I've built hana using MSVC modules and then using .ifc inside regular project, instead of including headers.
&gt;Why add the extra lines (there will be two) instead of making the combination keyword "enum switch"? ´using enum´ might be useful in other situations, not just in switch statements. &gt;Perhaps with the latter, compiler implementations can find it easier to not tell me my function can reach a non-returning state? I don't think it would make a difference. Compilers can already warn if you don't handle all the enumerators. What you need is something like std::unreachable as suggested by [P0627](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0627r3.pdf).
In that case, neither would `auto&amp;`, as he uses in his supposedly correct C++17 and C++20 examples. If it is a reference to a temporary inside `getUsers`, then the function is simply always wrong. Now if the temporary is the database from `getDatabase` and `getUsers` simply returns an lvalue reference to a `std::vector` or equivalent in the temporary database, then all the code he showed would be incorrect, and the correct version would be auto database = getDatabase(); for(auto&amp; user:database.getUsers()){ registerUser(user); } which could indeed be simplified using C++20. If I am wrong, which might be the case, could you write a dummy implementation of `getDatabase` and `getUsers`, that demonstrates the differences between auto users = getDatabase().getUsers(); for(auto&amp; user:users){ registerUser(user); } and for(auto&amp; user:getDatabase().getUsers()){ registerUser(user); }
Well, half of the purpose of contracts is to catch runtime errors by users without cluttering the functions body. I’d say the output checks helping the developer debug is almost a side-effect of the paradigm being implemented completely.
Sadly
Oh right, I get it now, thanks for the explanation.
&gt; The next version with as much impact may be C++20. I doubt that. There are many nerdy things [lib-dev-stuff], things you don't need in day-to-day programming, like concepts, modules [we still have to see how that works out], coroutines [I have great doubt that these things will ever be popular in the general programmer population, another `valarray` in my view], contracts [more-lib-dev-stuff] and then ranges [syntactic sugar as far as I can see, duh].
Totally agree with you. But I think the main thing that the C++ standard needs is a better/standard way to interoperate between such 2D/3D/LinAlg libraries. A standardized multi-dimensional array-view would go a long way. And as a bonus, it would work to represent images as well.
How do you know that module qt has namespace qt to alias it? &amp;#x200B; export module mine; &amp;#x200B; namespace his { export void f(); } &amp;#x200B; I think your proposed syntax would not work there with the current module design, where a module and namespace are totally unrelated, even if they usually match.
Ah. That looks like explicit modules. That's good news :) . Would you happen to have the patches you made to the source available? Or was it all header units?
The excessive processor usage is a little off putting, why not use a builder type pattern with something like ``` REFLECT(Class) .method&lt;decltype(Class::X)&gt;(&amp;Class::X) .method&lt;void()&gt;(&amp;Class::X) ``` This also gets rid of __COUNTER__ which can lead to undefined behavior
Exactly. Either all the code is wrong, or none of it is.
An explanation [a so-called motivating example, what problem are we solving] why we need another rocket-science-level-feature in C++ would be helpful to me (haskell [dunno] has it does not count). It all seems fraught with dangers all over the place, and the biggest foot-gun brought into the C++ standard ever.
Having a standard way to interface such libraries is exactly why we need a standard linalg library that provides such 2d/3D vector classes. A multidimensional array view is certainly also important, but I'd much more prefer to have an actual, concrete data type, that allows simple math functions. There is a lot of vector math code out there that doesn't involve crunching through hundred of megabytes of mesh data that is stored in a particular format. Sometimes I just want the position and/or orientation of my device and I think it is a shame that the isn't a simple standard value type that a `get_3d_position()` can return.
This usage of \_\_COUNTER\_\_ is completely safe and cannot lead to UB. A builder type pattern would require the reflection information to be queried at runtime, as the builder methods in your example would have to store the members in some type of a map underneath. Also, member name information would not be available unless typed out again in the form of a string, which is error-prone. I have explained why I have chosen this implementation in the blog post. I understand why some people might be put off by usage of macros, but the matter of the fact is that they are still needed in modern C++ for some more complex programming-utility scenarios.
How is P0627 different, in practice, from just sprinkling std::terminate()? Or in the future using [[assert: false]]? (Depending on how contracts look like now.)
maybe because it will put C++ leaps and bounds above other systems languages? do you see C getting anything like this ever?
I like most of these features, but things become much trickier than they already are. When you see \`Widget w(1,2,3);\` in code, you'll now have to wonder if that is calling a constructor or if it's aggregate initialization. Also, why not add all the designated init features from C? Except for the order of members in C++.
&gt; maybe because it will put C++ leaps and bounds above other systems languages? To achieve what, that's what I'm not getting. I read: The coroutines could be used in the exact same way as the coroutines in other languages. Coroutine will simplify writing: generators asynchronous I/O code lazy computations event driven applications Are there any numbers to support the claim that this makes life a lot easier, are they used and how much in those languages (Python and C#, I read). Just sticking to the 'asynchronous I/O code'. Already now, without coroutines, `boost::asio` (and boost::beast) are easily the biggest single generators (pun not intended) of questions/problems/misunderstandings/bugs on the Boost mailing list. Now we're going to add another level of complications (i.e. bugs), I don't think it will end well. &gt; do you see C getting anything like this ever? No, sounds good.
Also, I would argue that it is a matter of personal opinion whether you prefer your example, compared to: REFL_TYPE(Class) REFL_FUNC(X) REFL_END And just to for the sake of completeness, I would like to repeat that your suggestion is inapplicable to the end use-case - compile-time reflection.
His example is simply wrong. `auto&amp;&amp;` extends lifetime exactly as you would expect. As discussed in other comments, if `getDatabase` returns a temporary, and `getUsers` returns an lvalue reference to a member of that temporary, then C++20 does help fix the code, but his examples are all wrong. auto database = getDatabase(); for(auto&amp; user:database.getUsers()){ registerUser(user); } would be the correct C++17 example, and for(auto database = getDatabase();auto&amp; user:database.getUsers()){ registerUser(user); } is now possible with C++20, which allows for a tighter scope, and fits comfortably within an 80 column limit, even with a bit of indentation and different formatting. All in all I think it is an improvement.
This is indeed unfortunate. std::terminate() solves the compiler warning error for now. Still, implicit conversion is forbidden. The domain of "enum class" is constexpr-knowable. So warnings are bugs. The worst solution to these bugs is to turn off the warnings, since extensions of "enum class" is likely.
Richard is really busy, but does usually go to CppCon.
With std::terminate() the compiler would have to generate code to call std::terminate(). [https://godbolt.org/z/hilWGk](https://godbolt.org/z/hilWGk) With std::unreachable the compiler would be able to assume the code is never reached and could do optimizations based on that. [https://godbolt.org/z/U5MC5u](https://godbolt.org/z/U5MC5u) I guess \[\[assert: false\]\] will be similar to std::unreachable if contracts are *not checked* / *assumed* but if contracts are *turned off* it will probably not prevent a compiler warning for reaching the end of the function. [https://godbolt.org/z/nm5OEN](https://godbolt.org/z/nm5OEN)
I am not sure how I feel about the new aggregate initialization. On one side it feels like all kind of braces are so overloaded that nobody can keep track. On the other hand it might let me use () instead of {} and be worried that initializer\_list kicks in. How I often use {} is this: ```std::optional&lt;int&gt; func() { return {}; }``` and ```std::pair&lt;int, int&gt; func() { return {1, 2}; } will this work with return () resp. (1,2) ? It should otherwise it's not consistent with {} at all.
You misunderstand. I was saying that in an ideal world, the namespace should be defined by the party importing the module, rather than the module itself. Of course for current C++ this is hard to achieve because the imported symbols cannot be found by the linker anymore, which is why we cannot do it. But as an alternative language design it would have been a better choice than what we have now.
is that from the implementation? I think cppcoro is not a good place to learn the primitives, but it is a good library to start writing coroutines and thinking about them at a high level. it is like the stl for coroutines also, you will get used to this kind of thing. something you have to `co_await` before you `co_yield` so any exceptions are thrown inside the coroutine rather than outside
nice example
&gt;`std::pair&lt;int, int&gt; func() { return {1, 2}; }` &gt; &gt;will this work with return () resp. (1,2) ? I don't think so because `return (1, 2);` already has a different meaning.
You don't. You never fully learn any C++ expect 98 :D
Thanks for the example, I can accept the extra code so long as I can avoid default and not see the errors. Using the contracts-gcc build, "[[assert axiom: false]];" at the end of the file generates the same code without warnings. However, "[[assert: false]]" generates a lot of extra code.
If you have a dozen or so entries, don't even sort them, just do linear search. The cache-friendliness of linear search wins over binary search, for small numbers.
I don't think images should be the same type. I want my 2D/3D points and vectors to be copyable and trivial. An image is very different, and should likely be move-only (with a explicit clone function).
Isn't flat map allowed to do a linear search for small numbers of elements?
For classes, I'll take metaclasses instead. Do that without language extension. For functions, I wonder if coroutines plus lambdas plus functions means that we can start moving toward function bodies and class bodies being analogous. Probably not for a bit.
This is very interesting.
The talk is almost entirely about cache effects not on the C++ memory model. Very disappointing.
this new .var=value syntax is horrific. Why not var: value, or the previous one with var=value.
[removed]
 To be fair I think it's hard to set up a good school curriculum and keep it updated over time. Any time a big change is made there is a risk that something will go wrong and you'll end up with students not learning much. Maybe one thing us tool vendors can do is make a greater effort at lowering the learning curve and providing useful supplemental materials to educators and students for using our tools. Documentation designed for professional development is different than documentation targeted toward students working on small projects.
Could you please post a link?
&gt; but its error handling is something i think can be improved It is just that people coming from other languages think, but most people who are writing go for a long time don't have any problem with it, afaik &gt; Anyways i am just curious are you planning to integrate this lib in your daily code or you just wrote it for experimentation purposes ? :) Currently, I don't have something to use it on, but would surely try it out.
Writing new kinds of coroutines will be rare. Methods that return enumerable int? Will be common.
C++98, 03
Is that the version we landed on? At least some of the proposals emitted the data because there is a very valid use case of using constexpr programming to create constexpr (but accessible at run-time) data structures.
Good points &gt; It relies on specific warnings being enabled For brevity, I didn't include it, but you could do a #pragma diagnostic "-Wformat-string-literal" or whatever. &gt; __attribute__ is non-standard and will fail with compilers that don't support it. If it's supported in gcc/clang/msvc, then it's standard. There, I said it and I stand by it. &gt; It also produces a warning with all wide string literals: Yup, that's a limitation. On the other hand, eeeew.
It's already a C feature so for compatibility with C they wanted to use the same syntax. I don't know why C didn't settle for the `var: value` syntax. GCC has implemented this syntax so it should work. Maybe it looks too much like a case label? `var=value` is not really possible because that is already the syntax for variable assignment.
During the range-based for initializers part, someone in the audience laughs at the "solution", and the speaker says "it's very long, yes, but it's consistent, right? And it's still a lot better than this." Compare: (1) Range-for initializer for (auto&amp; users = getDatabase().getUsers(); auto&amp; user : users) { registerUser(user); } (2) Separate initialization with braces { auto&amp; users = getDatabase().getUsers(); for (auto&amp; user : users) { registerUser(user); } } Yeah, (1) uses fewer lines. But am I the only one who finds (2) easier to read? When I look at a for-loop, I want to be able to tell *at a glance* what the loop variable is and what the collection is. I find that mashing everything together results in too much information in a single line. Maybe I just haven't gotten used to it yet?
I work for the Visual Studio team so my opinion is biased, but I wanted to highlight that we've made a number of user experience changes designed in part to reduce the learning curve for new users (particularly students) over the past few releases. For example the console window no longer auto-closing itself when a debugging session completes, "This project is out of date" build prompt that was confusing to a lot of people, quick fixes for missing #include statements and semicolons (they both seem to be pretty popular), and even an overhauled new project dialog and a new start window to help a new user focus on the experience they want. &amp;#x200B; But putting that aside, I learned a lot by sitting in UX labs with many students over a period of a few months. My two biggest takeaways were: 1) Some of the biggest stumbling blocks are things that seem really basic to an experienced professional developer as they have already overcome and routinely bypass these issues. I think it's up to tool vendors to fix those (so please file bugs on tool vendors when you see a pattern with your students getting stuck somewhere). But even without that there is the second takeaway - 2) Tutorials work really well to reduce the learning curve. I put together a basic tutorial for a console-based calculator app in Visual Studio that took maybe 20-30 mins for a student to go through, and by the end of it they knew not only how to compile and debug their first C++ app, but even to do things like use a conditional breakpoint or step through the code. I was also careful to describe each line of code since all of it is brand new information to the reader. You can actually still find the tutorial here ( [https://tutorials.visualstudio.com/cpp-calculator/intro](https://tutorials.visualstudio.com/cpp-calculator/intro)) and we since integrated it into our docs as well. The difference between students who took the tutorial and those who were asked to get started on their own with only general guidelines was huge: students who followed the tutorial were much happier by the end of the session and felt they really learned something. Students who didn't couldn't get a program to run in an hour's worth of time. So as an educator, regardless of the tool you end up choosing, I suggest investing some time into a good getting started tutorial. That alone will make a huge difference. The GIFs are worth the time investment too and don't take too long to make with a decent tool. &amp;#x200B; Also to comment a bit on the console vs. IDE teaching method: I think it's fine to start off with just a console, a Makefile and a compiler you can call to build the code from the command prompt. My problem with it is that this often turns into years of students being asked to work this way. It's one thing to get students to understand basic principles, it's another to hurt their productivity by having them avoid tools everyone else uses for professional development. Students are busy too, and they could use the time savings provided by a good editor, IDE, or debugger. I wouldn't spend more than a few weeks in just a console. On top of that, learning tools is important to prepare them for their future career as well. Otherwise it's like insisting on teaching graphics design in Paint. Look, I love Paint, but it isn't Photoshop.
How does this compare to outcome, which is already in Boost?
&gt; On the surface of it it is a self-contradictory requirement, since where you have only a pointer, the information about original type and token kind is lost. You are right. I should have been more precise that I meant: * Accept only character pointers that are provable at compile time to refer to string literals That is, it's a half-open criteria, I should have been clear I don't care what happens to the unprovable ones.
&gt; This was this biggest blunder of Rust, in my opinion. You have this great idea about ownership and lifetimes that’s very different from the status quo, but it was implemented without ergonomic inference. Which is insane. Now you have the entire internet saying how frustrating this feature is—which is the very feature that is Rust’s superpower—and for the ridiculous reason that nobody thought to do some basic lifetime inference from the beginning. I’m talking basic inference here, easy stuff, not much harder than liveness analysis. A PL theorist should have known better. Anyone should have known better. To be fair to them, their intent for 1.0 was to prioritize things which would be a breaking change to fix later. To be honest, it's not as bad as the PR mess that was using the name KDE 4.0 rather than labelling that KDE release as the buggy alpha it was, but it's not completely different either.
You can reject those at compile time as not provably string literals.
https://zajo.github.io/leaf/#boost_outcome
&gt;If it's supported in gcc/clang/msvc, then it's standard. De facto standard, sure. But it is not supported by all of those: error C3646: '__attribute__': unknown override specifier Same goes for `#pragma diagnostic`
Really great documentation. Substantive and visually appealing. I imagine you put at least as much effort into the documentation as the design and implementation of your library.
You are mostly right. Coroutine ts may be the most complicated single feature being brought to c++. Not only the lib writers but also the lib users have to understand the whole thing to make good use of it. In that case, a lib based stackful coroutine is much easier to understand and still be reasonably fast. In the end, I think more choices are always welcome. As c++ has already been the most complicated language in the world, another complicated feature won't hurt.
It’s not initialization order that’s the main problem; it’s the destruction order in case of an exception thrown during the initialization.
They got changed a bit today. In particular, we had to drop the pack-based expansion because of semantic ambiguities.
`{X1=Y1, X2=Y2}` is supposed to be like doing fooX1 = Y1; fooX2 = Y2; So `.field = value` but also `.field[idx].field2 = value`.
Yes. After San Diego we found a tricky issue with the “promoted storage” case. EWG didn’t love the mechanism we can up with to resolve that issue. So the case of “non-transient” allocations was deferred to the next standard (assuming we find a solution the committee agrees to).
Right. Our constexpr interpreter has its special allocator. My implementation, for example, keeps enough metadata around to tell you when you allocated memory that “leaked” for example (used in the diagnostic when a constant-expression is not constant for failing to reallocate).
Totally agree. But: &gt;exactly why we need a standard linalg library that provides such 2d/3D vector classes. 2D/3D vector classes are a very, very small subset of LinAlg. Surely having 2D/3D vector classes in the standard would be useful but without looking at the bigger picture, this leaves 90% of today's LinAlg applications on the outside. Thankfully the LinAlg proposal is more generic!
Yeah maybe your are right since i don't really know much about go's community and recently started using go in our code base and also go's isn't my first language.
&gt; The same reasoning applies to error-neutral functions, but in this case there is the additional issue that the errors they need to communicate, in general, are initiated by functions multiple levels removed from them in the call chain, functions which usually are — and should be treated as — implementation details. An error-neutral function should not be coupled with error object types communicated by error-initiating functions, **for the same reason it should not be coupled with any other aspect of their interface**. I disagree, fully. Specifically, I find that this reasoning is in violation of the [Law of Demeter](https://en.wikipedia.org/wiki/Law_of_Demeter), much like exceptions. That is, the caller is somehow peering through the abstraction layers to know they should expect a particular error object, generated by some function 10 calls deep. The truth of the matter, therefore, is that *whether specified in the type system or not*, the error objects that are generated are as much part of the programming interface of the so called error-neutral function as its arguments and return type: - Generating a new error object in a particular error condition is a breaking change. - Generating a new error object, or existing error object, for a new error condition is a breaking change. - Not generating an error object which used to be generated in a particular error condition is a breaking change. Hiding this information from the compiler, and putting the onus of (1) documenting such changes, (2) reviewing such release notes and (3) catching all call sites where this should be dealt with on humans, rather than a compiler, seems to me like a step backward in term of usability.
So this... template&lt;typename... Ts&gt; void f(Ts&amp;&amp;... args) { for... (const auto&amp; x : args) cout &lt;&lt; x &lt;&lt; ‘\n’; } ... is not valid anymore? Also, does the removal of pack based expansion affect [P1789](https://wg21.link/P1789) in any way?
In a way, this "blunder" might just be a consequence of their success. Simon Peyton Jones talks about how Haskell's lack of success has been a huge benefit for Haskell's evolution, because they could continue to change things, breaking backward compatibility. The people using Haskell are often PL theorists themselves, so it's not like they had a significant segment of C/C++ programmers trying to learn Haskell for the first time. With Rust, on the other hand, there has been interest outside of academia from really early on (as I understand it). So in that sense, the ease of learnability matters more, as does backwards compatibility. So it's a mixed blessing.
That the _real_ core of C++ is the friends we made along the way.
Lol
Ah, interesting. Disappointing of course, but thank you for the explanation. :)
^ found the compiler expert :)
He's also possibly the nicest person you'll meet. Sutter for (CPP)2020! :)
Error types can't be meaningfully specified in the programming interface of generic error-neutral functions. Either you need to understand the internal error type or you do not. If you don't, ignore it and deal with the higher-level type only. If you do, LEAF provides a more elegant interface for access (compared to some sort of wrapping, which in addition is technically challenging to implement in general). Even if templates aren't involved, all error-handling libraries have to solve the interoperability problem. For example, here is a comparison between LEAF and the solution offered by Outcome: [https://zajo.github.io/leaf/#\_the\_interoperability\_problem](https://zajo.github.io/leaf/#_the_interoperability_problem).
Here is a comparison: https://zajo.github.io/leaf/#boost_outcome. Also, LEAF can work with most external result&lt;T&gt; types. Here is the example from the LEAF tutorial changed to use outcome::result&lt;T&gt; (which, if needed, is a drop-in replacement for leaf::result&lt;T&gt;): https://github.com/zajo/leaf/blob/master/examples/print_file_outcome_result.cpp?ts=4
It's this meant to be networked?
I'd like to throw my hate in as far as compile time reflection libraries go: [https://github.com/dtmoodie/ct](https://github.com/dtmoodie/ct)
No, it’s a pretty simple project. I’m coding on a virtual machine for a class so that’s the scale of the project
This is exactly the question we need to ask - are we going to specify flat_map such that we are boxed into a corner of implementation options (like unordered_map), or are we only going to specify the vital parts, leaving the rest implementation defined? (which has downsides, like your code assuming the flat_map was sorted, but that was only on your implementation) I think currently flat_map must always be sorted.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ce26i2/project_advice/etxwv90/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Out of curiosity, how would you check if the pointer points to the data segment rather than the stack or the heap?
You are not alone. I too consider declaring variables in for each or if statements clumsy
You are not alone, and getting used to it is probably a factor, but so is formatting: for(auto&amp; users = database().users(); auto&amp; user : users) { // ... } is rather nice to read IMO. And I find that explicitly expressing that users is in scope exactly for the for loop wins over the alternative.
is that the alt beer?
I'm not saying it doesn't have to be sorted (If we could go back 20-30 years, unsorted should probably be the default , but that's not the world we live in unfortunately). I'm just saying that I believe that a flat map should be able to do a linear search if the number of elements is smaller than a (implementation defined) constant factor.
Is the difference you're talking about what was discussed in the talk, (initializer_list + no narrowing conversions vs no initializer_list + narrowing conversions) or something else?
I also use {} in return statements like you described.
That is pretty readable. I wonder if I can convince clang-format to use that style.
\&gt; What's the rationale of There's your first mistake.
I guess if they wanted to sacrifice succinctness for accurate, they could have named it `remove_adjacent_duplicates` or something. As for why they didn't make the functionality match the name, I believe it's for performance and decoupling. First, `std::unique` is able to be O(n) because it only looks at adjacent values. If the range already satisfies that condition, it would be wasteful for `std::unique` to move things around first. Second, the way `unique` is designed allows the user to decide how to ensure the "precondition", e.g. by performing a full sort, by inserting elements next to existing values, etc.
&gt; You're holding it wrong. Jokes aside, when you work with STL algorithms, think them in iterator pairs. The elements between `std::begin` and `std::end` has duplicated elements, so `unique` returns a new end named `new_end`. Elements between `std::begin ~ new_end` are `unique`. Similarly, `std::remove` doesn't remove elements out of container, but generates a new pair of iterators so that all good folks are kept in our new range.
Your example is ambiguous because the return type of WithOption is what needs to match the function argument type. What type that member method is called on could be basically anything.
Because we have no way to get the types of function parameters. In general the stuff you can get with type_traits is pretty incomplete. The reflection ts aims to fix this, and indeed includes a way to get parameter types.
Agree with result type match, but as described, the initial "auto" would be matched against the function prototype. Point taken, though: it would likely have to be restricted to the first expression of the parameter for the deduction to work properly. But what I'm hypothesizing is a method to make the member method call unambiguous, by virtue of the deduction of the auto type in the expression. For instance, this would not work: foo( {}.WithOption( ... ) ); ... because the empty initializer list has no such method. I'm asking about a (hypothetical) alternative syntax for which the resulting type of an auto initializer expression would be well-defined.
&gt;Agree with result type match, but as described, the initial "auto" would be matched against the function prototype. The result type of the expression is what matters. The committee would never allow what you propose. It would be hard to specify and I suspect it would lead to ambiguity in most cases.
&gt; Elements between `std::begin ~ new_end` are `unique`. That's only true though if all duplicate elements between `begin` and `end` were adjacent.
I should have noted: I realize it would be ambiguous with template parameters in the Concepts TS. Also, obviously, it would need to be done at the compilation level; I don't see a way to make it work in a library in the existing language, for example. I guess I don't see why it would be difficult/ambiguous in the non-template case, though. If you can pass a "default" parameter based on the initializer specification with an empty initializer list, it should be unambiguous at compile time as to the result of that expression. Why would it be impossible to allow expression in the language of the result type of that expression (ie: the empty initializer list as a parameter)?
This could hypothetically work, but in general there would need to be an extremely compelling reason for adding such a feature. I think it's quite strange you are effectively saying, consult my parent expressions eventual result type for my type, then perform some operations, and then check that after all these operations we still get the correct result type to initialize a variable. This seems extremely fringe at best, at worst it's extremely confusing. The syntax here implies a degree of "make this work" thinking, which while not what you're proposing is how this reads. Automatically deduce a constructor, which has a function, and who's resulting call to that function, returns the thing I need. Trying to find the best match there, would be extremely expensive, subject to extreme surprises, and generally impractical. This just doesn't feel like C++ to me.
That's what I'm curious about: the "why". It seems unambiguous to me (ie: auto as parameter resolves to resulting type of initializer expression for parameter type), but I'm likely not considering some cases. Why would this be ambiguous?
It’s not impossible, but the people getting it into the standard are working on the reflection TS.
I'm actually having a hard time coming up with an ambiguous example. It *is* pretty limited though (the type returned by WithOptions mustc be the same type as what auto{} constructs). And I'm having a hard time seeing what problems this solves that can't be solved another way with the existing standard.
I guess the "feel" is a matter of perspective. As noted, I can already do: foo( {} ); ... which is sorta the "make it work" expression. What I'm asking about is more of a "make it work and give me the actual type to do something with without me typing it out unnecessarily" extension of the above. I'll accept the "might be confusing" argument, but to me, it's no more confusing than the above (but obviously, YMMV). Note: I'm not suggesting a "check after doing stuff" matching or anything; in my example, the resulting type of `auto{}` is unambiguous and strongly typed before the method call. Sorry if that part was confusing.
Admittedly, it's a syntactical shortcut only. I have a number of instances where I have nested namespace structures as optional arguments to methods, and it would be nice to have the compiler help me out when the result of the initializer syntax would be unambiguous. But it's only saving explicitly copy/paste of the namespace/type info, not anything else. ... In a sense, kinda what `auto` does in general.
Understood. I was going to float the idea to those people at cppcon, but I wanted to sanity check if I was missing major issues first. ;)
Check to see if you can do it with the reflection ts :)
The point of the initializer list though is to initialize a variable. This feels
Auto is also used where it's impossible to spell out the type - such as when storing lambdas in a variable.
Consider the fact you can have a list of elements that is already sorted, or one that is not. You can write an algorithm that is more efficient is you can assume that the list is already sorted. In the other case, it is a simple matter of sorting first and then pruning the redundant elements. As for naming, there is a utility called `uniq` in Unix. The man page says the following. &gt; A uniq command appeared in Version 3 AT&amp;T UNIX. And then Wikipedia says that it was released in 1982 : https://en.wikipedia.org/wiki/UNIX_System_III
Disagree? Or, to put another way, I'm augmenting the initialization syntax to allow the resulting type of the initializer expression to be captured in the expression. The result of the initialization would be the same (as far as the compiler is concerned); my syntax would just enable the developer to use the resulting type without typing out it's fully qualified name.
Something tells me that syntax would be more difficult to get right than just the fully qualified type name inline, but it would be a good academic experiment. :)
You can also use it to dynamically alter the result type of a method for which the compilation depends on compile time expression evaluation, such as the `if constexpr (...)` syntax, or template lambda parameter expression, etc. I'm aware of the various current uses for `auto`, for reference.
I'll have to think about this more... Just going off the top of my head.
That's why I'm asking the question... no rush. :)
It certainly could be done as a library. Define a class with a templated conversion operator that take a generic lambda in it's constructor to call when converting.
The main usage is to retain only the unique items in a sequence. For this one applies it to a sorted sequence, and applies `erase` after. I can't offhand think of any advantage of applying it to an unsorted sequence.
I struggled in programming. I was better with the simple coding like Apple 2's BASIC, Apple 2's LOGO, HTML, etc. :/
The sequence doesn't have to be completely sorted for `unique` to work. It just has to be grouped by value. [Example.](https://godbolt.org/z/2-rZMi)
The `auto` keyword existed before that, but was *very* different.
Which is useful if you don't have a comparison operator outside of equality.
You read my mind with remove\_adjacent\_duplicates, lol
So another feature of C++ ruined by its C legacy? :(
In case you're looking for an alternative then look at boost priority queue. It provides you exactly what you're looking for
For the first question: Correct. For the second: I think so, yes. I’ll try to confirm with Alisdair today, though I suspect he’s aware of this already.
&gt;There are many nerdy things [lib-dev-stuff], things you don't need in day-to-day programming, like concepts Well this is one of the biggest flaws of cpp getting sorted out imo: The overwhelming compiler-errors when you make a small template-error. From hundreds of lines the error messages will be just a few lines, and human readable. This enables new possibilities for lib-devs because most time they need to hold themselfs back because other devs have to work with their code as well.
With Clang you'll mostly only get a couple of lines already, often with a clear message as to what to change in your code to do make it compile.
yeah whatever, i'm using GCC anyway, so I'll use that syntax.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ce9zpi/best_c_books_for_beginners_in_order_please/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What's the definition of "a great image processing software developer"? Like, someone who works on Adobe Photoshop?
Check out [https://github.com/ImageMagick/ImageMagick](https://github.com/ImageMagick/ImageMagick)
I'd say someone that works for high-tech, innovative companies that produce high quality image processing software? Is that clear enough for you? O.o
std names are not always nice. There should be cognitive psychologist among the C++ standard members (half joking...)
that is an interesing site, but it directly relates to c++?
I still remember my confusion when I first learned that std::remove doesn't actually remove anything but moves elements to the end and you have then to std::erase them. Naming is not always the best in the standard libraries.
I would argue that current advancements in image processing are either GPGPU- or ML-related. So imho the answer to your question is unfortunately "not c++ at all". Learn OpenGL/vulkan and pytorch/tensorflow. Apart from that relevant c++ skills are those that are relevant to any major software projects...
Back in the day I learned from an earlier version of the book below. The main thing is to learn the concepts but you also need to know how to efficiently code in your language of your choice including multithreading. Digital Image Processing, Global Edition https://www.amazon.com/dp/1292223049/ref=cm_sw_r_cp_apa_i_-GUlDbTDQDTJQ
I didn't like that He's trying to convince that new way is the only proper one. New feature adds new possibility to write such code and developer should choose what is better for him.
You got the source code for a very well known image manipulation software, which is made with C/C++. If you understand C++ well enough, you can read and learn from it.
An old text book I had pictured the (virtual) memory layout very similarly to [this](https://en.wikipedia.org/wiki/File:Program_memory_layout.pdf). Compiling this: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; static int bss_var; char data_var[] = "Hello"; int main() { int stack_var; int *heap_var = malloc(sizeof(int)); printf("Data: %p\n", &amp;data_var); printf("BSS: %p\n", &amp;bss_var); printf("Heap: %p\n", heap_var); printf("Stack: %p\n", &amp;stack_var); free(heap_var); return 0; } Yields something like this (though not necessarily *exactly* like this because the kernel employs address space layout randomization): Data: 0x55d8475b6040 BSS: 0x55d8475b604c Heap: 0x55d8488bf260 Stack: 0x7ffc6116bff4 At least we can confirm that data, BSS and heap variable have low addresses compared to stack variables, and that data segment comes before BSS or heap. So if I were so inclined as to come up with a super ugly hack that *might* work *some* of the time on *some* machines, I'd rough-hew the following defines: #define SEGMENT_DATA_PTR 0x55 #define SEGMENT_STACK_PTR 0x7ff Then do checks like "is my pointer larger than `SEGMENT_DATA_PTR` but smaller than `SEGMENT_STACK_PTR`? It's (probably) a data, bss, or heap variable". Or like "is my pointer larger than `SEGMENT_STACK_PTR`? It's probably a stack variable".
Then probably the areas of interest are Computer Vision, Data Science, Computer Graphics, and Machine Learning.
This is definitely very interesting. Thanks for sharing this!
[https://opencv.org/](https://opencv.org/) OpenCV is an industry standard pretty much. It also has great python bindings, and unless you are going to do any kind of heavy lifting yourself, I wouldn't use C++ for image processing. Like /r/paulgilbert mentioned, machine learning is taking over the image processing fields, so python would also be a good tool in that regard.
then why is c++ a requierement for most job aplicants? Is it mainly for code reusability?
For the last sentence, I did mainly mean md array-view, yes. As it currently stands, there is no good way whatsoever to represent images in C++, except through a raw pointer, a custom class with vector&lt;uchar&gt; storage or something, or a library like Selene. In many of today's machine learning frameworks, tensors and images blur into each other, so I'm not sure whether the solution would be to have a separate image class or using tensors to represent images. For the LinAlg proposal, I think it aims to cover tensors as well, otherwise all ML people (and more) would be very unhappy. Meanwhile, a md array-view would help all the matrix, tensor and image folks for better interoperability.
No, because most work outside of research is to ship hardware products (or software on hardware) to carry out specific tasks. So C/C++ becomes a necessity for performance reasons for any embedded system.
You mean instagram filters?
The tutorial uses `leaf::result&lt;std::shared_ptr&lt;FILE&gt;&gt;`. Would it work with a moveable-only type like `unique_ptr`?
My biggest problem is, that it is shorter and you don't really see, that you are potentially invoking UB. I would prefer something `.unchecked_access()` for accesses, that may invoke UB.
That is an interesting approach; very similar to what some other languages do for inline configuration (ie: pass a lambda which manipulates the config structure, without passing the config structure directly). The indirection doesn't feel as clean or obvious to me, fwiw, but it does accomplish the same effect.
The thing is, most of the time you use optional like `if (opt) { use(*opt); } else {...}`. The interface is optimized for the common use case.
Yeah, the syntax isn't the best. But one could also abuse the `operator=` to create a new `auto_` with the lambda: func(autoeq = lambda); But that's for sure, it's not like the syntax you proposed.
C++ is still the primary language the software itself is written in, but you asked for directions on what to learn to be "great" especially w.r.t. image processing. The point was, that in contrast to e.g. game programming there is nothing in image processing that requires special c++ skills (e.g. in game programming more esoteric approaches to memory management help a lot). My suggestion is therefore to learn c++ without any special focus and if you want extra qualifications maybe implement some convolution filters using opengl fragment/compute shaders. You still *call* opengl code from C++... I am a CG researcher btw, if someone working in the actual industry had objections to my statements you should probably trust his/her advice :)
Yes, but in that case, `*opt` could probably still be throwing, as `operator bool` and the check in `operator*` should be the same, and the compiler and branch predictor should both be able to see through that. The issue is, that if you have something like: if(!opt) return; f(*opt); And for some reason the call to `f` gets reodered before the `if`, maybe through a bad merge or unclean refactoring, you invoke UB and may never notice that. If you still need the performance from avoiding the branch in `operator*`, you could call the longer `unchecked_access` version. Safety should be the default, especially if a feature is aimed at improving error handling.
IIRC this difference wasn’t mentioned in the talk. I’m talking about differences in lifetime extension: [https://twitter.com/klmr/status/1151061705780334592](https://twitter.com/klmr/status/1151061705780334592)
I've worked with COM for 7 years at Microsoft. I can't say I recommend the technology. It certainly does some interesting and useful things. But there are a ton of "mistakes" made 20 years ago that can't be fixed because of the need to maintain backwards compatibility. I'd recommend using just a straight C API instead. If you do use COM, the made sure you: 1. Only use the MTA (multithreaded apartment). STAs are a freaking pain in the butt. 2. You skip all the registry registration junk. Either use "Registration free COM interop" or use the COM-lite pattern. (XmlLite is an example of a library that does the latter.)
&gt; vcpkg only has the latest versions of some dependencies. I'm not on boost 1.70 for my project yet which is all vcpkg has so i'm stuck. its not a great solution for this. You can (and should!) choose a particular revision of the vcpkg repo to use for each of your projects. This fixes the revisions of all the ports, so you could pick a revision that uses the version of Boost you want. The idea is that is the versions of the various ports are chosen to be compatible with each other, a bit like a Linux distribution (although it doesn't always work out). &gt; Currently wasting my time getting Clucene to build on windows instead of writing business logic which I'm paid for. Well at least vcpkg *helps* with this. If you build it with CMake then it's fairly easy to wrap it in a vcpkg port. Even if you don't want the responsibility of contributing the port back to the main vcpkg repo (or aren't legally allowed to by your employer), you can still distribute your vcpkg ports internally within your organisation.
Do you think the syntax is that bad? Personally I don't have a problem with it.
Windows Runtime is entirely based on COM, with enhancements.
I'm interested in what com lite pattern is? I tried to get a registration free com interop working but failed because every example I saw was for Visual Studio and I'm using an ancient non-VS compiler (Delphi 5). I had to give up on com because of this, but I'm interested if I could get com lite working with it.
+1 - I've also worked with COM a lot, and IMO a flat C API is a lot easier to work with. If you want object-oriented C# or C++ interfaces to expose to your consumers, you can build wrappers on top of the C API pretty easily. It seems like a lot of extra work, but it ends up being easier than dealing with IDL files.
Would you have some pointers on how to do 2. ? I see that the only wizards available in VS2019 are for ATL COM objects, but I'm afraid they might be a bit cumbersome for what I have in mind. As you said, I don't need registration and all that jazz.
I think C interfaces are easier to work with, but if you want to used from C#/managed world, COM is easier.
Its the second time I get this suggestion, thanks, I'll look into.
Check [here](https://xkcd.com/138/) for some pointers.
Thx, but I need something for 64bit platform.
So if i pick the revision of vcpkg with boost 1.69 in, am I stuck with all the other versions in that revision or can I pick and choose ? It's another build system for C++ that I need to learn along with cmake and I only have so much time. I'm just going to steer clear of c++ as much as possible and go back to drinking heavily when I have to do it to numb the pain.
Is this to be cross platform? If it isn’t why do C++ compatibility issues manner? You will almost always end up with compatibility issues no matter what language you choose anyways, new compilers regularly fix bugs for example. I don’t see C++ being exceptional worse in this regard, especially when MS has put a lot of effort into recent C++ compilers. I’m not saying C++ is right here just that your reasoning doesn’t ring true. Now if cross platform support is important to you, you only have two valid choices that is with C or C++. I don’t see this as your goal because of the COM question. However SDK’s can often end up cross platform so if you are not 100% sure opt for portability.
Unfortunatelly, C++ is not platform compatible. Since STL is head-implementation, a library compiled for Windows with MSVC is not compatible with a client compiled by Clang also for MSVC (valid scenario for us). The standard specifies (almost) nothing about implementation details of STL, therefore all vectos, list, shared\_pointers, etc have private implementations at header level which are not (guaranteed to be) compatible.
C bindings are probably the way to go. It's going to depend heavily on the surface area of exposed functionality though. C bindings with a header only c++ wrapper is also an option. This gives you raii and the like. You can also use stl somewhat, assuming your c bindings are written to just accept the underlying buffers/ sizes.
&gt; there are a ton of "mistakes" made 20 years ago Could you please expand a little on that ?
That is...wow
I could see a use case where you are pulling data from a sensor and you want to log changes in the data rather than all of the data. You could use std::set (which is sorted so it probably uses the same std::unique) if you want only unique elements by default.
&gt;C bindings with a header only c++ wrapper is also an option Could you give a short example?
Not sure about this, naked `new` in the readme scares me.
&gt; I've authored 3 Boost libraries already (Spirit, Fusion and Phoenix). I am not sure I have the energy to submit another. FYI, there is a thing named [Boost UI](https://github.com/kosenko/ui) which (by its name) tries to be in the Boost. Both libraries look good for me (I really like the point that Elements does not own/hide event loop) but I was dissapointed when I realized that Boost UI uses wxWidgets underneath because that means it will pretty much never get dark mode UI or any sort of theming (wx uses only native widgets).
It doesn't move them to the end - it moves the elements to keep to the start, and the end elements are in "moved-from" state.
e.g. DCOM, in an office environment with perfect a network it works fine, but put DCOM in a factory where network cables maybe not always are shielded properly and you will notice that the DCOM timeout for an comm error is 6 minutes i.e. it will hang for 6 minutes before realizing there is an error. Not the greatest.
Each enum provides a limited set of typed, related, scoped (if using `enum class`), named symbols. The alternative is defining a constant (either with `const` or `#define`), which doesn't provide any relation between symbols and doesn't restrict inputs. Imagine a function `void setOrientation(int orientation)`. Then you define `const int ORIENTATION_HORIZONTAL = 0; const int ORIENTATION_VERTICAL = 1`. But what's stopping me from calling `setOrientation(42);`? Nothing. You have to check at runtime if `orientation` is a valid value, and throw an exception if not (because you have no way to return an error condition from this function). But define it as `void setOrientation(Orientation orientation)`, with `enum class Orientation {HORIZONTAL, VERTICAL};`. Now the compiler will stop anyone from calling `setOrientation` with any value except `Orientation::HORIZONTAL` or `Orientation::VERTICAL`.
(a) A usability example: consider this function declaration void processFile(const std::path&amp; file, bool skip_description) You might say, "it is clear to me what the parameter skip\_description does". Now take a look at how a caller would use this: int main() { processFile("foo.txt", true); return 0; } That "true" isn't very informative at all and forces you to look into the docs! Consider this change: enum SkipDescription { YES, NO, } void processFile(const std::path&amp; file, SkipDescription skip_description) with this declaration, the code is truly self explanatory! int main() { processFile("foo.txt", SkipDescription::TRUE); return 0; } (b) in most other cases, enums are used to represent multiple states in a program, which can be easily switched through switch (some_enum) { case FOO: do_foo(); break; ... // many other cases default: // ... }
wxWidgets is soo old school, and IMO does not belong in Boost. Also, it's a Boost policy that libraries should not depend on anything other than Boost and the standard libraries. My reliance on Cairo may be abstracted away. Hopefully, "Boost UI" does not rely heavily on wxWidgets as well. And BTW: "uses native system-provided widgets" can never be good enough for UIs used for Audio Plugins, for example. They are not rich enough. There's a thread about that here: [https://news.ycombinator.com/item?id=20383714](https://news.ycombinator.com/item?id=20383714)
Enum is useful, because it provides you with names for compile time constant unique integer values. Furthermore, it defines a subset of integer values that are valid.
As a class, it is a good way to list relevant cases in complicated control flows. Personal example: I use it for physics problems that have simplifications that I can know apply to some given setup. I also use them to only select relevant derivatives for computations.
Not quite sure why you mix COM and C and C++. You can do perfectly well COM programming both in C or C++. The header that you expose to the user of your SDK does not need to get a C++ header if you do not want that, you could expose only C-headers but internally have it all in C++. You just need to distribute your binary static or dynamic lib specific for the platform the user has. There is no need to make things complicated by using COM.
The shown `enum SkipDescription` doesn't portably give you type-qualified value names notation you use. There are two ways to get that notation: * Using an `enum class`. * Placing the `enum` in a named scope (I prefer a `struct`). I.e., either enum class Skip_description{ no, yes }; or struct Skip_description{ enum Enum{ no, yes }; }; Since the latter C++03-style declaration provides implicit conversion to, but not from, plain integer types, I find it more practical. It's more to write up-front, in exchange for less to write each place an enum-to-integer conversion is desired.
OK fair point. Few things are that well isolated unfortunately.
Those are library features, which implementations keep providing as they are allowed to. Funny thing about random_shuffle is the code may well be broken now anyway since it's not a thread safe function.
&gt; There is so much legacy code out there that wont get compiled by anything newer than C++03 [citation needed] I have "legacy code" (i.e. working, debugged) from before 2003 that I'm still using. Basically it works, it's correct and there's been no need to change it. Other bits of the library have been updated to a more modern style, but only when work actually needed doing because I have better things to do than put new bugs into working code. &gt; C++ will not survive as a language if it gets cluttered year after year. Well, that's a fine sentiment. What would *you* remove.
I think this common confusion stems from the lack of understanding that std algorithms operate on ranges of objects(denoted by iterators). \`remove\` does remove values from a range \[begin, end), resulting in a range \[begin, result). \[result, end) is a range that contains objects with unspecified values (i.e. moved-from). &amp;#x200B; TL;DR: \`std::remove\` removes values not objects.
That's a real shame. I was really looking forward to use parameter packs without recursion.
Do you plan on letting others use your library in languages other than your implementation language? Do you want them to use a FFI and call into your library or use a Windows specific COM mechanism to allow limited language interoperability? If your target is Windows and let VB or C# or C/C++ only, COM might work. Not sure if other languages that support COM If FFI is an option, I would expose it via plain C (implementation can be in C++) since many languages support C FFI (Python, Go)
Not 100% what you mean by example, but https://github.com/zeromq/cppzmq does this with libzmq.
COM is here to stay a long time. A lot of stuff on windows is based of COM. You didn't say if you wanted cross platform support or cross language support. If it is c++ on windows only then define pure virtual interfaces that exploses pod like types or other interfaces (or avoid STL or classes like string). Provide factories to create them and methods to destroy them. This should be enough. If you want cross platform cross language, Google Microsoft xlang
Let me volunteer: // c_api.h struct CalculatorState; CalculatorState Calculator_create(); void Calculator_destroy(CalculatorState* calculator); int Calculator_add(CalculatorState* calculator, int a, int b); // cpp_wrapper_api.hpp #include &lt;memory&gt; #include &lt;function&gt; class Calculator { using StatePtr = std::unique_ptr&lt;CalculatorState, std::function&lt;void(CalculatorState*)&gt;&gt;; public: Calculator() { m_State = StatePtr(Calculator_create(), [] (Calculator* c) { Calculator_destroy(c); }); } ~Calculator() { Calculator_destroy(m_State); } add(int a, int b) { Calculator_add(m_State, a, b) } private: StatePtr m_State; }
Weird how other languages have figured it out.
Hi! Article's author is here. I'll glad to answer questions (because I'm afraid it could be not so easy to add a comment on Harb).
Clang can bring in multiple precompiled headers.
You don't need IDL files for COM. Or any registration stuff, type libraries, whatever. Newer Windows APIs like Direct3D, Direct2D or DirectWrite just provide simple IUnknown-derived interfaces and C functions as entrypoints that return factory objects.
I'm not sure I know about other native 30+ y.o. languages with gigantic codebases that figured this out. Which ones and how do they work it out, C++ could totally learn from them.
This reminds me of [RaftLib](https://github.com/RaftLib/RaftLib), another nice C++ DSL for dataflow.
Thanks for the reference! I didn't see that library earlier.
Enum is useful for specifying some named values. Like, you can use an enum for colors, which has values like green, blue, yellow etc. And using the enum can make it easy to use the correct value. You have the option to specify the underlying values to be used, like `green = 1`, which could potentially be useful in a domain where you perform some mathematics on these values. Also it is useful if you have a protocol where specific values have specific meanings and you need multiple programs to speak the same protocol.
I have no knowledge of XmlLite, but I would guess he means using COM without all the (IMO) optional parts. You provide public interfaces derived from IUnknown and instead of registering your implementations globally in the registry (or locally with manifest) and instantiating them with CoCreateInstance you provide C factory functions which return your objects. All that's used from COM in this case are the compatible vtable layout, reference counting semantics and QueryInterface semantics. This is the approach taken by Direct2D or DirectWrite for example. There's no need to pull in ATL or (OLE) Automation stuff (which I guess are the things most people dislike when they hear "COM").
C libraries are actually very easy to use from C# with `[DllImport]`. I would not go for COM, there is a lot of cruft and little to gain.
Java's various package managers work pretty much fine, though that is made easier by Java's design. I don't see why it being 30 years old with gigantic codebases is particularly relevant.
What is the platform? (Unix, Windows, etc.)
Yes, the type must be no-throw moveable. Also, you can use most external \`result&lt;T&gt;\` types: [https://zajo.github.io/leaf/#is\_result\_type](https://zajo.github.io/leaf/#is_result_type).
It's a silly question without context. Who are the clients? Do they use COM? Is it that the code is mostly C++ but they are .NET? Or...? It depends on clients, not reddit. Ask them.
I second to it. Automation (subset of COM, basically \IDispatch`-derived or dual interfaces) is well integrated into Windows. If you provide Automation-compatible interfaces, your component will easily be usable from .NET, Windows Scripting Host (VBScript, JavaScript), PowerShell and, of course, native code. The good thing is that API can be made self-explanatory (there is even a way to provide built-in human readable description for interfaces, methods and classes); the bad thing is that the technology and especially tooling is a bit outdated. However, I have an experience of writing modern C++ wrappers around various COM concepts, so modern C++ code can easily both provide and consume COM interfaces without using macros. A good starting point would be to browse C++/WinRT because, as said above, Windows Runtime builds upon COM and C++/WinRT provides strong C++ support for the technology.
If you want to be focused on programming, opengl. If you want to be focused on building games, unreal.
I've heard of unreal but never heard of opengl. Thank you for your response.
Simple dml. We used it in university.
Com, OLE, and ActiveX makes me want to kick the guy who made it in the ballsack. I added the guy who developed the Bluetooth API to my ballsack kicking list and later found out that it may be the same guy who made OLE.
&gt; Now the compiler will stop anyone from calling `setOrientation` with any value except `Orientation::HORIZONTAL` or `Orientation::VERTICAL`. Not quite: https://godbolt.org/z/nlQfXz
This may not be a direct answer but the cppcast podcast has on a decent number of game developers from different background(indie-corporate) and you may be interested in listening to those episodes to see what they use in their work. When I did a small game for a school project I used SFML it has basic drawing and sprite features nothing too crazy but good to get your feet wet.
Yeah, but you're explicitly asking the compiler to cast. You could also drop to an `asm` block and call it with anything you want. But you're going to do that kind of nonsense because the compiler told you "`42` is not a value of type `Orientation`."
I listen to that podcast and it’s great, although i got on it late so i’m on like episode 80 😂, still a long way to go
Link to the actual article from the Microsoft Security Response Center: https://msrc-blog.microsoft.com/2019/07/16/a-proactive-approach-to-more-secure-code/ . The gist of the article is: &gt; A language considered safe from memory corruption vulnerabilities removes the onus of software security from the feature developer and puts it on the language developer. And while I agree with the premise that using a language safe from memory corruption is a boon for software security, and solving 70% of CVEs in one feel swoop would be an awesome achievement, I do not agree that this completely absolve the so-called "feature developer" from thinking about security. For example, I remember a new mobile phone application which allowed connecting to your car's computer at a distance, allowing you to review your car's travel history, lock/unlock the car, activate/deactivate the heater, etc... internally, the web-service used by the application was simply sending the car ID to the HTTPS endpoint. This meant that going down the street, checking the sticker with the car ID on the windshield of cars of that model, anybody with a "crafted" mobile app could unlock that car by its ID, check the owner's travels, etc... Now, it could be argued that it's a business analyst/designer to think about the security implications, and take that off the feature developer's lap too. Certainly. In practice, though, I do think that security works best if all involved consider it carefully during the whole development cycle.
&gt; Hopefully, "Boost UI" does not rely heavily on wxWidgets as well. No, no no no. Boost UI *is* just a RAII wrapper around wxWidgets which exposes modern C++ interface. There is no way you could plug a different implementation. I don't get the second part of your response because your library seems to draw own widgets. You say that native APIs can never be good enough (which I can agree with after even slight use of Microsoft APIs) but users point out that some of your widgets (knobs) are not convenient to use either.
A lot of the design of COM is still valid. I'm not sure if it's that relevant today, just because it's not been adopted outside windowsland. We are seeing a resurgence of various IDL languages. It /is/ worth learning if only to understand all the design decisions and why they were made. (Sidenote: I wish the history and design of the windows graphics stack was better documented, Direct3D and DXGI in particular would make a wonderful case study).
Outsourcing more and more of their core product isn't going to help much either. Also I wonder how long its going to take them to make a new project and then scrap it.
interestingly you can get a C API for most COM interfaces by defining `C_INTERFACE` or somesuch before including their header (note that the C output of the IDL compiler is much more likely to have bugs than the C++ output).
You answered yourself why Java case is completely different from C++ case. The age matters because pretty good solutions for C++ exist even today. Communities around them are very non-existent. They require either system lock (because of the fixed toolchain) or build system lock (what's the point of C++ if you can't use existing libraries, just go Rust then) or just rewriting all build scripts completely (which costs $$$). You would complain that a popular library doesn't support it. You would complain that it doesn't support Windows. You would complain that it doesn't work with anything other than autotools. You would complain that your favourite library isn't updated fast enough in the package manager's repository. If there is no common solution doesn't mean that people are not trying. It's hard to wrestle with dozens of years of very old code that is actively supported still and will be for another few dozens of years at least.
Take a look at [xlang](https://github.com/microsoft/xlang), it's effectively a light-weight cross-platform / cross-language COM-like technology. The documentation is not great (missing a "getting started") but it's designed specifically to solve the ABI issue.
How does Clang/MSVC matter here? Library compiled with MSVC will be (or rather should be, cons bugs) abi compatible with the same library compiled by Clang with MSVC ABI.
Just go for a plain c api. It can be used without hassle in c# and c++. Dont wrap it into something that is hard for you to make and others to use
If I remember correctly DCOM timeout can be set in the registry.
&gt; a library compiled for Windows with MSVC is not compatible with a client compiled with Clang also for Windows (valid scenario for us). That's incorrect. As long as you're using Clang with MSVC's STL, Clang will emit binary-compatible output. Source: I'm an MSVC STL maintainer, and have worked extensively on Clang compatibility. (This particular feature is because Clang did the insanely difficult work to match MSVC's ABI.) If you were to use libc++ on Windows (which isn't supported yet), then that would be thoroughly incompatible with MSVC's STL, of course.
So was i. I mean, they removed the best part of the proposal in my opinion. Being able to loop through the args of a parameter pack without using recursion would be really great! It would simplify a lot of code.
You need to be more specific. There are parts of C++ syntax, which are legal but considered outdated. But stuff like: int i; is valid C not considered bad by many people.
The following would be the first few things that come to mind for me: &amp;#x200B; |C|C++|Rationale| |:-|:-|:-| |Store strings in char\* + '\\0'|Use std::string|Less error-prone, easier API, can be turned into a const char\* to access its underlying memory| |Use malloc/free to allocate from heap|Use std::make\_unique / std::make\_shared|The make\_\* helpers return smart pointers that automagically free the heap memory when they go out of scope (unique\_ptr) or have no other references (shared\_ptr)| |Use (type) something to cast|Use std::static\_cast, std::dynamic\_cast, std::reinterpret\_cast &amp; co|The C++ style casts are better at showing your intention of the cast and it's not as easy to screw up (cast downwards in class hierarchy, etc.) | &amp;#x200B; Anything from the "C" column does work in C++ but it carries over all the potential pitfalls you probably know from C. The stuff in the "C++" column can be used to achieve the same at zero or near-zero performance overhead and you can rule out whole classes of errors (buffer overruns for string, memory leaks for heap allocations) by using them.
You can do whatever you want. All programming communities are full of people regurgitating cargo cult dogma. A lot of times whatever the current fad is in coding methodology sacrifices performance to gain readability/maintainability, but often even fails to achieve that. Stackoverflow is especially full of high and mighties repeating such platitudes as "premature optimization is the root of all evil" and "just let the compiler do it's thing". The #1 thing for a C/C++ program must be performance. Otherwise why even use a bare metal language? Something like C# or Java will give you better platform compatibility and faster application development. Python will make things even faster to develop. The #2 concern is readability and future maintainability. If you feel that C style is more appropriate for that, then go for it. I mix and match C++ idioms and C idioms in the same codebase depending on what is required.
How can I fix the issue?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ceha9r/beginner_with_canvasother_graphic_libraries/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Certainly makes sense. I think that most of the memory bugs could be fixed by using modern c++, but if you are rewriting the code anyway, why not just use a language that makes it much much harder to have memory bugs and to cut corners in the first place.
It would be interesting if MS let Anders Hejlsberg design a C/C++ competitor. The guy has the chops.
FWIW, static_cast/dynamic_cast/reinterpret_cast are keywords, not library functions, so don't accept a `std::` namespace qualifier.
std::vector instead of C style arrays. std::array if you must.
Good catch, That's what happens when writing posts while being distracted with other stuff ;) I'll edit it in a sec.
Sadly yes. I still get nightmares.
&gt; The #2 concern is readability and future maintainability. If you feel that C style is more appropriate for that, *You would be wrong* ~~then go for it.~~
It's more like std::array if you can... It's just usually you don't know sizes at compile time.
It is considered bad by most people since it's uninitialized ;-).
This is basically a call for totally statically typed error handling, which sounds nice in theory but is actually incredibly brittle. Really checked exceptions are the only example of this in real life and they're not exactly popular. I know you're a fan of rust, even rust suggests combining errors via type erasure mostly in the manual. Most error handling systems are statically typed by at most whether or not they can produce an error, not all the error types they can produce. LEAF is consistent with that.
Game development does not have to be synonymous with C++. I enjoy tinkering with game development and using c++ for that, but I just wanted to point out that UE4 gives you the option to do GUI programming via blueprints, and Unity would give you the option to use C# if you find that language to be preferable. If you do want to use c++, here's some recommendations from me in no particular order: SDL/SDL2 - A lower level graphics/sound/input library. Not hard to use, but harder than other options imho. It uses somewhat less modern conventions as part of it's API (lots of raw pointers) SFML - A little bit higher level graphics/sound/input library. I find it easier to use than SDL, and you get modern features like smart pointers. The tradeoff is that I think you'll have less control over your graphics pipeline, as SFML is abstracting a lot of that for you. CMake - If you're going to use one of the two libraries above, you probably should know how to generate a build system. UE4 - Obviously if you want to use a game engine you have to learn one. There are many other smaller options for engines that utilize c++, but UE4 is the biggest afaik. Unity - Also an option but it doesn't use c++ so I suppose it falls outside the scope of this post!
COM is still used by everything DirectX application, so yes. It is valid, but I don't think anyone actually likes dealing with it.
I would take a look into Lewis Baker's excellent articles on that subject: [https://lewissbaker.github.io/2017/09/25/coroutine-theory](https://lewissbaker.github.io/2017/09/25/coroutine-theory)
I also started learning game development this week using SDL2 I found this great tutorial [http://lazyfoo.net/tutorials/SDL/index.php#Getting%20an%20Image%20on%20the%20Screen](http://lazyfoo.net/tutorials/SDL/index.php#Getting%20an%20Image%20on%20the%20Screen)
Not all the time but sometimes it may be better to use C.
For the most part, I agree that it's important not to remove features that are widely used. However, I do think that it's entirely reasonable to deprecate a feature, and then remove it later. E.g. 1. Deprecate a feature, but leave it in the language standard. Make use of it issue a warning 2. Next release, make the deprecated feature issue a warning unconditionally 3. Release after that, remove the feature from the language, and simultaneously issue a TS describing the feature that was so removed. Use of the feature without explicitly enabling it in the build settings is now a compile error. 4. Last release, Issue a notice that the TS in question is now considered defunct and the C++ standards body has nothing to do with it. People using the feature are entirely on their own. That gives a 12 year, gradual, migration path for features that are removed. Lot of work? Yep. Worth it? Don't know.
The person you're responding to means the Unreal Engine, which is a commercial game engine that has a variety of license options that allow you to use it at no cost to you.
UWP applications are COM-based. COM has dominated Windows development for over 25 years and it's use has increased significantly over the last 5 years. I don't know what kind of mistakes people are talking about, but the fact is that for a 25 yo technology that managed to sustain and grow, COM is a masterpiece.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ceehke/why_is_enum_useful/eu2p7nu/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There's a vast difference between using C idioms and C library functionality, which is generally not a good idea in C++, and using C **syntax**. * Declarations. For declarations C syntax used in roughly the idiomatic C way is still what the vast majority of C++ programmers are used to and expect. There are two main exceptions. First, that instead of C style `typedef struct { int x } S;`, in C++ one writes `struct S{ int x; };`, and secondly, that in declarations of variables, in C++ one emphasizes that type and ideally declares just one thing per declaration. * Flow control statements. Where in C one would use a counting `for` loop, in modern C++ it's usually more convenient and clear with a range based `for`. * Casts. Most experienced C++ programmers agree that C style casts like `(Blah*)p` (even written in C++ style as `Blah_ptr(p)`) are bad, because when the code is maintained the meaning of such a cast can change, and because a reader of the code needs to inspect the declaration of whatever's casted to know what the cast does. Instead in C++ use the named casts: `static_cast`, `const_cast`, `dynamic_cast` or `reinterpret_cast` (of course that's not possible for a cast to inaccessible base, but if you find that you apparently need that, then consider if the design is really as good as possible). --- An example of using the pure C library is to use `malloc` and `free`. There can be good reasons for doing that in some special situations (in particular, use of `realloc` for efficiency), but in general it's ungood. In C++ use standard library containers and string types; if those don't cut it use smart pointers, preferably as the internal implementation of some custom container or thing; as the ultimate fallback, very rare, use `new` and `delete` expressions; don't use `malloc` &amp; family. In particular don't handle strings by allocating `char` arrays, just use `std::string`. And don't handle variable size arrays by using dynamic allocation yourself. Use `std::vector` (or other container). --- As an example of C syntax and idiom, consider int *p, x; That's IMO ungood because it declares two things of different types in the same declaration. C++ style (but still technically C syntax): int* p; int x; Whether these should be initialized by default, is another discussion. --- What if you want to name a string literal? In C++03 one would write something like char const* const s = "Hello"; That's pretty awkward notation, and it discards information about the length of the string. To keep that information one would instead declare an array, and just hope that the compiler would optimize away the copy initialization of that array: const char s[] = "Hello"; With C++11 and later one can instead just declare a reference to the object denoted by the literal: const auto&amp; s = "Hello"; Or one can declare a `std::string_view` to access it, with the length computation forced to be at compile time: constexpr string_view s = "Hello"; This is *still* C syntax, but used in a restricted way, and involving some C++ only features (`auto`, `std::string_view`). --- For pointer declarations I've experimented with and now find it generally useful to define template&lt; class T &gt; using P_ = T*; Then one can write things like const P_&lt;void()&gt; f = foo; ... instead of the more C style void (*const f)() = foo; The template based way is *still* C syntax, but using a pure C++ feature, templates. A main advantage is that it supports consistent prefix `const` notation. A main problem is that a majority of old-timers, the experienced C++ programmers, find it totally unnatural, so much that some claim to not understand it (which is clearly not true, but which reflects a very strong negative reaction to some aspect, probably the visual appearance). Another advantage is that it prevents *inadvertent* declaration of two or more things with different types: int* p, q; // Oops, different types. versus P_&lt;int&gt; p, q; // OK, same type. One could use a similar notation for references, for consistency, but since one can't have references to references the only advantage is that consistency. At one time I thought that was enough of an advantage to do it. I no longer think so: convincing old-timers that `P_` is objectively a practical notation, is hard enough.
Indeed. Error handling is at least to a degree a dynamic process, or else `EACCESS` and `ENOENT` would have to be different types. The reality is that they are different values. When matching an error to an error handler, both static and dynamic matching is needed. In LEAF, the static matching is supported by simply writing a handler that takes a given type: return leaf::handle_some( [&amp;]() -&gt; result&lt;T&gt; //the "try" block { ... }, [&amp;]( my_error_code ec ) { ... } ); Above, the error handler taking a `my_error_code` would be matched if there is an object of type `my_error_code` associated with the error, that is, the dispatch is done based on the static type of the object. It's also possible to dispatch dynamically: return leaf::handle_some( [&amp;]() -&gt; result&lt;T&gt; //the "try" block { ... }, [&amp;]( leaf::match&lt;my_error_code, 42&gt; ) { ... }, [&amp;]( my_error_code ec ) { ... } ); Above, if there is a `my_error_code` with value `42`, LEAF will hit the first error handler, while any other `my_error_code` will be handled by the second error handler.
I'm not seeing an actual concrete inhibitory problem there.
std::array is kind of silly. If I know the size at construction, you'd think that would be enough, and if the size can be known at compile time then be constexpr. Sometimes little restrictions in C++ I don't get.
Ah, good, so function-style casts are still OK ;)
 auto i = int{};
Depending on how it is being used, that is not necessarily a problem.
Will we ever embrace Herb Sutter's aaa style `auto i = int{};`? Wouldn't it be cool if auto became implicit?
`string_view` vs `const char[]` will give you quite different codegen, especially on microarchitectures. There's better ways to do it, but not in the standard library.
For your own projects you can do anything, but if you are working with me, you follow my style guide. &gt;The #2 concern is readability and future maintainability. If you feel that C style is more appropriate for that, then go for it. C is never more readable, unless you don't know C++. This is because C++ uses many sharp tools that present intent. C uses a few blunt tools that work on many things, which is great for 101, but doesn't replicate intent as well.
Not for network errors, maybe you are thinking of transaction timeout? DCOM uses RPC but DCOM does not give access to the RPC binding handle.
&gt; Since STL is header-implementation, a library compiled for Windows with MSVC is not compatible with a client compiled with Clang Ehhhh? If your library has a C interface, you're not going to pass STL objects using that interface. If your interface *does* use STL objects, your only choice is a C++ interface. So no need to decide between C and (ugh) COM.
I always write the std:: automatically and then have to go back and delete it
&gt;it's use has increased significantly over the last 5 years I call bullshit on that. Most people do not write new software with COM.
What restrictions are you talking about?
C doesn't show intent as well as C++, which is why, if you can, default to C++, so other people can have an easier time reading your code. Likewise, years later if you come back to it, it will be easier to read your own code. Also, no one has written about it in this thread so I might add [algorithm](https://en.cppreference.com/w/cpp/algorithm) can be a good idea, especially if you're writing the same kind of loop over and over again. Popular loops can be written as algorithms, which makes code easier to read. However, algorithms are not popular today, so you wouldn't be out of place not using them.
a vector can change size with push_back(). So no you can't determine the size at with a constexpr constructor on a std::vector because its fundamentally dynamic memory. I agree with you std::ring_array would be cool af.
Could you elaborate some, please?
The view is effectively a pointer, whereas `const char foo[] = "asd";` *is* the string value (but can be trivially decomposed to a pointer). When using said string on, say, AVR, you will get different codegen - substantially worse for the former. You can make a sorta-view type which instead stores the passed string as part of it (the syntax is wonky, though), so `sizeof(wonky_string("aaaaaaaaaaaaaaaa")` is 17 rather than `sizeof(const char *)`, thanks to class template argument deduction.
CppComponents was created for exactly your scenario. [https://github.com/jbandela/cppcomponents](https://github.com/jbandela/cppcomponents) It uses template metaprogramming and creates COM compatible classes under the hood and allows you to use STL types as function parameters and return values, even across different compilers and standard libraries. It is also cross-platform (tested with Windows and Linux). Here is a talk on it from C++Now. [https://www.youtube.com/watch?v=a4iFJuNBx7U](https://www.youtube.com/watch?v=a4iFJuNBx7U)
Is it, that the compiler for the AVR doesn't support `constexpr`?
The cool thing about std::array is that it had literally zero overhead. It is like the C style array, but with methods.
If it comes to this, I might as well directly code in python...
There is simply no reason to leave it uninitialized and it is UB waiting to happen.
It's really not as much about syntax (C++ uses C syntax, but has more features) as it's about not coding in a C-style. The reason you don't want to do this, is not because there's anything wrong with it (sometimes you really do need malloc), but because you're setting yourself up for not taking advantage of using C++ features which could help you get where you want faster and safer. That's really the issue here, because you could just keep on coding as if you were coding in C, but then you're kind of wasting a lot of resources C++ provides. Oh, and also a lot of people here are telling you to use smart pointers or wrap your pointers in a typedef or something - that's really a matter of taste, imo smart pointers are kinda awful, pointers are fine, just avoid them and use references whenever you don't accept nullptr.
The basic ideas of COM are IMHO still perfectly valid, there is nothing that can claim to replace it. The problem &amp;#x200B; Shameless plug: I've been toying with something like COM but with a clean, modern C++-syntax for years now - I'm not claiming it's perfect, but it nicely hides all the ugliness that traditional COM implies: [https://github.com/MFHava/CWC](https://github.com/MFHava/CWC) Warning: currently it's designed to only support C++, though creating a C#-binding would be easy to write...
I hate it. I did write a program with *auto*s all the way through, but decided in the end I **really** liked knowing exactly what types my variables were, and most of the time it just doesn't hurt to be explicit.
Android have the AIDL especially
Prior to C++ (which is in itself roughly 35 years old), the C language was a very different animal than it is now (modern cpp). Semantic issues, new features and language improvements have moved the ball very far along since that time. Modern conventions such as using *nullptr* instead of whatever *NULL* was defined to on your platform, ensures compile time safety of pointer checking and solves problems before they happen. The benefits to writing modern cpp is significant. We are no longer as critically interested in only const char * (see: std::string); we now have an STL which provides performant data structures with prescribed interfaces (see: std::vector, std::array, std::map, ...). We now have pointers with auto indirection which absolve us of checking them for null (see: references). Obsessing with old C issues, or avoiding modern STL only leads to mounting fear of cpp. And as we all know, "Fear leads to anger. Anger leads to hate. Hate leads to suffering." -Yoda
it's as good a time as any to boycott them, then
&gt; I think that most of the memory bugs could be fixed by using modern c++ For me this is simply [a myth](https://www.reddit.com/r/cpp/comments/cbsbls/c2a_coroutines_and_dangling_references/etixfmf/?context=3).
I'm not going to argue whether something is okay or not - that's totally up to the individual programmer and possibly their project's style guide ;) For myself I used to be an avid C programmer and know my way around its pitfalls but somewhere around the drafts for C++11 I realized that C++ is equally powerful and performant as C but has quite a lot of stuff that makes programming more productive and less error-prone so where possible I'm trying to use it since then. It's basically the best of two worlds: You can use it like a macro assembler on steroids - sometimes in even more extreme ways than C when you leverage template meta-programming - but If that isn't required it's not forced upon you in any way and you can switch to higher-level parts like the STL, smart pointers, etc. which are a huge time-saver when you can rule out complete categories of potential sources for bugs and e.g. prove that your code is leak-free by design.
I really prefer using C-style cast when casting numeric types, e.g. between size_t and int. Just for readability.
Hejlsberg is overrated; C# was utterly boring until Don Syme added generics to it.
Considering that you are addicted it doesn't really matter where you start, you'll eventually cover everything... :) j/k - Learn about RAII. Get badass at templates.
You could run your build with clang's sanitizer which would catch the use-before-init UB (I think). If you don't have any invalid value for your variable, you cannot check (with an assertion for example) that it was indeed written to before being read. Of course this is really bad design (if your initialisation is so complex you should probably return the value from a function) but that's one valid (albeit horrible) reason to do so
And I think stuff too, look: "yes, I think stuff".
Unless they also make cpp strongly typed that's never gonna happen
Pardon my ignorance, but is the buffer generally stack or heap allocated for std::array?
What are you referring to exactly? &gt;If I know the size at construction, you'd think that would be enough, and if the size can be known at compile time then be constexpr. ```std::array&lt;T, N&gt;``` is ```constexpr``` if ```T``` is constexpr.
All good points. My initial thought was not to change any of the other semantics, but simply have a way to capture/use the resulting type of the initializer expression. So if the initialization was unintuitive, it would still be unintuitive (perhaps leading to a compilation error as a result), and not adding any SFINAE cases (although that could be interesting and possibly fix some of the unintuitive cases), etc. Basically, my proposal is to treat it as passing an initializer list, but by adding the \`auto\` prefix, the resulting type would be the result of the initialization, as resolved by normal resolution rules for the parameter type. It would, of course, alter some of the "expected" behavior, as the initializer resolution would need to happen "before" the calls on the resulting type (captured via the \`auto\`). And indeed, depending on the effort required, it could certainly not be "worth it"; I'm primarily just curious if there's a reason why it would not be possible.
A lot of people find the use of ```auto``` everywhere to make code very difficult to read. There is a lot of value in knowing how a type can be used just by looking at its declaration.
AFAIK there's no requirement set out, but it's generally on the stack.
Ya, all the new software, which is most likely UWP apps, are not COM.
Adding to the malloc/free point, you can mostly get away with not directly dealing with heap memory at all by using containers. I've seen a lot of code where people use the heap for no reason at all, the most egregious cases are where someone calls new/delete on something like a std::vector, replacing that with make_unique is only slightly better. Sure there's some cases where you really do need to stick something on the heap directly using unique/shared_ptr, but those are exceptional and are often avoidable by adding a layer of abstraction.
In addition to the other comments: The idea is that C ABIs are notably more stable and can be used from most other language environments via a FFI(-like) interface or language bindings. Thus using C for the binary interface is good. For providing a "nicer" experience to the user you can provide a C++ wrapper around the low-level API, transforming C patterns to C++. Now distributing this as (binary) library of course defeats the point, but a set of headers can be compiled by whatever C++ setup, compilers, runtimes, ... as the consumer likes, while the bianry interface is still the C library. If well done this can even be a zero-cost abstraction.
Well, C and modern C++ have evolved into completely DIFFERENT languages today. Sure there are some programmers that continue to program in an old subset of C++, essentially using mostly C, with some added features from C++, which some of them refer to as "C with Objects". And that's perfectly fine! If that's all the project calls for, and you're hired to work on such a team--I mean if that's how the team's been doing it, then that's what you gotta do in a case like that! Or if you're a hobby programmer and enjoy this older style of "C with objects" and it works well for your projects, then again: great! Keep doing it if that's what you like and enjoy the most. C++ continues to support and allow for that older style. -------------------------------- BUT... most modern development projects use a decent range of modern and advanced features from C++. So... you'll be missing out on an entirely new language, and lots of powerful tools you can add to your programmers toolbox, if you dig in and resist learning modern C++ (which again is an utterly different programming language than C). If you resist learning... then you won't truly know modern C++. Again, you'll "only" know C with objects, or some slightly modified C... but again, you won't come to know true and modern C++. -------------------------------- FURTHER: it's worth mentioning that NOBODY ever learns all of modern C++! So if that's what you're afraid of--having to learn too much, that it seems overwhelming--then don't let that worry you! Nobody is going to expect you to "know all of C++"! C++ is a VAST language, that is PURPOSELY loaded up with lots and lots of programming features and different ways of doing things. Again this is done on purpose: It's meant to be the most powerful and comprehensive programming language, that supports multiple paradigms, from old to new. (Plus, if you know a decent amount of C++, then any other language you learn is going to be a walk in the park!) -------------------------------- So... given this... At the beginning, when learning C++, the best approach is probably: ------------------------ 1) Learn a smaller subset of C++ really well, and gradually and slowly learn the additional features slowly over time--focusing on the most used features first, such as OOP, but other aspects as well. ------------------------ 2) In addition to that small/slower approach, you can also read a book that survey's the entire C++ modern language. Not because you want to try to memorize or learn everything at once--which again is not possible with C++--but rather just so that you are slightly and vaguely familiar with all that C++ has to offer. That way when you join a new project, or encounter a problem you need solve, you'll know the basic foundation of what's going on, or what approach to use, and then you can just brush up on that area before diving into the project. -------------------------------- FINALLY... I said above that "nobody" knows all of modern C++, and that's pretty much universally true... almost... There are a few people--a very small number--in the world who learn C++ deeply, and fully. Those are people like PhD level university professors or computer scientists that work on standards committees, or end up heading the computer department at major world corporations. Or sometimes people who have loved C++ and worked with it for over a decade in depth and detail, day in, day out... But again nobody's going to expect you to be at those levels with C++ anytime soon in your career! (If ever.)
Some people just like to try and find anything they can be condescending about.
Well, C and modern C++ have evolved into completely DIFFERENT languages today. Sure there are some programmers that continue to program in an old subset of C++, essentially using mostly C, with some added features from C++, which some of them refer to as "C with Objects". And that's perfectly fine! If that's all the project calls for, and you're hired to work on such a team--I mean if that's how the team's been doing it, then that's what you gotta do in a case like that! Or if you're a hobby programmer and enjoy this older style of "C with objects" and it works well for your projects, then again: great! Keep doing it if that's what you like and enjoy the most. C++ continues to support and allow for that older style. -------------------------------- BUT... most modern development projects use a decent range of modern and advanced features from C++. So... you'll be missing out on an entirely new language, and lots of powerful tools you can add to your programmers toolbox, if you dig in and resist learning modern C++ (which again is an utterly different programming language than C). If you resist learning... then you won't truly know modern C++. Again, you'll "only" know C with objects, or some slightly modified C... but again, you won't come to know true and modern C++. -------------------------------- FURTHER: it's worth mentioning that NOBODY ever learns all of modern C++! So if that's what you're afraid of--having to learn too much, that it seems overwhelming--then don't let that worry you! Nobody is going to expect you to "know all of C++"! C++ is a VAST language, that is PURPOSELY loaded up with lots and lots of programming features and different ways of doing things. Again this is done on purpose: It's meant to be the most powerful and comprehensive programming language, that supports multiple paradigms, from old to new. (Plus, if you know a decent amount of C++, then any other language you learn is going to be a walk in the park!) -------------------------------- So... given this... At the beginning, when learning C++, the best approach is probably: ------------------------ 1) Learn a smaller subset of C++ really well, and gradually and slowly learn the additional features slowly over time--focusing on the most used features first, such as OOP, but other aspects as well. ------------------------ 2) In addition to that small/slower approach, you can also read a book that survey's the entire C++ modern language. Not because you want to try to memorize or learn everything at once--which again is not possible with C++--but rather just so that you are slightly and vaguely familiar with all that C++ has to offer. That way when you join a new project, or encounter a problem you need solve, you'll know the basic foundation of what's going on, or what approach to use, and then you can just brush up on that area before diving into the project. -------------------------------- FINALLY... I said above that "nobody" knows all of modern C++, and that's pretty much universally true... almost... There are a few people--a very small number--in the world who learn C++ deeply, and fully. Those are people like PhD level university professors or computer scientists that work on standards committees, or end up heading the computer department at major world corporations. Or sometimes people who have loved C++ and worked with it for over a decade in depth and detail, day in, day out... But again nobody's going to expect you to be at those levels with C++ anytime soon in your career! (If ever.) -------------------------------- EDIT: I guess a good metaphor is this: All doctors learn medicine, but then they specialize, or generalize. For example, if someone becomes a world class brain surgeon, then they still have know the basics of how to help someone give birth... But their main focus is brain surgery (not obstetrics). So modern C++ is like that--medicine. It lets you become a highly specialized world class expert in modern paradigms, but you won't be using all the paradigms and features of C++ everyday... you'll tend to specialize in a set of features (depending where you work, and on what types of projects). But you'll still need to know that those other paradigms/features exist, and some basics about how to use them... just in case! It will also make you a better all programmer all around... Because a brain surgeon never knows if they meant one day encounter an emergency birth they need to help with!
&gt; If I know the size at construction, you'd think that would be enough, A different template parameter means a different type, and types are generated at compile-time. The code for a `std::array` of a different size doesn't exist in your executable. If you want a contiguously-allocated container, use `std::vector`. Its elements are guaranteed to be allocated as one block, and you can use the `.data()` accessor method to get at that hunk of memory. The big win of `std::array` (versus `std::vector`) is the use of stack memory, and creating things of unknown size on the stack is pretty dangerous. There is probably a way to generate a class that does what you want using `alloca()`, but it would be way easier to use dangerously than `std::array&lt;&gt;`.
What's a good alternative to COM if you want interprocess communication on Windows? Does the registration free COM work for interprocess communication?
&gt;why not just use a language that makes it much much harder to have memory bugs and to cut corners in the first place. It's probably way harder to find competence for rust for one thing. It's hard enough to find c++ programmers sometimes.
Always stack
That you can't do something like this: #include &lt;iostream&gt; #include &lt;array&gt; #include &lt;vector&gt; int main() { std::vector vec = {1,2,3,6}; std::array&lt;int,vec.size()&gt; ary; } &gt;playground.cpp: In function ‘int main()’: playground.cpp:7:25: error: call to non-constexpr function ‘std::vector&lt;_Tp, _Alloc&gt;::size_type std::vector&lt;_Tp, _Alloc&gt;::size() const [with _Tp = int; _Alloc = std::allocator&lt;int&gt;; std::vector&lt;_Tp, _Alloc&gt;::size_type = long unsigned int]’ std::array&lt;int,vec.size()&gt; ary;
You can't use registration-free COM for system services. I am not sure about other types of interprocess COM. On Windows, the only supported frameworks for interprocess communication are RPC and COM (and network loop-back). That being said, there is nothing stopping you from using COM as the communication channel for something like Protocol Buffers. Though I've never actually tried this before.
No, I know std::vector is the way to go. 1) It is weird std::array has enforced constexpr. You can speculate reasons as to why it is, but the point is the logic behind the decision from the standards committee. Allocating an array on the heap isn't any slower, and even the C++ standards do not enforce that std::array be on the stack. 2) It makes code more explicit. If std::array is a contiguous datatype that does not grow, yet std::vector is a contiguous datatype that does grow, it's obvious what the intention is. Instead std::vector is used for arrays that do grow and do not grow, and std::array is used for constexpr time optimizations. That isn't obvious to a newcomer.
You know `auto i = int{};` is an int. The point of this syntax isn't hiding the type, but making code more readable. This is because when reading code eyes move from the left to the right, so when the left most real estate has the variable name, it's easier to find what you're looking for. Therefore, it is better if the type is specified on the right hand side. The same goes for templates. You'll often see the template bit then the function name on the next line, instead of all in one line, because it's harder to read without having the function name to the left.
You didn't even make `vec` constexpr, which it would obviously need to be for this to work; which just raises the question of why `vec` would be a `std::vector` in the first place if the elements were constexpr and known in advance. So why would this ever possibly be useful?
The point is constexpr is enforced, when not forcing it wouldn't slow std::array down.
This comment is completely nonsensical.
&gt;C++ programming is based on strong static type checking, and most techniques aim at achieving a high level of abstraction and a direct representation of the programmer’s ideas. This can usually be done without compromising run-time and space efficiency compared to lower-level techniques. To gain the benefits of C++, programmers coming to it from a different language must learn and internalize idiomatic C++ programming style and technique. The same applies to programmers used to earlier and less expressive versions of C++. -- Bjorn
What's the difference?
Hofstadter would be amused.
&gt;C++ programming is based on strong static type checking, and most techniques aim at achieving a high level of abstraction and a direct representation of the programmer’s ideas. This can usually be done without compromising run-time and space efficiency compared to lower-level techniques. To gain the benefits of C++, programmers coming to it from a different language must learn and internalize idiomatic C++ programming style and technique. The same applies to programmers used to earlier and less expressive versions of C++. -- Bjorn
When you right `auto var = VarType(...)` or `auto var = VarType{...};`you know exactly what type it is because you wrote it on the RHS. Unless someone is secretly going around putting in free functions that look like types into your code.
Because it's a template parameter. How could it not be constexpr? The size of vector is known only at runtime, but the size of array must be known at compile-time.
It's automatic memory. You can allocate an std::array itself on the heap, though.
&gt; even the C++ standards do not enforce that std::array be on the stack. It's not on the stack OR the heap. It's automatic memory. The standards do enforce that no heap is used.
Do you know why the standards enforce no heap?
Std array is a type that stores its contents contiguously within it. This has many benefits, including performance benefits. All types in C++ have known sizes at compile time. A std array that has a dynamic fixed size would not be able to store its contents within it. This requires using the free store, damages memory locality, prevents constexpr implementations, adds an indirection, makes SSO based optimization harder, and steals candy from cute babies.
&gt; but the size of array must be known at compile-time. Yes, but my point is asking why the standards committee made that rule.
&gt; It is weird std::array has enforced constexpr. You can speculate reasons as to why it is, but the point is the logic behind the decision from the standards committee. Because it's a templated type. Template parameters must be known at compile time (clause 17.3.2, paragraph 2). This is not speculation. Consider the case of a templated type which has a partial specialization for N=0 or N=1 which expose different functions. This would not be provably well-formed at compile time if templates could have variable non-type arguments.
Love the `CMAKE_GENERATOR` env variable feature as well as the ability to set the loglevel easily
Thanks. I was just curious so I benched std::array to std::vector and std::array constantly came out 2x faster.
Your reasoning is an example of something called the Oversimplified Cause Fallacy. Basically, just because something exists doesn't make it the cause for why it is. The standards committee chose std::array to not be on the heap and then to make it explicit to readers made the size of the array a template argument. Why its syntax is that way is an effect, not the cause.
Check out the Handmade Hero project! It is a series that shows the development of a full 3d game; it consists of 500+ live streams of a programming session, followed by a QA session. The project is directed by Casey Muratori, a somewhat well-known game programmer, he's also the person that does the live streams and most (all?) of the programming in the project. https://handmadehero.org/ https://www.youtube.com/user/handmadeheroarchive The youtube channel has the streams separated by topic into various playlists.
This is either a "how to get started with C++" question, in which case it's off-topic and you should read the sidebar, or it's a "how to get started with C++ game programming" question, in which case it's off-topic and you should consider /r/gamedev.
&gt; Your reasoning is an example of something called the Oversimplified Cause Fallacy. Your question was literally why you cannot do something like this: std::array&lt;int,vec.size()&gt; ary; I provided the answer to that question. &gt; The standards committee chose std::array to not be on the heap for speed reasons. Citation or Hitchens's Razor. N1479=03-0062 doesn't mention speed once.
It is not really only about syntax. Syntax is the least important.
I never asked why you can't do something like that.
Yeah whether the type is specified explicitly LHS or RHS doesn't matter, as long as it's there - what you want to avoid however is writing something like ```auto i = 0;```.
And tooling, debugging and high quality optimizations and stuff. It's a less mature language and there's no way around that. I don't think that alone means you shouldn't use it, but I agree it is an argument.
If it can throw exceptions then it might lead to code pessimisation, perhaps? I don't actually have comparisons to hand, might be interesting to check on godbolt.
Have fun writing for AVR.
C style code is considered "bad" in C++ for a variety of reasons, but lack of RAII is probably the biggest. If object construction is successful, it should be in a valid state. If object construction fails, it unwinds and throws an exception. When a variable of an object type goes out of scope, the destructor calls the cleanup. This is a massive boost over C code where all of this is manually done. RAII makes code far simpler because resource cleanup after you are done and you don't need to worry about cleanup of things that failed to initialize. C style mandates manually inserting the setup and unwinding. While it does, effectively, the same thing, good C++ style places such activities automatically via the constructor and calls the destructor once it goes out of scope. The code where logic is performed is simpler, and its harder to make mistakes managing your memory. Essentially, C style is discouraged because it makes you manually do what types and compilers can do for you.
&gt; "premature optimization is the root of all evil" I actually agree with that to some degree, but I think the real problem is optimizing *at the wrong level*. Too many people will spend hours or days optimizing a code section when a far more effective optimization is wholesale replacement: different algorithm, containers, etc.. Sometimes you do need to get down in the weeds, but very often I see that effort spent compensating for poor structural decisions.
My main concern is not memory leaks as i do huge testing on my software and has few quality issues but the fact that many companys are looking to Rust tells me that i should I think C/C++ committee should address all concerns and provide an 201X ecosystem as many other languages does today because it is only makes it harder to develop on it, if Rust can give me a 95% performance of C++ with half the pain you can bet i may consider about it, this time the threat it is real, Rust is not going to deflate as D or any other C++ killers from the past C++ should do something and soon about it because i think that once you switch is almost imposible that this developer/company come back, ISO is working hard and it is not easy as the language is very complex (thanks to all menbers for your job) but it is not going to matter, in a car example you can have the best engine on the world but if it has a 80s chassis and without AC or any today basic feature people will choose other options much more full of extras even it the engine is something worse, after all developers or company has to choose and we are only going to take facts, not promises or hopes that it will improve I like and love C++, dont call me wrong but i am not blind, if i find a superior product i may use it and many will do the same
It was probably named after the unix coomand `uniq` which does basically the same thing. `sort|uniq|wc` is pretty classic UNIX. Why have a program do 2 things when it can do 1?
My feelings about MS are not very good as a user and as a developer and even then i cant see your point
I will prefer that even having another option more that MS (or any other in a similar position) instead of creating the 15th standard to dominate all of then (https://xkcd.com/927/) choose one and helps to improve it, it will be nice if we start rowing together as a comunity
I will prefer that even having another option more that MS (or any other in a similar position) instead of creating the 15th language to dominate all of then (https://xkcd.com/927/) choose one and helps to improve it, it will be nice if we start rowing together as a comunity
I will prefer that even having another option more that MS (or any other in a similar position) instead of creating the 15th language to dominate all of then (https://xkcd.com/927/) choose one and helps to improve it, it will be nice if we start rowing together as a comunity
ah, right, still sorted, but don't bother binary searching. Interesting, technically probably fails the big-O complexity requirements that we will specify, but faster. :-/ And it is observable if you have a custom less than - you can tell how many times it gets called. (Thus it can't just be covered by the "as if" rule). Or we write the spec very carefully, like "O(logN) complexity or _faster_" :-)
\&gt; Developers love it because of its simpler syntax Really? That's the exact opposite of what I've heard. I admit I haven't tried Rust though.
&gt; And what's with the downvote craze? Reddiquette is about voting down what is factually incorrect or harmful. The My Little Pony sub has more maturity. Your statements are factually incorrect, as you even determined on your own based on your later comment about benchmarking `std::array`.
There is far less ambiguity. If you have never programmed, it is definitely simpler; if you are familiar with C-languages already and not ML, it will surely be confusing. It is worth learning regardless.
At last! The “Clang” compiler variant on Windows that targets the MSVC ABI but has a GNU-like command line is now supported.
so does rust.
The `CMAKE_MSVC_RUNTIME_LIBRARY` property couldn't arrive earlier. It's a shit show to set the runtime on Windows. It's actually similar for all compile flags, don't really know why it's so complicated and they've opted to use target property rather just setting the compile option
myFunction(a: myA, b: myB, log: true); =&gt; Basically like C# does it.
Sometimes I wish the standard library had an unresizable container with construction-time sizing.
I was overwhelmed by the token soup in rust's declarations the first time I tried the language. To be fair, I could have said "that's just syntax, I'll figure it out", but when you start learning a new language, writing "hello world" example is the simplest part. You also need to learn your toolchain, get used to a different terminology ("const generics" vs "non-type template parameters"). Rust isn't making only small differences like `fn f() -&gt; u64` vs `auto f() -&gt; uint64_t`, but also: let world: &amp;'static str = "world"; println!("Hello {}!", world); This is from [rust for C++ programmers tutorial - 1st lesson](https://github.com/nrc/r4cppp/blob/master/hello%20world.md) and it raised the following questions: - What's `str` and how does it differ from `String`? My vim is suggesting both when I type `str`. - `&amp;`? Are we talking about a reference? Why do I need a reference? - `'`? What's that? Lifetime? Okay, so is `'static` the same as C++ `static? If so then `&amp;'static` in this context makes little sense to me. - `println!` is a macro, right? Why do I need a macro for printing? Also, I've heard rust macros are more powerful than C macros, so... how do they differ?
Probably will ask elsewhere, but is there a reason the major implementers haven't been able to agree on an optional standard portable ABI?
The "no warning for signed/unsigned conversion" is wrong: - Clang: https://godbolt.org/z/ygnn-Q - GCC: https://godbolt.org/z/CcohTE - MSVC: https://godbolt.org/z/n_KQHC Other than that, it's an interesting article.
I recently did a new project with COM using ATL and couldn't be happier with the result. I broke the program into multiple EXEs for robustness (in case of one EXE crashes), each EXE exposed itself as a COM server, there was additional win service exposed as a COM server as well. Transparent cross-process method calls on objects, the system finds components automagically (you can use a COM component by importing the TLB and don't care about linking), etc. It's a really nice technology. Registration is a bit of pain, but I did that with RGS scripts. In addition, my high-level components implement `IDispatch` so I get scripting for free. When testing, I can grab the COM component with Powershell and call methods on it from there. I used only plain COM. Can't say anything about DCOM or COM+. As another user wrote: use only MTA. If you're starting from scratch, look into building WRL components. WRL is modernized COM built atop of COM. It supports C++ better (namespaces aren't supported in ordinary IDL) and the programming model is somewhat simpler (more modern C++ wrappers as opposed to ATL).
Probably won't take long for someone to make a C like fork.
&gt; The "cmake(1)" command gained a new "--install" option. This may be used after building a project to run installation without using the generated build system or the native build tool. Oh yeah! That's going to help some of my build scripts!
I do and I still don't see a reason. Unless of course you are stuck with a compiler from 1-2 decades ago and C90 coding patterns. Note that we are not talking about arrays or other huge datastructures, but a simple, probably local, int.
That's still an extra instruction, potentially, which can matter in interrupts.
Because it used to be a default in the set of per-config flags, many people had been find/replacing within it or doing other string manipulations. Moving to the property without the policy would have broken such logic. Brad and I had a number of design discussions of how to do it properly (before we found that it actually can be just a single policy and target property instead of having to be an entire "what stdlib do I want?" feature).
Big O complexity requirements allow for constant factors. (log(n/30)+30 (Do a binary search and when you are down to the last 30 elements, switch to linear) is still O(log(N)).
I'm new to here, thanks for tip
first time to hear this, will google them
Let's do something about the lack of static methods size()/capacity() in `std::array`. Due to this 'omission', it's not possible to determine at compile time that a given iterator is a std::array::iterator [because they're all different types], other than to 'iterate' (no pun intended) through all the possible sizes with TMP [which then obviously might hit some compiler-implementation maximum bound on iteration depth]. Standardizing a contiguous_iterator tag would solve the underlying problem I'm trying to solve as well, though.
It's been a time since last post! When I first wrote an example for wrapping a callback to an awaitable type, `pthread_create` was a good practice for it. I covered 2 things in the article. * How the awaitable can wrap the system function which uses a callback and it has a void* parameter * How to define await_transform and which limitation it makes
A few things to consider: Do you have a flat interface already, with just a handful of function calls? If so, a C style interface seems best. If you have a nested in-process API and the callers are using traditional Windows technologies then exposing the API through COM/WinRT is best. Simple cross thread/process scenarios might be ok. For real-world cross process/thread scenarios COM works in theory and fails in practice. Abandon all hope, you're in for a bug farm with reentrancy, timing problems, and debuggability nightmares. Note that those problems don't go away just because you don't use COM; you just have to cause the same issues more explicitly using another technique. But... Reference counting and lifetime management is a different beast compared to modern C++, so on one end or the other you have to build a buffer to keep things sane.
&gt; Why std::array is required to be constexpr is beyond me. It's because the size of the array is determined at compile time.
I would add: don't use smart pointers if you don't need ownership on these.
[CImg](http://cimg.eu) is a also a lightweight option for simple tasks.
I don't agree with a single word you said there, especially the left-to-right thing. I also don't think you've actually tried any of this in real life. Things start to get horrible when you have things like ```auto x = some_function_returning_something (a, b, c);``` While YMMV, I would rather give ```x``` a definite type in its locality, and have the compiler tell me if the type is incompatible with whatever the function returned.
[https://en.wikipedia.org/wiki/Comparison\_of\_integrated\_development\_environments#C/C++](https://en.wikipedia.org/wiki/Comparison_of_integrated_development_environments#C/C++)
I think /u/Ameisen is referring to AVR having separated data and instruction memory and so things like `const char* x = "asd";` is "burnt" into the flash, but then, when we enter the scope of `x`, it needs to be copied into RAM so `&lt;string.h&gt;` and similar would work as expected. &amp;nbsp; That said, there are special macros and function allowing you to operate on data for which you said "do not copy to RAM". What's topping you from passing a data from flash (not copied to ram) to something like `strcmp`? Nothing! It will have address `0xdeadbeef` just like some other data (in ram) will have the same address and you'll be silently operating on different data.
There is a proposal for this in the works! I just can't find it for some reason.
As much as I like arguments from authority, you just need 5min to realise it is *not * strongly typed...
Interesting, but the typos and spelling errors are a bit distracting. pthread_jointer_t definately
What's wrong with the tooling? VsCode + plugin + cargo + rustup works pretty miraculously. Rust is implemented on top of LLVM (like Clang), with specific mods of LLVM to cater for Rust-specifics. I doubt the optimizations are not up to scratch. The added safety cannot come for free, though, so one can not expect Rust to be as fast as unsafe C [but hey, who knows in the future].
It's the same as with for example an integer; if you make a global or static one, it's in static memory, if you declare it in a function scope it's on the stack, if you use new it's on the heap.
The only exception I can think of that could occur is a range exception when using the at() method.
Sorry. I will fix that now. Thanks for allowing bad english.
Very interesting, but the end is kinda funny. “Just include it in your project!” Right... not with a GPL license 🤦‍♂️
&gt;\* The "VS\_PACKAGE\_REFERENCES" target property was added to tell &gt; &gt; Visual Studio Generators to add references to "nuget" packages. I just wanted to share that I made my first cmake merge request and it's been directly accepted within days. I got some good guidance on how to write the tests and documentation and it was much easier than I intially thought. &amp;#x200B; Now VS just needs to add support to packet references to C++ projects :-) For C# it's working like a charm.
Got it.
I said most, not all. A surprising amount of these memory bugs seem to be very simple things (e.g. using ,memcpy with a wrong size) and not the result of some complicated async code. Obviously that is just based on my very limited experience.
*Named arguments* is not the same feature as *designated initializers*.
Maybe I'm just deluded, but as a long time user of clang-cl, I have the distinct impression that the latest iteration of cl (VS2019) consistently generates faster code now than clang-cl. This was the other way around previously. **Big cheer to all those putting in that hard work.** I guess this is also great news for Windows itself. I now use clang-cl in debug and cl in release, just to benefit from the 'still' much better and briefer error messages and analytics, while developing. Very often clang just tells [directly] you what to do to make your code compile, cl could still improve on that. I then occasionally run with asan in release [only available in release] to check for f'ups.
&gt;The added safety cannot come for free, though, so one can not expect Rust to be as fast as unsafe C \[but hey, who knows in the future\]. Some of it certainly can come for free (at runtime), because it is based on static analysis. For the rest, most of the time, the more relevant question is: How much time do I need to invest until the code meets my functional and performance requirements. A language that makes you more productive (I've no experience with rust, so I don't claim it does) gives you more time to optimize your code and write faster, but more complicated algorithms.
Why is using Java syntax is bad habit in Python? Because these are two different languages with different approaches and architectural designs. The same goes for C and C++. There would not be such question for f C++ compilers wouldn’t support C, like the questions about Java and Python above, right? So why treat C and C++ differently?
&gt; Some of it certainly can come for free (at runtime), because it is based on static analysis. You're absolutely right here, thanks for reminding me. &gt; For the rest, most of the time, the more relevant question is: How much time do I need to invest until the code meets my functional and performance requirements. I've only tried some toy programs, so I cannot speak out of experience, but [the 'infamous' struggle with] the borrow-checker seems [for many] to impede writing code faster. There is on-going work to in part relax and in part improve this [the borrow-checker] though.
Clang's sanitizers are dynamic analysis tools, so the require you to execute that particular code path (e.g. during tests) in which case you'll most likely detect if the initial value should have been overwritten anyway. On the other hand, I believe clang-tidy has a decent chance of catching most cases of uninitialized locals statically so yes, this might be a valid reason. But just as you mentioned: My post was more about that you should rarely end up in a situation, where you can't immediately initialize a variable with a sensible value in the first place and if you do: Consider refactor your code.
I think what you are asking is a way to stop the preprocessor from resolving a particular symbol. As always, the only viable way to ensure that this is taken into account is to write a paper, submit it to WG21, and either attend a meeting or find someone that will present it for you.
I don't have any relevant hands-on experience with Rust either. I was more speaking in general in the sense that very often, the language may not the limiting factor, but the time and competence of the programmer. Of course, at some point you are at the end of what you can achieve with the tools and the semantics of a particular language and you need to use something different (like assembly ;)). I can recommend this talk by Bryan Cantrill: [Is It Time to Rewrite the Operating System in Rust?](https://youtu.be/HgtRAbE1nBM) Around minute 40 he talks about performance comparison between one specific piece of code he ported from c to Rust and which suddenly worked faster. Of course he could have gotten the same performance out of C by using better data structures, but in rust it was apparently much easier to use the right data structure (both because a high quality implementation was readily available in the standard library and because Rust made it easier to use). Disclaimer: Most times that I see people praising Rust (including in this talk), they usually compare it to raw C not C++. Regarding programming speed in Rust: If (again, can't speak from personal experience) the language semantics reduce the number of bugs you have to debug, the increased up front development time may very well be worth it in terms of total development time. Anyway: I think we are on the same page here anyway
What about constexpr auto lambda = []{ return WM_LBUTTONDOWN; }; #undef WM_LBUTTONDOWN constexpr int WM_LBUTTONDOWN = lambda();
First of all, unless you compile with a c89 compiler, there should rarely be a need to declare a local int before you can initialize it with an appropriate value. Second, in the remaining cases, there is a very high chance that your compiler can optimize the instruction away ( [https://godbolt.org/z/XS9Z96](https://godbolt.org/z/XS9Z96)). Third: Yes, to every rule/guideline in programming, you can create an exceptional situation where it doesn't apply. I just think that in this case it is insanely rare. Have you actually encountered a case, where it really produced overhead and that overhead mattered in the context of your application.
&gt; Anyway: I think we are on the same page here anyway Yes, I think we are, I'm on the fence in respect of Rust, but keep a close eye on the blog-posts etc. It is unavoidable I'll throw myself in at some point. I'm waiting a bit to see how the promised [in the roadmap of [earlier] this year] improvements materialize. Microsoft looking into Rust is obviously potentially very interesting as well, since full scale adoption in Visual Studio [as opposed to VSCode] will be in the cards.
Why the lambda? Wouldn't a normal constexpr/const variable do?
I'm just making sure I avoid the static initialization order fiasco.
As far as I know c++ is more performing since go has a garbage collector. But I never actually used go.
I would go with C/C++ and the library ZeroMQ. I use it for a personal project and I am really happy with it.
This page gives some clues: [https://github.com/cplusplus/papers/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc](https://github.com/cplusplus/papers/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc)
No. It's against policy to live report proceedings several reasons. You can find out on Saturday immediately after plenary local time. There's usually a massive info drop the second it closes.
It's been a while since I tried Rust, but IIRC the main problem was that if you write a desktop app that naturally makes API calls everywhere, you basically need unsafe sections everywhere - which kind of defeats the entire purpose of Rust. If Microsoft provides (almost) the entire functionality of the WinAPI as a Rust library, sure I'll use it. If you use Rust in some kind of embedded environment were you need to write all the fundamental memory management etc. yourself - well, almost all your code is unsafe again. It seemed to me like the big benefits of Rust are really only there once you're already in a huge ecosystem where all the unsafe sections are taken care of and well-tested.
A human is derived from a monkey. Being human can be complex and tiresome: we use cutlery instead of hands, wear a suit and shoes instead of fur, work and pay taxes instead of climbing trees for bananas, talk to your opponents instead of throwing rocks or something else at them and so on. In return, however, we get some nice benefits like homes, sliced bread, TV remotes and reddit comments. Nothing can stop you from rejecting all that and going back to the nature if you wish and can't be bothered with the social acceptance. C++ is derived from C. Learning it can be complex and tiresome: we use types instead of void*, smart pointers instead of raw, algorithms instead of raw loops and so on. In return, however, we get some nice benefits like automatic resource management, safety, scalability and performance. Nothing can stop you from rejecting all that and going back to malloc and char* if you wish and can't be bothered with the social acceptance. P.S. No offence intended to either monkeys or C.
Yes. Removed and locked this post.
What's wrong with `#include`? Macros can't be exported for a very good reason, but there is nothing with using `#include` for macros that you still need.
`std::unique_ptr&lt;int[]&gt;` ? `make_unique` for `&lt;int[]&gt;` takes a size, but then can't be resized. It sounds like exactly what you want, except... it doesn't store the size, so it doesn't support begin/end, range for, and so on...
The only thing anyone should read is the rust book first and foremost. I tried using that guide as well but it is not structured properly to build up things in order. It's a valiant effort, but you'll waste less time reading the rust book instead, even though as a C++ programmer you'll have to read through some stuff you already know.
That would be a very difficult thing to do, as the syntax rust has is already c-like, but with changes where it's necessary to make distinctions for things rust-specific. That being said, you could probably whip something up that does the following pretty quick: - put the type in front of the variable/function name - make variables mutable by default - use int, long, etc But then someone using it would have to also know the rust syntax for any gaps in this system where there is no c-equivalent
It seems that C++ is at the risk of being stuck in a loop where : - $LARGECOMPANY insists on backwards compatibility and thus blocks breaking changes which may improve things in $OLDTECH - $NEWTECH is developped, which actually do the breaking change and much more - Some people in $LARGECOMPANY start using $NEWTECH, people notice that the breaking changes are worth it - $NEWTECH ends up replacing $OLDTECH at $LARGECOMPANY, $OLDTECH is left fucked up alone with its debt I've seen this pattern fold out multiple times in practice, with libraries, I wonder if there is any other way of evolution for tech stacks.
I'm a little surprised that lesson didn't answer some of these. &gt; What's `str` and how does it differ from `String`? My vim is suggesting both when I type `str`. So a `String` stores its data on the heap, and is responsible for cleaning it up when it gets dropped. The same basic idea as CPP's `std::String`, I believe. A `str` is view into some string data, does not own the data, and is not responsible for cleaning it up. &gt; `&amp;`? Are we talking about a reference? Why do I need a reference? The reason for this is that `str` does not have a specific size. It's just an arbitrarily long array of bytes representing a string. You will almost always see this used as a reference. This data could be stored anywhere. It could be obtained from a `String`, it could be from the executable's read-only data as it is in that specific example, it could also point to an array on the stack. When seen as a `&amp;str`, this will be stored as a pointer to the start of the string, and the length. You can see the same pattern with `Vec&lt;T&gt;` and slices (`&amp;[T]`). &gt;`'`? What's that? Lifetime? Okay, so is `'static` the same as C++ static? If so then `&amp;'static` in this context makes little sense to me. Yes, that is a lifetime. In general, lifetimes can be named anything you like, but `'static` is special in that it's a lifetime that lives for the entire length of the program. In this case, the data is stored in the executable's read-only data, so it has the `'static` lifetime. &gt; `println!` is a macro, right? Why do I need a macro for printing? Also, I've heard rust macros are more powerful than C macros, so... how do they differ? This is a little more complicated. It's been a while since I looked into it, but from what I remember it goes something like this: Your formatting string is split into segments at the points where the data is to be inserted, and then stored in an alternating pattern with the data to format. So it'd go something like String, Data, String, Data, String. If I recall correctly, pattern must always begin and end on a string. Now, the data here is stored as two parts, the data itself, and the function used to format it. However, because this formatting data could have an arbitrary number of arbitrary types, both it and the function are stored as *raw, untyped pointers*. It would be trivially easy to mess up and cause all sorts of issues if you allowed the user to build this data structure manually. This is where the `format_args!` macro comes in. This macro is implemented in the compiler, which can verify that everything is correct before it starts building the structure. All of the structures to hold the formatting information are in `stdlib`, but are private so you can't construct one, but the compiler is free to ignore that privacy because it's the compiler. All of the formatting macros `print`, `eprint`, `write` and `format` all wrap up the `format_args` macro in various ways. Now, as for how C macros differ from Rust macros. My understanding is that C macros are applied to the text before tokenization. In Rust (and I speak under correction here), I believe everything is parsed into the AST first and verified to be valid, and only *then* is the macro expanded. Additionally, macros in Rust cannot refer to or create variables outside of the macro, only those passed into it.
&gt;While YMMV, I would rather give `x` a definite type in its locality, and have the compiler tell me if the type is incompatible with whatever the function returned. My take on this is that I'd be fine with concepts being used - `Iterator x = some_function_returning_something (a, b, c);` is readable enough to me, but a bare `auto` is too general and isn't useful unless I completely don't care about the type.
The problem is not really solvable without breaking backwards compatibility in a major way, at which point, they might as well just make a new language. Modern C++ can be a very nice language to work with, but every large codebase has been built up for years since long before modern c++. The c++ committee is addressing rust with concepts (generics+traits in rust) and modules (crates in rust). You can already do some very nice stuff with tuples and structured binding that is similar to rust. You can use trailing return types. You can use auto. They are absolutely improving the language greatly, it's up to everyone using c++ to catch up, which isn't gonna happen when you have 40,000 c++ files written over years or decades. Rust was designed with the problems of c++ in mind, and started out with plenty of great language features and far less capability (or reasons) to write code similar to older c++. C++ can't just remove support for old code though, which is why imo rust is going to take over.
This isn't C++ "not being strongly typed", it's an intentional deviation from the standard in GCC to be more compatible with old/bad code. GCC allows the conversion to `char*` from a string literal, which then takes a higher priority in overload resolution because it's a direct conversion from a literal rather than two-step as with `std::string`: first literal to `const char*` (or `const char[]`?) and then from that to `std::string`. As far as I know GCC provides no option to disable this behaviour - `-Werror` still considers the conversion *valid* but makes it a compile error, rather than making it forbidden, which would result in the same behaviour as clang.
I realized that on my own. I tried the Rust Book first, but then though "do I really need to go through everything from scratch?" That's when I found r4cppp. I'll just have to grab the book again and not mind going through things I already know.
 #include &lt;array&gt; int main() { std::array&lt;int, 2&gt; a; // stack std::array&lt;int, 2&gt;* b = new std::array&lt;int, 2&gt;; // heap static std::array&lt;int, 2&gt; c; // neither stack nor heap }
It seems to me that some of the 'token soup' of rust is for the benefit of the reader, not the author. Consider C++: f(g); That's all you see. What's f's signature? You have to go and look in the header. In rust, it's up front: f(&amp;mut g); I sometimes wish C++ had that explicitness rather than having to rely on tooling (assuming I'm not looking at code on Github/the web). void f(const G &amp; g); void f(G &amp; g); void f(G g);
We don't need macros for constants.
[Yes?](https://godbolt.org/z/jMbLeI) Have you seriously never looked at the APIs and headers often provided by microprocessors? You often have to work with interfaces that are *not* conducive to return-initialization. On AVR, given their ridiculously poor performance *already*, overhead almost always matters.
Sorry but due to the rules you need to delete this post and make another one into r/cpp_questions
Changes since cmake 3.14 does not wrap lines well on safari/iOS. I can’t scroll to the right to read the lines. Can’t the text be embedded as regular HTML?
proud arch user for the last 10 years. linux is the last holdout for C and C++
Maybe use a code generator to extract #defines and then generate an appropriate module file? Then the generated code would be like this: export const int WM_LBUTTONDOWN = 0x201;
Wow... first of all thanks for taking the time to write all that! &gt; `str` vs `String` Okay, so rust's `str` is C++ `std::string_view` and `String` is `std::string`. Except that `str` above is a `'static` reference and `string_view` is usually a value type with automatic storage. &gt;&gt; &amp; &gt; The reason for this is that str does not have a specific size. It's just an arbitrarily long array of bytes representing a string. Okay, that makes `str` somewhat like C's `const char*`, except that rust refers to an object, not raw bytes. &gt; You will almost always see this used as a reference. Okay, that's still alike C's `const char*`. Except raw pointer vs reference. &gt; This data could be stored anywhere. It could be obtained from a String, it could be from the executable's read-only data as it is in that specific example, it could also point to an array on the stack. Once again, exactly like `const char*`. &gt;&gt; `'` &gt; `'static` is special in that it's a lifetime that lives for the entire length of the program. Okay, so it is like C or C++ `static`. The reason why it didn't (and potentially still doesn't) make sense is this: If I see `&amp;'static T`, am I supposed to read that as "a reference to `'static T`" or "a `'static` reference to regular `T`"? If it's the former then `let world: &amp;'static str = "world";` is analogous to `const char * world = "world";`, with the only difference being that C/C++ holds a pointer to the raw buffer of bytes and rust has a wrapper class around it. If it's the latter, which I assumed at first, and the `'static` refers to the reference, not the underlying data, then the reference would outlive the object. That's where I got confused. &gt;&gt; `println! &gt; Your formatting string is split into segments at the points where the data is to be inserted, and then stored in an alternating pattern with the data to format. So it'd go something like String, Data, String, Data, String. If I recall correctly, pattern must always begin and end on a string. C++20 should get `std::format`. Thanks Rust. (Not trying to be ironic or snarky.) &gt; Now, the data here is stored as two parts, the data itself, and the function used to format it. However, because this formatting data could have an arbitrary number of arbitrary types, both it and the function are stored as raw, untyped pointers. It would be trivially easy to mess up and cause all sorts of issues if you allowed the user to build this data structure manually. Exactly what `std::format` does with its arguments. &gt; Now, as for how C macros differ from Rust macros. C macros are very simple, with absolutely no regards to scope or accessibility. The preprocessor will expand the macro with no regards to the language's rules. &gt; macros in Rust cannot refer to or create variables outside of the macro, only those passed into it. C macros, again: "What's scope?" This restriction makes sense in order to have sane macros. A few days ago I wrote a macro that did the following: - Create an ad-hoc `struct` whose default constructor mutates a global `vector` - Create an object of the ad-hoc struct to call the constructor This was because the person asking for help didn't want to mutate the vector inside a function.
Leaks are just a minority of what goes under the "memory problems". Memory corruptions due to programs writing (maliciously or not) to memory they are not supposed to are by far the biggest and most feared ones.
I'm not disagreeing. My point is that in some (C) libraries macros are used for constants and in that case just `#include` them instead of manually "translating" them, which you also wouldn't do today.
That's one of the situations (there are others as well). Unfortunately, g++ doesn't support `__flash`, and it's support for program memory is... poor, at best.
That's a valid argument. I'm not so much against rust's explicit nature. I'm rather against it's terseness. There are these "unnamed" things everywhere: declarations (see above), return types (`-&gt;()` and `-&gt;!`), macros (`!` in `println!` seems unecessary). There are more things that seem confusing to me, as someone who has never spent much time with rust, but that's to be expected. However, I have had the need to read [rls](https://github.com/rust-lang/rls/) code and it wasn't too bad.
&gt; That's one of the situations (there are others as well). I'd be curious to hear about others. &gt; Unfortunately, g++ doesn't support `__flash`, and it's support for program memory is... poor, at best. That's because it is called `__attribute((__progmem__))` (`#define`d to `PROGMEM` in `avr/pgmspace.h`)in gcc. https://godbolt.org/z/hhQBMa
Agree. There is much less corner cases or "hacky" quirks. It took me less than a week to get accustomed to the the syntax, although I also have some OCaml and Haskell experience behind me, so many constructs were familiar. Semantics are harder to grok (mostly lifetimes), but that's another story, not related to syntax.
I think it can be done, Visual Studio is a major IDE and hides more or less well the complexity of CMake and Vcpkg or Nuget (the internal Visual Studio package manager) plays the roles of pain less dependencies, no need to do anything fancy, only standarized it. Break compatibility isnt a valid excuse because real products do the function without problem and maybe MS will be kind enough to share the know how about that if asked by the ISO I wasnt thinking about modules or anything directly related with Rust, if the ISO is doing that in my opinion they are doing wrong, if i want to use a json Rust make that really easy to be ready to go, in C/C++ thinks take longer to say at least. That for things that are out of the language but the real problem is that STL is a toy compared with any modern language and things that are common in both are less complete in C++, unfortunately is a fact, give me a good library because what i do in python/Java/.net in one line and in less than a minute may take hours or days. I dont need templates that allows auto as return (to put an example) or similar things to compete directly to code you can write in others, i will want that when the language is up to date but not when it is lagging so hard behind real threats I am not asking to deprecate things, i am asking about the real problems that we as developers face every day and suffer, i imagine that many of us code in other languages and can note the huge gap there is between C/C++ and any recent one, they make your life so much easy. Things that you or me envy about other languages as we use them and wish C++ could has this, it is about the kind of things that dont depend on your code and making the options of coding more complex is not going to help solve the problem C++ could be as modern as other competitors, it can be done and i hope they do, otherwise the language will slowly start being less used and be the new Cobol, a niche one
`__attribute((__progmem__))` and `__flash` are not the same thing. `__attribute((__progmem__))` (in gcc and g++) is a simple attribute modifier for data that specifies that it should be placed into program memory. Data access, however, follows regular semantics and thus doesn't work correctly. That is - reading from a pointer to something set as `__progmem__` without using the correct macro will not work correctly. `__flash`, on the other hand, is only supported in gcc (thanks to ISO/IEC WDTR 18037), but adds *access semantics* - that is, a `__flash` pointer can be dereferenced, *and the compiler will generate the correct access instructions*. The reason that this isn't supported in g++ (where it would be far more useful because of C++'s stronger typing)? Because there is no embedded extensions specification for C++, and the g++ maintainers refuse to port it from the C front-end to the C++ front-end.
It's a bit of off-topic, but can I use mingw (clang) with msvc ABI to build dll? I wasn't able to find any direction how to use this combo: clang with msvc ABI. :(
If you can't infer the type from function name and/or variable name then they are badly named. I don't use Herb's style but I do use auto wherever I can in real life.
Oh... I didn't know about `__flash` at all, I just assumed it was from some other compiler. I've only done small hobby projects on AVR and focused more on ARM. Thanks for correcting me.
&gt;It's been a while since I tried Rust, but IIRC the main problem was that if you write a desktop app that naturally makes API calls everywhere, you basically need unsafe sections everywhere - which kind of defeats the entire purpose of Rust. That might've been true long time ago, but it's rare nowadays. Usually you use some sort of ramework that abstracts native API calls away from you, be it React or Qt. &gt; If Microsoft provides (almost) the entire functionality of the WinAPI as a Rust library, sure I'll use it. https://github.com/retep998/winapi-rs &gt;If you use Rust in some kind of embedded environment were you need to write all the fundamental memory management etc. yourself - well, almost all your code is unsafe again. Not true again. In 99% of cases you can just abstract the unsafe parts behind the safe interface to use by the rest of the code. I.e. you implement Allocator using some unsafe parts, but the rest of the code can be the same regular safe Rust.
Weren't Generic "designed into it" from the start though? I.e. CLR had support for generics from the get go (in contrast to jvm which never got it).
It will likely be in clang-avr soon enough. Clang shares the same frontend for C and C++ (unlikely gcc), so implementing it is easier, though I haven't figured out the exact semantics that would be ideal.
&gt;It is weird std::array has enforced constexpr. To be clear: The elements in the array can change at runtime. It is only the size that has to be constexpr. Non-dynamically allocated C-style arrays has the same restriction. The motivation behind std::array is to provide a zero-overhead abstraction over C-style arrays with an interface and copy semantics that are more consistent with other types. &gt;Allocating an array on the heap isn't any slower Dynamic allocations are slower than stack allocations, and it spread things out in memory which makes things less "cache friendly" which can affect performance, at least for larger programs. &gt;the C++ standards do not enforce that std::array be on the stack. As with all types you can choose where you want to allocate the objects. The standard says it's an aggregate and relies on the implicit construct/copy/destroy for aggregates so I don't think it's possible to implement std::array by storing the elements separately. Even if it is, I would be surprised if any implementation did it because it goes against what everyone expects. &gt;std::vector is used for arrays that do grow and do not grow, and std::array is used for constexpr time optimizations. There is room for another type, there is always room for more specialized types, but we cannot have types for everything, so not sure it's something that is needed enough to be part of the standard library. &gt;That isn't obvious to a newcomer. Newcomers should learn about std::vector. std::array is a more "advanced" feature.
I think this might put C++ in the same boat as other languages requiring bindings for C functionality. Because you also want to split this up into proper modules like \`import windows.gdi.constants;\` \&gt; **Could the modules proposal please be augmented by a mechanism that allows us to keep using the original names for #define constants?** Unlikely. The preprocessor would then need to understand what a declaration is which is very context-dependent in C++ and is unlikely to be well-received by implementations.
Clang has had AVR backend support as experimental for so long I thought (without checking) that the project won't ever come out of experimental phase.
I was working on it for a while. The biggest issue is the same one GCC has - the general optimization model of the compiler isn't a good fit for an 8-bit chip - it makes too many assumptions about data, how scheduling works, etc. Even avr-gcc is pretty terrible. It has had *years* of improvements by the community *and* by Atmel, and it is still bad. It *always* assumes that any data type larger than 1 byte must always be in register pairs because they *might* be used as a pointer, which causes register scheduling issues. It basically must presume that a pointer must fit in a native data type, even though it doesn't. Neither Gimpl nor LLVM-IR really represent AVR very well, either. You have to manually implement all of the various bit shifts because the optimize has *no* way to derive that, for instance. Clang has to catch up on *years upon years* of AVR-specific optimization work, and since Atmel is basically dying/dead, I'm not sure that that's gonna happen. AFAIK, all of the existing AVR developers on GCC already jumped ship and moved to LLVM, since the GCC maintainers were pretty hostile towards uArchs like it, and there was also the pain with the G++ maintainers.
&gt; What's a good alternative to COM if you want interprocess communication on Windows? Named pipes. If you read my other, long, post in this thread, that's how I started with my multi-process architecture. But manully marshalling parameters, return values, errors, etc. was no fun and I went for COM. Which was a good decision.
In a modular world, the ideal would be to simply do this: import &lt;windows.h&gt; It will import both symbols and macros for the header. Just like a header today, but without processing the whole file over and over again.
Thanks for the write up. It sounds like I shouldn't expect `clang -target avr` to become available by default any time soon. Do I have a wrong impression?
Yes, agree completely if concepts are available. Nail the type down as much or as little as appropriate for the situation, but a *don't care* attitude leads to code which is too difficult to read for correctness.
&gt; https://github.com/retep998/winapi-rs That's pretty cool, maybe I'll try it out. &gt;Not true again. In 99% of cases you can just abstract the unsafe parts behind the safe interface to use by the rest of the code. Well yeah, that's the plan - it's just that often the "unsafe parts" become like half of the code if you're doing something relatively light from a logic perspective (as you tend to do on smaller CPUs). That's mainly where I see the problem with adoption, the benefits for small projects are only there if not a large part of code ends up being unsafe, and big projects just take a lot of effort to change. But if Microsoft is willing to invest massive amounts of money to make Rust on Windows as convenient as possible, I'm all for it.
\&gt; Besides being superior to C# in regards to better memory protections, Rust is also more popular with developers these days and might be easier to recruit for. &amp;#x200B; That's an impressive amount of bullshit right there. And please someone explain to me just how C# is memory unsafe compared to rust.
A `str` is not exactly the same as a `const char*`. A `const char*` is a pointer, with a known size, so you can store it in something on the stack, and pass it around to functions. You can't store `str` on the stack, or take it as a parameter, because it doesn't have a known size so the compiler can't know how much space it needs to store it. The only way you can pass around a `str` is behind a pointer type such as `Box&lt;str&gt;`, `Rc&lt;str&gt;` or `&amp;str`. After compilation, these three types get passed around as two values: a pointer to the data, and the length of the data. This all goes the same for slices (`[T]`) too. &gt; Okay, so it is like C or C++ `static`. The reason why it didn't (and potentially still doesn't) make sense is this: &gt; &gt; &gt; &gt; If I see `&amp;'static T`, am I supposed to read that as "a reference to `'static T`" or "a `'static` reference to regular `T`"? &gt; &gt; &gt; &gt; If it's the former then `let world: &amp;'static str = "world";` is analogous to `const char * world = "world";`, with the only difference being that C/C++ holds a pointer to the raw buffer of bytes and rust has a wrapper class around it. &gt; &gt; &gt; &gt; If it's the latter, which I assumed at first, and the `'static` refers to the reference, not the underlying data, then the reference would outlive the object. That's where I got confused. If you have a `&amp;'a T`, it should be read as a "reference (of lifetime `'a`) to a `T`". This applies to all lifetimes, `'static` is not special in that regard. This is where Rust's infamous borrow checker comes in. The compiler will determine the lifetime of your T (I'll call that lifetime `'b`) and will enforce that the lifetime `'a` lives *at most* as long as `'b`. If the borrow checker detects that `'a` might outlive `'b` you get a lifetime error, and it will refuse to compile. This is how Rust prevents dangling references and use-after-free errors. In this case, the compiler knows that the data "world" lives in the executable's read-only memory, and gives it the lifetime `'static`. For example, if I try to compile this: fn foo&lt;'a&gt;(input: &amp;'a str) { let b: &amp;'static str = input; } In this function, I'm taking in a `&amp;str` with a lifetime I've called `'a`. However, I've not told Rust that this lifetime has any specific bounds, so this lifetime could be anything. On the second line, I've tried to assign `input` to a variable with `'static` lifetime. A reference with a `'static` lifetime must be valid for the entire length of the program, but I've not told Rust that `'a` lives that long, so I therefore get the following error: error[E0312]: lifetime of reference outlives lifetime of borrowed content... --&gt; src/lib.rs:2:27 | 2 | let b: &amp;'static str = input; | ^^^^^ | = note: ...the reference is valid for the static lifetime... note: ...but the borrowed content is only valid for the lifetime 'a as defined on the function body at 1:8 --&gt; src/lib.rs:1:8 | 1 | fn Foo&lt;'a&gt;(input: &amp;'a str) { | ^^ Another example of a lifetime error without static would be this: fn foo(input: &amp;str, output: &amp;mut &amp;str) { *output = input; } This one's a bit of a strange beast, but what that second parameter means is that I can change what string the binding is pointing to, but I can't change the string itself. Because the lifetimes are unnamed, they have no provable relation to each other. Because they have no relation, the compiler cannot prove that this is valid, and rejects it: error[E0623]: lifetime mismatch --&gt; src/lib.rs:2:19 | 1 | fn foo(input: &amp;str, output: &amp;mut &amp;str) { | ---- ---- | | | these two types are declared with different lifetimes... 2 | *output = input; | ^^^^^ ...but data from `input` flows into `output` here In order to have that function accepted, I would need to name the lifetimes and bind them together. In the following example, I've named both lifetimes `'a` and `'b`, and told Rust that `'a` must live at least as long as `'b`, and the function is now accepted. fn foo&lt;'b, 'a: 'b&gt;(input: &amp;'a str, output: &amp;mut &amp;'b str) { *output = input; }
No. It's all gcc based.
What's wrong with [this](https://godbolt.org/z/1L3vUY) then? It doesn't have any `std` instructions, unlike either of your examples, and I don't see any additional jumps in the disassembly. I've never worked with AVR though, so there could be something wrong with this I don't see. Pre-initialization with a phony value isn't usually what people are talking about when talking about uninitialized variables. Striving to initialize with a useful value at declaration is. Immediately invoked lambda expression is preferred for complex initialization, afaict. (Well, it's preferred by me, anyway.)
What if you need to program against some C API directly? Maybe some API function accepts a pointer which it subsequently assumes ownership over? What I try to say; in some cases there is no way to get around using C within C++. Recently I had to implement a shared memory queue with some very specific characteristics which prohibited the usage of some off the shelf implementation. There is no way of getting around using C within a C++ context in that case. In short; those people on SO are wrong.
Thanks once again. I think I got it now. I also think that now I can imagine cases where the borrow checker would yell about valid code, but I also think that I will try learning rust once again soon.
Thank you all for your patience and feedback. I read through all the comments and to be honest, I only understand barely half of all what is mentioned. It really shows that I still have a lot to learn for C and C++. You all gave me a lot of direction to look into and I really appreciate it. Thanks again.
Lots of `std::cout`s in strategic locations or use the debugger.
I think the benefits of selectively importing symbols from windows.h (and other libraries, for that matter) are considerable. Think of it like this: why is `using namespace std;` bad? It's bad because you get countless unwanted symbols in your namespace. The situation for header files is no different: they bring countless unwanted symbols into your namespace as well. So far we didn't really think about this because we had no way to mitigate the situation, but with modules that changes: they let us choose which symbols we care about and which ones we don't.
The preprocessor doesn't need to know anything, other than that specifically marked symbols must not be substituted. That doesn't involve any knowledge of the language, it could be as easy as this: export const int ###WM_LBUTTONDOWN### = WM_LBUTTONDOWN; // expands to: export const int WM_LBUTTONDOWN = 0x201; In this scenario, all the preprocessor needs to know is that it must leave text enclosed in ### alone. The fact that it is part of a declaration is immaterial.
Why do you care?
And why is that? Because they are being prudent and shop for the best tool for the job?
I don't know what repos you're looking so I may be off-based here but in a lot of CS classes professors have their students write their own structures to use in assignments so that they can better understand them. I know in my data structures class (c++) we had complex assignments and a smaller but still important part of those assignments was that we had to use our own string, vector, list, hash table (I'm sure I'm forgetting something) that we wrote and implemented. So that could be a reason why, other than that I'm not sure.
There are quite a few things wrong with `#include`: * You import macros you may not be aware of and almost certainly don't want. * Those macros cannot be restricted to a specific scope. * Particular for windows.h, the number of symbols is absolutely massive, leading to hugely overinflated intellisense lists, intellisense files, precompiled header files, etc. It probably doesn't do much for compile speed either. * It should be possible to add some degree of type safety as well, increasing the amount of checking the compiler does for you.
I would be more surprised if there were not valid programs it rejected. As far as I'm aware, it's a limitation of all static analysis, including type systems. With the caveat that aside from a little hacking on Rustdoc most of my Rust experience is with smaller programs, I've not found it to be a major problem. After a while I just internalised what the compiler wants, and do that by default.
Ah, I hadn't considered that you can #undef a symbol - thanks! I guess this pretty much rules out any hope of a change to the preprocessor then, even though this solution is pretty ugly...
Because then you now exactly how it works, and you don't have to learn a new API. And maybe you don't want external dependencies.
all they're doing is facilitating language genocide. i have no idea why people are getting so excited about this. c++ is safe enough when used correctly
Maybe they are easy enough to implement for people not to feel the need to pull in a library (let alone Boost). Maybe they require some subtle adaptation for a specific use case. What do you find hard about adapting (to) other people's code?
That is a significant syntax change (it may have to be specified as another phase of compilation since the `###` has to be removed *somewhere*). And it still needs preprocessor changes to know of such a symbol. Can I macro-paste these together conditionally? What if there's no terminator? What if it crosses across lines? Intervening whitespace? Lots of questions here :) . The argument for such a facility may be solid, but its progress to actually becoming an accepted change has not even started and certainly won't make C++20.
Well, I don't have that much personal experience using Rust for embedded, but [these guys](https://www.rust-lang.org/what/embedded) do and after quick glance at listed books (that's another great feature of Rust ecosystem I've come to enjoy), I don't see anything that'd indicate ""unsafe parts" become like half of the code".
So far, I've had to design one ~60k lines long codebase from scratch. When the deadline got close I had an option - play with heap and type erasure to make multithreaded code work right then and there or spend a few days to avoid heap, set up object pools and again make everything work quickly. Rust wouldn't have given me that choice. Even for C++ that would formally be undefined behaviour. C jusr reared its ~~ugly~~ unsafe head, smiled and whispered "you're a good boy..." &amp;nbsp; Joking aside, I did create a memory leak, but it was caught at some point and further intensive testing proved that the code is correct. That said, "clever" unsafe tricks are hard to get right under stress. &amp;nbsp; "Clever is not a compliment." - Chandler Carruth
I would have listed **contracts** among my favourite proposals if I had known it was not going to make it into C++20.
True. P.S. "log(N) is a constant" - Sean Parent ie you probably don't have that much data, logN is probably 8 or 10 or something like that. Less that 64 I bet.
One part momentum, one part the bad state of package management. In 99% of cases with Python you get to use Numpy by `pip install numpy` and it's there.
A lot of data structures in std or boost have subpar performance characteristics. Such as polluting cache. Many of them are also kind of overkill for some scenarios. These are a couple of motivations c++ programmers have for rolling their own.
Why is using namespace std is bad is not because all symbols gets in your namespace. It's because of name collision, unwanted ADL, accidental overload calls and many others pitfalls. The amount of symbols is not one of them. Also, importing a large header is not that bad with module, since importers are not affected by that import, and there is a little cost of importing large header, since they will get compiled once. I don't see any advantages of extra fine granularity with modules.
Somewhere on stackexchange there is code for this. It inherits everything from the allocator class, but not the resizing stuff. It looks like black magic to me, but it works.
Thank you!!!!
When being taught python you tend to be taught libraries-first. When being taught C++ you tend to be taught ground-up. The problem with that is sometimes they forget to teach you the libraries...
The amount of name collisions, unwanted ADL, and overload calls are highly correlated with the amount of symbols
The key word in that sentence is *unwanted*, rather than *countless*. A header can also cause all those problems.
Also mostly correlated to the kind of names. The STL has very generic names which people tend to use.
1. There's no universal dead simple package manager yet like NPM, pip, or cargo. You can't just `&lt;package manager&gt; install &lt;package name&gt;` in C++. Crazy, right? For a language this mature hadn't resolve decades old issue is quite hard to believe sometimes. One external library could took you hours to even days to properly configure. 2. NIH syndrome. 3. Because they were told to not use any dependency. One could argue its to improve their understanding of said data structure, but surely there's a better option out there built by more than one person with complete and readable docs. ^(hahaha complete docs)
So sounds like no good alternative for Windows unless doing bulk data transfers. I dabbled with named pipes years ago.
&gt; Because they were told to not use any dependency. "Better to re-implement a buggy version of some library than to bring it in and have "bloat"!" -- some "Chief Architect" from another office &amp;nbsp; ^^sobs
Boy ain't that the truth... When I learned C++ in college, it was the only programming language we were learning for the first trimester. The teacher taught it like he was teaching C, and we only really learned what was in the standard library (save for iostream) in our second year... Then they just kind of plopped everything down on us in the first week of the second year and got mad when people still used raw C arrays instead of vectors or the array class. We only learned about Boost a month before graduation, and they didn't really teach us how to set it up (the teacher had a common repo we all used). I decided to just buy some C++ books and read about it during the second trimester of my first year. Boy did I dodge a bullet!
Thanks a lot! I'm trying to build the environment and seem to have okay-ish success. If I manage to get it working I will share my solution.
C# uses garbage collection. As with all garbage collection languages, they are the greatest lie in programming language history: they do leak memory, just in an easier to debug way. The advantage of garbage collection is that it automatically collect things to be deleted when nothing reference them anymore. The problem is that for sufficiently big applications, it's tricky to get rid of all references if you are not careful. Therefore, like all languages, it's tricky to not have memory leak if you are not careful. But in exchange you are guaranteed there exist a reference to it, and a debugger can tell you which, and help you figure it out. But the big mistake those languages do is to use that opportunity to hide pointers vs values. Which can cause issues when you modify them and they were inadvertently shared. On the other hand, Rust require static memory handling. The type system simply makes memory leak really hard to code. It's a pain in the but, but if you get used to it you usually end up with better programming habits. Added to that, everything is constant unless explicitly requested, and as with memory, you need to be the "owner" to modify the value. This avoid having unintended shared values that gets modified without knowing about it. In that way, Rust is safer than C#.
Do you mean [`static_vector`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0843r3.html) for a fixed capacity vector?
Every time you swap to numbers, print the whole array.
Everything is "safe enough" when used correctly. Even Assembly.
The same paper directly answers your question in the 'background' section...
yes. the programming world has worked just fine for the past 60+ years due to programmer discipline. it's a proven model and the world is still here. no need to tear up the industry to change it
Yes that's the one! Thanks
They were designed alongside .NET but only made it into version 2.0, as Microsoft did not want to delay the release waiting for generics support to be fully worked out.
TBF boost::spirit goes there.
What I see as trend is C++ being pushed down the stack, with OS drivers, UI composition engines, GPGPU shaders being written in it, while a large majority of userspace applications gets written in managed languages, built on top of it. Microsoft is the only OS vendor, among mainstream desktop and mobile OSes, that still gives first class support for it. And even them having been improving .NET (low level stuff taken from Midori) and playing around with Rust now. So I wonder when people like Herb Sutter or Kenny Kerr eventually leave, how it look like for C++ at Microsoft.
As /u/dodheim said, the paper lays out the arguments for the deprecation. As for replacement, I guess the paper could have mentioned the `alignas` specifier available since C++11: alignas(16) std::array&lt;std::byte, 8&gt;; There may be caveats I can't think of right now, but I believe this could be a suitable replacement for most uses of `std::aligned_storage_t`: template&lt;typename T&gt; using better_aligned_storage = alignas(T) std::array&lt;std::byte, sizeof(T)&gt;; I'm sure there's a way to define something similar for the union variant, but you'd have to fiddle with the size parameter to make it match the alignment requirement.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1413r1.pdf
That's 2 answers, but both right.
I'm not talking about all, I'm really talking about most, that "modern c++" can fix most of them, while at the same time bringing a new class of modern bugs (like some examples in one of the links) and which are not being covered by static analysis tools, which are generally slow to evolve to catch code constructs, and as the language invent new ways to invalidate memory on each release. "Modern C++" is simply set to avoid **some** memory bugs, when the developer is alert and always responsible, and with no guaranties.
Suppose you need to review data structures and algorithms anyway, and you don't have the months required to get the background knowledge you need to contribute to an open source project or create a library or something like that: you need modern C++ code on GitHub, and you need it now. Why not knock out two birds with one stone?
source?
I've used boost.graph instead of reinventing my own and now I regret, AMA
Can someone please explain the new install command. What exactly does it do compared to today's mechanism? Thanks
The replacement it suggests for `aligned_union` is not really a replacement. What do you suggest as a replacement for `std::aligned_union_t&lt;0, int, vector&lt;int&gt;, string&gt;` ?
Why are you expecting c-libraries to become modularized at all? How do you expect this to work, if c itself doesn't know about modules? Even in a modules world you will have to #include c header files. What you can easily do however is to provide a windows module that wraps windows.h and defines a constexpr variable with the same name as the original macro.
This is the correct answer. The [current top comment](https://www.reddit.com/r/cpp/comments/cet4zz/why_does_everyone_seem_to_reinvent_the_wheel_when/eu4q8qu/) is the justification that obstinate codgers tell themselves.
Do we have control on the alignment of data in boost graph? For instance, one might want to put the weights of edges to the neighbors in same struct of each vertex for cache locality, even though it has some memory overhead.
Why do you regret it? I've never used boost.graph.
If your API needs to work in Unix land then I don't think COM is going to work.
Can you elaborate your regrets?
Why use that instead of `std::variant&lt;int, vector&lt;int&gt;, string&gt;`?
The new install command is a wrapper over the old one. If my memory serves me, instead of `cmake - - build . - - target install` you write `cmake - - install . ` For components instead of `cmake - P - DCOMPONENT=MyComponent cmake_install. cmake` you write `cmake - - install . - - component MyComponent`
&gt;You can't just &gt; &gt;&lt;package manager&gt; install &lt;package name&gt; &gt; &gt; in C++. Have you heard about vcpkg? It allows you to do exactly that. If you use Visual Studio is even better, since it will automatically set up everything for you, just write the code, build and run. [https://github.com/microsoft/vcpkg](https://github.com/microsoft/vcpkg)
- The API is based on free functions. This was a cool idea when experimenting in 2005 when everyone thought that [UFCS](https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax) was around the corner. We're in 2019, there is no UFCS and will likely never be, and IDEs are utterly unable to "autocomplete" on boost graph structures, so you have to reach for the doc *every time*: boost::vertices(...), boost::edges(...), etc etc - All the algorithms on graphs - transitive closure, searches, etc - do heaps of temporary memory allocations, which suck when you want to do real-time processing. This is frustrating because they implementr so many interesting and useful algorithms on graphs. - If you want to dynamically add / remove nodes to the graph, in practice you always have to keep a mapping from vertices ID to your vertices objects - Examples are in my opinion unreadable : https://www.boost.org/doc/libs/1_70_0/libs/graph/example/dfs-example.cpp
https://www.reddit.com/r/cpp/comments/cet4zz/why_does_everyone_seem_to_reinvent_the_wheel_when/eu513jt/
1) it is fun ;-) 2) package/deployment issues mentioned 3) different coding conventions 4) performance considerations (I don't care for string performance, so I wrote it easy to use (automatic encoding conversion, ... I care about geometry primitives performance, so my geometry code is full of forceinline and low level stuff) 5) there is always something missing, like contains in STL containers, trim in STL string, ... 6) abi issues - STL is not binary compatible across compiler versions and switches, tbb is hell when 2 plugins use different versions in same app, ... 7) we have custom assert system hooked into unit testing 8) bugs/omissions in implementations not handcrafted for your specific purpose. Eg. You cannot set stack size for STL thread, nothing but CreateFile it's able to write to hidden/system file on Windows, ... Long story short, as your project gets bigger, cost of implementing custom X goes to 0 compared to the rest of development effort, and chance of running into some limitation of ready made solution goes to 1. We started with STL stuff, and over time completely replaced it with our internal library
QA: You have to prove the library is correct, their tests are not sufficient. That's a lot harder when you didn't write the code. In general, why trust someone on the internet over your team? External dependencies: Not just me who needs it. Everyone upstream needs it. Some environments this is way longer than just doing it yourself. Licensing: If you need to fork and modify but can't without some special condition, that's a no go for a lot of companies. Special usage: If you have a special requirement, you may need a special solution. You may have a different API requirement, complexity requirement, or other considerations.
If it's straightforward enough it does not warrant a dependency, and you can get best possible performance (if performance is not a priority you should not be using C++).
This is the big one for me. I recently got a 30% speed improvement in a section of code after swapping out std::deque for a custom implementation that handled allocations and growth differently.
Variants are not the same as unions, and do not have the same performance characteristics or behavior.
There is always a bit of NIH. But for me dependencies in C/C++ have always come with their own problems. Have you never experienced boost version hell? When a project will compile against the previous point release, but not the current one? When I've had that fun it hasn't even been my own projects, just open source I've been building. It's not encouraging that you're dealing with a project that values a stable API. (Forgive me, it was more than a decade ago, so I can't remember details of which versions it was happening with; but it's just an example)
Last time I tried to use graph boost I had to import more than 20Mo of header files (extracted with BCP), I didn't need any of the fancy algorithms or all the genericity of the structures: just the data structure. A simple adjacency list is easy to write so I ended up rewriting a graph data-structure with just what I need and I now perfectly understand and have total control on what I'm using.
 alignas(Ts...) std::byte storage[std::max({sizeof(Ts)...})];
How does this compare to [libsodium](https://libsodium.gitbook.io/doc/)?
Yes, when it comes to `vector&lt;int&gt;` and `string`, variants usually has less bug-prone behavior. Performance is a primarily QoI issue, and AFAIK currently `std::variant` is not that bad (at least when `std::visit` is not involved, which has no counterpart in unions).
&gt; Licensing: If you need to fork and modify but can't without some special condition, that's a no go for a lot of companies. Even including a boilerplate header for the MIT license has been a point of contention I've received in the past from above.
If I need the data structure to be very fast and expose a limited set of functionality, I will roll my own. Otherwise I would use a library.
&gt; alignas(Ts...) Never knew you could do that. Does it take the max?
Classic and Qi did for sure, but Spirit.X3 will be a pleasant surprise if you haven't tried it yet.
In Python, if you want to use numpy, you just run `pip install numpy` and you're done. In C++, the situation is much more complicated.
A few years ago, the Redox microkernel had about ~15% unsafe code, and the authors were looking at improving things. Similarly in the embedded world, developers have been working on creating HAL and free-standing OSes which encapsulate all unsafety so that application developers do not need a single `unsafe`. There are two things to retain from this: 1. Even in very low-level development, `unsafe` can be a very small portion of the code. 2. The `unsafe` parts can be isolated in reusable libraries that are peer-reviewed and audited by the community.
I thought the whole point of boost.graph is to be datastructure agnostic?
By the way, armadillo is horrible in terms of performance. You should rather use Blaze or Eigen. I personally prefer Blaze because of its modern C++ usage. It also has none of the irritating compiler warnings that Eigen causes.
What is your favorite ice cream flavor?
Free functions are not only just about UFCS. They reflect better the much weaker coupling. [Read this for more.](http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197) That said, the BGL API is not exactly great, and the documentation could be a LOT better.
&gt; - build . - - target install thanks
&gt; I know you're a fan of rust, even rust suggests combining errors via type erasure mostly in the manual. Indeed, and I firmly believe that *translating* errors is a crucial step. For example, imagine that you are calling `gethostbyname`, and you get an error "file `/etc/resolv.conf` does not exist". That's an implementation detail! On another platform it could very well require querying another file, or querying a kernel API! Instead, `gethostbyname` should return something like: - Invalid hostname. - Cannot find DNS service. - Cannot access DNS service. - DNS service could not resolve name. That is, errors must be *lifted* to make sense in the context of the *caller* without presuming said caller knows anything about implementation details.
The new install command does not invoke the generated build system.
Typically a variant will be implemented in terms of `aligned_union`since `aligned_union` is a lower level facility. But set that aside for a moment. Say I want make an dynamic array of `std::aligned_union_t&lt;0, int, vector&lt;int&gt;, string&gt;`, where all the elements have the same type. Effective an array of variants, but with a common discriminant. How do you suggest to do that with a variant?
The situation you mention, while possibly saving developer headache, would be difficult for the compiler to reason about. Let's see a simplified example: `m.h` ```c++ #pragma once #define MY_CONSTANT 1 ``` `m.ixx` ```c++ #include "m.h" export module m; export constexpr bool my_constant = MY_CONSTANT; ``` `main.cpp` ```c++ #include "m.h" import m; int main() { static_assert(MY_CONSTANT == my_constant); } ``` In this scenario `MY_CONSTANT` starts as a macro when the user includes `m.h` then turns into... a variable? Should it remain a macro in this case? Or should it become the global `constexpr` variable? How do you deal with function-like macros? What about macros that don't yet have their text fully substituted? ```c++ #define MY_CONSTANT MY_CONSTANT_INTERNAL ``` Where the definition for `MY_CONSTANT_INTERNAL` isn't needed by the TU which contains the module interface? Tweaking the preprocessor to magic up a global constant variable is not the correct answer here. As others have mentioned, header units were introduced as a stop-gap to preserve old macro based code in a modules world.
Yes. [From here](https://en.cppreference.com/w/cpp/language/alignas) &gt; The object or the type declared by such a declaration will have its alignment requirement equal to the strictest (largest) non-zero expression of all alignas specifiers used in the declaration, unless it would weaken the natural alignment of the type.
Specifically you mean the full release note block, correct?
&gt; What is your favorite ice cream flavor? coffee (the one with the fake coffee beans)
i thought alignas in using declarations is ignored and you have to put it on the variable declaration manually. If you don't template the using declaration gcc apparently warns about this, but with the templating the warning magically disappears. See [Godbolt](https://godbolt.org/z/jlUB_X) Am i missing something?
COM is very much alive and kicking. Take a look at DirectX and some of the Windows API’s. COM solves the problem of binary compatibility and has things like reference counting to clean up the things (interfaces) you ask from them. I would recommend learning COM. It’s not hard and I expect it to be relevant for a while.
&gt; They reflect better the much weaker coupling. I don't think that the act of getting vertices from a graph structure should be "weakly coupled". That would be like push_back / emplace_back being free functions instead of member functions : utterly unusable. If weak coupling did not have an incidence on development time when compared with more tightly coupled solutions, it wouldn't be a problem, but as it stands, with the tools that we have in C++, it is a complete impediment.
This is very similar to `aligned_union` is implemented - see [here](https://github.com/llvm-mirror/libcxx/blob/master/include/type_traits#L1818) for example.
I've used boost multi-table and I regretted that too.
I've used boost multi-table and I regretted that too.
My goodness, that's terrible. The heap allocations alone sound like a complete show stopper.
If you want that you'll have to install Visual Studio (or the build tools package) and Clang for Windows.
... but that is the reason those obstinate codgers have for reinventing the wheel, so it's a perfect answer to the question. OP didn't ask "what are some good reasons for reinventing the wheel instead of using external libraries", they asked "why _do_ people do this".
From my experiences: * If I want some *simple* data structure it takes just as much time to find it online as write it myself. * If I want some *complex* data structure it takes even more time to find one online that meets all of my requirements. * If I do find the complex data structure online it either is missing some nice feature I want or has so many extra features I'll never use but end up paying some cost to have exist * Writing my own data structure means I can control 100% of how it works and the interface it has. I don't pay for things I don't want to pay for and if I need to extend it I can easily do so. * If I write it myself I can use the fact I know 100% how it works to make using it in my code simpler (I can make contracts with myself like knowing end() is always valid and doesn't care about push/pops on the container) * I (almost always) get better performance when I write some data structure for the exact use-case I'm going to use it for. * My own version of a data structure (almost always) ends up being simpler and so compiles faster than the generic one I find online - if the generic online one even exists. * Trying to find a class/container online that has a license we can work with is also a huge pain. Self-written code is mine to use and I don't have to even think about licensing.
&gt; std::vector instead of C style arrays &gt; std::array [only] if you must Why though, if an `std::array` will do? Doesn't it add a level of overhead, or at least make it less obvious what you are doing with the container, if you always just use vectors?
I am using custom data structures in my projects simply because they outperform everything else I’ve found. Popular libraries come with their set of assumptions and design choices, it’s not often the most appropriate ones. And in regards to python, everyone uses bumpy simply because it’s the fastest kid on the block and there is nothing you can do in pure python that will end up better.
It kinda is from a generic standpoint. I mean, this: auto x = foo(y); is more generic than: auto x = y.foo(); since the latter implies that y is an object, while in the former example, y could be anything. And, the free-function foo() can make use of ADL, just like std::begin() does for example. Also, a free-function push_back() is actually something I wanted sometimes in generic code. For example, std::push_back() for containers that are simple sequences. I frequently work with free function, and they are not an impediment to me.
multi-table? do you mean multi-index?
Your codeblocks are broken on old reddit(and possibly many reddit phone apps). Indenting code with 4 spaces will fix that.
I don't think `&lt;windows.h&gt;` is a particularly importable header. And that *does* read the file over and over again because header units expose macros (for dependency discovery purposes). import &lt;windows.h&gt;; #ifdef MINMAX import required.modname; #endif
Seems like you are right. I guess we'd have to put the array as a member inside a templated struct, making it a little more awkward to use. Then again, such a construct probably *should* be a little inconvenient to use.
Often, you're not being taught c++, c++ is being used as an implementation detail for teaching data structures and algorithms. If you're being taught how to write an efficient matrix multiply, using a library that offers a function or operator to do it misses the point. I usually don't see python being used at that level. When python is being taught, it's usually in a space of doing data analysis/ML/etc. So you load a package, feed it your data, plot your results, etc. You may care about which algorithm is used, but only because of its properties.
Assuming that your average developer can get better performance than the library implementations is likely not correct. Things like optimizing for cache and making it easier for the compiler are not trivial things.
Random note: the conclusion of the paper of not providing a replacement is bullshit. Once the shortcomings have been identified (and the paper is quite good at it), it is somehow easy to redesign a correct version for the comity, while in absence of any correct design users will be at risk of doing the same mistakes as originally done (or worse). Also I don't get why: &gt; The second parameter, the alignment, has an implementation defined default value that may or may not be sufficient for T. because the spec requires the default alignment to be sufficient for any T that would fit...
Any C++ books you can recommend, or should I just go with 'the Bible'? I *know* C++, in that I taught myself back in high school and still dabble, and had to use R, Python, and Matlab in college for mathematics, but I have no formal experience with C++. I can read code, I can write spaghetti, but I need to get better at it.
That won't work with header unit. You have to set config macro as a compiler argument when compiling the header because imports isolate macros, even for header units. If header unit don't isolate macros and are read over and over again, there would be absolutely no point to having them.
The problem isn't that there aren't package managers for c++. The problem is there isn't *one* package manager for c++
While there is no doubt a practical benefit to having such a feature, it sounds like a nightmare to further increase the scope of modules to supporting C-like constructs where better C++ constructs exist.
Your post was eye-opening for me.
Is there caffeine in it?
Header units export macros.
Indeed, but cannot read macros that comes from the importer
To expand on this: they are read over and over *during dependency scanning* (though I've heard that clang has some `.pcm` middle-compilation-thing that could help here, but then you need to know to make that first before dependency scanning). When compiling, the BMI needs to already be made. That is where you save compilation time.
Hi, operating systems developer talking here. I'm teaching C++ for a systems programmer that would maybe want to also become an application developer, using the modern standard library features. I'm well-aware of the lack of standard libraries in many freestanding environments and I trust system programmers to be able to use C++ to their advantage after reading the upcoming Classes tutorial.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/cet0xb/how_can_i_show_the_array_while_being_sorted_upto/eu5ci1t/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yes. That's fine. This is just an optionally imported module. It doesn't see `MINMAX`, but it is conditionally imported on it.
This is because I'm using the markdown syntax. I suppose UI views don't make the two representations consistent :(
The situation you describe has no bearing on the situation under discussion, since you renamed the constant to be in lower case. I explained why this is undesirable in the posting. Are you... somehow... imagining that creating a constexpr constant with a completely different name is supposed to change the nature of MY\_CONSTANT? If so, how on Earth did you manage to come up with that after reading the posting? I'm not asking for the preprocessor to "magic up" anything, and it is a mystery to me why you would think such a thing. I'm asking for the preprocessor to be altered so we can instruct it, using code that we explicitly write, no magic anywhere, to leave certain symbols alone while it is preprocessing. That's all. As for header units: I explained in the posting why having a multitude of unused symbols is undesirable.
Ohh... My bad, I read it as a define for inside the module. Sorry for the noise
I think I've heard of about 4 "package managers" for c++, that are all really easy to use. It just requires all library creators to modify their build system and all libraries have custom built arcane machinations from the 80s as build system that noone but a few people feel qualified to refactor. Furthermore, none of these "package managers" have a very large group of people using it, so it's hard to justify the effort to begin with.
Could be, but it seems like something that will become an extremely common problem once we have modules. Anyone who uses 3rd-party libraries and wants to wrap them in a module (and it seems an obvious step to me, as 3rd-party libraries have always been a rich source of unwanted macros) is going to run into the question of somehow exporting constants, but not macros from the library module. So to me it makes a lot of sense to support this directly in the compiler, rather than in a separate tool.
Fake bean so fake caffeine, like the fake sugar
It is nice but damn these templates. So...many... templates and it is also impossible to debug
I expect to write those modules myself, actually. As I said, part of my goal is to prune the symbols I get from certain headers, and my specific needs for which symbols I need are unique to my situation anyway. Such a module will include whatever headers I need, and become the only source of symbols for that library everywhere in the source.
`std::variant` can't be implemented in terms of `aligned_union` because placement new can't yet be used in `constexpr`.
Bjarne's 'Tour of C++' is great! It's short but gives you all of the essentials and best practices for the core language and the standard library stuff. Even if you want more, it's a good place to start.
Sure, but #define is part of the preprocessor, not the compiler, and the preprocessor doesn't understand the language. What you need is a way to define a constant with a name without the preprocessor replacing the name. You can get very close using this: #define FOO 10 #define EXPORT_MACRO( type, macro ) export type macro##_ = macro EXPORT_MACRO( const int, FOO ); Which produces this: export const int FOO_ = 10; So if the preprocessor can be instructed to expand a macro to just the macro name it should work. Something like this: #define EXPORT_MACRO( type, macro ) export type ###macro### = macro Where the preprocessor will not expand macros it encounters between two ### tokens, but will still substitute macro parameters it encounters inside such a region.
I just suggested something similar but it would only be done within macros so you'd need to wrap this code inside of a macro to get the correct substitution. See https://old.reddit.com/r/cpp/comments/cepawu/exporting_constants_from_modules/eu5fk4c/
Ah, for some reason I was picturing that somehow the compiler would be responsible for exporting object-like macros automatically for you. This was my mistake. With regards to the proposal you mention, the scenario that would still be problematic is where you both include the header _and_ define that name as exported (i.e. change `my_constant` above to `MY_CONSTANT`). What are the expected semantics there?
You already do that in most cases: ~~~c++ template &lt;class... Ts&gt; void f(const Ts&amp;... vs) { (..., [&amp;]() { std::cout &lt;&lt; vs &lt;&lt; std::endl; }) ; } ~~~
Does it give you fake diabetes?
Yep and fake death
Well, tell me, what *is* a graph? Are the vertices labelled? Weighted? If so, are there any constraints on the labels or weights? How about the edges? Are the edges directed? Can you have an edge from a vertex to itself, or several different edges between two different vertices? Are the vertex and edge sets necessarily finite? Is the graph necessarily connected, and if so how do you enforce this? &amp;#x200B; How about trees? Aside from the general concerns about graphs above, are your trees rooted? If not, it's not easy to tell that they're actually trees. Do you enforce this, or trust the user not to construct a more general graph? &amp;#x200B; Once you've figured out what your objects even are, now we can start talking about data structures. Which operations need to be fast and which can be slow? Do you have constraints on the amount of memory you can use to store them? &amp;#x200B; Now that we've resolved these questions, let's begin digging through libraries available online and determining whether they provide the functionality you need. Oh, and while we're at it, do we have any requirements on the library itself? Do you need one that's header only? Do you need particular licensing terms? How stable are these libraries, and are they actively maintained? &amp;#x200B; By the way I don't know how numpy helps here. It doesn't have graph or tree data structures, and using it together with pyplot routinely results in horrible incompatibilities that you learn about because an exception was thrown twenty levels deep in some obscure utility function.
See what I replied above. Can be easily done without recursion: `(..., foo(vs));`
Matrices, trees or graphs? That's not bad at all. Lots and lots of people reinvent strings! Because [NIH](https://en.wikipedia.org/wiki/Not_invented_here).
Could not agree more about the free functions and API discoverability. Just been bitten by that on an internal project myself. I literally wrote a member function for something I thought was missing, then by chance scrolled to the bottom of the .h file to discover someone else had already done it as a free function.
One thing is it's exceedingly difficult to write a library that exposes all the different "knobs" that a user might want to modify. Consider [std::function](https://quuxplusone.github.io/blog/2019/03/27/design-space-for-std-function/). The post goes on for a number of pages just documenting all the different design choices you could make for a single pretty-darn simple thing like a type that holds a function. Other languages seem to get around it for a few reasons: they don't have zero-overhead contracts so they can manage a lot of this at runtime. Also they aren't as performance oriented, things like SBO and no-throw-movable are meaningless in high level languages where every function call is a runtime lookup.
Yes. Re scrolling: i was zoomed in at the time- it actually works, but still painful because it’s frame has so much margin vs the screen
In terms of "Bibles", I don't really have any good recommendations for C++. I do have Stroustrup's "The C++ Programming Language" and "Programming Principles and Practices Using C++ (2nd Edition)", which are two massive books. Although I mostly used them for reference at first, and barely use them anymore (Most of what I was using them for can be found online fairly easily). On a side note, I'd be wary of "bible" books. I decided to learn more C this summer and the non-C community seems to refer to "The C Programming Language" book as *the* resource for learning C, but when I ran into problems most answers on sites like Stack Overflow seemed to immediately notice that the poster was trying out a problem from that book, and were saying that the book has a good reputation from non-C programmers, but that most of them wouldn't recommend it because of how out-dated (and sometimes straight-up wrong) most of it. So I'd be careful with "bible" books when learning programming. My personal recommendations would be the following: For people who don't know C++ all too well: - Stroustrup's "A Tour of C++" is a great introduction. It goes over most of the language's features without really putting too much emphasis on the standard library (in the sense that it won't focus on a specific header). It's mostly useful if you're already familiar with programming, though (since they don't really explain the basics of programming, just the features of the language). Honestly, even if you *know* C++, I think this book is still a good refresher if you haven't done a lot of it lately. It's very easy to just skip the sections you're familiar. The book should give you a decent understanding of what C++ has and how some of it can be used. The problem is that it doesn't really give you any "meat". After that, I'd recommend the following books: - Scott Meyers' Effective C++ - Scott Meyers' Effective STL - Scott Meyers' More Effective C++ - Scott Meyers' Effective Modern C++ In that order. I say in that order, because the older books explain things that the later books correct (due to new or missing features being added to C++), so it's *very* useful to know about them (if you ever see someone using an old workaround) and to know how they've been handled later on. These books are also very useful to learn best practices, while also giving you some concrete examples of what to do and why to do it that way. Now, honestly, once you've read those books (arguably *while* you're reading those books) you should look into data structures. Understanding the performance difference between a `list` and a `vector` and when to use one over the other is fairly important in C++ since it's a performance oriented language. I'm not sure if the two massive books I mentioned at the start cover this (I'm assuming they do), because I learned it in college, not through the books, but it isn't very difficult to learn. Once you're done with the above, I'd say most of the learning experience comes from actually programming stuff. You can probably find a book of exercises if you *really* want to, but I'd just take a look at something like [Project Euler](https://projecteuler.net/archives)'s archives to get started. After doing a bunch of these, there's a couple of ways to keep learning. C++ and C especially have some concepts that are important to learn while not necessarily being exclusive to themselves. I'd recommend the following: - If you're comfortable with C++, check-out some C++ convention talks about certain things. They're typically heavily biased towards the speaker's job, but they tend to be interesting enough. Something I appreciate is how aggressive some of the Questions and Answers segments can get compared to other language conventions (some of the old guard *really* don't want what the speakers are selling). - I bought, but haven't gotten through, the following books: "Accelerated C++", "Exceptional C++", "More Exceptional C++", "Exceptional C++ Style", "C++ Coding Standard". I can't speak for all of them, but so far most of them are pretty interesting and offer some pretty good advice on coding in C++. - Reading the book "Linkers &amp; Loaders". It goes in depth about how the linking process works in programming languages. Even if it isn't perfect, it definitely helps in C++, since linking errors are the bane of people who don't understand how linking works. I read through it during an internship where we had a lot of templates and linking errors, and it was a god send! I'd definitely recommend it! - Since you've mentioned spaghetti code, I figured I'd mention "Clean Code" by Robert C. Martin. I know some people in the programming community thinks he's full of himself, but his book has some great tips for newcommers. You don't necessarily have to take his opinions of Test Driven Development (TDD) to heart though, as he's heavily biased and has been pushing to make it popular for a long time. He's also written "The Clean Coder", which is about being a professional software engineer. That one's more about professional practices than actual code writing, but it can be useful. I'd avoid his "Clean Architecture" book, though. I bought it and dropped it after it became apparent he was just repeating his other two books ad-nauseam (and he came off as kind of full of himself in that book). - If "Clean Code" wasn't enough, I'd recommend "Beautiful Code" which shows code that software engineers thought looked "beautiful" and explain *why* they liked reading it. It's definitely not a "how-to" book, but it's good to know *why* people might prefer to read some code over other code. - Another good way to avoid spaghetti code is to understand patterns and when to use them. Do note that patterns aren't set in stone. They're more like guidelines to how something should *behave*, rather than how it's *implemented*. I'd recommend the "Design Patterns" book by "the gang of four". It's widely considered the best book on programming patterns, and it just happens to use C/C++ for its examples (although some patterns' implementations are outdated due to new features making them *much* simpler to implement nowadays). - Finally, I'd recommend the book "The Pragmatic Programmer". It's not C++-specific, but it covers so much of how to approach programming problems, that it might as well be *the* programming "bible" of how to approach problems (do remember my warning about "bibles", though).
&gt;Typically a variant will be implemented in terms of aligned_unionsince aligned_union is a lower level facility. When you say "typically", what do you mean? None of MSVC, libc++ or libstd++ implement it this way and I'm not familiar with any non-standard implementation that does so such as boost.
Making it myself means I don't have to learn somebody elses thorougly enough not to get caught out.
So what you want is writing a wrapper. As I said, nothing is stopping you from writing a module that experts those constants as constexpr variables.
It's often easier to reinvent the wheel in C++ because of how hard it is to integrate third party libraries.
Yeah that's sadly the case
rolling my own tree that behaves the way i need it to for my specific use-case is pretty easy --- it's literally one of the first things i learned to do in school. on the other hand, libraries often involve complicated templates that i don't understand, and i've been burned before by a library overloading something i didn't expect &amp; getting whacky bugs because of it. TL;DR: i am a polyglot programmer. i understand data structures. i do not understand popular c++ libraries.
Point 5) annoys me to death. It's just boilerplate that every damn project needs to write again. I don't get it. Together with the atrocious build systems this killed any fun and interest in c++ from my side.
&gt; I don't think that the act of getting vertices from a graph structure should be "weakly coupled". That would be like push_back / emplace_back being free functions instead of member functions : utterly unusable. Like `ranges::action::push_back`? So unusable! /s
I apologize for being inexact. What I meant was `aligned_union` is a low level facility while variant is a high level facility. Typically a high level facility (not specifically std::variant, but generally speaking, like llvm::SmallVector) will be built on top of a lower level facility. So asking `aligned_union` to be implemented in terms of variant is a layering violation. As /u/redditsoaddicting notes, `std::variant` cannot be implemented in terms of `aligned_union` because placement new cannot be constexpr. So you pretty much have to use unions, as explained [here](https://akrzemi1.wordpress.com/2012/12/13/constexpr-unions/), to implement `std::variant`.
Windows makes it a bit harder for numerical stuff on python but then you just install Anaconda.
This is kind of a footgun though if you don't receive information from the compiler that the directive is being ignored. If anything `aligned_storage` and `aligned_union`, when used properly, should be an expression of intent that the standard library then takes care of executing for you. It may not be that currently, but removing it without providing clear documentation on how to reliably do what it does in a better(?) way strikes me as rather dangerous.
&gt; Random note: the conclusion of the paper of not providing a replacement is bullshit. It really is. Looking at other comments in here that are trying to provide alternatives, and how they have replies of "no that won't work do this" is very telling. This is an expression of intent, and the standard library is letting users down by not executing it. The answer isn't to remove the ability to express, but to improve how it's translated into execution.
Even better when you’re writing plugins for apps that each link dynamically to a different boost version. Boom!
I have enabled word wrap so it should be easier to read now
Thank you for the feedback, I realized that your objection needs special attention in the Design section. See [https://zajo.github.io/leaf/#errors\_are\_not\_implementation\_details](https://zajo.github.io/leaf/#errors_are_not_implementation_details).
Much better, thanks!
Well said. I learned after I wrote that comment how much faster the stack is. Totally blew me away.
sounds like a disaster waiting to happen, but good luck with it
Herb's style I was talking about is auto x = Iterator{foo(x,y,z)}. It's moving the type to the right. Also auto foo(x,y,z) -&gt; Iterator { ... } So we're talking about two different things.
A lot of libraries actually don't compile when using CMake with the Clang GNU frontend. I tested fmt, doctest and boringssl and none of them successfully built using the GNU frontend. I implemented the necessary fixes in [doctest](https://github.com/onqtam/doctest/pull/254) and reported the issue for [fmt](https://github.com/fmtlib/fmt/issues/1237). The first problem that I encountered with each of these libraries was the C++ version passed to clang. Each of these sets the C++ version to C++11 which is incorrect as soon as you use the MSVC standard library on Windows as its headers are written in C++14 which makes any code using it dependent on C++14 as well. This was never a problem until now because MSVC's compiler (cl) doesn't have a C++11 switch but with the Clang GNU frontend being added, a lot of C++11 libraries will have to update their minimum required C++ version on Windows to reflect the fact that the MSVC standard headers are written in C++14.
&gt; Trying to find a class/container online that has a license we can work with is also a huge pain. Self-written code is mine to use and I don't have to even think about licensing. lol. usefulness is directly correlated with the probability of the library being GPL
It does: https://godbolt.org/z/qDhyUb Marking it `constexpr` makes that a guarantee.
The compiler is a certain type of idiot, amazing at certain things horrendous at others, I've learned it's generally best to baby the compiler if you want fast code.
Where do I find resources on this topic? On how to write programs that take advantage of the capabilities of the compiler and avoid things that may seem fast and then result in slow code?
Thanks. In your opinion is it worth to add a keyword just to make the compiler do something it already does? I'm new to CPP and coming from C it seems so bloated...so many keywords and ways to do the same thing.
The borrow checker go beyond just preventing using unallocated memory. It prevent data races too.
Abseil provides lots of the missing stuff
Try doing "vcpkg install boost" how many times did it download and build boost? How much space did it use? Not to mention the awfulness of it defaulting to things like 32bit on Windows, yet MSVC defaults to 64bit when opening a folder with CMake
compilers weren't always as smart as they used to be now. there was a time before C++ compilers were smart enough to do `constexpr` analysis on their own, so the language added a mechanism for programmers to do it manually. then, compilers realized, "hey, since i already know how to evaluate these `constexpr`s at compile-time, why don't i try doing that to some code that isn't marked `constexpr`?" in 2019, if you don't want to add verbosity to your code with the `constexpr` keyword, just don't. but please, try to understand the origins of the tools you're using before you ask leading questions about "add[ing] a keyword just to make the compiler do something it already does".
Marking constexpr does not make any guarantees it just means it will warn if it won't be able to be constexpr. The constexpr only bubbles up if you put it in the right places.
Measure, benchmark, profile and read assembly.
Oh, I thought constexpr was a new feature. Just realised "modern cpp" is a decade old.
no one cares
That's why "modern" is a terrible way to describe anything.
https://www.youtube.com/watch?v=fQeqsn7JJWA
amen
Imagine you write some code: int myConstantInt = MyConstantFunction(); MyTemplate&lt;MyConstantInt&gt; myTemplateObject; Now, you KNOW that MyConstantFunction will always return the same value, and so you know that myConstantInt will always be the same value. So, lets use this as a template parameter. In order for this to work WITHOUT constexpr, then the C++ standard would have to mandate exactly what standard analysis compilers would need to implement so that they can guarantee this code would work with ALL standards compliant compilers, on ALL optimization levels. Now imagine having to write a comprehensive static analysis guideline to cover all these cases where compile time constant-ness can occur. It is far simpler for everyone involved to have these kind of guarantees highlighted by the programmer, so that compilers can be free to optimize code as they see fit.
obstinate codgers know more than you.
How are we supposed to put our copyright header if their header is there? /s
For simple data structures, it's easier to implement it myself than it is to pull in a dependency, unless said structure is part of a larger lib that I'm already using (i.e. Boost or Qt) For complex structures, I will usually find libs that provide that and that alone. If one doesn't exist I develop my own separate from the project that it's needed for. Dependencies are a liability and the more you have the more likely you are to get burned by one of them, especially if it's some random dude's github repo.
Whether something is evaluated at compile time is not as straightforward as it seems and constexpr ensures that it is. It also ensures that it's evaluated at compile time across compilers.
There's many reasons but the most important one in my experience is that most library developers seem to have a total disregard for the memory allocation requirements of those consuming their libraries. * First of all, having any dynamic allocation at all will exclude most embedded system devs. * The horrible std::allocator interface and the need for stateful allocators was the motivation behind libraries like the EASTL. Yes I know PMR exists but it's too little too late at this point. * Equality comparison of std::strings with different allocators will fail * Some library classes will dynamically allocate without even providing a std::allocator interface support ([like std::function](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0302r0.html)) * Over time companies build custom workarounds for these problems and now there's likely not a single library out there that can handle their specific requirements
I learned C++ on my own and when I got to college and had to learn Java, it was endlessly frustrating trying to figure out what was a value and what was a reference. It's definitely a language design issue and not one inherent to GC langs though.
I just don't want to give credit (or copy the license) of the original developer for MY work? Well, no, not really! I, personally, prefer to have my own implementation, so that I have greater customization (do I want a float or a double, both maybe?)
What's faster, understanding its documentation or reimplementing your own version?
I'm pretty junior but every time I interacted with boost I had a bad experience. It's nice as an experimentation platform for library developers I suppose but god how awful has my experience been so far
Python developer: "Why would I program it myself when someone did the job already?" C/C++ developer: "Why would I use someone else's code while I can do it myself?"
The current `constexpr` definition in the standard already mandates exactly what static analysis compilers need to implement. Couldn't the standard just say that everything that can be marked `constexpr` (by today's terms) is `constexpr` by default?
&gt; std::bitset would seem to be the perfect solution, as it is efficient and has rotation as a member function... It does? Anyway, `boost::multiprecision` with a constant number of bits, say `boost::multiprecision::uint128_t` might be an option.
"Automatic constexpr" is something that I've suggested a few times, and it's basically what D does with it's CTFE as I understand it. It should certainly be technically possible to automatically whether a function could be constexpr or not in C++ as well, because that's exactly what happens with constexpr lambdas in C++17. As I understand it, the argument again "automatic constexpr" is that it could lead to brittle interfaces. Let's say I have a library function that happens to be constexpr-callable today, and you start relying on that behaviour (say, by using that function to calculate the value of a non-type template parameter). Then I update my library so that the function is no longer constexpr callable -- which is fine from my point of view, because I never promised that it would be -- then your code will break *even though the interface of the library didn't change*.
No but you can have domain-specific knowledge the very generic library implementation does not have
I described one reason for constexpr like this a [while ago](https://old.reddit.com/r/cpp/comments/9opn16/lex_c14_fast_and_efficient_constexpr_tokenizer/e7yd10j/). This is certainly not *the* reason to have constexpr, but a nice advantage of it regardless. &gt; `constexpr` is the ultimate tool for detecting accidental reliance on undefined behavior, and hence it enables you to improve the portability and correctness of your software with respect to different compilers/compiler versions. &gt; This is possible because constexpr functions can be tested at compile-time using static_assert. While in a runtime-test the tester's C++ compiler may happily pass the test because UB incidentally produced the right result, if UB is triggered while checking a static_assert, C++ compilers are required to emit a compile error. &gt; Conversely, if a program that evaluates a constexpr expression at compile-time does indeed compile, it's guaranteed to be free of undefined behavior (and so are equivalent runtime uses of that expression). &gt; See for example: https://godbolt.org/z/ZBTaP8
Oxford University has a "New College" -- founded in [1379](https://en.wikipedia.org/wiki/New_College%2C_Oxford)
Too bad the committee didn't add a specialization for `std::valarray&lt;bool&gt;` like they did for vector. /s
I'm not sure I understand that last sentence.
If the compiler can statically compute the result of some operation at compile time or optimize based on const-ness it can and will without you telling it to. The purpose of constexpr is (1) for you, the programmer, to specify that you wish to compute something at compile time so the compiler can inform you if it is not possible, and (2) to formalize what subset of the language a compiler MUST support evaluating at compile time.
I love multi index. The only library besides serialization I will defend to death.
~~new~~ ~~modern~~ contemporary?
Have you ever used cereal?
The compiler won't necessarily statically evaluate constexpr value at compile time unless it has to (template argument). It could, but it will only do so if it is cheap. You know why? Because compiler users keep asking for fast compilers instead of asking for smart compilers. There is an incredible amount of research on compiler optimizations that are left out just because it would make them significantly slower.
That is a good question, but you also need to take into account the cost of maintenance of both. The maintenance of writing your own could be huge or small depending on how closely your own thing matches your future needs. The cost of using a library means extra complexity in the buid if you're not using package manager and needing to get updates from someone else. Some people are able to predict the future needs really well and they should use custom data of structures, while other people just need a whole bunch of flexibility often libraries will serve these people better.
This post is outdated. Clang 8.0.0 and GCC 9.1 emit optimal code for both forms. MSVC 19.21 strongly prefers the default constructor, though.
If it’s of any appreciable size, you don’t know exactly how it works.
&gt;This post is outdated. Considering it's from 2013, this isn't really surprising, but it's still good news, thanks. &gt; Clang 8.0.0 and GCC 9.1 emit optimal code for both forms. MSVC 19.21 strongly prefers the default constructor, though. How do clang and know that constructing a string from an empty C string is the same as default constructing it? Do they hardcode some knowledge about std:: basic_string or is this something that could apply to the user-defined classes too, somehow?
Now that I've thought about it a bit more, you're right, the more important feature is the interface guarantee. Not necessarily for better error messages, but to guarantee which things in, for example, the standard library are constexpr. Earlier this afternoon I was of the opinion that constexpr gave compiler developers more freedom, but this evening I have decided past me was wrong. They could have mandated that when something needed to be constexpr (like template parameters), that expression only was evaluated for its constexpr-ness. It would have been the same work for them either way.
Armadillo is great if you’re coming from numpy. In fact, there’s a translation app that converts numpy and python to c++ with armadillo.
Poolallocator for cheap allocations?
That’s a very modern point of view.
`std::char_traits&lt;&gt;::length()` is constexpr since C++17.
If you are interested in C++ in particular, C++ Weekly on YouTube is a great place to learn a lot. Jason Turner does a pretty good job explaining features of the language. His keynote at a recent conference may be a good place to start if you want to hear about the biggest language features before diving too far. https://m.youtube.com/watch?v=SZ__h7uEDGc
&gt;The C++ Programming Language This was the "bible" I was referring too. I was on mobile at the time, thought the title was *something* like this, but wasn't positive and didn't feel like jumping around apps and internet searches to check. All great recommendations that I am adding to my reading list. Thanks.
You could store the size in the deleter and use that but it's probably not a good idea.
And it's exception vs segfault, I don't think you can really complain there.
**Company:** Microsoft Corporation **Type:** Full time **Description:** Principal Engineering Manager *Responsibilities* The Project and Planner team, part of the Office organization, is seeking to hire an Engineering Manager to lead the team responsible for our core Project Scheduling Engine and the Windows Project client. As a leader of this team: You will manage a team of experienced engineers as part of larger Work Management investments. You will be responsible for delivering a highly reliable, secure and performant scheduling component underpinning Microsoft’s Project Management Cloud services. You will also own all aspects of engineering and shipping our Windows Project Client application in partnership with the larger Office engineering team. You will be part of a standalone business where engineering work is tightly bound to our business and growth priorities and objectives. You will use customer feedback to drive improvement and innovation in our products and ensure that customers are succeeding with our software and services. *Qualifications* Applications should have 2+ years of experience managing a software engineering team as well as a passion for C++, for solving complex problems and for delivering quality results. *Basic Qualifications:* A Master’s degree (or a Bachelor’s degree with 5+ years of work experience equivalent) in computer science or a related field. 7+ years of experience with coding in C and C++ 7+ years of experience creating, shipping and evolving large commercial software components or products at scale. **Location:** Redmond, WA **Remote:** No, management position **Visa Sponsorship:** Yes **Technologies:** C/C++. **Contact:** Feel free to PM, or apply here: https://careers.microsoft.com/i/us/en/job/671627/Principal-Engineering-Manager
Wow that sounds very pleasant to fake consume.
Curious, what work did you use graphs for?
Both 4 spaces and 3 backticks are Markdown syntax in CommonMark and Github-Flavored Markdown. It happens that reddit's traditional renderer doesn't support the backticks option.