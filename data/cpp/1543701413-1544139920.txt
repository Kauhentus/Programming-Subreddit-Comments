I toyed with coroutines (just once) to have non-intrusive monadic error handling : [https://wandbox.org/permlink/7kCCyNjJXh3qGLGz](https://wandbox.org/permlink/7kCCyNjJXh3qGLGz) Here, the promise\_type is more like a promise, altough this use case is not standard-compliant (for now ?). But I agree, your naming seems more right. 
No, I think they're just oblivious and submit their blogspam to any subreddit that is related to programming. We just make fun of their content over at /r/programmingcirclejerk, which I doubt is the poster's intent. They're likely submitting so many times to try and abuse search engine optimization, thus violating reddit's spam and self-promotion policies.
Thanks! They do take a while to write, so it's good to know it's useful :)
There is some logic in ISO's rule. A published document such as a TS meets certain quality requirements (e.g. the document as a whole having been reviewed by national standards bodies) that a working draft does not (necessarily). So, if a TS referenced a working draft as its base document, the document as a whole couldn't really be said to meet that quality bar. As a strawman example, suppose that some serious flaw in C++20 Concepts were to be discovered (and corrected) between now and the publication of C++20 (very unlikely, but bear with me). If in the meantime we had published the Reflection TS based on C++20 Concepts, we would have inadvertently put out a published document that inherited those flaws.
Ok? Doesn't ISO have a process to correct mistakes in documents?
thats awesome, thanks for that explanation. Makes total sense. &amp;#x200B; I'd love to see the c++ code and how that looks - im used to full stack javascript. Any github repos using this that aren't too complex?
Thanks a lot for your post, very nice! (Not sure who would down-vote this post...)
That's way better. With your proposal, you could even take it a step further and stuff it into a `namespace coroutine {}` . So suspend point would lose it's ambiguity and the worst case length for context is `std::coroutine::context co_ctx;`. I could live with that.
lol nevermind, [you guys just announced explicit support](https://aws.amazon.com/blogs/aws/new-for-aws-lambda-use-any-programming-language-and-share-common-components/)
It honestly doesn't matter that much. Implementers are free to start developing against any proposal or paper they darn well please, whether or not it's something the committee has officially ratified and published. It's of course probably wisest to only put effort into implementing major proposed features if they have a chance of making it into the standard, but a TS doesn't guarantee that \_anyway\_. :)
Post this to CodeReview.stackexchange.com. I'm sure it'll generate interesting reviews. Your "iterators" are all wrong: `iterator_traits` won't recognize them as iterators. You don't need to materialize your data as a vector; you could easily iterate it without materializing the whole sequence. E.g. `die::cast(1'000'000, 6)`. The parameter order makes sense if you think about it... but wouldn't it be cute to write `3_d(6)` instead of `die::cast(3, 6)`? Or at least let me write `die::cast(0x3d6)`! :D
If you're on windows, it's `std::ifstream file("lena.bmp", std::ios::binary);`
You should really use the binary flag for all code, tbh...
The for-loop accepts them just fine so it appears to be right. Unsure what you mean about materializing the sequence. Oh man! I could write a user defined literal for that! I lold at the hex representation. Brilliant.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a29mgy/why_ifstream_cant_read_after_0xc0000/eawf7ry/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a29uyi/odd_crash_behavior_with_stdfstream_in_a_thread/eawf8js/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your trip reports are the best, thanks! Do you know if [Expansion statements](http://wg21.link/p1306r0) still can make C++20?
Can somebody answer this question. An std::string is not necessarily null-terminated. Now c_str( ) returns a C-string with the contents of the string null-terminated. How does this work? Does c_str( ) make a copy of the string with a null-character behind it? If yes, who will own this copy? Or does it temporarily add a null character to the string? In both cases, it cannot be no_except. In the second case, it cannot be const. How does it work?
/r/cpp_questions, but you'll get mauled on for using Turbo C++ no matter where you post this.
Project updated. You can now do the following: using namespace die::literal; die::die_cast res = 4_D(6)+5 &lt;&lt; 3_D(8) &lt;&lt; 10_D(2)-30 &lt;&lt; 1_D(6);
Is this a troll post? The fuck are you using Turbo C++ for? &gt;my code is safe btw. Call me skeptical.
i know, i know but i am bound to use it as it is a school project and our country board has prescribed this shit and it hasn't been amended for ages.
Making up new terms for hints that already have names can be far more harmful than watching cat videos. 
instead of shitting on me for using this, wouldn't it be nicer to help me with this.
Actually, this code (and this concept in my usage) goes back to the mid-90s, so I imagine I probably have dibs on it if we want to get all legalistic about it. Everyone these days seems to want to come up with fancy new names for things that have been around forever. &amp;#x200B;
Yes, I believe expansion statements are targeting C++20 and should make it if no unexpected difficulties come up.
The compiler is crashing due to a general protection fault (trying to access an invalid memory address). There doesn't appear to be any more useful information provided by the exception handler. I recommend you try your code on a modern compiler, fix any warnings and errors, and try again with TurboC++.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a2agzo/weird_turbo_c_error_exits_the_complete/eawk4s2/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You can try solving your problem using modern IDE and compiler, and then running it in Turbo C++ in dosbox if you're not doing so already. Highly unlikely you'll get much help with doing what you're doing.
I mean...it just looks like the compiler itself crashed. After all this time, I imagine that there'd be some kind of documentation of what makes the compiler misbehave? Which version of Turbo C++ is this, exactly?
What is the benefit of writing this: ``` die::die_cast chain = 10_D(6) &lt;&lt; 1_D(20) &lt;&lt; 3_D(4) &lt;&lt; 1_D(8); std::vector&lt;int&gt; result = chain; ``` instead of this? ``` std::vector&lt;int&gt; result = { 10_D(6), 1_D(20), 3_D(4), 1_D(8) }; ``` That is, why do you bother with all the intermediate vectors? Just make `10_D(6)` evaluate to a single integer directly. Much faster and cheaper (in terms of memory usage), and doesn't require heap allocation at all! "Don't pay for what you don't use."
Is there any big difference to the RAII pattern? I'd say you should at least mention it and explain the differences if there are any.
Turbo C++ 3.2 I found it on developer insider &amp;#x200B;
Per the most recent comment, it would be nice to see what the differences are between RAII / initialisms and your janitors; if it is a duplicate term, I'd myself stick to referring to RAII when documenting or describing things. However, I could see janitor as a useful adjective for naming things that implement RAII, if other commonly used adjectives such as `guard` or `scoped` (or both, such as `ScopedGuard`) are awkward when used in the name.
This is one of the worst examples of overengineering I've seen in a while. The only API that makes sense is this one: int RollDie (int Sides); And you could implement it like this: return 1 + (rand () * (Sides - 1)) / RAND_MAX; That's one line of code instead of 175. All this constexpr template UDL namespace design pattern malarkey is exactly the kind of utterly unnecessary complication that turns people off from the language in the first place. It isn't even more efficient; any gains it might get from using a template are blown away because it allocates memory. If you are a student programmer who is trying to learn the language: great, you learned about a great many language facilities, well done. But please keep in mind that simplicity and clarity are highly valued skills, and don't forget to develop this as well. 
It seems you are unaware that the rest of the world call this pattern by the name RAII. Your claim to discovering it is doubtful; the [Wikipedia article](https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization#Limitations) states "The technique was developed for exception-safe resource management in C++ during 1984–89, primarily by Bjarne Stroustrup and Andrew Koenig." &amp;#x200B;
Some of the talks on HPX from hartmut kaiser at cppcon show these ideas being used for large scale dynamics simulations. When I saw Christian's talk at pacific++ I instantly thought of hpx. Personally I like the style and approach.
Not as far as I can tell. He also seems to have implemented his own \`unique\_ptr\`.
Please, write the names you invented to see where the most painful points were. It will be great to hear how people wrap their thinking so to make sense of coroutines. 
I like your proposal. Makes it much easier to reason about.
I suppose you are referring to [this talk](https://www.youtube.com/watch?v=xuL7rfkcWus)! Thanks very much for the pointer, looks very interesting, going to watch it now!
&gt; `template&lt;bool IsConst&gt;` It's a shame that that's the way to do it - it's very unintuitive, in my opinion. (and hard to learn &amp; teach)
This is great, thank you.
Debugger? James McNellis also showed a neat tool her that allows you to explore the program state at every instruction retroactively. https://youtu.be/BVslyei0804
Sourcetrail! https://www.sourcetrail.com
Look for code analyzers that spit class hierarchy, call graph, etc. [Callgrind](http://valgrind.org/docs/manual/cl-manual.html) for e.g.
[removed]
This!
I like tools that generate UML diagrams like Doxygen or plenty of others: https://stackoverflow.com/questions/405953/generating-uml-from-c-code
Note here: new (access()) wrap_lambda&lt;decltype(lambda), Return, Parameters...&gt;(std::forward&lt;Lambda&gt;(lambda)); `decltype(lambda)` is an rvalue reference here, thus the created `wrap_lambda` stores a dangling reference after the construction. I believe that's why [clang generates `ud2` when you invoke `item.transform`](https://godbolt.org/z/CwVLb3). 
You Can try cppdepend and it's code query language CQLinq to query tour large code bases.
A free and open source tool to visualize certain aspects of your code like components, compilation, call graph is called CodeCompass. You can check it out here: [https://github.com/Ericsson/CodeCompass](https://github.com/Ericsson/CodeCompass)
[removed]
We should make a page "Why is it important to not use capital letters"...
Good link and in traditional stackoverflow style, closed as off topic.
 constexpr void function() noexcept {}
I like the code browsing features by modern IDEs with good C++ parsers combined with an integrated debugger. MSVC17, CLion, to some extent KDevelop5 work pretty well.
It's too late for me... I'm already appending `noexcept(noexcept(...))` to the end of all my `constexpr` function templates
1. Documentation 2. Asking someone who knows 3. Grep These have been the most effective tools for me. Though I'm talking about a really large code base with a very high change rate.
 template&lt;class T&gt;struct tag_t{}; template&lt;class T, class C&gt; struct ptr_iterator:std::tuple&lt;T*, tag_t&lt;C&gt;&gt;{ using base=std::tuple&lt;T*, tag_t&lt;C&gt;&gt;; template&lt;class O, std::enable_if_t&lt;std::is_convertible_v&lt;O, base&gt;,bool &gt; =true&gt; ptr_iterator(O&amp;&amp; o):base(std::forward&lt;O&gt;(o)){} private: T* get() const { return std::get&lt;0&gt;( *this ); } T*&amp; get() { return std::get&lt;0&gt;( *this; ) } }; here I relegate storage to a std tuple, then use it to determine if we can convert. Because we can convert iterators iff we can convert their storage. I could make these SCARY, bit I included a container tag here (which could be void if you don't want to tag them). One worry with my approach is that a container of `Base` and a container of `Derived` could have one way iterator conversion needlessly and incorrectly. 
Probably because CppCon is in the title of the episode
Hi! GCC4 implements copy-on-write for std::basic_string and not small string optimization. Even when using newer versions of GCC, it is possible to switch to GCC4 ABI (using --with-default-libstdcxx-abi=gcc4-compatible). I guess using this switch is very common on legacy systems, so developers have to be careful. Please let me know if things are clear now :). Stack overflow for reference: https://stackoverflow.com/questions/46068529/no-small-string-optimization-with-gcc/46068722 
You can use crags and cscope to quickly jump through code such as declaration, calling function, and occurances.
Thanks for the explanation. I'm not a expert on spectre and haven't used aws lambdas at all, so I'm probably missing something, but IIRC spectre is not about cross-vm or cross process attacks, which can be mitigated on the OS-level (afaik that is more the meltdown domain), but about your program potentially leaking information through side-channels (timing) directly when processing untrusted input. Lambda functions don't seem like they would be an common or easy target for those attacks, but it is good to know that - if necessary - I can recompile my whole app (including the standard library) with spectre mitigations in place.
Don’t. Use a json parser library. RapidJSON is header only so there is pretty much no excuse to not use it. You will never be able to handle any kind of escaping nicely with regex anyway.
Needs more coroutines.
If you change `decltype(lambda)` to `Lambda` it works. I was thinking about it wrong, `decltype` preserves the value category. For some reason i was expecting it to discard value category, but that wouldn't make sense. Thanks for the refresher.
Just don't. Get a proper JSON parser. Your regex looks correct to me. Are you sure your JSON doesn't put quotes (") around your keys "name" and "id" as well?
I have a very specific opinion regarding the current Coroutine TS. I've been involved in the creation of [conduit](https://github.com/LoopPerfect/conduit/) and been using it in production. I'm quite disappointed with the Coroutine TS for a couple - quite fundamental issues: ## Allocators The Coroutine API does not provide any way to pass in a custom allocator object. By design, the compiler instantiates the promise\_type on the heap when a coroutine is called. Needless to say the optimizer is capable to optimize this away in some cases but we identified many cases where it does not. Although we believe this is possible to improve the optimizer, I think this is a flaw in the design. In fact I believe we can avoid the necessity of heap allocations in stackless coroutines entirely. ## Number of bytes to allocate are only known at runtime The size of the stack is known at compile time and the promise\_type::new method receives it's size at runtime. This means you cannot implement a block-allocator without a zero-overhead as you need to select the right bucket at runtime. ## Implementing syntactic sugar for Optional and Expected is awkward See [https://www.reddit.com/r/cpp/comments/6ly4rz/it\_had\_to\_be\_done\_abusing\_co\_await\_for\_optionals/](https://www.reddit.com/r/cpp/comments/6ly4rz/it_had_to_be_done_abusing_co_await_for_optionals/). Although it is possible to make this more efficient and avoid the heap allocations and usage of shared\_ptr's, the code just becomes more awkward. ## co_await Many languages have *await*. However all those languages, including C++, hide what it is doing. Await is in some sense a code transformation leading to inversion of the control flow: std::string url = "..."; auto html = co_await fetchUrl(url); std::cout &lt;&lt; "url: "&lt;&lt;"\n" &lt;&lt;html; What happens here under the hood is: The awaitable returned by fetchUrl receives the `coroutine_handle&lt;T&gt; h` and invokes `h.resume` some time in the future. This means that `fetchUrl`'s awaitable gains control over the execution of the code defined below the fetchUrl call. This necessitates the ownership of the coroutine state and code by fetchUrl's awaitable. This means the code is semantically equivalent to the following: fetchUrl(url, [=] (auto html) { std::cout &lt;&lt; "url: "&lt;&lt;"\n" &lt;&lt;html; }); Note: the capture explicitly denotes how to take ownership over the state. The current Coroutine-TS does not implement such code-transformation but "fakes" it by actually implementing suspend which in turn copies the stack onto the coroutine-frame (heap) and back from the heap on resume. This hides what is happening from the user and removes necessary control for best performance. I think we can learn from F# and Haskell. Both languages implement some variant of `do-notation` which is this code-transformation mentioned above. In pseudo c++ this could look like this: auto fetchAndRespond(auto url) { return async { auto! html = fetchUrl(url); auto parsed = parse(html); auto! response = sendMessage(parsed.links[0], "hi") return response; }; } which would transform to: auto fetchAndRespond(auto url) { return async{[url](auto done) { return fetchUrl(url, [=](auto html) { auto parsed = parse(html); return sendMessage(parsed.links[0], "hi", [=](auto response){ return done(response); }); }); }}; } I think `do-notation` would solve the same problems as the coroutine-ts but better. F# [computation-expressions](https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/computation-expressions) Haskell's [do-notation](https://en.wikibooks.org/wiki/Haskell/do_notation) 
How's it compared to Boost.PropertyTree?
RE are slow. What the point to use them in fast cpp for such things (there're lots of cpp JSON parsers), I don't understand...
The only slow part about a regex is building a dfa. Once you have that you can parse a string about as fast as you can read it in. The real problem is that JSON isn't regular in the regular expression sense, so regex is a bad tool if you want to get something out of JSON.
I have to read from a file and parse the values and save them. Some of these values have JSON format and some at simply separated by \\t, which i read using `fscanf(fileName, "%[^\t]\t%[^\t]", buffer1, buffer2);`. However, since the line format were getting a little bit complex (because of the JSON format for example), i decided to use `regex.h` instead. By the way, don't JSON parsers use `&lt;regex.h&gt;`?
What is a dfa?
Yes it does put the quotes around the values. But i do need the quote to detect if the value is of type string or array. I don't understand what different JSON parsers are from using plain regex. I mean, don't JSON Parsers use regular expressions?
Or use nlohmann's "JSON for Modern C++" library, which is neat and seems to be loved by pretty much everyone. Haven't tried RapidJSON though, so I don't know how they compare to each other.
Deterministic finite automaton
It’s not boost, so that should be enough for most users.
RapidJSON is faster and more conforming (https://rawgit.com/miloyip/nativejson-benchmark/master/sample/conformance.html), but for something small I would suggest whatever is easiest to set up.
Haven't tried RapidJSON either, but can really recommend nlohmann's 
your example is not uniform and does not provide roll counts nor roll information
the detailed example (you can find on in the readme) shows that you can loop over die::die_cast object to get more information about the roll: the roll # the value was from, the # of sides of the particular die,and any modifiers.
No. JSON is a context-free language. It's possible to use regexps for very limited cases, and it's error prone, so why even bother?
I don't think `Boost.PropertyTree` is a full json implementation. PropertyTree is kind of its own format I think, though "json-like". If you want to read json, better use a json parser library.
Can't stress this enough @OP. Don't. Just don't. Use nlohmann/json (or any other json library). They're header-only, simple, modern C++.
The toolchain should be as simple as the one in https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html#cross-compiling-for-qnx If that doesn't work for non-trivial builds due to library related issues, I suggest you file a bug in CMake (and perhaps a merge request).
Very few real world parsers use regular expressions! JSON cannot be recognized in general by regular expressions so it is literally impossible to do so. And thank goodness. How would you ever get useful error messages out of a regular expression? 
rapidJSON it is then!
While you shouldn't use RegEx as many have pointed out, I said quotes around the KEYS. Not your values. If your regex doesn't work, it's because the actual data you are reading is not 1-to-1 what you've posted, so I've made the assumption, that your KEYS also have quotes around them, breaking your regex to no longer match. And no, JSON parsers will just loop over the JSON sequence keeping track of the depth, and type that is currently read and building a tree out of it. Similar to lexers ([https://en.wikipedia.org/wiki/Lexical\_analysis](https://en.wikipedia.org/wiki/Lexical_analysis))
A multiple monitor setup is very helpful. The more code you can squeeze into your view, the better.
All this complexity to preserve TriviallyCopyable semantics. Wouldn't it be better to simply specialize std::is_trivially_copyable for the iterators?
At my company, we have an OpenGrok instance that is synced daily to our central repo (mostly C). I found myself using this a lot when I first joined. Recently, I’ve been dabbling with tags + cscope in Vim. It’s a powerful combination that works on a codebase pf this size, which is something I can’t say about any other IDE I’ve tried.
That's a really great visualization. It would be cool if it could integrate with JetBrains or other IDEs of that nature to use their indexing but Sourcetrail's visualization. Then perhaps it could work on many more languages. 
Yeah this sucks to deal with. cppitertools has it out here: https://github.com/ryanhaining/cppitertools/blob/master/internal/iterbase.hpp#L28
I used to support initializer_list in [cppitertools](https://github.com/ryanhaining/cppitertools) but I ended up dropping support because it's so weird. My recommendation to people actually wanting this would be to explicitly specify the type as `std::initializer_list` or just use a `vector` or `array`
How well does this work when a lot you have a lot of template generated code?
I'm not going to reply anymore to Xaxxon's comment below because the Committee for Overreaction has already down-voted it to the point that no one would see it. But, here is my response to that stuff... I obviously didn't claim to have invented the technique. If you would holster your outrage a bit and read what I said, it was that he was complaining that I didn't use a term that would have been not much known when I decided on these very fundamental naming concepts of my code base back in the early mid-90s. I don't know if Stroustroup actually used the term RAII around 1990, but I was writing these things years before the public internet, a LONG time before all this type of information was widely available and findable on the internet, and long before the modern practice these days of making everything a pattern and given it an overly elaborate name. So it would have been quite easy for me to have not been aware of it. And RAII is a bad name anway, because it doesn't both doesn't really capture the meaning of the concept and it's sort useless as a naming convention in code pretty much, whereas Janitor is a fairly meaningful term and unambiguous. It's not really about resource acquisition. In lots to most of the cases above the resource is already obtained and initialized or already long since existed, and the "thing that does resource acquisition and initialization but really doesn't" isn't really doing either of those things. Where any resource is involved it is really more about resource scope management and cleanup in most cases, though in some cases of course it could actually get the resource as well. In the above list, the one about getting an object from a pool and giving it back is of that sort. In some cases it has nothing at all to do with resource acquisition or initialization or even cleanup, it's about controlling a settable attribute of something on a scoped basis. So in those cases RAII is completely irrelevant as a descriptive name. &amp;#x200B; And it is also nothing like auto\_ptr really. There is no need for reference counting or synchronization of the management of the thing targeted, because both are either locally scoped objects, or the "thing that does resource acquisition and initialization but really doesn't" doesn't own it to start with, it is just modifying something about the (extra-scoped) object on a scoped basis. &amp;#x200B; Anyhoo, that's all I have to say about that. 
Real world parsers will frequently use regular expressions for subexpressions actually. Won't always pull in a library to do so though, as handwriting a regular expression parser is pretty easy for small expressions.
Making the type trait lie wouldn't actually make them trivially copyable.
Grep
How is it a lie when you know it's actually trivially copyable? It's just an iterator.
You sir are the best! Thank you for giving an insight!
Specializing the type trait does not magically inform the compiler that the type should be trivially copyable. ;-]
I work in a couple large code bases (hundred+ often-unrelated projects all in a giant source tree) which have a mixture of C, C++, C#. It may sound a bit primitive, but I've had great luck just putting the source on a SSD and using the Kate editor's "Find In Files" feature. Want to know what's in class Foo? Search for "class Foo", etc.
TIL. Seems weird that such a type trait exists for what sounds like a compiler intrinsic.
Not really a comprehensive list, just some random musings stemming from recent experience of setting up a team. - Use trunk based development (https://trunkbaseddevelopment.com) with code review before topic branch merge. Try to involve the whole team in reviews (with at least one approver. others should still look through the change to get informed about it.) This is the most unobtrusive way of maintaining at least some quality and keeping the team in sync. - Set up continuous integration ASAP and make it a requirement for tests to pass when merging a topic branch. - See if you could benefit from a monorepository to cut down on effort of maintaining many packages and libraries. - Use vcpkg or Conan.io to bring external dependencies into your project. - Since it is a small team, try to avoid scrum and other “fashionable” management methodologies — you’ll waste more time setting it up and having all those countless retro / demo / grooming meetings and focus on the real work.
&gt; I just realized that you will be maintaining an existing codebase. That changes things. Could you maybe then describe it in a bit more detail? The code base is around 500k lines of code. It has a lot of external (compiled) dependencies. The code is in a decent shape, i.e. I was able to grasp most of the architecture in a couple of days but the stuff around it is a nightmare. The code is versioned with git but there are no well defined workflows, the build system is based on cmake but with a very old style (not the target based modern style) and some external scripts to do... I am not even sure what. The release process is literally a dude moving on another pc, running the build system and then copying the whole output on a usb stick. 
Very well I guess
Oh, then it is not so terrible! Seen shit that’s way worse. So I’d say that my points still hold for your case. I’d maybe also add to try and run some static analysis tools on your code. Clang-tidy, cppcheck, just the basic direction to look at. I’d expect code to be based on some older pre-C++11 standard, and the static analyzer will probably help you start sanitizing the codebase. Integrate it into the CI routine. You will definitely need to set up CI. You can look into spinning up a server with TeamCity in your office. You can start to host the buildagent on the same server until you feel it is slowing down the whole setup. IMO TeamCity is a much nicer tool than Jenkins, but Jenkins is open-source. 
What CI systems have support for 18.04? 
Ubuntu 18.04? TeamCity should, Jenkins should. Other I can’t recommend. As for building, all of them are platform-agnostic. They just run whatever script you pass to them as if you did it by hand. If you need to build for several platforms, you can spin up several build agents.
Anything wrong with using inheritance? An iterator has all the API of a const iterator so it seems reasonable.
The make-up of the team varies, but also it's not material. The processes are much more important. In decreasing (approximately) order of important you should have these things in place: 1. Automated tests (ideally both unit and system tests). 1. Code review for changes 1. A bug-tracking system 1. Documentation (some bits of documentation are more important than this position in the list would imply, others less) 1. Static (e.g. to run before check-in) and dynamic (e.g. to run as part of your tests) analysis tools 1. A system for prioritising feature requests and other work (often you can use the bug tracker for this too) 
Most of them support Docker, so you can use any image?
I think this article is silly. If you assumed std::string did not contain intermittent null terminators then you where wrong and should not make that assumption in the future since it explicitly DOES allow null characters. You should use a different datatype if you don't want this. 
To figure this out, first write a program that does nothing except print "hello" 57 times. Then change it to print the same thing 11302 times. Then apply this lesson to the program you already have.
Just curious, what are "green trunk" &amp; lockstep upgrades? Never heard those terms.
Type traits are how the standard library exposes compiler intrinsics.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Not really advocating for Scrum, but I just wanted to say that Scrum is very much designed for smaller teams and doesn't scale well for big teams.
Though I guess it depends on how small the team is.
Green trunk means that your trunk should be in a workable state, i.e. everything compiles and tests pass on all levels. You don't merge anything that breaks that invariant, and if it gets broken nonetheless (e.g. when it is impractical to run all tests on every change), fixing it is top priority.
Not really the case, see above. It's a much broader concept.
Lip-service is the key thing to watch out for: I have seen people say they are XP or agile and blah blah about sprints, scrums, standups, etc, and then go waterfall so hard you would think it was 1995. Or they talk about being flat but only one person deals with upper management/investors. I also see people adopt tools and then allow the tool to dictate their workflow. I have seen people adopt tools because it is what (some hoodie wearing guru uses) they found on a tech website. Relative flatness is key: One of the huge changes in the last 20 year is the that modern strong teams have turfed the concept of seniority based on (something that makes the weak keep making up the rules) something someone pulled out of their ass. This has largely eliminated the concept of senior programmer, intermediate programmer, team lead, project manager, product manager, etc. Often in smaller teams everyone is kind of overlapping with different people bringing in something a bit different. Some are DB strong, others can make the OS dance. Others do have more of a checklist mentality that gets everyone through the final push to a product that is whole. But to arbitrarily make someone on the team a "lead" and all information filters up and down through them is management from 1980. The key is that the fewer people you empower on your team to make decisions the more that a single person will make decisions and that isn't really a team but a work gang with a master just yelling at them. You won't get good quality work, you won't keep your team, and you will have trouble attracting talent. The only people you will keep are those who make things suck and those so talent-less that they take it. What this boils down to is that every single tool, process, report, rule, procedure must have demonstrated value. So few companies adopt the idea that if they could do without something just fine that they should get rid of it. A perfect example would be a company that lives and dies by code formatting rules. But then the same company doesn't unit test. Even if you agree with strict code formatting rules that if you had to pick just one of the two you should absolutely pick unit testing as a priority to live and die by. The same with code reviews. I have seen so many code review procedures that aren't there to prevent problems and help make for a more solid product but to make sure the rules were followed and that is it. Follow the rules but make a crap bit of architecture and code and you are fine. Make the best code ever written but not in accordance with the rules and you will fail your code review. The last is very very important. A programmer can only keep so much in their brains at once. Do you want them following rules that if broken won't do anything but annoy someone with OCD or do you want them thinking about best practices along the lines of patterns, memory management, defensive programming etc. There is a limit to what a programmer can keep in their mind at one time and to impose one low (or no) value consideration in their heads is to displace another. Also, I have seen where someone will say how something should be done differently (and way better) but they did it the way they did to appease those who make the rules. 
I never made such a claim, see my post above.
It is a return value, not something you store in bulk.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
When you have a type mismatch, it doesn’t throw an exception at runtime, it errors out at compile time. The strlen implementation is being used for all types, and when it doesn’t work, the compile fails. Instead of using exceptions, you should use SFINAE to get the correct overload for a type. I’m on mobile right now but you should have one function body with strlen, and another with the bytes implementation, and the compiler will delete the first overload when strlen cannot be called on the type.
I thought I would never say this, but if you’re using gitlab, try their ci solution. It has its quirks, but once you get things running it’s very good.
Any good CI system is usually system-agnostic (unless it's extremely specialized one).
Found the Googler ;)
https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/
I'm cringing at this advice. Using floating point values for durations by default will add tricky edge cases to code that would otherwise produce accurate results. And the benefit - the ability to store _"something close to 61 seconds"_ in a variable that's promising to hold "minutes"? That strikes me as a design mistake. Am I wrong?
I sort of agree. I think the position to use `float` as a default is a lot more arguable than it might seem, though. Time is inherently continuous. You can never have "one minute" - it's simply not something that exists, other than conceptually. So it's always going to be "something close to one minute". It doesn't feel particularly disingenuous to me to have this as the default for a time-management library. Eh. It's a hard problem. What I typically do is just find the smallest denomination of time that I think will be useful for the current application (e.g. milliseconds) then `duration_cast` everything else to that. It works... okay.
I’m no ieee floating point expert but I feel like the ‘fixed’ example would turn into an infinite loop if I used a sufficiently large duration like fyears and added a sufficiently small duration to it like 1 fnanosecond. The beauty of std::chrono and it’s built in types is that they require duration_cast as soon as you’re entering ‘this might not work the way you think’ land. Don’t store in a large step size and then increment by smaller steps. Store milliseconds. Or seconds. Or whatever minimum step size you need.
Silver searcher or ripgrep
I agree, see my other post. The core issue is a matter of misunderstanding how to use std::chrono. If a function accepts std::chrono::hours, it is implicitly stating ‘I understand 0, 1, 2, ... whole hours’, if you as a user have 2 minutes, you need to decide if that means you can call with 0 hours, 1 hour, or wait until you’re at 60 minutes. Either way, you’re about to call duration_cast so you sure as hell better read the API docs of the function you’re about to call...
&gt;You can never have "one minute" - it's simply not something that exists, other than conceptually. These computer things are devices for storing concepts. This seems apropos. &gt;What I typically do is just find the smallest denomination of time that I think will be useful for the current application (e.g. milliseconds) then duration_cast everything else to that. I do something similar to this as well. Most active applications I am working default everything to microseconds. For reference I am working in gaming.
This is all wrong IMO. The library wasn't designed for storing durations as helper types. I've used the helper types *extensively* in real-world code, but always on the right-hand side of an assignment. They auto-convert beautifully when assigned to a duration; hinted at by the superfluous flurry of aliases recommended here.
It's almost as if the people who designed the standard library made it hard to misuse, and the word "cast" is a warning that people who use it need to know what it means.
where did you teach at?
So I like a lot of what you said, and I struggle with a lot of the being the 'lead' while having to answer to managers but wanting to give my team (too big of a team) some trust and autonomy. One thing you didn't mention that I would be curious to hear your opinion, if you have one, is distributed teams. I myself moved to being a remote worker, having moved 200 miles away from where I was in office. I have 4 teams members one time zone to the east of me and 11 team members in India. With 4 team members in my main office who I 'lead'. The 3 teams all essentially work ok the same thing, just different projects. I could lost many struggles and difficulties but I am curious what you have to say knowing what I just wrote. 
&gt; That being said, I suppose there's room for better documentation and real-world examples. When _isn't_ there room for that?
Floats have such problems, but the difference in orders of magnitude would have to be far greater than years and nanoseconds for that to happen. For a 32-bit float number of years, you should be able to add something like 10^-38 years and have it work (something like 10^-16 nanoseconds?). I agree with the point in general, though. If you need a precision of nanoseconds, then you should declare your type in terms of nanoseconds, not years.
&gt; And we don’t want to implement it with a conversion operator, because that disables implicit move. If move vs. copy matters, then by definition the iterator is non-trivial. So why do you then care about the copy not being trivial? Conversely, if it's trivial, then why do you care about move vs. copy? They are the same.
Shouldn't do that. You should try [https://github.com/danielaparker/jsoncons](https://github.com/danielaparker/jsoncons) or [https://stedolan.github.io/jq/](https://stedolan.github.io/jq/). Jsoncons provide jsonpath extensions, which was supported in some popular database, take a look here for detail: [https://github.com/danielaparker/jsoncons/blob/master/doc/ref/jsonpath/jsonpath.md](https://github.com/danielaparker/jsoncons/blob/master/doc/ref/jsonpath/jsonpath.md). 
&gt; Most active applications I am working default everything to microseconds. This makes sense 100%. The only concern that I would have immediately about this is integer overflow. Needs more management, but otherwise, definitely the way to go. &gt; These computer things are devices for storing concepts. This seems apropos. Yeah, I mean, that makes sense. What I was trying to say was more, if you generalize time as being stored *usually* for practical reasons, then *usually* you don't actually want to be storing the concept. You want to be storing something that is as close as possible to the "real thing". Of course, this totally depends on what you're doing. And maybe it's unfair to generalize, here. I guess the question is more, should we assume people are measuring/performing operations on time for practical reasons? Or should we assume that the use of this library is more conceptual/theoretical? The more I think about it, both assumptions seem kind of... poor. Defaulting time storage to integer types is really really bad for a lot of applications. But defaulting it to float is also really really bad for a lot of applications. It's an issue, perhaps, but I don't think we can really blame the library. Instead, I'm going to blame time. What a total jerk. Always making me late for appointments, never there when I need it. 
I just typed something about how floats should have enough range, then deleted it when I remembered how floats work. You're absolutely right. If you want nanosecond precision, then even for a 64-bit double (52 bits), the max value you could store is less than a year.
`numeric_limits&lt;float&gt;::epsilon` is only `1.19209e-07` on typical platforms; the corresponding number for `double` is `2.22045e-16`. Adding a second to a `fyears{1}` will get you a `fyears{1}` back, since 1.19209e-07 years is about 3.75 seconds.
If floats aren't precise enough for your use case, use doubles ;)
How a development team should look or What a development team should look like not How a development team should look like I'm not trying to be an ass pointing out a title typo, but you made this mistake in the body as well making me think you might not know. 
I haven't encountered any edge-cases so far, do you have any examples of what you are thinking about? Of course floating point values may be problematic when you need high precision, which is why I recommend doubles. 60.5 seconds is a completely valid time duration, as is 0.5 seconds, or 0.2 days, or 0.75 hours, etc.
What you really want if your time is coming from discreet sources is to define an int-based alias for it. I am suggesting treating time the same as you would DSP data. You receive discreet values in input, immediately convert them to floating-point, do your computations on that (which is much more natural as a plus), then convert back to discreet when outputting. I don't see how time differs. And lets be real here, the fact you can't add seconds to minutes by default makes it unusable for many application.
&gt; How often do you have to add seconds to minutes? Of course you can add seconds to minutes just fine with stock `chrono` types. You just get the result in seconds. As it should.
What if an api function requires minutes?
microseconds in gaming? Only really for benchmarking purposes...
But if you think of it naturally, as we understand the concept of time, your function accepting hours should work just fine with 0.5 hours. If you use floating-point values for time, it does, it will work as expected. If you really need discreet hours only, then you can use std::chrono::hours. I've personally never had a use case for that since the library release. Can you give me an example where it is absolutely crucial a function accepts discreet hours?
I’m on mobile, I used the first online floating point calculator I could find: http://weitz.de/ieee/ Scroll down and select 64 bit. Try the 1 year = 30758400 seconds (fyears is defined in terms of seconds. See the ratio bit) Add .000001. = 30758400.000001. Great, you’re right. Let’s try nanoseconds 30758400 + 0.000000001 = 30758400 Oops. This is indeed contrived. But so was your example. You used hours. The compiler gave you an error and then you through in casts (it was in the name... _cast) and then complained it resulted in an infinite loop. You didn’t even show the correct code of using seconds and initializing it hours{1}.
I find SlickEdit's indexing and navigation is very fast and efficient with large code bases.
Fair point. I'd argue adding nanoseconds to years is not a common use-case, but by using floating-point durations you open that door. For me personally, I find the usability gain to be worth it. One could not provide nanoseconds though, which would fix that.
The usability case is equally broken. Good luck using your custom duration types with any other price of software. You’d have duration_cast everywhere (remember, that is a red flag). Good luck passing code review
Even a double doesn't have adequate range for all the time scales people will use, but the bigger problem is that it discards precision silently when arithmetic fiddles with its range: std::cout &lt;&lt; "Nanoseconds: " &lt;&lt; dnanoseconds(12345).count() &lt;&lt; '\n'; std::cout &lt;&lt; "Nanoseconds: " &lt;&lt; (dnanoseconds(12345) + dyears(1) - dyears(1)).count() &lt;&lt; '\n'; Prints: Nanoseconds: 12345 Nanoseconds: 12344 I could accept a type that has limited range (you can never encompass both real-world dates and nanoseconds with only 64 bits), but I have a problem with a type where adding a number and subtracting the same number produces a different number than I started with, which is why in some domains people avoid floats like the plague.
Scheduling work across multiple threads. Duration of work feeds into an algorithm we have.
I agree that integer overflow concerns are real. Most of our timings last only 1 frame, which ought to be about 16.6ms. a 32 microsecond gives us about 72 minutes to play with so we do alright. Of course longer running workloads need to consider their types carefully if they are constrained to 32 bits. 64 bit microseconds gives us about 580, 000 years. This is suitable for most tasks. &gt; should we assume people are measuring/performing operations on time for practical reasons? Or should we assume that the use of this library is more conceptual/theoretical? I don't see that these have to be at odds. C++'s type system is phenomenal at allowing us to create high level abstractions around implementation details of any abstraction level. I can make a class that very concretely does something specific to bits or very abstractly serializes a group of objects and sends them to a database without caring about the transport, database implementation or serialization format. This does come at the cost of some cognitive load and effort spent creating and learning the class APIs. &gt; Instead, I'm going to blame time. What a total jerk. Always making me late for appointments, never there when I need it. Have you seen that video where the programmer accidentally signs on to making a time library and learns how hard it is. It is more about time zones, but the notion that simple things are complex when we pick out each detail in the extremely reductionist way that computers demand: https://www.youtube.com/watch?v=-5wpm-gesOY
I've used it many times before to great success. It has passed code review many times as well ;) You only need duration\_cast when entering/exiting your domain. I'd argue using the helper types requires \*much\* more duration\_casts.
Yep you are right. I've removed the nanoseconds and microseconds aliases from the post. I've never had to deal with that sort of precision, I cannot really recommend anything for industries that use those. However, for the rest of us (I'll argue the majority), my argument still stands :)
If that function is external to your code base it will almost certainly expect an std minute type that is integral and you are hosed if you used floats. If you didn't use floats you use a duration_cast and understand smaller units are truncated. If it is internal to your code base it you just use duration_cast and know that the units smaller than minutes are truncated (or not if you made them floats).
Your blog admits you don’t use the standard chrono types. Your contrived example demonstrates you don’t know how to use them properly. But you’d still argue your approach is better? I guess I’ll just have to say, I disagree 😅
11 in india. Fail
You are not hosed if you use float, you just duration\_cast to std::minutes. It works as expected.
&gt; 64 bit microseconds gives us about 580, 000 years. This is suitable for most tasks. ...huh. Okay, I should have expected that. That honestly kills my concerns about integer overflow. Somehow I thought you'd be constrained to a much shorter timeframe. &gt;I don't see that these have to be at odds. I think the point of the original blog post is that these are (kind of) at odds, specifically in this situation. Adding a second to an hour makes sense, in practical use cases, so you'd expect to be able to do that. When you can't, it is a bit weird. Even though the current defaults work better for theoretical/conceptual applications. &gt;Have you seen that video where the programmer accidentally signs on to making a time library and learns how hard it is. Why do I have the weeeeird feeling it's going to be that Tom Scott video... nah, that's about time zones. &gt;It is more about time zones Ah-hah! Although I don't particularly enjoy *watching* that video, it's still an excellent way to sort of communicate the less pleasant tasks programmers face. A lot of problems sound easy, but turn out to be way overly complex (or even impossible) when you start digging deeper.
The example demonstrates exactly the problem I've faced when creating simulation/ai/frame update apis that use the chrono types. Sure, you could change minutes to seconds, but if that is what you are suggesting then you've missed the point. Assume you are receiving minutes, you must do computations in seconds, and either return minutes or call another api with minutes. You are screwed.
&gt; Okay, I should have expected that. That honestly kills my concerns about integer overflow. Somehow I thought you'd be constrained to a much shorter timeframe. I know right! To truly grok the size of 64 bits I did an excercise where I tried to figure out the precision tradeoff off using different units to track solar system coordinates. Dropping this "(2^63) mm in au" into google tells us a signed 64 bit integer gives us a size of 61,654.4339 Astronomical Units. Presuming a 192 bit vector 3 with a 64 bit X, Y, and Z component we can track an object in solar system with millimeter precision for 60 thousand AU in any direction. Considering the solar system is 40~80 au in size depending on measurements this is plenty to not need floating point precision for most space sims. Put another way, this gives you .97 Light years from the sun with millimeter precision. &gt;A lot of problems sound easy, but turn out to be way overly complex (or even impossible) when you start digging deeper. Totally. This is the crux of this problem. C++ expects the programmer to know to use the most precise type their task requires and to specifically acknowledge potentially unsafe actions with casts. If one uses a cast without knowing what they are doing then one might be compelled to write this blog post.
Neat, I am a bit surprised, but neat.
That doesn't explain why you couldn't do this: `std::vector&lt;die::die_cast&gt; result = { 10_D(6), 1_D(20), 3_D(4), 1_D(8) };` Now you can still get all the info you want, but you don't have to create a whole vector if you just need one die roll.
&gt; Unsure what you mean about materializing the sequence. You're creating the whole vector up-front (eagerly). You could instead generate elements of the list only as you need them (lazily). Currently, `die::cast(1'000'000, 6)` would allocate an at least million-element vector, but if you're only using it to iterate over the results, you only need to generate one result at a time.
&gt; as we understand the concept of time, your function accepting hours should work just fine with 0.5 hours It appears you're conflating the concept of "arbitrary time" with a function declared to understand only the concept of "hours". `std::chrono::hours` is designed to be a strong type capable of representing exactly what it says: discrete hours. If you want to represent *time*, in general, this is best represented as a `std::chrono::duration` (typically expressed in terms of a specific type of clock), which implies that the duration can be of any time division. And this is precisely the case in `std::chrono` provided you use the correct cast. For the use case you're describing, you can change that function declaration to take `std::chrono::milliseconds` or a division corresponding to whatever resolution you require, and passing a value declared as `std::chrono::hours` will be easily and happily converted to milliseconds, and if it's a literal, it will be done at compile-time (literal conversions are `constexpr`).
I think the best part about all this is that floating point precision can still hugely screw with software applications. Even though you technically have insane precision, ugly data can still give you broken/incorrect results. &gt;If one uses a cast without knowing what they are doing then one might be compelled to write this blog post. Eh... I feel this is a bit harsh. Although I think the problem is a lot larger (and consequently worth less effort) than the post makes it out to be, the fundamental problems mentioned with how unintuitive the library can be are... definitely present. Time is something that's so important for so many applications, it feels bad to say "well, if you want to manage time, you just have to be really really good with our library". But, hey, as you say. What's the solution? Beats me. Time is awful.
&gt; Defaulting time storage to integer types is really really bad for a lot of applications. Is it? Do you have any examples? I work with time-sensitive embedded and real-time systems and I've never had a problem.
&gt; Adding a second to an hour makes sense, in practical use cases, so you'd expect to be able to do that. When you can't, it is a bit weird. I disagree that you should expect to be able to do that in C++. An hour is obviously less precise of a quantity than a minute. The following is fairly basic C++ and is not unexpected behavior: ```` int hours = 5; double oneMinute = 1 / 60.0; hours += oneMinute; std::cout &lt;&lt; "Hours: " &lt;&lt; hours &lt;&lt; std::endl; // Hours: 5 ```` The inability to add an increment of a higher-precision type to a lower-precision type is the exact same behavior we are already familiar with in basic C++.
Sure, I mean, isn't that the issue posited in the original post? You can't add any time denomination to a time storage that's of a greater time denomination. There's no adding seconds to minutes, minutes to hours, etc. Of course, there's workarounds (I've mentioned one or two) but it's still unintuitive and I'd have to imagine it could lead to unexpected behaviour and possibly bugs.
But then you are conflating fractional minutes with integral minutes. That will lead to pain and confusion for users of the API. `std::chrono` is explicit and clear.
The entire issue is resolved by using a higher-resolution `std::chrono` type or even simpler by directly using `std::chrono::duration` using a clock with well-defined resolution (eliminating unexpected behavior *and* bugs). While I agree it's not intuitive and it may be inconvenient, it's certainly not "really really bad" (IMHO).
As I've mentioned elsewhere you can pass around all the values you want specifically as `std::chrono::duration` with a clock of your choice and pretty much all of your issues will go away, and in fact, the use cases you just mentioned are made easier by the fact that any `std::chrono` helper type is automatically converted to a duration and will be constexpr where possible on top of that!
&gt; it's certainly not "really really bad" I agree, I think that was poorly worded. It's bad because it can introduce the "other UB" - unexpected behaviour. Which can be pretty bad, but it's not, like, doomsday stuff.
Any reason not to have a free function similar to `AsyncMessage(target, method, args...)` that just does target-&gt;AsyncMessage(method, target, args...);` ? or does that fail something that you're trying to solve?
My main problem with this API is that synchronous version of all of the functions are exposed directly on the class, and have to be public so that callers can get function pointers to them. What's to stop somebody from just calling the method directly, and bypassing the actor framework completely? Especially when calling the method directly is much shorter. I would probably make all of the public methods of the class async, and handle all of the async-ness inside the class. So something like this: class Actor { private: std::deque&lt;std::function&lt;void ()&gt; &gt; fMessageQueue; void BehaviorImpl(Arg1 arg1, Arg2 arg2) {...} public: void Behavior(Arg1 arg1, Arg2 arg2) { fMessageQueue.emplace_back([=]() -&gt; void { this-&gt;BehaviorImpl(arg1, arg2); }); } }; Then the caller's syntax is just "target-&gt;Behavior(args);".
This technique would require clients to double up on functions. Not ideal. 
Valid point (regarding direct access). I think it’s impossible to prevent this in C++, unless I somehow enforce a “behaviour” like keyword (see Pony programming language) and have a “validity checking tool” which runs before compilation. Regarding your second point, it is an option but slightly harder to read than **target-&gt;AsyncMessage(method, args)**
If you have to do only thing, do code review. No-one can commit to git until it has received at least one "ship it" from another developer. Make sure that people are expected to provide feedback about making code cleaner, not just fixing stuff that "doesn't work". Review Board is a FOSS code review tool that works pretty well.
you can prevent direct access in C++ (anything that the compiler would allow anyway)... they are talking about making the directly callable public version do the async stuff... so it is the only one they have in interface for...
I guess it depends on the nature of your system. Like, if you design it so that methods for sending messages are generally free functions, then it might make more sense when reading it. Ex: SendMessage(message, destination, ...). It might free you up to also have different forms of "destination" - ex: you don't need to have a reference to the actual destination - it could be a key or something that is used to find the destination (or even queue it in the system allowing for the recipient to attach and detach over the course of operations).
Strict formatting rules have one advantage: You can easily use automatic formatting tools and not worry about lots of whitespace changes in code review, just because someone hit the formatting shortcut and the whole file got reformatted. 
I get the idea, but that's not unexpected behaviour only because you're explicitly saying that `hours` is an integer type. So it's fully expected that you can't add a double and expect things to work. However, the issue here is that time (hours, minutes, etc) is (both conceptually and in practice) continuous. So, a mental model of hours, minutes, etc might assume that time units would be treated as floating point - continuous, rather than discrete. This issue only really occurs because `std::chrono` helper classes mask the underlying type, which - as the original blog post says - is unintuitive for (some) people. Honestly, this entire thing makes me think that perhaps underlying types for things where it's not 100% obvious should maybe be specified. `std::chrono::minutes&lt;int&gt;`... but it's so ugly. And kind of defeats the point of the classes in the first place? Meh. 
&gt; If you use floating-point values for time, it does, it will work as expected. How is that better than 1/2 hours though? One can be represented exactly, and at compile-time no less, while the other cannot, but you propose the latter is better..?
What do you mean by large? Are we talking multiple different processes and services communicating via IPC or one monolithic App?
You should not need to use duration cast most of the time. 
Oh, it works properly in the other direction? That is, `my_microseconds += std::chrono::minutes{3};`? If that's the case, even better. Although, I'd be wary about potentially combining multiple additions into a single expression.
There are other formatting "rules" camelCase, comment_rules, and so on. Not caught by an automatic formatting tool. The simple rule is that if you can't read code that isn't in the format that your religion dictates, you suck at programming and must be lost looking at code examples on the net. Or maybe the rules are just people with OCD making everyone around them miserable. 
Then cast the duration to minutes (with the according less of precision) at the point where you use that api. Same goes for printing: Just because wou want to print minutes doesn't mean you should do hie commission in minutes. 
Yes, that does work flawlessly and is one of the reasons, why I think the post is - pardon my language - garbage.
&gt; There are other formatting "rules" camelCase, comment_rules, and so on. Not caught by an automatic formatting tool. Imho that's not about formatting, but about naming (although I'm not 100% sure what you mean with comment_rules), so I don't see how that contradicts what I said. Also, I said it is one advantage - not that it is so important that it tops all other considerations. I agree that there is often an overemphasis on formatting and naming and such. That's why I let tools do their job, automate what can be automated and essentially completely eliminate that topic from peer review discussions. 
And what have you gained by the whole process compared to just using an integral type with enough precision to behin with. 
&gt; You are screwed. Not at all. If you need more precision than what you got, then just use a type with more precision. And simply round or truncate the result (aka duration cast) .
A std::chrono::duration doesn't have a clock. Are you talking about std::chrono::time_point?
Are you mixing up durations and time points? Or why are you talking about clocks?
Sorry, but I think you have completely missed how this library is supposed to be used (which may indicate a flaw in teaching material or API desig) and instead try to coerce the library into your mental model of how such a library "should work" (maybe you conce from another language that does things differently). In your initial example you try to do arithmetic with a precision of seconds, so why on earth are you trying to use minutes as the type for accumulation? What your example should actually read is this (using namespace std::chrono and std::litterals for brevity as I am on my mobile): seconds time{ 0 }; while (time &lt; 1m) { time += 1s; } printf("minutes : %dm\n", time/1m); A strong indication that you are doing something wrong in this library is when you start writing `count` and `duration_cast` everywhere - that should only be necessary, when interfacing with legacy APIs or for printing (I think c++20 finally resolves the latter issue) 
If you are writing a function that actually understands half an hour, don't use hours as the type in the interface (e.g. minutes). Simple and that.
&gt;There are other formatting "rules" camelCase, comment_rules, and so on. Not caught by an automatic formatting tool. You are mixing naming convention and formating rules.
Maybe I misunderstood something but your janitor sounds like [https://www.boost.org/doc/libs/1\_68\_0/libs/scope\_exit/doc/html/index.html](https://www.boost.org/doc/libs/1_68_0/libs/scope_exit/doc/html/index.html)
Imho it is - in many cases - better to just write two separate classes (also helps readability in the debugger and error messages. It is like the old regex joke: You have a problem and you try to solve it via TMP. Now you have two problems. 
A common problem is that your combat iterator stores e.g. something like a `const T*` internally. How do you now allow the non--const iterator to modify the T?
&gt; If you use floating-point values for time, it does, it will work as expected. Until you run into precision issues with too big numbers.
&gt;Actually, this code base (and my use of this concept and publicly calling them janitors) goes back to the mid-90s, so I imagine I probably have dibs on it relative to the term you might use, if we want to get all legalistic about it. So you didn't write this, then? &gt;Actually, this code base (and my use of this concept and publicly calling them janitors) goes back to the mid-90s, so I imagine I probably have dibs on it relative to the term you might use, if we want to get all legalistic about it. 
Thanks very much, nicely detailed report. Trying to ship a browser instead of a simple 2D looks ridiculous to me, so instead of something like BGI, lets pack Electron into the standard library.
One extra point about the to_chars interface: there’s a “plain” floating-point overload that doesn’t take chars_format, which switches between fixed and scientific according to an overall-shortest-length criterion with visually pleasing results. (chars_format::general uses the printf criterion which is less visually pleasing as the output length varies.) There’s also a precision overload that behaves like printf; rounding to a given precision can lose data (if the precision is too low) or waste characters (if the precision is too high) but if you want to format something with 3 digits after the decimal point for a human-readable table or whatever, then precision may be what you want. Otherwise, use shortest round-trip. &gt; Visual Studio 2017 15.9 - full support (from_chars and also to_chars) (see notes about changes in 15.8 and in 15.9) to_chars() is not quite complete. In 15.9 I was able to ship shortest round-trip decimal (scientific, fixed, and general notation), powered by Ulf Adams’ novel Ryu algorithm which is faster than all previously known correct algorithms. In VS 2019 16.0, I improved the speed of fixed notation by about 60% thanks to a suggestion from Ulf (the implementation is now a hybrid of Ryu and elementary school long division). For 16.0 I also recently implemented hexfloat shortest and hexfloat precision, with correct rounding (our CRT’s rounding has a known bug). Hexfloat precision rounding uses a clever technique that I devised after a suggestion from Billy O’Neal, although I haven’t profiled it (everything hexfloat is going to be very fast already). The remaining work is decimal precision (scientific, fixed, general), like what printf can do (except charconv is non-null-terminated and hopefully faster). I am working on this now but can’t promise an ETA yet. I will also have the ability (thanks to a suggestion from my boss, VCLibs dev lead Daniel Griffing) to retroactively “bolt on” a complete charconv implementation to VS 2017 15.9 via a helper header (as no new features can be added to 2017 itself now). We haven’t committed to actually spending a bit of time on that (which couldn’t be spent on C++20 features) but our options are open if there is sufficient demand from customers who don’t want to upgrade to 2019 immediately despite the continued binary compatibility.
If you're on Windows, try out [https://www.superluminal.eu/](https://superluminal.eu/). It's a profiler, but one of its features is that it will give you a timeline showing you what the program is doing at any point in time. Great for understanding which functions are being called when, why, how often, etc. You can make a recording of arbitrary length in time, so it can function as a sort of historical debugging/execution visualizer.
This article seems to have two main opinions, both of which I agree with: - Nullability should be opt-in, and if you opt-in to nullability, the compiler should force you to deal with the possibility that your type might be null. - It's silly that pointers and references are both pointers under the hood, but one uses the arrow operator and one uses the dot operator. Both of these are only marginally related to smart pointers, in that smart pointers are nullable and traditionally use the arrow operator. But if you fix these, you still have the rest of the language to deal with. A better title might have been "C++'s archaic pointer semantics make for bad APIs".
I believe messenger and phone are the best tools :) Just contact someone who wrote or fixed this code and ask him to explain you main components and how do they interact with each other. Looking at each component details then will be a trivial thing.
I get that undefined behavior can help the compiler optimize better in many situations. But there might be certain 'undefined behaviors' that don't contribute a lot to performance. Maybe this should somehow be surveyed and then the standard could define a little more.
&gt; Trick question, it doesn’t compile. The reason is because std::chrono’s helper types are shit. No, the reason it doesn't compile is because it would destroy precision and result in bugs if it compiled silently. You can argue all you want that the default types should be floats and allow downscales silently but saying that the integer based chrono types should do it too is madness.
**Company:** [JLG Consulting](http://jlg.ro/) **Type:** Full time **Description:** We are a software development and IT consultancy company specialized in the development of cutting-edge software for Air Traffic Control such as safety critical real-time applications for the aviation business worldwide. Working with us would mean being part of an international and dynamic team, full of diverse characters, guided by a modern and open leadership. You’ll participate in all phases of development (specification, design, development and maintenance) and have the chance to bring your ideas to life by coming up with the best technical solutions. Our company’s culture rewards innovation, creativity and personal working style, making it so that our employees benefit from autonomy while also building significant relationships. We provide the space for skill mastery and find meaning in our goal to make exceptional products. We offer: ✓ Motivational salary ✓ Private medical assurance ✓ Flexible schedule ✓ Gym subscription ✓ Pleasant work atmosphere ✓ Location near the metro ✓ Coffee at work ✓ Casual dress code **Location:** Bucharest, Romania (Languages: Romanian, English) **Remote:** No **Visa Sponsorship:** No **Technologies:** C++ (mainly using STL, templates, design patterns, Model-view-controller, OOP), development environment hosted on GNU/Linux. **Contact:** Apply by sending an email to [elvira.ionita@jlg.ro](mailto:elvira.ionita@jlg.ro)
Sounds like [SG12](https://isocpp.org/std/the-committee): &gt; SG12, UB &amp; Vulnerabilities: Gabriel Dos Reis (Microsoft). A systematic review to catalog cases of vulnerabilities and undefined/unspecified behavior in the standard, and recommend a coherent set of changes to define and/or specify the behavior.
Just wanted to point out that GCC's optimization levels go up to -O3. -O9 is currently the same as -O3.
&gt; `std::from_chars(str.data(),str.data() + str.size()...` So everyone is ok with the absence of string_view overload and happy to type that abomination every single time?
Provide your own.
The example in the article perhaps a little unfortunate const std::string str { "12345678901234" }; int value = 0; std::from_chars(str.data(),str.data() + str.size(), value); Because (well, at least for me) even in a (Linux) 64 bit build, g++ and clang++ use a 32 bit int, and the example string `"12345678901234"` needs 44+1 bits to store. So the example fails. `value` should be a `long int`. I dunno about MSVC.
You are correct regarding access protection - however responsibility is left for client to implement in 3rd party code, while library/well written code can mandate this pattern. If we rely on developer adherance in 3rd party code, then we can also rely on them using async calling convention eliminating the need to provide a public wrapper for private code. I guess it’s a case of picking your poison. 
I got to this point in the article: &gt; while (m.count() &lt; 1) { and that's exactly how chrono should never be used. But he said just before that code snippet that he's demonstrating pitfalls, so I figured that he was going to call that out as how not to use chrono. Unfortunately he never did and apparently he thinks there's nothing wrong with that usage. Here's the 'corrected' version of his code snippet: using namespace std::literals::chrono_literals; std::chrono::seconds t = 0min; // 1 while (t &lt; 1min) { // 2 t += 1s; } std::cout &lt;&lt; "minutes: " &lt;&lt; t/1min &lt;&lt; '\n'; // 3 1. We select the type based on the code requirements. Since we need ticks of one second we select the type that works in terms of ticks of one second. 2. The power of chrono comes from strong typing. Both `m.count() &lt; 1` and `m &lt; 1` are avoiding that for no apparent reason except that the author is more familiar with untyped time APIs. Asking "is this duration less than one minute?" is much clearer than asking "Is the count of ticks of this duration less than one?" or "is this number less than one?" 3. `cout` is used so that we don't have to figure out the right printf type specifier, because that's easy to get wrong and isn't portable.
&gt; And it is also nothing like unique_ptr really. There is no need for reference counting or synchronization of the management of the thing targeted `unique_ptr` does neither of those things.
I think it’s fine, there aren’t overloads for any of the std algorithms for containers so this is just consistent, and that signature is a pretty solid convention when dealing with functions that act on ranges of data. 
Sorry, I am not a native english speaker.
You’re right, I’m mixing things up. I’ll fix it soon. 
Fixed, thanks!
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I love formatting tools. But way too many organizations have created coding rules that are religious in nature; format my way, comment my way, name my way, structure my way, and then a huge list of don'ts. Most of these are born of fear, not actual statistical proof. I see people ranting about smart pointers and whatnot and they are able to come up with very specific(as with most fear based rules) examples of where that rule will save you from damnation. I have two problems with most coding rules and styles being enforced. One is that I can read pretty much any good code that I find on the net regardless of its style. The other is that there are so many bigger fish to fry and wasting one braincell on a single person's preferences is just that a waste. The argument that so many will then make is "Well you have to code in some style so why not make it easier on your coworkers and use the common style?" Not completely wrong but this is exactly the origin of my point from where the OP was asking a question and I pointed out that a flat organization largely eliminates the concept of manager/team lead/etc which then also eliminates a single person who gets to dictate their own personal preferences arbitrarily. Yes, you probably shouldn't code in some style that wildly clashes with your coworkers. But that would be completely covered by the rule "Don't be a dick." I would say the only style argument that has to be resolved across a codebase is tabs vs spaces as that will get really old really quickly unless you have a very good tool for sorting it out. In this particular case the only "rule" that I have seen work is that when code goes into git that it must be tabs. That way anyone checking it out can convert to spaces, the key being that it allows different space people to use varying numbers of spaces (and I have witnessed a person who used 8). 
&gt; **”** &gt; namespace { &gt; // All the loggers we might create &gt; map&lt;logger_params, weak_ptr&lt;logger&gt;&gt; loggers; &gt; mutex loggers_mutex; &gt; } &gt; &gt; /** &gt; * Get a shared_ptr to a logger instance. It may already exist, or it may need &gt; * to be created within this call. &gt; */ &gt; shared_ptr&lt;logger&gt; logging::logger::get_or_create(logger_params params) { &gt; unique_lock map_lock{loggers_mutex}; &gt; // Find an existing entry &gt; auto existing = loggers.find(params); &gt; if (existing == loggers.end()) { &gt; // Create a new instance from the parameters &gt; auto ret = make_shared&lt;logger&gt;(params, logger::create_cookie{}); &gt; // Insert it in our map &gt; loggers.emplace(params, ret); &gt; // Return the shared_ptr to the caller &gt; return ret; &gt; } &gt; // We found an entry. Lock the weak_ptr to get a shared_ptr &gt; shared_ptr&lt;logger&gt; ret = existing-&gt;second.lock(); &gt; if (!ret) { &gt; // The weak_ptr expired, so we need to recreate the logger. &gt; ret = make_shared&lt;logger&gt;(params, logger::create_cookie{}); &gt; // Fill the entry with the new instance &gt; existing-&gt;second = ret; &gt; } &gt; return ret; &gt; } &gt; &gt; This is a pretty common design Then programming expertise has gone drastically downhill the last few decades. Instead of all that, the client code can just declare a logger instance each place it needs a customized logger. 
Rather, if you need a specific width just use appropriate types like `int_least64_t`
Depends, if the numbers are all single digits, you could copy just a character range into your target strings, Otherwise i would use a regular expression
As time goes on more and more, I am still astounded how C++ doesn't have anything as widespread as Enumerable from C# or other languages. If a container is able to have &amp;T container&lt;T&gt;::next() called on it, then it's enumerable. Doesn't have to be contiguous in memory, doesn't have to be O(1), doesn't have to be cache friendly, doesn't have to handle random lookup quickly. Just let me enumerate over it with for(item : items) and pass it into algorithms. Mark it in linters as (could be slow, non optimal). None of this ::begin() or ::end() nonsense. Why on earth did the committee stop at having iterators but needing to call begin and end on them for almost all functions which work with a sequence of them?
I think, in general, it's wise for a language like C++ to favor performance over user-friendliness (if there's no other choice) so I think using integral types was the right move, but I definitely understand how that can be confusing. I'm not sure how it can be improved without using floating point (and hurting performance and portability to embedded systems).
A mutex lock and possible O(N) lookup + shared_ptr creation just to get a logger? That's crazy. &gt; Instead of all that, the client code can just declare a logger instance each place it needs a customized logger. Agreed. If something as simple as logging has all of that overhead it's going to discourage anyone from using it. Additionally the entire example is just crazy. I've yet to come across a place where I would want more than 1 log output. The whole point of a log file is "logging goes into it".
 const std::string record; // this is your line const std::string date = record.substr(record.rfind(" ")); If you don't know if it's a whitespace or tab or anything else - use regex
You have something against Amherst!? I joke... it is near me. Obviously, the issue is lack of C++ large scale experience.
&gt; The way forward for this paper is simple. Keep `std::initializer_list`. Make `std::init_list`. Duplicate every `std::initializer_list` constructor to one that takes a `std::init_list` for the entire Standard Library. Add an implicit conversion from `std::init_list` to `std::initializer_list` Then, apply the new rules to the core wording from p1249. Then we can finally have not-broken init_list. I always felt like brace init lists should behave like a language based tuple (that may extend `std::init_list` if all elements are the same type!). That way we could deduce init list in forwarding functions and maybe add suitable CTAD form `std::map`.
I believe the main reason for that - as pathetic as it might sound - was not needing an extra wrapper for arrays (but rather being able to pass in begin/end pointers). The ranges proposal more or less adds a single type that contains both the `begin` and `end` iterators and lets you more easily chain algorithms working on them. Apparently, this is surprisingly hard to get right for all the things that you want it to work with, you can use ranges already today with the ranges-v3 library and ranges have been merged into C++20 IIRC. ``` for(item : items) ``` This has worked in C++ since C++11.
&gt; This has worked in C++ since C++11. My wording was poor. I meant the requirement for a container to be used on a for loop (or even for_each) would be limited to just implementing next(). Thanks for the ranges v3 suggestion! Happy to see it's being added in C++20,
This helps: https://scitools.com/trial-download-3/ But generally, CLion .. 
&gt; I've yet to come across a place where I would want more than 1 log output. Hmm I'd say it's quite a common use case to want to log to a file as well as to a terminal, at the same time, often with different log levels. Or are you talking about something else?
With explicit begin and end you can easily constrain the range as needed. &gt; Just let me enumerate over it with for(item : items) std::vector&lt;int&gt; v; for(auto n: v) { } std::map&lt;int,int&gt; m; for(auto [key,value]: m) { } Something which needs to be `Enumerable` can easily provide `begin()` and `end()`.
The thing is, it's not an algorithm, first of all because it's not generic - it supports only const char\*. There's no even a wchar\_t equivalent, so it's basically useless on Windows. Secondly, there are overloads for all of the std algorithms for containers *now*, because [Ranges](https://en.cppreference.com/w/cpp/experimental/ranges#Algorithms), so no, it's not consistent. The return value &amp; error checking is also abominable: const auto res = std::from_chars(...); if (res.ec == std::errc()) ... else if (res.ec == std::errc::invalid_argument) ... else if (res.ec == std::errc::result_out_of_range) ... \- Really? No one ever suggested to at least add `explicit operator bool()` there for the cases when you don't care? if (!from_chars(...)) throw runtime_error("check your input"); Quite a few people seem to be a bit obsessed with the speed of these convertors, but their interfaces are so wrong on so many levels :(
This is the precondition for Continuous Delivery as an evolution of Continuous Integration. You should (ideally) be able to release your software straight from trunk at any time.
So if we were to encode module names in file names, how do you tell the build system where to find those filenames? Would the solution map to (for instance) target_include_directories in cmake? I.e. give your build system folders to search? Does a module correspond to something like a shared or static library as far as a build system would be concerned? How much would it take for build systems that don't support modules to add support? Also would you need standardized naming for module files (including conventions for interface and implementation file names)?
For those who haven't already done so - give conan a try! It's easy to use and incredibly powerful. (As in runs rings around \`vcpkg\`.) NB: I'm not affiliated to conan in any way, but my company, zenAud.io , uses it.
Modules form translations units(.o), modules binary interfaces are glorified precompiled header. The files from which the Binary Module Interface are generated are basically "headers", and so I would expect them to be in the "include" directory &gt; How much would it take for build systems that don't support modules to add support? Depends on the build system. I tried to add support for it in qbs and it's proved too difficult for me to do because of some assumptions they made in their dependency graph. One of the challenges of retrofitting modules is that modifying a source file might modify the dependency graph, and a single file might produce several artifacts. For a build system like CMake, it's quite challenging - you have to add support for it in both cmake and cmake generators ( make, ninja, msbuild etc) and it might be rather clunky. &gt; Also would you need standardized naming for module files (including conventions for interface and implementation file names)? For interface, I think it would be highly beneficial - It's however not useful to do it for implementation files.
Hey guys, &amp;#x200B; this library bundles your header and source file to one single header file. &amp;#x200B; It's my first self-written library in python, ever. The idea comes from Catch2 and this issue: [https://github.com/catchorg/Catch2/issues/1269](https://github.com/catchorg/Catch2/issues/1269) &amp;#x200B; I hope you like it and I would love the hear your constructive criticism about it. &amp;#x200B; &amp;#x200B;
\&gt; post mentions the word Rust Better downvote it.
Reference and pointers are every different types and I don't see the problem with giving member-access different syntax, just because they are sometimes implemented the same way under the hood.
&gt; std::embed - p1040 This makes me very excited. I would love to do this for Embedded systems so I won't have to mess around with linker scripts or convert my data to massive char arrays which get pasted in a header/c file.
To be fair, this is more than 10 years old. I wouldn't be surprised if his general thoughts haven't changed but it still seems like there's a better discussion to be had than "Look what Linux said 11 years ago about C++".
How does it resolve potential name collisions among entities declared inside source files?
LT is against C++ with Git, that much we know. LT uses C++ with [subsurface](https://subsurface-divelog.org/). Maybe, just maybe, he considers using the right tool for the job?
you say #include has a correspondence with filename. That's true. But it also corresponds to directories when using / or \ and that is very important for structuring your code. Just imagine an executable which links with several static libraries and then uses some more external libraries. You sure wouldn't want to have header files from all those smacked together in one directory would you? If you will not give the dot in the module name same meaning as / in #include you are effectively requiring all module files to be in single directory (okay maybe you can specify multiple module directories but still it's a mess and modules files from different libraries can clash easily). That's not good enough. Too bad the committee is afraid to specify this clearly because it should be done before modules are officially released.
Spoiler: This will be covered in an other article
I never pinned Travolds as a diving enthusiast. I also didn't know Git is +10 years old. Things you learn in one day...
Linus is against C++ in the linux kernel. As stated before me, he uses C++/Qt for his diving application Subsurface. 
I'm pretty sure the post is not down voted because it mentions rust, but because it is bit relevant for this subreddit and has imo a misleading title. Writing a C++ wrapper around a C api is as old as the language itself, and what language provides that C apu is pretty irrelevant
&gt; Unfortunately, `build2` module&lt;-&gt;file mapping is fuzzy and as such more brittle. It is fuzzy but I would argue it's not brittle because the guesses are verified against the actually extracted module names. In other words, if you mess up, the feedback is very quick and very clear on what to do. And I, personally, will take that over any inconsistencies in the file naming of my projects.
i think as always the email is pretty expressive and he makes pretty clear points why he doesn't like it, not sure what you want us to add. I mostly agree with him and it's his project so if he thinks C is the way to go it's his decision. And i do think he has a point with reliance on external libraries - have i cursed about many open source projects because building them is such a pain with tons of dependencies with only certain versions of each working. Even some of the projects i really like have such horrible things in the backend that it makes a rework basically necessary because some random library was used without thinking too much about it (it was there and we needed it!) and now nobody updates it, things are broken and nobody wants to fix it. 
&gt; I've yet to come across a place where I would want more than 1 log output. This apply to you but not to everyone. We extensively use more than one appender per logger, e,g. network appender to get the logs when we don't have directly filesystem access to the device.
I think his issue is wanting to always use C with the kernel. 
I have no idea what just changed in the last few months between YouTube and Reddit, but it just recently started stripping the "++" out of the auto generated post titles if I'm not careful to catch it. &amp;#x200B; Sorry about that.
If I look on [Conan center](https://bintray.com/conan/conan-center), I cannot find any of the packages I actually need, whereas vcpkg has all of them. Or maybe it is just their search that is completely broken? Search for Cairo, and it returns args, excel, cfgfile, and wiringpi as the first four hits... 
At the same time, the question of dependencies is certainly real, and a *standard* solution would be so much better... it's a tough one.
Jesus, what did you people do before the internet? My point was \*I\* was using two and a half decades ago, well before it had a well established name, so I chose one of my own. Given that, I didn't feel obligated to use some other name now when I took the time to write up something to help newbies understand the concept. &amp;#x200B;
Sorry, I was thinking that was a counted pointer. So, yeh, one of the classes mentioned above is equivalent to that. None of the others are that sort of thing. My THeapJanitor and TArrayJanitor classes are equivalent to unique\_ptr. &amp;#x200B;
It feels to me like what you're saying in the case of the logger is an unconscious instance of incompatibility with the design of the current generation std smart pointer and the sharing philosophy you want users to use with the objects created by your get_or_create function. You solve that problem by creating a smart pointer of your own type specifically to handle the logger object. I've seen plenty of projects trade off features to similar effect and create their own custom smart pointers in their API. The first issue you bring up at all is that they derefrence like pointers with an arrow, not a dot, you keep treating pointers like references rather the a separate concept with it's own use cases, and like all language concepts not universally applicable. It seems to me the problem is that auto hides the fact that the object being returned is a pointer and not an object specific to the API or a non nullable refrence. Not a general issue with smart pointers all together. Smart pointers are always going to seem problematic if you use them as if they aren't pointers. There are plenty of issues with introducing them to an API even if used right and I think it would be useful if you expanded on that.
Thanks man. I solved it. Seems SFINAE is not well known.
as someone who is currently banging his head through the compiler learning c++, I am curious what language you would recommend as a first language? &amp;#x200B; I say first because, the only experience I've had was highschool qbasic and we never really did anything with it for first year. C++ is interesting but I have a lot of questions that I'm finding are... problimatic when I ask. There are many subjects, such as the compiler, that aren't covered by the many of the sources I'm learning from.
&gt;C++ doesn’t define an ABI, but every vendor has one and right now what we do is simple: promise infinity binary compatibility forever and ever, never breaking users with backwards compatibility stories for millennia. This means that if you compile C++98 code with a std::string it doesn’t matter if you learned things in the last 20 years: you can build and link an application today with std::string in the interface and it’ll work. &amp;#x200B; WAT.jpg &amp;#x200B; std::string is used to be ref-counted at least in GCC, but since C++11 the Standard forbids that, how can it work? I remember an announcement by someone from MSVC team around 2012 about how they reduced the sizes of all standard containers and how good it is, how can it work? std::string even [has different sizes](https://godbolt.org/z/J8ACtK) in Debug and Release, so how can it work?
That's what Doug Schaeffer used for his toolchain file, and since CMake failed to determine \`${\_CMAKE\_TOOLCHAIN\_PREFIX}\` , he has manually added values for \`ar\` and \`ranlib\`. I will file a merge request to fix this, but this won't fix the other issues that QCC has (not forwarding -gsplit-dwarf, Qt Creator issues, and possibly slow down ccache)
So when it fails it what, throws an exception?
MSVC is LLP64: int and long are 32, long long is 64.
Sure. That's what our logging does as well. I guess I'm used to having complete control over the implementation details of anything we use. Being able to make logging go to the terminal if one is attached as needed is just "how logging works" for me so I didn't give it a second thought (or a first one). Most likely due to all my C++ experience being game development we just don't use 3rd-party libraries frequently because they never give enough customization options or try to be too generic and have some overhead we aren't willing to pay (such as the mutex and iteration example here).
I've found Boost.PropertyTree to be kind of a pain in the ass to use if you ever nest objects. Iterating through object trees seems like it's harder than it should be. But it does work for what I need it to do, so I'm OK with that. I am getting to the point where I've eliminated most of the boost dependencies from my libraries. I'm mostly down to Boost.log and Boost.signals2 now. But if you ever need it, Boost.Python is awfully goddamn sweet, and I find that to be VERY hard to ignore.
I don't understand this either. Is the author saying that C++ garuntees that the standard library from a given vendor will have the same ABI, no matter the version? 
&gt; the compiler should force you to deal with the possibility that your type might be null. Sometimes I know a pointer isn't null (let's ignore cosmic rays and bit flips). Why should I deal with that? Regarding the article: what's the problem with providing a fine grained and a safer API on top of that? All the author does is to wrap the "bad" API in a "not-so-bad" but less flexible one. No problem in exposing both.
It was originally specified to use error_code which is boolean testable but that had problematic performance and header circularity issues, so it was patched to use errc (and move from &lt;utility&gt; to &lt;charconv&gt;) in a Defect Report. The resulting interface is not super convenient, but it can easily be wrapped. string_view overloads could easily be standardized. wchar_t would need additional templating but wouldn’t complicate the core logic very much (since the relevant characters all occupy one code unit).
You should try in [bincrafters](https://bintray.com/bincrafters/public-conan). This is one of the things that annoy me about conan, actually. The reason is that there's the "official" conan package repo, and a community-crafted one. Your algorithm for finding a package is to first search Conan center, and if it's not there, then check bincrafters. It's usually in one of the two. At least for me, there were no (non-replaceable) packages that weren't there. By the way, the fact that there are multiple package repos is one of the reasons conan is better. For [zenAud.io](https://zenAud.io), we have our own package repo with tweaked packages to allow building using clang/windows. The fact that everything pretty much just works is pretty awesome, and I'm 100% certain you can't do it with vcpkg.
Yeah, that was me. Up until VS 2015, we indeed changed the STL’s ABI in every major release. VS 2015, 2017, and 2019 are binary compatible (which requires a great deal of attention and prevents significant bugs from being fixed). We are working towards a binary incompatible release but we want to make migration easier than before, so we’re still working on that plan.
Conan provides a [wishlist](https://github.com/conan-io/wishlist) where you can ask for a new package. I believe [Conan community](https://bintray.com/conan-community/conan) and [Bincrafters](https://bintray.com/bincrafters/public-conan) are working hard to provide new packages, which includes support for on popular platforms.
&gt; std::string is used to be ref-counted at least in GCC, but since C++11 the Standard forbids that, how can it work? And that's why GCC had dual ABI support. Set `_GLIBCXX_USE_CXX11_ABI` to 0 and you get the backwards compatible ABI. You also have `-Wabi-tags`. More info [here](https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html)
Now I worry about him having an aneurysm at depth.
`co_*`
No, you really don't *ever* want `aligned_storage` (or `aligned_union`); it's fundamentally broken. The core language rules (http://eel.is/c++draft/intro.object#3) specify that only "array of *N* `unsigned char`" and "array of *N* `std::byte`" can "provide storage" for another object. This program: ```c++ struct S { alignas(long long) unsigned char space_[sizeof(long long)]; std::vector&lt;int&gt; vec_; }; int main() { S s{{}, {3,2,1,0}}; ::new (&amp;s.space_) long long(42); return s.vec_.back(); } ``` has well-defined behavior; the placement new doesn't end the lifetime of `s` since `space_` provides storage for the `long long`. If we instead use `aligned_storage_t&lt;sizeof(long long), alignof(long long)&gt;` which cannot "provide storage", the placement new *reuses* the storage of `s` and implicitly ends its lifetime, so the access of `s.vec_` in the `return` has undefined behavior. I really should write a proposal to deprecate `aligned_storage` and `aligned_union`.
Fails accessing the next element? Undefined behavior probably via a seg fault accessing a null/invalid pointer.
As a very creative programmer, and a lone wolf type, I obviously would agree with what you say. However, it is sort of predicated on the fact that the only lazy and incompetent people are in management, which is almost certainly seldom the case, right? Ultimately, if you want to get back to real root causes, isn't the ultimate source of successful team makeup the actual selection of the team members, and how that happens? I'm not putting forward any suggestions as to how it would happen, as I would be a horrible person to make such choices myself. But, ultimately, you only get lazy, incompetent, controlling, etc... people in either management or development if you actually hire them. I think that, on the issue of different types of personalities, that's clearly true but there's probably seldom a mechanism to identify such personalities and apply them appropriately. Some companies I guess use the Myers-Briggs assessment, which would be one means. Put their MB type on their name tags in very readable type and make people aware of what those types mean, and it might go a long way towards team members understanding how best to interact/use their fellows. For someone like me, if you give me something big and challenging and just leave me alone, I can crank out a lot of very high quality code very fast. If you try to get me into meetings where I have to express my feelings and hug people and such, and I may run away.
I'm a big fan of these flags. There are some for VC, too. I have a library which is my general C++ toolbelt. It includes this: \[Documentation\]([https://github.com/ProgramMax/max/blob/master/Documentation/max/v0/Compiling/AliasingOptimizations.md](https://github.com/ProgramMax/max/blob/master/Documentation/max/v0/Compiling/AliasingOptimizations.md)) and \[code\]([https://github.com/ProgramMax/max/blob/master/Code/Include/max/Compiling/AliasingOptimizations.hpp](https://github.com/ProgramMax/max/blob/master/Code/Include/max/Compiling/AliasingOptimizations.hpp))
Yeah I know. But the author asserts that exposing std types from DLL (!) is ok and supposed to just work out of the box with any version of any compiler from any vendor because the committee "promise infinity binary compatibility", but that's not exactly true.
And here I am, porting the kernel to C++.
It doesn't. If you have name collision, the library cannot be used as a single header. This is a limitation. But you could use namespaces (if C++) to solve this.
Just felt compelled to point out that not all the symbols on their site work with the fonts for the site ;) At least not in the Windows 7 rendering through Chrome. "Source Sans Pro" and all subsequent fallback fonts seem to be missing the Shield and Dagger Knife symbols on my box.
Madness. You'd be better off helping me finish my gaming engine. Pure C at the bottom, clean C++ at the top, I even use snake casing for improved speed.
I would like more time to work on the Haiku OS project. I think it has real potential. KDE has already ported several applications there. 
So the loop using it will never finish? How would you get previous element?
std::string owns its storage, which it always allocates one byte larger to put a null byte there. Qt's QByteArray does this too. &amp;#x200B; When people say that std::string is not null-terminated, it means that it can have embedded null bytes. That's not possible with a null-terminated string since the first null would mark the end.
Most vendors these days promise ABI compatibility to their customers, and the committee isn't going to standardize something that most vendors refuse to implement.
A few more questions - 1) You mentioned still having Boost.log in the codebase, have you used spdlog for logging? 2) Boost.Test or Google Test? 3) Since you have mentioned Boost.Python(which I like as well), what about Boost.Hana and Boost.Fusion? Are they pretty hard to ignore as well? 
Then what does this tool offer over simple `cat`?
Scrum works fine if you bust your teams up into groups of 4-8. It's almost always better to break big projects into smaller bite size chunks anyway. I've worked at some very large companies and most use agile development styles. My preferred ones were heavily invested in TDD from the get go
Reddit wants you to do C videos....
If you do nothing else concentrate on test driven development as it will keep you from being end heavy on the project "due" periods. It keeps you honest and not assuming stuff works. Make sure you have continuous automated test set up with Jenkins or similar. Make developers responsible for confirming they didn't break trunk by pushing to a branch for any testing.
Please show me the cat command for the example in the repository, combining header and source files and also consider all kind of comments, raw literals and line wraps. If you know Catch2 or other single header libraries: They ship one header for the hole library. To use them in your app you include the header with sources (mostly over a define LIBRARY_MAIN) in one translation unit. All other translation units just include the header without source.
The author confuses/conflate language ABI (Itanium ABI, anyone?) with library ABI.
Isn't clang-format the solution?
Do you know Catch2 or other single header libraries? They ship one file which has all needed public headers and all source files with private headers. In one of your translation units you define: *#define LIBRARY\_MAIN* before the include to compile the sources in only this translation unit. All other translation units just include the header like normal. So there shouldn't be any multiple definition errors.
&gt; VS 2015, 2017, and 2019 are binary compatible (which requires a great deal of attention and prevents significant bugs from being fixed). Aren't they "mostly BC"? Ignoring stuff like `shared_ptr` alignment issues I think there is still stuff that introduces potential BIC (I saw something on that in discussion of wether Qt should ship VS2015 binaries or it could just ship VS2017 ones).
pretty sure he has issues with C as well e.g. https://lkml.org/lkml/2009/1/12/369
Why are you assuming that a const_iterator has to store a `const T*` internally? It can just store a `T*` and enforce const-ness via the API. const-ing class members is often a bad idea.
Lol he almost sounds like Terry Davis there 
&gt; &gt; Additionally the entire example is just crazy. I've yet to come across a place where I would want more than 1 log output. The whole point of a log file is "logging goes into it". huh, most of the systems I've worked on have needed logging to file as well to websocket servers at least
They should be completely compatible - if they aren't, that's a severe bug. I broke tuple once and quickly patched it, for example. (Note that the compatibility has limitations, as documented on MSDN. Notable ones: you can't mix LTCG objects, you can't perform the final link of a binary with an older toolset than the objects, and you can't use an older redist.)
Yes-ish. I love tools in that vein, but it won't solve petulant arguments such as beginning a function with an uppercase, or lower case letter, etc.
I mentioned that the reason for a different `-&gt;` from `.` is "arcane." Saying "Different syntax for different types" doesn't do it justice. [Here's a great rundown on why C uses `-&gt;` to access the member of a `struct` through a pointer.](https://stackoverflow.com/a/13366168) Of course, if `-&gt;` was never a thing, and we used `.` with pointers, this warrants the question of how one would implement `unique_ptr&lt;T&gt;` without being able to overload `-&gt;`. The short answer is "I don't know." The long and more strenuous answer is "Allow overloading of `operator.`"
If you define a function taking a non-null reference to `T`, with the _requirement_ that it be non-null, you take a `T&amp;`. Some programming languages, such as TypeScript, have control-flow aware type systems that recognize when an expression is non-null based on the control flow around the usage of the expression.
Disregard that, I said something retarded.
 1) I haven't. I went poking around for a C++ logger 2-3 years ago and already had boost on my system at that point, so Boost.log was kind of a no-brainer. I prefer it to std::cout or std::cerr, but I assign a huge cost to adding external dependencies to my projects. I will if I absolutely have to, but each one does make the entire project that much harder to maintain and set up for the first time. 2) Heh heh. cppunit with cmake. I've tried google test and found it to be really too complex for the basic testing I've tried to do, and I've written cppunit tests that kick off services in threads and consume those services in the main test. The only thing I find that cppunit doesn't do is catch and report sigsegvs, but if you add cppunit tests as cmake tests, ctest will. I actually have a little cppunit_contrib project I wrote a little while ago that creates a test listener for cppunit and provides a test runner that uses that listener to generate a test report with total run time for each test, at https://github.com/FlyingRhenquest/cppunit_contrib. I've heard good things about Boost.Test, but haven't had enough of a "learn another new test system" to dig into it. 3) Not really. I don't usually want to do that much at compile time, and my own template metaprogramming needs are fairly lightweight. I'm usually gluing third-party libraries together that mostly only work at run-time, to the point where even std::chrono can be somewhat problematic for me. I'm using libav* from ffmpeg a lot lately and I want to be able to create run-time chrono ratios!
&gt; Then programming expertise has gone drastically downhill the last few decades. What? This is the idiomatic design of a "thread-safe shared instance cache." How would you implement such an API? Don't say "I wouldn't use a shared instance cache," because that was the implicit requirements I was programming against. Don't insult me for writing code against a requirement you don't think is necessary. A similar design exists in one of the most popular C++ logging libraries. In fact, that library was the inspiration for this post. That's why I chose to implement these semantics. &gt; Instead of all that, the client code can just declare a logger instance each place it needs a customized logger. _What are you even talking about?_ Using this API is as simple as declaring a logger: shared_logger log = logging::logger::get_or_create("My Logger Parameters"); The reason I made this a free function is to make it clear that this is an expensive operation. One should not be calling it in a tight loop. I can just as easily make it look like a regular constructor call, should you so desire it: shared_logger(logger_params p) : _impl(detail::logger_impl::get_or_create(p)) {} Now creating a logger is as simple as calling the constructor: shared_logger log{ "My logger params" }; But you now have an implicit synchronization and map lookup. Of course, maybe you are referring to the client simply creating their own logger instance without any of the thread-safe shared instance caching at all. That works alright until you need to plumb your logger object all throughout your application because you can't make more than one with the same parameters. **But none of that matters.** It is beside the pointer of the post.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a2t26x/new_to_c_and_need_help_putting_this_equation_into/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thank you for the detailed response! I will have to look into cppunit for personal projects, current company uses Google Test , Boost only for cases where there are no other decent alternatives, most of it is Boost.graph, Boost.program_options and Boost.geometry, there's Boost.filesystem too but with it now being part of C++17 we might switch to using that. Might give Boost.Test a shot too if the consensus is good.
The standard guarantees that all the standard `duration` typedefs can represent at least 292 years.
Sure, my point was that you can't just pass any library through this too, it has been written in a special way, i.e. you can't do `static int foo() { return 1; }` in `a.cpp` and `static int foo() { return 2; }` in `b.cpp` since those are no longer in different compilation units.
Aside: Thanks for the Factorio. It eats my free time like candy. --- The point of the `get_or_create` being a free function is to make it clear that it is an expensive operation. If I were to implement the same semantics via a regular constructor, that would be extremely surprising to people that a constructor call incurs so much overhead. The design (and the design of the library from which this post was inspired) emphasizes that you should not call the "get/create a logger" API in a tight loop: You call it *once* and then re-use the object for the duration of the program/loop. You could create your own logger instance without the instance cache, but you then need to take care to plumb it throughout your application. The design of the library is such that you do not need users to do this plumbing on their own. But none of this really matters in the context of this post: It's beside the point: &gt; It could be optimized in a few places, but don’t worry about that for the purpose of this post. And: &gt; So, what would my ideal `logger` API look like? I dunno. This isn't how _I_ would design a logger, but this is how I would improve the existing one.
&gt; If you define a function taking a non-null reference to T, with the requirement that it be non-null, you take a T&amp;. I fully agree but fail to see how it is related to what I wrote. Often it's more convenient to simply use a pointer if I want to assign different values to said pointer. Using something like a `reference_wrapper` is simply overkill.
&gt; You solve that problem by creating a smart pointer of your own type ... No, I create a type with the semantics of "shared"-ness, and I use a `shared_ptr` to obtain that in a correct manner. The API is not that of a pointer, but of a logger with shared semantics. The semantics of the standard library's smart pointers are fine. The issue with `-&gt;` and `.` is a fairly petty one, and not one I like to emphasize. [You may also find this interesting (TL;DR: There's no good reason present C uses `-&gt;` over `.`)](https://stackoverflow.com/a/13366168). The usage of `auto` is not problematic in the case that you return an actual API object. Returning the actual API object actually makes `auto` less appealing, since you have these alternatives: std::shared_ptr&lt;logging::shared_logger&gt; log = logging::shared_logger::get_or_create(...); versus this: logging::shared_logger log = logging::shared_logger::get_or_create(...); Since you are now already providing the name of the type on the right-hand-side (via the access of a `static` factory function of the class), it is a prime example of where `auto` is beneficial: auto log = logging::shared_logger::get_or_create(...); 
The point is the use the type system to your benefit. If not a reference, then a `gsl::non_null&lt;T*&gt;`. It's about helping both human and machine eyes to perform static analysis of your code. Both `T&amp;`, `non_null&lt;T*&gt;`, and even `reference_wrapper&lt;T&gt;` help with that.
cppunit is very basic, but it's easy to add to a project. If you have a test system you like and it ain't broken, that's a pretty good place to be. I try to look at competitors for test and build systems every so often. If there's something amazingly better for my needs than what I'm using now, I'll often jump on the bandwagon. For example, I only recently started using cmake. My projects were fine with make up until a point, but I started needing packaging at work and cmake handles that pretty well. I've tried gradle in the past for C++ projects and actually had pretty good results moving a project between windows and Linux doing that, but found the setup to be overly complex. I've also looked at bazel briefly but cmake seems better-established and easier to find help on, which does play a role in that decision. I'll move to something else if I run across anything significantly better. I like Boost.program_options, which is weird. The syntax is a bit more bizarre than I usually like, but it's pretty easy to wrap your head around. If I ever need any serious math, I'd add the Eigen C++ math library without even thinking about it. Eigen and Boost get a pretty free pass in my book, although in my cppunit project I thought about having it emit test headers and footers using Boost.log and decided against it. Simplicity and all that. It's easy enough to change if I ever decide I need to do that, doesn't have to be now. Software's never carved in stone. I'm moving away from boost::bind in favor of std::bind even though I'm still using boost.signals2 -- std::bind works with it, although you do have to specify std::placeholders::_1 instead of _1, which is kind of annoying. I see why they did it, though.
I like very this idea, I have thought about doing something similar. I have done it manually and it payed off well.
Iove the idea, though I feel it would be much better served being written in C++
Rather silly when you have interesting subsets of C++ that would be very useful in the kernel. Getting rid of some of the macro hell, function overloading, lambdas, type safe variadics, RAII, etc. I’m pretty sure he hates virtual member functions, but drivers and the file system essentially simulate them so I’m not sure that’s a good reason to reject them in the kernel. I wonder what he would think of using C11/17 instead of C89. I don’t know if anybody has proposed that.
Because you e.g. want to be able to construct a const_iterator from a constant container variable? And I wouldn't call a const T* a constant class member. 
I'll have to pick different emoji.
People rejected language-level tuple literals and all of its implications. It's why we have a weak, boring form of it with variadic packs (that honestly should have just been the language-level tuple) where you can't inspect anything inside the variadic without recursing or instantiating over it.... Or packing it in a std::tuple and kissing your compile-times goodbye for any tuple size of N &gt; 9 or something.
My example was exaggerated, but I don't confuse anything. Even if this wasn't in C++98, this is definitely the case today. Take any proposal that affects ABI to the committee. Watch as the notable Standard Library and Compiler implementers slowly filter into your room during LEWG(I) discussion or EWG(I) discussion, raise their hand, and then say "this breaks ABI". ~~Cry because there is no escape from the Demon.~~
&gt;No, I create a type with the semantics of "shared"-ness, and I use a shared\_ptr to obtain that in a correct manner. The API is not that of a pointer, but of a logger with shared semantics. It's just simple wrapper around a smart pointer to get the reference counting functionality without allowing the object to be destroyed outside the reference counting system. You can call it "not a smart pointer" but it sure behaves like one. You've basically written a "smart reference". BTW, there are also plenty of other advantages to the system you've built here. The API can essentially do all sorts of crazy things like swapping implementations of the logger behind the scenes while keeping all the references valid, or even abstracting away using multiple implementations at once, but that's not what you cover here. &gt; The semantics of the standard library's smart pointers are fine. Not my issue with smart pointers in APIs actaully. I agree the semantics are fine. Reference counting overhead and potentially unpredictable destructor calls when the count gets to 0? Less so. Also the standard ABI stuff you get with shoving std objects waay up into your API. Also there's a good chance your client already has his own memory management scheme, and adding the std smart pointers ain't always ideal. &gt;The usage of auto is not problematic in the case that you return an actual API object. I wasn't saying using auto was problematic, I'm saying that the issue of the smart pointer using a -&gt; derfrence only exists because auto creates ambiguity about the type being returned. BTW that's one reason why some people would argue the signature "get\_or\_create(...)" should have some reference to the fact it's returning a pointer. Look I'm not saying I disagree with your points, just that your case here doesn't really explain why smart pointers are bad for APIs, just that nullable types are problematic when they're also doing reference counting, and also you don't assume the user is checking for nulls. It's a good argument for the use of "smart references", but not against smart pointers in APIs. It's a "think twice"er not a "don't do it"er. Using an STD smart pointer inherently adds nulliability to the object being returned, if it shouldn't be nullable, that's an issue, don't use an object that adds nullability.
How do you deal with anonymous namespaces and static memory?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a2oqxn/skipping_a_surden_number_of_text_in_a_file/eb15iwo/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I don't see any inherent reasons why `std::tuple` throughput should massively degrade with large tuples. (That's ignoring specific choices in existing implementations, like MSVC's recursive inheritance, which could be implemented differently at the cost of an ABI break.) In particular, `make_integer_sequence` is ultrafast, so most tuple processing should be fast.
I think it's safe to clarify that people _had_ rejected language-level tuple literals. The committee changes its minds. Often. Especially as people come and go, different people are in different sessions, or papers are updated to make better arguments. The committee also learns, of course, as its constituent members learn. :)
And why it's a bad thing? "This breaks ABI" means "It breaks potentially all existing running programs that rely on dynamic linking", it's always painful, so it's best to avoid it without really good reason. And it's not frozen it's just needs a lot of justification and some escape hatches. It's basically the question of "is breaking the world worth it for this thing or not".
Great example even game developers should appreciate: logging to a text file and to the in-game console Another example that game developers working on Big Games With Big Servers should appreciate: Servers logging to a text file, to OS console, and to remote telemetry service/queue I very much appreciate the problems that client/engine programmers have with C++ (I _am_ a client/engine programmer, and I have those some complaints) but we have to remember that C++ is used by more people even in our own organizations (I have been a lead game server engineer for instance and had to directly deal with scaling out and reliability/stability at scale and not just micro-optimizing client code).
You will get the same problems that this article describes for integer types. Given a `dminutes` - as defined in the article - adding `dseconds{1}` to the value **may**: * increase the duration by a second * increase the duration by less than a second * increase the duration by more than a second * not modify the value at all! ... and it's **very hard** to predict the circumstances that would lead to each of those 4 scenarios. Outside of `std::chrono`, you might learn a lot by searching the web for "why floating point is dangerous" 
Symbian OS was an embedded kernel written entirely in C++, but long before a lot of things with the language were improved.
&gt; There's no even a wchar_t equivalent Thank god for that, `wchar_t` is basically useless as a character type because you can't rely at all on its size. In any case, even on windows you can use `WideCharToMultiByte` and `MultiByteToWideChar` and internally just use utf-8 for everything.
I think these flags are quite cool. They have the potential to enable c++ compilers to do a lot of the optimizations that functional languages' compilers do. Although I don't see the flags being used very much so I guess right now the compilers are not written to take full advantage of them.
Wait. Does this mean even the backward incompatible parts of the `char8_t` paper are likely to make it into C++20? I really love that paper, but was sure that the backward incompatibilities would kill or at least severely hobble it. 
Great idea, I wish all libraries shipped with a complementary header only file.
&gt;on windows you can use `WideCharToMultiByte` and `MultiByteToWideChar` and internally just use utf-8 for everything Allocate memory and convert data back and forth every time you need to make an API call? That's nice. &amp;#x200B;
I find it strange that language and library implementers (including non-standard libraries) say &gt; We can't do `&lt;X&gt;` because it breaks the ABI. while anyone maintaining anything of even slight complexity (including myself) says &gt; Don't assume ABI compatibility unless you compile with the exact same compiler with the same options. If using `&lt;X&gt;` requires a compiler upgrade, you're already breaking the ABI. I can with near certainty assure you that if you compile a library with `-std=c++14` and link it with another compiled with `-std=c++17`, *you are violating ODR somewhere*. I know that Linux (all Unix?) platforms have stronger ABI guarantees, but I've come to believe that these guarantees are extremely flimsy and detrimental under scrutiny. Because it is so unreasonable (in the existing ecosystem) to build your dependencies from source/against your current "platform", everyone wants their pre-compiled binaries to be compatible with every other compilation they wish to do in the future. It's a meme that needs to die.
These would be _so_ much more useful if the compiler also enforced them.
The recursive implementation is the bane of my existence right now, but there are other problems. With the current `std::tuple` things like the SFINAE required and metaprogramming necessary for the several constructors that handle their explicitness, triviality propagation, and other things, the cost of compilation is quite high when you go from a variadic pack to a tuple, especially if you have to take really big tuples and put them in `std::forward_as_tuple`s. Even if the integer sequence generation is quick, materializing and constructing that tuple is one of the most expensive things I have to do right now in terms of what the compiler does. I particularly struggle with this when I need to pull out more-than-one at a time from a variadic pack. Subsequently destructing a `std::forward_as_tuple` I just created into 2-arg calls (to say, handle a key-value set of different types in sequential order) just reeks of silliness: pack -&gt; cram into tuple -&gt; tuple -&gt; de-tuple to pull out 2 items at a time, just so I can do a folding expression with 2 arguments at a time. There's no reason to do this round tripping through `std::tuple`. This is a waste of my compiler's energy. We should be making variadic packs have more expressive operations rather than going the "long way" through `std::tuple`. This should include being able to pull patterns without recursion, which is where some Mythical, Magical `for constexpr( [a, b] : pack... ) { ... }` would be MEGA cool. But I'm not writing that paper. ... Yet.
I'm sure we do, but now someone needs to write the paper, generate the motivation, figure out the syntax, etc. etc... That's a crazy amount of effort, and I'm not even sure I have the will for that.
No, he is saying that the standard *allows* standard libraries from different versions to have the same ABI by not adoption changes that would force an ABI break. Whether they actually do or not is up to the implementors.
I've found implementations of from\_chars to be more compelling than to\_chars. Using from\_chars was an easy decision.
He just doesn't want C++ in either Linux Kernel or Git. That's really a good idea, you don't want C++ virtual methods to be used to manage page faults. Both Linux Kernel and Git are massively successful projects. C didn't change much. I hope Linux and Git don't change much for another decade. C++ is not used because it's a better-designed language than C. It's used because C++ is easier to write, easier to design an application. Most applications are written by decent programmers with a limited budget. You don't just write many functions who take a generic pointer as an argument and try to do some difficult to understand things. He is known for his arrogance and open dislike of C++. After all, I am happy for Linux and millions like me don't give a fuck who wrote that. In fact, I feel C is too outdated with macros, generic pointers, arrays and function pointers. Probably, Linux Kernel will be written in a templated C++ language or may be Rust. Or, some better OS will be a 2nd option(android and iPhone didn't even take a decade to make Nokia obsolete). 
The OP title is oddly worded unless one interprets it to mean that Linus Torvalds would like to take a blow torch to C++ and incinerate it
Bits/stdc++?
Vcpkg is pretty much decentralized... If you want a new package you just write an wrapper file and put it in ports... And if you want it to be directly bundled you can make a request at M$. Hmm, maybe I'll try Conan one day.
thanks. Does this mean that: std::string s = "die_liebe"; s[ s.length ]; // always a null character?
This is really neat. I wonder if it can be advanced a bit more to generate a single file .hpp and single file .ipp like some libraries, so the .ipp just needs included in one translation unit.
I dunno why people are downvoting this. The replies to his question are very valuable. I've explained the concept of hours in the past to a bunch of my coworkers. It's a popular misconception with the usage of chrono's helper types. The more people see why he's wrong the better.
So pImpl basically?
`gsl::not_null&lt;&gt;` works with smart pointers too, right? I think it disables `std::unique_ptr&lt;&gt;`'s movability though (for safety reasons), rendering it not so usable for interfaces, but you could imagine a (third party provided) "safe" `unique_ptr` that supports movability, checks (at run-time) for post-move dereferences and doesn't support nullability. So the arrow operator does not necessarily imply the nullability of smart pointers. It's just that the two standard library smart pointers happen to support nullability. Your initial complaint about the nullability of smart pointers was about safety. But because C++ doesn't support smart references yet (limited emulation techniques notwithstanding), safe pass-by-reference interfaces arguably require smart pointers (if not the ones from the standard library). A native reference function parameter is not only missing any enforcement mechanism that ensures that it will refer to a valid object for the duration of the function, but it is arguably not even able to fully communicate the requirements for the caller to ensure that the reference remains valid for the duration of the function. For example, consider this function interface: void foo(const std::string&amp; str, std::vector&lt;std::string&gt;&amp; strvec);` Is the (first parameter) string reference allowed to reference a string contained in the vector referenced by the second parameter? What if the the `foo()` function resizes the vector at some point? The SaferCPlusPlus library (shameless plug), for example provides a non-owning, never-null, non-retargetable, zero-overhead [smart pointer](https://github.com/duneroadrunner/SaferCPlusPlus/blob/master/README.md#txscopeitemfixedpointer) that, in concert with the other library elements, ensures that it won't outlive its target object, and can be used to make safe pass-by-reference interfaces. Also note that in the first example in the article, there is an unsafe implicit interface for accessing the "global" `loggers` map and the `loggers_mutex`. I'll just point out that the SaferCPlusPlus library also provides [data types](https://github.com/duneroadrunner/SaferCPlusPlus/blob/master/README.md#asynchronously-shared-objects) that in turn provide (never-null) smart pointers that automatically ensure that an object is only accessed when an appropriate mutex lock is held. If safe interfaces (and code safety in general) is the goal, the smartness of smart pointers is arguably indispensable. Arguably.
So here is an example. You have a vector of pointers. At every entrypoint you confirm they are non-null. It gets serialized into a memory buffer of raw bits. Then deserialized. You can mathematically prove they are non-null, but references cannot be stored like pointers. So now you have reference wrappers; which require pointers to implement. Or, you have an any and can prove it contains type X iff function pointer Y is set. One of the rules guiding C++ is to leave no room for a lower level language. 
Just use LTO.
I don't know what a mat is here, and if I don't, most people don't either
The title is quite misleading, it's a Rust library that exposes a C interface that is wrapped in C++. The value is in connecting all the little things that Rust and C++ do in the same or a similar way. I guess it's a very good guide how to expose Rust code to C++ though.
If you don't know what mat is then you don't need it.
I am totally ignorant so bear with me, but what is the problem with literally copying and pasting a header and a source file, isn't that what an include is anyway?
Did you log in for your one comment every two months to say this? Adults are talking.
I've read motivation part on the github page. Perfectly good reason to write something like this but I don't think it is good enough to actually make it into a library and share it (at least in its current state). Like you said "OpenCV has direct support for that", so I don't see any benefits in using some external code instead of OpenCV's native ffmpeg wrapper.
Diversity hires, that shit is everywhere. 
&gt; std::out_ptr is possibly the best thing Are you trying to replace this: ComPtr&lt;IDXGIAdapter&gt; adapter; EnumAdapterByGpuPreference(... IID_PPV_ARGS(&amp;adapter)); with this: std::unique_ptr&lt;IDXGIAdapter, ComDeleter&gt; adapter; EnumAdapterByGpuPreference(... IID_IDXGIAdapter, std::out_ptr(adapter)); ? Not only it is two times more to type, it is also error-prone as you have to specify IID manually. And I fail to see how `std::out_ptr(adapter)` is an improvement over `&amp;adapter`. Also I'd like to point out that `avformat_open_input` is an example of bad API. From documentation: "Note that a user-supplied AVFormatContext will be freed on failure". WUT? Should I clone my `AVFormatContext` before calling `avformat_open_input`?
It is a matrix I believe.
I didn't say the original reason isn't arcane (and quite frankly I don't care). I'm saying it is a good thing that "give me a member of object x" and "give me a member of whatever x points to" have different syntax as they are two different things (in particular because in the latter case I might have to check for nullptr). An overloaded dot operator might sometimes be useful, but overloading operator-&gt; on smart pointers would still be the right thing to do, even if we had it.
For C++ I recommend putting them in an extra named namespace before using anonymous namespaces/static variables, if you have name collision across your source files. I think and hope that modern C++ libraries have less static allocation. &amp;#x200B; For C it is a bit nasty. You would have to name your variables different. But this tool is and shouldn't be the solution for every library. ;)
That is absolute right. This cannot work. Please see my comment here: [https://www.reddit.com/r/cpp/comments/a2q34r/quom\_a\_single\_header\_generator\_for\_cc\_libraries/eb22cjb](https://www.reddit.com/r/cpp/comments/a2q34r/quom_a_single_header_generator_for_cc_libraries/eb22cjb)
Thank you. Now you can do it automatically. ;)
Can you explain what do you mean with this?
It would be easy to rewrite this in C++ since the tokenizer comes from a tokenizer I wrote in C++. ;) &amp;#x200B; But its written in Python because of the same reason why header-only/single header libraries exist: non-uniform build/dependency tools in C/C++. &amp;#x200B; Python has pip and it's easy to use. I would say that many modern developer environments have python installed. 
Thank you. :)
Your repository states that its built agains LLVM 893a41656b527af1b00a1f9e5c8fcecfff62e4b6, which is a fairly old version if I understand it correctly. Is it also possible to build concepts with newer LLVM/Clang versions? 
Hmm, please take a look this [example](https://github.com/Viatorus/quom/tree/master/examples/flat_structure). &amp;#x200B; Copy and paste doesn't resolve multiple pragma onces, include guards and multiple includes of the same file. It doesn't separate public header and source files with private headers in one file automatically.
That is a good idea for a feature. So you don't need to define a `#define LIBRARY_MAIN` first. But then there are two generated files, which would be acceptable. &amp;#x200B; Do you know libraries which have .ipp files?
Addresses. Both are abstraction for memory address.
You may also try https://github.com/MaskRay/ccls/wiki/Getting-started if you use Emacs, Neovim, Atom, VSCode, ...
I feel like const qualifying free functions is a low hanging fruit syntax that the language could easily use: `void pure_func() const;`
Dude, you are free to call everything by names you like! You can call cats 'dogs', you can call C++ 'rust', you can call red 'blue', and you can call cars 'horses'. You can call the earth flat for all I, sorry, "we" care. As for why you are being downvoted... You've been informed that everybody else has been using the name 'RAII' for this pattern. Instead of responding "gee, thanks, I didn't realize but I'll be sure to use the correct phrase from now on" you act like you own the naming rights. You invented a mountain of stuff, but apparently never bothered to check what the rest of the world was up to. You don't even know what a unique\_ptr is, or what a 'counted pointer' is named like! (hint: it's shared\_ptr). Your inventiveness and desire to teach others are admirable, but your choice not to learn anything new yourself or your reactions to people trying to fill the gaps in your knowledge - not so much.
Thanks for sharing the code, can you summarise the advantage of this approach over the opencv wrapper around ffmpeg [https://docs.opencv.org/4.0.0/d8/dfe/classcv_1_1VideoCapture.html](cv::VideoCapture)?
&gt; **”** Of course, maybe you are referring to the client simply creating their own logger instance without any of the thread-safe shared instance caching at all. Yes, with respect to logger objects. Sink objects (that the logger objects send completed records to) can have different requirements. E.g. there can be a rotation policy for a disk file so that it doesn't increase in size indefinitely, and that behavior should better be the same for all loggers using that sink, which implies more persistent sink object configurations. &gt; **”** That works alright until you need to plumb your logger object all throughout your application … Providing globally safe access to a globally initialized singleton such as a logger is, uhm, not rocket science. However, designing a logger so that this sharing is not necessary, isn't rocket science either. E.g. Boost provides thread safe loggers for the case where a single instance is used by multiple threads, but ordinarily one will use the non-thread safe loggers and just instantiate them wherever needed, because the sink objects that they send complete records to, are thread safe. &gt; **”** because you can't make more than one with the same parameters. Identifying logger objects by their set of parameters, sounds very much like dynamic type checking. 
If I understand the reference implementation correctly, there is also the potential for subtle breakage with some usage patterns due to lifetime extension, i.e.: if (GetSomething(std::out_ptr(p)) &amp;&amp; p-&gt;IsSomething()) The destructor of out_ptr propagates the received object to p, but is delayed to the end of the full expression which then breaks the dependent call. This isn't very intuitive for out parameters. 
&gt; Because a const function cannot have any side effects it does not make sense for such a function to return void I was just wondering about this - what about functions that throw exceptions? Such as void test_if_params_valid(int a, int b, int c) __attribute__((const)) { if (a&lt;0 || b&lt;0 || c&lt;0) throw "whatever"; }
For a moment my hope as up that someone actually made C videos.
The main vcpkg maintainer gave a talk on cppcon and had a great comment on that: If fully want a stable ABI, go all the way and implement a C interface don't do half things. 
`std::out_ptr`'s primary motivation is not for just replacing `ComPtr`. It's for making a whole class of smart pointer types place nice without overloading the addressof operator, which is unilaterally considered a very poor idea and the only reason why the standard library has to aggressively apply `std::addressof`. Obviously we are not going to get rid of the operator, but more and more libraries with smart pointers are coming out. Furthermore, the code difference looks "worse" for `ComPtr`, but makes interoperating with `unique_ptr`, `shared_ptr`, and upcoming `retain_ptr`/`unique_resource` seamless and with less code. Regarding `av_format_input` being bad API: yeah, absolutely, I wouldn't want to work with that kind of code. But it's there, people build applications on top of it all the time, and that's the choice being made. We can either snub our noses at it (just like we could snub our noses at `ComPtr` for overriding the addressof operator and leave all the other smart pointers out to dry), or we can bridge the gap. I'd much rather bridge the gap.
I've been using 18.04 with docker on gitlab for months now. Anything docker-based should permit it (modulo host kernel version mismatch issues?)
This single header will include all the required headers
My personal understanding is that, the primary reason to throw an exception is there is a [fault](https://en.wikipedia.org/wiki/Fault_(geology)) between the invariant (assumption) of a scope and the environment (reality). A function cannot be pure if it depends on a possibly changing environment.
C++ videos about C would make good episodes. You know, C–C++ interoperability, C–C++ compatibility, stuffs like those.
Don't think so. Some boost TMP-heavy headers cause dozens of seconds slowdown for each TU they are included.
Even on Windows, XML and JSON streams should contain UTF-8 data, not a stream of wchar\_t. The first C++ API that guarantees shortest round trip of floating point values for byte oriented stream handling is not useless, it is a fundamental building block for many applications.
Business as usual, nothing extraterrestrial. 
That would be a contract violation, which is different from throwing exceptions. Except in special cases, you don't write a function such `test_if_params_valid`, i.e. you don't lift contract violations into exceptions. As for the attribute, it is effectively UB to throw exceptions inside a `pure` or `const` function. Exceptions can be considered side-effects.
Yeah, this isn't very intuitive, but I haven't quite written code like this. It's a common idiom so I'm going to need to bring it up to the Powers That Be to see how they feel about it.
It should be `cv::Mat` to be precise, and it's OpenCV's image &amp; matrix format.
His name is Torvalds. You made same mistake in the title too.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a2zc9h/compile_mupdf_for_android_arm_plafrom_from_source/eb28isz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
A strict subset of C++ would be very useful in the kernel. Forbid the things you don't want, and permit a select number of things which would provide compelling advantages over C (RAII, vtables, stricter type checking). While he rails about exceptions, they are optional. Ignore them. Ignore the standard library. Ignore excessive use of templates, or forbid them completely. He's right that C++ is horrible. So is C. But they are also powerful and flexible, C++ even more than C. It would make sense to take advantage it where possible.
While I love C++, I would hope that extraterrestrials would have better languages.
It's basically just a container for an image, although I think in its simplest form it's just a matrix of numbers. OpenCV provides a lot of image operations using Mats, including decoding, writing, drawing, edge detection and image recognition. A lot of third party libraries (Tensor Flow and Tesseract off the top of my head) support using images stored in OpenCV mats in their operations. To summarize the summary, I'm providing a way to get images from ffmpeg, which can read pretty much every video format ever invented, into an AI library, in about 2 milliseconds per image on my test system. This project includes a fairly portable build file; it should build on Linux and OSX if you have the libraries it needs, though I won't vouch for windows. It also provides a couple of very basic unit tests for timing and to prove it's working. The build generates a small test video using ffmpeg and uses it in its testing, and saves a few images from the video out to png file as part of one of its tests. If I actually want to verify the pixels are the same ones in the test video, I could actually use OpenCV to do that, and may at some point. It only takes a few lines of code in OpenCV to do that.
There are really not a lot of well-documented examples of opening and reading a file using ffmpeg, which was another motivating factor. The examples directory that comes with ffmpeg has several moldy old C examples, all of which do so in a variety of conflicting ways. I want to get down as close to the metal as I can with a small, self-contained object that does everything I need it to, and which can be easily tested for memory leaks. Anything I do in the future that needs a video source will likely use this. It should also work with the RTP stream from a wireless web cam I have laying around here somewhere, and one of my early projects will probably be to build a motion detector using that.
Hey someone beat me to the punch: [https://wg21.link/p1306](https://wg21.link/p1306)
Other than the educational aspect, the main object doesn't need to involve OpenCV if you don't want to use it. It just uses raw ffmpeg to provide image and audio buffers. I can build that in any direction I want to. Admittedly it's not a particularly compelling advantage to anyone else, unless someone's looking for a quick and dirty way to avoid having to rewrite all that boilerplate to open and read a file with ffmpeg.
You misunderstand me. Contract (precondition) violation happens *at the moment of entering* the scope of execution. What I call a fault happens *during* the scope of execution. That's why I emphasize the changing environment—it's a sudden change that cannot be checked before hand and the scope of execution cannot adapt to. And the impurity is more primary than the exception mechanism in the language—dependency on the changing environment is one of the textbook reasons a function is impure.
Hi Sorry to Hijack the thread but I see that you are the maintainer and the writer of the blog. Are there any restrictions we need to know before starting? I have a code that utilizes Boost, and other 3rd party libraries, will there be any problem building it for lambda?
Implement C interface for what? STL? How would you propose to do that and what would you expect? And C++ library is perfectly capable of upholding BC, but requires designing it with that in mind from the start (pimpl, no STL/3rdparty in public API, strict rules, etc.), see Qt.
That's an awesome proposal! Any idea where it is in the queue?
The guest mentioned a tool used to view performance test results. Did anyone catch the name of that tool? I'd like to learn about it.
Thanks
How often are you actually doing that for this to become a problem?
Why would I use some python script to integrate into my multiplatform CI? Especially where does not bring any benefit...
works well only if they do this style: void func(/* ... */)
Doxygen, works even if there are no doc comments - it can still create various dependency/usage/inclusion/inheritance/... graphs
How much time I have saved thanks to "find usages" and automatic refactors...
&gt; I wonder what he would think of using C11/17 instead of C89. I don’t know if anybody has proposed that. IIRC it's not C89 either. It's some GNU C fork which compiles only with GCC
surname actually
&gt; I even use snake casing for improved speed. Code runs faster when it has underscores. This is why we need concepts, they encourage proper coding style and \_s\_p\_e\_e\_d\_
My office has been using [boost format](https://www.boost.org/doc/libs/1_66_0/libs/format/doc/format.html) for at least a decade now. It accepts printf-like syntax (%s, %i) and lets you pass std::string into a %s argument. I guess we don't log enough that performance of logging is a problem, and don't do enough logging in customer-facing builds that code size is a problem. fmtlib is an interesting alternative though!
needs more examples
If you don't need a single header with integrated sources of your library you don't have to us this.
This is a good article, I love the humor you added too, makes it an enjoyable read. I would also add however that smart pointers in APIs also remove the ability for the end user to control how their memory is used. If you want to put your types on the stack or in a vector, you can no longer do this. What the best solution is I don't know, but we stick to C style interfaces and make smart ptr types with custom deleters to call the appropriate destroy functions. C style interfaces also allow the struct definition (which often requires many more header files) to be declared separately than the interface and save some compile time. 
\+fzf
What you call "fault" is typically called assertions (invariants at a given point in "time"); and still are different from exceptions. Invariants/contracts/assertions are meant to establish what the code relies on, exceptions are meant to signal cases where the function cannot succeed (invariants still holding). I am unsure what you mean by "sudden change". Exceptions have nothing to do (necessarily) with "sudden changes"; nor they necessarily come from the environment at all. Also, I don't see how function impurity textbook definitions have anything to do with what I said about `pure`/`const` and UB.
Pure functions don't have state silly
&gt; Would something like int f(int, int) pure { /* ... */ } improve performance by helping compilers? By what margin? Yes. I'd guess the margin of improvement is very context sensitive &gt; Do pure functions help with aliasing optimizations? Or only argument types? I'm not sure I follow your question &gt; Has something like this already been proposed? If so, what happended with it? I think so, not sure though. GCC has had support for pure functions for a while and optimizes nicely for them &gt; Are there other potentially useful __compiler_specific attributes/extensions that could be standarized (like recent addition of [[likely]])? Don't know
Isn't shared_logger(const shared_logger&amp;) = default; premature pessimization? It look like you are trying to fight a language feature (use after move) when all good practices say "don't use after move". And this line prevent the compiler to do any optimization on all the valid case were a move could have been used.
took me a while to understand, lol
\&gt; He just doesn't want C++ in either Linux Kernel or Git. That's really a good idea, you don't want C++ virtual methods to be used to manage page faults. &amp;#x200B; But you do want them to manage VFS calls, which is exactly what the kernel has. Only because it's in C the implementation is done by hand. Nothing about C++ makes you use virtual functions in inappropriate places and nothing in C prevents it. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; Has something like this already been proposed? If so, what happended with it? At least P0078 and IIRC there was another one more recently about adding a few more attributes but I cannot find it (and not sure if they included `pure`/`const`).
He doesn't have issues with C, he has issues with GCC authors because he doesn't understand well enough how modern optimizers work. He, like many people assume that the compiler authors have the most pedantic reading of the rules they can get then hand code things in to fuck over hapless programmers. &amp;#x200B; What actually happens is that the optimizer has a big list of potential reductions it can make, and a big list of language rules. It then shoves them all into a big theorem prover to prove that a reduction yields the same result given the rules. It then just crunches on that repeatedly testing reductions and applying the ones that are valid. &amp;#x200B; What a lot of people really really don't seem to get is the theorem prover is not human and does not make human decisions. It cannot tell what is sensible and what is not. The only way for it to "know" is if someone goes and special cases every way that people "reasonably" break the rules. No compiler writer will ever catch them all. &amp;#x200B; What he's whining about is that he broke the rules and the compilers didn't put an special case into the optimizer just for him. What's particularly silly is that he's happy with the optimization in general: assuming that types don't alias. What he really wants is for the compiler to assume that the types don't alias unless it can prove that addresses do alias. &amp;#x200B; That's really very odd, because it means that progressively more and more code will become valid as the alias analysis improves. It's also very back to front because normally the compiler assumes everything can alias unless it can prove otherwise (using the language rules and data flow). &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Why would you not use it in your CI? Especially since Python is multiplatform...
[IOKit](https://developer.apple.com/library/archive/documentation/DeviceDrivers/Conceptual/IOKitFundamentals/Features/Features.html#//apple_ref/doc/uid/TP0000012-TPXREF101), the device driver framework in macOS, uses a restricted subset of C++, which disallows exceptions, multiple inheritance, templates, and RTTI.
As a side note, why should we have to annotate this? Can't we rely on optimizing compilers to detect which functions are pure? Unlike a const qualifier which I use because I want the compiler to enforce it, a pure qualifier is largely there for speed. It doesn't help me write the function correctly. 
At the risk of sounding really dumb - how do you find these proposals? I tried to find P0078 via googling `site: www.open-std.org P0078` but it comes up with nothing.
It's not dumb. The link to know is https://wg21.link. That provides a description of all the things it can do. Specifically, you want https://wg21.link/p0078
There are some problems with autodetect: - any memory allocation will make your functions impure - same with user handling of asserts (we have assert you can hook your handlers to - different one for manual QA testing, different for automated testing, ...) - I have the same suspicion about more stuff, e.g. float intristics - no (easy) way to detect which function is pure when it is defined in different translation unit I would love to have pure functions too. Not for speed though (we __forceinline the shit out of our code anyways), but for various static analysis tools (it would be much easier to reason where there are bugs and unused variables)
Perfect - thanks!
yes, in a perfect world, or in years from now. today, telling the compiler a function is pure is the best there is and it works nicely, gcc optimizes quite a lot (jason turner released a video where he shows this).
Wait -- of course hitting the heap makes your function impure. You can't expect the compiler to automatically verify that you didn't leak that heap memory! 
&gt; It doesn't help me write the function correctly. Well of course it does. If you think your function is pure but actually isn't that's kind of a problem, and your compiler can't help you with problems of that sort if you don't tell it you were expecting the function to be pure in the first place. Silly example, ``` pair&lt;int, random_generator&gt; totally_pure_random_number(random_generator gen) { return {globalRandomValue, gen}; } ``` -- again, that looks silly, but without compiler support it's not that difficult for nontrivial examples to boil down to something like this. That doesn't even go into purity across translation units.
Why do you say 'years from now'? We have LTO today... Compilers can and do figure this out for you.
\&gt; Would something like \`int f(int, int) pure { /\* ... \*/ }\` improve performance by helping compilers? By what margin? Problem is what do you do if it isn't pure? If it is UB that is introducing a class of error that is new which makes adding the feature hard to digest as a language designer, you are setting your users up to fail. If it is compiler enforced you have two bad options: be so restrictive on what you can do in a pure function as to make them worthless (common examples being how do you get the square root of a number given \`sqrt\` sets \`errno\`) or you annotate everything with \`pure\` which is a bad path they have thought about extensively. \&gt; Are there other potentially useful \`\_\_compiler\_specific\`attributes/extensions that could be standarized (like recent addition of \`\[\[likely\]\]\`)? Only if everyone agrees on the "what if they lied" part.
Did you try it?
If an app, say, reads the data from stdin, applies some math to it and dumps to stdout - yes, that's probably not a big deal. A typical end-user app, however, accesses the filesystem, uses standard UI controls, reads from / writes to registry etc. All those communications with the outside world use wide chars and happen on different abstraction layers (and possibly even in different components). Yes, it's definitely possible to ~~waste your battery, make the room and the planet warmer and increase the entropy of the universe~~ convert the strings every time, why not, especially with a mantra like "this will make porting to linux easier"... Or just use wchar\_t and call it a day. &amp;#x200B;
Hopefully modules will give us both. :) Speed and easy to include files.
&gt; Designing a C++ build system is hard. Let’s not make it harder. Amen!
Why not let the compiler check if a function is actually pure and give an error otherwise? Pure functions are not only relevant for performance, but also make it easier for the programmer to reason about a program.
1. The VERY FIRST sentence in my original post states that this is not new to most programmers, the concept at least. What might have been interesting to some was some ideas for various other ways to use the concept. 2. Did I claim anywhere in that article that I know anything about the standard C++ libraries? No, I did not. 3. I never said I owned the 'naming rights'. I said that I had been using my name equally as long, longer than some folks around here have probably been alive, much less programmers, and hence I called them what I call them. It's not my responsibility to inform people otherwise. I also said in the THIRD paragraph that other people may use other terms and that Janitors was MY term for them. 4. Does what I know about the standard C++ libraries in ANY WAY invalidate the point I was making, which is that there are a lot of ways to use this concept? No, it doesn't. 5. Does RAII even actually describe more than a few of the examples I gave? No, it doesn't. And everyone just keeps ignoring this. It only vaguely relates to the bulk of the examples, so why would I use the term for those? &amp;#x200B;
I _seriously_ doubt your GUI applications are anywhere in the general vicinity of being efficient enough for string conversions to become an in any way noticeable overhead.
Apparently it's targeting C++20, [see](https://www.reddit.com/r/cpp/comments/a1tmni/trip_report_c_standards_meeting_in_san_diego/eawff5r/). I hope it gets in.
If we had infinitely fast systems and infinitely smart optimizers, then leaving all the work to the optimizer would indeed be fine (although if we had them we wouldn't need optimization) as it is, optimization is often a tradeoff between compiletime and speed gains and leaves plenty for the human do. However, if this ever gets standardized I'd very much hope that the compiler would verify my assessment of the pureness of my function and not treat it as a "trust me" point.
Your function would be impure even if you returned the memory. You are reading in modifying global state.
Why would a compiler enforced version be any more restrictive than the UB version?
A virtual object model is very different than C++ virtual functions. C++ virtual functions break a pile of assumptions about the type. Once you have them, you must have RTTI. Your layout becomes so undefined that piles of sane operations are banned. And you are locked into exactly what the 1980s C-with-classes C++ thought would be an efficient and effective vtable solution. Then there is the strangeness that results when you have virtual inheritance, and how the tables get messed up when you overload members in some compilers. Implementating your own vtable in C doesn't carry with it that baggage. Your data is still plain old data; it can be memcpy'd, memset'd, etc. There is only the RTTI that you write. The features of your vtable implementation are exactly those you need, no extra, for your purposes. And you can add features that C++ lacks, like the ability to patch vtables at dynaically at runtime or on a per-object basis. Heck, you could split the vtable from the object. This is one of the reasons why I am excited about the metaclass proposal. With metaclasses, we'll able to write (in C++) alternative object models, while having the "client" code be as easy to write as C++ types. IKernelDriver foo { virtual void print(); }; KernelDriver bar:foo { void print() override {} }; The metaclass `IKernelDriver` can rewrite the body of `foo` to be a pointer to a vtable of C-style functions, and write a new `print` method that calls through that vtable. `KernelDriver bar` can inspect its bases, find that interface, wire the call to `print` in `foo`'s vtable to calling the `print_impl` implementation method in `bar`. To the end user this looks just like the C++ object model, but instead of everything being defined by the language, it is defined by C++ metaclass code. So the output types `foo` and `bar` are plain old data, the layout of the vtables in memory is defined, etc. There are many object models out there, C++'s is just one of them, and the others have advantages. Objective C's where classes are just another kind of object. Lua's. Java or C#'s with its reflection richness. Python's. Perl's. Features of all them could be implemented in C++ using these kind of techniques. Or, as noted, whatever OO features they are using in the Linux kernel driver. 
A agree with this list. I would add "leadership &amp; project policies". In academia (where I am too) it is often that people just do what they like/want the way the like/want. In such a project, it can really lead to messy code and lots of time wasted. I have found useful to meet with core developers and define project "rules" that we need to follow. Such as what can pass the code review an be merged in the main repo, an what can't, do we need 100% code coverage or not? What should commit messages look like? We use clang-format, define the style together. Do we want "code that works" or do we have more strict criteria about code quality and expressiveness, what are the criteria? I found it useful to write all those project choices in our project wiki so that we can remind ourselves we have, someday, all accepted these rules :) &amp;#x200B;
&gt; Problem is what do you do if it isn't pure? Throw a compiler error and stop compiling.
What are the C++ specific improvements?
The podcast for this episode is now available: https://cppchat.fireside.fm/44
For Preview 1, we have some productivity features: IntelliCode and Live Share support for C++ developers. IntelliCode is basically IntelliSense completion powered by machine learning, highlighting five suggested results at the top of the completion list. Live Share lets you collaborate in real-time with a coworker on your codebase. You can edit and navigate code together and even debug. The New Project Dialog UI has also been updated, which also impacts C++, and there is a new start window for VS to help you get to your code more quickly. &amp;#x200B; Some blog posts will be coming out on the Visual C++ Blog: [https://blogs.msdn.microsoft.com/vcblog/](https://blogs.msdn.microsoft.com/vcblog/) The Live Share one is already out. &amp;#x200B; By the way, this is just the first preview of VS 2019, so there is more stuff coming down the pipeline later... :) &amp;#x200B;
This is more about mental overhead and code overhead than performance overhead. Also, "no work is less work than some work" - this is C++ after all.
That's all UI stuff right? Is there anything related to the C++ programming language, such as new language support?
&gt;IntelliSense completion powered by machine learning So effectively the guesses are going to get better as we use them, meaning I'll see less completion hints for stuff from large Windows and 3rd-party headers and more stuff from my own code? That's a pretty nifty and nice QoL improvement, tbh
Okay, I could imagine some scenarios where I wish to exempt a function from its enclosing scope. To be fair though, we already know that we should minimize the number of global variables we have. Because of this widely-known principle we have well-known techniques for reducing the number of things in global scope. 
Sure, you could. If you look at the rules for constexpr which achieves a strong version of this, you aren't allowed to do much. You can't call any non-pure functions, you can't define any user types, the heap is way off limits. It's quite restricted. I would suggest you reduce the number of global variables in your program. 
Does live share work on a non-internet connected network? If I remember correctly it originally required a handshake to a web service to set up the connection. Looking forward to smarter intellisense!
&gt; IntelliCode is basically IntelliSense completion powered by machine learning Why don’t you guys just buy Whole Tomato Software at this point?
Another big improvement in VS 2019 Preview 1 is the out-of-proc 64bit debugger. From the blog: &gt; and better performance when debugging large C++ projects; thanks to an out-of-process 64-bit debugger. More on this coming soon on VCBlog
Is it binary compatible like MSVS 2017 with MSVC 2015?
Totally understand. I was more than happy to let Zach push his `flat_map` proposal and drop my own since I don't have the constitution for what I feel is an incredibly archaic and excessively process-/ceremony-heavy ISO process.
Aside from what /u/sphere991 said, there's https://wg21.link/index.txt which gathers all the paper numbers and titles together in one location. If you don't remember the paper number, you can often find it from there.
Which was the brunt of his second paragraph. :) C/C++ have a lot of design issues right now that make anything but the most trivial/useless function impure. The basic core C and C++ math libraries are impure due to some legacy questionable design (`errno` global values). Until that's fixed in some fashion, having a language flag that enforces purity basically means you'd have a useless language flag. :)
It wouldn't be _more_ restrictive per se. The UB version would allow you to still write a lot of functions that _technically_ work but which _shouldn't_ work by the standard, while the compiler-enforced version wouldn't allow you to write those. The ultimate sentiment he's making is that there'd be exceedingly few pure functions you could usefully write which wouldn't be UB due to the core C library being impure even in some of its simplest low-level math routines; those functions can't be called from a pure function without UB (but likely would Work Just Fine(tm) so long as you don't actually care about `errno`) while compiler enforcement would mean you just couldn't write those at all.
The new toolchain isn't in preview 1, but when it's released it will be binary compatible.
If you want to do logging with `{fmt}`, you should consider using [https://github.com/gabime/spdlog](https://github.com/gabime/spdlog), which is not only efficient for logging, but also uses `{fmt}` for message formatting.
It's not about "referencing things in enclosing scope" or even global variables at all. This was just a simple example of a function that _says_ its pure but is actually not (depends on global state).
C++ also lets you write portable programs which you can throw right out of the window if you use `wchar_t` or worse, `wstring` anywhere.
Constexpr functions aren't pure - not even in c++11. What I meant was that the compiler should enforce that a function which is declared pure is actually pure instead of just trusting the user.
are there consequences for C++ development?
thanks for the link! dr. stroustrup is absolutely incredible... i've been working with him over the last month or so and it's been a dream come true.
Considering what kind of crazy optimizations modern compilers do based on the assumption that UB doesn't happen, I'd certainly not accept any such function that deliberately makes use of unsanctioned UB in my codebase.
I actually think this is pretty cool. I like that Microsoft is treating C++ as a first class citizen. I actually tried to write an UWP C++/WinRT App and found the documentation pretty lacking. Most (XAML) things are only shown for C# so this is quite a great ressource to look things up, how is it's done properly in C++. 
Does VS support bit field initialization(C++ 20 feature I think) ? Not being able to do this is a constant source of irritation-- bool \_someBool:1 = false; 
You can use [[gnu::pure]] or [[gnu::const]]. [[gnu::const]] is a even more strict restriction than *pure* because it additionally prohibits the function from reading memory except for constant global variables. I've used [[gnu::const]] in math functions with great success in reducing code size when compiling for an AVR embedded platform. Note that these are essentially exactly the same as __attribute__((__pure__)) or __attribute__((__const__)), but nicer looking in my opinion and possible more cross-compiler compatible.
And be accused of Embrace-Extend-Extinguish? I think not!
Right. I think the only way to word things properly without changing the library is that writing to `errno` is allowed in pure functions, but reading `errno` in or after a pure function is called but before (re)setting it would be UB. Which is the most likely/realistic case of what calling these math functions today from a pure function would be: they _might_ set `errno` but you just couldn't rely on it because of optimizations assuming no impure side effects, and you certainly couldn't rely on it being set according to the functions' standard behavior (e.g. it may be set to intermediate values that shouldn't be exposed or may be left unchanged or really anything).
&gt;So effectively the guesses are going to get better as we use them, meaning I'll see less completion hints for stuff from large Windows and 3rd-party headers and more stuff from my own code? That's a pretty nifty and nice QoL improvement, tbh I should clarify a bit more. Right now the model is built off a few hundred real world projects and can help with things like figuring out how to use STL functions and types in the right context. This is just the initial version though, so I think it will be further improved in future releases. I believe we have a blog post for IntelliCode scheduled for tomorrow on the Visual C++ Blog. In the meantime you can see it in action in this video (along with other C++ stuff available in Preview 1: [https://www.youtube.com/watch?v=Y5Els11sY1A](https://www.youtube.com/watch?v=Y5Els11sY1A)
There is always lots of compiler work being done. Since I focus on the IDE itself, I just asked someone from the language team to comment with some updates there. 
&gt;Main problem with #pragma once or include guards is why they're needed at all. Why doesn't the compiler just &gt; &gt;not &gt; &gt; include files more than once? because multiple includes of the same file might be what you want. I'm thinking about SDL, wich uses \`begin.h\` and \`end.h\` to set some local defines, and some padding fuckery
Nice! It would be really cool if this could be used as a Qt Widgets/QML "backend". But I guess that's mainly up to the Qt guys... and will very likely never happen.
That's surely a good thing. The standard requires compilers to ignore unknown attributes.
Cool! There's not yet enough though to make me install the Preview. Live Share has been there before (as a plugin or something in VS 2017). IntelliCode, okay maybe - but is it in Community or only in Enterprise? And then again I use VAX, which is pretty much perfect and lightning-quick already. Other than these, not really anything that would make me try it yet. But it's still really cool you guys are making it available now. And I'll for sure be jumping on the train once the next preview (preview 2 or whatever) is out.
https://youtu.be/rX0ItVEVjHc Mike Acton's keynote from CppCon 2014
Regarding Live Share, the C++ support for it is new. IntelliCode is available for Community as well as Professional and Enterprise SKUs. Also can confirm Preview 2 will have more features coming in... :)
Opinion: I wish API designers of non-graphics domains would take cues from how graphics APIs work. They are honestly the best example of communication across async boundaries, just by the sheer number of requirements and users. I've been around the ASIO block quite a bit, and honestly, the biggest problem I have is that the "socket" object is the lowest level construct you have to work with. What I really want, is the analogue of MultiDrawIndirect in networking land. It'd be nice to write to a flat buffer and in a separate buffer a list of sockets I would like to dispatch data to. The inverse occurs for reading data. Buffer overflow is handled based on options (either allocate and mark the old one as "garbage," or block until the buffer is available for writing). If sockets close (which is a possibility no matter what api you use), status codes are written to the read buffer. Reads need to be pumped at the user's discretion to keep buffers empty for a high-perf server, or can be waited on with a conditional variable/semaphore. Now you can implement a "socket" abstraction yourself, but over cache-friendly code. You don't have this madness of a shared_ptr per socket, mutexes everywhere, and you actually have a chance of writing a "zero-copy" handling mechanism. Furthermore, you have more flexibility in farming work out to worker threads, handling it all in one thread, etc. On a given frame, you can reason more easily about current load and statistics without needing more expensive aggregators. If this is, say, video data, I can transfer all the data to the GPU for fast video decoding. If I'm encoding data to upload, I can write from a compute shader to host-local memory (which is then uploaded directly). This lack of existence of type of design is the main reason why I haven't bothered holding out for executors and such very much. The leaky abstraction is that your OS uses epoll/io completion ports and mapping it straight to some OO interface skips steps that prevent a better optimized design.
Can we please, please finally get an option where the console window doesn't close after program termination?
We have added support to this for MSBuild projects back in 15.8 for C++. The console window should stay open by default when the program terminates while running the debugger. Are you experiencing different behavior? It currently doesn't work for Open Folder projects, but we plan to replicate this behavior there as well. 
That is great. I wasn't aware of that, as I almost exclusively use open folder these days, but will test it as soon as I'm on my dev machine again. 
If only all portability issues were about data types.
Cool! Btw I could swear I saw a demo of Live Share a few months ago and it was C++... I even downloaded the extension (but never really tried it). Glad I didn't waste the time then since it really wasn't obvious that it didn't support C++ yet! Looking forward to all the stuff that's coming :)
Btw, when/how will it pop up in the Visual Studio Installer? Still showing me 15.9.3 Preview 1.0 there (I did just restart the installer). Do I need to do anything or just wait a couple days longer?
Microsoft is the only big desktop/mobile vendor left that still supports C++ as first class citizen for the whole stack. Still it appears that the uptake from C++/CX, now C++/WinRT, has not been that great outside Redmond, given some remarks during the C++/WinRT sessions at BUILD.
This year's CppCon had a good talk about DoD with an in depth look at a problem solved with it. https://www.youtube.com/watch?v=yy8jQgmhbAU&amp;t=1s
The best way to optimize C codes is to implement better algorithms. As the largest impact on memory is due to the algorithm applied. Try to figure out the best tradeoff between space and time requirements in your selected algorithm. A good programming practice is to keep small functions and simple. This can be achieved by limiting the lines to a small amount and calling a function whenever the line count exceeds that limit. A very sweet trick to make a C or C++ code faster is by inlining a common function as a macro. As macros are preprocessors, that function will be preprocessed even before the main code itself runs. But don’t overdo this or the program will take longer to be processed. Another way is loop unrolling in which by increasing the lines of code inside the loop you actually reduce the number of times the termination condition is checked. Or when possible simply reduce the overall number of loops. One should use pointers only when they know what they are doing as un-optimized use of pointers can easily chock the main memory dry if used on a large scale. There are many other ways to optimize a C or C++ code. The best way to learn about them is by joining special academies that teach programming at a professional level, such as “[*Holberton School*](https://www.holbertonschool.com/)”.
&gt;Cool! Btw I could swear I saw a demo of Live Share a few months ago and it was C++... I even downloaded the extension (but never really tried it). Glad I didn't waste the time then since it really wasn't obvious that it didn't support C++ yet! &gt; &gt;Looking forward to all the stuff that's coming :) I believe we did early demos at CppCon and Pacific++. Those were previews of the experience though, it was not publicly available yet for C++ developers. As of today though, anyone can try it out. &amp;#x200B; &gt;Btw, when/how will it pop up in the Visual Studio Installer? Still showing me only 15.9.3 Preview 1.0 there as "Available" (I did just restart the installer). Do I need to do anything or just wait a couple days longer? I am not 100% sure, but it sounds like the VS 2017 Preview channel in the installer doesn't move you up to VS 2019 automatically. You can however install VS 2019 Preview from here: [https://visualstudio.microsoft.com/vs/preview/](https://visualstudio.microsoft.com/vs/preview/). It will show up as another instance of VS in the installer, alongside any existing installations you have. The preview is available as of today.
Slightly off-topic, currently Intellisense has a very hard time with the projects that I work in and the autocomplete results are almost always incorrect or incomplete; this means that 95% of the time I type out a identifier I have to escape out of the suggestion window otherwise hitting space or any other punctuation will replace it with the incorrect autocomplete result. I've played around with the settings but I can't figure out how to disable the autocomplete-commit behavior aside from just disabling Intellisense completely. Am I doing something wrong? How do I get this feature to behave?
&gt;Does live share work on a non-internet connected network? If I remember correctly it originally required a handshake to a web service to set up the connection. I believe that is still the case. 
When it *is* feasible to run tests lots and lots then [there are some tools](https://bors.tech/essay/2017/02/02/pitch/) that can help pointing out when delayed changes would end up breaking the trunk when all applied together. Which can happen because codereviews are not instantanious.
They have computers that use alienese as their native instruction set. 
Hi qartar, for the inaccurate / incorrect IntelliSense, if you run into these issues again, could you file a bug on our Developer Community website? [http://developercommunity.visualstudio.com/](http://developercommunity.visualstudio.com/). We would love to check it out. Regarding IntelliSense commit behavior, you can configure it in Tools &gt; Options &gt; Text Editor &gt; C/C++ &gt; Advanced (under the IntelliSense dropdown). You can control which characters cause commits under "Member List Commit Characters". I think a space by default does not trigger autocompletion. You can also take a look at "Member List Commit Aggressive". If it is set to True, pressing Enter will commit the result. You can also turn off completion for a few specific scenarios. 
When it comes to performance, I guess it does not matter: with the LTO enabled compiler shall detect automatically which functions are pure.
If this ever happens, I'm going back to Qt. 
STL improvements (not sure if they'll all be in Preview 2): * More parallelized algorithms: `is_sorted()`, `is_sorted_until()`, `is_partitioned()`, `set_difference()`, `set_intersection()`, `is_heap()`, `is_heap_until()` * Many bugfixes. * `vector` and `variant` runtime performance improvements. * Compiler throughput improvements powered by `if constexpr` even in C++14 mode. * Floating-point `to_chars()` improvements: `chars_format::fixed` is 60% faster (thanks to Ulf Adams suggesting long division), `chars_format::hex` is implemented (both shortest and precision). Decimal precision is the only part not yet implemented. * **We applied clang-format to the entire STL!**
That's nice, thanks. There's one issue with it though: if you don't close that window after the program termination and start a new debug session, it will reuse that window *without bringing it to the foreground*, which can be quite confusing - "I've just started my app, where is it?"
This book is more concrete than most resources: http://dataorienteddesign.com/site.php?postid=138
Or an integrated terminal, like other IDEs. But I know there are a few extensions for that. 
You are on a HighDPI display and the application does not support HighDPI and is being scaled. You could lower the display scaling back to 100% in the display settings, but it will be smaller. &amp;#x200B;
Help pls...
So create a set of pure variations as to not break backwards compatibility. I read his second paragraph, I just don't agree with it. If something marked pure does impure things, fail to compile.
There's also Qt Framework and the company behind it.
What made you abandon Qt?
I guess I'll just stick with this. Thanks for the help.
Found this some weeks ago: https://savas.ca/nomad ECS on Game Engine using DoD 4.4 to me clearly shows how C++ is confusing and unproductive nowadays (I'm hoping Jai helps), but the overall posts are nice
Not that person, but I abandoned it because of the sheer overwhelming size and invasiveness of it. Code written in a Qt project usually winds up wholly dependent on Qt and requires translation to use elsewhere. And code not written for a Qt project often requires significant adaptation to plug into the framework.
&gt;Properties &gt; linker &gt; subsystem &gt; console should keep the console open. That's how I do it now, at least.
Honestly just use a better IDE and compiler, that one hasn't been updated in ages. Visual Studio is free, if it's too big for you then try Qt Creator. 
But Qt Company is not really a vendor by themselves. At least not in the way /u/pjmlp probably meant. They don't own any OS/platform they support.
This is actually a similar thing I'd been thinking. Some years ago I had replace a higher-level networking API I wrote to work in a bulk fashion - and actually modeled a good deal off of how DX/Vulkan are designed - for performance reasons. I replaced the equivalent of a bunch of individual `Connection` objects with a single `ConnectionManager` object, and replaced all the individual `connection-&gt;send(data)` kinds of things with `connections.send(connection_id, data)` equivalents, where the `connection_id` was the opaque cheap handle returned when accepting or creating connections. That API change ultimately allowed me to make single CPU perf better, allowed me to multi-thread the expensive part of the underlying protocol serialization far more intelligently than they had been, and ultimately actually ended up being an easier API to work with for end-users. It was one of my first lessons in how building APIs that work in bulk operations can be both faster and easier to use. It's actually also something I think about a lot when all those "OOP is terrible" and "data-oriented forever!" posts come up. Specifically, I think OOP is great, it just has to be used in the right places and not shoved into everything. Going with your graphics comparison, `ID3D12Device` or Vulkan's `VkPhysicalDevice` parallel are very OOP in design and usage while items like resource handles are not. The OOP patterns work wonderfully at higher layers where composition, polymorphism, abstraction, and encapsulation have high utility and low cost, but OOP patterns exhibit all the performance problems people talk about when used in places where we didn't really need its benefits in the first place. I'd add further that the graphics APIs can teach some great lessons in doing monadic-style error handling (without actual monads).
What do you mean by that exactly? UWP has been a supported Qt platform for some time.
Great thing about DoD is that you don't need to use it for a whole game. It's just a way of thinking about problems and structuring your solutions. You can use it for _pieces_ of a game and still get a lot of great benefits. I bring that up because it's useful to know that you can experiment with DoD in existing projects without needing to build out a whole new project, or that you can adapt it incrementally as you learn. I'd actually caution against trying to stick to DoD for a whole engine/game until you get some practice with the ideas in simpler and smaller pieces.
But in LTO mode, the compiler's already going to look at all functions and attempt to identify purity. It's not a very expensive check. In non-LTO, it'll likely look at every function in each TU and optimize each TU based on that. The only advantage of the attribute appears to be for functions outside of a calling TU in non-LTO compilations.
Another option: put this at the end of your main ``` std::cin.get();```
Agreed on the oop vs dop points. People swing way too hard one direction or the other. I think of it in terms of plurality. I want to use classes to describe my data pipeline. I don’t want classes to describe my data, and then more classes to describe those classes. The thing that C++ programmers have a tough time with is that because RAII is a thing, we decide to wrap every resource into it’s own snowflake, instead of judiciously applying it where appropriate. Taken to the extreme (which seems to be the recommendation in vogue these days) everything cleans up nicely but is individually tracked/managed and is a nightmare for the person trying to optimize it all (which is more often than not what I end up doing). 
That's huge! We deal with VS debugger crashing due to OOM often when debugging Unreal Engine 4, with loading all symbols along with running a few of the more memory hungry extensions. We're always carefully managing extensions and which modules to load symbols for. Finally having a 64 bit debugger will save us so much hassle. 
Curious, what clang format rules did you use? LLVM? Custom?
&gt; but drivers and the file system essentially simulate them so I’m not sure that’s a good reason to reject them in the kernel I suppose you need something like C++ ABI standard, before suggest to use C++ for drivers &lt;-&gt; kernel, vfs &lt;-&gt; fs interfaces.
&gt; A strict subset of C++ would be very useful in the kernel. Forbid the things you don't want, Too many contributors, to control usage of strict c++ subset you need some auto tool for checking of usage exactly the chosen subset. Plus ABI, you want allow to build 3thparties the drivers out of the tree and then load them without problems.
It's a joke because it plays on two meanings of state: the internal state of a function (that a pure function cannot have), and the state of proposals to make pure functions standard.
You just answered for the both of us.
Am I the only one to think that reading global variables means it's not really pure? I'd argue pure can only depend on `constexpr` globals.
They are not only for optimization, they are for your own sanity. If a function is pure, you don't have to worry about it messing up your program state. If you can structure your code around as many pure functions as possible, you can reduce the thinking required in many cases.
Do you use another framework instead?
I hope at least one of the preview releases will be binary compatible or we will be unable to test the builds and report major issues like compiler regressions ahead of the official release.
Only problem with const is that you cannot dereference pointers, and passing arguments as const T&amp; is not uncommon...
I think they mean to translate QML stuff to use this underneath, not draw everything like Qt does. 
There should be more.writing complex and extremely reactive UI is difficult in many cases and CPP does the job pretty well
Nothing to contribute but this comment thread was a joy to read. Balance of oop v dop, resource management etc. Wish this was the common thinking.
Creepy photo
Yea I’ve been following along since /u/kennykerr announced it a couple years ago. It always makes me sad that this infra exists yet all you ever see from evangelists inside Microsoft is C#. It also makes me a little scared that the team has already moved on to a new framework. I guess the other big question is AppContainer a doomed platform? Hard to read the future with all these announcements today.
Please don't include `&lt;Windows.h&gt;` in your header-only library.
This is only done on the Windows platform, and I would argue that it is quite difficult to access the Win32 API without including this header file. In the same way that it is also impossible to do what this library tries to do on a Unix platform without the good old collection of "sys/socket/inet/netdb/netinet/arpanet/unistd" header files... An effort as been made to make the inclusion of the Windows header the least "antisocial" by defining \`WIN32\_LEAN\_AND\_MEAN\` and \`NOMINMAX\`, as a way of reducing the damage done, and not destroying your code by introducing these horrible \`min\` and \`max\` macros somebody at Microsoft decided to write some day, and that I hate with a passion.
Sounds like something that would have unpredictable behaviour.
LLVM plus customizations, see [this comment](https://www.reddit.com/r/cpp/comments/9mwtcm/who_is_stl_i_mean_the_person_not_the_library/).
All previews will be binary compatible. Our compiler and library development is happening in our usual git branch uninterrupted, and we’re following our usual rules to preserve compatibility.
I would like to know as well.
DoD imposes a lot of restrictions too if you take it to the extremes. Using value semantics means adding/removing objects may require extra thought and having an external identity handle requires a separate index/revision array which must be kept valid. Code readability also isn't improved by always having to peek through a keyhole and not seeing even the object picture. It's like multithreading imo, use it when it's a good fit for the problem.
Is it possible to conditionally include/exclude implementation details Ya know, like stb. If there was a `#ifdef KISSNET_PLATFORM_IMPL` symbol then you could put the windows.h behind the `IMPL` symbol and people who don't care and just include your whole header every time, and people who do care can keep platform headers isolated while using your interface.
On Linux, they are a platform vendor.
Hello, Sorry to late reply. Currently, Hearthstone++ supports 55 cards. I'm implementing core/expert1 cards. Also, I added documentations to contribute for adding card(s). Thanks.
Ohne day I hope to learn what is so difficult about porting VS to 64bit. VS2017 is literally the last 32 bit program I use and has been for quite some time now. 
Here's a [curated list](https://github.com/dbartolini/data-oriented-design) of resources on github.
WPF also draws everything on a canvas, it's exactly the same approach than QML but branded by Microsoft 
Yes, now I remember - I think the was some drawback with that option, but I can't remember what. In any case, I should have mentioned that I'm talking about debugging in "open folder"/cmake projects. 
That's strange, CMake appears to default to console applications for me, but I'm not using open folders.
Does this mean that XAML controls will one day be usable in desktop applications or is it still an app-store-lock-in?
You mean, when you let cmake create a vs project file and you open that?
I don't see any Linux distribution here, https://www.qt.io/what-is-qt/ And if you mean KDE, it is an minority in an already small desktop userbase of Linux distributions, which isn't sold as a product by Qt Company anyway. Also noted that not only did I mentioned OS vendor, I addionlally made the point of full stack. While Windows kernel has been slowly migrating to C++ compliant C subset, I doubt very much Linux will ever allow a single line of C++ code on the kernel. 
Can you share .clang-format file?
Don't see any tooltips in debugger now, is it the price we have to pay for out-of-process debugger or will we make a return eventually?
This is so true! It doesn't matter how bad the CMake syntax and concepts (e.g. everything is a string) are. As long as everybody uses and understands it, it saves time. Moreover, the Kitware team has shown that they can bring significant improvements without breaking old scripts.
No, they are only for optimization. You are talking about documentation purposes, which sounds reasonable; however, you are better off using a comment or an empty macro in that case instead. The reason is that marking a function as `pure` or `const` can effectively trigger UB if you mark them incorrectly (or, more likely, modifying functions after marking it), so you need to tread very carefully. It is like the original version of `noexcept` which triggered UB.
&gt; • ⁠We applied clang-format to the entire STL! Wait, so we can actually read STL files now?
They don't produce a Linux distribution, but Qt builds on top of only X11 / Wayland, rather than a native GUI toolkit as on Windows / macOS. There is no such thing as a "full-stack" platform vendor on Linux, that's just not how it works. Each layer is produced by a different set of developers. But what I was really referring to is the embedded space, where Qt-on-Linux is very much a platform of it's own.
For the compiler point of view I agree, but the sanity part is for you.
Whole Tomatoe were just bought by Embarcadero.
https://docs.microsoft.com/en-us/windows/uwp/xaml-platform/xaml-host-controls
They're really both the same meaning (of *state*), just different contexts.
Yep. Our identifiers still need to be `_Ugly` but the braces and other styling are much more readable. Billy refactored vector's functions to improve codegen in certain microbenchmarks (e.g. moving infrequently executed code to separate functions, so that the remaining code can be inlined).
Glad that somebody is working on it, but I have yet to see a working example of it that executes when compiled with the latest VS release.
Will you add catch to test engines (I remember it was planned to add more test libraries)? As far I saw Vcpkg integration is still manual (through CLI/props files). E.g. to use a static triplet I need to import a specific .props file for each project. Will there be some options to control vcpkg within VS (with an extension or through project/solution properties)? Or vcpkg is still in beta and you will not integrate it until it will be a stable release?
I just tried it with a new project (new project -&gt;Visual c++ -&gt; empty project) and sadly it didn't work. I had to manually set the subsystem to console (properties-&gt;linker-&gt;system-&gt; SubSystem).
&gt; My code (which doesn;t work) What does that mean? * Does it compile? * Does it crash? * Does it give the wrong result? * What's the error? * What's the expected behavior? struct myDatatypes{ typedef uint8_t size1; typedef uint16_t size2; } unordered&lt;const char*, myDataTypes&amp; myDatatype&gt; myMap; myMap["type1"] = myDatatype.size1; This is not valid C++ code, it's missing a `;` after the struct definition, `unordered` is not a type, you can't declare variables inside template parameters, you can't declare a reference without initializing it and you can't use a type as an rvalue.
&gt;A very sweet trick to make a C or C++ code faster is by inlining a common function as a macro. This article explains why this statement is not true &gt;As macros are preprocessors, that function will be preprocessed even before the main code itself runs. No. Macros are macros. They will be replaced with their contents, and contents will be evaluated at runtime. &gt;Another way is loop unrolling in which by increasing the lines of code inside the loop you actually reduce the number of times the termination condition is checked. This article explicitly explains why manual loop unrolling is a bad idea. &gt; One should use pointers only when they know what they are doing as un-optimized use of pointers can easily chock the main memory dry if used on a large scale. This sentence doesn't even make sense. This comment is a low-effort spam.
Use std::string and **not** char* as key!
you cannot store typenames in a map. you can store string representation of types in a map. look at the builtin function typeid()
Dön't use a reference as value. 
&gt;Discussions, articles, and news about the C++ programming language or programming in C++. &gt;For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. 
I have edited the question. Please take a look.
 `typedef` declares a type. Your `myDatatypes` struct contains no data, it only defines two types. This mean that `myDatatype.size1`is not valid C++ (it should be `myDatatype::size1`). You can't put types in maps, only values, so `myMap["type1"] = myDatatype.size1;` won't ever work. If the goal is to ultimately get the size of the type, you can just do `myMap["type1"] = sizeof(myDatatype.size1;)` 
Why?
thanks
My expirience has been that it's not hard to keep Qt code from infecting every bit of your code, but it is *very* unintuitive to do so. It takes a lot of trial and error to make it second nature, and less expirienced devs often struggle as they rely on programming by example which in the case of It's documentation, well, of course it's gonna assume Qt is almost always present.
WinUI doesn't. UWP XAML uses DWM for rendering
What is the result of `"aa" &lt; "b"?
Thanks. I finally got clang-format setup on the main code base I use at work a few months ago... don’t know how I lived without it for so long! We use stock llvm (was first item I tried tbh) but lately I’ve been wondering if I should customize it for the edge cases that I’m not happy with..
Typemaps are usually realized using template specialization: template &lt;typename T&gt; struct type_map; struct element1 {}; struct element2 {}; template &lt;&gt; struct type_map&lt;element1&gt; { typedef uint8_t type; }; template &lt;&gt; struct type_map&lt;element1&gt; { typedef uint8_t type; }; template &lt;typename T&gt; using type_map_t = type_map&lt;T&gt;::type; Usage: auto size1 = sizeof(type_map_t&lt;element1&gt;); auto size2 = sizeof(type_map_t&lt;element2&gt;);
That's the least of OPs problems.
I abandoned Qt for the very same reasons of /u/Netzapper, and nowadays I'm using [WinLamb](https://github.com/rodrigocfd/winlamb), but my target is Windows only.
I don't know but it seems that MS loves 32bit... IIRC, vcpkg by default tries to install the 32bit version of a package... isn't it?
It's a bit lengthly, but even as a pure C++ dev I found this to be one of the best explanations of DOD (even though it's written for rust, half of the examples are C++). &amp;#x200B; [https://kyren.github.io/2018/09/14/rustconf-talk.html](https://kyren.github.io/2018/09/14/rustconf-talk.html)
Wrapping a handle into a RAII class is almost always a good thing to do, even up to the point of assigning some related operations to it. Actual trouble comes when you start to assign more responsibilities into what was a simple, cheap handle class. For instance, trying to use OOP patterns, creating relationships to other classes, keeping references, adding more state than just the handle itself, etc. Proposals like `unique_resource` and `unique_val` go in the direction of providing the means to create cheap handle wrappers, which are usable in many contexts (e.g. in a `ConnectionManager` as Sean talked above).
 std::unordered_map&lt;std::string, size_t&gt;; This is the data layout you're looking for. No need for fancy typenames.
1. \`const char \*\` is a non-owning pointer to a string. That can work, but only if you take full responsibility for lifetime management of all the strings you put in there - something that is almost always considered to be too much of a hassle. \`std::string\`, on the other hand, just owns its data, so you don't have to worry about it. 2. The map will compare keys to determine if one key is the same as another. Your key is a pointer - so it will compare pointers. The problem is that you could easily have two identical strings with different addresses, so they should be considered identical (same string) but are considered different (different address). Again, this can be worked around, but why bother when std::string will just do the right thing... As to the down votes: it may be incredibly obvious to you, but it \_clearly\_ isn't to the OP. Give him a chance to learn...
\`\`\`\[\[gnu::pure\]\]\`\`\` and \`\`\`\[\[gnu::const\]\]\`\`\` are a thing that g++ supports that do pretty much what you describe. Here is a [C++ Weekly video](https://www.youtube.com/watch?v=8ZxGABHcu40) on the topic
Is there a way to define a function as returning different results (depending on global states), but not having any side effects (not changing global states)? So that they can be optimized away when the result is not used? Because that would be handy for functions coming from shared libraries.
Except for dynamically linked functions... and anything using them.
I don't think so. If they return something different each time, it sounds you would like to deny some updates of the result and compiler is not going to ignore them.
It's very possible with this upcoming direction they're taking for a new API: http://blog.qt.io/blog/2017/02/06/native-look-feel/ This should make the windows implementations of native controls a lot easier for the Qt team I think
There are use cases for this. Just maybe not that many. My example would be querying OpenGL function pointers. There are a few thousand pointers that are mostly not used. The compiler does fine at removing all unused pointers but still calls into the getGlFunctionPointer functions because he does not know it has no side effects. (at last none that I care about) I was thinking about making it a pure function on compilers that support it. But there are maybe some differences when loading pointers with a different OpenGL context that I do not know about.
&gt;IIRC, vcpkg by default tries to install the 32bit version of a package. Yes it does and the reason is to be consistent with VS' default to 32bit. Would have thought they would default to 64bit for 2019 😕
Just to give you guys an update. I myself haven't launched any projects using Qt yet, I use it for my pet projects. However, upon planing on developing commercial apps using it, it came to my attention that Qt Framework licensing (LGPL with GPL parts) is a painful headache. 
I found it: [https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana)
I was thinking about exactly this issue a while ago: https://stackoverflow.com/questions/48703424/overflow-in-stdchronoduration-for-remaining-time-measurement With ints you get into over/underflow very easily. Try to add or subtract any period from `clock::now()` and you may already be in UB because you don't know what value you currently have. Just pray for your library that the epoch is somewhere near the current time. (includes year 1970...) With C++20 and defined int *flow this will be solved ofc
No, see this is exactly the sentiment I am actually not 100% in favor for. It's actually the way I programmed for a long time, and a very elegant abstraction. The problem is that it manages lifetime at far too granular a level to write efficient code where it matters. As an example, the presence of a copy/move constructor prevents an object from being trivially copyable/movable, and if that handle gets moved in bulk (say on vector resize etc), the code generated will be a lot worse. https://godbolt.org/z/qcvyvr Here's an example of what I mean. The first code automatically vectorizes what amounts to an efficient memcpy. The second code is forced to execute a loop that moves only one element at a time. I think the RAII idiom is useful, and awesome most of the time, but for low-level constructs, I think it unnecessarily inhibits the design space. As I mentioned in my original post, you can always create this resource RAII handle/wrapper at a higher level. With the existing API designs, my hands are tied.
Taken the other way round: It is only unexpected when you are saying `hours` is a non-integral type ;) Important concept: You have `duration` for durations and standard types for `hours` etc. which rely are just that: hours. If you were to say `hours(0.5)` you'll get a truncation warning on supporting compilers. But you CAN say `myDuration &gt;= 1h + 5m` and it does exactly what you want.
2018.3 EAP builds from [https://www.jetbrains.com/resharper/eap/](https://www.jetbrains.com/resharper/eap/) should work with VS2019.
On top of @shmoopty argument usage of floating point where reproducibility is a concern is (almost) impossible. (Examples include LockStep algorithms) When you say `dminutesValue = clock::now()` you don't know how high the value is you get so adding `dseconds(1)` may do nothing at all (or anything shmoopty mentioned)
Ok I'll try them
I agree, but haven’t found any must-try alternatives that feel as complete. I think QT does a reasonable job of keeping things well abstracted, and translating to regular c++ would require a lot of external help/code-to-write if you use things like the QNetworkAccessManager. Im not trying to QT shill, but what requires significant adaptation with a QT project? Maybe something like boost, wxwidgets? Ive used smaller things like nlohmanns json with no issues 
I'm a C++ dev, but I have some experience in C#/Xaml. When I tried to write an C++/WinRt App everything felt a little akward, since the whole workflow of writing an app has been shoehorned for C# and some of the things are just more complicted in C++. This starts with simple things like boxing/unboxing of values. &amp;#x200B; And while the documentation at [https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/index](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/index) is quite nice, as soon as you find something which is not really handled there your already lost, since there are barely any C++/WinRt ressources available. &amp;#x200B; E.g. I tried to implement a tree view with an hierarchical data template... and while you will find tons of C# related ressources that guide you step by step, you will barely find anything for C++. 
Did nobody object of "given function **input** depends only on it's **output**."? ;-)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt;the compiler should enforce the type system That's what it's for! &gt;Constexpr functions aren't pure Could you explain this? It seems to be debated and you must agree there is much similarity between the two. 
&gt; An effort as been made to make the inclusion of the Windows header the least "antisocial" possible by defining What if I `#define` those things?
I do agree with you. Nowadays I am a Java/.NET dev that only reaches to C++ when needed, or hobby coding on rainy weekends. Still as former C++ dev, I do enjoy following up on C++. So when UWP / C++/CX came around I was enthusiastic about it, as I though finally Visual C++ made sense and Microsoft had C++ tooling similar to C++ Builder RAD capabilities. I was wrong, and while C++/WinRT has been an improvement, it is as you say. On the other hand, C++ has even less love on Apple and Google OS offerings.
Why do you need mutexes everywhere in ASIO code? ASIO code is only as parallel as you make it (i.e. how parallel the associated execution context is) so if it's single threaded synchronization is not necessary. You can also pump reads/writes at the user's discretion with ASIO, depending on the execution context you're using. For `boost::asio::io_context` just call `boost::asio::io_context::poll` et al. rather than `boost::asio::io_context::run` et al..
my phone runs a Qt-based OS.
Thanks, I'll definitely try it!
I’m aware of the poll/run api and use it. I consider it to be “high level” control and the difference between the two modes is not much of one at all - in both cases you operate on an item at a time which is not what I want. As for the mutexes they are within the io context itself. 
I doubt very much that Blackberry, Symbian, Maemo or Jolla are relevant for anyone doing mobile business.
I think you misunderstood me a bit (or I didn't explain myself properly :-), I actually agree on what you are saying about the interfaces, but I tried to avoid mixing it up with RAII itself. Let me explain: there is no reason to drop RAII or wrapper classes in general to implement the interface you speak about (the MultiDrawIndirect analogue). In such an interface, you are not really asking the user to give you handles, you are only interested in their value, not their lifetime, i.e. as an index/reference. So, such an interface shouldn't ask for handle types, only for handle "values" (the underlying type, which is typically trivial, and may be a plain integer/pointer alias or a non-RAII wrapper). But internally, you can most likely still use the RAII handlers for managing the lifetime. It is the same as the problem of interfaces asking for `unique_ptr`s instead of "raw" pointers where lifetime is not a concern. In the end, we are talking about avoiding to give library users RAII resources, instead of managing them internally ourselves (or providing the user the means to do so properly); not about avoiding RAII itself. What I tried to say in my previous message is that the problem actually comes when you start creating complex handler classes that tie lifetime management with a bunch of other stuff (and this is what makes optimization impossible). That is why, afterwards, I suggested `unique_resource` and `unique_val`, since they try to simplify creating RAII objects/classes as much as possible (instead of, say, not bothering to write RAII classes for your internal lifetime management since your users are not going to see the classes anyway).
Depends on the embedded device's capabilities. What's wrong with HTTP?
I don't think there's anything wrong it's just that there's a solution space so wide that I am kot sure what direction to take. The embedded device hosting the app could. Be rather large (say a raspi zero W if possible or a 3+ if needed). Its a lab tool don't need to go to production. 
If you are using a recent version of boost then beast could be a good option. It's fairly easy to get up and running. The author (u/VinnieFalco) did a talk about using it at CppCon this year.
Right, I think that's what people want. That's just a heck of a lot easier said than done. :)
Is this ABI compatible with VS2015/2017?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a3e6ff/practice_making_a_code_for_quiz_grades_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; &gt; the compiler should enforce your declarations &gt;That's why we have a type system! This has nothing to do with the type system. Just as an example, constexpr functions have the same type as a regular function with the same signature. Noexcept also only became part of the type of a function in c++17. I mentioned this, because some seem to suggest to let `pure` be just an attribute that the compiler is allowed to take at face value and if you lied you get UB. And constexpr functions aren't pure, because they can have arbitrary side-effects when they are not executed during compile time (including printf or OS calls) and in c++20 they might even be able to "allocate" memory during compiletime. 
Thanks sorry as you can see i am a new poster lol I appreciate it thanks!
A constant container variable doesn't typically have pointers to const, it has const pointers. There are exceptions, mostly something like std::array. But most containers consist of pointers to the heap, and the const-ness simply means that those pointers cannot change, not that the pointed to memory cannot change. So it's zero extra effort in practice (for most containers) to put a non-const pointer inside your const_iterator. Even when that's not the case you can solve this problem with mutable, which isn't really a big deal (given that you don't actually plan to modify the modify the mutable variable in any of the const paths, it doesn't affect anything beyond sticking in the keyword).
Not a day goes by without a bloggers writing about how span should be a pair of iterators, while imagining that that makes them look smarter than everyone else...
Is the libreoffice code base well made? I haven't looked at it but I've never heard it said it was particularly good--or even mentioned in that context at all.
Let's just say it has a lot of history. Ever since the establishment of LibreOffice in 2010, there has been an aggressive push to clean up and modernise everything. Due to constrained resources, in the past few years homegrown Clang plugins have been heavily employed to get rid of badness: https://opengrok.libreoffice.org/xref/core/compilerplugins/ The current compiler baseline is gcc 7, Clang 5.0.2 and Visual Studio 2017 version 15.7. This means the majority of C++17 features can be used. Lots of presentations have been given regarding the clean-up effort. "The program" sections of the past conferences have slides: https://conference.libreoffice.org/
But it is quite common for older boosts to be installed on Linux systems, and trying to update them, or to provide alternative distributions cleanly to your build tooling (save just using plain old make files with hard coded paths) can be a real pain. I actually asked a very junior engineer to do just this recently and they seemed to have a less than great experience.
Well maybe the very junior in the sentence is the explanation. When i develop an application i never rely on the system boost. I've built them in windows and linux without much hassle. Now you can also rely on vcpkg or conan.. 
This is the talk [CppCon 2018: Vinnie Falco “Get rich quick! Using Boost.Beast WebSockets and Networking TS”](https://www.youtube.com/watch?v=7FQwAjELMek)
Other things and people depend on boost, and you dont always get to control if some part of boost gets installed or not -- and once they are installed in one of the default locations, it takes some effort to get tools (like cmake) to use the right stuff. It wasnt their fault for the most part.
Speaking of `span`...now that the committee (rightly) decided to make sizes unsigned for `span`, will Microsoft's GSL follow suit?
No need to install recent boost. Just bundle it with your application and link it statically. 
I don't believe you could simultaneously define two functions that differ only in this qualifier. "Pure" if it ever gets off the ground, would be added to the function's signature so it has something to do with the type system. 
Company: Bitfusion Type: Full time [https://angel.co/bitfusion-io/jobs/193268-senior-systems-software-engineer](https://angel.co/bitfusion-io/jobs/193268-senior-systems-software-engineer) Bitfusion is an Austin, TX and a Bay Area company developing advanced virtualization technologies for the most compute-intensive applications delivering automatic acceleration and efficiency on any infrastructure. Bitfusion is looking for talent to drive market success by building readily deployable software solutions that redefine computing and unleash the power of heterogeneous computing to end users. We are looking for an extremely talented systems programmer with excellent C/C++ skills, deep algorithms and data structures knowledge, and strong familiarity with Linux operating system internals and driver development. You should have a BS, MS, or PhD in Computer Science, Computer Engineering or equivalent. Top-notch communication skills are essential. Strong problem solving skills and out of the box thinking are a must. Experience with network programming, GPU programming (CUDA and OpenCL) is highly desired. Must work well in a fast paced team of talented, motivated, and coworkers. Working closely without our core engineering team in Austin, TX is highly preferred, though remote work may be possible depending on qualifications. Must Haves \* Excellent understanding of algorithms and data structures theory with practical application \* Good experience in C/C++, multi-threaded software development, distributed systems \* Strong understanding of optimization, memory management, concurrency and multithreading \* Experience with development on Linux and related tools: gcc, gdb, git \* Should be able to pick up any new programming language quickly Nice to Haves \* Experience with CUDA or OpenCL programming \* Experience working on high speed networking (e.g. IB, DPDK) \* Familiarity with one or more performance profilers such as: VTune, XPerf, gprof, etc. \* Knowledge of GPU and CPU architectures \* Knowledge of at least one scripting language (Python, Perl, Ruby, Shell scripting) \* Experience with software performance analysis, optimization and low-level programming We are an equal opportunity employer. Subsidized health, dental, vision, and relocation provided. Relocation to Austin, TX highly desired.
I define a pure function as one which does not or promises not to alter things in its enclosing scope.
There isn't much that truly needs to be restricted. Can't use the standard allocator, though you can redefine it. Exceptions could actually be useful in the kernel if done well - way less error code testing. Forbidding templates kills much of the allure.
Or inexact values.
not yet
It was header and library search via cmake that needed wrangling. 
Thanks for the shout out! Yes, the original poster should have a look at that video, it is very relevant to their problem.
Thanks! 
A useful definition of pure doesn't have anything to do with scope. A pure function is a function that promises you that if you call it twice with the same parameters it will have the same results and it will have no observable side effects. If you only have the latter half it's not a pure function anymore; Procedures with no observable side effects can still be useful to some extent because you can reorder them as you like and within a certain context you can even memoize their results; And you can drop calls to them if their results aren't used. But they don't give you the same benefits as pure functions which are always safe to call or delay to call.
It's pretty easy to find alternative versions of boost via CMake. I've found that main thing to be aware of is that your `FindBoost.cmake` should be newer than your version of boost. If you are using a version of CMake from before your version of boost, take the FindBoost.cmake from a newer version and bundle it with your code.
With the new std::ssize(), when will you ever call .size() though?
Always.
But then you'd have to cast it to signed anyway if you want to use it for anything other than plain sequential indexing, which you rarely do anyway these days with range based for loops. That is, since you should never mix signed an unsigned arithmetic, when can you actually ever use the unsigned size in practice?
Yes, I'm familiar with how STB does it's implementations. This is a possible improvement indeed. You could limit the definition of an implementation to one single compilation unit that way. I'll have to see because the codepath actually compiled for the socket logic is templated on being constructed with either protocol::tcp/udp and ip::v4/v6. I'll think about that, thanks.
&gt; Has something like this already been proposed? If so, what happended with it? I've got something in the works which extends contracts with API purity expectations and ensurements. I put it through a first pass on std-proposals, seems fairly uncontroversial despite the SAL-likeness of it when you push it out to the max. I hope to get a proper paper to WG21 sometime in 2019, but it's fairly low down my priority queue.
In case people have more complex needs for single header generation, I'd remind them of my https://pypi.org/project/pcpp/ which lets you do true, unmitigated, evil e.g. fuse your C++ program into a specially simplified C++ syntax suitable for doxygen to parse.
Monotonically increasing indexing is by far the most common case I ever have to deal with. Unsigned works just fine, and the type matches the semantics. People sometimes bring up `operator[]` which can technically take in negative indices, but I can't think of many cases where such usage wasn't a bad choice.
Question 5 is a classic example of a problem that can be solved cleanly with a stack data structure: constexpr auto convert = 'a' - 'A'; bool matches(char lhs, char rhs) { if (rhs &gt;= lhs) { return (rhs - lhs) == convert; } else { return matches(rhs, lhs); } } std::size_t fully_react(const std::string&amp; s) { std::stack&lt;char, std::vector&lt;char&gt;&gt; stack; for (auto c : s) { if (stack.empty() || !matches(stack.top(), c)) { stack.push(c); } else { stack.pop(); } } return stack.size(); }
But if you have a simple for-loop with monotonically increasing indices, don't you pretty much always want to use a range based for-loop?
One thing that I know about it is that it takes ages to compile. Could take half a day some years ago. Probably not that long on machines of today.
Here is some more info on IntelliCode for C++ [https://blogs.msdn.microsoft.com/vcblog/2018/12/05/cppintellicode/](https://blogs.msdn.microsoft.com/vcblog/2018/12/05/cppintellicode/)
I'm using spdlog in a multithreaded web service: so far so good. [https://github.com/gabime/spdlog](https://github.com/gabime/spdlog) 
Aside from being UB on overflow instead of defined-but-never-useful-in-this-context, what extra edge cases does signed introduce? On the other hand, it's very obvious that unsigned introduces major surprises for people as approximately 100% of people's first reverse loop using unsigned is infinite.
Please follow the template in its entirety - posting should have the Remote, Visa, etc. sections.
I have never hears of it but just had a quick look at the github. Gotta say, looks promising. I like the docs and how they are structured as well as the general approach and simplicity of use. I have been using Boost.Test for a long time but this very much looks like an option I should look into. Are there any hints on how it integrates with CMake?
When we finally get `std::indices` or whatever, maybe. Why would you necessarily want signed indices for arithmetic? Because of UBSAN? In that case, maybe what we really want is `SafeInt&lt;T&gt;`.
Unsigned has one problem zone centered around 0; signed has one centered around 0 (especially with indices/sizes, where &lt; 0 is rarely intended), and another around `XXX_MIN`. Whereas an unsigned range check will usually be `index &lt; x.size()`, with signed sizes/indices you will need `index &gt; 0 &amp;&amp; index &lt; x.ssize()`. And you will have to do this consistently. Frankly I don't see how people think this is simpler. 
at the office we have an architecture of c++ mixed with web technologies (php, typescript, angular, node.js). according to my experience rest service is easier integrated than websocket.
Yeah, it gets me every time I want to install a package with vcpkg. Seriously annoying. It's 2018 FFS, who cares about 32-bit at this point (as a default). I haven't even owned a 32-bit machine for 15 years! I haven't run 32-bit Windows for that time either.
Eh one example is reversed for loop, when end condition of form `i &gt;= 0` will not work with unsigned.
This should be fully possible on Windows 10 now, with the addition of proper support for PTYs?
What's the point of any ::size () anyway? What's the use case nowadays?
I agree entirely. I mentioned the opposite though since that opinion is unlikely to be true for the kernel developers. If this were to ever happen, I think it would need to start out completely minimal, and then whitelist features one by one as they are shown to be useful.
Won't this be very dependent on what functionality you need on the web UI? A front end for an embedded device could mean anything from a status page with two buttons to something close to a complete office suite. The requirements for that will be very different.
Not sure if it was fixed but there is \`std::ranges::distance\` which takes a range and returns \`iter\_difference\_t&lt;iterator\_t&lt;R&gt;&gt;\` which is a signed integral type.
Technically it’s impossible to write a code that will take the same amount of time in any system. Even if the different systems are on the same machine, the difference in the systems will mean that they have a different way of allocating time as a resource to the program. They will always take up a different percent of the CPU. To be honest it is not even possible to make the system take the same time even if run on the same system inside the same machine only based on the number of background tasks it is running. And to be honest, as of now it is literally impossible to write such a code not only in C++ but literally in any other language either. But you could use functions like sleep to decide how much time, which might seep similar across machines, but it will still differ even if by milliseconds. You could a lot more interesting pieces of stuff from different programming schools such as “[*Holberton School*](https://www.holbertonschool.com/)”. And you could also seek help from participants of programming contests, as they ensure codes that take minimum space and time but even they cannot make functions that take constant time.
Unsigned sizes, while almost optimal (you can still represent size 0...) is dangerous in practice and problematic for compiler optimization. Dangerous because unsigned comparisons have overflow behaviors on 0 (which is quite a common value). As opposed to signed values which only wrap on "far" less common numbers. Problematic for compilers because address computation is signed (you can index negatively on arrays) and loop boundaries are up to the users choice. Mixing unsigned/signed algebra forbid lots of optimizations. In addition to that, signed arithmetic overflow is undefined behavior, which allow the compiler to ignore those Eddie case, while unsigned arithmetic have well defined behavior that must be enforced, even if the programmer didn't care.
You are obviously right! But i was just exploring the solution space. Obviously it's not two button neither office...(but I suppose not an overly complex UI some widget, some status, maybe some plot...). 
You can tell cmake where to find boost (BOOST_ROOT). Not saying it is always painless, but usually it is not a big deal.
Wow, that's amazing! I love your solution!
Err, I don't think signed has a problem around 0. It behaves exactly as you would expect, like a normal integer. That's why, looking at my example, if you use signed integers it works exactly the way people expect. And both unsigned and and signed have more or less the same problem at max/min magnitudes, overflow is pretty much always a bug outside rare domains where it's ok (like e.g. hashing, where it indeed makes sense to use unsigned). Another common example where you can see how much easier it is to be burned by unsigned is in many DP problems, like pseudo-polynomial knapsack solution. It's common to do `auto prev_index = j - w[i]; if (prev_index &gt;= 0) { ... w[prev_index] } else { .... }`. This code is very intuitive and looks correct, but fails with unsigned.
I use and like this framework, but I haven't figured out why it doesn't work with the `ctest` command for me (doesn't print the details of why the test failed).
We've started using loguru on some of our projects and I've been very happy with it. https://github.com/emilk/loguru
What do you mean exactly? 
Another vote for spdlog. Only for hobby projects, but super easy to get what I need 
Interesting! Wondering what happens with this in the last (nearly) 2 years.
I meant mainly that it would use true native controls under the hood.
I use a bit of [EasyLogging++](https://github.com/zuhd-org/easyloggingpp). Can't speak to its performance cost because I don't use it in core loops, but it's easy enough to use. `LOG(INFO) &lt;&lt; "Log something into the default file under INFO";`
Extensibility (can be defined without changing the class/struct). And works for regular C arrays.
Do you run `ctest -V` for verbosity? `ctest` squashes the stdout of run commands IIRC.
I agree with your reasoning, but note that C and C++ allow you call a function pointer as if it is the function itself, i.e. `fp(x)` rather than `(*fp)(x)`. If `fp` is null then `fp(x)` is undefined behavior AFAIK. So there is a precedent for this kind of syntactic sugar.
Another approach might be [https://www.webtoolkit.eu/wt](https://www.webtoolkit.eu/wt)
I'd probably use something like SimplyHTTPServer for python and write bindings so that the python code can call directly into your C++ library. https://docs.python.org/2/library/simplehttpserver.html 
Just FYI you can set a system environment variable to change that. `VCPKG_DEFAULT_TRIPLET=x64-windows` They should still move to x64 default though for VS2019.
Catch2 support is definitely on our radar. The best way to capture your feedback and help us prioritize is to add it on [http://developercommunity.visualstudio.com/](http://developercommunity.visualstudio.com/) and paste the link back so people can upvote it. For Vcpkg, we are working on additional integration improvements in VS, and there is an open PR ([https://github.com/Microsoft/vcpkg/pull/4361](https://github.com/Microsoft/vcpkg/pull/4361)) that adds some vcpkg items to the project settings dialog. Thanks for the great feedback.
However unsigned sizes also have problems. There are architectures where the addresses are from `0` to `2^16-1` and these architectures decided to use 16bit pointers.
That's silly reasoning... for (auto i = c.size(); i--;) { ... } Type agnostic, signedness agnostic.
Didn't think of that.
You meant "signed sizes" also have problems? Technically unsigned size is not even what we want on those architectures as you can't represent the size of an object that take the entire address space. Typically, in systems where bits are precious we encode size with implicit +1. So from 1 to 2^16 (included).
Well, `span&lt;&gt;`, like `std::string_view`, has an inherently (memory) unsafe interface, unlike the older standard containers. For example, the specified interface of, say, `std::vector&lt;&gt;`, does not require that it be implemented in such a way that its iterators are prone to use-after-free bugs. In fact, in debug builds with the microsoft compiler they are not (by default). But iterators of `std::span&lt;&gt;` are necessarily prone to use-after-free bugs, right? (At least until the lifetime checker is completed. But even then the imposed restrictions will be fairly draconian.) A templated `subrange&lt;&gt;` or a "`subrange&lt;any_iterator&lt;&gt;&gt;`", on the other hand, are not inherently unsafe and would inherit the safety checks of, for example, microsoft's debug iterators. It's a trade-off between performance, safety, convenience and (perceived?) compile speed. Different situations will have different priorities. Often including different situations with the same code (eg. test builds vs release builds). You could imagine a scenario where you could, with a compile-time directive, switch between `std::span&lt;&gt;` and a code-compatible substitute with the safety properties of a "`subrange&lt;any_iterator&lt;&gt;&gt;`". I don't think that quite exists yet for `std::span&lt;&gt;`, but it does [exist](https://github.com/duneroadrunner/SaferCPlusPlus/blob/master/README.md#string_view) for `std::string_view` (shameless plug): #ifdef SAFE_BUILD #include "msetl.h" using my_string_view = mse::mstd::string_view; using my_string = mse::mstd::string; /* just a safe implementation of std::string */ template&lt;T&gt; using my_span = mse::TAnyRandomAccessSection&lt;T&gt;; /* interface not quite compatible with std::span yet */ template&lt;T&gt; using my_vector = mse::mstd::vector&lt;T&gt;; #else //SAFE_BUILD using my_string_view = std::string_view; using my_string = std::string; template&lt;T&gt; using my_span = std::span&lt;T&gt;; template&lt;T&gt; using my_vector = std::vector&lt;T&gt;; #endif //SAFE_BUILD
Take a look at range-v3 library [https://github.com/ericniebler/range-v3](https://github.com/ericniebler/range-v3) ( which should be a part of c++20 ). It makes algorithmic problem solving much more declarative and less error prone. Multiple AdventOfCode solutions using range v3 can be seen in my repo [https://github.com/voivoid/advent-of-code](https://github.com/voivoid/advent-of-code)
This is super cool! It would be cool to have three types of builds: - All in one file - One header, one source, one that includes both - Original headers + one source What this does is let users pick the compile time hit they are willing to take of having a lot of headers to parse. It still makes projects easy to vendor or pull down and build, but you can save on some compile time if you want.
I solved this by remove to copy constructor on span&lt;T&gt; const. Now it isn't trivial to remove and some explicit effort is needed. span&lt;T const&gt; gets full treatement though and can copy, along with copying from a span&lt;T&gt; const or span&lt;T&gt;. Alsong with proper const correctness on the accessor methods( e.g. operator[], front, back,... ). But, in general, like other value like things, free flow to const, but effort to remove it. I like this cost a bit better than inadvertantly overwriting data I promised not to.
&gt;Just bundle it It's possible to download and build my software in a few seconds on older PCs. I aim to minimize the amount of code users have to download/build/maintain. Besides blowing up download times, Boost isn't very portable in terms of all the files and bytes they consume. I want to appeal to embedded and mobile developers with software that takes minimal amount of space.
Is it possible you mistook my question for being about std::size vs e.g vector::size()? I was wondering why one would need either regularly...
\+1, includes the \`{fmt}\` library which is very fun to use.
I commonly wrap the AvContexts in unique pointers with the appropriate closing code, as libavcodec often has different and non-obvious clean up code per context type. i.e struct ContextDel { void operator()(AVCodecParserContext *ptr) { av_parser_close(ptr); av_freep(ptr); } void operator()(AVCodecContext *ptr) { av_freep(ptr); } void operator()(AVCodec *ptr) { //do nothing we dont own this, } }; std::unique_ptr&lt;AVCodecContext, ContextDel&gt; codecContext; std::unique_ptr&lt;AVCodec, ContextDel&gt; codec; std::unique_ptr&lt;AVCodecParserContext, ContextDel&gt; parserContext; &amp;#x200B;
&gt; You meant "signed sizes" also have problems? Yes, thanks for correcting me.
I wonder whether there are some benchmarks comparing signed and unsigned for sizes
Honestly, it's pretty trash. I tested it out yesterday, it's extremely slow, 40% CPU usage on a 7700k, and VS lags so much it takes 0.5-1 seconds for keystrokes to register. Keep in mind, this was on a project with a single source file.
Are you calling ctest with the --output-on-failure flag?
This sub is for discussion of the C++ language. Programming questions should be posted on /r/cpp_questions. The mods here will very likely remove your post.
&gt;String pointer first 8 bytes are garbage, however the rest are fine! I did not know, i'll post there instead, thanks!
Because it's convenient to write `v.size()` instead of `size(v)`? Are you just asking why might someone need to know a size of a container? 
Do you mean you've only used it for *your* hobby projects, or you'd only recommend it *for* hobby projects?
It's the opposite. For `string_view` and `span`, the iterators are implementation defined... so implementations are free (but not required to) to add the kind of safety checks that you're talking about. On the other hand, `subrange&lt;T*&gt;::iterator` _must_ be exactly `T*`, so no such checks are possible.
Agreed that this is the wrong subreddit for this, but I did notice that you’re using i before it is initialized.
You’re actively triggering me with that `cout` with no `std::` prefix.
There's a main function as well, however i did not include it in this picture. Somewhere bewtween the return call and using cout in main function the string on the adress changes. :/
Sorry for the ambiguity. I only used it for my hobby projects.
&gt;Ohne day I hope to learn what is so difficult about porting VS to 64bit. VS2017 is literally the last 32 bit program I use and has been for quite some time now. If you feel strongly about this, you can upvote this feature suggestion to raise more attention to the idea of a 64-bit VS: [https://developercommunity.visualstudio.com/idea/360039/make-a-visual-studio-64-bit-version.html](https://developercommunity.visualstudio.com/idea/360039/make-a-visual-studio-64-bit-version.html) We use Developer Community feature suggestions to help set our priorities for future releases. 
Wow! I had no idea. Guess that ship has sailed then.
I like that! I hadn't thought about doing this with contexts, as I was largely unaware of these complexities, but I had thought about wrapping AVFrames, and would probably do so if I kept them around any longer than I currently do. My current instinct is to get images out of that format as quickly as possible, although I'm not sure how much it could be helped if I wanted to re-encode the video after doing something to the images.
Apart from i being uninitialized, the bigger problem is that your function returns a pointer to a stack-allocated (local variable) string, which will no longer exist once the function returns. Change the return type to just string and modify your code to return it by value and you should be okay (and initialize i). 
Indeed I do. It seems way too rare for the heat this signed'ness debate unleashes :)
I just e-mailed the authors. Unfortunately, they're not going to pursue the structured-binding like syntax I had, and said I should wait for reflection. C++26, here we come...!
Well, that's a really weird question. Taking the size of a container is one of the most basic things. It's frequently used in all languages. Even more so in C++, since you basically have no choice in vanilla C++ right now for non trivial iteration or if you need an index. Not to mention when you just need to know the size.
Did you seriously link your code as a screenshot of your editor? Use [pastebin](https://pastebin.com/) or something like that.
Moving to signed types for indices because of compiler optimization is the most ass backwards line of thinking I've ever heard, and shows how deep the cargo cult of performance goes in C++. If semantics of unsigned integers inhibit optimization do something to address that problem. Don't make negative sizes something that's representable, that's nonsense. I thought we were moving towards making invalid states unrepresentable through the type system. 
There is a semantic issue too: comparison between signed and unsigned numbers of the same size are broken, as well as adding an unsigned value to a signed value of the same size. Most people work with signed values (size_t).
Sounds like a typical microsoft product. 
What's your point? Why are you mixing signed and unsigned types? 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a3ibh9/string_pointer_first_8_bytes_are_garbage_however/eb6mq1t/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Because array indexing use std::ptrdiff_t (which is signed) and that's the most common use case for ranges, or any variable that you compare to a size. If you make sizes unsigned, you force a mixing between unsigned and signed types.
Yeah, `subrange&lt;T*&gt;` is necessarily unsafe, but not the `subrange&lt;&gt;` template in general, right? For example, `subrange&lt;vector&lt;int&gt;::iterator&gt;` would inherit any safety mechanisms that `vector&lt;int&gt;::iterator` might have. The safety issue with `string_view` and `span` is that their interface is such that they would commonly be constructed from raw pointers, which (without a completed lifetime checker) have no safety mechanism or information. So even though they may have complete freedom in their implementation, they (often) wouldn't have access to any safety mechanisms provided by the target container's iterators.
Fair point. I guess a different meaning would be like state as a country.
Fair point. I guess a different meaning would be like state as a country.
&gt;I just tried it with a new project (new project -&gt;Visual c++ -&gt; empty project) and sadly it didn't work. I had to manually set the subsystem to console (properties-&gt;linker-&gt;system-&gt; SubSystem). Thank you for the feedback. This is of course not an ideal experience. We will rectify this in a future release so all console apps will have a consistent experience with respect to the window staying open (whether they are from the Empty Project template, Console Application template, or even a CMake project template). I'll rummage around and make sure this bug is effectively prioritized...
Thanks for trying out Live Share. The performance metrics you stated are certainly unexpected and we’d like to dig deeper into your experience. Could you Report a Problem on [https://developercommunity.visualstudio.com](https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdevelopercommunity.visualstudio.com%2Fspaces%2F8%2Findex.html&amp;data=02%7C01%7Cnicku%40microsoft.com%7C25f601cef9134ca7f90b08d65b1a8a3e%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636796566871997213&amp;sdata=ioF42i0n9P8X0jqJuaywtT6DlHvpJoCwIWSeuwT1Z%2F8%3D&amp;reserved=0) with more information? For example, is this experience isolated to C++ or do you have a similar experience when using other languages? Please comment with a link back to your reported problem so that others may reference it.
Put CodeLens into Community!
&gt;That's nice, thanks. &gt; &gt;There's one issue with it though: if you don't close that window after the program termination and start a new debug session, it will reuse that window without bringing it to the foreground, which can be quite confusing - "I've just started my app, where is it?" That's good feedback. I've filed a bug with our team to fix this. 
&gt; Because array indexing use std::ptrdiff_t (which is signed) No, it uses std::size_t (explicitly since C++14), as do all standard containers' relevant `operator[]`s.
I had hoped that the Ranges TS would be the kernel of a new version of the Standard Library in which all the little foibles were fixed, but the Committee got cold feet. The functionality of the Ranges TS will ship in namespace `std::ranges`, and we won't be getting a chance to fix problems like the (un)signed-ness of container size. As for the new range types that will ship in `std::ranges`, they are a bit schizophrenic regarding the size type. I recently opened a [bug](https://github.com/ericniebler/stl2/issues/586) to track this issue. My preference, now that the Committee has weighed in on the `span::size` debate, is to force all range size types to be unsigned for the sake of consistency. I'm a bit sad.
Based on how it mangles half my spreadsheets beyond recognition I'd say it needs some TLC
I also recommend wt. My only suggestion is to install it from the github repo instead of using apt-get. The github version uses more modern c++ practices and matches the online examples better. (I'm still using ubuntu 14.04 so maybe this isn't an issue on newer systems)
Thanks!
Anyone has a recommendation for a mocking framework that is easy to integrate with doctest in cmake projects? I ended using FakeIt as it has off the shelf Catch2 but I'm missing the fast build cycles with doctest.
 inline constexpr auto for_each = []&lt;Range R, Iterator I = iterator_t&lt;R&gt;, IndirectUnaryInvocable&lt;I&gt; Fun&gt;(R&amp;&amp; r, Fun fun) requires Range&lt;indirect_result_t&lt;Fun, I&gt;&gt; { return std::forward&lt;R&gt;(r) | view::transform(std::move(fun)) | view::join; }; inline constexpr auto yield_if = []&lt;Semiregular T&gt;(bool b, T x) { return b ? maybe_view{std::move(x)} : maybe_view&lt;T&gt;{}; }; You know, I've just had a thought about how different C++ looks like today compared to when I started learning it. Basically every token above except for `bool` and `return` weren't in C++98. I got homework.
If you need something very simple, you could use Mongoose/CivetWeb. [Mongoose if you are OK with a GPL/paid license.](https://github.com/cesanta/mongoose) or the [CivetWeb fork if you prefer MIT.](https://github.com/civetweb/civetweb)
OP's scenario is pretty much the perfect use case for Wt. It would definitely be my first choice.
Tangent: I have a need for logging in a hard real time requirement. Is there a logging library with wait/lockfree logging? Even if it's optional or with caveats like short logging messages that's alright, I really just need a logger that doesn't allocate on the producer side. 
Thanks for this. I too have this problem and I’m forever deleting accidentally auto completed things. I can’t believe I’ve left it so long and not explored ways of turning it off.
Not true! `inline` also. :-)
Is it that bad?
Thank you, I will do it.
[trompeloeil](https://github.com/rollbear/trompeloeil) - doctest can be [easily integrated with it](https://github.com/rollbear/trompeloeil/blob/master/docs/CookBook.md#adapt_doctest) Support for FakeIt would be nice as well though...
Thanks!
Well it is just a single header - there are many ways to go about it. The CMakeLists.txt file in the repository provides a CMake interface target to link against, there is a conan package, you can also just download the header with wget and place it somewhere... https://github.com/onqtam/doctest/blob/master/doc/markdown/build-systems.md
whats the tl;dr of what are ranges?
Super short? It passes around the begin and end iterators as a pair instead of as separate parameters. Many things follow from that, many functional programming-esque. 
\+1, very clean and easy to use. I was confused about a certain interface and received immediate feedback from the developer helping me through it. Very excellent.
 A shameless plug wrapped in a question. I made a Test Adapter for Catch2 and made it available on the Visual Studio Marketplace for VS2017 (I was tired of waiting for someone else to do it). Though in general I think the adapter works quite nicely, I did run into some quirks that I think are related to the Test Explorer. These quirks sadly diminish the user experience in some cases. Is there a place to discuss such issues to make sure it’s not me that is doing something wrong? For those interested the project is also on GitHub ([https://github.com/JohnnyHendriks/TestAdapter\_Catch2](https://github.com/JohnnyHendriks/TestAdapter_Catch2)).
Thanks for the spam report! 😸
What parts of boost are you using anyway (admittedly, beast probably drags in half of boost as a dependency)? Have you verified how much overhead this it would actually generate? Also, if you don't want to use beast, you'll need a different library instead - are you sure this will be more efficient? Most embedded systems I worked on either didn't have a pre-installed boost anyway (ok, most of them didn't have a linux so those might not be relevant here), or had so much memory, that it didn't matter. &gt; Boost isn't very portable in terms of all the files and bytes they consume. No idea what you mean. I mean. If it doesn't work for you, it doesn't work, but the notion of "I can't use anything newer than what the oldest imaginable system provides by default" is really the bane of c++ these days and often completely unwarranted. 
Jesus that looks awful... Makes me want my C99 back :D
No restrictions.
That's just how cpp is though. You are not going to make a complex system in cpp that doesn't take forever to make from clean. It's the price we pay for theconstructs cpp provides. There are ways to mitigate it but not eliminate it...and thebest way to limit compile times is to forego the use of practically every modern idiom that exists. Cpp takes forever to compile. Everyone knows this. So long compile times didn't speak at all to the correctness or maintainability of any design. 
&gt; I thought we were moving towards making invalid states unrepresentable through the type system That's a good guiding principle, and by this container sizes should be signed. When considering which type to use you don't just need to take into account which numbers it can represent, but also how it behaves. A real world size behaves like a non-negative integer, while `unsigned` does not. The difference between two sizes can indeed be negative in the real world.
Slightly longer, but important... End is not neceasarily an iterator. It can be, but technically it can be anything that is equality comparable to the iterator type. 
Yep, [I thought the same thing](https://github.com/JamesBoer/Heady). I wanted a utility that did this for my scripting library. Interestingly, I was inspired by Catch2 as well. I heard Phil Nash had a utility to do this for him automatically, and when I couldn't find what he used, I just decided to write my own. Was a fun little project, and thought I'd share the source in case anyone else wanted to use it. A utility like this can't do everything automagically, of course. You have to prep your code in a few ways, making it "header-only friendly", so to speak. At some point maybe I'll write a tutorial to go along with my tool, but I only have so much free time... you know how it goes. 
`std::array` uses `size_t`, but the builtin `operator[]` for C-arrays and pointers has the signatures `T&amp; operator[](T *, std::ptrdiff_t)`and `T &amp; operator[](std::ptrdiff_t, T *)`, see [over.built]/14 in e.g. [N4659](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf)
There are (or there were) several high-level Web-frameworks for C++: [Wt](http://www.webtoolkit.eu/wt), [TreeFrog](http://www.treefrogframework.org/), [Tntnet](http://www.tntnet.org/), [CppCMS](http://cppcms.com/wikipp/en/page/main), [Cutelyst](https://cutelyst.org/). But if you need something low-level, like Boost.Beast already mentioned here, then there are a plenty of more easy to use alternatives, like: [RESTinio](https://github.com/Stiffstream/restinio), [Silicon](http://siliconframework.org/), [CROW](https://github.com/ipkn/crow), [Pistache](https://github.com/oktal/pistache), [RestBed](https://github.com/Corvusoft/restbed), [served](https://github.com/meltwater/served), [C++REST SDK](https://github.com/Microsoft/cpprestsdk) and so on. You can still prefer Boost.Beast if you need extremely high performance or control over everything (or if you liked to do a lot of work by yourself). But just for comparison: [there is an implementation](https://bitbucket.org/sobjectizerteam/beast-cppcon2018-vs-restinio) of example shown for Boost.Beast at CppCon-2018, but implemented by using RESTinio.
&gt; Whereas an unsigned range check will usually be index &lt; x.size(), with signed sizes/indices you will need index &gt; 0 &amp;&amp; index &lt; x.ssize(). but the problem is more than that. if you want to do, e.g. "i - x &gt; n" with unsigned and values "around 0" you have to remember every time that you must do "i &gt; n + x" instead. With signed this does not matter for most values of i, n, x that you will encounter - sure, there is the possibility of signed overflow but let's be honest, the immense majority of the indices of your software are closer to 0 than to INT_MAX.
Great post. Couple of questions come to my mind: 1. The nested namespaces make everything look verbose so that even yourself you better use using in every example. Do you think something could be improved here? For example std::r instead of std::ranges and std::rv instead of std::ranges::view. Using using everywhere is a bit tedious. 2. There is an interesting paper [P1214](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1214r0.html). I think it's a great idea and it would make invocables not needed right? 3. You mentioned ref_view. Is it needed to wrap lvalues (like instance of std::vector) with this??
Thanks! Lots of food for thought! 
But we are not talking about vanilla c++ right now, but span and the future of the STL. I grepped through the last 2 years of code and in roughly 800k lines of code I have found 21 instances of .size(). In neither of these was the size's signedness an issue. In fact almost all of these were buffer sizes for calls to opengl functions. I would argue that modern approaches like for (auto &amp;&amp; [i,v] : zip(ints(0u), vec)) {} for looping give you full control over the index type and "just needing to know the size" is rare and most importantly rarely a signedness issue.
I believe most of us will want to write simpler code so we rather skip requires constraints altogether and then the code could be rewritten in this style ``` auto for_each(Range auto&amp;&amp; r, Invocable auto fun) { return std::forward&lt;decltype(r)&gt;(r) | view::transform(std::move(fun) | view::join; } ``` which already looks quite readable imho.
Way too clever. I would avoid such snippets in my production code.
awesome article! It will be better if there is an article introducing the design of range, esp for those two technology insid meta namespace
I wish we didn't need the `std::forward` :(
Coming from other languages I love this functional style, but there is quite a bit of syntactic overhead that will require getting used to
Visual studio is the best IDE I've ever used and it's also a Microsoft product.
I tried the Live Share plugin a few month ago and thought the performance was quite nice. This was in our company network, not sure if that was one of the reasons...
As someone who has no large knowledge of the web but picked Beast for random web app uni assignment: it was easy to setup but I'm struggling with the doc and examples on basic things. Perhaps due to my lack of web-tech knowledge but I feel the library lacks some dedicated API for typical needs like AJAX, JWT, GET/POST url parsing (I know this is WIP already). The lambda-based approach feels like a large opportunity to customize but even after watching this year's CppCon I don't fully get the control flow inside the library 
that would be a first
It needs lots of syntax highlighting. Without it it’s kind of hard to follow.
I thought they gave up on contiguous iterator.
I have voted on that and similar topics on user voice in the past and wrote a couple of rants about it on various internet pages. It didn't help then and I don't believe it will help now. If you (as in the people in charge of strategic decisions like this) are convinced that clinging to 32 bit is the right thing to do, then I find it hard to believe a few hundred votes on the internet from people that don't have any insight into your code base, budget and development strategies are going to change your mind. Let me just say that I find it ridiculous how much time and energy is spent by the industry on keeping windows software working in x86 mode in general and that it seems to me that the VS-Team in particular is investing a lot of time, working around problems it wouldn't have or could be solved easier if it was a 64 bit application (but as I said, I have no insight into your codebase, so I'm probably completely wrong). And yes, I have suffered from VS running out of memory regularly... on a machine with 16 and 32 gigs of ram ... in 2018! Now that you moved another chunk out of process it might solve the problem for some time .. until it crops up again. Anyway, if I may make a more realistic wish for VS2019 than porting everything to x64: Please, modernize your *project defaults* (x64, /arch:avx, permissive-, unicode, nominmax ...)
Not to forget that pure functions also make parallel programming way easier.
Do you have a link with more information on `std::ssize()`? Search engines aren’t finding anything for me. 
I have used plog. It simple but powerful enough for my needs, it is also header only and cross platform so it is very easy to integrate in any project. [https://github.com/SergiusTheBest/plog](https://github.com/SergiusTheBest/plog)
I was baffled by the triples code until I read down to see that `view::iota` is very different from `std::iota`. Great read!
By the principle that invalid states shouldn't be representable `-1` should be a representable container size? The contortions that the people in the signed-size camp do to try and make it make sense... If the difference between two sizes can be negative the whole computation itself probably doesn't make sense. 
Awesome stuff. Can't help but be bitter thinking how better chaining operations would look if we had some sort of UFCS, though...
You can use `namespace sr = std::ranges` to make it easier to type.
&gt;If the difference between two sizes can be negative the whole computation itself probably doesn't make sense. Right. If the preconditons of a piece of code allow that the difference between two sizes might become negative then there is a case that has to be checked and acted upon - before the actual subtraction. The proposition of negative sizes and indices reminds me of "if two more people would enter the bus it would become empty".
Yet it still manages to look as cryptic as templates and STL using code of ’98.
[fff](https://github.com/meekrosoft/fff) works great for scaffolding free functions 
What if I `#define` those macros and `#include &lt;Windows.h&gt;` in my own code, is your code well-behaved in that circumstance?
To make it more precise, `signed` can represent all states and behaviour or a real-world size but is a bit too lenient, while `unsigned` can't represent the correct behaviour because it models Z/nZ, not Z+. The ideal match would be either to have 1) `signed` values with assertions for the range, or 2) `unsigned` but cast to `signed` everytime you perform arithmetic. For convenience you probably want to create an actual type to represent non-negative integers.
&gt; Right. If the preconditons of a piece of code allow that the difference between two sizes might become negative then there is a case that has to be checked and acted upon - before the actual subtraction. The whole idea of "make invalid states unrepresentable" is that you shouldn't need to, it should be impossible. &gt; The proposition of negative sizes and indices reminds me of "if two more people would enter the bus it would become empty". The "signed sizes" camp isn't trying to represent negative sizes, it's about correctly representing the behaviour of non-negative numbers which `unsigned` can't do. Example: let's say I measure my height every year unsigned my_height; unsigned my_height_last_year; my_height_change = my_height - my_height_last_year; Clearly the type of 'my_height_change' cannot be unsigned, regardless of how large numbers it can represent. Hence 'my_height' also needs to be signed if we want the behaviour almost everyone would expect from a number. That's the point the "signed size" camp is trying to make. Unsigned doesn't model non-negative integers, and cannot be used for such. It's not just a poor fit, it's objectively wrong. 
Except `signed` **can't** represent all states and behavior because it can have a range that's too small. This is especially evident on systems with a 32-bit or smaller `std::ptrdiff_t`.
An argument against LOGURU is very slow issue resolution. https://github.com/emilk/loguru/issues/69
A bit sad that `view::zip` isn't part of C++20. I use it a lot.
How can an office suite take half a day to compile, on a CPU from the last ~6 years? Does it have dependencies on half of the Linux universe (KDE/Qt, ...), and that time includes building all dependencies (which you typically only build once)? Even KDE or Qt shouldn't take more than an hour to build nowadays, much quicker if you only build the core modules, and maybe a bit longer if you build it with all possible extensions.
for advent of code, no. for a big project , using namespaces even in cpp files (i've seen libraries doing that in header files) is not recommended.
That's correct and an inherent limitation. Signed numbers break down when you push them to the extremes of what they try to model, whereas unsigned (when used to represent non-negative integers) breaks down when you do everyday operations.
If by easier you mean "only way to make it work without bugs" then yes.
I agree, the issue tracker doesn't seem to get much of the developer's time. This is fairly common for small, single-dev open source projects. For us, this has been mitigated by the small, easy to navigate source. It's pretty easy to modify it to suit your needs, and I've submitted several patches that were all addressed and merged within a day. So while filing an issue might be slow, the single-header library is easy to customize and MRs are handled very quickly. I suspect that if the last comment on that issue had been submitted as an MR, the issue would have been closed. Overall I've been happy with the library, though you might have to do some tinkering if it doesn't do what you need out-of-the-box.
Okay, I'll take your advice and submit that one line patch as a PR. I didn't do that when I wrote the comment, because I thought it's too small of a change to be worth a PR. Besides, whoever needs the linked issue resolved can do the corrected loguru checking on behalf of loguru and explicitly set `-DLOGURU_STACKTRACES`, so musl users aren't left out, but it would be nice if LOGURU were to fix the problem.
How do unsigned numbers break down when you do everyday operations? You're using rhetoric to try and diminish the issue with signed overflow, and equate the so-called "*shortcomings*" of unsigned and signed. The issue with signed integers is that unless your signed integers are wider than the pointer size of the machine (this isn't the case for `std::ptrdiff_t` on any arch I know of) then you are **guaranteed** that there are array sizes that machine is capable of representing that you simply cannot represent, at all, and if you try to do so it's undefined behavior. There's no reason why: std::string str; str.resize(std::numeric_limits&lt;std::size_t&gt;::max() / 2U + 1U); Ought to be UB. Now that will crash, in the real world, on most modern PCs because most modern PCs are 64 bit and have nowhere near that much RAM or storage. But on 32 bit, or especially 16 bit machines that's suddenly not so ridiculous. Now the edge cases for unsigned are when it overflows (and does the wrong thing, rather than being UB) and when you perform arithmetic which is logically and mathematically negative. If you can get a negative size your program is completely busted since that makes no sense, and if you're going to overflow your program is completely busted since that also makes no sense. To summarize: - If you're going to overflow a `std::size_t` then your program is broken: How were you intending to fit that many objects in memory? If you're going to overflow a `std::ptrdiff_t` then in a large number of cases your program isn't broken, it's the type that's broken - If you're going to reach a negative result with unsigned arithmetic then your program doesn't make logical sense, and the argument from the pro-signed crowd basically amounts to: If you're going to compute `i = a - b` then it's much easier to remember to `assert(i &gt;= 0)` afterwards rather than `assert(a &gt;= b)` beforehand, because nothing else is really going to save you, you're still going to have a completely busted number floating around in your program
Here you go Towards Better C++ Modules - Part 2: Modules naming https://cor3ntin.github.io/posts/modules_naming/
`auto smaller_size = vec.size() - 1` oh look, I mixed a signed and unsigned type.
yes then the question is why to invent long names in standard if people will not use it and are expected to shorten it? Same thing happened to std::filesystem everybody uses namespace fs and so we got [P1005](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1005r0.html). I prefer to have a standard library which would be well usable as is. 
I thought C++20 was adopting two's complement as the One True Signed Integer Representation. Am I mistaken on that, or is that not enough to remove UB on signed integer overflow?
What's your point? Don't do that. Parenthetically that one line raises the question: How do we know `vec.size()` is non-zero? So: auto smaller_size = vec.size(); assert(smaller_size); --smaller_size; You could make the argument that if `std::vector&lt;T&gt;::size_type` were signed we wouldn't need the assert, and it's tempting to say that's true, but as I said before: &gt;This is just a reflection of the fact that such arithmetic doesn't make sense in the vast majority of cases if dimension is considered Where "*dimension*" is the units of the operation. Note that the correctness of this is implicit in the variable naming that you yourself presented since you called it `smaller_size`: It's still a size. Performing operations on it that would (mathematically) yield a negative result is broken, and it's just as broken yielding `-1` as it is yielding `std::numeric_limits&lt;std::size_t&gt;::max()`.
I like and use spdlog. But it was a bit difficult in async on windows with a mix of static AND dynamic lib all using spdlog. The header only make us do some extra work and the initialisation order may become important. I'll love to have a library version for cleaner usage in our context. The choice to use fmt is great. Replacing all our cout, printf.... make it real better. I like to be able to start logging application since startup with queued message til we give the name of the outputfile. 
&gt; How do unsigned numbers break down when you do everyday operations? Well, in the real world I can easily log how the container changes by computing size2-size1. If I try this with 'unsigned' it breaks down. Ok let me try reformulate since I can tell we're not talking the same language. Consider this: for (std::size_t i = 0; i &lt; container.size(); ++i) { foo(container[i]); } That probably doesn't matter, you're not actually giving `i` a logical meaning and you're not doing arithmetic, so nothing can really go wrong.. But then again this you pretty much never do this in C++11 anyway so it's a non-issue. However if you do something like: std::size_t measurements_during_this_cycle = x.size(); std::size_t measurements_during_previous_cycle = y.size(); where you're attributing a logical meaning to the size, well then this is a grave modelling error. I see this all the time where people confusingly give `unsigned` the meaning of a non-negative number. Or say that "this function can only return positive numbers, so I'll return unsigned". No please don't! If that number represent a logical quantity I have to cast it anyway to signed before I can use it. &gt; If you're going to reach a negative result with unsigned arithmetic then your program doesn't make logical sense, and the argument from the pro-signed crowd basically amounts to: If you're going to compute i = a - b then it's much easier to remember to assert(i &gt;= 0) afterwards rather than assert(a &gt;= b) beforehand, because nothing else is really going to save you, you're still going to have a completely busted number floating around in your program. Well no I think you're missunderstanding, - in your example `i` can frequently be negative, that entirely depends on what it represents. - saying something like "If you're going to reach a negative result with unsigned arithmetic then your program doesn't make logical sense" is what we want to avoid, we want strong types that prevents this from ever happening. So it's simpler to model non-negative numbers using signed numbers so that they behave correctly but check that they don't fall outside of bounds, compared to model non-negative numbers using modular arithmetic which have correct bounds but behave differently inside the bounds. Another more pragmatic viewpoint, based on the fact that the underlying problem are the all the implicit conversions together with unchecked overflow, is that it's simply less error prone to just use signed and where appropriate check that the bounds are maintained.
I'd say constrained lambdas are great for library stuff, but not for the main program code. In this case, `for_each` would probably end up hidden in some header file (as it will end up in `&lt;ranges&gt;` at some point, so it's fine to have a constrained lambda. A generic function object wouldn't look better TBH. For the main program logic, as terse as possible - to make it easier to read and reason about the logic. WRT your post, it is a great post for people that already followed the ranges evolution. Not so much for beginners - there are much prettier examples where ranges shine :)
&gt;Clearly the type of 'my\_height\_change' cannot be unsigned, regardless of how large numbers it can represent. I totally agree. Height differences are completetly different things than heights. The latter must be represented by `unsigneds`, the former by `signeds`. &gt;Hence 'my\_height' also needs to be signed if we want the behaviour almost everyone would expect from a number. I totally disagree: you are changing number domains and categories. That's the whole point! &amp;#x200B;
Well, if you do that you define the same macros as this thing is using. So everything should be good. As it is today, theses ones are "leaking" from the header, so you may have a warning that tell you that e.g. `NOMINMAX` was already defined. Maybe I shouldn't force them by default?
Perhaps our experiences differ massively but in my day-to-day programming if I perform a calculation on unsigned integers and the result would mathematically negative that represents a massive flaw in the program's logic the overwhelming majority of the time. Moving to a signed type isn't going to fix this. When you're doing a calculation with two sizes and the result **can** be negative then it **should** require care and attention, you **should** have to do something like: std::size_t measurements_during_this_cycle = x.size(); std::size_t measurements_during_previous_cycle = y.size(); using delta_type = std::make_signed_t&lt;std::size_t&gt;; auto delta = delta_type(measurements_during_this_cycle) - delta_type(measurements_during_previous_cycle); Because you're fundamentally changing what the thing represents/means. &gt;it's simply less error prone to just use signed and where appropriate check that the bounds are maintained. You're assuming that the check exists, and if a check exists you can just as easily check an unsigned integer as well. The fundamental issue is this: In a supposedly low-level, close to the machine language, why can't I have an array bigger than half the addressable memory size and address every element in it? The reason people give seems to be: Because people might write incorrect programs. Everyone is obsessed with working around the core of the issue (unsigned arithmetic wraps) rather than fixing the core of the issue.
Boost.Log as we're using Boost anyway. A bit complex to set up, but very powerful and configurable. The maintainer answers usually within a day, if you ask questions on stackoverflow.com
That's clever! 
I can really recommend Wt. Very powerful and feature complete. Version 4 uses modern C++. Support is outstanding. Paid support answers almost instantly, but also in the forums you get quick and good answers. Check out the gallery https://webtoolkit.eu/widgets 
Wait a minute. I don't like your definition. It consists of two parts (1) repeatable (2) no observable side effects Delete "observable," and then (2) implies (1) for free! One great way to get (2) is to disallow the function from basing its execution on the values of global variables. Then its result must be strictly a function of its inputs. 
TL;DR Modules offer us the opportunity to come up with a good naming scheme used across the entire C++ community. It also offers us the opportunity to be massively inconsistent and introduce additional possibilities for unnecessary inconsistencies and incompatibilities between various projects. I'm not really holding my breath for which option we'll go for.
The 'observable' qualifier means that a pure function may in its _implementation_ use side effects like assignments to variables and what not, as long as those aren't visible to the caller they might as well not exist.
Long live standardese. May it become more used, and perhaps drop/make optional a boost library dependence. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a3oi3o/book_cmake_cookbook_looking_for_opinions/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; Do you mean you've only used it for &gt; your &gt; hobby projects, or you'd only recommend it &gt; for &gt; hobby projects? yes.
You know the reason why? Such a useful little tool.
It's hard to specify, and hard to implement correctly. It'll come eventually.
The problem here is that `for_each` is now subject to accidental ADL, which is not the case for a lambda or function object.
You're right, thanks for the correction; I was thinking of C-array _declarations_, which take an expression of/convertible to size_t. Also, FYI, the latest draft is [N4778](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4778.pdf). :-]
Not so different. `std::iota` fills a buffer with monotonically increasing values. `std::view::iota` is a range of monotonically increasing values.
`std::forward&lt;decltype(foo)&gt;(foo)` can be safely rewritten as `decltype(foo)(foo)` 100% of the time. Yes, C-casts are evil, but only because they're error-prone, and this isn't.
You can repeat yourself all day long without explaining the rationale. If you allow unobservable side effects they damn well do matter to the caller. How do you propose to enforce (1) with hidden side effects? 
Not necessarily? They would have to specify, for each operation, the overflow behavior. But I guess that is not too hard (division and remainder of INT_MIN by -1 is a weird one). Also, UB is not the biggest problem. It is the missmatch between the behavior and the intuition on mixed operations, the most confusing one being the comparison. Two's complement is great, as it match modular arithmetic (except they messed up the signed division and remainder), but modular arithmetic has many ways to implement comparison. And programmers typically think true integers when they write a comparison. For instance: i+1 &lt; n and i &lt; n-1 become significantly different.
Instead of \`std::sort(std::begin(xs), std::end(xs))\`, write \`ranges::sort(xs)\`.
Yes, I indeed used N4659 as the pre-C++17 draft.
What do you mean by amalgamation? Amalgamation of what?
Amalgation of the source code [https://www.sqlite.org/amalgamation.html](https://www.sqlite.org/amalgamation.html) [https://github.com/vinniefalco/Amalgamate](https://github.com/vinniefalco/Amalgamate) &amp;#x200B;
There's advantages and disadvantages, advantage for things that are given out widely is that it's less source files to distribute, the disadvantage is if you're only working on them that you're going to have a harder time with tracking down specific errors and separating them. In terms of compiler optimizations? if your compiler supports link-time optimizations with its linker than it most likely won't affect too much unless you have a function that's like a 1 linker that's extern somewhere and you refuse to pull it into a header file to use it inline when it should be.
You just gave another example that shows scope is irrelevant... `hidden` clearly isn't a global variable in _scope_, yet the function clearly isn't pure. &gt; you have broken the chain of purity I have no idea what the "chain of purity" is supposed to be, but yeah obviously it's not a pure function if it does something like that. _But_ you don't need to touch any global variables for that, which is why I brought it up as an example for why ``` he should confirm the function does not read globals in its calculations. Then its result must be purely a function of its inputs. ``` Is bullshit.
&gt;I like this cost a bit better than inadvertantly overwriting data I promised not to. But you *didn’t* promise that. There’s a difference between `span&lt;T&gt; const` and `span&lt;T const&gt;`, just as there is a difference between `T const*` and `T*` const. This really shouldn’t be confusing but all these discussions shows that, apparently, it is.
In that example we had writes to a function-local variable. Scope is relevant where we read from a global variable. pure function g(x) return x * global Nothing bullshit about that. Watch your language.
Beast is a low-level library which implements the HTTP and WebSocket protocols. It is up to the users to write those "dedicated API for typical needs." When someone goes to write that middleware, Beast will take care of the protocol details so they can focus on making it easy to use. Beast does not "lack" anything, it is specifically designed to address a narrow set of concerns. It is the responsibility of intermediate layers to stack on top of Beast and provide the higher level abstractions such as AJAX, JWT, et. al.
What about \`noexcept(cond)\` in the lambda? Does that code perform as fast as possible (in C++, without assembly).
I think std::rng would be enough taking into account that the standard should be something well-known by everyone.
You can also do it in one pass by manipulating the string in place, using the left side of the string as a stack. See https://www.reddit.com/r/adventofcode/comments/a3912m/2018_day_5_solutions/eb4hp81 .
I don't know how often I have to reiterate this, you don't need to read any global variables to make a syscall. ``` pure function launch_nukes(bool mutually_assured_destruction) { if(mutually_assured_destruction) { api_t nukes_backend = connect("https://launch-the-nukes.org"); nukes_backend.post("/do_launch"); } } ``` No global variables, clearly this is a pure function right?
Your code runs off the edge of the screen and I can't read the body of the function. Could you please format it properly.
My point is twofold 1) In C++, signed values are much closer to the expected semantics of numbers 2) This piece of code is obviously correct template &lt;typename T, typename Callback&gt; void for_each_unordered_pair(std::vector&lt;T&gt; const&amp; vec, Callback cb) { for (size_t i = 0; i &lt; vec.size() - 1; ++i) { for (size_t j = i + 1; j &lt; vec.size(); ++j) { cb(vec[i], vec[j]); } } } _if_ `size_t` behaved like a proper number (in other words, was signed). It has a critical bug because of the fact that `size_t` does not behave like a proper number, but like a member of a closed group.
This seems to be related to unity-builds and is still relevant today. [A guide to unity builds](http://onqtam.com/programming/2018-07-07-unity-builds/)
Well, I think the listed naming rules make sense, are consistent with how C++ projects name namespaces already and shouldn't be a problem to adopt.
something is badly screwed up on your machine honestly you should inherently recognize that 
I've quick-read a couple of blogposts on the topic of C++20 ranges recently and I'm still not sure I see how all the pieces fit together. Will people here get mad if I post Rust here? I guess I'll just risk it. Suppose I have this Rust code: let strings = vec!["123", "456", "x", "789"]; let numbers: Vec&lt;_&gt; = strings .iter() .filter_map(|s| s.parse::&lt;i32&gt;().ok()) .map(|i| i as f32 / 2.0) .collect(); Can C++20 ranges do this yet? What would an equivalent C++20 'ranged' code look like? (I program in C++14 regularly but don't know much C++17 or C++20.) 
C-casts aren't evil because they're error prone. They're evil because they go through every other cast, which is inefficient if you simply want it to do what something like static_cast does, but don't want to type static_cast...
You're focusing merely on code working. Yes if `std::size_t` worked like a signed number the code you posted would work, but code working isn't a very high bar. I can write a program that works that uses `std::tuple` instead of actual objects. My point is that `std::size_t` actually has meaning: It's a size, not just a number. As such it shouldn't permit negative numbers anymore than `gsl::not_null` should permit `NULL`. This is where I take issue with your analysis: You seem to view `std::size_t` as just a number, and as such you think you should be able to effortlessly transition between units. Whereas I see it as a type which should model the domain it seeks to represent (namely size). template&lt;typename ForwardIterator, typename Callback&gt; Callback for_each_unordered_pair(ForwardIterator begin, ForwardIterator end, Callback cb) { for (; begin != end; ++begin) { ForwardIterator next = begin; ++begin; for (; next != end; ++next) { cb(*begin, *next); } } return cb; } The people running around preaching about wrapping are onto something, but their conclusion (we should just use signed types) is off in my estimation. The real answer is to synthesize a type which: - Has the properties of an unsigned integer - Has undefined overflow behavior - Can be instrumented to `assert` in debug mode on UB
&gt; They're evil because they go through every other cast, which is inefficient if you simply want it to do what something like static_cast does That has nothing to do with efficiency; that has to do with correctness. Neither correctness nor efficiency is an argument against avoiding `forward` as I suggested.
Inefficient at compile time? Maybe, but I doubt you will notice it. At runtime it doesn't "go through" anything, the compiler has already decided what kind of cast it will perform. They are evil because the type of cast you think it will pick and the kind your compiler actually picks are not always the same thing.
&gt; are consistent with how _some_ C++ projects _of the ones that actually use namespaces_ name namespaces already
We really don't need to devolve into C-istic half-words...
&gt; If you make a syscall clearly that is not pure. Yes, that's why I've been saying that checking whether or not a function accesses globals is not enough &gt; because it is not marked pure You started this comment thread by arguing the compiler doesn't need purity annotations &gt; Your code runs off the edge of the screen and I can't read the body of the function. Could you please format it properly. It's properly formatted, you're apparently just reading this on a tiny screen which really isn't my problem. In summary: I'm done with your BS. ``` ............................................________ ....................................,.-'"...................``~., .............................,.-"..................................."-., .........................,/...............................................":, .....................,?......................................................, .................../...........................................................,} ................./......................................................,:`^`..} .............../...................................................,:"........./ ..............?.....__.........................................:`.........../ ............./__.(....."~-,_..............................,:`........../ .........../(_...."~,_........"~,_....................,:`........_/ ..........{.._$;_......"=,_......."-,_.......,.-~-,},.~";/....} ...........((.....*~_......."=-._......";,,./`..../"............../ ...,,,___.`~,......"~.,....................`.....}............../ ............(....`=-,,.......`........................(......;_,,-" ............/.`~,......`-...................................../ .............`~.*-,.....................................|,./.....,__ ,,_..........}.&gt;-._...................................|..............`=~-, .....`=~-,__......`,................................. ...................`=~-,,.,............................... ................................`:,,...........................`..............__ .....................................`=-,...................,%`&gt;--==`` ........................................_..........._,-%.......` ..................................., ```
No, we do not need, so that every piece of code does: namespace r = std::ranges; No, wait, maybe &amp;#x200B; namespace rn = std::ranges; &amp;#x200B; No, I changed my mind, I meant: &amp;#x200B; namespace rng = std::ranges; &amp;#x200B; How about: using namespace std::ranges; &amp;#x200B; Well, wait, std::ranges is long, so people will make it shorter in their own ways, why not make the name shorter since the start? Many people use using namespace std; in their functions or .cpp files... 
&gt; I think std::rng would be enough taking into account that the standard should be something well-known by everyone. I suspect this namespace would be confusing to people using the `&lt;random&gt;` header... 
&gt;are consistent with how C++ projects name namespaces already and shouldn't be a problem to adopt. Which projects? I've never found consistency in how C++ projects name namespaces. Boost likes to use long and deeply nested namespaces, Qt doesn't use namespaces and instead prefixes all its classes, Folly uses one top-level namespace... there's no consistency.
Can't tell if satire
Agreed
A vector that allowed mutation on the data from a const member would be considered wrong and I think that this is the correct model I think correct code. Either way, I cannot change the standard, but I can keep my own contracts. And I get why it is the way it is, I just don't like it as it breaks assumptions in generic code.
It's not, and he's right – if you thought things were working as intended, that's on you.
Yeah, I couldn't get that in the short version! This is really important for file input iterators where EOF isn't really an iterated value.
The only consistent way forward is to do what the standard library does
Here's my guess, which I think gets you close: ``` template &lt;typename T&gt; struct cast_t { template &lt;typename U&gt; requires Constructible&lt;T, U&gt; constexpr T operator()(U&amp;&amp; u) const { return static_cast&lt;T&gt;(std::forward&lt;U&gt;(u)); } }; template &lt;typename T&gt; inline constexpr cast_t&lt;T&gt; cast{}; inline constexpr auto deref = [](auto&amp;&amp; e) -&gt; decltype(auto) { return *e; }; inline constexpr auto filter_map = [](auto f){ return view::transform(f) | view::filter(cast&lt;bool&gt;) | view::transform(deref); }; auto numbers = strings | filter_map([](std::string const&amp;){ /* ... */} | view::transform([](int i) { return i / 2.0; }); ``` There is no easy conversion to vector... yet, but probably will be. There might be a better way to do this?
So I heard we should put everything in `std` and name all our "private" identifiers `_Like_this`?
really? it's not satire. microsoft doesn't release editors that take a second to register a keystroke.
&gt; common examples being how do you get the square root of a number given sqrt sets errno My hope is that all those `errno`-using functions will be replaced by pure versions using Herbceptions.
1. Here's a dirty secret: the `std::ranges` namespace is designed such that you can just do `using namespace std::ranges;` and do everything unqualified. All the usual ADL issues have been worked around. This is safe. 2. I have been in favor of making pointers to members callable with function call syntax. EWG has opted not to act, though. -( 3. `ref_view` is used a lot under the covers to automatically turn lvalue `Range`s into `View`s. You generally don't need it, but it will be there if you do.
Yes can this be answered please, even if it asked poorly?
/u/eric_niebler IIRC (too lazy to look it up), in your 2013-2014 blog post about pythagorean triples, there were some performance issues either with clang or GCC on the order of ~100x slow downs. How is ranges performance today?
There is no `ranges::sort`. It's an additional `std::sort` overload :)
&gt; I wanted to show an example of a constrained lambda. I'm still trying to work out for myself if constrained lambdas make sense, or whether it's always better to write them as a custom class with less off-putting syntax. I mean, the blog post is using an `inline constexpr` variable. Typically `constexpr` implies `inline`, but not for variables, where `inline` might be used in this case to avoid ODR issues if the variable ends up in a header that ends up in different TUs, which is not show in this small example. In any case, the blog post back off very quickly from discussing any of these "details" when it just summarizes all of this as &gt; This declares an object for_each
Congratulations, and thank you, to /u/eric_niebler for their relentless push for ranges!
I know I might be looking for trouble but have you tried Rust? If you come from functional languages and wanna go the C++ way you might love it :)
&gt; It is fortunate indeed that linguists are not C++ developers. Think again. Conlanger and linguistics enthusiast here with [this project](https://gitlab.com/Kyarei/zt).
Awesome to see you extending the product! What are the quirks related to the Test Explorer? If it's a lengthy topic, please reach out at visualcpp@microsoft.com
There's more difference in 2 threads compared to 8 than even 10 years of progress in CPU architecture, and the amount of memory matters a lot as well. Realistically you can expect a complete build of LibreOffice to take 1-3 hours on a reasonable system.
Note that the triple backticks don't work on the old reddit. If you want your code to be formatted properly everywhere, you should put a leading 4 spaces on every line instead.
- there's a bug in your version - neither signed nor unsigned is the right type, but signed is closer - you want UB on going below 0, or alternatively - have subtraction return a different type
C++ `unsigned` does not mean "positive numbers and zero", it means "positive numbers and zero **with modulo arithmetic**". Modulo arithmetic rarely matches the semantics of working with sizes, indices, etc.
&gt; unsigned can't represent the correct behaviour because it models Z/nZ, not Z+. Can you elaborate on that? Sizes aren't negative. Z/nZ doesn't matter compared to signed types because they'd overflow even earlier and induce UB.
&gt; I totally agree. Height differences are completetly different things than heights. The latter must be represented by unsigneds, the former by signeds. Right, how do you suggest doing that? As was mentioned earlier in the thread you have two choices, either you 1. force the modular numbers into being non-negative integers by casting everytime you do arithmetic, or 2. use signed numbers and assert the range of values where appropriate. &gt; I totally disagree: you are changing number domains and categories. That's the whole point! You're missing the point. The result of a subtraction between two unsigned is again an unsigned, this is not at all how a non-negative number behaves.
I don't see how this comment helps the discussion at all.
&gt; there's a bug in your version By pointing out that there's a bug in throwaway Reddit comment code but not pointing out what the bug is (`++begin` rather than `++next` after `ForwardIterator next = begin; most likely) what were you hoping to achieve? Illustrate the importance of testing in a discussion about integer types? &gt;signed is closer If literally every system was 64 bit then I'd be more sympathetic to this point-of-view. As it is I've written valid programs that compile, run, and pass that deal with sizes larger than `std::size_t(std::numeric_limits&lt;std::ptrdiff_t&gt;::max())` so signed types fail on the most basic test for a type to represent a size: Being able to represent sizes. &gt;have subtraction return a different type This is the incorrect approach in my estimation because you can subtract two sizes and wind up with something that is conceptually still a size, for example: std::size_t size_without_prefix(std::string_view prefix, std::string_view str) noexcept { std::size_t retr = str.size(); if (str.starts_with(prefix)) { retr -= prefix.size(); } return retr; } In fact in my experience this is **most** subtractions involving sizes: They should never generate negative results. Calculations with sizes which legitimately need to yield negative answers definitely exist (deltas, for example) but I run into them rarely.
&gt; Perhaps our experiences differ massively but in my day-to-day programming if I perform a calculation on unsigned integers and the result would mathematically negative that represents a massive flaw in the program's logic the overwhelming majority of the time. I know this has been covered earlier in the thread, but let's reiterate anyway. I want to use the static type system to avoid having to remember to things like this. It's why we use types in the first place. As far as day-to-day experience when I call `size` on a container for me that represents the number of items in the collection, pretty much never (ok, very rarely) does it have anything to do with the maximum contiguous block of memory I can represent on the current hardware or anything like that. If I may ask what is a typical piece of code that you write where you use `unsigned`? &gt; std::size_t measurements_during_this_cycle = x.size(); std::size_t measurements_during_previous_cycle = y.size(); using delta_type = std::make_signed_t&lt;std::size_t&gt;; auto delta = delta_type(measurements_during_this_cycle) - delta_type(measurements_during_previous_cycle); Yes this is the workaround you have to do to force modular numbers to behave like non-negative numbers. Why not just use signed numbers from the start and get the correct arithmetic behaviour automatically? It's far less error prone. &gt; The fundamental issue is this: In a supposedly low-level, close to the machine language, why can't I have an array bigger than half the addressable memory size and address every element in it? The reason people give seems to be: Because people might write incorrect programs. During my 10 years of writing C++ this has always been a pretty much non-issue, while accidental bugs involving signed/unsigned comparisons, arithmetic etc I see semi-frequently. &gt; Everyone is obsessed with working around the core of the issue (unsigned arithmetic wraps) rather than fixing the core of the issue. The real solution is of course to not use primitive data types when your number actually represents something logical, such as your `measurements_during_this_cycle`, unfortunately it's clunky in C++ without having opaque typedefs.
You don't want messages at all then. You want structured logging.
The thing that all the `unsigned` proponents get hooked up on are the values represented, which of course is only half of the picture. You also have take into account how the numbers behave when used together with binary operations (+,-,/,*). The difference between sizes can be negative, while the difference between two numbers in Z/nZ are not, hence they are not the same and a poor fit.
We use [log4cxx](https://logging.apache.org/log4cxx/latest_stable/)at my work. Can't really compare it to anything else, but it gets the job done. I think one reason why we use it is because we have both Java and C++ in our code base and probably chose a common-ish log system for both. &amp;#x200B; Then again, we use ant for our C++ builds too...
I've been a reluctant convert to an amalgamated approach over the past year or so. I like how it reduces the lines of code and leads to faster builds, when building from scratch. It surprised me as an approach, but it has grown on me. I think it's worth checking out.
For common things that is exactly what c++ should do. Makes reading more efficient.
"Modulo" is the way it is because of programmers forgetting the difference between "modulo" and "remainder" (the latter being the behavior we actually have). 
I argue that a difference between sizes is always non-negative. If you're calculating a negative value from two sizes, then this resulting value is not a size. With unsigned sizes this conversion is explicit and obvious.
Chromium has support for unity builds and it halves the build time
The compiler doesn't pick which kind of cast to use; the standard specifies that a C-style cast is equivalent to the first well-formed expression from the following const_cast&lt;ToT&gt;(from_v) static_cast&lt;ToT&gt;(from_v) // Special case: treat all inheritance as if `public` static_cast&lt;cv ToT&gt;(const_cast&lt;cv FromT&gt;(from_v)) // " reinterpret_cast&lt;ToT&gt;(from_v) reinterpret_cast&lt;cv ToT&gt;(const_cast&lt;cv FromT&gt;(from_v)) That said it's still not necessarily obvious which kind of cast is performed.
I really really hope, typical ranges code will not look like this. Otherwise they are much less useful than I thought. 
We're the authors of the Boden cross-platform framework which recently got attention on Hacker News and GitHub. We're happy to get feedback and answer your questions!
In [this talk](https://www.youtube.com/watch?v=IY8tHh2LSX4), Titus Winters mentions that there's a plan to eventually move the current `std` algorithms (and other things replaced by ranges) to a `std::legacy` namespace and promote the `std::ranges` namespace to just be `std`. I think that would certainly help with the verbosity, but I'm sure if it's really feasible (I think the commitee is scared of such breaking changes?).
I'd like to add, that the problem is not typing (I assume everyone is using autocomplete these days). The problem is readability. 
Oh yes, this is a good advice. Thank you!
&gt; This is safe. As long as there are no name collisions?!
It also does not hold with the natural numbers, which `unsigned` is supposed to "model". Pretending unsigned numbers represent, or even try to approximate Z, is the mistake here.
If you define signed division so that it rounds towards minus infinity, "remainder" and "modulo" are the same. The mistake was to round towards 0.
&gt; A vector that allowed mutation on the data from a const member would be considered wrong and I think that this is the correct model I think correct code. It's not a vector though. It doesn't own the memory. It's member is the pointer, not the pointee.
&gt;Here's a dirty secret: the std::ranges namespace is designed such that you can just do using namespace std::ranges; and do everything unqualified. All the usual ADL issues have been worked around. This is safe. What about this? using namespace std; using namespace std::ranges; sort(std::begin(foo), std::end(foo)); // what happens with ADL?
Which means?
Like I said, I understand that. I just don't agree that it is the correct interface. In generic code, where one does not know it is a span, just a Container const &amp;, a const iterator, or whatever. span&lt;T&gt; const's semantics allow for a more prominent for of error that is harder to see.
Nothing of that works in the current standard without pulling tons of dependencies. And not sure what signedness has to do with any of this. You've just asked what is the usage for `size()`. You've found at least `21` such usages in your codebase. Other might have more.
**Company**: 128 Technology **Type**: Full Time **Description**: Do you want to solve complex problems and build systems that will change the Internet? Do you want to be part of a company that is on the cutting edge of technology? Do you want to work with a world-class team of engineers? Do you have what it takes? The engineering team at 128 Technology is looking for a software engineer focused on developing industry leading software based routing solutions. There is the opportunity to work with new technologies and multiple large-scale networks, each with their own unique challenges, requirements, and business goals. We are looking for extremely motivated engineers who can work collaboratively to help build carrier-grade networking infrastructure. RESPONSIBILITIES**:** * Design for solutions for next-gen routed networks. * Develop state-of-the art routing solutions while implementing and supporting interoperability with legacy routed networks * Customer design first mentality to make software easy do deploy and use. QUALIFICATIONS**:** * B.S. or M.S. in Computer Science, Electrical Engineering, Computer Engineering, or a related technical field * 8+ years experience in developing large-scale software/network systems and services software on all platforms * Computer Science fundamentals in algorithm and object-oriented design, problem solving, data structures, and complexity analysis * Extensive working experience with development, debugging and testing multi-threaded applications on distributed systems. * Thorough understanding of IP networking and socket-based programming * Excellent C++ developer and debugging skills * Intimate understanding of IP Routing Protocols such as; BGP, ISIS, OSPF. * Demonstrated ability to mentor other software developers to maintain architectural vision and software quality. * Ability to deliver clean, modular code quickly and efficiently * Strong background in developing networking software applications on Linux/Unix. BONUS POINTS**:** * Familiarity with Free Range Routing, Quagga, Zebra * Working experience with C++11/14 * Team player with strong interpersonal skills and able to adapt and thrive in an Agile environment. * Experience with Test Driven Development and Continuous Integration * Good sense of humor. **Location**: Burlington, MA **Remote**: No **Visa Sponsorship**: Yes **Technologies**: C++11/14, Linux/Mac **Contact**: To apply visit [https://www.128technology.com/careers/](https://www.128technology.com/careers/)
Could you shed some light on why the committee killed std2?
**Company**: 128 Technology **Type**: Full Time, Software Engineer- Application Services **Description**: Do you want to solve complex problems and build systems that will change the Internet? Do you want to be part of a company that is on the cutting edge of technology? Do you want to work with a world-class team of engineers? Do you have what it takes? The engineering team at 128 Technology is looking for a software engineer focusing on developing a highly scalable distributed networked applications. We are looking for extremely motivated engineers who can work collaboratively to help build carrier-grade networking infrastructure. RESPONSIBILITIES: * Design and develop large-scale, distributed systems and services * Develop robust data storage solutions around NoSQL databases * Develop scalable real time, fault tolerant, high throughput message and event driven services QUALIFICATIONS: * B.S. or M.S. in Computer Science, Electrical Engineering, Computer Engineering, or a related technical field * 5 - 7+ years of experience developing large-scale software systems * Computer Science fundamentals in object-oriented design * Computer Science fundamentals in data structures * Computer Science fundamentals in algorithm design, problem solving, and complexity analysis * Demonstrated ability to mentor other software developers to maintain architectural vision and software quality. * Thorough understanding of IP networking and socket-based programming * High degree of competency working with multi-threaded development * Excellent C++ developer and debugging skills * Ability to deliver clean, modular code quickly and efficiently * Experience developing on Linux OS BONUS POINTS: * Experience with Agile development process * Experience with Test Driven Development and Continuous Integration * Working experience with C++11/14 * Familiarity with networking and or routing protocols * Familiarity with Linux networking functions * Good sense of humor **Location**: Burlington, MA **Remote**: No **Visa Sponsorship**: Yes **Technologies**: C++11/14, Linux/Mac **Contact**: To apply visit [https://www.128technology.com/careers/](https://www.128technology.com/careers/)
Clang has caught up. This benchmark shows that the range-v3 solution is "only" 2.4x slower than writing a triply-nested `for` loop: &lt;http://quick-bench.com/Zy9RklAoALbF7-mcXsb7I_-K1Y8&gt; 
where is ptrdiff_t not big enough? 32bit systems where you are actually using more than half the memory (and your elements have size == 1)? (I believe you, just curious) 
&gt; Subtracting a smaller number from a larger one has no meaning there. Exactly, which is why it should error, instead of silently wrapping around.
Forking the Standard Library is bad, and will create headaches and confusion forever. They had a point.
The compiler will complain that `sort` is ambiguous. 
If there are name collisions, the compiler will tell you about them by complaining about an ambiguity at the point of use.
My crystal ball is currently at the shop. That would be a pleasant but distant future.
&gt; decltype(foo)(foo) &gt; [...] Yes, C-casts are evil Technically, this isn't a C-style cast, it's a functional cast. In C++, a functional cast is equivalent to a C-style cast, but it's not valid C. Sorry, I'll get back to work now.
That's huge progress. `view`s are pretty powerful, which makes it easy to construct state machines that do not look much like classical nested loops.
I hope we can get language support for functions and function templates that aren't find-able by ADL, and that suppress ADL when found by normal lookup. That would help greatly.
I need to write a "6 Easy Pieces" for ranges.
Ah ok. I had a different understanding of the term "safe".
That would simplify things.
A simple example: today I weight x lbs, yesterday I weighed y lbs, how much did my weight change? x-y? My weight like a size is non-negative, is my weight change also non-negative?
 auto strings = {"123"sv, "456"sv, "x"sv, "789"sv}; auto vu = strings | view::transform([](auto &amp;&amp;s) -&gt; pair&lt;int64_t, bool&gt; { int64_t n = 0; bool b = from_chars(data(s), &amp;*end(s), n).ptr == data(s); return {n, b}; }) | view::filter([](auto &amp;&amp;t) {return get&lt;bool&gt;(t);}) | view::transform([](auto &amp;&amp;t) {return get&lt;int64_t&gt;(t);}); vector numbers(vu.begin(), vu.end()); 
In this context? Yeah I don't know modules so you'll have to take it as a guiding philosophy instead :)
32 bit systems are the culprit that immediately comes to mind. 16 bit systems seem like they'd be even more ripe for this issue, but I've never worked on one in an instance where I'd have run into it. I remember at least once writing a unit test that created a container of size `std::uint32_t(std::numeric_limits&lt;std::int32_t&gt;::max()) + 1U` to use as degenerate input, ironically, to a serializer for a protocol which used signed integers to represent sizes, just to make sure the serializer rejected it.
I never considered std2 a fork of std. Just a much better name space for range based algorithms than `std::ranges` and a place to put improved but incompatible versions of things like vector or unordered_map. But anyway, that ship had apparently sailed. 
You realize this is a thread about a future STL container and whether its size member function returns a signed integer? I wonder why you even answered when you aren't interested in a discussion about either...
... and can be easily passed as arguments to other function templates
Ok, misunderstood what you meant by "safe."
Thanks!
&gt;Then again, we use ant for our C++ builds too... Oh dear....
YW!
Dereferencing `end` will probably explode if you have "debug iterators" like in MSVC. You'll need to use `std::addressof`, `std::pointer_traits::to_address` or `std::pointer_traits::pointer_to` or some combination of those )). Or `data(s) + size(s)`.
But why? And also: &gt; dlopen. This system call does not seem to work in a statically linked executable. `dlopen` is not a system call.It's a library call and you can implement it yourself using `open` `mmap` and `mprotect` system calls.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a3t82h/help_me_with_this_problem/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The difference is |x-y| if we're talking about actual weights. There's no weight of -13 lbs. There's only a delta-weight of -13 lbs. So let me rephrase what I wrote earlier: there's no difference between sizes that is negative and also a size. 
Really cool. I am a big fan of static linking. It gets rid of a lot of potential weirdness. In addition, it is much easier to have a single binary that will just run.
&gt; I know this has been covered earlier in the thread, but let's reiterate anyway. I want to use the static type system to avoid having to remember to things like this. It's why we use types in the first place. I'm trying really hard to understand that, but I currently simply cannot. How does relaxing the domain of a certain value give you stronger guarantees at compile time?
it took me \~ an hour to master the paths module in python. In cpp it takes ....wait is it even possible to master? I totally agree about + being confusing, but there can just be a simple function such as os.path.join in python which allows me to write (dir1,dir2,dir3) and get dir1/dir2/dir3 &amp;#x200B; the really cool part is the function that returns the home directory for the user....Alas I digress, think boost should take a long look at the python system. 
Thanks; I'm not all that familiar with MSVC-land since I mostly program for *nix or embedded. I believe you, but I would've thought dereferencing would be a no-op there because I was immediately taking the address. Anyway, replaced `&amp;*end(s)` with `&amp;s[size(s)] - 1` — that should work fine on any reasonable implementation, right?
&gt; &amp;s[size(s)] Nope. `string_view::operator[](size())` has undefined behavior. /u/---sms--- had it right: `data(s) + size(s)`.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a3tm9y/3_char_returning_the_same_value_even_though_they/eb914cv/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Good point. Would this specific case still be UB?—all the strings are NUL-terminated and the result of the operator isn't used. In any event, you're right; better safe than sorry.
I've also created a couple docker images for exactly this purpose: https://github.com/foonathan/docker Really small images for building fully statically linked executables compatible with any Linux.
Wow, this is ambitious!
Also, usually faster, especially with LTO.
As you say, LTO basically renders it irrelevant.
... How... How is that 'clever'? It's incredibly obvious as to what is happening.
New type attribute: `indexing`. Wrapping is undefined (or an error), never &lt; 0. Gains optimization potential of signed and unsigned.
Does this avoid the need to use Swift/Objective-C to write IOS apps?
I don't suppose you'd have some search terms or articles to learn more about this, would ya?