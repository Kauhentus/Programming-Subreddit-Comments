I covered that already. &gt; this allows one program to be latter expanded to using two separate If you used the singleton every place that uses the singleton needs to somehow know which context it is on. If you pass the container around, just pass a different container around when you want one object to use a different sound card. Argument passing is cheap, and flexible for requirements that you don't know about. Singleton locks you into design that is much harder to fix latter if wrong. Again, I'm not saying never use singleton. I am however saying that it is the wrong solution for most of the cases where it is used. Better to pay a small price at design time to not have one, than to pay a large price latter when something changes.
I'm guessing you don't do a lot of multi-threaded programming. The global allocator can destroy any gains you work for by using threads. If you don't have thread-managed memory pools, your program will likely spend a lot of time waiting on the global allocator. This is not rare in the real world, nor is it a C++ specific problem.
&gt; This release contains one new library and numerous enchancements and bug fixes for existing libraries. The new library is "uuid" (overdue, IMO). Boost is one of the best things to happen to C++ in a while, IMO.
I would actually avoid these above and the "effective" books until after you are comfortable with the language, STL, and std. libraries in their simpler basic usage. I think way to many people obsess about the right way to do singletons or factories way too early. Getting things "perfect" is actually very difficult. So start by looking for easy ways to get them done, and go ahead and have the edge cases bite you in the butt and then you'll know personally why there things like scope guard and arguments about the right way to cast to bool and such. Some details not to miss early on though: const-correctness. Note that you can overload on const-ness. explicit vs. implicit conversion. The "clone" paradigm is very useful. The first thing you really need to master is remembering that every pointer needs to be owned by someone, and you need to be checking yourself that every owner is properly managing those things that they own and will clean them up whether or not an exception is thrown. I don't necessarily agree with the other fellow that every new and delete be in a constructor or destructor, but that is one approach to managing the problem. (auto_ptr is another, it has pitfalls too) But don't jump down these rabbit holes too soon: Don't go overboard with templates. If are spending more time trying to understand partial-template specialization and "Substitution Failure is Not An Error (SFINAE)" before you have written a lot of code you are wasting your time. You probably don't need them yet, we lived without them for a long time and got along fine! Boost has a lot of crazy crap in it. Extremely well done and potentially useful crap. But if I were you, I wouldn't even touch the good-old reference-counted pointer until you've mastered the basics. Until you find yourself tempted to write your own, then you really should be using boost instead. Don't try to write any "libraries" or "utilities" as a novice. You know, code that think will be useful to you in the future. There is almost zero chance that you will be happy with this code in the future, and you probably just doing it to procrastinate doing anything that really does anything. The most important advice for you is to work as follows: Write a little bit of code. Compile it. Try to do some sort of test that it works. repeat. Try to never get in a state were you can't do the whole cycle at least 5 times a day. The longer you go unable to compile or test the more bugs and more headaches you are making. Any function you have to scroll way up and way down to get from the first { to the last } is full of bugs. Keep your code chunks small enough to understand the whole thing. enjoy yourself!
Looks line a fine release and look, my favorite personal gripe was fixed: Program Options: Add general split function: split_unix() (#2561). 
hear, hear. I recommend these video lectures (or the book, which you can also get from the same page): http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/ They take you through all the major programming concepts, which really helps to broaden your horizon, even if you will never write a single line of lisp or scheme in your life. And since they use Scheme to implement each of these concepts, it gives you a much more concrete and complete picture of the underlying semantics of each (at least in my opinion). Much less magic and hand-waving than in most other approaches to the subject.
OpenMP is not a library. MPI is for distributed memory. OpenCL is for accelerators. TBB and Fastflow are similar. TBB exploit lock/CAS based synchronizations whereas Fastflow nonblocking synchronizations. Anyway Fastflow is the only one among those exploiting a lock-free approach.
Can someone convince me this isn't the death knell for gcc?
If CLang (1) can build CLang (2), and then you build CLang again (3)... The blog says that it all worked and tests passed, but shouldnt #2 and #3 then be binary identical? I'd be curious to see if that's true, and if not, why not.
Well, it handles the C++ that it itself is written in, not /all of/ C++, yet. But, since it's got backing it may be the death of it eventually. 
gcc is also bootstrapped that way.
For _italic_ you could use underscores, like \_all of\_.
I know, but I don't like them. I like '/' because it works in or out of markdown, wiki, email, everything. It's onomatopoeia for text. 
| stackless coroutines with Asio That could be awesome. 
you linked to #comments part of article
Just wondering, why are you setting x, then getting x immediately afterwards? Why not just test if a &gt; 50? Anyways, if you return an int reference (int&amp;) from getX, then you can keep a reference at the top of the loop scope, and set it and get it using the same variable.
make x public?
&gt; shouldnt #2 and #3 then be binary identical? Not always. Linkers have been known to put information like the time the linking was done inside the file. I've heard one story about a bug that depending on the phase of the moon because the guy added the phase of the moon as a joke, but screwed up the buffer lengths. Still, on systems where the linker doesn't try to get cleaver, this is a good check.
Not sure where your comment went, so in reply: If you use a reference to an integer, as so: int&amp; y = smellsFunny[i].getX(); // where getX() is defined as such: // int&amp; getX(); to return a reference to a member variable It is essentially an alias to the variable x, and can be written to and read from directly as if you were working with x.
Yes - it was just one article on a long page otherwise (with no anchors, I checked). I would have had to give the main page link and say 'scroll down to: ...'. I tried the comments, and that made a better link. 
In my case the killer feature for static analyzers (besides correctness / low false positives) is ease of use. If I have to compile something there's a big chance I won't be using it. Cppcheck for example is a free and easy to install/use checker. I also know of PC-lint and Coverity, but these are expensive.
There is a difference between double radius = 0.0; and double radius(0.0); The difference is that the "=" notation could end up calling the default constructor, doing an implicit type conversion on the number, then calling the copy constructor. The () notation calls a non-default constructor to begin with. You could end up using an extra temporary object by using the "=" notation. For built-in types the compiler will likely optimize this out, but for non-built in types you could be paying a performance penalty for the default constructor. I seem to remember this being mentioned in one of the Scott Meyers books.
This is really old, but I'm glad you posted it, as my teacher never taught us that.
C++ as a first language in the '90s is not the same C++ as the kids today are using. Modern C++, the stuff that's in the Scott Myers books, the boost libraries, and C++0x, is a dramatically different beast. Templates provide an incredible power, but at the cost of great fragility. Exceptions dramatically change how code is structured. People like to pretend they can avoid them, but that's dubious to me. I didn't say treat C++ as more advanced C. I agree that good C++ code is not good C code. What I said was, understanding the abstraction that C++ provides is valuable. Otherwise, you'll never understand funny terms like "binary compatibility", "name mangling", or why delete and delete[] and free are different things. Incidentally, understanding that Java is bytecode is also valuable.
iostreams suck as they make it impossible to i18n your program. If you want type safety and extensibility, use [boost::format](http://www.boost.org/doc/libs/1_42_0/libs/format/index.html).
It only sucks if you want to internationalize your program.
yes, boost::format is actually really good about all that, even if its balls-slow. still, i prefer it over the alternative, which is really ugly code just to print out a string. i, for one, welcome our new &lt;iomanip&gt; overlords...
Lisp is too ugly.
What is so hard about i18n with iostreams?
Two problems: fragments and reordering. Consider something like `cout &lt;&lt; "the user's name is " &lt;&lt; name &lt;&lt; " and is " &lt;&lt; age " years old" &lt;&lt; endl;` The output has three sentence fragments but translators need to work with the whole sentence (different uses of "and is" may need different translations depending on the full sentence). The other problem is that this example always prints name before age, but depending on the language, it may be better to print the age before the name.
Normally i18n is done with an additional level of indirection that handles figuring out what the format is for your specific locale. Said entity is the one that should be invoking operator&lt;&lt;(ostream&amp;,T). Particularly if you are reordering elements depending on locale, it's helpful to have a typesafe way of specifying what the args to the formatter are.
Spirit.Karma (from boost) is fast, elegant and unbelievably flexible: http://www.boost.org/doc/libs/1_41_0/libs/spirit/doc/html/spirit/karma/performance_measurements/numeric_performance.html
Even in English we already see your problem. &gt; and is " &lt;&lt; age " years old" If age == 1 that should be year old not years. Some languages have much more complex plural rules.
Since LLVM works on Windows, and Clang didn't, does this mean that, at least theoretically, Clang could now be made to work on Windows?
And there's a simpler way to do stuff like that...yeah it's not packaged up in boost but it's not much code either: http://pastebin.ca/1800272
Wow, there is almost no difference between struct and class in C++, yet this person gets the differences wrong anyway. "You can even forward-declare your class using one keyword and then define it with the other, though compilers have been known to complain about this usage:" - No, you can't forward declare with one keyword and then define with the other. It violates the C++ standard, and recent versions of many compilers reject it.
The article forgets to mention that structs have public inheritance by default, and classes have private inheritance by default.
He showed it in an example, but didn't mention it explicitly.
It does mention this and provides examples. I mean that's what I dislike about this article though. It uses up so many paragraphs and wordings to make a very simple statement that it becomes hard to actually find out just what the difference is, not to mention that in trying to be so overly comprehensive, it ends up getting a detail about forward declarations wrong. It really should just be a two sentence entry: - Default access and inheritance in a struct is public, for a class it's private. - struct can't be used as a template's parameter type whereas class and typename can. Done.
You'd think those two sentences to be sufficient to educate a person on such a simple matter. But you're not just explaining it to newcomers. Someone needs to explain it in a way that 10yr C++ veterans -- veterans that have operated under a contradictory view for those years -- will get it. After all, they've got 10 yrs of experience. All those extra words and examples are to point the point in over and over until it sticks. Just because it's simple doesn't mean it's easy to accept.
I use [astyle](http://astyle.sourceforge.net/), it seems quite good with lots of options for different code styles, and has yet to choke on anything I have thrown at it.
I like the indenting built in Qt Creator- you can highlight all your code and it auto indents everything the way I like it. 
vim: ggVG= ta-da :D
gg=G or G=gg :D
This is why I included that statement in the article: this IS allowed by the C++ standard, but some compilers reject it. Try it out yourself in Comeau Computing's online compiler (widely regarded as one of the most standard conforming compilers) http://comeaucomputing.com/tryitout/
The best tools are free. I came in to say the same thing :) gg=G is epic win
cb works pretty well 
bcpp for cpp
Emacs
Neat thanks for the new tool.
Thank you so much!
[Visual assist](http://wholetomato.com) does a pretty good job.
http://uncrustify.sourceforge.net/
Hmm, something like described in the following link? http://www.suodenjoki.dk/us/archive/2010/cpp-checkstyle.htm
I don't know if this is cout magic as much as it is a laundry list of why iostreams just sucks balls. 
 * Astyle : Spacing &amp; Moving Braces only. EOL handling is a bit weird. * Bcpp: Pretty basic. * Uncrustify: Lots of options. Can force blocks to have braces &amp; Sort your includes. * GreatCode: Windows Only? Check out Universal Indent Gui to help you get up and running: http://universalindent.sourceforge.net/ NOTE: The advantage of one of these over using an editor is that you can run it across your entire codebase in one or two commands, and you can also make it a trigger in your source-control if you want, so you always have code is SC in the "right" format which makes Diff/Merge much easier. *Edit for formatting &amp; Note.*
Comments like this are the reason reddit isn't just a drag on my time and soul. Imagine what undergrad programming would be like if these were commonly recommended. What a savings that would be.
Here is what I do in emacs Choose a mode: M-x c++-mode Choose a style: M-x c-set-style stroustrup (i set my .emacs up to do this for me for all C++ files) then Select buffer: C-x h Indent selection: M-x indent-region some times also: M-x whitespace-cleanup sure would be nice to have these three in a single command, but I'm too stupid with lisp to do it, any ideas?
"class vs struct" is as old as the web. Why write these articles? Is this like a kid discovering a new rude word then using it all that week?
You should add a c-hook to set stroustrup mode. You can also adjust the auto-mode alist to match certain file names (say ones that end in .cpp) to C++-mode. Then to reformat the buffer, check the key bindings for indent region.
It is an old issue, but people STILL get it wrong. Hence the article.
Undergrads don't really count. If someone is getting this wrong, then they can't program C++, so why do they claim to?
Any of them integrate in visual studio nicely?
Thank you! I spent quite a bit of time researching it for my job. We're currently integrating Astyle (Artistic Style) into our process as it seemed like it had most of the feature set we wanted, and was fairly easy to set up. To handle the EOL issue, we just pipe the file through dos2unix first, then through Astyle. The only thing that I really wish it had that it doesn't is the ability to force braces around blocks. I'll have to dig into the source code again and see if I can figure out how to add that.
I thought it was called ducK typing http://en.wikipedia.org/wiki/Duck_typing
I think they mean [duct taping](http://en.wikipedia.org/wiki/Duct_taping).
It is- the person who wrote the article didn't know and was corrected in the comments.
&gt; In other languages (specifically, in languages with so-called “duck” or “duct” typing), such automatic conversions are syntactically correct. Members get mapped based on the name as a part of the conversion. Consider the following JavaScript example which defines two object types. As is typical in JavaScript, this is done by simply defining the constructors. An instance of one type is then created, and converted automatically to the second type This is totally incorrect. The first type is not "converted" to the second type. In the example given, `w=v` causes `w` and `v` to point to the same object of type `PointType1`. The object of type `PointType2` that `w` pointed to is no longer accessible and will get garbage collected.
Am I the only one who can't see this in Firefox? It complains about some XML parsing error, probably some non-html-entity-encoded code samples. Is there a way to turn this conforming nazi-ism off in Firefox?
If you are posting a bunch of code you should FIRST write what it does before diving in! I can't be bothered to read code if I don't know if I will care!
Marco Aldinucci, Marco Danelutto, Peter Kilpatrick, Massimiliano Meneghin, and Massimo Torquati. Accelerating sequential programs using FastFlow and self-offloading, Università di Pisa, Dipartimento di Informatica, Italy, number TR-10-03, February 2010. http://compass2.di.unipi.it/TR/Files/TR-10-03.pdf.gz
"You must have Javascript enabled to view this site." Next.
I thought concepts had been pulled from the upcoming standard?
That was my thought exactly. I guess this guy hasn't got the memo. 
FWIW, 'this guy' is Dave Abrahams (ISO C++ committee member and founder of Boost). I'm pretty sure he knows concepts aren't in the next standard. It seems like many of the big players in C++ remain very interested in concepts (Stepanov's new book Elements of Programming for instance is heavily based on concepts), and I think the point is less about writing C++10 than as a thought experiment to try to figure out what the right design for concepts in C++1x is (since, after all the whole reason it is not in -10 is that the proposal at the time was not fully baked).
Good to know.
This is relevant to my interests. Can somebody who has experience with this lib share their experiences? What would I gain/lose vs. using Intel Threading Blocks for instance?
This looks pretty interesting, but seems pretty cumbersome, especially if very high performance data sharing at multiple levels is involved...it may lead to too much verboseness (class overload). I think their ideas are good, in fact I'll borrow some to help make our own internal threading library more robust. I'm not exactly fond of how they are using exceptions to bail out and clean up the thread blocks, that seems like a "hack" to me, but I'm not sure what other way could be used to cleanly have the same effect.
While reading the Design and Evolution of C++ book I noticed that all of his examples called some error() function. I thought it was just a simplification for the book, but there it is, error.c! 
[From Herb Sutter himself](http://herbsutter.wordpress.com/2010/03/03/where-can-you-get-the-iso-c-standard-and-what-does-open-standard-mean).
What good is the ISO anymore? Just publish your documents as PDF or whatever and be done with it.
I think you may be confusing these two: http://en.wikipedia.org/wiki/International_Organization_for_Standardization http://en.wikipedia.org/wiki/ISO_image The later was defined by the former.
&gt; I think you may be confusing these two: No, I think LordVoldemort is referring to the open/free/libre/gratis debate at Sutter's blog. "What good is the ISO?" is a good question. Lots of languages and technical standards are defined by communities who have an open membership and open archives. I think the ISO has value, but its core competency is standardizing things other than programming languages.
OP you should edit the title to state on click it will download a pdf file..
Very nice read, thanks.
Many of them require a third-party library (eg HTTPS, SOAP and 'Send email'). While these tasks are ok for languages that are distributed with libraries that implement such things for C++ it just doesn't fit. -- www.josuegomes.com
I would liked to have read this but I cbf installing a shitty PS viewer.
I don't think you can do that, can you? Sorry, I thought about that after, when people had already voted for it (hated to lose those votes. Plus, I've found that when you cancel a story you can't resubmit, it says it's already been submitted).
Hey, site owner here. I'd like to apologize for the site being read-only at the moment; you've caught me in the middle of a server migration. (Hey, it's Saturday night. You guys should be out watching a movie or something. ;) )
Rosetta Code is very practical-minded, at least as far as I'm concerned. (Just call me the local benevolent dictator.) We're not focused only allowing libraries and features that are built-in or de jure standard. If you need to call into SDL, GDI, OpenGL or DirectX to solve a problem, then that's what you need to do. If a third party library is how you should solve a problem in C++ (and I expect the vast majority of problems on RC have been solved in C++ at one time or another; coding in it is my bread and butter), then that's an acceptable way for it to be demonstrated. Incidentally, the only third-party library strictly required for any of the problems you mentioned is the platform's network libraries. That doesn't make it the *smart* way to do it, of course. In fact, I wouldn't recommend it be shown solved that way; if there's anything interesting about the solution, it's probably best broken into parts, and if there's not, then it's probably best not to risk someone putting copypasta in their own codebases.
Hah thanks, I don't know why I didn't think of searching for an online converter. Turns out the paper isn't really all that useful.
The site is extremely slow to respond to link clicks today (Sunday around 11am PST)
For a variety of reasons, things didn't finally settle until around 3PM EST Sunday. prgmr.com hosting seems to have some quirks; near as I can tell, there's been some horrid latency between when an HTTP request is sent and when the domU RC is running under even saw the connection. It may be the dom0's scheduling rebalancing resources; restoring a 1GB DB dump into MySQL is expensive.
Hello, 1995.
On the site my handle is [Sc4Freak](http://rosettacode.org/wiki/Special:Contributions/Sc4Freak) (I joined not long ago). I added a C++ implementation of [Huffman Coding](http://rosettacode.org/wiki/Huffman_coding) but it still shows up in the "Tasks not implemented in C++" page. Any ideas?
FTFY: changed `Cpp` to `cpp`
Hi. I think the best thing to do if you're using visual studio is to work with it's own gui library, at least until you become familiar with working with visual studio.
You need to add the include and lib paths in VS options
Ah, that sound like what I'm looking for. Where and how do I have to add the paths in the options exactly?
Look in Tools-&gt;Options-&gt;Projects and Solutions-&gt;VC++ Directories
I disagree. I admire OP's ambition and interest in alternative libraries. But I do agree that if he has never programmed before, yes, maybe he should stick with the MS .NET gui stuff. I think WPF is pretty cool. 
Requiring Javascript to read text is just stupid.
If you're totally new to programming, starting with C++ and GTK may not be the easiest way to learn. C++ itself is very, very far from trivial, and trying to learn how to use a third-party library before you have a good grasp of the language is going to be pretty painful. If you want to get started building some simple GUI apps, you might want to consider using a .NET language first. C# or even (gasp!) VB.NET are better choices than C++ for beginners. .NET languages with WinForms include a simple drag-and-drop interface integrated into Visual Studio for designing GUI apps.
I agree with the sentiment, but I wouldn't recommend a microsoft-only language, at least not to a beginner. I think he'd be better off starting with a platform-agnostic language such as python for example, to avoid learning to depend too much on a platform.
You can also set those on a project by project basis. Right click on the project to get to its properties and then it's under the C++ language options and the linker options for the gtkmm library. If you keep having trouble you might want to evaluate using Qt instead of gtkmm. It's also a C++ library for desktop GUI applications but it has a much wider user base for developing Windows applications so you'll find much more information on the internet about it.
I'm missing how this is better than boost::signals2
This is really already a solved problem. Boost.Function and Boost.Bind already provide this functionality in a safe, generic and portable manner. using namespace boost; function&lt;int (int)&gt; callback(bind(&amp;TestClass::Foo, &amp;TestObject, _1)); //Call TestObject.Foo(5). callback(5); //Change callback to a free function. callback = SomeRandomFunction; //Call SomeRandomFunction(8). callback(8); The only thing is that the syntax is slightly less clean. I don't see much benefit to this library.
It is slightly less clean, but it is also much more powerful, being able to bind values to parameters. Also bind and function are now part of the standard library, no need to use boost.
Boost has a dirtier syntax and is a huge dependency. Boost also doesn't support comparison operators on its callback objects. PlusCallback is contained in only one header file; Its purpose is to only do one thing and do it well. I did a [comparison with boost here](http://codeplea.com/cpp-callback-comparisons). Boost is more flexible though, and of course much more widely used. Probably the biggest advantage to using Boost, is that it'll be worked into the standard soon. I appreciate the feedback, though.
The fact that it's completely contained in a single header file is also a plus... Including boost files often involves including many dozens of other files.
What is your definition of weak ordering for a function object? OK for parameter count perhaps it's clear, but is A::foo() less than A::bar()? If so, why? If not, how do you come to that conclusion? I think there's a reason why boost.function doesn't support them.
But to be fair, it doesn't really matter how it's implemented - a less-than operator for a function is going to be pretty much meaningless however you implement it. The only thing that matters is that you consistently maintain a stict weak ordering, which can be done even if the concept of "less than" or "greater than" is meaningless for the underlying type.
Isn't the bind/function stuff already part of TR1? Adding comparisons to boost::function should be easy (if you really think that's a good idea). But STL containers requiring an order allow to set your own comparator anyway. 
It's done by memory address. C function pointers are ordered the same way. It's useful for using containers that require a sort order, like std::set and std::map, or for algorithms that require a sort order, like a binary search. There is a caveat that the sort order cannot be well defined for virtual functions, which is why I would speculate that Boost avoids the issue. Edit: Just to clarify, the comparison takes into consideration the object's address as well as the function's address. Also, comparison is only supported for callbacks of the same type (i.e. pointing to functions/methods with the same signature).
Requiring functions to be distinguishable by address might not be a good idea, as that prevents the compiler from coalescing identical functions.
What happens if I do this? typedef cb::Callback1&lt;int, int&gt; MyCallBack; MyCallBack callbackA(&amp;a, &amp;TestClass::Foo); MyCallBack callbackB(&amp;b, &amp;TestClass::Foo); std::set&lt;MyCallBack&gt; callbacks; callbacks.insert(callbackA); callbacks.insert(callbackB); assert(callbacks.size() == 2); In this situation the memory addresses of callbackA and callbackB are the same and so callbacks.size() will equal 1, even though it should equal 2. Furthermore two different functions can technically have the same address, this happens a lot with templates whose arguments are pointers. The compiler won't generate a unique function for every template instantiation, it will simply reuse a single instantiation and use something similar to type erasure (ie. treat the pointers as a void*). You can imagine the horror of using this library and debugging strange behavior because of that. There are a lot more reasons why Boost and the standard library avoid providing comparison operators for 'functors', and a lot of it has to do with the fact that more often than not, you get behavior you likely did not intend to get. In the few cases where you can get reasonable behavior, the alternatives are much better, such as providing your own comparator and passing it as a parameter to std::set/std::map.
I think the importance of the implementation is to know how this library solved a problem that no one on the standards committee or anyone working on Boost or anyone period for that matter managed to solve. In theory sure the implementation doesn't matter... in practice though, if this library has an elegant or even semi practical solution to what is a very very difficult problem, the implementation matters to a LOT of people. I for one would love to switch to this library if the implementation correctly defines comparison between callbacks. From what I've seen of the implementation, however, it has not done so, but nevertheless it's a good attempt and I wish the author the best of luck in finding a solution.
Here's a simple example of what I mean... Two different functions, different types, but same address. #include &lt;iostream&gt; using namespace std; void f(int*) { cout &lt;&lt; "Hello world" &lt;&lt; endl; } void g(char*) { cout &lt;&lt; "Hello world" &lt;&lt; endl; } int main() { void (*a)(int*) = &amp;f; void (*b)(char*) = &amp;g; cout &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; b &lt;&lt; endl; } If you compile that using optimizations the output will print the same address twice: 000000013F231000 000000013F231000
As mentioned, boost has code to solve this problem (boost.function, boost.bind, boost.signals and boost.signals2). Another library that solves this (used eg. by GTKmm) is sigc++ which is quite good. (again, signals, not technically callbacks)
Maybe I'm being pedantic, but the problem I'm having with this is that strict weak ordering is more than just a way of making it easy to put things into a container of unique keys. It's a guarantee about how your objects can be used. If all you want is a unique container, just shove your functions into a vector/list/etc. and pay the linear penalty of guaranteeing uniqueness yourself (or switch to using tr1::unordered\_set and unordered\_map and write your own hashing function for these objects).
I wasn't quite clear above. The comparison methods for method callbacks use both the object address and the function address. Your above assertion would be true.
I wasn't aware of this, so I thank you for the information. However, I don't believe it is a problem for two reasons. * C function pointers have the same problem (as you've shown), so I am providing the same functionality. * If you tried to use (PlusCallback) callbacks with the above example, they would be impossible to compare anyway because of static typing (i.e. compile time error because the functions have different signatures). Furthermore, if two functions have the same address, then they must provide the same functionality. If two functions provide the exact same functionality, aren't they in fact the same function? I do still agree that this is undesirable though, because it won't be applied consistently be the compiler. In any case, thank you for your input. You've given me some things to think about, and you've shown me that my documentation is lacking.
I guess I'm not following you. Why is being able to put items in a set for quick removal or deletion a bad thing? A hash container is a good alternative, but that doesn't make an ordered container bad. And the uniqueness thing is secondary. std::multiset still requires a sort order too, of course.
Yes, you're right about [TR1](http://en.wikipedia.org/wiki/C%2B%2B_Technical_Report_1#Function_objects). And you can make a comparison function for the boost objects. PlusCallback does it for you. It's just an alternative, that's all.
What compiler are you using? I'm thought that was forbidden by the C++ standard, different objects have to have different addresses.
He's talking about function addresses, not object addresses.
So that's boost, but what about std::tr1::function? No offence, but at what point do people stop writing their own string and list classes? 
Well, it does mess up the callstack less than boost. Which is something you might appreciate after debugging boost code long enough. For member functions the stack compares like that: boost: #0 X::Foo (this=0xbfffdc8f, a=5) at boost_callback.cpp:45 #1 0x08049861 in std::mem_fun1_t&lt;int, X, int&gt;::operator() (this=0xbfffdc80, __p=0xbfffdc8f, __x=5) at /usr/include/c++/4.3/bits/stl_function.h:597 #2 0x08049888 in std::binder1st&lt;std::mem_fun1_t&lt;int, X, int&gt; &gt;::operator() (this=0xbfffdc80,__x=@0xbfffdc04) at /usr/include/c++/4.3/backward/binders.h:121 #3 0x080498a8 in boost::detail::function::function_obj_invoker1&lt;std::binder1st&lt;std::mem_fun1_t&lt;int, X, int&gt; &gt;, int, int&gt;::invoke (function_obj_ptr=@0xbfffdc80, a0=5) at ../lib/boost/boost_1_42_0/boost/function/function_template.hpp:132 #4 0x0804a3e0 in boost::function1&lt;int, int&gt;::operator() (this=0xbfffdc7c, a0=5) at ../lib/boost/boost_1_42_0/boost/function/function_template.hpp:1013 #5 0x08049316 in main () at boost_callback.cpp:60 PlusCallback: #0 X::Foo (this=0xbfffdc7b, a=5) at boost_callback.cpp:45 #1 0x08049afb in cb::Callback1&lt;int, int&gt;::ChildMethod&lt;X&gt;::operator() (this=0x8065040, t0=5) at callback.hpp:496 #2 0x0804a6f5 in cb::Callback1&lt;int, int&gt;::operator() (this=0xbfffdc74, t0=5) at callback.hpp:418 #3 0x08049357 in main () at boost_callback.cpp:65 Switching boosts flexibility and stability against code which is more readable and easier to debug might be an option sometimes. I still would prefer a debugger which lets me define to ignore stuff so I could simply step into X::Foo directly.
Is there any performance comparasion against BOOST, and C function pointers ? 
I could not help to notice the big speed difference between Spirit.Karma and sprintf on VC++ 2010. Are the standard libraries that bad or is it something related to the compiler?
I'd love to see the source for each.
Without actual numbers and only tested on one machine, these percentages just raise more questions than they answer. snprintf uses 100% of what? 100 milliseconds? 10000? On what? 32-bit machines? 64? What are the numbers like for converting to std::wstring? There's a far better benchmark from Boost, but sadly I can't find it in Google anymore. And they used ltoa as their starting point, which got much better mileage and was a fairer target than snprintf. snprintf is paying the penalty of having to tokenize the formatter string and using a variadic argument list, for Christ's sake.
I think he used sprintf as the reference time - hence the 100% and all others percentages are relative to that. I don't think putting ltoa would have added anything to the test because the whole idea was to test the performance of *Writing Generators* as Spirit.Karma calls itself.
Using itoa and friends isn't a fair comparison. All of the tested methods are generic: they work on more than just integers. Of course a specialised function designed for converting an integer to a string will be faster, but that isn't the point.
I'm really surprised that boost::lexical\_cast was faster than sprintf. I had always thought that lexical\_cast used std::stringstream under the hood. Perhaps it has a specialisation just for integers that does things faster?
I tried running the code on my machine (VC10, boost 1.3.9), and the karma implementation seemed to be spitting out empty strings. Has anybody else tried this?
Do you mean [this](http://www.boost.org/doc/libs/1_42_0/libs/spirit/doc/html/spirit/karma/performance_measurements/numeric_performance/int_performance.html)?
Boost V1.39 contains a very old pre-release version of Spirit V2, you should compile using at least Boost V1.41. 
Yeah, but if you're going to use a 3rd party library to do this, there's no better choice than boost. Everybody already knows it and you're likely already using it for other stuff. I could see using a callback library like this on a small project where maintenance isn't a priority. 
Sure enough. Downloaded 1.42.0, and the test worked fine.
Same here. I took a quick look at the source to see how it works, but then realized that it was naive of me to think that a quick look would be enough to figure out something in Boost.
I'm working on a comparison now. I'll post it later tonight. Performance wasn't a priority with this library, but Boost isn't hard to beat. Edit) Actually, it's going to have to be tomorrow. I did some optimizations and it looks like it is roughly twice as fast as Boost. Edit 2) [Here's the benchmark.](http://codeplea.com/cpp-callback-benchmarks) If anyone else wants to do a comparison it would be appreciated.
Why are stringstreams so slow? Since they are part of the language, can't compiler writers optimize them particularly well?
They are not part of the language, they are only part of the standard library. The reason they are so slow is because they do alot of memory allocation and copying of strings. Putting the int into the stream causes a memory allocation, then creating a string from the stream causes a memory allication, and then a string copy to put it into the final string. finally, when the stream and the string go out of scope, you have a memory free each going on. Between all of that, due to the way it works, it constructs and destructs alot of temporary objects on the stack, which each have to be initialized, possibly cleared again, etc.etc.etc. something like karma, for example, just writes directly into the given buffer on the stack, done. 
(Sorry for the late reply; I don't browse Reddit often.) It looks like everything you did was correct. The "Tasks not implemented in ..." pages are generated by querying the database with a special MediaWiki extension, but the results are cached for fifteen minutes, to avoid those pages being a point of an accidental DDOS. It looks like it just took a little while...
I've also noticed that sprintf is slow on VC++ 2008. I don't know why, my guess is that it's doing some secure_scl-like checks.
He says: &gt;Microsoft Visual C++ 2010 Express as VC10 with \_SECURE\_SCL disabled so that doesn't seem to be it. Unfortunately I don't have access to any windows computer to check this, it would have been quite interesting why such a speed difference.
Sorry, I made a mistake, \_SECURE\_SCL is for iterators and I was thinking about the secure CRT (Microsoft's \_s C runtime functions). http://msdn.microsoft.com/en-us/library/8ef0s5kh%28VS.80%29.aspx I've taken a look in sprintf.c. I think that sprintf forwards to sprintf\_s (can't find a declaration for sprintf in stdio.h). sprintf\_s calls \_vsprintf\_s\_l which does a simple validation of the parameters (e.g not null) and then calls \_vsnprintf\_helper. If the helper returns != 0 then it calls \_SECURECRT\__FILL\_STRING for the string parameter. The helper calls \_output\_l which is defined in output.c and does the actual printing. It's huge, with many branches and over 1300loc long. There are several \_SAFECRT\_IMPL checks inside the output function. The strtol implementation looks much simpler (140loc). 
With VS2005 32bit: * printf family: Huge switch loop for the format strings, ugly loop calling _aulldvrm to do the division/remainder in the format loop * stringstream: Creates a mutex &amp; intializes locale garbage when the stream is created. The int-&gt;string conversion locks the mutex, does a ton of allocations, looks up the conversion function which in this case is sprintf * lexical_cast is a somewhat decent conversion loop, wrapped in a bunch of locale garbage/mutexes which slows it down. No radix, divisions are optimized in to multiplications * Karma turns in to an unrolled recursive function, divisions are optimized in to multiplications * itoa is a tight small loop, divisions are used since the radix is passed in as a parameter 
[This](http://google.com/codesearch/p?hl=en#5ge3gHPB4K4/gnu/glibc/glibc-2.5.tar.bz2|HT3Jwvgod1I/glibc-2.5/stdio-common/vfprintf.c&amp;q=vfprintf%20glibc) is printf &amp; friends from glibc.
I didn't realize how bad std::streambuf really was until I ran mutrace on one of our heavily threaded apps. For a 20m total 8 thread process one program generating a few hundred kb of text output was spending over 2s time contending over the locale mutex. Its nice the speed check was done. I'm not a huge fan of the vast templatization and unreadability of boost. It generally seems like a classic example of over engineering in some places.
I think their rationale is the same reason why std::type_info has before() but not operator&lt;.
If you're using GDB, it has python scripting support now so you can write a filter that cuts out the intermediate boost functions. I don't know if anybody has done it yet though.
Kill it with fire!
Yeah the lack of random access or iterators is really bad. Especially considering what boost.mpl and boost.fusion did in the last couple of years. IIRC did the original proposal contain random access. 
And GCC will stop printing default template parameters (can be reactivated) in error/warning messages **tl;dr** reading template errors will be slightly less painful! 
Simpler but slow. Stringstream is not the fastest (by far) solution in this case.
In general it's a good argument. However i disagree specifically that it's a good idea to add copy/assignment/dtor functions to *every* class. When the compiler-generated shallow memberwise copy fails you, I'd first look to isolate the problem member variables in RAII classes like smart pointers. If you can do this, and keep the compiler-generated functions, your classes are more maintainable and readable. Hand-written copy and assignment functions hide semantics (is that pointer pointing to resources owned by this class or just shared? A smart pointer will tell you straight away) and are liable to go stale as new member variables are added. Of course there will come a point where you need to roll your own - probably to handle exceptions or in implementing those RAII classes - but you've isolated yourself from many of the pitfalls.
First time I've seen "201x" (not 0x or 10) in something like this. :(
C++-2XXX :-)
i've always felt that if they went the template route first instead of all that inheritance nuttiness (tragically aped by both java **and** c#), a lot more people would be using c++ today. you have to admit, variadic templates are pretty cool.
&gt; When the compiler-generated shallow memberwise copy fails you, I'd first look to isolate the problem member variables in RAII classes like smart pointers. Good advice. Whenever you can do something automatically, it's usually a good idea. With the Boost libraries, there's rarely an excuse not to.
i have used a few but all seem to mess up my make files after a while :( found the linux terminal and gedit to be the best
Everyone here uses Vim. Save for a few heretics.
Visual Studio is still the best AFAIK. Especially if you need a decent debugger. The IDE coming with newer versions of QT seems to be decent, too, I'd use that for developing on linux. I tried getting into emacs, but it is just too different from what I'm used.
Yep, still use VS at work for the windows side. Emacs if I'm doing stuff on the linux side, a lot of the other guys use KDevelop though.
I use Code Blocks for most of my projects. Free and available for all platforms. 
I would recommend QtCreator using CMake as your build tool (qmake if you're going to do something with Qt - but CMake handles that aswell). It's a really good editor and you'll get used to it a lot faster than vim. But do try to learn some vim too though. You'll get a long way with just vim, gdb, valgrind and cmake too, IMO.
I like Eclipse and vim, and in a pinch, XCode. Mostly vim, though.
Don't use Dev-C++. It's absolutely horrible and outdated. On Windows, you don't have much reason not to use Visual Studio. It's free, and Visual Studio is to C++ as Photoshop is to photo manipulation. It's the best IDE available.
On Windows Visual Studio with VisualAssistX. On Linux I haven't really settled on an IDE. Eclipse CDT is OK but I find its project management methodology too rigid. It does have a pretty good debugging interface though. More recently I've been using QtCreator which looks promising. It's really snappy. 
I'm a big fan of Vim, but I don't plan on coding in it beyond shell scripts.
My only reason to avoid VS is how easy it makes the creation of projects. Part of what I'd like to achieve here is a deeper understanding of the libraries I'm using and the construction of projects. Not that this couldn't be done in VS, but I'm betting other IDEs would force my hand a little more. For instance needing to manually select a compiler.
Thanks, I'll check that one out, hadn't heard of it before.
Emacs. Look at CEDET.
Visual Studio for Visual C++ and NetBeans for Standard C++.
I'm pretty handy with Vim, but don't really like using it for anything beyond scripting. I really like syntax highlighting and compiler warnings. And yes I'm aware that makes me a wimp. Edit: Also is there a reason to go with cmake over gcc?
I use vim. 2 years ago I would have shot future-me for saying that. However, the biggest problem with IDEs is that they always want projects set up in their personal way which causes a real pain if you want to share projects with other people, particularly across operating systems. On the other hand, if everything you are doing is on windows, use visual studio, there is no better alternative.
Qt seems to be getting a few votes here, and I've heard good things about the SDK. I'll probably give that a shot along with the Eclipse plugin. I spend most of my day in Eclipse so that kind of feels like home anyway.
Windows for now, but I'm not ruling out the possibility of getting ambitious and trying my hand at a Linux app or two. That would be all command line though, not windowed.
Thanks for the tip I'll avoid it.
I generally consider NetBeans to be pretty similar to Eclipse, which already has my loyalty as far as Java goes. Any reason in particular why NetBeans would be better than just using the Eclipse plugin?
As an Emacs user, I suspect it is now my duty to track you down and challenge you to a Nerf duel to the death or something.
I do my project setup with CMake. This way I can code in VS and compile with GCC or whatever.
I can really recommend CMake. Setting up projects is pretty easy, and you can compile your stuff with a number of IDEs and compilers.
I don't get the VS deal. Probably because I came fromthe unix world and am utterly hirrified bt the whole /MT /MD, etc library crap. Also just sitting down and trying to use it it was entirely counter intuitive. So cygwin, vs express and ssh server on windows helps there. I've been usinf jam (not boost) for builds. 
The problem with emacs for me is the learning curve. I tried picking it up last year and quickly realized it was going to require more time than I had to put into it. I'll be honest though, I do still want to pick it up at some point, just a little out of scope for my current needs.
You get syntax highlighting from vim, and compiler warnings from your compiler, I do not understand what you're saying.
So how does that work, do you organize all of your files outside of VS, and then just import the project to work on? Isn't the default behavior of VS to try and convert your project to Visual C++? Sorry if these questions are a little basic, I'm really back at the cusp of trying to remember how all this stuff works.
I think you just like what you know. I had the exact opposite reaction when I ventured over to Linux, having to understand proper use of file permissions drove me nuts.
cmake is not the same type of thing as gcc. GCC is the gnu compiler collection, cmake is a build tool, it calls the compiler, passing it the relevant parameters needed to correctly build your code. cmake works with GCC, it doesn't replace it.
Will you get compiler warnings at design time, or do you have to actually compile to get them?
Ah thank you, this is the kind of info that's really helpful. It would have taken me a while to figure out my assumption was incorrect on my own.
CMake is a build tool, not a compiler. So it's comparable to qmake, ant, autotools, etc. You might think of CMake as a "make replacement", except that CMake actually spits out a Makefile for you (just like autotools does) and it can also output project files for Eclipse, KDevelop, Code::Blocks and Visual Studio.
You will get the compiler warnings at compile time.
I might just have had bad luck, or bad projects, but I tried generating an xcode, eclipse, and visual studio project all from a cmake-based program, and none of them produced a valid project file.
I'm using [Code::Blocks](http://www.codeblocks.org/). It's pretty straight forward and reminds me of Dev-C++ except better in some places. I'm probably going to drop it and look at the Eclipse C++ since I use Eclipse for all my Java development. Visual Studio is pretty standard for Windows developers, so you really can't go wrong with that. 
Is VS really the best C++ IDE? That's depressing... About a year ago I was doing Java development with IDEA. IDEA absolutely rocks. Great refactoring support, fast (enough), well supported, and good looking. I moved to a Windows shop doing C++ and have been hating VS ever since. It seems really primitive. Perhaps that's just the best they can do when the language doesn't have reflection. 
One of the best things about developing on Windows is getting to use WinDbg. It's substantially better than the integrated debugger in VS. In fact, it's my favorite debugger on any platform. It does take some time to learn, but it is time well spent. 
Geany (www.geany.org) is just an editor, but much nicer than gedit.
I have to put my weight behind Vim and KDevelop 4. Note that in Vim, you can do your entire process except debugging: make can be invoked from inside Vim and errors are put in a special buffer that will open relevant files for you. Combined with cscope, I find Vim to be the only truly productive environment, save for perhaps Emacs (which I've never used). That said, I've found KDevelop 4 to be a powerfully useful tool: It supports CMake natively now (and very well, I might add), and with Kate 4's Vi-mode support, it's almost as comfortable as using Vim. But KDevelop 3.5 is trash. Don't use it.
Your question doesn't make sense: Compiler warnings come from the compiler. Vim happens to handle compiler messages very well (:help quickfix), as well as how to run it (:help make).
Geany and Visual Slick Edit for C++. Mostly Geany. 
&gt; Perhaps that's just the best they can do when the language doesn't have reflection. String-based preprocessor macros, Turing-complete templates, and a non-context-free grammar don't help either.
Yeah, C++ is an absolute nightmare to parse. Intellisense isn't great, but for a minimal price you get can Visual Assist X integrated into VS which provides some of the best C++ refactoring and code completion tools I've ever seen. If you're coming from Java or C#, I can't think of a single C++ IDE which provides the same level of refactoring and code completion tools. Code completion and refactoring using C# in VS is way ahead of C++ in VS, for example. Visual Assist makes it significantly better, but even then it's not quite on par.
To the thunderdome!!!
&gt; just a little out of scope for my current needs. Odd you should say that, since it's so broadly useful. I have been a C++ dev for many years, but not for the last 4 months, when I've been doing general system troubleshooting, scripting, administration. I use Emacs for both, and find it a fantastic tool. From editing files to filesystem browsing to IRC to developing in any language, Emacs does it all. There may be narrow aspects of each which other tools do better, but there is a lot of benefit of having a consistent environment for so many of your tasks. I did draw the line at web browsing and email - it can do them both, but not as well as purpose-made tools. Edit: oh, and with gdb for C++ debugging, current emacs is very nice indeed. Multiple windows, as you'd expect from an IDE - breakpoints, stack, variable tracing etc..
When I say design time I mean that code is checked as I edit, and I get visual feedback in real time if there is an error the compiler can pick up. I don't have to actually build the project in order to detect them.
Doing so would require compiling your code. Some languages this is trivial (Java, C#) and effective to continuously try compiling, other languages this is not (C++). 
There are VC++ options to simply call into external make tools. However, with CMake, you can generate a Visual Studio .dsp file automatically based on your CMake rules. 
SlickEdit!
That reminds me that the one feature I missed the most when I went from c# to a c++ job was reflection. It really makes life that much better in some cases, and from your comment I get the feeling that implementing intellisense is one of those cases.
I can tell you to avoid Visual C++. It's great for learning, but it makes things difficult when you need to build exe's and try them on other machines. 
I started programming with VS, I honestly had eaten so much of the candy I had no idea how the .o/.lib/etc... files all connected together to make the final binary file. All I knew was &lt;F5&gt; == working program. I know better now, but VS will do that to ya.
Advanced C++ tools are able to perform checking of your code while you edit it, and underline errors in your code. Visual Studio with Visual Assist X will do this, for example. It helps you ensure your code is correct before you compile it, which is a great time saver especially in the case of simple typos.
Be sure to try Kdevelop 3, the new version is not yet fully featured.
You can try also bakefile (http://www.bakefile.org/). It also generates various kinds of build files (plain makefile, autoconf input, vs studio files for various versions) - but doesn't give you "configure" power as CMake.
I don't think that the learning curve is very high. You can simply use Emacs as a normal text editor with all those buttons and menus Emacs has today. Learning a bit emacs lisp and M-x foo comes with the time and before you realise you are using some elaborate key sequences.
but kdev4 is supposed to have a great c++ parser. 
I try to stay IDE agnostic as much as I can. I use [bam](http://github.com/matricks/bam) to build everything and then call it from VS or vim depending on which platform I'm on. Vim is a much better environment to edit code in, and with some setup of completion it is quite workable, even in large code bases (one could argue that you learn your code better without completion =). VS is a bit better for code navigation, but the integrated build system sucks and I miss some vim editing tricks (ViEmu is not nearly as good).
Definitely Slick Edit.
I don't use an IDE for any programming language, just a simple text editor, plus GCC. In my opinion an IDE veils too much of the process for the programmer by automating too many things in the background, making it too much of a "magical" process. This could prevent a programmer from thoroughly understanding what he/she is actually doing.
Not so; there's an emacs mode, 'flymake' which will try to compile your code every few seconds, showing you errors as you go. I don't use it, it can take setting up if your setup is not vanilla but, it's not unthinkable. 
Ah, it's just a "Something's Different!" reaction, you're just disliking the new, like everyone else; it's not intrinsic to VS. I can assure you that going from an IDE to Unix style is just as shocking, everything feels 'bare' and primitive. You just have to bite down and Master Technical Details like we all do every day. 
Eh? It's all about building .exes; what does it do that makes copying it to another machine hard? Maybe you're thinking of the accompanying .dlls, which you get to take for granted on your own machine? 
VisualStudio + [viemu](http://www.viemu.com/). It's $99 and if you code for a living, it's worth every penny.
 If you really want to, you can use plain old Make under visual studio by using utility projects, specify custom build tools, etc. Then when you hit F5, all visual studio is doing is running make for you.
Full disclaimer: I'm a Vim user. Fuller disclaimer: I don't buy into the Vim-vs.-Emacs debate. I'm just curious about the tool I don't use (yet). My question for you is: I've heard that Emacs users often run into "Emacs pinky" from pressing Control all the time. As somebody who gets sore wrists and hands from typing without resorting to excessive amounts of potentially-unergonomic key chords, this is probably the single largest deterrent to learning Emacs. Do you have any insight on the subject?
&gt;going from an IDE to Unix style is just as shocking I'd just like to point out that what you probably meant to write was, &gt;going from a **Windows GUI IDE** to **commandline tools** is just as shocking There are GUI-based IDEs for *NIX (e.g. KDevelop, Eclipse), and furthermore, many people call the collection of commandline tools an "IDE" as well (myself included). Having a graphical user interface is not intrinsic to the nature of an integrated development environment. Just FYI. Your point is still very valid. =)
 *munches popcorn*
As somebody who used to have what I think was probably a similar outlook to yours, let me tell you that the most valuable advice I wish I could have told myself a few years ago is this: coding GUIs is not as hard as you think it is. Just choose a framework, do some tutorials, and *run with it*. The easiest way to learn is to mess around and screw things up, and figure out why that widget exploded when you frobnicated the bizbaz. Similarly, coding for \*NIX is not any more difficult than coding for Windows. In fact, once I started to get the hang of it, I was astounded at how much *easier* it was. Do yourself a favour: anytime you're intimidated by something you think you might want to learn, just dive in headfirst. Join the relevant subreddit. Hop on an IRC channel. Most importantly: get coding, make mistakes, ask questions, and **learn**. You will be amazed at how quickly you pick up a vast array of new talents. Coding is fun! Learning is too. =)
I think this is true for vim too, but with the escape key. It is in a better location but still too far away. That is why I swapped my escape and caps lock key but you can do that too with Control...
I actually never use the escape key in Vim. To exit Insert mode (or any other mode), I find that the most ergonomic shortcut is ^c or ^[. For ^c, my index finger is already right there - I just slide my whole hand, instead of stretching my pinky - and for ^[, the second key is done with my right hand, so there's very little stretching. Although I suppose I've just shown that it *is* possible to use Control frequently without being excessively unergonomic. Nevertheless, I'd still find the insight of an experienced Emacs user valuable.
&gt; many people call the collection of commandline tools an "IDE" Then they're wrong, as far as I know, since it stands for "*integrated development environment", and by their nature those tools aren't "integrated" into an "environment". http://en.wikipedia.org/wiki/Integrated_development_environment
If you don't know how to use .lib files, it isn't the IDE you need to learn, it's C++.
CMake basically uses a meta project file that can then generate project files for Visual Studio, make files, etc. Awesome for cross platform development, worthless if everyone is using the same IDE on the same platform.
Its too bad ReSharper isn't available for C++. Its made by JetBrains (the guys who make IDEA) to make Visual Studio more IDEA like.
If you're on Windows, go for Visual Studio. No gain from using anything else. For *nixes, go with Eclipse, Netbeans , vim or emacs, for OSX, Xcode. 
The Visual Assist plugin for Visual C++ does this.
Yeah, but what I'm saying is that when I originally started, VS hides all that stuff away from you so you don't actually need to know how that stuff works. 
"Integrated" just means "composed and coordinated to form a whole". As long as the tools work well together, they're integrated. Since many or all of them can be extended to work together explicitly (e.g. make support within Vim), that's even better integration. Merriam-Webster defines "environment" as "a computer interface from which various tasks can be performed", so, again, as long as the tools work together, it doesn't matter if they're CLI or GUI tools. Let's look at that Wikipedia page you referenced. &gt;An IDE normally consists of: &gt; * a source code editor [e.g. Vim] &gt; * a compiler and/or an interpreter [e.g. gcc] &gt; * build automation tools [e.g. CMake] &gt; * a debugger [e.g. gdb] I can use the four examples I gave very well together. It's even nicer if you use [screen](http://en.wikipedia.org/wiki/GNU_Screen) to run gdb and Vim side-by-side. It's all one "environment" and it all works together to serve a higher purpose - development. If that's not an "integrated development environment", then your definition of IDE is so specific as to be useless - just say what you mean and call it "a GUI-based development environment".
This is exactly why I wanted to use something else. With Java I know what all of the packaging, and descriptor files are doing for me. I know what's in my classpath, and what is needed when I transfer from development to build to deployment. Visual Studio really makes it too easy on you, I'm sure it's very useful after you already know all the underpinnings of what you're doing, but less so if the underpinnings are what you're looking to learn.
Yep, I do think it would a useful thing to know and any machine I use is either a *nix or has Cygwin, so it's always available. You have to admit though, that it has a pretty steep initial learning curve. Since I'm more concerned with getting back into the code/packaging/building of C++ apps right now, that curve is just not something I want to take on.
I don't really have any issue with writing GUIs, it's just that I work with my Linux machines almost exclusively over SSH. Anything I write for Windows will likely be GUId. &gt;Do yourself a favour: anytime you're intimidated by something you think you might want to learn, just dive in headfirst. Join the relevant subreddit. This is good advice, and precisely why I'm here. Lot's of great feedback from my first post here is great to see. I was going to put this under the programming subreddit, but when I read their FAQs I saw this subreddit existed and decided to try here. Glad I did.
Yes, I am talking about all the accompanying .dll's. I do take it for granted. :)
iexplore.exe
I gotta say, I like the progress made in this meeting way more than the prior one.
It never really bothered me, but also for quite some time I've had caps-lock mapped to be another control. That's one approach, but otherwise I'm not much help. There was a discussion about it on r/emacs not long ago, but suggestions were pretty varied.
steep learning curve - absolutely. I had the luxury of being a junior coder at the time, with few expectations. Also, I was coming from old-school vi - one edit per term window, so my productivity level overtook vi in very short order after working through the tutorial. In-editor-compilation, syntax highlighting, and other things were instant hooks. I had been using various hacks like external programs to justify comment blocks in vi, and then I moved to emacs and it was all built in. These days, there isn't such an unequivocal superiority, next to vim.
Would you please send me a link or point me in the right direction on understanding this please. I'm currently a CS student and all I've ever used is VS. Didn't really understand that there might be major work that goes into compiling a program until I saw this comment.
This link has a pretty good explanation of some of the basic stuff: http://markuskimius.wikidot.com/programming:explain:compiling And of course the wikipedia article goes into a pretty good amount of depth: http://en.wikipedia.org/wiki/Compiler 
Geany is fantastic as a c++ editor, This is probably not a typical use case but I used it exclusively to grade c++ assignments at the school I attend, I could track down errors and do a quick compile without the bulk of a huge IDE
[cppcheck](http://cppcheck.wiki.sourceforge.net/) is pretty good but there doesn't seem to be a great deal out there unless you're willing to part with some cash unfortunately!
I've had a look at cppcheck and indeed it's not that bad!!
We're using at the moment for some code checking and some of issues it picks up are pretty good. We currently have it hooked up to a continuous build server as well so that all developers can get a look at the problems which need fixing. Another good tool is GCC if you can use it, used with the -Wall and -Werror flags it will give you some rules checking functionality.
We use Coverity Prevent. It's pretty good, and found some good issues, but it's not cheap. The web based tracking is good for figuring out how you're progressing on the number of issues. I've used cppcheck on some smaller projects with good results. It's good for checking single-source files, while Coverity works on a compiled-product that can find issues across files.
I've given up on various free tools. When compared to something like Coverity, Fortify, Klockwork, etc, you realize how bad the free tools are. Downside, as posted earlier in this thread, is that they are expensive.
There's a python script bundled with linux kernel source that checks syntax. Laybe you could take a look a that one.
g++ also supports -Weffc++ that aims at warning violations of the guidelines from Scott Meyers' Effective C++ book. But they are just a dozen of rules...
Actually, any self respecting programmer shouldn't use any programming language that needs a compiler. My code is all writen with a binary key that alternates between 0 and 1 and I do write it directly in binary. A real programmer should thoroughly understand how to perform his/hers low-level optimizations, register/stack/memory allocations, etc. He shouldn't even rely on Macro Assembler to translate instuctions into binary code.
I use this tool as well. I've also tried out [Yasca](http://www.scovetta.com/yasca.html), which can use cppCheck as a plug-in and lets you write PHP scripts for custom rules.
You can also look at Cqual++ and its associated tools. Basically the open source equivalent of Coverity.
I use Visual Studio on Windows and Emacs on Linux.
codelite
What about something in between "free" and Coverity / Klocwork / etc... -- something like Gimpel's PC-Lint &amp; Flexelint. Every time I see a Coverity sales pitch they seem to be aiming their $25K tool right at the $299 PC-Lint, so it must be doing **something** right....
Herb Sutter (head of the committee) suggests 11, as that's when it'll be done. 
But it got fixed right after I made the change (`Cpp` -&gt; `cpp`). Wasn't that the problem?
Netbeans?
&gt; will do this It's a key point. The only IDE i know of that does that efficiently atm is XCode, and only for C/Objective C code. VS 2010 will do it but it's not out yet. 
Have you tried qtcreator ? It has a quite detailed model of the code you write, and correctly find most errors (it also mean great contextual code completion, since knowing what to expect is mostly identical to knowing why something shouldn't be there...). (And they are adding Obj-C support too....)
I'm using qtcreator as my main C++ IDE, and i don't find the error detection to be top notch. It's ok but only detects most basic things. It doesn't even check if a symbol is defined or not, probably for efficiency purposes. The code completion is quite great OTOH and the whole IDE has a very solid feel to it. I think live analysis of C++ code in open source tools is gonna make a huge leap when clang for C++ will be finished. Then devs will be able to use clang as a library very easily to analyze C++ code without compiling it. I'm waiting :)
It sorta already does the check, since when you ctrl-hover on an undefined symbol, it does not highlight it, it knows it's not defined since it has no definition to jump to. I think the problem is with false positive, it still fails to follow iterator pointee type (don't know exactely why, maybe because of the weird inclusion order of files or maybe too many indirections in typedefs or... well too powerfull templates). I actually think I had the feeling it checked this kind of error because when completion does not work I always think I'v made a mistake, like in a shell...
Name one better thing to ever actually happen to C++.
I think it should be called C++0xB.
this has nothing to do with c++
Agreed. Though the same technique could be used for C++. Just substitute C++ in the FFI for Haskell instead. 
upvoted for the elegant use of sarcasm
The assignment operator for that class is trivial if you use the copy-swap idiom (http://www.gotw.ca/gotw/059.htm): TFoo&amp; TFoo::operator=(const TFoo&amp; that) { TFoo tmp(that); swap(tmp); return *this; } I also agree with tenpn that preferring smart pointers over raw pointers in the first place averts the need to write an assignment operator in the first place. 
I felt like sharing this link. I am fairly new to C/C++ and EVERY book I've read explains what pointers do, but never clear enough to really understand them. I was surfing around and stumbled upon this, which caused me to have one of them moments of revelation and I am utterly overjoyed. Maybe it will help someone starting out.
Will do. 
[learnprogramming](http://www.reddit.com/r/learnprogramming/) would probably appreciate and benefit from this as well, though I've no idea if you want to cross post this to three separate subreddits.
Does anyone have a *fast* locale-less implementation of general input/output stuff? I've got some scientific software that is just getting killed by writing hundreds of thousands of point records. Right now it's using std::streams for all of this...windows takes an especially bad hit here too.
Another reason aside from the standards argument is that some people write really dumb headers that redefine system types or important functions for whatever reason and then stick a neat little #pragma once at the top. If this header gets included in another header that you don't control (which can happen in a large company), there's no way to avoid this badly written one from messing up your code. If they had used header guards, you can define their guard to knock out the stupid header and then write your own that is sane. Lame but useful.
 **Boost Your Business for FREE!** Free advertise your [products](http://www.bytrade.com/factory-2-1.htm) and services? Get your business more exposure? Go to [ByTrade.com](http://www.bytrade.com)! Market your business to one of the largest [international trade marketplace](http://www.bytrade.com) ! FR-E-E! 
Anyone know how the VC++ printf compares with the user32.dll built-in wsprintf? 
very nice, thanks.
Please look at ivrworx project which uses the framework http://code.google.com/p/altalena/
If the Cpp -&gt; cpp change was in the lang tag, then no. The "Tasks not Implemented in X" counting, where X is an arbitrary language, is done as part of Template:Header, with the presence of {{header|X}} at the beginning of the example. Having the text {{header|C++}} was the bit that was needed for things to eventually get counted. There are two factors that cause delay, though. One is the 15-minute caching of data behind the dynamically-generated "Tasks not implemented in X" page, and the other is the MediaWiki-internal job queue of updating all the things that can change when a page is edited. For example, if I were to edit a commonly-used template like Template:Header to put all pages that use it in an additional category, then that task gets broken up into a series of many smaller operations that get processed over time each time MediaWiki's index.php gets executed. Right now, RC's job queue length is 4, but I don't think many core edits have been made recently. I don't know what it was on that particular day.
No self-respecting programmer would use such an arcane input method. Real programmers use [more elegant tools](http://xkcd.com/378/) .
In Borland, you just need "__closure". 
If you really want to understand everything about pointers and their relationships with arrays get a copy of the book C-FAQ's by Steve Summit, you wont ever need anything else. Great for interview questions too.
i'm using code::blocks too and i'm pretty happy with it. but i should look into eclipse, because we will start with java soon at school.
ugh
It looks like they're using switch case statements to manage flow control like duff's devices and [protothreads](http://www.sics.se/~adam/pt/). I'm still confused by how some of this stuff works. The post says that you can do "reenter(this) for(;;) { }", my understanding is that reenter is just a switch statement, which I thought you had to have { right after. And I don't get how you can use "yield break;" within a for loop either.
Thanks for this, I'm just diving into boost::asio and the official documentation is not that great.
&gt; my understanding is that reenter is just a switch statement, which I thought you had to have { right after That may be a common belief. The C++ grammar says otherwise. &gt; And I don't get how you can use "yield break;" within a for loop either. "yield" is just a macro which includes its own for loop. The "break;" applies to that loop, not the outer for loop.
Ah yes, thanks for clearing that up. I now want to place switch for loops everywhere to piss off everyone I know. Hazaah!
For more fun in code reviews, instead of this: switch (x) { case foo: ... break; ... default: ... break; } write this: switch (x) case foo: { ... break; ... default: ... break; } 
Yeah thank you for this. I just started working with boost and this will come in handy.
It is shallow and pedantic. It insists upon itself.
Really? I found it to be assertive without being pushy.
Asio has been submitted as a candidate for the standard library. I wonder if it isn't too complicated for the general public though. It's taking work for /me/ to understand it, and I've used ACE + am familiar with what's going on behind the scene. 
I'm going to wait for someone to write an overview article on what's in this final draft, including some code samples, etc, before commenting. I just haven't had the time to keep track of what they've put in and taken out. And it'll take a couple of years for the features to be included and fixed in many compilers. Hopefully it's not as long as it took to get everyone up to date on templates...
I may be wrong, but I think some of your confusion stems from the fact that Visual Studio does the job of several programs all packaged into one useful development tool. Visual Studio comes with a code editor, a compiler, a project management/build tool, a GUI designer and possibly other things that I'm not aware of. All these components would come as separate programs in other set ups.
This article is about a potentially interesting topic, but I think it would benefit from an example or two showing how to achieve the things it describes in practice.
Does this mean I'll have a reader for part 2 then? :)
That depends. Will it have code samples and stuff? :-)
Does that mean that if I start coding in gcc-4.5 I am pretty much using most effective and newly added features to c++0x? 
Poor Sun compiler :(
Why are Concepts still listed as a feature?
no.
Am I nuts? Aren't 'explicit' conversion operators really old? It's not some new wrinkle either, that I can tell. 
yes. It's been pretty stable but, that can change at any time. 
Better (at least for MSVC and GCC): http://www.aristeia.com/C++0x/C++0xFeatureAvailability.htm Click the tabs at the *bottom of the page*. Good information, terrible UI.
They have been around for constructors, but not operators. Imagine you had a class that implements `operator bool()`, so you could do `if (!my_object) {...}`. In another context `my_object` could nonsensically be converted to integer or floating point. Now you can make it `explicit`. [Wikipedia](http://en.wikipedia.org/wiki/C%2B%2B0x#Explicit_conversion_operators)
you have to turn it on explicitly: -std=c++0x
Ah right, thanks much. 
Except that he leaves off GCC 4.5 entirely..
Thank you
TIL that Scott Meyers looks just like Bon Jovi.
TIL that Scott Meyers looks just like Bon Jovi.
GCC 4.5 was just released last week, so hopefully he'll add it soon.
I don't think it's actually released yet, though it's been branched, and I do see it as the 'latest series' on the homepage. Soon, anyway, I'm sure. 
Great link, thanks a lot :D
I really like the source code transactional type commands. I have to admit their "qi.prj" and compile.h and link.h file conventions are just plain wierd. Couldn't they just use ".qi" as a file extension??
Sounds really cool. Seems a bit immature, but we really need smarter build tools for C++. CMake is a step in the right direction, but it still is pretty dumb.
I used BCB extensively quite some time ago and still consider it to be the finest development tool ever written for cranking out win32 GUI applications. Unfortunately around the year 2000 Borland really started to lose focus. BCB5 was the high water mark of the platform and after that they seemed to add bugs to each release instead of features. Don't know about the latest stuff.
We used to use it, but we found several "ISSUES" including bad code generation (the compiler generate bad assembly code) when used with the VCL. The support was horrible, no support in reality, Borland-Codegear-Embarcadero keep asking us to buy next releases that theoretically will solve all the issues, just 500k USD in labor cost, we moved to Intel compilers with Visual Studio IDE. Half the cost and better support. We expend just two months moving away from BCB, we loose 500K to solve issues related to BCB compiler. 
 Opinion? [Visual Studio Express is a free download.](http://www.microsoft.com/exPress/) If my next project was a strict native COM application I might take another look at Borland tools, but beyond that, MS has surpassed them a long time ago in most regards. 
Borland's C++ Builder and Delphi are very fine IDEs for windows applications. I have seen a lot of very nice (and very successful ) windows apps written in Delphi and C++ Builder. 
I have had several run-ins with Delphi and C++ Builder over the past 15 years. Usually as applications that were built and deployed to corperate desktops ala. the [Client Server](http://en.wikipedia.org/wiki/Client-server) model as it was understood in the early 90's ([PowerBuilder](http://en.wikipedia.org/wiki/PowerBuilder) falls into that same crowd). Its a decent IDE and there's nothing wrong with most of the tools they provide: you could still use it to develop and deploy decent Windows desktop apps. It's been many, many years since I have used either so I'm not sure if that's changed. Two things to be aware of: Support - as mentioned by others you won't get much support from Embarcadero - I think they are more in the business of selling boxes and not so much interested in building and supporting a decent development platform. Borland Database Engine: Stay away from this at all costs - the BDE is and has been slow, buggy, and unscalable for almost 2 decades now. Stick with ADO if you need to add any database connectivity to your apps. 
I like how effectively the Makefile is embedded in the code itself; I think that makes a lot of sense in that adding/removing sources automatically modifies the build process. I would prefer it to be in shell script though, since (shocking, I know!) sometimes I don't have python available.
Someone needs to post a performance comparison to investigate the overhead of using these lambda constructs versus the plain-old C/C++ style way of accomplishing the same thing.
While implementations are free to differ, the common implementation is if you capture variables by reference, the lambda expression will store a pointer to the stack frame where the variables are declared, as opposed to storing references to every individual variable. If you capture by value, then a copy is made of every captured variable.
This is nice, but I'll stick with Phoenix, and move to actual C++0x lambdas when my primary compilers (MSVC and GCC) support them. GCC 4.5 and MSVC10 already support them, even though I haven't moved to them yet. Been meaning to check that out. Edit: Neat! This compiles in VC10. #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; int main() { std::vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); std::for_each(v.begin(), v.end(), [](int x) { std::cout &lt;&lt; "i: " &lt;&lt; x &lt;&lt; std::endl; }); return EXIT_SUCCESS; } 
Well, for someone who wants to avoid .net (and is not masochistic enough to go with MFC) this is not really an option...
You can use any extension for 'compile.h' and 'link.h'. For qi.prj I can't think of a good name.
 #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; #include &lt;iterator&gt; int main() { std::vector&lt;int&gt; v; int i = 0; std::generate_n(std::back_insert_iterator&lt;std::vector&lt;int&gt;&gt;(v), 10, [&amp;]() {return ++i;}); std::for_each(v.begin(), v.end(), [](int x) { std::cout &lt;&lt; "i: " &lt;&lt; x &lt;&lt; std::endl; }); return EXIT_SUCCESS; } ;)
This is not a good idea, given that lambda as actually natively supported by the language in C++0x. Also, Boost.Lambda has provided this functionality for ages, so it makes more sense to stick with Boost.
Yes, but I found the implementation technique interesting. Of course, I could probably learn more by reading the Boost libraries, but one step at a time...
 It's pretty easy to avoid .net when using Visual C++ 2010 Express.
Well, you can debug if you like. There are scripts that make it easier. If I am going to debug then I'll probably just _use_ GDB alone. You don't really need to leave Vim. !gcc % is your friend as well. There are a couple of generic scripts for different languages as well: * http://www.vim.org/scripts/script.php?script_id=1954 * http://www.vim.org/scripts/script.php?script_id=663 
I know you guys are writing trivial examples but it seems like a regular for loop with the handy new auto keyword would be much cleaner than a for_each loop.
Haha thank you! :) New territory for me you know, I have to re-train my brain for this.
I believe that internally VS2010 will convert lambdas into the old C++-way of doing things anyway - that is, just using an unnamed functor. There really shouldn't be any performance difference at all.
That's kind of the point of the C++0x revision -- there is no "plain-old C/C++ style way of accomplishing" lexical closures. You either have function pointers or functor objects, and either way you have to manage captured state entirely on your own. C++'s lambdas aren't as pretty as they are in other languages, but with so many reserved keywords and tokens, and without garbage collection, it's hard to make them look like anything other than syntactic sugar for a functor with explicit semantics of how to capture stack-based variables.
 [&amp;]() {return ++i;} *what*
It's a neat hack for its own sake. You can't even fluff up your lambda with anything beyond a few simple operations.
If someone wants a decent IDE for RAD, even is not that full featured, it may look for Qt Creator that worth the buck (is free also). It is supported by Nokia. It is also cross platform which may matter for some.
and still have RAD?
Includes a lot of other great changes, like http://gcc.gnu.org/gcc-4.5/changes.html * Link Time Optimization (LTO) * Doesn't print default template parameters in error messages (error messages more readable) * And more C++0x support http://gcc.gnu.org/gcc-4.5/cxx0x_status.html
A lambda with access to current context that takes no argument and returns i after incrementing it, I believe.
I wish I can use this and VS2010 right now at work
Wow, that's totally awesome!
When will it be ported to MinGW?
Also the [&amp;] means it can change the value of 'i'. If it was [=] it would always return 1. [] means it wouldn't have access to i at all. This is my understanding, I probably won't use C++1x for another 20 years when it becomes standard in the workplace.
Hmm...I took our highly parallel image processing system, just compiled STLport *without* threading turned on, changed about 3 files due to some namespace confusion with stlport and ran...~2% faster than gcc's libstdc++. Ran with mutrace and noticed the lock acqusition/contention dropped by an factor of about 10 million or so running a 5 minute test. I'm testing with gcc 4.4.3 Any of this stuff getting fixed in the new gcc? (this is a dual core i7 box)
You are saying that profiling locking itself greatly affect the locking ? With libstdc++ or stlport (or both ) ?
The post has been updated with actual numbers and hopefully a clearer idea what the relative factor means. It really doesn't matter what you set as baseline, though. But the point remains that people will go to sprintf() as first choice since that is the portable way (itoa() is non-standard), so I found it logical to set that as baseline to compare against.
It's a problem with gcc's using COW for strings (requiring locking) and locale locking as part of strings. mutrace does not introduce locking, stlport can be compiled without any locking. So yes libstdc++ is very bad about spamming mutexes for multithreading. Probably wrong place for the above post, but its something I bumped into recently, and now with amd's real 12 core system this will continue to be an issue.
Qt Creator http://qt.nokia.com/products/developer-tools
[KDevelop 4.0](http://www.kdevelop.org/) (currently at RC3) has some very nice features.
Qt Creator is damn fine. I'm using it exclusively for a moderately sized project. I'd recommend finding a current, stable build from the dailies. A lot has progressed since even it's January release. Very fast development cycle on this atm with lots of eyeballs. KDevelop is never going to get out of beta, much to my chagrin.
I like Qt Creator, but its editor is kind of lame. The only way to do text navigation is with the arrow keys, no customization. &gt;.&lt;
Qt Creator
Emacs + Xrefactory
Uh, did you see the 'for linux' part??
One word: SlickEdit. It kicks the shit out of all the rest. There is no messing around, it just works.
Not that this is necessarily a counter to your objection, but it may be worth noting that the Qt Creator editor supports a "fake Vim" mode: &gt; In the FakeVim mode, you can run the main editor in a manner similar to the Vim editor. To run the editor in the FakeVim mode, select Edit &gt; Advanced &gt; Toggle vim-style editing or press Alt+V,Alt+V. &gt; &gt;In the FakeVim mode, most keystrokes in the main editor will be intercepted and interpreted in a way that resembles Vim. -- http://doc.trolltech.com/qtcreator-snapshot/creator-editor-using.html Now that I've discovered that, I may have to try it out and see how badly it sucks. :)
The problem is in fakevim mode, you don't get things like code completion making it like an external editor.
Erm, code completion seems to work fine here, with FakeVim enabled.
CEDET
I am kind of surprise nobody mentioned Eclipse CDT (http://www.eclipse.org/cdt) yet. I use it at home and at work - it's great; the c++ highlighter and indexer is fantastic. It even has call hierarchy and and other nice things built in.
I suspect the reason nobody else has mentioned it is that a vast majority of those able to run Eclipse smoothly are off playing Crysis instead of coding or redditing...
They asked for the best C++ code completion. Eclipse CDT is not it.
Unfortunately Wine doesn't run Visual Studio. You can run it in a VirtualBox VM semi-integrated into the host OS fairly comfortably though. When I was using Linux as my main OS, I had a windows VM on every computer I owned, just so I could use Visual Studio. I have a feeling that I'll change allegiance to KDevelop 4.0 once it is released though. VS2010's minuscule autocomplete box is driving me nuts.
Go with NetBeans or Eclipse CDT.
It takes resources, yes. Your CPU/RAM is useless unless you use it. I develop daily on a 3 year old dual core 2Gb ram, Eclipse runs fine. You can worry about this stuff in your own programs you make, but come one, don't be cheap on the development environment.
&gt; Fortunately Wine doesn't run Visual Studio. FTFY
MonoDevelop
It has a fake vim mode.
The developer in that video calls it "cute". Everyone I know calls it "q-t". Have we been saying it wrong?
I take it you've never used VS 2008 or 2010.
I take it you are a "Windows guy" ;) Not that there is anything wrong with that, it's just that most of those who learned to program on Windows grow to love VS, and most of those who learn on unix can't stand it. As with most things, whatever people learn early and become familiar with, tends to stick. I use emacs personally, but I can see why many people would not appreciate it, or simply not want to invest the time into learning it. Going back to the OPs question, there are several emacs options, but I can't say one way or another which are worth looking at. [GNU Global](http://www.gnu.org/software/global/) is getting a lot of praise, but if you want a VS-like environment, you still may not like it. Eclipse maybe?
Well, people are mentioning Visual Studio, and Crysis has nothing on that hog ;)
ratatask, damn right! Eclipse CDT (Only, do not download the java developer edition and then install the CDT) works really good. I use it every day to work on really big projects like the linux kernel, webkit, etc. and it just rocks!
Actually I started programming on SCO Unix and then did some C++ compiler work for Solaris at the beginning of my career. I like VS when I write Windows applications but if it were available for Linux I would pick that over other IDEs.
Yeah, Cute is the proper pronunciation but a lot of people call it Q-t.
Well here's a /book/ which I don't own, but looks very relevant. I can vouch for the author, he's one of the best C++ minds out there. http://www.amazon.com/Extended-STL-1-Collections-Iterators/dp/0321305507 (It's about making your own containers look like / work with the STL, not a catalog of the STL like Josuttis' work.) But, reading your post more closely, you've got a new collection with new functionality, so the complexity doesn't matter. Have you looked at Boost by the way? It wouldn't surprise me if it's been done already. If not Boost then /somewhere/. 
I didn't look at boost too much. Even if it had skiplists, what I need goes well beyond what I describe above. But is built upon what I've created so far. So for the common stuff, I'd like to release it and have it conform as closely as possible to what's already available in STL. I find an indexed and keyed Linked List with O(logn) guarantee with random iterators to be appealing. I like your suggestion. I think I will create my own new categories similar to the existing ones, but with different complexity guarantees. Like Reversible Container LogN. And Forward Arbitrary Access Iterator LogN. That book is a little pricey for what I want to do, but might check it out anyways to get a better grasp everything. 
I, for one, abhor the shit out of Windows. The whole OS is riddled with bugs, usability issues and doesn't have a lot of the features that Linux has had for years. Visual Studio, OTOH, it a very usable IDE. Sure it has the odd bug and until its latest release a few days ago didn't have a plugins system worth bothering with, but for the languages MS condones it's really very good, requiring virtually no configuration and providing the best code completion I've seen in an IDE. I'm offended that you would accuse someone of liking Windows just because they support Visual Studio. The only reason I even have this crappy OS installed is because it's the only OS my graphics card manufacturer bothers to make usable drivers for.
VS2010 actually runs like a dream compared to Eclipse, at least on every computer I've owned. On my computer, it starts in half the time(3s for VS vs 6s for Eclipse*), uses less memory when nothing is opened(40MB for VS, 197MB for Eclipse), and uses less memory after a small project has been loaded and compiled (71MB for VS, 355 for Eclipse). Even on the older versions of VS I rarely saw it take more than 300MB, and yet Eclipse is using 355 for a simple "Hello World" app. **Measured after several test runs to make sure they're both equally cached from the HDD. VS wins by a landslide otherwise because I use it more* Get your facts straight before you flame. Your bigotry is doing more harm than good.
Maybe "cutey" (homonym to "q-t") is just an endearing nickname they give to the awesome product formally named "cute"...
How long did it take to render that image?
The guy who wrote Metatrace is a really arrogant prick.
Just the closures and properties extensions in C++ make it great. 
Do you feel a little silly for taking such a comment, made in jest, that seriously? I even had the wink emoticon! ;) If I managed to exemplify bigotry as well as come remotely close to causing actual 'harm', you have definitely not seen the world that I have. Edit: I am actually slightly concerned that someone with your posts in the LGBT subreddit throws the "bigotry" label around that easily. You really are doing a disservice to LGBTA by doing that, FYI. But, if you have actually had VS 2010 on every computer you've owned, you certainly can't be very old :D 
I'm just offended there seems to be so much VS hatred on Reddit. Also, I messed up ALOT while rephrasing that first sentence. It should be more like: &gt; VS actually runs like a dream compared to Eclipse, at least on every computer I've coded on(at least the last 8). On my computer, for VS2010, ... I've actually used VS since it was VC++ 6.0, and while I've had my share of grievances, I've always been revolted at how slowly Eclipse runs. But you're right, I was being excessive in calling you bigoted. Sorry. In future I'll say "Your smarm is doing more harm than good."
Now I want to see a C++ meta-compiler. 
wow, what a completely useless post
How on earth does a compile time ray-tracer work?
C++'s templates are Turing-complete, meaning that you can perform any sort of calculation with them at compile time. Google for template metaprogramming to find out more (:
Why?
The C method is to call [stat](http://www.opengroup.org/onlinepubs/000095399/functions/stat.html). There may be a streamy way of doing this.
thanks it worked
You can try opening the file for reading with a local input stream. If it works, then close it and you know it exists. You can use in.is_open() just fine to tell that the file exists. 
In all fairness stat() is a POSIX call, not part of the C standard library. Microsoft does include the function as an extension in their C runtime though. [MSDN link](msdn.microsoft.com/en-us/library/14h5k7ff\(v=VS.80\).aspx). I don't think it's cheating to use the Operating System for what it's supposed to do though. ;) Of course, even if it was a part of C, C++ included damn near the entire C standard library, you'd just use an include like #include &lt;cstdio&gt; (instead of stdio.h) and then all the C functions you're used to are in the std namespace (e.g. std::printf, std::fopen, etc.). There's a race condition doing stat() followed by opening a stream, but I doubt your instructor is worried about this for introductory C++ courses. ;)
This will fail if the file exists but the program doesn't have read permission.
Don't. You're just programming a race condition. The OP wants to open the file `O_CREAT | O_EXCL`. Anything else is idiotic.
No, it didn't. It never should have been suggested because it's buggy and introduces a race condition. However C++ exposes C's `open(2)` syscall, you want to open the file `O_CREAT | O_EXCL`. Do that and only that.
I know this is just a sample program, but a couple of comments anyway: 1) you don't need the first pair of cout/cin lines; the way you've initialized 'user' guarantees that the while loop will be executed at least once 2) the while condition will always evaluate to 'true'. what you want is '&amp;&amp;' (and not '||'). 3) the (user = "yes") should be (user == "yes"). it rubs some people the wrong way but if this has bitten you more than once you might want to consider writing it as ("yes" == user).
Ta!
&gt; A lambda can contain everything a function/method can have - local variables, static variables, calls to other functions, memory allocation and **other lambdas too**! Following code is valid (absurd though!): Not very much of a functional programming guy, it seems.
These are not "new features in Visual C++ 2010". They're simply new features of the language!
I also believe that you can omit the ().
&gt; The auto keyword now also has *one more meaning*. Actually, not true. The previous mostly-useless use of the auto keyword from C and C++98 is no longer in C++0x; auto only means one thing in C++0x. So for instance you can't say auto int x = 5; in C++0x. This is described further in the WG paper N2546, and is already implemented by GCC (and probably Visual C++; I suspect it would be difficult to implement type-inference auto along with C-style auto at the same time).
Yes, the previous semantics were useless anyway.
You are coding old school c++. Anything recent supports [RTTI](http://en.wikipedia.org/wiki/Run-time_type_information).
Monodevelop is great with C#, but does it do autocompletion with C++? I know it doesn't with Java. 
Fun, increasing knowledge, exploiting compiler limits, xmas + welcome-new-year coding, basically the same reasons why ppl write quines :)
To be honest, when I think of user-defined literals in C++0x (which means you can write stuff like "float x = 5degrees;" e.g.), this really seems to be a valid option for things like typesafe regexes or sql inside C++ code :)
About using a constructor in the return statement, I didn't think this was necessary if all your return statements returned the same local variable. The author says that some compilers don't support this. While this may be true, it looks more like a hack to get around compiler inefficiencies than a technique to be used all the time. On that end, it's fine I suppose. If I really don't want copies, I use pointers directly and call methods instead of using operator overloading. It may not look as clean to the user, but it's not meant to be. It's to be clear that you're doing something ugly to get faster speeds and there is no mistaking what is happening with the objects' memory. edit: After re-reading my comment, I'm amazed at how differently I think of C++ since getting a better handle on RAII, templates and RVO optimizations. Is this normal after using some of the more advanced features? A few years back, I would have applauded tricks like this 100% (though I still like it if it gets around a known problem). 
&gt; CINT, a repl for C++ No, no it really isn't. CINT is not C++. It is a near facsimily that teaches people a bizarre version of C++ that will confuse, confound and lead to bad C++ habits. CINT, at least as used in ROOT, is the "Hidden Variables" of programming. At best its use in ROOT is convenient; at worse you can not trust your results. Thankfully, some reasonable ideas have percolated up into the form of PyRoot. Python bites CINT in its shiny, rusty ass. But, now I begin to digress. 
[Yes, it does](http://monodevelop.com/Download/What's_new_in_MonoDevelop_2.2#Other).
Blabla haskell. Blabla C++.
There is no operator[][]. What you do is overload operator[] and have it return an instance of a helper class; this helper class also overloads operator[]. That said, it sounds like you can have your original operator[] return a reference to a vector&lt;int&gt;. Since vector&lt;int&gt; overloads operator[] you will be good to go.
You can't overload [][]. However, you can overload [] to return another object that also overloads []. With this setup, you can write g[x][y], which is really just (g[x])[y]. The first operator ([x]) is called on your grid, but the second one ([y]) is called on the returned object. Maybe the returned object is just a vector, maybe it's something else; it's up to you.
Are you really going to just put your homework on here instead of trying to figure it out yourself? You learn more figuring it out :/
Although in a Sudoku solver he'll probably make things a lot easier for himself if he returns a wrapper object, so that he can move up/down/left/right x rows from a given cell and automatically wrap back around to the other side in case of overflow. By exposing the vector, he loses that positional information. And I've written enough Sudoku solvers and Games of Life in enough languages to know you don't want to expose the cells too directly if you want your algorithms to remain legible and reasonably short.
What I like to do with matrices is overload the parentheses operator, something like this: g(0, 1) = 7; instead of this: g[0][1] = 7; just do: operator()(int x, int y)
thanks
I don't remember exactly, but I think it was like 14hours (http://ompf.org/forum/viewtopic.php?f=8&amp;t=1556).
1.) Don't post your homework. 2.) StackOverflow.com is a better place to ask programming questions.
Pretty sure the compiler is smarter than this guy.
Pretty sure the compiler will soon have C++0x lambdas...
Also, [C++ has an inline keyword](http://www.functionx.com/cpp/keywords/inline.htm) that actually does this...
Just admit you have no idea what this guy is talking about and move on. Code that uses functors such as for_each have 2 problems, one is that you have to define the functors far away from where you use it, which makes the code harder to understand, even when it is simple. The other is that there is some overhead to calling the functor, so if it were in a high performance tight loop, you really wouldn't want to do it. This guy has figured out how to eliminate both problems with the new C++ standard (to-be) lambda feature. It is very, very cool in my opinion. Now he picked a simple example, so it easy to snipe and say he could have just written out the loop. But it is like a macro in a way, and it is a feature he can use to set up frequently used control structures again and again. My only real concern, like with all of C++s template features, is how long does this take to compile, and how gruesome are the error messages?
Actually this guy is not using C++0X lambdas - he rolled his own!
Kinda odd to go through all that work without even mentioning C++0X? Anyway, with gcc 4.5 all his hairy code can be deleted, and replaced with this: template &lt; typename F &gt; inline double integrate (F f, double a, double b, int n) { double delta = (b - a) / n ; double area = 0.0 ; double x = a ; for (int i = 0; i &lt; n; ++i, x += delta) { double y = f(x) ; area += (y * delta) ; } return area ; } int main () { double area = integrate([](double x) { return x * x; }, 0.0, 1.0, 10000) ; printf("output: %f\n", area) ; } And with -O2 it still totally inlines, just like the assembler dump in his article!
I should just admit here that I don't know what he is talking about.... But I won't! I guess he's not patient enough to wait for C++2X to be released?
You should really [link to the site](http://vmakarov.fedorapeople.org/spec/). The charts are available via the last six links.
ah; I did, originally, then saw the text box and wrote a note in it. That killed the link and turned it into a 'self' post. 
Huppy Burfday
So Clang/LLVM are still slightly faster and produce better code than GCC 4.5.0. Clang also has much better diagnostics. I would like to use Clang but there is one problem: their C++ coverage is still incomplete. In the past couple of years I have read a lot of articles/blogs about how new releases of Clang produce better code, compile faster and issue ever more helpful diagnostics. Every time I read something like this I would get a feeling that the Clang developers are focusing on the wrong thing. What use are all these (good, no argument about that) improvements if I still cannot compile my programs with Clang? Looks like a case of premature optimization to me.
Better at compilation time, but not better at performance of generated code. Higher = better for performance.
I don't think they are not focusing on C++ support. It's just that extensive C++ support is an incredibly hard task.
All in due time. The C++ compiler is improving with each release. They'll get it.
The key thing to understand is how Clang development works. The compiler is built in pieces by first adding support for all the C features, then adding support for all the C++ features. Features are added one by one (and can happen at any time). If something doesn't compile, well that means that feature is either not finished or has not even been added yet. See this page: http://clang.llvm.org/cxx_status.html C support was finished sometime back... C++ is being worked on. Just recently, there were enough C++ features that they could actually compile Clang. This does not mean all the feature of C++ exist yet, however. The key point in all of this, is that the core design was made years ago when the project was first started: these features, part of the core design and core philosophy of the project are what you are reading about most likely. On the other hand, it takes years to program a C++ compiler to support all features of the language. Consider the fact there there is no other open source C++ compiler in existence other than GCC and Clang seems even that much more special. * Several years back Chris started work on the Clang compiler * Within a year or two, all the features of the C language were added. * Over the years, they are working towards the goal of C++ support, by adding feature after feature. * As of right now, there is enough C++ support to compile Clang, but there are still unfinished items. An additional note: I suspect it was very important to get a good design/framework/philosophy in place from the beginning of the project, that would allow them to so easily add features to compiler over all of these years.
If all you need is to parse C++ there is [gcc-xml](http://www.gccxml.org/HTML/Index.html)
Two problems with gcc-xml, the first is conceptual and the second is practical: What gcc-xml does is pretty much take the GCC AST (which is actually more of a graph than a tree) and then "flatten" it into an XML format. For any serious processing you will need to re-create some kind of an in-memory representation from this. Which brings the question: why not use the GCC AST in the first place? The other issue with gcc-xml is that it is no longer developed/maintained. The last release was made in 2004. I doubt it will build with any recent version of GCC.
Ok, so it's been a while since I tried to parse C++ in a project :) When I did, gcc-xml was about the best thing around. Parsing c++ is horrendous.
No Linux support? Really?!
Damnit! Just compiled 1.42 (took a loooooong time), now it's time to compile 1.43... Ah well, at least it includes some nice improvements.
This is one of the things Java's container classes got right: The functionality is specified in an interface, without any performance guarantees, and you pick an implementation to match the performance characteristics you require.
It's a double edged sword, because not having the performance guarantees means exactly that. If I have a function which takes a List&lt;T&gt; in Java, there's no way to be sure how it's going to behave.
It was an easier choice in Java since all the functions are always virtual. In C++, to support this, you would have to make the container's interface out of virtual functions with all the performance consequences of this choice. Half of the people would love it, the other half would hate it. Then there is the fact that each type of container has a slightly different "natural" interface (compare: vector, stack, and map). 
&gt; If I have a function which takes a List&lt;T&gt; in Java, there's no way to be sure how it's going to behave. From the callee's point of view, I prefer to think of performance requirements as suggestions: You can document that callers should provide a `List&lt;T&gt;` with particular characteristics due to the nature of the function, but it really should be up to the caller to decide whether to use a container with those characteristics, copy to a new one that does have those characteristics, or plunge ahead because neither option makes sense.
This guy appears to have completely misread the documentation he's spent an entire blog post criticising, nor has he apparently bothered to look at any STL implementations, or read any of Stepanov's articles or docs. In his paragraph on Associative Containers he's confusing the complexity requirements for erasing an element with erasing a key, from the docs: &gt; Average complexity for erase key is at most O(log(size()) + count(k)). &gt; Average complexity for erase element is constant time. The former is typical erase complexity for a map or set implemented as a binary tree. The latter describes the complexity for erasing an element when you already have a pointer/iterator to the element you want to erase; this requirement is basically just saying that if you erase an element you shouldn't have to do complicated rebalancing of your data structure. The complexity requirements associated with the STL are incredibly useful once you learn how to interpret them. 
I disagree, with both you and the article. The performance requirements are listed there so they are easy to find. A C++ programmer will have guarantees about the performance of the STL data structures, something that does not exist in Java. In particular, while reading Java documentation, generally only two functions out of any particular container class seemed to have any guarantees on the performance.
You seem to have some really fundamental misunderstandings about C++ and the standard template library. The functionality in C++ *is* specified as an interface: an interface to a concrete class. This interface is shared inasmuch as is possible by different concrete classes, to support maximum genericity. The complexity requirements are part of the specification, so you *can* pick the implementation that matches the performance characteristics you require for the operations you need.
&gt; The complexity requirements are part of the specification In other words, what it does and how fast it does it are not separable, which was the whole point of the article. An associative container is any ADT that associates a key with a value, but SGI decided to include complexity requirements in their *abstraction* `Associative Container`, so a concrete class that implements all the functionality of an associative container isn't an `Associative Container` unless it also meets certain complexity requirements.
I consider it a failure of the documentation not to provide complexity guarantees for implementation classes, but I don't consider it a failure to omit all guarantees from the interfaces.
&gt; In other words, what it does and how fast it does it are not separable No, they're not separable. In order to choose which container is most appropriate, an engineer needs to know *both*. &gt; An associative container is any ADT that associates a key with a value, The standard template library doesn't define associative containers; it defines vectors, lists, deques, maps, and so on. &gt; but SGI decided No, Stepanov decided. &gt; to include complexity requirements in their abstraction Associative Container, What abstraction "associative container"? Do you know the STL? &gt; so a concrete class that implements all the functionality of an associative container isn't an Associative Container unless it also meets certain complexity requirements. It isn't a vector if it doesn't offer constant indexing, amortized constant `push_back`, and doesn't store elements in contiguous memory. These are essential to the nature of what a vector is, and that's why skiplists are inappropriate for vectors. Skiplists would actually be a fine implementation of `std::map`, though they typically perform worse than balanced trees. (Just as an aside, the only people who seriously implement skiplists are students who choose them for ease of programming; at nearly every task they're inferior to some other data structure in some important way.)
&gt; What abstraction "associative container"? [Associative Container](http://www.sgi.com/tech/stl/AssociativeContainer.html) (see Complexity Guarantees in particular) I suppose the question I have is this: Is this normative for the C++ STL or is this an SGI offshoot from the standard? If it's not normative, there's no dispute here at all; I expect any actual container to meet specific complexity requirements, as with your example of `std::vector`, and I'm only referring to concepts that are expressed strictly in the documentation.
&gt; I suppose the question I have is this: Is this normative for the C++ STL or is this an SGI offshoot from the standard? Historically, the SGI implementation preceded the standard. Some parts of the SGI implementation didn't make it into the standard (e.g., `hash_map`); "Associative Container" seems to be one of those parts. Stroustrup mentions the term (p. 480 in my copy) but never defines it as something standardized; he just explains the concept and then goes on to describe `std::map`, which fulfills the concept.
Ah, mine's a 2nd edition and predates the adoption of the STL into the C++ standard, so I've always referred to the STL site for documentation. It seems the article's author and I both made the same mistake of assuming the STL docs described the ANSI/ISO standard, and this is much ado about nothing :-)
Personally, VS on Windows, VIM otherwise.
You need to handle your base case. What happens when lo and hi are 0? 
The key to recursion is knowing what to do in your last step. What should you do when sum is called where lo == hi?
Your current code assumes `lo = 0`. The midpoint is `(lo + hi) / 2`
I am learning about all this, but I don't believe I confused the two at all. In a skiplist, you have logn levels of forward (and optionally backward) pointers. This is what makes a skiplist a skiplist. It takes logn time to update all the levels no matter what even if you already have access to the iterator. Because the complexity requirement for erasing an element is constant time, a skiplist can never be an associative container. However, you say I should have interpreted the complexity requirements differently. Please explain. 
So concepts are NOT part of the STL? That doesn't make sense considering that forward iterators, bidirectional iterators and random access iterators are very much part of the functioning of STL. I still can't tell which came first, concepts or actual containers like vector and map. Also, I'm using skiplists because I need something that works both as a set and a vector (or both as a map and a vector) at the same time. A skiplist can work with keys and indexes at the same time within the same data structure (insert only works with the key, but you get an index with the iterator). They all work in logarithmic time which is the disadvantage. Still, I haven't seen anything that compares and certainly nothing in the STL can do what I need. 
When I said separate, I didn't mean that they shouldn't be specified. I just meant that an Associative Container should define the functionality only. And a different Performance Concept would define different sets of performance requirements that would be specified by the implementation of your actual container (vector, set, map, etc.). 
Thank you. I wish I could have worded it like this. 
Is anyone else as excited as I am to think about all the new and creative ways that we can abuse C++ now? Seriously, now we'll be able to write code that's not only impossible to port, but to compile correctly when a certain plugin isn't available. Yay!
There are a number of flags on istreams: eof, good, bad, fail. You almost never want to check for these explicitly. Instead, just check `while (somefile)`. By the way, this is a much better question for StackOverflow than reddit.
Both libstdc++ and stlport are correct. In this case, when istream::get() encounters an EOF, it will set **both** the failbit and eofbit. Why? Consider what is happening. After you read the last character, the stream is still in "good" condition. That is, good() is still true after you read and print the last 'e' from "reddit is awesome". The next time you loop, you try and get a character. But there are no more characters in the stream - so it sets eofbit. But get() also failed to retrieve a valid character, so failbit is also set.
Thanks for your help, I was even more puzzled after I made the submission and realized that eof() was in fact returning 'false' even after the last character had been read. I can tell my preconceived notions about streams from C, sockets &amp; other frameworks are killing me right now. :) At least from the perspective of exceptions, it seems counterintuitive/poorly thought out at best, since ordinary and successful file reading cannot be accomplished without generating a failure exception - even though there's an entire exception bit for EOF (but no corresponding exception; only ios_base::failure). Seems more proficient to me to loop while (fstream::good()) and assume an error occurred if the loop ever exits, but then turn on EOF exceptions and carry on with the program after the catch. I really don't like that approach, so I'm going to do as AnonymousCowered suggested and *not* use stream exceptions. :-) Thanks again for your help, I thought I was going crazy. Turns out the GNU docs mention that eofbit and failbit can be set at the same time, though cplusplus.com doesn't say so. Neither mention specifically that eof() will only return false after an unsuccessful extraction attempt like get() or getline().
Thank you, agreed, and thank you, bookmarked. :-)
&gt; Neither mention specifically that eof() will only return false after an unsuccessful extraction attempt like get() or getline(). It does that because how else would it know when it reached eof? The “file” could be stdin, not necessarily a disk file where the size is known. Even with a disk file, it’s abstracted as a stream. You could argue that it should know, when reading a disk file, that it reached eof, but then you would no longer have a generic stream-handling mechanism—you would have to read it differently if it was a disk file vs. another type of stream.
First of all, it doesn't work to open the stdin file with an fstream. All of the read calls are nonblocking and gcount() doesn't go up whether you press keys, press enter or pipe files into it. I'm not sure why. I don't know about std::stdin or std::cin. I still don't think I'm getting the big picture. It looks like they've designed one object to work with both synchronous and asynchronous streams, but have in fact exposed details of both types of streams to users of either type; even fstreams, a specialization for files. I've used interfaces that can work fork both asynchronous and synchronous operations, and the only difference there was which calls blocked, and some way to distinguish "can't read right now" from "can't read ever again" from "an actual error occurred". Either way I'm especially not seeing the usefulness of exceptions() in the fstream classes; seems like the goto keyword would be more straightforward for organizing simple file open/read code.
I prefer to use: while( somefile.peek() &gt; -1 ) Just a suggestion.
Ah yes, peek()... not sure why I didn't recall it after having used it just a few weeks ago. Thx :)
You're welcome :) In my Intro to C++ class, I had to show my teacher that using peek() was a better alternative than any other option she was trying to show us.
so normal behaviour is an infinite file? There should be an exception for an infinite file since those aren't normal. One thing about c++, declare stuff as you need and use the constructors. Lazy declaration and construction are huge plusses over ansi 'c'. Use them.
&gt; so normal behaviour is an infinite file? No, it turns out EOF really is a failure in STL streams. I learned EOF as a seek position, where asking a stream if it's EOF is like asking if its seek position is equal to the file size. A completely separate concept from a stream error. In STL streams, EOF is an event that occurs only after trying to read data from a file that's already at the end. Asking it if it's EOF before that unsuccessful attempt to extract data returns false. So instead of using eof(), it appears best to use (peek() == -1) as daminkz suggested. Basically, I was wildly unprepared for the idea that C++ STL streams were suitable for asynchronous reading; and Sc4Freak helped me get my head around that. &gt; One thing about c++, declare stuff as you need and use the constructors. Lazy declaration and construction are huge plusses over ansi 'c'. Use them. Agreed. In my real code the 'somefile' object is a class member and I want to call the exceptions() method before opening it, so I don't initialize it. I'm (obviously) still very new to STL streams, and it escaped me when I was writing the snippet above that I could use the constructor instead. Thanks for the reply, sorry if I wrote too much.
i always though functors were general type (func)tion poin(ters) and that operator() is primarily an stl adaptor.
I understand that this is a cool exercise, but is this really something that people feel that they need or even want?
It has begun! (Now to see if it'll build Ogre...)
I got pretty far building my qt4.7 application with it. 
It does not :(
[Here's a detailed post on navigation meshes](http://www.ai-blog.net/archives/000152.html)
Not to burst your bubble, but when a friend and I used spirit, the resulitng parser was ridiculously slower than the others written in Java using Flex and Bison.
Stackoverflow is a better place for this.
Interesting that you jump on the speed point considering not once in the article did the author tout the speed of Boost.Spirit. Did you read the article?
well, you either need to pass in a value to compare everything with or return both a boolean and value. I would pass in a value personally like: bool allequal_helper(vector&lt;int&gt; &amp;v, int low, int hi, int value) { if (low == hi) { return v[low] == value; } else { int mid = (low+hi)/2; return allequal_helper(v, low, mid, value) &amp;&amp; allequal_helper(v, mid+1, hi, value); } } and bool allequal(vector&lt;int&gt; &amp;v) { return allequal_helper(v, 0, v.size() - 1, v[0]); } untested of course.
okay you used a int value to deal with that oaky.... thanks so much.
will do next time
This doesn't correctly handle the case where the vector (or a subvector) has zero elements.
Or you can use [/r/reviewmycode](http://www.reddit.com/r/reviewmycode/) :)
I didn't say he did. But when the solution is orders of magnitude slower, you shouldn't use it. Also, maybe knowing this the author will be able to find out how to make a complex grammar using boost spirit that isn't slow.
What an odd thing to use recursion for. That just makes the algorithm slower than doing it iteratively. What you have is almost right, just move those inner if-statements outside the outer if-statement and inside the if statement return the &amp;&amp; of the two recursive calls.
Don't be silly. Any question as to whether a solution is or is not too slow should depend the requirements of the project you are working on. Sometimes an elegant but slow solution is the right choice. The author's post was about the elegance of Boost.Spirit not about it's speed. Your negative comments are irrelevant to the discussion. Don't be a troll.
If I understand your question right, you want to find out why 'allequal' should be true on an empty range -- that is the base case. You can think of 'all equal' as 'all equal to k, for some constant k', and then as 'no exceptions to the property of being equal to k, for some constant k'. Since there are no values in an empty range, there are no exceptions.
At that time you probably used the older Spirit version which was known to be slow (especially when you were using AST's). The version the author is talking about is a complete rewrite. And it's fast - pure unadultered speed! See for example here: http://www.reddit.com/r/programming/comments/anbc5/boostspirit2_vs_atoi/. 
Darn. Now **that** is a milestone I'll be watching for...
Can't say that I would ever use it. Posted entirely in the spirit of 'interesting technique, might be useful in some other context someday (or maybe not).'
For the next trick, I expect a demonstration of how to achieve dynamic polymorphism without the overhead of virtual function calls, by using this magic type number as an index into a table of function pointers. 
Didn't you hear? Subtype polymorphism is on the same par as goto. That's why he needs to reinvent it using a much more cumbersome approach.
So if I browse his blog history, what are the odds of finding a templated Dequeue class "so you don't have to rely on the stl"? 
Seems like tr1 could be used in prof code these days given the level of compiler support. 
Ah, yes I'll admit the version I used is rather old (2 or 3 years now).
While I'll certainly agree that in the general case, there's nothing wrong with RTTI, it is worth noting that there are some specific cases where it *is* a bit too heavy. Really, I'd have to see the context this system is being used in before I could possibly make any judgement call on whether or not it was warranted.
Can you give an example of a case where it's too heavy? I am very skeptical of anyone that claims to do RTTI faster than the compiler and still do it correctly. If someone can, then I hope they join the GCC team and submit their clever implementation so the world can benefit.
I put a comment on the blog. The class SomethingValueBase needs a virtual destructor. Without it, it wont properly destroy all those T objects in the subclasses. For example, Something&lt;std::string&gt; will fail to release the heap-allocated buffer it uses internally. The author appears to try to avoid using a virtual destructor and then attempts to rewrite the RTTI functionality. Given that the class heirarchy he is proposing is as simple as it gets (one base and single-inheritance subclasses one level deep), I would wager his solution (even once corrected with the virtual dtor) is not better than the compiler's native dynamic_cast support. 
Well, the big issue with RTTI is that it's an all or nothing thing. You can't choose to enable RTTI for some types of objects, but not others. Even if you only need the functionality for a handful of types, you get the overhead of RTTI information for every single object type. So, lets say you're writing game engine middleware. You want your code to be as light and thin as possible, especially if you support consoles, as every bit of memory is important. You can provide a custom RTTI solution and only have it apply to the handful of types that you require, rather than everything. I know from experience that Emergent Gamebryo takes this approach, using macros to designate concrete classes and add inheritance information to the internal RTTI implementation.
This isn't true. RTTI is not produced for types where the RTTI isn't used. If you have some type X, and you never use dynamic_cast with it, you never throw it as part of an exception, you never take its typeid or in general, you never do something that would make use of its RTTI, the compiler will not generate any RTTI for it. The compiler doesn't produce RTTI information unless that RTTI is going to be used at some point. It simply gets optimized away as if it were dead code. Could you imagine the kind of bloat that would be produced otherwise? Consider every function which has its own type or different calling conventions. Consider template instantiations with crazy memory allocators which in turn are template instantiations whose names can take up 150-200 characters or the bazillion of other types that get produced. If each single type had its own RTTI produced even though that RTTI was never used, executable files would literally be megabytes just for the simplest of things. Fortunately, like many things in C++, if you don't use it, the compiler doesn't produce any code or data for it.
This whole blog post is really a disaster when you think about it. It's the equivalent of someone who religiously believes that goto is bad, so in a dogmatic fashion re implements something that for all intents and purposes is a goto statement but names it 'togo.' Then writes a blog post showing off his custom buggy togo statement instead of using goto just so they can say they never use goto because it's OMG EVVVIIILLL.
Hrm, it's certainly possible that I've been taught wrong. My own quick research on the subject, however, appears inconclusive. My own searching turned up [this blog page](http://meshula.net/wordpress/?p=182), commenting on [this technical report on C++ performance](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1666.pdf). From page 24 of that report: &gt; In addition, a perclass space overhead of a “type information object” (also called “run-time type information” or RTTI) is typically about 40 bytes per class, consisting of a name string, a couple of words of other information and another couple of words for each base class. Whole program analysis (WPA) can be used to eliminate unused virtual function tables and RTTI data. Such analysis is particularly suitable for relatively small programs that do not use dynamic linking, and which have to operate in a resource-constrained environment such as an embedded system. The statement that WPA *can* be used to eliminate overhead strikes me as suggesting that this is a compiler dependent issue, likely influenced by specific settings, though it is likely safe to assume that most major compilers do eliminate unnecessary RTTI overhead by default. The fact that the report specifically mentions that this WPA is suitable for small programs without dynamic linking also makes me question whether or not we can assume that this overhead will be optimized out for large, complex programs, in which the overhead would most certainly begin to add up. It also jumps out at me that the overhead is typically 40 bytes per class, considering that depending on your exact needs for an RTTI system, you can probably get away with only needing 4 * (n + 1) bytes, where n is the number of inherited classes, by using a static uint equal to its own address in each class. This would also avoid the expense of strcmp in type checking, as the blog notes in its highlight of section 5.3.7. Again, from my admittedly limited research, things seem rather inconclusive. Build environment and program size can both potentially play an important role in this answer. It does appear however, that if nothing else, it can still be more memory efficient to roll your own in some, specialized cases. Regardless, kudos for prompting me to do some research into the topic that I likely would not have done otherwise. Have an upvote :)
 // here's one /* here's another one */ #if 0 here's an old-fashioned one #endif
Omg. I have not noticed. Thanks - let me get my head out of my v̶i̶s̶u̶a̶l̶ ̶b̶a̶s̶i̶c̶ ass and write some insightful comments on rvalue implementation aspects while dealing with closures...
Is the bit about the standard library doing the same thing untrue then? How does use_facet work, and why? Did the people who designed C++ make the same mistake?
There is no one-one mapping between facets and locale::ids. Only base facets need to define a locale:id and derived facets can use the id of their parent.
I think the title of the book is misleading. There isn't much about the C++ standard library in this book. Rather, it is a very basic introduction to general programming and OOP in C++ that, naturally, uses the C++ standard library in its examples.
This seems to be assuming a seriously good whole program optimizer. In particular, if some of your code is in shared libraries it seems like it would be quite difficult for the compiler to optimize RTTI away.
No this doesn't assume any whole program optimizer and different compilers handle the issue of how to deal with shared libraries in different ways. While the subtle details are different from compiler to compiler, in general RTTI information is exported into each shared library/DLL where the RTTI is made use of. Each class contains a pointer to the RTTI as part of its vtable and the actual RTTI instance that's chosen is in the the first shared library where the RTTI is used. So once again, if RTTI is never used, then none of the shared libraries will contain any RTTI and it will never get loaded. Only libraries that use RTTI contain any RTTI and sure there will be duplicate RTTI if multiple libraries use it, but only one single instance of that RTTI will get chosen.
I made a similar container. It is based on trees instead of lists, but I think it's similar to your container in terms of computational complexity (log N random access, log N insertion/removal). I really like the fact that STL implementations specify the complexity of every operation. When I read the documentation of other languages' containers, I'm irritated by the lack of such specifications. I don' want to go through the details and get to know the exact underlying data structure in order to realize which is the right way to use it. The problem for your container is not the existence or absence of such specifications. The real problem is that the generic algorithms were designed for the typical containers. Your container doesn't match any of the predefined sets (constant time random access; constant time insertion/removal). For this reason, [I didn't qualify my iterators as fully random access](http://avl-array.sourceforge.net/avl_array/rationale.html#full_ra), and [I reimplemented some specific algorithms inside the container](http://avl-array.sourceforge.net/avl_array/rationale.html#algo). If you want to fully integrate your container with the STL, you need to add a new [iterator tag](http://www.sgi.com/tech/stl/iterator_tags.html) to the STL (and redefine every algorithm...). You would have the same problem with any other language if you tried to plug your container with existing algorithms. The tight specifications of the STL just help in pointing out that there is a problem. By the way, I recently posted the _thing_ [here](http://www.reddit.com/r/programming/comments/c6nxa/why_dont_ordinary_files_and_arrays_support/). Warning: I think the title was a bit sensationalist and misleading :( And the name of the _thing_ was misleading too. 
forgot to mention: easy in C++ parsing using Boost.Spirit
for those downvoting -- let me know what you didn't like so I can improve.
Damn it your not supposed to boot-strap because it's useful, your supposed to do it because it's cool. I say write gcc in something that can compile gcc just for the sake of it. 
The only thing that comes to mind is, they're doing this because llvm and clang is written in C++. I'm not saying C is bad, but I don't think the GCC team would have even considered it if it wasn't for the competition clang and llvm have brought on. I'm all for it though. Two great compilers are better than one decent compiler.
I think you haven't seen GCC source code. Look for example at the C/C++ AST (abstract syntax tree) implementation. They had to invent their own OO with polymorphism in C. The result is a barely-comprehensible system with hundreds (if not thousands) of macros. This all could have been implemented much, much cleaner and simpler in C++ and I think the GCC folks realize it. As for LLVM and CLang, I don't think it has anything to do with this. I also don't see what competition you are talking about, at least when it comes to C++: GCC is a mature and proven C++ implementation. CLand currently can't compile most real-world C++ programs. Though, I agree with you, having another open-source, cross-platform C++ compiler implementation would be fantastic.
&gt; CLang currently can't compile most real-world C++ programs. http://blog.llvm.org/2010/05/clang-builds-boost.html Doesn't boost pretty much cover the breadth of C++ fairly well?
Clang has been recently released as stable for C99 and C++ support is approaching very quickly. FreeBSD is already moving to dump GCC in favour of Clang. So I certainly see huge competition.
No. Boost is intentionally designed to be compatible with the vast array of different C++ compilers out there. The blog post is pretty high on LLVM hype &gt; Boost has become a benchmark and a selling point for C++ compilers: is your compiler standards-confomant enough to build Boost? No, no it isn't. Maybe 10 years ago it was. These days it's had loads of work done on it to get it to work with every compiler out there. Check out there (very impressive) test suite. They have been sepcifically building with Clang for a while now. http://www.boost.org/development/tests/trunk/developer/summary.html Not that Clang isn't cool, but there's no reason to shit on GCC. Competition is good and they both excellent compilers.
As they start using their own medicine, we now stand a chance to see long lived nagging issues dealt with (ie multiple ctor instances commoning). 
Ugh...boost is a quagmire of stupid template tricks. I guess the price of trying to be a library that's everything to everyone. Very irritating boost broke with gcc-4.5.0 I'm sure most major compiler releases are followed soon by new boost release.
That is a problem with RTTI. I was on a project and we disabled RTTI (and exceptions) because our project was extremely memory-constrained. However, I'm not sure I agree with the approach taken by the author of this post.
In general, that may be true... But if you turn on RTTI (and by extension, Exceptions), you can actually introduce completely different code. For example, I worked on an embedded project that had two versions of STL depending on whether RTTI/Exceptions were on or off. Boost has lots of features and pragmas that will change the way the classes operate if you have them just turned on in your compiler... So, you CAN actually induce different code into a project in places where you wouldn't have expected it.... that's the theory, whether the practice matters, that's a harder question :) Still... if you need RTTI, you cannot do it both correctly and better than the native version.
I definitely agree that C++ with RTTI and C++ without RTTI are two different languages. There are many good reasons for avoiding RTTI, such as wanting to avoid cross casting/dynamic casting, not using exceptions, not using multiple inheritance etc...
Agreed. It seems kind of silly to switch to templates, which typically cause code bloat, if you're worried about the weight of RTTI.
But if you read the blog, it claims their compile *doesn't* hit any of those work-arounds. Who's shitting on GCC?
&gt; But if you read the blog, it claims their compile doesn't hit any of those work-arounds. It does not say that explicitly. It says that Boost has been tuned for compilers which are not LLVM. My point is that Boost is especially designed to work with a wide range of compilers. Regardless of magical #ifdef workarounds all over the place some of that compatibility comes simply from being aware of the problem and coding to avoid such issues in the first place. The original question was &gt; Doesn't boost pretty much cover the breadth of C++ fairly well? and the answer is no. Because Boost is incredibly above average. 
Quoting the blog: &gt; According to today's results, Clang is successfully compiling more of Boost than other, established compilers for which Boost has historically been tailored (through various workarounds and configuration switches). **In fact, Clang's compiler configuration in Boost is completely free of any of Boost's C++98/03 defect macros.** emph mine
You fail to get it.
I succeed in getting your mom
Aren't there slow implementations of RTTI on some compilers? Wouldn't a custom implementation make sense in that case? Disclaimer: I haven't read the article.
You must be 12 or at least in mind. I've done work with both GCC and LLVM, the latter is much easier to get up to speed and is enjoyable to work with compared to GCC. On top of this, GCC has lost some really good talent for not making this step sooner...hopefully they can make it up as things shape up..I just hope the documentation situation becomes better in this new journey
&gt; The problem for your container is not the existence or absence of such specifications. The real problem is that the generic algorithms were designed for the typical containers. Correct. But the situation could have been dealt with in one simple step. Separate the performance from the interface. They're still both specified for implementations. 
"Ok?" "\*smack\*" And like csoriented says on the 3rd page, "blah blah blah". 
So basically rvalue references and their implications are so complicated, that this guy has to spend most of 8 pages to explain what they are for. He mentions - even if not very loudly - that modern compilers can apply most of the optimizations that rvalue are supposed to enable even without them. Then he concludes that rvalues are full of "gory details" but the benefits are "considerable"? So in the end, we have gained a way to make explicit the kind of optimization opportunities, that most compilers were apparently pretty capable of figuring out by themselves. Even well-known C++ gurus are perpetually confused by them, and yet they are gonna go ahead and keep them in the standard because presumably it helps someone somewhere with a corner case that his compiler could not figure out by itself? (Concepts on the other hand are considered too complicated...) With a standard body like that it's little wonder, that C++ is the clusterfuck of accidental complexity that it is (and C++0x even more so, of course). I am actually generally pretty okay with C++ and for many things, that I do there is really no substitute for it, but sometimes I would really like to slap that Stroustrup guy around the head with a blunt object (say "The C++ Programming Language" published by Addison-Wesley). /rant
Yes, the details of the wording in the standard may be a little complex, but what useful part of any standard isn't? From a programmer/user perspective, rvalues aren't all that complicated and in practice they'll be used in a library like STL so you get the benefit without any work and you can just continue the old style of use or not even worry about using them. There's a pretty good summary about why they're used on wikipedia: http://en.wikipedia.org/wiki/C%2B%2B0x#Rvalue_reference_and_move_semantics These are also two very good resources about the types of solutions they enable and their benefits: http://www.artima.com/cppsource/rvalue.html http://blogs.msdn.com/b/vcblog/archive/2009/02/03/rvalue-references-c-0x-features-in-vc10-part-2.aspx
The problem IMHO is not, that rvalue references don't make sense from the vantage point of where C++ is right now. Every single feature I of C++ that I have encountered so far makes sense for the context it was developed in. The C++ standard body consists of some very smart people after all. However... I can't help but feel, that C++ as a language is lacking the big picture and gets completely caught up in ever smaller technical problems. C++ progresses by accumulating a large number of language features, each with a very limited scope. You only have to look at the Rube-Goldberg-Machine that is template meta-programming to see how language features with too limited a scope can be harmful. With TMP you practically never get to just write down what you intend, but basically have to trick the compiler into producing the desired result by accident. Now templates weren't really designed with meta-programing in mind and as such it is perfectly excusable, that things are as awkward as they are right now. What's less excusable in my mind is, that instead taking a step back and looking for a more general solution, a large number of small language tweaks are introduced, so that you have more different parts to build even fancier Rube-Goldberg-Machines. The argument, that the average programmer (the library end-user if you will) needs not concern him-/herself with these complexities, only applies as long as everything works fine. If things break with a library that makes heavy use of TMP for example, they will often break for terribly complicated reasons (usually with almost completely unhelpful error messages) and suddenly they do need to understand what's going on under the hood if they don't want to resort to trial-and-error programming. I think it is no accident, that more and more people are switching to other languages for their application development unless they have a very compelling reason why it has to be C++. Compared to learning all the intricacies of C++ even figuring out whatever the heck monads are supposed to be starts to look simple.
Couple thoughts. 1) sizeof gives the size of the datatype in bytes not bits. Therefore 2^(sizeof size_t) - 1 should read 2^(sizeof(size_t)*8) - 1 2) If you are using c-strings strlen isn't overflow safe, which makes it no less valid than for(i=0; some_string[i] != '\0'; i++). This avoids the problem in several cases.
Basically: Learn to code
Using strlen to iterate over a string is right off the bat a bad idea. strlen will iterate over the string in search of the NULL terminator. Using it to iterate over a string means doing two passes. Just use a pointer to iterate over a string, the terminating condition being when the *pointer == '\0'.
Oh, shush. Like your code is perfect. I've programmed C++ for over a decade, and have made this mistake at least twice in the last year. It's on the list of dumb but common mistakes, right up there with accidentally throwing a semicolon after after your for() or if() or using = when you meant ==. It usually happens when I'm comparing against STL's .size() result, which is also an unsigned size_t.
since an operation involving N and N+1 doesn't make sense without at least 2 elements in the array, how about if (len &gt; 1) { // do that loop } 
&gt; 2^(sizeof(size_t)*8) - 1 2^(sizeof(size_t)*CHAR_BIT) - 1 
This is why I compile my code with -Wall and -Werror. Let the compiler help you spot these errors. Comparing a signed variable to an unsigned variable will result in a warning and halting of compilation.
Oh as if : pointer[negative number] = FAIL; Is any better then rolling over into max int or what ever. It's all crap. 
&gt; Still, it remains a gotcha even seasoned programmers stumble upon from time to time. Not really. Just sayin'. And everybody knows the proper formula is: for(i = begin; i &lt; end; ++i) { ... } Note the pre-increment rather than post-increment for reasons that a "seasoned" C++ programmer would understand. Also, we know that C++ programmers should be using std::string rather than raw char arrays unless you're programming some extremely (seriously extremely) sensitive algorithm or something.
No idea. One of the more fun things I've done is writing parsers with Spirit 1.x, and I'd like to convert some of my older grammars to 2.x at some point. Problem is, for at least one of them, I used just about every Spirit 1.x trick in the book (dynamic parsing - if_p, for_p, etc, a custom iterator, all kinds of stuff) and it's not quite easy to convert to Spirit 2.x. Luckily according to Joel de Guzman et al, 1.x is here to stay in Boost.
Yes, plus "-Weffc++ -Wextra" for me ;) .
sizeof definitely doesn't return size in bytes. It returns size in chars.
Of course nobody code is perfect, but when you blog about how stupid a crappy your code is, this is what you deserve.
After being corrected on this twice, I must now [partially] counter-correct you. according to the C standard which defines sizeof() (I am looking at C99 ATM) it states: * The sizeof operator yields the size (in bytes) of its operand, which may be an expression or the parenthesized name of a type. The size is determined from the type of the operand. The result is an integer. * When applied to an operand that has type char, unsigned char, or signed char, (or a qualified version thereof) the result is 1. When applied to an operand that has array type, the result is the total number of bytes in the array.85) When applied to an operand that has structure or union type, the result is the total number of bytes in such an object, including internal and trailing padding. Therefore, we are both correct. In a standard system that has a compiler sizeof will always return the size of the structure in chars. On a non-standard system I guess the choice would be left to implementation of the compiler. Do you know of any system which has a &gt;1 byte char type?
&gt; The STL (more correctly known as the SC++L, or Standard C++ Library) How about just calling it by the correct name to begin with and leaving out "STL" altogether?
Because no one calls it SC++L.
Because it's not correct. For example, both the STL and SC++L include std::vector, but only the SC++L has std::string. Things like C++ IO streams are also a part of the SC++L but not part of the STL.
Removing 3 * 1 2 3 4 5 6 7 8 - original * 1 2 8 4 5 6 7 3 - swap 3 &amp; last value before pop (happens to be 8) * 1 2 8 4 5 6 7 - pop_back( ) (7 is last value after pop) * 1 2 7 4 5 6 8 - swap 7 &amp; 8 That's not sorted. Please correct me if I worked through your algorithm wrong.
Removing 1 from 1234 would result in 324, so it's not about the sequence being over a length of 4. For removing both the last and second to last element, the operations are either redundant (swapping with itself) or unable to be performed (swapping with the popped location). I believe that algorithm works for a special case where the element removed is 2 locations away from the end. When you swap the last value over 2 spots and pop the last element, you essentially need to sort the back 2 elements. They were previously sorted and are now unsorted, so the only operation ends up being a swap.
I wish people would call it the Standard C++ Library. Almost nobody uses the actual STL (which was published in 1994). As SC4Freak points out, the STL doesn’t even have `string`s.
OK, I'm serious here. Can someone please draw a Venn diagram showing the relationship between the C++ Std Lib &amp; the STL? Because I always thought that the STL was a subset of the C++ Std Lib (uh oh, introducing set theory, another weak point of mine). But I've encountered people who say that the STL &amp; the C++ Std Lib are the same thing, and others who say that some strange aspects of the STL are outside the C++ Std Lib. Quoting Nicolai Josuttis (First sentence, Ch. 5 of ["The Standard C++ Library"](http://www.amazon.com/Standard-Library-Tutorial-Reference/dp/0201379260)): &gt; The heart of the C++ standard library, the part that influenced &gt; its overall architecture, is the *standard template library (STL).*
The C++ Standard Library was *based on* the STL, but not a direct copy of it. The standards committee took the parts they liked, modified them (for example, by allowing it to be optionally implemented as a library instead of just headers), and left out the parts they didn’t like. It’s as simple as that. The STL was popular *before* the C++ Standard Library incorporated it. Therefore, when that happened, people said “STL is now part of C++” and continued to call it STL. As far as I know, STL itself is now a dead project.
&gt;Subtype polymorphism is also called runtime polymorphism for a good reason Well, except that you can get compile-time subtype polymorphism via the [Curiously Recursive Template Pattern](http://en.wikipedia.org/wiki/Curiously_recurring_template_pattern). [Armadillo](http://arma.sourceforge.net/) uses it pretty heavily.
Hey pkrumins, please do us a favor. You seem like a smart guy, so I think you'll understand my criticism: Don't let your blog degenerate into lots of funny pictures to take place of real content. One is probably enough.. when two or three creep in... I would be a regular reader but your posts are a little too applied for my taste. That's not a bad thing. Blogging about Unix one-liners is probably a decent niche if there was one.. But please quell the urge to put up cute pics to fill a space or entertain your readers. That's the last thing the internet needs.
There was only one drawing in the post and it was relevant to that C++ inheritance example. So I am not sure how it degenerates the content. That drawing by no means took place of real content. A lot of people liked that drawing, btw. Talking about applied posts, I sometimes post some theoretical stuff as well.
Just be consistent.
Isn't a lot, if not all, of this very compiler dependent. Obviously, that isn't necessarily a bad thing, but I just didn't notice it pointed out in the article that mileage may vary depending on platform and compiler.
Everyone's switching to HTML5 if they aren't using Flash and then we have this site. Using Silverlight. Ugh.
msdn stands for *Microsoft* Developer Network. Silverlight was created by Microsoft, and they will use it. Also, nobody is switching to HTML5 just yet.
Apple uses it for their video. But sure, no one else except for iPhones. Maybe soon.
That's a great video, I hope he keeps publishing them. Thanks for the link OP!
Unless HTML5 starts supporting &lt;advertise the shit out of this video&gt;, I doubt it'll be soon :p
[Top of the page / TOC](http://predef.sourceforge.net/precomp.html)
I think part of the perceived "complexity" is just due to lack of familiarity. The benefits of the concept system would be dramatic and hopefully it is resurected in the next standard.
Me thinks the complexity mostly comes out of wanting to cram in semantic concepts, on top of the syntactic ones. Just getting the syntactic concepts into the language would have been a whole lot better than getting nothing at all. I think they threw out the baby with the bath water here, when they opted for all or nothing. I bet 15 years from now, we still wont have concepts in the language. (The problem with semantic concepts are that they are not automatic, so you are forced to manually name each type that belong to a semantic concept. That kind of defeats the whole purpose of templated functions, where any type goes without having to know their actual name.)
It's unfortunate that concepts were shot down. I've been saying (to myself) that templates need some sort of type constraint syntax for years. And reducing template spaghetti errors? Hell yeah, we desperately need that.
I agree, something "like" concepts are desperately needed. I really, really dislike what was actually proposed though. First, they tried to add on all this semantic baggage which is probably what made the proposal complicated. Who cares if push() has a different meaning in one type than it does in another? it's highly unlikely that someone is going to make an error that would be solved by giving these operations semantic meaning. All they really needed to do was check syntax (does this type have a push method?). Second, concept maps are simply unnecessary. I think there's a general problem in c++ of trying to handle every single possible case. At a certain point, you can just say "if you want to use your types with our library you need to name the push operation push and not push_object or pushObject". Maybe that forces the use of adapters in some cases, but that's much better than adding another layer of complexity in the language itself.
I love how they wanted to clarify template errors. That's cute. Maybe they (gcc) should work on what happens when a symbol is undeclared. error: expected ‘)’ before ‘*’ token What? 
Three more kinds of polymorphism in C++. 5. unions 6. null pointers 7. unchecked exceptions
At the heart of the problem, in my opinion at least, are templates. That's hard for me to say because I really love how powerful templates are, and STL and Boost libraries have saved my ass many times. But concepts wouldn't even be needed if templates had been thoroughly thought out and well designed from the beginning. And I feel that C++ as a language has really suffered because of it.
Interesting stance. D provides Templates, but it also has "Template Constraints" which fulfill most of what concepts are in its own way. Error reporting is better in D (issue is usually with the name mangling), but the reason I bring this up, is if you can "fix" templates without hindering them, you could probably get it in the next major version of D. There would be lot of opposition to point out flaws in a suggested replacement.
&gt; I bet 15 years from now, we still wont have concepts in the language. I bet you won't get C++1x spec in the next 15 years.
Related: [01:33:50] [eldil:2:~]$ type cdefines cdefines is aliased to `gcc -E -dD - &lt;/dev/null | grep -v ^\#\ ' Same trick should apply to C++
Google "profiling". Then profile your code. Then come back to us.
* [boost::iterator_facade](http://www.boost.org/doc/libs/1_43_0/libs/iterator/doc/iterator_facade.html) * [boost::iterator_adapter](http://www.boost.org/doc/libs/1_43_0/libs/iterator/doc/iterator_adaptor.html) *edit* Never do what someone else has already done and probably done better. :)
The sad thing is...the example he gave doesn't even need an iterator (assuming the compiler can handle the pointer to an overloaded function, since he chose the same name--process--for both): std::foreach( v.begin(), v.end(), boost::bind( &amp;process, _1 ) ); Also: 1) since his iterator classes require access to the original container, you really don't gain anything at all by using them. For example, he stores a set of all visited elements of the container to avoid repeating any of them. The normal set iterator can get around this because it's just traversing a red-black tree and thus cannot repeat any of its elements when iterating forward anyway. 2) He has to allocate new iterators on the heap inside the begin() and end() functions. 3) he uses virtual methods, which means you pay an additional overhead for that. 4) I don't see where his iterators can invalidate themselves when the original container is modified. 5) his post-increment calls pre-increment on the real iterator, and returns void, which violates the contract for a forward iterator. So if you're using his class with an insert iterator, you might as well go fuck yourself. 6) he doesn't define any of the common typedefs or traits needed by a lot of STL algorithms. 7) ItrBase's == operator always returns true. Jesus, he could at least compare the pointers. 8) It's posted on CodeProject.com, which means it has to automatically suck. 9) The code doesn't compile. ItrAll and ItrNoRepeat don't even have the template keyword before them let alone the parameter list. 10) The guy is fucking clueless. He posted the same code on his blog, which I found through my powers of stalking, and somebody asked him why he didn't just use Boost. Here was his reply: &gt; Yes, the idea here is to hide the implementation of the visitor and &gt; its gory details, so that the user only see a STL-like API (which &gt; means that any STL application using iterators can be applied). &gt; Boost’s iterator\_facade and iterator\_adaptor are answers to similar &gt; concerns. The main differences here are that the API is exactly as &gt; an STL iterator –so you can conveniently reuse any STL algorithm &gt; that takes a range–. Uh, yeah, except Boost does that too, with the added benefit that **it's not a blatant lie**. This iterator class is totally missing all of the support for iterator traits, value_type, reference, etc. that many of the STL algorithms need to work properly (or compile at all).
I admit I didn't even read the code. The title was a pretty direct question, so I just threw up the best answer to that problem I knew. :P
This comment makes this article worthwhile. 
I have used this fantastic resource on several occasions. Big thanks to the developer(s) for compiling this (can't imagine it being fun).
Wow, pretty cool, I never knew about this.
&gt; Using the bit flipping of negative to very large positive effect is really programming with side effects [...] Undefined behavior (UB) is a very well defined term in the C and C++ standards. It would be nice if people used the defined, established terms instead of making up their own.
The issue is with using "unsigned int" as the input parameter to represent a memory index and not with ptrdiff_t. Like they always says, "the problem with pointing a finger at someone is that there are still 3 fingers pointing back at you."
This is correct. The proper type to use here is size\_t, which is 8 bytes on a 64-bit system. Using size\_t in this case instead of unsigned int would have avoided the problem entirely.
I'm missing something here. Why would someone represent a pointer as signed integer? It's an intrinsically unsigned entity. I've honestly never seen anyone do this intentionally.
a compiler with warnings turned on will scream at you for this code. Those warnings are there for a reason, use them! Also add more parens to the if operation...or even better, declare a const temporary of capaciy = maxp - ptr and add a check for if (0 &lt;= capacity &amp;&amp; (ptrdiff_t)nels &lt; capacity). and btw make you input function arg const. what you wrote there IMHO is fairly obfuscated. be a bit more descriptive in your code and don't get so fancy short circuiting stuff. The compiler doesn't care either way honestly.
things do get a little muddy when you start looking at file positions (off_t). Those are usually signed. So this case is conceivable... Also note std::distance() returns a signed type.
typeof(ptr as &lt;some integral type&gt;) != typeof(difference of two ptrs of &lt;some integral type&gt;) The first is unsigned, the second is signed.
The Good idea is to connect thread lifetime to object lifetime (and to avoid over sharing and having to synchronizing data between concurrent tasks by hiding the data away in the private parts of independent message objects). Here is a quote: *"Unlike with free threading, which lets us randomly do anything at all, active objects make it easier to express what we mean by automatically organizing the private thread's work around an event-driven message pump, naturally expressing isolated private data as simple member data, **and offering strong lifetime guarantees by letting us express thread and task lifetime in terms of object lifetime** (and therefore directly leverage the rich support for object lifetime semantics already built into our programming languages)."*
Probably to distinguish the call to std::toupper (declared in C++ std library locale) from ::toupper (defined in the C std library ctype).
if youre sitting inside of a namespace block, your current namespace is the scope that is checked first for name resolution. if you know that what you are looking for is in the empty namespace (like any of the standard C libraries), `::` denotes the empty namespace, much like `std::` denotes the std namespace.
For naked threads, you should be looking in /r/gonewild
Someone, please, outline a problem for which this is the solution.......??/? Why would you do that???? When would you need to do this????
How about any clue as to location?
Sorry, I should have mentioned that: Chicago.
Did the last guy die from bullet related injuries?
He ate a raw pointer and dumped a painfully massive core. That was the end of him.
I'm looking for that kind of work in NY :(
Well, consider moving to Chicago. You can get a NYC pay with the cost of living being dramatically lower. Plus, the company will pay for your relocation if you're hired.
I'm guessing you wouldn't cover relocation from the uk. I have experience that would prob make me an ideal candidate. But I'm across the pond.
Chicago is too cold. Would your company consider relocating to the tropics?
Why sell yourself short? Just be so awesome that they are willing to relocate you even though you're in the UK.
To anyone considering this dude's offer: be very careful asking about how many hours people usually work and how many hours people are *expected* to work, not how long they're *required* to work. There are a lot of investment companies in Chicago that have a huge reputation for "burn and churn." Often times you're paid 25-50% more than you would be at a sane job but you're working 100% more. If you don't live in Chicago already try to snag multiple interviews so you'll have some source of comparison. Remember with no social life you can't spend any of that money you're making. Disclaimer: I'm a programmer for a hedge fund in Chicago (one of the sane ones).
I will be the old spice man of c++ development.
Any potential candidates that this kind of job should be aware this could be incredibly lucrative for your career. I work in the same area and get paid 2x what i would doing similar work in another field. Whilst I don't know the details of the job most of these companies are actually really good to work for. And there are a LOT of jobs at the minute compared to other sectors.
Look up. Look down. The char pointers are now strings.
Aw, not looking for new college grads I see.
True, he never specified WHO would relocate, the firm or the individual
If you want the answer, try writing that without :: in CGG 4.4 (probably other versions too): As they automatically insert std:: namespace into default namespace resolution, you get into problems trying to decide between 'int toupper(int)' and 'char std::toupper(char, locale)'. So you really need it to cover that case.
Thing is, all of these would be a non issue with a really good implementation of C++. And by good I mean with modules, and the like. All the "include this, guard that" would be a non issue if modules was implemented as it's supposed to.
Wow sounds great..cept it's in Chicago !! Only 3 years experience.. not bad for relocation in a shitty economy. Yea yea so it's lots of hours.. It's a bad economy and you can quite any time you want. Plus they pay relocation. Plenty of people need work and 3 years experience is not hard to cover. Though.. I wouldn't move to Chicago unless i had to. Interesting offer though. I need some offers like this for Network or System admin.. or even just a field tech position that pays well and has health. 
Stating the obvious : thumbs up.
Good article and great book. I agree with all the advice in that article, but vary slightly on a couple. For example, I never use include guards any more and instead use "#pragma once" directives. It's non-standard, but supported an all modern compilers. The advice to avoid using preprocessor macros in header files is very good advice. If you don't you will end up with ODR (one definition rule) violations. The project I work on doesn't follow this rule and it leads to weird runtime problems. Unfortunately, the developers here (including me) like to use #ifdef / #endif macros in header files to make methods available only in certain builds. e.g: #ifdef ENABLE_NEW_FEATURE void someSpiffyNewFunction(); #endif The alternative, I suppose, is to use source code branches more often, but that has an overhead as well.
I am a programmer in Chicago downtown. Are you crazy, have you ever been to Chicago. Its great!
Chicago isn't that cold. And its not year round, you so crazy. 
Can somebody explain this? &gt; The only caveat here is that most C++ compilers don’t support making symbols internal by including them in an anonymous namespace even though this is the standard recommended method and the static method is officially deprecated. I was about to jump on his recommendation to use static, then I read the quoted paragraph... now I'm wondering, what does he mean by this? Aren't they essentially equivalent?
A really good implementation of C++ is one that is standards compliant. Are you implying that modern compilers don't correctly implement modules? Can you clarify this?
It means that if you put a symbol in an anonymous namespace, that symbol will still get exported and can be referenced in another 'translation unit' ie. an object file. If you make a symbol static, then it can not be referenced in another translation unit. Now you might think big whoop, the whole point of an anonymous namespace is to prevent the symbol from being used in another translation unit... For the most part this is true but there are some subtle exceptions in C++. Templates are the biggest one; they are instantiated in a translation unit of their own, independent of object files. If you use a symbol declared as static, then the template will not have access to that symbol and you'll get a compiler error. The recommendation in C++ is to use an anonymous namespace instead of static.
Your explanation hasn't added anything to my understanding... how can it be referenced in another translation unit? I tried it with extern, yet I still get this: MSVC++: cu2.obj : error LNK2019: unresolved external symbol "int static_global_var" (?static_global_var@@3HA) referenced in function "void __cdecl foo(void)" (?foo@@YAXXZ) cu2.obj : error LNK2019: unresolved external symbol "int anon_cu_var" (?anon_cu_var@@3HA) referenced in function "void __cdecl foo(void)" (?foo@@YAXXZ) main.exe : fatal error LNK1120: 2 unresolved externals g++ /cygdrive/c/DOCUME~1/myusername/LOCALS~1/Temp/ccQwUjDv.o:cu2.cpp:(.text+0x5): undefined reference to `_anon_cu_var' /cygdrive/c/DOCUME~1/myusername/LOCALS~1/Temp/ccQwUjDv.o:cu2.cpp:(.text+0xf): undefined reference to `_static_global_var' collect2: ld returned 1 exit status Edit: Perhaps this is what you're talking about: dumpbin /all cu1.obj ... 008 00000000 SECT3 notype External | ?anon_ns_var@?A0xd3e2b7a4@@3HA (int `anonymous namespace'::anon_ns_var) ... But I still don't see how/why that matters... Edit 2: Hold on... I think we might be talking about two different things... the author of the blog post was recommending use of static, against the recommendation of the standards body, which surprised me, and I couldn't see any benefit of doing that. If anything, your comment about templates makes me think that it's even more wrong.
The compiler can reference a symbol in an anonymous namespace when it uses that symbol as a template parameter. That's just one example but there are probably other examples as well. C++ is full of surprises/corner cases like this. Templates exist in their own separate translation unit, if you pass a symbol declared as static to it, then the template will not be able to find that symbol because of the internal linkage. If you pass a symbol declared in an anonymous namespace, then even though it has its own unique symbol per translation unit, the symbol has external linkage and will be accessible to the template. template&lt;const int&amp; I&gt; class MyClass {}; static int x; namespace { int y; } int main() { MyClass&lt;x&gt; mx; // Does not compile since x is not available in MyClass's translation unit MyClass&lt;y&gt; my; // Does compile since y is available. }
Do you recommend this book to someone who has only a year of C++ under their hat and isn't going into CS?
Are you designing large scale systems in C++ with only one year of C++ experience? That's going to be tough. If it is just something that you are interested in, then it is a good book. Pick up a used copy though. It's old and expensive. If you haven't already read the Design Patterns book (commonly called the gang of four book), then I would start there. 
I won't be designing large systems but my programs are getting larger. I'll start with the Design Patterns book. That's what I was looking for. Thanks.
No comment yet? OK, I will try one. - Duplicate syntax and operator, - Less and greater operators, and template declaration ('&lt;' and '&gt;'). - Bit shift and stream operator ('&lt;&lt;' and '&gt;&gt;'). - AND logical operator and reference ('&amp;'). With just that in mind I cannot imagine how they designed it in the first place, imagine the "if" check that compiler do. That is why I try to avoid using template, stream, and reference. 
I think those are waste of space, so I don't use them if the file contains only one class and the documentation of the class is equivalent to the documentation of the file. If the file contains macros or utility functions of some kind, I'll use doxygen comment like /** * @file * * Template functions to wrap Squirrel::functionCall */ 
None at the top. I hate opening a file and having to scroll just to see some code. I especially hate the block of boilerplate BSD or GPL at the top of many projects. If it's really important to have so much identical text, put it in a separate file and refer the reader to it. I do, however, think it's necessary to have large blocks of documentation preceding every function or object declaration. You know, actual documentation. Just standard Purpose, Arguments, Return values, Example usage, Implementation notes, [etc](http://github.com/victorliu/RNP/blob/master/inc/Eigensystems.h).
Usually I open it with #ifndef #define ;)
For personal projects. I do a little comment at the top of each file that states what the file is, who the author is and what the license is. Functions, classes, variables, etc are commented in Doxygen format in two different ways. On the declaration I comment what is expected from that class/function/etc - inout values, output values, etc - and on the definition I comment what it actually does if it's not obvious from the code itself. The declaration is always commented and the definition often isn't commented at all...
At one point, I was in a (graduate) programing class with an indian TA. He would take off points for not indenting the code. So I put /* * * Use fucking emacs to indent the fucking code like a real programmer can do * (instruction of downloading emacs and do the indentation */ Not that I didnt indent the code but the indentation got screwed up in translation. Funny that he was marking homework for bunch of PhD professional programmer.
Well, to be fair, he can't tell the difference between "got screwed up in translation" and "written by an idiot", and the fact that you were all "professional programmers" adds very little information either, as anyone who's ever looked at the state of professional programmers can quickly agree. On the other hand, you could have used your emacs wizardry to type `C-x h M-x untabify` and preempted the problem in the first place.
doxygen
I did my wizardry in the first place. First time he encountering the problem I would understand. this should not persist for an entire semester. In the end, the professor even agrees that the TA is an idiot.
Maybe the TA was pissed off by your snarky comment.
perhaps, but I don't unix/linux prog. expierience. (did some in school, about 10 yrs ago)
Be careful with this! auto_ptr&lt;cache&gt; cache_p_; You can't use auto_ptr in a pimpl unless you also provide the full definition of the implementation class destructor. Which kind of defeats the main objective of using a pimpl. One of the downsides of C++ is the frequent need to either allocate objects on the heap or to resort to hacks such as described in this article. 
The thing with licenses is that if the files are separated from the whole project and used by themselves, the developer is still responsible to make sure that the license terms are not separated from the files. So instead of copying a single file from some project, the developer would have to copy the LICENSE file also. And if the project would contain multiple licenses, rename it accordingly eg. like LICENCE.BSD and make sure that the copied source file refers to the correct license. Of course the original developer could refer to license terms hosted online, but it's not clear if the license would be valid, since the terms were not provided with the software,
&gt; One of the downsides of C++ is the frequent need to either allocate objects on the heap or to resort to hacks such as described in this article. As opposed to most other languages where you don't have any choice and you are stuck with heap allocations
Well, yes. But when I look at workarounds such as Andrei Alexandrescu's Small Object Allocator, I can't help thinking that there has to be a better way. 
Call me petty, but if a student put a comment like that in an assignment, I'd dock points and wouldn't feel the least bit bad about it.
While this is a good thing to keep in mind in general and, thankfully, GCC warns you if you are trying to delete an incomplete type, the article doesn't suggest that one should use auto_ptr in pimpl. Even if one does use auto_ptr in pimpl, the easy way to resolve this issue is to provide a non-inline destructor for the interface class. This way the auto_ptr destructor will be called with the complete definition of the implementation class, which is provided in the source file.
 #pragma once ////////////////////////////////////////////////////////////////// // MyClass // Put description here...which I basically never get to write // one and so most of the header files contain just "MyClass" // in the comment section ////////////////////////////////////////////////////////////////// class MyClass { public: }; 
Can you describe what you think would be a better way? I'm interested.
This all rather misses the point of the Pimpl idiom... to break a compile time dependency on the implementation details of your class and the other files that include its header. By using sizeof(impl) you reintroduce this dependency.
I'm curious what the author would think of the D programming language. Edit: the author says D is instantly disqualified because it requires gc. Actually, it does allow you to completely bypass gc, and at least one D program I wrote (Empire) does not do any gc. The author also says D "went crazy" for version 2. I don't know what he means by that. :-)
Someone needs a hug. :) I wouldn't mind seeing something like type methods similar to Go appear in C, but I'm not sure how to add it without it being horribly broken.
The article actually makes exactly the same point: *In the canonical pimpl form the implementation class is left undefined in the header file and as a result we cannot know its alignment and size, which are needed to allocate the buffer.* *Providing the definition of the implementation class in the header file is not an option since hiding the implementation details from the clients of our class is the reason why we choose to use the pimpl idiom in the first place.* 
A few ways spring to mind, but to implement them in a consistent manner would mean some changes to the language itself. The problem is that the compiler needs to see the full class definition in order to work out how much space to allocate. This is hard to resolve because C++ doesn't have the concept of modules. I'd like to be able to allocate statically or on the stack objects with partial definition, but because there's no concept of modules the compiler doesn't know where to go and get the size of the objects. The other option could be to finish off the allocation at link time when the compiler knows about how large objects are because it's already compiled them. This would require a special linker though. 
What a bunch of bullshit. *The problem isn't interchangeable string classes. The problem is that the default C++ string class is so utterly godawfully stupid.* *No garbage collection? Check.* Huh? Don't remember ever having std::string leak memory on me. *No refcounting? Check.* Most modern implementations are refcounted and COW (copy-on-write). Still using VC 6? *Need to allocate/free heap space just to pass a string constant to a function? Check.* Pass it as const char* if it is always a string constant? If not, and it is critical to avoid memory allocation, overload the function/ctor to take both const char* and const std::string&amp;. *No support for null strings? Check.* Evere tried to pass it by pointer (std::string*)? *Horrendous mess of templates that makes tracing in a debugger utterly painful? Check.* Can't remember last time I had such an experience. *Horrendous mess of templates that makes non-ultramodern compilers unable to optimize them so that, for years, your toy homemade string class was 5x faster? Check.* Definitely still uses VC 6? *Totally unclear what character type it uses (actually you can use whatever you want at different times)? Check.* Huh? He doesn't know what std::string uses as character type? *Totally missing a sprintf-like formatter so you have to use something, anything, oh god please save me from iostreams just to produce a dynamic string? Check.* Why would a string class provide formatting capabilities? *Can't append to a string without allocating a whole new one? Check.* Nonsense. Any sane implementation has exponential buffer growth so if there is space available for the string being appended, then there are no allocations. *Using the "+" append operator produces more temporary objects than you can count? Check.* I can: at most two. *Using the "+" operator with two string constants gives a weird compiler error about adding pointers? Check.* What does this have to do with std::string? 
I wanted to stop reading when he's comparing C++ with Python - It's like comparing a wrench to a spoon and say you can eat soup faster and easier with a spoon. But when I read the following, I couldn't help it but stop it and posting a comment here: "python's strings: refcounted, passed by reference, nullable, compatible with string constants, no templates, trivially easy debugging, always the same character type (although they changed it in python 3, sigh)" What the heck? -std::string is null-able -compatible with literals -why are templates bad? -as easy to debug as anything else - depending on the debugger and std::string implementation -you can use the character type you want C++ is just a tool as is Python - I've been using C++ for years and love it, I love python too, but you can't compare an apple to a bicycle.
You need to use the "typename" keyword before C&lt;T&gt;::MyInt. When the compiler compiles SomeFunction, it doesn't know what C&lt;T&gt;::MyInt is. The meaning of "C&lt;T&gt;::MyInt" could change depending on the template parameter you supply. Take for example the following: template &lt;class T&gt; class C { public: typedef int MyInt; MyInt SomeFunction (T); }; // template specialization of C which defines MyInt as a function template&lt;&gt; class C&lt;int&gt; { public: void MyInt() {} }; // If T=float, C&lt;T&gt;::MyInt is a typedef. If T=int, C&lt;T&gt;::MyInt is a function! template &lt;class T&gt; C&lt;T&gt;::MyInt C&lt;T&gt;::SomeFunction (T t) { return 0; } int main() { C&lt;int&gt; c; c.SomeFunction(0); } Because it is ambiguous what C&lt;T&gt;::MyInt actually _is_, you need to qualify it with "typename" to tell the compiler that C&lt;T&gt;::MyInt is a type regardless of what is specified for the template parameter T.
 template &lt;class T&gt; typename C&lt;T&gt;::MyInt C&lt;T&gt;::SomeFunction (T t) { // do stuff } 
For string formatting use boost/format.hpp and for popular string operations use boost/algorithm/string.hpp. Yes it would be better for this stuff to be built in (it's due to historical arguments over purity when it came to implementing the STL), but there we are. In all my years of writing C++, I've never felt the need to write my own string class. I don't see what is wrong with C++ exceptions once you understand them properly. I admit I avoided exceptions for years, but I use them all the time now. I recommend the "Exceptional C++" books by Herb Sutter. It seems pointless to fight the language with things like your map example. Just use find() and insert() and be done with it. Possibly function objects might serve you better than function pointers, or you could use a std::pair and store the this pointer along with member function pointer (then use x.first-&gt;*x.second()). I would agree that C++ does seem to use very complex solutions to solve simple problems at times and the standards committee appears to be collapsing under its own weight, but you'll be a lot happier if you stop fighting the language and use it the best way you can (sometimes this may mean somewhat verbose syntax). One day there will be a replacement for C++ and just maybe that replacement will be D. But until then, just make the most of what you have.
Thanks, template specialization is crazy.
You must admit that there are a lot of changes from D1 to D2, though :) I assume the author refers to those.
I don't want to be saved.
&gt;&gt; Horrendous mess of templates that makes tracing in a debugger utterly painful? Check. &gt; Can't remember last time I had such an experience. To be fair, this is a problem if you're using gdb.
Use valgrind? :)
No
About the second, I find int *p; the best, especially when you have more than one on a single line. int* p1, p2; looks like you declare two pointers if you don't pay attention, although p2 is an int, not a pointer to an int, whereas int *p1, p2; is clearer.
Learning CPP here... I'm curious out something related to this. If you delete an object, and there is a reference, does the compiler keep the object around for the reference, or can that memory be re-used making the reference invalid?
Changes, sure. But crazy?
If I remember correctly, D required GC for a few core language features, like dynamic arrays and closures. Is this not valid anymore? Also, it was impossible to link a D program without linking the standard library. Not only the GC, but also the core exception classes, the root Object class and others. This is another criticism that I made in the early days of D (around 2003-2004) in the newsgroup, that was simply ignored, and now the author makes exactly the same point (#5 in his list). (disclaimer: You may remember that I [already criticized](http://www.reddit.com/r/programming/comments/9zqj0/the_state_of_d_programming_is_this_situation/c0f6jwu) the language before)
This is not accurate. GC is required if you are appending or concatenating dynamic arrays. It is not required if you use, dereference, or slice them. In particular, you can use dynamic arrays with malloc() if you choose. Closures work without GC unless the compiler thinks a reference is escaping. Alternatively, you can just supply your own version of the routine that allocates space for the closure variables, and the gc won't be linked in. I sometimes use D without linking to the standard library. It's fairly straightforward, though of course you won't be able to use library types like Objects and exceptions.
References are just syntactic sugar on top of pointers, with some capabilities removed. If the object you're looking at stands a chance of being deleted elsewhere, don't use a reference. Only use references when you can guarantee that the lifetime of the object outlasts the lifetime of the reference. If you want shared access to an object so that it isn't deleted until all references to it are destroyed, use std::tr1::shared\_ptr&lt;T&gt; or boost::shared\_ptr&lt;T&gt;. If you'd like a handle to that object that allows it to be deleted elsewhere, and has a mechanism to tell you, use std::tr1::weak\_ptr&lt;T&gt; or boost::weak\_ptr&lt;T&gt;.
I would imagine D would also be instantly disqualified for the lack of a 64 bit compiler. It isn't 2002 anymore, and hobbyist programmers, the people who ultimately decide if a new language lives or dies, are probably going to pick a language that works natively with their OS. edit: You're working on a 64 bit port for D2 right? For all OS versions?
If you have a reference to a deleted object, any operation done on that reference results in undefined behaviour. Most of the time your program will crash.
About the const issue: http://codecraft.pool-room.com/Cpp/const-correctness-3.html 
&gt; Why would a string class provide formatting capabilities? HAHHAHAHAHAHA!!!! Sorry, but a string class without formatting capabilities is beyond useless. 
That's what I figured, was just curious, thanks! 
I admittedly haven't used D much, but I think the immutable strings by default and value arrays changes might be what he calls crazy.
&gt;&gt; Using the "+" append operator produces more temporary objects than you can count? Check. &gt; I can: at most two. Heh; rvalue references to the rescue!
One day there will be a replacement for C++ and it will be the C++0x. Not sure what you mean by the standards committee collapsing under its own weight. I think C++ just keeps getting better. Have a upvote anyway. Cant wait for all the new features in C++0x. Just to name one that will take care of one thing this guy is ranting about: std::function encapsulates everything that can be called with the "()" syntax, under a common interface.. so function pointers, member functions, functors, lamdas, etc. Couple that with the new auto type inference, and you wont even have to know the specific type of the std::function you are using. Oh, and the lambdas will make the somewhat cumbersome task of writing functors a thing of the past. As for std::string. I find it ugly, but not for the reason this guy mentioned. Its bad not because it does too little but because it does too much. Its interface is bloated. It has something like a hundred member methods. It was standardised before the STL. I sometimes prefer using vector&lt;char&gt; and the STL algorithms instead, or stringstream. C++0x includes regex which will make charachter manipulation even easier. So good things to come. I agree that Herb Sutters (and Scot Meyers) books are good. They should be required reading for every C++ programmer. Its crazy how many C++ programmers have been working for a decade or more but still dont know how to code C++ properly. I guess you really have to read best practices books to learn this stuff. I dont think thats too much to ask though. 
Couldn't the map container be implemented with [const overloading](http://www.parashift.com/c++-faq-lite/const-correctness.html#faq-18.12), to only create an entry if you write to it, but return .end() if reading a non existing entry?
Crazy awesome.
Does he also fail to know std::string of every major C++ standard library nowadays is copy-on-write?
I suggest you read C++ best practices type books. Starting off with the 3 books in Scott Meyers *Effective C++* series (one of which is about STL).. if you ever Finish those you can continue with the 4 books in the Herb Sutters *Exceptional C++* series. If you take the time to read all those you will probably be a better programmer than 90% of the C++ programmers out there. If you want a beginners book, Stroustrup new *Programming: Principles and Practice Using C++* is supposed to be much better than the rest (it teaches the important STL stuff first and leaves the unimportant C stuff for last, unlike most books). Maybe if you only have time for one book. This might be the one. I wouldnt worry about spending time learning to use boost, before I understood how to use STL well. STL covers most. Boost is just like an addon for STL. I rarely need to use boost libs (the boost regex lib is handy though).
If you want to bake your brain (it's like C++ on drugs ;) ) read Modern C++ Design. You'll either say "cool!" or "wtf is this shit?", but either way it'll shock you :) 
Yes, I agree, and am a good way along in implementing a 64 bit backend for dmd for all supported platforms (Linux will be first). Or, you can just use LDC which already supports 64 bits.
I should add that you can't use full C without some library support (startup, long divide, etc.) and neither C++ (exceptions, RTTI, etc.).
Immutability is a hard sell to programmers who aren't used to it, but it really is a big win once you are.
Good List! Thank you
This unknown Romainian guy writes a book that is just out of this world. *"You got your compiler to do what!?"* Somekind of sorcery. Its about template metaprogramming. Making programs that "run" at compile time. Its about tricking your compiler into sorting a list of numbers, or calculating prime numbers at compile time, etc. Its not that useful in the real world, but its still super cool. 
The key to C++ is thinking multidimensional. C++ is a set of paradigms that cooperate. This is something that is very uncommon in other languages that are mostly layered. Another key is to known when not to use certain paradigm. This comes with experience. The list of books is definitely good. I don't agree with "C style code" as bad code. "C style code" is the best solution for many problems. Using paradigms that don't fit the problem is bad code. C++ is about experience and I would also say age.
It is a matter of having one concept doing one thing (hopefully well). String class manages arrays of characters. Streams/formatter provide formatting functionality. Let's say we put formatting into a string class. Tomorrow I want to write formatted output to a file instead of a string. Do I have to first format it to a string (extra memory allocation, slow) or should we also add formatting support to the file object?
template meta-programming... think Fahrenheit 451... burn it with FIRE! In theory it sounds great, in practice be ready for long build times, barely readable error messages and painful debugging... but you may be into this sort of thing, who knows. Most of the other books (especially Meyers) are great.
If you're outputting text to a file, regardless of the format, it's still text. The formatted text needs to be obtained before being sent to the file. 
You may also want to take a look at [F-35 Joint Strike Fighter Coding Standards](http://www2.research.att.com/~bs/JSF-AV-rules.pdf). 
To be honest, I dont think I finished reading *"C++ Template Metaprogramming"*. *"Modern C++ Design"* though blew my mind... "You got your compiler to do what!?" Somekind of sorcery. They are about making programs that "run" at compile time. Its about tricking your compiler into sorting a list of numbers, or calculating prime numbers at compile time, etc. Its not that useful in the real world, and they are abit hackish, but its still very interesting to read about.
[Curious reply](http://www.reddit.com/r/cpp/comments/csj5a/looking_for_modern_c_general_purpose/c0ux9ig)
I first saw it in "Game Programming Gems 1" and when I worked on code (about 10 years ago) where some developers were using it, I realized that most of the time it blew away the pre-compiled headers since the source has to be generated as the template is expanded and instantiated, which resulted in build times long enough to get a LAN game of some RTS or FPS while we waited, we even synchronized builds so that many of us started at the same time and could play... sad in retrospect. After months of this pain, I finally removed all the meta-templates and wrote a small pre-step using python and a data file which generated the headers and few source files which only needed to run when some data was changed and not every build and oddly the build times went down to 3-4 minutes for a full build and severely reduced game playing sessions for which many were not so happy with me.
* [Game Programming Gems](http://www.amazon.com/Game-Programming-Gems/dp/1584500492/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1279834474&amp;sr=1-1) there are a bunch of hardcover books in this series * [Algorithms in C++](http://www.amazon.com/Algorithms-Parts-1-4-Fundamentals-Structure/dp/0201350882/ref=pd_sim_b_3) * [Expert Programming in C](http://www.amazon.com/Expert-Programming-Peter-van-Linden/dp/0131774298/ref=pd_sim_b_2) it is C, but a great book 
It's not about reading, it's about years and years of practice. To be an expert in anything from C++ to Painting, you need to spend at least 10,000 hours. Maybe a little reading, like Code Complete and that's about it, wait that's not in your reading list, lame.
I found Herb Sutter's books quite useful when I was learning the STL: Exceptional C++ Addison-Wesley, 2000, ISBN 0-201-61562-2. More Exceptional C++ Addison-Wesley, 2002, ISBN 0-201-70434-X. The books are based on his gotw articles which originated on comp.lang.c++.moderated and are available here: http://www.gotw.ca/gotw/ 
Thanks, I skimmed through it. It seems quite good in that it not only has rules but also abit of rationale for the rules. However, knowing what not to do is not quite as useful as knowing what one should do. It would be nice if accompanied to every *"dont do this"*-type coding standard document there would be some *"best practices"* document with code examples. Something like; always try and use RAII, do as the ints, value semantics, STL, exception safe design, patterns from the GOF book, prefer composition to inheritance.. and then have some code examples.
Code Complete is really introductory, simple stuff. It's a good quick read but really doesn't belong in a reading list for obtaining expert proficiency in coding (any language). It definitely isn't a good C++ specific book. You're right that true proficiency requires real experience, but it should go hand in hand with lots of reading.
Thanks, I'd like to read an algorithms book when I get the time. Its a gap in my, brain. For the past year I have only been reading math books as thats another gap I'm trying to fill. The gems books.. does that mean you work in games programming? I would be very curious to learn what programmers and the code quality is like there. I thought about making the switch, but I dont know. On one hand I have heard that the games programmers are passionate about what they do, and very good at maths. On the other hand I have heard that there are alot of young programmers that dont really care about code quality, with lots of hackish messy code. And that its mostly C and not a whole lot of STL, etc. What do you think?
Yes, I copy pasted my own message (and edited it abit). Maybe thats bad practice, but then again programmers are lazy creatures. :)
Well, I have met plenty of C++ programmers with over a decade of practice who have never read a C++ best practices book. So they never learned how to code better (RAII, exception safety, do-as-the-ints, patterns and the rest of it), but are stuck in their old hackish C-with-classes ways. It was the same for me. The only time I felt I progressed above whatever was the low quality status quo of the code base in question, was when reading books and applying what I learnt. Alot of this is stuff you wont stumble into. A lifetime is too short to learn it just by trial and error. 
These are what I use: - stl in general - boost: smart_ptr, bind, function, asio, datetime, filesystem, foreach, signals2, system, thread, exception, variant, any, fusion, mpl, interprocess, pool, serialization, enable if - tinyXPath - otl 
I'm not saying I don't read. I just haven't read a programming book since I left college, and everyone who knows me considers me to be a top-caliber developer. It's because I challenge myself and put myself into situations in which I'll learn, and not because I'm reading a new 500page book with only 5 pages of original material. Reading a programming book isn't a programming challenge, it's a bore. I'd much rather read good code and then implement better code myself. E.g. I've become quite proficient in opengl es1.1 and 2.0 using code examples only. Currently am writing several applications for android, one which is pulling a 4.5/5 star rating. How many android/opengl books do I have on my shelves? 0 [screenshot for my game 5 weeks into development, everything from scratch](http://www.adamhammer.ca/images/stories/mr_screen10.png)
;)
&gt;You got your compiler to do what!? Heh, I know what you mean. However, if I'm telling myself that, it's probably not a good thing.
I think you are right about learning libraries and such. You can do that well without books. The language itself though is a different beast. Like some other guy said here, C++ is such a huge (multiparadigm) language with lots of interacting features. Knowing whats the best or worst way of using them together is not trivial. There are lots of bad pitfalls, but also lots of good patterns. Its like building a house. One can build one with straws and duct tape, but it wont be as good as one built with materials and arcitecural techniques that have stood the test of time. There are similar patterns or idioms in computer languages, but especially in C++ because of its big scope. It might not matter so much for smaller programs made by one person. But when systems get old and huge, with tens of millions of lines of code and with tens if not hundreds of programmers working with it. It gets miserably messy quick if everyone is not very careful about the code quality of the system. As for programmers, many people liken them to painters or musicians. I dont see it that way; I think programmers are much more like mathematicians or structural engineers. Its about the plumbing really, not so much about the paint.
Some people just don't care about code - and I partly Blame Agile. At least, that's been the case for the last two places I've contracted, corps with Agile. Where the pressure is high to just pump out features. Though, at the most recent one, the two leads just truly lacked curiosity and didn't give a rats. I pointed out things, and not mild 'const-correctness'-level things, but that caused bugs and, they weren't interested, beyond fixing the specific bugs. Ahem, I ramble. But yeah, really, some people out there just aren't interested in the craft, and, it may be temperamental, but it may be partly Agile, too, with its ever-persistent focus on features. But, I just wanted to sympathize, I couldn't believe there were C++ people who don't know good practice and don't care. Some were probably Java transplants but, some not. And very smart, one of these people. 
You have it right, I worked in the game industry for a bit but the code quality was not up to par and many designs were flawed from the start just to get something working (this is not true for all game shops, just the few I dealt with, some of my friends in the game industry have had better luck). I also did not care for the constant crunch to release the game, where working 12 hours a day, 6 days a week was on the low side. I have met many fantastic developers who were passionate about their code and the vision of the game and that was often enough to make you forget all the shortcomings and put your best effort to succeed. I worked mostly in C++ against DirectX and windows API and lua for in-game scripting and python for out of game scripting (builds, environment, tools, etc). There is a fair amount of C but I have not found a case where C would be appreciably faster. There is STL in gaming, mostly on the tool side; many people write their own core classes (strings, lists, maps, tables, etc) so they can optimize them for how they are used. For example if you do a lot of appends then you want a string class optimized for appends that allocated in blocks and doesn't immediately release/resize to reduce calls to new/delete (which were almost always overwritten to optimize allocations by pooling memory objects for common classes)... oh the list goes on :)
Sadly, if you want to write excellent code you need to write in such a way that a idiot will understand it. Hence the best way to any solution is the simplest way, using lots of in-depth language features can be a academic pursuit, but when someone takes over it they just want simplicity.
Maybe you are on to something there. Im not quite sure how Agile is different from Cowboy coding. To me they seem an awful alot alike. Maybe someone can tell me the difference. To me its development by shooting from the hip. Close enough is good enough. The opposite of planning ahead. You dont have a fixed specification, which means feature creep at best, and the overall design becomes whatever. A bunch of quick-fixes, as opposed to *"doing it right"* from the beginning. When the system grows larger it becomes very difficult to correct ill-thought out designs. I find it better never to give my project manager the option of choosing between a quick fix or doing it properly. Its better in the long run not to tell them about the quick fix options at all. Some designs just wont scale as well as others. Its like building a sky scraper, you wouldnt start by building a tree house and then continue adding sticks to it. You would figure out the overall design first and make sure you have a good foundation to build upon. It may work Okay for small project.. but it seems bad for big systems or large teams.
When NOT to use a paradigm. Haha, even features. C++ is the only language where you have to write negative code. That is, code that says, "don't do this". Other languages have "private" but they don't do things like have you declare a copy constructor private as a way to remove it. That's annoying. Explicit constructors is another example. Hey language, don't cast here. It's more code to do less. It's funny, over half of the C++ best practices amount to turning things off. It's like the defaults are designed to kill you. 
I wrote a small dungeon crawler and used a large class to represent the main character. Whoops. Some things have to be learned painfully. :D
Oh, no arguments whatsoever about immutability - in fact, I've been trying to find a good way of making strings immutable for my C++ code after seeing this. As another data point, the PLT team also faced a fair amount of whining when they made cons immutable, which seems to me to be far more fundamental change for the kind of coding style scheme normally seems to encourage. What about the value array change, though, didn't that irritate more users? (I'm sorry, but D is one of the least google-friendly names for a language, and I cannot find this myself.)
I have become a huge fan of Qt, even when I'm doing non-GUI code. The standard containers are way more convenient to use than the STL ones. And the QString class kicks std::strings's ass!
&gt;It's like the defaults are designed to kill you. That's the beauty of it, it gives you more than enough rope to hang yourself and everybody around you if you so choose.
[Michael Abrash](http://en.wikipedia.org/wiki/Michael_Abrash) has written a few good ones, most of his early stuff is more 8086 assembly based but it does help develop the programmer mindset. IIRC his books pertaining to graphics programming from his days working on Doom and Quake are more C/C++ orientated.
I am actually outputting various types (strings, integers, floats, etc.) to a file in their "text" representation. Which in most cases means they are actually written to a file buffer before being stored on disk. Why do I have to first write to a string, then copy the string over to a file buffer? Don't you think formatting them directly into the file buffer is a better idea?
If you want to know "why" and not just "what" and "how" of C++, then I suggest you read Stroustrup's "The Design and Evolution of C++". I bet not a single person from that loud-mouth "C++ sucks/Let's fix C++" crowd read this book. Other good books are "C++ Templates" (thorough treatment of C++ templates) and "Inside the C++ Object Model" (good for understanding what's going on under the hood).
I read those in the voice of Gunnery Sergeant Hartman from Full Metal Jacket. 
He's written an awesome and useful book called "The D Programming Language" and he tried to keep it true to the K&amp;R C spirit. D is pretty neat and with this book I think it stands a chance of catching on once LLVM's D compiler matures.
The value array change was met with approval by the community. To google for D, use the phrase "D programming language". That works very well.
You can, it just takes a lot more time to learn.
Thank you for making my point.
gluing shit together isn't really what the OP after. You are also unnecessarily overselling yourself quite a bit as well. &gt; and everyone who knows me considers me to be a top-caliber developer Of course you can still write software with poor programming skills. To the untrained eyes around you, they probably think you are the best. But if you lack engineering, design and knowledge about the language quirks that can only comes from books your code is most likely an unmaintainable mess that is only understandable by yourself.
After you wrap your head around Alexandrescu's book, take the next step up to C++ Template Metaprogramming: Concepts, Tools, and Techniques from Boost and Beyond by David Abrahams and Aleksey Gurtovoy. Note that David is one of the main boost authors. 
Disagree; he isn't even familiar with the STL. Let the guy learn to walk before he tries to .. do Olympic floor exercises. 
Thank you for all the suggestions, they are all of great help !! I am looking forward to some good reading.
"Anyone can screw up any implementation of any given methodology at any time." - jv
No no, it's not 'screw it up', it's that management likes and understands features, but doesn't like refactoring. Which is to say it's not an 'oops, we screwed that up' thing. I might like 'true', 'pure', wonderful Agile. It's just that, you see it sold one way, and implemented another. 
Bloomberg? Their appetite is endless. 
I frankly prefer immutable strings. These lame std::string libraries that use COW are pretty horriffic when it comes to extreme multi threaded code.
That appears to be, at least to me, an example of a way to screw up an implementation of a methodology. just sayin.
I'm talking about phd's and such who have told me that, not untrained eyes. I just get pissed at the amount of "academics" who have never actually accomplished anything useful in code except solving puzzles. Edit: Example would be the whole NP thing, it could very well be unsolvable given current paradigms, but it doesn't stop millions of man hours being wasted on it, when there are other obvious paths to improvement. If there is a solution to NP Complete one of the 6 billion+ people on this world will naturally find it when we progress enough. C++ isn't THAT hard, sure it's a pain in the ass, but just be thankful your not programming assembly.
Well I have to admit RAII type stuff is extremely powerful, especially when coupled with operators like (). I haven't read any of the stuff above, but I fully understand the need for modularity, orthogonal interfaces and unit testing. Spending time thinking about design and no fear of refactoring is always a big positive.
I hadn't seen anything about this til I saw it [here](http://msdn.microsoft.com/en-us/magazine/cc500572.aspx). It's too bad it didn't make it in. Anyone know what happened to it? edit: Doh, he says it was done too late to make it in, in the linked article. What a shame!
And it's C style. But, the comeback to that is, that good C++ style is to have one var definition per line. 
Thank you for your reply. I agree about C++ being unusual in that it is very multiparadigm and there are lots of different viable coding styles. With the risk of starting another C vs C++ flame war. I do consider *"C style code"* bad mostly because of C++ superior type safety and error handling. The most important areas where I think one can make a good case that *"C++ is a safer C"* are: - Using C++ pointer polymorfism (or just function overloading) instead of C's unsafe void pointers, casting, and type switches. The C way leaves room for misstakes. - Doing something similar to RAII in C is almost practically impossible, as C does not have the language support of destructors and exceptions. Error handling is cumbersome in C, in that return value error flags are ignored by default and manual cleanup/deallocation code has to be sprinkled at every exit path. Leaving room for misstakes. - In C++ you can extend the typesystem with your own types, and have the compiler take over the job of managing the lifetime of such objects (they are simply created when you declare the object, and die when the object go out of scope, just like the built in types). Copying objects is as easy as creating them, and the compiler takes care of the lifetime issues. In C "object" memory management is manual and therefore leaves plenty of room for misstakes. Why do something the compiler can do perfectly for you instead? 
I think that you don't have the same interpretation of "C style code" as I do. For me "C style code" does not equal "C code". We are talking about C++ here. That said, there is only one point that I can react to. "C style" usage of pointers (static and reinterpret cast) is valid for many different situations. Its mostly in very low level code, but its still valid. When you need fast code, but still can't go for static polymorphism (like function overloading, or templates) "C style" use of pointers is the way to go.
You know, you really pinpointed the problem w/ Modern C++ design that I just couldn't put my finger on. Its very impressive, and the techniques as shown are very powerful, but when it comes down to my code, aside from the use of policy classes here and there, I find it really hard to incorporate the concepts into my code in a natural way. I felt a similar way about Design Patterns. At least for the code I do, Abstract factories and singletons are useful, everything else seemed overengineered or inapplicable to the problems I encounter every day. The above can be said pretty much for templates in general. They are too hard to debug, template metaprogramming is just way too complex and not understood by the general c++ programming population, not even the "star" developers, and really put your software at a greater risk of being unsupportable. 
Maybe [ask him directly](http://www.reddit.com/user/andralex/) for some pointers. I like his ideas but I think C++ is somewhat limiting to his techniques. I'd use them more frequently if compiler error messages these kinds of metaprogramming designs weren't hell to figure out. Concepts could have really helped with this but they didn't make it. I think he's moved on to D which is a much better fit for his ideas (especially since he helped Walter Bright design the additions to D 2.0).
Thanks for replying. I guess I should say that I’m not trying to apply ModernC++ (for want of a better name) to every situation. In the early days of C++ everyone went objects &amp; inheritance crazy because it was cool new paradigm. Jumping headlong into ModernC++ would be equally ill advised. However the rare situations I do think it might be useful, I’m finding it hard to apply ModernC++ because I’m not familiar enough with the techniques. In a few cases I have persevered, but I find the code just too hard to manage. I’m imposing this stuff on other member of the team and in some cases they are not that impressed. To be honest I can see their point. It takes me a long time to interpret a gargantuan, incomprehensible compile error or track down obscure run time errors. Some times I give up and rip it all out. Doing this takes up time and I’m not improving my understanding by taking code out. It’s a bit of a chicken and egg situation. I cannot convince my colleagues to let use some of this code without being familiar with the techniques. But I cannot get familiar with the techniques until I’m using them in the real world (just reading the book will not cut it for me I have to be hands on). So I guess I’m really asking how to I break this cycle. Are there piratical problems I can try to learn this stuff by example? I’ve not been able to find any. A booked called “Modern C++ By Example” would be nice (kinda wet dream for me). But I’ve not found it yet. If I understood the topic I’d write one. But I don’t. Yet. 
You have a point. I have a suspicion that these metaprogramming mind games should not be implemented via compiler tricks as real world compilers subject to real world deadlines cannot handle them. Rather they should be part of the language where they can be properly implemented. If that means a whole new language that it means I'll have to give up on this for the foreseeable futures as we're pretty much tied to specific C++ compilers for several reasons that I won't go into. A compiler upgrade is a nightmare so a language upgrade just isn't going to happen. Food for thought... 
Dunno, but, here's some more of his material to go through, less sophisticated than 'Modern C++ Design'. http://erdani.com/publications/main.html ('other publications' link on the left, from here: http://erdani.com/)
Well, In my previous job people were "afraid" of introducing new methods to the code. so After a while I just quit, went to a job were people wont be afraid. But this fear is not a bad thing, New methods usually bring new problems, different and sometimes much more complicated problems. Before trying to introduce a new method\paradigm\concept\library\pattern we need to ask ourselves.. do we need it?
My 2 cents about the template metaprogramming books. I think reading them is mostly just for fun (and bragging rights). Actually using these techniques, thats probably only recomendable for computer scientists developing *"datastructures and algorithms"* type libraries. Good code (in most cases) is easy to read and maintain code, and metaprograms just arnt. Alexandrescu's (and Sutters) book *"C++ Coding Standards"* though, is a good read and practically useful. If you feel like going abit meta (in a different way), GoF's, *"Design Patterns"* book is good and useful.
&gt; include &lt;strstream&gt; use `#include &lt;sstream&gt;`
Nothing particularly wrong with that list, but if you want to be more modern, do the following replacements: &lt;strstream&gt; --&gt; &lt;sstream&gt; &lt;time.h&gt; --&gt; &lt;ctime&gt; &lt;limits.h&gt; --&gt; &lt;climits&gt; or even &lt;limits&gt; But be aware that except for &lt;climits&gt;, switching header files will also require small code changes.
You, Sir, are a scholar and a gentleman!
Wait, I read that wrong never mind 
what's up with include&lt;iostream&gt; include &lt;vector&gt; include &lt;algorithm&gt; include &lt;iterator&gt; What compiler are you using?
I love Stephen, but STOP TALKING ABOUT HIS ACRONYM!!! Sorry I had to load it off my chest.
for STL and for reminding the C++ basic: http://www.linuxtopia.org/online_books/programming_books/c++_practical_programming/index.html For design patterns: http://www.vincehuston.org/dp For idioms and more DP: http://en.wikibooks.org/wiki/More_C%2B%2B_Idioms It's a wiki book in progress and it is for intermediate users but it's good to have it around (CHECK RAII!) The bible for all programmers: C++ FAQ LITE http://www.parashift.com/c++-faq-lite/index.html
You can probably get away without a lot of those headers, especially &lt;iterator&gt; and &lt;limits.h&gt;/&lt;climits&gt;/&lt;limits&gt;. These are usually included by one of the other headers you have there.
I have taken all the header files from my main file and my Class file. I am using g++ and have also just recently started using icc...
This code was adopted from someone else and I am trying to optimise it at the moment, and get out all the kinks, so any more information you could give me would be great :)
That's a very bad approach. Always include all header files that you are directly using. Never depend upon compiler/version specific behavior.
Perhaps that's as it should be. Recent experience in other languages suggests that immutable collections are better.
This is one of the reasons why C++ programmers should usually prefer to use the standard library algorithms. For loops are prone to bugs, off-by-one errors, and the iterator invalidation problem highlighted in the blog post. The correct way to do it in C++ is to use std::remove_if. It's generic, safe, and best of all it just works: vector&lt;int&gt; vec; /*...*/ vec.erase(std::remove_if(vec.begin(), vec.end(), pred), vec.end());
This will likely become more prevalent in C++0x, but as things stand, doing it right now is pretty obscure given no lightweight facility for writing local functions or closures.
It tends to be a generally good idea to use the data structure best suited to the problem as well :P
I know boost is not lightweight, but bind and smart_ptr are simply indispensable. It should be a standard part of a c++ developer's toolchain. 
I think this is a solution to a different problem. The example in the article should have used one of the deque or list STL containers. 
The difficult part is to find out a scenario where a certain technique can be applied. I try to pick up an area where (i) I have full control to start with, and (ii) the feature is not already in production. This keeps the expectation low and stakes low. That gives me more time stabilize the code before others start using and maintaining it. &gt; It’s a bit of a chicken and egg situation. I cannot convince my colleagues to let use some of this code without being familiar with the techniques. But I cannot get familiar with the techniques until I’m using them in the real world (just reading the book will not cut it for me I have to be hands on). I read and liked, Code Complete. I regularly apply many techniques learned there. One of the early things I wrote was a custom assert macro. Then I started writing template based data structures (mimicking STL). I eat my dog food first, i.e. use my data structure first, before releasing it to the world. That way I have been successful in building few containers, array, list, vector, bitset, dynamic_bitset, map, set etc. I am doing it for some time now. This way, I learned a lot about writing template codes. 
they are already part of [TR1](http://en.wikipedia.org/wiki/C%2B%2B_Technical_Report_1).
Better stay with the headers, for example in visual studio 10 you have to include the iterator header for back_inserter. http://blogs.msdn.com/b/vcblog/archive/2009/05/25/stl-breaking-changes-in-visual-studio-2010-beta-1.aspx
This is nothing unique to C++. It's generally true that modifying containers whilst iterating is potentially hazardous.
I know I'm very, very late in replying, but: Vim does do limited syntax checking as you describe. The only thing it doesn't do is static type tracking.
The biggest problem IMHO is that no matter how many "best practice" books you are going to read, when you get to work you can't use 90% of those best practices, and half of the time you can't explain why it is better because people don't care. My previous job wouldn't use STL, because it's slow. They never tested it, they just didn't care. I once tried to enter a RAII base criticalSection into the code, It ended disastrously. (I even wrote a comment that explains what is RAII). I hope you'll find a good place to work in.
What's wrong with c++, they ask? well, I don't even know where to start (the criticism takes into account the c++0x standard); in no particular order: 1) the grammar is not context free. This makes writing good C++ tools extremely difficult. I haven't seen a C++ IDE to offer refactoring capabilities like the ones for Java, and C++ intellisense usually sucks a lot, being extremely slow and inaccurate. 2) headers is a pain the a$$. You have to write things twice, and then you have to maintain things twice. And it makes compile times extremely large. 3) no support for first class functions. Seriously, functional programming helps reduce code bloat and increase correctness. C++0x will have lambdas, but no support for first class functions, i.e. you can't have functions overloaded on different function types. 4) no support for first class tuples. Initializer lists are a hack. The value {1, 2, 3, 4, 5} still has no first-class type in the language (it's a tuple in other languages). 5) primitives are not classes. C++ is value based, so I don't see why primitives are not classes. It's not like in other languages that classes have different allocation strategies from primitives, for example. This is an inconsistency that makes it difficult to make strong subtypes of primitives. 6) array indexing is by default not checked. This has caused numerous problems. Safety should come first, performance second. The default should be to check array indexes against bounds and only use unchecked access through special functions. 7) primitives do not have constructors that initialize them to meaningful values. When writing a class with lots of members, or when declaring lots of local variables, it's easy to forget to initialize some of them. The default should have been to initialize all variables to a default value, and only avoid initialization if requested explicitly by the programmer. 8) const correctness is nice, but it is deceitful: a function A that accepts const may call a method B that has a non-const reference to the variable passed to A. It would be better if the language had a 'pure' modifier to enforce constness all throughout the execution of function. This would also help optimizations. 9) initialization order across modules is undefined. This is a serious problem that prohibits hiding meaningful initializing code in modules. There are workarounds but they are not thread safe. 10) templates lack any sort of type system. C++0x concepts would have fixed that, but it didn't make it in the new standard. 11) the language is not as low level as they say. For example, it has complete lack of support for tools to help write a good garbage collector. You don't know which threads are running, and where the stack of each thread is, for example. It does not allow you to manipulate the current CPU context unless you resort to asm, prohibiting writing co-routines. 12) parameters with default values can only be present at the end of the parameter list. It could have been otherwise: default parameters could be at any position of the parameter list, and calling a function with default parameters could have been achieved by omitting arguments in the function call. 15) lack of ranges in the STL. 16) operators new and delete are type agnostic. This causes many problems when the operator new and delete code wants to do type-specific work (installing a deleter that invokes the destructor of the type, for example). 17) no support for compile time introspection. If c++ offered this, then it would be possible to use compile time introspection to visit members of classes and do interesting things on them, for example automate serialization or provide run time introspection. 18) no operators for sequencing. The shift operators are abused to work as sequencing operators. 19) operator precedence is wrong. The bitwise and bitshift operators should have greater precedence over the arithmetic operators. 20) no support for properties. We can either have the get/is/set pattern, or property hacks with templates that increase the memory usage. 21) no first-class support for delegates. Pointers to members are useful for constructing delegates, but the syntax &amp;foo.bar does not automatically construct a delegate. 22) forward references. Compilers should be smart enough to figure them out. It's a solved problem in other languages and has nothing to do with run time properties. 23) no name mangling rules. Each compiler vendor is free to make up their own, forbidding linking of modules from different compilers. 24) no common ABI across compilers. At least one part of the language should specify an ABI, allowing using modules from different compilers together. 25) the default primitive integer types should be of the same size in all platforms; the compiler should have another set of primitives that are platform specific. Not having the same size of primitives on all platforms could lead to subtle but difficult to trace bugs. 26) implicit conversions should be optional. This is another source of subtle bugs. 27) no binary operators with right-to-left associativity. This prohibits writing single linked lists as sequences of expressions as in functional languages without hacks/overhead. 28) streams are not serialized between threads. If two threads write to cout, the end result would be garbage. The STL library doesn't offer a way to output a message from two or more different threads without mixing the messages. It has to be done manually via a mutex or write the output to a temporary local stream first or use printf. 29) no named arguments. Named arguments help readability quite a lot, and when coupled with default parameters they can seriously decrease lines of code (since most objects can be created and an arbitrary number of properties set with one call). 30) no way to overload the message passing mechanism. It's either a straightforward call or an indirect call. Meanwhile, the programming world has invented many more types of message passing. That's just on top of my head. I am sure that there are many more. 
Usually people just save data to a delimited list. It doesn't really matter what the delimiter (could be returns even) is as long as none of the variables you're saving contain the character(s). Getting more sophisticated, you could encode the variables into an output file, but that means you would need to decode them when reading them back into your program. It really depends on the needs of your program and data.
So, say you just save the variables as a list, how would you go about reading them... how would you tell the program to assign the first number to "x", the second number to "y", etc. Sorry, I'm very new to C++.
The simple answer is read them back in the same order you wrote them in.
If you're only writing built-in types (i.e., numeric types), you can separate them with whitespace (newline or space), and read them back in using an ifstream. You would read in the same order you wrote them, i.e., int x, y; ifstream myfile; myfile.open("save.h"); myfile &gt;&gt; x; myfile &gt;&gt; y; myfile.close(); If you don't need the file to be human-readable and you're not concerned about portability, you can just read and write the raw bytes as they're stored in memory, using fread and fwrite (from stdio.h or cstdio). This has the advantage of working with structs, although it's non-trivial for strings. For example, the following is valid C and C++: typedef struct { int x; int y; } MySaveDataType; MySaveDataType savedata; savedata.x = 7; savedata.y = 10; FILE* myfile = fopen("savefile.dat", "w"); fwrite(&amp;savedata, sizeof(MySaveDataType), 1, myfile); fclose(myfile); And you would read it in elsewhere as: MySaveDataType savedata; FILE* myfile = fopen("savefile.dat", "r"); fread(&amp;savedata, sizeof(MySaveDataType), 1, myfile); fclose(myfile); 
As CapnDeviance said, something like: myfile &lt;&lt; x &lt;&lt; "\n" &lt;&lt; y; Then at the top of the program, to read in the values at start: myfile &gt;&gt; x &gt;&gt; y; This only works with values with no spaces, though; if you had x="hello world" and y="foo" you would read them in as x="hello" and y="world". To get around this, use getline instead of the '&gt;&gt;' operator to read the whole line, including spaces.
Awesome, thanks so much!
Check out boost seialization if you want to get really involved. But like a lot of boost, sometimes it can be like sandblasting a cracker. 
As an aside: let the ofstream object manage the file for you. int main( ) { ofstream myfile("save.h"); // do stuff with myfile } // myfile object is destructed and file is closed
&gt; If you don't need the file to be human-readable and you're not concerned about portability, you can just read and write the raw bytes as they're stored in memory, using fread and fwrite (from stdio.h or cstdio). This has the advantage of working with structs, although it's non-trivial for strings. For example, the following is valid C and C++: You can do that with `ifstream` as well. I would recommend not using `fread` or `fwrite` in your C++ code and instead do this to open a new stream for reading/writing: // input stream for reading binary data std::ifstream input; input.open("file.ext", std::ios::in | std::ios::binary); // output stream for writting binary data std::ofstream output; output.open("file.ext", std::ios::out | std::ios::out);
If you're only doing simple stuff like storing arrays of numbers, you can use something simple like this: template&lt;class ElementType&gt; ElementType parse_value(std::string str) { std::istringstream parser(str); ElementType value; parser &gt;&gt; value; assert(!parser.fail()); return value; } template&lt;class ElementType&gt; std::vector&lt;ElementType&gt; parse_string(std::string str,char delim) { std::istringstream ss(str); std::string token; std::vector&lt;ElementType&gt; result; while (std::getline(ss,token,delim)) { result.push_back(parse_value&lt;ElementType&gt;(token)); } return result; } template&lt;class ElementType&gt; std::vector&lt;std::vector&lt;ElementType&gt; &gt; parse_file(const char* filename,char delim) { std::ifstream fs(filename); std::string line; std::vector&lt;std::vector&lt;ElementType&gt; &gt; result; while (std::getline(fs,line)) { if (line[0] != '#') //skip comments result.push_back(parse_string&lt;ElementType&gt;(line,delim)); } return result; } Otherwise start looking for a decent serialization framework.
Aren't the extra byte of '\n' interfering with the reading? I thought it's supposed to work without a delimiter. For example let's say `int` is 4 bytes long and we store two values (1 and 2) with this method, we get the following byte sequence: 00 00 00 01 0D 00 00 00 02 And when we try to read them back, we get the first value right, but the next one will be the four bytes starting with the \n (0x0D) byte. Isn't that what's happening?
I see a lot of people suggesting {i,o}fstream or boost, but why not look at something like sqlite?
http://mschnlnine.vo.llnwd.net/d1/ch9/7/6/3/9/0/4/STLIteratorDebugging_ch9.mp4
please don't suggest boost. it's awesome, and I use it extensively, but for someone who is "quite new at c++", why would you want to suggest killing a moth with an RPG that also has a recoil capable of killing small children?
If you don't want to pull in boost, for whatever reason, Google's [Protocol Buffers](http://code.google.com/p/protobuf/) are reasonably simple and pretty efficient. That said, unless you have a crapload of data to save, I'd probably just stick to plain text.
the question is not so well-posed. using template parameters, you could probably write this function yourself. the question is better posed as **why** would you want to do this? if you need to compare two values, they should already be in the same datatype. if not, they probably arent representing comparable values. do you have two lengths, one of which is a float and the other is an integer? wrong, theyre both floating point, one of which just happens to have no fractional part. reconsider **why** you want to do this, not how.
It's designed to compare like-for-like types. It uses one template parameter to enforce this. As a side-note, the standard library can provide optimized versions, e.g.: template &lt;&gt; std::max&lt;std::vector&lt;int&gt; &gt;(const std::vector &amp;v1, const std::vector &amp;v2); via template specialization, and provide a general implementation which uses template &lt;typename T&gt; operator &lt;(const T &amp;t1, const T &amp;t2); which also allows you to provide optimized `std::max` implementations.
The first alternative that you propose is impossible. Don't forget that C++ is a statically typed language, which means that it must know the data type of the function definition at compile time and the data type of what it's being assigned to at compile time (still true, even with the new auto data type for the next version of the C++ standard). What you propose there would only work in a dynamically typed language. The second one could work, I guess, but as other posters have said I don't see the purpose. I can't think of a single example of where I'd want that. Instead, it makes much more sense to have the compared types and the return type be the same and have me explicitly cast the vale that I want converted to the type that I want if I encounter this situation, for example: int i = 27; float f = 30.23f; int max_value = std::max&lt;int&gt;(i, static_cast&lt;int&gt;(f)); Since I'm throwing away precision in the value of f I like to be explicit about it!
Ah, thanks. I guess I never considered the motivation behind a dual-type max. I've used max a bunch of times and never needed a dual-type yet.
&gt; Could somebody please explain why my suggestion for a two-type max would be unfavorable? Because it encourages ambiguity. If you have a max with two parameter types, the comparison will convert one of them and that will happen using the compiler's implicit conversion rules (if at all possible). Instead of doing that, the max function (that uses _one_ parameter type) forces you to solve any ambiguity explicitly (by specifying the parameter type yourself in case of ambiguity). In the current implementation, the code behaves more as expected (you have less surprises due to implicit conversions).
I honestly haven't been able to determine the upside of doing boost serialization in a world where Protocol Buffers et al exist.
As a side benefit, it also helps you avoid silly things like comparing a signed integer to an unsigned one, since they have different types.
max(apples,oranges)
D:
IOCCC material. Just throw a bunch of `#define`s around.
Why don't you post your attempt and the errors you get so we can help you? :)
errr... Show up some code ? It works like this : if (){} else if(){} else if(){} else (){}
Uhh.. about that.. I forgot to email the code I made since I made the code in our computer lab. :( But Im currently doing it now so I can show it. 
 std::vector &lt;int&gt; numbers; numbers.push_back (31); numbers.push_back (7); numbers.push_back (74); numbers.push_back (93); numbers.push_back (49); numbers.push_back (35); numbers.push_back (50); numbers.push_back (102); std::sort (numbers); size_t size = numbers.size (); std::cout &lt;&lt; "lowest = " &lt;&lt; numbers.at (0) &lt;&lt; ", " &lt;&lt; numbers.at (1) &lt;&lt; ", " &lt;&lt; numbers.at (2) &lt;&lt; std::endl; std::cout &lt;&lt; "highest = " &lt;&lt; numbers.at (size - 1) &lt;&lt; ", " &lt;&lt; numbers.at (size - 2) &lt;&lt; ", " &lt;&lt; numbers.at (size - 3) &lt;&lt; std::endl;
(a &gt; b) ? (a &gt; c ? a : c) : (b &gt; c ? b : c);
We are using the 6.0 version of C++ which is.. the year 2005 I guess. Our instructor won't teach us the latest format. She's crazy right?
First of all, you probably mean "Visual Studio C++ version 6.0", not C++ 6.0. C++ is a language, Visual Studio C++ is one implementation of that language. Secondly, what I just wrote is just standard C++, it will work in VC++ 6.0.
The compiler in visual studio 6 is horribly broken (for loops will leek variables etc). And I would NOT trust it with anything STL as that implementation is not very compatible. Also, I must say that this solution might solve the problem, but it does not teach anything about programming other than invoking library functions. Your teacher is probably looking for something that does not use std::sort and premade containers to make sure that you actually can program.
I meant MS Visual Studio ver 6.0 That code looks a lot different than the code our instructor taught us. It always look like this: #include &lt;iostream.h&gt; int main () { double k, mr; cout &lt;&lt;"Enter your meter reading:"; cin &gt;&gt; k; if (k&gt;=0 &amp;&amp; k&lt;=500) cout &lt;&lt;"Your electric bill is Php 10" &lt;&lt; endl; else if (k&gt;=501 &amp;&amp; k&lt;=1000) mr = 10 + (k - 500 * .5); cout &lt;&lt;"Your electric bill is " &lt;&lt; mr &lt;&lt; endl; if (k&gt;=1001) mr = 35 + (k - 100 * .03); cout &lt;&lt;"Your electric bill is " &lt;&lt; mr &lt;&lt; endl; return 0; } 
 if else is illegal, yes. You want to do if(something) { ... } else if(something_else) { ... }
There are almost always several different ways of writing a program that preforms a task. stingraycharles has just shown you one way, using the built in c++ libraray.
Okay, here's my problem in if else, what I understand about it is that: if (condition) *formula here if needed* cout or output text *if the input doesnt fall under the condition on the first if, it'll proceed here* else if (condition) else Sometimes, I get error saying, illegal else without matching if blah blah. So I try changing all of them to if with no else.. but that's wrong. So the only way that works is that having only ONE cout which is in the end of the code. Meaning, no cout on EVERY if. And the last one will always end in else with no condition. But I can't always do this technique since you can't solve other problems with this. Like the problem I mentioned above. 
What's with the bracket? I put the formula or process and output text there right?
if you have several lines after an if, you need to put it inside curly brackets. if() { line1; line2; } Otherwise only the first line will be inside the if, indentation is completely ignored.
Yes. You can put newlines in there too.
Really? By the way This is the code I tried: if (x&gt;y &amp;&amp; y&gt;z) hi = x lo = z else if (y&gt;x &amp;&amp; x&gt;z) hi = y lo = z else if (z&gt;x &amp;&amp; x&gt;y) hi = z lo = y It runs but when I input high numbers, the answer isn't correct. 
as joeldevahl said above, you can't have more than one line in your if statement in this format. To put more than one line like you're doing, you need curly braces {} #include &lt;iostream.h&gt; int main () { double k, mr; cout &lt;&lt;"Enter your meter reading:"; cin &gt;&gt; k; if (k&gt;=0 &amp;&amp; k&lt;=500) { cout &lt;&lt;"Your electric bill is Php 10" &lt;&lt; endl; } else if (k&gt;=501 &amp;&amp; k&lt;=1000) { mr = 10 + (k - 500 * .5); cout &lt;&lt;"Your electric bill is " &lt;&lt; mr &lt;&lt; endl; } if (k&gt;=1001) { mr = 35 + (k - 100 * .03); cout &lt;&lt;"Your electric bill is " &lt;&lt; mr &lt;&lt; endl; } return 0; } otherwise your code will be executed more like this: #include &lt;iostream.h&gt; int main () { double k, mr; cout &lt;&lt;"Enter your meter reading:"; cin &gt;&gt; k; if (k&gt;=0 &amp;&amp; k&lt;=500) cout &lt;&lt;"Your electric bill is Php 10" &lt;&lt; endl; else if (k&gt;=501 &amp;&amp; k&lt;=1000) mr = 10 + (k - 500 * .5); cout &lt;&lt;"Your electric bill is " &lt;&lt; mr &lt;&lt; endl; if (k&gt;=1001) mr = 35 + (k - 100 * .03); cout &lt;&lt;"Your electric bill is " &lt;&lt; mr &lt;&lt; endl; return 0; } since c++ ignores whitespace
I really don't know why you are downvoted. Here, have a sympathy upyacht.
Earlier than that. Waaay earlier. Like 1998 early. VC6 is an ancient relic. It was built before C++ was even a standardised language. It's completely non-conformant as a result. Any compiler from the past 10 years or so will be vastly superior. VS2010 is the latest release, and the Express Edition is free for everybody. If you're a university student, the professional edition (which usually costs $300) is specially available [free of charge](http://www.dreamspark.com/) too. Trying to learn C++ on VC6 is like trying to learn to walk with your hands and legs bound. You should probably start complaining to the administration. Loudly.
Yeah I know! I was like, what the hell, how are we gonna code programs in the future if we're using an old version of c++ codes without the knowledge of the latest codes! Our school sucks obviously. 
This is the way your code is being executed: if (x&gt;y &amp;&amp; y&gt;z) hi = x lo = z else if (y&gt;x &amp;&amp; x&gt;z) hi = y lo = z else if (z&gt;x &amp;&amp; x&gt;y) hi = z lo = y If you don't use brackets, only the first line following the IF statement is considered part of it's block. All subsequent lines are considered separate and executed without condition. WHITE SPACE IS NOT SIGNIFICANT IN C/C++ It seems like you'd like Python, which uses white space to define control blocks.
I'm not sure *why* this runs, some combination of missing semicolons and assignments coming together to the "elses" actually legal. If you have more than one line after an "if" (condition) then it has to be in curly braces; you should probably just put them all in curly braces (even if it were just one line), it'll make your life easier in the long run, but what you need is: if (x&gt;y &amp;&amp; y&gt;z) { hi = x; lo = z; } else if (y&gt;x &amp;&amp; x&gt;z) { hi = y; lo = z; } else if (z&gt;x &amp;&amp; x&gt;y) { hi = z; lo = y; } Okay, so great, now you've go the code you *thought* you wrote. Now, onto the logical error. There's 6 cases, not three. x &gt; y &gt; z y &gt; x &gt; z z &gt; x &gt; y x &gt; z &gt; y y &gt; z &gt; x z &gt; y &gt; x How many of these cases have you covered? (Hint: Not all of them.) 
So is that the reason why the answers aren't consistent? Like when I input 1, 2, 3. The answer is "Highest is 3;Lowest is 1" which is correct. But when I input random high numbers, the answer is wrong like, lowest number is -9.32139e? 
Oops, forgot to type the semicolon. So I have to have 3 cases? Wait.. you can't have a condition with two relational symbols right? Now the only problem is.. the cout. I don't know if I have to put only one cout in the end of the if's. But if I do every cout on every if's, it'll run but it'll output a the string 6 times. (like what always happens to me when I use cout on every if's)
probably not. It's more likely an uninitialized variable. Fix your control first, then worry about where the extra values are coming from.
&gt;So I have to have 3 cases? Three *more* cases. &gt;Wait.. you can't have a condition with two relational symbols right? This is definitely correct, you would have to change the "cases" (which just means possible situations that exist) into C++ syntax. &gt;But if I do every cout on every if's, it'll run but it'll output a the string 6 times. (like what always happens to me when I use cout on every if's) You have several confusions of ideas here I'd like to clear up. First, if you put it in every branch, it would work, but the question comes up, do you want to write it six times?! Remember, only the bodies of "if"s that have a true condition will execute. Hopefully, this structure of indentation will help you *see* what will run. If a cout runs regardless of the "trueness" of the if statement, then it's probably outside the curly braces {} or you forgot to add curly braces. if (x&gt;y &amp;&amp; y&gt;z) { hi = x; lo = z; } else { if (y&gt;x &amp;&amp; x&gt;z) { hi = y; lo = z; } else { if (z&gt;x &amp;&amp; x&gt;y) { hi = z; lo = y; } } } Anyway, it's still **not what you want to do**. You've now saved the highest number in a variable called **hi** You've also saved the lowest number in a variable called **lo** So after all the if's you just want to print out those variables using cout, with a little formatting.
I'm putting this in a separate post to try to keep it separate. It's clear to me that you've seen behavior with if statements and drawn some logical (but wrong) conclusions from that. Basically how they work is like this: if(false) x = 0; cout &lt;&lt; "Say Something"; The line right after the "if" is the only thing the "if" applies to so the cout statement is executed. This is rarely good. THE INDENTATION DOES NOT MATTER. Now, in C++ you can group a bunch of lines together in brackets to make them into "one statement" and then the "if" can apply to them all. Like this: if(false) { x = 0; cout &lt;&lt; "Say Something"; } Now, the program will **not** output "Say Something". It will evaluate the "if" and skip both lines. ALL control statements (that I can think of) work this way in C++: for, while, if, try, catch, finally...
I've read the answers and I think [your logic](http://www.reddit.com/r/cpp/comments/d0cae/if_else_on_cpp_hates_me/c0wlhuq) is not OK (which is why you failed the test). The problem of finding the max and min of three numbers is a classic CS problem and is usually formulated as "define the algorithm that puts X numbers in order, using the minimal number of comparisons). For three numbers, the problem is equivalent to asking for the min and max (the remaining number is the middle one). If that is the problem, the answer is the following: void minmax(int a, int b, int c) { int min, max; if(a &lt; b) // one comparison, a &lt; b, c unknown { if(b &lt; c) // two comparisons { min = a; max = c; // a &lt; b &lt; c } else // still two comparisons, a &lt; b, c &lt; b, compare a and c { max = b; if(a &lt; c) // three comparisons min = a; // a &lt; c &lt; b else // still three comparisons, c &lt; a &lt; b min = c; // c &lt; a &lt; b } } else // still one comparison, b &lt; a, c unknown { if(a &lt; c) // second comparison { min = b; max = c; // b &lt; a &lt; c } else // still two comparisons, b &lt; a, c &lt; a, compare b and c { max = a; if(b &lt; c) // third comparison min = b; // b &lt; c &lt; a else // still three comparisons min = c; // c &lt; b &lt; a } } cout &lt;&lt; "min: " &lt;&lt; min &lt;&lt; ", max: " &lt;&lt; max &lt;&lt; endl; } Conclusion: best case scenario: you perform two if tests, worst case scenario you perform three. This is the optimal algorithm.
To reiterate, never use *if(something)* without **{** and **}**. You can break that rule when you're an expert, but not as a beginner. Right now, **ALWAYS USE BRACKETS** because **SPACES and TABS DO NOT MATTER**. 
Yes, for example: int x = 2; if (x &gt; 2) { cout &lt;&lt; "x is bigger than 2!" &lt;&lt; endl; } else if (x &lt;= 2) { cout &lt;&lt; "x is less than or equal to 2!" &lt;&lt; endl; } Would output: &gt; x is less than or equal to 2! Use that general structure with brackets because you need them to help separate the work you want to do. 
 static int min(int a, int b) { return a &lt; b ? a : b; } static int min(int a, int b, int c) { return min(a, min(b, c)); } static int max(int a, int b) { return a &gt; b ? a : b; } static int max(int a, int b, int c) { return max(a, max(b, c)); }
That's kind of extreme. As long as they are taught that white space exists solely for formatting purposes, and understand what constitutes an expression, neither of which I think a beginner should have trouble with given a good explanation, then I don't see a problem. Granted, I wrote some code and a friend modified it with a similar bug because he'd never use if statements without brackets but I did.
Ah yes, function composition, exploiting function overloading. Tell me though, what does the static keyword do for this? I believe the last time I looked it up, it was that static makes the code be compiled to a single point in the executable, but I don't think copies of my function are being compiled all over the place. I thought that only happened with template instantiations.
Oh my god. iostream.h? Wow. #include &lt;iostream&gt; If that doesn't work, fuck that compiler.
This sentence hurt. Specifically the word "codes" caused me to wince.
What's the problem with iostream.h man?
Thanks man. I get it now. But what's with the void minmax(int a, int b, int c)? Is that the variable declarations? Also, you forgot to cout the "Enter three numbers:". 
It will not output "Say Something" ONLY IF the user input doesn't meet the condition of the if right? For example: cout &lt;&lt; Enter a number: //I enter 3 cin &gt;&gt; num if(num&gt;1) { blah = num + 1 cout &lt;&lt; BLAH BLAH; } If the user input doesnt meet the first condition, which is, the number should be greater than 1. Let's say, the user inputs 0. It's less than 1 so it'll not process the first if. So, you always have to put *else if(condition)* after the first condition right? Because, some problem I encountered that it says illegal else without matching if. But the else has an if! And when I remove the else, it runs but the result has two answers! It outputs the cout's that I put on every IF! 
Okay okay. Problem solved: JUST USE CURLY BRACKETS. All I have to do now is to know those other c++ formats with those std::cout blah blah. To impress my instructor.. :) Thanks guys. 
Right. I just meant in that context since the if condition was just "false" so it could never be satisfied.
Not that bad, actually. Each cout is one line. Puts minimum space between start of line and first possible location for hands, checks if the hands need to be drawn, minimum space again, checks, minimum space, checks, repeat *ad nauseam*.
The standard template library includes do not have extensions. They are just &lt;iostream&gt;, &lt;string&gt;, &lt;vector&gt; and so on.
No it's not. In fact, the only major implementation that does copy on write is libstd++.
Noob here. How did you do it?
Kind of scary. This is almost exactly my C++ library. I have a couple O'reilly books thrown in there, the Lakos book on large scale C++, maybe a couple others... and I don't have *Ruminations on C++* &amp; *Inside the C++ Object Model* (although they're both on my Amazon wishlist). *Imperfect C++* is very good &amp; not very well known. I wish more people read it. The only omission worth mentioning, IMHO, is Cline et. al.'s *C++ FAQs, 2nd edition* - I think that it's a fantastic tour-de-force that most C++ programmers should read at least once. Also, I think Lippman's *C++ Primer* (4th ed., natch) is a great all-around desktop reference.
I havent read a C++ book in a year (been reading maths). But im getting back to C++ now. Large scale C++ is on my wishlist. Clives C++ FAQ LITE, thats an interesting one. Its actually a book? Googling. Yes, I'll put that one on the list aswell. I probably need to read the GOFs patterns book again also. Stroustrup has a new book I havent read, and I'm waiting for Sutter's concurrent C++ book. Now with C++0x almost out the door, there will probably be an explotion of new interesting books out. Anyways, the Ruminations on C++ &amp; Inside the C++ Object Model where really good. They might sound abit dull, old and arcane but they where among the more interesting. In the same way that "The design and evolution of C++" was so interesting. Anyways, its good to know there are other C++ programmers out there that actually read these books. Do your colleagues read aswell?
April 2010, newish. And, pdf. 
What are you asking? I wrote the dungeon crawler in C++ over a year after taking a class at college. I would have had better results if I had learned a simplier language first like python. If you're asking about the main character, I made one class that had all the functions I should have used in the monsters. I should have written a simple entry class that contains a name, and location on a map. From there I should have tied it to a living class giving it the ability to hold stuff and have hit points. And then on and then on. 
Got it. Thanks!
I just opened the PDF and stumbled on page 2. A new operator: move constructor/assignment. Seriously? BS? you may be think pointer is bad and it is different with what you call "&amp;" and "&amp;&amp;", but it fast: playing with the address in memory. Yet another duplicate syntax in C++(0x).
I got a surprise with this syntax too: wouldn't expanded STL smart pointers achieve the same result without changing the language syntax?
I want my range based for loops in gcc now. There is a patch on the mailing list but it is not in trunk yet. I hope I'll see it in gcc 4.6.
The main reason for the new constructor is actually support for smart pointers, auto\_ptr is broken, it cannot be used in STL containers. C++0x has a new unique\_ptr that can be used in containers, but to implement it the new move constructor was needed. 
It formalizes the ability of initializing things on a stack from a temporary. Pretty damned confusing at first.. but it should have a *stronger* syntax change.
I want my range based for loops in VS10!
Boost has implemented smart pointers for years without this new syntax. So could you clarify what you mean when you save this move constructor is needed for smart pointers?
&gt; "The *(daft)* standard is written by and for experts ..." 
See http://stackoverflow.com/questions/2876641/so-can-unique-ptr-be-used-safely-in-stl-collections or http://www.devx.com/cplus/10MinuteSolution/39071/1954 The boost smart pointers generally don't have this problem, e.g. scoped\_ptr can't be copied at all, and shared\_ptr is intended to be used when having multiple valid pointers to the same object, so using a temporary copy in a move operation doesn't violate its constraints. 
The only compiler you need is gcc/g++. If you aren't using Linux, I'd start dual-booting, as personally, I prefer it for my development time in C++. As for sites, well, personally I have some books to recommend instead. [Accelerated C++](http://www.amazon.com/Effective-Specific-Addison-Wesley-Professional-Computing/dp/0201924889) taught me the beginning. [Effective C++](http://www.amazon.com/Effective-Specific-Addison-Wesley-Professional-Computing/dp/0201924889) taught me more in depth important details of OOP design with C++. But read Accelerated C++ before this. 
Wait a minute.. I think I have a different meaning for compiler.. What I meant was a software that'll compile c++ codes like MS Visual Studio. Since it's not a freeware, I can't find a download link. Also, I was asking about an online site. Not a book.
Multimethods in C++1x would be wonderful.
A slight correction of terms: Visual Studio is an IDE (Integrated Development Environment). That means it contains everything necessary to develop C++ applications. So it contains a text editor, a debugger, a compiler, etc. all built-in. GCC on the other hand is just a compiler. It takes in text files, and produces executables (roughly speaking). Visual Studio ships with a compiler built-in, called MSVC. Visual Studio is pretty much the best C++ IDE available. The [Express Edition](http://www.microsoft.com/express/windows/) is free for everybody. For beginners or hobbyist developers, it's more than adequate. The features that are missing aren't likely to be used by a beginner. But if you're a university/college student, you can also get the [full Professional edition](http://www.dreamspark.com/) free as well (as well as a whole heap of other software). A word of warning, however: VS has a pretty steep learning curve. It's intended for professionals - VS is to IDEs as Photoshop is to image editors.
If you already know C, then this is good... http://www.4p8.com/eric.brasseur/cppcen.html
www.cplusplus.com/ It has a comprehensive tutorial of all the features of the language 
I can't download from the dreamspark site since it needs some verification or a key of some sort. It's not free. Also, I think you're right. My classmates said that those express editions are so hard to use and very much different and hard for a beginner. And it's different from the c++ our instructor taught us. We use VS 6.0 which is so easy to use. But the c++ codes and formats are a little outdated.
[Thinking in C++, 2nd. ed](http://www.mindview.net/Books/TICPP/ThinkingInCPP2e.html) - It's free and it's awesome. You can get g++ for free. The Windows port of it is called MinGW. There's a IDE that comes with it, it's called DevC++.
Dreamspark is most certainly free, but you need to be a college/university student. I'm using Visual Studio 2010 Professional right now, which I got free from Dreamspark. You just log in with you Windows Live ID, verify your student status, and download whatever you want. I think your institution needs to be registered before you Dreakspark - I can't quite remember the exact procedure. Either way, you should read their FAQ on what steps are necessary.
What's the point in using MSVC6 for anything other than compiling legacy code?
They're still teaching students C++ using a 12 year old compiler, or are you like that Twilight Zone where the old shows from 30 years ago are still received by that creepy radio?
Also, the samples are very good quality. They demonstrate the intended usage of the standard library elegantly and well.
&gt; Did you notice the absence of a space between &gt; and &gt; above? That was intentional and arguably the smallest improvement in C++0x. Not having to remember that space certainly helps novices, but it also helps me. I write a lot of template code – some of it complicated – and frequently forget that space. Ha, I find that difficult to believe. This little annoyance is deeply ingrained in my memory, and certainly in Bjarne's, too.
You can also check out http://www.reddit.com/r/carlhprogramming/
&gt; Thinking in ... Fuck that. The design of those books are puke-tastically awful.
Thanks for the link. I haven't had a chance to watch Part 3 yet but I started by watching Part 1 and 2 and found them both quite interesting.
Thats not so surprising. It's what the compiler writers use as a spec. Edit: Oh, See what you did there. Daft, not draft. Punny.
There is even a couple of pun's and jokes in there. Quoting from memory: &gt; *"It does not matter who finds Higgs Boson first. The guys at CERN or Fermilabs. As there will be some C++ involved either way. [...] Thats very cool. Its cool because the accelerator runs at 1.9 Kelvin. Very cool."* Find the timecode and win an upvote!
Seems like it was quite the popular event: &gt; I tried to go to the Bjarne Stroustrup lecture. I opened the doors to the auditorium and there were people packed all the way to the door and &gt; I had to stand off to the side for 2 hours. It was great. http://ritfml.com/2009/12/05/i-tried-to-go-to-the-bjarne-stroustrup-l/
Visual Studio really isn't hard to use, the only hurdle for a beginner is knowing what sort of project you need to create. Also, you're really not going to need the professional edition features yet, so just use the express one.
*I* didn't do it... It's in the original text. Look it up.
If you want something like Visual Studio, but truly free, try QtCreator. There are also some other alternatives such as Code::Blocks, KDevelop, Eclipse CDT, Netbeans, ...
Ahh, Okay. That actually is funny. This is a bit like Inception. One level of miss-conception after another :)
http://www.cplusplus.com/ and using: http://sourceforge.net/projects/dev-cpp/ Ive found it to be a good combo. I develop now in newLISP on MAC OS/Linux now but its a good starting point. Also G++ is good for *nix.
I helped run the damn event, did a good bit of the still photography, and still didn't get a seat (ended up sitting on the floor in the back). http://www.flickr.com/photos/kuchta/sets/72157622954851250/ Yeah, here's a shot of people packing in one of the side doors: http://www.flickr.com/photos/kuchta/4166959450/in/set-72157622954851250/
Can't see the slides. :( Bjarne is interesting and all, but I don't really need to see him just standing there and talking - I'd prefer to see the slides to which he's constantly referring.
Uhh.. What? Yes. I don't know what's the deal with them teaching us a very old version of C++. But I hope it's almost the same with the latest version.. I hope.
Dude, my school is still teaching people VB6, for cryin' out loud, so yes, I can see schools still teaching C++ using an old compiler. As for the OP, try http://www.cplusplus.com http://www.learncpp.com/ http://www.cprogramming.com/ and http://www.cplusplus.com/doc/tutorial/ Also, like someone else said, dualboot at least with Linux, if you can. If you can't afford VS, then try code::blocks
I downloaded the Package Manager. But I can't understand how to use it. It says I need some package or something.. 
That is far from C++ and in his case will probably hurt his progress. Despite popular believe, C != C++.
For an IDE, get [QT Creator](http://qt.nokia.com/products/developer-tools/). It is free, open and arguably the best cross-platform IDE out there. It's easy to use and pick-up and that matters in your case, I suppose. You do not learn C++ online though. Go with Mabbo's book suggestions. They are awesome. Also, consider using Linux for C++ development, it is more fun. If you have no clue about Linux, get Ubuntu and just install qtcreator from your package manager. It will grab *all* dependencies automatically and just work. Good luck.
&gt; But I hope it's almost the same with the latest version No, it's not. And if your teacher says it is, then he/she doesn't know a thing about C++ beyond what's in the first couple chapters of your textbook. VC6 was horribly buggy and unstable (although to be fair, 2008 still crashes about as often as VC6 did back in the end--it's just much faster to restart). What's worse is that it came out prior to finalization of the 1998 C++ standard. In other words, it doesn't fully support the old standard let alone the revisions of 2003, TR1, or C++0x. Once you get a little more advanced and start needing more and more features of the language (or even if you just want to, you know, use some tiny, simple utility from Boost to save time in your work), you'll realize that half of it won't even compile in VC6. Or that the optimizer strips out Windows' own atomic functions in Release build. Or that you end up having to write a special version of mem\_fun for void returning functions because the one in Microsoft's STL doesn't support it and VC6 can't build Boost.Bind. Or that their auto\_ptr implementation is incorrect and will result in you having to write nonstandard code. Or that they implemented their std::list as a circular linked list where going past the end iterator brings you back to begin and vice versa--but have fun tracking down all the mysterious crashes when you upgrade the compiler or your STL headers later on and this is no longer the case. Come to think of it, so much shit is wrong in their STL implementation that you'll have to find a 3rd party STL once you've moved beyond doing something other than simple copies and transforms. Oh, and don't ever touch the MFC threading classes. Even Microsoft tells you not to use them in VC6. AHHHHH!!!! It was seriously one of the worst fucking IDEs I've ever had to put up with in my entire life. If you apply for a job and they say, "We use VC6," that would be a good enough sign to run as fast as you can in the opposite direction. I would punch your teacher in the face right now, if I were you. Just for ruining your life by exposing you to that piece of garbage. The only thing VC6 will teach you is how to appreciate bad software design and poor quality control.
Nice. Would have loved to be there. So [this](http://www.flickr.com/photos/kuchta/4166155363/in/set-72157622954851250) was the guy who filmed it (or is there another video of this event?). The video is still a bit shaky though, even with that pod. And he focuses on Bjarne most of the time instead of the slides he is talking about. Im still happy someone filmed it for the rest of the Internets. I originaly found it [here](http://www.reddit.com/r/programming/comments/d15ih/explaining_the_new_c_standard_c0x_and_its/c0wrxwh). It was 3 Gigs. It took forever to download, finding a convert program, compressing it down, finding a streaming site that accepts big files, and uploading it there. But it was worth it. By any chance, do you have the slides? That would be great.
Yeah, not so good camera work. I am hoping someone who was there might be able to provide the slides. I guess the other option is for someone to go through the video and screen cap whenever it flies past the slides, and make a powerpoint of it. I think most of the slides are in frame at one time or another. Im not doing that though. 
You post made me feel bad. I feel like I wouldn't land in a good job as a programmer. I mentioned to my classmate earlier that the version our instructor is teaching us is way old when I read a reply somewhere here. And I asked her why won't our instructor just teach the latest version.. Then my classmate said that maybe because she's a bit lazy to learn the latest version because of the fact that our instructor is a bit old and obviously, the version that was taught to them was like.. a 90's version.. or worse case scenario, older version. Fuck my school. Well maybe I'll just study on my own perhaps?
I know. That's why I didn't subscribe to that reddit. I was like wtf when I saw all the topics.
So I downloaded Dev C++ and it's surprisingly easy to use and kinda like MS VS 6.0 which is the software we use at school. Unfortunately, when I debug it, I can't see the errors. As opposed to seeing errors on VS 6.0 just at the bottom of the screen. Also, when I compile and run, I can see the black window but as soon as I enter anything then press ENTER to see the result, the window closes automatically. 
Since I already downloaded the [Dev C++ and having problems with it](http://www.reddit.com/r/cpp/comments/d1p5b/whats_a_good_site_to_learn_c/c0x01lr), would that QT Creator be much easier to use? Also, oh wow, takes an hour to download! 
http://sourceforge.net/projects/devcpp-portable/ try that. It comes with the whole deal. It also can be run anywere so its easy on you. 
also a good website to see information on premade solutions in C++ is: http://rosettacode.org/wiki/Main_Page Try to see the 99 bottles to start out with. they go over quite a few algorithms/problem solving. http://rosettacode.org/wiki/99_Bottles_of_Beer#C.2B.2B I produced the C++ recursive solution myself on that page. Hope that helps!
here is a sample program: #include&lt;iostream&gt; using namespace std; int main(){ cout &lt;&lt;"hello wold"; system("pause");//this will solve your problem. Its also possible with Cin. }
I'm not saying you can't learn how to program with VC6. You can learn how to program with VC1. You can learn how to program with cat, echo, and gas if you want. I'm just saying you should prepare yourself for a mountain of frustration and disappointment at the severe failings of such an old, buggy compiler and its old, buggy IDE. Perhaps it will even be a positive experience in that it will make you appreciate...every other programming environment you'll ever use.
I didn't know it is Version. I thought it is named Boost.
Hm, the new state machine library looks like it has some nice features I've either missed or half-assedly implemented with boost.statechart (flags &amp; completion events). On the minus side, holy hell those state diagrams saved as jpegs are fugly and hard to read.
What?! I have to include system("pause") on every program I will make!?
QT Creator is probably easier and neater than anything else, just go ahead and use it. Dev C++ is really outdated. The next best step from Dev C++ is Code::Blocks but in comparison to QT Creator even C::B seems outdated.
I haven't seen enough information about mixins in c++
Try also posting this at http://www.reddit.com/r/reviewmycode/
It's not my code, I just think it's a great discussion on the subject.
So the codes my instructor teaches us will run there? Still using iostream.h and cout cin.
While I'm glad there is someone else on the planet who is starting to look at these issues, there are significant errors on all three web pages.
huh? system() is a function that calls whatever OS its currently on. system("pause"); makes sure that you can see what is on the screen. You can also use cin &gt;&gt; foo; if you want (where foo is a variable of some type, i suggest keeping it simple with int). Its just a construct. I dont see where the confusion lies. Its one line either way. If one line is giving you problems.....perhaps you need to learn programming a bit more. I wish you luck!
It will work. The iostream.h library is in most C++ versions. You will most likely not encounter any problems with new code vs old code yet. Its only when you start getting into STL and some datastructures that this issue will pop up. So dont worry about it. Also if you want the most recent c++ its going to be g++ (most likely). 
Anyone have any experience using this? I'm curious as to its performance concerning real-time 3d graphics.
This doesn't look like it offers much more than you can get out of Boost and C++0x. The `List` class is interesting, but only because it's lazy. Am I missing something?
Looks nice for those who love Haskell but have to use C++ for their day job. And to make ther coworkers say "WTF?"
It would have been great if it would contain a bit more details, i.e. why are there at least 3 passes (or why does the author think it can't be done in less than 3 passes)? Also, I would have thought that you should be able to disable trigraph processing and \ line splicing when processing a raw string literals (and therefore not having to revert the processing for raw string literals) - but that's probably related to the number of passes needed.
C++0x should have baned trigraphs. No one needs them anymore! But everybody suffers because of them. Yes maybe you still need to develop for some ancient IBM machine with some ancient EBCDIC codec. But even then you probably crosscompile and I doubt that anybody will develop a C++0x compiler for such a system. tl;dr BAN TRIGRAPHS NOW!
It seems it would be very easy to have a compiler flag (environment variable) that says 'no trigraphs' and speed things up and save yourself some pain.
The problem with trigraphs, \ and raw string literals is you cannot just turn off trigraphs if you're doing a raw string literal, because you cannot tell if you are starting such a literal without first doing the trigraphs and \ splicing.
That's all jolly until you port your code to another C++ compiler, and the trigraph translation subtly changes the behavior of your program.
Sorry, but I still don't get it. Of course, you have to do trigraphs and \ splicing up to the point where you have found the start of a raw string literal. You then switch trigraph processing and \ splicing off until you have found the end of that raw string literal where you switch it back on. Or would there be a problem with finding the end of the raw string literal? e.g. what about R"(a??)" Is that a valid raw-string literal?
Consider code like: R\ "... asdf ..."
Still don't see a real problem here. Essentially, I read 'R', '\', '\n' then I delete the '\n' and '\' from my buffer (as I haven't yet found the start of a raw-string literal), and continue with the '"' which leaves me with 'R"' as the start of a raw-string literal. Only then (may even only after reading the d-char sequence) I switch off trigraph processing and \ splicing. BTW, looking at 2.5 (3) this appears to be the "intended" way of doing it. So I still think that you can avoid having to revert trigraph processing and \ splicing if you put in some effort to not do the trigraph processing for raw-string literals in the first place (although it might be a bit tricky as mentioned above).
You also have to know that R is the start of a token, and not inside something else.
I agree it is much more readable, but you'll be adding a tons of classes, calling cTors and dTors and all for passing a value to a function? 
Now there might be something I am missing but isn't use of an interface (purely abstract base class) superior in every way to pimpl, in particular in the way of code readability in the class implementation and the ability to mock the class in unit tests?
Not with his proposal just using typedefs, since there are no new types introduced. Note that typedef bool useOptionX; useOptionX(false)); is completely equivalent to bool useOptionX = false;
ah... I just sinned the the most deadly of sins. I haven't RTFM. still as much as I love to have parametrized arguments in C++, I don't think that this is going to catch, Maybe for Library authors that want to go the extra mile.
You're missing nothing as far as I can see. Why don't you make a private branch, replace the verbose code with the 'static const ...' line, see if it compiles, and run the unit tests?
&gt; You're missing nothing as far as I can see. Thanks! I was beginning to think I was losing my mind and there was some great master plan I wasn't seeing. Now I can go to my coworkers and say, "WTF is this crap?" without being a total n00b. &gt; [...] and run the unit tests? LAWL. If only the old code had these. I'm cracking the whip now, and all the code I'm writing has them. 
Yuck.
That is some ugly ugly code. Snippets like that make me realize why so many programmers prefer scripting languages like python or ruby.
FWIW, I'm guessing that whoever wrote that code was either: - experimenting with template metaprogramming, - having a bit of fun at the expense of his successors, or - unsubtly trying to look clever and increase job security. If you break it all down, there are several parts of the snippet that don't seem to have any merit it at all. Even without all the template mess, for example, what is the point of casting twice with that combination of types? I suspect the required functionality could best be expressed as `'.'` in this case, or with a semantically meaningful named constant (i.e., not `period`).
C++0x should have named parameters. I don't know why it doesn't have named parameters. Named parameters is great help and reduce code clutter greatly. Furthermore, it should be dead simple to add it in the language.
Have you heard the saying about "Always write your code assuming it will be maintained by a homicidal maniac"? You know, basically reminding people that their code will be maintained by others, and it should be readable &amp; clear? I suggest you track the original author down, and impersonate a homicidal maniac. I think he/she needs a reminder.
As I dig further I think this was an attempt at premature generalization... I just found some comments that lead me to believe the original author had greater things in mind when he came up with this, but the need for those things never materialized. &lt;sigh&gt;
Technically speaking[1], the simpler version gives undefined results by C/C++ standards. I think C++0x user-defined literals is meant to fix this kind of problem. It's possible the author attempted to be pedantically correct at the expense of verbosity, which is an arguable trade-off for most systems that are not airplane control systems, et al. The problem is '.' is of type char, which is *neither* signed char or unsigned char (though specific implementations may make it one or the other). The author is normalizing this situation by defining it as an unsigned char, and placing it in a signed int. He is saving the cost of a constructor for that code by having the compiler do this at compile time. The simpler version may result in either a signed or unsigned extension from 46, depending on the compiler; which should only be material if he's using extended ascii characters. If the extended char (let's say the 128th character) is signed, then the resulting constant is 0xFFFFFF80; if it's unsigned the constant is 0x00000080. It depends on what result is required. Without further context in what the author intended, it's hard to be overly critical. C++ is like that -- depending on whether you really know what you're doing, any given piece of code is technical brilliance or utter stupidity. It's good for your career to not assume the latter of your coworkers. :) [1] http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf Section 6.2.5 edit: Yes, static const int32_t period = (unsigned char)'.'; would appear to be a much simpler option, and a good C++ programmer would default to that before the original author's fanciness. On the other hand, I'm now curious what the original context was, and how such a thing was used. I've done similar fanciness, but I always try to have a reason.
The argument in "The Design and Evolution of C++" is that it doesn't need them, because you can do it all using classes. The question then becomes how do you write classes with the minimum amount of boilerplate while not introducing too much overhead. http://ciaranm.wordpress.com/2010/05/20/c-named-function-parameters/ is one approach that was discussed here at some point.
Thanks for this explanation, I appreciate it. I wasn't assuming any malice or stupidity on my coworker. The 'simpler' version that I mention could just as easily been written static const int32_t PERIOD = 0x2E; The point is taken on the type of the character constant. However, given that the use of '.' instead of 0x2E was merely one of (implementation specific) convenience, does the use of the template specialization make sense? 
boost already has this, it's called Boost.Parameter
or: static const int32_t period = (unsigned char)'.'; but anyway, are we to believe that "period" is going to be changed to another value in the future? I'm as against magic numbers as the next guy, but it's no use if you name your variables: static const int FOUR_HUNDRED_TWENTY_TWO = 422; as you couldn't actually change the value without making matters *much* worse.
Nope, these are _constants_: used in a state machine that is parsing text. If it would be clearer, we could just as well use the Unicode name for it: static const int32_t FULL_STOP = 0x2E; static const int32_t IDEOGRAPHIC_NUMBER_ZERO = 0x3007; // etc. 