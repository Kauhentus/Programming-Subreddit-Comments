Yeah that makes sense. We were trying to hope we could release every app with the same exact version but it probably makes more sense do what you guys did and have releases with slightly tweaked versions. 
&gt; This could be done with comments though. I feel like this misses a couple of very important points: * It allows the compiler to catch mismatches, misspellings, and other code changes. * It allows IDEs and other tooling to autocomplete or otherwise verify expectations. Commenting is a poor alternative.
&gt; Rationale: In C++, members are destroyed in reverse construction order and the elements of an initializer list are evaluated in lexical order, so field initializers must be specified in order. I find the argument weak. The object does not exist, and the destructor will not run, until the full object is constructed, therefore the order of destruction does not matter for initializer lists and a fortiori for aggregate initialization. There is no reason that the code for destroying the members in case an exception occurs during the initializer list/aggregate initialization cannot be specialized to run in reverse order *of the list*.
The problem with comments is who is meant to read them, the compiler doesn't read them, and other programmers don't read them either, so who are you writing them for?
You can use this macro do named initialization for up to 64 parameters in C++14(and it supports constexpr in C++17): template&lt;class F&gt; struct initialize { F f; template&lt;class X&gt; constexpr operator X() const { return f(X{}); } }; template&lt;class F&gt; constexpr initialize&lt;F&gt; make_initialize(F f) { return {f}; } #define INIT_IMPL(arg,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25,x26,x27,x28,x29,x30,x31,x32,x33,x34,x35,x36,x37,x38,x39,x40,x41,x42,x43,x44,x45,x46,x47,x48,x49,x50,x51,x52,x53,x54,x55,x56,x57,x58,x59,x60,x61,x62,x63,x64, ...) \ (void)(arg x1); \ (void)(arg x2); \ (void)(arg x3); \ (void)(arg x4); \ (void)(arg x5); \ (void)(arg x6); \ (void)(arg x7); \ (void)(arg x8); \ (void)(arg x9); \ (void)(arg x10); \ (void)(arg x11); \ (void)(arg x12); \ (void)(arg x13); \ (void)(arg x14); \ (void)(arg x15); \ (void)(arg x16); \ (void)(arg x17); \ (void)(arg x18); \ (void)(arg x19); \ (void)(arg x20); \ (void)(arg x21); \ (void)(arg x22); \ (void)(arg x23); \ (void)(arg x24); \ (void)(arg x25); \ (void)(arg x26); \ (void)(arg x27); \ (void)(arg x28); \ (void)(arg x29); \ (void)(arg x30); \ (void)(arg x31); \ (void)(arg x32); \ (void)(arg x33); \ (void)(arg x34); \ (void)(arg x35); \ (void)(arg x36); \ (void)(arg x37); \ (void)(arg x38); \ (void)(arg x39); \ (void)(arg x40); \ (void)(arg x41); \ (void)(arg x42); \ (void)(arg x43); \ (void)(arg x44); \ (void)(arg x45); \ (void)(arg x46); \ (void)(arg x47); \ (void)(arg x48); \ (void)(arg x49); \ (void)(arg x50); \ (void)(arg x51); \ (void)(arg x52); \ (void)(arg x53); \ (void)(arg x54); \ (void)(arg x55); \ (void)(arg x56); \ (void)(arg x57); \ (void)(arg x58); \ (void)(arg x59); \ (void)(arg x60); \ (void)(arg x61); \ (void)(arg x62); \ (void)(arg x63); \ (void)(arg x64); #define INIT(...) make_initialize(\ [&amp;](auto&amp;&amp; hidden_arg) { \ INIT_IMPL(hidden_arg,__VA_ARGS__,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,) return hidden_arg; \ }) Just write: struct A { int x, y; }; A a = INIT(.x = 1, .y = 2); Also, order doesn't matter for this like it does for C++20 named initializers.
It was definitely something that we wanted too, but it just wasn't feasible when Apple held up the release pipeline for weeks and we were aiming for a release every month.
I find it weak too. It's not that hard to detect explicit argument dependencies either and make them an error. I use a (local) severely hacked clang branch that allows any order without warnings but makes it an error if you refer to an uninitialized member directly from an initializer. It does the same for constructor initializer lists and also for combined declaration-initialization. Thus it prevents UB when you e.g. pass an address to or reference to a not-initialized yet member. The initialization is still done in the order of declaration, we didn't want to make this totally at odds with how C++ is expected of behave. We're nuts but we aren't stupid (most of the time) :) Although I am considering an extension that would allow to reorder member field declarations, i.e. declare members so that it makes most sense from understanding/maintainability POV, but then reorder them for purposes of binary layout and initialization. A coworker expanded the check to cover constexpr functions/methods, so indirect references via those are also hard errors. He said it wouldn't be that hard to expand it to non-constexpr functions, but of course there are indirections in those that are impossible to detect.
Hmmm. Apple review times have gotten better tbh. I'm tally not an apple fan (arguably the opposite) but I will give credit that review times are like 24 to 48 hours these days. 
Out of curiosity I opened your first link and the first thing I see is NT's SRW lock outperforms both boost mutex and shared locks by a noticeable margin in that particular benchmark. Not a good start to prove that naive serialization outperforms more sophisticated designs where multiple readers are allowed to proceed concurrently, and also shows that boost needs some work :-)
Pointers are unfortunately still the way to go in many scenarios, such as a replacement for the non existent `std::optional&lt;T&amp;&gt;` and cases where you need to do something with a member reference at destruction but only if the object hasn't been moved from. `std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;` is too verbose and seems like such an ugly workaround for what could have been a very simple addition of a template specialization to C++17.
Rust works like this. When you try to use the `.` operator on a reference, it autodereferences the reference until it finds a type where the `.` makes sense. It makes the `-&gt;` completely unnecessary.
The committee has a tendency to add features as standard library facilities (such as some magic in `&lt;type_traits&gt;` that can't be implemented without special compiler-specific hooks) instead of new syntax and keywords, all in the name of backwards compatibility and the fear of breaking code which might. This is the reason no "real" keyword has been introduced since C++11, and the reason that final and override are only considered keywords on certain contexts. IMO, they have gone way too far with this philosophy. `std::variant` could have been a lot nicer to language users, library writers, and the compilers that have to instantiate that template voodoo, had it been standardized as a proper language feature.
Yes, since removing them is much bigger thing than delaying them for another day(delaying stuff is national sport of WG21). And like I said there is no way in hell that will happen regardless if it is right thing to do or not. And this does not happen just at WG21. People get attached to projects they worked for 6 months and think that management that canceled it is stupid and uninformed. :) Like I said it is basic psychology. Just because most of people at WG21 are smart does not mean they are robots.
This is not initialization but assignment. It initializes all the members, then assign each member, which simply won't work if there is any member who cannot be default initialized.
Modern compilers will optimise away any inefficiency in your proposed solution.
I was referring to this comment, but I didn't figure out how to link to it directly at first: https://github.com/ericniebler/stl2/issues/182#issuecomment-287683189 More succinctly from another comment in the thread: "The problem is that many people think of unsigned int as maintaining an invariant, when what it really does is modulus arithmetic, [... refers to video] Subtraction causes the most bugs, and you can't assert or check that the desired "invariant" has been maintained, because 4294967295 is a valid value for an unsigned int." EDIT: I also dabbled in Java a while ago and missed unsigned types only when I needed bit manipulation (specifically, it was unsigned comparison which is tricky to implement with signed 2nd complement arithmetic). Now I'm also coding in C# which uses signed int for just about everything in its standard library.. without any issues.
I'm quite a fan of your library, I've recently started using it in a couple of my projects which provide interfaces for some hardware controllers. Personally, I've found it much easier to use than boost::units, so thanks! One little niggle I do have is that your library isn't available in [vcpkg](https://github.com/Microsoft/vcpkg), do you think you could add it so I don't need to remember to check for updates? :)
We use artifactory and conan for this: You submit a PR/commit to github. That triggers a build on all platforms in the CI and is uploaded to artifactory into the testing repo. We then do manual and automatic testing and when we are happy we promote the binaries to stable and it can now be used by the release build step. You can add any step you need in between or use automated testing to do promotion. Artifactory + conan has really cleaned up our workflow. 
&gt; you can't assert or check that the desired "invariant" has been maintained Yes, you can. You may not want to (or at least want to _have_ to), but `&gt;` is not a secret.
It's a DR, fixing a bug in the standard, so is de facto retroactive all the way back.
You didn't mention where does the Conan fit in your workflow. 
Don't forget std::experimental::observer_ptr. 
I'm glad this is possible, but also somewhat sad that so much code is required to express a no-op. 
A video game
[removed]
A family of VoIP desk phones
www.i-score.org and https://github.com/OSSIA/libossia
image processing
At work: high quality turn-by-turn navigation software. At home: retro ANSI terminal emulation software: https://github.com/KazDragon/terminalpp and https://github.com/KazDragon/telnetpp
I use it to write software for thermal testing of spacecraft, as part of their pre-launch checkout procedure. The application is roughly 300K lines of C++11, with bits from later standards where supported by our compilers. It runs on a dedicated network of computers, acquiring several thousands of channels of data from about two dozen types of acquisition devices, and controls a few hundred power supplies (of a dozen different types) that supply power for various purposes. The software is responsible for the health of the spacecraft, so yeah - it would be best if there weren't too many mistakes in it. Actually quite a few of the power supply and acquisition drivers are written in a home-grown special-purpose language. It is encoded as XML, and has three data types: string, formula, and regex ;-) The software is celebrating its 20st birthday in a few months; our initial compilers were Visual Studio 5 and HP's aCC. I loved aCC's error messages: it didn't just tell you what was wrong, but also how to fix it. Alas, the HPUX systems are long gone; these days we are on Visual Studio 2017 and gcc 4.9 - hopefully soon to be a newer version. 
a high performance no-nonsense scientific tensor network library :')
XML, what were you thinking :D
According to [cppreference](http://en.cppreference.com/w/cpp/numeric/math/pow), since C++11 there is no overload `pow(float, int)` anymore but only a single template `pow(A1, A2)`, where integral types are cast to double. The wording is not entirely clear, but this likely explains why there is a difference for floats (where casting to double takes place at some point during the algorithm) but not for doubles. Hence, to properly test the float case, it might make sense to call `pow(x, 2.f)` instead of `pow(x, 2)`. The following code on gcc.godbolt.org with at least `-O2` or `-O3` #include &lt;cmath&gt; float ff(float x) { return std::pow(x, 2.f);} float fi(float x) { return std::pow(x, 2); } float fm(float x) { return x * x; } double dd(double x) { return std::pow(x, 2.);} double di(double x) { return std::pow(x, 2); } double dm(double x) { return x * x; } (sharing from there doesn’t seem to work) compiles to the same function for `dd`, `di` and `dm` while `ff` and `fm` take a shorter path compared to `fi`, which needs a float-to-double and double-to-float conversion around a double-precision multiplication: ff(float): mulss xmm0, xmm0 ret fi(float): cvtss2sd xmm0, xmm0 mulsd xmm0, xmm0 cvtsd2ss xmm0, xmm0 ret fm(float): mulss xmm0, xmm0 ret dd(double): mulsd xmm0, xmm0 ret di(double): mulsd xmm0, xmm0 ret dm(double): mulsd xmm0, xmm0 ret
Cool. I didn't know about this. No need for raw_ptr&lt;T&gt;.
It started out as a simple collection of command strings to be sent to the instrument. It was trivial to add some replies, and some regex for processing. Then we needed a variable for something. Soon an 'if' statement followed (`&lt;if&gt; ... &lt;else/&gt; ... &lt;/if&gt;`). In short, it got out of hand a little... ;-) I complain about it, although I'm the sole person responsible for that abomination. At the same time: it is actually really good at what it does, so it's not all bad. 
&gt; Clang-format is a code linter for C++ I'm quite sure that's doesn't fit the widely used definition of a linter. If anything, clang-tidy is a linter, not clang-format.
Personally I love the IDE of Qt, Qt creator. It feet perfectly on my dark theme for eyes saving: https://i.imgur.com/yDpL0tn.png The debugger interfaces are really good, and you have plugins with interesting features like the ClangModelCore (real time errors and warnings with clang). You can use cmakefiles, you can run multiples times your application (usefull for multiplayer games), and also you can run the debugger + a release version of you app (also usefull for multiplayer). The syntax highlighting is very good and fast, you have refactoring tools, and many usefull shortcuts (ex: ctrl + mouse click to access the definition/declaration). 
You forgot the most important part! For what `n` does calculating x^n become faster with `std::pow` than with exponentiation by squaring? And what about accuracy?
It's worth noting that the C [*Floating-point extensions TS part 4: supplementary functions*](http://en.cppreference.com/w/c/experimental/fpext4) introduces the `pown` family of functions which « compute x raised to the nth power, where n is integer ». So... if it makes its makes into the C standard, then the C++ standard might adopt those functions as well, and the `pown` family of functions might reintroduce the integer overloads of `std::pow`.
Gotta get on that embedded DSL train, except you pick a language that already supports branching. :P
Everything that doesn't fit with C#.
[removed]
Not necessarily important part for his use case, but I agree that it would be interesting.
Command line with: Vim Gdb Git Valgrind Grep ... List goes on...
I just use vim. I would use gdb for debugging, but the thing I work on is too big for that to be useful (executable without debug info is still around a GB) so just logging messages mostly. That is for the day job, but I do the same for any personal projects too. (Though I could use gdb for them, since I wouldn't build anything so crazy huge myself).
VirtualBox with Windows and Visual Studio? Anyway, mostly I use vim with a simple makefile for Linux development... CLion when I have a GUI.
I use emacs for every job. I use gdb for debugging. I also use `ccache` for pretty much every executable. I have 5 phases in development (and thus, equivalently, 5 phases in my Makefiles). While developing, I just do `g++ -fsyntax-only` because I tend to do stupid syntax errors but not so much semantic errors, so every now and then (say every half an hour of coding) I check syntax. Then I precompile my headers. Then I build my test environment on `ccache clang -g` because I like clang's `-fsanitize=...` options and use `-Weverything`. At this stage, I use the compiler (clang) very aggressively and try to fail as much programs as possible (every warning is an error, try to get as many warning as possible). This is the environment where my unit tests live in. Once I pass all (conclusive) test cases, I build debug environment `ccache g++ -DDEBUG -g`. I casually test my programs, play around. Then I release with `g++ -O2 -s`. That's mostly it. Nowadays, I pretty much only use C but my workflow is the same in C and C++.
It's faster to calculate x^4 as `y=x*x; y*=y;`
+1 for Qt Creator, but damn, that font is ugly. It can look so much better with a proper font: https://imgur.com/a/EKSBI (This is Ubuntu Mono)
- Distros: Linux Mint 18.2 (based on Ubuntu 16.04) in a VirtualBox on Windows 10 and Ubuntu 14.04 (on Travis CI) - Toolchains: gcc 7.2 from [ppa:ubuntu-toolchain-r/test](https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test), clang 5.0 and clang SVN from [apt.llvm.org](http://apt.llvm.org), linking against libstdc++ 7.2 for all compilers. - Libraries: Boost 1.65.1 compiled with gcc 7.2. - Build tools: CMake 3.9.2, git, lcov, no debugger (just `printf`) - Hosting: GitHub, Travis CI, codecov - IDE: Eclipse CDT for editing, command line for building Main pain point: I haven't been able to sort out ABI issues when linking programs using a pre-built [libc++](https://launchpad.net/~anthony-justsoftwaresolutions/+archive/ubuntu/libcxx) against libstdc++-linked libraries (such as Boost). I'd appreciate if someone (/u/EricWFCpp perhaps?) could give pointers on how to: - either: build libc++ in such a way that it can be linked against libstdc++ linked modules (in particular a gcc-built Boost version) - or: set up a libc++-linked Boost version alongside a libstdc++-linked Boost version (building Boost with `layout=versioned` on Linux is not working nicely with FindBoost.Cmake)
Ahah yes, everyone's telling me this, but me eyes don't like anti-aliasing x) I have a friend that uses "Source Code Pro" and likes it very much.
A screenshot of my development environment is [here.](https://imgur.com/a/FH7q2) Desktop session: plasma5 IDE: Qt Creator Debugger: std::cout 
aside from the common issue that pointers apply to the specific variable, not with the type (so declaring multiple variables in a single line, which is not something you should actually ever do btw, only really works with ```int *a, *b```, 'auto' also infers the type of the variable as a T* accordingly. This distinction is also why I feel people would prefer to use left-alignment for references - e.g.: int *a; auto x = a; // x is int* int&amp; b = *a; auto y = b; // y is int auto&amp; z = b; // z is int&amp; 
Editor: Visual Studio Code with cpp extension Debugger: Visual Studio Code or gdb in terminal
processing of larger measurement data sets / number chrunching / scientific computing / a lot of image/signal processing / a lot of solving optimization problems, possibly nonlinear ones
Can you share what kind of project is that?
CodeBlocks
It's a tool people use to design microchips.
For me it's sublime, and the terminal window. Just use cmake to generate the build files, and then "make" to compile.
[removed]
Maybe you're the right person I can ask this: How to do project setup (as in Cmake vs. autotools) properly in c++ dev? I came from Rust (cargo is awesome) but have to write my master thesis in C++ and I don't even know how to fetch all the dependencies I want to pull in ... do I have to do this on a distro-level or can CMake / Autotools do this properly?
CLion, with clang I just love Jetbrains' IDE and I haven't found a single other C++ IDE that I like, If I can't use CLion, I'd rather do sublime/command line than use another IDE
Is this proposal or parts of it accepted? Which parts, in case they are?
I'll take a look at it. I'm also happy to take pull requests for build system/package manager support.
&gt; Ahah yes, everyone's telling me this, but me eyes don't like anti-aliasing x) I have a friend that uses "Source Code Pro" and likes it very much. I don't like antialiasing either but the font you use is meant for antialiasing. A properly hinted or bitmap font like Anonymous pro at 9-10-11 is much better for this use case : https://i.imgur.com/J2Ykt39.png
distro-level or conan.io
I have several setups. My current job uses windows but my previous was embedded Linux. New Work: Was tasked with porting some stuff to Linux, but I had to work in a VM, so everything had to be lightweight. Sublime, GDB + KDGB. All tasks handled in bare command line. Old Work: Codeblocks as main IDE, Sublime text for altering Makefiles, data files and quick changes. Nano for working on remote boxes ( sometimes vi if nano isn't available ). Debugging is always GDB. At home I tend to work like my old work, but I've been trying out Atom and the Visual Studio ports recently. Not wholly sold on either though.
Vouching for QtCreator too: https://i.imgur.com/CF1BHIm.png with : Base 16 Mocha as theme, Fira Code as font on hidpi screens and anonymous pro on lowdpi screens Also: * Gammaray for Qt apps: https://www.kdab.com/development-resources/qt-tools/gammaray/ * Heaptrack for memory usage: https://github.com/KDE/heaptrack * KCacheGrind for analyzing callgrind and cachegrind results: https://i.imgur.com/o6rAmjx.png
- Vim ([Why i still use vim](https://medium.freecodecamp.org/why-i-still-use-vim-67afd76b4db6)) - Clang/GCC - LLDB/GDB - Valgrind from time to time - xdo or similar to automate from time to time Build depends on project, usually cmake, plain make or automake
&gt; no debugger (just `printf`) Christ, someone just sent this message from the dark ages.
How well does it work?
Hi. The part about accuracy is really not important for me, but I agree that the first part is interesting. I'll try to do it in the following days if I have some free time. 
Yes, it would be faster normally, but I would expect the compiler to do it by itself as part of the common subexpression eliminiation optimization, although I didn't verify if it was done. 
Check out the hunter package manager : https://github.com/ruslo/hunter it is awesome 
To add to the other answers: Check out the [Effective CMake](https://www.youtube.com/watch?v=bsXLMQ6WgIk) talk. If it needs to compile on Windows, too, there is [vcpkg](https://github.com/Microsoft/vcpkg). Forget about Autotools.
Na, just a lot of `assert` and `static_assert` statements that catch most of the logic and off-by-one errors. And full coverage unit testing of course :)
Hi, sorry for the late reply. I just compiled it again from the git://anongit.kde.org/kdevelop.git repository (with KF 5.38, CMake 3.9 and clang/LLVM snapshots). `kdevelop -v` says `kdevelop 5.1.40`. What I did (shortened, obviously): Create a CMakeLists.txt: add_library(foo foo.cpp) target_compile_features(foo PUBLIC cxx_std_17) Import the project using the CMake project manager Leave the configuration settings at their default In foo.cpp C++17 features are incorrectly highlighted as syntax errors. The same happens to definitions via `target_compile_definitions`, but interestingly the include paths are correctly resolved. I can try using stable releases if you want, but I remember seeing the same problem on another machine running the Arch Linux package.
Your C++ code compiles cleanly with -Weverything?
Do you use any additional packages with your emacs?
Currently working on my emacs/gdb setup. Completely different experience coming from Visual Studio, but I'm beginning to see its power with packages like cmake-ide, magit, rtags, flycheck etc.
Or what do you do with warnings that you can't fix?
Pretty cool idea (and nice article). I'll give it a try. Minor remark: Does this repository need to be so big: $ git clone https://github.com/weliveindetail/llvm-expected.git Cloning into 'llvm-expected'... remote: Counting objects: 1373472, done. remote: Compressing objects: 100% (231152/231152), done. remote: Total 1373472 (delta 1137254), reused 1373461 (delta 1137246), pack-reused 0 Receiving objects: 100% (1373472/1373472), 324.55 MiB | 1.76 MiB/s, done. Resolving deltas: 100% (1137254/1137254), done. ? 324MB for few files? Maybe you could consider removing LLVM git history from this repo? Also, the project won't compile under MinGW (gcc 6.1.0) because of Clang specific extensions: llvm-expected/include/ErrorBase.h:59:31: error: missing binary operator before token "(" #if __GNUC__ &amp;&amp; !__has_feature(cxx_alignas) &amp;&amp; !EXPECTED_GNUC_PREREQ(4, 8, 1) ^ Adding: #ifndef __has_feature # define __has_feature(x) 0 #endif #ifndef __has_attribute # define __has_attribute(x) 0 #endif #ifndef __has_builtin # define __has_builtin(x) 0 #endif to `llvm-expected/include/ErrorBase.h` solves the problem.
It used to be vim with clang complete. That combination has ide-level autocomolete and error highlighting. If I absolutely had to debug, I would use lldb. Usually I would rely on logging for debugging though. Now I'm using clion. It's a great ide.
Same for me. I'm slowly dropping real Visual Studio on Windows also as Code gets better.
* IDE: spacemacs w/ rtags for navigation &amp; magit for git * debuggers: gdb and rr (gdb's python interface let's you write some powerful debugging scripts) * compilers: clang 5 and gcc 7 * build: cmake (w/ the ninja generator) and ccache * shell: zsh * distro: ubuntu 16.04
Clion, cmake, git, gdb, strace. I'd like to hear if anyone is doing Clion+CUDA+cmake development.
That article tho &gt;Why I Still Use Vim &gt;Memory Usage, Startup Time &gt;The end For serious development these are not even top 5 priorities...
Install gentoo in one of your partitions (or vm's) you'll get out of the box the most 'dope' cpp build env you could ever dream of.
distro: latest fedora (26) editors: vscode / Qt Creator compilers: latest gcc / clang tools (in no particular order): * cmake (project setup) * ninja ( replacement for make) * ccache (compilation caching) * gdb (debugging) * valgrind (debugging) * kcachegrind (visualising callgrind output) * clang-tidy (refactoring + static analysis) * compiler-rt/sanitizers (debugging+run time error detection) * perf (instrumentation/performance profile generation) * jemalloc (an alternative to malloc, tcmalloc is also good) If you are a student you can probably also get a free copy of Intel vTune, it's a very powerful tool for performance analysis. and finally docker... it's really useful for running different environments with different configurations.
Also battery life but did not graph it out for that article. Anyway, serious development can only happen on your desktop overpowered machine? Maybe I'm getting old and senile but I like using my laptop.
EDA?
Emacs with projectile and ctags, clang-format!, clang-format, clang-tidy, cmake, gdb, ninja instead of make cppcheck is neat but don't use it often
that would be weird considering there are some incompatible warnings (eg C++98 features incompatible with C++11 and conversely)
I'm just curious about one thing if you don't mind. If you take away the basic vim navigation and commands, which can be emulated in basically any popular IDE/environment, what is left that makes vim better (if you don't necessarily care about memory usage and startup time)?
I don't think that most compilers will make that optimization unless perhaps with a flag like `-ffast-math`. Floating point operations are not truly associative (different rounding error for different order of operations), so the compiler should not assume associativity during optimization. EDIT: From [gcc documentation](https://gcc.gnu.org/onlinedocs/gcc-4.6.1/gcc/Optimize-Options.html#Optimize-Options): &gt;`-fassociative-math` &gt; &gt; Allow re-association of operands in series of floating-point operations. This violates the ISO C and C++ language standard by possibly changing computation result. NOTE: re-ordering may change the sign of zero as well as ignore NaNs and inhibit or create underflow or overflow (and thus cannot be used on a code which relies on rounding behavior like (x + 2\*\*52) - 2\*\*52). May also reorder floating-point comparisons and thus may not be used when ordered comparisons are required. This option requires that both `-fno-signed-zeros` and `-fno-trapping-math` be in effect. Moreover, it doesn't make much sense with `-frounding-math`. For Fortran the option is automatically enabled when both `-fno-signed-zeros` and `-fno-trapping-math` are in effect. &gt; &gt; The default is `-fno-associative-math`. 
is conan the best dependency manager for C++?
So keep going
Previous job: brain computer interface and epilepsy research, with matlab for research/modeling Now: algo trading, with python for research and wrapping large systems
[Emacs](https://www.gnu.org/software/emacs/) + [cmake](https://cmake.org/) + [Cmake-IDE](https://github.com/atilaneves/cmake-ide) . And GDB for debugging.
Well, on Linux/Darwin (and windows if you set it up that way) the operating system IS the IDE. Vim/Emacs basically just becomes the editor so it's really not helping me to run a graphical IDE, on top of.. the IDE, in which I need to hunt for buttons or have 2-3 monitors to fit everything on screen. Dunno, call it personal taste? nowdays i prefer to live in a terminal shell, early days I preferred GUI's, its just easier typing exactly what i intend to do. e.g I'd rather do zip &lt;files...&gt; or git commit -p than fiddling around with a gui.
Yup, thought more people would know what I was on about if I didn't just use the acronym though :)
Eclipse with the CDT plugin. Has all the debugging and refactoring you would need, an excellent code completion, good error markers and the syntax highlighting works very well. It has a very nice git integration that lets you compare to older versions of the code easily in a gui. Plus largely customizable key bindings and a project/workspace wide search for symbols. I write my own Makefiles, though, or use cmake. In parallel, I have a basic vim setup with ycm for smaller stuff (where setting up a project in Eclipse isn't worth it). 
\+ Vim's YouCompleteMe plugin
emacs.
A high-performance [NoSQL database](http://www.scylladb.com/) at work. Video game pet-project at home.
It is so called "NMake project", it runs nmake script (could be any other make-like script). It also has options to help intellisense like include directories, project defines etc. Linker options supposed to be in your makefile in this case.
&gt; Check out the Effective CMake talk. Nice suggestion, will do. Thanks! &gt; Forget about Autotools. May I ask why?
Recently had to evaluate a number of IDEs. I already had CLion at number 1 considering my experience with it over the last two years but found CodeLite to be a great alternative. It's not perfect but for the great price of $0, it works well. Supports CMake based projects and offers clang-based code completion.
Research in [abstract algebra](https://en.wikipedia.org/wiki/Abstract_algebra) is what I've done for a long time. More recently, I developed a collection of classes to generate [SVG](https://en.wikipedia.org/wiki/Scalable_Vector_Graphics) files for drawing images. 
Could you elaborate on the workflow of that setup compared to VS? I keep considering switching to Linux as my primary desktop OS, but VS is the one thing that really holds me back.
Everything is the same except with Emacs. Command line makes development so much quicker.
i feel the same way. The title could have been anything else but, instead, its some political sounding stuff. ugh. unnecessary.
Changing the induction variable isn't always as straightforward as it should be. std::vector&lt;int&gt; container(0); for(size_t idx = container.size() - 1; idx &gt;= 0; --idx) { } Doesn't do what you would think it should.
Ooh, never heard of it, Guess I should check it out, thanks :D Does it have a Linux version? 
Why not use cairo's SVG backend?
You can disable them by adding "no-" between "-W" and the rest of the warning name, i.e. in CMake: add_compile_options( -Weverything -Wno-c++98-compat ) Or you can disable them in parts of files like here: https://stackoverflow.com/questions/20078941/how-to-use-pragma-clang-diagnostics
Simulation software, particularly where real time performance is critical.
Same here. I've been using https://github.com/cyrus-and/gdb-dashboard for a nice gdb view after trying out cgdb (which is unfortunately a bit buggy). Although, I've been thinking of trying out https://github.com/cs01/gdbgui which is essentially a nicely formatted web viewer that might be a little nicer for quickly toggling breakpoints &amp; viewing stack frames that are fairly large.
You want pictures? - https://imgur.com/a/bhyds - https://imgur.com/a/OqFaI - https://i.imgur.com/CBlEHXS.png
You're right indeed! I forgot about floating points operations being not associative. Using godbolt, we can see that it's only optimized with Ofast: https://godbolt.org/g/mpmcWa 
1. I didn't know about Cairo. 2. I wanted to learn SVG, and the best way for me to learn something is to write a program to do it. (At first, I speculated that I could just adapt my home-brew C++ support for [PostScript](https://en.wikipedia.org/wiki/PostScript), but things turned out altogether different.) 
&gt;&gt; Forget about Autotools. &gt; &gt;May I ask why? Autotools has poor integration with pretty much every tool, is poorly documented, works poorly on Windows, and is rather confusing to use. If you don't want to use cmake go with something modern like qbs or meson. I really like qbs but there is a large community around cmake. 
Managing variable numbers of windows quickly and easily to be able to visualize more of the project as you go. I will pretty frequently go from 1-4 splits open on one monitor over the span of a few minutes. To go along with that, screen real-estate. Using gvim + i3wm, outside of my code editor there are about 5 text-line heights worth of screen used up. I've almost got the entire monitor screen dedicated to just my editor. Compare to visual studio, where in the default view your code window is sharing space with the solution explorer, output menu, GUI menu bar, etc and only takes up maybe 40% of the screen, if that. When I have 4 splits open in vim, each has almost as much screen space as the code view does in Visual Studio with the default view. You can configure this differently and use multiple monitors to help manage it, but I can honestly efficiently work with a single monitor with my setup and not feel hobbled in the least. And that's coming from a 3x monitor setup. Outside of that, the ability to quickly navigate a complex project with the keyboard alone is pretty nice. This is obviously not a "top priority", but I find it's a lot easier (and more fun) to keep focused on work when I don't feel bogged down by how clunky my editor is to use. The original reason I switched was that I wanted a consistent coding experience working across multiple platforms. I used sublime text previously, and was annoyed at ctrl+* hotkeys on windows and cmd+* hotkeys on mac. Switched to vim to unify everything and I can have my preferred dev environment setup on a fresh mac/win/linux machine in &lt; 5 minutes (and usually faster).
Yeah that sounds a lot cleaner. Thats pretty close to what we have discussed being our "one-day" goals. Who knows, maybe today can be that day!
Good point. We build a shared library and it’s dependencies for iOS/Android/Windows with conan and artifactory is our conan remote server (that enables promotion). We then grab the shared lib in the different clients with conan. That way we have a structured way to build the lib and it’s deps everywhere. 
vim, gdb, valgrind, autotools, whatever command line tools i find helpful
Happy to help out if you have any deeper / more specific questions. 
I use FakeVim plugin with Qt Creator, best of both worlds.
CLion with Vim keybindings. I love debugging within CLion. Our studio licenses TotalView as our debugger of choice, and I hate it with a fiery passion.
Vim and cmake and git on my multipurpose home server. Which I connect to remotely from windows using putty or kitty.
Terminus is the best bitmap font, if you don't like antialiasing.
Right now I'm using Netbeans for regular C++ and QT Creator for QT-specific programs. I haven't tried too much, but I have used Eclipse and IDEA, but Netbeans seems great to me. Pretty slick.
You should try building projects with sublime ctrl+b, saved me a lot of time!
(Soft) Real-time video processing, streaming and compositing. Soon to be synchronizing and merging multiple data sources in RT.
Another vote for QtCreator. It's lightweight (compared to CLion and Eclipse), it has got acceptable CMake integration (I use cmake a lot) and FakeVim is very good for advanced edits. I usually debug with gdb from the command line, but it's an old habit. I haven't tried QtCreator's debugging features.
It's not ideal for huge projects as intelliSenseEngine is super slow (at least for me) but other than that it's ok.
data storage.
Yep, there's versions available for Debian based distros [here](https://downloads.codelite.org/)
I use a very mildly altered VIM for my editor and GDB for my debugger.
Visual studio dev essentials: https://www.visualstudio.com/dev-essentials/
Eclipse CDT, have been using it for a few years now.
Ah, through wine or a VM with remote debugging, that's interesting
Embedded digital signal processing and PC-models. GNSS, most of the time (GPS/GLONASS/etc)
FYI you've got some kind of markdown mess in the quote
Fixed. Thanks.
&gt;I haven't been able to sort out ABI issues when linking programs using a pre-built libc++ against libstdc++-linked libraries (such as Boost). I'd appreciate if someone (/u/EricWFCpp perhaps?) could give pointers on how to: So long as you expect to never pass STL types, or types containing STL types, across library boundaries everything should just work, so long as your firewall between the two sets of code is perfect. However since you're asking about Boost, which is largely header only, I suspect that isn't the case.
I use KDevelop master + CMake, on Arch. For the compilers, I switch between Clang and GCC. All my prebuilt dependencies are in a folder that I add as a cmake prefix.
GCC protects from this (upd: Clang and ICC provide similar warninngs): 8 : &lt;source&gt;:8:44: warning: comparison of unsigned expression &gt;= 0 is always true [-Wtype-limits] for(size_t idx = container.size() - 1; idx &gt;= 0; --idx) ~~~~^~~~ Compiler exited with result code 0 There are several ways how to fix it: for example, use a helper index: std::vector&lt;int&gt; container(0); for(size_t idx = container.size(); idx &gt; 0; --idx) { size_t j = idx-1; } or use operator `--&gt;`. 
Out of that list the only thing you felt an IDE would help you with is CMake?
You can also break it by doing for(size_t idx = container.size() - 1; idx != 0; --idx) Which doesn't give a warning on gcc for me. There are work arounds - for(auto iter = end(container); iter != begin(container); --iter) But I'd rather just use: for(int idx = (int)container.size() - 1; idx &gt;= 0; --idx)
I usually use Make for things that are simple to build, or CMake for things that are complicated. Normally I use vi and other commandline friends for initial project creation and setup, and for occasional stuff throughout development. Whenever I want something bigger, I use netbeans as my IDE. Almost all my projects have a "valgrind" target, which builds and runs the app under valgrind with valgrind's flags to give as much info as possible. "make valgrind" is so, breathtakingly, convenient.
Emacs is an IDE.
Is it? I never used it, thought it was just a text editor.
1. Distro: RHEL7 2. Compiler: g++ 4.8.5 3. Editor: vim + cscope + molokai colorscheme, experimenting VS Code 4. Version Control: TFS 5. Debugger / build : std gnu tools 6. IDE : Took a while to get used to but been using Eclipse CDT for last 5 years. 7. Misc: Bunch of aliases to search code files along with cscope/ctags+vim integration. 8. Script to rebuild cscope index
hunter.sh is the package manager (cmake-based) I'm going with. I'm actually working on learning to build packages to help grow the project. it fixed nearly all the issues I had getting boost built properly. 
Looks like his \`\`magic-linter`` failed to warn him that he's in the wrong thread.
I use Sublime Text and printf debugging normally, although when I _really_ need a debugger, I'll open vscode and use its awesome GDB ui. Also, I use cmake for large projects, and a simple build.sh that `find`s all the CPP files and compiles them on small projects
Why is their a small bump in the graphs at around 100 000 before going up really quickly?
It's really not either--and it's both. It's sort of an editor "kernel". You can program it to do pretty much anything. XEmacs can even start up a GUI...not sure of the original Emacs. So you can make or install an IDE into Emacs. There are a lot of common programming editor scripts you can install into it to enhance how it works as an editor as well.
It is a text editor (well, a runtime technically), but can be extended to fit most purposes. This includes commong IDE features for many languages, C++ included.
IMO async goes beyond "a little bit of syntax sugar".
Isn't that going to involve generating more code? At the moment, presumably if an exception is thrown mid-list, it's the same as an exception being thrown midway through a member initializer list (it just jumps to the cleanup code corresponding to how far it got before the exception). If you allow different orders, you'd have to generate cleanup code in the correct order too, presumably. I'm not saying it's not worth it for the extra expressiveness, just taking a guess why they did it like that.
g++, Vim, gtags, unite.vim, a.vim, GNU Make. I try to avoid CMake and other such things to the extent possible. Every time I try one of the IDEs or any sort of smart-completion I find enough flakiness that it's not worth it.
Same here - the command line (and all that entails) *is* my "ide"
I use a [self-written editor](http://www.github.com/marssaxman/ozette) and handwritten makefiles. I rarely use a debugger anymore, but I'll put up with just a little bit of the awfulness that is gdb, on occasion. Never really got the point of cmake, never managed to learn how to use autotools.
Visual studio code with g++. Other than that, vim is pretty nice.
I mostly just use the command line, except at work where I am forced to use XCode. At home (where I work most of the time, because of the forced XCode at work) I use ArchLinux with vim, lldb and cmake as build system. I mostly use multiple actual terminal windows than screen or vim tabs.
That is a very interesting workflow. One question, I found that precompiling headers didn't do much for compilation speed on Linux (loading the giant header precompiled stuff took almost as long as parsing it). Can you share how you get precompiling to be worthwhile?
The idea is - you get polymorphism - you avoid awkwardness of lambdas and visitation - you avoid pointers - you get value semantics (copy, etc) It is intrusive to Button/Label/Textbox, but I assume they already derive from Control. At least in all the places I'm thinking of using it, it replaces existing traditional polymorphism via derivation. 
[Painting with light](https://www.youtube.com/watch?v=ZZBgsNFMDFs&amp;list=PL7CBEC9E4CFDB1FD9)
That creates future-compat problems with your library and -Weverything though. If you want to use it to discover warnings that's fine but what goes in to your build script should be turning useful warnings on (which is future compatible) instead of saying "give me everything except these 3 things I don't care about".
Evolution sims, generic AI toolkit for fully-autonomous NPCs, and eventually a game engine.
Exactly, I don't work for google, but my understanding is that devs tend to use clang, but production servers still run gcc compiled code, because of performance. Basically, wherever 5% performance means "we need 5% more rivers in the world for our additional power consumption", because google is at that scale.
That's because you are virtually never actually working with types smaller than int (due to the UACs / Integral Promotion rules). This is an extremely common source of bugs.
I did that exact switch (VS -&gt; emacs/linux) years ago and my professional satisfaction went up significantly. VS is unstable, slows, inscrutable, hard to get pre-compiled binaries for, optimized for beginners and perpetually behind in standards compliance. If you can get over the initial hump of unfamiliarity Linux is a far more productive environment for C++.
CLion (Vim plug-in), gcc or clang/llvm Or GVim, CMake/CTest, gcc or clang/llvm Depends on how I feel that day.
`x += 4` triggering a warning if x is not an int is correct behavior. That generates an intermediate int and then converts that int into the smaller type, which means overflow / wraparound (for unsigned types or `-fwrapv` land) does the wrong thing there. This kind of problem has been the source of many bugs where you get "impossible" values which don't occur if the math is done in the narrower type.
Atom or Sublime Text (I know they aren't IDEs, but I use them for everything) + Valgrind.
It might be that OpenCV-3.3 got a lot better at it (I think the last ones I tried for LinAlg stuff was 2.4.12 and possibly 3.0) - but I doubt it to be honest that they seriously worked on that. For C++, Eigen is the go-to library for LinAlg stuff (unless you have a compelling reason to use something else).
Compiling unit tests using clang/libc++ and linking against Boost.Test built with gcc/libstdc++ gives me linker errors for `std::string`. 
I assume that when `n` is a constant expression, `std::pow` may always be slower.
I think the point of this post was explicitly for you to enumerate the list...
It's... It's not pretty. :S * For starters, the project include kernel module work, meaning it pretty much has to run/be tested on a VM. I use KVM/LibVirt for that. * The VM has the toolchain (gcc, gdb, make, et al) installed. Everything is built on the VM, not the host. * On the host, I run Emacs. I have a number of elisp scripts bound to hotkeys that rsync the source tree to the VM over a virtual network, execute make, and pipe the output back over ssh into an Emacs buffer. * More elisp/hotkeys to open up project runtime configuration files, makefiles, and other common files I look at daily. * First among the Emacs packages I couldn't live without is Magit. Its lead developer Jonas Bernoulli is [running a kickstarter](https://www.patreon.com/tarsius), and I'd support his work more if I could. It's truly one of the killer features of Emacs. * Other Emacs packages I like are (in no particular order) Helm, Projectile, GTags, and Company. Most of the other packages I use are built on or extend those. Frankly, it's a hot, steaming pile of shit. I'd love to be able to integrate some libclang stuff to work as a tagging/autocompleting backend, but the project just doesn't build with it. The tagging engine (GNU Global) guesses heavily, the Emacs syntax highlighter isn't up to date with C++ 17 syntax, and the workflow is sometimes awkward as hell to the point where "grep" is sometimes the best tool. I dream of one day being good enough at Lisp to fix it, and not cry when I look at the resulting code...
I'm just a hobbyist developer, but here's my setup. - Distro: Arch Linux - IDE: Eclipse CDT - Build System: cmake-gui + make - Compiler: trunc build of Clang/LLVM - Debugger: LLDB via cmd or GDB via eclipse - Standard library: glib/libstdc++ - Source Control: git w/github - Terminal: Yakuake w/zsh &amp; Terminator w/zsh - Documentation: Doxygen + Graphiz
I'm currently using VS Code on OSX and a few VMs. All compilation actually done on the target machines with make using a shared folder so I don't need to commit for every typo I make though timestamps are trash so I end up doing cleans most of the time. Not really happy with this setup. VS Code's C++ plugin seems to stop doing intellisense randomly like when I resume from sleep and it was a huge pain to find and copy over all of my headers (not VS codes problem but still sucks). 
What it is "for real" is a lisp interpreter which has lots of text-editing software written for it. It *is* a text editor. But it can do anything, if you program it in it's lisp dialect (elisp, or emacs-lisp). I use it with evil-mode (vim emulation). Emacs makes integrating bits and pieces together trivial, but vim is king of text-editing.
I'm using it to [write a DAW](https://zenaud.io) (digital audio workstation).
Qt Creator + emacs + cmake. Same as my dev environment on macOS or, rarely, Windows. I'm using VS Code for other languages, but it's C++ goodness hasn't reached the level of Qt Creator yet.
If you look at https://www.reddit.com/r/cpp/comments/70tl51/c11_performance_tip_when_to_use_stdpow/dn5t75w/ note that the compilers already understand std::pow.
Here is the source code any advice is helpful for a beginner like me! Link: https://drive.google.com/folderview?id=0BwR0uEwDqV9VTF9FS3RLSTFyVVU
Advice #1 as seeing source code being shared in a shared folder: Use a VCS such as Git, Mercurial or alike!
Haha okay I will look into it! I will try to upload any further projects to github. Thanks!
Right, because `std::string` is externally instantiated in the dylib. so you need to link that to w/e is using the libc++ `std::string`.
VSCode has become my surprise favorite (with vim mode).
Real-time controller for robot-like machines. So it's basically a bunch of math (kinematics, filters, control loops) and networking, programmed in c++14.
- Ubuntu 17.04 - Emacs - CMake - Ninja (and Make) - gdb I've recently been playing with CLion. Still using Emacs, as my primary editor though.
I use FreeBSD 11.1 for testing with clang, since it uses clang 4.0 and libc++ as the base compiler and stdlib. This means Boost and everything else is compiled against it, and if you want a newer clang you can get 5.0 from the ports and it's still compatible with all the other libraries. It's already updated to Boost 1.65.1, latest cmake etc., so for development it nicely complements a Linux system with GCC, avoiding the rather nasty ABI compatibility issues you've already identified.
², QtCreator rocks. You also don't have to use cmake/qmake, you can import a directory directly and then specify build and run commands. Debugging (stepping through code) is slower than Visual Studio (the Windows IDE, not code, which is even slower) but usable. I haven't found an easy way to profile though, whilst profiling in visual studio is a dream.
You probably already know most, if not all, of this, but perhaps it may serve purpose to someone else. Some tips to increase the debugging quality: * Only enable debug info for translation units that need it. - a hack I commonly use with CMake-based projects is compile it without debug info, touch the source file I'm interested in (removing compiled object file works too) and do `make VERBOSE=1` to steal the compilation command, manually execute it with `-g` and redo `make` for final linking. * Use `-Og`, optimisation level that has "debug-safe" optimisations (unfortunately it's not exposed as cmake build type). `-Og` only enables optimisations and does not imply `-g` * `-g`, just like `-O`, has levels. `-g` is synonymous to `-g2`, you can use `-g0` (negates `-g`), `-g1` (limited variable tracking, mostly backtraces), `-g3` (includes macros). * `-fvar-tracking` and `-fvar-tracking-assignments` enable (or disable in their `-fno-var-tracking` form) tracking of variables. It might be useful for stripping parts of debug information. - I recently investigated that topic a little and it looks like variable tracking debug information in DWARF is stored in designated section, `.debug_loc`, it can easily take 25% of `-O2 -g` binary. Compilation with `-fno-var-tracking` produces binary that is devoid of that section, so most likely stripping said section from binary (or extracting it to separate map file) can yield similar results. * DWARF has multiple versions, latest is 5 supported by GDB8 and GCC7 (only experimental), they can contain varying quality of debug information * `-gz` can compress debug info * You can look into [reproducible builds](https://wiki.debian.org/ReproducibleBuilds), which make compiler output deterministic. One benefit of that is being able to produce debug symbols for already compiled programs that don't have them. * clang and GCC produce very different quality of debug symbols, see https://www.youtube.com/watch?v=EjwN7Gf8JIs
OK, so that would require me to rebuild Boost with clang/libc++? Is there no way to build libc++ with a `std::string` that is compatible across modules with libstdc++? If all else fails, I should dive into how to let CMake pick up the correctly versioned Boost libs. Or just set up a separate clang/libc++ VM :) Thanks anyway for the help.
I believe you're right for C, I do not have benchmarks though. If I use C++, I do use a lot of template metaprogramming: anecdotally, I can say that it speeds up if you have intense templates. The main reason I use precompiled headers is because it works well with `ccache` as it can cache your .pch files and what not. Once again, I don't have benchmarks, but this seemed to have speeded up some things for me.
Only if you have `-Werror` (`/Wx`) on for non-dev builds, which is a terrible idea no matter the warning level. If you do not have `-Werror` on, at worst the future versions of your compiler will find something new to complain about, which doesn't matter.
I'm not sure with what you mean by "compatible across modules". Can you give an example? You can link both libc++ and libstdc++ into the same TU, since they both mangle almost all of their names differently using versioning namespaces. So you won't/shouldn't run into conflicting symbols. However you can't link libc++s `std::string` header to libstdc++s definitions of `std::string` or vice versa. They don't even mangle the same. 
Oh thanks, that is certainly an interesting direction to keep in mind. For the moment I'll try and set up a separate Linux VM with a clang-based toolchain. For now I am only using Boost so no interference from other pre-compiled libs. Apart from me having zero FreeBSD knowledge, it also appears that Travis CI only supports Linux and OSX.
OK, let me try and whip up a reproducible example in a test repo on Travis. I'll get back to you if I keep failing.
Wow this looks good! Nice one!
Funtoo + Vanilla Kernel which builds in 2 minutes + LLVM/Clang + Qt Creator + Unreal Engine All in one for game development. There's also an integration plugin for Qt Creator and UE4 which seems to be abandoned by the developer. I forked it and fixed it up to 4.16. I' won't use it any more. Debugging or profiling UE games inside Qt Creator is such a huge pain. It' hangs not only the IDE and engine together, but also the whole desktop. I have to go to a tty and kill U4Editor to go back normal. If I could only make that works. Build times are at least 5x compared to UE4 on Windows.
Same question then really - what's your setup like? What're the main issues you encountered when switching and how did you deal with them? I've been using VS for many years now, and VS2017 feels very pleasant to work in - especially with Visual Assist X. Are there similar tools to make refactoring a matter of a couple of clicks? Are the debuggers up to scratch these days (exploring STL structures in memory, for example)? Ideologically I really want to switch, as I can't bear the idea of having to update to Windows 10 eventually. Please sell me on the practicalities!
You can easily isolate specific files that won't pass certain warnings, and those (that you wrote from scratch and contain important stuff) that will be tested with every warning. I honestly never had problem with incompatible, contradictory warnings, but I do know that they exist and if you're 100% convinced that one warning is unhelpful, you can always disable it.
Cool! Did not expect that
I have a lot of custom keybindings. Other than that, on top my head, I use org mode, auctex, hs-minor-mode pretty regularly. I don't think my emacs is crazily customized, you could get my emacs by customizing it for a day or two if you know what you're doing. I don't like highly customized emacs because then it's kind of a problem if you connect to some other emacs via ssh and can't send your configs there.
my man, you seem to prefer new tools to the old ones; ever considered moving to Arch?
I am using vim 8 with the following plugins that are essential for my workflow. But most of them are not specific for C++ development * YouCompleteMe * vim-cmake-completion * vim-cmake-syntax * vim-clang-format * vim-cpp-enhanced-highlight * zeavim.vim * vim-surround * auto-pairs * vim-grepper * majutsushi/tagbar * ctrlpvim/ctrlp.vim * scrooloose/nerdcommenter * SirVer/ultisnips * honza/vim-snippets * tpope/vim-fugitive * airblade/vim-gitgutter * w0rp/ale Additional tools I use cmake, valgrind, (c)gdb, clang-tidy, cppcheck, zeal (zeavim), ag / ripgrep (vim-grepper), zsh, tmux
&gt; I haven't found an easy way to profile though, QtCreator integrates with valgrind for this ; it's one menu click away ([Analyse -&gt; Valgrind Function Profiler](http://doc.qt.io/qtcreator/creator-cache-profiler.html))
warehouse management software material flow computer Industrial Flexible Manufacturing System (automotive) 
If I understood floating point math correctly, x * x == pow(x,2), while x * x * x != pow(x,3) because of rounding. This is because 2 operations are involved on the left side, so the rounding error from the first multiplication accumulates with the second. OTOH `pow` &amp; friends are required to return the closest representable floating point value, so there should be more logic involved. I might be completely wrong, but this explains why the tests with N=3 are slower. EDIT: yep, see: http://coliru.stacked-crooked.com/a/9bf17d9b65ea6927
I use it to write compilers. I have a small [project](https://github.com/thelostt/ccompiler) going on which aims to be a source for studying/learning how C compilers (or compilers in general) work. It's implemented in C++17, and I'm trying to stay close to the standard as much as possible. It's going slow lately, because I don't have much free time to work on it.
What set up is this?
But valgrind runs my code at like 30x slowdown no? Or is there a way to avoid that?
I use evil-mode (vi emulation) in emacs along with rtags and some simple emacs scripts to ensure that when I build my project rtags gets updated with the latest version of every file in the project. With rtags I get some refactoring tools (rename symbol, accept clang's fixit suggestion, probably others are available now), browsing (goto definition, goto reference, find symbol), on the fly compilation and error highlights overlaid on the source, and auto completion (intelisense like - I do not use it much but its there). I added some simple emacs scripts to help with file navigation to any file in the project's repo. You can get most of this out of the box with cmake-ide, but I needed a bit more control over some details. As for your other questions, gdb is more powerful but less friendly than the VS debugger. You can get pretty printing of stl structures through gdb's python plugins, I think its a simple as installing an apt package. I use cgdb to give gdb a minimum but efficient curses based interface. Emacs has support for driving gdb as well if you prefer. If you want a motivation for change just consider that the whole environment on Linux is mostly built by and for people like you, i.e. experienced developers. That means that most things are programmable and most tools are highly polished, stable and optimized for expert use.
Where did you pickup this code style? What is the advantage of spacing semi-colons after statements, no spaces between arguments, etc? I'm curious because I'm having a hard time seeing where the advantages exist in this style.
What about images, which are normally single or 3-channel uchar's?
https://www.visualstudio.com/vs/older-downloads/
No where, i just started coding with no supervision and no one to tell anything and i went with whatever came to mind. After a while, i decided that code consistency was important and i settled with whatever i was looking at and it looked like the code on the screenshot. 
That is one step removed from having a dickbutt in the code. 
neovim (with YouCompleteMe, NERDTree, nerdcommenter, A, Ultisnips, and vim-clang-format). I use both g++ and clang++ to develop with (switching for some errors, and because sometimes I get useful warnings from one but not the other) and gdb for debugging (haven't yet used lldb, but planning on getting my feet wet with it soon) and Valgrind for profiling and all the other cool stuff Valgrind does. I use standard GNU Make in almost every case, and CMake if I really want to hate myself in order to support Windows. I like Premake a lot, but I really want some features of Premake 5, and 5 has been in alpha for like 3 years. Other than that, I use the whole "Linux is an IDE" thing, and heavily use standard and nonstandard command line tools wherever appropriate.
 for (auto idx = container.size(); idx--;) Short and to the point; don't overthink the simple stuff. ;-] EDIT: oops, idx--, not --idx
ctags, make, gcc, ssh (because the actual machine was headless)
Emacs is a great operating system, it's only missing a good text editor.
&gt; (loading the giant header precompiled stuff took almost as long as parsing it) It's generally necessary to "tune" the prefix header so that it does not include everything and the kitchen sink. My software builds multiple times faster with it but I only put the library headers I use most (vector, string, functional, QString, QWidget, etc...)
[NeoVim based](https://github.com/oblitum/dotfiles), with [custom YCM fork](http://nosubstance.me/articles/2015-01-29-better-completion-for-cpp/). Zen mode by Goyo ([also fork](https://github.com/junegunn/goyo.vim/issues/156#issuecomment-328386711)).
OS: Ubuntu Text Editor: Vim Compiler: g++ Still kinda new to using Unix, as my past development stations have used Qt for the most part. But the uni I'm at uses Unix almost solely so I figured now is the time to get used to it. For the most part its really enjoyable and haven't really had any issues!
It is just low value syntax candy. The last thing we need is C++ with syntax diabetes. 
I've been learning c++ using "Programming: Principles and Practice Using C++" it's pretty beginner friendly but sometimes he talks too much.
Awesome! I watched a similar show in France but on a church. It was one of the coolest things I have ever seen. We were just passing by and their were loads of events happening their.
I made a [minimal example on GitHub](https://github.com/rhalbersma/libcxx_libstdcxx_compat) that builds on Travis CI for gcc-7 / clang-5.0 with libstdc++ but fails with clang-5.0 and libc++. The example is a trivial unit test asserting `true` using Boost.Test. The error is an unknown reference to `boost::test_tools::tt_detail::print_log_value&lt;bool&gt;::operator()(std::__1::basic_ostream&lt;char, std::__1::char_traits&lt;char&gt; &gt;&amp;, bool)` Build commands are in the .travis.yml (I pass `-stdlibc=libc++` as compile/link option and `-lc++abi` as link option). Any help would be appreciated!
And the vim emulation is well integrated *cough* eclipse *cough*
Two terminal windows (sometimes with tabs), bash, make or cmake, git, gdb and other tools, various git &amp; bash aliases and scripts, and vim (tricked out a little bit with some plugins and custom commands) is all I usually need. I used Qt Creator a bit when it first came out when working on a project that used Qt, but had trouble configuring it for a non-Qt project (i.e. didn't use qmake to build, used existing Makefiles.) I tried using Atom for a while and while there are some modules to support C++ it's definitely second class vs. Javascript. I just downloaded Visual Studio Code (I also do Windows software and have learned how to be efficient and effective with Visual Studio) but haven't tried it yet. 
Easy solution, but what about accessing the items in the container? You're now back to the temporary variable solution above.
If you only have to do it once, just install them on your system (and document the library names and package names for your distro). If this is not a long term project, just something you need to share it with a handful people, they can use your instructions to install dependencies, or if you don't want to force them do that but or to bother with the more advanced dependency management tools mentioned in this thread, just install them in subdirectories of your project and set up your build flags to use those local directories. This works best when you don't need to track updates to the dependencies, and those dependencies are relatively small, standalone libraries without any or many of their own dependencies. But if your dependencies are complex or evolving/changing frequently, you should look into some of the more comprehensive management tools mentioned in this thread. KISS -&gt; YAGNI. 
It's an index variable in a for loop just like any other – why would this pose an issue for accessing items in the container? If the intent was to iterate a collection in reverse, that's exactly what this accomplishes. EDIT: I just noticed I used the wrong decrement in my comment. :-S Fixed now, if that relates to your point. Demo here: http://coliru.stacked-crooked.com/a/513850b14acd68a4
Oh. Now I totally understand! Makes much more sense now!
&gt; In Elixir, the snippet `&amp;String.downcase(&amp;1 &lt;&gt; "-tag")` is idiomatic and commonplace. Sure, but is that really better than `[](s) =&gt; String.downcase(s &lt;&gt; "-tag")`? And by a sufficient degree that it merits the additional complexity of parsing? 
* OS: **Fedora** * Editor: **Emacs**; sometimes even **Vim** for non-code related edits like configuration, note taking; I was even experimenting with [Kakoune](https://github.com/mawww/kakoune), but it seems that I don't have time to actually learn it. * Compiler: **GCC**; sometimes **CLANG** * Code browsing: [Rtags](https://github.com/Andersbakken/rtags) daemon. It can be used either from within *emacs* itself or from the command line. * Build system: **Autotools**; I'm using [Build EAR](https://github.com/rizsotto/Bear) to get a compilation database out of makefiles. It is necessary for some build-upon-clang tools like: **rtags** and **clang-tidy** * VCS: **git**; I'm using it from bash directly, with some aliases. One day I should actually learn *magit*. * I don't debug that often, but when I do, it's: **GDB**, **Valgrind**, **gcc/clang sanitizers**, **ltrace**, **strace**, old plain printfs or stream operators, extra logging, sometimes even putting sleeps in the code :), I'm sure you can imagine. * some other tools: **screen**, **bash**, **grep**, **sed**, **awk**, this list of shell related utilities would be long, **clang-tidy** for refactoring and moving from *C++03* to *C++14*, sometimes even **python** for things that require a lot of logic or are for some other reason inconvenient to do in bash. I didn't put URLs to everything as most of those tools are notoriously known. 
Surprised this is so far down. Cdt is really mature and quite awesome. Also vrapper for vim bindings and eclipse is golden for any project that's bigger than a single file. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/70v9tv/visual_studio/dn6vo8b/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/70uw3c/vs2017_no_linker_option_in_project_settings/dn6vpd1/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
High-performance parallel distributed build system: [ElectricAccelerator](http://electric-cloud.com/products/electricaccelerator).
https://github.com/Microsoft/vcpkg/pull/1842
For a [database management system](https://en.wikipedia.org/wiki/SAP_HANA), specifically its [text analysis subsystem](https://open.sap.com/courses/hsta1)
+1 for Qt Creator. Switched from MS Visual Studio 6 years ago and never looked back. 
Come on, we now have more than 64KB of RAM, you can afford to declare one variable per line. 
When you do arithmetic on them they get promoted to ints, and then narrowed back to uchars (the crux of my "you're almost never working with smaller than int" comment). If you don't engage the UACs (that is, all the types in the arithmetic are uchar) then no promotion occurs but if that's the case `-Wconversion` won't yell at you.
I write programs that perform data acquisition, logging, and network forwarding for self driving vehicles. 
Better close to the type. Close to the variable name looks like a dereference operator. In the middle looks like multiplication operator. Also close to the name is not even consistent when you have a const in the middle to declare a const pointer to int: int* const ptr; Not the same as a pointer to a const int: const int* ptr; And not the same as a const pointer to a const int: const int* const ptr; 
I have rather big projects and it works fine, the autocomplete guesses are alright, it is not as good as with typescript, but hey, it's hugely more complex than typescript. You only have to configure the C/C++ plugin (intellisense with clang) with your defines and the include path, and it works like a charm. 
Writing C++ compilers.
This was mostly an experiment, but there seems to be some coroutine interest here so I thought I would upload it for others to see
vim + gradle + gdb Or Qt creator + cmake/qmake 
It is likely that it'll generate some more code (compilers are not magic, only the most trivial cases will be proven to be equivalent). I am not sure it matters though, you could always have lints that warn you if your initializer list is not in the same order (like we have today) so that you do not accidentally end up with more code when it's not strictly needed.
&gt; Although I am considering an extension that would allow to reorder member field declarations, i.e. declare members so that it makes most sense from understanding/maintainability POV, but then reorder them for purposes of binary layout and initialization. This is something that Rust did (at the language level), the default layout is unspecified which allowed them to pack fields to avoid padding as much as possible. A simple "sorting field by descending alignment" is really efficient at that. As long as there's a way to opt-out, or finely tune it, so as to be able to avoid false-sharing, etc... then it's a really neat optimization.
I use C++ forteen.
Sorry for the late answer, so far nothing. The unary operator&lt;&lt; got moved out of the first version of the proposal. I know that Barry Revzin is working on the version 2 and will present both proposal for the next WG21 meeting, until then finger crossed.
IMO, the goal of syntactic sugar is to make the most common idiom compact and quick to use. That's the idea behind [the many ways you can use a concept](https://youtu.be/H8HplZtVGT0?t=97), which is far more explosive in terms of parsing complexity. Just make the common case easy and quick, and users are more likely to use the nice thing. If they have more complex requirements, they can just break out the more complex syntax to get more control. Either way, I'm really hoping we can get some abbreviated lambda syntax for that common use case of "just return this expression." I'm not too picky about how it looks at the other end.
asan &gt; valgrind
Looks awesome - what do you use for the UIs? I want to learn to do some futuristic UIs for myself, (in code, not by After Effects), and don't know what devs use as their API.
Ctrl+O so good
Right, so the functions that are compiled into the Boost library using libstdc++ are still declared when you're attempting to use libc++. What's happening is some inline boost code is referencing an out-of-line symbol in boost. When you link to boost it obviously doesn't contain that symbol, at least not for libc++. The version it contains is for libstdc++. For example: // Boost.h #include &lt;string&gt; void foo(std::string); // out-of-line inline void bar(std::string s) { foo(s); } // inline calls out-of-line // Boost.cpp -- Compiled with libstdc++ #include &lt;Boost.h&gt; void foo(std::string) {} // gets libstdc++ definition. // MyCode.cpp -- Compiled with libc++ #include &lt;Boost.h&gt; int main() { bar(); } // generates call to out-of-line boost function that doesn't exist. I would strongly suggest you don't sink too much time into this. It's not going to work, at least not in any way you seem to be wanting. I should reiterate that libc++ and libstdc++ types mangle differently. Ex. // libc++ namespace std { inline namespace __1 { template &lt;class ...&gt; struct string; }} // libstdc++ namespace std { /* some other versioning namespace */ template &lt;class ...&gt; struct string; } 
It looks like /u/oni-link had something wrong with antialiasing on the fonts. Ubuntu Mono looks slick though. Personally, I like the looks of Hack. https://github.com/source-foundry/Hack If you like ligatures then Fira Code is pretty cool. https://github.com/tonsky/FiraCode 
I'd love to get into vim, would you mind sharing your setup instructions/config? Also, it sounds like even though you have 3 monitors, you only have vim on one of them. Is there a way to open a "new window" in vim or have you truly found that limitation to not bother you? 
What about in the initializer of a `for` loop, admittedly much less commonly needed since C++11 range-based `for` loops: for (std::vector&lt;int&gt;::const_iterator begin = vec.begin(), end = vec.end(); begin != end; ++begin) { // ... } Incidentally this causes the pointer issue to crop up if your iterator type is a pointer, although it immediately causes a compiler error so it's not as bad as it might otherwise be.
[Although...](https://www.reddit.com/r/cpp/comments/709v0m/which_is_the_standard_way_to_place_for_pointers/dn71su4/)
&gt; which is not something you should actually ever do btw [There's an exception to every rule.](https://www.reddit.com/r/cpp/comments/709v0m/which_is_the_standard_way_to_place_for_pointers/dn71su4/)
Typically the only time I need to iterate using begin() and end() is if I plan on erasing/inserting elements as I iterate and in those cases I can't cache end() since it changes. That, or I want to iterate using a numeric index so I can use the numeric index in some other way.
And you could always init members in a correct order (with compiler warning/error being a lint), so I don't see a problem with it being stricter. Safer/faster by-default is the way to go IMHO.
Sure, I can go over my setup a bit. I've been working with vim for a few years now so this configuration has built up bit by bit over time. I initially started with this as a base: https://github.com/amix/vimrc/blob/master/vimrcs/basic.vim for some reasonable defaults. After I learned a bit, I stripped out a bunch of the stuff I wasn't using and didnt like, while adding my own hotkeys and such. As for plugins, i'm using these: * Pathogen: plugin loader (https://github.com/tpope/vim-pathogen) * ctrl-p: fuzzy search for file names and open then, modeled after the feature in sublime text (https://github.com/kien/ctrlp.vim) * minibufexpl: source code window tabs (https://github.com/fholgado/minibufexpl.vim) * nerdtree: file tree browser (https://github.com/scrooloose/nerdtree) * vim-cpp-enhanced: better code highlighting for c++ (https://github.com/octol/vim-cpp-enhanced-highlight) * tcomment: quickly comment in/out highlighted source code blocks (https://github.com/tomtom/tcomment_vim) * tagbar: view the file layout (classes, functions, members, etc) and allows you to jump to their definition in the file (https://github.com/majutsushi/tagbar) * vim-easymotion: quick and accurate jumping through text in a file with the keyboard only (https://github.com/easymotion/vim-easymotion). Admittedly, this was kind of a crutch. I'm kind of surprised how much faster I am with just the f F keys and relative line numbering. * universal-ctags: quickly jump through the project to class/function/member variable definitions. Sometimes the first result isn't the one you want (because it's not context-aware like an IDE), but theres a command you can set up to bring up a list of matches to jump to instead. I find this pretty quick for my usage. (https://github.com/universal-ctags/ctags) That pretty much covers the core of what I'm using. The rest are a few language-specific utilities (glsl highlighting, python pep-8 linter). I manage my setup with git and have my plugins registered as git submodules. So, when I need to set up on a new machine i just git clone, then run git submodule init &amp;&amp; git submodule update --recursive and I'm good to go. &gt; Also, it sounds like even though you have 3 monitors, you only have vim on one of them. Is there a way to open a "new window" in vim or have you truly found that limitation to not bother you? Yeah, my normal setup is a web browser, vim, and a terminal each running full screen on a separate monitor. Since I can fit 4 splits comfortably in the vim window, I've never really had an issue. The only time I have more is when I'm also viewing a separate project that I need to reference, which I just give it's own vim instance in another window. I definitely felt like I could have made use of more monitors than 3 when I was using Ubuntu's Unity window manager. i3wm (and tiling window managers in general, probably) is so damn efficient that I honestly feel I'm not hindered just working on 1 monitor. i3 lets you manage 9 (maybe more? i've never used more than 6) virtual screens and swap between them without even having to use the mouse. All in all, vim is a good fit if you want to make your setup fit you like a glove. If you've ever found something lacking in your IDE of choice and wished you could fix it, vim gives you tons of power to do that. It's amazing how fun coding is when you have a workflow super focused to your taste.
Just gedit and gcc/g++. My projects are all small-time.
Visual studio on windows, a version control system, a build script that gets run on a build machine, and a few thousand revisions entitled "Linux build fix"
Do you use any plugins for VS Code?
You may find [dyno](https://github.com/ldionne/dyno) interesting. It takes type erasure slightly further by allowing you to customize the underlying storage and dispatch mechanisms used.
Terminal, tmux, vim, and GCC.
Sublime Text + CMake + shell scripts. I use a Python script I've been working on that creates a module template, auto generating CMakeLists.txt, source, headers, etc...just have to add it to the build script.
Emacs, [cmake-ide](https://github.com/atilaneves/cmake-ide) (my C/C++ package for Emacs) with rtags, company and flycheck, gdb, clang
Mine is pretty similar to this list, except no zeavim (I use Cppman) and no ctrlp. Two more plugins I use constantly: * [fzf](https://github.com/junegunn/fzf), it works as a replacement of ctrlp, but you can use its fuzzy search for many more things (grep, buffers, history, etc). * [Asyncrun](https://github.com/skywind3000/asyncrun.vim) I am impressed with rtags, but it's not in my workflow yet. Also, looking forward for clangd...
[Me too!](http://www.wlandry.net/Projects/FTensor)
[Emacs](https://www.gnu.org/software/emacs/) + [waf](https://waf.io/) + [M-x gdb](https://www.gnu.org/software/emacs/manual/html_node/emacs/GDB-Graphical-Interface.html) + [xcscope](https://www.emacswiki.org/emacs/CScopeAndEmacs#toc2) + [compilation-mode](https://www.emacswiki.org/emacs/CompilationMode) running on [Debian](https://www.debian.org/) 
I write a C++ standard library. :-)
Thanks!
&gt; macro Hard pass.
You're absolutely right. But in most of the cases, you actually don't care about this extra accuracy, especially for small N. In case of big N, all the small inaccuracies will accumulate and it's quite possible that the accuracy will be pretty bad. 
I think that's only because of the scale. At the beginning, it is very small compared to the maximum and so is almost no showing and then it's going up. If you use the logarithmic scale, it does not show that bump. 
Definitely interested in your workflow. I have a friend moving to Linux dev and would prefer vscode as well.
The only thing slower than Eclipse are basically web interfaces.
At work I use C++14-ish for AAA game dev (mostly engine/tech side), and at home I use whatever C++17 draft spec in MSVC I can for my own server/engine/game stack.
It depends on how many memory allocations you have. I suspect you have quite a few. Valgrind is going to slow down your cpde because it needs to check every memory access. But it can really save your ass when you can't figure out where your segfault is.
I've yet to see libraries that don't produce any warnings at -Wall or equivalent. But yeah when it's "inlined function was removed from your code because it wasn't used" it's pretty safe to ignore usually.
Valgrind isn't a "single" software. Most people think of memcheck, the default mode, 's speed which is indeed quite slow, but the profiling tools, callgrind and cachegrind have a much smaller impact.
They both have their uses. Libstdc++'s debug mode (and some boost libraries, eg boost.multiindex) are also very useful: for instance asan will not detect if you go past size but under capacity for a std::vector since it's still technically allocated memory.
Most builds/debugging I tend to do through terminal and VSCode has an integrated one so this makes life easier. (If you use Powerline fonts you need to set the font in the vscode settings otherwise the integrated terminal will look like a garbled mess.). I tend to use multiple build configurations in parallel, each config has a separate build directory and so far I've not found an IDE that's builtin cmake integration works nicely with this workflow. The relevant plugins I have installed are below. c/c++ related ones: * MS C/C++ plugin - language support + debugging * Clang-Format - automated formatting (xaver.clang-format) * CMake - cmake language/syntax support (twxs.cmake) * CMake Tools - integrates cmake workflow into vscode, probably the nicest feature is that is tracks test pass rates. (vector-of-bool.cmake-tools) * cppcheck - static analysis (matthewferreira.cppcheck) general: * Code Spell Check - vscode doesn't have a spell checker, if you modify documentation you'll want this. (streetsidesoftware.code-spell-checker) * reStructuredText - rst language/syntax support (lextudio.restructuredtext) * LaTeX Workshop - Latex support (James-Yu.latex-workshop)
I use c++ for a rest api server on a large db serving custom GIS/Maps services, raster data and vectorial.
Great summary, thank you. Just today I was playing with how the optimizer interacts with recursive functions. In one instance, it would seg fault, with -O3 it would not.
I used to use Sublime but have since transitioned almost entirely to vscode. On a rare occasion I do have to revert back to sublime for an operation or two but this is becoming less and less frequent as vscode matures. The pace of vscode's development is impressive, it feels like a completely different editor to the versions released even a year ago.
I was talking about callgrind, which in my recollection (last used it 5+ years ago) made my program run unusably slow, I want to profile an operation in a GUI application where I have to go through some steps before I reach the point that I actually want to profile. I recently read somewhere that collection can be switched on and off so that might be a way to move forward. 
&gt;For all the Linux C++ developers on /r/cpp, what does your Linux development environment look like? I just install a stock Linux distro. No GUI. &gt;Specifically, what do you use for the IDE, debugger, etc? The IDE is the stock Linux distro. The debugger is included in the stock Linux distro. This isn't sarcasm, btw. Linux literally is a C and C++ development environment. If you really need intellisense, you can install YouCompleteMe for Vim. I don't bother with it. Editor: Vim Compiler: g++ or clang++, depending on mood Debugger: cout or gdb
&gt;That is a very interesting workflow. One question, I found that precompiling headers didn't do much for compilation speed on Linux (loading the giant header precompiled stuff took almost as long as parsing it). Can you share how you get precompiling to be worthwhile? Code using the CImg library compiles about 40% faster with precompiled headers. 
hello, author here any comments? :) do you like the attached book? I am happy to do the updates and fixes.
I'm with you on everything there, apart from using Clion as my IDE. Intel Vtune is well worth paying for, if you're a commercial user. Intel's other dynamic analysis tools have some benefits but aren't quite "no brainers" in the same way. 
Linus, is that you browsing around the /r/cpp subreddit?
It's because despite being mature, the indexer still has issues, the refactoring support is limited and doesn't really work (and often just crashes), Eclipse itself seems to get slower with every release, there's no native support for existing build systems per se, and so on. More than once, a new major release of Eclipse has come out with serious regressions that go unfixed for many months. I used it for several years and the moment a better alternative came along (Clion, despite having issues of its own), I wasn't sorry to say goodbye to CDT. 
Is that the Open Source or Commercial version?
Debian Linux 4 life. ratpoison tiling window manager. firefox with vimperator plugin. roxterm terminal emulator. vim, of course. I build my kernel, compilers, libraries and build tools from scratch (now I actually have to, for work). 
Love the honesty in the readme
GPUs.
Looks very cool... Good to see people playing with coroutines! Not sure if you are aware (or have interest) but it looks like some of the lower-level plumbing you've written has overlap with this guy's project: https://github.com/lewissbaker/cppcoro I think he's intending his library to be general-purpose (e.g., create a coroutine Task, etc) and so it might be able to be used as underpinnings by your stuff, which seems higher-level (i.e., Erlang-ish coding).
Ooh I see, thank you a lot for the info/clarification!
You're a very humble person. I loved your README.
That's most likely because of tail call elimination: if you look at [this example](https://godbolt.org/g/Q9oCHP) you can see that the tail-recursive version actually optimizes to an iterative one which means it'll behave differently with optimizations enabled.
Gentoo &amp;&amp; KDevelop. https://imgur.com/a/NIqhd For really large and complicated sources, KDevelop can be a bit unstable, but for me, with LLVM and Clang both loaded, it sits at around 1GB RAM.
Open Source, if I remember correctly the commercial version is usefull only if you create Qt applications. And it's not directly linked to the IDE, more on the modules you can use.
Clion/Kdevelop/Qt creator/Kate, gdb/lldb, ld/lld/ld gold, valgrind, gcc/clang/intel, cppcheck/PVS-Studio.
Thank you for the detailed response :)
shout out for KDevelop, best IDE I've found on linux. I use cmake build system for all my own projects, and am becoming more and more of a fan of conan for dependency management outside system packages.
Does anybody have a link to the clang bug report for the performance issue ? I can't find it.
Amusingly, this post "outed me" at work, because there apparently can't be two such people ;)
&gt; As long as there's a way to opt-out Rust has a `#[repr(...)]` attribute that allows you manually set the representation of a type. For example `#[repr(C)]` uses the same representation as C where the fields are stored in order (e.g. this allows FFI or manually grouping "hot" and "cold" fields together), but also `#[repr(u8)]` which can be used to set the representation of an `enum`, or `#[repr(simd)]` which can be used to set the representation of tuple structs, e.g., `struct(f32, f32, f32, f32)`.
You shouldn't need the clang format plugin. The C/C++ plugin has clang-format support for full files or parts of files built in. You just need to set "C_Cpp.clang_format_path".
Have you tested zapcc? That might give you some boost too.
Thats one less plugin to worry about now
Not a direct answer, but FWIW your `base` looks strange to me... Changing that also makes gcc compile, without changes to `test` or `foo`: https://godbolt.org/g/hBZWqQ
Thanks :) The UI is done "by hand", using Metal API and OpenGL (lately). I'm just applying techniques that have been popularised by games (scene graphs), and adding a few shader tricks (such as the glow effects) myself. It's really nice using the GPU, you can afford to be quite luxurious overdraw even on retina :)
At work, very seldom, only when interfacing native code within Java (including Android) and .NET/UWP projects. We left the realm of pure C++ applications about 10 years ago. Outside work, for fun, I enjoy keeping up with the language's evolution, since I know it since the C++ARM days.
Thank you, that was a stupid mistake. I should have caught that when I condensed the minimal example. 
Yes, pascal is the future. (you know it's true)
That still doesn't explain why gcc is giving an error though. This is the minimal case I can produce where gcc fails but icc and clang compiles without error: https://godbolt.org/g/BR7s3V
`co_await` is cancer, Nat Goodspeed explains this in great detail at [CppCon](https://www.youtube.com/watch?v=e-NUmyBou8Q). Use stackful coroutines (Boost.Coroutine2, Boost.Fiber or even `CreateFiberEx` on Windows), do not use stackless.
Not a totally fair comparison between C++ and Cuda, seeing as the `Our C++` method uses double, and the Cuda method uses floats (eigen is also double precision). I assume numpy is double precision too? Still an interesting article! Would also be interesting to compare to the same algorithm in parallel C++, rather than a serial C++ comparison with a parallel GPU algorithm
I work on a web framework ([Wt](https://www.webtoolkit.eu/wt)). We have our own niche, web development with C++ turns out not to be as crazy as you might initially think.
Interesting stuff. For me it was about learning a new language feature, but if I try extend it (which I might) it'd start to make sense to build on others. One thing I've noticed is that by design coroutines are pretty invasive. Not only do you need to have all your return types using a similar sort of interface, you need to have something right at the top of the stack pumping some event queue/processing io and able to resume them. And then you need to probably pass this stuff all the way to the top of the stack. I don't think theres a way around it, but it might (without having tried it) make it difficult to incorporate new libraries as you have to plug them in all over the place 
Yes indeed, this library is awesome, I forgot to mention it in my article! It inspired me in my work. Thank you for working on this kind of things, it really opens new horizons.
Eric calls it "pretty easy". How can this mess of co_await/co_yield, generators (that you have to implement yourself), "for co_await", future_t, async ranges etc be "easy"? Just look at the sheer number of new constructs that have to be introduced to make these stackless coroutines work. In comparison, the boost::coroutine2 library has only a couple constructs: coroutine&lt;&gt;::push_type and coroutine&lt;&gt;::pull_type (http://www.boost.org/doc/libs/1_65_1/libs/coroutine2/doc/html/coroutine2/coroutine/asymmetric.html). All existing algorithms, ranges, for loops, etc just work. This is what I call easy.
Bad title - closures do not need SBO, `std::function` does.
Trying to understand here. so looking at the overloaded definition of `foo`, compiler has two options when choosing the base class of `bar`. The first overload is `foo&lt;int, int&gt;` which is a just an empty struct. The second overload requires `foo&lt;int, int&gt;` to be expanded to the base class hierarchy. (and I guess the second is better match because it allows `T` to be assigned to a type? Is this correct reasoning?)
i want to try this out.
Thanks for noticing this! I reran the C++ code with `float` and it doesn't change the numbers really. I agree, it would be interesting to try out with multithreaded C++, maybe even with the `reduce` function from the C++17 parallelism TS/library.
Oh, I'm glad you found it useful. Thanks for helping spread the word about type erasure, we need more of it and less inheritance :-).
Having tried Boost.Coroutine (the first version) awhile ago, I expected Boost.Coroutine2 performance to be quite bad. Surprisingly, it's very *very* good. The coroutine switch latency is only 26ns (nanoseconds) according to the author of the library, and I measured it as 20ns on my machine. This kind of performance makes the choice between stackless and stackful coroutines a no brainer - just use stackful.
Loved reading it! I have been playing with CUDA recently and this was very a interesting read to see someone write a clustering technique in vanilla C++. 
[eNodeB](https://en.wikipedia.org/wiki/EnodeB) Basically what makes your smartphone not be a brick.
&gt; with printf replaced by std::cout And very inconsistent at that. One line uses "\n" and one std::endl ( != "\n"). The loop uses printf, which also reminded me to check if sync with stdio is disabled, which it isn't.
I'd say the real reason it is not totally fair is because it is running on different hardware, making meaningful comparison difficult... 
&gt; eigen is also double precision Eigen is whatever type you want (that supports the required arithmetic and conversion ops).
Anybody use this in production? (besides its authors)
Some weeks ago I was helping a coworker who does embedded stuff. Their compiler was not fully C++11 compliant bc it didn't ship a C++11 standard library, only a 98 one. The feature list of the compiler cited lambdas as "partially supported", just because std::function is not implemented. I didn't know whether to laugh or cry.
Was specifically taking about in the code OP provided. 
Read a good book. And then another. 
I'm using it to develop distributed storage systems.
Programming is something that you have to practice. Most of your learning will be on your own time and self directed. Not excusing your teacher if they are being lazy, but in the end this is probably the best thing for your skills as a programmer. Fortunately, there are many online resources to help you to get direction. Code Academy, Coursera, MIT, Khan Academy all have good beginners materials that you can use to figure out what problems to try out, but at the end of the day the only way to learn is to sit down and write a bunch of programs. 
Same
I am already using fzf in my zsh setup. Maybe it is time to expand it to vim. Never heard of clangd. What is its purpose? I Love YouCompleteMe on Linux. I tried to get it running on Windows Server with gVim and I have to say it was very difficult. We don't use cMake at my workplace and finding all the needed include directories and defines from our perl based build system was pretty nerve wrecking. In the end I seem to have a working solution but autocompletion is super slow. I have to wait several seconds. Maybe I should have a look at tags.
For a beginner, I recommend a [book](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) because it's likely to give you a good overview. My opinion: when in doubt, read Stroustrup. Many web pages address specific topics, sometimes in exhaustive detail; and if you're a beginner, you have no idea if they apply to you. As a result, they will be less helpful.
Fair enough! Cheers to making some awesome stuff. 
Ditto -- for at least 9 years. The early years (before Galileo) were rough going. But certainly better than an editor. The releases the last few years have been *really* good. For simple projects I just use Eclipse builder. Otherwise Cmake for newer stuff and GNU make for older projects. Using GCC 5, 6, &amp; 7 (for x86, ARM and AVR). The nice thing about Eclipse for me is I can go from C++ application or firmware development, to Python, to Java (Android apps) to database development, all in the same tool. Also, many of the ARM MCU expert systems are based on Eclipse and/or have Eclipse plugins. It's also easy to go from debugging a networked service to an embedded system using the same IDE. I'm developing on both Fedora (latest) and CentOS (6 &amp; 7). I've been using RPM-based distros since Red Hat 3.0.3 (Picasso).
I agree, but don't start with Stroustrup's C++ programming language. Although it is an excellent book, I think it is not suitable for beginners.
nope, on an older version I was struggling with the auto-layout not working quite as nice as I'd want. Considering the web-standard it has to work with, results are quite impressive, though.
I didn't know that, I'll check. Thanks.
We generally recommend that our users familiarize themselves with HTML and CSS and use WTemplates these days, although I do wonder in what way you struggled with the auto-layout. Was it bugged, or was it just too difficult to configure it the way that you wanted?
I found astyle more for my preference
Our customers do. You can see some of the users of Wt at the [bottom of the index page](https://www.webtoolkit.eu/wt/). Some are using JWt (Noesis, Brussels Expo and RIVM), but the others are using Wt.
I worked around this by building Boost with layout=versioned for both the gcc and clang toolsets, linking libc++ and c++abi for the latter. Took some CMake-fu to correctly marshall the various libs to my own program, depending on the active compiler, but in the end it all works smoothly. Thanks anyway for the detailed help.
Good choice moving away from Boost, especially shit like Signals. The stack traces and debugging for those things was like digging through feces.
I'm writing a bot for World of Warcraft in C++ and the combat rotation scripting is in Lua.
The latter, I'm sure it was just me being spoiled by Qt, which always seems to do the right thing. For someone with little CSS knowledge, Wt does allow me to do things otherwise only possible with a native app, even if I probably don't make that most of it
1. Eigen has [tensors](https://bitbucket.org/eigen/eigen/src/9b065de03d016d802a25366ff5f0055df6318121/unsupported/Eigen/CXX11/src/Tensor/README.md?at=default). 2. `auto distance = ... ` is very wrong. `auto` plays badly with expression templates. See [here](http://eigen.tuxfamily.org/dox-devel/TopicPitfalls.html) 3. OP mixes MatrixXd abd ArrayXd. It would be better to stick to one. I don't have time now to go deeper.
Yes. I have no relation to the authors. Do you have a question about it?
No, he does not explain why `co_await` is cancer. Also using stackless coroutines for simple yielding coroutines (where you don't exactly need suspend-down) might be unefficient, with stackless coroutines you basically avoid heap allocation for the stack.
Mixing underlying types would be painful for type deduction in certain areas, and you probably wouldn't want implicit narrowing casts. I wouldn't worry that much about the performance of the floats vs. doubles though because the compile-time conversion factors offered by units are going to save you a lot more cycles than using raw floats except for the most trivial conversions. I've personally used units on very large scientific datasets and seen performance improvements.
It's something I want to support, and I think with a (planned) change in the way base dimensions are handled that it will be possible. Some of my users have told me they are doing limited things with natural numbers right now, but you wouldn't be able to convert between SI and natural until at least v3.
Thanks for the feedback. I do mention that Eigen has Tensors, but they didn't seem to have the same API as Matrices, for example I see no way of getting the argmin. There seem to be a lot of useful functions in the TensorFlow library that aren't in Eigen itself. (2) is a great catch, thank you. I reran the experiment and Eigen code is indeed 40% faster than before. I'll update my post and repo. Also switched to just Arrays. I'd be grateful if you have any more suggestions on how to make the Eigen code faster :)
My university teaches their intro classes in c++. It's actually pretty awesome and really gets you into the nitty-gritty.
Ease of use. Both libraries set out to do the same thing and have the same basic overall features, although since units leverages c++14 it's a bit more powerful than boost units and can do some math like exponential temperature conversions that I don't think boost::units can handle. Boost::units also has a lot of dependencies on mpl, etc, so if you don't already have a boost dependency it can be a barrier to bring in to some projects. Some other differences: - Units has a minimal, natural language syntax and very little boilerplate. - For most applications, library users won't need to write any templates. - Conversions all happen implicitely so you can mix and match units safely without casts everywhere. - There are no unit systems. All units (e.g. SI, Imperial, Ancient) are treated as first-class citizens. - All units are defined with rational conversion factors (except for pi obviously), so there's no loss of precision no matter how long your conversion chain is. - Any unit can be defined in terms of any other unit, not just a base SI unit. - Almost all cmath functions (including c++11/14) have unit overloads. - constexpr/noexcept support for everything that makes sense. - supports build systems including cmake, vcpkg, and buckaroo,or just copying the single required header (I recommend the build systems though because it builds a lot faster w/ certain compile options) - Has a _simple_ getting started guide. - Actively developed and improved.
&gt;Linus, is that you browsing around the /r/cpp subreddit? Hah, thanks, but no. I've never submitted any of my kernel patches to the main line.
If I understand your question, then tensor just has an [argmin method](https://bitbucket.org/eigen/eigen/src/1f0f8337c029a3a8f2720bfcabbed13579bc9093/unsupported/Eigen/CXX11/src/Tensor/TensorBase.h?at=default&amp;fileviewer=file-view-default#TensorBase.h-633). 
Mind sharing how such a target would be implemented?
Ah, well, I guess it's a documentation issue then. The API does seem quite complete looking at what's in that file. Thanks for clarifying!
So the obvious question: How does it compare to [cxx-prettyprint](http://louisdx.github.io/cxx-prettyprint/)?
What compiler and standard library did you use? At least msvc and I believe also libc++ provide an implementation of std:: function with SBO that is big enough to hold two ints.
Why does the first example of RVO not working - "Deciding on Instance at Runtime" - not work? Snitch CreateSnitch(bool runtime_condition) { Snitch a, b; if (runtime_condition) { return a; } else { return b; } } int main() { Snitch snitch = CreateSnitch(true); } Aren't `a` and `b` of the same size? If the calling site has memory reserved for a function's return type normally, why can't either `a` or `b` fit into that in this case?
**Company:** Hawksoft **Type:** Full time **Description:** Hawksoft is a creator, seller and supporter of a SaaS CRM for Independent Insurance Agencies throughout the United States. We are looking for 2 Virtual C++ Developers to join our team. **Location:** Canby OR, Just South of Portland OR. **Remote:** We do not offer remote work at this time. **Visa Sponsorship:** We do not sponsor Visas. **Technologies:** • Visual C++ and MFC • C#/.NET 4.0 • Database/SQL • Web Development and Web Services experience a plus • Additional technologies desired: WPF, CSS, JavaScript **Contact:** https://hawksoftinc.applicantpro.com/jobs/ or email HR@hawksoft.com 
I think that what you mean is that you do not see why the compiler should support out-of-order aggregate initialization. That is: struct Point { int x, y; }; int main() { Point { .y = 2, .x = 3 }; } The problem of enforcing in-order aggregate initialization is that it makes the order of elements matter. Ideally you'd like to be able to add new members (with a default value) and shuffle members around (to avoid padding, pack hot/cold members together, ...) without having to chase after all clients and patch them up.
I just started a wt project. I needed a webserver with the lowest possible power use, and all C++ seem like a good idea. Is there a debian or ubuntu PPA for this?
This is no longer used in C++ unless you don't understand new features. 
Both 'a' and 'b' are initialized in their declaration. They can't both be initialized into the same memory provided by the caller.
That... makes a lot of sense. Thanks!
I'm not the best at c++, on chapter 5 cpp primer and ch 4 exercises [no. 5] in practice and principles using c++. But from what I understand, which is a lot so far, and what I can see, your code looks very impressive, and it's neat and easy to read. I do have python and java experience, but I'm loving c++ much more and how it's written, I love getting into the details of every objective I'm tasked till I achieve my goal. It's much easier then python to understand what's actually going on in the code. I hate the little amounts detail python and java provides in the code, less the latter, but I feel that way none the less. It's just not fun programming if your not really "programming", and to me that means to get the detail of the system that C++ provides you. Great code :) I'm hoping to lean how to write windows functions once I get to chapter 7 of both books I'm using. 
Well, you can use something like factory (i.e. `Point().y(2).x(3)...`), but I see what you mean. Though in C/C++ usually "silent" ABI-breaking shenanigans (like member addition/reordering) can require some potential code changes anyway. 
ABI-breakage can exist but is generally limited, and hopefully guarded against (with `static_assert`, `assert` or unit-tests). And yes, the aggregate initialization is not necessary, just a convenient short-hand.
Yep. I use it for some data analysis webapps that have a lot of underlying complex calculations (hence the c++). One thing I've done for applications where data was stored/provided locally (from a physical detector, email, etc) was to make a WebView wrapper (native, Atom, or Qt) to make iOS, Android and desktop standalone versions that dont required internet; its worked out quite well so far. Other than the web traffic being a little "chatty" and the occasional struggle with the layout system, which is understandable given what I try to do with it sometimes, I'm pretty happy with Wt. If you use Wt, I would recommend not being shy about using other 3rd party JS libraries, or writing your own JS to customize things. For example, I use D3 for charting in some places rather than the built in capabilities, or I use JS to customize default widget behaviour or rendering.
&gt;Yeah so I guess that's a pretty natural idea to make it become std::array. I do think it'd be nice if backwards compatibility could be preserved. &gt;But you would also lose a lot with this change. Like, every C library that uses string literals would break, and you could no longer compile it in C++ mode. Not necessarily? I think we'd just need a built-in conversion operator to automatically convert array&lt;char&gt; to char *. &gt;Also, again a lot of code would break, like, anyone that's using C standard library functions with string literals, in their C++ code. All that stuff, atoi, strchr, etc.. It'd obviously be better to just do a s.length() (or s.size()) but if we had an implicit conversion operator, then all these functions would work as well. Thoughts?
konsole/vim/clion/clang/gcc/git
You're probably over-thinking it :-) valgrind: all valgrind --leak-check=full ${OUTPUTBINARY} args 
Thanks for the detailed list! I wonder... have you thought about proposing your library to boost? units2, units_modern or similar with no dependencies? Such a pity that the: &gt; Actively developed and improved. is not a boost library.
Have a look here: [clangd](https://clang.llvm.org/extra/clangd.html).
If I remember correctly this website was ugly as a sin until recently? 
From my LinkedIn feed. I didn't watch the video, but as advertised, the pictured code looks over my head.
Since I am a backend dev I am not familiar with this FE issue. I posted your message to the FE dev list and got this response: "I don’t know what 15.3.3 is (and 15.3 is relatively old) but using today’s build I see that code does indeed compile – at least I think it does – it is also hard to tell when you aren’t provided with a complete example."
Man, next week is going to be fun. 
FWIW, the numbers I measured on my machine per suspend-resume round-trip: * Boost.Coroutine2: 34ns/125cycles * CO2: 3ns/12cycles * CoroutineTS: 3ns/10cycles
I'm a university student who's only experience with C++ has been from my intro to programming courses (and also data structures and algorithms) but that has also been learning web development on the side. I just wanted to say thank you for this comment because I was trying to decipher what the motivation for making a web server in C++ would be, especially when there are languages like PHP already built to run servers and frameworks like Python's Django framework. But I can already see now how C++ would be an excellent choice for a server to try to use the lowest possible power (I'm sure memory management would be another motivation if a server needs to be incredibly small). 
Arch Linux + Sublime Text 3 + Clang + Valgrind + plain GDB in TUI mode with custom Python commands
MSVCs will hold 2 std strings, which in turn hold 2 or 3 pointers (I forget).
 Because: void foo(int x, int y); void foo(int y, int x); are compatible declarations. Depending on what last was seen, `foo( x=3, y=4 )` does ... different things?
You can scale with power consumption, and even then GPUs are going to win for highly parallel cases.
Hello, it's 2017 and my object oriented programming language doesn't provide basic logical string operations and has a 1970s locale paradigm
Not to mention that it allows thing like smart pointer to be written extremely succinctly. I'm always saddened by this when writing C# code and having use use `.Value` in places where C++ would use `-&gt;`.
On a mildly related note, How do you even write `T(x)` where T is `unsigned char`?
Very interesting writeup, however a lot of what you are proposing is to add more complicated syntax. Don't we have enough of that already?
Modules TS deals with the header problem, so it's not that bad. I don't understand why you think `var` is better than `auto`? I don't think being able to be written just with the left hand is a good criteria to be considered when selecting keywords. I really agree that the `new` operator should return some sort of smart pointer like `unique_ptr`, but if it did so, how do you plan to implement something like `shared_ptr`? boost's `lexical_cast` does what you describe with `toString` Runtime reflection? I doubt it. It just needs so much metadata to be put in the executable. Compile time reflection is definitely essential though. And runtime reflection can be somewhat achieved in an opt in manner in library if we had compile time reflection. Enums is about the same, needs metadata in the executable. Bounds checking for arrays just doesn't play nice with C++. If the simple array syntax instantiated an STL class, how would you use arrays in implementations without a proper STL, like arduino? Json is quite easily provided with a library, I don't see why we should include Json but say not Yaml or XML? I agree with your first tuple argument but not the second. You can't have `auto x = tuple[0];` since the type needs to be determined at compile time. If you enforce the index to be a compile time entity, than that could be doable, even in a library today. I'm definitely on the side that C++ should get more modern and simple, but I think behind (almost) every stupid C++ quirk, there is actually a legitimate reason. 
As someone learning C++ with a C background - thank you. However, I feel part of the trouble picking up C++ is overloaded syntax. Some of the proposed changes might make this worse. Using -&gt; for lambdas, for example, would overload the pointer reference operator to have 2 meanings with arguably no relation between their usage.
Is that why everyone implements their own, slightly incompatible with each other string implementation?
&gt;**no work** is **always** going to be faster than **some work** Maybe, but more C++ code does not always imply more work. 
It is literally the reason.
I've many issues with the items here, but I particularly like headers! Let me explain; İn Java you don't need headers because everything is essentially a pointer in Java. So, in C++ parlance, whenever you see a reference, insert a forward declaration just before it and you're good. Another example is Haskell; There, the compiler does similar thing to C++, so it can't just pretend everything is "forward declare"d so in Haskell, circular dependencies between modules is a huge pain in the back-end. I love how in C++ you're able to do crazy things with templates AND you're able to solve circular dependencies easily. You just need to use your wetware for a short while, but it's free anyway. İn conclusion, I'm annoyed by people complaining about the header situation, without giving a moment's thought about what that buys us. They complain as if other languages have just solved the issue without sacrificing anything.
&gt; If you enforce the index to be a compile time entity, than that could be doable, even in a library today. Boost.Hana does exactly this, i.e. `auto x = tuple[0_c];` is usual.
The problem I had with cpp when O played with it in the early 200s wat how hostile it was against using libraries. Getting even basic external libs to link was a hassle if not impossible. There still is no module system or package manager afaik?
The common themes I see here are an idealistic view that has zero chance of happening and lack of research. You want to completely break everyone's code. I love breaking code, but it's not going to happen, end of story. Having a mass divide of existing code and new code is unhealthy. Libraries would basically need to be rewritten. In addition, the syntax changes are not fully thought through. There are so many consequences to new syntax, as you can see from many papers proposing language changes. Modules, coroutines, reflection? These are all existing TSes. Tons of *volunteer work* has gone into them, and they've been hot topics for years and years. It sounds like you don't know they exist. Speaking of which, there's a proposal for abbreviated lambas. There have been an insane number of discussions and proposals for named parameters. There's a proposal for some nice lifetime stuff. There's a proposal for metaclasses on top of the reflection TS. There are proposals for better tuples and related things. There have been many discussions on a standard package format/manager. Heck, we already have `enum class`, which is one of the things you were complaining about not having. All of what I mentioned is publicly available online. Tons of discussions. Many papers. Current proposals and TSes. I highly suggest reading previous discussions related to things you want, because they've been brought up time and time again. By the way, casts are verbose for a reason. C-style casts already have compiler checks. The problem is that they do too much, don't stick out as something to read extra carefully, and aren't easily greppable. When I see a `dynamic_cast`, I know something suspicious is going on. You also have a baseless claim that programmers enjoy the C syntax. Finally, what can we do? If you want anything to change, you're going to have to write papers, just like everyone else does. You're also going to have to provide meaningful motivation and strong arguments for every change, including the consequences.
I'm excited that C++ is getting ranges and modules. 
&gt; There still is no module system That's coming. &gt; or package manager There are multiple, such as [Conan](https://conan.io/) and [Buckaroo](https://buckaroo.pm/). On Linux, you normally use your package manager. I personally usually use `git submodule`, as it's fairly easy to use.
To write a Rust compiler (http://github.com/thepowersgang/mrustc)
&gt; basic logical string operations What, you want JavaScript semantics in c++?
There's nothing "JavaScript" about segmenting, substring replacement, or stripping whitespace. All of which are really easy to give subtle bugs or make very slow. And you're going to have to do at least one of them if your program uses text in nontrivial ways. Reminds me of how Go refused to implement max/min and all of the boilerplate examples people posted in response to requests for it were subtly wrong.
&gt; I think we'd just need a built-in conversion operator to automatically convert array&lt;char&gt; to char *. Are we not back where we started then though? Because `char *` would still have conversion to `bool`.
What exactly does JavaScript semantics have to do with string operations?
You have to use `strtok` otherwise you are JavaScript programmer. Patrician method of splitting strings coming through. #include &lt;stdio.h&gt; #include &lt;string.h&gt; int main() { char str[] = "JS programmers - when will they learn?"; char* pch; printf("Splitting string \"%s\" into tokens:\n", str); pch = strtok(str, " ,.-"); while (pch != NULL) { printf("%s\n", pch); pch = strtok(NULL, " ,.-"); } return 0; } 
&gt; Maybe, but more C++ code does not always imply more work. I understand that. But in this example, it's a situation where using the C++ abstraction *is* going to cause more work to be performed (unless there is some very fancy compiler optimisation , which is the point of this thread). we are talking about an implied operation - a destructor call, which must check if an object is in an *empty* state, versus **eliding that call**, when you know for a fact that a previous operation *put it in en empty state*. The maximum possible optimisation will even elide using any memory or register for the object in question.(because 'putting the object in the empty state' isn't even necasqry.. just take the pointers and forget the original) . This behaviour has been demonstrated in Rust, so we know it's possible (beyond the abstract logic I present here) To rely on C++ abstractions to compile efficiently, we need a smart compiler that can spot these opportunities. Otherwise *you'd have to drop back to raw pointers to get the most efficient code* (in this specific example, handing over the ownership of an object, and forgetting the original variable altogether). If we can't count on the compiler to do this, then we have a gap in the language that needs to be filled , to match Rust: a new kind of 'destructive move' to complement the existing one. (in it's low level 'intrinsics', rust does also provide such a mechanism , https://doc.rust-lang.org/std/mem/fn.forget.html, if there are any scenarios beyond what they planned. A 'destructive move' in c++ would have to use this 'forget', and flag that the variable is no longer useable).
The bottom line here is you don't want C++. You don't know what makes C++ different than other languages. You don't know why people are using C++. You don't know what features C++ already has, or why. And you don't know what C++ has been working on for years or decades. Just go use rust or go -- they really are very fine languages. There's a lot of legitimate complaint about many parts of C++, but everyone who understands C++ is well aware of them and working to fix them as best they can. You seem to think you're the first one to notice.
If you want to write C#, use C#. It's what you're describing. I kinda feel like you actually don't understand the language you want to completely replace with an incompatible doppleganger. Your proposals range from no-benefit bikeshedding ('var' instead of 'auto') to things that are already being standardised (rtti, and honestly C++ doesn't need reflection nearly as much as other languages because it has actually functioning metaprogramming features and multiple inheritance) to things that already exist (the C++ dictionary is called 'map') References to 'industry standard' are not exactly compelling. Outside the C++ universe it's standard to require ludicrous hoop-jumping to do trivial metaprogramming because unrestricted templates are apparently too hard for programmers to understand. It's apparently standard for languages to use UTF-16, the worst character encoding ever standardised. It's standard to not have reliable object lifetimes, requiring multiple extraneous language features to do trivial cleanup work. Etc. Etc. I'll take the ability to shoot myself in the foot over a padded straitjacket any day.
&gt; By default (x) → { code; } should translate to [=](var x) → var { a thing }. [Abbreviated Lambdas for Fun and Profit](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0573r1.html) &gt; Template syntax should be reduced to &lt;T&gt; added to the function or class. I really wonder how can you deal with non-type template parameters and partial specialization using that syntax. And template templates parameters? Other languages can afford that syntax because they lack these features. Also, concepts are official! I want to constrain my template classes like that: `template&lt;Container T&gt; struct Foo{};`. Template parameters have different kinds. Just as function parameters, they need to have a type (a kind) specified. If you have an idea to fit all that into a simpler syntax, you're welcome! Also, an abbreviated syntax for template declaration + concepts was [proposed](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3878.pdf), but then [removed](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0696r0.html). It might be added back in future revisions. &gt; Tuples should be created by syntax akin to: var tup = (1,2,4,5) In C++17, tuples are declared like that: std::tuple tup{1, 2, 4, 5}; Is this still unfriendly? I love that syntax. Although, language level tuple might be useful, I think better handling of parameter packs would be more useful. &gt; Tuples should have feature parity with arrays, except for being immutable. What?? I mutate my tuples all the time! Why would you make them const only? You're doing too much python I think. Forcing immutability for tuples is a limitation IMO, especially if your tuple contains move only types. &gt; Accessing those tuples: var a = tup[0]; For that, `std::integral_constant` should be deductible from an integer literal. But again, if the language don't do it for us, we can always ship it [as a library](http://www.boost.org/doc/libs/1_65_1/libs/hana/doc/html/index.html#tutorial-quickstart). &gt; I should be able to set string values in class member: class Dog { var Name = “Woofy”; }; Do you mean this? (c++11) struct Dog { std::string name = "Woofy"; }; &gt; When I write var name = “dog”, the compiler should auto gen a keyword lookup file. I can then go through and specify all the different languages I want to support, and when selected by the STL, those keywords instances of “dog” will be replaced with the localized word. The language don't need to implement that. A [good localization library](http://www.boost.org/doc/libs/master/libs/locale/doc/html/messages_formatting.html) is probably what you need. &gt; Allowing the user to write var str = “%d Bananas” &lt;&lt; (5) is really handy. About string formatting, yeah, a better support for that should be in the standard library, but not as a language feature. &gt; Named and variable length parameters We will get them for struct at least, but still don't permit reorder. You can receive struct as function parameter. It will allow you named arguments, and passing struct is much better than passing ints and strings anyway. For variable length parameters, use variadic templates. Again, a C++11 feature. &gt; Python nailed this behavior. The yield/for interaction are exactly the correct model C++ needs. I think C++ needs a way to implement the yield/for behaviors. That way, new kind of coroutines never seen in other languages can be implemented and used. C++ programmers usually prefer being able to implements their favourite idiom instead of the language implementing them. &gt; and a foreach ( var x : co-routine ) It's been six year we have that: `for (auto&amp;&amp; x : range)`. &gt; C++ needs to provide detailed reflections. indeed. &gt; Run time reflection Ugh no! compile time reflection please! &gt; Class initialization through a string name also needs to be implemented. Initialize.Create&lt;BaseClass&gt;(“MyClass”) where MyClass extends BaseClass I don't quite understand it's use. What if `MyClass` is not default constructible? Anyway, with good reflection, I'm pretty sure you can implement a factory automatically. Give the poor standard library implementers a rest! Also, I would really recommend you implement it yourself, especially if you have reflection. This is so a specific use case, and it might not even be applicable in some cases. &gt; Meta classes are needed, not sure what else to say there. Agreed! &gt; The compiler should create this info at compile time. No. You should use available info at compile time. &gt; Hopefully it would go without saying, the syntax to accomplish this needs to be brief. Are you looking for [this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0590r0.pdf)? &gt; Arrays is C++ should be safe by providing bounds checking and all the typical helper functions. `.at(i)` throws if out of range. Use it when needed, but by default, the fast, unchecked one should be used. &gt; When a user creates an array, it should be a STL class, not pointer math. `std::vector` for heap, `std::array` for stack. Only you can stop yourself from doing pointer maths. &gt; var str = “Run “ &lt;&lt; 5 &lt;&lt; “ times”; You're close! (c++11) `auto str = "Run" + std::to_string(5) + " times"` &gt; Enums revamp All issues mentioned in that paragraph are solved with static reflection: `$my_enum.count()` &gt; Provide a way to attach symbols to the reflection system which can be accessed during run-time. No no no! compile time! But yeah, attaching metadata to any reflectable symbols could come very handy. I have some very nice use cases. I agree with you in that case. &gt; Primitive helpers Non-member functions are your friend: `std::to_string(4)`. &gt; Provide common names for all similar actions inside the STL. If dictionaries, arrays, and vectors all provide a “search” functionality, ensure it is called search or find in all different implements. Read about the range-v3 library. I think you'll really like it, and it's headed for standardization. &gt; Json rules the world. C++ should support the json format of data, which is stored into a dictionary. Again, why add it to the language when you can ship it as [a library](https://github.com/nlohmann/json)? &gt; Community owned package manager [build2](https://build2.org/) is our hope. Although [modern cmake make a pretty decent job](https://www.youtube.com/watch?v=bsXLMQ6WgIk). &gt; Header files You mean [modules](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0142r0.pdf)? They enable [writing code like that](https://schneide.wordpress.com/2017/07/09/c-modules-example/). &gt; Breaking old code compatibility IS okay Not at the language level. But one day, with a proper module system, developing a new textual binding for the language may be possible. Also, [the standard library already introduced breaking changes](http://en.cppreference.com/w/cpp/memory/auto_ptr). This is another argument for shipping feature as library. You can remove it in later standard revision, and legacy code can be provided with an alternative implementation if needed. &gt; Community owned ORM and web framework [Wt4](https://www.webtoolkit.eu/wt/) was released just yesterday! But if you want some cool framework that uses all the most modern idioms and exposes feature parity with Django, maybe you should start it! But again, reflection might be needed. Check [this talk](https://www.youtube.com/watch?v=75aUjcYr6vE) and [this library](http://www.codesynthesis.com/products/odb/) for databases. &gt; There are many many more features the STLv2 needs to provide but here is an example. Well, all these points already exist, and are pretty friendly, especially when used with ranges: - Array stack allocated --&gt; `std::array` - Array heap allocated --&gt; `std::unique_ptr&lt;T[]&gt;` - Friendly tuples *(with class template argument deduction, like above)* - Vector (do I need to explain those four?) - String - Stack - Queue - Sort --&gt; `#include &lt;algorithm&gt;` or use range-v3 - Regex --&gt; available since C++11 - Random --&gt; available since C++11 - Mutexs --&gt; available since C++11 Also, `std::filesystem` is part of C++17. Also, C++ don't need Memcache in any way. Tcp, Http/Https are coming (maybe) to C++20 with networking ts. &gt; What can we do? Searching for already available solutions is a must. Also, [stop teaching C when teaching C++](https://www.youtube.com/watch?v=YnWhqhNdYyk). ## Conclusion The C++ committee is doing a lot of efforts to introduce further simplifications and enable new idioms. Even if there are feature that takes some time to be available, a large blocker remains for new feature adoption: *users*. You mentioned a lot of feature in regards of arrays, stl and fancy way to juggle with containers. But most of these feature are already available either in the standard library or in standalone libraries, like range-v3. Nevertheless, I agree with a lot of these points. Things like type introspection, metaclasses, friendlier syntax for templates, modules and much more is needed, but are already in the way to be standardized. And even though I agree with a lot of feature you think should be available, but I mostly think they should be shipped as library instead of language feature. A lot of tool you needed already exist in the form of library. Use them! Also, a lot of modern feature a begging for you to be used. A lot of those links I provided you in this reply was found doing quick research. More solution is at your reach than you think, and C++ is in a better shape than you might thought! There may be other points to tackle, but I've done way enough for a sane person. Sorry for scrambling the order of the quotes.
&gt; When a user creates an array, it should be a STL class, not pointer math. No thank you, I don't want to lug around an STL implementation just to use arrays. Besides, there is std::array in the STL if you are going to use the STL anyway.
How does it comparable with other implementations, e.g. listed in https://github.com/jamboree/CxxFunctionBenchmark ? 
&gt; Are we not back where we started then though? Because char * would still have conversion to bool. Isn't there a one-step limit for conversions in C++? Or is that only for non-basic types? In other words if there is a constructor for Foo that takes a Bar, you can pass a Bar to a function that expects a Foo. But you can't pass something that would construct Bar, if my C++ trivia knowledge holds.
Btw, your new website is slow as hell, even just simple scrolling. Please specify particular projects/details how each costumer used Wt. Saying that someone from Philips used Wt says absolutely nothing. How is Dbo licensing now? I remember it had prohibitive/proprietary license in the past.
It is the opposite actually - it is ugly and unusable (unscrollable) at the moment.
Maybe. I know for certain it is at least big enough for one string, which is afaik even bigger than 3 pointers, thanks to extra SSO buffer space (I vaguely recall sizeof(string) == 32 on x64). In any case, holding a lambda with 2 ints would definitely not require any dynamic memory allocation. Hence my question.
You can also try this if you can afford to have Qt as dependency: http://stefanfrings.de/qtwebapp/index-en.html I have it running in a Orange Pi Lite. For me it is the easiest setup I found.
ODB uses 'dark magic' - its own precompiler. That's why it confuses me. But its interface is great. C++ has it's own precompiler called `preprocessor` that processes C macros, Qt has its own precompiler called MOC (meta-object compiler). And what I cannot understand which precompiler is primary? I mean is MOC must process classes first and ODB - second? Or reverse? And what about preprocessor? Maybe we need to know it from C++ standard? Oh standard knows nothing about foreign precompilers. Yes it is a dark magic. ODB is a nice lib but is have zero chance of becoming a part of C++ standard one day. But sqlite_orm has cause it uses pure C++ and no macros.
Strange that it's slow for you. Are you using a particular operating system or browser? Are you on a slow connection? As far as I know, Wt::Dbo has been GPL-licensed from the start, just like Wt. Proprietary licensing is only required for those who want to use Wt or Wt::Dbo outside of the terms of the GPL.
This has been a good laugh
I felt "I want C#" from them too. It felt like stuff a Unity/Web Developer would say after trying to learn C++ from C#/JavaScript and missing their garbage collector. "industry standard" is definitely a buzzword used in the game development scene so I just got that smell. One thing I do agree with is that legacy backwards compatibility can be crippling some parts of C++ from moving forward but some progress is absolutely being made with that in the recent years(such as 'register' being fully depreciated)
It had character :-). It was a bit old school. I personally wouldn't have described it as "ugly as sin", but it certainly didn't present the necessary information well, with a wall of text. When I started out with Wt, it was hard to find the important bits of documentation between it.
I thought maybe it's like, you get one "user-defined" conversion and two "standard" conversions? I don't remember exactly. It might indeed be that if you move enough steps from `char *` then you can allow that conversion while preventing literal to `bool`. But I think you also want some other things, like, `std::string` should be constructible from string literal? I guess you can add a new constructor for that from `std::array&lt;char, N&gt;` to fix this though... I don't see any obvious reason that you can't change the type of string literals this way with enough minor tweaks. But, I'll also point out, it's not that commonly an issue that `char * -&gt; bool` is a thing. In [my variant class](https://github.com/cbeck88/strict-variant), the approach I took to fix this was, if you see `char *` or `char (&amp;)[N]` converting to `bool` while the variant is being assigned, then block the `bool` option using SFINAE preemptively. In a practical situation, if you are writing an overloaded function and getting bad standard conversions to `bool`, you could declare also a `char *` overload and forward it unambiguously to the correct overload. So even though it kind of sucks, I'm not sure if it's worth making a big breaking change when we have decent workarounds. I think the real answer is that the whole `C` array concept is crappy. If they were going to make a change like this, they should just rip out the whole thing and respecify it, so that arrays can be R-values just like everything else, and don't allow decay to pointer. Then there would be no need for `std::array`, we would have a proper array right in the language. IDK, that's my 2 cents.
I won't go over each statement. I agree with some of them, some of them are outdated /already being addressed for c++20 and some are just insane. About breaking backwards compatibility: Breaking some code is imho OK and there was even a paper of Titus winter's from Google some time ago that promoted a more aggressive deprecation strategy. However, what you ask for effectively comes down to creating a new language and guess what: They already exists (D, rust, swift, Ada ...). Why do you think this new C++ would be so much better than the other ones? Regarding the libraries: Afaik the Problem is that decisions are made by committee and compared to other languages, very few people are actually prayed to work on the c++ standard. So adding any sizable, domain specific library is a very slow process. Think about how long it took the file system library to be created and put into the standard.
The Debian package maintainer used to have an up-to-date PPA, but it seems that he hasn't updated it in a while. It seems that they're starting to lag behind a bit on Debian, because I see that they're still on 3.3.6 for now.
cause it's easy to use. Yes it causes some runtime overhead but `std::shared_ptr` is a workaround until `std::optional` appears in C++17. BTW `std::shared_ptr` is not the only class used for nullable columns. You also can use `std::unique_ptr` instead or even bind your custom class
The readme should include how the output looks like. 
I thought about it. What databases do you expect?
&gt; if C++ doesn’t get with the times in the next 5 years, young programmers should learn Go/rust and skip C++. People will use the languages they are taught at college, and/or that they have to use at their jobs. Most people are not in a position to actually pick a language without explaining to their bosses what the ROI will be. &gt; This statement kills me because I love C++ I would suggest not thinking about C++ (or any other language) like this. You should remember that programming languages are tools, and even if you have a preferred tool, do not let it cloud your judgement when it is time to pick the right tool to do the job. &gt; C++ in the late 90’s was the best language. This is hyperbolic speculation, what are the metrics and parameters being used here to define C++ as the best late 90's language? Popularity alone doesn't mean that something is the best. &gt; No on considered memory safe languages to be a requirement Again this is pure speculation on your part. There is plenty of research about memory safety, Java first appeared in 1995 (according to [Wiki](https://en.wikipedia.org/wiki/Java_(programming_language))), and Ada first appeared in 1980 ([Wiki](https://en.wikipedia.org/wiki/Ada_(programming_language)). Memory safety was always a concern, just think of the many buffer overflow exploits of the past. &gt; Breaking old code compatibility IS okay This is not about programmers, this is about money ($$$) for companies. If C++ was any less stable than it is right now, which company would pick it to develop their flagship application? There is a bunch of new code that is built on top of old code, you can't make breaking changes without careful analysis, and this takes time. C++ is moving forward, evolving, but at its own pace. As for your other C++ suggestions, most of them already exist (or are coming in the near future) in Rust , which you cite on your opening, so if you have the freedom of choice, why no try it out? C++ isn't going to die anytime soon (if ever), do a hobby project in Rust, learn Lisp, you'll find things you dislike in every programming language, as there is no perfect one. If you want a more direct approach to making C++ change, try the [WG21](http://www.open-std.org/jtc1/sc22/wg21/), sign up for the mailing list and see how you can help shape it to be more like your ideal C++.
I honestly stopped reading when you said the only "usable STLs" were Boost and Qt.
Use a vector if you want
&gt; requiring a user to wrap try/catch around the basic STL logic makes for ugly hard to trace code. Deep STLv2 that plays nice together Actually, exceptions are specifically designed, so that you DON'T have to wrap your low level code in any error handling code. If you write a try catch block around every function that could throw an exception you have completely mis-understood how the exception mechanism is supposed to be used.
I stopped reading at "No one likes auto". I like auto and dislike absolute statements based on unspecified evidence.
lol I had the exact same rant when I was transitioning from beginner/intermediate to advanced C++ programming stages. Nothing from the above list is really important for C++, and some of these are coming anyway. 
Heh, as someone who grew up on C# and use it daily as a professional (all my C++ stuff is purely on my own time, unfortunately), I find myself wanting more C++ in my C# than the other way around. Object lifetimes are a big one--C#'s `IDisposable` pattern sucks, to say nothing of the lack of true destructors. I also miss how "strict" you can be with function parameters in C++ (const/not const, by value or by reference, etc.), although at the very least we may get const parameters in one of the next versions of C# (yay!) Somewhere lurking between C++ and C# is my perfect language. 
Have they fixed the performance issues? It wasn't able to parse a project with a few large template-based libs on a very decent hardware half a year ago. 
&gt; There's nothing "JavaScript" about segmenting, substring replacement, or stripping whitespace. These are not "logical operations"
This works as long as you are not dealing with Unicode, which has &gt; 20 different whitespace characters, not all of them are of `char` size. Even better, try to tokenize on a character that is not within a byte range. I don't understand why this has not been dealt with at the language or stdlib level.
...and when I continued reading, the whole thing strikes me as poorly researched and backed by a poor understanding of what C++ is (and aims to be), and ongoing developments to the language (though /u/graciot covered a lot of it already). It also has a hint of "I want Python, but with magically induced performance". The bottom line is, as /u/sempuki points out, that you don't want C++. You don't know what makes C++ different than other languages. &gt; **Breaking old code compatibility IS okay** I think you underestimate the effort that has to go in to large projects in order to transition from one standard to the next. We _want_ people to use the most recent standard, with the most useful features and so on; if everyone has to rewrite their project from scratch every iteration of the language because you constantly break backwards compatibility you're going to prohibit a lot of large projects from transitioning. (See for instance D, which breaks compatibility on practically every iteration even though it iterates much more often; this is tons of work to keep up with.) The way the language handles it today (deprecation and removal after two or three more iterations) is a pretty good compromise. &gt; **Header files** See [N4681 "Extensions to C++ for modules"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4681.pdf). Automatically generating header files might seem like a good idea, but you lose the opportunity to omit parts of the implementation from the public API (although granted such parts should be easily detectable as members of an anonymous namespace anyway). You would still have to ship actual headers with your libraries, unless you want to mandate shipping the entire source code (which is not always feasible or desirable). Selectively importing symbols (to me) just seems like a work-around for poor module/namespace management. &gt; **Overly complex or long winded syntax** As others have pointed out regarding lambdas, see [P0573 "Abbreviated Lambdas for Fun and Profit"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0573r1.html). Regarding template parameters: not all parameters are typenames, and you additionally lose some expressiveness with your proposal. Your beef with auto is honestly not a meaningful discussion to have, and your objection to std::function (or function pointers) is vague (besides, most of the time you'd have a template parameter when passing functors). &gt; **Revamp of memory allocation syntax** In general, you're proposing implementing library functionality (smart pointers) as core language features. Why? As it is, there's at least the option of not using smart pointers if you have to (or if you for some reason want to use another implementation, etc., etc.). Overall, incorrect use of raw pointers is a social problem that should be solved by teaching people the right way to start with rather than the technical solution of constraining the language. It's not like smart pointers are somehow harder to use, discover or teach than raw pointers (if they are, that's a problem), it's rather the case that a lot of introductory material pre-date them. &gt; **Stack safe destructors** This sounds more like a QoI issue than a core language issue to me. &gt; **co-routines (yield) and a proper foreach** Again, as others have pointed out: we already have a `foreach` equivalent, and we have [N4680 "C++ Extensions for Coroutines"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4680.pdf). &gt; **Dictionaries as first class citizens** There are several good JSON libraries already, and there is no real need to embed JSON as a core language feature. You already have all the building blocks, and some of them (std::any, notably) are justifiably ugly because JSON is, although human-readable, essentially weakly typed by definition and willy in some sense fundamentally have poor compatibility with strongly typed languages. &gt; **Safe arrays as first class citizens** Again, we have library building blocks for safe arrays/vectors, localization, string formatting ([fmtlib](http://fmtlib.net/latest/index.html)). Use them. A variable-size fixed-length array is missing from the standard library, which is a fair point, and the overall state of Unicode support in the C++ standard library is honestly a disgrace (but also somewhat mitigated by non-standard-library support). &gt; **Enums revamp** We have strong enums since C++11; these cover your first point. String conversion could absolutely be nicer, but I anticipate improvements on this front once the buzz about reflection gets closer to standardization. &gt; **Keep C style overload syntax with updated modern behavior** C-style casts are awful, because they are way too aggressive. Keeping them reinforces what you say you don't want with unexpected behavior and "dragons". Having casts be a lot of typing is _good_ because it makes the casts explicit (as they should be). The compiler can't magically make code "work the way a coder would want", because what you _actually_ want varies across different situations, and C++ casts give you the granularity to express this. &gt; **Run time reflections and meta classes** Compile-time reflection (which is what you actually want, keeping in mind what C++ is and aims to be) is already in the works. See for instance [P0590 "A design for static reflection"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0590r0.pdf), which is one of several proposals. Wishing for run-time reflection just seems like missing the point of C++ altogether. &gt; **Friendly tuples** Some of this is mitigated by C++17 structured bindings, some of it could rightly be implemented as part of the standard library (but until they are, can be implemented outside). &gt; **Primitive helpers** I don't see how `1.toString()` is an improvement over `std::to_string(1)`. It doesn't read nice, and it implies that `1` is some kind of object, when it isn't. &gt; **Common names for similar STLv2 actions** The standard library is in general pretty consistent on this. I don't know what particular gripes you have with naming, though, because you don't provide any actual examples. &gt; **Functional STL, none or extremely rare use of try catch** Much of the new functionality going into the standard library has `nothrow` alternatives, and so does most of the old stuff as well. See for instance the networking proposal ([N4656 "C++ Extensions for Networking"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4656.pdf)). Your list of features contains a bunch of stuff that would be appropriate to have in the standard library (most of it already is in there or will be shortly, including networking, filesystem, etc.), but also things that are perhaps better placed in non-standard-library implementations to keep complexity down (notably perhaps HTTP and memcache). Having stuff outside the standard library is not a problem _per se_, especially not if you have a good package management system. &gt; **Community owned ORM and web framework** There are plenty of ORMs and web frameworks provided by the C++ community. They should absolutely not be crammed into the standard. &gt; **Slay the dragons!** The language has come a long way since C++03. If you're using the features provided by the core language and standard library, C++ is both safe and joyful to use; the language can't cover for all cases of programmer error. Some points have merits, though: * Named parameters would be useful, and designated initializers would be _very_ useful. * A community owned package manager is absolutely something the C++ ecosystem would benefit from.
Nice, any chance to have it for zsh as well? /usr/share/clang/bash-autocomplete.sh:83: command not found: complete
First impressions: * Anonymous namespace in header is a bad idea. Use `namespace detail` or something similar instead. * You're using `enum` instead of `enum class`. This is a bad idea as `enum` is unscoped. --- const std::string delimiter = ", "; using brace_type = std::pair&lt;std::string, std::string&gt;; brace_type const CURLY_BRACES = std::make_pair("{", "}"); // ... * Using `std::string` for things like delimiters and single characters is overkill. It cannot be `constexpr` and it's bigger than it should. It's hard for the compiler to optimize away due to SBO. Consider using `char` or `std::array&lt;char, N&gt;`. --- std::unordered_map&lt;std::string, std::pair&lt;std::string, brace_type&gt;&gt; Names = { { "carray", std::make_pair("carr", BOX_BRACES) }, { "array", std::make_pair("arr", BOX_BRACES) }, * You're using `unordered_map` and copious amount of `std::string` instances for something that could be done at compile-time. In order to print a `vector`, you do this: `return printElementsCont(ar, "vector", ar.size());`, where `"vector"` is an `std::string`. This should just be handled by overloads/template specializations and it would be done completely at compile-time. --- inline std::string get_name(std::string _name) { return std::get&lt;NAME&gt;(Names[_name]); } * So many unnecessary string copies and instantiations. Again, this dispatch could be done at compile-time by overloading/specialization. --- template&lt;typename T&gt; std::enable_if_t&lt;is_str&lt;T&gt;::value, std::string&gt; to_string(const T&amp; val) { std::stringstream ss; ss &lt;&lt; "\"" &lt;&lt; val &lt;&lt; "\""; return ss.str(); } * You're instantiating `stringstream` and calling `.str()` all over the place. How about taking an input stream as an argument instead, so that you can directly stream into it without having to create temporary strings and streams? --- template&lt;typename T&gt; std::string to_string(const std::stack&lt;T&gt; &amp;ar) { std::vector&lt;T&gt; vt; auto ar_clone = ar; vt.reserve(ar_clone.size()); while (!ar_clone.empty()) { vt.push_back(ar_clone.top()); ar_clone.pop(); } return reversePrintElementsCont(vt, "stack", vt.size()); } * You print stacks and queues by copying them and pushing back into a vector... you realize that can be extremely expensive, right? It can also be impossible for types that do not support copying. --- #if defined(_GLIBCXX_FORWARD_LIST) || defined(_LIBCPP_FORWARD_LIST) || defined(_FORWARD_LIST_) * Why? Just target a C++ Standard (e.g. C++11) and assume that the user of your library will have a compliant compiler/standard library. 
Nothing particular, neither a slow connection.
Performance still isn't great, Indexing can sometimes take a really long time and right now there's also a really annoying bug ien the windows version where it spawns a background process that it doesn't kill and this process can take up a significant amount of CPU time. I don't know how relevant my opinion is though since most of my projects are rather small(&lt;10K loc) tl;dr no, but I may not have the most representative opinion
&gt; I think the real answer is that the whole C array concept is crappy. If they were going to make a change like this, they should just rip out the whole thing and respecify it, so that arrays can be R-values just like everything else, and don't allow decay to pointer. Then there would be no need for std::array, we would have a proper array right in the language. IDK, that's my 2 cents. Yeah, I'd definitely be on board with that as well. 
Sorry, I meant to ask what operating system, browser or device you are using, to see if I can somehow reproduce your issue. Are you using any browser add-ons that might interfere? There is some onscroll callback that we can take a look at, but we've tested the site on our workstations, laptops and mobile devices, and didn't experience any issues with performance. The initial load can take a bit longer (because of images, fonts, etc.), but for the most part it's been quite fast for us.
I never heard that and I will check that and improve the README file
I'm working on it :)
This is full of shit, to use Linus lingo. :-)
C# has pass by reference (see ref and out keywords).
Awesome, thanks!
'tokenising unicode strings' is not a common operation. That's what projects like http://site.icu-project.org/ are for.
&gt; The only usable STL is boost or QT and the learning curve for either is large. ... and the only usable bicycle is the city metro. `stl`, `boost` and `Qt` are different beasts. &gt; There are a few core issues causing this: &gt; &gt; An unwillingness to break legacy code This unwillingness is a very good thing. It is also a very bad thing. Depends. &gt; Unsafe memory manipulation Do not use unsafe memory manipulation, unless you know what you are doing. for example, in the last 5 years of C++, I haven't written any pointer arithmetic. I am not sure if I wrote any in the five years before that. &gt; Clunky STL This is being addressed (through ranges, for example) but it will take time. &gt; Ruby/python taught us how flexible languages can be. Javascript taught us how forgiving code can be. Rust taught us memory allocation can be safe and monitored by the compiler. The list of functional languages have taught us new ways to think about state. Today C++ isn’t the best language, there are many others which can do all the things C++ does, and in many ways, they do it better. No. There are many languages that _put together_ can do all the things C++ does. There are newer languages that have nice(r) features, but not the same availability on various platforms; Then, there are languages that have the availability, but not the speed; Then, there are languages that have the speed, but not the abstraction, that have the safety but not the speed or availability or something else. This will change with time (as other languages mature) but I do not believe there are many languages that can do _all the things_ C++ does. &gt; So why do I care? Why should we care? We should care because C++ provides the performance tuning nobs that most languages hide. So other languages _do not provide all the things that C++ does_? &gt; The compiler should auto generate header files for each cpp file on the fly. The compiler _could_ auto generate header files, and it is a horrible idea. Include files are broken, but this is not a practical solution (it would bring it's own host of problems, that headers do not have). &gt; Perhaps a new pre processor keyword needs to be created? #import “xxx.cpp” which causes the header file to be generated? With this new pre-processor, please also provide a way to explicitly state which items to include from the remote file. #import “xxxx.cpp” with foo, bar, Klass. It is better to rely on the module system (when it becomes available) than to add new macrodefinition syntax. Aditionally, the module system is comming to address this exact problem. &gt; Function pointers need a nicer syntax to pass themselves around. I’m not sure what is, but std:func&lt;&gt; isn’t right. `std::function&lt;...&gt;` is also not a function pointer. To pass functors arround, consider code like this: using callback = void(int); // this is a function or function pointer, depending how you use it void set_callback1(callback f); void set_callback2(callback *f); // this has the same signature as set_callback1 using callback_function = std::function&lt;callback&gt;; // this is not a function pointer, it is // type erasure on a callable It is idiomatic, minimalistic, explicit and clear; &gt; Template syntax should be reduced to &lt;T&gt; added to the function or class. Users just want to write: class Dog&lt;T&gt; {}; or Dog&lt;T&gt; → int () one time and then use T inside that class/function. I heard is said that every problem, no matter how complex, has an obvious, simple and good solution, that is impossible to apply in practice. for your `class Dog&lt;T&gt; {};` how do you specify that T is an int, or that T is a template template argument? &gt; The “new” keyword needs to replace unique_ptr. When new is called, a scoped based unique_ptr should be created. No; Just no. If you want raw memory you should use `new`. If you want unique pointers, then use unique pointers. &gt; Pointer syntax is great, but its not safe. I want to use pointers, but the compiler needs to monitor my usage and ensure the pointer is treated safely. No, the compiler doesn't need to do that. If you want restrictions on the use of raw memory, wrap the memory in classes. If you want uniqueness restrictions over raw pointers, use std::unique_ptr; If you want sharing, use std::shared_ptr; If you want sequences, use std::vector (or something else). C++ was designed so that the language _can be extended_ through the use of classes. Classes are there to ensure the compiler _doesn't need to monitor your usage and ensure the pointer is treated safely_. &gt; shared_ptr needs its own keyword. That is my point: declaring a class effectively makes a a new keyword available to your client code. &gt; When shared pointers are used in functions, their reference count should be pinned to the lifecycle of the function they are used to avoid possible premature cleanup. If I understand you correctly, you are referring to passing `std::shared_ptr&lt;T&gt;` instances by value (instead of reference or const reference). &gt; There are also times when parameter order doesn’t matter as much as name grouping: action(slope=0.5,offset=2,foo=9) is much easier to read and understand over: action( 0.5, 2, 9 ); Naming parameters in C++ is done through strong-typing: struct slope { double value; }; struct offset { double value; }; struct foo { double value; }; action( slope{.5}, offset{2}, foo{9} ); &gt; Json rules the world. C++ should support the json format of data, which is stored into a dictionary. C++ supports the json format of data though [an external library](https://github.com/nlohmann/json). &gt; Keep C style overload syntax with updated modern behavior &gt; Programmers enjoy C-Style syntax casts No, they do not. These casts are impossible to find through lexical search (a C++ context-sensitive is required, which implies compiling the code). &gt; var x = (int)a; Is this C# or javascript? &gt; Allow this syntax to play nice and have compiler checks. If that is impossible, then have the new style double { x } be more aggressive and work the way a coder would want. So ... is "the way a coder would want" in this case a const cast (remove const-ness?) Is it a down-cast in a class hierarchy? Is it a reinterpretation of raw memory? Should the compiler be telepatic? &gt; C++ cast syntax of dynamic_cast&lt;XXX&gt;(x) is way too much typing. Then write your code in a way that doesn't need it (that's half the point of explicit casts). &gt; Class initialization through a string name also needs to be implemented. For what purpose? There's a lot more to say, but I do not have that much time :(
&gt; Simply put, a “yield” like keyword, and a foreach ( var x : co-routine ) to handle it would go a long way. Python nailed this behavior. To clarify - python nailed generators. Later on python coroutines were based on generators and that is absolute failure noone wants to see. C++ definitely needs python generators, but no python coroutines. &gt; The new STL should hopefully never throw exceptions. IMHO exceptions in exceptional cases are fine, like accessing vector accessing index that does not exist. STL should build without exception support and abort in this case. &gt; Community owned ORM and web framework That would be very weird. Maybe no good solutions exist because language is not exactly very suitable for that kind of job.
In fact, you can already use module system in visual studio 2017, follow [this instruction](https://blogs.msdn.microsoft.com/vcblog/2017/05/05/cpp-modules-in-visual-studio-2017/).
It depends... there are many databases around, but the imho the most important within business applications should be: * postgresql * Mariadb * mysql That were the open source ones. As commercial ones: * oracle * MS Sql Server 
Oh, if it isn't great for small projects, I'll wait one more year before considering switching back. Thanks for the information. 
No shit. Have you tried using visual studio under linux ? Then you would say that linux sucks.
Well, technically, there should be no such thing as antialiasing in font rendering, and fonts should be rendered smooth and nice by default. There really is no need to bring the whole AAA games graphics arsenal to font rendering, font should be rendered perfectly by default and thats it. But, in real world, font rendering mostly sucks, and sometimes it requires such techniques as antialiasing to not look as it was just pulled from the ass, and you can easily end up with super blurry font, which is pain to look at, too. So its not that you dont like antialiasing, the point is that the font rendering is either broken/really bad or the font was designed to have hard edges.
Is there any way to get the values for the option "-x" to autocomplete? That's by far the most undocumented feature of clang and the names are usually quite obscure! Also, I've tried getting `./bin/clang --autocomplete=-std=,` to work or the exact same command as in the example and it didn't suggest anything at all.
But I don't think you can pass objects of a class by value
Hi, thanks for the feedback. I will improve the readme.
Thanks for the detailed feedback and I will improve it.
Your library has the same name as mine :-/ https://github.com/robhz786/stringify
You should join the standards committee. Good luck.
whooosh
Yes, and the '*' is part of the type, so it should be attached to 'int'.
Yes, true, but kinda unrelated :-). You can pass parameters by value or by reference. When the parameter is a reference type (a class, or an interface), you pass a "reference" to it (it's a "pointer" in C or C++ parlance), but you are still passing that reference by value or by reference. Yeah, it's complicated for dumb reasons :-).
&gt; var str = “Run “ &lt;&lt; 5 &lt;&lt; “ times”; &gt; &gt; You're close! (c++11) auto str = "Run" + std::to_string(5) + " times" Or just use a stringstream.
Congratulations on the release, but I must ask: Why do you need to control everything? Granted I come from the php framework and things are a bit simpler. Why is there a need for these widgets? Why can't the user simply have html, css and js for the frontend and just feed in the data via c++? Most php frameworks help you manage the routes and help you output data (via html, json etc) but they don't have any special magic for the frontend (except for form stuff) Is all these things really necessary for the c++ world? 
For that to be useful, we'd need `max_capacity` for containers, which would return `size_t(-1) / sizeof(T)`.
Like [`std::allocator_traits&lt;&gt;::max_size`](http://en.cppreference.com/w/cpp/memory/allocator_traits/max_size) (exposed by e.g. [`std::vector&lt;&gt;::max_size`](http://en.cppreference.com/w/cpp/container/vector/max_size))? ;-]
I'm currently working on a patch for adding support for this to -x. Thanks for the hint! And -std values patch has closely missed the 5.0 release and is only in the nightly build. Sorry for the confusion, I'll update the blog post!
Oh god... My brain literally skipped that part.
Does anyone know how it performs compared to the 3.x branch? I use to use Wt but after looking at TechEmpower benchmarks, I decided to roll my own web server using Poco (C++) and Lapis (Lua/OpenResty). I would like to get back to Wt but not sure if I should invest in porting code over if I'm going to lose performance.
This is how autocomplete should always work... sigh. Writing complicated bash scripts that reimplement your programs argument knowledge / parsing logic is dumb.
&gt; the language still allows the user to easily do unsafe things with memory uhm, that's one of the big advantages of c / c++, not a disadvantage.
From my testing, performance of Wt 4 should be a bit better on those kinds of microbenchmarks than Wt 3. However, when I test Wt it's not even close to the results that TechEmpower reports. Wt actually performs a lot better in our tests. I'll see if I can dig up our benchmarking figures, but I managed to get better results on my workstation than TechEmpower gets on their beastly hardware. I tried to find an explanation for this discrepancy, but I haven't found the source of the problem yet. I gave up looking for what was going wrong, but it's alarming that you actually decided not to use Wt over those benchmarks. Did you compare Wt with your own web server for your application, and found the same difference in performance? I believe Poco normally performs worse than Boost.Asio. Of course, note that the TechEmpower framework benchmarks only test a very thin slice of Wt. If you look at the `Data updates` test Wt is suddenly performing a lot better, which suggests how much less significant the performance of the underlying HTTP server gets when the application logic gets more advanced.
Ah, lovely, thanks! Those are a nice addition to check for language support I believe!
I'll tell you. Zsh does have Bash-compatible completion utility, you can use the the same script via Zsh. All you need to do is this. autoload -U +X bashcompinit &amp;&amp; bashcompinit Include that before the `complete` function. cc. /u/phcerdan
:P well, I need to find a better name may be !!
Or even `auto str = std::format("Run {} times", 5);` if the text formatting proposal makes it in the standard :)
Response from the author. Thank you for all your feedback. I've been writing c++ since 1996 and I wanted to make my observations know. I appreciate those that sited the up coming changes, I'm aware of many of those, just because something was proposed, doesn't mean I wanted to leave it out. I hope everyone took this as the positive feedback it was ment to be and that in a small way it encouraged people to think about the language and where it can improve. -Orby
&gt; When learning how to code, understand segfaults and fighting dragons is unacceptable. Then you aren't learning to code, you're learning to script something else that codes for you. If you want to do anything well, you need to learn it right. If you can't understand memory addresses, how do you think you're going to learn more complex systems?
There was not testing done between what I have and what I had. What I had going with Wt was done a couple years ago but work had me drop the project for a period of time. In the past few months I've been able to renew it and I've kept an TechEmpower since they started the benchmarks. Since I had been diverted from the project for a couple years, my old code base was foreign to me. Since the benchmarks didn't shine a favorable light on Wt I opted to start over with Poco and Lapis. Wt also didn't have C++11 support when I restarted the project and we had moved all our stuff to C++11 a couple years ago. It's an ETL program that uses Lua for scripting some non-standard conversions. Since Lapis did well I opted to use that since I was going to be embedding Lua anyways. I'll probably look at prototyping some stuff in Wt to see how it compares to what I'm doing now. But it would be interesting to know TechEmpower has lower benchmarks than it should
Works fine for me.
To elaborate on what you've hinted at with a divide of existing and new code, breaking language changes prevent a gradual migration of existing codebases to the new standard. Legacy code is one of C++'s greatest strengths; if C++ broke backward compatibility as thoroughly as OP suggests, I'd probably just use a newer language like Rust that has a head start on the good part of OP's proposals rather than waiting for C+=2 to catch up.
Thanks, this is going onto a "battery" (potato actually) powered Raspberry Pi. It seems like the orange might have been better too. I will looking at this and see what it does on the volt meter and ammeter.
Read the release notes. Once it is stable it will remain so (it wouldn't be stable otherwise!)
This web-server literally needs to run on a potato. I thought about Ruby and C# but ruled them out early because they have been too inefficient in the past even connected to wall power. Memory that is storing stuff, even stuff I am not using is memory that needs power. Modern devices are smart enough to not power things that don't need it. So yeah, the memory footprint is part of it. I was thinking about the CPU though. every web request is going to max the CPU briefly and if that time is long enough the clock speed and voltage is going up. I really cannot afford that.
If you include unpublished software that is never released to anyone as "closed-source" and take that sentence out of context, yes, it's wrong. If you read the entire comment and engage brain it should be obvious what I'm saying. &gt; if you distribute that outside your company then you have to release the source code for those customizations. If you don't distribute it then you don't have to.
The Itanium ABI says how the return value is passed, I don't believe it says the RVO must be performed. i.e. it's allowed to create a local variable as specified by the C++ abstract machine, then copy it to the caller-supplied address when returning it.
Can a potato even power a Raspberry Pi in standby? Or are you using multiple potatoes?
Does this work with the older GPLv2 bash that Apple ships?
The base potato provides only .8 to 1.1 volts and negligible amperage. Boiling moves that up to almost 10v and nearly 200 mA. So I am actually trying not to fry the Pi because it wants 5V but I understand as much as 6V is safe. For load with the old version of wt our peak draw is 260 mA. So in theory we can get this to work. 10V x 200 mA = 2 watts, our target is 5V at 300 mA for a total of 1.5 watts. I swear I am not trolling, we are experimenting with boiling times and salting the potato to get the power output we want. The only reason we aren't trying cheese and bacon to modify the potato's electrical characteristics is that it still needs to look like a normal potato. All the theory is there, but as far as I know no one else is running a Pi on just one potato. There might be good reason for this and we might fail. Our backup plan is hollow out the potato and stuff it with 4 AA batteries.
&gt; Named parameters would be useful, and designated initializers would be very useful. 1. *named parameters hiss* -- making things contractual which have previously been implementation details causes problems.... 2. Designated initializers voted in in Toronto.
....
it is nice but I decided to begin from sqlite3 cause most popular API it has is implemented with pure C which means it is used with C++. Other databases are more used with C++ more seldom. So if we want to define which database will be next (I think about a separate ORM for a different database) we must know which database is used more often with C++. Maybe you have some thoughts?
This is nice, but TBH I would prefer Visual Studio kind of style where you have options organized nicely into categories and you see the command line if you need it. But yeah that is sci-fi because linux people hate GUIs. :)
I never use auto, I guess it's just that I haven't come to terms with it yet. And to say "No one likes auto" is the opposite of my impression. It seems that everyone loves auto and I'm the only dummy who doesn't get why it isn't more appealing to write out the full type name.
best comment so far
Interested to hear why coroutines in Python were a disaster? I heard alot of talks at python conference and chatter about them in my local user group meeting by some senior developers. Seemed like a lot of ppl liked them, but I have no idea what they are all about. 
Wt serves a specific market. For example embedded solutions can't afford running a webserver and PHP, it will cost way too much resources for the often extremely simple interface they want to run on a very low powered device (we're talking way simpler than a raspberry pi here). Beyond that there's also many large companies who prefer to have the backend and frontend be a monolith in the same language, that is their choice of course. Why widgets instead of using HTML and CSS directly? Wt aims to be like developing for the desktop. It abstracts away having to check what browser supports what, etc. For example it will use websockets, fallback to comet, fallback to ajax, fallback to direct links. It supports text browsers without a shred of javascript just as well as the latest release of Firefox and Chrome. That convience matters to certain people who aren't focussing as much on the web aspect. 
Great! Please post here your results, they would be really interesting! By the way, here you have a discussion about different Orange Pi's power consumption and how to tweak them: https://forum.armbian.com/index.php?/topic/1614-running-h3-boards-with-minimal-consumption/ Good luck!
In all fairness, I have to agree with him that I sometimes whish some of the library constructs where actually native language features with shorter/nicer syntax (including std::make_unique and most things related to std::tuple). Yes, C++ is so powerfull that you can implement almost anything as a library feature, but sometimes it would be so much nicer if native arrays would behave as std::array and new would return a smart pointer, whereas getting a raw pointer would have to be spelled out in_a_long_and_ugly_manner ;). And regarding the template syntax: As the concepts TS has shown, there are ways simplify the syntax for the most common use cases for templates - you can always fall back to the more ugly and expressive version when needed, just like there are different levels of verbosity for lambdas (and I'm really looking forward to the day, when a short lambda syntax that actually deserves that name finds it's way into my compiler - lets hope P0573 gets adopted soon). 
&gt; Overall, incorrect use of raw pointers is a social problem that should be solved by teaching people the right way to start with rather than the technical solution of constraining the language. It's not like smart pointers are somehow harder to use, discover or teach than raw pointers (if they are, that's a problem), it's rather the case that a lot of introductory material pre-date them. oh god someone please tell the embedded devs at work this: they can use `std::unique_ptr` and many do once they know it exists, but its so untaught and unknown (especially by EEs and embedded devs, who really get the shit end of the C++ teaching stick) that it is still mostly unused
&gt; Besides, there is std::array in the STL if you are going to use the STL anyway. Yes, and it is way more verbose to type and can't deduce it's size from an init list. Except for backwards compatibility (which IS important) there is imho no reason, why the compiler could not generate the moral equivalent of a std::array&lt;int,N&gt; from `int foo[10]`- no STL needed.
Forgive me for daring to use a usage of the word "logical" that doesn't have to do with boolean logic.
Actually, this is very common as soon as you deal with non-english text.
I just added this: string(CONCAT CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS}" " -std=c++14" " -Wall" " -Wextra" " -Wpedantic" " -Wnull-dereference" " -Wold-style-cast" " -Wdouble-promotion" " -Wshadow") Wasn't sure how to format it to make it look nice
Compiling with `clang`?
i would expect the compiler to notice in this instance that a and b are the same and not mutated and therefore can be reduced to one variable and RVO'd.
... the fuck?! `yum fucking install` can do it...
They're not really "the same" since the default constructor performs side-effects. If the type was properly [trivial](http://en.cppreference.com/w/cpp/concept/TrivialType) then I'd agree.
I used to run Windows. 
No need to be condescending. There is no place for imprecision and assumptions when it comes to IT and law. 
Well when you get big types like this: std::unique_ptr&lt;webgl2::WebGL2_Painter&lt;webgl2::WebGL2_Object&gt;&gt; painter = std::make_unique&lt;webgl2::WebGL2_Painter&gt;(width, height); Then you wish to just use auto on the left since you know the type from the right. auto painter = std::make_unique&lt;webgl2::WebGL2_Painter&gt;(width, height); I like to state the type just once, either on the left and use an braced initialization or use an auto and state it on the right, but don't state the type on both sides.
Well, it goes both ways :-) I really missed a bash on Windows, before there was WSL. Also, the best to have is a GUI that is *designed* to work with keyboard shortcuts. Gives you the best of both worlds. Unfortunately many programs nowadays just ignore keyboard users and provide shitty or buggy keyboard interaction or none at all.
&gt; distro-level What is 'distro-level'? Can't find anything about it.
I think they mean 'your distro's package manager', e.g. emerge or yum or apt.
GCC has something like this too right?
Because bash3.2 or older doesn't have compopt builtin command, a space is also autocompleted between "-stdlib=" and its value. Apart from that, it works fine.
&gt; there is imho no reason, why the compiler could not generate the moral equivalent of a std::array&lt;int,N&gt; from int foo[10]- no STL needed. but... what would be the difference then ?
https://github.com/scop/bash-completion/blob/master/completions/gcc GCC is using this shell script for bash-autocompletion, so I don't think they have something like this.
VS? Get a build of whatever lib you want, put it in header/lib include dir, add it to linker properties, done.
Async creep. Only functions marked as a sync can yield. Only functions marked as a sync can call other async functions. This divides code into two islands - async and normal, and it gets really complicated to have them interoperate. Especially when callbacks are involved, or libs whose code we do not control and can't make async. In short - everything should be async by default and we should opt out of it by simply not yielding. As it is now it's a lazy back on top of generators that complicates life more than eases it. These are fake coroutines.
I'm a sublime user as well, are you on 2 or 3? Are there any plugins you find helpful?
IDK, I only use browsers and VS, and I do not need many shortcuts in browsers that are hard, I only use ctrl+k/t/r. For Visual studio shortcuts are ok, my only complaint is that commenting out code is not ctrl+/ but 3 key shortcutctrl+k+c iirc. 
I'm on sublime 3. Truth be told, *most* of my work is in another language (Odin), but when I do C++ I just use syntax highlighting and let the compiler tell me about any issues with my code.
It's got a full vi implementation. I don't know if anyone has implemented ed(1), though. 
That mostly doesn't work for many C++ workflows, because it also means being locked in to the system compiler, and the implied ABI of the things you use. It's an unfortunate truth that you will generally have to build all of your dependencies with the toolchain and options you are using for your application. 
You could just use macports to install a recent version of bash. 
To be fair, when you write std::sort(vec.begin(), vec.end(), ...{x.size()&lt;y.size()}) what you probably want is `vec.sort{it.size()}` where `it` is an implicit name for first argument (pick $0, $1, etc. if you have several), curly braces `{}` make a lambda as the first and only function argument, the lambda takes things by reference, and `sort()` is a member of `vector`.
a) with concepts we will not need to write vec.begin(), vec.end() so that goes away b) sort being nonmember function is kind of a point of STL, where you do not need to implement sort for every container as member as long as container has random access iterators Other than that I like your idea. Since most of the time you sort on the same thing on lhs and rhs (you do not write [](const auto&amp; a, const auto&amp; b){return a.name()&lt;b.last_name();} )your solution is even shorter. 
FWIW, clang-tidy even looks for these kinds of obvious cases with its modernize checks.
I guess you could use a single-word typedef/using instead. Otherwise, I don't know.
`std::array` isn't there out of the box in freestanding implementations.
 autoload -U +X bashcompinit &amp;&amp; bashcompinit source "/usr/share/clang/bash-autocomplete.sh" I tried this in my `.zshrc` But when trying to autocomplete `clang &lt;tab&gt;` I get: _clang:49: command not found: sed sed in is my `$PATH` though. I thought maybe the the script was missing a `#!/bin/bash`, but didn't solve it either.
And then you don't get any security fixes to bash from Apple anymore. That's not worth it.
&gt; but... what would be the difference then ? Difference between what? std::array has a lot of advantages, like a proper size() member function, proper value semantics (no decay to pointer, copy by assignment) but it is really sad that c++ needs an extra library type (verbose syntax and library dependency included) for something so fundamental and simple as an array.
between this theoretical moral equivalent of `std::array&lt;int, N&gt;` and `int[n]`. You can use both in range loops, you can get the size of both and iterators of both, you won't have out-of-bounds safety...
What does "-x" do, actually?
I dont see the problem, just update it on a regular basis.
This is amazing.
It allows you to specify the language your code is written in. Useful when piping to clang, for example: `echo "int main() { return 0; }" | clang -x c -o empty -` Not that I do that sort of thing often, but it happens. You might also want to force a .c file to compile as C++ (for whatever reason). There's a list of possible language names in the GCC manpages, I imagine clang supports similar options (though the clang manpages, on my system at least, don't list them).
" C++ using STL containers I hit a wall" If you dont mind cheating ;) std::array&lt;int, 1234&gt; will for sure suck when it comes to performance without RVO. :D
`std::array` can deduce its size from an init list in C++17. See this example: http://en.cppreference.com/w/cpp/container/array/deduction_guides
The world runs on good-enough layers on top of piles of legacy design decisions. Everybody can agree that we do most things wrong, but we'll probably be stuck with pretty much all of it for the rest of our careers because that's the way it's always been done.
Uh, very interesting. Thanks!
One thing that is not clear to me... Example that prevents NRVo. `if (runtime_condition)` unless that runtime_condition needs a and b IDK why they can not be constructed in the branches (and that would make RVO possible I guess/wonder). 
"To test how quickly we can allocate and call functors, we will be saving all the many instances in a vector and executing them in a loop." Very realistic test :P Anyway I think the biggest problem with std::function is that it prevents inlining, for example try doing a sort of vector of integers where once you use as predicate a lambda that does std::less and once using a std::function that stores lambda that does std::less and tell me the results. :) tl;dr - I think most users of std::function do not construct many std::functions, they do call often one std::function.
Qt and Eclipse run remarkably well on Windows, Linux and OS X. Visual Studio only has to run on Windows, yet it's still a bloated mess. 
Which OS are you using? It works on my mac but doesn't on ubuntu, so maybe some default setting are causing problems. Anyway, I'll work on zsh version because many useful features that bash doesn't have (including showing flag's description when completing) are available in zsh autocompletion :)
Our heuristic is one string, not two.
But it isn't Apple bash!
thank you!
You are right, perhaps =&gt; would be better
How often do you actually need to tokenise strings though? I've never found it to be a particularly common operation
Thank you for the response. My point was &lt;&lt; is nice to read/type, the above does work but isn't brief.
Auto is awesome but it's more typing than var was my point. Thanks
Thank you
I am an embedded coder and in 15 years, I've never had to use new inside my firmware. For the cases where allocation is unavoidable, malloc or a helper function for malloc should be used. My point is the new keyword now exists as an exception to the rule of allocating. Thanks for the response.
My auto point was var is less typing. I love what auto does. Compiler time bounds checking can go a long way. I ment compile time reflections, that was a typeo, as you pointed out run time reflections makes no sense for c++. You're right the quirks have a legitimate reason, and I don't want to get rid of them, I'd just rather the defaults we're less... quirky? Thanks for the response.
I'm not the first to notice, there are lots of very smart people working very hard. Thanks for your reply
Thank you, I'll look into that.
Perhaps you're right these changes are essentially a new language. I see it as about 20 tweaks that would make the language feel more modern. Thanks for your response
Doesn't the same apply to `std::initializer_list`? Or does it have special requirements in regards to freestanding implementations because of its deeper integration with the language-proper?
I don't want to get rid of the unsafe memory, I'd just rather the default be safe. Thanks for your response.
I'm not suggesting headers be removed. I'd just prefer the default to not require them. Thanks for your response
The ORM piece would be relatively straight forward with proper compile time reflections and function generators. Thanks for your response 
Thanks for your response
Thank you, I'll look into it.
I actually agree with your statement, I learned it the hard way back in the early 90s, others should to. My statement is parroted from the professors I've talked to over the years that have switch to Java or c#. I'd propose that a compiler error message telling you what line you have a memory mistake on is more helpful than a segfault. Thanks for your response.
If it did add complexity I don't want it either. Thanks for your response
I am on arch. Thanks for pursuing `zsh` autocompletion! I have no idea why fails, but maybe related with`sed` enclosed in `$()`?
Unicode strings are the typical strings.
You download Qt and go to town, son. 
I hope you don't feel discouraged by the harsh (but somewhat fair) criticism of the overall comments, but some of the things you wrote about are either coming or cannot be done. I would like to reiterate that most of the features you want are present in Rust. I suggest you go spend some time with it, maybe you'll find some features that will make you wish they were done the C++ way. Rust is a also a nice language to help you understand what "modern C++" looks like by default, with unsafe being put in `unsafe {}` blocks.
What you did there, I see it
There's a lot of GUI frameworks, some are open source, like QT, others are limited to one platform like c++/winrt or c++cx (although that's not technically c++) for UWP
Yeah, get QT5 and check out QT Creator.
In general, you need to use APIs provided by the OS (directly or indirectly) to create graphical applications. (Note that the APIs you use for console applications are the same- provided by the OS at some level.) Another comment mentions Qt, which is a library that wraps various platforms' graphical APIs to let you create widgets. There's also GTK, wxWidgets, or OS-specific APIs like Win32, Cocoa, or X11. You can also look at APIs like SDL or SFML that are directed more toward games than toward widgets. They wrap APIs like OpenGL and Direct3D that let you render things on the GPU.
OpenGL / Direct3D! 
You can definitely do GUI and graphical programs in C++, I'm pretty sure it's one of the most popular languages for both video games and GUI applications. The reason you see the console used so much in tutorials and programming lessons is because it uses nothing outside of the standard library and runs pretty much everywhere. Whereas everything outside of that is system specific, though there are some cross-platform libraries that support both Windows and Unix-like operating systems (Linux, BSD, MacOS, etc) which covers pretty much all PC operating systems that are in widespread use today.
* If you want to make cross platform video games, [SDL2](https://www.libsdl.org/index.php) is a library that allows you to create a window and display stuff in it. You can use it to get input (keyboard, mouse, touch ...), draw things using a graphics API (OpenGL, DirectX) and so on; * If you want to make more traditional applications (an email browser, a graphics calculator, ...), then you have many options: * Cross platform: You have the [QT](https://www.qt.io/) framework as probably the most used one. * Windows only: You can use the [Win32](https://msdn.microsoft.com/en-us/library/bb384843.aspx) API, which is on the old side of things (but still being used to date). You also can use the [WPF](https://docs.microsoft.com/en-us/dotnet/framework/wpf/getting-started/), or the most recent framework [UWP](https://docs.microsoft.com/en-us/windows/uwp/get-started/universal-application-platform-guide). A bunch of tutorials will stick to the console because GUIs (Graphical User Interface) programs come with a bunch of boilerplate code that you have to write (create a window, grab event, create a textbox, ...), so when you're learning how to program these things can get in the way of the actual important topics. 
Unreal engine for game development is written in C++. The most intensive graphics programs are for the most part written in C++.
It works better IMHO. Windows has many issues and problems that are simply not on linux, and you have a great selection of open-source apps and libraries for almost everything. It has it's quirks and stupidities, but still more manageable in mass than windows, and you can configure it to be extremely lightweight, both of which is really useful for cloud applications.
Nobody mentioned websockets (eg boost beast) and HTML interface via Webserver. You can go WT so it handles Webserver and websockets without much difficulty. 
Qt - yes, eclipse - not by a long shot, it is super slow java based ide, one of the slowest ides on this planet.
1. much much... better dev enviroment, like packages, compilers. 2. cost much less when deploy web service.
For me it would be : * better command line - even if you do everything from an IDE sometimes you have to use it and when you do have to use it, it is so much nicer and easier to use with man pages for almost everything and almost every tool having a nice command line interface in Linux. For example, on Linux git runs in the same command line as everything else rather than needing its own terminal. Furthermore, Linux has great tools such as zshell, or tmux. * better environment - thanks to package managers you can have a development environment set up in minutes. On a fresh debian install it's literally "sudo apt install build-essential". Furthermore, finding and installing libraries is trivial as it can all be done from the command line. * better support for dev tools - dev tools developed by the community tend to have better support on Linux. It tends to be the opposite for paid tools. I feel this is particularly true for new things e.g. the new programming language, rust, which don't have a well developed ecosystem yet, but the gaps are easily filled in by the plethora of generic command line tools in Linux. * playing with open source - whilst open source projects aren't limited to Linux it is so trivial to just download and start messing about with them in Linux. Open the terminal, git clone, install dependencies, configure, make, and there you go - you've set up your build environment for a new project using a single window. Now open your favourite editor and you're in business. Edit: just remembered * some Linux package managers will have a build-deps command which installs all build dependencies of a package so if you're interested in working on a package provided by a Linux distro it's even easier Finally, what better endorsement of Linux as a dev environment then "Bash for Windows" which as far as I know was introduced specifically for developers ;) BTW, from my personal experience it cannot replace a proper Linux environment. It's what you use when you can't have Linux. 
There's simply no way that one extra character justifies breaking billions of dollars (trillions by now??) worth of existing code. `auto` was chosen precisely because it was already a reserved word (that has lost its previous meaning), and using it would break nothing. 
Then to have a meaningful conversation, you first have to join the existing, fully functional one already going on.
`new` *is* malloc -- with some extra customization points. `new` was always supposed to support fancy allocators and customizations, but the confluence of APIs and STL allocators never really took off then way it was hoped.
&gt; a lot of cloud solution service use linux os as their develop environment. why not use Windows os. Where the resulting program runs is completely orthogonal with where the code is developed... Do you mean 'develop _for_ Linux'?
Windows is a pile of unmanageable mess. Linux is a pile of manageable mess. macOS is a pile of unmanageable shit. I prefer mess than shit. And I handle Linux much better than Windows. 
No it's not "sad", it's C-compatibility. The compiler generates the same code, it just looks "ugly" to you as a human -- probably because you value looks over function. Again, if you don't like that C++ pays a price for C heritage and strict compatibility, then you don't want C++. If you want a language that "looks good" you don't want C++ -- it's ugly as hell! If using C++ gives you emotions like "shame" and "sadness", I suggest using it is not healthy for your well-being, and you should stick to something else.
Microsoft Office is written in C++.
You could not have searched very hard for those tutorials, I suggest you try harder. (Honestly, kids these days...) C++ is used in **a lot** of GUI and graphics contexts.
People have beginners write console applications because it's significantly less complicated than anything else. Most GUI frameworks are built around an asynchronous event loop, which is a very different way of thinking about things compared to a simple `std::cin &lt;&lt; foo` which is synchronous and blocking and very easy to comprehend. You can't dive into the deep end if you don't know how to swim yet. But there is absolutely nothing about the language that requires one style or the other. The browser you used to post this was almost certainly written in C++, for example. 
Here you go, OP https://github.com/fffaraz/awesome-cpp
A different ORM per database is not a very good approach imho. If you wanna / have to change the database you must exchange the ORM too.. Sometimes you have to support multiple databases as backend as your customers dictate the infrastructure. I have no clue, which databases are used the most in C++... I named the most important one that you stumble around in your career and when dealing with db programming...
You most certainly can build graphical apps in C++. If you have come from C# and Java then you may be used to standard GUI libraries. C++ doesn't have a standard library but pretty much every low level graphics library is written in C or C++. C++ is often the go to choice for high performance graphical apps. Depends what kind of app you want to make: For your traditional style app look at Qt. For games or total control look into DirectX/OpenGL/Vulkan and the frameworks built on top of them such as SDL. 
Before you go to town, check your wallet. I think people should stop recommend Qt, because it's not cute at all... it's not standard (Java-styled) C++. For standard C++ your options are indeed limited to ancient tools. WTL, MFC, GTKMM or use plain C API (winapi/gtk+) to create something more modern with C++ tooling. 
And there's nix on Linux. Add all the reasons you might like Windows for, they won't amount to a tenth of the utility you get from nix even as a beginner.
You might want to read up on licensing 
You might want to read up their website
Maybe I'm misunderstanding what you're saying, but how are any of those more standard than qt? There's nothing in the standard about GUIs at all, every library there relies on platform specific (read: nonstandard) APIs to draw to the screen at the very least.
I don't have to. I work there
What about [CopperSpice](http://www.copperspice.com/)?
What sort of issues and problems does it have that aren't on Linux? The great selection of open source tools also exists on windows too. Also, I don't see how the weight of your development OS has any bearing on the weight of your developed application.
QT AMA? Personally really interested to see where you guys are going.
I wouldn't really be the person to ask. Your best bet is looking at the blog posts and reading the mailing lists. 
What compilers (given were talking about c++ here) exist on Linux that don't run on windows? Clang and gcc (and intel icc if you're a sadist) all run on windows. Packages - again what packages? Sure there are libraries out there that run on Linux but not windows, but there aren't that many, and the ones that do, it's not because Linux does something windows can't, it's because the developer decided to not support windows. Regarding your point about it being cheaper to deploy a web service - what does that have to do with developing on windows? Edit: regarding the downvotes - could you explain why you're downvoting me? The OP posted a few single line snarky responses and I'm looking for some more details,
Incompetence goes a long way. You should read LGPL more carefully and take it seriously. Is it possible to show us a few examples of commercial Qt applications that take advantage of your LGPL licensing? Don't get me wrong, LGPL is great and it works in many cases but in the case of Qt many things are vague...
I think what feverzsj means to say is: * It's a lot easier to install compilers. * It's a lot easier to install missing libraries * You can keep both up to date All this is due to package-managers. I don't think he mentioned software running exclusively on Linux. But it does exist (google). As for web services It's probably not relevant to the question but still true nontheless. Edit: Spelling and addition
There isn't much inherent differences between Linux and windows, IMHO. However, most of the c++ community develops on Linux, so there's a multitude of development tools and libraries that only work on Linux or are developed primarily for Linux with only token windows support. I'd like to leave you with some things I remember vaguely (i.e. take with a grain of salt) from documentation of windows versions in some libraries I've read the documentation of. "you can download a windows version of this library which is several versions older and developer by this other dude, who updates it whenever he feels like it" "Compiling on window: oh geez, I think it should compile on windows but I've honestly never tried. Try giving these commands a try (lists some commands) and that should give you a manageble amount of errors which you can then fix." This is how many libraries treat their windows compatibility...
You didn't misunderstood something, you are right about that. On other hand on those APIs you are typing standard C/C++, you compile exactly what you typed. In the case of Qt you have moc, the code you typed is pre-processed and then compiled. That's a big deal if you're the kind of programmer who cares about such things.
 https://remarkable.com/ uses GPL or LGPL, don't remember. And companies like Dropbox could easily use the lgpl license for their desktop app (but I don't have access to the license stuff so don't know if they have a commercial license).
Thank you, although it's not really what the OP said. I don't necessarily agree about it being easier to install compilers/libraries on Linux. For clang, on windows you downlod and unzip it, just like you would on Linux. (I've not installed gcc in a long time). Big Libraries like boost come prebuilt for windows and for Linux. Less "major" libraries come as source anyway, and it comes down to how familiar you are with your platforms tooling at that stage. Keeping up to date is definitely easier if your lib or tool cane from a package manager, but if it doesn't (which most of mine don't) it's a zero sum IMO. &gt; software running exclusively on Linux. But it does exist (google). Apologies I thought he did - and sure there are tools that run on Linux but not on windows but there are plenty of tools that do the opposite too Web services - yeah it's true but developing on windows doesn't stop you from deploying on Linux. 
&gt; most of the c++ community develops on Linux Citation needed? I mean, this might be true, I don't know, but the number of people who love Visual Studio and/or are required to use it at work makes me a bit sceptical.
Fair point. It's been a while since I worked with qt, I'd forgotten the moc business.
The weight of the deployment OS does have an effect on the overall weight of your deployed app. If you deployed app going to run only on linux, it doesn't make much sense to develop on windows.
Well, for starters your application will work without crashing the OS every 5 minutes 
Thanks for the time you spend to provide the links, it's appreciated. You have to note that my disagreement is not against LGPL and its merits. It's just that LGPL works really great for C source code, but in the case of certain C++ code with excessive implementation in header files it's not entirely clear if the code should be LGPL or GPL and that creates a lot of issues (lawyers are not happy), etc.
Okay, I guess it makes sense. Thanks!
How dare you call BSD shit? &lt;/not-funny&gt;
The Linux environment is optimized to be friendly for development, then for general use (not talking about an IDE under Linux, but the entire environment). The optimization at OS level is so prevalent, that many Linux developers feel an IDE is not even necessary under Linux. The Windows environment is optimized for general use, with options and optimizations for developers, mostly present in an IDE or another. On Windows, without an IDE, the environment is about as non-friendly as it gets, and if an IDE doesn't offer the functionality you are looking for, you are out of luck.
cloud services are often billed by resource usage. and licensing. windows instantly loses in the former, and the default system is not that small in terms of memory/disk footprint. as for development, on linux most libraries are available within package manager, and there are tools that will automate their inclusion into your development environment (pkgconfig especially) to save you the hassle. building software on linux is also quite trivial, compared to windows.
Better environment, tools that motivate better workflow. GNU/Linux works better. Also: free, if something is annoying you, you can just go there and change it. Like, I use terminator as my terminal, but I constantly change its code, even though you don't send a pull request to the master, you're free in your own environment. Sure, there are free softwares for Windows too, bla bla, but the whole environment reliably being free is simply better. In my opinion, it just boils down to the fact that, GNU/linux is simply more practical and comfortable to use.
All UNIXs are shit. Linux is not shit because it's not UNIX. So is Windows.
Try io2d. https://github.com/cristianadam/io2d https://cristianadam.eu/20160228/introducing-c-plus-plus-experimental-io2d/ It should be add in next c++ revision. https://isocpp.org/std/status
Exactly. Windows without an IDE is as unfriendly to developers as you can possibly get.
We had Wt under evaluation 3-4 years ago and although it was looking promising, the C++ model for the web didn't fit well in our needs. Furthermore the result wasn't very beautiful and the resulted pages so slow, that the solution for the embedded device, was dropped. We chose and never regret, to use [GWT](http://www.gwtproject.org) and implement our REST server. I hope that things have improved since then.
I don't understand why is this downvoted? Ok, it's certainly exaggerated, but have you guys really never had random blue screens, freezes and weird stuff in Windows every now and then? I'm a systems programmer for years, I don't think I experienced even one purely linux kernel bug. Just by looking at the kernel, linux is demonstrably better than Windows' kernel (whatever it is called).
/u/Drugbird's comment is probably more relevant to the open source community which for natural reasons is centered around Linux. Probably not so applicable to proprietary/enterprise software. 
Furthermore, for those who live in the dark ages, the traditional Qt widgets are no longer developed, it looks like that it's in maintenance mode for a very long time. The modern era of Qt (5.x) prefers QML for GUI, QML has many dependencies (it's huge) and certainly it's not C++. So, more or less you are in the same league with the tool-set provided by the vendors for C++. The main advantage is that you would be much leaner without Qt, etc. Qt is an "excellent" framework for what it does, it's just that I cannot accept it as the "de facto" standard for GUI development in C++ and the right solution for everything because it isn't... 
No problem. I can see that being a concern when you have to pass it by lawyers
To be frank, I don't "download and unzip" anything on Linux, and I would be willing to claim neither does any other sane person.
&gt; have you guys really never had random blue screens, freezes and weird stuff in Windows every now and then Only if you have a bad driver. And I've had *terrible* drivers and GUI software in linux over the years. Overall Windows has been much more stable than any linux desktop I've used in the last decade.
You've called out the linux fanboys, that's for sure. Remember, Visual Studio is still *by far* the best IDE out there. The linux CLI is great, which is why Windows has it too. Frankly I think the whole .so versioning situation in linux sucks ass. And documentation? MSDN is great despite the occasional oversights (which really burn). And build systems/scripts for linux? There's a ton of them and they all suck. Download any project with a *configure* script and open it up. 100,000 lines of total auto-generated crap, no surprise they only work half the time. There's a reason Microsoft has already made big inroads in linux C++ development with their alpha-quality VS Code IDE. Their biggest competition is emacs, literally.
Your internet browser you're using right now is written in C++. 
&gt; Remember, Visual Studio is still by far the best IDE out there. I share this opinion. Still, how good Visual Studio is for an IDE, has nothing to do with OP's question ("what is the advantage when you develop on linux os instead Windows os?") Rest of your answer: &gt; The linux CLI is great, which is why Windows has it too. Ok. &gt; Frankly I think the whole .so versioning situation in linux [...] documentation? MSDN is great [...] build systems/scripts for linux [...] they all suck; [...]There's a reason Microsoft has [...] alpha-quality VS Code IDE [...] emacs. This has nothing to do with OP's question. Downvoted.
&gt; For clang, on windows you downlod and unzip it, just like you would on Linux. (I've not installed gcc in a long time). No, on linux you type 'apt install clang' or 'pacman -S clang' or 'yum install clang', you wait ten seconds and you're good to go.
Outstanding, make sure that your software does not use an architecture around plugins because among the other things Qt is bad, it seems doesn't do very well with non-Qt plugins. I would recommend to stay native to the platform you are interested in; historically cross-platform has always been rubbish.
&gt; This has nothing to do with OP's question. It's the rebuttal to all the bad answers here.
&gt; every tool having a nice command line interface in Linux. For example, on Linux git... *That's* your example of a nice CLI? &gt; Open the terminal, git clone, install dependencies, configure, make, and there you go You make it sound easy. It's not easy. Dependencies can have dependencies can have dependencies, and configure is the worst development tool I've ever seen. It only works half the time because it's a horrible mountain of autogenerated shell code.
Fair enough - seems that the advantage is a package manager though, rather than it being linux (e.g. `brew install llvm` on mac)? There are package managers on windows (chocolatey comes to mind), but I can't speak for how good they are. 
Look a lot of simple: - ./configure &amp;&amp; make -j8 install, then grab coffee OR - cmake . &amp;&amp; make -j8 install Becomes painful on WINDOWS, and most times end in tears. Shitty OS, Shitty Compiler...
I never mentioned deployment os. I said development OS. And it still doesn't, e.g. you don't get a bloated rasbpi executable because you're running with a GUI on the machine you compiled it with. If your deployed app is going to only run on linux then sure it doesn't make much sense, but you just brought that up there. OP didn't mention deploying only on linux, neither did you in your first reply, and neither did I in my reply. 
they are not good
If the app is going to be deployed in the cloud, it's most likely going to be linux. So it makes more sense to develop on linux.
&gt; Still, how good Visual Studio is for an IDE, has nothing to do with OP's question ("what is the advantage when you develop on linux os instead Windows os?") OP's question presumes that there's a clear, singular advantage to developing on Linux; VS' quality and existence as a Windows-only product challenges that presumption. This is perfectly on-topic. &gt; &gt; ... &gt; This has nothing to do with OP's question. Again, it challenges OP's question rather than answering it. No problems here IMO. EDIT: added 'singular'
I think Visual Studio's debugger is by far the best one
Yes, I was indeed over-thinking it. Thanks anyways :)
Have you used CLion yet? From the same authors as ReSharper and IDEA, it's an amazing IDE. Works also on Linux, and is the best IDE for C++ I've used yet.
[nana](http://nanapro.org/en-us/) allows you to write gui in modern c++.
&gt; OP's question presumes that there's a clear advantage to developing on Linux There are clear advantages in developing on Linux (just like there are clear disadvantages). One of the advantages (for example), is that the Linux environment is much more friendly to developers, **in the absence of an IDE**. The fact you have no access to Visual Studio under Linux is a disadvantage, but not as big as that disadvantage would be on Windows (because the Windows environment is optimized for general use, not for development, and developing _on Windows_ without an IDE gives you cancer). The disadvantage of not having an IDE as feature-complete as Visual Studio under Linux is not as big as (mostly) Windows developers imagine it to be. For someone with at least 1-2 years of development under Linux, this is at best a minor inconvenience. When I was developing under Linux (I am on Windows at my current position) sometimes I didn't even fire up an IDE to work (we were using Netbeans for C++ and Eclipse+CDT at the time) - it was unnecessary. 
Yes, there are advantages, but the question was "what is _the advantage_?" – singular, and presumptuous that there is some notable/overwhelming one. I don't need a sales pitch for Linux – I rather like it myself. ;-] I was just putting /u/JavierTheNormal's response in context, which _does_ makes sense if you interpret the question literally (as I also did, TBH; at least initially). People are so downvote-happy here...
I know it isn't the same, but you can add git to your CMD path in Windows, and you can get something like Cygwin to emulate a lot of Linux commands. 
Yeah, `&lt;initializer_list&gt;` is required to be present in freestanding implementations.
&gt; Congratulations! Love the new design... I hope Wt will some day implement Python scripting too, which would make development much faster! ... 
Git does have a nice and easy CLI. Though, I accept this is subjective. The dependency problem you mentioned is a solved problem. The package manager should install all dependencies or just use build-dep. I'm sorry, but this part of your comment is FUD. 
Ah yes, but why imitate when you can have the original. For free nonetheless. I think what you mention is a viable option only for people who can't have Linux for whatever reason (company IT policy for example) 
The biggest pro for using Linux over Windows as your development environment is how easy to is to get and manage third party libraries and frameworks. Package managers make life so simple. It is such a pain in the ass in Windows to install a library and realise it's for an older or newer version of the MSVC compiler or something. Even doing it manually is simpler on Linux though as you don't have to do annoying things like mess about with registry entries and such. Usually it is just extract an archive and point to it. On Windows things are not usually that simple. Also until relatively recently the MSVC C++ compiler is kinda crap. It is very good now but switching compiler vendor can be painful. 
I'm waiting for the U-turn: discard all these QML/js crap and orient on C++ again.
I understand, just thought it was worth mentioning. 
No harm in doing so :) 
On the other hand: gcc can be a tricky compiler. For example the function which is defined to return something doesn't need to return a value and gcc doesn't even give a warning. So you get a segfault when the function is run and exits. There could be a switch I don't know but popular IDEs (Android Studio) don't include it by default. Another one is the libraries specified to link against must be in certain order. If you have them in wrong order it can happen gcc will ignore the library you specified and complains about undefined externals later. Not saying linux development is bad but it's important to know it will never be a rose garden. Both platforms have their pros and cons. It matters just which platform is more familiar to you.
I mean, I'll freely admit to not know what I'm missing out on, but we don't use moc, and we've been fine. We're using Qt for making a game engine's editor (like a simplified student version of what you might find in Unity) and it's been working out. https://imgur.com/a/ZAEoY
He is probably just brainwashing you. I can only say that even companies that develop for linux, do that on windnows, so.... Also, this whole thread smells like linux propaganda, because all the reasons are wrong, and all the reasons in a nutshell would be "ima a linux fuccboii and windoz doesnt work the same way that linux does, booooooo". Visual studio is superior to anything that linux has or will ever have. Thats all there is to say. Edit: the person you responded to says some reasons, but those reasons are because the devs or the libraries are shit, not because it is somehow windows fault.
KDevelop and the standard tools. 
No, there are no concurrency-safe containers in std. This is a good thing, since making them safe for concurrent access adds a significant performance penalty that most apps should not have to pay. Protect concurrent access to containers using a mutex or something similar, or use a third-party concurrency-safe container library instead.
No, it's not safe. STL Containers are not thread safe. Only concurrent reading is safe (using only const functions), not concurrent modification.
[More detail on this](http://en.cppreference.com/w/cpp/container#Thread_safety).
That's what smart pointers and tools like valgrind are for :D
This gentleman is right, you definitely can do GUI applications in C++. Although in reality in order to make professional grade GUI applications with C++ still the barrier is pretty high and involves a lot of skill and hard work. The situation has not been improved much the last decade or so. You see as a general observation no software vendor favors C++ for GUI programming in their ecosystem anymore, in Microsoft's land the recommended way is to use their .NET things, in Apple's ecosystem Objective-C, Android uses Java, etc. So if you want to stick with vanilla C++ there are "bad" news for you since all the available tools are from the '90s, and those tools are for "Pros". (yeah, I know there is C++/CX/CLI (or whatever cute framework comes to mind) but it gets funny using those things in 2017 because none of them takes advantage of modern C++ features or style, etc). So these days, with the current trends C++ is mostly favored for infrastructure work, libraries, graphics, etc. If I wanted to start GUI programming I would peak the basic WTL for Windows, it's not perfect, but is reasonable intuitive and straight forward, plus you will learn some valuable lessons of how things work internally. If I wanted cross-platform C++ in a Java fashion and allocate memory every 3 lines of code I would pick Qt. There are tons of other widgets toolkit to choose from, none satisfactory good... It's a little bit sad to describe our situation in native development, it looks like that "next year" we are going to Mars, a year after that AI will solve all of our problems and yet after 35 years of R&amp;D we don't have a proper GUI library for C++. 
Look a lot of simple: - ./configure &amp;&amp; make -j8 install, then grab coffee OR - cmake . &amp;&amp; make -j8 install Becomes painful on WINDOWS, and most times end in tears. Shitty OS, Shitty Compiler...
You know I'm not the OP right? That aside, just because I know the reason for something (as I said, I know compatibility is important) and I'm willing to make the tradeoff (you'll never find the perfect language for your particular needs/preferences) doesn't mean I have to like it.
I have to find it online, download, unzip, install, then try to install clang. In the end, there's no clang in the chocolatey's repository.
Thanks, this was what I was suspecting
If you enjoy it and makes you happy, good for you. If you are satisfied with Qt there is no reason for me to disagree with your preference, it's your valuable work, I'm sure you will find people to love your software and prosper in the software business. For me, it's just a personal preference to dislike Qt for various technical reasons, it just doesn't feel right to me. Qt is being praised as the "best" cross-platform C++ framework and that's far from the truth, it's more of the case of "that's what we've got"; we can't do any better. Even in its native environment KDE, it feels inferior compared to GNOME. Then again it's just opinions and taste, we learn each other by being antithetical.
Thanks to the Linux Subsystem for Windows, you get a full Ubuntu install in your Windows 10 nowadays. It's a real boon for cross-platform development. A few useful bits of tooling don't work e.g. AddressSanitiser, ThreadSanitiser, valgrind, and for those you need a real Linux. But for the rest, "it just works" (TM).
http://i0.kym-cdn.com/photos/images/original/001/054/069/936.jpg
&gt; gcc doesn't even give a warning Given that everyone who is not completely insane uses `-Wall -Wextra -Wpedantic` this is not really true, though I agree that the default is an attrocity. With regards to library-linker-order: I don't think I ever had any issue there, so I cannot confirm that.
I mean, I don't love Qt, but it does the job, and from what I've seen it is the best for the things we care about. That being cross platform (for now we're windows only, but we'd like to target other platforms), good documentation, big community. We plan to eventually do what other engines have done and rewrite the editor as just another project in the engine. Essentially dogfooding the engine by using it to make itself, sort of. For now though, Qt fills the need. That post was more that, if your hatred of Qt is due to moc, well I agree, moc was terrible when I used it. When I rebooted our editor project this year and threw out our old Qt stuff that used moc, I told the new editor programmer to see what he could do without it. And thus far we haven't hit an issue. We use cmake too, and I absolutely hate that program, but it's the best if only due to community and reach.
One library to check out is cereal. It can do the same thing in a sense using its json serialization. 
CopperSpice has the potential to be a better/modern Qt, at least on paper, with more modern C++ features and no moc. But if I recall correctly on an on-line presentation I watched a few years ago, the team of CopperSpice was 2-3 persons or something along the lines and as you realize Qt is a HUGE code base, I am not sure if such a small team can conceptualize their vision into something real, production ready. I wish them good luck, hoping more people to jump ship to make it happen. Time will tell.
This might sound stupid, but... write a RESTful webservice, and write your frontend in html/javascript/css (take your pick of whatever lib, like angular/react/bootstrap/jquery). A bit of javascript hackery is pretty easy compared to native frameworks. And then who has a supported web browser can now use your client application, and in addition, you're employable as a web developer too :P Web stuff is way more general than "specific language thing for specific platform for specific type of UI", but obviously it has its downsides too. But it will force you to separate your data model from your display engine in such a way that replacing one or the other is a little easier.
&gt; What sort of issues and problems does it have that aren't on Linux? From my personal experience, all of the following: 1. Start menu not opening in a timely manner (where timely means &lt; 1 minute). 2. Not recognizing a keyboard and/or mouse, making control difficult or impossible. 3. IE won't open (illegal instruction) 4. The file explorer won't open (missing DLL). Combined with #3 this makes it difficult to install a better browser 5. Network disconnects/refusal to connect to networks 6. Laggy mouse movements, slowing productivity 7. Laggy keyboard inputs. Really bothersome during development plus many other issues that I've since forgotten about. These issues are not specific to software development.
As a general rule of thumb, any method call on an object containing data which is not marked as 'const' is not thread safe (with the obvious implication that running a non-const method in parallel with a const one will cause the const one to also have undefined behavior). If you wish to write to a container in parallel consider using mutexes or a higher level message passing library. If you specifically need a thread-safe list and don't want to use mutexes look for an implementation online, there are loads of them out there, since push_back on a list can be made thread safe without a mutex. If you end up using mutexes consider using lock_guards instead of the lock and unlock semantics.
&gt; Just by looking at the kernel, linux is demonstrably better than Windows' kernel (whatever it is called). My understanding is that Windows NT is a pretty decent kernel -- and competitive with Linux in performance -- and Windows' issues stem from its userspace. To be fair to Windows NT, Windows 7 doesn't blue screen very frequently, mostly the UI or applications just lock up or misbehave.
If something is running slow, the first thing to do is take out memory allocations inside loops anyway. The same thing slowing down valgrind could be the same thing slowing down your interactivity.
&gt; (yeah, I know there is C++/CX/CLI (or whatever cute framework comes to mind) but it gets funny using those things in 2017 because none of them takes advantage of modern C++ features or style, etc). So in MS land recently there have been developments here. Kenny Kerr and others have been working to bring C++ into their modern frameworks. They even allow you to use the MSVC coroutine TS stuff: https://github.com/Microsoft/cppwinrt
Double click exe to install compilers We have had NuGet for years now They auto update?
To be fair nowadays 99% of my command line work in linux is in bash scripts, which run just fine on Windows 10. But yes, package management alone is worth it.
Sounds like you have a bad install, because if we wanted to play error for error, Unity/Gnome being fully unresponsive and ignoring clicks at time, the drivers in Linux if you have anything other than "what everyone else uses" are trash and with no support other than "add support yourself" I get on a clean OS of Linux crash reports on Ubuntu, Cent, Debian for strange services that are broken out of the box, God fuck wireless on Linux end of story, once again back to unity being a POS and gnome builds having regressions. Sounds like a VM issue for you, if it was running native then idk what's wrong with your build. Issues come down to OS are complex pieces of work, how long have you worked with windows, just curious because most extreme Linux haters use Windows only a few times then decide they hate it off of a few issues which aren't standard. I have to flip flop between windows and Linux for development and as the base development OS as long as I have Idea/Visual Studio it doesn't really matter what OS I'm on. 
This is where your information is outdated, Server 2016 is doing exactly that, easy server depolyments and small software/os resources required. My old windows build server was 6GB 2012R2 and build slow, my new build server is 2016 nano/barebones with 2GB ram (OS uses .5gb, which is getting closer to Linux bare servers) and builds faster.
Then blame the package dev, I have downloaded many larger tools and applications ran cmake + NuGet and gotten everything I need for a clean build. (Llvm, webkit, etc) it comes down to does the original developer want to support windows or use the STL to have 100% portable code. Most people hate windows and intentionally don't do these things and release leaving windows people to figure out how to adapt their libraries
Support is being added for that iirc, technically WSL is still in beta dn under development.the pre-creators version was really janky and post creators they fixed and implemented a ton
On linux, installing and using a new compiler is a breeze: sudo pacman -S clang CXX=/usr/bin/clang++ Done! You're good to go! Simply type `make` and maybe `cmake .` in the big black square with letters in it then everything is build using your favorite compiler. 3 or 4 commands, including building the stuff I need to build with clang. On windows, I can imagine myself screaming in agony after 10 hours of trial and error and little config there and scrambling directories here.
These ranged from Windows XP through Windows 8, over several native installs. In my experience, Windows is much less buggy in a VM, although it's still pretty slow (but not unresponsive). I have little experience running it in a VM, though (only Windows 7). I used Windows heavily from the ages of 8 through 18, because my family's computers as well as my school district's computers were all Windows machines. Throughout college (for another 4 years), I continued being forced to use Windows because most of the school's machines are Windows machines and a handful of classes required me to use Windows-only software. It's only the past year (my first year after college) where I have not been required to use Windows. This totals 7 years of *only* using Windows, followed by another 7 using Windows on a frequent basis. Yeah, GNU/Linux isn't the most reliable OS out there either but at least I *can* get it working well with some effort. With Windows the usual fix is to reinstall until it's usable then give up on productivity. With Linux, I can: 1. Change configurations more freely to work around issues 2. Upgrade or downgrade packages to find versions without the bug (without a while OS upgrade and the new bugs one would introduce) 3. Switch out packages for equivalent packages (sometimes) that are less buggy. I can typically install a Linux distro then work out the kinks in the installation faster than I can get a working Windows install on a machine, and I could never quite work all of the issues out of a Windows install (that wasn't in a VM).
Agreed, I can now fire up a copy of kdevelop and it runs surprisingly well for gdb based debugging sessions, all under emulated Linux by the Windows kernel. Can't complain!
Yeah so it sounds like you have just used shit machines your whole life. Not to say your points aren't valid, but you as being experienced power user may fare better as a second install. Parents and public machines normally have issues for many reasons (changes, lockdown, malware, etc) 10 runs pretty nicely in a VM and so does 7 once updated. (Look at Modern.IE for free windows VMs to try). I would get a build environment going and port some small projects to Windows as a test. VS 2017 supports Cmake and so does Idea. On Windows I use WSL to build for Debian based systems straight out VS. not saying you have to do this, but would be worth a try in some spare time I'd you have it
Certainly Qt does some things right there is no denying about that and it's a huge benefit to have a large community around a software product and I think in general it's beneficial for some scenarios to use Qt, KDE has been a success as an alternative choice of GNOME, variety is good. I also understand your concerns and the common sense while choosing Qt, that's all fine. It's not moc only, it's the very frequently memory allocations, the dependencies, the window rendering, the feel of the software, the size of the software, reliability is not that great especially in Debian (at least in my case), baby-talk code, valuation of the software, code base is huge, the list goes on and on... I use cmake too (I have little sympathy for that too), for CLI applications is okay, cmake is a big failure for cross-platform GUI applications for Windows and macOS, the hacks involved to make our things work is extraordinary... but then again software complexity is huge too, somewhere you have to draw a line on what it's acceptable and what it's not, I guess.
What do you mean by "plugin" in the context of C++? I wrote Qt programs for 10+ years and mixed stl, qt, boost, and other libraries.
&gt; Only concurrent reading is safe Only if the methods are marked const (I don't know a case where they aren't though).
it seems that only my information on resource footprint is outdated. how is managing 3rd party dependencies in a software project on windows anyway? is there some sort of automated helper to get this under control?
Linux _is_ the IDE
NuGet for C++
Are you making software or salad? Greek salad is the best by the way. C++ does not know a lot of things about shared libraries, it's vendor specific. My example would be loading a DLL/dylib/so at runtime. This has not been very successful in my case with Qt, but then again I'm not a Qt user, I tried it at some point in 4.x era for evaluation for a software product, it was terrible, I have never used Qt in production. I just google it to see the progress since then. none. The bottom line is that Qt is good enough up to a certain point, if you want full control you have to go arcana '90s, and as an engineer you have to accept the trade-offs going that route, it's all about choice.
&gt; Double click exe to install compilers and first go on some website, download them, etc etc &gt; We have had NuGet for years now NuGet doesn't have one tenth of what's in Debian or the AUR.
&gt; &gt; &gt; "you can download a windows version of this library which is several versions older and developer by this other dude, who updates it whenever he feels like it" sounds like libxml2 or ffmpeg
&gt; which is getting closer to Linux bare servers) My Linux graphical desktop uses less than 100 megabytes of RAM on boot.
Not really, I can install clang and previous build tools all from vs, or they give you DDL links to just run a exe. And that's true, but who really says you are going to use 1/10th of what's in the repo? Most popular libraries or well maintained repo's are all up to date and support all VS supported compilers. Also I personally like NuGet better because of versioning issues, I can get latest or oldest at a single click. Trying to get a newer or older versions you will have to modify your repositores to get them. (Feel free to correct me on this, I'm always looking for better alts) This isn't a war on which platform is better but what I feel personally is quicker to use, the less time devs spend setting up and configuring their environment the more code they write. Idea helps this greatly on Linux but it's (imo) the only xplatform contender
Okay do you want a medal? Doesn't apply to the current convo much :/
I've got plenty of experience developing on windows, and _some_ experience on linux. I've had more issues with autotools on linux than I have with cmake on windows. What compiler are you talking about? clang and gcc both run on windows. 
vcpkg
In the end it boils down to the way linux distros are designed. The linux kernel in itself lends itself better to developers because of the amount of its open source nature and the API, however that is not what makes it so great. Linux distors and BSD are designed with the idea that the user is someone that will write code and try to modify the environment. A quick example is the idea that users should be able to use a ptty, which leads to being able to get help quicker because you can use bash snipets to do something instead of following visual guides. You can have linux distros (Android) and BSD offshoots (OSX) which are just as bad for development as windows. On top of that, due to various factors I won't dive into now, most servers, especially those in large scale systems or systems that need to be efficient run a linux distro. That means the environment you have on your dev machine is much closer to the deployment environment.
Thanks for the link, that's interesting, and some terrifying ugly code at the same time. It also does not use bottom line C++ which is a big problem. From experience I never use things from random sources like github and the like due to some required functionality on my long term software projects, I tend to use only what it's provided by the vendor. See what happened with WTL and latest VS, it was broken, it's an unofficial library and you rely on volunteer work to get the fixes, that's not how you run a software business (I think they fixed it immediately by the way, not sure although).
I personally love [the Linux subsystem on Windows 10](https://msdn.microsoft.com/de-de/commandline/wsl/about). Obviously you don't have a native graphical interface, but for a lot of terminal-only stuff it works like a charm.
Thank you. No I don't feel discouraged, honestly the responses were better than I expected. I already program in rust and have played with go. I would move all my cpp programming to rust if qt bindings worked with it. For firmware I still prefer c/cpp. Rust is great but over annotated. Cpp was my first real language I learned back in the mid 90s, I guess I look back with rose colored glasses and hope. Thanks for the kind words. 
&gt;Big Libraries like boost come prebuilt for windows And then you end up compiling them yourself anyway, because you use different compiler flags, or a different VS version. Gcc is much more lenient to this, but there are a few occassions where you don't want to use the distro bundled version.
Prepackaged, readily-available dependencies is the only advantage. This makes the threshold for downloading, compiling and playing with $random project much lower. Everything else is inferior compared to the windows experience. 
You do see that that's Microsoft's official repo, right? WTL was developed by MS and then abandoned to the community; C++/WinRT was developed by the community then acquired by MS. Not really comparable...
Weeeell the standard does require that for `std::vector` (except `std::vector&lt;bool&gt;`, but we don't talk about `std::vector&lt;bool&gt;`) concurrent access to _different_ elements is safe. So you can do certain things, and not many others.
I'm a Linux user (Fedora) who is going this route -- I got a new laptop and kept the Windows 10. I installed the WSL, and for things in the terminal, it's the same as a "real" Linux. At my "level" of development, I can also work with Node, Ruby and Java in their Windows versions but have the Linux versions available as well. Sure, I miss all of my backup scripts that used rsync, but I could probably re-create them in the Windows version of the utility. On the negative side, I use Unison for file sync in Linux, and the lack of proper ssh in the Windows version makes Unison on that platform pretty much useless. the Windows file manager isn't the worst thing in the world, so until something really irritating happens, I will probably stick with this setup.
I do acknowledge the lack of a Linux-style updating mechanism in Windows, and I do miss it. Fedora is a great system, and it gets lots of updates. You get a patched system without doing much thinking, and I appreciate that. But once I started needed to install Node modules and Ruby gems, it's a bit of a mess to have half of them under Linux package management and others installed via the programming environments' package managers. 
I actually prefer Windows to Linux as a development platform. Backward compatibility on Linux machines is hilarious.
&gt;better command line [PowerShell Core](https://github.com/PowerShell/PowerShell) &gt;better environment [vcpkg](https://github.com/Microsoft/vcpkg) &gt;better support for dev tools, ..., the new programming language, rust ??? rust is cross-platform. I could not figure out why Linux beats Windows on rust dev. With rls, VSCode, WinDbg, I develop rust programs smoothly. &gt;playing with open source ??? Windows can "Open the terminal, git clone, install dependencies, configure, make, and there you go" too ? Windows has git for Windows, Powershell has Posh-Git. 
&gt; Yeah so it sounds like you have just used shit machines your whole life. If you are blaming hardware, then I'll point out that Linux driver issues are the same story. When I buy machines for myself, I always purchase hardware with good Linux compatibility -- with the exception of graphics cards, where there is no good option. If you are blaming the machine's management (IT/parents/users), see below: &gt; Parents and public machines normally have issues for many reasons (changes, lockdown, malware, etc) My parents installs weren't locked down, weren't highly customized, and malware hasn't been an issue. The IT-managed machines I've used generally haven't had the listed issues either, other than being a bit locked down. &gt; and so does 7 once updated My experience: A new, clean, updated Windows 7 install experiences few bugs in a VM but still runs far slower than Linux. It is a useful environment for running Windows-only applications but I see no other uses. &gt; I would get a build environment going and port some small projects to Windows as a test. VS 2017 supports Cmake and so does Idea. On Windows I use WSL to build for Debian based systems straight out VS. not saying you have to do this, but would be worth a try in some spare time I'd you have it "Why?" Best case, I end up with an OS that is slightly easier to setup than Linux (assuming my experience with Windows 10 is *far* better that my past experiences with Windows) and supports the same functionality with lower performance. The *expected* outcome is I've wasted my time and money trying to configure an OS I have no reason to use. The original post asked what the advantage of developing on Linux over Windows is. I gave an answer based on my personal experiences. Convincing me to try Windows again will take more than "I swear it's less broken now", it will take "Windows has X advantage over Linux", and I don't see such an advantage.
because the operations have a defined order, and '/' happens before '='. http://en.cppreference.com/w/cpp/language/operator_precedence
The / operator is used within int variables. Therefore, it's the int / operator. Then it's stored in a double variable.
The right hand side is evaluated before being assigned to the double variable. So really it's just saying "double Foo = 1" Not very satisfying in this case, but at least it's consistent.
Being open and at least trying it, that was all
But c++ already makes assumptions about what you mean. For instance, that / is the int's /. So why doesn't it look at what its being assigned to, a double, and make the assumption that you don't want the truncation?
std::map inserts on operator[] if the key does not exist.
An operator only knows about its operands. It doesn't know about any other context. The division operator only sees 5 and 4, and those are both ints, so it performs integer division. The fact that the result is assigned to something or used as an initializer is not relevant. That's a separate step that happens after the division operator has been evaluated. 
Yeah, I saw it, sometimes it takes years to consider something for our production software. You're correct about the history! When that software gets in the production line I will "consider it for evaluation". Have in mind that Microsoft is a software company (the software company), when it does not put the effort to produce something for their own needs or the needs of their customers, "maybe" the quality or support is questionable. I paid a hefty amount of licensing for VS, do you expect me to use some random community acquired software? Certainly not, I will wait for the official stuff. After all, at first glance that code there, is not production ready. 
Most of them are fine with concurrent reads, just not writes.
Because an operator is wholly defined by its operands and nothing else. If it were any other way, operator overloading wouldn't be possible, as there would be no way to communicate any extra context. Besides, it would be wildly inconsistent. Very few programming languages have context-dependent operators; Perl is the only one the comes to mind. 
&gt; when it does not put the effort to produce something for their own needs or the needs of their customers, "maybe" the quality or support is questionable. They formed a team and hired people specifically to make this compiler better, faster – that doesn't sound questionable to me, that sounds like a long-term investment. What _is_ questionable is clinging to old truths and assuming they still hold... MS has been a different beast since Ballmer left (in regards to OSS); it's been _years_ now – time to clear that mental cache, if you know what I mean. -- &gt; After all, at first glance that code there, is not production ready. It's generated code; the entire project is (that's sort of the point), and personally, I've rarely encountered generated code that was intended to look pretty. I get a strong impression you didn't really read what the project is even about... &gt;_&gt;
Everyone has answered the why, but you may want to know how you get the value you were looking for in the second case: double num = 5. / 4.; Actually, just one of them needs to be considered double by the compiler, and it will promote the other to double. Edit: double, not float.
I believe _all_ the `std` containers are good with concurrent reads, though using the non-const `operator::[]`indexing in e.g. `map` or `unordered_map` has the potential side effect of creating the element if it didn't already exist, so it isn't actually a pure "read" (use `find()` or `at()` instead). EDITED: add `find()`.
That makes perfect sense in other situations. But what is the purpose of not making all division floating point based, and auto truncating if needed?
Nitpicking: 3. (and 3.0) are of type *double*. 3.f (and 3.0f) would be *float*.
Thats handy to know, thanks. Do you also happen to know why all division isn't floating-point by default, with auto truncation as needed?
Because floating point operations are ridiculously slow.
Because that would make integer math wildly inaccurate.
Because compared to integer division, floating point division is much more expensive, especially on platforms that do not have hardware float support. This has been carried over from C, which comes from a time well before our fancy and speedy floating point computers.
I don't remember exactly which library it was, but I've worked with both of those libraries so you might be correct 
That's all true, when your environment is an exact match, but it gets much more complicated if you're using a different distribution than the package developer and trying to build the latest source that has dependencies on different versions of things that your distribution depends on. It's still easier than Windows, but far from trivial. 
Yes. Editted. Thanks! 
I feel like either you misunderstood the argument, or I misunderstood you. struct Foo { Bar a; Baz b }; Given this declaration, when a `Foo` is destroyed, `b` will be destroyed followed by `a`. And, of course, `a` is always constructed before `b`. Aggregate initialization does not literally create any initializer list; the members are initialized directly in place as though in a constructor initializer list. This means that if you wrote: Foo f = { .b=0 , .a=5}; I don't see what option the compiler has other than to initialize members in a different order, or evaluate the contents of the curly braces in a different order. Both of these options would contradict widely held rules in C++ so the third option was just to make it illegal. 
The language spec could be rewritten to specify a double return type for integer division, and I'm sure compilers would handle it optimally (emitting integer divides for the case where it was immediately truncated after the division), but it would break a large number of existing programs, and so would _never_ be done.
I would assume because C++ was derived from C, and C was designed at a time when you'd have wanted int to be default. The opcodes are different, and the runtimes are dramatically different (not that it matters for single a one-time initialization). Floating point division was insanely expensive for many years (compared to integer). 
Your hack doesn't solve the problem. If you allow different instances of a class to have its members initialized in different orders, there is no way to destruct in reverse order without storing extra information in the instance. And if you allow destruction to occur in not-reverse order to construction, you open the door to more issues: construction can be completely valid where one member grabs a reference to an already-initialized member, but then in its destructor it may use that reference, which would be safe if correct destruction order was followed but not otherwise.
I agree. ......I have always had stability issues when dealing with windows. After using linux for 15 years straight, back in 2013 I bought a windows laptop and challenged myself to not format it when I made a drunken bet. Windows 8 was pretty stable, windows 8.1 was even more stable, but once I upgraded to windows 10, bam same old windows I remember from the early part of the century. Constant lockups and blue screens.
Windows 10 solved a lot of this by having a native Linux environment built in. Developing on Windows now a days is better than developing on Linux in my opinion, with the only major problems being a lack of a good built in xserver, which is coming "soon". I don't see any reason to develop on Linux anymore, the Ubuntu ENV isn't even a VM, it's native, so it's like having everything in Linux, but with the support of Windows.
It came across as a strong indignation rather than a mild lamentation. Text is bad for these subtleties. I'll just never understand people who criticize a valid set of trade-offs. Rust and Go and Python and Haskell are all very nice languages. I even enjoy C and Java for what they are. Use the best tool for the job at hand...
&gt;concurrent access to different elements is safe. That's true. It's important to keep in mind the limitations of the guarantee. If you access an old element while pushing back a new one you may find that the vector has grown and your first iterator has been invalidated.
This is a more general question and should be posted in r/programming instead.
&gt; This is unfortunate, it means we aren't really getting named parameters in the sense of being able to reorder the parameters at will and have the compiler sort it out. The real value of named parameters is not re-ordering. It's just the fact that it documents what each parameter does in a compiler-enforced way. Having a function with 3-4 arguments where two of them are ints or doubles is just a recipe for disaster in C++ (and most languages), which is kind of sad. Python isn't even statically typed, and regularly has functions with many more arguments, and doesn't have problems because the code is so clear to read and write. The other thing you aren't consider is that named parameters gain a lot of value when there are many defaults. AFAICS, this proposal only said that the members which are being initialized have to be in the right order, but there could be many members you don't initialize which fall back to the defaults (as of C++14, things like `struct A { int x = 0; int y = 1; }` are still considered aggregates, so you should be able to do `struct A a = {.y = 4};`. In C++ you can only override defaults in left to right order, making the value of defaulted arguments past 1 per function very low. Again, contrast with python which often has functions with many arguments, but where all of the arguments have reasonable defaults, and users will typically only provide 1-2 of their own keyword arguments. It's true that usually there are not dependencies among the members, but destruction in reverse order of construction for all stack and member variables is one of the most reliable things in C++. It applies even to globals, and static locals. Basically to anything other than new (i.e. situations where a destructor gets called manually). It's an important thing to preserve. My conclusion is basically that this proposes a lot of value and they decided to steer around the complexities and "play it safe". I can respect that decision.
You could use a circle-drawing algorithm with a progressively larger radius... Or just floodfill testing the distance from the "center" point each tile to cap how far it can flood. But otherwise no, a grid will always try to give you square or diamond shapes, and you have to somewhat fake any circular effects.
Ofcourse CMAKE works better with Linux. &gt; What compiler are you talking about? clang and gcc both run on windows. Visual *crap* 
Windows 10 eliminates this problem by natively supporting debian packages through their bash shell. 
Last time I used a windows 7 computer I had nothing but blue screens. .....it was a work computer and I would blue screen about mid morning and everyday at around 4pm. And yes for the time period, windows nt did not blue screen as much as windows 95/98 but it still did very often. For me I personally thought windows 2000 and windows 8.1 were the most stable. 
TBB is providing concurrent vectors which are threadsafe.
Keep in mind that 30 years ago most consumer computers didn't even have floating-point hardware; it was [a separate processor](https://en.wikipedia.org/wiki/X87#Architectural_generations) and you certainly couldn't take its presence for granted (until the 486 became sufficiently widespread).
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
As an embedded developer I can tell you that floating point math is still insanely expensive.
True. It's not so bad on modern desktop. 
It doesn't. I want to build a native windows executable.
Removed, off-topic. Try r/programming
&gt; use `at()` instead I'd recommend `find()` instead; `at()` is a perfect example of how _not_ to use exceptions.
Well, it depends on what you're doing. If you have a tight inner loop doing a lot of math, it can be a big difference even on modern desktop. Think of game engines and physics simulation, etc.
When I took a C++ class in community college, they made us use Visual Studio. At the time I was running Linux, and I used a combo of Netbeans and Geany (which can easily compile and run most things in the editor).
Normally I would agree with you, and my Windows 7 desktop that is aging rapidly at the office is more creaky than I'd like it to be. But my Windows 10 laptop, which is only 6 months old at this point, runs like the proverbial wind. 
I've used a lot of Linux over the past 10 years, and driver issues are real, especially with new hardware. Windows isn't a bed of roses, but there is more vendor support.
Which translates to how many pointers? Including this? 
If t works it will be.
The debian packages are native which makes the pseudo-cross compile super easy. 
You're almost always better off doing everything in float. Physics is almost always done completely in FP these days, for accuracy and simplicity. GL uses FP. The days of using integer or fixed for that stuff are long gone. 
The first thing I do is profile to find bottle-necks. Optimizing my code to be able to run a profiler... Ill just boot into windows and fire up VS thanks.
On your platform. 
&gt; On your platform. ? I stated "modern desktop". This is almost always, with very few exceptions, a modern Intel or AMD CPU. I've done a shit ton of physics and game simulation. I actually have written several distributed simulation engines. With some care around data structures, and getting compilers to produce the code you want, and making use of SSE/SIMD, it's more than performant enough, and no one would consider not using FP. And consoles are not using integer for that stuff any more, either. 
"Native" as in, COFF executable, not ELF executable. "Native" as in being usable in the Win32 subsystem and in VS builds.
I see you're uncomfortable with the design decision here, judging by your comments like the following. &gt; why all division isn't floating-point by default, with auto truncation as needed? So let me show you why that wouldn't make sense. First of all, I'm going to use axioms to prove why a multiplicative operation (product or division) doesn't produce a value of type float/double when both operands are integral values. The first axiom is that `operator /` could be treated as a function. So let's define it: int div(int lhs, int rhs); float div(float lhs, float rhs); Second axiom is that function overload works by selecting the right function for some given arguments. This involves matching the arguments' types to every proponent. For example, calling `div` with the arguments `42` and `0`, the first overload is selected, because both arguments are of integral type. If you call it, however, with `3.14f` and `42`, the second overload is picked, because `3.14f` is of type `float`, and the second argument is cast into a float (this behavior is defined by the standard). Alright, let's analyze some of your code examples now: int num = 5 / 4; Transforming this code using the axioms we just defined: int num = div(5, 4); We clearly see that the first overload (`int div(int, int)`) is called here, producing a return value of type `int`. double num = 5 / 4; double num = div(5, 4); // transformed In the second code example, it's still calling `div` with the same arguments as before. Hence, the same overload is called, which returns an integer. Following question is now easily answered by using the axioms defined above. &gt; Why isnt this operation automatically handled as a float operation, then cast to int if needed? Because that is **not** how function overload works.
I'm not saying consoles. But to say that no one would consider not using FP is wrong. We had to get Fourier transforms performant in near real time on a mips processor to analyze motion. I'm talking about that sort of thing. Also doing calculations for smooth curves on a small arm processor, same deal, had to do it in fixed 
&gt; But to say that no one would consider not using FP is wrong. I didn't say that. You used the example of game engines and physics on modern CPUs. &gt; We had to get Fourier transforms performant in near real time on a mips processor to analyze motion. I'm talking about that sort of thing. That is not the example you used. &gt; Also doing calculations for smooth curves on a small arm processor, same deal, had to do it in fixed Not a modern desktop CPU. I'm not sure why you've changed everything. I agreed that in embedded, FP isn't a default choice. 
Okay I'll grant you that most physics engines use FP these days.
Right, like I said you still have to cross compile but because of the collaboration with Canonical that support is very good since all the Linux binaries are translated to run natively anyways. 
In Ballmer era we paid and most software was working, in the modern era we pay and we are beta testers. But does that code compile with exceptions turned off in companion with the VS' exceptions switch? 
I do. Checkout the source code here https://github.com/NuLL3rr0r/blog-subscription-service I also used the 3.x release throughout the years for a few customers.
Good point - edited.
&gt; ... not concurrent modification This could be read as "multiple modifications cannot be done concurrently" so, to be clear, a read concurrent with a modification is also unsafe.
Sorry, but this &gt; since all the Linux binaries are translated to run natively anyways does not make any sense. Nothing is "translated", the NT kernel emulates Linux system calls. Care to outline how would I use the Linux subsystem to build, say, ffmpeg that I can use in visual studio and link against a native Win32 program? 
By using GCC and cross compiling to a windows target? 
Also, `auto` communicates "this is a variable with an automatically defined type" better than `var`.
This looks like an implementation bug in the library: http://en.cppreference.com/w/cpp/container/unordered_set/deduction_guides Deduction guides are really new, so it's not surprising that implementations are still a bit rough around the edges.
If you're asking specifically about MSVC's `std::string`, in release builds it's the size of 4 pointers and in debug it's 5.
Indeed, CLang's error message is to the point: &gt; error: no viable constructor or deduction guide for deduction of template arguments of 'unordered_set' Read as: "implementation incomplete".
&gt; Deduction guides are really new, so it's not surprising that implementations are still a bit rough around the edges. But Herb told me compilers are all implementing C++ standards now super fast. ;) Anyway this is good news, I was already preparing myself to explain my dev friends about this cool new feature in C++, but then having to explain to them 8923 exceptions where they can not use it.
Nowhere does my hack allow different instances of a class to have its members initialized in different orders: &gt; The initialization is still done in the order of declaration [...]. The key change is that the members of the initializer list are evaluated in initialization order, not in lexical order, and a hard dependency check is performed to ensure that no uninitialized values are accessed from the initializer list, or from member initializers within the class declaration.
You are right, forgot about that c++17 feature. What's afaik still not possible though is the equivalent of `struct A{int i;double d;}; A a[] = {{1,3},{1,4}};` ?
Not necessarily. It just means the compiler couldn't find one. It has no bearing on wether one should have been implemented or not.
Is it the water or the cooked potato? Would microwaving help. I really hope you are not trolling because this would fit classical trolling and would be awesome. This could also be nerd sniping... I don't care. It's an awesome thought trajectory
Right, agreed; but the way the question was phrased, I assumed OP knew it's supposed to compile. Maybe a poor assumption on my part. :-S
Pre-emptive reminder for this thread to stay sane.
I do with the isapi plug-in for https. Avoid using packer on your javascript because it causes my site to break due to incompatibilities with the Wt internal javascript. Closure works fine with Wt though.
that's pretty neat. i'll have to try it once i find some vs project to build.
If the dependencies you want are in your package manager, great. That's rarely been my experience. Usually I'm developing with some oddball software that's not popular enough to be in a package manager and it's a PITA.
I haven't, but it's on my list to try.
You're kidding, right? For years that was how you got video drivers, VMWare, and other commercial software on linux. It's nice when they offer the right kind of package file for download, but not everything is in your distros repository.
libstdc++ hasn't implemented deduction guides for non-sequence containers yet. All those standard library deduction guides were rushed into C++17 at the very last minute, and the underlying core language feature got even more tweaks after C++17 was voted out. Not surprising that this is taking some time to implement.
 const var = 1; wooo const var foo = 1; // correction 
something something fearless concurrency
&gt; bought a windows laptop and challenged myself to not format it when I made a drunken bet Windows + bloatware is not a bet I'd take on.
I optimized it...removing all of the bloatware. ...I actually bought windows 8 professional and did a full reinstall for this bet and used it with software I selected personally. 
&gt; were rushed into C++17 at the very last minute whoever did this big thanks to them. Most "normal" people need automatic template parameter deduction fo classes mostly when they use containers.
&gt; Most "normal" people need automatic template parameter deduction Considering that this is an extremely new feature, I'm somehow skeptical that anyone "needs" it right now. Is it a good feature? Sure. Should the compiler implementation teams be working harder to get it working? Maybe. Is anyone going to see their project stall because of an inability to use this feature? Probably not.
Do Rust-related threads in here tend to derail?
You need to lean a GUI API. Those are either light weight but highly coupled to an specific operative system, or huge code bases with thick layers of abstraction that allow them to support different operative systems.
Have you considered rewriting it in rust?
Did you even try it? I mean, exactly that code will work fine. It works in *C++03*! Or are you talking about a std::array equivalent TO that code? 
&gt; What's afaik still not possible though is _the equivalent of_ ... ;-]
Have you considered rewriting your comment in Rust?
Savagery!
What do you mean by "lack of proper ssh"? You can [run sshd as a service on the WSL](https://superuser.com/questions/1111591/how-can-i-ssh-into-bash-on-ubuntu-on-windows-10), the only shortcoming is that it runs only after login.
Mind letting me know how you learned? Sources etc? I've taken apart someone's malware before and turned it into a keylogger buts that all I know right now, and what I'm able to extrapolate from gray hat python. Your reward for your help? I'm bringing my currently open source invention, the shake separator to your attention. Just Google 'Shake separator' 
&gt; Is it a good feature? Sure. Should the compiler implementation teams be working harder to get it working? Maybe. Is anyone going to see their project stall because of an inability to use this feature? Probably not. I am not talking about how it should be prioritized. What I am saying that most of normal users just want their template types to be deduced automagically in containers since most users do not really deal with huge amount of other templated structs/classes. So this was praise for somebody in ISO for being reasonable wrt Average Joe McDeveloper.
I think this is off-topic, actually. Why do I care that it's written in C++? This doesn't help me as a C++ programmer.
Gah, I'm dumb. Deleted, thank you. I looked at "other discussions" and didn't see it listed.
I looked into this a little further. Now, with the deduction guide present for std::array this isn't possible, because "partial" deduction of template parameters from constructors is not legal. Therefore there is no way to specify the element type, but not the size. Another deduction guide would have to be written to do this job, if possible, though I can't think of how to do this without something like a tag type as a first argument to tell it what the element type should be. However, I think that it is possible to achieve what you want like this: `auto a = std::experimental::make_array&lt;A&gt;({0,1}, {1,0});` This uses code from the Library Fundamentals v2 TS, so not even in C++17. However, it doesn't compile using GCC, and Clang doesn't even have the requisite header. I suspect this is a quality of implementation issue, though. I couldn't find an absolutely equivalent example in any proposal or implementation of the feature, but I did find other similar snippets which should compile, but do not. So, assuming that this is meant to work, it's probably as close as you can get, without repeating the 'A' for each element. 
Not trolling or nerd sniping. Real technical problem. I am making a remote controllable GladOS Potato like from Portal 2. It will broadcast a wifi network and you can control the voice from the web page it is serving. I have the web server working right now with Wt 3. Still working on the potato power details. But I have copper, zinc and steel nails to play with. Not exactly a serious project so I skipped the details until now.
They forked Qt4 and it's lacking lots of cool important stuff (and things that got massively overhauled) in Qt-5.5, 5.6, 5.7, 5.8, and 5.9. As one example, the whole QtGui/OpenGL/Qt3D stuff.
That's a good point about default arguments. I agree that this feature will be more useful than I thought at first. I hope at some point they review the spec regarding out-of-order initializer lists in constructors, and the rules they are making now for tagged initialization in aggregates. It seems that the concerns are the same, but the committee reached different conclusions. In constructor initializer lists, if you initialize things in the wrong order and create a bad dependency, you shoot yourself in the foot, and the standard doesn't say it is ill-formed or anything. In the case of an aggregate though, they are conservative and require you to use the correct order. IMO it would be good if they either made both of these one way, or both of them the other.
Yes I did, but then I discovered the Kotlin to Lisp to Reddit transpiler.
Really though? If yo'ure making a set I can't imagine a scenario where you don't know what you're making a set *of*. It wouldn't have been an issue to write unordered_set&lt;int&gt; or vector&lt;int&gt;, and tbh I'd probably want the type to be written out fully if I was reviewing code like that anyways. Either it's obvious enough to use auto or it's non-obvious enough that the type should be spelled out.
ah, this is just auto arguments all over again... I am auto fanatic except when it is replacing bool, or there is some signed/unsigned tomfoolery.
I can't even tell if you're presenting a counter-example or an example of what I'm saying. This could not be a valid C++ statement in any case. To clarify my previous post, there are many languages where identifiers are not bound to types. `var` communicates that this is a variable declaration but it is not a good indicator of whether the identifier has a static or dynamic type. `auto` indicates that the omitted type is defined at the point of declaration. I feel it suits a statically typed language better than `var` does. Also, before `auto` the C++ language required explicit type declaration for variables. `auto` is more consistent in this regard because it means "automatically deduce the type", so it is an intuitive replacement for the variable type in a declaration. On the other hand, `var` is a keyword which you wouldn't guess replaces the type declaration unless somebody told you.
I thought refactoring was Rust's feature with the fear free guarantee
Actually most of the tooling for Rust right now is really immature so there aren't any powerful refactoring tools like Eclipse Java has yet. We can barely get suggestions working because apparently doing local type inferencing is an unsolved problem. Hopefully RLS solves some of these issues once IDE tooling comes up to speed.
Yeah, when people talk about it they usually mean "manual refactoring" rather than automatic. This stuff is coming along though; RLS reliably gives me suggestions these days. Lots of work to do though, as you say, C++ has extremely mature tooling here, Rust doesn't yet. It should get much much better over the next few months.
tested on clang-6+libc++ and gcc-6+stdlibc++; the github readme has been updated https://github.com/loopperfect/smallfunction. Turns out clang optimizes slightly better but libc++ std::function implementation performs 25% worse compared to stdlibc++ 
GPU stuff with Vulkan.
The thing is that I will bet money that if the committee could go back in time, they would have made constructor initializer lists in different order from declaration an error. I think it's more recently that people understand the value of not being unnecessarily permissive; it keeps code more homogenous and prevents misunderstandings. Having a different ordering in declaration and constructor initializer list btw triggers quite a serious and standard warning, -Wreorder, that I highly highly recommend everyone utilize anyway. So for me I'd say the right thing to do is to be conservative in both cases.
Actually, I was asking about how many pointers I can capture "for free" in a lambda that I stash into std::function. Yes, MSVC.
I am pretty sure you have a communicable form of nerd sniping. Cool project. I wonder if the study of the parametrics of potatoes for the use as a renewable power source could be Ig Nobel worthy. 
I think of it more like corrosion than derailing...
Agreed. Removed it.
I use it to remind myself how superior Rust is. Come at me bro.
The reason you see less development around qt widgets is that they are largely feature complete. What would you honestly expect them to be adding? 
Qt is still very much a c++ framework, and there have been a steady stream of new c++ only modules in recent releases. QtQuick just provides a convenient way to create certain types of guis.
Everything the company I work for makes is released with Qt under an lgpl license.
STL said the SBO heuristic is the size of one `std::string`, and I listed the size of `std::string`, so.. there you go. ;-]
Actually, I think containers are the least needed application domain of this feature. For one, it usually only saves a single template parameter about which I prefer to be explicitly anyway. And second, I'd guess that most containers are defined in contexts, where they are not directly filled with elements (e.g. as class members, function parameters/ return types or before a loop which will fill it iteratively.
AFAIK, GCC C++ ABI is not compatible with MSVC ABI, plus it doesn't implement windows exception handling (SEH). Has something changed in the meantime? But now that you've mentioned cross-compilation, I might give clang a try when I get the time.
&gt; On the negative side, I use Unison for file sync in Linux, and the lack of proper ssh in the Windows version makes Unison on that platform pretty much useless. "Proper ssh" is called WinRM on Windows and is fully documented: https://msdn.microsoft.com/en-us/library/aa384426(v=vs.85).aspx Unison is open-source, so there's your opportunity to contribute something to an open-source project ;) 
I find your lack of imagination disturbing
&gt; demonstrably better than Windows' kernel Demonstrably... how? It still doesn't have a decent asynchronous IO, os-level exceptions are delivered through the abomination called "signals" (as compared to structured exception handling), tracing and performance monitoring are an afterthought, etc...
Very good point, I didn't think of that one :)
&gt; I think this is off-topic, actually. Why do I care that it's written in C++? &gt; This doesn't help me as a C++ programmer. Well, it's an open source C++ project with ~100kLOC that uses modern C++ to write a compiler that goes beyond the level of "toy project". The author also comments on his experience using C++ to write a compiler in that sub. Not many people choose C++ as their language to write a compiler nowadays unless you are in the business of writing C++ compilers. And the major intent of the project is breaking trusting-trust attacks which is also relevant. Is there a non C++ compiler that can recompile any of the major C++ compilers? I found this interesting. Anyways, people post here all the time about their own C++ projects. If this is where you want to set the bar, all those "raytracers, window process managers, ..." posts here have a chance. None of them helps me as a C++ programmer either, and the only reason they are here is that they are written in C++. Since those posts seem to be allowed, this does look like a double bar to me.
That's kind of the point. One uses this to compile a rust compiler that then recompiles itself, breaking trusting trust attacks.
It's be valid if var replaced auto. But a "constant variable" doesn't make a lot of sense. Anyway, I agree, auto &gt; var because auto actually makes sense. Edit: oh shit, I see. I forgot the identifier. Woops.
Thanks for having a closer look. Afaik the fundamental limitation of a `make_array` that I hit in the past is that you cannot forward a braced-init-list. Maybe universal references could deduce a `std::initializer_list` if all elements in the braced-init-list are of the same type (as in this example), but even then you couldn't use them to initialize POD members of the array. This is one reason I'd really like to see the ability to create a parameter pack of a fixed type. The best I could come up with in the past are two functions: template&lt;class T, size_t N&gt; std::array&lt;T,N&gt; make(const T(&amp;p)[N]) { return {{p[0],p[1],p[2],p[3],p[4], ...}}; // &lt;-- in real code this requires another helper function } template&lt;class ... T&gt; std::array&lt;std::common_type&lt;T...&gt;,sizeof...(T)&gt; make(T&amp;&amp; ... t) { return {{t...}}; } where the first one woul to be called like this: ` make&lt;A&gt;({{1,3},{1,4}})`
How is this achieved? There has to be some memory barrier, otherwise other threads could see stale values.
Interesting. Have you verified, that there is actually dynamic allocation going on? I haven't looked into the implementation of std:function, but my guess would be that the performance difference is actually due to some other overhead of std::function. E.g. maybe it is easier for the compiler to "devirtualize" the call through your "SmallFun" than through std::function.
Hello, I just wanted to say that I read your series, and it was helpful :) Some nice features are coming ! I didn't read the book tho.
&gt; There are a lot of resources about how to implement it correctly in C++, and in particular a whole section in Herb Sutter’s Exceptional C++ (items 26 to 30) that gets into great details. &gt; There is one thing that I’ve found a bit less documented though: how to implement the pimpl idiom with a smart pointer (although excellent and still relevant today, Exceptional C++ was published before smart pointers came into the standard). [GotW #100: Compilation Firewalls](https://herbsutter.com/gotw/_100/) and [its followup](https://herbsutter.com/gotw/_101/) were posted in 2011... &gt;_&gt;
It always amazes me how different the expectations about how the mythical average programmer is using c++ are. I just would like to point out that specifying the value type of a container is a far cry from having to understand and being able to write templates yourself, let alone tmp. So I would at least question your statement, but I have no empirical evidence supporting this assumption. Afaik the main advantage comes from making most make_&lt;type&gt; functions obsolete and simplifying usage of scope guards (e.g. std::lock_guard).
&gt; Discussions, articles, and news about the C++ programming language or **programming in C++**. 
This is more an article on "how to use smart pointers with forward declared classes"
Of course, that's why I couldn't get it to compile. Your syntax is equivalent to using `std::experimental::to_array()`, which I think is very similar to your own function. One of the example uses here: https://gist.github.com/lichray/6034753 Is this: `auto a7 = to_array&lt;std::pair&lt;int, float&gt;&gt;( { { 3, .0f }, { 4, .1f }, { 4, .1e23f } });` Which I think you'll agree does the job. This is the other code snippet which I mentioned does not compile with GCC at the moment, which misled me into thinking the make_array method might be buggy as well. 
&gt; you compile exactly what you typed. In the case of Qt you have moc, the code you typed is pre-processed and then compiled. Standard C++ has a preprocessor too though... so "what you see" is not, in fact, what is compiled in C/C++, whether you use qt moc or not. Using CMake moc is also painless, since CMake can handle it automatically
Oh, that's another valid point.
That we need/use the pimpl idiom is to me a (small) sign of a weak language/tooling. I mean, this is a kind of a work around, right? A well designed language/tools should not need workarounds.
Well said. Therefore if you are interested to do GUI programming in standard C++ for the desktop, you are at least 2 decades behind in comparison to other offerings. It doesn't matter if you are going to use Modern C++ or not, you will be ancient anyway. People have noticed and they use JavaScript in Electron, Qt, etc.
Very poor indeed... Cutting compilation times should not be a driver to change a design, especially where it makes it less readable and more incoherent.
Too much Fentanyl?
I'm guessing you've never worked on a large C++ project? Compile times can be monstrous if left unchecked. My workstation has 32GB ram, 40 cores at 3.2GHz and a 980Ti, and my main work project takes just shy of 40 minutes to build from clean. Multiply this by 100 developers, and suddenly you have an incentive to optimise for compile time in your design.
Wouldn't a (yet-to-be-standardised) `value_ptr` or a pointer that takes its copy/movability from the pointed-to type be a better choice for pimpl? Using `unique_ptr` means you have to manually implement copy construction even when it's otherwise unnecessary.
&gt; I just would like to point out that specifying the value type of a container is a far cry from having to understand and being able to write templates yourself I was talking about convenience, I know 99% of C++ developers know to use vector and set...
Well, maybe modules will fix this at some point? The upcoming version for C++20 will not as I understand it, but maybe future ones could.
C != C++ Also, the link submitted just goes to a (currently empty) discussion board. (Edit: in terms of order of operations and values, it is but the languages are different) 
You can also use a private scopped class: `class Foo { struct Impl; std::unique_ptr&lt;Impl&gt; _impl; }; struct Foo::Impl { // foo };` 
/r/C_Programming/
If you're NOT using `unique_ptr` for pimpl you're doing it wrong. (Assuming the object is non-copyable)
IMHO it's always been a flaw in the language that private data has to be visible in the header. It breaks the separation of interface and implementation which is a key development principle, not only in OO. 
I would have suggested the same change. If there is no reason for clients to know there is an `Engine` class, then there is no reason for clients to know there is a FridgeImpl class either (even if it's just a forward declaration).
In my experience, classes that you need to use pImpl for are generally singletons or large objects you rarely/never want to copy. But you're right, copyable pImpl classes would want to use something like that. 
Please do not do this unless you keep a boost-free version available and up-to-date (like asio). Boost is a taboo in many cases.
Private data impacts the size of the object, which needs to be known by owners of the object to allocate the correct amount of stack space. You could avoid this requirement by accessing everything through a pointer to dynamic memory (which is what pimpl does) but this is c++ so that feature needs to be opt in. 
There would be various ways the language could solve this problem without requiring pImpl or dynamic memory use.
How? The calling object needs to know the size of the created object when the calling object creates it in the caller's stack frame. I admit I am not familiar with the fine details of how all this works, but with my rudimentary understanding it doesn't seem possible without incurring some extra overhead when creating objects on the stack.
I'm not sure why you keep talking about "stack". The size must be known for any creation of an object, and many other situations too. There could be a mechanism added to the language for the size (and any other relevant properties) to be accessible without exposing the detail of the private members.
I don't understand. The size of an object needs to be a public attribute and how else do you expose that ?
Name even one then. Other languages solve this problem by using dynamic memory.
This is just false plain and simple. unique_ptr doesn't provide binary compatibility so if you're using pimpl to provide a stable binary compatible shared library then you can not rely or use unique_ptr.
&gt; A well designed language/tools should not need workarounds. I wouldn't call it a workaround, since pimpl is not a 100% win... you're trading compile speed for the heap allocation/pointer indirection. C++ gives you the flexibility to choose either.
hi, could you explain how unique ptr doesn't provide binary compatibility?
&gt; Private data impacts the size of the object You could implement `sizeof()` in a way analogous to the virtual function table (a compiler-managed function pointer). It would require extensions to the language but it isn't impossible (and could be an opt-in feature so if you don't need it, you don't pay for it). Instantiating such objects on the stack could be handled in a way similar to VLAs in C. That said, my guess is the standards committee would probably reject such an extension to the language. EDIT: It just occurred to me that infinite `sizeof()` loops would be possible. Definitely would be rejected.
Srsly?
People have been linking shit questions from this shit site recently. There was one earlier that was something like "what is the most complex line of c code you have ever seen" which has been deleted.
Well, there's bad, but this is egregiously bad. Doesn't even answer the question (gives an if-else, not an else-if) and then essentially tells the reader to bugger off and use Google/RTFM! Of course, if you're making money out of the outrage-energy of people using your site, this is one way to make a fortune.
Technically, clients know about it either way, since the declaration is still visible in the header. Private nesting just makes it clear that it's none of their business.
Just as important to me as copy/movability is const correctness. With a raw pointer or `unique_ptr` PIMPL implementation, the compiler happily lets `const` methods in `Fridge` call non-`const` methods in `FridgeImpl`, meaning you must do all const correctness checks yourself. A `value_ptr` that implemented proper `const` propagation would be a major boon here.
I dont know why this comment was downvoted. Was there anything in this commemt wrong?
What you've described is dynamic memory allocation.
Effective Modern C++ has it too.
Object's user has to know object's size. If it depends on other objects' sizes, it has to know them too. Some of them can be templates, with possible specializations, etc. You basically totally need all that "knowledge" in the included headers for it to work. Maybe not "all" of it, only classes, class templates and specializations, without functions and their implementations. But would or make a difference to separate them somehow? 
... allocated (potentially) on the stack.
Compiler has to know stack size. Why would you need heap otherwise?
Strictly speaking, it could be done, but it would be ugly and awful. Something like this (syntax might need tweaking): // in Foo.h #structsize(16) struct Foo { uint64_t a; } // in Foo.cpp struct FooImpl : structsize_impl Foo { private: uint64_t b; } Stuff like pragma pack already impacts struct sizing, so there is already precedent for using preprocessor annotations in this manner.
Also http://en.cppreference.com/w/cpp/language/pimpl
&gt; Why would you need heap otherwise? For objects that live beyond the lifespan of the function that created them? Stack allocations are dynamically adjustable. C's VLAs depend on it being so. Size information is not required at compilation time -- it's just more efficient if it is known.
You're right in this. Although sizeof is very often used in compile time and I can't imagine not having it. 
That requires you to pay attention to all CVEs. Maybe that works for you, but it doesn't for the vast majority of users.
In a dev. cycle I never build from clean. Heck, I very rarely, if ever, build all. Why do you do it? Is your large project **one** single thing?!
C legacy, as usual.
Are you sure? Any sane implementation will consist of a single pointer - that is very unlikely to change. The member function implementations could change, but if you use it for the pimpl, then all instantiations will happen in the implementation file and as this will be the only instance of a unique_ptr of the impl object in the whole program, you are not in danger of odr violations. 
Yes, it does the job and is way more verbose than native arrays :( I know, c++ can't throw backwards compatibility out of the window (espeicially not for such minor benefits), but that doesn't stop me from dreaming of a better world ...
Sorry, I misinterpreted your sentence about &gt;[...] since most users do not really deal with huge amount of other templated structs/classes. You where saying that most users don't use other templates, so they don't care how the feature would affect other classes right? You might be right. Although, as I said in another post, in the code bases I've been dealing with so far, there are actually very few situations where you could use this feature on containers. But the code I've seen is of course only a tiny drop of water in the ocean that is the total amount of c++ code out there. 
Short response - it's not one single thing but there are issues like multiple (dozens) of unnecessary includes, circular dependencies in projects, slow codegen tools, lots of templates in library code. We check binary artefacts into source control for artists (I work in gamedev), and our build system craps out every time these get updated, and forces a full rebuild. The codegen tool that we have is a bit trigger happy and ends up updating headers that are included _everywhere_ (whether they need to be or not). - which also triggers a full rebuild. Sometimes the wind blows the wrong direction and you have to do a full rebuild. Don't get me wrong, it's not good, but it's the reality of what people deal with every day.
still dynamic
1. For faster switching don't use exclusive full screen. 2. Create two windows: one boderless, unmovable, occupying all the screen, the other window with borders and standard window controls. 3. To switch just hide one window, show the other and set the directX window handle to the visible window. 
GLFW is a very good library for that kind of things. Also, it's multiplatform. I'd suggest you to stay away from platform specific code in this particular case, unless you have a very compelling reason.
GLFW is for OpenGL and I'm learning (or at least trying to learn) Direct3D right now
Interesting, I'll try it!
I don't use `auto` either. But when I start typing a return type as something like `typename some_template_type&lt;std::remove_reference&lt;T&gt; ... blah blah yada yada` - screw it - `auto`!
This is common across all platforms - and Windows is a lot easier than Linux, in my experience. The C++ standard does not care for graphics, and leaves all parts of it to the operating system. The general suggestion is to go with a third-party library, such as Qt or SDL2. Graphics programming is hard, often badly documented, and often very low level (or C-like, if you will). If you want to implement this yourself, what you want to do is build the library for your own usage and *keep the platform specific code super far away from your actual use*. For example, I have a small game engine I am working on and for windows, I have a `WinWindow` class, and a `XWindow` class. Both of these classes implement an interface `BaseWindow`. These two classes allow me to use a similar interface for create and set up the core of the window - get a window handle, set styles, initial sizes, deal with message pumps, etc. I then wrap this in a further class, `WindowImpl`, which uses my own internal API to interact with this window. This `WindowImpl` class only knows about the interface, and such any new functionality has to (1) be added to the interface and (2) be implemented in the platform code. So for example, a completely made up example from memory: //SettingsManager.cpp if (m_settings.get&lt;GraphicsSettings&gt;().isFullscreen() &amp;&amp; !WindowImpl::get()-&gt;isFullscreen()) { WindowImpl::get()-&gt;toggleFullscreen(); } //WindowImpl.cpp // This implements all business logic around toggling a window size bool WindowImpl::toggleFullscreen() { if (!m_window-&gt;hasCapabilities(WindowCapabilities::Fullscreen)) return false; if (!m_window-&gt;isFullscreen()) { m_window-&gt;setFullscreen(); } else { m_window-&gt;setFloating(m_resizable); } return true; } //WinWindow.cpp bool WinWindow::setFullscreen() { LONG Style = GetWindowLong( m_hwnd, GWL_STYLE); style &amp;= ~WS_BORDER; style &amp;= ~WS_DLGFRAME; style &amp;= ~WS_THICKFRAME; // Probably want some extended styles here too SetWindowLong(m_hwnd, GWL_STYLE, style | WS_POPUP); ShowWindow(m_hwnd, SW_SHOWMAXIMIZED); } Doing it this way forces you to be very strict about containing your platform code AND you can easily test and version control it.
I've been always doing all the window stuff in WinMain, since I need only one of those so making a whole class for it seems kinda stupid for me. Plus I need to also do lots of other stuff with the window for Direct3D. Many times I've tried to make such a window class and always ended up with a mess...
Note that the problem is not "allow splitting classes between headers" but rather the problem is "don't make it necessary to split 'headers' in the first place." Which most other languages do via a proper module system that avoids the transitive-dependency problems of C++ headers, which is almost the only reason any uses PIMPL in the first place. That said, if you are specifically looking for a solution to splitting 'headers' in other languages, this is easily solved and has been in other languages via partial modules and partial classes, allowing a class's full definition to be spread across multiple files and assembled at compile time into a static complete unit at the module boundary; consumers of the class can then statically know the size of the class.
.pptx? I'll pass...
You could equally argue that any sane implementation of iterators would consist of a single pointer, and yet there is Microsoft with their debug iterators. 
Fair point. Although I really don't see what additional members you'd want to add to a unique_ptr, even in debug mode. 
What format do u suggest, if it contains animations? From my point of view, this works on windows and os x, and it worked fine in default libreoffice in ubuntu Edit: I tried flattening it to a pdf using a special method, see below. It *mostly* worked. Link here: http://chrisbeck.co/strict_variant_static.pdf
I'm interested but I can't open this on my android tablet. Is there a PDF or HTML version?
I think you're approaching this lacking some core concepts. You very rarely need to mix your rendering code with your window code, because they are (for the major part) completely separated. I primarily do OpenGL, but from my experience you need the window handle when setting up the rendering context and chain. And you definitely do not need to put your rendering code together with your window code. Furthermore, using a class only once is not necessarily a bad design. Almost all major programs I've worked on have had some things that there is only one of - be it a window, a WebSocket, a database connection or something else. Classes are not about code reuse, it's about separating responsibilities and **abstracting** code. By abstracting, I mean that for someone to consume the `setFullscreen()` method of my `WinWindow` class, they need to know nothing about the Win32 API. As a counterexample, putting a lot of code in the WinMain function is a clear example of faulty design because it is likely far too long and does too many things. If all you need is a window and toggling the size, that's three functions and a `HWnd`. But you want to deal with message pumps, and perhaps resizing, and always-on-top, and borderless, and... I agree that it is hard, but if you back down from the challenge you cannot become a better developer. You don't need to get it right from the beginning. But I assure you, WHEN you get it right it will feel like magic when you can bash out hundreds of lines of code without giving a damn about what Windows thinks about using `WS_THICKFRAME` with `WS_OVERLAPPEDWINDOW`, or how WinSock2 works, or some other thing Microsoft managed to make really hard.
Anything that doesn't require proprietary file formats with possible malicious scripts like: https://gitpitch.com/ ? 
Are you telling him his name sucks? :O
Yeah the size needs to be public but the number and types of variables that make up that size do not need to be. 
`unique_ptr` just wraps a pointer, it doesn't have any extra storage or alignment requirements. 
Brevity is not a strong enough argument to introduce your proposed completely inconsistent and non backward compatible syntax. "Run " is a NTBS (null terminated byte string) it does not support operator overloading.
&gt; What format do u suggest, if it contains animations? I honestly find any kind of animations in slides quite unprofessional.
Ok, I tried making a pdf version here: http://chrisbeck.co/strict_variant_static.pdf I did it using this guy's VB macro: http://neilmitchell.blogspot.com/2007/11/creating-pdf-from-powerpoint-with.html It's better than the default PDF export, and a different free tool that I tried. But it still mangles the animations somewhat. I think it should mostly be okay, but it might be harder to follow in the animation-heavy part. It's like 90% good.
Admittedly I've never tried to use GLFW with DirectX, but I see no reason why it couldn't be used. GLFW to my knowledge doesn't require GL. There's also SDL, which is also quite popular for this sort of thing.
So, I initially wrote the slides using reveal.js, someone posted slides on reddit earlier using that format so I took a look at it. https://github.com/hakimel/reveal.js/ But I also really wanted to have animations, and I don't really know javascript or this framework. I got my slides looking quite nice in this quickly, but I realized after looking at it for 15 minutes that I could not place any upper bound on how long it would take me to make animations like I wanted in this system, so I decided to rewrite in powerpoint. (Since I used that since I was like a kid.) I was really happy with reveal.js, it would be great for a short talk with some code, unless you want to have animations. I thought the animations had the potential to make it really easy to follow, and I didn't really know the audience beforehand so it seemed like a safe move.